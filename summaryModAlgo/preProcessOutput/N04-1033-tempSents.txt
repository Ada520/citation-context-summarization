4	we use a state-of-the-art phrase-based translation system as described in . 
2	we experimented with two levels of distortion: monotonic, where the phrasal alignment is monotonic and limited distortion, where only adjacent phrases are allowed to exchange positions . 
19	several strategies to compute these probabilities have been proposed , but none of them takes into account the fact that, when it comes to translation, many different inflected forms of words share the same translation. 
14	we use a phrase-based translation approach as described in . 
15	as described above, and use two different variants of glass-box smoothing over the phrasetable, and combine the resulting estimates with pure relativefrequency ones in a loglinear model. 
18	 describe a noisy-orù combination: p = 1‚àíp ‚âà 1‚àí Àúiproductdisplay i=1 ) where ¬Øsj is the probability that sj is not in the translation of Àút, and p is a lexical probability. 
8	for the confidence measures which will be introduced in section 5, we use a state-of-the-art phrasebased approach as described in . 
21	we define the source and target projection of a hypothesis h by the proj operator which collects in order the words of a hypothesis along one language: projf = braceleftbig fp : p‚ààuniontextui=1{jin}n‚àà bracerightbig proje = braceleftbig ep : p‚ààuniontextui=1{lim}m‚àà bracerightbig if we denote by hf the set of hypotheses that have f as a source projection ‚â° f}), then our translation engine seeks ÀÜe = proje where: ÀÜh = argmax h‚ààhf s the function we seek to maximize s is a loglinear combination of 9 components, and might be better understood as the numerator of a maximum entropy model popular in several statistical mt systems . 
20	more details about the baseline system can be found in . 
16	this is the traditional approach for glass-box smoothing . 
5	there is, however, a large body of work using morphological analysis to define cluster-based translation models similar to ours but in a supervised manner , . 
11	we use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. 
3	finally, we use pos features to parameterize a distortion model in a limited distortion decoder . 
6	our approach to phrase-table smoothing contrasts to previous work in which smoothed phrase probabilities are constructed from word-pair probabilities and combined in a log-linear model with an unsmoothed phrase-table. 
13	we extended the monotone search algorithm from such that reorderings are possible. 
22	recently, various works have improved the quality of statistical machine translation systems by using phrase translation . 
23	more details about the baseline system can be found in . 
17	 obtain p from smoothed relative-frequency estimates in a wordaligned corpus. 
1	we thus propose to adapt the statistical machine translation model for sms text normalization. 
7	nowadays, most of the state-of-the-art smt systems are based on bilingual phrases . 
12	the approach presented here has some resemblance to the bracketing transduction grammars of , which have been applied to a phrase-based machine translation system in . 
9	today's statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see . 
10	above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content , or not at all . 
