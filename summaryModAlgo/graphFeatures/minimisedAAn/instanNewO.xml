<paper>
<cited id="O0">
<title id=" N04-1032.xml">shallow semantic parsing of chinese </title>
<section> currently at department of linguistics, stanford university..  </section>
<citcontext>
<prevsection>
<prevsent>2 semantic annotation and the corpus.
</prevsent>
<prevsent>work on semantic parsing in english has generally related on the propbank, portion of the penn treebank in which the arguments of each verb are annotated with semantic roles.
</prevsent>
</prevsection>
<citsent citstr=" W03-1707 ">
although project to produce chinese propbank is underway (xue and palmer 2003), <papid> W03-1707 </papid>this data is not expected to be available for another year.</citsent>
<aftsection>
<nextsent>for these experiments, we therefore hand-labeled small corpus following the penn chinese propbank labeling guidelines (xue, 2002).
</nextsent>
<nextsent>in this section, we first describe the semantic roles we used in the annotation and then introduce the data for our experiments.
</nextsent>
<nextsent>2.1 semantic roles.
</nextsent>
<nextsent>semantic roles in the english (kingsbury et al 2002) and chinese (xue 2002) prop banks are grouped into two major types: (1) arguments, which represent central participants in an event.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1">
<title id=" N04-1032.xml">shallow semantic parsing of chinese </title>
<section> semantic parsing.  </section>
<citcontext>
<prevsection>
<prevsent>table 2 list of verbs for experiments verb # of senses arg number freq ??/set up 1 2 106 ??/emerge 1 1 80 ??/publish 1 2 113 ??/give 2 3/2 41 ??/build into 2 2/3 113 ??/enter 1 2 123 ??/take place 1 2 230 ??/pass 3 2 75 ??/hope 1 2 90 ??/increase 1 2 167
</prevsent>
<prevsent>3.1 architecture and classifier.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
following the architecture of earlier semantic parsers like gildea and jurafsky (2002), <papid> J02-3001 </papid>we treat the semantic parsing task as 1-of-n classification problem.</citsent>
<aftsection>
<nextsent>for each (non-aux/non-copula) verb in each sentence, our classifier examines each node in the syntactic parse tree for the sentence and assigns it semantic role label.
</nextsent>
<nextsent>most constituents are not arguments of the verb, and so the most common label is null.
</nextsent>
<nextsent>our architecture is based on support vector machine classifier, following pradhan et al  (2003).
</nextsent>
<nextsent>since svms are binary classifiers, we represent this 1-of-19 classification problem (18 roles plus null) by training 19 binary one-versus-all classifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3">
<title id=" N04-1032.xml">shallow semantic parsing of chinese </title>
<section> semantic parsing.  </section>
<citcontext>
<prevsection>
<prevsent>our architecture is based on support vector machine classifier, following pradhan et al  (2003).
</prevsent>
<prevsent>since svms are binary classifiers, we represent this 1-of-19 classification problem (18 roles plus null) by training 19 binary one-versus-all classifiers.
</prevsent>
</prevsection>
<citsent citstr=" W00-0730 ">
following pradhan et al  (2003), we used tinysvm along with yamcha (kudo and matsumoto 2000, <papid> W00-0730 </papid>2001) as the svm training and test software.</citsent>
<aftsection>
<nextsent>the system uses poly nominal kernel with degree 2; the cost per unit violation of the margin, c=1; tolerance of the termination criterion e=0.001.
</nextsent>
<nextsent>3.2 features.
</nextsent>
<nextsent>the literature on semantic parsing in english relies on number of features extracted from the input sentence and its parse.
</nextsent>
<nextsent>these include the constituents syntactic phrase type, head word, and governing category, the syntactic path in the parse tree connecting it to the verb, whether the constitutent is before or after the verb, the subcategorization bias of the verb, and the voice (active/passive) of the verb.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O7">
<title id=" N04-1032.xml">shallow semantic parsing of chinese </title>
<section> semantic parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in paris take place de intl olympic conf.
</prevsent>
<prevsent>the international olympic conference held in paris?
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
figure 1 example of deconstruction since the governing category information is encoded in the path feature, it may be redundant; indeed this redundancy might explain why the governing category feature was used in gildea &amp; jurafsky(2002) <papid> J02-3001 </papid>but not in gildea and palmer(2002).<papid> P02-1031 </papid></citsent>
<aftsection>
<nextsent>since the de?
</nextsent>
<nextsent>construction caused us to modify the feature for chinese, we conducted several experiments to test whether the governing category feature is useful or whether it is redundant with the path and position features.
</nextsent>
<nextsent>using the paradigm to be described in section 3.4, we found small improvement using governing category, and so we include it in our model.
</nextsent>
<nextsent>3.2.4 head word and its part of speech.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O8">
<title id=" N04-1032.xml">shallow semantic parsing of chinese </title>
<section> semantic parsing.  </section>
<citcontext>
<prevsection>
<prevsent>?/statement  occurs 19 times, 18 for  ??/release; publish  and one for  ??/hope .
</prevsent>
<prevsent>these statistics emphasize the key role of the lexicalized head word feature in capturing the collocation between verbs and their arguments.
</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
due to the sparsity of the head word feature, we also use the part-of-speech of the head word, following surdeanu et al  (2003).<papid> P03-1002 </papid></citsent>
<aftsection>
<nextsent>for example, 7?
</nextsent>
<nextsent>26?/july 26?
</nextsent>
<nextsent>may not be seen in the training, but its pos, nt(temporal noun) , is good indicator that it is temporal.
</nextsent>
<nextsent>3.2.5 voice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O9">
<title id=" N04-1032.xml">shallow semantic parsing of chinese </title>
<section> using automatic parses.  </section>
<citcontext>
<prevsection>
<prevsent>we first describe how we ported the collins parser to chinese and then present the results of the semantic parser with features drawn from the automatic parses.
</prevsent>
<prevsent>4.1 the collins parser for chinese.
</prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
the collins parser is state-of-the-art statistical parser that has high performance on english (collins, 1999) and czech(collins et al  1999).<papid> P99-1065 </papid></citsent>
<aftsection>
<nextsent>there have been attempts in applying other algorithms in chinese parsing (bikel and chiang, 2000; <papid> W00-1201 </papid>chiang and bikel 2002; <papid> C02-1126 </papid>levy and manning 2003), <papid> P03-1056 </papid>but there has been no report on applying the collins parser on chinese.</nextsent>
<nextsent>the collins parser is lexicalized statistical parser based on head-driven extended pcfg model; thus the choice of head node is crucial to the success of the parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O10">
<title id=" N04-1032.xml">shallow semantic parsing of chinese </title>
<section> using automatic parses.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 the collins parser for chinese.
</prevsent>
<prevsent>the collins parser is state-of-the-art statistical parser that has high performance on english (collins, 1999) and czech(collins et al  1999).<papid> P99-1065 </papid></prevsent>
</prevsection>
<citsent citstr=" W00-1201 ">
there have been attempts in applying other algorithms in chinese parsing (bikel and chiang, 2000; <papid> W00-1201 </papid>chiang and bikel 2002; <papid> C02-1126 </papid>levy and manning 2003), <papid> P03-1056 </papid>but there has been no report on applying the collins parser on chinese.</citsent>
<aftsection>
<nextsent>the collins parser is lexicalized statistical parser based on head-driven extended pcfg model; thus the choice of head node is crucial to the success of the parser.
</nextsent>
<nextsent>we analyzed the penn chinese treebank data and worked out head rules for the chinese treebank grammar (we were unable to find any published head rules for chinese in the literature).
</nextsent>
<nextsent>there are two major differences in the head rules between english and chinese.
</nextsent>
<nextsent>first, np heads in chinese are rigidly rightmost, that is to say, no modifiers of an np can follow the head.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O11">
<title id=" N04-1032.xml">shallow semantic parsing of chinese </title>
<section> using automatic parses.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 the collins parser for chinese.
</prevsent>
<prevsent>the collins parser is state-of-the-art statistical parser that has high performance on english (collins, 1999) and czech(collins et al  1999).<papid> P99-1065 </papid></prevsent>
</prevsection>
<citsent citstr=" C02-1126 ">
there have been attempts in applying other algorithms in chinese parsing (bikel and chiang, 2000; <papid> W00-1201 </papid>chiang and bikel 2002; <papid> C02-1126 </papid>levy and manning 2003), <papid> P03-1056 </papid>but there has been no report on applying the collins parser on chinese.</citsent>
<aftsection>
<nextsent>the collins parser is lexicalized statistical parser based on head-driven extended pcfg model; thus the choice of head node is crucial to the success of the parser.
</nextsent>
<nextsent>we analyzed the penn chinese treebank data and worked out head rules for the chinese treebank grammar (we were unable to find any published head rules for chinese in the literature).
</nextsent>
<nextsent>there are two major differences in the head rules between english and chinese.
</nextsent>
<nextsent>first, np heads in chinese are rigidly rightmost, that is to say, no modifiers of an np can follow the head.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O12">
<title id=" N04-1032.xml">shallow semantic parsing of chinese </title>
<section> using automatic parses.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 the collins parser for chinese.
</prevsent>
<prevsent>the collins parser is state-of-the-art statistical parser that has high performance on english (collins, 1999) and czech(collins et al  1999).<papid> P99-1065 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1056 ">
there have been attempts in applying other algorithms in chinese parsing (bikel and chiang, 2000; <papid> W00-1201 </papid>chiang and bikel 2002; <papid> C02-1126 </papid>levy and manning 2003), <papid> P03-1056 </papid>but there has been no report on applying the collins parser on chinese.</citsent>
<aftsection>
<nextsent>the collins parser is lexicalized statistical parser based on head-driven extended pcfg model; thus the choice of head node is crucial to the success of the parser.
</nextsent>
<nextsent>we analyzed the penn chinese treebank data and worked out head rules for the chinese treebank grammar (we were unable to find any published head rules for chinese in the literature).
</nextsent>
<nextsent>there are two major differences in the head rules between english and chinese.
</nextsent>
<nextsent>first, np heads in chinese are rigidly rightmost, that is to say, no modifiers of an np can follow the head.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O16">
<title id=" N04-1032.xml">shallow semantic parsing of chinese </title>
<section> comparison with english.  </section>
<citcontext>
<prevsection>
<prevsent>the results are shown in table 9.
</prevsent>
<prevsent>table 9 result for semantic parsing using automatic syntactic parses p(%) r(%) f(%) 110 sentences 86.0 70.8 77.6 113 sentences 86.0 69.2 76.7 compared to the f-score using hand-corrected syntactic parses from the treebank, using automatic parses decreases the f-score by 6.4.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
recent research on english semantic parsing has achieved quite good results by relying on the large amounts of training data available in the propbank and framenet (baker et al  1998) <papid> P98-1013 </papid>databases.</citsent>
<aftsection>
<nextsent>but in extending the semantic parsing approach to other languages, we are unlikely to always have large datasets available.
</nextsent>
<nextsent>thus it is crucial to understand how small amounts of data affect semantic parsing.
</nextsent>
<nextsent>at the same time, there have been no comparisons between english and other languages with respect to semantic parsing.
</nextsent>
<nextsent>it is thus not clear what language-specific issues may arise in general with the automatic mapping of syntactic structures to semantic relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O17">
<title id=" N01-1014.xml">identifying cognates by phonetic and semantic similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an example of cognate pair is french lait and spanish leche, both of which come from latin lacte.
</prevsent>
<prevsent>in other contexts, including this paper, the term is often used more loosely, denoting words in different languages that are similar in form and meaning, without making distinction between borrowed and genetically related words; for example, english sprint and the japanese borrowing supurinto are considered cognate, even though these two languages are unrelated.in historical linguistics, the identification of cog nates is component of two principal tasks of the field: establishing the relatedness of languages and reconstructing the histories of language families.
</prevsent>
</prevsection>
<citsent citstr=" P93-1001 ">
in corpus linguistics, cognates have been used for bi text alignment (simard et al , 1992; church, 1993; <papid> P93-1001 </papid>mcenery and oakes, 1996; melamed, 1999), <papid> J99-1003 </papid>andfor extracting lexico graphically interesting word pairs from multilingual corpora (brew and mckelvie, 1996).the task addressed in this paper can be formulated in two ways.</citsent>
<aftsection>
<nextsent>on the word level, given two words (lexemes) from different languages, the goal is to compute value that reflects the likelihood of the pair being cognate.
</nextsent>
<nextsent>i assume that each lexemeis given in phonetic notation, and that it is accompanied by one or more glosses that specify its meaning in meta language for which lexical resource is available (for example, english).
</nextsent>
<nextsent>on the language level, given two vocabulary lists representing two languages, the goal is to single out all pairs that appear to be cognate.
</nextsent>
<nextsent>tables 1 and 2 show sample entries from two typical vocabulary lists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O18">
<title id=" N01-1014.xml">identifying cognates by phonetic and semantic similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an example of cognate pair is french lait and spanish leche, both of which come from latin lacte.
</prevsent>
<prevsent>in other contexts, including this paper, the term is often used more loosely, denoting words in different languages that are similar in form and meaning, without making distinction between borrowed and genetically related words; for example, english sprint and the japanese borrowing supurinto are considered cognate, even though these two languages are unrelated.in historical linguistics, the identification of cog nates is component of two principal tasks of the field: establishing the relatedness of languages and reconstructing the histories of language families.
</prevsent>
</prevsection>
<citsent citstr=" J99-1003 ">
in corpus linguistics, cognates have been used for bi text alignment (simard et al , 1992; church, 1993; <papid> P93-1001 </papid>mcenery and oakes, 1996; melamed, 1999), <papid> J99-1003 </papid>andfor extracting lexico graphically interesting word pairs from multilingual corpora (brew and mckelvie, 1996).the task addressed in this paper can be formulated in two ways.</citsent>
<aftsection>
<nextsent>on the word level, given two words (lexemes) from different languages, the goal is to compute value that reflects the likelihood of the pair being cognate.
</nextsent>
<nextsent>i assume that each lexemeis given in phonetic notation, and that it is accompanied by one or more glosses that specify its meaning in meta language for which lexical resource is available (for example, english).
</nextsent>
<nextsent>on the language level, given two vocabulary lists representing two languages, the goal is to single out all pairs that appear to be cognate.
</nextsent>
<nextsent>tables 1 and 2 show sample entries from two typical vocabulary lists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O19">
<title id=" N01-1014.xml">identifying cognates by phonetic and semantic similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the correspondences inturn can be used to distinguish between genuine cog nates and borrowings or chance resemblances.
</prevsent>
<prevsent>my approach to the identification of cognates isbased on the assumption that, inspite of the inevitable dia chronic changes, cognates on average display higher semantic and phonetic similarity than aniskohocikan string of beads tied end to end asikan sock, stocking kamamakos butterfly kostacwin terror, fear misiyew large partridge, hen, fowl namehpin wild ginger napakihtak board tehtew green toad wayakeskw bark table 1: an excerpt from cree vocabulary list (hewson, 1999).
</prevsent>
</prevsection>
<citsent citstr=" A00-2038 ">
words that are unrelated.1 in this paper, presentcogit, cognate-identification system that combines aline (kondrak, 2000), <papid> A00-2038 </papid>feature-based algorithm for measuring phonetic similarity, with anovel procedure for estimating semantic similarity that employs keyword selection and wordnet.when tested on data from four native american languages, cogit was able to discover, on average, nearly 75% percent of cognates at 50% precision,without resorting to table of systematic sound correspondences.</citsent>
<aftsection>
<nextsent>the results show that large percentage of cognates can be detected automatically.
</nextsent>
<nextsent>to my knowledge, no previously proposed algo rithmic method is able to identify cognates directly in vocabulary lists.
</nextsent>
<nextsent>guys (1994) program cognate identifies probable letter correspondences between words and estimates how likely it is that the words are related.
</nextsent>
<nextsent>the algorithm has no semantic component, as the words are assumed to have already been matched by their meanings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O22">
<title id=" N01-1014.xml">identifying cognates by phonetic and semantic similarity </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>several contemporary algonquian languages.
</prevsent>
<prevsent>the proto-projections, generated using long-establishedsystematic sound correspondences, were then examined individually in order to select true cognates.the reconstruction engine?
</prevsent>
</prevsection>
<citsent citstr=" J94-3004 ">
of lowe and mazaudon (1994) <papid> J94-3004 </papid>uses similar strategy of generating proto-projections to establish cognate sets.</citsent>
<aftsection>
<nextsent>both 1the assumption was verified during the evaluation of my system (section 6).
</nextsent>
<nextsent>however, in the case of very remotely related languages, the difference may no longer be statistically significant (ringe, 1998).
</nextsent>
<nextsent>asikan dock, bridge anakaekkw bark kipaskosikan medicine to induce clotting kottacwin fear, alarm memkwan?
</nextsent>
<nextsent>butterfly misisse?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O28">
<title id=" N01-1014.xml">identifying cognates by phonetic and semantic similarity </title>
<section> semantic similarity.  </section>
<citcontext>
<prevsection>
<prevsent>and stone?;.
</prevsent>
<prevsent>2for different phonetic?
</prevsent>
</prevsection>
<citsent citstr=" W97-1102 ">
approach, based on binary artic ulatory features, see (nerbonne and heeringa, 1997).<papid> W97-1102 </papid></citsent>
<aftsection>
<nextsent>6.
</nextsent>
<nextsent>complements and adjuncts: stone?
</nextsent>
<nextsent>and stone.
</nextsent>
<nextsent>of peach?, island?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O30">
<title id=" N01-1014.xml">identifying cognates by phonetic and semantic similarity </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>the preprocessing of the glosses involves stop word removal and keyword selection.
</prevsent>
<prevsent>a simple heuristic is used for the latter: the preprocessing script marks as keywords all nouns apart from those that follow wh-word or preposition other thanof?.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
nouns are identified by part-of-speech tagger (brill, 1995), <papid> J95-4004 </papid>which is applied to glosses after pre pending them with the string it is a?.</citsent>
<aftsection>
<nextsent>checking and correcting the spelling of glosses is assumed to have been done beforehand.the phonetic module calculates phonetic similarity using either aline or straightforward method such as lcsr, dice, or truncation.
</nextsent>
<nextsent>the truncation coefficient is obtained by dividing the length of the common prefix by the average of the lengths of thetwo words being compared.
</nextsent>
<nextsent>the similarity score returned by aline is also normalized, so that it falls in the range ffi 0
</nextsent>
<nextsent>1  . the implementation of aline is described in (kondrak, 2000).<papid> A00-2038 </papid>for the calculation of wordnet-based semantic similarity score, initially used the length of the shortest path between synsets, measured in the num rank similarity level score coverage 1 gloss identity 1.00 .618 2 gloss synonymy 0.70 .020 3 keyword identity 0.50 .105 4 gloss hyponymy 0.50 .023 5 keyword synonymy 0.35 .012 6 keyword hyponymy 0.25 .021 7 gloss meronymy 0.10 .002 8 keyword meronymy 0.05 .000 9 none detected 0.00 .199 table 3: semantic similarity levels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O35">
<title id=" N04-4019.xml">speech graffiti vs natural language assessing the user experience </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>overall, they accounted for the six highest sg-ml word- and understanding-error rates and the six lowest sg-ml task completion rates: clearly not positive experience.
</prevsent>
<prevsent>an additional measure of habitability is grammaticality: how often do users speak within the speech graffiti grammar?
</prevsent>
</prevsection>
<citsent citstr=" W04-2315 ">
the six nl-ml-preferring users also had low grammaticality rates (tomko &amp; rosenfeld, 2004).<papid> W04-2315 </papid></citsent>
<aftsection>
<nextsent>these users have become motivator of future work: what can be done to make the interface work for them and others like them?
</nextsent>
<nextsent>(future studies will focus on broader population of adults.)
</nextsent>
<nextsent>how can we help users who are having severe difficulties with an interface learn how to use it better and faster?
</nextsent>
<nextsent>to improve the habitability of speech graffiti, we plan to explore allowing more natural language-esque interaction while retaining an application-portable structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O36">
<title id=" N07-1053.xml">a cascaded machine learning approach to interpreting temporal expressions </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>while our architecture is novel, we are not the firstto modularize timex annotation systems.
</prevsent>
<prevsent>even thoroughly rule-based systems (negri and marseglia,2004; saquete et al , 2002), separate temporal anchor tracking from the rest of the normalization process.
</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
the system of mani and wilson (2000) <papid> P00-1010 </papid>goes further in using separate sets of hand-crafted rules for recognition and normalization and in separating out several disambiguation tasks.</citsent>
<aftsection>
<nextsent>ahn et al  (2005b)decouple recognition from normalization even using machine learning for recognition and handle several disambiguation tasks separately.
</nextsent>
<nextsent>in none of these systems, though, are context-independent and context-dependent processing thoroughly separated, as here, and in all these systems, it is the rules that drive the proces singin both mani et al  and ahn et al systems, sets of rules are used to determine which timexes need to be disambiguated.
</nextsent>
<nextsent>systems that perform both recognition and normalization tend to take rule-based approach to recognition (mani and wilson, 2000; <papid> P00-1010 </papid>saquete et al ., 2002; schilder, 2004; negri and marseglia, 2004).</nextsent>
<nextsent>recognition-only systems are often based on machine learned classifiers (hacioglu et al , 2005; bethard and martin, 2006), <papid> W06-1618 </papid>although some do use finite-state methods (boguraev and ando, 2005).ahn et al  (2005a) find benefit to decoupling recognition from normalization, and since our goal is to build modular, trainable system, we take amachine-learning approach to recognition that is independent of our normalization components.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O39">
<title id=" N07-1053.xml">a cascaded machine learning approach to interpreting temporal expressions </title>
<section> component a: recognizing timexes.  </section>
<citcontext>
<prevsection>
<prevsent>in none of these systems, though, are context-independent and context-dependent processing thoroughly separated, as here, and in all these systems, it is the rules that drive the proces singin both mani et al  and ahn et al systems, sets of rules are used to determine which timexes need to be disambiguated.
</prevsent>
<prevsent>systems that perform both recognition and normalization tend to take rule-based approach to recognition (mani and wilson, 2000; <papid> P00-1010 </papid>saquete et al ., 2002; schilder, 2004; negri and marseglia, 2004).</prevsent>
</prevsection>
<citsent citstr=" W06-1618 ">
recognition-only systems are often based on machine learned classifiers (hacioglu et al , 2005; bethard and martin, 2006), <papid> W06-1618 </papid>although some do use finite-state methods (boguraev and ando, 2005).ahn et al  (2005a) find benefit to decoupling recognition from normalization, and since our goal is to build modular, trainable system, we take amachine-learning approach to recognition that is independent of our normalization components.</citsent>
<aftsection>
<nextsent>generally, machine learned timex recognition systems reduce the task of identifying timex phrase to one of classifying individual words by using (some variant of) b-i-o tagging, in which each word is tagged as (b)eginning, (i)nside, or (o)utsidea timex phrase.
</nextsent>
<nextsent>such tagging scheme is not inherently sensitive to syntactic constituency and not well-suited to identifying nested timexes (but cf.
</nextsent>
<nextsent>(hacioglu et al , 2005)).
</nextsent>
<nextsent>considering that syntactic parsers are readily available, we have explored several ways of leveraging parse information in recognition, although we describe here only the method we use for experiments later in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O40">
<title id=" N07-1053.xml">a cascaded machine learning approach to interpreting temporal expressions </title>
<section> component a: recognizing timexes.  </section>
<citcontext>
<prevsection>
<prevsent>we restrict classification to the following phrase types and lexical categories (based on (ferro et al , 2004, 5)): np, advp, adjp, nn, nnp, jj, cd, rb, and pp.2 in order to identify candidate phrases and to extract2we include pps despite the tides guidelines, which explicitly exclude temporal pps such as before thursday because of prepositional modifiers such as around and about.
</prevsent>
<prevsent>422 identification exact match prec rec prec rec text 0.912 0.786 0.844 0.850 0.732 0.787 doc 0.929 0.813 0.867 0.878 0.769 0.819 bro 0.973 0.891 0.930 0.905 0.829 0.865 bft 0.976 0.880 0.926 0.885 0.798 0.839 table 1: recognition results: identification.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
parse-based features, we parse the text elements of our documents with the charniak parser (char niak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>because of both parser and annotator errors, only 90.2% of the timexes in the training data align exactly with parse, which gives an estimated upper-bound on recall using this method.
</nextsent>
<nextsent>we use support vector machines for classification,in particular, the libsvm linear kernel implementation (chang and lin, 2001).
</nextsent>
<nextsent>the features we extract include character type patterns, lexical features such as weekday name and numeric year, context window of two words to the left, and several parse based features: the phrase type, the phrase head and initial word (and pos tag), and the dependency parent (and corresponding relation) of the head.
</nextsent>
<nextsent>as with all our experiments in this paper, we train on the tern training corpus and test on thetest corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O43">
<title id=" N07-1053.xml">a cascaded machine learning approach to interpreting temporal expressions </title>
<section> component c: semantic composition.  </section>
<citcontext>
<prevsection>
<prevsent>their error rate for this task is 27%, but since set of heuristics is first used to select just ambiguous timexes, this score cannot be compared to ours.
</prevsent>
<prevsent>the semantic composition module uses context independent, class-specific rules to compute for each timex an underspecified representationa typed feature structure that depends on the timexs semantic class (features include unit and value for durations, year, month, date, and referential class for points; cf.
</prevsent>
</prevsection>
<citsent citstr=" W06-0902 ">
(dale and mazur, 2006)).<papid> W06-0902 </papid></citsent>
<aftsection>
<nextsent>as the rules arenot responsible for identification or class or direction disambiguation, they are fewer in number and simpler than in other systems (cf.
</nextsent>
<nextsent>1000+ in (negriand marseglia, 2004)).
</nextsent>
<nextsent>each rule consists of an re pattern, which may refer to small lexicon of names,units, and numeric words, and is applied using custom transducer.
</nextsent>
<nextsent>in total, there are 89 rules; table 3 gives the distribution of rules and an example rule for each class.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O44">
<title id=" N07-1053.xml">a cascaded machine learning approach to interpreting temporal expressions </title>
<section> temporal anchors.  </section>
<citcontext>
<prevsection>
<prevsent>424 7.1 component e: temporal anchor tracking.
</prevsent>
<prevsent>since temporal anchors are not annotated in thetimex2 standard, our system uses simple heuristic method for temporal anchoring (cf.
</prevsent>
</prevsection>
<citsent citstr=" W97-0320 ">
(wiebe et al , 1997), <papid> W97-0320 </papid>who use more complex rule-based system for timex anchoring in scheduling dialogues).</citsent>
<aftsection>
<nextsent>since we distinguish deictic and anaphoric timexes during semantic composition, we use combination of twomethods: for deictic timexes, the document time stamp is used, and for (some) anaphoric timexes, the most recent point timex, if it is fine-grained enough,is used as the temporal anchor (otherwise, the document time stamp is used).
</nextsent>
<nextsent>because the documents in our corpora are short news texts, we actually treat anaphoric name-like points as deictic and use the most recent timex only for anaphoric offsets.
</nextsent>
<nextsent>7.2 component d: direction classification.
</nextsent>
<nextsent>the idea of separating direction classification from the remainder of the normalization task is not new.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O46">
<title id=" N04-4015.xml">morphological analysis for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the algorithm identifies morphemes to be merged or deleted in the morphologically rich language to induce the desired morphological and syntactic symmetry.
</prevsent>
<prevsent>the technique improves arabic-to-english translation qualities significantly when applied to ibm model 1 and phrase translation models trained on the training corpus size ranging from 3,500 to 3.3 million sentence pairs.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
translation of two languages with highly different morphological structures as exemplified by arabic and english poses challenge to successful implementation of statistical machine translation models (brown et al 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>rarely occurring inflected forms of stem in arabic often do not accurately translate due to the frequency imbalance with the corresponding translation word in english.
</nextsent>
<nextsent>so called word (separated by white space) in arabic often corresponds to more than one independent word in english, posing technical problem to the source channel models.
</nextsent>
<nextsent>in the english-arabic sentence alignment shown in figure 1, arabic word alahmr (written in buckwalter transliteration) is aligned to two english words the red?, and llmeardp to three english words of the opposition.?
</nextsent>
<nextsent>in this paper, we present technique to induce morphological and syntactic symmetry between two languages with different morphological structures for statistical translation quality improvement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O47">
<title id=" N04-4015.xml">morphological analysis for statistical machine translation </title>
<section> word segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>arabic-english sentence alignment after arabic morphological analysis is shown in figure 3, where the suffix is merged into their stems mwajh and meard.
</prevsent>
<prevsent>for phrase translation models, we apply additional morphological analysis induced from noun phrase parsing of arabic to accomplish syntactic as well as morphological symmetry between the two languages.
</prevsent>
</prevsection>
<citsent citstr=" P03-1051 ">
we pre-suppose segmentation of word into prefix(es)-stem-suffix(es), as described in (lee et al. 2003) <papid> P03-1051 </papid>the category prefix and suffix encompasses function words such as conjunction markers, prepositions, pronouns, determiners and all inflectional morphemes of the language.</citsent>
<aftsection>
<nextsent>if word token contains more than one prefix and/or suffix, we posit multiple prefixes/suffixes per stem.
</nextsent>
<nextsent>a sample word segmented arabic text is given below, where prefixes are marked with #, and suffixes with +.
</nextsent>
<nextsent>w# s# y# hl sa}q al# tjarb fy jagwar al# brazyly lwsyanw bwrty mkan ayrfayn fy al# sbaq gda al# ahd al*y s# y# kwn awly xtw +at +h fy ealm sbaq +at alfwrmwla
</nextsent>
<nextsent>morphological analysis identifies functional morphemes to be merged into meaning-bearing stems or to be deleted.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O48">
<title id=" N04-4015.xml">morphological analysis for statistical machine translation </title>
<section> morphological  analysis.  </section>
<citcontext>
<prevsection>
<prevsent>morpheme or word, i.e. no combination tag of the form det+noun, etc. probability into null tag is not the highest, merge the prefixi_tagik/suffixj_tagjk into its stem in the stemtaga context.
</prevsent>
<prevsent>merge/deletion analysis is applied to all prefixi_tagik/suffixj_tagjk occurring in the appropriate stem tag contexts in the training corpus (for translation model training) and new input text (for decoding).
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
3.2.2 phrase translation model for phrase translation models (och and ney 2002), <papid> P02-1038 </papid>we induce additional merge/deletion analysis on the basis of base noun phrase parsing of arabic.</citsent>
<aftsection>
<nextsent>one major asymmetry between arabic and english is caused by more frequent use of the determiner al# in arabic compared with its counterpart the in english.
</nextsent>
<nextsent>we apply al#-deletion to arabic noun phrases so that only the first occurrence of al# in noun phrase is retained.
</nextsent>
<nextsent>all instances of al# occurring before proper noun ? as in al# qds, whose literal translation is the jerusalem ? are also deleted.
</nextsent>
<nextsent>unlike the automatic induction of morphological analysis described in 3.2.1, al#-deletion analysis is manually induced.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O49">
<title id=" N04-4015.xml">morphological analysis for statistical machine translation </title>
<section> performance evaluations.  </section>
<citcontext>
<prevsection>
<prevsent>unlike the automatic induction of morphological analysis described in 3.2.1, al#-deletion analysis is manually induced.
</prevsent>
<prevsent>system performances are evaluated on ldc distributed multiple translation arabic part consisting of 1,043 segments derived from afp and xinhua newswires.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
translation qualities are measured by uncased bleu (papineni et al 2002) <papid> P02-1040 </papid>with 4 reference translations, sysids: ahb, ahc, ahd, ahe.</citsent>
<aftsection>
<nextsent>systems are developed from 4 different sizes of training corpora, 3.5k, 35k, 350k and 3.3m sentence pairs, as in table 1.
</nextsent>
<nextsent>the number in each cell indicates the number of sentence pairs in each genre (newswires, ummah, un corpus).4 genre 3.5k 35k 350k 3.3m news 1,000 1,000 9,238 12,002 ummah 500 1,000 13,027 13,027 un 2,000 33,000 327,735 3,270,200 table 1.
</nextsent>
<nextsent>training corpora specifications 4.1 ibm model 1.
</nextsent>
<nextsent>impact of morphological analysis on ibm model 1 is shown in table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O50">
<title id=" N04-4015.xml">morphological analysis for statistical machine translation </title>
<section> performance evaluations.  </section>
<citcontext>
<prevsection>
<prevsent>bleu scores under morph analysis?
</prevsent>
<prevsent>is obtained by model 1 training on arabic morphologically analyzed and english symbol tokenized parallel corpus and model 1 decoding on the arabic morphologically analyzed input text.5 4.2 phrase translation model.
</prevsent>
</prevsection>
<citsent citstr=" W03-1001 ">
impact of arabic morphological analysis on phrase translation model with monotone decoding (tillmann 2003), <papid> W03-1001 </papid>is shown in table 3.</citsent>
<aftsection>
<nextsent>corpus size baseline morph analysis 3.5k 0.17 0.24 35k 0.24 0.29 350k 0.32 0.36 3.3m 0.36 0.39 table 3.
</nextsent>
<nextsent>impact of morphological analysis on phrase translation model bleu scores under baseline and morph analysis are obtained in manner analogous to model 1 except that the morphological analysis for the phrase translation model is combination of the automatically induced analysis for model 1 plus the manually induced al#-deletion in 3.2.2.
</nextsent>
<nextsent>the scores with only automatically induced morphological analysis are 0.21, 0.25, 0.33 and 0.36 for 3.5k, 35k, 350k and 3.3m sentence pair training corpora, respectively.
</nextsent>
<nextsent>automatic induction of the desired linguistic knowledge from word/morpheme-aligned parallel corpus is analogous to (yarowsky et al 2001).<papid> H01-1035 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O51">
<title id=" N04-4015.xml">morphological analysis for statistical machine translation </title>
<section> related  work.  </section>
<citcontext>
<prevsection>
<prevsent>impact of morphological analysis on phrase translation model bleu scores under baseline and morph analysis are obtained in manner analogous to model 1 except that the morphological analysis for the phrase translation model is combination of the automatically induced analysis for model 1 plus the manually induced al#-deletion in 3.2.2.
</prevsent>
<prevsent>the scores with only automatically induced morphological analysis are 0.21, 0.25, 0.33 and 0.36 for 3.5k, 35k, 350k and 3.3m sentence pair training corpora, respectively.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
automatic induction of the desired linguistic knowledge from word/morpheme-aligned parallel corpus is analogous to (yarowsky et al 2001).<papid> H01-1035 </papid></citsent>
<aftsection>
<nextsent>word segmentation and merge/deletion analysis in morphology is similar to parsing and insertion operation in syntax by (yamada and knight 2001).<papid> P01-1067 </papid></nextsent>
<nextsent>symmetrization of linguistic structures can also be found in (niessen and ney 2000).<papid> C00-2162 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O52">
<title id=" N04-4015.xml">morphological analysis for statistical machine translation </title>
<section> related  work.  </section>
<citcontext>
<prevsection>
<prevsent>the scores with only automatically induced morphological analysis are 0.21, 0.25, 0.33 and 0.36 for 3.5k, 35k, 350k and 3.3m sentence pair training corpora, respectively.
</prevsent>
<prevsent>automatic induction of the desired linguistic knowledge from word/morpheme-aligned parallel corpus is analogous to (yarowsky et al 2001).<papid> H01-1035 </papid></prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
word segmentation and merge/deletion analysis in morphology is similar to parsing and insertion operation in syntax by (yamada and knight 2001).<papid> P01-1067 </papid></citsent>
<aftsection>
<nextsent>symmetrization of linguistic structures can also be found in (niessen and ney 2000).<papid> C00-2162 </papid></nextsent>
<nextsent>5 our experiments indicate that addition of al#-.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O53">
<title id=" N04-4015.xml">morphological analysis for statistical machine translation </title>
<section> related  work.  </section>
<citcontext>
<prevsection>
<prevsent>automatic induction of the desired linguistic knowledge from word/morpheme-aligned parallel corpus is analogous to (yarowsky et al 2001).<papid> H01-1035 </papid></prevsent>
<prevsent>word segmentation and merge/deletion analysis in morphology is similar to parsing and insertion operation in syntax by (yamada and knight 2001).<papid> P01-1067 </papid></prevsent>
</prevsection>
<citsent citstr=" C00-2162 ">
symmetrization of linguistic structures can also be found in (niessen and ney 2000).<papid> C00-2162 </papid></citsent>
<aftsection>
<nextsent>5 our experiments indicate that addition of al#-.
</nextsent>
<nextsent>deletion, cf.
</nextsent>
<nextsent>phrase translation model, does not affect the performance of ibm model 1.
</nextsent>
<nextsent>acknowledgements this work was partially supported by the defense advanced research projects agency and monitored by spawar under contract no.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O54">
<title id=" N07-1054.xml">building and refining rhetorical semantic relation models </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we report results of experiments which build and refine models of rhetorical semantic relations such as cause and contrast.
</prevsent>
</prevsection>
<citsent citstr=" P02-1047 ">
we adopt the approach of marcu and echihabi (2002), <papid> P02-1047 </papid>using small set of patterns to build relation models, and extend their work by refining the training and classification process using parameter optimization, topic segmentation and syntactic parsing.</citsent>
<aftsection>
<nextsent>using human-annotated and automatically-extracted test sets, we find that each of these techniques results in improved relation classification accuracy.
</nextsent>
<nextsent>relations such as cause and contrast, which we callrhetorical-semantic relations (rsrs), may be signaled in text by cue phrases like because or how ever which join clauses or sentences and explicitly express the relation of constituents which they connect (example 1).
</nextsent>
<nextsent>in other cases the relation may be implicitly expressed (2).1example 1 because of the recent accounting scandals, there have been spate of executive resigna tions.example 2 the administration was once again be set by scandal.
</nextsent>
<nextsent>after several key resignations ...1the authors would like to thank the four anonymous reviewers for helpful comments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O56">
<title id=" N07-1054.xml">building and refining rhetorical semantic relation models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we find that the parameter optimization andsegmentation-based filtering techniques achieve significant improvements in classification performance.
</prevsent>
<prevsent>rhetorical and discourse theory has long tradition in computational linguistics (moore and wiemerhastings, 2003).
</prevsent>
</prevsection>
<citsent citstr=" J96-3006 ">
while there are number of different relation taxonomies (hobbs, 1979; mckeown, 1985; mann and thompson, 1988; martin, 1992; knott and sanders, 1998), many researchers have found that, despite small differences, these theories have wide agreement in terms of the core phenomena for which they account (hovy and maier, 1993; moser and moore, 1996).<papid> J96-3006 </papid>work on automatic detection of rhetorical and discourse relations falls into two categories.</citsent>
<aftsection>
<nextsent>marcu and echihabi (2002) <papid> P02-1047 </papid>use pattern-based approach in mining instances of rsrs such as contrast and elaboration from large, unannotated corpora.</nextsent>
<nextsent>we discuss this work in detail in section 3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O59">
<title id=" N07-1054.xml">building and refining rhetorical semantic relation models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>marcu and echihabi (2002) <papid> P02-1047 </papid>use pattern-based approach in mining instances of rsrs such as contrast and elaboration from large, unannotated corpora.</prevsent>
<prevsent>we discuss this work in detail in section 3.</prevsent>
</prevsection>
<citsent citstr=" W01-1605 ">
other work uses human-annotated corpora, such as the rst bank (carlson et al, 2001), <papid> W01-1605 </papid>used by soricut and marcu (2003), <papid> N03-1030 </papid>the graph bank (wolf and gibson, 2005), <papid> J05-2005 </papid>used by wellner et al (2006), <papid> W06-1317 </papid>or ad hoc annotations, used by (girju, 2003; baldridge and lascarides, 2005).<papid> W05-0613 </papid></citsent>
<aftsection>
<nextsent>in the past year, the ini 428 tial public release of the penn discourse treebank(pdtb) (prasad et al, 2006) has significantly expanded the discourse-annotated corpora available to researchers, using comprehensive scheme for both implicit and explicit relations.some work in rsr detection has enlisted syntactic analysis as tool.
</nextsent>
<nextsent>marcu and echihabi (2002) <papid> P02-1047 </papid>filter training instances based on part-of-speech (pos)tags, and soricut and marcu (2003) <papid> N03-1030 </papid>use syntactic features to identify sentence-internal rst struc ture.</nextsent>
<nextsent>lapata and lascarides (2004) <papid> N04-1020 </papid>focus their work syntactically, analyzing temporal links between main and subordinate clauses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O60">
<title id=" N07-1054.xml">building and refining rhetorical semantic relation models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>marcu and echihabi (2002) <papid> P02-1047 </papid>use pattern-based approach in mining instances of rsrs such as contrast and elaboration from large, unannotated corpora.</prevsent>
<prevsent>we discuss this work in detail in section 3.</prevsent>
</prevsection>
<citsent citstr=" N03-1030 ">
other work uses human-annotated corpora, such as the rst bank (carlson et al, 2001), <papid> W01-1605 </papid>used by soricut and marcu (2003), <papid> N03-1030 </papid>the graph bank (wolf and gibson, 2005), <papid> J05-2005 </papid>used by wellner et al (2006), <papid> W06-1317 </papid>or ad hoc annotations, used by (girju, 2003; baldridge and lascarides, 2005).<papid> W05-0613 </papid></citsent>
<aftsection>
<nextsent>in the past year, the ini 428 tial public release of the penn discourse treebank(pdtb) (prasad et al, 2006) has significantly expanded the discourse-annotated corpora available to researchers, using comprehensive scheme for both implicit and explicit relations.some work in rsr detection has enlisted syntactic analysis as tool.
</nextsent>
<nextsent>marcu and echihabi (2002) <papid> P02-1047 </papid>filter training instances based on part-of-speech (pos)tags, and soricut and marcu (2003) <papid> N03-1030 </papid>use syntactic features to identify sentence-internal rst struc ture.</nextsent>
<nextsent>lapata and lascarides (2004) <papid> N04-1020 </papid>focus their work syntactically, analyzing temporal links between main and subordinate clauses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O61">
<title id=" N07-1054.xml">building and refining rhetorical semantic relation models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>marcu and echihabi (2002) <papid> P02-1047 </papid>use pattern-based approach in mining instances of rsrs such as contrast and elaboration from large, unannotated corpora.</prevsent>
<prevsent>we discuss this work in detail in section 3.</prevsent>
</prevsection>
<citsent citstr=" J05-2005 ">
other work uses human-annotated corpora, such as the rst bank (carlson et al, 2001), <papid> W01-1605 </papid>used by soricut and marcu (2003), <papid> N03-1030 </papid>the graph bank (wolf and gibson, 2005), <papid> J05-2005 </papid>used by wellner et al (2006), <papid> W06-1317 </papid>or ad hoc annotations, used by (girju, 2003; baldridge and lascarides, 2005).<papid> W05-0613 </papid></citsent>
<aftsection>
<nextsent>in the past year, the ini 428 tial public release of the penn discourse treebank(pdtb) (prasad et al, 2006) has significantly expanded the discourse-annotated corpora available to researchers, using comprehensive scheme for both implicit and explicit relations.some work in rsr detection has enlisted syntactic analysis as tool.
</nextsent>
<nextsent>marcu and echihabi (2002) <papid> P02-1047 </papid>filter training instances based on part-of-speech (pos)tags, and soricut and marcu (2003) <papid> N03-1030 </papid>use syntactic features to identify sentence-internal rst struc ture.</nextsent>
<nextsent>lapata and lascarides (2004) <papid> N04-1020 </papid>focus their work syntactically, analyzing temporal links between main and subordinate clauses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O62">
<title id=" N07-1054.xml">building and refining rhetorical semantic relation models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>marcu and echihabi (2002) <papid> P02-1047 </papid>use pattern-based approach in mining instances of rsrs such as contrast and elaboration from large, unannotated corpora.</prevsent>
<prevsent>we discuss this work in detail in section 3.</prevsent>
</prevsection>
<citsent citstr=" W06-1317 ">
other work uses human-annotated corpora, such as the rst bank (carlson et al, 2001), <papid> W01-1605 </papid>used by soricut and marcu (2003), <papid> N03-1030 </papid>the graph bank (wolf and gibson, 2005), <papid> J05-2005 </papid>used by wellner et al (2006), <papid> W06-1317 </papid>or ad hoc annotations, used by (girju, 2003; baldridge and lascarides, 2005).<papid> W05-0613 </papid></citsent>
<aftsection>
<nextsent>in the past year, the ini 428 tial public release of the penn discourse treebank(pdtb) (prasad et al, 2006) has significantly expanded the discourse-annotated corpora available to researchers, using comprehensive scheme for both implicit and explicit relations.some work in rsr detection has enlisted syntactic analysis as tool.
</nextsent>
<nextsent>marcu and echihabi (2002) <papid> P02-1047 </papid>filter training instances based on part-of-speech (pos)tags, and soricut and marcu (2003) <papid> N03-1030 </papid>use syntactic features to identify sentence-internal rst struc ture.</nextsent>
<nextsent>lapata and lascarides (2004) <papid> N04-1020 </papid>focus their work syntactically, analyzing temporal links between main and subordinate clauses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O63">
<title id=" N07-1054.xml">building and refining rhetorical semantic relation models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>marcu and echihabi (2002) <papid> P02-1047 </papid>use pattern-based approach in mining instances of rsrs such as contrast and elaboration from large, unannotated corpora.</prevsent>
<prevsent>we discuss this work in detail in section 3.</prevsent>
</prevsection>
<citsent citstr=" W05-0613 ">
other work uses human-annotated corpora, such as the rst bank (carlson et al, 2001), <papid> W01-1605 </papid>used by soricut and marcu (2003), <papid> N03-1030 </papid>the graph bank (wolf and gibson, 2005), <papid> J05-2005 </papid>used by wellner et al (2006), <papid> W06-1317 </papid>or ad hoc annotations, used by (girju, 2003; baldridge and lascarides, 2005).<papid> W05-0613 </papid></citsent>
<aftsection>
<nextsent>in the past year, the ini 428 tial public release of the penn discourse treebank(pdtb) (prasad et al, 2006) has significantly expanded the discourse-annotated corpora available to researchers, using comprehensive scheme for both implicit and explicit relations.some work in rsr detection has enlisted syntactic analysis as tool.
</nextsent>
<nextsent>marcu and echihabi (2002) <papid> P02-1047 </papid>filter training instances based on part-of-speech (pos)tags, and soricut and marcu (2003) <papid> N03-1030 </papid>use syntactic features to identify sentence-internal rst struc ture.</nextsent>
<nextsent>lapata and lascarides (2004) <papid> N04-1020 </papid>focus their work syntactically, analyzing temporal links between main and subordinate clauses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O67">
<title id=" N07-1054.xml">building and refining rhetorical semantic relation models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the past year, the ini 428 tial public release of the penn discourse treebank(pdtb) (prasad et al, 2006) has significantly expanded the discourse-annotated corpora available to researchers, using comprehensive scheme for both implicit and explicit relations.some work in rsr detection has enlisted syntactic analysis as tool.
</prevsent>
<prevsent>marcu and echihabi (2002) <papid> P02-1047 </papid>filter training instances based on part-of-speech (pos)tags, and soricut and marcu (2003) <papid> N03-1030 </papid>use syntactic features to identify sentence-internal rst struc ture.</prevsent>
</prevsection>
<citsent citstr=" N04-1020 ">
lapata and lascarides (2004) <papid> N04-1020 </papid>focus their work syntactically, analyzing temporal links between main and subordinate clauses.</citsent>
<aftsection>
<nextsent>sporleder and lascarides (2005) extend marcu and echihabis approach with the addition of number of features,including syntactic features based on pos and argument structure, as well as lexical and other surface features.
</nextsent>
<nextsent>they report that, when working with sparse training data, this richer feature set, combined with boosting-based algorithm, achieves more accurate classification than marcu and echihabis simpler, word-pair based approach (we describe the latter in the next section).
</nextsent>
<nextsent>we model two rsrs, cause and contrast, adopting the definitions of marcu and echihabi (2002)(<papid> P02-1047 </papid>henceforth m&e;) for their cause-explanation evidence and contrast relations, respectively.</nextsent>
<nextsent>in particular, we follow their intuition that in building an automated model it is best to adopt higher-level view of relations (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O70">
<title id=" N07-1054.xml">building and refining rhetorical semantic relation models </title>
<section> using topic segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>431before applying these segment-augmented patterns, we must add boundary markers to our corpus.
</prevsent>
<prevsent>while the concept of topic segment canbe defined at various granularities, we take goal oriented view and aim to identify segments with amean length of approximately four sentences, reasoning that these will be long enough to exclude some candidate norel instances, yet short enough to exclude non-trivial number of contrasts and cause instances.
</prevsent>
</prevsection>
<citsent citstr=" P03-1071 ">
we use an automatic topic segmentation tool, lcseg (galley et al, 2003) <papid> P03-1071 </papid>setting parameters so that the derived segments are of the approximate desired length.</citsent>
<aftsection>
<nextsent>using these parameters, lc seg produces topic segments with mean length of 3.51 sentences over gigaword, as opposed to 1.54sentences for paragraph boundaries.
</nextsent>
<nextsent>using simple metric that assumes correct?
</nextsent>
<nextsent>segment boundaries always occur at paragraph boundaries, lcseg achieves 76% precision.
</nextsent>
<nextsent>we rerun the instance mining step of textrels over the segmented training corpus, after adding the segment-based constraints mentioned above to our pattern set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O71">
<title id=" N07-1054.xml">building and refining rhetorical semantic relation models </title>
<section> using syntax.  </section>
<citcontext>
<prevsection>
<prevsent>for contrast (accounts for 41% of training instances).
</prevsent>
<prevsent>lastly, we limit the size of our training set because of parsing time demands.
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
we use the collins parser (collins, 1996) <papid> P96-1025 </papid>to parse 400,000instances each of cause and contrast for our final results.</citsent>
<aftsection>
<nextsent>compared with our other models, this is approximately 43% of our total cause instances and 13% of our total contrast instances.
</nextsent>
<nextsent>for the norel model, we use randomly selected subset of400,000 instances from our training set.
</nextsent>
<nextsent>for all relations, we use the non-segment-constrained instance set as the source of these instances.
</nextsent>
<nextsent>7.1 analyzing and classifying syntactic errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O72">
<title id=" N04-4033.xml">polarity sensitivity and evaluation order in type logical grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it takes not justscopal relations but also linear order into account, using the programming-language notions of delimited continuations and evaluation order, respectively.
</prevsent>
<prevsent>it thus achieves greater empirical coverage than previous proposals.
</prevsent>
</prevsection>
<citsent citstr=" P97-1019 ">
polarity sensitivity (ladusaw, 1979) has been popular linguistic phenomenon to analyze in the categorial (dowty, 1994), lexical-functional (fry, 1997, <papid> P97-1019 </papid>1999), and type-logical (bernardi, 2002; bernardi and moot, 2001)approaches to grammar.</citsent>
<aftsection>
<nextsent>the multitude of these analyses is in part due to the more explicit emphasis that these traditions place on the syntax-semantics interface be itin the form of montague-style semantic rules, the curry howard isomorphism, or linear logicas glueand the fact that polarity sensitivity is phenomenon that spans syntax and semantics.on one hand, which polarity items are licensed or prohibited in given linguistic environment depends, by and large, on semantic properties of that environment (ladu saw, 1979; krifka, 1995, inter alia).
</nextsent>
<nextsent>for example, to first approximation, negative polarity items can occur only in downward-entailing contexts, such as under the scope of monotonic ally decreasing quantifier.
</nextsent>
<nextsent>a quantifier q, of type (e ? t) ? where is the type of individuals and is the type of truth values, is monotonic ally decreasing just in case (1) s1.s2.
</nextsent>
<nextsent>( x. s2(x) ? s1(x) ) ? q(s1) ? q(s2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O73">
<title id=" N04-4032.xml">parsing conversational speech using enhanced segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper explores the usefulness of identifying boundaries of sentence-like units (referred to as sus) and ips in parsing conversational speech.early work in parsing conversational speech was rule based and limited in domain (mayfield et al, 1995).
</prevsent>
<prevsent>results from another rule-based system (core and schubert, 1999) suggests that standard parsers can be used to identify speech repairs in conversational speech.
</prevsent>
</prevsection>
<citsent citstr=" N01-1016 ">
work in statistically parsing conversational speech (charniak and johnson, 2001) <papid> N01-1016 </papid>has examined the performance of aparser that removes edit regions in an earlier step.</citsent>
<aftsection>
<nextsent>in contrast, we train parser on the complete (human-specified) segmentation, with edit-regions included.
</nextsent>
<nextsent>we choose to work with all of the words within edit regions anticipating that making the parallel syntactic structures of the edit region available to the parser can improve its performance in identifying that structure.
</nextsent>
<nextsent>our work makes use of the structured language model (slm) as parser and an existing su-ip detection algorithm, described next.
</nextsent>
<nextsent>2.1 structured language model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O74">
<title id=" N04-4032.xml">parsing conversational speech using enhanced segmentation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>for further details on the slm, see (chelba and jelinek, 2000).
</prevsent>
<prevsent>2.2 su and ip detection.
</prevsent>
</prevsection>
<citsent citstr=" N04-1018 ">
the system used here for su and ip detection is (kim et al, 2004), <papid> N04-1018 </papid>modulo differences in training data.</citsent>
<aftsection>
<nextsent>it combines decision tree models of prosody with hidden event language model in hidden markov model (hmm) framework for detecting events at each word boundary, similar to (liu et al, 2003).
</nextsent>
<nextsent>differences include the use of lexical pattern matching features (sequential matching words or pos tags) as well as prosody cues in the decision tree, and having joint representation of su and ip boundary events rather than separate detectors.
</nextsent>
<nextsent>on the darpa rt-03f meta data test set (nist, 2003), the model has 35.0% slot error rate (ser) for sus (75.7% recall, 87.7% precision), and 68.8% ser for edit ips (41.8% recall, 79.8% precision) on reference transcripts, using the rt eval scoring tool.2 while these error rates are relatively high, it is difficult task and the su performance is at the state of the art.
</nextsent>
<nextsent>since early work on sentence?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O76">
<title id=" N04-4032.xml">parsing conversational speech using enhanced segmentation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>because the nave system does not predict ips, we only have experiments for 5 of the 6 possible combinations.
</prevsent>
<prevsent>4.2 evaluation.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
we evaluated parser performance by using bracket precision and recall scores, as well as bracket-crossing, using the parseval metric (sekine and collins, 1997; black etal., 1991).<papid> H91-1060 </papid></citsent>
<aftsection>
<nextsent>this bracket-counting metric for parsers, requires that the input words (and, by implication, sen tences) be held constant across test conditions.
</nextsent>
<nextsent>since our experiments deliberately vary the segmentation, we needed to evaluate each conversation side as single sentence?
</nextsent>
<nextsent>in order to obtain meaningful results across different segmentations.
</nextsent>
<nextsent>we construct this top-level sentence by attaching the parsers proposed constituents for each su to new top-level constituent (labeled tiptop).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O77">
<title id=" N04-1019.xml">evaluating content selection in summarization the pyramid method </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluating content selection in summarization has proven to be difficult problem.
</prevsent>
<prevsent>our approach acknowledges the fact that no single best model summary exists, and takes this as foundation rather than an obstacle.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
in machine translation, the rankings from the automatic bleu method (papineni et al, 2002) <papid> P02-1040 </papid>have been shown to correlate well with human evaluation, and it has been widely used since and has even been adapted for summarization (lin and hovy, 2003).<papid> N03-1020 </papid></citsent>
<aftsection>
<nextsent>to show that an automatic method is reasonable approximation of human judgments, one needs to demonstrate that these can be reliably elicited.
</nextsent>
<nextsent>however, in contrast to translation, where the evaluation criterion can be defined fairly precisely it is difficult to elicit stable human judgments for summarization (rath et al, 1961) (lin and hovy, 2002).<papid> W02-0406 </papid>our approach tailors the evaluation to observed distributions of content over pool of human summaries, rather than to human judgments of summaries.</nextsent>
<nextsent>our method involves semantic matching of content units towhich differential weights are assigned based on their frequency in corpus of summaries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O78">
<title id=" N04-1019.xml">evaluating content selection in summarization the pyramid method </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluating content selection in summarization has proven to be difficult problem.
</prevsent>
<prevsent>our approach acknowledges the fact that no single best model summary exists, and takes this as foundation rather than an obstacle.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
in machine translation, the rankings from the automatic bleu method (papineni et al, 2002) <papid> P02-1040 </papid>have been shown to correlate well with human evaluation, and it has been widely used since and has even been adapted for summarization (lin and hovy, 2003).<papid> N03-1020 </papid></citsent>
<aftsection>
<nextsent>to show that an automatic method is reasonable approximation of human judgments, one needs to demonstrate that these can be reliably elicited.
</nextsent>
<nextsent>however, in contrast to translation, where the evaluation criterion can be defined fairly precisely it is difficult to elicit stable human judgments for summarization (rath et al, 1961) (lin and hovy, 2002).<papid> W02-0406 </papid>our approach tailors the evaluation to observed distributions of content over pool of human summaries, rather than to human judgments of summaries.</nextsent>
<nextsent>our method involves semantic matching of content units towhich differential weights are assigned based on their frequency in corpus of summaries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O79">
<title id=" N04-1019.xml">evaluating content selection in summarization the pyramid method </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in machine translation, the rankings from the automatic bleu method (papineni et al, 2002) <papid> P02-1040 </papid>have been shown to correlate well with human evaluation, and it has been widely used since and has even been adapted for summarization (lin and hovy, 2003).<papid> N03-1020 </papid></prevsent>
<prevsent>to show that an automatic method is reasonable approximation of human judgments, one needs to demonstrate that these can be reliably elicited.</prevsent>
</prevsection>
<citsent citstr=" W02-0406 ">
however, in contrast to translation, where the evaluation criterion can be defined fairly precisely it is difficult to elicit stable human judgments for summarization (rath et al, 1961) (lin and hovy, 2002).<papid> W02-0406 </papid>our approach tailors the evaluation to observed distributions of content over pool of human summaries, rather than to human judgments of summaries.</citsent>
<aftsection>
<nextsent>our method involves semantic matching of content units towhich differential weights are assigned based on their frequency in corpus of summaries.
</nextsent>
<nextsent>this can lead to more stable, more informative scores, and hence to meaningful content evaluation.
</nextsent>
<nextsent>we create weighted inventory of summary content unitsa pyramid that is reliable, predictive and diagnostic, and which constitutes resource for investigating alternate realizations of the same meaning.
</nextsent>
<nextsent>no other evaluation method predicts sets of equally informative summaries, identifies semantic differences between more and less highly ranked summaries, or constitutes tool that can be applied directly to further analysis of content selection.in section 2, we describe the duc method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O83">
<title id=" N04-1019.xml">evaluating content selection in summarization the pyramid method </title>
<section> 0.33 3 </section>
<citcontext>
<prevsection>
<prevsent>finally, they report reliability of the annotation using recall and precision, rather than reliability metric that factors in chance agreement.
</prevsent>
<prevsent>in (passon neau, 2004), we note that high recall/precision does not preclude low inter annotator reliability on coreference annotation task.
</prevsent>
</prevsection>
<citsent citstr=" P03-1048 ">
radev et al (2003) <papid> P03-1048 </papid>also exploits relative importance of information.</citsent>
<aftsection>
<nextsent>evaluation data consists of human relevance judgments on scale from 0 to 10 on for all sentences inthe original documents.
</nextsent>
<nextsent>again, information is lost relative to the pyramid method because unique reference summary is produced instead of using all the data.
</nextsent>
<nextsent>the reference summary consists of the sentences with highest relevance judgements that satisfy the compression constraints.
</nextsent>
<nextsent>for multi document summarization compression rates are high, so even sentences with the highest relevance judgments are potentially not used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O87">
<title id=" N07-1014.xml">a random text model for the generation of statistical language in variants </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they introduce sub linear vocabulary growth by additionally making the new word probability dependent on the time step.
</prevsent>
<prevsent>furthermore, they introduce threshold on the maximal probability previously seen word can be assigned to for generation, being able to modify the exponent as well as to model the flatter curve for high frequency words.
</prevsent>
</prevsection>
<citsent citstr=" C02-1117 ">
in (ha et al, 2002), <papid> C02-1117 </papid>zipfs law is extended to words and phrases, showing its validity for syllable-class based languages when conducting the extension.</citsent>
<aftsection>
<nextsent>neither the mandelbrot nor the simon generation model take the sequence of words into account.
</nextsent>
<nextsent>simon treats the previously generated stream as bag of words, and mandelbrot does not consider the previous stream at all.
</nextsent>
<nextsent>this is certainly an over-simplification, as natural language exhibits structural properties within sentences and texts that are not grasped by bags of words.
</nextsent>
<nextsent>the work by kanter and kessler (1995) is, to our knowledge, the only study to date that takes the word order into account when generating random text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O88">
<title id=" N07-1014.xml">a random text model for the generation of statistical language in variants </title>
<section> the random text generation model.  </section>
<citcontext>
<prevsection>
<prevsent>distribution of word length: according to (sigurd et al, 2004), the distribution of word frequencies by length follows variant of the gamma distribution ? distribution of sentence length: the random texts sentence length distribution should resemble natural language.
</prevsent>
<prevsent>in (sigurd et al, 2004), the same variant of the gamma distribution as for word length is fit to sentence length.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
significant neighbor-based co-occurrence: as discussed in (dunning 1993), <papid> J93-1003 </papid>it is possible to measure the amount of surprise to see two neighboring words in corpus at certain frequency under the assumption of in dependence.</citsent>
<aftsection>
<nextsent>at random generation without word order awareness, the number of such pairs that are significantly co-occurring in neighboring positions should be very low.
</nextsent>
<nextsent>we aim at reproducing the number of significant pairs in natural language as well as the graph structure of the neighbor-based cooccurrence graph.
</nextsent>
<nextsent>the last characteristic refers to the distribution of words in sequence.
</nextsent>
<nextsent>important is the notion of significance, which serves as means to distinguish random sequences from motivated ones.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O90">
<title id=" N07-1014.xml">a random text model for the generation of statistical language in variants </title>
<section> the random text generation model.  </section>
<citcontext>
<prevsection>
<prevsent>it should be noted that the sentence generator produces very diverse sequence of sentences which does not deteriorate in repeating the same sentence all over again in later stages.
</prevsent>
<prevsent>both word and sentence generator can be viewed as weighted finite automata (cf.
</prevsent>
</prevsection>
<citsent citstr=" P03-1006 ">
allauzen et al, 2003) <papid> P03-1006 </papid>with self training.</citsent>
<aftsection>
<nextsent>109after having defined our random text generation model, the next section is devoted to testing it according to the criteria given in section 2.1.
</nextsent>
<nextsent>to measure agreement with our bnc sample, we generated random text with the sentence generator using w=0.4 and n=26 to match the english average word length and setting to 0.08 for reaching comparable sentence length.
</nextsent>
<nextsent>the first 50,000 sentences were skipped to reach relatively stable sentence length throughout the sample.
</nextsent>
<nextsent>to make the samples comparable, we used 1 million words totaling 125,345 sentences with an average sentence length of 7.977.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O92">
<title id=" N04-4038.xml">automatic tagging of arabic text from raw text to base phrase chunks </title>
<section> svm based approach.  </section>
<citcontext>
<prevsection>
<prevsent>support vector machines (svms) (vapnik, 1995) are one class of such model.
</prevsent>
<prevsent>svms are supervised learning algorithm that has the advantage of being robust where it can handle large number of(overlapping) features with good generalization performance.
</prevsent>
</prevsection>
<citsent citstr=" W00-0730 ">
consequently, svms have been applied in many nlp tasks with great success (joachims, 1998; kudo and matsu mato, 2000; <papid> W00-0730 </papid>hacioglu and ward, 2003).<papid> N03-2009 </papid></citsent>
<aftsection>
<nextsent>we adopt tagging perspective for the three tasks.thereby, we address them using the same svm experimental setup which comprises standard svm as multiclass classifier (allwein et al, 2000).
</nextsent>
<nextsent>the difference for the three tasks lies in the input, context and features.
</nextsent>
<nextsent>none of the features utilized in our approach is explicitly language dependent.
</nextsent>
<nextsent>the following subsections illustrate the different tasks and their corresponding features and tag sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O93">
<title id=" N04-4038.xml">automatic tagging of arabic text from raw text to base phrase chunks </title>
<section> svm based approach.  </section>
<citcontext>
<prevsection>
<prevsent>support vector machines (svms) (vapnik, 1995) are one class of such model.
</prevsent>
<prevsent>svms are supervised learning algorithm that has the advantage of being robust where it can handle large number of(overlapping) features with good generalization performance.
</prevsent>
</prevsection>
<citsent citstr=" N03-2009 ">
consequently, svms have been applied in many nlp tasks with great success (joachims, 1998; kudo and matsu mato, 2000; <papid> W00-0730 </papid>hacioglu and ward, 2003).<papid> N03-2009 </papid></citsent>
<aftsection>
<nextsent>we adopt tagging perspective for the three tasks.thereby, we address them using the same svm experimental setup which comprises standard svm as multiclass classifier (allwein et al, 2000).
</nextsent>
<nextsent>the difference for the three tasks lies in the input, context and features.
</nextsent>
<nextsent>none of the features utilized in our approach is explicitly language dependent.
</nextsent>
<nextsent>the following subsections illustrate the different tasks and their corresponding features and tag sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O95">
<title id=" N06-2013.xml">arabic preprocessing schemes for statistical machine translation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 presents the tools and datasets used, along with the results of our experiments.
</prevsent>
<prevsent>section 6 contains discussion of the results.
</prevsent>
</prevsection>
<citsent citstr=" H05-1085 ">
the anecdotal intuition in the field is that reduction of word sparsity often improves translation quality.this reduction can be achieved by increasing training data or via morphologically driven preprocessing (goldwater and mcclosky, 2005).<papid> H05-1085 </papid></citsent>
<aftsection>
<nextsent>recent publications on the effect of morphology on smt quality focused on morphologically rich languages such as german (nieen and ney, 2004); spanish, catalan, and serbian (popovic?
</nextsent>
<nextsent>and ney, 2004); and czech (goldwater and mcclosky, 2005).<papid> H05-1085 </papid></nextsent>
<nextsent>they all studied 2we conducted several additional experiments that we do not report on here for lack of space but we reserve for separate technical report.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O99">
<title id=" N06-2013.xml">arabic preprocessing schemes for statistical machine translation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>they all studied 2we conducted several additional experiments that we do not report on here for lack of space but we reserve for separate technical report.
</prevsent>
<prevsent>49the effects of various kinds of tokenization, lemma tization and pos tagging and show positive effect on smt quality.
</prevsent>
</prevsection>
<citsent citstr=" N04-4015 ">
specifically considering arabic,lee (2004) <papid> N04-4015 </papid>investigated the use of automatic alignment of pos tagged english and affix-stem segmented arabic to determine appropriate tokenizations.</citsent>
<aftsection>
<nextsent>her results show that morphological preprocessing helps, but only for the smaller corpora.
</nextsent>
<nextsent>as size increases, the benefits diminish.
</nextsent>
<nextsent>our results are comparable to hers in terms of bleu score and consistent in terms of conclusions.
</nextsent>
<nextsent>we extend on previous work by experimenting with wider range of preprocessing schemes for arabic, by studying the effect of morphological disambiguation (beyondpos tagging) on preprocessing schemes over learning curves, and by investigating the effect on different genres.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O100">
<title id=" N06-2013.xml">arabic preprocessing schemes for statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>en: english-like.
</prevsent>
<prevsent>this scheme is intended to minimize differences between arabic and english.it decliticizes similarly to d3; however, it uses lexeme and english-like pos tags instead of the regenerated word and it indicates the pro-dropped verb subject explicitly as separate token.
</prevsent>
</prevsection>
<citsent citstr=" W05-0822 ">
we use the phrase-based smt system, portage (sa dat et al, 2005).<papid> W05-0822 </papid></citsent>
<aftsection>
<nextsent>for training, portage uses ibm word alignment models (models 1 and 2) trained in both directions to extract phrase tables.
</nextsent>
<nextsent>maximum phrase size used is 8.
</nextsent>
<nextsent>trigram language models are implemented using the srilm toolkit (stol cke, 2002).
</nextsent>
<nextsent>decoding weights are optimized using ochs algorithm (och, 2003) <papid> P03-1021 </papid>to set weights for the four components of the log-linear model: language model, phrase translation model, distortion model, and word-length feature.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O101">
<title id=" N06-2013.xml">arabic preprocessing schemes for statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>maximum phrase size used is 8.
</prevsent>
<prevsent>trigram language models are implemented using the srilm toolkit (stol cke, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
decoding weights are optimized using ochs algorithm (och, 2003) <papid> P03-1021 </papid>to set weights for the four components of the log-linear model: language model, phrase translation model, distortion model, and word-length feature.</citsent>
<aftsection>
<nextsent>the weights are optimized over the bleu metric (papineni et al, 2001).
</nextsent>
<nextsent>the portage decoder, canoe, is dynamic-programming beam search algorithm, resembling the algorithm described in (koehn, 2004<papid> W04-3250 </papid>a).</nextsent>
<nextsent>all of the training data we use is available from the linguistic data consortium (ldc).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O102">
<title id=" N06-2013.xml">arabic preprocessing schemes for statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>decoding weights are optimized using ochs algorithm (och, 2003) <papid> P03-1021 </papid>to set weights for the four components of the log-linear model: language model, phrase translation model, distortion model, and word-length feature.</prevsent>
<prevsent>the weights are optimized over the bleu metric (papineni et al, 2001).</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
the portage decoder, canoe, is dynamic-programming beam search algorithm, resembling the algorithm described in (koehn, 2004<papid> W04-3250 </papid>a).</citsent>
<aftsection>
<nextsent>all of the training data we use is available from the linguistic data consortium (ldc).
</nextsent>
<nextsent>we use an arabic-english parallel corpus of about 5 million words for translation model training data.4 we created the english language model from the english side of the parallel corpus together with 116 million words from the english gigaword corpus(ldc2005t12) and 128 million words from the english side of theun parallel corpus (ldc2004e13).english preprocessing comprised down-casing, separating punctuation from words and splitting offs?.
</nextsent>
<nextsent>arabic preprocessing was varied using the proposed schemes and techniques.
</nextsent>
<nextsent>decoding weight optimization was done on 200 sentences from the 2003 nist mt evaluation test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O106">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>the parsing model uses predicate-argumentdependencies for training, which are derived from sequences of ccg lexical categories rather than full derivations.
</prevsent>
<prevsent>a simple method is used for extracting dependencies from lexical category sequences, resulting in high precision, yet incomplete and noisy data.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
the dependency parsing model of clark and curran (2004<papid> P04-1014 </papid>b) is extended to exploit this partial training data.</citsent>
<aftsection>
<nextsent>remarkably, the accuracy of the parser trained on data derived from category sequences alone is only 1.3% worse in termsof f-score than the parser trained on complete dependency structures.
</nextsent>
<nextsent>state-of-the-art statistical parsers require large amounts of hand-annotated training data, and are typically based on the penn treebank, the largest treebank available for english.
</nextsent>
<nextsent>even robust parsers using linguistically sophisticated formalisms, such as tag (chiang, 2000), <papid> P00-1058 </papid>ccg (clark and curran, 2004<papid> P04-1014 </papid>b; hockenmaier, 2003), hpsg (miyao et al, 2004) and lfg (riezler et al, 2002; <papid> P02-1035 </papid>cahill et al, 2004), <papid> P04-1041 </papid>often use training data derived from the penntreebank.</nextsent>
<nextsent>the labour-intensive nature of the tree bank development process, which can take many years, creates significant barrier for the development of parsers for new domains and languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O128">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>remarkably, the accuracy of the parser trained on data derived from category sequences alone is only 1.3% worse in termsof f-score than the parser trained on complete dependency structures.
</prevsent>
<prevsent>state-of-the-art statistical parsers require large amounts of hand-annotated training data, and are typically based on the penn treebank, the largest treebank available for english.
</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
even robust parsers using linguistically sophisticated formalisms, such as tag (chiang, 2000), <papid> P00-1058 </papid>ccg (clark and curran, 2004<papid> P04-1014 </papid>b; hockenmaier, 2003), hpsg (miyao et al, 2004) and lfg (riezler et al, 2002; <papid> P02-1035 </papid>cahill et al, 2004), <papid> P04-1041 </papid>often use training data derived from the penntreebank.</citsent>
<aftsection>
<nextsent>the labour-intensive nature of the tree bank development process, which can take many years, creates significant barrier for the development of parsers for new domains and languages.
</nextsent>
<nextsent>previous work has attempted parser adaptation without relying on treebank data from the new do main (steedman et al, 2003; <papid> E03-1008 </papid>lease and charniak,2005).</nextsent>
<nextsent>in this paper we propose the use of annotated data in the new domain, but only partially annotated data, which reduces the annotation effort required (hwa, 1999).<papid> P99-1010 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O135">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>remarkably, the accuracy of the parser trained on data derived from category sequences alone is only 1.3% worse in termsof f-score than the parser trained on complete dependency structures.
</prevsent>
<prevsent>state-of-the-art statistical parsers require large amounts of hand-annotated training data, and are typically based on the penn treebank, the largest treebank available for english.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
even robust parsers using linguistically sophisticated formalisms, such as tag (chiang, 2000), <papid> P00-1058 </papid>ccg (clark and curran, 2004<papid> P04-1014 </papid>b; hockenmaier, 2003), hpsg (miyao et al, 2004) and lfg (riezler et al, 2002; <papid> P02-1035 </papid>cahill et al, 2004), <papid> P04-1041 </papid>often use training data derived from the penntreebank.</citsent>
<aftsection>
<nextsent>the labour-intensive nature of the tree bank development process, which can take many years, creates significant barrier for the development of parsers for new domains and languages.
</nextsent>
<nextsent>previous work has attempted parser adaptation without relying on treebank data from the new do main (steedman et al, 2003; <papid> E03-1008 </papid>lease and charniak,2005).</nextsent>
<nextsent>in this paper we propose the use of annotated data in the new domain, but only partially annotated data, which reduces the annotation effort required (hwa, 1999).<papid> P99-1010 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O136">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>remarkably, the accuracy of the parser trained on data derived from category sequences alone is only 1.3% worse in termsof f-score than the parser trained on complete dependency structures.
</prevsent>
<prevsent>state-of-the-art statistical parsers require large amounts of hand-annotated training data, and are typically based on the penn treebank, the largest treebank available for english.
</prevsent>
</prevsection>
<citsent citstr=" P04-1041 ">
even robust parsers using linguistically sophisticated formalisms, such as tag (chiang, 2000), <papid> P00-1058 </papid>ccg (clark and curran, 2004<papid> P04-1014 </papid>b; hockenmaier, 2003), hpsg (miyao et al, 2004) and lfg (riezler et al, 2002; <papid> P02-1035 </papid>cahill et al, 2004), <papid> P04-1041 </papid>often use training data derived from the penntreebank.</citsent>
<aftsection>
<nextsent>the labour-intensive nature of the tree bank development process, which can take many years, creates significant barrier for the development of parsers for new domains and languages.
</nextsent>
<nextsent>previous work has attempted parser adaptation without relying on treebank data from the new do main (steedman et al, 2003; <papid> E03-1008 </papid>lease and charniak,2005).</nextsent>
<nextsent>in this paper we propose the use of annotated data in the new domain, but only partially annotated data, which reduces the annotation effort required (hwa, 1999).<papid> P99-1010 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O137">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even robust parsers using linguistically sophisticated formalisms, such as tag (chiang, 2000), <papid> P00-1058 </papid>ccg (clark and curran, 2004<papid> P04-1014 </papid>b; hockenmaier, 2003), hpsg (miyao et al, 2004) and lfg (riezler et al, 2002; <papid> P02-1035 </papid>cahill et al, 2004), <papid> P04-1041 </papid>often use training data derived from the penntreebank.</prevsent>
<prevsent>the labour-intensive nature of the tree bank development process, which can take many years, creates significant barrier for the development of parsers for new domains and languages.</prevsent>
</prevsection>
<citsent citstr=" E03-1008 ">
previous work has attempted parser adaptation without relying on treebank data from the new do main (steedman et al, 2003; <papid> E03-1008 </papid>lease and charniak,2005).</citsent>
<aftsection>
<nextsent>in this paper we propose the use of annotated data in the new domain, but only partially annotated data, which reduces the annotation effort required (hwa, 1999).<papid> P99-1010 </papid></nextsent>
<nextsent>we develop parsing model which can be trained using partial data, by exploiting the properties of lexicalized grammar formalisms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O138">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the labour-intensive nature of the tree bank development process, which can take many years, creates significant barrier for the development of parsers for new domains and languages.
</prevsent>
<prevsent>previous work has attempted parser adaptation without relying on treebank data from the new do main (steedman et al, 2003; <papid> E03-1008 </papid>lease and charniak,2005).</prevsent>
</prevsection>
<citsent citstr=" P99-1010 ">
in this paper we propose the use of annotated data in the new domain, but only partially annotated data, which reduces the annotation effort required (hwa, 1999).<papid> P99-1010 </papid></citsent>
<aftsection>
<nextsent>we develop parsing model which can be trained using partial data, by exploiting the properties of lexicalized grammar formalisms.
</nextsent>
<nextsent>the formalism we use is combinatory categorial grammar (steedman, 2000), together with parsing model described in clark and curran (2004<papid> P04-1014 </papid>b) which we adapt for use with partial data.</nextsent>
<nextsent>parsing with combinatory categorial grammar (ccg) takes place in two stages: first, ccg lexical categories are assigned to the words in the sentence, and then the categories are combined by the parser (clark and curran, 2004<papid> P04-1014 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O167">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the lexical categories can be thought of as detailed part of speech tags and typically express subcategorization information.
</prevsent>
<prevsent>we exploit the fact that ccg lexical categories contain lot of syntactic information, and can therefore beused for training full parser, even though attachment information is not explicitly represented in category sequence.
</prevsent>
</prevsection>
<citsent citstr=" W04-3215 ">
our partial training regime only requires sentences to be annotated with lexical categories, rather than full parse trees; therefore the datacan be produced much more quickly for new do main or language (clark et al, 2004).<papid> W04-3215 </papid></citsent>
<aftsection>
<nextsent>the partial training method uses the log-linear dependency model described in clark and curran(2004<papid> P04-1014 </papid>b), which uses sets of predicate-argument de 144 pendencies, rather than derivations, for training.</nextsent>
<nextsent>our novel idea is that, since there is so much information in the lexical category sequence, most of the correct dependencies can be easily inferred from the categories alone.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O170">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more specifically, forgiven sentence and lexical category sequence, we train on those predicate-argument dependencies which occurin k% of the derivations licenced by the lexical categories.
</prevsent>
<prevsent>by setting the parameter high, we can produce set of high precision dependencies for training.
</prevsent>
</prevsection>
<citsent citstr=" C02-1013 ">
a similar idea is proposed by carroll and briscoe (2002) <papid> C02-1013 </papid>for producing high precision data for lexical acquisition.using this procedure we are able to produce dependency data with over 99% precision and, remarkably, up to 86% recall, when compared against the complete gold-standard dependency data.</citsent>
<aftsection>
<nextsent>the high recall figure results from the significant amount of syntactic information in the lexical categories,which reduces the ambiguity in the possible dependency structures.
</nextsent>
<nextsent>since the recall is not 100%, we require log-linear training method which works with partial data.
</nextsent>
<nextsent>riezler et al (2002) <papid> P02-1035 </papid>describe partial training method for log-linear lfg parsing model in which the correct?</nextsent>
<nextsent>lfg derivations for sentence are those consistent with the less detailed gold standard derivation from the penn treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O194">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> the ccg parsing model.  </section>
<citcontext>
<prevsection>
<prevsent>surprisingly, the accuracy of the parser trained on partial data approaches that of the parser trained on full data: our best partial-data model is only 1.3%worse in terms of dependency f-score than the full data model, despite the fact that the partial data does not contain any explicit attachment information.
</prevsent>
<prevsent>clark and curran (2004<papid> P04-1014 </papid>b) describes two log-linear parsing models for ccg: normal-form derivation model and dependency model.</prevsent>
</prevsection>
<citsent citstr=" P02-1043 ">
in this paper we use the dependency model, which requires sets of predicate-argument dependencies for training.1 1hockenmaier and steedman (2002) <papid> P02-1043 </papid>describe generative model of normal-form derivations; one possibility for training this model on partial data, which has not been explored, is to use the em algorithm (pereira and schabes, 1992).<papid> P92-1017 </papid>the predicate-argument dependencies are represented as 5-tuples: hf , f, s, ha, l?, where hf is the lexical item of the lexical category expressing the dependency relation; is the lexical category; isthe argument slot; ha is the head word of the ar gument; and encodes whether the dependency is non-local.</citsent>
<aftsection>
<nextsent>for example, the dependency encoding company as the object of bought (as in ibm bought the company) is represented as follows: bought2, (s\np1 )/np2 , 2, company4,??
</nextsent>
<nextsent>(1)ccg dependency structures are sets of predicate argument dependencies.
</nextsent>
<nextsent>we define the probability of dependency structure as the sum of the probabilities of all those derivations leading to that structure (clark and curran, 2004<papid> P04-1014 </papid>b).</nextsent>
<nextsent>spurious ambiguity?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O195">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> the ccg parsing model.  </section>
<citcontext>
<prevsection>
<prevsent>surprisingly, the accuracy of the parser trained on partial data approaches that of the parser trained on full data: our best partial-data model is only 1.3%worse in terms of dependency f-score than the full data model, despite the fact that the partial data does not contain any explicit attachment information.
</prevsent>
<prevsent>clark and curran (2004<papid> P04-1014 </papid>b) describes two log-linear parsing models for ccg: normal-form derivation model and dependency model.</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
in this paper we use the dependency model, which requires sets of predicate-argument dependencies for training.1 1hockenmaier and steedman (2002) <papid> P02-1043 </papid>describe generative model of normal-form derivations; one possibility for training this model on partial data, which has not been explored, is to use the em algorithm (pereira and schabes, 1992).<papid> P92-1017 </papid>the predicate-argument dependencies are represented as 5-tuples: hf , f, s, ha, l?, where hf is the lexical item of the lexical category expressing the dependency relation; is the lexical category; isthe argument slot; ha is the head word of the ar gument; and encodes whether the dependency is non-local.</citsent>
<aftsection>
<nextsent>for example, the dependency encoding company as the object of bought (as in ibm bought the company) is represented as follows: bought2, (s\np1 )/np2 , 2, company4,??
</nextsent>
<nextsent>(1)ccg dependency structures are sets of predicate argument dependencies.
</nextsent>
<nextsent>we define the probability of dependency structure as the sum of the probabilities of all those derivations leading to that structure (clark and curran, 2004<papid> P04-1014 </papid>b).</nextsent>
<nextsent>spurious ambiguity?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O226">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> the ccg parsing model.  </section>
<citcontext>
<prevsection>
<prevsent>the function fi is the integer-valued frequency function of the ith feature;i is the weight of the ith feature; and zs is normalising constant.
</prevsent>
<prevsent>clark and curran (2004<papid> P04-1014 </papid>b) describes the training procedure for the dependency model, which uses discriminative estimation method by maximising the conditional likelihood of the model given the data(riezler et al, 2002).<papid> P02-1035 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
the optimisation of the objective function is performed using the limited-memory bfgs numerical optimisation algorithm (nocedal and wright, 1999; malouf, 2002), <papid> W02-2018 </papid>which requires calculation of the objective function and the gradient of the objective function at each iteration.</citsent>
<aftsection>
<nextsent>the objective function is defined below, where l(?)
</nextsent>
<nextsent>is the likelihood and g(?)
</nextsent>
<nextsent>is gaussian prior term for smoothing.
</nextsent>
<nextsent>145 he anticipates growth for the automaker np (s [dcl ]\np)/np np (np\np)/np np [nb]/n /n figure 1: example sentence with ccg lexical categories l?(?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O229">
<title id=" N06-1019.xml">partial training for a lexicalized grammar parser </title>
<section> the ccg parsing model.  </section>
<citcontext>
<prevsection>
<prevsent>an other way to think of the estimation process is that it attempts to put as much mass as possible on the derivations leading to the gold-standard structures (riezler et al, 2002).<papid> P02-1035 </papid></prevsent>
<prevsent>calculation of the feature expectations requires summing over all derivations for sentence, and summing over all derivations leading to gold standard dependency structure.</prevsent>
</prevsection>
<citsent citstr=" W03-1013 ">
clark and curran (2003) <papid> W03-1013 </papid>shows how the sum over the complete derivation space can be performed efficiently using packed chart and the inside-outside algorithm, and clark and curran (2004<papid> P04-1014 </papid>b) extends this method to sum over all derivations leading to gold-standard dependency structure.</citsent>
<aftsection>
<nextsent>the partial data we use for training the dependency model is derived from ccg lexical category sequences only.
</nextsent>
<nextsent>figure 1 gives an example sentence adapted from ccgbank (hockenmaier, 2003) together with its lexical category sequence.
</nextsent>
<nextsent>note that, although the attachment of the prepositional phrase to the noun phrase is not explicitly represented, it can be inferred in this example because the lexical category assigned to the preposition has to combine with noun phrase to the left, and in this example there is only one possibility.
</nextsent>
<nextsent>one of the key insight sin this paper is that the significant amount of syntactic information in ccg lexical categories allows us to infer attachment information in many cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O387">
<title id=" N06-4006.xml">knowtator a protege plugin for annotated corpus construction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there exists plethora of manual text annotation tools for creating annotated corpora.
</prevsent>
<prevsent>while it has been common for individual research groups to build customized annotation tools for their specific 1 http://protege.stanford.edu 273 figure 1 simple co-reference annotations in knowtator annotation tasks, several text annotation tools have emerged in the last few years that can be employed to accomplish wide variety of annotation tasks.
</prevsent>
</prevsection>
<citsent citstr=" N03-4009 ">
some of the better general-purpose annotation tools include callisto2, wordfreak3 (morton and lacivita, 2003), <papid> N03-4009 </papid>gate4, and mmax25.</citsent>
<aftsection>
<nextsent>each of these tools is distributed with limited number of annotation tasks that can be used out of the box.?
</nextsent>
<nextsent>many of the tasks that are provided can be customized to limited extent to suit the requirements of users annotation task via configuration files.
</nextsent>
<nextsent>in callisto, for example, simple annotation schema can be defined with an xml dtd that allows the creation of an annotation schema that is essentially tag set augmented with simple (e.g. string) attributes for each tag.
</nextsent>
<nextsent>in addition to configuration files, word freak provides plug-in architecture for creating task specific code modules that can be integrated into the user interface.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O388">
<title id=" N04-1039.xml">exponential priors for maximum entropy models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>exponential priors also lead to simpler learning algorithm and to easier to understand behavior.
</prevsent>
<prevsent>furthermore, exponential priors help explain the success of some previous smoothing techniques, and suggest simple variations that work better.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
conditional maximum entropy (maxent) models have been widely used for variety of tasks, including language modeling (rosenfeld, 1994), part-of-speech tagging, prepositional phrase attachment, and parsing (rat naparkhi, 1998), word selection for machine translation (berger et al, 1996), <papid> J96-1002 </papid>and finding sentence boundaries(reynar and ratnaparkhi, 1997).<papid> A97-1004 </papid></citsent>
<aftsection>
<nextsent>they are also sometimes called logistic regression models, maximum likelihood exponential models, log-linear models, and are even equivalent to form of perceptrons/single layer neural networks.
</nextsent>
<nextsent>in particular, perceptrons that use the standard sigmoid function, and optimize for log-loss are equivalent to maxent.
</nextsent>
<nextsent>multi-layer neural networks that optimize log loss are closely related, and much of the discussion will apply to them implicitly.
</nextsent>
<nextsent>conditional maxent models have traditionally either been un regularized or regularized by using gaussian prior on the parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O389">
<title id=" N04-1039.xml">exponential priors for maximum entropy models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>exponential priors also lead to simpler learning algorithm and to easier to understand behavior.
</prevsent>
<prevsent>furthermore, exponential priors help explain the success of some previous smoothing techniques, and suggest simple variations that work better.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
conditional maximum entropy (maxent) models have been widely used for variety of tasks, including language modeling (rosenfeld, 1994), part-of-speech tagging, prepositional phrase attachment, and parsing (rat naparkhi, 1998), word selection for machine translation (berger et al, 1996), <papid> J96-1002 </papid>and finding sentence boundaries(reynar and ratnaparkhi, 1997).<papid> A97-1004 </papid></citsent>
<aftsection>
<nextsent>they are also sometimes called logistic regression models, maximum likelihood exponential models, log-linear models, and are even equivalent to form of perceptrons/single layer neural networks.
</nextsent>
<nextsent>in particular, perceptrons that use the standard sigmoid function, and optimize for log-loss are equivalent to maxent.
</nextsent>
<nextsent>multi-layer neural networks that optimize log loss are closely related, and much of the discussion will apply to them implicitly.
</nextsent>
<nextsent>conditional maxent models have traditionally either been un regularized or regularized by using gaussian prior on the parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O390">
<title id=" N04-1039.xml">exponential priors for maximum entropy models </title>
<section> learning algorithms and discounting.  </section>
<citcontext>
<prevsection>
<prevsent>k 2k = expected[k] exp ( f#k ) and then solve for k. there is no closed form solution:it must be solved using numerical methods, such as newtons method, making this update much more complex and time consuming than the exponential prior.one can also derive variations on this update.
</prevsent>
<prevsent>for instance, in the appendix, we derive an update for improved iterative scaling (della pietra et al, 1997) with an exponential prior.
</prevsent>
</prevsection>
<citsent citstr=" P02-1002 ">
perhaps more importantly, one canalso derive updates for sequential conditional generalized iterative scaling (scgis) (goodman, 2002), <papid> P02-1002 </papid>which is several times faster than gis.</citsent>
<aftsection>
<nextsent>the scgis update for binary features with an exponential prior is simply := max ( 0, + log observed[k]?
</nextsent>
<nextsent>k expected[k] )one might wonder why we simply dont use conjugate gradient (cg) methods, which have been shown to converge quickly for maxent.
</nextsent>
<nextsent>there has not been formal comparison of scgis to conjugate gradient methods.
</nextsent>
<nextsent>in our own pilot studies, scgis is sometimes faster and sometimes slower.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O391">
<title id=" N04-1039.xml">exponential priors for maximum entropy models </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>for the language modeling experiments, we used three variances, one each for the unigram, bigram, and trigram models, again optimized on held out data.
</prevsent>
<prevsent>we were inspired to use an exponential prior by an actual examination of dataset.
</prevsent>
</prevsection>
<citsent citstr=" H01-1052 ">
in particular, we used the grammar-checking data of banko and brill (2001).<papid> H01-1052 </papid>we chose this set because there are commonly used versions both with small amounts of data (which is when we expect the prior to matter) and with large amounts ofdata (which is required to easily see what the distribution over correct?</citsent>
<aftsection>
<nextsent>parameter values is.) for one experiment, we trained model using gaussian prior, using large amount of data.
</nextsent>
<nextsent>we then found those parameters (s) that had at least 35 training instances ? enough to typically overcome the prior and train the parameter reliably.
</nextsent>
<nextsent>we then graphed the distribution of these parameters.
</nextsent>
<nextsent>while it is common to look at the distribution of data, the nlp and machine learning communities rarely examine distributions of model parameters, and yet this seems like good way to get inspiration for priors to try, using those parameters with enough data to help guess the priors for those with less, or at least to determine the correct form for the prior, if not the exact values.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O393">
<title id=" N07-1045.xml">near synonym choice in an intelligent thesaurus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this problem is difficult because the near-synonyms have senses that are very close to each other, and therefore they occur in similar contexts; we need to capture the subtle differences specific to each near-synonym.
</prevsent>
<prevsent>our thesaurus brings up only alternatives that have the same part-of-speech with the target word.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
the choices could come from various inventories of near-synonyms or similar words, for example theroget thesaurus (roget, 1852), dictionaries of synonyms (hayakawa, 1994), or clusters acquired from corpora (lin, 1998).<papid> P98-2127 </papid>in this paper we focus on the task of automatically selecting the best near-synonym that should be used in particular context.</citsent>
<aftsection>
<nextsent>the natural way to validate an algorithm for this task would be to ask human readers to evaluate the quality of the algorithms output, but this kind of evaluation would be very laborious.
</nextsent>
<nextsent>instead, we validate the algorithms by deleting selected words from sample sentences,to see whether the algorithms can restore the missing words.
</nextsent>
<nextsent>that is, we create lexical gap and evaluate the ability of the algorithms to fill the gap.
</nextsent>
<nextsent>two examples are presented in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O394">
<title id=" N07-1045.xml">near synonym choice in an intelligent thesaurus </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we also propose method that uses collocations and anti-collocations, and supervised method that uses words and mutual information scores as featured for machine learning.
</prevsent>
<prevsent>the idea of using the web as corpus of text shas been exploited by many researchers.
</prevsent>
</prevsection>
<citsent citstr=" P99-1020 ">
grefenstette (1999) used the web for example-based machine translation; kilgarriff (2001) investigated the type of noise in web data; mihalcea and moldovan (1999) <papid> P99-1020 </papid>and agirre and martinez (2000) used it as an additional resource for word sense disambiguation; resnik (1999) <papid> P99-1068 </papid>mined the web for bilingual texts;turney (2001) used web frequency counts to compute information retrieval-based mutual-information scores.</citsent>
<aftsection>
<nextsent>in computational linguistics special issue on the web as corpus (kilgarriff and grefenstette,1we thank egidio terra, charlie clarke, and univ. of waterloo for allowing us to use multi text, and to peter turney and iit/nrc forgiving us access to their local copy of the corpus.
</nextsent>
<nextsent>2003), keller and lapata (2003) <papid> J03-3005 </papid>show that web counts correlate well with counts collected from balanced corpus: the size of the web compensates for the noise in the data.</nextsent>
<nextsent>in this paper we are using very large corpus of web pages to address problem that has not been successfully solved before.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O395">
<title id=" N07-1045.xml">near synonym choice in an intelligent thesaurus </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we also propose method that uses collocations and anti-collocations, and supervised method that uses words and mutual information scores as featured for machine learning.
</prevsent>
<prevsent>the idea of using the web as corpus of text shas been exploited by many researchers.
</prevsent>
</prevsection>
<citsent citstr=" P99-1068 ">
grefenstette (1999) used the web for example-based machine translation; kilgarriff (2001) investigated the type of noise in web data; mihalcea and moldovan (1999) <papid> P99-1020 </papid>and agirre and martinez (2000) used it as an additional resource for word sense disambiguation; resnik (1999) <papid> P99-1068 </papid>mined the web for bilingual texts;turney (2001) used web frequency counts to compute information retrieval-based mutual-information scores.</citsent>
<aftsection>
<nextsent>in computational linguistics special issue on the web as corpus (kilgarriff and grefenstette,1we thank egidio terra, charlie clarke, and univ. of waterloo for allowing us to use multi text, and to peter turney and iit/nrc forgiving us access to their local copy of the corpus.
</nextsent>
<nextsent>2003), keller and lapata (2003) <papid> J03-3005 </papid>show that web counts correlate well with counts collected from balanced corpus: the size of the web compensates for the noise in the data.</nextsent>
<nextsent>in this paper we are using very large corpus of web pages to address problem that has not been successfully solved before.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O396">
<title id=" N07-1045.xml">near synonym choice in an intelligent thesaurus </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>grefenstette (1999) used the web for example-based machine translation; kilgarriff (2001) investigated the type of noise in web data; mihalcea and moldovan (1999) <papid> P99-1020 </papid>and agirre and martinez (2000) used it as an additional resource for word sense disambiguation; resnik (1999) <papid> P99-1068 </papid>mined the web for bilingual texts;turney (2001) used web frequency counts to compute information retrieval-based mutual-information scores.</prevsent>
<prevsent>in computational linguistics special issue on the web as corpus (kilgarriff and grefenstette,1we thank egidio terra, charlie clarke, and univ. of waterloo for allowing us to use multi text, and to peter turney and iit/nrc forgiving us access to their local copy of the corpus.</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
2003), keller and lapata (2003) <papid> J03-3005 </papid>show that web counts correlate well with counts collected from balanced corpus: the size of the web compensates for the noise in the data.</citsent>
<aftsection>
<nextsent>in this paper we are using very large corpus of web pages to address problem that has not been successfully solved before.
</nextsent>
<nextsent>in fact, the only work that addresses exactly the same task is that of edmonds (1997), <papid> P97-1067 </papid>as far as we are aware.</nextsent>
<nextsent>edmonds gives solution based on alexical co-occurrence network that included second order co-occurrences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O397">
<title id=" N07-1045.xml">near synonym choice in an intelligent thesaurus </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>2003), keller and lapata (2003) <papid> J03-3005 </papid>show that web counts correlate well with counts collected from balanced corpus: the size of the web compensates for the noise in the data.</prevsent>
<prevsent>in this paper we are using very large corpus of web pages to address problem that has not been successfully solved before.</prevsent>
</prevsection>
<citsent citstr=" P97-1067 ">
in fact, the only work that addresses exactly the same task is that of edmonds (1997), <papid> P97-1067 </papid>as far as we are aware.</citsent>
<aftsection>
<nextsent>edmonds gives solution based on alexical co-occurrence network that included second order co-occurrences.
</nextsent>
<nextsent>we use much larger corpus and simpler method, and we obtain much better results.our task has similarities to the word sense disambiguation task.
</nextsent>
<nextsent>our near-synonyms have senses that are very close to each other.
</nextsent>
<nextsent>in senseval, some of the fine-grained senses are also close to each other, so they might occur in similar contexts, while thecoarse-grained senses are expected to occur in distinct contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O399">
<title id=" N07-1017.xml">the domain restriction hypothesis relating term similarity and semantic consistency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>relation extraction is fundamental step in many natural language processing applications such as learning ontologies from texts (buitelaar et al., 2005) and question answering (pasca and harabagiu, 2001).the most common approach for acquiring concepts, instances and relations is to harvest semantic knowledge from texts.
</prevsent>
<prevsent>these techniques have been largely explored and today they achieve reasonableaccuracy.
</prevsent>
</prevsection>
<citsent citstr=" P06-1015 ">
harvested lexical resources, such as concept lists (pantel and lin, 2002), facts (etzioni etal., 2002) and semantic relations (pantel and pennacchiotti, 2006) <papid> P06-1015 </papid>could be then successfully used in different frameworks and applications.the state of the art technology for relation extraction primarily relies on pattern-based approaches (snow et al, 2006).<papid> P06-1101 </papid></citsent>
<aftsection>
<nextsent>these techniques are based on the recognition of the typical patterns that express particular relation in text (e.g. such as y?
</nextsent>
<nextsent>usually expresses an is-a relation).
</nextsent>
<nextsent>yet, text-based algorithms for relation extraction, in particular pattern-based algorithms, still suffer from number of limitations due to complexities of natural language, some of which we describe below.
</nextsent>
<nextsent>irrelevant relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O400">
<title id=" N07-1017.xml">the domain restriction hypothesis relating term similarity and semantic consistency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>relation extraction is fundamental step in many natural language processing applications such as learning ontologies from texts (buitelaar et al., 2005) and question answering (pasca and harabagiu, 2001).the most common approach for acquiring concepts, instances and relations is to harvest semantic knowledge from texts.
</prevsent>
<prevsent>these techniques have been largely explored and today they achieve reasonableaccuracy.
</prevsent>
</prevsection>
<citsent citstr=" P06-1101 ">
harvested lexical resources, such as concept lists (pantel and lin, 2002), facts (etzioni etal., 2002) and semantic relations (pantel and pennacchiotti, 2006) <papid> P06-1015 </papid>could be then successfully used in different frameworks and applications.the state of the art technology for relation extraction primarily relies on pattern-based approaches (snow et al, 2006).<papid> P06-1101 </papid></citsent>
<aftsection>
<nextsent>these techniques are based on the recognition of the typical patterns that express particular relation in text (e.g. such as y?
</nextsent>
<nextsent>usually expresses an is-a relation).
</nextsent>
<nextsent>yet, text-based algorithms for relation extraction, in particular pattern-based algorithms, still suffer from number of limitations due to complexities of natural language, some of which we describe below.
</nextsent>
<nextsent>irrelevant relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O403">
<title id=" N07-1017.xml">the domain restriction hypothesis relating term similarity and semantic consistency </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a pattern-based relation extraction algorithm is particularly likely to extract erroneous relations if it uses generic patterns, which are defined in (pantel and pennacchiotti, 2006) <papid> P06-1015 </papid>as broad coverage, noisy patterns with high recall and low precision (e.g. of y?</prevsent>
<prevsent>for part-of relation).</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
harvesting algorithms either ignore generic patterns(hearst, 1992) (<papid> C92-2082 </papid>affecting system recall) or use manually supervised filtering approaches (girju et al, 2006) or use completely unsupervised web-filtering methods (pantel and pennacchiotti, 2006).<papid> P06-1015 </papid></citsent>
<aftsection>
<nextsent>yet, these methods still do not sufficiently mitigate the problem of erroneous relations.
</nextsent>
<nextsent>background knowledge.
</nextsent>
<nextsent>another aspect that makes relation harvesting difficult is related to the 131nature of semantic relations: relations among entities are mostly paradigmatic (de saussure, 1922), and are usually established in absentia (i.e., they arenot made explicit in text).
</nextsent>
<nextsent>according to ecos position (eco, 1979), the background knowledge (e.g. persons are humans?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O407">
<title id=" N07-1017.xml">the domain restriction hypothesis relating term similarity and semantic consistency </title>
<section> semantic domains.  </section>
<citcontext>
<prevsection>
<prevsent>semantic domains are common areas of human discussion, which demonstrate lexical coherence, such as economics, politics, law, science,(magnini et al, 2002).
</prevsent>
<prevsent>at the lexical level, semantic domains identify clusters of (domain) related lexical-concepts, i.e. sets of highly paradigmatically related words also known as semantic fields.
</prevsent>
</prevsection>
<citsent citstr=" E06-2016 ">
in the literature, semantic domains have been inferred from corpora by adopting term clustering methodologies (gliozzo, 2005), and have been used for several nlp tasks, such as text categorization and ontology learning (gliozzo, 2006).<papid> E06-2016 </papid></citsent>
<aftsection>
<nextsent>semantic domains can be described by domain models (dms) (gliozzo, 2005).
</nextsent>
<nextsent>a dm is com 132putational model for semantic domains, that represents domain information at the term level, by defining set of term clusters.
</nextsent>
<nextsent>each cluster represents asemantic domain, i.e. set of terms that often cooccur in texts having similar topics.
</nextsent>
<nextsent>a dm is represented by k ? k? rectangular matrix d, containing the domain relevance for each term with respect to each domain, as illustrated in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O412">
<title id=" N07-1017.xml">the domain restriction hypothesis relating term similarity and semantic consistency </title>
<section> the pattern-based espresso system.  </section>
<citcontext>
<prevsection>
<prevsent>pattern induction.
</prevsent>
<prevsent>given an input set of seed instances , espresso infers new patterns connecting as many instances as possible in the given corpus.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
to do so, espresso uses slight modification of the state of the art algorithm described in (ravichandran and hovy, 2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>for each instance in input, the sentences containing it are first retrieved and then generalized, by replacing term expressions with terminological label using regular expressions on the pos-tags.
</nextsent>
<nextsent>this generalization allows to ease the problem of data sparseness in small corpora.
</nextsent>
<nextsent>unfortunately, as patterns become more generic, they are more prone to low precision.
</nextsent>
<nextsent>pattern ranking and selection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O423">
<title id=" N06-1024.xml">fully parsing the penn treebank </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we present two stage parser that recovers penn treebank style syntactic analyses of new sentences including skeletal syntactic structure, and, for the first time, both function tags and empty categories.
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
the accuracy of the first-stage parser on the standard parseval metric matches that of the (collins, 2003)<papid> J03-4003 </papid>parser on which it is based, despite the data fragmentation caused by the greatly enriched space of possible node labels.</citsent>
<aftsection>
<nextsent>this first stage simultaneously achieves near state-of-the art performance on recovering function tags with minimal modifications to theun derlying parser, modifying less than ten lines of code.
</nextsent>
<nextsent>the second stage achievesstate-of-the-art performance on the recovery of empty categories by combining linguistically-informed architecture and rich feature set with the power of modern machine learning methods.
</nextsent>
<nextsent>the trees in the penn treebank (bies et al, 1995) are annotated with great deal of information to make various aspects of the predicate-argument structure easy to decode, including both function tags and markers of empty?
</nextsent>
<nextsent>categories that represent displaced constituents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O429">
<title id=" N06-1024.xml">fully parsing the penn treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the trees in the penn treebank (bies et al, 1995) are annotated with great deal of information to make various aspects of the predicate-argument structure easy to decode, including both function tags and markers of empty?
</prevsent>
<prevsent>categories that represent displaced constituents.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
modern statistical parsers suchas (collins, 2003)<papid> J03-4003 </papid>and (charniak, 2000) <papid> A00-2018 </papid>however ignore much of this information and return only an we would like to thank fernando pereira, dan bikel, tony kroch and mark liberman for helpful suggestions.</citsent>
<aftsection>
<nextsent>this work was supported in part under the gale program of the defense advanced research projects agency, contract no.
</nextsent>
<nextsent>hr001106-c-0022, and in part by the national science foundation under grants nsf iis-0520798 and nsf eia 02-05448 and under an nsf graduate fellowship.
</nextsent>
<nextsent>impoverished version of the trees.
</nextsent>
<nextsent>while there hasbeen some work in the last few years on enriching the output of state-of-the-art parsers that output penn treebank-style trees with function tags (e.g.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O432">
<title id=" N06-1024.xml">fully parsing the penn treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while there hasbeen some work in the last few years on enriching the output of state-of-the-art parsers that output penn treebank-style trees with function tags (e.g.
</prevsent>
<prevsent>(blaheta, 2003)) or empty categories (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
(johnson, 2002; <papid> P02-1018 </papid>dienes and dubey, 2003<papid> W03-1005 </papid>a; dienes and dubey,2003<papid> W03-1005 </papid>b), only one system currently available, the dependency graph parser of (jijkoun and de rijke, 2004), <papid> P04-1040 </papid>recovers some representation of both these aspects of the treebank representation; its output, however, cannot be inverted to recover the original tree structures.</citsent>
<aftsection>
<nextsent>we present here parser,1 the first we know of, that recovers full penn treebank-style trees.
</nextsent>
<nextsent>this parser uses minimal modification of the collins parser to recover function tags, and then uses this enriched output to achieve or better state-of-the art performance on recovering empty categories.
</nextsent>
<nextsent>we focus here on treebank-style output for two reasons: first, annotators developing additional treebanks in new genres of english that conform to the treebank ii style book (bies et al, 1995) must currently add these additional annotations by hand, much more laborious process than correcting parser output (the currently used method for annotating the skeletal structure itself).
</nextsent>
<nextsent>our new parser is now in use in new treebank annotation effort.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O434">
<title id=" N06-1024.xml">fully parsing the penn treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while there hasbeen some work in the last few years on enriching the output of state-of-the-art parsers that output penn treebank-style trees with function tags (e.g.
</prevsent>
<prevsent>(blaheta, 2003)) or empty categories (e.g.
</prevsent>
</prevsection>
<citsent citstr=" W03-1005 ">
(johnson, 2002; <papid> P02-1018 </papid>dienes and dubey, 2003<papid> W03-1005 </papid>a; dienes and dubey,2003<papid> W03-1005 </papid>b), only one system currently available, the dependency graph parser of (jijkoun and de rijke, 2004), <papid> P04-1040 </papid>recovers some representation of both these aspects of the treebank representation; its output, however, cannot be inverted to recover the original tree structures.</citsent>
<aftsection>
<nextsent>we present here parser,1 the first we know of, that recovers full penn treebank-style trees.
</nextsent>
<nextsent>this parser uses minimal modification of the collins parser to recover function tags, and then uses this enriched output to achieve or better state-of-the art performance on recovering empty categories.
</nextsent>
<nextsent>we focus here on treebank-style output for two reasons: first, annotators developing additional treebanks in new genres of english that conform to the treebank ii style book (bies et al, 1995) must currently add these additional annotations by hand, much more laborious process than correcting parser output (the currently used method for annotating the skeletal structure itself).
</nextsent>
<nextsent>our new parser is now in use in new treebank annotation effort.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O444">
<title id=" N06-1024.xml">fully parsing the penn treebank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while there hasbeen some work in the last few years on enriching the output of state-of-the-art parsers that output penn treebank-style trees with function tags (e.g.
</prevsent>
<prevsent>(blaheta, 2003)) or empty categories (e.g.
</prevsent>
</prevsection>
<citsent citstr=" P04-1040 ">
(johnson, 2002; <papid> P02-1018 </papid>dienes and dubey, 2003<papid> W03-1005 </papid>a; dienes and dubey,2003<papid> W03-1005 </papid>b), only one system currently available, the dependency graph parser of (jijkoun and de rijke, 2004), <papid> P04-1040 </papid>recovers some representation of both these aspects of the treebank representation; its output, however, cannot be inverted to recover the original tree structures.</citsent>
<aftsection>
<nextsent>we present here parser,1 the first we know of, that recovers full penn treebank-style trees.
</nextsent>
<nextsent>this parser uses minimal modification of the collins parser to recover function tags, and then uses this enriched output to achieve or better state-of-the art performance on recovering empty categories.
</nextsent>
<nextsent>we focus here on treebank-style output for two reasons: first, annotators developing additional treebanks in new genres of english that conform to the treebank ii style book (bies et al, 1995) must currently add these additional annotations by hand, much more laborious process than correcting parser output (the currently used method for annotating the skeletal structure itself).
</nextsent>
<nextsent>our new parser is now in use in new treebank annotation effort.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O446">
<title id=" N06-1024.xml">fully parsing the penn treebank </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>under this representation the above sentence would look like ?(np-1 the dragon) 0 (np-2 i) am trying (np *-2) to slay (np *t*-1) is green.?
</prevsent>
<prevsent>despite their importance, these annotations have largely been ignored in statistical parsing work.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
the importance of returning this information for most real applications of parsing has been greatly obscured by the parseval metric (black et al, 1991), <papid> H91-1060 </papid>which explicitly ignores both function tags and null elements.</citsent>
<aftsection>
<nextsent>because much statistical parsing research has been driven until recently by this metric, which has never been updated, the crucial role of parsing in recovering semantic structure has been generally ignored.
</nextsent>
<nextsent>an early exception to this was (collins,1997) <papid> P97-1003 </papid>itself, where model 2 used function tags during the training process for heuristics to identify arguments (e.g., the tmp tag on the np in figure 1 disqualifies the np-tmp from being treated as anargument).</nextsent>
<nextsent>however, after this use, the tags are ignored, not included in the models, and absent fromthe parser output.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O447">
<title id=" N06-1024.xml">fully parsing the penn treebank </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>the importance of returning this information for most real applications of parsing has been greatly obscured by the parseval metric (black et al, 1991), <papid> H91-1060 </papid>which explicitly ignores both function tags and null elements.</prevsent>
<prevsent>because much statistical parsing research has been driven until recently by this metric, which has never been updated, the crucial role of parsing in recovering semantic structure has been generally ignored.</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
an early exception to this was (collins,1997) <papid> P97-1003 </papid>itself, where model 2 used function tags during the training process for heuristics to identify arguments (e.g., the tmp tag on the np in figure 1 disqualifies the np-tmp from being treated as anargument).</citsent>
<aftsection>
<nextsent>however, after this use, the tags are ignored, not included in the models, and absent fromthe parser output.
</nextsent>
<nextsent>collins?
</nextsent>
<nextsent>model 3 attempts to recover traces of wh-movement, with limited success.
</nextsent>
<nextsent>our system for restoring function tags is modification of collins?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O450">
<title id=" N06-1024.xml">fully parsing the penn treebank </title>
<section> function tags: results.  </section>
<citcontext>
<prevsection>
<prevsent>scores are for all sentences, not just those with less than 40 words.
</prevsent>
<prevsent>parseval labelled recall/precision scores for the unmodified and modified parsers, show that there is almost no difference in the scores: parser lr/lp model 2 88.12/88.31 model 2-funcb 88.23/88.31we find this somewhat surprising, as we had expected that sparse data problems would arise, due to the shattering of np into np-tmp, np-sbj, etc.table 1 shows the overall results and the breakdown for the different function tag groups.
</prevsent>
</prevsection>
<citsent citstr=" A00-2031 ">
for purposes of comparison, we have calculated our over all score both with and without clr.5 the (blaheta, 2003) numbers in parentheses in table 1 are fromhis feature trees specialized for the syntactic and semantic groups, while all his other numbers, including the overall score, are from using single feature set for his four function tag groups.6 5(jijkoun and de rijke, 2004) <papid> P04-1040 </papid>do not state whether they are including clr, but since they are comparing their results to (blaheta and charniak, 2000), <papid> A00-2031 </papid>we are assuming that they do.</citsent>
<aftsection>
<nextsent>they do not break their results down by group.
</nextsent>
<nextsent>6the p/r/f scores in (blaheta, 2003)[p. 23] are internally 186 ? overall ? ?
</nextsent>
<nextsent>breakdown by function tag group ? w/clr w/o clr syn sem top misc clr tag group frequency 55.87% 36.40% 2.60% 1.03% 5.76% model2-ftags 88.95 90.78 95.76 84.56 93.89 17.31 65.86 88.28 95.16 79.81 93.72 39.44 blaheta, 2003 (95.89) (83.37) jijkoun and de rijke, 2004 <papid> P04-1040 </papid>88.50 musillo and merlo, 2005 <papid> W05-1509 </papid>96.5 85.6 table 1: overall results (f-measure) and breakdown by function tag groups even though our tagging system results from only eliminating few lines of code from the collins parse, it has higher overall score than (blaheta,2003), and large increase over blah etas non specialized semantic score (79.81).</nextsent>
<nextsent>it also outperforms even blah etas specialized semantic score (83.37), and is very close to blah etas specialized score for the syntactic group (95.89).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O453">
<title id=" N06-1024.xml">fully parsing the penn treebank </title>
<section> function tags: results.  </section>
<citcontext>
<prevsection>
<prevsent>they do not break their results down by group.
</prevsent>
<prevsent>6the p/r/f scores in (blaheta, 2003)[p. 23] are internally 186 ? overall ? ?
</prevsent>
</prevsection>
<citsent citstr=" W05-1509 ">
breakdown by function tag group ? w/clr w/o clr syn sem top misc clr tag group frequency 55.87% 36.40% 2.60% 1.03% 5.76% model2-ftags 88.95 90.78 95.76 84.56 93.89 17.31 65.86 88.28 95.16 79.81 93.72 39.44 blaheta, 2003 (95.89) (83.37) jijkoun and de rijke, 2004 <papid> P04-1040 </papid>88.50 musillo and merlo, 2005 <papid> W05-1509 </papid>96.5 85.6 table 1: overall results (f-measure) and breakdown by function tag groups even though our tagging system results from only eliminating few lines of code from the collins parse, it has higher overall score than (blaheta,2003), and large increase over blah etas non specialized semantic score (79.81).</citsent>
<aftsection>
<nextsent>it also outperforms even blah etas specialized semantic score (83.37), and is very close to blah etas specialized score for the syntactic group (95.89).
</nextsent>
<nextsent>however,since the evaluation is over different set of nonterminals, arising from the different parsers,7 it is difficult to draw conclusions as to which system is definitively better?.
</nextsent>
<nextsent>it does seem clear, though,that by integrating the function tags into the lexicalized parser, the results are roughly comparable with the post-processing work, and it is much simpler, without the need for separate post-processing level or for specialized feature trees for the different tag groups.8 our results clarify, we believe, the recent results of (musillo and merlo, 2005), <papid> W05-1509 </papid>now state-of-the-art, which extends the parser of report significant modification of the henderson parser to incorporate strong notions of linguistic lo cality.</nextsent>
<nextsent>they also manually restructure some of the function tags using tree transformations, and then train on these re labelled trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O477">
<title id=" N06-1024.xml">fully parsing the penn treebank </title>
<section> empty categories: approach.  </section>
<citcontext>
<prevsection>
<prevsent>processing approaches.
</prevsent>
<prevsent>the linguistic sophistication of the work of (musillo and merlo, 2005) <papid> W05-1509 </papid>then provides an added boost in performance over simple in tegration.</prevsent>
</prevsection>
<citsent citstr=" P04-1042 ">
most learning based, phrasestructurebased (pslb) work9 on recovering empty categories has fallen into two classes: those which integrate empty category recovery into the parser (dienes and dubey, 2003<papid> W03-1005 </papid>a; dienes and dubey, 2003<papid> W03-1005 </papid>b) and those which recover empty categories from parser output in postprocessing step (johnson, 2002; <papid> P02-1018 </papid>levy and manning, 2004).<papid> P04-1042 </papid></citsent>
<aftsection>
<nextsent>levy and manning note that thus far no pslb postprocessing approach has come close to matching the integrated approach on the most numerous types of empty categories.
</nextsent>
<nextsent>however, there is rule based postprocessing approach consisting of set of entirely hand?
</nextsent>
<nextsent>designed rules (campbell, 2004) <papid> P04-1082 </papid>which has better 9as above, we consider only that work which both input sand outputs phrase structure trees.</nextsent>
<nextsent>this notably excludes jijkoun and de rijke (jijkoun and de rijke, 2004), <papid> P04-1040 </papid>who have system which seems to match the performance of dienes and dubey.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O478">
<title id=" N06-1024.xml">fully parsing the penn treebank </title>
<section> empty categories: approach.  </section>
<citcontext>
<prevsection>
<prevsent>levy and manning note that thus far no pslb postprocessing approach has come close to matching the integrated approach on the most numerous types of empty categories.
</prevsent>
<prevsent>however, there is rule based postprocessing approach consisting of set of entirely hand?
</prevsent>
</prevsection>
<citsent citstr=" P04-1082 ">
designed rules (campbell, 2004) <papid> P04-1082 </papid>which has better 9as above, we consider only that work which both input sand outputs phrase structure trees.</citsent>
<aftsection>
<nextsent>this notably excludes jijkoun and de rijke (jijkoun and de rijke, 2004), <papid> P04-1040 </papid>who have system which seems to match the performance of dienes and dubey.</nextsent>
<nextsent>however, they provide only aggregate statistics over allthe types of empty categories, making any sort of detailed comparison impossible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O499">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using empirical results based on parsing the wall street journal corpus we show that training statistical parse ron the combined labeled and unlabeled data strongly outperforms training only on the labeled data.
</prevsent>
<prevsent>the current crop of statistical parsers share similar training methodology.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
they train from the penn treebank (marcus et al, 1993); <papid> J93-2004 </papid>collection of 40,000 sentences that are labeled with corrected parse trees (ap proximately million word tokens).</citsent>
<aftsection>
<nextsent>in this paper, we explore methods for statistical parsing that can be used to combine small amounts of labeled data with unlimited amounts of unlabeled data.
</nextsent>
<nextsent>in the experiment reported here, we use 9695 sentences of bracketed data (234467word tokens).
</nextsent>
<nextsent>such methods are attractive for the following reasons:  bracketing sentences is an expensive process.
</nextsent>
<nextsent>aparser that can be trained on small amount of labeled data will reduce this annotation cost.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O500">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent> creating statistical parsers for novel domains and new languages will become easier.
</prevsent>
<prevsent> combining labeled data with unlabeled data allows exploration of unsupervised methods which cannow be tested using evaluations compatible with supervised statistical parsing.in this paper we introduce new approach that combines unlabeled data with small amount of labeled(bracketed) data to train statistical parser.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
we use co training method (yarowsky, 1995; <papid> P95-1026 </papid>blum and mitchell,  would like to thank aravind joshi, mitch marcus, mark liberman, b. srinivas, david chiang and the anonymous reviewers for helpful comments on this work.</citsent>
<aftsection>
<nextsent>this work was partially supported by nsf grant sbr8920230, aro grant daah0404-94-g-0426, and darpa grant n66001-00-1-8915.1998; goldman and zhou, 2000) that has been used previously to train classifiers in applications like word-sensedisambiguation (yarowsky, 1995), <papid> P95-1026 </papid>document classification (blum and mitchell, 1998) and named-entity recognition (collins and singer, 1999) <papid> W99-0613 </papid>and apply this method to the more complex domain of statistical parsing.</nextsent>
<nextsent>processing while machine learning techniques that exploit annotated data have been very successful in attacking problems in nlp, there are still some aspects which are considered to be open issues:  adapting to new domains: training on one domain, testing (using) on another.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O504">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent> combining labeled data with unlabeled data allows exploration of unsupervised methods which cannow be tested using evaluations compatible with supervised statistical parsing.in this paper we introduce new approach that combines unlabeled data with small amount of labeled(bracketed) data to train statistical parser.
</prevsent>
<prevsent>we use co training method (yarowsky, 1995; <papid> P95-1026 </papid>blum and mitchell,  would like to thank aravind joshi, mitch marcus, mark liberman, b. srinivas, david chiang and the anonymous reviewers for helpful comments on this work.</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
this work was partially supported by nsf grant sbr8920230, aro grant daah0404-94-g-0426, and darpa grant n66001-00-1-8915.1998; goldman and zhou, 2000) that has been used previously to train classifiers in applications like word-sensedisambiguation (yarowsky, 1995), <papid> P95-1026 </papid>document classification (blum and mitchell, 1998) and named-entity recognition (collins and singer, 1999) <papid> W99-0613 </papid>and apply this method to the more complex domain of statistical parsing.</citsent>
<aftsection>
<nextsent>processing while machine learning techniques that exploit annotated data have been very successful in attacking problems in nlp, there are still some aspects which are considered to be open issues:  adapting to new domains: training on one domain, testing (using) on another.
</nextsent>
<nextsent> higher performance when using limited amounts of annotated data. separating structural (robust) aspects of the problem from lexical (sparse) ones to improve performance on unseen data.
</nextsent>
<nextsent>in the particular domain of statistical parsing there has been limited success in moving towards unsupervised machine learning techniques (see section 7 for more discussion).
</nextsent>
<nextsent>a more promising approach is that of combining small amounts of seed labeled data with unlimited amounts of unlabeled data to bootstrap statistical parsers.in this paper, we use one such machine learning tech nique: co-training, which has been used successfully in several classification tasks like web page classification,word sense disambiguation and named-entity recognition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O506">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> unsupervised techniques in language.  </section>
<citcontext>
<prevsection>
<prevsent>a more promising approach is that of combining small amounts of seed labeled data with unlimited amounts of unlabeled data to bootstrap statistical parsers.in this paper, we use one such machine learning tech nique: co-training, which has been used successfully in several classification tasks like web page classification,word sense disambiguation and named-entity recognition.
</prevsent>
<prevsent>early work in combining labeled and unlabeled data for nlp tasks was done in the area of unsupervised part of speech (pos) tagging.
</prevsent>
</prevsection>
<citsent citstr=" A92-1018 ">
(cutting et al, 1992) <papid> A92-1018 </papid>reported very high results (96% on the brown corpus) for unsupervised pos tagging using hidden markov models (hmms) by exploiting hand-built tag dictionaries and equivalence classes.</citsent>
<aftsection>
<nextsent>tag dictionaries are predefined assignments of all possible pos tags to words in the test data.
</nextsent>
<nextsent>this impressive result triggered several follow-upstudies in which the effect of hand tuning the tag dictionary was quantified as combination of labeled and unla pierre/nnp vinken/nnp np will/md join/vb the/dt board/nn np as/in a/dt nonexecutive/jj director/nn np pp vp vp figure 1: an example of the kind of output expected from statistical parser.beled data.
</nextsent>
<nextsent>the experiments in (merialdo, 1994; <papid> J94-2001 </papid>elworthy, 1994) <papid> A94-1009 </papid>showed that only in very specific cases hmms were effective in combining labeled and unlabeled data.however, (brill, 1997) showed that aggressively using tag dictionaries extracted from labeled data could be used to bootstrap an unsupervised pos tagger with high accuracy (approx 95% on wsj data).</nextsent>
<nextsent>we exploit this approach of using tag dictionaries in our method as well (see section 3.2 for more details).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O507">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> unsupervised techniques in language.  </section>
<citcontext>
<prevsection>
<prevsent>tag dictionaries are predefined assignments of all possible pos tags to words in the test data.
</prevsent>
<prevsent>this impressive result triggered several follow-upstudies in which the effect of hand tuning the tag dictionary was quantified as combination of labeled and unla pierre/nnp vinken/nnp np will/md join/vb the/dt board/nn np as/in a/dt nonexecutive/jj director/nn np pp vp vp figure 1: an example of the kind of output expected from statistical parser.beled data.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
the experiments in (merialdo, 1994; <papid> J94-2001 </papid>elworthy, 1994) <papid> A94-1009 </papid>showed that only in very specific cases hmms were effective in combining labeled and unlabeled data.however, (brill, 1997) showed that aggressively using tag dictionaries extracted from labeled data could be used to bootstrap an unsupervised pos tagger with high accuracy (approx 95% on wsj data).</citsent>
<aftsection>
<nextsent>we exploit this approach of using tag dictionaries in our method as well (see section 3.2 for more details).
</nextsent>
<nextsent>it is important to point out that, before attacking the problem of parsing using similar machine learning techniques, we face representational problem which makes it difficult to define the notion of tag dictionary for statistical parser.
</nextsent>
<nextsent>the problem we face in parsing is more complex than assigning small fixed set of labels to examples.
</nextsent>
<nextsent>if the parser is to be generally applicable, it has to produce fairly complex label?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O508">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> unsupervised techniques in language.  </section>
<citcontext>
<prevsection>
<prevsent>tag dictionaries are predefined assignments of all possible pos tags to words in the test data.
</prevsent>
<prevsent>this impressive result triggered several follow-upstudies in which the effect of hand tuning the tag dictionary was quantified as combination of labeled and unla pierre/nnp vinken/nnp np will/md join/vb the/dt board/nn np as/in a/dt nonexecutive/jj director/nn np pp vp vp figure 1: an example of the kind of output expected from statistical parser.beled data.
</prevsent>
</prevsection>
<citsent citstr=" A94-1009 ">
the experiments in (merialdo, 1994; <papid> J94-2001 </papid>elworthy, 1994) <papid> A94-1009 </papid>showed that only in very specific cases hmms were effective in combining labeled and unlabeled data.however, (brill, 1997) showed that aggressively using tag dictionaries extracted from labeled data could be used to bootstrap an unsupervised pos tagger with high accuracy (approx 95% on wsj data).</citsent>
<aftsection>
<nextsent>we exploit this approach of using tag dictionaries in our method as well (see section 3.2 for more details).
</nextsent>
<nextsent>it is important to point out that, before attacking the problem of parsing using similar machine learning techniques, we face representational problem which makes it difficult to define the notion of tag dictionary for statistical parser.
</nextsent>
<nextsent>the problem we face in parsing is more complex than assigning small fixed set of labels to examples.
</nextsent>
<nextsent>if the parser is to be generally applicable, it has to produce fairly complex label?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O509">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> unsupervised techniques in language.  </section>
<citcontext>
<prevsection>
<prevsent>since the entire parse cannot be reasonably considered as monolithic label, the usual method in parsing is to decompose the structure assigned in the following way: s(join) ! np(vinken) vp(join) np(vinken) ! pierre vinken vp(join) ! will vp(join) vp(join) ! join np(board) pp(as) : : : however, such recursive decomposition of structure does not allow simple notion of tag dictionary.
</prevsent>
<prevsent>we solve this problem by decomposing the structure in an approach that is different from that shown above which uses context-free rules.
</prevsent>
</prevsection>
<citsent citstr=" C92-2066 ">
the approach uses the notion of tree rewriting as defined in the lexicalized tree adjoining grammar(ltag) formalism (joshi and schabes, 1992)<papid> C92-2066 </papid>1 which re 1this is lexicalized version of tree adjoining grammar (joshi et al., 1975; joshi, 1985).tains the notion of lexicalization that is crucial in the success of statistical parser while permitting simple definition of tag dictionary.</citsent>
<aftsection>
<nextsent>for example, the parse in figure 1 can be generated by assigning the structured labels shown in figure 2 to each word in the sentence (for simplicity, we assume that the noun phrases are generated here as single word).
</nextsent>
<nextsent>we use tool described in (xiaet al, 2000) <papid> W00-1307 </papid>to convert the penn treebank into this rep resentation.</nextsent>
<nextsent>pierre vinken np will vp vp np join np vp the board np vp as np pp vp non executive director np figure 2: parsing as tree classification and attachment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O510">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> unsupervised techniques in language.  </section>
<citcontext>
<prevsection>
<prevsent>the approach uses the notion of tree rewriting as defined in the lexicalized tree adjoining grammar(ltag) formalism (joshi and schabes, 1992)<papid> C92-2066 </papid>1 which re 1this is lexicalized version of tree adjoining grammar (joshi et al., 1975; joshi, 1985).tains the notion of lexicalization that is crucial in the success of statistical parser while permitting simple definition of tag dictionary.</prevsent>
<prevsent>for example, the parse in figure 1 can be generated by assigning the structured labels shown in figure 2 to each word in the sentence (for simplicity, we assume that the noun phrases are generated here as single word).</prevsent>
</prevsection>
<citsent citstr=" W00-1307 ">
we use tool described in (xiaet al, 2000) <papid> W00-1307 </papid>to convert the penn treebank into this rep resentation.</citsent>
<aftsection>
<nextsent>pierre vinken np will vp vp np join np vp the board np vp as np pp vp non executive director np figure 2: parsing as tree classification and attachment.
</nextsent>
<nextsent>combining the trees together by rewriting nodes as trees (explained in section 2.1) gives us the parse tree in figure 1.
</nextsent>
<nextsent>a history of the bi-lexical dependencies that define the probability model used to construct the parse is shown in figure 3.
</nextsent>
<nextsent>this history is called the derivation tree.in addition, as byproduct of this kind of representation we obtain more than the phrase structure of each sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O512">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> unsupervised techniques in language.  </section>
<citcontext>
<prevsection>
<prevsent>pierre_vinken will the_board a_nonexecutive_director as join figure 3: derivation indicating all the attachments between trees that have occurred during the parse of the sentence.
</prevsent>
<prevsent>2.1 the generative model.
</prevsent>
</prevsection>
<citsent citstr=" C92-2065 ">
a stochastic ltag derivation proceeds as follows (sch abes, 1992; <papid> C92-2066 </papid>resnik, 1992).<papid> C92-2065 </papid></citsent>
<aftsection>
<nextsent>an initial tree is selected with probability pinit and other trees selected by words in the sentence are combined using the operations of substitution and adjoining.
</nextsent>
<nextsent>these operations are explained below with examples.
</nextsent>
<nextsent>each of these operations is performed with probability pattach.
</nextsent>
<nextsent>for each  that can be valid start of derivation:  pinit() = 1substitution is defined as rewriting node in the frontier of tree with probability pattach which is said to be proper if:  0 pattach(;  !  0 ) = 1 where ;  !  0 indicates that tree  0 is substituting into node  in tree  . an example of the operation of substitution is shown in figure 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O520">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>the following aresome aspects of the scoring that might be useful for com pari sion with other results: no punctuations are scored, including sentence final punctuation.
</prevsent>
<prevsent>empty elements are not scored.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
we used evalb (written by satoshisekine and michael collins) which scores based on parseval (black et al, 1991); <papid> H91-1060 </papid>with the standard parameter file (as per standard practice, part of speech brackets were not part of the evaluation).</citsent>
<aftsection>
<nextsent>also, we used adwait ratnaparkhis part-of-speech tagger (ratnaparkhi, 1996) <papid> W96-0213 </papid>to tag unknown words in the test data.</nextsent>
<nextsent>we obtained 80.02% and 79.64% labeled bracketing precision and recall respectively (as defined in (black et al, 1991)).<papid> H91-1060 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O521">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>empty elements are not scored.
</prevsent>
<prevsent>we used evalb (written by satoshisekine and michael collins) which scores based on parseval (black et al, 1991); <papid> H91-1060 </papid>with the standard parameter file (as per standard practice, part of speech brackets were not part of the evaluation).</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
also, we used adwait ratnaparkhis part-of-speech tagger (ratnaparkhi, 1996) <papid> W96-0213 </papid>to tag unknown words in the test data.</citsent>
<aftsection>
<nextsent>we obtained 80.02% and 79.64% labeled bracketing precision and recall respectively (as defined in (black et al, 1991)).<papid> H91-1060 </papid></nextsent>
<nextsent>the baseline model which was only trained on the 9695 sentences of labeled data performed at 72.23% and 69.12% precision and recall.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O523">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> previous work: combining labeled and.  </section>
<citcontext>
<prevsection>
<prevsent>however, there are still inherent computational limitations due to the vast search space (see (pietra et al, 1994) for discussion).
</prevsent>
<prevsent>none of these approaches can even be realistically compared to supervised parsers that are trained and tested on the kind of representations and the complexity of sentences that are found in the penn treebank.
</prevsent>
</prevsection>
<citsent citstr=" P98-1035 ">
(chelba and jelinek, 1998) <papid> P98-1035 </papid>combine unlabeled and labeled data for parsing with view towards language modeling applications.</citsent>
<aftsection>
<nextsent>the goal in their work is not to get the right bracketing or dependencies but to reduce the word error rate in speech recognizer.our approach is closely related to previous co training methods (yarowsky, 1995; <papid> P95-1026 </papid>blum and mitchell, 1998; goldman and zhou, 2000; collins and singer, 1999).<papid> W99-0613 </papid></nextsent>
<nextsent>(yarowsky, 1995) <papid> P95-1026 </papid>first introduced an iterative method for increasing small set of seed data used to disambiguate dual word senses by exploiting the constraint that in segment of discourse only one sense of word is used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O531">
<title id=" N01-1023.xml">applying co training methods to statistical parsing </title>
<section> previous work: combining labeled and.  </section>
<citcontext>
<prevsection>
<prevsent>also, em has been used successfully in text classification in combination of labeled and unlabeled data (see (nigam et al, 1999)).
</prevsent>
<prevsent> in our experiments, unlike (blum and mitchell,1998) we do not balance the label priors when picking new labeled examples for addition to the training data.
</prevsent>
</prevsection>
<citsent citstr=" W00-1306 ">
one way to incorporate this into our algorithm would be to incorporate some form of sample selection (or active learning) into the selection of examples that are considered as labeled with high confidence (hwa, 2000).<papid> W00-1306 </papid></citsent>
<aftsection>
<nextsent>in this paper, we proposed new approach for training statistical parser that combines labeled with unlabeleddata.
</nextsent>
<nextsent>it uses co-training method where pair of models attempt to increase their agreement on labeling the data.
</nextsent>
<nextsent>the algorithm takes as input small corpus of 9695 sentences (234467 word tokens) of bracketed data,a large pool of unlabeled text and tag dictionary of lexicalized structures for each word in this training set (basedon the ltag formalism).
</nextsent>
<nextsent>the algorithm presented itera tively labels the unlabeled dataset with parse trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O532">
<title id=" N03-2018.xml">towards emotion prediction in spoken tutoring dialogues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>or uncertainly?), but most intelligent tutoring dialogue systems are text-based and thus limited in their ability to recognize such learning states (rose and freedman, 2000; rose and aleven, 2002).
</prevsent>
<prevsent>building spoken dialogue tutoring systems has great potential benefit, for speech is the most natural and easy to use form of natural language interaction, and it supplies rich source of prosodic and acoustic information about the speakers current mental state, which can be used to monitor the pedagogical effectiveness of student-computer interactions.
</prevsent>
</prevsection>
<citsent citstr=" P01-1048 ">
the success of computer-based tutoring systems could increase if they predicted and adapted to student emotional states, e.g. reinforcing positive states, while rectifying negative states (evens, 2002).although (ang et al, 2002; litman et al, 2001; <papid> P01-1048 </papid>batliner et al, 2000) have hand-labeled naturally-occurring utterances in variety of corpora for various emotions, then extracted acoustic, prosodic and lexical features and used machine-learning techniques to develop predictive models, little work to date has addressed emotion detection in computer-based educational settings.</citsent>
<aftsection>
<nextsent>in this paper we describe preliminary annotation of positive, negative, and neutral emotions in human-human tutoring corpus and discuss the results of pilot machine learning experiments whose goal is to develop computational models of specific emotional states (section 3) for use in spoken dialogue system (section 2).
</nextsent>
<nextsent>we are developing spoken dialogue system, called it spoke (intelligent tutoring spoken dialogue system), which uses as its back-end?
</nextsent>
<nextsent>the text-based why2-atlas dialogue tutoring system (vanlehn et al, 2002).
</nextsent>
<nextsent>inwhy2-atlas, student types an essay answering qualitative physics problem and computer tutor then engageshim/her in dialogue to provide feedback, correct misconceptions, and elicit more complete explanations, after which the student revises his/her essay, thereby ending the tutoring or causing another round of tutoring/essay revision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O533">
<title id=" N06-2003.xml">museli a multi source evidence integration approach to topic segmentation of spontaneous dialogue </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>existing topic segmentation approaches can be loosely classified into two types: (1) lexical cohesion models, and (2) content-oriented models.
</prevsent>
<prevsent>the underlying assumption in lexical cohesion models is that shift in term distribution signals shift in topic (halliday and hassan, 1976).
</prevsent>
</prevsection>
<citsent citstr=" J97-1003 ">
the best known algorithm based on this idea is text tiling (hearst, 1997).<papid> J97-1003 </papid></citsent>
<aftsection>
<nextsent>in text tiling, sliding window is passed over the vector-space representation of the text.
</nextsent>
<nextsent>at each position, the cosine correlation between the upper and lower region of the sliding window is compared with that of the peak cosine correlation values to the left and right of the window.
</nextsent>
<nextsent>a segment boundary is predicted when the magnitude of the difference exceeds threshold.
</nextsent>
<nextsent>one drawback to relying on term co-occurrence to signal topic continuity is that synonyms or related terms are treated as thematically-unrelated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O534">
<title id=" N06-2003.xml">museli a multi source evidence integration approach to topic segmentation of spontaneous dialogue </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>one drawback to relying on term co-occurrence to signal topic continuity is that synonyms or related terms are treated as thematically-unrelated.
</prevsent>
<prevsent>one solution to this problem is using dimensionality reduction technique such as latent semantic analysis (lsa) (landauer and dumais, 1997).
</prevsent>
</prevsection>
<citsent citstr=" H05-1122 ">
two such algorithms for segmentation are described in (foltz, 1998) and (olney and cai, 2005).<papid> H05-1122 </papid></citsent>
<aftsection>
<nextsent>both text tiling and foltzs approach measure coherence as function of the repetition of thematically-related terms.
</nextsent>
<nextsent>text tiling looks for cooccurrences of terms or term-stems and foltz uses lsa to measure semantic relatedness between terms.
</nextsent>
<nextsent>olney and cais ortho normal basis approach also uses lsa, but allows richer representation of discourse coherence, which is that coherence is function of how much new information discourse unit (e.g. dialogue contribution) adds (informativity) and how relevant it is to the local context (relevance) (olney and cai, 2005).<papid> H05-1122 </papid></nextsent>
<nextsent>content-oriented models, such as (barzilay and lee, 2004), <papid> N04-1015 </papid>relyon the re-occurrence of patterns of topics over multiple realizations of thematically similar discourses, such as series of newspaper articles about similar events.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O542">
<title id=" N06-2003.xml">museli a multi source evidence integration approach to topic segmentation of spontaneous dialogue </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>text tiling looks for cooccurrences of terms or term-stems and foltz uses lsa to measure semantic relatedness between terms.
</prevsent>
<prevsent>olney and cais ortho normal basis approach also uses lsa, but allows richer representation of discourse coherence, which is that coherence is function of how much new information discourse unit (e.g. dialogue contribution) adds (informativity) and how relevant it is to the local context (relevance) (olney and cai, 2005).<papid> H05-1122 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1015 ">
content-oriented models, such as (barzilay and lee, 2004), <papid> N04-1015 </papid>relyon the re-occurrence of patterns of topics over multiple realizations of thematically similar discourses, such as series of newspaper articles about similar events.</citsent>
<aftsection>
<nextsent>their approach utilizes hidden markov model where states correspond to topics, and state transition probabilities correspond to topic shifts.
</nextsent>
<nextsent>to obtain the desired 9 number of topics (states), text spans of uniform length (individual contributions, in our case) are clustered.
</nextsent>
<nextsent>then, state emission probabilities are induced using smoothed cluster-specific language models.
</nextsent>
<nextsent>transition probabilities are induced by considering the proportion of documents in which contribution assigned to the source cluster (state) immediately precedes contribution assigned to the target cluster (state).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O547">
<title id=" N06-2003.xml">museli a multi source evidence integration approach to topic segmentation of spontaneous dialogue </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>travel agent and customer) 10 how conversational role affects how speakers mark topic shifts.
</prevsent>
<prevsent>table 1 presents statistics describing characteristics of these two corpora.
</prevsent>
</prevsection>
<citsent citstr=" P93-1020 ">
similar to (passonneau and litman, 1993), <papid> P93-1020 </papid>we adopt flat model of topic segmentation for our gold standard based on discourse segment purpose, where shift in topic corresponds to shift in purpose that is acknowledged and acted upon by both conversational agents.</citsent>
<aftsection>
<nextsent>we evaluated inter-coder reliability over 10% of the thermo corpus mentioned above.
</nextsent>
<nextsent>3 annotators were given 10 page coding manual with explanation of our informal definition of shared discourse segment purpose as well as examples of segmented dialogues.
</nextsent>
<nextsent>pairwise inter-coder agreement was above 0.7 kappa for all pairs of annotators.
</nextsent>
<nextsent>olney &amp; cai corpus thermo corpus # dialogues 42 22 contributions/ dialogue 195.40 217.90 contributions/ topic 24.00 13.31 topics/dialogue 8.14 16.36 words/ contribution 28.63 5.12 table 1: evaluation corpora statistics 4.2 baseline approaches.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O554">
<title id=" N06-4004.xml">mttk an alignment toolkit for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel text alignment procedures attempt to identify translation equivalences within collections of translated documents.
</prevsent>
<prevsent>this can be be done at various levels.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
at the finest level, this involves the alignment of words and phrases within two sentences that are known to be translations (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>vogel et al, 1996; <papid> C96-2141 </papid>deng and byrne,2005).<papid> H05-1022 </papid></citsent>
<aftsection>
<nextsent>another task is the identification and alignment of sentence-level segments within document pairs that are known to be translations (gale and church, 1991); <papid> P91-1023 </papid>this is referred to as sentence-levelalignment, although it may also involve the alignment of sub-sentential segments (deng et al, ) as well as the identification of long segments in either document which are not translations.</nextsent>
<nextsent>there is also document level translation which involves the identification of translated document pairs in collection of documents in multiple languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O555">
<title id=" N06-4004.xml">mttk an alignment toolkit for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel text alignment procedures attempt to identify translation equivalences within collections of translated documents.
</prevsent>
<prevsent>this can be be done at various levels.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
at the finest level, this involves the alignment of words and phrases within two sentences that are known to be translations (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>vogel et al, 1996; <papid> C96-2141 </papid>deng and byrne,2005).<papid> H05-1022 </papid></citsent>
<aftsection>
<nextsent>another task is the identification and alignment of sentence-level segments within document pairs that are known to be translations (gale and church, 1991); <papid> P91-1023 </papid>this is referred to as sentence-levelalignment, although it may also involve the alignment of sub-sentential segments (deng et al, ) as well as the identification of long segments in either document which are not translations.</nextsent>
<nextsent>there is also document level translation which involves the identification of translated document pairs in collection of documents in multiple languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O556">
<title id=" N06-4004.xml">mttk an alignment toolkit for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel text alignment procedures attempt to identify translation equivalences within collections of translated documents.
</prevsent>
<prevsent>this can be be done at various levels.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
at the finest level, this involves the alignment of words and phrases within two sentences that are known to be translations (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>vogel et al, 1996; <papid> C96-2141 </papid>deng and byrne,2005).<papid> H05-1022 </papid></citsent>
<aftsection>
<nextsent>another task is the identification and alignment of sentence-level segments within document pairs that are known to be translations (gale and church, 1991); <papid> P91-1023 </papid>this is referred to as sentence-levelalignment, although it may also involve the alignment of sub-sentential segments (deng et al, ) as well as the identification of long segments in either document which are not translations.</nextsent>
<nextsent>there is also document level translation which involves the identification of translated document pairs in collection of documents in multiple languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O558">
<title id=" N06-4004.xml">mttk an alignment toolkit for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel text alignment procedures attempt to identify translation equivalences within collections of translated documents.
</prevsent>
<prevsent>this can be be done at various levels.
</prevsent>
</prevsection>
<citsent citstr=" H05-1022 ">
at the finest level, this involves the alignment of words and phrases within two sentences that are known to be translations (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>vogel et al, 1996; <papid> C96-2141 </papid>deng and byrne,2005).<papid> H05-1022 </papid></citsent>
<aftsection>
<nextsent>another task is the identification and alignment of sentence-level segments within document pairs that are known to be translations (gale and church, 1991); <papid> P91-1023 </papid>this is referred to as sentence-levelalignment, although it may also involve the alignment of sub-sentential segments (deng et al, ) as well as the identification of long segments in either document which are not translations.</nextsent>
<nextsent>there is also document level translation which involves the identification of translated document pairs in collection of documents in multiple languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O559">
<title id=" N06-4004.xml">mttk an alignment toolkit for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this can be be done at various levels.
</prevsent>
<prevsent>at the finest level, this involves the alignment of words and phrases within two sentences that are known to be translations (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>vogel et al, 1996; <papid> C96-2141 </papid>deng and byrne,2005).<papid> H05-1022 </papid></prevsent>
</prevsection>
<citsent citstr=" P91-1023 ">
another task is the identification and alignment of sentence-level segments within document pairs that are known to be translations (gale and church, 1991); <papid> P91-1023 </papid>this is referred to as sentence-levelalignment, although it may also involve the alignment of sub-sentential segments (deng et al, ) as well as the identification of long segments in either document which are not translations.</citsent>
<aftsection>
<nextsent>there is also document level translation which involves the identification of translated document pairs in collection of documents in multiple languages.
</nextsent>
<nextsent>as an example, figure 1 shows parallel chinese/english text that is aligned at the sentence, word, and phrase levels.
</nextsent>
<nextsent>parallel text plays crucial role in multi-lingualnatural language processing research.
</nextsent>
<nextsent>in particular, statistical machine translation systems require collections of sentence pairs (or sentence fragment pairs) as the basic ingredients for building statistical word and phrase alignment models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O581">
<title id=" N04-3002.xml">itspoke an intelligent tutoring spoken dialogue system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(aist et al, 2002) have shown that adding emotional processing toa dialogue-based reading tutor increases student persistence.
</prevsent>
<prevsent>information in the speech signal such as prosody has been shown to be rich source of information for predicting emotional states in other types of dialogue interactions (ang et al, 2002; lee et al, 2002; batliner et al., 2003; devillers et al, 2003; shafran et al, 2003).
</prevsent>
</prevsection>
<citsent citstr=" W01-1609 ">
with advances in speech technology, several project shave begun to incorporate basic spoken language capabilities into their systems (mostow and aist, 2001; fry et al, 2001; <papid> W01-1609 </papid>graesser et al, 2001; rickel and johnson, 2000).</citsent>
<aftsection>
<nextsent>however, to date there has been little examination of the ramifications of using spoken modality for dialogue tutoring.
</nextsent>
<nextsent>to assess the impact and evaluate the utility of adding spoken language capabilities to dialogue tutoring systems, we have built itspoke (intelligent tutoring spoken dialogue system), spoken dialogue system that uses the why2-atlas conceptual physics tutoring sys tem (vanlehn et al, 2002) as its back-end.?
</nextsent>
<nextsent>we are using itspoke as platform for examining whether acoustic-prosodic information can be used to improve the recognition of pedagogic ally useful information such as student emotion (forbes-riley and litman, 2004; litman and forbes-riley, 2004), and whether speech can improve the performance evaluations of dialogue tutoring systems (e.g., as measured by learning gains, efficiency, usability, etc.)
</nextsent>
<nextsent>(rose?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O582">
<title id=" N04-1023.xml">discriminative reranking for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we provide experimental results on the nist 2003 chinese-english large data track evaluation.
</prevsent>
<prevsent>we also provide theoretical analysis of our algorithms and experiments that verify that our algorithms provide state-of-the art performance in machine translation.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
the noisy-channel model (brown et al, 1990) <papid> J90-2002 </papid>has been the foundation for statistical machine translation (smt)for over ten years.</citsent>
<aftsection>
<nextsent>recently so-called reranking techniques, such as maximum entropy models (och and ney,2002) <papid> P02-1038 </papid>and gradient methods (och, 2003), <papid> P03-1021 </papid>have been applied to machine translation (mt), and have provided significant improvements.</nextsent>
<nextsent>in this paper, we introduce two novel machine learning algorithms specialized for the mt task.discriminative reranking algorithms have also contributed to improvements in natural language parsing and tagging performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O584">
<title id=" N04-1023.xml">discriminative reranking for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also provide theoretical analysis of our algorithms and experiments that verify that our algorithms provide state-of-the art performance in machine translation.
</prevsent>
<prevsent>the noisy-channel model (brown et al, 1990) <papid> J90-2002 </papid>has been the foundation for statistical machine translation (smt)for over ten years.</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
recently so-called reranking techniques, such as maximum entropy models (och and ney,2002) <papid> P02-1038 </papid>and gradient methods (och, 2003), <papid> P03-1021 </papid>have been applied to machine translation (mt), and have provided significant improvements.</citsent>
<aftsection>
<nextsent>in this paper, we introduce two novel machine learning algorithms specialized for the mt task.discriminative reranking algorithms have also contributed to improvements in natural language parsing and tagging performance.
</nextsent>
<nextsent>discriminative reranking algorithms used for these applications include perceptron, boosting and support vector machines (svms).
</nextsent>
<nextsent>in the machine learning community, some novel discriminative ranking (also called ordinal regression) algorithms have been proposed in recent years.
</nextsent>
<nextsent>based on this work, in this paper, we will present some novel discriminative reranking techniques applied to machine translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O585">
<title id=" N04-1023.xml">discriminative reranking for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also provide theoretical analysis of our algorithms and experiments that verify that our algorithms provide state-of-the art performance in machine translation.
</prevsent>
<prevsent>the noisy-channel model (brown et al, 1990) <papid> J90-2002 </papid>has been the foundation for statistical machine translation (smt)for over ten years.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
recently so-called reranking techniques, such as maximum entropy models (och and ney,2002) <papid> P02-1038 </papid>and gradient methods (och, 2003), <papid> P03-1021 </papid>have been applied to machine translation (mt), and have provided significant improvements.</citsent>
<aftsection>
<nextsent>in this paper, we introduce two novel machine learning algorithms specialized for the mt task.discriminative reranking algorithms have also contributed to improvements in natural language parsing and tagging performance.
</nextsent>
<nextsent>discriminative reranking algorithms used for these applications include perceptron, boosting and support vector machines (svms).
</nextsent>
<nextsent>in the machine learning community, some novel discriminative ranking (also called ordinal regression) algorithms have been proposed in recent years.
</nextsent>
<nextsent>based on this work, in this paper, we will present some novel discriminative reranking techniques applied to machine translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O589">
<title id=" N04-1023.xml">discriminative reranking for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this means unlikely alignments are being considered while training the model and this also results in additional decoding complexity.
</prevsent>
<prevsent>several mt models were proposed as extensions of the ibm models which used this intuition to add additional linguistic constraints to decrease the decoding perplexity and increase the translation quality.
</prevsent>
</prevsection>
<citsent citstr=" P98-2221 ">
wang and waibel (1998) <papid> P98-2221 </papid>proposed an smt model based on phrase-based alignments.</citsent>
<aftsection>
<nextsent>since their translation model reordered phrases directly, it achieved higher accuracy for translation between languages with different word orders.
</nextsent>
<nextsent>in (och and weber, 1998; <papid> P98-2162 </papid>och et al,1999), <papid> W99-0604 </papid>two-level alignment model was employed to utilize shallow phrase structures: alignment between templates was used to handle phrase reordering, and word alignments within template were used to handle phrase to phrase translation.</nextsent>
<nextsent>however, phrase level alignment cannot handle long distance reordering effectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O590">
<title id=" N04-1023.xml">discriminative reranking for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wang and waibel (1998) <papid> P98-2221 </papid>proposed an smt model based on phrase-based alignments.</prevsent>
<prevsent>since their translation model reordered phrases directly, it achieved higher accuracy for translation between languages with different word orders.</prevsent>
</prevsection>
<citsent citstr=" P98-2162 ">
in (och and weber, 1998; <papid> P98-2162 </papid>och et al,1999), <papid> W99-0604 </papid>two-level alignment model was employed to utilize shallow phrase structures: alignment between templates was used to handle phrase reordering, and word alignments within template were used to handle phrase to phrase translation.</citsent>
<aftsection>
<nextsent>however, phrase level alignment cannot handle long distance reordering effectively.
</nextsent>
<nextsent>parse trees have also been used in alignment models.
</nextsent>
<nextsent>wu (1997) <papid> J97-3002 </papid>introduced constraints on alignments using probabilistic synchronous context-free grammar restricted to chomsky normal form.</nextsent>
<nextsent>(wu, 1997) <papid> J97-3002 </papid>was an implicit or self organizing syntax model as it did not use treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O591">
<title id=" N04-1023.xml">discriminative reranking for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wang and waibel (1998) <papid> P98-2221 </papid>proposed an smt model based on phrase-based alignments.</prevsent>
<prevsent>since their translation model reordered phrases directly, it achieved higher accuracy for translation between languages with different word orders.</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
in (och and weber, 1998; <papid> P98-2162 </papid>och et al,1999), <papid> W99-0604 </papid>two-level alignment model was employed to utilize shallow phrase structures: alignment between templates was used to handle phrase reordering, and word alignments within template were used to handle phrase to phrase translation.</citsent>
<aftsection>
<nextsent>however, phrase level alignment cannot handle long distance reordering effectively.
</nextsent>
<nextsent>parse trees have also been used in alignment models.
</nextsent>
<nextsent>wu (1997) <papid> J97-3002 </papid>introduced constraints on alignments using probabilistic synchronous context-free grammar restricted to chomsky normal form.</nextsent>
<nextsent>(wu, 1997) <papid> J97-3002 </papid>was an implicit or self organizing syntax model as it did not use treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O592">
<title id=" N04-1023.xml">discriminative reranking for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, phrase level alignment cannot handle long distance reordering effectively.
</prevsent>
<prevsent>parse trees have also been used in alignment models.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
wu (1997) <papid> J97-3002 </papid>introduced constraints on alignments using probabilistic synchronous context-free grammar restricted to chomsky normal form.</citsent>
<aftsection>
<nextsent>(wu, 1997) <papid> J97-3002 </papid>was an implicit or self organizing syntax model as it did not use treebank.</nextsent>
<nextsent>yamada and knight (2001) <papid> P01-1067 </papid>used statistical parser trained using treebank in the source language to produce parse trees and proposed tree to string model for alignment.gildea (2003) <papid> P03-1011 </papid>proposed tree to tree alignment model using output from statistical parser in both source and target languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O594">
<title id=" N04-1023.xml">discriminative reranking for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wu (1997) <papid> J97-3002 </papid>introduced constraints on alignments using probabilistic synchronous context-free grammar restricted to chomsky normal form.</prevsent>
<prevsent>(wu, 1997) <papid> J97-3002 </papid>was an implicit or self organizing syntax model as it did not use treebank.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
yamada and knight (2001) <papid> P01-1067 </papid>used statistical parser trained using treebank in the source language to produce parse trees and proposed tree to string model for alignment.gildea (2003) <papid> P03-1011 </papid>proposed tree to tree alignment model using output from statistical parser in both source and target languages.</citsent>
<aftsection>
<nextsent>the translation model involved tree alignments in which subtree cloning was used to handle cases of reordering that were not possible in earlier tree-based alignment models.
</nextsent>
<nextsent>1.2 discriminative models for mt. och and ney (2002) <papid> P02-1038 </papid>proposed framework for mt based on direct translation, using the conditional model</nextsent>
<nextsent> estimated using maximum entropy model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O595">
<title id=" N04-1023.xml">discriminative reranking for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wu (1997) <papid> J97-3002 </papid>introduced constraints on alignments using probabilistic synchronous context-free grammar restricted to chomsky normal form.</prevsent>
<prevsent>(wu, 1997) <papid> J97-3002 </papid>was an implicit or self organizing syntax model as it did not use treebank.</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
yamada and knight (2001) <papid> P01-1067 </papid>used statistical parser trained using treebank in the source language to produce parse trees and proposed tree to string model for alignment.gildea (2003) <papid> P03-1011 </papid>proposed tree to tree alignment model using output from statistical parser in both source and target languages.</citsent>
<aftsection>
<nextsent>the translation model involved tree alignments in which subtree cloning was used to handle cases of reordering that were not possible in earlier tree-based alignment models.
</nextsent>
<nextsent>1.2 discriminative models for mt. och and ney (2002) <papid> P02-1038 </papid>proposed framework for mt based on direct translation, using the conditional model</nextsent>
<nextsent> estimated using maximum entropy model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O603">
<title id=" N04-1023.xml">discriminative reranking for machine translation </title>
<section> ranking and reranking.  </section>
<citcontext>
<prevsection>
<prevsent>like machine translation, parsing is another field of natural language processing in which generative models have been widely used.
</prevsent>
<prevsent>in recent years, reranking techniques,especially discriminative reranking, have resulted insignificant improvements in parsing.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
various machine learning algorithms have been employed in parse reranking, such as boosting (collins, 2000), perceptron (collins and duffy, 2002) <papid> P02-1034 </papid>and support vector machines (shen and joshi, 2003).<papid> W03-0402 </papid></citsent>
<aftsection>
<nextsent>the reranking techniques have resulted in 13.5% error reduction in labeled recall/precision over the previous best generative parsing models.
</nextsent>
<nextsent>discriminative reranking methods for parsing typically use the notion of margin as the distance between the best candidate parse and the rest of the parses.
</nextsent>
<nextsent>the reranking problem is reduced to classification problem by using pairwise samples.
</nextsent>
<nextsent>in (shen and joshi, 2004), we have introduced new perceptron-like ordinal regression algorithm for parse reranking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O604">
<title id=" N04-1023.xml">discriminative reranking for machine translation </title>
<section> ranking and reranking.  </section>
<citcontext>
<prevsection>
<prevsent>like machine translation, parsing is another field of natural language processing in which generative models have been widely used.
</prevsent>
<prevsent>in recent years, reranking techniques,especially discriminative reranking, have resulted insignificant improvements in parsing.
</prevsent>
</prevsection>
<citsent citstr=" W03-0402 ">
various machine learning algorithms have been employed in parse reranking, such as boosting (collins, 2000), perceptron (collins and duffy, 2002) <papid> P02-1034 </papid>and support vector machines (shen and joshi, 2003).<papid> W03-0402 </papid></citsent>
<aftsection>
<nextsent>the reranking techniques have resulted in 13.5% error reduction in labeled recall/precision over the previous best generative parsing models.
</nextsent>
<nextsent>discriminative reranking methods for parsing typically use the notion of margin as the distance between the best candidate parse and the rest of the parses.
</nextsent>
<nextsent>the reranking problem is reduced to classification problem by using pairwise samples.
</nextsent>
<nextsent>in (shen and joshi, 2004), we have introduced new perceptron-like ordinal regression algorithm for parse reranking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O614">
<title id=" N07-1005.xml">automatic evaluation of machine translation based on rate of accomplishment of sub goals </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>promising results are shown.
</prevsent>
<prevsent>in machine translation (mt) research, appropriately evaluating the quality of mt results is an important issue.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
in recent years, many researchers have triedto automatically evaluate the quality of mt and im prove the performance of automatic mt evaluations (niessen et al, 2000; akiba et al, 2001; papineni et al., 2002; <papid> P02-1040 </papid>nist, 2002; leusch et al, 2003; turian et al., 2003; babych and hartley, 2004; <papid> P04-1079 </papid>lin and och, 2004; <papid> C04-1072 </papid>banerjee and lavie, 2005; <papid> W05-0909 </papid>gimenez et al,2005) because improving the performance of automatic mt evaluation is expected to enable us to use and improve mt systems efficiently.</citsent>
<aftsection>
<nextsent>for example,och reported that the quality of mt results was improved by using automatic mt evaluation measures for the parameter tuning of an mt system (och,2003).<papid> P03-1021 </papid></nextsent>
<nextsent>this report shows that the quality of mt results improves as the performance of automatic mt evaluation improves.mt systems can be ranked if set of mt results for each system and their reference translations are given.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O615">
<title id=" N07-1005.xml">automatic evaluation of machine translation based on rate of accomplishment of sub goals </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>promising results are shown.
</prevsent>
<prevsent>in machine translation (mt) research, appropriately evaluating the quality of mt results is an important issue.
</prevsent>
</prevsection>
<citsent citstr=" P04-1079 ">
in recent years, many researchers have triedto automatically evaluate the quality of mt and im prove the performance of automatic mt evaluations (niessen et al, 2000; akiba et al, 2001; papineni et al., 2002; <papid> P02-1040 </papid>nist, 2002; leusch et al, 2003; turian et al., 2003; babych and hartley, 2004; <papid> P04-1079 </papid>lin and och, 2004; <papid> C04-1072 </papid>banerjee and lavie, 2005; <papid> W05-0909 </papid>gimenez et al,2005) because improving the performance of automatic mt evaluation is expected to enable us to use and improve mt systems efficiently.</citsent>
<aftsection>
<nextsent>for example,och reported that the quality of mt results was improved by using automatic mt evaluation measures for the parameter tuning of an mt system (och,2003).<papid> P03-1021 </papid></nextsent>
<nextsent>this report shows that the quality of mt results improves as the performance of automatic mt evaluation improves.mt systems can be ranked if set of mt results for each system and their reference translations are given.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O617">
<title id=" N07-1005.xml">automatic evaluation of machine translation based on rate of accomplishment of sub goals </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>promising results are shown.
</prevsent>
<prevsent>in machine translation (mt) research, appropriately evaluating the quality of mt results is an important issue.
</prevsent>
</prevsection>
<citsent citstr=" C04-1072 ">
in recent years, many researchers have triedto automatically evaluate the quality of mt and im prove the performance of automatic mt evaluations (niessen et al, 2000; akiba et al, 2001; papineni et al., 2002; <papid> P02-1040 </papid>nist, 2002; leusch et al, 2003; turian et al., 2003; babych and hartley, 2004; <papid> P04-1079 </papid>lin and och, 2004; <papid> C04-1072 </papid>banerjee and lavie, 2005; <papid> W05-0909 </papid>gimenez et al,2005) because improving the performance of automatic mt evaluation is expected to enable us to use and improve mt systems efficiently.</citsent>
<aftsection>
<nextsent>for example,och reported that the quality of mt results was improved by using automatic mt evaluation measures for the parameter tuning of an mt system (och,2003).<papid> P03-1021 </papid></nextsent>
<nextsent>this report shows that the quality of mt results improves as the performance of automatic mt evaluation improves.mt systems can be ranked if set of mt results for each system and their reference translations are given.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O619">
<title id=" N07-1005.xml">automatic evaluation of machine translation based on rate of accomplishment of sub goals </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>promising results are shown.
</prevsent>
<prevsent>in machine translation (mt) research, appropriately evaluating the quality of mt results is an important issue.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
in recent years, many researchers have triedto automatically evaluate the quality of mt and im prove the performance of automatic mt evaluations (niessen et al, 2000; akiba et al, 2001; papineni et al., 2002; <papid> P02-1040 </papid>nist, 2002; leusch et al, 2003; turian et al., 2003; babych and hartley, 2004; <papid> P04-1079 </papid>lin and och, 2004; <papid> C04-1072 </papid>banerjee and lavie, 2005; <papid> W05-0909 </papid>gimenez et al,2005) because improving the performance of automatic mt evaluation is expected to enable us to use and improve mt systems efficiently.</citsent>
<aftsection>
<nextsent>for example,och reported that the quality of mt results was improved by using automatic mt evaluation measures for the parameter tuning of an mt system (och,2003).<papid> P03-1021 </papid></nextsent>
<nextsent>this report shows that the quality of mt results improves as the performance of automatic mt evaluation improves.mt systems can be ranked if set of mt results for each system and their reference translations are given.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O621">
<title id=" N07-1005.xml">automatic evaluation of machine translation based on rate of accomplishment of sub goals </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in machine translation (mt) research, appropriately evaluating the quality of mt results is an important issue.
</prevsent>
<prevsent>in recent years, many researchers have triedto automatically evaluate the quality of mt and im prove the performance of automatic mt evaluations (niessen et al, 2000; akiba et al, 2001; papineni et al., 2002; <papid> P02-1040 </papid>nist, 2002; leusch et al, 2003; turian et al., 2003; babych and hartley, 2004; <papid> P04-1079 </papid>lin and och, 2004; <papid> C04-1072 </papid>banerjee and lavie, 2005; <papid> W05-0909 </papid>gimenez et al,2005) because improving the performance of automatic mt evaluation is expected to enable us to use and improve mt systems efficiently.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
for example,och reported that the quality of mt results was improved by using automatic mt evaluation measures for the parameter tuning of an mt system (och,2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>this report shows that the quality of mt results improves as the performance of automatic mt evaluation improves.mt systems can be ranked if set of mt results for each system and their reference translations are given.
</nextsent>
<nextsent>usually, about 300 or more sentences are used to automatically rank mt systems (koehn, 2004).<papid> W04-3250 </papid></nextsent>
<nextsent>however, the quality of sentence translated by an mt system is difficult to evaluate.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O622">
<title id=" N07-1005.xml">automatic evaluation of machine translation based on rate of accomplishment of sub goals </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example,och reported that the quality of mt results was improved by using automatic mt evaluation measures for the parameter tuning of an mt system (och,2003).<papid> P03-1021 </papid></prevsent>
<prevsent>this report shows that the quality of mt results improves as the performance of automatic mt evaluation improves.mt systems can be ranked if set of mt results for each system and their reference translations are given.</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
usually, about 300 or more sentences are used to automatically rank mt systems (koehn, 2004).<papid> W04-3250 </papid></citsent>
<aftsection>
<nextsent>however, the quality of sentence translated by an mt system is difficult to evaluate.
</nextsent>
<nextsent>for example, the results of five mts into japanese of the sentence the percentage of stomach cancer among the workers appears to be the highest for any asbestosworkers.?
</nextsent>
<nextsent>are shown in table 1.
</nextsent>
<nextsent>a conventional automatic evaluation method ranks the fifth mt result first although its human subjective evaluation is the lowest.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O632">
<title id=" N07-1005.xml">automatic evaluation of machine translation based on rate of accomplishment of sub goals </title>
<section> automatic evaluation of machine.  </section>
<citcontext>
<prevsection>
<prevsent>the term iindicates similarity between translated sentence and its reference translation, and ? iis weight for the similarity.
</prevsent>
<prevsent>many methods for calculating the similarity have been proposed (niessen et al, 2000; akiba et al, 2001; papineni et al, 2002; <papid> P02-1040 </papid>nist, 2002; leusch et al, 2003; turian et al, 2003; babych and hartley, 2004; <papid> P04-1079 </papid>lin and och, 2004; <papid> C04-1072 </papid>banerjee and lavie, 2005; <papid> W05-0909 </papid>gimenez et al, 2005).</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
in our research, 23 scores, namely bleu (papineni et al, 2002) <papid> P02-1040 </papid>with maximum n-gram lengths of 1, 2, 3, and 4, nist (nist, 2002) with maximum n-gram lengths of 1, 2, 3, 4, and 5, gtm (turian et al, 2003)with exponents of 1.0, 2.0, and 3.0, meteor (ex act) (banerjee and lavie, 2005), <papid> W05-0909 </papid>wer (niessen et al., 2000), per (leusch et al, 2003), and rouge (lin, 2004) <papid> W04-1013 </papid>with n-gram lengths of 1, 2, 3, and 4 and4 variants (lcs, s?, su?, w-1.2), were used to calculate each similarity i . therefore, the value of m. in eq.</citsent>
<aftsection>
<nextsent>(1) was 23.
</nextsent>
<nextsent>japanese word segmentation was performed by using juman 4 in our experiments.
</nextsent>
<nextsent>as you can see, the definition of our new measure is based on combination of an evaluation measure focusing on local information and that focusing on global information.
</nextsent>
<nextsent>3.2 automatic estimation of rate of.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O634">
<title id=" N04-4040.xml">a lexicallydriven algorithm for dis fluency detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these results suggest that the cleaning?
</prevsent>
<prevsent>of text by removing dis fluent words can increase the speed at which readers can process text.
</prevsent>
</prevsection>
<citsent citstr=" N01-1016 ">
recent work on detecting edits for use in parsing of speech transcripts (core and schubert, 1999), (char niak and johnson, 2001) <papid> N01-1016 </papid>has shown an improvement in the parser error rate by modeling disfluencies.</citsent>
<aftsection>
<nextsent>many researchers investigating dis fluency detection have focused on the use of prosodic cues, as opposed to lexical features (nakatani and hirschberg, 1994).
</nextsent>
<nextsent>there are different approaches to detecting disfluencies.
</nextsent>
<nextsent>in one approach, one can first try to locate evidence of general dis fluency, e.g., using prosodic features or language model discontinuations.
</nextsent>
<nextsent>these locations are called interruption points (ips).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O635">
<title id=" N04-4040.xml">a lexicallydriven algorithm for dis fluency detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>following this, it is generally sufficient to look in the nearby vicinity of the ip to find the dis1this work is supported in part by bbnt contract 9500006806 and an nsf cise infrastructure award eia0130422.fluent words.
</prevsent>
<prevsent>the most successful approaches so far combine the detection of ips using prosodic features and language modeling techniques (liu et al , 2003), (shriberg et al , 2001), (stolcke et al , 1998).our work is based on the premise that the vast majority of disfluencies can be detected using primarily lexical features specifically the words themselves andpart-of-speech (pos) labels without the use of extensive prosodic cues.
</prevsent>
</prevsection>
<citsent citstr=" J99-4003 ">
lexical modeling of disfluencies with only minimal acoustic cues has been shown to be successful in the past using strongly statistical techniques(heeman and allen, 1999).<papid> J99-4003 </papid></citsent>
<aftsection>
<nextsent>we shall discuss our algorithm and compare it to two other algorithms that make extensive use of acoustic features.
</nextsent>
<nextsent>our algorithm performs comparably on most of the tasks assigned and in some cases outperforms systems that used both prosodic and lexical features.
</nextsent>
<nextsent>we discuss the task definition in section 2.
</nextsent>
<nextsent>in section 3 we describe our transformation-based learning (tbl) algorithm and its associated features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O636">
<title id=" N04-4040.xml">a lexicallydriven algorithm for dis fluency detection </title>
<section> the algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>the evaluation data was held out, and not available for tuning system parameters.the input to system is transcript of either conversational telephone speech (cts) or broadcast news speech (bnews).
</prevsent>
<prevsent>in all experiments, the system was trained on reference transcripts, but was tested on both reference and speech output transcripts.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
we use transformation-based learning (tbl) (brill, 1995) <papid> J95-4004 </papid>algorithm to induce rules from the training data.</citsent>
<aftsection>
<nextsent>tbl is technique for learning set of rules that transform an initial hypothesis for the purpose of reducing the error rate of the hypothesis.
</nextsent>
<nextsent>the set of possible rules is found by expanding rule templates, which are given as an input.
</nextsent>
<nextsent>the algorithm greedily selects the rule that reduces the error rate the most, applies it to the data, and then searches for the next rule.
</nextsent>
<nextsent>the algorithm halts when there are no more rules that can reduce the error rate by more than the threshold.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O637">
<title id=" N04-4040.xml">a lexicallydriven algorithm for dis fluency detection </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>we compare our system to two other systems that were designed for the same task, system and system c. system was only applied to conversational speech, so there are no results for it on broadcast news transcripts.
</prevsent>
<prevsent>our system was also given the same speech recognition output as system for the conversational speech condition, whereas system used transcripts produced by different speech recognition system.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
2we use pos tagger (ratnaparkhi, 1996) <papid> W96-0213 </papid>trained on switchboard data with the additional tags of fp (filled pause) and frag (word fragment).system used both prosodic cues and lexical information to detect disfluencies.</citsent>
<aftsection>
<nextsent>the prosodic cues were modeled by decision tree classifier, whereas the lexical information was modeled using 4-gram language model, separately trained for both cts and bnews.system first inserts ips into the text using decision tree classifier based on both prosodic and lexical feature sand then uses tbl.
</nextsent>
<nextsent>in addition to pos, system cs feature set al includes whether the word is commonly usedas filler, edit, back-channel word, or is part of short repeat.
</nextsent>
<nextsent>turn and segment boundary flags were also used by the system.
</nextsent>
<nextsent>whereas system only attempted to learn three labels (filler, edit and fluent), system attempted to learn many sub types of disfluencies, which were not distinguished in the evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O638">
<title id=" N04-4040.xml">a lexicallydriven algorithm for dis fluency detection </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>assuming the basic forms of disflu encies in other languages are similar to those in english, very few modifications would be required.
</prevsent>
<prevsent>the longer edits that the system currently misses may be detectable using parsing, with the intuition that parser trained on fluent speech may perform poorly in the presence of longer edits.
</prevsent>
</prevsection>
<citsent citstr=" P83-1019 ">
techniques using parse trees to identify disfluencies have shown success in the past (hin dle, 1983).<papid> P83-1019 </papid></citsent>
<aftsection>
<nextsent>the system could use portions of the parse structure as features and could relabel entire subtrees of the parse tree.
</nextsent>
<nextsent>repeated words are another feature of the longer edits, which we might leverage off of by performing weighted alignment of the edit and the repair.
</nextsent>
<nextsent>eventually it may prove that more elaborate acoustic cues will be needed to identify these edits, at which point model of interruption points could be included as feature in the rules learned by the system.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O639">
<title id=" N04-4039.xml">converting text into agent animations assigning gestures to text </title>
<section> linguistic theories and gesture studies.  </section>
<citcontext>
<prevsection>
<prevsent>given information usually has low degree of rhematicity, while new information has high degree.
</prevsent>
<prevsent>this implies that rhematicity can be estimated by determining whether the np is the first mention (i.e., new information) or has already been mentioned (i.e., old or given information).
</prevsent>
</prevsection>
<citsent citstr=" P96-1039 ">
contrastive relationship: prevost (1996) <papid> P96-1039 </papid>reported that into national accent is often used to mark an explicit contrast among the salient discourse entities.</citsent>
<aftsection>
<nextsent>on the basis of this finding and kendons theory about the relationship between intonation phrases and gesture placements (kendon, 1972), cassell &amp; prevost (1996) <papid> P96-1039 </papid>developed method for generating contrastive gestures from semantic representation.</nextsent>
<nextsent>in syntactic analysis, contrastive relation is usually expressed as coordination, which is syntactic structure including at least two conjuncts linked by conjunction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O643">
<title id=" N04-4039.xml">converting text into agent animations assigning gestures to text </title>
<section> empirical study.  </section>
<citcontext>
<prevsection>
<prevsent>a gesture consists of preparation, stroke, and retraction (mcneill, 1992), and stroke co-occurs with the most prominent syllable (kendon, 1972).
</prevsent>
<prevsent>thus, we annotated the stroke time as well as the start and end time of each gesture.
</prevsent>
</prevsection>
<citsent citstr=" J94-4001 ">
linguistic analysis: each bunsetsu unit was automatically annotated with linguistic information using japanese syntactic analyzer (kurohashi &amp; nagao, 1994)<papid> J94-4001 </papid>2.</citsent>
<aftsection>
<nextsent>the information was determined by asked the following questions for each bunsetsu unit.
</nextsent>
<nextsent>(a) if it is an np, is it modified by clause or com plement?
</nextsent>
<nextsent>(b) if it is an np, what type of post positional particle marks its end (e.g., wa?, ga?, wo?)?
</nextsent>
<nextsent>(c) is it wh-interrogative?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O644">
<title id=" N04-4039.xml">converting text into agent animations assigning gestures to text </title>
<section> discussion and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we plan to enhance our model by incorporating more general discourse level information, though the current system exploits cue words as very partial kind of discourse information.
</prevsent>
<prevsent>for instance, gestures frequently occur at episode boundaries.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
pushing and popping of discourse segment (grosz &amp; sidner, 1986) <papid> J86-3001 </papid>may also affect gesture occurrence.</citsent>
<aftsection>
<nextsent>therefore, by integrating discourse analyzer into the ltm, more general structural discourse information can be used in the model.
</nextsent>
<nextsent>another important direction is to evaluate the effectiveness of agent gestures in actual human-agent interaction.
</nextsent>
<nextsent>we expect that if our model can generate gestures with appropriate timing for emphasizing important words and phrases, users can perceive agent presentations as being more alive and comprehensible.
</nextsent>
<nextsent>we plan to conduct user study to examine this hypothesis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O645">
<title id=" N07-1040.xml">whose idea was this and why does it matter attributing scientific work to citations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the success of citation indexers such as cite seer (giles et al, 1998) and google scholar relies on the robust detection of formal citations in arbitrary text.
</prevsent>
<prevsent>in bibliographic information retrieval, anchor text, i.e.,the context of citation can be used to characterise (index) the cited paper using terms out side of that paper (bradshaw, 2003); oconnor (1982) presents an approach for identifying the area around citations where the text focuses onthat citation.
</prevsent>
</prevsection>
<citsent citstr=" W06-1613 ">
and automatic citation classification (nanba and okumura, 1999; teufel etal., 2006) <papid> W06-1613 </papid>determines the function that citation plays in the discourse.for such information access and retrieval purposes, the relevance of citation within paperis often crucial.</citsent>
<aftsection>
<nextsent>one can estimate how important citation is by simply counting how often it occurs in the paper.
</nextsent>
<nextsent>but as kim and webber (2006) argue, this ignores many expressions in text which refer to the cited authors work but which are not as easy to recognise as citations.
</nextsent>
<nextsent>they address the resolution of instances of the third person personal pronoun they?
</nextsent>
<nextsent>in astronomy papers: it can either refer to citation or to some entities that are part of research within the paper (e.g., planets or galaxies).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O646">
<title id=" N07-1040.xml">whose idea was this and why does it matter attributing scientific work to citations </title>
<section> the scientific attribution task.  </section>
<citcontext>
<prevsection>
<prevsent>they decide whether the pronoun theyanaphorically refers to the authors of cited paper, or whether it refers to some entity that is discussed in (a subpart of) paper (e.g., galax ies?).
</prevsent>
<prevsent>in this paper, we tackle the other problem of scientific attribution.
</prevsent>
</prevsection>
<citsent citstr=" J02-4002 ">
we do not distinguish between the two typesof links stated above, but only identify which ci tation(s) linguistic expression is attributable1we use list of around 40 research methodology related nouns from teufel and moens (2002)<papid> J02-4002 </papid>such as e.g., study, account, investigation, result?</citsent>
<aftsection>
<nextsent>etc. these are nouns we are particularly interested in.
</nextsent>
<nextsent>to.
</nextsent>
<nextsent>for tasks of interest to us, it is not enough to only consider anaphoric references to entirepapers; authors often make statements compar ing/using/criticising aspects or subparts of cited work.
</nextsent>
<nextsent>we therefore consider far wider rangeof markables than kim and webbers single pronoun they?.our attribution task differs from the traditional anaphora resolution task in that we have fixed list of possible referents (the reference list items, current-paper or no-specific paper) that are known upfront.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O650">
<title id=" N07-1040.xml">whose idea was this and why does it matter attributing scientific work to citations </title>
<section> evaluation metrics.  </section>
<citcontext>
<prevsection>
<prevsent>we briefly discuss both below.
</prevsent>
<prevsent>5.1 the muc-6/muc-7 metric.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
the muc-6/muc-7 co-reference evaluation metric (vilain et al, 1995) <papid> M95-1005 </papid>works by comparing co-reference classes across two annotated 318 files.</citsent>
<aftsection>
<nextsent>calling one annotation the model?
</nextsent>
<nextsent>and the other the system?, for each co-referenceclass in the model, c(s) is the minimal number of co-reference links needed to generate the class (this is one less than the cardinality of the class; c(s) = |s| ? 1).
</nextsent>
<nextsent>m(s) is the number ofmissing?
</nextsent>
<nextsent>links in the system annotation relative to the co-reference class as marked up in the model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O664">
<title id=" N06-1017.xml">unknown word sense detection as outlier detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in cases where sense is missing from the inventory, wsd will wrongly assign one of the existing senses.
</prevsent>
<prevsent>figure 1 shows an example, sentence from the hound of the baskervilles, analyzed by the shalmaneser (erkand pado, 2006) shallow semantic parser.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the analysis is based on framenet (baker et al, 1998), <papid> P98-1013 </papid>are source that lists senses and semantic roles for english expressions.</citsent>
<aftsection>
<nextsent>framenet is lacking sense of expectation?
</nextsent>
<nextsent>or being mentally prepared?
</nextsent>
<nextsent>for the verb prepare, so prepared has been assigned the sense cooking creation, possible but improbable analysis2.
</nextsent>
<nextsent>such erroneous labels can be fatal when further processing builds on the results of shallow semantic parsing, e.g. for drawing inferences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O665">
<title id=" N06-1017.xml">unknown word sense detection as outlier detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>all sense inventories face the problem of missing senses, either because of their small overall size (as is the case for some non-english wordnets) or when they encounter domain-specific senses.
</prevsent>
<prevsent>our study will be evaluated on framenet because of our main aim of improving shallow semantic parsing, but the method we propose is applicable to any sense inventory that has annotated data; in particular, it is also applicable to wordnet.in this paper we model unknown sense detection as outlier detection, using simple nearest neighbor-based method (tax and duin, 2000) that compares the local probability density at each test item with that of its nearest training item.
</prevsent>
</prevsection>
<citsent citstr=" N03-1036 ">
to our knowledge, there exists no other approach to date to the problem of detecting unknown senses.there are, however, approaches to the complementary problem of determining the closest known sense for unknown words (widdows, 2003; <papid> N03-1036 </papid>curran, 2005; <papid> P05-1004 </papid>burchardt et al, 2005), which can be viewed as the logical next step after unknown sense detection.</citsent>
<aftsection>
<nextsent>plan of the paper.
</nextsent>
<nextsent>after brief sketch of framenet in section 2, we describe the experimental setup used throughout this paper in section 3.
</nextsent>
<nextsent>section 4 tests whether very simple model suffices for detecting unknown senses: threshold on confidence scores returned by the shalmaneser wsd 2unfortunately, the semantic roles have been mis-assigned by the system.
</nextsent>
<nextsent>the word should fill the food role, while for hound could be assigned the optional receiver role.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O666">
<title id=" N06-1017.xml">unknown word sense detection as outlier detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>all sense inventories face the problem of missing senses, either because of their small overall size (as is the case for some non-english wordnets) or when they encounter domain-specific senses.
</prevsent>
<prevsent>our study will be evaluated on framenet because of our main aim of improving shallow semantic parsing, but the method we propose is applicable to any sense inventory that has annotated data; in particular, it is also applicable to wordnet.in this paper we model unknown sense detection as outlier detection, using simple nearest neighbor-based method (tax and duin, 2000) that compares the local probability density at each test item with that of its nearest training item.
</prevsent>
</prevsection>
<citsent citstr=" P05-1004 ">
to our knowledge, there exists no other approach to date to the problem of detecting unknown senses.there are, however, approaches to the complementary problem of determining the closest known sense for unknown words (widdows, 2003; <papid> N03-1036 </papid>curran, 2005; <papid> P05-1004 </papid>burchardt et al, 2005), which can be viewed as the logical next step after unknown sense detection.</citsent>
<aftsection>
<nextsent>plan of the paper.
</nextsent>
<nextsent>after brief sketch of framenet in section 2, we describe the experimental setup used throughout this paper in section 3.
</nextsent>
<nextsent>section 4 tests whether very simple model suffices for detecting unknown senses: threshold on confidence scores returned by the shalmaneser wsd 2unfortunately, the semantic roles have been mis-assigned by the system.
</nextsent>
<nextsent>the word should fill the food role, while for hound could be assigned the optional receiver role.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O669">
<title id=" N06-1017.xml">unknown word sense detection as outlier detection </title>
<section> framenet.  </section>
<citcontext>
<prevsection>
<prevsent>currently,framenet contains 609 frames with 8,755 lemma frame pairs, of which 5,308 are exemplified in annotated sentences from the british national corpus.
</prevsent>
<prevsent>the annotation comprises 133,846 sentences.as framenet is growing resource, many lem mas are still lacking senses, and many senses are still lacking annotation.
</prevsent>
</prevsection>
<citsent citstr=" H05-1047 ">
this is problematic for the use of framenet analyses as basis for inferences over text, as e.g. in tatu and moldovan (2005).<papid> H05-1047 </papid></citsent>
<aftsection>
<nextsent>for example, the verb prepare from figure 1 is associated with the frames cooking creation: prepare food activity prepare: get ready for an activity activity ready state: be ready for an activity willingness: be willing of which only the cooking creation sense hasbeen annotated.
</nextsent>
<nextsent>the sense in figure 1 is not covered yet: activity ready state would be more appropriate than cooking creation, but still not optimal, since the sentence refers to mental state rather than the preparation of an activity.
</nextsent>
<nextsent>129
</nextsent>
<nextsent>experimental setup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O670">
<title id=" N06-1017.xml">unknown word sense detection as outlier detection </title>
<section> experimental setup and data.  </section>
<citcontext>
<prevsection>
<prevsent>all experiments in this paper were performed on the framenet 1.2 annotated data pertaining to ambiguous lemmas.
</prevsent>
<prevsent>after removal of instances that were annotated with more than one sense, we obtain 26,496 annotated sentences for the 1,031 ambiguous lemmas.
</prevsent>
</prevsection>
<citsent citstr=" P93-1016 ">
they were parsed with minipar (lin, 1993); <papid> P93-1016 </papid>named entities were computed using heart of gold (callmeier et al, 2004).</citsent>
<aftsection>
<nextsent>for unknown sense detection in this section we test very simple model of unknown sense detection: classifiers often return confidence score along with the assigned label.
</nextsent>
<nextsent>we will try to detect unknown senses by threshold on confidence scores, declaring anything below the threshold as unknown.
</nextsent>
<nextsent>note that this method can only be applied to lemmas that have more than one sense, since for single-sense lemmas the system will always return the maximum confidence score.
</nextsent>
<nextsent>data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O674">
<title id=" N07-1025.xml">using wikipedia for automatic word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, the english noun plant can mean green plant or factory; similarly the french word feuillecan mean leaf or paper.
</prevsent>
<prevsent>the correct sense of an ambiguous word can be selected based on the context where it occurs, and correspondingly the problem of word sense disambiguation is defined as the task of automatically assigning the most appropriate meaning to polysemous word within given context.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
among the various knowledge-based (lesk,1986; galley and mckeown, 2003; navigli and velardi, 2005) and data-driven (yarowsky, 1995; <papid> P95-1026 </papid>ngand lee, 1996; <papid> P96-1006 </papid>pedersen, 2001) <papid> N01-1011 </papid>word sense disambiguation methods that have been proposed todate, supervised systems have been constantly observed as leading to the highest performance.</citsent>
<aftsection>
<nextsent>in these systems, the sense disambiguation problem is formulated as supervised learning task, where each sense-tagged occurrence of particular word is transformed into feature vector which is then used in an automatic learning process.
</nextsent>
<nextsent>despite their high performance, these supervised systems have an important drawback: their applicability is limited tothose few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.to address the sense-tagged data bottleneck problem, different methods have been proposed in the past, with various degrees of success.
</nextsent>
<nextsent>this includes the automatic generation of sense-tagged data usingmonosemous relatives (leacock et al, 1998; <papid> J98-1006 </papid>mihalcea and moldovan, 1999; agirre and martinez, 2004), <papid> W04-3204 </papid>automatically boot strapped disambiguation patterns (yarowsky, 1995; <papid> P95-1026 </papid>mihalcea, 2002), parallel texts as way to point out word senses bearing different translations in second language (diab and resnik, 2002; <papid> P02-1033 </papid>ng et al, 2003; <papid> P03-1058 </papid>diab, 2004), <papid> P04-1039 </papid>and the use of volunteer contributions over the web (chklovski and mihalcea, 2002)<papid> W02-0817 </papid></nextsent>
<nextsent>in this paper, we investigate new approach for building sense tagged corpora using wikipedia as asource of sense annotations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O676">
<title id=" N07-1025.xml">using wikipedia for automatic word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, the english noun plant can mean green plant or factory; similarly the french word feuillecan mean leaf or paper.
</prevsent>
<prevsent>the correct sense of an ambiguous word can be selected based on the context where it occurs, and correspondingly the problem of word sense disambiguation is defined as the task of automatically assigning the most appropriate meaning to polysemous word within given context.
</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
among the various knowledge-based (lesk,1986; galley and mckeown, 2003; navigli and velardi, 2005) and data-driven (yarowsky, 1995; <papid> P95-1026 </papid>ngand lee, 1996; <papid> P96-1006 </papid>pedersen, 2001) <papid> N01-1011 </papid>word sense disambiguation methods that have been proposed todate, supervised systems have been constantly observed as leading to the highest performance.</citsent>
<aftsection>
<nextsent>in these systems, the sense disambiguation problem is formulated as supervised learning task, where each sense-tagged occurrence of particular word is transformed into feature vector which is then used in an automatic learning process.
</nextsent>
<nextsent>despite their high performance, these supervised systems have an important drawback: their applicability is limited tothose few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.to address the sense-tagged data bottleneck problem, different methods have been proposed in the past, with various degrees of success.
</nextsent>
<nextsent>this includes the automatic generation of sense-tagged data usingmonosemous relatives (leacock et al, 1998; <papid> J98-1006 </papid>mihalcea and moldovan, 1999; agirre and martinez, 2004), <papid> W04-3204 </papid>automatically boot strapped disambiguation patterns (yarowsky, 1995; <papid> P95-1026 </papid>mihalcea, 2002), parallel texts as way to point out word senses bearing different translations in second language (diab and resnik, 2002; <papid> P02-1033 </papid>ng et al, 2003; <papid> P03-1058 </papid>diab, 2004), <papid> P04-1039 </papid>and the use of volunteer contributions over the web (chklovski and mihalcea, 2002)<papid> W02-0817 </papid></nextsent>
<nextsent>in this paper, we investigate new approach for building sense tagged corpora using wikipedia as asource of sense annotations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O677">
<title id=" N07-1025.xml">using wikipedia for automatic word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, the english noun plant can mean green plant or factory; similarly the french word feuillecan mean leaf or paper.
</prevsent>
<prevsent>the correct sense of an ambiguous word can be selected based on the context where it occurs, and correspondingly the problem of word sense disambiguation is defined as the task of automatically assigning the most appropriate meaning to polysemous word within given context.
</prevsent>
</prevsection>
<citsent citstr=" N01-1011 ">
among the various knowledge-based (lesk,1986; galley and mckeown, 2003; navigli and velardi, 2005) and data-driven (yarowsky, 1995; <papid> P95-1026 </papid>ngand lee, 1996; <papid> P96-1006 </papid>pedersen, 2001) <papid> N01-1011 </papid>word sense disambiguation methods that have been proposed todate, supervised systems have been constantly observed as leading to the highest performance.</citsent>
<aftsection>
<nextsent>in these systems, the sense disambiguation problem is formulated as supervised learning task, where each sense-tagged occurrence of particular word is transformed into feature vector which is then used in an automatic learning process.
</nextsent>
<nextsent>despite their high performance, these supervised systems have an important drawback: their applicability is limited tothose few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.to address the sense-tagged data bottleneck problem, different methods have been proposed in the past, with various degrees of success.
</nextsent>
<nextsent>this includes the automatic generation of sense-tagged data usingmonosemous relatives (leacock et al, 1998; <papid> J98-1006 </papid>mihalcea and moldovan, 1999; agirre and martinez, 2004), <papid> W04-3204 </papid>automatically boot strapped disambiguation patterns (yarowsky, 1995; <papid> P95-1026 </papid>mihalcea, 2002), parallel texts as way to point out word senses bearing different translations in second language (diab and resnik, 2002; <papid> P02-1033 </papid>ng et al, 2003; <papid> P03-1058 </papid>diab, 2004), <papid> P04-1039 </papid>and the use of volunteer contributions over the web (chklovski and mihalcea, 2002)<papid> W02-0817 </papid></nextsent>
<nextsent>in this paper, we investigate new approach for building sense tagged corpora using wikipedia as asource of sense annotations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O678">
<title id=" N07-1025.xml">using wikipedia for automatic word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in these systems, the sense disambiguation problem is formulated as supervised learning task, where each sense-tagged occurrence of particular word is transformed into feature vector which is then used in an automatic learning process.
</prevsent>
<prevsent>despite their high performance, these supervised systems have an important drawback: their applicability is limited tothose few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.to address the sense-tagged data bottleneck problem, different methods have been proposed in the past, with various degrees of success.
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
this includes the automatic generation of sense-tagged data usingmonosemous relatives (leacock et al, 1998; <papid> J98-1006 </papid>mihalcea and moldovan, 1999; agirre and martinez, 2004), <papid> W04-3204 </papid>automatically boot strapped disambiguation patterns (yarowsky, 1995; <papid> P95-1026 </papid>mihalcea, 2002), parallel texts as way to point out word senses bearing different translations in second language (diab and resnik, 2002; <papid> P02-1033 </papid>ng et al, 2003; <papid> P03-1058 </papid>diab, 2004), <papid> P04-1039 </papid>and the use of volunteer contributions over the web (chklovski and mihalcea, 2002)<papid> W02-0817 </papid></citsent>
<aftsection>
<nextsent>in this paper, we investigate new approach for building sense tagged corpora using wikipedia as asource of sense annotations.
</nextsent>
<nextsent>starting with the hy per links available in wikipedia, we show how we can generate sense annotated corpora that can beused for building accurate and robust sense classifiers.
</nextsent>
<nextsent>through word sense disambiguation experiments performed on the wikipedia-based sense tagged corpus generated for subset of the senseval ambiguous words, we show that the wikipedia annotations are reliable, and the quality of sense tagging classifier built on this dataset exceeds by large margin the accuracy of an informed baseline that selects the most frequent word sense by default.the paper is organized as follows.
</nextsent>
<nextsent>we first pro 196 vide brief overview of wikipedia, and describe the view of wikipedia as sense tagged corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O679">
<title id=" N07-1025.xml">using wikipedia for automatic word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in these systems, the sense disambiguation problem is formulated as supervised learning task, where each sense-tagged occurrence of particular word is transformed into feature vector which is then used in an automatic learning process.
</prevsent>
<prevsent>despite their high performance, these supervised systems have an important drawback: their applicability is limited tothose few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.to address the sense-tagged data bottleneck problem, different methods have been proposed in the past, with various degrees of success.
</prevsent>
</prevsection>
<citsent citstr=" W04-3204 ">
this includes the automatic generation of sense-tagged data usingmonosemous relatives (leacock et al, 1998; <papid> J98-1006 </papid>mihalcea and moldovan, 1999; agirre and martinez, 2004), <papid> W04-3204 </papid>automatically boot strapped disambiguation patterns (yarowsky, 1995; <papid> P95-1026 </papid>mihalcea, 2002), parallel texts as way to point out word senses bearing different translations in second language (diab and resnik, 2002; <papid> P02-1033 </papid>ng et al, 2003; <papid> P03-1058 </papid>diab, 2004), <papid> P04-1039 </papid>and the use of volunteer contributions over the web (chklovski and mihalcea, 2002)<papid> W02-0817 </papid></citsent>
<aftsection>
<nextsent>in this paper, we investigate new approach for building sense tagged corpora using wikipedia as asource of sense annotations.
</nextsent>
<nextsent>starting with the hy per links available in wikipedia, we show how we can generate sense annotated corpora that can beused for building accurate and robust sense classifiers.
</nextsent>
<nextsent>through word sense disambiguation experiments performed on the wikipedia-based sense tagged corpus generated for subset of the senseval ambiguous words, we show that the wikipedia annotations are reliable, and the quality of sense tagging classifier built on this dataset exceeds by large margin the accuracy of an informed baseline that selects the most frequent word sense by default.the paper is organized as follows.
</nextsent>
<nextsent>we first pro 196 vide brief overview of wikipedia, and describe the view of wikipedia as sense tagged corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O682">
<title id=" N07-1025.xml">using wikipedia for automatic word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in these systems, the sense disambiguation problem is formulated as supervised learning task, where each sense-tagged occurrence of particular word is transformed into feature vector which is then used in an automatic learning process.
</prevsent>
<prevsent>despite their high performance, these supervised systems have an important drawback: their applicability is limited tothose few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.to address the sense-tagged data bottleneck problem, different methods have been proposed in the past, with various degrees of success.
</prevsent>
</prevsection>
<citsent citstr=" P02-1033 ">
this includes the automatic generation of sense-tagged data usingmonosemous relatives (leacock et al, 1998; <papid> J98-1006 </papid>mihalcea and moldovan, 1999; agirre and martinez, 2004), <papid> W04-3204 </papid>automatically boot strapped disambiguation patterns (yarowsky, 1995; <papid> P95-1026 </papid>mihalcea, 2002), parallel texts as way to point out word senses bearing different translations in second language (diab and resnik, 2002; <papid> P02-1033 </papid>ng et al, 2003; <papid> P03-1058 </papid>diab, 2004), <papid> P04-1039 </papid>and the use of volunteer contributions over the web (chklovski and mihalcea, 2002)<papid> W02-0817 </papid></citsent>
<aftsection>
<nextsent>in this paper, we investigate new approach for building sense tagged corpora using wikipedia as asource of sense annotations.
</nextsent>
<nextsent>starting with the hy per links available in wikipedia, we show how we can generate sense annotated corpora that can beused for building accurate and robust sense classifiers.
</nextsent>
<nextsent>through word sense disambiguation experiments performed on the wikipedia-based sense tagged corpus generated for subset of the senseval ambiguous words, we show that the wikipedia annotations are reliable, and the quality of sense tagging classifier built on this dataset exceeds by large margin the accuracy of an informed baseline that selects the most frequent word sense by default.the paper is organized as follows.
</nextsent>
<nextsent>we first pro 196 vide brief overview of wikipedia, and describe the view of wikipedia as sense tagged corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O683">
<title id=" N07-1025.xml">using wikipedia for automatic word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in these systems, the sense disambiguation problem is formulated as supervised learning task, where each sense-tagged occurrence of particular word is transformed into feature vector which is then used in an automatic learning process.
</prevsent>
<prevsent>despite their high performance, these supervised systems have an important drawback: their applicability is limited tothose few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.to address the sense-tagged data bottleneck problem, different methods have been proposed in the past, with various degrees of success.
</prevsent>
</prevsection>
<citsent citstr=" P03-1058 ">
this includes the automatic generation of sense-tagged data usingmonosemous relatives (leacock et al, 1998; <papid> J98-1006 </papid>mihalcea and moldovan, 1999; agirre and martinez, 2004), <papid> W04-3204 </papid>automatically boot strapped disambiguation patterns (yarowsky, 1995; <papid> P95-1026 </papid>mihalcea, 2002), parallel texts as way to point out word senses bearing different translations in second language (diab and resnik, 2002; <papid> P02-1033 </papid>ng et al, 2003; <papid> P03-1058 </papid>diab, 2004), <papid> P04-1039 </papid>and the use of volunteer contributions over the web (chklovski and mihalcea, 2002)<papid> W02-0817 </papid></citsent>
<aftsection>
<nextsent>in this paper, we investigate new approach for building sense tagged corpora using wikipedia as asource of sense annotations.
</nextsent>
<nextsent>starting with the hy per links available in wikipedia, we show how we can generate sense annotated corpora that can beused for building accurate and robust sense classifiers.
</nextsent>
<nextsent>through word sense disambiguation experiments performed on the wikipedia-based sense tagged corpus generated for subset of the senseval ambiguous words, we show that the wikipedia annotations are reliable, and the quality of sense tagging classifier built on this dataset exceeds by large margin the accuracy of an informed baseline that selects the most frequent word sense by default.the paper is organized as follows.
</nextsent>
<nextsent>we first pro 196 vide brief overview of wikipedia, and describe the view of wikipedia as sense tagged corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O685">
<title id=" N07-1025.xml">using wikipedia for automatic word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in these systems, the sense disambiguation problem is formulated as supervised learning task, where each sense-tagged occurrence of particular word is transformed into feature vector which is then used in an automatic learning process.
</prevsent>
<prevsent>despite their high performance, these supervised systems have an important drawback: their applicability is limited tothose few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.to address the sense-tagged data bottleneck problem, different methods have been proposed in the past, with various degrees of success.
</prevsent>
</prevsection>
<citsent citstr=" P04-1039 ">
this includes the automatic generation of sense-tagged data usingmonosemous relatives (leacock et al, 1998; <papid> J98-1006 </papid>mihalcea and moldovan, 1999; agirre and martinez, 2004), <papid> W04-3204 </papid>automatically boot strapped disambiguation patterns (yarowsky, 1995; <papid> P95-1026 </papid>mihalcea, 2002), parallel texts as way to point out word senses bearing different translations in second language (diab and resnik, 2002; <papid> P02-1033 </papid>ng et al, 2003; <papid> P03-1058 </papid>diab, 2004), <papid> P04-1039 </papid>and the use of volunteer contributions over the web (chklovski and mihalcea, 2002)<papid> W02-0817 </papid></citsent>
<aftsection>
<nextsent>in this paper, we investigate new approach for building sense tagged corpora using wikipedia as asource of sense annotations.
</nextsent>
<nextsent>starting with the hy per links available in wikipedia, we show how we can generate sense annotated corpora that can beused for building accurate and robust sense classifiers.
</nextsent>
<nextsent>through word sense disambiguation experiments performed on the wikipedia-based sense tagged corpus generated for subset of the senseval ambiguous words, we show that the wikipedia annotations are reliable, and the quality of sense tagging classifier built on this dataset exceeds by large margin the accuracy of an informed baseline that selects the most frequent word sense by default.the paper is organized as follows.
</nextsent>
<nextsent>we first pro 196 vide brief overview of wikipedia, and describe the view of wikipedia as sense tagged corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O687">
<title id=" N07-1025.xml">using wikipedia for automatic word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in these systems, the sense disambiguation problem is formulated as supervised learning task, where each sense-tagged occurrence of particular word is transformed into feature vector which is then used in an automatic learning process.
</prevsent>
<prevsent>despite their high performance, these supervised systems have an important drawback: their applicability is limited tothose few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.to address the sense-tagged data bottleneck problem, different methods have been proposed in the past, with various degrees of success.
</prevsent>
</prevsection>
<citsent citstr=" W02-0817 ">
this includes the automatic generation of sense-tagged data usingmonosemous relatives (leacock et al, 1998; <papid> J98-1006 </papid>mihalcea and moldovan, 1999; agirre and martinez, 2004), <papid> W04-3204 </papid>automatically boot strapped disambiguation patterns (yarowsky, 1995; <papid> P95-1026 </papid>mihalcea, 2002), parallel texts as way to point out word senses bearing different translations in second language (diab and resnik, 2002; <papid> P02-1033 </papid>ng et al, 2003; <papid> P03-1058 </papid>diab, 2004), <papid> P04-1039 </papid>and the use of volunteer contributions over the web (chklovski and mihalcea, 2002)<papid> W02-0817 </papid></citsent>
<aftsection>
<nextsent>in this paper, we investigate new approach for building sense tagged corpora using wikipedia as asource of sense annotations.
</nextsent>
<nextsent>starting with the hy per links available in wikipedia, we show how we can generate sense annotated corpora that can beused for building accurate and robust sense classifiers.
</nextsent>
<nextsent>through word sense disambiguation experiments performed on the wikipedia-based sense tagged corpus generated for subset of the senseval ambiguous words, we show that the wikipedia annotations are reliable, and the quality of sense tagging classifier built on this dataset exceeds by large margin the accuracy of an informed baseline that selects the most frequent word sense by default.the paper is organized as follows.
</nextsent>
<nextsent>we first pro 196 vide brief overview of wikipedia, and describe the view of wikipedia as sense tagged corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O702">
<title id=" N04-1003.xml">robust reading identification and tracing of ambiguous names </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous work in the context of question answering has not addressed this problem.
</prevsent>
<prevsent>several works in nlp and databases, though, have addressed some aspects of it.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
from the natural language perspective, there hasbeen lot of work on the related problem of coreference resolution (soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2003; kehler, 2002) - which aims at linking occurrences of noun phrases and pronouns within document based on their appearance and local context.</citsent>
<aftsection>
<nextsent>(charniak, 2001) <papid> N01-1007 </papid>presents solution to the problem of name structure recognition by incorporating coreference information.</nextsent>
<nextsent>in the context of databases, several works have looked at the problem of record linkage - recognizing duplicate records in database (cohen and richman, 2002; hernandez and stolfo, 1995; bilenko and mooney, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O703">
<title id=" N04-1003.xml">robust reading identification and tracing of ambiguous names </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several works in nlp and databases, though, have addressed some aspects of it.
</prevsent>
<prevsent>from the natural language perspective, there hasbeen lot of work on the related problem of coreference resolution (soon et al , 2001; <papid> J01-4004 </papid>ng and cardie, 2003; kehler, 2002) - which aims at linking occurrences of noun phrases and pronouns within document based on their appearance and local context.</prevsent>
</prevsection>
<citsent citstr=" N01-1007 ">
(charniak, 2001) <papid> N01-1007 </papid>presents solution to the problem of name structure recognition by incorporating coreference information.</citsent>
<aftsection>
<nextsent>in the context of databases, several works have looked at the problem of record linkage - recognizing duplicate records in database (cohen and richman, 2002; hernandez and stolfo, 1995; bilenko and mooney, 2003).
</nextsent>
<nextsent>specifically,(pasula et al , 2002) considers the problem of identity uncertainty in the context of citation matching and suggests probabilistic model for that.
</nextsent>
<nextsent>some of very few works we are aware of that works directly with text data and across documents, are (bagga and baldwin, 1998; <papid> P98-1012 </papid>mann and yarowsky, 2003), <papid> W03-0405 </papid>which consider one aspect of the problem ? that of distinguishing occurrences of identical names in different documents, and only of people.the rest of this paper is organized as follows: we formalize the robust reading?</nextsent>
<nextsent>problem in sec.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O704">
<title id=" N04-1003.xml">robust reading identification and tracing of ambiguous names </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the context of databases, several works have looked at the problem of record linkage - recognizing duplicate records in database (cohen and richman, 2002; hernandez and stolfo, 1995; bilenko and mooney, 2003).
</prevsent>
<prevsent>specifically,(pasula et al , 2002) considers the problem of identity uncertainty in the context of citation matching and suggests probabilistic model for that.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
some of very few works we are aware of that works directly with text data and across documents, are (bagga and baldwin, 1998; <papid> P98-1012 </papid>mann and yarowsky, 2003), <papid> W03-0405 </papid>which consider one aspect of the problem ? that of distinguishing occurrences of identical names in different documents, and only of people.the rest of this paper is organized as follows: we formalize the robust reading?</citsent>
<aftsection>
<nextsent>problem in sec.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>sec.
</nextsent>
<nextsent>3 describes generative view of documents?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O705">
<title id=" N04-1003.xml">robust reading identification and tracing of ambiguous names </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the context of databases, several works have looked at the problem of record linkage - recognizing duplicate records in database (cohen and richman, 2002; hernandez and stolfo, 1995; bilenko and mooney, 2003).
</prevsent>
<prevsent>specifically,(pasula et al , 2002) considers the problem of identity uncertainty in the context of citation matching and suggests probabilistic model for that.
</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
some of very few works we are aware of that works directly with text data and across documents, are (bagga and baldwin, 1998; <papid> P98-1012 </papid>mann and yarowsky, 2003), <papid> W03-0405 </papid>which consider one aspect of the problem ? that of distinguishing occurrences of identical names in different documents, and only of people.the rest of this paper is organized as follows: we formalize the robust reading?</citsent>
<aftsection>
<nextsent>problem in sec.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>sec.
</nextsent>
<nextsent>3 describes generative view of documents?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O706">
<title id=" N03-2006.xml">adaptation using outofdomain corpus within ebmt </title>
<section> translation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 conditions.
</prevsent>
<prevsent>in order to evaluate the adaptability of an ebmt with out-of-domain examples, we applied the methods described in section 2 to the ebmt and evaluated the translation quality in japanese-to-english translation.
</prevsent>
</prevsection>
<citsent citstr=" W01-1401 ">
we used an ebmt, dp-match driven transducer (d3, sumita, 2001) <papid> W01-1401 </papid>as test bed.</citsent>
<aftsection>
<nextsent>we used two japanese-and-english bilingual corpora.
</nextsent>
<nextsent>in this experiment on adaptation, as an out-ofdomain corpus, we used basic travel expression corpus (btec, described as be-corpus in takezawa, 2002); as an in-domain corpus, we used telephone conversation corpus (tel).
</nextsent>
<nextsent>the statistics of the corpora are shown in table 1.
</nextsent>
<nextsent>tel is split into two parts: test set of 1,653 sentence pairs and training set of 9,918.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O707">
<title id=" N06-1056.xml">learning for semantic parsing with statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>semantic parsing has found its way in practical applications such as natural-language (nl) interfaces to databases (androutsopoulos et al, 1995) and advice taking (kuhlmann et al, 2004).
</prevsent>
<prevsent>figure 1 shows sample mr written in meaning-representation language (mrl) called clang, which is used for ((bowner our {4}) (do our {6} (pos (left (half our))))) if our player 4 has the ball, then our player 6 should stay in the left side of our half.
</prevsent>
</prevsection>
<citsent citstr=" P96-1008 ">
figure 1: meaning representation in clang encoding coach advice given to simulated soccer playing agents (kuhlmann et al, 2004).prior research in semantic parsing has mainly focused on relatively simple domains such as atis (air travel information service) (miller et al, 1996; <papid> P96-1008 </papid>papineni et al, 1997; macherey et al, 2001), in which typcial mr is only single semantic frame.learning methods have been devised that can generate mrs with complex, nested structure (cf.</citsent>
<aftsection>
<nextsent>figure 1).
</nextsent>
<nextsent>however, these methods are mostly based on deterministic parsing (zelle and mooney, 1996; kate et al, 2005), which lack the robustness that characterizes recent advances in statistical nlp.other learning methods involve the use of fully annotated augmented parse trees (ge and mooney,2005) <papid> W05-0602 </papid>or prior knowledge of the nl syntax (zettlemoyer and collins, 2005) in training, and hence require extensive human efforts when porting to new domain or language.in this paper, we present novel statistical approach to semantic parsing which can handle mrs with nested structure, based on previous work on semantic parsing using transformation rules (kate et al., 2005).</nextsent>
<nextsent>the algorithm learns semantic parser given set of nl sentences annotated with their correct mrs. it requires no prior knowledge ofthe nl syntax, although it assumes that an unambiguous, context-free grammar (cfg) of the targetmrl is available.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O708">
<title id=" N06-1056.xml">learning for semantic parsing with statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1: meaning representation in clang encoding coach advice given to simulated soccer playing agents (kuhlmann et al, 2004).prior research in semantic parsing has mainly focused on relatively simple domains such as atis (air travel information service) (miller et al, 1996; <papid> P96-1008 </papid>papineni et al, 1997; macherey et al, 2001), in which typcial mr is only single semantic frame.learning methods have been devised that can generate mrs with complex, nested structure (cf.</prevsent>
<prevsent>figure 1).</prevsent>
</prevsection>
<citsent citstr=" W05-0602 ">
however, these methods are mostly based on deterministic parsing (zelle and mooney, 1996; kate et al, 2005), which lack the robustness that characterizes recent advances in statistical nlp.other learning methods involve the use of fully annotated augmented parse trees (ge and mooney,2005) <papid> W05-0602 </papid>or prior knowledge of the nl syntax (zettlemoyer and collins, 2005) in training, and hence require extensive human efforts when porting to new domain or language.in this paper, we present novel statistical approach to semantic parsing which can handle mrs with nested structure, based on previous work on semantic parsing using transformation rules (kate et al., 2005).</citsent>
<aftsection>
<nextsent>the algorithm learns semantic parser given set of nl sentences annotated with their correct mrs. it requires no prior knowledge ofthe nl syntax, although it assumes that an unambiguous, context-free grammar (cfg) of the targetmrl is available.
</nextsent>
<nextsent>the main innovation of this al 439 answer(count(city(loc 2(countryid(usa))))) how many cities are there in the us?
</nextsent>
<nextsent>figure 2: meaning representation in geoquerygorithm is its integration with state-of-the-art statistical machine translation techniques.
</nextsent>
<nextsent>more specifically, statistical word alignment model (brownet al, 1993) <papid> J93-2003 </papid>is used to acquire bilingual lexicon consisting of nl sub strings coupled with their translations in the target mrl.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O709">
<title id=" N06-1056.xml">learning for semantic parsing with statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main innovation of this al 439 answer(count(city(loc 2(countryid(usa))))) how many cities are there in the us?
</prevsent>
<prevsent>figure 2: meaning representation in geoquerygorithm is its integration with state-of-the-art statistical machine translation techniques.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
more specifically, statistical word alignment model (brownet al, 1993) <papid> J93-2003 </papid>is used to acquire bilingual lexicon consisting of nl sub strings coupled with their translations in the target mrl.</citsent>
<aftsection>
<nextsent>complete mrs are then formed by combining these nl sub strings and their translations under parsing framework called the synchronous cfg (aho and ullman, 1972),which forms the basis of most existing statistical syntax-based translation models (yamada and knight, 2001; <papid> P01-1067 </papid>chiang, 2005).<papid> P05-1033 </papid></nextsent>
<nextsent>our algorithm is called wasp, short for word alignment-based semantic parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O710">
<title id=" N06-1056.xml">learning for semantic parsing with statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 2: meaning representation in geoquerygorithm is its integration with state-of-the-art statistical machine translation techniques.
</prevsent>
<prevsent>more specifically, statistical word alignment model (brownet al, 1993) <papid> J93-2003 </papid>is used to acquire bilingual lexicon consisting of nl sub strings coupled with their translations in the target mrl.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
complete mrs are then formed by combining these nl sub strings and their translations under parsing framework called the synchronous cfg (aho and ullman, 1972),which forms the basis of most existing statistical syntax-based translation models (yamada and knight, 2001; <papid> P01-1067 </papid>chiang, 2005).<papid> P05-1033 </papid></citsent>
<aftsection>
<nextsent>our algorithm is called wasp, short for word alignment-based semantic parsing.
</nextsent>
<nextsent>in initial evaluation on several real-world datasets, we show that wasp performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring thesame amount of supervision, and shows better robustness to variations in task complexity and word order.section 2 provides brief overview of the domains being considered.
</nextsent>
<nextsent>in section 3, we present the semantic parsing model of wasp.
</nextsent>
<nextsent>section 4 outlines the algorithm for acquiring bilingual lexicon through the use of word alignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O711">
<title id=" N06-1056.xml">learning for semantic parsing with statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 2: meaning representation in geoquerygorithm is its integration with state-of-the-art statistical machine translation techniques.
</prevsent>
<prevsent>more specifically, statistical word alignment model (brownet al, 1993) <papid> J93-2003 </papid>is used to acquire bilingual lexicon consisting of nl sub strings coupled with their translations in the target mrl.</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
complete mrs are then formed by combining these nl sub strings and their translations under parsing framework called the synchronous cfg (aho and ullman, 1972),which forms the basis of most existing statistical syntax-based translation models (yamada and knight, 2001; <papid> P01-1067 </papid>chiang, 2005).<papid> P05-1033 </papid></citsent>
<aftsection>
<nextsent>our algorithm is called wasp, short for word alignment-based semantic parsing.
</nextsent>
<nextsent>in initial evaluation on several real-world datasets, we show that wasp performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring thesame amount of supervision, and shows better robustness to variations in task complexity and word order.section 2 provides brief overview of the domains being considered.
</nextsent>
<nextsent>in section 3, we present the semantic parsing model of wasp.
</nextsent>
<nextsent>section 4 outlines the algorithm for acquiring bilingual lexicon through the use of word alignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O713">
<title id=" N06-1056.xml">learning for semantic parsing with statistical machine translation </title>
<section> the semantic parsing model.  </section>
<citcontext>
<prevsection>
<prevsent>figure 3(b) shows the corresponding clang parse from which the mr is constructed.
</prevsent>
<prevsent>this process can be formalized as an instance of synchronous parsing (aho and ullman, 1972), originally developed as theory of compilers in which syntax analysis and code generation are combined into single phase.
</prevsent>
</prevsection>
<citsent citstr=" P04-1083 ">
synchronous parsing has seen surge of interest recently in the machine translation community as way of formalizing syntax-based translation models (melamed, 2004; <papid> P04-1083 </papid>chiang, 2005).<papid> P05-1033 </papid></citsent>
<aftsection>
<nextsent>according to this theory, semantic parser defines translation, set of pairs of strings in which each pair is an nl sentence coupled with its mr. to finitely specify potentially infinite translation, we use synchronous context-free grammar (scfg) for generating the pairs in translation.
</nextsent>
<nextsent>analogous toan ordinary cfg, each scfg rule consists of single non-terminal on the left-hand side (lhs).
</nextsent>
<nextsent>the right-hand side (rhs) of an scfg rule is pair of strings, ??, ??, where the non-terminals in ? are permutation of the non-terminals in ?.
</nextsent>
<nextsent>below are some scfg rules that can be used for generating the parse trees in figure 3: rule ? if condition 1 , directive 2 . , (condition 1 directive 2 )?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O716">
<title id=" N06-1056.xml">learning for semantic parsing with statistical machine translation </title>
<section> lexical acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>(bowner team {unum}) figure 4: partial word alignment for the clang statement and its english gloss shown in figure 1 nl sentences and their mrs in the training set.
</prevsent>
<prevsent>by defining mapping of words from one language to another, word alignments define bilingual lexicon.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
using word alignments to induce lexicon is not new idea (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>indeed, attempt shave been made to directly apply machine translation systems to the problem of semantic parsing (pa pineni et al, 1997; macherey et al, 2001).
</nextsent>
<nextsent>however, these systems make no use of the mrl grammar, thus allocating probability mass to mr translations that are not even syntactically well-formed.
</nextsent>
<nextsent>here we present lexical induction algorithm that guarantees syntactic well-formedness of mr translations by using the mrl grammar.the basic idea is to train statistical word alignment model on the training set, and then form lexicon by extracting transformation rules from the = 10 most probable word alignments between the training sentences and their mrs. while nl words could be directly aligned with mr tokens, this is bad approach for two reasons.
</nextsent>
<nextsent>first, not all mr tokens carry specific meanings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O720">
<title id=" N06-1056.xml">learning for semantic parsing with statistical machine translation </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>a similar feature set is used by zettlemoyer and collins (2005).
</prevsent>
<prevsent>decoding of the model can be done in cubic time with respect to sentence length using the viterbi algorithm.
</prevsent>
</prevsection>
<citsent citstr=" J95-2002 ">
an earley chart is used for keeping trackof all derivations that are consistent with the input (stolcke, 1995).<papid> J95-2002 </papid></citsent>
<aftsection>
<nextsent>the maximum conditional likelihood criterion is used for estimating the model parameters, i. gaussian prior (2 = 1) is used for regularizing the model (chen and rosenfeld, 1999).
</nextsent>
<nextsent>since gold-standard derivations are not available in the training data, correct derivations must be treat edas hidden variables.
</nextsent>
<nextsent>here we use version of im 443proved iterative scaling (iis) coupled with em (riezler et al, 2000) <papid> P00-1061 </papid>for finding an optimal set of parameters.1 unlike the fully-supervised case, the conditional likelihood is not concave with respect to ?,so the estimation algorithm is sensitive to initial parameters.</nextsent>
<nextsent>to assume as little as possible, ? is initial ized to 0.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O721">
<title id=" N06-1056.xml">learning for semantic parsing with statistical machine translation </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>the maximum conditional likelihood criterion is used for estimating the model parameters, i. gaussian prior (2 = 1) is used for regularizing the model (chen and rosenfeld, 1999).
</prevsent>
<prevsent>since gold-standard derivations are not available in the training data, correct derivations must be treat edas hidden variables.
</prevsent>
</prevsection>
<citsent citstr=" P00-1061 ">
here we use version of im 443proved iterative scaling (iis) coupled with em (riezler et al, 2000) <papid> P00-1061 </papid>for finding an optimal set of parameters.1 unlike the fully-supervised case, the conditional likelihood is not concave with respect to ?,so the estimation algorithm is sensitive to initial parameters.</citsent>
<aftsection>
<nextsent>to assume as little as possible, ? is initial ized to 0.
</nextsent>
<nextsent>the estimation algorithm requires statistics that depend on all possible derivations for sentence or sentence-mr pair.
</nextsent>
<nextsent>while it is not feasible to enumerate all derivations, variant of the inside-outside algorithm can be used for efficiently collecting the required statistics (miyao and tsujii, 2002).
</nextsent>
<nextsent>following zettlemoyer and collins (2005), only rules that are used in the best parses for the training set are retained in the final lexicon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O726">
<title id=" N03-1020.xml">automatic evaluation of summaries using ngram cooccurrence statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the results show that automatic evaluation using unigram cooccurrences between summary pairs correlates surprising well with human evaluations, based on various statistical metrics; while direct application of the bleu evaluation procedure does not always give good results.
</prevsent>
<prevsent>automated text summarization has drawn lot of interest in the natural language processing and information retrieval communities in the recent years.
</prevsent>
</prevsection>
<citsent citstr=" H01-1056 ">
a series of workshops on automatic text summarization (was 2000, 2001, 2002), special topic sessions in acl, coling, and sigir, and government sponsored evaluation efforts in the united states (duc 2002) and japan (fukusima and okumura 2001) have advanced the technology and produced couple of experimental online systems (radev et al 2001, <papid> H01-1056 </papid>mckeown et al 2002).</citsent>
<aftsection>
<nextsent>despite these efforts, however, there are no common, convenient, and repeatable evaluation methods that can be easily applied to support system development and just-in-time comparison among different summarization methods.
</nextsent>
<nextsent>the document understanding conference (duc 2002) run by the national institute of standards and technology (nist) sets out to address this problem by providing annual large scale common evaluations in text summarization.
</nextsent>
<nextsent>however, these evaluations involve human judges and hence are subject to variability (rath et al 1961).
</nextsent>
<nextsent>for example, lin and hovy (2002) <papid> W02-0406 </papid>pointed out that 18% of the data contained multiple judgments in the duc 2001 single document evaluation1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O727">
<title id=" N03-1020.xml">automatic evaluation of summaries using ngram cooccurrence statistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the document understanding conference (duc 2002) run by the national institute of standards and technology (nist) sets out to address this problem by providing annual large scale common evaluations in text summarization.
</prevsent>
<prevsent>however, these evaluations involve human judges and hence are subject to variability (rath et al 1961).
</prevsent>
</prevsection>
<citsent citstr=" W02-0406 ">
for example, lin and hovy (2002) <papid> W02-0406 </papid>pointed out that 18% of the data contained multiple judgments in the duc 2001 single document evaluation1.</citsent>
<aftsection>
<nextsent>to further progress in automatic summarization, in this paper we conduct an in-depth study of automatic evaluation methods based on n-gram co-occurrence in the context of duc.
</nextsent>
<nextsent>due to the setup in duc, the evaluations we discussed here are intrinsic evaluations (sprck jones and galli ers 1996).
</nextsent>
<nextsent>section 2 gives an overview of the evaluation procedure used in duc.
</nextsent>
<nextsent>section 3 discusses the ibm bleu (papineni et al 2001) and nist (2002) n-gram co-occurrence scoring procedures and the application of similar idea in evaluating summaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O728">
<title id=" N03-1020.xml">automatic evaluation of summaries using ngram cooccurrence statistics </title>
<section> document understanding conference.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 evaluation metrics.
</prevsent>
<prevsent>recall at different compression ratios has been used in summarization research to measure how well an automatic system retains important content of original documents (mani et al 1998).
</prevsent>
</prevsection>
<citsent citstr=" W00-0408 ">
however, the simple sentence recall measure cannot differentiate system performance appropriately, as is pointed out by donaway et al (2000).<papid> W00-0408 </papid></citsent>
<aftsection>
<nextsent>therefore, instead of pure sentence recall score, we use coverage score c. we define it as fol lows7: )1( summary model in the mus of number total marked) mus of(number ec ?= e, the ratio of completeness, ranges from 1 to 0: 1 for all, 3/4 for most, 1/2 for some, 1/4 for hardly any, and 0 for none.
</nextsent>
<nextsent>if we ignore (set it to 1), we obtain simple sentence recall score.
</nextsent>
<nextsent>we use average coverage scores derived from human judgments as the references to evaluate various automatic scoring methods in the following sections.
</nextsent>
<nextsent>to automatically evaluate machine translations thema chine translation community recently adopted an n-gram co-occurrence scoring procedure bleu (papineni et al 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O732">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in some cases researchers need large quantities of parsed data and do not have the hundreds of machines necessary to parse gigaword corpora in weekor two.
</prevsent>
<prevsent>more pres singly, in real-time applications such as speech recognition, parser would be only part of much larger system, and the system builders are not keen on giving the parser one of the ten seconds available to process, say, thirty-word sentence.
</prevsent>
</prevsection>
<citsent citstr=" P04-1005 ">
even worse,some applications require the parsing of multiple candidate strings per sentence (johnson and charniak, 2004) <papid> P04-1005 </papid>or parsing from lattice (hall and johnson, 2004), <papid> P04-1006 </papid>and in these applications parsing efficiency is even more important.</citsent>
<aftsection>
<nextsent>we present here multilevel coarse-to-fine (mlctf) pcfg parsing algorithm that reduces the complexity of the search involved in finding the best parse.
</nextsent>
<nextsent>it defines sequence of increasingly more complex pcfgs, and uses the parse forest produced by one pcfg to prune the search of the next more complex pcfg.
</nextsent>
<nextsent>we currently use four levels of grammars in our mlctf algorithm.
</nextsent>
<nextsent>the simplest pcfg, which wecall the level-0 grammar, contains only one non trivial nonterminal and is so simple that minimal time is needed to parse sentence usingit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O733">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in some cases researchers need large quantities of parsed data and do not have the hundreds of machines necessary to parse gigaword corpora in weekor two.
</prevsent>
<prevsent>more pres singly, in real-time applications such as speech recognition, parser would be only part of much larger system, and the system builders are not keen on giving the parser one of the ten seconds available to process, say, thirty-word sentence.
</prevsent>
</prevsection>
<citsent citstr=" P04-1006 ">
even worse,some applications require the parsing of multiple candidate strings per sentence (johnson and charniak, 2004) <papid> P04-1005 </papid>or parsing from lattice (hall and johnson, 2004), <papid> P04-1006 </papid>and in these applications parsing efficiency is even more important.</citsent>
<aftsection>
<nextsent>we present here multilevel coarse-to-fine (mlctf) pcfg parsing algorithm that reduces the complexity of the search involved in finding the best parse.
</nextsent>
<nextsent>it defines sequence of increasingly more complex pcfgs, and uses the parse forest produced by one pcfg to prune the search of the next more complex pcfg.
</nextsent>
<nextsent>we currently use four levels of grammars in our mlctf algorithm.
</nextsent>
<nextsent>the simplest pcfg, which wecall the level-0 grammar, contains only one non trivial nonterminal and is so simple that minimal time is needed to parse sentence usingit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O734">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>finally in section 5 we suggest that because the search space of mlctf algorithms is, at this point, almost totally unexplored, future work should be able to improve significantly on these results.
</prevsent>
<prevsent>coarse-to-fine search is an idea that has appeared several times in the literature of computational linguistics and related areas.
</prevsent>
</prevsection>
<citsent citstr=" J93-4001 ">
the first appearance of this idea we are aware of isin maxwell and kaplan (1993), <papid> J93-4001 </papid>where covering cfg is automatically extracted from more detailed unification grammar and used to identify the possible locations of constituents in the more detailed parses of the sentence.</citsent>
<aftsection>
<nextsent>maxwell and kaplan use their covering cfg to prune the search of their unification grammar parser in essentially the same manner as we do here, and demonstrate significant performance improvements by using their coarse-to-fine approach.the basic theory of coarse-to-fine approximations and dynamic programming in stochastic framework is laid out in geman and kochanek (2001).
</nextsent>
<nextsent>this paper describes the multilevel dynamic programming algorithm needed forcoarse-to-fine analysis (which they apply to decoding rather than parsing), and show how to perform exact coarse-to-fine computation, rather than the heuristic search we perform here.
</nextsent>
<nextsent>a paper closely related to ours is goodman (1997).<papid> W97-0302 </papid></nextsent>
<nextsent>in our terminology, goodmans parser is two-stage ctf parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O735">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>maxwell and kaplan use their covering cfg to prune the search of their unification grammar parser in essentially the same manner as we do here, and demonstrate significant performance improvements by using their coarse-to-fine approach.the basic theory of coarse-to-fine approximations and dynamic programming in stochastic framework is laid out in geman and kochanek (2001).
</prevsent>
<prevsent>this paper describes the multilevel dynamic programming algorithm needed forcoarse-to-fine analysis (which they apply to decoding rather than parsing), and show how to perform exact coarse-to-fine computation, rather than the heuristic search we perform here.
</prevsent>
</prevsection>
<citsent citstr=" W97-0302 ">
a paper closely related to ours is goodman (1997).<papid> W97-0302 </papid></citsent>
<aftsection>
<nextsent>in our terminology, goodmans parser is two-stage ctf parser.
</nextsent>
<nextsent>the second stage is standard tree-bank parser while the first stage isa regular-expression approximation of the grammar. again, the second stage is constrained by the parses found in the first stage.
</nextsent>
<nextsent>neither stage is smoothed.
</nextsent>
<nextsent>the parser of charniak (2000) <papid> A00-2018 </papid>is also two-stage ctf model, where the first stage is smoothed markov grammar (it uses up to three previous constituents as context), and the second stage is lexicalized markov grammar with extra annotations about parents and grandparents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O736">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>the second stage is standard tree-bank parser while the first stage isa regular-expression approximation of the grammar. again, the second stage is constrained by the parses found in the first stage.
</prevsent>
<prevsent>neither stage is smoothed.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the parser of charniak (2000) <papid> A00-2018 </papid>is also two-stage ctf model, where the first stage is smoothed markov grammar (it uses up to three previous constituents as context), and the second stage is lexicalized markov grammar with extra annotations about parents and grandparents.</citsent>
<aftsection>
<nextsent>the second stage explores all of the constituents not pruned out after the first stage.
</nextsent>
<nextsent>related approaches are used in hall (2004) and charniak and johnson (2005).<papid> P05-1022 </papid>a quite different approach to parsing efficiency is taken in caraballo and charniak (1998) <papid> J98-2004 </papid>and refined in charniak et al (1998)).<papid> W98-1115 </papid></nextsent>
<nextsent>here efficiency is gained by using standard chart parsing algorithm and pulling constituents off the agenda according to (an estimate of) their probability given the sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O737">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>the parser of charniak (2000) <papid> A00-2018 </papid>is also two-stage ctf model, where the first stage is smoothed markov grammar (it uses up to three previous constituents as context), and the second stage is lexicalized markov grammar with extra annotations about parents and grandparents.</prevsent>
<prevsent>the second stage explores all of the constituents not pruned out after the first stage.</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
related approaches are used in hall (2004) and charniak and johnson (2005).<papid> P05-1022 </papid>a quite different approach to parsing efficiency is taken in caraballo and charniak (1998) <papid> J98-2004 </papid>and refined in charniak et al (1998)).<papid> W98-1115 </papid></citsent>
<aftsection>
<nextsent>here efficiency is gained by using standard chart parsing algorithm and pulling constituents off the agenda according to (an estimate of) their probability given the sentence.
</nextsent>
<nextsent>this probability is computed by estimating equation 1: p(nki,j | s) = ?(nki,j)?(nki,j) p(s) .
</nextsent>
<nextsent>(1) 169 it must be estimated because during the bottom-up chart-parsing algorithm, the true outside probability cannot be computed.
</nextsent>
<nextsent>the results cited in caraballo and charniak (1998) <papid> J98-2004 </papid>cannot be compared directly to ours, but are roughly in the same equivalence class.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O738">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>the parser of charniak (2000) <papid> A00-2018 </papid>is also two-stage ctf model, where the first stage is smoothed markov grammar (it uses up to three previous constituents as context), and the second stage is lexicalized markov grammar with extra annotations about parents and grandparents.</prevsent>
<prevsent>the second stage explores all of the constituents not pruned out after the first stage.</prevsent>
</prevsection>
<citsent citstr=" J98-2004 ">
related approaches are used in hall (2004) and charniak and johnson (2005).<papid> P05-1022 </papid>a quite different approach to parsing efficiency is taken in caraballo and charniak (1998) <papid> J98-2004 </papid>and refined in charniak et al (1998)).<papid> W98-1115 </papid></citsent>
<aftsection>
<nextsent>here efficiency is gained by using standard chart parsing algorithm and pulling constituents off the agenda according to (an estimate of) their probability given the sentence.
</nextsent>
<nextsent>this probability is computed by estimating equation 1: p(nki,j | s) = ?(nki,j)?(nki,j) p(s) .
</nextsent>
<nextsent>(1) 169 it must be estimated because during the bottom-up chart-parsing algorithm, the true outside probability cannot be computed.
</nextsent>
<nextsent>the results cited in caraballo and charniak (1998) <papid> J98-2004 </papid>cannot be compared directly to ours, but are roughly in the same equivalence class.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O740">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>the parser of charniak (2000) <papid> A00-2018 </papid>is also two-stage ctf model, where the first stage is smoothed markov grammar (it uses up to three previous constituents as context), and the second stage is lexicalized markov grammar with extra annotations about parents and grandparents.</prevsent>
<prevsent>the second stage explores all of the constituents not pruned out after the first stage.</prevsent>
</prevsection>
<citsent citstr=" W98-1115 ">
related approaches are used in hall (2004) and charniak and johnson (2005).<papid> P05-1022 </papid>a quite different approach to parsing efficiency is taken in caraballo and charniak (1998) <papid> J98-2004 </papid>and refined in charniak et al (1998)).<papid> W98-1115 </papid></citsent>
<aftsection>
<nextsent>here efficiency is gained by using standard chart parsing algorithm and pulling constituents off the agenda according to (an estimate of) their probability given the sentence.
</nextsent>
<nextsent>this probability is computed by estimating equation 1: p(nki,j | s) = ?(nki,j)?(nki,j) p(s) .
</nextsent>
<nextsent>(1) 169 it must be estimated because during the bottom-up chart-parsing algorithm, the true outside probability cannot be computed.
</nextsent>
<nextsent>the results cited in caraballo and charniak (1998) <papid> J98-2004 </papid>cannot be compared directly to ours, but are roughly in the same equivalence class.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O746">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>the results cited in caraballo and charniak (1998) <papid> J98-2004 </papid>cannot be compared directly to ours, but are roughly in the same equivalence class.</prevsent>
<prevsent>those presented in charniak et al (1998) <papid> W98-1115 </papid>are superior,but in section 5 below we suggest that combination of the techniques could yield better results still.</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
klein and manning (2003<papid> P03-1054 </papid>a) describe efficient a?</citsent>
<aftsection>
<nextsent>for the most likely parse, where pruning is accomplished by using equation 1 and true upper bound on the outside probability.
</nextsent>
<nextsent>while their maximum is looser estimate of the out side probability, it is an admissible heuristic and together with an a?
</nextsent>
<nextsent>search is guaranteed to findthe best parse first.
</nextsent>
<nextsent>one question is if the guarantee is worth the extra search required by the looser estimate of the true outside probability.tsuruoka and tsujii (2004) explore the framework developed in klein and manning (2003<papid> P03-1054 </papid>a), and seek ways to minimize the time required by the heap manipulations necessary in this scheme.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O770">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>they also speed computation by pre computing more accurate upper bounds on the outside probabilities of various kinds of constituents.
</prevsent>
<prevsent>theyare able to reduce by half the number of constituents required to find the best parse (com pared to cky).
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
most recently, mcdonald et al (2005) <papid> P05-1012 </papid>have implemented dependency parser with good accuracy (it is almost as good at dependency parsing as charniak (2000)) <papid> A00-2018 </papid>and very impressive speed (it is about ten times faster than collins (1997) <papid> P97-1003 </papid>and four times faster than charniak (2000)).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>it achieves its speed in part because it uses the eisner and satta (1999) <papid> P99-1059 </papid>algorithm for n3 bilexical parsing, but also because dependency parsing has much lower grammar constant than does standard pcfg parsing ? after all, there are no phrasal constituents to consider.</nextsent>
<nextsent>the current paper can be thought of as way to take the sting out of the grammar constant for pcfgs by parsing first with very few phrasal constituents and adding them only level: 0 1 2 3 s1 { s1 { s1 { s1 ? ?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O772">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>they also speed computation by pre computing more accurate upper bounds on the outside probabilities of various kinds of constituents.
</prevsent>
<prevsent>theyare able to reduce by half the number of constituents required to find the best parse (com pared to cky).
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
most recently, mcdonald et al (2005) <papid> P05-1012 </papid>have implemented dependency parser with good accuracy (it is almost as good at dependency parsing as charniak (2000)) <papid> A00-2018 </papid>and very impressive speed (it is about ten times faster than collins (1997) <papid> P97-1003 </papid>and four times faster than charniak (2000)).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>it achieves its speed in part because it uses the eisner and satta (1999) <papid> P99-1059 </papid>algorithm for n3 bilexical parsing, but also because dependency parsing has much lower grammar constant than does standard pcfg parsing ? after all, there are no phrasal constituents to consider.</nextsent>
<nextsent>the current paper can be thought of as way to take the sting out of the grammar constant for pcfgs by parsing first with very few phrasal constituents and adding them only level: 0 1 2 3 s1 { s1 { s1 { s1 ? ?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O774">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> previous research.  </section>
<citcontext>
<prevsection>
<prevsent>theyare able to reduce by half the number of constituents required to find the best parse (com pared to cky).
</prevsent>
<prevsent>most recently, mcdonald et al (2005) <papid> P05-1012 </papid>have implemented dependency parser with good accuracy (it is almost as good at dependency parsing as charniak (2000)) <papid> A00-2018 </papid>and very impressive speed (it is about ten times faster than collins (1997) <papid> P97-1003 </papid>and four times faster than charniak (2000)).<papid> A00-2018 </papid></prevsent>
</prevsection>
<citsent citstr=" P99-1059 ">
it achieves its speed in part because it uses the eisner and satta (1999) <papid> P99-1059 </papid>algorithm for n3 bilexical parsing, but also because dependency parsing has much lower grammar constant than does standard pcfg parsing ? after all, there are no phrasal constituents to consider.</citsent>
<aftsection>
<nextsent>the current paper can be thought of as way to take the sting out of the grammar constant for pcfgs by parsing first with very few phrasal constituents and adding them only level: 0 1 2 3 s1 { s1 { s1 { s1 ? ?
</nextsent>
<nextsent>hp ? ?
</nextsent>
<nextsent>s ? ?
</nextsent>
<nextsent>s vp ucp sq sbar sbarq sinv ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O775">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> multilevel course-to-fine parsing.  </section>
<citcontext>
<prevsection>
<prevsent>the complete nonterminal clustering is given in figure 1.
</prevsent>
<prevsent>we do not cluster preterminals.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
these remain fixed at all levels to the standard penn-tree-bank set marcus et al (1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>level-0 makes two distinctions, the root node and everybody else.
</nextsent>
<nextsent>at level 1 we make one further distinction, between phrases that tend to be heads of constituents (nps, vps, and ss) and those that tend to be modifiers (adjps, pps, etc.).
</nextsent>
<nextsent>level-2 has total of five categories: root, things that are typically headed by nouns,those headed by verbs, things headed by prepositions, and things headed by classical modifiers (adjectives, adverbs, etc.).
</nextsent>
<nextsent>finally, level 3 is the 170 s1 p prp he vbd ate in at dt the nn mall . . s1 hp hp prp he hp vbd ate mp in at hp dt the nn mall . . s1 s_ n_ prp he s_ vbd ate p_ in at n_ dt the nn mall . . s1 np prp he vp vbd ate pp in at np dt the nn mall . . figure 2: tree represented at levels 0 to 3 classical tree-bank set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O776">
<title id=" N06-1022.xml">multilevel coarsetofine pcfg parsing </title>
<section> multilevel course-to-fine parsing.  </section>
<citcontext>
<prevsection>
<prevsent>for example, consider the rule a c e where is the head constituent.
</prevsent>
<prevsent>we binarize this as follows: a1 a1 a2 a2 a3 a3 c grammars induced in this way tend to be too specific, as the binarization introduce very large number of very specialized phrasal categories (the ai).
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
following common practice johnson (1998; <papid> J98-4004 </papid>klein and manning (2003<papid> P03-1054 </papid>b) we markovize by replacing these nonterminals with ones that remember less of the immediate rule context.</citsent>
<aftsection>
<nextsent>in our version we keep track of only the parent, the head constituent and the constituent immediately to the right or left, depending on which side of the constituent we are processing.
</nextsent>
<nextsent>with this scheme the above rules now look like this: ad,c ad,c aa,c aa,c ab,c ab,c c so, for example, the rule ad,c e?
</nextsent>
<nextsent>would have high probability if constituents of type a, with as their head, often have followed by at their end.
</nextsent>
<nextsent>lastly, we add parent annotation to phrasal categories to improve parsing accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O837">
<title id=" N07-1039.xml">extracting appraisal expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data mining on appraisal expressions gives meaningful and non-obvious insights.
</prevsent>
<prevsent>sentiment analysis, which seeks to analyze opinion in natural language text, has grown in interest in recent years.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
sentiment analysis includes variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (pang et al, 2002) <papid> W02-1011 </papid>or positive and negative words (turney, 2002; <papid> P02-1053 </papid>mullen and collier, 2004); <papid> W04-3253 </papid>classifying sentences in document as either subjective or objective (riloff and wiebe, 2003; <papid> W03-1014 </papid>pang and lee, 2004); <papid> P04-1035 </papid>identifying or classifying appraisal targets (nigam and hurst, 2004); identifying the source of an opinion in text (choi et al, 2005), <papid> H05-1045 </papid>whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (gamon et al, 2005; popescu and etzioni, 2005).<papid> H05-1043 </papid></citsent>
<aftsection>
<nextsent>much of this work has utilized the fundamental concept of semantic orien tation?, (turney, 2002); <papid> P02-1053 </papid>however, sentiment analysis still lacks unified field theory?.</nextsent>
<nextsent>we propose in this paper that fundamental task underlying many of these formulations is the extraction and analysis of appraisal expressions, defined as those structured textual units which express an evaluation of some object.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O838">
<title id=" N07-1039.xml">extracting appraisal expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data mining on appraisal expressions gives meaningful and non-obvious insights.
</prevsent>
<prevsent>sentiment analysis, which seeks to analyze opinion in natural language text, has grown in interest in recent years.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
sentiment analysis includes variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (pang et al, 2002) <papid> W02-1011 </papid>or positive and negative words (turney, 2002; <papid> P02-1053 </papid>mullen and collier, 2004); <papid> W04-3253 </papid>classifying sentences in document as either subjective or objective (riloff and wiebe, 2003; <papid> W03-1014 </papid>pang and lee, 2004); <papid> P04-1035 </papid>identifying or classifying appraisal targets (nigam and hurst, 2004); identifying the source of an opinion in text (choi et al, 2005), <papid> H05-1045 </papid>whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (gamon et al, 2005; popescu and etzioni, 2005).<papid> H05-1043 </papid></citsent>
<aftsection>
<nextsent>much of this work has utilized the fundamental concept of semantic orien tation?, (turney, 2002); <papid> P02-1053 </papid>however, sentiment analysis still lacks unified field theory?.</nextsent>
<nextsent>we propose in this paper that fundamental task underlying many of these formulations is the extraction and analysis of appraisal expressions, defined as those structured textual units which express an evaluation of some object.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O839">
<title id=" N07-1039.xml">extracting appraisal expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data mining on appraisal expressions gives meaningful and non-obvious insights.
</prevsent>
<prevsent>sentiment analysis, which seeks to analyze opinion in natural language text, has grown in interest in recent years.
</prevsent>
</prevsection>
<citsent citstr=" W04-3253 ">
sentiment analysis includes variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (pang et al, 2002) <papid> W02-1011 </papid>or positive and negative words (turney, 2002; <papid> P02-1053 </papid>mullen and collier, 2004); <papid> W04-3253 </papid>classifying sentences in document as either subjective or objective (riloff and wiebe, 2003; <papid> W03-1014 </papid>pang and lee, 2004); <papid> P04-1035 </papid>identifying or classifying appraisal targets (nigam and hurst, 2004); identifying the source of an opinion in text (choi et al, 2005), <papid> H05-1045 </papid>whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (gamon et al, 2005; popescu and etzioni, 2005).<papid> H05-1043 </papid></citsent>
<aftsection>
<nextsent>much of this work has utilized the fundamental concept of semantic orien tation?, (turney, 2002); <papid> P02-1053 </papid>however, sentiment analysis still lacks unified field theory?.</nextsent>
<nextsent>we propose in this paper that fundamental task underlying many of these formulations is the extraction and analysis of appraisal expressions, defined as those structured textual units which express an evaluation of some object.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O840">
<title id=" N07-1039.xml">extracting appraisal expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data mining on appraisal expressions gives meaningful and non-obvious insights.
</prevsent>
<prevsent>sentiment analysis, which seeks to analyze opinion in natural language text, has grown in interest in recent years.
</prevsent>
</prevsection>
<citsent citstr=" W03-1014 ">
sentiment analysis includes variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (pang et al, 2002) <papid> W02-1011 </papid>or positive and negative words (turney, 2002; <papid> P02-1053 </papid>mullen and collier, 2004); <papid> W04-3253 </papid>classifying sentences in document as either subjective or objective (riloff and wiebe, 2003; <papid> W03-1014 </papid>pang and lee, 2004); <papid> P04-1035 </papid>identifying or classifying appraisal targets (nigam and hurst, 2004); identifying the source of an opinion in text (choi et al, 2005), <papid> H05-1045 </papid>whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (gamon et al, 2005; popescu and etzioni, 2005).<papid> H05-1043 </papid></citsent>
<aftsection>
<nextsent>much of this work has utilized the fundamental concept of semantic orien tation?, (turney, 2002); <papid> P02-1053 </papid>however, sentiment analysis still lacks unified field theory?.</nextsent>
<nextsent>we propose in this paper that fundamental task underlying many of these formulations is the extraction and analysis of appraisal expressions, defined as those structured textual units which express an evaluation of some object.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O841">
<title id=" N07-1039.xml">extracting appraisal expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data mining on appraisal expressions gives meaningful and non-obvious insights.
</prevsent>
<prevsent>sentiment analysis, which seeks to analyze opinion in natural language text, has grown in interest in recent years.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
sentiment analysis includes variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (pang et al, 2002) <papid> W02-1011 </papid>or positive and negative words (turney, 2002; <papid> P02-1053 </papid>mullen and collier, 2004); <papid> W04-3253 </papid>classifying sentences in document as either subjective or objective (riloff and wiebe, 2003; <papid> W03-1014 </papid>pang and lee, 2004); <papid> P04-1035 </papid>identifying or classifying appraisal targets (nigam and hurst, 2004); identifying the source of an opinion in text (choi et al, 2005), <papid> H05-1045 </papid>whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (gamon et al, 2005; popescu and etzioni, 2005).<papid> H05-1043 </papid></citsent>
<aftsection>
<nextsent>much of this work has utilized the fundamental concept of semantic orien tation?, (turney, 2002); <papid> P02-1053 </papid>however, sentiment analysis still lacks unified field theory?.</nextsent>
<nextsent>we propose in this paper that fundamental task underlying many of these formulations is the extraction and analysis of appraisal expressions, defined as those structured textual units which express an evaluation of some object.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O842">
<title id=" N07-1039.xml">extracting appraisal expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data mining on appraisal expressions gives meaningful and non-obvious insights.
</prevsent>
<prevsent>sentiment analysis, which seeks to analyze opinion in natural language text, has grown in interest in recent years.
</prevsent>
</prevsection>
<citsent citstr=" H05-1045 ">
sentiment analysis includes variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (pang et al, 2002) <papid> W02-1011 </papid>or positive and negative words (turney, 2002; <papid> P02-1053 </papid>mullen and collier, 2004); <papid> W04-3253 </papid>classifying sentences in document as either subjective or objective (riloff and wiebe, 2003; <papid> W03-1014 </papid>pang and lee, 2004); <papid> P04-1035 </papid>identifying or classifying appraisal targets (nigam and hurst, 2004); identifying the source of an opinion in text (choi et al, 2005), <papid> H05-1045 </papid>whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (gamon et al, 2005; popescu and etzioni, 2005).<papid> H05-1043 </papid></citsent>
<aftsection>
<nextsent>much of this work has utilized the fundamental concept of semantic orien tation?, (turney, 2002); <papid> P02-1053 </papid>however, sentiment analysis still lacks unified field theory?.</nextsent>
<nextsent>we propose in this paper that fundamental task underlying many of these formulations is the extraction and analysis of appraisal expressions, defined as those structured textual units which express an evaluation of some object.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O843">
<title id=" N07-1039.xml">extracting appraisal expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data mining on appraisal expressions gives meaningful and non-obvious insights.
</prevsent>
<prevsent>sentiment analysis, which seeks to analyze opinion in natural language text, has grown in interest in recent years.
</prevsent>
</prevsection>
<citsent citstr=" H05-1043 ">
sentiment analysis includes variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (pang et al, 2002) <papid> W02-1011 </papid>or positive and negative words (turney, 2002; <papid> P02-1053 </papid>mullen and collier, 2004); <papid> W04-3253 </papid>classifying sentences in document as either subjective or objective (riloff and wiebe, 2003; <papid> W03-1014 </papid>pang and lee, 2004); <papid> P04-1035 </papid>identifying or classifying appraisal targets (nigam and hurst, 2004); identifying the source of an opinion in text (choi et al, 2005), <papid> H05-1045 </papid>whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (gamon et al, 2005; popescu and etzioni, 2005).<papid> H05-1043 </papid></citsent>
<aftsection>
<nextsent>much of this work has utilized the fundamental concept of semantic orien tation?, (turney, 2002); <papid> P02-1053 </papid>however, sentiment analysis still lacks unified field theory?.</nextsent>
<nextsent>we propose in this paper that fundamental task underlying many of these formulations is the extraction and analysis of appraisal expressions, defined as those structured textual units which express an evaluation of some object.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O846">
<title id=" N07-1039.xml">extracting appraisal expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mullen and colliers (2004) <papid> W04-3253 </papid>notion of classifying appraisal terms using multidimensional set of attributes is closely tied to the definition of an appraisal expression, which is classified along several dimensions.</prevsent>
<prevsent>in previous work (whitelaw etal., 2005), we presented related technique of finding opinion phrases, using multidimensional setof attributes and modeling the semantics of modifiers in these phrases.</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
the use of multiple text classifiers by wiebe and colleagues (wilson et al,2005; <papid> H05-1044 </papid>wiebe et al, 2004) <papid> J04-3002 </papid>for various kinds of sentiment classification can also be viewed as sentence level technique for analyzing appraisal expressions.nigam and hursts (2004) work on detecting opinions about certain topic presages our notion of connecting attitudes to targets, while popescu and etzionis (2005) <papid> H05-1043 </papid>opinion mining technique also fits well into our framework.</citsent>
<aftsection>
<nextsent>in this paper we describe system for extractingadjectival appraisal expressions, based on hand built lexicon, combination of heuristic shallow parsing and dependency parsing, and expectation maximization word sense disambiguation.
</nextsent>
<nextsent>each ex 308 tracted appraisal expression is represented as set of feature values in terms of its evaluative function in the text.
</nextsent>
<nextsent>we have applied this system to two domains of texts: product reviews, and movie reviews.
</nextsent>
<nextsent>manual evaluation of the extraction shows our system towork well, as well as giving some directions for improvement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O847">
<title id=" N07-1039.xml">extracting appraisal expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mullen and colliers (2004) <papid> W04-3253 </papid>notion of classifying appraisal terms using multidimensional set of attributes is closely tied to the definition of an appraisal expression, which is classified along several dimensions.</prevsent>
<prevsent>in previous work (whitelaw etal., 2005), we presented related technique of finding opinion phrases, using multidimensional setof attributes and modeling the semantics of modifiers in these phrases.</prevsent>
</prevsection>
<citsent citstr=" J04-3002 ">
the use of multiple text classifiers by wiebe and colleagues (wilson et al,2005; <papid> H05-1044 </papid>wiebe et al, 2004) <papid> J04-3002 </papid>for various kinds of sentiment classification can also be viewed as sentence level technique for analyzing appraisal expressions.nigam and hursts (2004) work on detecting opinions about certain topic presages our notion of connecting attitudes to targets, while popescu and etzionis (2005) <papid> H05-1043 </papid>opinion mining technique also fits well into our framework.</citsent>
<aftsection>
<nextsent>in this paper we describe system for extractingadjectival appraisal expressions, based on hand built lexicon, combination of heuristic shallow parsing and dependency parsing, and expectation maximization word sense disambiguation.
</nextsent>
<nextsent>each ex 308 tracted appraisal expression is represented as set of feature values in terms of its evaluative function in the text.
</nextsent>
<nextsent>we have applied this system to two domains of texts: product reviews, and movie reviews.
</nextsent>
<nextsent>manual evaluation of the extraction shows our system towork well, as well as giving some directions for improvement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O850">
<title id=" N07-1039.xml">extracting appraisal expressions </title>
<section> corpora.  </section>
<citcontext>
<prevsection>
<prevsent>there are 905 reviews of strollers, 5778 2see http://www.cs.cornell.edu/people/pabo /movie-review-data/reviews of ink-jet printers and 8479 reviews of digital cameras, covering 516 individual products.
</prevsent>
<prevsent>each document in each corpus was preprocessed into individual sentences, lower-cased, and tokenized.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we used an implementation of brills (1992)part-of-speech tagger to find adjectives and modi fiers; for parsing, we used the stanford dependency parser (klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>we performed two manual evaluations on the system.
</nextsent>
<nextsent>the first was to evaluate the overall accuracy of the entire system.
</nextsent>
<nextsent>the second was to specifically evaluate the accuracy of the probabilistic dis ambiguator.
</nextsent>
<nextsent>6.1 evaluating accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O852">
<title id=" N07-1028.xml">a case for shorter queries and helping users create them </title>
<section> selecting sub-queries.  </section>
<citcontext>
<prevsection>
<prevsent>the mutual information is then defined as: i(x;y ) = ? ? p(x, y)log p(x, y)p(x)p(y) (1)intuitively, mutual information measures the information about that is shared by . if and are independent, then contains no information about and vice versa and hence their mutual information is zero.
</prevsent>
<prevsent>mutual information is attractive because it isnot only easy to compute, but also takes into consideration corpus statistics and semantics.
</prevsent>
</prevsection>
<citsent citstr=" P89-1010 ">
the mutual information between two terms (church and hanks, 1989) <papid> P89-1010 </papid>can be calculated using equation 2.</citsent>
<aftsection>
<nextsent>i(x, y) = log n(x,y) n(x) n(y) (2)n(x, y) is the number of times terms and occurred within term window of 100 terms across the corpus, while n(x) and n(y) are the frequencies of and in the collection of size terms.to tackle the situation where we have an arbitrary number of variables (terms) we extend the two variable case to the multivariate case.
</nextsent>
<nextsent>the extension, called multivariate mutual information (mvmi) can be generalized from equation 1 to: i(x1;x2;x3; ...;xn ) = ? i=1 (1)i1 ? x?(x1,x2,x3,...,xn),|x|=k h(x) (3) the calculation of multivariate information using equation 3 was very cumbersome, and we instead worked with the approximation (kern et al, 2003) given below.
</nextsent>
<nextsent>i(x1;x2;x3; ...;xn ) = (4) ? i,j={1,2,3,...,n ;i6=j} i(xi;xj) (5)for the case involving multiple terms, we calculated mvmi as the sum of the pair-wise mutual information for all terms in the candidate sub-query.this can be also viewed as the creation of completely connected graph = (v,e), where the vertices are the terms and the edges are weighted using the mutual information between the vertices they connect.
</nextsent>
<nextsent>to select score representative of the quality ofa sub-query we considered several options including the sum, average, median and minimum of the edge weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O856">
<title id=" N04-1041.xml">automatically labeling semantic classes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 describes our algorithm for labeling concepts and for extracting hyponym relationships.
</prevsent>
<prevsent>experimental results are presented in section 4 and finally, we conclude with discussion and future work.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
there have been several approaches to automatically discovering lexico-semantic information from text (hearst 1992; <papid> C92-2082 </papid>riloff and shepherd 1997; <papid> W97-0313 </papid>riloff and jones 1999; berland and charniak 1999; <papid> P99-1008 </papid>pantel and lin 2002; fleischman et al  2003; <papid> P03-1001 </papid>girju et al  2003).</citsent>
<aftsection>
<nextsent>one approach constructs automatic thesauri by computing the similarity between words based on their distribution in corpus (hindle 1990; <papid> P90-1034 </papid>lin 1998).<papid> P98-2127 </papid></nextsent>
<nextsent>the output of these programs is ranked list of similar words to each word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O857">
<title id=" N04-1041.xml">automatically labeling semantic classes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 describes our algorithm for labeling concepts and for extracting hyponym relationships.
</prevsent>
<prevsent>experimental results are presented in section 4 and finally, we conclude with discussion and future work.
</prevsent>
</prevsection>
<citsent citstr=" W97-0313 ">
there have been several approaches to automatically discovering lexico-semantic information from text (hearst 1992; <papid> C92-2082 </papid>riloff and shepherd 1997; <papid> W97-0313 </papid>riloff and jones 1999; berland and charniak 1999; <papid> P99-1008 </papid>pantel and lin 2002; fleischman et al  2003; <papid> P03-1001 </papid>girju et al  2003).</citsent>
<aftsection>
<nextsent>one approach constructs automatic thesauri by computing the similarity between words based on their distribution in corpus (hindle 1990; <papid> P90-1034 </papid>lin 1998).<papid> P98-2127 </papid></nextsent>
<nextsent>the output of these programs is ranked list of similar words to each word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O858">
<title id=" N04-1041.xml">automatically labeling semantic classes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 describes our algorithm for labeling concepts and for extracting hyponym relationships.
</prevsent>
<prevsent>experimental results are presented in section 4 and finally, we conclude with discussion and future work.
</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
there have been several approaches to automatically discovering lexico-semantic information from text (hearst 1992; <papid> C92-2082 </papid>riloff and shepherd 1997; <papid> W97-0313 </papid>riloff and jones 1999; berland and charniak 1999; <papid> P99-1008 </papid>pantel and lin 2002; fleischman et al  2003; <papid> P03-1001 </papid>girju et al  2003).</citsent>
<aftsection>
<nextsent>one approach constructs automatic thesauri by computing the similarity between words based on their distribution in corpus (hindle 1990; <papid> P90-1034 </papid>lin 1998).<papid> P98-2127 </papid></nextsent>
<nextsent>the output of these programs is ranked list of similar words to each word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O859">
<title id=" N04-1041.xml">automatically labeling semantic classes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 describes our algorithm for labeling concepts and for extracting hyponym relationships.
</prevsent>
<prevsent>experimental results are presented in section 4 and finally, we conclude with discussion and future work.
</prevsent>
</prevsection>
<citsent citstr=" P03-1001 ">
there have been several approaches to automatically discovering lexico-semantic information from text (hearst 1992; <papid> C92-2082 </papid>riloff and shepherd 1997; <papid> W97-0313 </papid>riloff and jones 1999; berland and charniak 1999; <papid> P99-1008 </papid>pantel and lin 2002; fleischman et al  2003; <papid> P03-1001 </papid>girju et al  2003).</citsent>
<aftsection>
<nextsent>one approach constructs automatic thesauri by computing the similarity between words based on their distribution in corpus (hindle 1990; <papid> P90-1034 </papid>lin 1998).<papid> P98-2127 </papid></nextsent>
<nextsent>the output of these programs is ranked list of similar words to each word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O860">
<title id=" N04-1041.xml">automatically labeling semantic classes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>experimental results are presented in section 4 and finally, we conclude with discussion and future work.
</prevsent>
<prevsent>there have been several approaches to automatically discovering lexico-semantic information from text (hearst 1992; <papid> C92-2082 </papid>riloff and shepherd 1997; <papid> W97-0313 </papid>riloff and jones 1999; berland and charniak 1999; <papid> P99-1008 </papid>pantel and lin 2002; fleischman et al  2003; <papid> P03-1001 </papid>girju et al  2003).</prevsent>
</prevsection>
<citsent citstr=" P90-1034 ">
one approach constructs automatic thesauri by computing the similarity between words based on their distribution in corpus (hindle 1990; <papid> P90-1034 </papid>lin 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>the output of these programs is ranked list of similar words to each word.
</nextsent>
<nextsent>for example, lins approach outputs the following top-20 similar words of orange: (d) peach, grapefruit, yellow, lemon, pink, avocado, tangerine, banana, purple, santa ana, strawberry, tomato, red, pineapple, pear, apricot, apple, green, citrus, mango common problem of such lists is that they do not discriminate between the senses of polysemous words.
</nextsent>
<nextsent>for example, in (d), the color and fruit senses of orange are mixed up.
</nextsent>
<nextsent>lin and pantel (2001) proposed clustering algorithm, unicon, which generates similar lists but discriminates between senses of words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O861">
<title id=" N04-1041.xml">automatically labeling semantic classes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>experimental results are presented in section 4 and finally, we conclude with discussion and future work.
</prevsent>
<prevsent>there have been several approaches to automatically discovering lexico-semantic information from text (hearst 1992; <papid> C92-2082 </papid>riloff and shepherd 1997; <papid> W97-0313 </papid>riloff and jones 1999; berland and charniak 1999; <papid> P99-1008 </papid>pantel and lin 2002; fleischman et al  2003; <papid> P03-1001 </papid>girju et al  2003).</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
one approach constructs automatic thesauri by computing the similarity between words based on their distribution in corpus (hindle 1990; <papid> P90-1034 </papid>lin 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>the output of these programs is ranked list of similar words to each word.
</nextsent>
<nextsent>for example, lins approach outputs the following top-20 similar words of orange: (d) peach, grapefruit, yellow, lemon, pink, avocado, tangerine, banana, purple, santa ana, strawberry, tomato, red, pineapple, pear, apricot, apple, green, citrus, mango common problem of such lists is that they do not discriminate between the senses of polysemous words.
</nextsent>
<nextsent>for example, in (d), the color and fruit senses of orange are mixed up.
</nextsent>
<nextsent>lin and pantel (2001) proposed clustering algorithm, unicon, which generates similar lists but discriminates between senses of words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O864">
<title id=" N04-1041.xml">automatically labeling semantic classes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>they reported an accuracy of about 55% precision on corpus of 100,000 words.
</prevsent>
<prevsent>girju, badulescu and moldovan (2003) improved upon this work by using machine learning filter.
</prevsent>
</prevsection>
<citsent citstr=" W02-1111 ">
mann (2002) <papid> W02-1111 </papid>and fleischman et al  (2003) <papid> P03-1001 </papid>used part of speech patterns to extract subset of hyponym relations involing proper nouns.</citsent>
<aftsection>
<nextsent>the research discussed above on discovering hyponym relationships all take bottom up approach.
</nextsent>
<nextsent>that is, they use patterns to independently discover semantic relationships of words.
</nextsent>
<nextsent>however, for infrequent words, these patterns do not match or, worse yet, generate in correct relationships.
</nextsent>
<nextsent>ours is top down approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O866">
<title id=" N04-1041.xml">automatically labeling semantic classes </title>
<section> labeling classes.  </section>
<citcontext>
<prevsection>
<prevsent>== ? = 11 log (1) where is the number of words and = ? ?
</prevsent>
<prevsent>= = i j ijc 1 1 is the total frequency count of all features of all words.
</prevsent>
</prevsection>
<citsent citstr=" P89-1010 ">
mutual information is commonly used to measure the association strength between two words (church and hanks 1989).<papid> P89-1010 </papid></citsent>
<aftsection>
<nextsent>a well-known problem is that mutual information is biased towards infrequent elements/features.
</nextsent>
<nextsent>we therefore multiply mief with the following discounting factor: 1,min ,min 1 11 11 +???
</nextsent>
<nextsent>== == j jf i ei j jf i ei ef ef cc cc c (2) 3.2 phase ii.
</nextsent>
<nextsent>following (pantel and lin 2002), we construct committee for each semantic class.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O867">
<title id=" N04-1041.xml">automatically labeling semantic classes </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>in this section, we present an evaluation of the class labeling algorithm and of the hyponym relationships discovered by our system.
</prevsent>
<prevsent>4.1 experimental setup.
</prevsent>
</prevsection>
<citsent citstr=" C94-1079 ">
we used minipar (lin 1994), <papid> C94-1079 </papid>broad coverage parser, to parse 3gb of newspaper text from the aquaint (trec-9) collection.</citsent>
<aftsection>
<nextsent>we collected the frequency counts of the grammatical relationships (contexts) output by minipar and used them to compute the pointwise mutual information vectors described in section 3.1.
</nextsent>
<nextsent>we used the 1432 noun clusters extracted by cbc1 as the list of concepts to name.
</nextsent>
<nextsent>for each concept, we then used our algorithm described in section 3 to extract the top-20 names for each concept.
</nextsent>
<nextsent>1 available at http://www.isi.edu/~pantel/demos.htm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O869">
<title id=" N03-1017.xml">statistical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>learning only syntactically motivated phrases degrades the performance of our systems.
</prevsent>
<prevsent>various researchers have improved the quality of statistical machine translation system with the use of phrase translation.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
och et al [1999]<papid> W99-0604 </papid>s alignment template model can be re framed as phrase translation system; yamada and knight [2001] <papid> P01-1067 </papid>use phrase translation in syntax based translation system; marcu and wong [2002] <papid> W02-1018 </papid>introduced joint-probability model for phrase translation; and the cmu and ibm word-based statistical machine translation systems1 are augmented with phrase translation capability.</citsent>
<aftsection>
<nextsent>phrase translation clearly helps, as we will also show with the experiments in this paper.
</nextsent>
<nextsent>but what is the best1presentations at darpa iao machine translation work shop, july 22-23, 2002, santa monica, ca method to extract phrase translation pairs?
</nextsent>
<nextsent>in order to investigate this question, we created uniform evaluation framework that enables the comparison of different ways to build phrase translation table.
</nextsent>
<nextsent>our experiments show that high levels of performance can be achieved with fairly simple means.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O870">
<title id=" N03-1017.xml">statistical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>learning only syntactically motivated phrases degrades the performance of our systems.
</prevsent>
<prevsent>various researchers have improved the quality of statistical machine translation system with the use of phrase translation.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
och et al [1999]<papid> W99-0604 </papid>s alignment template model can be re framed as phrase translation system; yamada and knight [2001] <papid> P01-1067 </papid>use phrase translation in syntax based translation system; marcu and wong [2002] <papid> W02-1018 </papid>introduced joint-probability model for phrase translation; and the cmu and ibm word-based statistical machine translation systems1 are augmented with phrase translation capability.</citsent>
<aftsection>
<nextsent>phrase translation clearly helps, as we will also show with the experiments in this paper.
</nextsent>
<nextsent>but what is the best1presentations at darpa iao machine translation work shop, july 22-23, 2002, santa monica, ca method to extract phrase translation pairs?
</nextsent>
<nextsent>in order to investigate this question, we created uniform evaluation framework that enables the comparison of different ways to build phrase translation table.
</nextsent>
<nextsent>our experiments show that high levels of performance can be achieved with fairly simple means.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O871">
<title id=" N03-1017.xml">statistical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>learning only syntactically motivated phrases degrades the performance of our systems.
</prevsent>
<prevsent>various researchers have improved the quality of statistical machine translation system with the use of phrase translation.
</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
och et al [1999]<papid> W99-0604 </papid>s alignment template model can be re framed as phrase translation system; yamada and knight [2001] <papid> P01-1067 </papid>use phrase translation in syntax based translation system; marcu and wong [2002] <papid> W02-1018 </papid>introduced joint-probability model for phrase translation; and the cmu and ibm word-based statistical machine translation systems1 are augmented with phrase translation capability.</citsent>
<aftsection>
<nextsent>phrase translation clearly helps, as we will also show with the experiments in this paper.
</nextsent>
<nextsent>but what is the best1presentations at darpa iao machine translation work shop, july 22-23, 2002, santa monica, ca method to extract phrase translation pairs?
</nextsent>
<nextsent>in order to investigate this question, we created uniform evaluation framework that enables the comparison of different ways to build phrase translation table.
</nextsent>
<nextsent>our experiments show that high levels of performance can be achieved with fairly simple means.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O874">
<title id=" N03-1017.xml">statistical phrase based translation </title>
<section> evaluation framework.  </section>
<citcontext>
<prevsection>
<prevsent>the hypotheses are stored in stacks.
</prevsent>
<prevsent>the stack +, contains all hypotheses in which - foreign words have been translated.
</prevsent>
</prevsection>
<citsent citstr=" W01-1408 ">
we re combine search hypotheses as done by och et al [2001].<papid> W01-1408 </papid></citsent>
<aftsection>
<nextsent>while this reduces the number of hypotheses stored in each stack somewhat, stack size is exponential with respect to input sentence length.
</nextsent>
<nextsent>this makes an exhaustive search impractical.
</nextsent>
<nextsent>thus, we prune out weak hypotheses based on the cost they incurred so far and future cost estimate.
</nextsent>
<nextsent>for each stack, we only keep beam of the best . hypotheses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O875">
<title id=" N03-1017.xml">statistical phrase based translation </title>
<section> methods for learning phrase.  </section>
<citcontext>
<prevsection>
<prevsent>we report most experimental results on german english translation task, since we had sufficient resources available for this language pair.
</prevsent>
<prevsent>we confirm the major points in experiments on additional language pairs.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
as the first method, we learn phrase alignments from corpus that has been word-aligned by training toolkit for word-based translation model: the giza++ [och and ney, 2000] <papid> P00-1056 </papid>toolkit for the ibm models [brown et al, 1993].<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>the extraction heuristic is similar to the one used in the alignment template work by och et al [1999]<papid> W99-0604 </papid>.</nextsent>
<nextsent>a number of researchers have proposed to focus onthe translation of phrases that have linguistic motivation [yamada and knight, 2001; <papid> P01-1067 </papid>imamura, 2002].</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O876">
<title id=" N03-1017.xml">statistical phrase based translation </title>
<section> methods for learning phrase.  </section>
<citcontext>
<prevsection>
<prevsent>we report most experimental results on german english translation task, since we had sufficient resources available for this language pair.
</prevsent>
<prevsent>we confirm the major points in experiments on additional language pairs.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
as the first method, we learn phrase alignments from corpus that has been word-aligned by training toolkit for word-based translation model: the giza++ [och and ney, 2000] <papid> P00-1056 </papid>toolkit for the ibm models [brown et al, 1993].<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>the extraction heuristic is similar to the one used in the alignment template work by och et al [1999]<papid> W99-0604 </papid>.</nextsent>
<nextsent>a number of researchers have proposed to focus onthe translation of phrases that have linguistic motivation [yamada and knight, 2001; <papid> P01-1067 </papid>imamura, 2002].</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O880">
<title id=" N03-1017.xml">statistical phrase based translation </title>
<section> methods for learning phrase.  </section>
<citcontext>
<prevsection>
<prevsent>a number of researchers have proposed to focus onthe translation of phrases that have linguistic motivation [yamada and knight, 2001; <papid> P01-1067 </papid>imamura, 2002].</prevsent>
<prevsent>they only consider word sequences as phrases, if they are constituents, i.e. subtrees in syntax tree (such as noun phrase).</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
to identify these, we use word-aligned corpus annotated with parse trees generated by statistical syntactic parsers [collins, 1997; <papid> P97-1003 </papid>schmidt and schulte im walde, 2000].</citsent>
<aftsection>
<nextsent>the third method for comparison is the joint phrase model proposed by marcu and wong [2002].<papid> W02-1018 </papid></nextsent>
<nextsent>this model learns directly phrase-level alignment of the parallel corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O887">
<title id=" N03-1017.xml">statistical phrase based translation </title>
<section> methods for learning phrase.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, translations for phrases such as house themay be learned.
</prevsent>
<prevsent>intuitively we would be inclined to believe that such phrases do not help: restricting possible phrases to syntactically motivated phrases could filter out such non-intuitive pairs.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
another motivation to evaluate the performance of phrase translation model that contains only syntactic phrases comes from recent efforts to built syntactic translation models [yamada and knight, 2001; <papid> P01-1067 </papid>wu, 1997].<papid> J97-3002 </papid></citsent>
<aftsection>
<nextsent>inthese models, reordering of words is restricted to reordering of constituents in well-formed syntactic parse trees.
</nextsent>
<nextsent>when augmenting such models with phrase translations,typically only translation of phrases that span entire syntactic subtrees is possible.
</nextsent>
<nextsent>it is important to know if this is helpful or harmful restriction.consistent with imamura [2002], we define syntactic phrase as word sequence that is covered by single subtree in syntactic parse tree.we collect syntactic phrase pairs as follows: we word align parallel corpus, as described in section 3.1.
</nextsent>
<nextsent>we then parse both sides of the corpus with syntactic parsers [collins, 1997; <papid> P97-1003 </papid>schmidt and schulte im walde, 2000].</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O894">
<title id=" N03-1017.xml">statistical phrase based translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in direct comparison, learning all phrases consistent with the word alignment (ap) is superior to the joint model (joint), although not by much.
</prevsent>
<prevsent>the restriction to only syntactic phrases (syn) is harmful.
</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
we also included in the figure the performance of an ibm model 4 word based translation system (m4), which uses greedy decoder [germann et al, 2001].<papid> P01-1030 </papid></citsent>
<aftsection>
<nextsent>its performance is worse than both ap and joint.
</nextsent>
<nextsent>these results are consistent over training corpus sizes from 10,000 sentence pairs to 320,000 sentence pairs.
</nextsent>
<nextsent>all systems improve with more data.
</nextsent>
<nextsent>table 1 lists the number of distinct phrase translation pairs learned by each method and each corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O898">
<title id=" N06-2022.xml">automatic recognition of personality in conversation </title>
<section> experimental method.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 feature selection.
</prevsent>
<prevsent>features are automatically extracted from each extract (see table 2).
</prevsent>
</prevsection>
<citsent citstr=" P90-1010 ">
we compute the ratio of words in each category from the liwc utility (pennebaker et al , 2001), as those features are correlated with the big five dimensions (pennebaker and king, 1999).additional psychological characteristics were computed by averaging word feature counts from the mrc psycho linguistic database (coltheart, 1981).in an attempt to capture initiative-taking in conversation (walker and whittaker, 1990; <papid> P90-1010 </papid>furnham, 1990), we introduce utterance type features using heuristics on the parse tree to tag each utterance as command,prompt, question or assertion.</citsent>
<aftsection>
<nextsent>overall tagging accuracy over 100 randomly selected utterances is 88%.
</nextsent>
<nextsent>as personality influences speech, we also use praat liwc features (pennebaker et al , 2001): ? standard counts: - word count (wc), words per sentence (wps), type/token ratio (unique), words captured (dic), words longer than 6 letters (sixltr), negations(negate), assents (assent), articles (article), prepositions (preps), numbers (number) - pronouns (pronoun): 1st person singular (i), 1st person plural (we), total 1st person (self), total 2nd person (you), total 3rd person (other) ? psychological processes: - affective or emotional processes (affect): positive emotions (posemo), positive feelings (posfeel), optimism and energy (optim), negative emotions (negemo), anxiety or fear (anx), anger (anger), sadness (sad) - cognitive processes (cogmech): causation (cause), insight (insight), discrepancy (discrep), inhibition (inhib), tentative (tentat), certainty (certain) - sensory and perceptual processes (senses): seeing (see), hearing (hear), feeling (feel) - social processes (social): communication (comm), other references to people (othref), friends (friends), family (family), humans (humans) ? relativity: - time (time), past tense verb (past), present tense verb (present), future tense verb (future) - space (space): up (up), down (down), inclusive (incl), exclusive (excl) - motion (motion) ? personal concerns: - occupation (occup): school (school), work and job (job), achievement (achieve) - leisure activity (leisure): home (home), sports (sports), television and movies (tv), music (music) - money and financial issues (money) - metaphysical issues (metaph): religion (relig), death (death), physical states and functions (physcal), body states and symptoms (body), sexuality (sexual), eating and drinking (eating), sleeping (sleep), grooming (groom) ? other dimensions: - punctuation (allpct): period (period), comma (comma), colon (colon), semi-colon (semic), question (qmark), exclamation (exclam), dash (dash), quote (quote), apostrophe (apostro), parenthesis (parenth), other (otherp) - swear words (swear), nonfluencies (nonfl), fillers (fillers) mrc features (coltheart, 1981):number of letters (nlet), phonemes (nphon), syllables (nsyl), kucera francis written frequency (k-f-freq), kucera-francis number of categories(k-f-ncats), kucera-francis number of samples (k-f-nsamp), thorndikelorge written frequency (t-l-freql), brown verbal frequency (brown freq), familiarity rating (fam), concrete ness rating (conc), image ability rating (imag), meaningful ness colorado norms (meanc), meaningful ness paivio norms (meanp), age of acquisition (aoa) utterance type features: ratio of commands (command), prompts or back-channels (prompt), questions (question), assertions (assertion) prosodic features: average, minimum, maximum and standard deviation of the voices pitch in hz (pitch-mean, pitch-min, pitch-max, pitch-stddev) and intensity in db (int-mean, int-min, int-max, int-stddev), voiced time (voiced) and speech rate (word-per-sec)table 2: description of all features, with feature labels in brackets.(boersma, 2001) to compute prosodic features characterizing the voices pitch, intensity, and speech rate.
</nextsent>
<nextsent>2.3 statistical model.
</nextsent>
<nextsent>by definition, personality evaluation assesses relative differences between individuals, e.g. one per 86 son is described as an extra vert because the average population is not.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O899">
<title id=" N04-1005.xml">balancing data driven and rule based approaches in the context of a multimodal conversational system </title>
<section> the match application.  </section>
<citcontext>
<prevsection>
<prevsent>in section 3, we discuss various approaches to rapid prototyping of the language model for the speech recognizer and in section 4we present two approaches to robust multimodal understanding.
</prevsent>
<prevsent>section 5 presents the results for speech recognition and multimodal understanding using the different approaches we consider.
</prevsent>
</prevsection>
<citsent citstr=" P02-1048 ">
match (multimodal access to city help) is working city guide and navigation system that enables mobile users to access restaurant and subway information for new york city (nyc) (johnston et al, 2002<papid> P02-1048 </papid>b; johnston et al, 2002<papid> P02-1048 </papid>a).</citsent>
<aftsection>
<nextsent>the user interacts with graphical interface displaying restaurant listings and dynamic map showing locations and street information.
</nextsent>
<nextsent>the inputs canbe speech, drawing on the display with stylus, or synchronous multimodal combinations of the two modes.
</nextsent>
<nextsent>the user can ask for the review, cuisine, phone number,address, or other information about restaurants and subway directions to locations.
</nextsent>
<nextsent>the system responds with graphical cal louts on the display, synchronized with synthetic speech output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O907">
<title id=" N04-1005.xml">balancing data driven and rule based approaches in the context of a multimodal conversational system </title>
<section> the match application.  </section>
<citcontext>
<prevsection>
<prevsent>their speech and ink are processed by speech recognition (sharp et al, 1997) (asr) and handwriting/gesture recognition (gesture, hw reco) components respectively.
</prevsent>
<prevsent>these recognition processes result in lattices of potential words and gestures.
</prevsent>
</prevsection>
<citsent citstr=" C00-1054 ">
these are then combined and assigned meaning representation using multimodal finite-state device (mmfst) (johnston and bangalore, 2000; <papid> C00-1054 </papid>johnston et al., 2002<papid> P02-1048 </papid>b).</citsent>
<aftsection>
<nextsent>this provides as output lattice encoding all of the potential meaning representations assigned to the user inputs.
</nextsent>
<nextsent>this lattice is flattened to an n-best list and passed to multimodal dialog manager (mdm) (john ston et al, 2002<papid> P02-1048 </papid>b), which re-ranks them in accordance with the current dialogue state.</nextsent>
<nextsent>if additional information or confirmation is required, the mdm enters into short information gathering dialogue with the user.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O920">
<title id=" N04-1005.xml">balancing data driven and rule based approaches in the context of a multimodal conversational system </title>
<section> bootstrapping corpora for language.  </section>
<citcontext>
<prevsection>
<prevsent>although there are number of ways of generalizing the out-of-domain corpus, the generalization we have investigated involved identifying linguistic units,such as noun and verb chunks in the out-of-domain corpus and treating them as classes.
</prevsent>
<prevsent>these classes are then instantiated to the corresponding linguistic units from the match domain.
</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
the identification of the linguistic units in the out-of-domain corpus is done automatically usinga super tagger (bangalore and joshi, 1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>we use corpus collected in the context of software help desk application as an example out-of-domain corpus.
</nextsent>
<nextsent>in cases where the out-of-domain corpus is closely related to the domain at hand, more semantically driven generalization might be more suitable.
</nextsent>
<nextsent>3.6 adapting the switchboard language model.
</nextsent>
<nextsent>we investigate the performance of large vocabulary conversational speech recognition system when applied to specific domain such as match.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O922">
<title id=" N04-1005.xml">balancing data driven and rule based approaches in the context of a multimodal conversational system </title>
<section> bootstrapping corpora for language.  </section>
<citcontext>
<prevsection>
<prevsent>an ltag consists of set of elementary trees (supertags) (bangalore and joshi, 1999) <papid> J99-2004 </papid>each associated with lexical item.</prevsent>
<prevsent>the set of sentences generated by an ltag can be obtained by combining supertags using substitution and adjunction operations.</prevsent>
</prevsection>
<citsent citstr=" C02-2026 ">
in related work (rambow et al, 2002), <papid> C02-2026 </papid>it has been shown that for restricted version of ltag, the combinations of set of supertags can be represented as an fsm.</citsent>
<aftsection>
<nextsent>this fsm compactly encodes the set of sentences generated by an ltag grammar.
</nextsent>
<nextsent>we derive domain-specific corpus by construct inga lexicon consisting of pairings of words with their supertags that are relevant to that domain.
</nextsent>
<nextsent>we then compile the grammar to build an fsm of all sentences upto given length.
</nextsent>
<nextsent>we sample this fsm and build language model as discussed in section 3.3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O923">
<title id=" N04-1005.xml">balancing data driven and rule based approaches in the context of a multimodal conversational system </title>
<section> robust multimodal understanding.  </section>
<citcontext>
<prevsection>
<prevsent>) for  token multimodal utterance (   ) by maximizing the posterior probability as shown in equation 7.
</prevsent>
<prevsent>  ()+,   * ( 2     8 (7)we view the problem of identifying and extracting arguments from multimodal input as problem of associating each token of the input with specific tag that encodes the label of the argument and the span of the argument.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
these tags are drawn from tagset which is constructed by extending each argument label by three additional symbols   #  , following (ramshaw and marcus, 1995).<papid> W95-0107 </papid></citsent>
<aftsection>
<nextsent>these symbols correspond to cases when atoken is inside (  ) an argument span, outside ( # ) an argument span or at the boundary of two argument spans ( ) (see table 1).given this encoding, the problem of extracting the arguments is search for the most likely sequence of tags (
</nextsent>
<nextsent>) given the input multimodal utterance   as shownin equation (8).
</nextsent>
<nextsent>we approximate the posterior probability * ( 2    8 using independence assumptions as user cheap thai upper west side utterance argument  price  cheap  /price   cuisine  annotation thai  /cuisine   place  upper west side  /place  iob cheap price   thai cuisine   encoding upper place   west place   side place   table 1: the  i,o,b 5 encoding for argument extraction.
</nextsent>
<nextsent>shown in equation (9).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O924">
<title id=" N04-1005.xml">balancing data driven and rule based approaches in the context of a multimodal conversational system </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>two possible reasons for this are:first, argument extraction requires more non-local information that is available in the pattern-matching based approach while the classification-based approach relies on local information and is more conducive for identifying the simple predicates in match.
</prevsent>
<prevsent>second, the pattern matching approach uses the entire grammar as model for matching while the classification approach is trained on the training data which is significantly smaller when compared to the number of examples encoded in the grammar.
</prevsent>
</prevsection>
<citsent citstr=" P93-1008 ">
although we are not aware of any attempts to address the issue of robust understanding in the context of multimodal systems, this issue has been of great interest in the context of speech-only conversational systems (dowd ing et al, 1993; <papid> P93-1008 </papid>seneff, 1992; <papid> H92-1060 </papid>allen et al, 2000; lavie,1996).</citsent>
<aftsection>
<nextsent>the output of the recognizer in these systems usually is parsed using handcrafted grammar that assignsa meaning representation suited for the downstream dialog component.
</nextsent>
<nextsent>the coverage problems of the grammar and parsing of extra-grammatical utterances is typically addressed by retrieving fragments from the parse chart and incorporating operations that combine fragments to derive meaning of the recognized utterance.
</nextsent>
<nextsent>we have presented an approach that achieves robust multimodal utterance understanding using the edit-distance automaton in finite-state-based interpreter without the need for combining fragments from parser.the issue of combining rule-based and data-driven approaches has received less attention, with the exception of few (wang et al, 2000; rayner and hockey, 2003; <papid> E03-1078 </papid>wang and acero, 2003).</nextsent>
<nextsent>in recent paper (rayner and hockey, 2003), <papid> E03-1078 </papid>the authors address this issue by employing decision-list-based speech understanding system as means of progressing from rule-based models to data-driven models when data becomes available.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O925">
<title id=" N04-1005.xml">balancing data driven and rule based approaches in the context of a multimodal conversational system </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>two possible reasons for this are:first, argument extraction requires more non-local information that is available in the pattern-matching based approach while the classification-based approach relies on local information and is more conducive for identifying the simple predicates in match.
</prevsent>
<prevsent>second, the pattern matching approach uses the entire grammar as model for matching while the classification approach is trained on the training data which is significantly smaller when compared to the number of examples encoded in the grammar.
</prevsent>
</prevsection>
<citsent citstr=" H92-1060 ">
although we are not aware of any attempts to address the issue of robust understanding in the context of multimodal systems, this issue has been of great interest in the context of speech-only conversational systems (dowd ing et al, 1993; <papid> P93-1008 </papid>seneff, 1992; <papid> H92-1060 </papid>allen et al, 2000; lavie,1996).</citsent>
<aftsection>
<nextsent>the output of the recognizer in these systems usually is parsed using handcrafted grammar that assignsa meaning representation suited for the downstream dialog component.
</nextsent>
<nextsent>the coverage problems of the grammar and parsing of extra-grammatical utterances is typically addressed by retrieving fragments from the parse chart and incorporating operations that combine fragments to derive meaning of the recognized utterance.
</nextsent>
<nextsent>we have presented an approach that achieves robust multimodal utterance understanding using the edit-distance automaton in finite-state-based interpreter without the need for combining fragments from parser.the issue of combining rule-based and data-driven approaches has received less attention, with the exception of few (wang et al, 2000; rayner and hockey, 2003; <papid> E03-1078 </papid>wang and acero, 2003).</nextsent>
<nextsent>in recent paper (rayner and hockey, 2003), <papid> E03-1078 </papid>the authors address this issue by employing decision-list-based speech understanding system as means of progressing from rule-based models to data-driven models when data becomes available.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O926">
<title id=" N04-1005.xml">balancing data driven and rule based approaches in the context of a multimodal conversational system </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the output of the recognizer in these systems usually is parsed using handcrafted grammar that assignsa meaning representation suited for the downstream dialog component.
</prevsent>
<prevsent>the coverage problems of the grammar and parsing of extra-grammatical utterances is typically addressed by retrieving fragments from the parse chart and incorporating operations that combine fragments to derive meaning of the recognized utterance.
</prevsent>
</prevsection>
<citsent citstr=" E03-1078 ">
we have presented an approach that achieves robust multimodal utterance understanding using the edit-distance automaton in finite-state-based interpreter without the need for combining fragments from parser.the issue of combining rule-based and data-driven approaches has received less attention, with the exception of few (wang et al, 2000; rayner and hockey, 2003; <papid> E03-1078 </papid>wang and acero, 2003).</citsent>
<aftsection>
<nextsent>in recent paper (rayner and hockey, 2003), <papid> E03-1078 </papid>the authors address this issue by employing decision-list-based speech understanding system as means of progressing from rule-based models to data-driven models when data becomes available.</nextsent>
<nextsent>the decision-list-based understanding system also provides amethod for robust understanding.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O928">
<title id=" N01-1029.xml">a structured language model based on context sensitive probabilistic left corner parsing </title>
<section> structured language modeling.  </section>
<citcontext>
<prevsection>
<prevsent>it scored somewhat lower in perplexity before reestimation (presumably by avoiding search errors), but remained roughly at the same level after full inside-outside reestimation (van aelten and hogenhout, 2000).
</prevsent>
<prevsent>an obvious weakness of the chelba-jelinek slm is the bottom-up behavior of the parser: it creates isolated constituents and only afterwards is it able tocheck whether constituent fits into higher structure.
</prevsent>
</prevsection>
<citsent citstr=" J95-2002 ">
van uytsel (2000) developed top-down alternative along similar lines but based on lexicalized and context-sensitive dp version of an efficient earley parser (stolcke, 1995; <papid> J95-2002 </papid>jelinek and lafferty, 1991).<papid> J91-3004 </papid></citsent>
<aftsection>
<nextsent>the earley-based slm performed worse than the chelba-jelinek slm, mostly due to the fact that the rule production probabilities cannot be conditioned on the underlying lexical information, thus producing lot of wrong parses.
</nextsent>
<nextsent>the weaknesses of our earley slm have led us to consider probabilistic left-corner grammar (plcg) parsing (manning and carpenter, 1997),which follows mixed bottom-up and top-down approach.
</nextsent>
<nextsent>its potential to enhance parsing efficiency has been recognized by roark and johnson (2000), who simulated left-corner parser with top-down best-first parser applying left-corner-transformed pcfg grammar.
</nextsent>
<nextsent>for the language model described in this paper, however, we implemented dp version of native left-corner parser using left-cornertreebank grammar (containing projection rules instead of production rules).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O929">
<title id=" N01-1029.xml">a structured language model based on context sensitive probabilistic left corner parsing </title>
<section> structured language modeling.  </section>
<citcontext>
<prevsection>
<prevsent>it scored somewhat lower in perplexity before reestimation (presumably by avoiding search errors), but remained roughly at the same level after full inside-outside reestimation (van aelten and hogenhout, 2000).
</prevsent>
<prevsent>an obvious weakness of the chelba-jelinek slm is the bottom-up behavior of the parser: it creates isolated constituents and only afterwards is it able tocheck whether constituent fits into higher structure.
</prevsent>
</prevsection>
<citsent citstr=" J91-3004 ">
van uytsel (2000) developed top-down alternative along similar lines but based on lexicalized and context-sensitive dp version of an efficient earley parser (stolcke, 1995; <papid> J95-2002 </papid>jelinek and lafferty, 1991).<papid> J91-3004 </papid></citsent>
<aftsection>
<nextsent>the earley-based slm performed worse than the chelba-jelinek slm, mostly due to the fact that the rule production probabilities cannot be conditioned on the underlying lexical information, thus producing lot of wrong parses.
</nextsent>
<nextsent>the weaknesses of our earley slm have led us to consider probabilistic left-corner grammar (plcg) parsing (manning and carpenter, 1997),which follows mixed bottom-up and top-down approach.
</nextsent>
<nextsent>its potential to enhance parsing efficiency has been recognized by roark and johnson (2000), who simulated left-corner parser with top-down best-first parser applying left-corner-transformed pcfg grammar.
</nextsent>
<nextsent>for the language model described in this paper, however, we implemented dp version of native left-corner parser using left-cornertreebank grammar (containing projection rules instead of production rules).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O930">
<title id=" N01-1029.xml">a structured language model based on context sensitive probabilistic left corner parsing </title>
<section> extending the plcg framework.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, in the penn treebank an np in subject position produces personal pronoun in 13.7% of the cases, while in object position it only does so in 2.1% of the cases (manning and carpenter, 1997).furthermore, findings from corpus-based linguistic studies and developments in functional grammar indicate that the lexical realization of context, besides its syntactic analysis, strongly influences patterns of syntactic preference.
</prevsent>
<prevsent>todays best automatic parsers are made substantially more efficient and accurate by applying lexicalized grammar (manning and schutze, 1999).
</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
3.2.1 context-sensitive and lexicalized state sin our work we did not attempt to find semantic generalizations (such as casting verb form to its infini tive form or finding semantic attributes); our simple (but probably suboptimal) approach, borrowed from (magerman, 1994; collins, 1996; <papid> P96-1025 </papid>chelba, 2000), is to percolate words upward in the parse tree in the form in which they appear in the sentence.</citsent>
<aftsection>
<nextsent>in our experiments, we opted to hard code the head positions as part of the projection rules.3 the nodes of the resulting partial parse trees thus are annotated with category label (the cat feature) and lexical label (the word feature).
</nextsent>
<nextsent>the notation (1) of state is now replaced with = (g, l1, l2; z/z ? x/x ? j?;?, ?)
</nextsent>
<nextsent>(13) where is the word of the mother (possibly empty), is the word of the first daughter (not empty), and the extended context contains ? = cat of goal state qg; ? l1 = (cat, word) of the state q1 projecting qg; ? l2 = (cat, word) of the state q2 projecting goal state dominating q1.
</nextsent>
<nextsent>if the grammar only contains unary and binary rules, l1 and l2 correspond with chelbas concept of exposed heads ? which was in fact the idea behind the definition above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O931">
<title id=" N01-1029.xml">a structured language model based on context sensitive probabilistic left corner parsing </title>
<section> empirical evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we have trained two sets of models.
</prevsent>
<prevsent>the first set was trained on sections 020 of the penn treebank (ptb) (marcus et al, 1995) using sections 2122 for development decisions and tested on sections 2324.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the second set was trained on the bllip wsj corpus (bwc), which is machine-parsed (charniak, 2000) <papid> A00-2018 </papid>version of (a selection of) the acl/dci corpus, very similar to the selection made for the wsj0/1 csr corpus.</citsent>
<aftsection>
<nextsent>as the training set, we used the bwc minus the wsj0/1 dfiles?
</nextsent>
<nextsent>andefiles?
</nextsent>
<nextsent>intended for csr development and evaluation testing.the ptb devset was used for fixing sub model parameterizations and software debugging, while perplexities are measured on the ptb testset.
</nextsent>
<nextsent>the bwc tra inset was used in rescoring n-best lists in order to assess the models?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O932">
<title id=" N06-1011.xml">named entity transliteration and discovery from multilingual comparable corpora </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>83
</prevsent>
<prevsent>there has been other work to automatically discover ne with minimal supervision.
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
both (cucerzan and yarowsky, 1999) <papid> W99-0612 </papid>and (collins and singer, 1999)<papid> W99-0613 </papid>present algorithms to obtain nes from untagged cor pora.</citsent>
<aftsection>
<nextsent>however, they focus on the classification stageof already segmented entities, and make use of contextual and morphological clues that require knowledge of the language beyond the level we want to assume with respect to the target language.the use of similarity of time distributions for information extraction, in general, and ne extraction, in particular, is not new.
</nextsent>
<nextsent>(hetland, 2004) surveys recent methods for scoring time sequences for similarity.
</nextsent>
<nextsent>(shinyama and sekine, 2004) <papid> C04-1122 </papid>used the idea to discover nes, but in single language, english, across two news sources.</nextsent>
<nextsent>a large amount of previous work exists on transliteration models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O933">
<title id=" N06-1011.xml">named entity transliteration and discovery from multilingual comparable corpora </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>83
</prevsent>
<prevsent>there has been other work to automatically discover ne with minimal supervision.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
both (cucerzan and yarowsky, 1999) <papid> W99-0612 </papid>and (collins and singer, 1999)<papid> W99-0613 </papid>present algorithms to obtain nes from untagged cor pora.</citsent>
<aftsection>
<nextsent>however, they focus on the classification stageof already segmented entities, and make use of contextual and morphological clues that require knowledge of the language beyond the level we want to assume with respect to the target language.the use of similarity of time distributions for information extraction, in general, and ne extraction, in particular, is not new.
</nextsent>
<nextsent>(hetland, 2004) surveys recent methods for scoring time sequences for similarity.
</nextsent>
<nextsent>(shinyama and sekine, 2004) <papid> C04-1122 </papid>used the idea to discover nes, but in single language, english, across two news sources.</nextsent>
<nextsent>a large amount of previous work exists on transliteration models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O934">
<title id=" N06-1011.xml">named entity transliteration and discovery from multilingual comparable corpora </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>however, they focus on the classification stageof already segmented entities, and make use of contextual and morphological clues that require knowledge of the language beyond the level we want to assume with respect to the target language.the use of similarity of time distributions for information extraction, in general, and ne extraction, in particular, is not new.
</prevsent>
<prevsent>(hetland, 2004) surveys recent methods for scoring time sequences for similarity.
</prevsent>
</prevsection>
<citsent citstr=" C04-1122 ">
(shinyama and sekine, 2004) <papid> C04-1122 </papid>used the idea to discover nes, but in single language, english, across two news sources.</citsent>
<aftsection>
<nextsent>a large amount of previous work exists on transliteration models.
</nextsent>
<nextsent>most are generative and consider the task of producing an appropriate transliteration forgiven word, and thus require considerable knowledge of the languages.
</nextsent>
<nextsent>for example, (abduljaleel and larkey, 2003; jung et al, 2000) <papid> C00-1056 </papid>train english-arabic and english-korean generative transliteration models, respectively.</nextsent>
<nextsent>(knight andgraehl, 1997) <papid> P97-1017 </papid>build generative model for backward transliteration from japanese to english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O935">
<title id=" N06-1011.xml">named entity transliteration and discovery from multilingual comparable corpora </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>a large amount of previous work exists on transliteration models.
</prevsent>
<prevsent>most are generative and consider the task of producing an appropriate transliteration forgiven word, and thus require considerable knowledge of the languages.
</prevsent>
</prevsection>
<citsent citstr=" C00-1056 ">
for example, (abduljaleel and larkey, 2003; jung et al, 2000) <papid> C00-1056 </papid>train english-arabic and english-korean generative transliteration models, respectively.</citsent>
<aftsection>
<nextsent>(knight andgraehl, 1997) <papid> P97-1017 </papid>build generative model for backward transliteration from japanese to english.</nextsent>
<nextsent>while generative models are often robust, they tend to make independence assumptions that do not hold in data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O936">
<title id=" N06-1011.xml">named entity transliteration and discovery from multilingual comparable corpora </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>most are generative and consider the task of producing an appropriate transliteration forgiven word, and thus require considerable knowledge of the languages.
</prevsent>
<prevsent>for example, (abduljaleel and larkey, 2003; jung et al, 2000) <papid> C00-1056 </papid>train english-arabic and english-korean generative transliteration models, respectively.</prevsent>
</prevsection>
<citsent citstr=" P97-1017 ">
(knight andgraehl, 1997) <papid> P97-1017 </papid>build generative model for backward transliteration from japanese to english.</citsent>
<aftsection>
<nextsent>while generative models are often robust, they tend to make independence assumptions that do not hold in data.
</nextsent>
<nextsent>the discriminative learning framework argued for in (roth, 1998; roth, 1999) as an alternative to generative models is now used widely in nlp, even in the context of word alignment (taskar et al, 2005; moore, 2005).<papid> H05-1011 </papid></nextsent>
<nextsent>we make use of it here too, to learn discriminative transliteration model that requires little knowledge of the target language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O937">
<title id=" N06-1011.xml">named entity transliteration and discovery from multilingual comparable corpora </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>(knight andgraehl, 1997) <papid> P97-1017 </papid>build generative model for backward transliteration from japanese to english.</prevsent>
<prevsent>while generative models are often robust, they tend to make independence assumptions that do not hold in data.</prevsent>
</prevsection>
<citsent citstr=" H05-1011 ">
the discriminative learning framework argued for in (roth, 1998; roth, 1999) as an alternative to generative models is now used widely in nlp, even in the context of word alignment (taskar et al, 2005; moore, 2005).<papid> H05-1011 </papid></citsent>
<aftsection>
<nextsent>we make use of it here too, to learn discriminative transliteration model that requires little knowledge of the target language.
</nextsent>
<nextsent>discovery in essence, the algorithm we present uses temporal alignment as supervision signal to iteratively train discriminative transliteration model, which can be viewed as distance metric between and english ne and potential transliteration.
</nextsent>
<nextsent>on each iteration, it selects set of transliteration candidates for each ne according to the current model (line 6).
</nextsent>
<nextsent>it then uses temporal alignment (with thresholding) to select the best transliteration candidate for the next round of training (lines 8, and 9).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O938">
<title id=" N01-1003.xml">spot a trainable sentence planner </title>
<section> the sentence plan generator.  </section>
<citcontext>
<prevsection>
<prevsent>this transforms predicative use of an adjective into an adnominal construction.
</prevsent>
<prevsent>  period.
</prevsent>
</prevsection>
<citsent citstr=" A92-1006 ">
joins two complete clauses with period.these operations are not domain-specific and are similar to those of previous aggregation components (rambow and korelsky, 1992; <papid> A92-1006 </papid>shaw, 1998; <papid> W98-1415 </papid>danlos, 2000), although the various merge operations are, to our knowledge, novel in this form.</citsent>
<aftsection>
<nextsent>the result of applying the operations is sentence plan tree (or sp-tree for short), which is binary tree with leaves labeled by all the elementary speech acts rule sample first argument sample second argument result merge you are leaving from newark.
</nextsent>
<nextsent>you are leaving at 5 you are leaving at 5 from newark merge-general what time would you like to leave?
</nextsent>
<nextsent>you are leaving from newark.
</nextsent>
<nextsent>what time would you like to leave from newark?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O939">
<title id=" N01-1003.xml">spot a trainable sentence planner </title>
<section> the sentence plan generator.  </section>
<citcontext>
<prevsection>
<prevsent>this transforms predicative use of an adjective into an adnominal construction.
</prevsent>
<prevsent>  period.
</prevsent>
</prevsection>
<citsent citstr=" W98-1415 ">
joins two complete clauses with period.these operations are not domain-specific and are similar to those of previous aggregation components (rambow and korelsky, 1992; <papid> A92-1006 </papid>shaw, 1998; <papid> W98-1415 </papid>danlos, 2000), although the various merge operations are, to our knowledge, novel in this form.</citsent>
<aftsection>
<nextsent>the result of applying the operations is sentence plan tree (or sp-tree for short), which is binary tree with leaves labeled by all the elementary speech acts rule sample first argument sample second argument result merge you are leaving from newark.
</nextsent>
<nextsent>you are leaving at 5 you are leaving at 5 from newark merge-general what time would you like to leave?
</nextsent>
<nextsent>you are leaving from newark.
</nextsent>
<nextsent>what time would you like to leave from newark?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O940">
<title id=" N01-1003.xml">spot a trainable sentence planner </title>
<section> the sentence plan generator.  </section>
<citcontext>
<prevsection>
<prevsent>this dsynts can be sent to realpro, which returns sentence (or several sentences, if the dsynts contains period nodes).
</prevsent>
<prevsent>the spg is designed in such way that if dsynts is associated with the root node, it is valid structure which can be realized.
</prevsent>
</prevsection>
<citsent citstr=" P98-1118 ">
2 1 3impconfirm(month) request(time) softmergegeneral impconfirm(destcity) impconfirm(origcity) impconfirm(day) soft merge softmergegeneral softmergegeneral figure 5: alternative 0 sentence plan tree figure 2 shows some of the realizations of alternative sentence plans generated by our spg for utterance sys3the sp-tree is inspired by (lavoie and rambow, 1998).<papid> P98-1118 </papid></citsent>
<aftsection>
<nextsent>the representations used by danlos (2000), gardent and webber (1998), orstone and doran (1997) <papid> P97-1026 </papid>are similar, but do not (always) explicitly represent the clause combining operations as labeled nodes.</nextsent>
<nextsent>21 3 softmergegeneral impconfirm(day) period softmergegeneral impconfirm(month) impconfirm(origcity) impconfirm(destcity) request(time)softmergegeneral figure 6: alternative 5 sentence plan tree 2 1 softmergegeneral impconfirm(origcity) request(time) impconfirm(destcity) relative clause impconfirm(day) period period impconfirm(month) figure 7: alternative 8 sentence plan tree tem5 in dialog d1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O941">
<title id=" N01-1003.xml">spot a trainable sentence planner </title>
<section> the sentence plan generator.  </section>
<citcontext>
<prevsection>
<prevsent>the spg is designed in such way that if dsynts is associated with the root node, it is valid structure which can be realized.
</prevsent>
<prevsent>2 1 3impconfirm(month) request(time) softmergegeneral impconfirm(destcity) impconfirm(origcity) impconfirm(day) soft merge softmergegeneral softmergegeneral figure 5: alternative 0 sentence plan tree figure 2 shows some of the realizations of alternative sentence plans generated by our spg for utterance sys3the sp-tree is inspired by (lavoie and rambow, 1998).<papid> P98-1118 </papid></prevsent>
</prevsection>
<citsent citstr=" P97-1026 ">
the representations used by danlos (2000), gardent and webber (1998), orstone and doran (1997) <papid> P97-1026 </papid>are similar, but do not (always) explicitly represent the clause combining operations as labeled nodes.</citsent>
<aftsection>
<nextsent>21 3 softmergegeneral impconfirm(day) period softmergegeneral impconfirm(month) impconfirm(origcity) impconfirm(destcity) request(time)softmergegeneral figure 6: alternative 5 sentence plan tree 2 1 softmergegeneral impconfirm(origcity) request(time) impconfirm(destcity) relative clause impconfirm(day) period period impconfirm(month) figure 7: alternative 8 sentence plan tree tem5 in dialog d1.
</nextsent>
<nextsent>sp-trees for alternatives 0, 5 and 8 are in figures 5, 6 and 7.
</nextsent>
<nextsent>for example, consider the sp-tree in figure 7.
</nextsent>
<nextsent>node soft-merge-general merges an implicit-confirmations of the destination city and the origin city.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O943">
<title id=" N01-1003.xml">spot a trainable sentence planner </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the template outputs are typically concatenated to produce turn realizing all the communicative goals.
</prevsent>
<prevsent>it is hard to achieve high quality output by concatenating the template-based output for individual communicative goals, and templates are difficult to develop and maintain for mixed-initiative dialog system.
</prevsent>
</prevsection>
<citsent citstr=" W00-0306 ">
for these reasons,oh and rudnicky (2000) <papid> W00-0306 </papid>use -gram models and ratnaparkhi (2000), <papid> A00-2026 </papid>maximum entropy to choose templates, using hand-written rules to score different candidates.but syntactically simplistic approaches may have quality problems, and more importantly, these approaches only deal with inform speech acts.</citsent>
<aftsection>
<nextsent>and crucially, these approaches suffer from the need for training data.
</nextsent>
<nextsent>in general there may be no corpus available for new application area, or if there is corpus available, it is atranscript of human-human dialogs.
</nextsent>
<nextsent>human-human di alogs, however, may not provide very good model of sentence planning strategies for computational system because the sentence planner must plan communicative goals such as implicit confirmation which are needed to prevent and correct errors in automatic speech recognition but which are rare in human-human dialog.other related work deals with discourse-related aspects of sentence planning such as cue word placement (moser and moore, 1995), <papid> P95-1018 </papid>clearly crucial task whose integration into our approach we leave to future work.mellish et al (1998) <papid> W98-1411 </papid>investigate the problem of determining discourse tree for set of elementary speech acts which are partially constrained by rhetorical rela tions.</nextsent>
<nextsent>using hand-crafted evaluation metrics, they show that genetic algorithm achieves good results in finding discourse trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O944">
<title id=" N01-1003.xml">spot a trainable sentence planner </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the template outputs are typically concatenated to produce turn realizing all the communicative goals.
</prevsent>
<prevsent>it is hard to achieve high quality output by concatenating the template-based output for individual communicative goals, and templates are difficult to develop and maintain for mixed-initiative dialog system.
</prevsent>
</prevsection>
<citsent citstr=" A00-2026 ">
for these reasons,oh and rudnicky (2000) <papid> W00-0306 </papid>use -gram models and ratnaparkhi (2000), <papid> A00-2026 </papid>maximum entropy to choose templates, using hand-written rules to score different candidates.but syntactically simplistic approaches may have quality problems, and more importantly, these approaches only deal with inform speech acts.</citsent>
<aftsection>
<nextsent>and crucially, these approaches suffer from the need for training data.
</nextsent>
<nextsent>in general there may be no corpus available for new application area, or if there is corpus available, it is atranscript of human-human dialogs.
</nextsent>
<nextsent>human-human di alogs, however, may not provide very good model of sentence planning strategies for computational system because the sentence planner must plan communicative goals such as implicit confirmation which are needed to prevent and correct errors in automatic speech recognition but which are rare in human-human dialog.other related work deals with discourse-related aspects of sentence planning such as cue word placement (moser and moore, 1995), <papid> P95-1018 </papid>clearly crucial task whose integration into our approach we leave to future work.mellish et al (1998) <papid> W98-1411 </papid>investigate the problem of determining discourse tree for set of elementary speech acts which are partially constrained by rhetorical rela tions.</nextsent>
<nextsent>using hand-crafted evaluation metrics, they show that genetic algorithm achieves good results in finding discourse trees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O945">
<title id=" N01-1003.xml">spot a trainable sentence planner </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>and crucially, these approaches suffer from the need for training data.
</prevsent>
<prevsent>in general there may be no corpus available for new application area, or if there is corpus available, it is atranscript of human-human dialogs.
</prevsent>
</prevsection>
<citsent citstr=" P95-1018 ">
human-human di alogs, however, may not provide very good model of sentence planning strategies for computational system because the sentence planner must plan communicative goals such as implicit confirmation which are needed to prevent and correct errors in automatic speech recognition but which are rare in human-human dialog.other related work deals with discourse-related aspects of sentence planning such as cue word placement (moser and moore, 1995), <papid> P95-1018 </papid>clearly crucial task whose integration into our approach we leave to future work.mellish et al (1998) <papid> W98-1411 </papid>investigate the problem of determining discourse tree for set of elementary speech acts which are partially constrained by rhetorical rela tions.</citsent>
<aftsection>
<nextsent>using hand-crafted evaluation metrics, they show that genetic algorithm achieves good results in finding discourse trees.
</nextsent>
<nextsent>however, they do not address clause combining, and we do not use hand-crafted metrics.
</nextsent>
<nextsent>we have presented spot, trainable sentence planner.
</nextsent>
<nextsent>spot re-conceptualizes the sentence planning task as consisting of two distinct phases: (1) very simple sentence plan generator spg that generates multiple candidate sentence plans using weighted randomization; and (2) sentence plan ranker spr that can be trained from examples via human feedback, whose job is to rank the candidate sentence plans and select the highest ranked plan.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O946">
<title id=" N01-1003.xml">spot a trainable sentence planner </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>and crucially, these approaches suffer from the need for training data.
</prevsent>
<prevsent>in general there may be no corpus available for new application area, or if there is corpus available, it is atranscript of human-human dialogs.
</prevsent>
</prevsection>
<citsent citstr=" W98-1411 ">
human-human di alogs, however, may not provide very good model of sentence planning strategies for computational system because the sentence planner must plan communicative goals such as implicit confirmation which are needed to prevent and correct errors in automatic speech recognition but which are rare in human-human dialog.other related work deals with discourse-related aspects of sentence planning such as cue word placement (moser and moore, 1995), <papid> P95-1018 </papid>clearly crucial task whose integration into our approach we leave to future work.mellish et al (1998) <papid> W98-1411 </papid>investigate the problem of determining discourse tree for set of elementary speech acts which are partially constrained by rhetorical rela tions.</citsent>
<aftsection>
<nextsent>using hand-crafted evaluation metrics, they show that genetic algorithm achieves good results in finding discourse trees.
</nextsent>
<nextsent>however, they do not address clause combining, and we do not use hand-crafted metrics.
</nextsent>
<nextsent>we have presented spot, trainable sentence planner.
</nextsent>
<nextsent>spot re-conceptualizes the sentence planning task as consisting of two distinct phases: (1) very simple sentence plan generator spg that generates multiple candidate sentence plans using weighted randomization; and (2) sentence plan ranker spr that can be trained from examples via human feedback, whose job is to rank the candidate sentence plans and select the highest ranked plan.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O947">
<title id=" N01-1021.xml">a probabilistic earley parser as a psycho linguistic model </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in human sentence processing, cognitive load can bede ned many ways.
</prevsent>
<prevsent>this report considers de ni tion of cognitive load in terms of the total probability of structural options that have been discon rmed at some point in sentence: the surprisal of word i given its pre w 0...i1on phrase-structural language model.
</prevsent>
</prevsection>
<citsent citstr=" J95-2002 ">
these loads can be eciently calculated using probabilistic earley parser (stolcke, 1995) <papid> J95-2002 </papid>which is interpreted as generating predictions about reading time on word-by-word basis.</citsent>
<aftsection>
<nextsent>under grammatical assumptions supported by corpus frequency data, the operation of stolckes probabilistic earley parser correctly predicts processing phenomena associated with garden path structural ambiguity and with the subject/object relative asymmetry.
</nextsent>
<nextsent>what is the relation between persons knowledge of grammar and that same persons application of that knowledge in perceiving syntactic structure?
</nextsent>
<nextsent>the answer to be proposed here observes three principles.
</nextsent>
<nextsent>principle 1 the relation between the parser and grammar is one of strong competence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O948">
<title id=" N01-1021.xml">a probabilistic earley parser as a psycho linguistic model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>probability of each possible outcome for n can be estimated using that outcomes relative frequency in sample.traditional language models used for speech are gram models, in which ? 1 words of history serveas the basis for predicting the nth word.
</prevsent>
<prevsent>such models do not have any notion of hierarchical syntactic structure, except as might be visible through an word window.
</prevsent>
</prevsection>
<citsent citstr=" P98-1035 ">
aware that the n-gram obscures many linguistically-signi cant distinctions (chomsky, 1956, section 2.3), many speech researchers (jelinekand laerty, 1991) sought to incorporate hierarchical phrase structure into language modeling (see (stolcke, 1997)) although it was not until the late 1990s that such models were able to signi cantly improve on 3-grams (chelba and jelinek, 1998).<papid> P98-1035 </papid></citsent>
<aftsection>
<nextsent>stolckes probabilistic earley parser is one way to use hierarchical phrase structure in language model.
</nextsent>
<nextsent>the grammar it parses is probabilistic context-free phrase structure grammar (pcfg), e.g. 1:0 ! np vp 0:5 np ! det 0:5 np ! np vp ...
</nextsent>
<nextsent>... see (charniak, 1993, chapter 5) such grammar denes probabilistic language in terms of stochastic process that rewrites strings of grammar symbols according to the probabilities on the rules.
</nextsent>
<nextsent>then each sentence in the language of the grammar has probability equal to the product of the probabilities of all the rules used to generate it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O954">
<title id=" N01-1021.xml">a probabilistic earley parser as a psycho linguistic model </title>
<section> plausibility of probabilistic.  </section>
<citcontext>
<prevsection>
<prevsent>if phrase level contingent frequency constraints are necessary, can they subsume the eects of other constraints (e.g. locality) ?
</prevsent>
<prevsent>(gibson and pearl mutter, 1998, page 13)equally, formal work in linguistics has demonstrated the inadequacy of context-free grammars as an appropriate model for natural language in the general case (shieber, 1985).
</prevsent>
</prevsection>
<citsent citstr=" P98-2157 ">
to address this criticism, the same pre probabilities could be computing using tree-adjoining grammars (nederhof et al, 1998).<papid> P98-2157 </papid></citsent>
<aftsection>
<nextsent>with context-free grammars serving as the implicit backdrop for much work in human sentence processing, as well as linguistics2 simplicity seems as good guide as any in the selection of grammar formalism.
</nextsent>
<nextsent>6.1 celebrated example probabilistic context-free grammar (1) will help illustrate the way phrase-structured language model 2some important work in computational psycho linguistics (ford, 1989) assumes lexical-functional grammar where the c-structure rules are essentially context-free and have attached to them \strengths  which one might interpret as probabilities.
</nextsent>
<nextsent>could account for garden path structural ambiguity.
</nextsent>
<nextsent>grammar (1) generates the celebrated garden path sentence \the horse raced past the barn fell  (bever, 1970).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O955">
<title id=" N06-1023.xml">a fully lexicalized probabilistic model for japanese syntactic and case structure analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in english, syntactic case structure can be mostly derived from word order.
</prevsent>
<prevsent>for example, the left argument of the predicate is the subject, and the right argument of the predicate is the object in most cases.
</prevsent>
</prevsection>
<citsent citstr=" A00-2031 ">
blaheta and charniak proposed statistical method currently, national institute of information and communications technology, japan, dk@nict.go.jpcurrently, graduate school of informatics, kyoto university, kuro@i.kyoto-u.ac.jp for analyzing function tags in penn treebank, and achieved really high accuracy of 95.7% for syntactic roles, such as sbj (subject) and dtv (da tive) (blaheta and charniak, 2000).<papid> A00-2031 </papid></citsent>
<aftsection>
<nextsent>in recent years, there have been many studies on semantic structure analysis (semantic role labeling) based on propbank (kingsbury et al, 2002) and framenet (baker et al,1998).<papid> P98-1013 </papid></nextsent>
<nextsent>these studies classify syntactic roles into semantic ones such as agent, experiencer and instru ment.case structure analysis of japanese is very different from that of english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O957">
<title id=" N06-1023.xml">a fully lexicalized probabilistic model for japanese syntactic and case structure analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the left argument of the predicate is the subject, and the right argument of the predicate is the object in most cases.
</prevsent>
<prevsent>blaheta and charniak proposed statistical method currently, national institute of information and communications technology, japan, dk@nict.go.jpcurrently, graduate school of informatics, kyoto university, kuro@i.kyoto-u.ac.jp for analyzing function tags in penn treebank, and achieved really high accuracy of 95.7% for syntactic roles, such as sbj (subject) and dtv (da tive) (blaheta and charniak, 2000).<papid> A00-2031 </papid></prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
in recent years, there have been many studies on semantic structure analysis (semantic role labeling) based on propbank (kingsbury et al, 2002) and framenet (baker et al,1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>these studies classify syntactic roles into semantic ones such as agent, experiencer and instru ment.case structure analysis of japanese is very different from that of english.
</nextsent>
<nextsent>in japanese, postpositionsare used to mark cases.
</nextsent>
<nextsent>frequently used postposi tions are ga?, wo?
</nextsent>
<nextsent>and ni?, which usually mean nominative, accusative and dative.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O958">
<title id=" N06-1023.xml">a fully lexicalized probabilistic model for japanese syntactic and case structure analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we run such case structure analysis based on example-based case frames thatare constructed from huge raw corpus in an unsupervised manner.
</prevsent>
<prevsent>let us consider syntactic analysis, into which our method of case structure analysis is integrated.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
recently, many accurate statistical parsers have been proposed (e.g., (collins, 1999; charniak, 2000) <papid> A00-2018 </papid>for english, (uchimoto et al, 2000; kudo and matsumoto, 2002) <papid> W02-2016 </papid>for japanese).</citsent>
<aftsection>
<nextsent>since they somehow use lexical information in the tagged corpus, they are called lexicalized parsers?.
</nextsent>
<nextsent>on the other hand, un lexicalized parsers achieved an almost equivalent accuracy to such lexicalized parsers (klein and manning, 2003; <papid> P03-1054 </papid>kurohashi and nagao, 1994).<papid> J94-4001 </papid></nextsent>
<nextsent>accordingly, we can say that the state-of-the-art lexicalized parsers are mainly based on unlexical (grammatical) information due to the sparse data problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O959">
<title id=" N06-1023.xml">a fully lexicalized probabilistic model for japanese syntactic and case structure analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we run such case structure analysis based on example-based case frames thatare constructed from huge raw corpus in an unsupervised manner.
</prevsent>
<prevsent>let us consider syntactic analysis, into which our method of case structure analysis is integrated.
</prevsent>
</prevsection>
<citsent citstr=" W02-2016 ">
recently, many accurate statistical parsers have been proposed (e.g., (collins, 1999; charniak, 2000) <papid> A00-2018 </papid>for english, (uchimoto et al, 2000; kudo and matsumoto, 2002) <papid> W02-2016 </papid>for japanese).</citsent>
<aftsection>
<nextsent>since they somehow use lexical information in the tagged corpus, they are called lexicalized parsers?.
</nextsent>
<nextsent>on the other hand, un lexicalized parsers achieved an almost equivalent accuracy to such lexicalized parsers (klein and manning, 2003; <papid> P03-1054 </papid>kurohashi and nagao, 1994).<papid> J94-4001 </papid></nextsent>
<nextsent>accordingly, we can say that the state-of-the-art lexicalized parsers are mainly based on unlexical (grammatical) information due to the sparse data problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O960">
<title id=" N06-1023.xml">a fully lexicalized probabilistic model for japanese syntactic and case structure analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, many accurate statistical parsers have been proposed (e.g., (collins, 1999; charniak, 2000) <papid> A00-2018 </papid>for english, (uchimoto et al, 2000; kudo and matsumoto, 2002) <papid> W02-2016 </papid>for japanese).</prevsent>
<prevsent>since they somehow use lexical information in the tagged corpus, they are called lexicalized parsers?.</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
on the other hand, un lexicalized parsers achieved an almost equivalent accuracy to such lexicalized parsers (klein and manning, 2003; <papid> P03-1054 </papid>kurohashi and nagao, 1994).<papid> J94-4001 </papid></citsent>
<aftsection>
<nextsent>accordingly, we can say that the state-of-the-art lexicalized parsers are mainly based on unlexical (grammatical) information due to the sparse data problem.
</nextsent>
<nextsent>bikel also indicated that collins?
</nextsent>
<nextsent>parser can use bilexical dependencies only 1.49% of the time; the rest of the time, it backs off to condition one word on just phrasal and part-of-speech categories (bikel, 2004).<papid> J04-4004 </papid></nextsent>
<nextsent>this paper aims at exploiting much more lexical information, and proposes fully-lexicalized probabilistic model for japanese syntactic and case structure analysis.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O961">
<title id=" N06-1023.xml">a fully lexicalized probabilistic model for japanese syntactic and case structure analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, many accurate statistical parsers have been proposed (e.g., (collins, 1999; charniak, 2000) <papid> A00-2018 </papid>for english, (uchimoto et al, 2000; kudo and matsumoto, 2002) <papid> W02-2016 </papid>for japanese).</prevsent>
<prevsent>since they somehow use lexical information in the tagged corpus, they are called lexicalized parsers?.</prevsent>
</prevsection>
<citsent citstr=" J94-4001 ">
on the other hand, un lexicalized parsers achieved an almost equivalent accuracy to such lexicalized parsers (klein and manning, 2003; <papid> P03-1054 </papid>kurohashi and nagao, 1994).<papid> J94-4001 </papid></citsent>
<aftsection>
<nextsent>accordingly, we can say that the state-of-the-art lexicalized parsers are mainly based on unlexical (grammatical) information due to the sparse data problem.
</nextsent>
<nextsent>bikel also indicated that collins?
</nextsent>
<nextsent>parser can use bilexical dependencies only 1.49% of the time; the rest of the time, it backs off to condition one word on just phrasal and part-of-speech categories (bikel, 2004).<papid> J04-4004 </papid></nextsent>
<nextsent>this paper aims at exploiting much more lexical information, and proposes fully-lexicalized probabilistic model for japanese syntactic and case structure analysis.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O962">
<title id=" N06-1023.xml">a fully lexicalized probabilistic model for japanese syntactic and case structure analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>accordingly, we can say that the state-of-the-art lexicalized parsers are mainly based on unlexical (grammatical) information due to the sparse data problem.
</prevsent>
<prevsent>bikel also indicated that collins?
</prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
parser can use bilexical dependencies only 1.49% of the time; the rest of the time, it backs off to condition one word on just phrasal and part-of-speech categories (bikel, 2004).<papid> J04-4004 </papid></citsent>
<aftsection>
<nextsent>this paper aims at exploiting much more lexical information, and proposes fully-lexicalized probabilistic model for japanese syntactic and case structure analysis.
</nextsent>
<nextsent>lexical information is extracted notfrom small tagged corpus, but from huge raw corpus as case frames.
</nextsent>
<nextsent>this model performs case structure analysis by generative probabilistic model based on the case frames, and selects the syntactic structure that has the highest case structure probability.
</nextsent>
<nextsent>we employ automatically constructed case frames (kawahara and kurohashi, 2002) <papid> C02-1122 </papid>for our model oftable 1: case frame examples (examples are expressed only in english for space limitation.).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O963">
<title id=" N06-1023.xml">a fully lexicalized probabilistic model for japanese syntactic and case structure analysis </title>
<section> automatically constructed case frames.  </section>
<citcontext>
<prevsection>
<prevsent>lexical information is extracted notfrom small tagged corpus, but from huge raw corpus as case frames.
</prevsent>
<prevsent>this model performs case structure analysis by generative probabilistic model based on the case frames, and selects the syntactic structure that has the highest case structure probability.
</prevsent>
</prevsection>
<citsent citstr=" C02-1122 ">
we employ automatically constructed case frames (kawahara and kurohashi, 2002) <papid> C02-1122 </papid>for our model oftable 1: case frame examples (examples are expressed only in english for space limitation.).</citsent>
<aftsection>
<nextsent>cs examples ga  agent , group, party, ? ?
</nextsent>
<nextsent>youritsu (1) wo  agent , candidate, applicant (support) ni  agent , district, election, ? ?
</nextsent>
<nextsent>ga  agent  youritsu (2) wo  agent , member, minister, ? ?
</nextsent>
<nextsent>(support) ni  agent , candidate, successor ...
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O968">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these statistics suggest that without accounting for paraphrases, automatic evaluation measures may never reach the accuracy of human evaluation.
</prevsent>
<prevsent>as solution to this problem, researchers use multiple references to refine automatic evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
papineni et al (2002) <papid> P02-1040 </papid>shows that expanding the number of references reduces the gap between automatic and human evaluation.</citsent>
<aftsection>
<nextsent>however, very few human annotated sets are augmented with multiple references and those that are available are relatively1each pair included different translations of the same sentence, produced by two human translators.
</nextsent>
<nextsent>455 small in size.
</nextsent>
<nextsent>moreover, access to several references does not guarantee that the references will include the same words that appear in machine-generated sentences.in this paper, we explore the use of paraphrasing methods for refinement of automatic evaluation techniques.
</nextsent>
<nextsent>given reference sentence and amachine-generated sentence, we seek to find paraphrase of the reference sentence that is closer in wording to the machine output than the original reference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O969">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we select these candidates using existing lexico-semantic resources such as wordnet.
</prevsent>
<prevsent>next, the algorithm tests whether the candidate paraphrase is admissible in the context of the reference sentence.
</prevsent>
</prevsection>
<citsent citstr=" J02-2001 ">
since even synonyms cannot be substituted in any context (edmonds and hirst, 2002), <papid> J02-2001 </papid>this filtering step is necessary.</citsent>
<aftsection>
<nextsent>we predict whether word is appropriate in new context by analyzing its distributional properties in large body of text.
</nextsent>
<nextsent>finally, paraphrases that pass the filtering stage are used to rewrite the reference sentence.
</nextsent>
<nextsent>we apply our paraphrasing method in the context of machine translation evaluation.
</nextsent>
<nextsent>using this strategy, we generate new sentence for every pair ofhuman and machine translated sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O970">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wethen describe our paraphrasing algorithm and explain how it can be used in an automatic evaluationsetting.
</prevsent>
<prevsent>next, we present our experimental framework and data and conclude by presenting and discussing our results.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
automatic paraphrasing and entailment ourwork is closely related to research in automatic paraphrasing, in particular, to sentence level paraphrasing (barzilay and lee, 2003; <papid> N03-1003 </papid>pang et al, 2003; <papid> N03-1024 </papid>quirket al, 2004).<papid> W04-3219 </papid></citsent>
<aftsection>
<nextsent>most of these approaches learn paraphrases from parallel or comparable monolingual corpora.
</nextsent>
<nextsent>instances of such corpora include multiple english translations of the same source text written in foreign language, and different news articles about the same event.
</nextsent>
<nextsent>for example, pang etal.
</nextsent>
<nextsent>(2003) expand set of reference translations using syntactic alignment, and generate new reference sentences that could be used in automatic evaluation.our approach differs from traditional work on automatic paraphrasing in goal and methodology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O972">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wethen describe our paraphrasing algorithm and explain how it can be used in an automatic evaluationsetting.
</prevsent>
<prevsent>next, we present our experimental framework and data and conclude by presenting and discussing our results.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
automatic paraphrasing and entailment ourwork is closely related to research in automatic paraphrasing, in particular, to sentence level paraphrasing (barzilay and lee, 2003; <papid> N03-1003 </papid>pang et al, 2003; <papid> N03-1024 </papid>quirket al, 2004).<papid> W04-3219 </papid></citsent>
<aftsection>
<nextsent>most of these approaches learn paraphrases from parallel or comparable monolingual corpora.
</nextsent>
<nextsent>instances of such corpora include multiple english translations of the same source text written in foreign language, and different news articles about the same event.
</nextsent>
<nextsent>for example, pang etal.
</nextsent>
<nextsent>(2003) expand set of reference translations using syntactic alignment, and generate new reference sentences that could be used in automatic evaluation.our approach differs from traditional work on automatic paraphrasing in goal and methodology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O973">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wethen describe our paraphrasing algorithm and explain how it can be used in an automatic evaluationsetting.
</prevsent>
<prevsent>next, we present our experimental framework and data and conclude by presenting and discussing our results.
</prevsent>
</prevsection>
<citsent citstr=" W04-3219 ">
automatic paraphrasing and entailment ourwork is closely related to research in automatic paraphrasing, in particular, to sentence level paraphrasing (barzilay and lee, 2003; <papid> N03-1003 </papid>pang et al, 2003; <papid> N03-1024 </papid>quirket al, 2004).<papid> W04-3219 </papid></citsent>
<aftsection>
<nextsent>most of these approaches learn paraphrases from parallel or comparable monolingual corpora.
</nextsent>
<nextsent>instances of such corpora include multiple english translations of the same source text written in foreign language, and different news articles about the same event.
</nextsent>
<nextsent>for example, pang etal.
</nextsent>
<nextsent>(2003) expand set of reference translations using syntactic alignment, and generate new reference sentences that could be used in automatic evaluation.our approach differs from traditional work on automatic paraphrasing in goal and methodology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O974">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our work also has interesting connections with research on automatic textual entailment (dagan et al., 2005), where the goal is to determine whether given sentence can be inferred from text.
</prevsent>
<prevsent>while we are not assessing an inference relation between reference and system output, the two tasks face similar challenges.
</prevsent>
</prevsection>
<citsent citstr=" H05-1049 ">
methods for entailment 456recognition extensively relyon lexico-semantic resources (haghighi et al, 2005; <papid> H05-1049 </papid>harabagiu et al,2001), <papid> P01-1037 </papid>and we believe that our method for contextual substitution can be beneficial in that context.automatic evaluation measures variety of automatic evaluation methods have been recently proposed in the machine translation community (nist, 2002; melamed et al, 2003; <papid> N03-2021 </papid>papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>all these metrics compute n-gram overlap between reference and system output, but measure the overlap in different ways.
</nextsent>
<nextsent>our method for reference paraphrasing can be combined with any of these metrics.
</nextsent>
<nextsent>in this paper, we report experiments with bleu due to its wide use in the machine translation community.
</nextsent>
<nextsent>recently, researchers have explored additional knowledge sources that could enhance automaticevaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O976">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our work also has interesting connections with research on automatic textual entailment (dagan et al., 2005), where the goal is to determine whether given sentence can be inferred from text.
</prevsent>
<prevsent>while we are not assessing an inference relation between reference and system output, the two tasks face similar challenges.
</prevsent>
</prevsection>
<citsent citstr=" P01-1037 ">
methods for entailment 456recognition extensively relyon lexico-semantic resources (haghighi et al, 2005; <papid> H05-1049 </papid>harabagiu et al,2001), <papid> P01-1037 </papid>and we believe that our method for contextual substitution can be beneficial in that context.automatic evaluation measures variety of automatic evaluation methods have been recently proposed in the machine translation community (nist, 2002; melamed et al, 2003; <papid> N03-2021 </papid>papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>all these metrics compute n-gram overlap between reference and system output, but measure the overlap in different ways.
</nextsent>
<nextsent>our method for reference paraphrasing can be combined with any of these metrics.
</nextsent>
<nextsent>in this paper, we report experiments with bleu due to its wide use in the machine translation community.
</nextsent>
<nextsent>recently, researchers have explored additional knowledge sources that could enhance automaticevaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O977">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our work also has interesting connections with research on automatic textual entailment (dagan et al., 2005), where the goal is to determine whether given sentence can be inferred from text.
</prevsent>
<prevsent>while we are not assessing an inference relation between reference and system output, the two tasks face similar challenges.
</prevsent>
</prevsection>
<citsent citstr=" N03-2021 ">
methods for entailment 456recognition extensively relyon lexico-semantic resources (haghighi et al, 2005; <papid> H05-1049 </papid>harabagiu et al,2001), <papid> P01-1037 </papid>and we believe that our method for contextual substitution can be beneficial in that context.automatic evaluation measures variety of automatic evaluation methods have been recently proposed in the machine translation community (nist, 2002; melamed et al, 2003; <papid> N03-2021 </papid>papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>all these metrics compute n-gram overlap between reference and system output, but measure the overlap in different ways.
</nextsent>
<nextsent>our method for reference paraphrasing can be combined with any of these metrics.
</nextsent>
<nextsent>in this paper, we report experiments with bleu due to its wide use in the machine translation community.
</nextsent>
<nextsent>recently, researchers have explored additional knowledge sources that could enhance automaticevaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O979">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we report experiments with bleu due to its wide use in the machine translation community.
</prevsent>
<prevsent>recently, researchers have explored additional knowledge sources that could enhance automaticevaluation.
</prevsent>
</prevsection>
<citsent citstr=" P04-1079 ">
examples of such knowledge sources include stemming and tf-idf weighting (babych and hartley, 2004; <papid> P04-1079 </papid>banerjee and lavie, 2005).<papid> W05-0909 </papid></citsent>
<aftsection>
<nextsent>our work complements these approaches: we focus on the impact of paraphrases, and study their contribution to the accuracy of automatic evaluation.
</nextsent>
<nextsent>the input to our method consists of reference sentence = r1 . . .
</nextsent>
<nextsent>rm and system-generated sentence = w1 . . .
</nextsent>
<nextsent>wp whose words form the sets and respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O980">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we report experiments with bleu due to its wide use in the machine translation community.
</prevsent>
<prevsent>recently, researchers have explored additional knowledge sources that could enhance automaticevaluation.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
examples of such knowledge sources include stemming and tf-idf weighting (babych and hartley, 2004; <papid> P04-1079 </papid>banerjee and lavie, 2005).<papid> W05-0909 </papid></citsent>
<aftsection>
<nextsent>our work complements these approaches: we focus on the impact of paraphrases, and study their contribution to the accuracy of automatic evaluation.
</nextsent>
<nextsent>the input to our method consists of reference sentence = r1 . . .
</nextsent>
<nextsent>rm and system-generated sentence = w1 . . .
</nextsent>
<nextsent>wp whose words form the sets and respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O984">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>a quarter of the machine-translated segments are scored by human evaluators on one-to-five scale along twodimensions: adequacy and fluency.
</prevsent>
<prevsent>we use only adequacy scores, which measure how well content is preserved in the translation.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
4.1.3 alternative paraphrasing techniques to investigate the effect of paraphrase quality on automatic evaluation, we consider two alternative paraphrasing resources: latent semantic analysis (lsa), and brown clustering (brown et al, 1992).<papid> J92-4003 </papid>these techniques are widely used in nlp applications, including language modeling, information extraction, and dialogue processing (haghighi et al, 2005; <papid> H05-1049 </papid>serafin and eugenio, 2004; <papid> P04-1088 </papid>miller et al, 2004).<papid> N04-1043 </papid></citsent>
<aftsection>
<nextsent>both techniques are based on distributional similarity.
</nextsent>
<nextsent>the brown clustering is computed by considering mutual information between adjacent words.
</nextsent>
<nextsent>lsa is dimensionality reduction technique that projects word co-occurrence matrix to lower dimensions.
</nextsent>
<nextsent>this lower dimensional representation is then used with standard similarity measures to cluster the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O987">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>a quarter of the machine-translated segments are scored by human evaluators on one-to-five scale along twodimensions: adequacy and fluency.
</prevsent>
<prevsent>we use only adequacy scores, which measure how well content is preserved in the translation.
</prevsent>
</prevsection>
<citsent citstr=" P04-1088 ">
4.1.3 alternative paraphrasing techniques to investigate the effect of paraphrase quality on automatic evaluation, we consider two alternative paraphrasing resources: latent semantic analysis (lsa), and brown clustering (brown et al, 1992).<papid> J92-4003 </papid>these techniques are widely used in nlp applications, including language modeling, information extraction, and dialogue processing (haghighi et al, 2005; <papid> H05-1049 </papid>serafin and eugenio, 2004; <papid> P04-1088 </papid>miller et al, 2004).<papid> N04-1043 </papid></citsent>
<aftsection>
<nextsent>both techniques are based on distributional similarity.
</nextsent>
<nextsent>the brown clustering is computed by considering mutual information between adjacent words.
</nextsent>
<nextsent>lsa is dimensionality reduction technique that projects word co-occurrence matrix to lower dimensions.
</nextsent>
<nextsent>this lower dimensional representation is then used with standard similarity measures to cluster the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O988">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>a quarter of the machine-translated segments are scored by human evaluators on one-to-five scale along twodimensions: adequacy and fluency.
</prevsent>
<prevsent>we use only adequacy scores, which measure how well content is preserved in the translation.
</prevsent>
</prevsection>
<citsent citstr=" N04-1043 ">
4.1.3 alternative paraphrasing techniques to investigate the effect of paraphrase quality on automatic evaluation, we consider two alternative paraphrasing resources: latent semantic analysis (lsa), and brown clustering (brown et al, 1992).<papid> J92-4003 </papid>these techniques are widely used in nlp applications, including language modeling, information extraction, and dialogue processing (haghighi et al, 2005; <papid> H05-1049 </papid>serafin and eugenio, 2004; <papid> P04-1088 </papid>miller et al, 2004).<papid> N04-1043 </papid></citsent>
<aftsection>
<nextsent>both techniques are based on distributional similarity.
</nextsent>
<nextsent>the brown clustering is computed by considering mutual information between adjacent words.
</nextsent>
<nextsent>lsa is dimensionality reduction technique that projects word co-occurrence matrix to lower dimensions.
</nextsent>
<nextsent>this lower dimensional representation is then used with standard similarity measures to cluster the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O993">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>table 3 shows synthetic references produced by the different paraphrasing methods.
</prevsent>
<prevsent>4.2 impact of paraphrases on machine.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
translation evaluation the standard way to analyze the performance of an evaluation metric in machine translation is to compute the pearson correlation between the automatic metric and human scores (papineni et al, 2002; <papid> P02-1040 </papid>koehn, 2004; <papid> W04-3250 </papid>lin and och, 2004; <papid> C04-1072 </papid>stent et al, 2005).pearson correlation estimates how linearly dependent two sets of values are.</citsent>
<aftsection>
<nextsent>the pearson correlation values range from 1, when the scores are perfectly linearly correlated, to -1, in the case of inversely correlated scores.
</nextsent>
<nextsent>to calculate the pearson correlation, we create document by concatenating 300 segments.
</nextsent>
<nextsent>this strategy is commonly used in mt evaluation, because of bleus well-known problems with documents of small size (papineni et al, 2002; <papid> P02-1040 </papid>koehn, 2004).<papid> W04-3250 </papid></nextsent>
<nextsent>for each of the ten mt system translations, 459 reference: the monthly magazine choices?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O994">
<title id=" N06-1058.xml">paraphrasing for automatic evaluation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>table 3 shows synthetic references produced by the different paraphrasing methods.
</prevsent>
<prevsent>4.2 impact of paraphrases on machine.
</prevsent>
</prevsection>
<citsent citstr=" C04-1072 ">
translation evaluation the standard way to analyze the performance of an evaluation metric in machine translation is to compute the pearson correlation between the automatic metric and human scores (papineni et al, 2002; <papid> P02-1040 </papid>koehn, 2004; <papid> W04-3250 </papid>lin and och, 2004; <papid> C04-1072 </papid>stent et al, 2005).pearson correlation estimates how linearly dependent two sets of values are.</citsent>
<aftsection>
<nextsent>the pearson correlation values range from 1, when the scores are perfectly linearly correlated, to -1, in the case of inversely correlated scores.
</nextsent>
<nextsent>to calculate the pearson correlation, we create document by concatenating 300 segments.
</nextsent>
<nextsent>this strategy is commonly used in mt evaluation, because of bleus well-known problems with documents of small size (papineni et al, 2002; <papid> P02-1040 </papid>koehn, 2004).<papid> W04-3250 </papid></nextsent>
<nextsent>for each of the ten mt system translations, 459 reference: the monthly magazine choices?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1009">
<title id=" N06-2029.xml">exploiting variant corpora for machine translation </title>
<section> corpus-based machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 hypothesis selection.
</prevsent>
<prevsent>in order to select the best translation among outputs generated by multiple mt systems, we employ an smt-based method that scores mt outputs by using multiple language (lm) and translation model (tm) pairs trained on different subsets of the training data.
</prevsent>
</prevsection>
<citsent citstr=" C02-1076 ">
it uses statistical test to check whether the obtained tmlm scores of one mt output are significantly higher than those of another mt output (akiba et al,2002).<papid> C02-1076 </papid></citsent>
<aftsection>
<nextsent>given an input sentence, translation hypotheses are produced by the element mt engines, whereby different tmlm scores are assigned toeach hypothesis.
</nextsent>
<nextsent>in order to check whether the highest scored hypothesis is significantly better then the other mt outputs, multiple comparison test based on the kruskal-wallis test is used.
</nextsent>
<nextsent>if one of the mt outputs is significantly better, this output is selected.
</nextsent>
<nextsent>114otherwise, the output of the mt engine that performs best on develop set is selected.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1010">
<title id=" N06-2029.xml">exploiting variant corpora for machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the effectiveness of the proposed method is verified for the ce translation task (500 sentences) oflast years iwslt evaluation campaign.
</prevsent>
<prevsent>for the experiments, we used the four statistical (smt) and three example-based (ebmt) mt engines described in detail in (paul et al, 2005).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for evaluation, we used the bleu metrics, which calculates the geometric mean of n-gram precision for the mt outputs found in reference translations(papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>higher bleu scores indicate better translations.
</nextsent>
<nextsent>4.1 performance of element mt engines.
</nextsent>
<nextsent>table 2 summarizes the results of all element mt engines trained on the bteco and btecv corpora.
</nextsent>
<nextsent>the result show that the smt engines outperform table 2: bleu evaluation of element mt engines smt bteco btecv ebmt bteco btecv mt1 0.4020 0.4633 mt5 0.2908 0.3445 mt2 0.4474 0.4595 mt6 0.2988 0.4100 mt3 0.5342 0.5110 mt7 0.0002 0.0074 mt4 0.3575 0.4460the ebmt engines whereby the best performing system is marked with bold-face.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1011">
<title id=" N06-1054.xml">a fast finite state relaxation method for enforcing global constraints on sequence decoding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the best labeling of an unlabeled sequence.
</prevsent>
<prevsent>nonetheless, such global properties can improve the accuracy of model, so recent nlp paper shave considered practical techniques for decoding with them.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
such techniques include gibbs sampling (finkel et al, 2005), <papid> P05-1045 </papid>general-purposemonte carlo method, and integer linear programming (ilp), (roth and yih, 2005), general-purpose exact framework for np-complete problems.</citsent>
<aftsection>
<nextsent>under generative models such as hidden markov models, the probability of labeled sequence depends only on its local properties.
</nextsent>
<nextsent>the situation improves with discriminatively trained models, such as conditional random fields (lafferty et al, 2001), which do efficiently allow features that are functions of the entire observation sequence.
</nextsent>
<nextsent>however, these features can still only look locally at the label sequence.
</nextsent>
<nextsent>that is significant shortcoming, because in many domains, hard or soft global constraints on the label sequence are motivated by common sense: ? for named entity recognition, phrase that appears multiple times should tend to get the same label each time (finkel et al, 2005).<papid> P05-1045 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1014">
<title id=" N06-1054.xml">a fast finite state relaxation method for enforcing global constraints on sequence decoding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, these features can still only look locally at the label sequence.
</prevsent>
<prevsent>that is significant shortcoming, because in many domains, hard or soft global constraints on the label sequence are motivated by common sense: ? for named entity recognition, phrase that appears multiple times should tend to get the same label each time (finkel et al, 2005).<papid> P05-1045 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1042 ">
in bibliography entries (peng and mccallum, 2004), <papid> N04-1042 </papid>given field (author, title, etc.) should be filled by at most one substring of the input, and there are strong preferences on the cooccurrence and order of certain fields.</citsent>
<aftsection>
<nextsent>in seminar announcements, given field (speaker, start time, etc.) should appear withat most one value in each announcement, although the field and value may be repeated (finkel et al, 2005).<papid> P05-1045 </papid></nextsent>
<nextsent>for semantic role labeling, each argument should be instantiated only once forgiven verb.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1017">
<title id=" N06-1054.xml">a fast finite state relaxation method for enforcing global constraints on sequence decoding </title>
<section> hard constraints.  </section>
<citcontext>
<prevsection>
<prevsent>note that line 2 does not specify how to choose from among multiple violated constraints.
</prevsent>
<prevsent>this is discussed in 7.
</prevsent>
</prevsection>
<citsent citstr=" C90-2040 ">
our algorithm resembles the method of koskenniemi (1990) <papid> C90-2040 </papid>and later work.</citsent>
<aftsection>
<nextsent>the difference is that there lattices are unweighted and may not contain path that satisfies all constraints, so that the order of constraint intersection matters.
</nextsent>
<nextsent>the semantic role labeling task (carreras and ma`rques, 2004) involves choosing instantiations of verb arguments from sentence forgiven verb.
</nextsent>
<nextsent>the verb and its arguments form proposition.
</nextsent>
<nextsent>we use data from the conll-2004 shared taskthe propbank (palmer et al, 2005) <papid> J05-1004 </papid>annotations of the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>with sections1518 as the training set and section 20 as the development set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1018">
<title id=" N06-1054.xml">a fast finite state relaxation method for enforcing global constraints on sequence decoding </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>the semantic role labeling task (carreras and ma`rques, 2004) involves choosing instantiations of verb arguments from sentence forgiven verb.
</prevsent>
<prevsent>the verb and its arguments form proposition.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
we use data from the conll-2004 shared taskthe propbank (palmer et al, 2005) <papid> J05-1004 </papid>annotations of the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>with sections1518 as the training set and section 20 as the development set.</citsent>
<aftsection>
<nextsent>unless otherwise specified, all measurements are made on the development set.
</nextsent>
<nextsent>we follow roth and yih (2005) exactly, in order to compare system runtimes.
</nextsent>
<nextsent>they, in turn, follow hacioglu et al (2004) <papid> W04-2416 </papid>and others in labeling only the heads of syntactic chunks rather than all words.</nextsent>
<nextsent>we label only the core arguments (a0a5), treating 425 (a) 0?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1019">
<title id=" N06-1054.xml">a fast finite state relaxation method for enforcing global constraints on sequence decoding </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>the semantic role labeling task (carreras and ma`rques, 2004) involves choosing instantiations of verb arguments from sentence forgiven verb.
</prevsent>
<prevsent>the verb and its arguments form proposition.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we use data from the conll-2004 shared taskthe propbank (palmer et al, 2005) <papid> J05-1004 </papid>annotations of the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>with sections1518 as the training set and section 20 as the development set.</citsent>
<aftsection>
<nextsent>unless otherwise specified, all measurements are made on the development set.
</nextsent>
<nextsent>we follow roth and yih (2005) exactly, in order to compare system runtimes.
</nextsent>
<nextsent>they, in turn, follow hacioglu et al (2004) <papid> W04-2416 </papid>and others in labeling only the heads of syntactic chunks rather than all words.</nextsent>
<nextsent>we label only the core arguments (a0a5), treating 425 (a) 0?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1020">
<title id=" N06-1054.xml">a fast finite state relaxation method for enforcing global constraints on sequence decoding </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>unless otherwise specified, all measurements are made on the development set.
</prevsent>
<prevsent>we follow roth and yih (2005) exactly, in order to compare system runtimes.
</prevsent>
</prevsection>
<citsent citstr=" W04-2416 ">
they, in turn, follow hacioglu et al (2004) <papid> W04-2416 </papid>and others in labeling only the heads of syntactic chunks rather than all words.</citsent>
<aftsection>
<nextsent>we label only the core arguments (a0a5), treating 425 (a) 0?
</nextsent>
<nextsent>1 a0 a0 2 ? ?
</nextsent>
<nextsent>(b) 0 1 a0 a1 a2 a3 a4 a5 2 (verb osition )a1a2a3a4a5 oa0 (c) 0oa0a1a2a3 figure 4: automata expressing no duplicate a0 (?
</nextsent>
<nextsent>matches anything but a0), known verb position[2], and disallow arguments[a4,a5].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1021">
<title id=" N06-1054.xml">a fast finite state relaxation method for enforcing global constraints on sequence decoding </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>the last three constraints require information about the example, and the automata must be constructed on per-example basis: ? argument candidates (fig.
</prevsent>
<prevsent>5) encodes aset of position spans each of which must receive only single label type.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
these spans were proposed using high-recall heuristic (xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>known verb position (fig.
</nextsent>
<nextsent>4(b)) simply encodes the position of the verb in question, which must be labeled o. ? disallow arguments (fig.
</nextsent>
<nextsent>4(c)) specifies argument types that are compatible with the verb in question, according to propbank.
</nextsent>
<nextsent>5.2 experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1022">
<title id=" N06-1054.xml">a fast finite state relaxation method for enforcing global constraints on sequence decoding </title>
<section> semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>4(c)) specifies argument types that are compatible with the verb in question, according to propbank.
</prevsent>
<prevsent>5.2 experiments.
</prevsent>
</prevsection>
<citsent citstr=" P04-1065 ">
we implemented our hard constraint relaxation algorithm, using the fsa toolkit (kanthak and ney,2004) <papid> P04-1065 </papid>for finite-state operations.</citsent>
<aftsection>
<nextsent>fsa is an open source c++ library providing useful set of algorithms on weighted finite-state accept ors and transducers.
</nextsent>
<nextsent>for each example we decoded, we chose random order in which to apply the constraints.
</nextsent>
<nextsent>lattices are generated from what amounts to unigram mode lthe voted perceptron classifier of roth and yih.
</nextsent>
<nextsent>the features used are subset of those commonly applied to the task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1023">
<title id=" N03-2027.xml">bayesian nets for syntactic categorization of novel words </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>existing probabilistic taggers also dont farewell on unknown words.
</prevsent>
<prevsent>reported results on oov rarely exceed brills performance by tiny fraction.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
they are mostly based on (hidden) markov models [brants 2000, <papid> A00-1031 </papid>kupiec, 1992].</citsent>
<aftsection>
<nextsent>a model based on conditional random fields [lafferty et al ] outperforms the hmm tagger on unknown words yielding 24% error rate.
</nextsent>
<nextsent>the best result known to us is achieved by toutanova[2002] by enriching the feature representation of the maxent approach [ratnaparkhi, 1996].<papid> W96-0213 </papid></nextsent>
<nextsent>2 dbn for pos tagging unlike toutanova[2002], we deliberately base our model on the original feature set of ratna parkhis maxent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1024">
<title id=" N03-2027.xml">bayesian nets for syntactic categorization of novel words </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are mostly based on (hidden) markov models [brants 2000, <papid> A00-1031 </papid>kupiec, 1992].</prevsent>
<prevsent>a model based on conditional random fields [lafferty et al ] outperforms the hmm tagger on unknown words yielding 24% error rate.</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the best result known to us is achieved by toutanova[2002] by enriching the feature representation of the maxent approach [ratnaparkhi, 1996].<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>2 dbn for pos tagging unlike toutanova[2002], we deliberately base our model on the original feature set of ratna parkhis maxent.
</nextsent>
<nextsent>our bayesian network includes set of binary features (1-3, below) and set of vocabulary features (4-6, below).
</nextsent>
<nextsent>the binary features indicate the presence or absence of particular character in the token: 1.
</nextsent>
<nextsent>does the token contain capital letter; 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1025">
<title id=" N03-2022.xml">semantic extraction with wide coverage lexical resources </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we report results obtained from combining ie and graphical modeling techniques, with semantic resources (wordnet and framenet) for automatic semantic extraction.
</prevsent>
<prevsent>semantic extraction has become strong research focus in the last few years.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
a good example is the work of gildea and jurafsky (2002) (<papid> J02-3001 </papid>gj).</citsent>
<aftsection>
<nextsent>gj present comprehensive empirical approach to the problem of semantic role assignment.
</nextsent>
<nextsent>their work looked at the problem of assigning semantic roles to text based on statistical model of the framenet1 data.
</nextsent>
<nextsent>in their work, gj assume that the frame of interest is determined a-priori for every sentence.
</nextsent>
<nextsent>in the ie community, there has been an ongoing effort to build systems that can automatically generate required pattern sets as well as the extraction relevant lexicon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1026">
<title id=" N03-2022.xml">semantic extraction with wide coverage lexical resources </title>
<section> framenet.  </section>
<citcontext>
<prevsection>
<prevsent>3) we employed ie methods (including pattern sets and named entity recognition) as initial extraction steps.
</prevsent>
<prevsent>1 http://www.icsi.berkeley.edu/~framenet
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
framenet (baker et. al. 1998) <papid> P98-1013 </papid>is building lexicon based on the theory of frame semantics.</citsent>
<aftsection>
<nextsent>frame semantics suggests that the meanings of lexical items (lexical units (lu)) are best defined with respect to larger conceptual chunks, called frames.
</nextsent>
<nextsent>individual lexical units evoke specific frames and establish binding pattern to specific slots or roles (frame elements (fe)) within the frame.
</nextsent>
<nextsent>the berkeley framenet project describes the underlying frames for different lexical units, examines sentences related to the frames using very large corpus, and records (annotates) the ways in which information from the associated frames are expressed in these sentences.
</nextsent>
<nextsent>the result is database that contains set of frames (related through hierarchy and composition), set of frame elements for each frame, and set of frame annotated sentences that covers the different patterns of usage for lexical units in the frame.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1027">
<title id=" N03-2022.xml">semantic extraction with wide coverage lexical resources </title>
<section> framenet.  </section>
<citcontext>
<prevsection>
<prevsent>we filtered out all of the non-relevant terms in all frame element lexicons.
</prevsent>
<prevsent>we hypothesized that using highly precise set of patterns along with precise lexicon should enable promising ie performance.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
for our information extraction experiments, we used gate (cunningham et. al. 2002), <papid> P02-1022 </papid>an open source natural language engineering system.</citsent>
<aftsection>
<nextsent>the component-based architecture of gate enabled us to plug-in our framenet based lexicon and pattern set and run ie experiments on this system.
</nextsent>
<nextsent>3.2 initial experiment:.
</nextsent>
<nextsent>as preliminary test, we compiled set of 100 news stories from yahoo news service with topics related to criminal investigation.
</nextsent>
<nextsent>we also compiled set of ie patterns and also the lexicon from the crime related frames (arrest?, detain?, arraign?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1028">
<title id=" N07-1038.xml">multiple aspect ranking using the good grief algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we prove that our agreement based joint model is more expressive than individual ranking models.
</prevsent>
<prevsent>our empirical results further confirm the strength of the model: the algorithm provides significant improvement over both individual rankers and state-of-the-art joint ranking model.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
previous work on sentiment categorization makes an implicit assumption that single score can express the polarity of an opinion text (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002; <papid> P02-1053 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>however, multiple opinions on related matters are often intertwined throughout text.
</nextsent>
<nextsent>for example, restaurant review may express judgment on food quality as well as the service and ambience of the restaurant.
</nextsent>
<nextsent>rather than lumping these aspects into single score, we would like to capture each aspect of the writers opinion separately, thereby providing more fine-grained view of opinions in the review.
</nextsent>
<nextsent>to this end, we aim to predict set of numeric ranks that reflects the users satisfaction for each aspect.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1030">
<title id=" N07-1038.xml">multiple aspect ranking using the good grief algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we prove that our agreement based joint model is more expressive than individual ranking models.
</prevsent>
<prevsent>our empirical results further confirm the strength of the model: the algorithm provides significant improvement over both individual rankers and state-of-the-art joint ranking model.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
previous work on sentiment categorization makes an implicit assumption that single score can express the polarity of an opinion text (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002; <papid> P02-1053 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>however, multiple opinions on related matters are often intertwined throughout text.
</nextsent>
<nextsent>for example, restaurant review may express judgment on food quality as well as the service and ambience of the restaurant.
</nextsent>
<nextsent>rather than lumping these aspects into single score, we would like to capture each aspect of the writers opinion separately, thereby providing more fine-grained view of opinions in the review.
</nextsent>
<nextsent>to this end, we aim to predict set of numeric ranks that reflects the users satisfaction for each aspect.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1032">
<title id=" N07-1038.xml">multiple aspect ranking using the good grief algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we prove that our agreement based joint model is more expressive than individual ranking models.
</prevsent>
<prevsent>our empirical results further confirm the strength of the model: the algorithm provides significant improvement over both individual rankers and state-of-the-art joint ranking model.
</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
previous work on sentiment categorization makes an implicit assumption that single score can express the polarity of an opinion text (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002; <papid> P02-1053 </papid>yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>however, multiple opinions on related matters are often intertwined throughout text.
</nextsent>
<nextsent>for example, restaurant review may express judgment on food quality as well as the service and ambience of the restaurant.
</nextsent>
<nextsent>rather than lumping these aspects into single score, we would like to capture each aspect of the writers opinion separately, thereby providing more fine-grained view of opinions in the review.
</nextsent>
<nextsent>to this end, we aim to predict set of numeric ranks that reflects the users satisfaction for each aspect.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1033">
<title id=" N07-1038.xml">multiple aspect ranking using the good grief algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the algorithm presented in this paper models the dependencies between different labels via the agreement relation.
</prevsent>
<prevsent>the agreement relation captures whether the user equally likes all aspects of the item or whether he or she expresses different degrees ofsatisfaction.
</prevsent>
</prevsection>
<citsent citstr=" P02-1047 ">
since this relation can often be determined automatically forgiven text (marcu and echihabi, 2002), <papid> P02-1047 </papid>we can readily use it to improve rank prediction.</citsent>
<aftsection>
<nextsent>the good grief model consists of ranking model for each aspect as well as an agreement model which predicts whether or not all rank aspects are1in this paper, ranking refers to the task of assigning an integer from 1 to to each instance.
</nextsent>
<nextsent>this task is sometimes referred to as ordinal regression?
</nextsent>
<nextsent>(crammer and singer, 2001) and rating prediction?
</nextsent>
<nextsent>(pang and lee, 2005).<papid> P05-1015 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1034">
<title id=" N07-1038.xml">multiple aspect ranking using the good grief algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this task is sometimes referred to as ordinal regression?
</prevsent>
<prevsent>(crammer and singer, 2001) and rating prediction?
</prevsent>
</prevsection>
<citsent citstr=" P05-1015 ">
(pang and lee, 2005).<papid> P05-1015 </papid></citsent>
<aftsection>
<nextsent>300equal.
</nextsent>
<nextsent>the good grief decoding algorithm predicts set of ranks ? one for each aspect ? which maximally satisfy the preferences of the individual rankers and the agreement model.
</nextsent>
<nextsent>for example, ifthe agreement model predicts consensus but the individual rankers select ranks 5, 5, 4?, then the decoder decides whether to trust the the third ranker,or alter its prediction and output 5, 5, 5?
</nextsent>
<nextsent>to be consistent with the agreement prediction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1041">
<title id=" N07-1038.xml">multiple aspect ranking using the good grief algorithm </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our model significantly outperforms individual ranking models as well as state of-the-art joint ranking model.
</prevsent>
<prevsent>sentiment classification traditionally, categorization of opinion texts has been cast as binary classification task (pang et al, 2002; <papid> W02-1011 </papid>turney, 2002; <papid> P02-1053 </papid>yu and hatzivassiloglou, 2003; <papid> W03-1017 </papid>dave et al, 2003).</prevsent>
</prevsection>
<citsent citstr=" W06-3808 ">
more recent work (pang and lee, 2005; <papid> P05-1015 </papid>goldberg andzhu, 2006) <papid> W06-3808 </papid>has expanded this analysis to the ranking framework where the goal is to assess review polarity on multi-point scale.</citsent>
<aftsection>
<nextsent>while this approach provides richer representation of single opinion, it still operates on the assumption of one opinion pertext.
</nextsent>
<nextsent>our work generalizes this setting to the problem of analyzing multiple opinions ? or multiple aspects of an opinion.
</nextsent>
<nextsent>since multiple opinions in single text are related, it is insufficient to treat them as separate single-aspect ranking tasks.
</nextsent>
<nextsent>this motivates our exploration of new method for joint multiple aspect ranking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1044">
<title id=" N07-1038.xml">multiple aspect ranking using the good grief algorithm </title>
<section> experimental set-up.  </section>
<citcontext>
<prevsection>
<prevsent>and ranking model for the ambience aspect such as = (1,1, 0),b = (0), the good grief decoder will produce perfect rank.
</prevsent>
<prevsent>we evaluate our multi-aspect ranking algorithm on acorpus5 of restaurant reviews available on the web site http://www.we8there.com.
</prevsent>
</prevsection>
<citsent citstr=" P06-1034 ">
reviews from this website have been previously used in other sentiment analysis tasks (higashinaka et al, 2006).<papid> P06-1034 </papid></citsent>
<aftsection>
<nextsent>each review is accompanied by set of five ranks,each on scale of 1-5, covering food, ambience, service, value, and overall experience.
</nextsent>
<nextsent>these ranks are provided by consumers who wrote original reviews.
</nextsent>
<nextsent>our corpus does not contain incomplete data points since all the reviews available on this website contain both review text and the values for all the five aspects.training and testing division our corpus con 5data and code used in this paper are available at http://people.csail.mit.edu/bsnyder/naacl07tains 4,488 reviews, averaging 115 words.
</nextsent>
<nextsent>we randomly select 3,488 reviews for training, 500 forde velopment and 500 for testing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1045">
<title id=" N06-1057.xml">paraeval using paraphrases to evaluate summaries automatically </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, when resources are limited, automated evaluation methods become more desirable.
</prevsent>
<prevsent>for years, the summarization community has been actively seeking an automatic evaluation methodology that can be readily applied to various summarization tasks.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
rouge (lin and hovy, 2003) <papid> N03-1020 </papid>has gained popularity due to its simplicity and high correlation with human judgments.</citsent>
<aftsection>
<nextsent>even though validated by high correlations with human judgments gathered from previous document understanding conference (duc) experiments, current automatic procedures (lin and hovy, 2003; <papid> N03-1020 </papid>hovy et al, 2005) only employ lexical n-gram matching.</nextsent>
<nextsent>the lack of support for word or phrase matching that stretches beyond strict lexical matches has limited the expressiveness and utility of these methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1049">
<title id=" N06-1057.xml">paraeval using paraphrases to evaluate summaries automatically </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>this paper is organized in the following way:section 2 introduces previous work in summarization evaluation; section 3 describes the motivation behind this work; paraphrase acquisition is discussed in section 4; section 5 explains in detail our summary comparison mechanism; section 6validates paraeval with human summary judg ments; and we conclude and discuss future work in section 7.
</prevsent>
<prevsent>there has been considerable work in both manual and automatic summarization evaluations.
</prevsent>
</prevsection>
<citsent citstr=" N04-1019 ">
three most noticeable efforts in manual evaluation are see (lin and hovy, 2001), factoid (van halteren and teufel, 2003), and the pyramid method (nenkova and passonneau, 2004).<papid> N04-1019 </papid></citsent>
<aftsection>
<nextsent>see provides user-friendly environment in which human assessors evaluate the quality of system-produced peer summary by comparing it to reference summary.
</nextsent>
<nextsent>summaries are represented by list of summary units (sentences, clauses, etc.).
</nextsent>
<nextsent>assessors can assign full or partial content coverage score to peer summary units in comparison to the corresponding reference summary units.
</nextsent>
<nextsent>grammaticality can also be graded unit-wise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1056">
<title id=" N06-1057.xml">paraeval using paraphrases to evaluate summaries automatically </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 synonymy relations.
</prevsent>
<prevsent>synonym matching and paraphrase matching are often mentioned in the same context in discussions of extending current automated summarization evaluation methods to incorporate the matching of semantic units.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
while evaluating automatically extracted paraphrases via wordnet (miller et al,1990), barzilay and mckeown (2001) <papid> P01-1008 </papid>quantitatively validated that synonymy is not the only source of paraphrasing.</citsent>
<aftsection>
<nextsent>we envisage that this claim is also valid for summary comparisons.from an in-depth analysis on the manually created scus of the duc2003 summary set d30042 (nenkova and passonneau, 2004), <papid> N04-1019 </papid>we find that 54.48% of 1746 cases where non-stop word fromone scu did not match with its supposedly hu man-aligned pairing scus are in need of some level of paraphrase matching support.</nextsent>
<nextsent>for example, in the first two extracted scus (labeled as 1 and 2) in figure 1for the lockerbie bombing?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1059">
<title id=" N06-1057.xml">paraeval using paraphrases to evaluate summaries automatically </title>
<section> paraphrase acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>paraphrases are alternative verbalizations for conveying the same information and are required bymany natural language processing (nlp) applications.
</prevsent>
<prevsent>in particular, summary creation and evaluation methods need to recognize paraphrases and their semantic equivalence.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
unfortunately, wehave yet to incorporate into the evaluation framework previous findings in paraphrase identification and extraction (barzilay and mckeown, 2001; <papid> P01-1008 </papid>pang et al, 2003; <papid> N03-1024 </papid>bannard and callison-burch, 2005).</citsent>
<aftsection>
<nextsent>4.1 related work on paraphrasing.
</nextsent>
<nextsent>three major approaches in paraphrase collection are manual collection (domain-specific), collection utilizing existing lexical resources (i.e. wordnet), and derivation from corpora.
</nextsent>
<nextsent>hermjakob et al (2002) view paraphrase recognition as reformulation by pattern recognition.
</nextsent>
<nextsent>pang et al(2003) <papid> N03-1024 </papid>use word lattices as paraphrase representations from semantically equivalent translationssets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1062">
<title id=" N06-1057.xml">paraeval using paraphrases to evaluate summaries automatically </title>
<section> paraphrase acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 extracting paraphrases.
</prevsent>
<prevsent>our method to automatically construct large do main-independent paraphrase collection is based on the assumption that two different english phrases of the same meaning may have the same translation in foreign language.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
phrase-based statistical machine translation(smt) systems analyze large quantities of bilingual parallel texts in order to learn translational alignments between pairs of words and phrases intwo languages (och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>the sentence based translation model makes word/phrase alignment decisions probabilistically by computing the optimal model parameters with application of the statistical estimation theory.
</nextsent>
<nextsent>this alignment process results in corpus of word/phrase-aligned parallel sentences from which we can extract phrase pairs that are translations of each other.
</nextsent>
<nextsent>we ran the alignment algorithm from (och and ney, 2003) <papid> J03-1002 </papid>on chinese-english parallel corpus of 218 million english words.</nextsent>
<nextsent>phrase pairs are extracted by following the method described in (och and ney, 2004) <papid> J04-4002 </papid>where all contiguous phrase pairs having consistent alignments are extraction candidates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1063">
<title id=" N06-1057.xml">paraeval using paraphrases to evaluate summaries automatically </title>
<section> paraphrase acquisition.  </section>
<citcontext>
<prevsection>
<prevsent>the sentence based translation model makes word/phrase alignment decisions probabilistically by computing the optimal model parameters with application of the statistical estimation theory.
</prevsent>
<prevsent>this alignment process results in corpus of word/phrase-aligned parallel sentences from which we can extract phrase pairs that are translations of each other.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we ran the alignment algorithm from (och and ney, 2003) <papid> J03-1002 </papid>on chinese-english parallel corpus of 218 million english words.</citsent>
<aftsection>
<nextsent>phrase pairs are extracted by following the method described in (och and ney, 2004) <papid> J04-4002 </papid>where all contiguous phrase pairs having consistent alignments are extraction candidates.</nextsent>
<nextsent>the resulting phrase table is of high quality; boththe alignment models and phrase extraction meth 449 ods have been shown to produce very good results for smt.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1070">
<title id=" N07-1004.xml">what decisions have you made automatic decision detection in meeting conversations </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, researchers have begun to make progress towards this goal.
</prevsent>
<prevsent>for example, gatica et al (2005) and wrede and shriberg (2003) automatically identify the level of emotion in meeting spurts (e.g., group level of interest, hot spots).
</prevsent>
</prevsection>
<citsent citstr=" N03-2012 ">
other researchers have developed models for detecting agreement and disagreement in meetings, using models that combine lexical features with prosodic features (e.g., pause, duration,f0, speech rate) (hillard et al, 2003) <papid> N03-2012 </papid>and structural information (e.g., the previous and following speaker) (galley et al, 2004).<papid> P04-1085 </papid></citsent>
<aftsection>
<nextsent>more recently, purver et al (2006) <papid> W06-3405 </papid>have tackled the problem of detecting one type of decision, namely action items, which embody the transfer of group responsibility.</nextsent>
<nextsent>however, no prior work has addressed the problem of automatically identifying decision-making units more generally in multiparty meetings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1071">
<title id=" N07-1004.xml">what decisions have you made automatic decision detection in meeting conversations </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, researchers have begun to make progress towards this goal.
</prevsent>
<prevsent>for example, gatica et al (2005) and wrede and shriberg (2003) automatically identify the level of emotion in meeting spurts (e.g., group level of interest, hot spots).
</prevsent>
</prevsection>
<citsent citstr=" P04-1085 ">
other researchers have developed models for detecting agreement and disagreement in meetings, using models that combine lexical features with prosodic features (e.g., pause, duration,f0, speech rate) (hillard et al, 2003) <papid> N03-2012 </papid>and structural information (e.g., the previous and following speaker) (galley et al, 2004).<papid> P04-1085 </papid></citsent>
<aftsection>
<nextsent>more recently, purver et al (2006) <papid> W06-3405 </papid>have tackled the problem of detecting one type of decision, namely action items, which embody the transfer of group responsibility.</nextsent>
<nextsent>however, no prior work has addressed the problem of automatically identifying decision-making units more generally in multiparty meetings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1072">
<title id=" N07-1004.xml">what decisions have you made automatic decision detection in meeting conversations </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for example, gatica et al (2005) and wrede and shriberg (2003) automatically identify the level of emotion in meeting spurts (e.g., group level of interest, hot spots).
</prevsent>
<prevsent>other researchers have developed models for detecting agreement and disagreement in meetings, using models that combine lexical features with prosodic features (e.g., pause, duration,f0, speech rate) (hillard et al, 2003) <papid> N03-2012 </papid>and structural information (e.g., the previous and following speaker) (galley et al, 2004).<papid> P04-1085 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-3405 ">
more recently, purver et al (2006) <papid> W06-3405 </papid>have tackled the problem of detecting one type of decision, namely action items, which embody the transfer of group responsibility.</citsent>
<aftsection>
<nextsent>however, no prior work has addressed the problem of automatically identifying decision-making units more generally in multiparty meetings.
</nextsent>
<nextsent>moreover, no previous research has provided quantitative account of the effects of different feature types on the task of automatic decision detection.
</nextsent>
<nextsent>our aim is to develop models for automatically detecting segments of conversation that contain decisions directly from the audio recordings and transcripts of the meetings, and to identify the feature combinations that are most effective for this task.
</nextsent>
<nextsent>meetings can be viewed at different levels of granularity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1073">
<title id=" N07-1004.xml">what decisions have you made automatic decision detection in meeting conversations </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 features used.
</prevsent>
<prevsent>to provide qualitative account of the effect of different feature types on the task of automatic decision detection, we have conducted empirical analysis onfour major types of features: lexical, prosodic, contextual and topical features.
</prevsent>
</prevsection>
<citsent citstr=" P05-1054 ">
4.2.1 lexical features previous research has studied lexical differences(i.e., occurrence counts of n-grams) between various aspects of speech, such as topics (hsueh and moore, 2006), speaker gender (boulis and ostendorf, 2005), <papid> P05-1054 </papid>and story-telling conversation (gordonand ganesan, 2005).</citsent>
<aftsection>
<nextsent>as we expect that lexical differences also exist in dm conversations, wegener ated language models from the dm dialogue acts in the corpus.
</nextsent>
<nextsent>the comparison of the language models generated from the dm dialogue acts and the rest of the conversations shows that some differences exist between the two models: (1) decisionmaking conversations are more likely to contain we than and you; (2) in decision-making conversations there aremore explicit mentions of topical words, such as advanced chips and functional design; (3) in decision 27 type feature duration number of words spoken in current, previous and next sub dialogue duration (in seconds) of current, previous and next sub dialogue pause amount of silence (in seconds) preceding sub dialogue amount of silence (in seconds) following sub dialogue speech rate number of words spoken per second in current, previous and next sub dialogue number of syllables per second in current, previous and next sub dialogue energy overall energy level average energy level in the first, second, third, and fourth quarter of sub dialogue pitch maximum and minimum f0, overall slope and variance slope and variance at the first 100 and 200 ms and last 100 and 200 ms, at the first and second half, and at each quarter of the sub dialogue table 1: prosodic features used in this study.making conversations, there are fewer negative expressions, such as dont think and dont know.
</nextsent>
<nextsent>in an exploratory study using unigrams, as well as bigrams and trigrams, we found that using bigram sand trigrams does not improve the accuracy of classifying dm das, and therefore we include only unigrams in the set of lexical features in the experiments reported in section 6.
</nextsent>
<nextsent>4.2.2 prosodic features functionally, prosodic features, i.e., energy, and fundamental frequency (f0), are indicative of segmentation and saliency.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1074">
<title id=" N03-2011.xml">rhetorical parsing with under specification and forests </title>
<section> introduction </section>
<citcontext>
<prevsection>

<prevsent>we combine surface based approach to discourse parsing with an explicit rhetorical grammar in order to efficiently construct an underspecified representation of possible discourse structures.
</prevsent>
</prevsection>
<citsent citstr=" J00-3005 ">
the task of rhetorical parsing, i.e., automatically determining discourse structure, has been shown to be relevant, inter alia, for automatic summarization (e.g., marcu, 2000).<papid> J00-3005 </papid></citsent>
<aftsection>
<nextsent>not surprisingly, though, the task is very difficult.
</nextsent>
<nextsent>previous approaches have thus emphasized the need for heuristic or probabilistic information in the process of finding the best or most likely rhetorical tree.
</nextsent>
<nextsent>as an alternative, we explore the idea of strictly separating high-confidence?
</nextsent>
<nextsent>information from hypothetical reasoning and of working with underspecified trees as much as possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1076">
<title id=" N03-2011.xml">rhetorical parsing with under specification and forests </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>segment rst_tree mc macro_seg non_rst_tree pp sc fig 3: simplified inheritance hierarchy for cat
</prevsent>
<prevsent>similar to marcu (2000) <papid> J00-3005 </papid>we assume discourse markers as indicators for rhetorical relations.</prevsent>
</prevsection>
<citsent citstr=" P99-1047 ">
but contrary to marcu (1999) <papid> P99-1047 </papid>and also to schilder (2002) we use full-fledged discourse grammar and standard parsing algorithm, which makes it, in our opinion, unnecessary to propose special rhetorical tree building operations, as suggested e.g. by marcu (1999).<papid> P99-1047 </papid></citsent>
<aftsection>
<nextsent>by using the chart parsing algorithm combined with the construction of an underspecified parse forest, it can easily be shown that our method is of cubic complexity.
</nextsent>
<nextsent>this is crucial property, because it is commonly assumed that the number of distinct structures that can be constructed over sequence of discourse units is exponential in n, (as it is for example implicit in the dcg based algorithm proposed by schilder, 2002).
</nextsent>
<nextsent>our system is robust in the same way as the one in schilder (2002) because the grammar admits underspecified rhetorical trees in the absence of overt discourse markers.
</nextsent>
<nextsent>we have shown that grammar based approach to rhetorical parsing is suitable for efficient and robust construction of underspecified rhetorical structures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1078">
<title id=" N04-4027.xml">summarizing email threads </title>
<section> previous and related work.  </section>
<citcontext>
<prevsection>
<prevsent>the reader can reconstruct the interact ional aspect of the thread, which we assume is crucial for understanding the summary.
</prevsent>
<prevsent>we acknowledge that other techniques should also be explored for email summarization, but leave that to separate work.
</prevsent>
</prevsection>
<citsent citstr=" W01-0719 ">
muresan et al (2001) <papid> W01-0719 </papid>describe work on summarizing individual email messages using machine learning approaches to learn rules for salient noun phrase extraction.</citsent>
<aftsection>
<nextsent>in contrast, our work aims at summarizing whole threads and at capturing the interactive nature of email.nenkova and bagga (2003) present work on generating extractive summaries of threads in archived discussions.
</nextsent>
<nextsent>a sentence from the root message and from each response to the root extracted using ad-hoc algorithms crafted by hand.
</nextsent>
<nextsent>this approach works best when the subject of the root email best describes the issue?
</nextsent>
<nextsent>of the thread, and when the root email does not discuss more than one issue.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1079">
<title id=" N04-4027.xml">summarizing email threads </title>
<section> previous and related work.  </section>
<citcontext>
<prevsection>
<prevsent>as discussed in section 1, email is different in important respects from (multi-party) dialog.
</prevsent>
<prevsent>how ever, some important aspects are related.
</prevsent>
</prevsection>
<citsent citstr=" J02-4003 ">
zechner (2002), <papid> J02-4003 </papid>for example, presents meeting summarization system which uses the mmr algorithm to find sentences that are most similar to the segment and most dissimilar to each other.</citsent>
<aftsection>
<nextsent>the similarity weights in the mmr algorithm are modified using three features, including whether sentence belongs to question-answer pair.
</nextsent>
<nextsent>the use of the question-answer pair detection is an interesting proposal that is also applicable to our work.
</nextsent>
<nextsent>however, overall most of the issues tackled by zechner (2002) <papid> J02-4003 </papid>are not relevant to email summarization.</nextsent>
<nextsent>our corpus consists of 96 threads of email sent during one academic year among the members of the board ofthe student organization of the acm at columbia uni versity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1081">
<title id=" N06-1062.xml">unlimited vocabulary speech recognition for agglutinative languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in (kneissler and klakow, 2001; arisoy and arslan,2005) different combinations of words, grammatical morphemes and endings are utilized to decrease the oov rate and optimize the speech recognition accuracy.
</prevsent>
<prevsent>however, constant large improvements over the conventional word-based language models in lvcsr have been rare.
</prevsent>
</prevsection>
<citsent citstr=" W02-0603 ">
the approach presented in this paper relies on data-driven algorithm called morfessor (creutz and lagus, 2002; <papid> W02-0603 </papid>creutz and lagus, 2005) which is alan guage independent unsupervised machine learning method to find morpheme-like units (called statistical morphs) from large text corpus.</citsent>
<aftsection>
<nextsent>this method has several advantages over the rule-based grammatical morphemes, e.g. that no hand-crafted rules are needed and all words can be processed, even the foreign ones.
</nextsent>
<nextsent>even if good grammatical morphemes are available, the language modeling results by the statistical morphs seem to be at least as good, if not better (hirsimki et al, 2005).
</nextsent>
<nextsent>in this paper we evaluate the statistical morphs for three agglutinative languages and describe three different speech recognition systems that successfully utilize the n-gram language models trained for these units in the corresponding lvcsr tasks.
</nextsent>
<nextsent>models 2.1 unsupervised discovery of morph units.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1083">
<title id=" N04-2003.xml">maximum entropy modeling in sparse semantic tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, to guarantee the convergence of the bootstrapping process, three adjusting strategies are proposed to soft tag unlabeled data.
</prevsent>
<prevsent>semantic analysis is an open research field in natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
two major research topics in this field are named entity recognition (ner) (n. wacholder and choi,1997; cucerzan and yarowsky, 1999) <papid> W99-0612 </papid>and word sense disambiguation (wsd) (yarowsky, 1995; <papid> P95-1026 </papid>wilks and stevenson, 1999).</citsent>
<aftsection>
<nextsent>ner identifies different kinds of names such as person?,location?
</nextsent>
<nextsent>or date?, while wsd distinguishes the senses of ambiguous words.
</nextsent>
<nextsent>for example, bank?
</nextsent>
<nextsent>can be labeled as financial institution?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1084">
<title id=" N04-2003.xml">maximum entropy modeling in sparse semantic tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, to guarantee the convergence of the bootstrapping process, three adjusting strategies are proposed to soft tag unlabeled data.
</prevsent>
<prevsent>semantic analysis is an open research field in natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
two major research topics in this field are named entity recognition (ner) (n. wacholder and choi,1997; cucerzan and yarowsky, 1999) <papid> W99-0612 </papid>and word sense disambiguation (wsd) (yarowsky, 1995; <papid> P95-1026 </papid>wilks and stevenson, 1999).</citsent>
<aftsection>
<nextsent>ner identifies different kinds of names such as person?,location?
</nextsent>
<nextsent>or date?, while wsd distinguishes the senses of ambiguous words.
</nextsent>
<nextsent>for example, bank?
</nextsent>
<nextsent>can be labeled as financial institution?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1085">
<title id=" N04-2003.xml">maximum entropy modeling in sparse semantic tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one category may denote concept which is subset of that of another.
</prevsent>
<prevsent>examples of the category structures are illustrated in figure 1.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
figure 1: structure of some semantic categories used in the langman dictionary.maximum entropy (maxent) principle has been successfully applied in many classification and tagging tasks (ratnaparkhi, 1996; <papid> W96-0213 </papid>k. nigam and a.mccallum, 1999; a. mccallum and pereira, 2000).</citsent>
<aftsection>
<nextsent>we use maxent modeling as the learning component.
</nextsent>
<nextsent>a major issue in maxent training ishow to select proper features and determine the feature targets (berger et al, 1996; <papid> J96-1002 </papid>jebara and jaakkola, 2000).</nextsent>
<nextsent>to discover useful features, we exploit the concept of association rules (ar) (r. agrawal and swami, 1993; srikant and agrawal, 1997), which is originally proposed in data mining research field to identify frequent item sets in large database.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1086">
<title id=" N04-2003.xml">maximum entropy modeling in sparse semantic tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1: structure of some semantic categories used in the langman dictionary.maximum entropy (maxent) principle has been successfully applied in many classification and tagging tasks (ratnaparkhi, 1996; <papid> W96-0213 </papid>k. nigam and a.mccallum, 1999; a. mccallum and pereira, 2000).</prevsent>
<prevsent>we use maxent modeling as the learning component.</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
a major issue in maxent training ishow to select proper features and determine the feature targets (berger et al, 1996; <papid> J96-1002 </papid>jebara and jaakkola, 2000).</citsent>
<aftsection>
<nextsent>to discover useful features, we exploit the concept of association rules (ar) (r. agrawal and swami, 1993; srikant and agrawal, 1997), which is originally proposed in data mining research field to identify frequent item sets in large database.
</nextsent>
<nextsent>like many other classification tasks, human-annotated data for semantic analysis is expensive and limited, while large amount of unlabeled data is easily obtained.
</nextsent>
<nextsent>many researchers (blum and mitchell, 1998; k. nigam and mitchell, 2000; corduneanu and jaakkola, 2002) have attempted to improve performance with unlabeled data.
</nextsent>
<nextsent>in this paper, we also propose framework to bootstrap with unlabeled data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1088">
<title id=" N04-4008.xml">automatic construction of an english chinese bilingual framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation results show that we achieve promising 82% average measure for the most ambiguous lexical entries.
</prevsent>
<prevsent>since the early 90s, automatic alignment of bilingual documents and sentences based on lexical and syntactic information has been major focus of the statistical nlp community as their results are valuable resource for statistical machine translation, cross-lingual question answering, and other bilingual or cross-lingual tasks.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
recently, there has been an increasing trend of using semantic information for these tasks spurred by the availability of various ontology databases such as wordnet, framenet, propbank, etc. among these, the berkeley framenet database is semantic lexical resource consisting of frame-semantic descriptions of more than 7000 english lexical items, together with example sentences annotated with semantic roles (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>the current version of framenet has been applied successfully to english question answering systems (gildea, 2002).
</nextsent>
<nextsent>however, the manual development of framenet in other languages has been on small scale (e.g. german, spanish, japanese) or unfinished (e.g. chinese).
</nextsent>
<nextsent>since manually annotation is rather time consuming, the main objective of our work is to automatically create multilingual framenet to enable semantic analysis in multiple languages rather than in english.
</nextsent>
<nextsent>another objective is to quantify the mapping between semantic structures across language pairs for statistical nlp systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1089">
<title id=" N04-4008.xml">automatic construction of an english chinese bilingual framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>much like wordnet, cilin is thesaurus with hierarchical structure of word clusters, but it does not describe any semantic relationship between words and categories.
</prevsent>
<prevsent>hownet, on the other hand, is an ontology with graph structure of in ter-concept relations and inter-attribute relations.
</prevsent>
</prevsection>
<citsent citstr=" C02-1143 ">
in addition, hownet has been widely used in resolving nlp problems, such as word sense disambiguation (dang et al, 2002) <papid> C02-1143 </papid>and machine translation (dorr et al, 2002).</citsent>
<aftsection>
<nextsent>for our work, we choose to align hownet concepts to lexical entries in framenet in order to construct the english-chinese bilingual framenet.
</nextsent>
<nextsent>(dorr et al, 2002) describes technique for the construction of chinese-english verb lexicon based on hownet and an english verb database called the lcs verb database (lvd).
</nextsent>
<nextsent>they created links between chinese concepts in hownet and english verb classes in lvd using both statistics and manually constructed seed mapping?
</nextsent>
<nextsent>of thematic classes between hownet and lvd.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1090">
<title id=" N04-4008.xml">automatic construction of an english chinese bilingual framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they created links between chinese concepts in hownet and english verb classes in lvd using both statistics and manually constructed seed mapping?
</prevsent>
<prevsent>of thematic classes between hownet and lvd.
</prevsent>
</prevsection>
<citsent citstr=" C02-1162 ">
ngai et al (2002) <papid> C02-1162 </papid>employed word-vector based approach to create the alignment between wordnet and hownet classes without any manual annotation.</citsent>
<aftsection>
<nextsent>in this paper, we present fully automatic approach to create links between framenet semantic frames and hownet concepts.
</nextsent>
<nextsent>we also plan to release an on-line demonstration for the community to access the bilingual framenet we built.
</nextsent>
<nextsent>framenet and hownet are ontologies with different structures and different semantic role/relation definitions.
</nextsent>
<nextsent>framenet is collection of lexical entries grouped by frame semantics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1091">
<title id=" N07-1043.xml">an integrated approach to measuring semantic similarity between words using information available on the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, the proposed semantic similarity measure significantly improves the accuracy (f measure of 0.78) in named entity clustering task, proving the capability of the proposed measure to capture semantic similarity using web content.
</prevsent>
<prevsent>the study of semantic similarity between words has been an integral part of natural language processing and information retrieval for many years.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
semantic similarity measures are vital for various applications in natural language processing such as word sense disambiguation (resnik, 1999), language modeling (rosenfield, 1996), synonym extraction (lin, 1998<papid> P98-2127 </papid>a) and automatic thesaurus extraction (curran, 2002).<papid> W02-1029 </papid></citsent>
<aftsection>
<nextsent>pre-compiled taxonomies such as wordnet 1 andtext corpora have been used in previous work on semantic similarity (lin, 1998<papid> P98-2127 </papid>a; resnik, 1995; jiang and conrath, 1998; lin, 1998<papid> P98-2127 </papid>b).</nextsent>
<nextsent>however, semantic similarity between words change over time as new senses and associations of words are constantly created.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1094">
<title id=" N07-1043.xml">an integrated approach to measuring semantic similarity between words using information available on the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, the proposed semantic similarity measure significantly improves the accuracy (f measure of 0.78) in named entity clustering task, proving the capability of the proposed measure to capture semantic similarity using web content.
</prevsent>
<prevsent>the study of semantic similarity between words has been an integral part of natural language processing and information retrieval for many years.
</prevsent>
</prevsection>
<citsent citstr=" W02-1029 ">
semantic similarity measures are vital for various applications in natural language processing such as word sense disambiguation (resnik, 1999), language modeling (rosenfield, 1996), synonym extraction (lin, 1998<papid> P98-2127 </papid>a) and automatic thesaurus extraction (curran, 2002).<papid> W02-1029 </papid></citsent>
<aftsection>
<nextsent>pre-compiled taxonomies such as wordnet 1 andtext corpora have been used in previous work on semantic similarity (lin, 1998<papid> P98-2127 </papid>a; resnik, 1995; jiang and conrath, 1998; lin, 1998<papid> P98-2127 </papid>b).</nextsent>
<nextsent>however, semantic similarity between words change over time as new senses and associations of words are constantly created.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1101">
<title id=" N07-1043.xml">an integrated approach to measuring semantic similarity between words using information available on the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, apple is frequently associated with computers on the web but this sense of apple is not listed in the wordnet.
</prevsent>
<prevsent>maintaining an up-to-date taxonomy of all the new words and new usages of existing words is costly if not impossible.the web can be regarded as large-scale, dynamic corpus of text.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
regarding the web as live corpus has become an active research topic recently.simple, unsupervised models have shown to perform better when n-gram counts are obtained from the web rather than from large corpus (keller and lapata, 2003; <papid> J03-3005 </papid>lapata and keller, 2005).</citsent>
<aftsection>
<nextsent>resnik and smith (2003) <papid> J03-3002 </papid>extract bilingual sentences from theweb to create parallel corpora for machine trans lation.</nextsent>
<nextsent>turney (2001) defines pointwise mutual information (pmi-ir) measure using the number of hits returned by web search engine to recognize synonyms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1102">
<title id=" N07-1043.xml">an integrated approach to measuring semantic similarity between words using information available on the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>maintaining an up-to-date taxonomy of all the new words and new usages of existing words is costly if not impossible.the web can be regarded as large-scale, dynamic corpus of text.
</prevsent>
<prevsent>regarding the web as live corpus has become an active research topic recently.simple, unsupervised models have shown to perform better when n-gram counts are obtained from the web rather than from large corpus (keller and lapata, 2003; <papid> J03-3005 </papid>lapata and keller, 2005).</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
resnik and smith (2003) <papid> J03-3002 </papid>extract bilingual sentences from theweb to create parallel corpora for machine trans lation.</citsent>
<aftsection>
<nextsent>turney (2001) defines pointwise mutual information (pmi-ir) measure using the number of hits returned by web search engine to recognize synonyms.
</nextsent>
<nextsent>matsuo et. al, (2006<papid> W06-1664 </papid>b) follows similar 1http://wordnet.princeton.edu/ 340 approach to measure the similarity between word sand apply their method in graph-based word clustering algorithm.</nextsent>
<nextsent>due to the huge number of documents and thehigh growth rate of the web, it is difficult to directly analyze each individual document separately.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1103">
<title id=" N07-1043.xml">an integrated approach to measuring semantic similarity between words using information available on the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>resnik and smith (2003) <papid> J03-3002 </papid>extract bilingual sentences from theweb to create parallel corpora for machine trans lation.</prevsent>
<prevsent>turney (2001) defines pointwise mutual information (pmi-ir) measure using the number of hits returned by web search engine to recognize synonyms.</prevsent>
</prevsection>
<citsent citstr=" W06-1664 ">
matsuo et. al, (2006<papid> W06-1664 </papid>b) follows similar 1http://wordnet.princeton.edu/ 340 approach to measure the similarity between word sand apply their method in graph-based word clustering algorithm.</citsent>
<aftsection>
<nextsent>due to the huge number of documents and thehigh growth rate of the web, it is difficult to directly analyze each individual document separately.
</nextsent>
<nextsent>search engines provide an efficient interface to this vast information.
</nextsent>
<nextsent>page counts and snippets are two useful information sources provided by most web search engines.
</nextsent>
<nextsent>page count of query is the number of pages that contain the query words 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1104">
<title id=" N07-1043.xml">an integrated approach to measuring semantic similarity between words using information available on the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>snippets provide useful information about the immediate context of the query term.this paper proposes web-based semantic similarity metric which combines page counts and snippets using support vector machines.
</prevsent>
<prevsent>we extractlexico-syntactic patterns from snippets.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
for example, is y indicates there is high semantic similarity between and y. automatically extractedlexico-syntactic patterns have been successfully employed in various term extraction tasks (hearst, 1992).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>our contributions are summarized as follows: ? we propose lexico-syntactic patterns-based approach to compute semantic similarity using snippets obtained from web search engine.
</nextsent>
<nextsent>we integrate different web-based similarity scores using wordnet synsets and support vector machines to create robust semantic similarity measure.
</nextsent>
<nextsent>the integrated measure outperforms all existing web-based semantic similarity measures in benchmark dataset and named entity clustering task.
</nextsent>
<nextsent>to the best ofour knowledge, this is the first attempt to combine both wordnet synsets and web content to leverage robust semantic similarity measure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1106">
<title id=" N07-1043.xml">an integrated approach to measuring semantic similarity between words using information available on the web </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>each vector is l2 normalized and the centroidof the set of vectors is computed.
</prevsent>
<prevsent>semantic similarity between two queries is then defined as the inner product between the corresponding centro id vectors.
</prevsent>
</prevsection>
<citsent citstr=" P06-1127 ">
they do not compare their similarity measure with taxonomy based similarity measures.chen et al , (2006) <papid> P06-1127 </papid>propose web-based double 341checking model to compute semantic similarity between words.</citsent>
<aftsection>
<nextsent>for two words and q, they collect snippets for each word from web search engine.
</nextsent>
<nextsent>then they count the number of occurrences of word in the snippets for word and the number of occurrences of word in the snippets for wordp . these values are combined non-linearly to compute the similarity between and q. this method heavily depends on the search engines ranking algorithm.
</nextsent>
<nextsent>although two words and may be very similar, there is no reason to believe that one can findq in the snippets for , or vice versa.
</nextsent>
<nextsent>this observation is confirmed by the experimental results in their paper which reports 0 similarity scores for many pairs of words in the miller and charles (1998) dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1107">
<title id=" N07-1043.xml">an integrated approach to measuring semantic similarity between words using information available on the web </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 page counts-based similarity scores.
</prevsent>
<prevsent>for the rest of this paper we use the notation h(p ) to denote the page count for the query in search engine.
</prevsent>
</prevsection>
<citsent citstr=" N03-1032 ">
terra and clarke (2003) <papid> N03-1032 </papid>compare various similarity scores for measuring similarity between words in corpus.</citsent>
<aftsection>
<nextsent>we modify the traditional jac card, overlap (simpson), dice and pmi measures for the purpose of measuring similarity using page counts.
</nextsent>
<nextsent>webjaccard coefficient between words (or phrases) and q, webjaccard(p,q), is defined by, webjaccard(p,q) = { 0 if h(p q) ? h(pq) h(p )+h(q)h(pq) otherwise .(1) here, ? denotes the conjunction query and q. given the scale and noise in the web, some words might occur arbitrarily, i.e. by random chance, on some pages.
</nextsent>
<nextsent>given the scale and noise in web data, it is possible that two words man order to reduce the adverse effect due to random co-occurrences, we set 3http://www.google.com the webjaccard coefficient to zero if the page counts for the query q is less than threshold c. 4 likewise, we define web overlap coefficient, weboverlap(p,q), as, weboverlap(p,q) = { 0 if h(p q) ? h(pq) min(h(p ),h(q)) otherwise .(2)we define webdice as variant of dice coefficient.
</nextsent>
<nextsent>webdice(p,q) is defined as, webdice(p,q) = { 0 if h(p q) ? 2h(pq) h(p )+h(q) otherwise .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1112">
<title id=" N07-1043.xml">an integrated approach to measuring semantic similarity between words using information available on the web </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for each pair of names in our dataset, we measure the association between the two names using the proposed method and baselines.
</prevsent>
<prevsent>we use group-average agglomerative hierarchical clustering to cluster the names in our dataset into five clusters.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
we employed the b-cubed metric (bagga and baldwin, 1998) <papid> P98-1012 </papid>to evaluate the clustering results.</citsent>
<aftsection>
<nextsent>as summarized in table 5 the proposed method outperforms all the baselines with statistically significant (p ? 0.01 tukey hsd) score of 0.7897.
</nextsent>
<nextsent>we propose an svm-based approach to combine page counts and lexico-syntactic patterns extracted from snippets to leverage robust web-based semantic similarity measure.
</nextsent>
<nextsent>the proposed similarity measure outperforms existing web-based similarity measures and competes with models trained on wordnet.
</nextsent>
<nextsent>it requires just 2500 synonymous word-pairs, automatically extracted from wordnet synsets, for training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1113">
<title id=" N06-2008.xml">temporal classification of text and automatic document dating </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>temporal analysis has also been applied in question-answering systems (pustejovsky et al, 2004; schilder and habel, 2003; prager et al, 2003), email classification (kiritchenko et al 29 0100 200 300 400 500 600 23 7 46 24 12 17 10 19 30 7 22 3 16 18 13 35 33 31 14 17 5 6 0 100 200 300 400 500 600 23 7 46 24 12 17 10 19 30 7 22 3 16 18 13 35 33 31 14 17 5 6 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 1 164 327 490 653 816 979 1142 1305 1468 1631 1794 1957 0 500 1000 1500 2000 2500 3000 3500 4000 1 161 321 481 641 801 961 1121 1281 1441 1601 1761 1921 2081 figure 1 effects of applying the temporal periodical algorithm on time series for  january  (top) and  the  (bottom) with original series on the left and the remaining time series component after filtering on the right.
</prevsent>
<prevsent>y-axis shows frequency count and x-axis shows the day number (time).
</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
2004), aiding the precision of information retrieval results (berlanga et al, 2001), document summarisation (mani and wilson, 2000), <papid> P00-1010 </papid>time stamping of event clauses (filatova and hovy, 2001), <papid> W01-1313 </papid>temporal ordering of events (mani et al, 2003) <papid> N03-2019 </papid>and temporal reasoning from text (boguraev and ando, 2005; moldovan et al, 2005).</citsent>
<aftsection>
<nextsent>there is also large body of work on time series analysis and temporal logic in physics, economics and mathematics, providing important techniques and general background information.
</nextsent>
<nextsent>in particular, this work uses techniques adapted from seasonal auto regressive integrated moving average models (sarima).
</nextsent>
<nextsent>sarima models are class of seasonal, non-stationary temporal models based on the arima process (defined as non-stationary extension of the stationary arma model).
</nextsent>
<nextsent>non stationary arima processes are defined by: ( ) ( ) ( ) ttd zbxbb ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1114">
<title id=" N06-2008.xml">temporal classification of text and automatic document dating </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>temporal analysis has also been applied in question-answering systems (pustejovsky et al, 2004; schilder and habel, 2003; prager et al, 2003), email classification (kiritchenko et al 29 0100 200 300 400 500 600 23 7 46 24 12 17 10 19 30 7 22 3 16 18 13 35 33 31 14 17 5 6 0 100 200 300 400 500 600 23 7 46 24 12 17 10 19 30 7 22 3 16 18 13 35 33 31 14 17 5 6 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 1 164 327 490 653 816 979 1142 1305 1468 1631 1794 1957 0 500 1000 1500 2000 2500 3000 3500 4000 1 161 321 481 641 801 961 1121 1281 1441 1601 1761 1921 2081 figure 1 effects of applying the temporal periodical algorithm on time series for  january  (top) and  the  (bottom) with original series on the left and the remaining time series component after filtering on the right.
</prevsent>
<prevsent>y-axis shows frequency count and x-axis shows the day number (time).
</prevsent>
</prevsection>
<citsent citstr=" W01-1313 ">
2004), aiding the precision of information retrieval results (berlanga et al, 2001), document summarisation (mani and wilson, 2000), <papid> P00-1010 </papid>time stamping of event clauses (filatova and hovy, 2001), <papid> W01-1313 </papid>temporal ordering of events (mani et al, 2003) <papid> N03-2019 </papid>and temporal reasoning from text (boguraev and ando, 2005; moldovan et al, 2005).</citsent>
<aftsection>
<nextsent>there is also large body of work on time series analysis and temporal logic in physics, economics and mathematics, providing important techniques and general background information.
</nextsent>
<nextsent>in particular, this work uses techniques adapted from seasonal auto regressive integrated moving average models (sarima).
</nextsent>
<nextsent>sarima models are class of seasonal, non-stationary temporal models based on the arima process (defined as non-stationary extension of the stationary arma model).
</nextsent>
<nextsent>non stationary arima processes are defined by: ( ) ( ) ( ) ttd zbxbb ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1115">
<title id=" N06-2008.xml">temporal classification of text and automatic document dating </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>temporal analysis has also been applied in question-answering systems (pustejovsky et al, 2004; schilder and habel, 2003; prager et al, 2003), email classification (kiritchenko et al 29 0100 200 300 400 500 600 23 7 46 24 12 17 10 19 30 7 22 3 16 18 13 35 33 31 14 17 5 6 0 100 200 300 400 500 600 23 7 46 24 12 17 10 19 30 7 22 3 16 18 13 35 33 31 14 17 5 6 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 1 164 327 490 653 816 979 1142 1305 1468 1631 1794 1957 0 500 1000 1500 2000 2500 3000 3500 4000 1 161 321 481 641 801 961 1121 1281 1441 1601 1761 1921 2081 figure 1 effects of applying the temporal periodical algorithm on time series for  january  (top) and  the  (bottom) with original series on the left and the remaining time series component after filtering on the right.
</prevsent>
<prevsent>y-axis shows frequency count and x-axis shows the day number (time).
</prevsent>
</prevsection>
<citsent citstr=" N03-2019 ">
2004), aiding the precision of information retrieval results (berlanga et al, 2001), document summarisation (mani and wilson, 2000), <papid> P00-1010 </papid>time stamping of event clauses (filatova and hovy, 2001), <papid> W01-1313 </papid>temporal ordering of events (mani et al, 2003) <papid> N03-2019 </papid>and temporal reasoning from text (boguraev and ando, 2005; moldovan et al, 2005).</citsent>
<aftsection>
<nextsent>there is also large body of work on time series analysis and temporal logic in physics, economics and mathematics, providing important techniques and general background information.
</nextsent>
<nextsent>in particular, this work uses techniques adapted from seasonal auto regressive integrated moving average models (sarima).
</nextsent>
<nextsent>sarima models are class of seasonal, non-stationary temporal models based on the arima process (defined as non-stationary extension of the stationary arma model).
</nextsent>
<nextsent>non stationary arima processes are defined by: ( ) ( ) ( ) ttd zbxbb ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1116">
<title id=" N04-4009.xml">competitive self trained pronoun interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the result outperforms hobbs ian baseline algorithm and is only marginally inferior (2.3%) to an essentially identical, state-of-the-art supervised model trained from manually-annotated coreference corpus.
</prevsent>
<prevsent>this result leaves open the possibility that systems self-trained on very large datasets with more finely-grained features could eventually outperform supervised models that relyon manually annotated datasets.the remainder of the paper is organized as follows.
</prevsent>
</prevsection>
<citsent citstr=" N04-1037 ">
we first briefly describe the supervised system (described in more detail in kehler et al (2004)) <papid> N04-1037 </papid>to which we will compare the self-trained system.</citsent>
<aftsection>
<nextsent>both systems use the same learning algorithm and feature set; they differ with respect to whether the data they department of linguistics.
</nextsent>
<nextsent>department of computer science and engineering.are trained on is annotated by human or the algorithm itself.
</nextsent>
<nextsent>we then describe our hobbs ian baseline algorithm, and present the results of all three systems.
</nextsent>
<nextsent>the supervised model was trained using the improved iterative scaling algorithm for maximum entropy (maxent) models described by berger etal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1117">
<title id=" N04-4009.xml">competitive self trained pronoun interpretation </title>
<section> the supervised algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>number agreement: includes features to test strict match of number (e.g., singular pronoun and singular antecedent), as well as mere compatibility (e.g., singular pronoun with an antecedent of unknown number).
</prevsent>
<prevsent>these features are likewise more liberal than the number-based hard constraint mentioned above.distance: includes features pertaining to the distance between the pronoun and the potential antecedent.
</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
examples include the number of sentences between them and the hobbs distance?, that is, the number of noun groups that have to be skipped before the potential antecedent is found per the search order used by the hobbs algorithm (hobbs, 1978; ge et al, 1998).<papid> W98-1119 </papid></citsent>
<aftsection>
<nextsent>grammatical role: includes features pertaining to the syntactic position of the potential antecedent.
</nextsent>
<nextsent>examples include whether the potential antecedent appears to be the subject or object of verb, and whether the potential antecedent is embedded in prepositional phrase.
</nextsent>
<nextsent>linguistic form: includes features pertaining to the referential form of the potential antecedent,e.g., whether it is proper name, definite description, indefinite np, or pronoun.
</nextsent>
<nextsent>the values of these features ? computed from text pros error ful shallow constituent parses ? comprised the input to the learning algorithm, along with the outcome as indicated by the annotated key.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1119">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we present multilingual experiments which show that parsing with hierarchical state-splitting is fast and accurate in multiple languages and domains, even without any language-specific tuning.
</prevsent>
<prevsent>treebank parsing comprises two problems: learning, in which we must select model given tree bank, and inference, in which we must select aparse for sentence given the learned model.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
previous work has shown that high-quality unlexical ized pcfgs can be learned from treebank, either by manual annotation (klein and manning, 2003) <papid> P03-1054 </papid>or automatic state splitting (matsuzaki et al , 2005;<papid> P05-1010 </papid>petrov et al , 2006).<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>in particular, we demonstrated in petrov et al  (2006) <papid> P06-1055 </papid>that hierarchically split pcfg could exceed the accuracy of lexicalized pcfgs (collins, 1999; charniak and johnson, 2005).<papid> P05-1022 </papid></nextsent>
<nextsent>however, many questions about inference with such split pcfgs remain open.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1120">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we present multilingual experiments which show that parsing with hierarchical state-splitting is fast and accurate in multiple languages and domains, even without any language-specific tuning.
</prevsent>
<prevsent>treebank parsing comprises two problems: learning, in which we must select model given tree bank, and inference, in which we must select aparse for sentence given the learned model.
</prevsent>
</prevsection>
<citsent citstr=" P05-1010 ">
previous work has shown that high-quality unlexical ized pcfgs can be learned from treebank, either by manual annotation (klein and manning, 2003) <papid> P03-1054 </papid>or automatic state splitting (matsuzaki et al , 2005;<papid> P05-1010 </papid>petrov et al , 2006).<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>in particular, we demonstrated in petrov et al  (2006) <papid> P06-1055 </papid>that hierarchically split pcfg could exceed the accuracy of lexicalized pcfgs (collins, 1999; charniak and johnson, 2005).<papid> P05-1022 </papid></nextsent>
<nextsent>however, many questions about inference with such split pcfgs remain open.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1121">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we present multilingual experiments which show that parsing with hierarchical state-splitting is fast and accurate in multiple languages and domains, even without any language-specific tuning.
</prevsent>
<prevsent>treebank parsing comprises two problems: learning, in which we must select model given tree bank, and inference, in which we must select aparse for sentence given the learned model.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
previous work has shown that high-quality unlexical ized pcfgs can be learned from treebank, either by manual annotation (klein and manning, 2003) <papid> P03-1054 </papid>or automatic state splitting (matsuzaki et al , 2005;<papid> P05-1010 </papid>petrov et al , 2006).<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>in particular, we demonstrated in petrov et al  (2006) <papid> P06-1055 </papid>that hierarchically split pcfg could exceed the accuracy of lexicalized pcfgs (collins, 1999; charniak and johnson, 2005).<papid> P05-1022 </papid></nextsent>
<nextsent>however, many questions about inference with such split pcfgs remain open.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1124">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>treebank parsing comprises two problems: learning, in which we must select model given tree bank, and inference, in which we must select aparse for sentence given the learned model.
</prevsent>
<prevsent>previous work has shown that high-quality unlexical ized pcfgs can be learned from treebank, either by manual annotation (klein and manning, 2003) <papid> P03-1054 </papid>or automatic state splitting (matsuzaki et al , 2005;<papid> P05-1010 </papid>petrov et al , 2006).<papid> P06-1055 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
in particular, we demonstrated in petrov et al  (2006) <papid> P06-1055 </papid>that hierarchically split pcfg could exceed the accuracy of lexicalized pcfgs (collins, 1999; charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>however, many questions about inference with such split pcfgs remain open.
</nextsent>
<nextsent>in this work, we present 1.
</nextsent>
<nextsent>an effective method for pruning in split pcfgs2.
</nextsent>
<nextsent>a comparison of objective functions for inference in split pcfgs,3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1126">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>3, we present novel coarse-to-fine processing scheme for hierarchically split pcfgs.
</prevsent>
<prevsent>our method considers the splitting history of the final grammar, projecting it onto its increasingly refined prior stages.
</prevsent>
</prevsection>
<citsent citstr=" N06-1043 ">
for any projection of grammar, wegive new method for efficiently estimating the projections parameters from the source pcfg itself(rather than treebank), using techniques for infinite tree distributions (corazza and satta, 2006) <papid> N06-1043 </papid>and iterated fixpoint equations.</citsent>
<aftsection>
<nextsent>we then parse with each refinement, in sequence, much along the lines of charniak et al  (2006), <papid> N06-1022 </papid>except with much more complex and automatically derived intermediate grammars.</nextsent>
<nextsent>thresholds are automatically tuned on held out data, and the final system parses up to 100 times faster than the baseline pcfg parser, with no loss in test set accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1127">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our method considers the splitting history of the final grammar, projecting it onto its increasingly refined prior stages.
</prevsent>
<prevsent>for any projection of grammar, wegive new method for efficiently estimating the projections parameters from the source pcfg itself(rather than treebank), using techniques for infinite tree distributions (corazza and satta, 2006) <papid> N06-1043 </papid>and iterated fixpoint equations.</prevsent>
</prevsection>
<citsent citstr=" N06-1022 ">
we then parse with each refinement, in sequence, much along the lines of charniak et al  (2006), <papid> N06-1022 </papid>except with much more complex and automatically derived intermediate grammars.</citsent>
<aftsection>
<nextsent>thresholds are automatically tuned on held out data, and the final system parses up to 100 times faster than the baseline pcfg parser, with no loss in test set accuracy.
</nextsent>
<nextsent>in sec.
</nextsent>
<nextsent>4, we consider the well-known issue of inference objectives in split pcfgs.
</nextsent>
<nextsent>as in many model families (steedman, 2000; vijay-shanker and joshi, 1985), split pcfgs have derivation / parsedistinction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1129">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as in many model families (steedman, 2000; vijay-shanker and joshi, 1985), split pcfgs have derivation / parsedistinction.
</prevsent>
<prevsent>the split pcfg directly describes generative model over derivations, but evaluation is sensitive only to the coarser treebank symbols.
</prevsent>
</prevsection>
<citsent citstr=" P96-1024 ">
while the most probable parse problem is np-complete (simaan, 1992), several approximate methods exist, including n-best reranking by parse likelihood, the labeled bracket al orithm of goodman (1996), <papid> P96-1024 </papid>and variational approximation introduced in matsuzaki et al  (2005).<papid> P05-1010 </papid></citsent>
<aftsection>
<nextsent>we present experiments which explicitly minimize various evaluation risks over candidate set using samples from the split pcfg, and relate those conditions to the existing non-sampling algorithms.
</nextsent>
<nextsent>we demonstrate that n-best reranking according to likelihood is superior for exact match, and that the non-reranking methods are superior for maximizing f1.
</nextsent>
<nextsent>a specific contribution is to discuss the role of unary productions, which previous workhas glossed over, but which is important in understanding why the various methods work as they do.
</nextsent>
<nextsent>404 finally, in sec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1136">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> hierarchically split pcfgs.  </section>
<citcontext>
<prevsection>
<prevsent>in petrov et al  (2006), <papid> P06-1055 </papid>some simple smoothing is also shown to be effective.</prevsent>
<prevsent>it is interesting tonote that these grammars capture many of the structural zeros?</prevsent>
</prevsection>
<citsent citstr=" N06-1040 ">
described by mohri and roark (2006)<papid> N06-1040 </papid>and pruning rules with probability below e10 reduces the grammar size drastically without influencing parsing performance.</citsent>
<aftsection>
<nextsent>some of our methods and conclusions are relevant to all state-split grammars, such as klein and manning (2003) <papid> P03-1054 </papid>or dreyer and eisner (2006), <papid> W06-1638 </papid>while others apply most directly to the hierarchical case.</nextsent>
<nextsent>when working with large grammars, it is standard to prune the search space in some way.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1139">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> hierarchically split pcfgs.  </section>
<citcontext>
<prevsection>
<prevsent>it is interesting tonote that these grammars capture many of the structural zeros?
</prevsent>
<prevsent>described by mohri and roark (2006)<papid> N06-1040 </papid>and pruning rules with probability below e10 reduces the grammar size drastically without influencing parsing performance.</prevsent>
</prevsection>
<citsent citstr=" W06-1638 ">
some of our methods and conclusions are relevant to all state-split grammars, such as klein and manning (2003) <papid> P03-1054 </papid>or dreyer and eisner (2006), <papid> W06-1638 </papid>while others apply most directly to the hierarchical case.</citsent>
<aftsection>
<nextsent>when working with large grammars, it is standard to prune the search space in some way.
</nextsent>
<nextsent>in the case of lexicalized grammars, the un pruned chart often will not even fit in memory for long sentences.
</nextsent>
<nextsent>several proven techniques exist.
</nextsent>
<nextsent>collins (1999) combines apunctuation rule which eliminates many spans entirely, and then uses span-synchronous beams to prune in bottom-up fashion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1140">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> search.  </section>
<citcontext>
<prevsection>
<prevsent>several proven techniques exist.
</prevsent>
<prevsent>collins (1999) combines apunctuation rule which eliminates many spans entirely, and then uses span-synchronous beams to prune in bottom-up fashion.
</prevsent>
</prevsection>
<citsent citstr=" W98-1115 ">
charniak et al  (1998) <papid> W98-1115 </papid>g0 g1 g2 g3 g4 g5 g6 x-bar = = pi dt: dt-1: dt-2: the that this this 0 1 2 3 4 that 5 6 7 some some 8 9 10 11 these 12 13 the the the 14 15 the 16 a 17figure 1: hierarchical refinement proceeds top-down while projection recovers coarser grammars.</citsent>
<aftsection>
<nextsent>the top word for the first refinements of the determiner tag (dt) is shown on the right.introduces best-first parsing, in which figure-of merit prioritizes agenda processing.
</nextsent>
<nextsent>most relevant to our work is charniak and johnson (2005) <papid> P05-1022 </papid>which uses pre-parse phase to rapidly parse with very coarse, un lexicalized treebank grammar.</nextsent>
<nextsent>any item x:[i, j] with sufficiently low posterior probability inthe pre-parse triggers the pruning of its lexical variants in subsequent full parse.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1152">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> search.  </section>
<citcontext>
<prevsection>
<prevsent>3.2.1 estimating projected grammars fortunately, there is well worked-out notion of estimating grammar from an infinite distribution over trees (corazza and satta, 2006).<papid> N06-1043 </papid></prevsent>
<prevsent>in particular, we can estimate parameters for projected grammar pi(g) from the tree distribution induced by (whichcan itself be estimated in any manner).</prevsent>
</prevsection>
<citsent citstr=" J05-2002 ">
the earliest work that we are aware of on estimating models from models in this way is that of nederhof (2005),<papid> J05-2002 </papid>who considers the case of learning language models from other language models.</citsent>
<aftsection>
<nextsent>corazza and satta (2006) <papid> N06-1043 </papid>extend these methods to the case of pcfgs and tree distributions.the generalization of maximum likelihood estimation is to find the estimates for pi(g) with minimum kl divergence from the tree distribution induced by g. since pi(g) is grammar over coarser symbols, we fit pi(g) to the distribution induces over pi-projected trees: (pi(t )|g).</nextsent>
<nextsent>the proofs of the general case are given in corazza and satta (2006), <papid> N06-1043 </papid>but the resulting procedure is quite intuitive.given (fully observed) treebank, the maximum likelihood estimate for the probability of rule ? z would simply be the ratio of the count of to the count of the configuration ? z . if we wish to find the estimate which has minimum divergence to an infinite distribution (t ), we use the same formula, but the counts become expected counts: (x ? z) = ep (t )[x ? z] ep (t )[x] with unaries estimated similarly.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1155">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> search.  </section>
<citcontext>
<prevsection>
<prevsent>of course, training also gives us parameters for the grammars, but only the chain of projections is needed.
</prevsent>
<prevsent>note that the projected estimates need not 1whether or not the system has solutions depends on the parameters of the grammar.
</prevsent>
</prevsection>
<citsent citstr=" J99-1004 ">
in particular, may be improper, though the results of chi (1999) <papid> J99-1004 </papid>imply that will be proper if it is the maximum-likelihood estimate of finite treebank.(and in general will not) recover the original parameters exactly, nor would we want them to.</citsent>
<aftsection>
<nextsent>instead they take into account any smoothing, substate drift, and so on which occurred by the final grammar.starting from the base grammar, we run the projection process for each stage in the sequence, calculating pii (chained incremental projections would also be possible).
</nextsent>
<nextsent>for the remainder of the paper, except where noted otherwise, all coarser grammars?
</nextsent>
<nextsent>estimates are these reconstructions, rather than those originally learned.
</nextsent>
<nextsent>3.3 experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1167">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> objective functions for parsing.  </section>
<citcontext>
<prevsection>
<prevsent>this distribution in turn induces parse distribution (t ?|g) = (pi(t )|g) over (projected) trees with unsplit evaluation symbols, where (t ?|g) = :t ?=pi(t ) (t |g).
</prevsent>
<prevsent>we now have several choices of how to select tree given these posterior distributions over trees.
</prevsent>
</prevsection>
<citsent citstr=" W06-1666 ">
in this section, we present experiments with the various options and explicitly relate them to parse risk minimization (titov and henderson, 2006).<papid> W06-1666 </papid></citsent>
<aftsection>
<nextsent>g0 g2 g4 g6 nonterminals 98 219 498 1140 rules 3,700 19,600 126,100 531,200 no pruning 52 min 99 min 288 min 1612 min x-bar pruning 8 min 14 min 30 min 111 min c-to-f (no loss) 6 min 12 min 16 min 20 min f1 for above 64.8 85.2 89.7 91.2 c-to-f (lossy) 6 min 8 min 9 min 11 min f1 for above 64.3 84.7 89.4 91.1table 1: grammar sizes, parsing times and accuracies for hierarchically split pcfgs with and without hierarchical coarse-to fine parsing on our development set (1578 sentences with 40 orless words from section 22 of the penn treebank).
</nextsent>
<nextsent>for comparison the parser of charniak and johnson (2005) <papid> P05-1022 </papid>has an accuracy of f1=90.7 and runs in 19 min on this set.</nextsent>
<nextsent>the decision-theoretic approach to parsing wouldbe to select the parse tree which minimizes our expected loss according to our beliefs: p = argmin tp ? tt (tt |w,g)l(tp , tt ) where tt and tp are true?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1173">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> objective functions for parsing.  </section>
<citcontext>
<prevsection>
<prevsent>exact match (likelihood) has this property.
</prevsent>
<prevsent>in general, however, we can approximate the expectation with samples from (t |w,g).
</prevsent>
</prevsection>
<citsent citstr=" W06-1673 ">
the method for sampling derivations of pcfg is given in finkel et al  (2006) <papid> W06-1673 </papid>and johnson et al  (2007).<papid> N07-1018 </papid></citsent>
<aftsection>
<nextsent>it requires single inside-outside computation per sentence andis then efficient per sample.
</nextsent>
<nextsent>note that for split grammars, posterior parse sample can be drawn by sampling derivation and projecting away the substates.fig.
</nextsent>
<nextsent>2 shows the results of the following experiment.
</nextsent>
<nextsent>we constructed 10-best lists from the full grammar in sec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1174">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> objective functions for parsing.  </section>
<citcontext>
<prevsection>
<prevsent>exact match (likelihood) has this property.
</prevsent>
<prevsent>in general, however, we can approximate the expectation with samples from (t |w,g).
</prevsent>
</prevsection>
<citsent citstr=" N07-1018 ">
the method for sampling derivations of pcfg is given in finkel et al  (2006) <papid> W06-1673 </papid>and johnson et al  (2007).<papid> N07-1018 </papid></citsent>
<aftsection>
<nextsent>it requires single inside-outside computation per sentence andis then efficient per sample.
</nextsent>
<nextsent>note that for split grammars, posterior parse sample can be drawn by sampling derivation and projecting away the substates.fig.
</nextsent>
<nextsent>2 shows the results of the following experiment.
</nextsent>
<nextsent>we constructed 10-best lists from the full grammar in sec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1178">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> multilingual parsing.  </section>
<citcontext>
<prevsection>
<prevsent>2), the max-rule product algorithm consistently outperformed the other two.
</prevsent>
<prevsent>overall, the closed-form options were superior to the reranking ones, except on exact match, where the gains from correctly calculating the risk outweigh the losses from the truncation of the candidate set.
</prevsent>
</prevsection>
<citsent citstr=" P03-1056 ">
most research on parsing has focused on english and parsing performance on other languages is generally significantly lower.3 recently, there have been some attempts to adapt parsers developed for english to other languages (levy and manning,2003; <papid> P03-1056 </papid>cowan and collins, 2005).<papid> H05-1100 </papid></citsent>
<aftsection>
<nextsent>adapting lexicalized parsers to other languages in not trivial task as it requires at least the specification of head rules, and has had limited success.
</nextsent>
<nextsent>adapting unlexi calized parsers appears to be equally difficult: levy and manning (2003) <papid> P03-1056 </papid>adapt the un lexicalized parser of klein and manning (2003) <papid> P03-1054 </papid>to chinese, but even after significant efforts on choosing category splits, only modest performance gains are reported.</nextsent>
<nextsent>in contrast, automatically learned grammars like the one of matsuzaki et al  (2005)<papid> P05-1010 </papid> and petrov et al (2006) <papid> P06-1055 </papid>require treebank for training but no additional human input.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1179">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> multilingual parsing.  </section>
<citcontext>
<prevsection>
<prevsent>2), the max-rule product algorithm consistently outperformed the other two.
</prevsent>
<prevsent>overall, the closed-form options were superior to the reranking ones, except on exact match, where the gains from correctly calculating the risk outweigh the losses from the truncation of the candidate set.
</prevsent>
</prevsection>
<citsent citstr=" H05-1100 ">
most research on parsing has focused on english and parsing performance on other languages is generally significantly lower.3 recently, there have been some attempts to adapt parsers developed for english to other languages (levy and manning,2003; <papid> P03-1056 </papid>cowan and collins, 2005).<papid> H05-1100 </papid></citsent>
<aftsection>
<nextsent>adapting lexicalized parsers to other languages in not trivial task as it requires at least the specification of head rules, and has had limited success.
</nextsent>
<nextsent>adapting unlexi calized parsers appears to be equally difficult: levy and manning (2003) <papid> P03-1056 </papid>adapt the un lexicalized parser of klein and manning (2003) <papid> P03-1054 </papid>to chinese, but even after significant efforts on choosing category splits, only modest performance gains are reported.</nextsent>
<nextsent>in contrast, automatically learned grammars like the one of matsuzaki et al  (2005)<papid> P05-1010 </papid> and petrov et al (2006) <papid> P06-1055 </papid>require treebank for training but no additional human input.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1185">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> multilingual parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, automatically learned grammars like the one of matsuzaki et al  (2005)<papid> P05-1010 </papid> and petrov et al (2006) <papid> P06-1055 </papid>require treebank for training but no additional human input.</prevsent>
<prevsent>one has therefore reason to3of course, cross-linguistic comparison of results is complicated by differences in corpus annotation schemes and sizes, and differences in linguistic characteristics.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
english german chinese (marcus et al , 1993) (<papid> J93-2004 </papid>skut et al , 1997) (<papid> A97-1014 </papid>xue et al , 2002) <papid> C02-1145 </papid>tra inset section 2-21 sentences 1-18,602 articles 26-270 devset section 22 18,603-19,602 articles 1-25 testset section 23 19,603-20,602 articles 271-300 table 3: experimental setup.believe that their performance will generalize better across languages than the performance of parsers that have been hand tailored to english.</citsent>
<aftsection>
<nextsent>5.1 experiments.
</nextsent>
<nextsent>we trained models for english, chinese and german using the standard corpora and splits as shown in tab.
</nextsent>
<nextsent>3.
</nextsent>
<nextsent>we applied our model directly to each of the treebanks, without any language dependentmodifications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1186">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> multilingual parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, automatically learned grammars like the one of matsuzaki et al  (2005)<papid> P05-1010 </papid> and petrov et al (2006) <papid> P06-1055 </papid>require treebank for training but no additional human input.</prevsent>
<prevsent>one has therefore reason to3of course, cross-linguistic comparison of results is complicated by differences in corpus annotation schemes and sizes, and differences in linguistic characteristics.</prevsent>
</prevsection>
<citsent citstr=" A97-1014 ">
english german chinese (marcus et al , 1993) (<papid> J93-2004 </papid>skut et al , 1997) (<papid> A97-1014 </papid>xue et al , 2002) <papid> C02-1145 </papid>tra inset section 2-21 sentences 1-18,602 articles 26-270 devset section 22 18,603-19,602 articles 1-25 testset section 23 19,603-20,602 articles 271-300 table 3: experimental setup.believe that their performance will generalize better across languages than the performance of parsers that have been hand tailored to english.</citsent>
<aftsection>
<nextsent>5.1 experiments.
</nextsent>
<nextsent>we trained models for english, chinese and german using the standard corpora and splits as shown in tab.
</nextsent>
<nextsent>3.
</nextsent>
<nextsent>we applied our model directly to each of the treebanks, without any language dependentmodifications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1187">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> multilingual parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, automatically learned grammars like the one of matsuzaki et al  (2005)<papid> P05-1010 </papid> and petrov et al (2006) <papid> P06-1055 </papid>require treebank for training but no additional human input.</prevsent>
<prevsent>one has therefore reason to3of course, cross-linguistic comparison of results is complicated by differences in corpus annotation schemes and sizes, and differences in linguistic characteristics.</prevsent>
</prevsection>
<citsent citstr=" C02-1145 ">
english german chinese (marcus et al , 1993) (<papid> J93-2004 </papid>skut et al , 1997) (<papid> A97-1014 </papid>xue et al , 2002) <papid> C02-1145 </papid>tra inset section 2-21 sentences 1-18,602 articles 26-270 devset section 22 18,603-19,602 articles 1-25 testset section 23 19,603-20,602 articles 271-300 table 3: experimental setup.believe that their performance will generalize better across languages than the performance of parsers that have been hand tailored to english.</citsent>
<aftsection>
<nextsent>5.1 experiments.
</nextsent>
<nextsent>we trained models for english, chinese and german using the standard corpora and splits as shown in tab.
</nextsent>
<nextsent>3.
</nextsent>
<nextsent>we applied our model directly to each of the treebanks, without any language dependentmodifications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1190">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> multilingual parsing.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 corpus variation.
</prevsent>
<prevsent>related to cross language generalization is the generalization across domains for the same language.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
it is well known that model trained on the wall street journal loses significantly in performance when evaluated on the brown corpus (see gildea (2001) <papid> W01-0521 </papid>for more details and the exact setup of their experiment, which we duplicated here).</citsent>
<aftsection>
<nextsent>recently mcclosky et al  (2006) <papid> P06-1043 </papid>came to the conclusion that this performance drop is not due to over fitting the wsj data.</nextsent>
<nextsent>fig.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1191">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> multilingual parsing.  </section>
<citcontext>
<prevsection>
<prevsent>related to cross language generalization is the generalization across domains for the same language.
</prevsent>
<prevsent>it is well known that model trained on the wall street journal loses significantly in performance when evaluated on the brown corpus (see gildea (2001) <papid> W01-0521 </papid>for more details and the exact setup of their experiment, which we duplicated here).</prevsent>
</prevsection>
<citsent citstr=" P06-1043 ">
recently mcclosky et al  (2006) <papid> P06-1043 </papid>came to the conclusion that this performance drop is not due to over fitting the wsj data.</citsent>
<aftsection>
<nextsent>fig.
</nextsent>
<nextsent>4 shows the performance on the brown corpus during hierarchical training.
</nextsent>
<nextsent>while the f1 score on the wsj is rising we observe drop in performance after the 5th iteration, suggesting that some over fitting is occurring.
</nextsent>
<nextsent>410 ? 40 words all parser lp lr lp lr english charniak et al  (2005) 90.1 90.1 89.5 89.6 petrov et al  (2006) <papid> P06-1055 </papid>90.3 90.0 89.8 89.6 this paper 90.7 90.5 90.2 89.9 english (reranked) charniak et al  (2005)4 92.4 91.6 91.8 91.0 germandubey (2005) <papid> P05-1039 </papid>f1 76.3 this paper 80.8 80.7 80.1 80.1 chinese5 chiang et al  (2002) 81.1 78.8 78.0 75.2 this paper 80.8 80.7 78.8 78.5 table 4: our final test set parsing performance compared to the best previous work on english, german and chinese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1194">
<title id=" N07-1051.xml">improved inference for un lexicalized parsing </title>
<section> multilingual parsing.  </section>
<citcontext>
<prevsection>
<prevsent>4 shows the performance on the brown corpus during hierarchical training.
</prevsent>
<prevsent>while the f1 score on the wsj is rising we observe drop in performance after the 5th iteration, suggesting that some over fitting is occurring.
</prevsent>
</prevsection>
<citsent citstr=" P05-1039 ">
410 ? 40 words all parser lp lr lp lr english charniak et al  (2005) 90.1 90.1 89.5 89.6 petrov et al  (2006) <papid> P06-1055 </papid>90.3 90.0 89.8 89.6 this paper 90.7 90.5 90.2 89.9 english (reranked) charniak et al  (2005)4 92.4 91.6 91.8 91.0 germandubey (2005) <papid> P05-1039 </papid>f1 76.3 this paper 80.8 80.7 80.1 80.1 chinese5 chiang et al  (2002) 81.1 78.8 78.0 75.2 this paper 80.8 80.7 78.8 78.5 table 4: our final test set parsing performance compared to the best previous work on english, german and chinese.</citsent>
<aftsection>
<nextsent>78 80 82 84 86 grammar size 1 hierarchically split pcfgs charniak and johnson (2005) <papid> P05-1022 </papid>generative parser charniak and johnson (2005) <papid> P05-1022 </papid>reranking parser g3 g5 g6g4figure 4: parsing accuracy starts dropping after 5 training iterations on the brown corpus, while it is improving on the wsj, indicating overfitting.</nextsent>
<nextsent>the coarse-to-fine scheme presented here, in conjunction with the risk-appropriate parse selection methodology, allows fast, accurate parsing, in multiple languages and domains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1205">
<title id=" N07-1058.xml">combining lexical and grammatical features to improve readability measures for first and second language texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the reap tutoring system (heilman, et al 2006), aims to provide authentic reading materials of the appropriate difficulty level, in terms of both vocabulary and grammar, for english as second language students.
</prevsent>
<prevsent>an automatic measure of readability that incorporated both lexical and grammatical features was thus needed.
</prevsent>
</prevsection>
<citsent citstr=" P05-1065 ">
for first language (l1) learners (i.e., children learning their native tongue), reading level has been predicted using variety of techniques, based on models of students lexicon, grammatical surface features such as sentence length (flesch, 1948), or combinations of such features (schwarm and ostendorf, 2005).<papid> P05-1065 </papid></citsent>
<aftsection>
<nextsent>it was shown by collins thompson and callan (2004) that vocabulary based language modeling approach was effective at predicting the readability of grades 1 to 12 of web documents of varying length, even with high levels of noise.
</nextsent>
<nextsent>prior work on first language readability by schwarm and ostendorf (2005) <papid> P05-1065 </papid>incorporated grammatical surface features such as parse tree depth and average number of verb phrases.</nextsent>
<nextsent>this work combining grammatical and lexical features was promising, but it was not clear to what extent the grammatical features improved predictions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1207">
<title id=" N07-1058.xml">combining lexical and grammatical features to improve readability measures for first and second language texts </title>
<section> sampling |t| tokens from gis multinomial.  </section>
<citcontext>
<prevsection>
<prevsent>the choice of parser is not essential to the approach, although the accuracy of parsing does play role in successful identification of certain grammatical patterns.
</prevsent>
<prevsent>pcfg scores from the parser were also used to filter out some of the illformed text present in the test corpora.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the default training set of penn treebank (marcus et al 1993) <papid> J93-2004 </papid>was used for the parser because the domain and style of those texts actually matches fairly well with the domain and style of the texts on which reading level predictor for second language learners might be used.</citsent>
<aftsection>
<nextsent>once document is parsed, the predictor uses tgrep2 (rohde, 2005), tree structure searching tool, to identify instances of the target patterns.
</nextsent>
<nextsent>a tgrep2 pattern defines dominance, sisterhood, precedence, and other relationships between nodes in the parse tree for sentence.
</nextsent>
<nextsent>a pattern can also place constraints on the terminal symbols (e.g., words and punctuation), such that pattern might require form of the copula be?
</nextsent>
<nextsent>to exist in certain position in the construction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1208">
<title id=" N07-1058.xml">combining lexical and grammatical features to improve readability measures for first and second language texts </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>however, most languages have rich morphology by which single root form may have thousands or perhaps millions of inflected or derived forms.
</prevsent>
<prevsent>language technologies must account for morphological features in such languages or the vocabulary grows so large that it becomes unmanageable.
</prevsent>
</prevsection>
<citsent citstr=" N04-4015 ">
lee (2004), <papid> N04-4015 </papid>for example, showed that morphological analysis can improve the quality of statistical machine translation for arabic.</citsent>
<aftsection>
<nextsent>thus it seems that grammatical features could contribute even more to measures of readability for texts in other languages.
</nextsent>
<nextsent>that said, the use of grammatical features appears to play more important role in readability measures for l2 than for l1.
</nextsent>
<nextsent>when interpolated with grammar-based scores, the reduction of mean squared error over the language modeling approach for l1 was only 7%, while for l2 the reduction or squared error was 22%.
</nextsent>
<nextsent>an evaluation on corpora with less noise would likely bring out these differ 466 ences further and show grammar to be an even more important factor in second language readability.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1209">
<title id=" N06-4010.xml">factoid question answering with web mobile and speech interfaces </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>similarly, for our japanese language system we have evaluated the performance ofour approach on the ntcir-3 qac-1 task (whittaker et al, 2005c).
</prevsent>
<prevsent>although our japanese experiments were applied retrospectively, the results would have placed us in the mid-range of participating systems.
</prevsent>
</prevsection>
<citsent citstr=" W06-1907 ">
in (whittaker et al, 2006<papid> W06-1907 </papid>b) we described how our approach could be used for the rapid development of web-based qa systems in five very different languages.</citsent>
<aftsection>
<nextsent>it was shown that developer proficient with the tools, and with access to suitable training data, could build system in new language in around 10 hours.
</nextsent>
<nextsent>in (whittaker et al, 2006<papid> W06-1907 </papid>a) we evaluated the performance of the systems for four of our five languages.</nextsent>
<nextsent>we give brief summary of our approach to qa in section 2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1213">
<title id=" N06-4010.xml">factoid question answering with web mobile and speech interfaces </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this prototype is currently intended primarily as platform for further research into speech recognition and answering of questions from an acoustic modelling point-ofview (e.g. low-bandwidth, low-quality voip channel), from language modelling perspective (e.g. irregular word order in questions vs. text, and very large out-of-vocabulary problem) and also in termsof dialog modelling.
</prevsent>
<prevsent>there have been several attempts at speech interfaces to qa systems in the literature e.g.
</prevsent>
</prevsection>
<citsent citstr=" P03-2034 ">
(schofield and zheng, 2003) <papid> P03-2034 </papid>but as far as we know ours is the only system that is publicly accessible.</citsent>
<aftsection>
<nextsent>we discuss this interface in section 5.
</nextsent>
<nextsent>approach to qa the answer to question depends primarily on the question itself but also on many other factors such as the person asking the question, the location of the person, what questions the person has asked before, and so on.
</nextsent>
<nextsent>for simplicity, we choose to consider only the dependence of an answer   on the question
</nextsent>
<nextsent>. in particular, we hypothesize that the answer  .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1214">
<title id=" N03-2003.xml">getting more mileage from web text sources for conversational speech language modeling using class dependent mixtures </title>
<section> collecting text from the web.  </section>
<citcontext>
<prevsection>
<prevsent>and well actually i really havent seen her for years.we used slightly different search strategy when collecting topic-specific data.
</prevsent>
<prevsent>first we extended the baseline vocabulary with words from small in-domain training corpus (schwarm and ostendorf, 2002), and then we used n-grams with these new words in our web queries, e.g. wireless mikes like?, know that recognizer?
</prevsent>
</prevsection>
<citsent citstr=" H01-1051 ">
for meeting transcription task (morgan et al 2001).<papid> H01-1051 </papid></citsent>
<aftsection>
<nextsent>web pages returned by google mostly contained technical material related to topics similar to what was discussed in the meetings, e.g. we were inspired by the weighted countscheme...?, for our experiments we used the bellman ford algorithm...?, etc.the retrieved web pages were filtered before their content could be used for language modeling.
</nextsent>
<nextsent>first we stripped the html tags and ignored any pages with very high oov rate.
</nextsent>
<nextsent>we then piped the text througha maximum entropy sentence boundary detector (rat naparkhi, 1996) <papid> W96-0213 </papid>and performed text normalization using nsw tools (sproat et al 2001).</nextsent>
<nextsent>linear interpolation is standard approach to combining language models, where the probability of word wi given history is computed as linear combination of the corresponding n-gram probabilities from different models: p(wi|h) = ss sps(wi|h).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1215">
<title id=" N03-2003.xml">getting more mileage from web text sources for conversational speech language modeling using class dependent mixtures </title>
<section> collecting text from the web.  </section>
<citcontext>
<prevsection>
<prevsent>web pages returned by google mostly contained technical material related to topics similar to what was discussed in the meetings, e.g. we were inspired by the weighted countscheme...?, for our experiments we used the bellman ford algorithm...?, etc.the retrieved web pages were filtered before their content could be used for language modeling.
</prevsent>
<prevsent>first we stripped the html tags and ignored any pages with very high oov rate.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
we then piped the text througha maximum entropy sentence boundary detector (rat naparkhi, 1996) <papid> W96-0213 </papid>and performed text normalization using nsw tools (sproat et al 2001).</citsent>
<aftsection>
<nextsent>linear interpolation is standard approach to combining language models, where the probability of word wi given history is computed as linear combination of the corresponding n-gram probabilities from different models: p(wi|h) = ss sps(wi|h).
</nextsent>
<nextsent>depending on how much adaptation data is available it may be beneficial to estimate larger number of mixture weights (more than one per data source) in order to handle source mismatch, specifically letting the mixture weight depend on the context h. one approach is to use mixture weight corresponding to the source posterior probability s(h) = p(s|h) (weintraub et al 1996).
</nextsent>
<nextsent>here, we instead choose to let the weight vary as function of the previous word class, i.e. p(wi|h) = ? ss s(c(wi1))ps(wi|h), where classes c(wi1) are part-of-speech tags except forthe 100 most frequent words which form their own individual classes.
</nextsent>
<nextsent>such scheme can generalize across domains by tapping into the syntactic structure (pos tags), already shown to be useful for cross-domain language modeling (iyer and ostendorf, 1997), and at the same time target conversational speech since the top 100 words cover 70% of tokens in switchboard training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1217">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>however, it does havea serious drawback: the training time is often in torelably long, especially on the large corpora which are often used in nlp.
</prevsent>
<prevsent>in this paper, we present anovel and realistic method for speeding up the training time of transformation-based learner without sacricing performance.
</prevsent>
</prevsection>
<citsent citstr=" P00-1036 ">
the paper compares and contrasts the training time needed and performance achieved by our modied learner with two other systems: standard transformation-based learner, and the ica system (hepple, 2000).<papid> P00-1036 </papid></citsent>
<aftsection>
<nextsent>the results of these experiments show that our system is able to achieve signicant improvement in training time while still achieving the same performance as standard transformation-based learner.
</nextsent>
<nextsent>this is valuable contribution to systems and algorithms which utilize transformation-based learning at any part of the execution.
</nextsent>
<nextsent>much research in natural language processing has gone into the development of rule-based machine learning algorithms.
</nextsent>
<nextsent>these algorithms are attractive because they often capture the linguistic features of corpus in small and concise set of rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1219">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>much research in natural language processing has gone into the development of rule-based machine learning algorithms.
</prevsent>
<prevsent>these algorithms are attractive because they often capture the linguistic features of corpus in small and concise set of rules.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
transformation-based learning (tbl) (brill,1995) <papid> J95-4004 </papid>is one of the most successful rule-based machine learning algorithms.</citsent>
<aftsection>
<nextsent>it is exible method which is easily extended to various tasks and domains, and it has been applied to wide variety of nlp tasks, including part of speech tagging (brill,1995), <papid> J95-4004 </papid>noun phrase chunking (ramshaw and marcus, 1999), parsing (brill, 1996), phrase chunking (florian et al, 2000), <papid> W00-1304 </papid>spelling correction (mangu and brill, 1997), prepositional phrase attachment (brill and resnik, 1994), <papid> C94-2195 </papid>dialog act tagging (samuelet al, 1998), <papid> P98-2188 </papid>segmentation and message understanding (day et al, 1997).<papid> A97-1051 </papid></nextsent>
<nextsent>furthermore, transformation based learning achieves state-of-the-art performance on several tasks, and is fairly resistant to over train ing (ramshaw and marcus, 1994).<papid> W94-0111 </papid>despite its attractive features as machine learning algorithm, tbl does have serious draw back in its lengthy training time, especially on the larger-sized corpora often used in nlp tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1221">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these algorithms are attractive because they often capture the linguistic features of corpus in small and concise set of rules.
</prevsent>
<prevsent>transformation-based learning (tbl) (brill,1995) <papid> J95-4004 </papid>is one of the most successful rule-based machine learning algorithms.</prevsent>
</prevsection>
<citsent citstr=" W00-1304 ">
it is exible method which is easily extended to various tasks and domains, and it has been applied to wide variety of nlp tasks, including part of speech tagging (brill,1995), <papid> J95-4004 </papid>noun phrase chunking (ramshaw and marcus, 1999), parsing (brill, 1996), phrase chunking (florian et al, 2000), <papid> W00-1304 </papid>spelling correction (mangu and brill, 1997), prepositional phrase attachment (brill and resnik, 1994), <papid> C94-2195 </papid>dialog act tagging (samuelet al, 1998), <papid> P98-2188 </papid>segmentation and message understanding (day et al, 1997).<papid> A97-1051 </papid></citsent>
<aftsection>
<nextsent>furthermore, transformation based learning achieves state-of-the-art performance on several tasks, and is fairly resistant to over train ing (ramshaw and marcus, 1994).<papid> W94-0111 </papid>despite its attractive features as machine learning algorithm, tbl does have serious draw back in its lengthy training time, especially on the larger-sized corpora often used in nlp tasks.</nextsent>
<nextsent>for example, well-implemented transformation-based part-of-speech tagger will typically take over 38hours to nish training on 1 million word cor pus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1222">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these algorithms are attractive because they often capture the linguistic features of corpus in small and concise set of rules.
</prevsent>
<prevsent>transformation-based learning (tbl) (brill,1995) <papid> J95-4004 </papid>is one of the most successful rule-based machine learning algorithms.</prevsent>
</prevsection>
<citsent citstr=" C94-2195 ">
it is exible method which is easily extended to various tasks and domains, and it has been applied to wide variety of nlp tasks, including part of speech tagging (brill,1995), <papid> J95-4004 </papid>noun phrase chunking (ramshaw and marcus, 1999), parsing (brill, 1996), phrase chunking (florian et al, 2000), <papid> W00-1304 </papid>spelling correction (mangu and brill, 1997), prepositional phrase attachment (brill and resnik, 1994), <papid> C94-2195 </papid>dialog act tagging (samuelet al, 1998), <papid> P98-2188 </papid>segmentation and message understanding (day et al, 1997).<papid> A97-1051 </papid></citsent>
<aftsection>
<nextsent>furthermore, transformation based learning achieves state-of-the-art performance on several tasks, and is fairly resistant to over train ing (ramshaw and marcus, 1994).<papid> W94-0111 </papid>despite its attractive features as machine learning algorithm, tbl does have serious draw back in its lengthy training time, especially on the larger-sized corpora often used in nlp tasks.</nextsent>
<nextsent>for example, well-implemented transformation-based part-of-speech tagger will typically take over 38hours to nish training on 1 million word cor pus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1223">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these algorithms are attractive because they often capture the linguistic features of corpus in small and concise set of rules.
</prevsent>
<prevsent>transformation-based learning (tbl) (brill,1995) <papid> J95-4004 </papid>is one of the most successful rule-based machine learning algorithms.</prevsent>
</prevsection>
<citsent citstr=" P98-2188 ">
it is exible method which is easily extended to various tasks and domains, and it has been applied to wide variety of nlp tasks, including part of speech tagging (brill,1995), <papid> J95-4004 </papid>noun phrase chunking (ramshaw and marcus, 1999), parsing (brill, 1996), phrase chunking (florian et al, 2000), <papid> W00-1304 </papid>spelling correction (mangu and brill, 1997), prepositional phrase attachment (brill and resnik, 1994), <papid> C94-2195 </papid>dialog act tagging (samuelet al, 1998), <papid> P98-2188 </papid>segmentation and message understanding (day et al, 1997).<papid> A97-1051 </papid></citsent>
<aftsection>
<nextsent>furthermore, transformation based learning achieves state-of-the-art performance on several tasks, and is fairly resistant to over train ing (ramshaw and marcus, 1994).<papid> W94-0111 </papid>despite its attractive features as machine learning algorithm, tbl does have serious draw back in its lengthy training time, especially on the larger-sized corpora often used in nlp tasks.</nextsent>
<nextsent>for example, well-implemented transformation-based part-of-speech tagger will typically take over 38hours to nish training on 1 million word cor pus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1224">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these algorithms are attractive because they often capture the linguistic features of corpus in small and concise set of rules.
</prevsent>
<prevsent>transformation-based learning (tbl) (brill,1995) <papid> J95-4004 </papid>is one of the most successful rule-based machine learning algorithms.</prevsent>
</prevsection>
<citsent citstr=" A97-1051 ">
it is exible method which is easily extended to various tasks and domains, and it has been applied to wide variety of nlp tasks, including part of speech tagging (brill,1995), <papid> J95-4004 </papid>noun phrase chunking (ramshaw and marcus, 1999), parsing (brill, 1996), phrase chunking (florian et al, 2000), <papid> W00-1304 </papid>spelling correction (mangu and brill, 1997), prepositional phrase attachment (brill and resnik, 1994), <papid> C94-2195 </papid>dialog act tagging (samuelet al, 1998), <papid> P98-2188 </papid>segmentation and message understanding (day et al, 1997).<papid> A97-1051 </papid></citsent>
<aftsection>
<nextsent>furthermore, transformation based learning achieves state-of-the-art performance on several tasks, and is fairly resistant to over train ing (ramshaw and marcus, 1994).<papid> W94-0111 </papid>despite its attractive features as machine learning algorithm, tbl does have serious draw back in its lengthy training time, especially on the larger-sized corpora often used in nlp tasks.</nextsent>
<nextsent>for example, well-implemented transformation-based part-of-speech tagger will typically take over 38hours to nish training on 1 million word cor pus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1225">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>transformation-based learning (tbl) (brill,1995) <papid> J95-4004 </papid>is one of the most successful rule-based machine learning algorithms.</prevsent>
<prevsent>it is exible method which is easily extended to various tasks and domains, and it has been applied to wide variety of nlp tasks, including part of speech tagging (brill,1995), <papid> J95-4004 </papid>noun phrase chunking (ramshaw and marcus, 1999), parsing (brill, 1996), phrase chunking (florian et al, 2000), <papid> W00-1304 </papid>spelling correction (mangu and brill, 1997), prepositional phrase attachment (brill and resnik, 1994), <papid> C94-2195 </papid>dialog act tagging (samuelet al, 1998), <papid> P98-2188 </papid>segmentation and message understanding (day et al, 1997).<papid> A97-1051 </papid></prevsent>
</prevsection>
<citsent citstr=" W94-0111 ">
furthermore, transformation based learning achieves state-of-the-art performance on several tasks, and is fairly resistant to over train ing (ramshaw and marcus, 1994).<papid> W94-0111 </papid>despite its attractive features as machine learning algorithm, tbl does have serious draw back in its lengthy training time, especially on the larger-sized corpora often used in nlp tasks.</citsent>
<aftsection>
<nextsent>for example, well-implemented transformation-based part-of-speech tagger will typically take over 38hours to nish training on 1 million word corpus.
</nextsent>
<nextsent>this disadvantage is further exacerbated when the transformation-based learner is used as the base learner in learning algorithms such as boosting or active learning, both of which require multiple iterations of estimation and application of the base learner.
</nextsent>
<nextsent>in this paper, we present novel method which enables transformation-based learner to reduce its training time dramatically while still retaining all of its learning power.
</nextsent>
<nextsent>in addition, we will show that our method scales better with training data size.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1228">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> transformation-based learning.  </section>
<citcontext>
<prevsection>
<prevsent>the ica system was designed and tested on thetask of part-of-speech tagging, achieving an impressive reduction in training time while suering onlya small decrease inaccuracy.
</prevsent>
<prevsent>the experiments presented in section 4 include ica in the training time and performance comparisons 2 . 2.1.3 other approaches samuel (1998) proposed monte carlo approach to transformation-based learning, in which only fraction of the possible rules are randomly selected for estimation at each iteration.
</prevsent>
</prevsection>
<citsent citstr=" W99-0705 ">
the -tbl system described in lager (1999) <papid> W99-0705 </papid>attempts to cut downon training time with more ecient prolog implementation and an implementation of lazy learning.</citsent>
<aftsection>
<nextsent>the application of transformation-based learning can be considerably sped-up if the rules are compiled in nite-state transducer, as described in roche and schabes (1995).<papid> J95-2004 </papid></nextsent>
<nextsent>the approach presented here builds on the same foundation as the one in (ramshaw and marcus, 1994): <papid> W94-0111 </papid>instead of regenerating the rules each time, they are stored into memory, together with the two values good (r) and bad (r).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1229">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> transformation-based learning.  </section>
<citcontext>
<prevsection>
<prevsent>the experiments presented in section 4 include ica in the training time and performance comparisons 2 . 2.1.3 other approaches samuel (1998) proposed monte carlo approach to transformation-based learning, in which only fraction of the possible rules are randomly selected for estimation at each iteration.
</prevsent>
<prevsent>the -tbl system described in lager (1999) <papid> W99-0705 </papid>attempts to cut downon training time with more ecient prolog implementation and an implementation of lazy learning.</prevsent>
</prevsection>
<citsent citstr=" J95-2004 ">
the application of transformation-based learning can be considerably sped-up if the rules are compiled in nite-state transducer, as described in roche and schabes (1995).<papid> J95-2004 </papid></citsent>
<aftsection>
<nextsent>the approach presented here builds on the same foundation as the one in (ramshaw and marcus, 1994): <papid> W94-0111 </papid>instead of regenerating the rules each time, they are stored into memory, together with the two values good (r) and bad (r).</nextsent>
<nextsent>the following notations will be used throughout this section:  (r) = fs 2 sjp (s) = true and c[s] 6= r and r = [s]g  the samples on which the rule applies and changes them to the correct classication; therefore, good(r) = jg(r)j.  (r) = fs 2 sjp (s) = true and c[s] 6= r and c[s] = [s]g  the samples on which the rule applies and changes the classication from correct to incorrect; similarly, bad(r) = jb(r)j. given newly learned rule that is to be applied to s, the goal is to identify the rules for which at least one of the sets (r) ; (r) is modied by the application of rule b. obviously, if both sets are not modied when applying rule b, then the value of the objective function for rule remains unchanged.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1235">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the goal of this task is to assign to each word in the given sentence tag corresponding to its part of speech.
</prevsent>
<prevsent>a multitude of approaches have been proposed to solve this problem, including transformation-based learning, maximum entropy models, hidden markov models and memory-based approaches.
</prevsent>
</prevsection>
<citsent citstr=" P98-1029 ">
the data used in the experiment was selected from the penn treebank wall street journal, and is the same used by brill and wu (1998).<papid> P98-1029 </papid></citsent>
<aftsection>
<nextsent>the training set contained approximately 1m words and the test set approximately 200k words.
</nextsent>
<nextsent>table 1 presents the results of the experiment 4 . all the algorithms were trained until rule with score of 2 was reached.
</nextsent>
<nextsent>the fasttbl algorithm performs very similarly to the regular tbl, while running in an order of magnitude faster.
</nextsent>
<nextsent>the two assumptions made by the ica algorithm result in considerably less training time, but the performance is also degraded (the dierence in performance is statistically signicant, as determined by signed test,at signicance level of 0:001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1236">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>also present in table 1 are the results of training brill tagger on the same data.
</prevsent>
<prevsent>the results of this tagger are presented to provide performance comparison with widely used tagger.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
also worth mentioning is that the tagger achieved an accuracy of 96:76% when trained on the entire data 5; maximum entropy tagger (rat naparkhi, 1996) <papid> W96-0213 </papid>achieves 96:83% accuracy with the same training data/test data.</citsent>
<aftsection>
<nextsent>4 the time shown is the combined running time for both the lexical tagger and the contextual tagger.
</nextsent>
<nextsent>5 we followed the setup from brill tagger: the contextual tagger is trained only on half of the training data.
</nextsent>
<nextsent>the training time on the entire data was approximately 51 minutes.
</nextsent>
<nextsent>brill tagger regular tbl indexed tbl fasttbl ica (hepple) accuracy 96:61% 96:61% 96:61% 96:61% 96:23% running time 5879 mins, 46 secs 2286 mins, 21 secs 420 mins, 7 secs 17 mins, 21 secs 6 mins, 13 secs time ratio 0:4 1:0 5:4 131:7 367:8 table 1: pos tagging: evaluation and running times regular tbl indexed tbl fast tbl ica (hepple) accuracy 81:0% 81:0% 81:0% 77:8% running time 190 mins, 19 secs 65 mins, 50 secs 14 mins, 38 secs 4 mins, 1 sec time ratio 1:0 2:9 13 47:4 table 2: pp attachment:evaluation and running times 4.2 prepositional phrase attachment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1239">
<title id=" N01-1006.xml">transformation based learning in the fast lane </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the following example shows sentence with text chunks and part-of speech tags: [np a.p. nnp green nnp ] [advp currently rb ] [vp has ] [np 2,664,098 cd shares nns ] [adjp outstanding jj ] . the problem can be transformed into classication task.
</prevsent>
<prevsent>following ramshaw &amp; marcus  (1999) work in base noun phrase chunking, each word is assigned chunk tag corresponding to the phrase to which it belongs . the following table shows the above sentence with the assigned chunk tags: word pos tag chunk tag a.p. nnp b-np green nnp i-np currently rb b-advp has vbz b-vp 2,664,098 cd b-np shares nns i-np outstanding jj b-adjp . . othe data used in this experiment is the conll 2000 phrase chunking corpus (tjong kim sang and buchholz, 2000).
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the training corpus consists of sections 15-18 of the penn treebank (marcus et al, 1993); <papid> J93-2004 </papid>section 20 was used as the test set.</citsent>
<aftsection>
<nextsent>the chunk tags are derived from the parse tree constituents, regular tbl indexed tbl fast tbl ica (hepple) f-measure 92.30 92.30 92.30 86.20 running time 19211 mins, 40 secs 2056 mins, 4secs 137 mins, 57 secs 12 mins, 40 secs time ratio 1:0 9:3 139:2 1516:7 table 3: text chunking: evaluation and running times and the part-of-speech tags were generated by brill tagger (brill, 1995).<papid> J95-4004 </papid></nextsent>
<nextsent>all the systems are trained to completion (until all the rules are learned).table 3 shows the results of the text chunking experiments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1242">
<title id=" N03-2036.xml">a phrase based unigram model for statistical machine translation </title>
<section> phrase-based unigram model.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W99-0604 ">
various papers use phrase-based translation systems (och et al, 1999; <papid> W99-0604 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>yamada and knight, 2002) <papid> P02-1039 </papid>that have shown to improve translation quality over single-word based translation systems introduced in(brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present similar system with much simpler set of model parameters.specifically, we compute the probability of block sequence bn1 . the block sequence probability pr(bn1 ) is decomposed into conditional probabilities using the chain rule: pr(bn1 ) ? ? i=1 pr(bi|bi1) (1) = ? i=1 p?(bi|bi1) ? p(1??)(bi|bi1) ? ? i=1 p?(bi) ? p(1??)(bi|bi1) we try to find the block sequence that maximizes pr(bn1 ): bn1 = argmaxbn1 pr(b 1 ).
</nextsent>
<nextsent>the model proposed is joint 1 1 s 4 s s
</nextsent>
<nextsent>t t 2 3 figure 1: block sequence that jointly generates 4 target and source phrases.
</nextsent>
<nextsent>model as in (marcu and wong, 2002), <papid> W02-1018 </papid>since target and source phrases are generated jointly.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1243">
<title id=" N03-2036.xml">a phrase based unigram model for statistical machine translation </title>
<section> phrase-based unigram model.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W02-1018 ">
various papers use phrase-based translation systems (och et al, 1999; <papid> W99-0604 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>yamada and knight, 2002) <papid> P02-1039 </papid>that have shown to improve translation quality over single-word based translation systems introduced in(brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present similar system with much simpler set of model parameters.specifically, we compute the probability of block sequence bn1 . the block sequence probability pr(bn1 ) is decomposed into conditional probabilities using the chain rule: pr(bn1 ) ? ? i=1 pr(bi|bi1) (1) = ? i=1 p?(bi|bi1) ? p(1??)(bi|bi1) ? ? i=1 p?(bi) ? p(1??)(bi|bi1) we try to find the block sequence that maximizes pr(bn1 ): bn1 = argmaxbn1 pr(b 1 ).
</nextsent>
<nextsent>the model proposed is joint 1 1 s 4 s s
</nextsent>
<nextsent>t t 2 3 figure 1: block sequence that jointly generates 4 target and source phrases.
</nextsent>
<nextsent>model as in (marcu and wong, 2002), <papid> W02-1018 </papid>since target and source phrases are generated jointly.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1244">
<title id=" N03-2036.xml">a phrase based unigram model for statistical machine translation </title>
<section> phrase-based unigram model.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P02-1039 ">
various papers use phrase-based translation systems (och et al, 1999; <papid> W99-0604 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>yamada and knight, 2002) <papid> P02-1039 </papid>that have shown to improve translation quality over single-word based translation systems introduced in(brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present similar system with much simpler set of model parameters.specifically, we compute the probability of block sequence bn1 . the block sequence probability pr(bn1 ) is decomposed into conditional probabilities using the chain rule: pr(bn1 ) ? ? i=1 pr(bi|bi1) (1) = ? i=1 p?(bi|bi1) ? p(1??)(bi|bi1) ? ? i=1 p?(bi) ? p(1??)(bi|bi1) we try to find the block sequence that maximizes pr(bn1 ): bn1 = argmaxbn1 pr(b 1 ).
</nextsent>
<nextsent>the model proposed is joint 1 1 s 4 s s
</nextsent>
<nextsent>t t 2 3 figure 1: block sequence that jointly generates 4 target and source phrases.
</nextsent>
<nextsent>model as in (marcu and wong, 2002), <papid> W02-1018 </papid>since target and source phrases are generated jointly.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1245">
<title id=" N03-2036.xml">a phrase based unigram model for statistical machine translation </title>
<section> phrase-based unigram model.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J93-2003 ">
various papers use phrase-based translation systems (och et al, 1999; <papid> W99-0604 </papid>marcu and wong, 2002; <papid> W02-1018 </papid>yamada and knight, 2002) <papid> P02-1039 </papid>that have shown to improve translation quality over single-word based translation systems introduced in(brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>in this paper, we present similar system with much simpler set of model parameters.specifically, we compute the probability of block sequence bn1 . the block sequence probability pr(bn1 ) is decomposed into conditional probabilities using the chain rule: pr(bn1 ) ? ? i=1 pr(bi|bi1) (1) = ? i=1 p?(bi|bi1) ? p(1??)(bi|bi1) ? ? i=1 p?(bi) ? p(1??)(bi|bi1) we try to find the block sequence that maximizes pr(bn1 ): bn1 = argmaxbn1 pr(b 1 ).
</nextsent>
<nextsent>the model proposed is joint 1 1 s 4 s s
</nextsent>
<nextsent>t t 2 3 figure 1: block sequence that jointly generates 4 target and source phrases.
</nextsent>
<nextsent>model as in (marcu and wong, 2002), <papid> W02-1018 </papid>since target and source phrases are generated jointly.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1248">
<title id=" N03-2036.xml">a phrase based unigram model for statistical machine translation </title>
<section> 3 4 </section>
<citcontext>
<prevsection>
<prevsent>the right picture shows three blocks that cannot be obtain from source interval projections . computed for all blocks in the training data: we would obtain hundreds of millions of blocks.
</prevsent>
<prevsent>the blocks are restricted by an underlying word alignment.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
the word alignment is obtained from an hmm viterbi training (vo gel et al, 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>the hmm viterbi training is carried out twice with english as target language and chinese as source language and vice versa.
</nextsent>
<nextsent>we take the intersection of the two alignments as described in (och et al, 1999).<papid> W99-0604 </papid></nextsent>
<nextsent>to generate blocks from the intersection, we proceed as follows: for each source interval [j, ?], we compute the minimum target index and maximum target index i?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1253">
<title id=" N03-2036.xml">a phrase based unigram model for statistical machine translation </title>
<section> 3 4 </section>
<citcontext>
<prevsection>
<prevsent>table 1 shows the effect of the unigram threshold.
</prevsent>
<prevsent>the second column shows the number of blocks selected.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the third column reports the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>along with 95% confidence interval.</citsent>
<aftsection>
<nextsent>we use ibm 2we did not use the first 25 documents of the 105-document dry-run test set because they were used as development test set before the dry-run and were subsequently added to our training data.
</nextsent>
<nextsent>table 1: effect of the unigram threshold on the bleu score.
</nextsent>
<nextsent>the maximum phrase length is 8.
</nextsent>
<nextsent>selection # blocks bleur4n4 restriction selected ibm1 baseline 1.23m 0.11 ? 0.01 n2 4.23 0.18 ? 0.02 n3 1.22 0.18 ? 0.01 n4 0.84 0.17 ? 0.01 n5 0.65 0.17 ? 0.01 table 2: effect of the maximum phrase length on the bleu score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1254">
<title id=" N03-1014.xml">inducing history representations for broad coverage statistical parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this sequence is the parse for the phrase structure tree.
</prevsent>
<prevsent>we can then define probabilistic model of phrase structure trees by defining probabilistic model of each parser action in its parse context, and apply machine learning techniques to learn this model of parser actions.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
many statistical parsers (ratnaparkhi, 1999; collins, 1999; charniak, 2000) <papid> A00-2018 </papid>are based on history-basedmodel of parser actions.</citsent>
<aftsection>
<nextsent>in these models, the probability of each parser action is conditioned on the history of previous actions in the parse.
</nextsent>
<nextsent>but here again we are faced with an unusual situation for machine learning problems, conditioning on an unbounded amount of information.a major challenge in designing history-based statistical parser is choosing finite representation of theun bounded parse history from which the probability of thenext parser action can be accurately estimated.
</nextsent>
<nextsent>previous approaches have used hand-crafted finite set of features to represent the parse history (ratnaparkhi, 1999; collins, 1999; charniak, 2000).<papid> A00-2018 </papid></nextsent>
<nextsent>in the work presented here, we automatically induce finite set of real valued features to represent the parse history.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1263">
<title id=" N03-1014.xml">inducing history representations for broad coverage statistical parsing </title>
<section> the inductive bias on history.  </section>
<citcontext>
<prevsection>
<prevsent>thus,  top   includes nodes which are structurally local to top  . these nodes are the left-corner ancestor of top  (which is below top  on the stack), top  left-corner child (its left most child, if any), and top  most recent child (which is top #
</prevsent>
<prevsent>, if any).
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
for right-branching structures, the left-corner ancestor is the parent, conditioning on which has been found to be beneficial (johnson, 1998), <papid> J98-4004 </papid>as has conditioning on the left-corner child (roark and johnson, 1999).<papid> P99-1054 </papid></citsent>
<aftsection>
<nextsent>because these inputs include the history representations of both the left-corner ancestor and the most recent child, derivation step  always has access to the history representation from the previous derivation step $#&amp;% , and thus (by induction) any information from the entire previous derivation history could in principle be stored in the history representation.
</nextsent>
<nextsent>thus this model is making no priori hard independence assumptions, just priori soft biases.
</nextsent>
<nextsent>as mentioned above,  top   also includes top  itself,which means that the inputs to
</nextsent>
<nextsent>always include the history representation for the most recent derivation step assigned to top  . this input imposes an appropriate bias because the induced history features which are relevant to previous derivation decisions involving top  are likely to be relevant to the decision at step  as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1264">
<title id=" N03-1014.xml">inducing history representations for broad coverage statistical parsing </title>
<section> the inductive bias on history.  </section>
<citcontext>
<prevsection>
<prevsent>thus,  top   includes nodes which are structurally local to top  . these nodes are the left-corner ancestor of top  (which is below top  on the stack), top  left-corner child (its left most child, if any), and top  most recent child (which is top #
</prevsent>
<prevsent>, if any).
</prevsent>
</prevsection>
<citsent citstr=" P99-1054 ">
for right-branching structures, the left-corner ancestor is the parent, conditioning on which has been found to be beneficial (johnson, 1998), <papid> J98-4004 </papid>as has conditioning on the left-corner child (roark and johnson, 1999).<papid> P99-1054 </papid></citsent>
<aftsection>
<nextsent>because these inputs include the history representations of both the left-corner ancestor and the most recent child, derivation step  always has access to the history representation from the previous derivation step $#&amp;% , and thus (by induction) any information from the entire previous derivation history could in principle be stored in the history representation.
</nextsent>
<nextsent>thus this model is making no priori hard independence assumptions, just priori soft biases.
</nextsent>
<nextsent>as mentioned above,  top   also includes top  itself,which means that the inputs to
</nextsent>
<nextsent>always include the history representation for the most recent derivation step assigned to top  . this input imposes an appropriate bias because the induced history features which are relevant to previous derivation decisions involving top  are likely to be relevant to the decision at step  as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1265">
<title id=" N03-1014.xml">inducing history representations for broad coverage statistical parsing </title>
<section> the experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>this was done because we found that the best-first search tended to pursue large number of alternative labels for nonterminal before pursuing subsequent derivation steps, even though only the most probable labels ended up being used in the best derivations.
</prevsent>
<prevsent>we found that branching factor of 10was large enough that it had virtually no effect on the validation accuracy.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we used the penn treebank (marcus et al , 1993) <papid> J93-2004 </papid>to perform empirical experiments on this parsing model.</citsent>
<aftsection>
<nextsent>to length   40 all lr lp lr lp costa-et-al01 na na 57.8 64.9 manning&carpenter97; 77.6 79.9 na na charniak97(pcfg) 71.2 75.3 70.1 74.3 ssn-tags 83.9 84.9 83.3 84.3 ratnaparkhi99 na na 86.3 87.5 collins99 88.5 88.7 88.1 88.3 charniak00 90.1 90.1 89.6 89.5 collins00 90.1 90.4 89.6 89.9 bod01 90.8 90.6 89.7 89.7 ssn-freq
</nextsent>
<nextsent>200 88.8 89.6 88.3 89.2 ssn-freq
</nextsent>
<nextsent>20 89.3 89.9 88.8 89.5table 1: percentage labeled constituent recall and precision on the testing set.test the effects of varying vocabulary sizes on performance and tract ability, we trained three different models.
</nextsent>
<nextsent>the simplest model (ssn-tags?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1266">
<title id=" N03-1014.xml">inducing history representations for broad coverage statistical parsing </title>
<section> the experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>200 model, and 10 days for ssn-freq
</prevsent>
<prevsent>20 model (on 502mhz sun blade computer).
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
we then tested the best models for each vocabulary size on the testing set.4 standard measures of performance are shown in table 1.5 3we used publicly available tagger (ratnaparkhi, 1996) <papid> W96-0213 </papid>to provide the tags used in these experiments, rather than the hand corrected tags which come with the corpus.</citsent>
<aftsection>
<nextsent>4all the best networks had 80 hidden units.
</nextsent>
<nextsent>weight decay regularization was applied at the beginning of training but reduced to 0 by the end of training.
</nextsent>
<nextsent>training was stopped when maximum performance was reached on the validation set, using post-word beam width of 5.5all our results are computed with the evalb program following the standard criteria in (collins, 1999), and using the standard training (sections 222, 39,832 sentences), validation(section 24, 1346 sentence), and testing (section 23, 2416 sen tences) sets (collins, 1999).the top panel of table 1 lists the results for the non lexicalized model (ssn-tags) and the available results for three other models which only use part-of-speech tags as inputs, another neural network parser (costa et al , 2001), an earlier statistical left-corner parser (manning and carpenter, 1997), and pcfg (charniak, 1997).
</nextsent>
<nextsent>the ssn-tags model achieves performance which is much better than the only other broad coverage neural network parser (costa et al , 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1268">
<title id=" N03-1014.xml">inducing history representations for broad coverage statistical parsing </title>
<section> the experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the bottom panel of table 1 lists the results for the two lexicalized models (ssn-freq
</prevsent>
<prevsent>200 and ssn-freq
</prevsent>
</prevsection>
<citsent citstr=" P01-1010 ">
20) and five recent statistical parsers (ratnaparkhi, 1999; collins, 1999; charniak, 2000; <papid> A00-2018 </papid>collins, 2000; bod, 2001).<papid> P01-1010 </papid></citsent>
<aftsection>
<nextsent>on the complete testing set, the performance ofour lexicalized models is very close to the three best current parsers, which all achieve equivalent performance.
</nextsent>
<nextsent>the performance of the best current parser (collins, 2000) represents only 4% reduction in precision error and only 7% reduction in recall error over the ssnfreq
</nextsent>
<nextsent>20 model.
</nextsent>
<nextsent>the ssn parser achieves this result using much less lexical knowledge than other approaches, which all minimally use the words which occur at least 5 times, plus morphological features of the remaining words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1278">
<title id=" N03-1014.xml">inducing history representations for broad coverage statistical parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to the method proposed in this paper, another alternative to choosing finite set of features is to use kernel methods, which can handle unbounded feature sets.
</prevsent>
<prevsent>however, this causes efficiency problems.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
collins and duffy (2002) <papid> P02-1034 </papid>define kernel over parse trees and apply it to re-ranking the output of parser, but the resulting feature space is restricted by the need to compute the kernel efficiently, and the results are not as good as collins?</citsent>
<aftsection>
<nextsent>previous work on re-ranking using finite set of features (collins, 2000).
</nextsent>
<nextsent>future work could use the induced history representations from our work to define efficiently computable tree kernels.
</nextsent>
<nextsent>the only other broad coverage neural network parser(costa et al , 2001) also uses neural network architecture which is specifically designed for processing structures.
</nextsent>
<nextsent>we believe that their poor performance is due to network design which does not take into consideration the recency bias discussed in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1279">
<title id=" N04-1027.xml">the tao of chi towards effective human computer interaction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>based on the resulting findings, we spell out set of criteria which lie orthogonal to dialogue quality, but nevertheless constitute an integral part of more comprehensive view on dialogue felicity as function of dialogue quality and efficiency.
</prevsent>
<prevsent>research on dialogue systems in the past has focused on engineering the various processing stages involved in dia logical human-computer interaction (hci) - e. g., robust automatic speech recognition,intention recognition, natural language generation or speech synthesis (cf.
</prevsent>
</prevsection>
<citsent citstr=" P96-1009 ">
allen et al (1996), <papid> P96-1009 </papid>cox et al (2000) or bailly et al (2003)).</citsent>
<aftsection>
<nextsent>alongside these efforts the characteristics of computer-directedlanguage have also been examined as general phenomenon (cf.
</nextsent>
<nextsent>zoeppritz (1985), wooffitt et al (1997) or darves and oviatt (2002)).
</nextsent>
<nextsent>the flip side, i. e., computer-human interaction (chi), has received very little attention as research question by itself.
</nextsent>
<nextsent>that is not to say that natural language generation and synthesis have not made vast improvements, but rather that the nature and design of the computer as an interlocutor itself, i. e., the effects of human-directed language, have not been scrutinized as such.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1280">
<title id=" N04-1027.xml">the tao of chi towards effective human computer interaction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>looking at broad levels of distinctions for dialogue systems, e. g., that of allen et al (2001) between controlled and conversational dialogue systems, we note the singular employment of human-based different iae, i. e., the degree of the restriction of the human interactions.
</prevsent>
<prevsent>different iae stemming from the other communication partner, i. e., the computer, are not taken into account neither on practical nor on theoretical level.in the past controlled and restricted interactions between the user and the system increased recognition and understanding accuracies to level that systems became reliable enough for deployment in various real world applications, e. g., transportation or cinema information systems (aust et al, 1995; gorin et al, 1997; gallwitz et al, 1998).
</prevsent>
</prevsection>
<citsent citstr=" P02-1048 ">
todays more conversational dialogue systems, e. g., smartkom (wahlster et al, 2001) or match (johnston et al, 2002), <papid> P02-1048 </papid>are able to cope with much less predictable user utterances.</citsent>
<aftsection>
<nextsent>despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (rapp et al., 2000), robust understanding and discourse modeling techniques (johnston, 1998; <papid> P98-1102 </papid>engel, 2002; alexandersson and becker, 2001) combined with onto logical reasoning capabilities (gurevych et al, 2003; <papid> W03-0903 </papid>porzel et al, 2003).however, the usability of such conversational dialogue systems is still unsatisfactory, as shown in usability experiments with real users (beringer, 2003) that employed the promise evaluation framework described in beringer et al (2002), which offers some multimodal extent ions over the paradise framework described in walker et al (2000) . the work described herein constitutes starting point for scientific examination of the whys and where fores of the challenging results stemming from such end-to-end evaluations of conversational dialogue systems.</nextsent>
<nextsent>following brief description of the state of the art in examinations of computer-directed language, we describe new experimental paradigm, the first two studies using the paradigm and their corresponding re sults.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1281">
<title id=" N04-1027.xml">the tao of chi towards effective human computer interaction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>different iae stemming from the other communication partner, i. e., the computer, are not taken into account neither on practical nor on theoretical level.in the past controlled and restricted interactions between the user and the system increased recognition and understanding accuracies to level that systems became reliable enough for deployment in various real world applications, e. g., transportation or cinema information systems (aust et al, 1995; gorin et al, 1997; gallwitz et al, 1998).
</prevsent>
<prevsent>todays more conversational dialogue systems, e. g., smartkom (wahlster et al, 2001) or match (johnston et al, 2002), <papid> P02-1048 </papid>are able to cope with much less predictable user utterances.</prevsent>
</prevsection>
<citsent citstr=" P98-1102 ">
despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (rapp et al., 2000), robust understanding and discourse modeling techniques (johnston, 1998; <papid> P98-1102 </papid>engel, 2002; alexandersson and becker, 2001) combined with onto logical reasoning capabilities (gurevych et al, 2003; <papid> W03-0903 </papid>porzel et al, 2003).however, the usability of such conversational dialogue systems is still unsatisfactory, as shown in usability experiments with real users (beringer, 2003) that employed the promise evaluation framework described in beringer et al (2002), which offers some multimodal extent ions over the paradise framework described in walker et al (2000) . the work described herein constitutes starting point for scientific examination of the whys and where fores of the challenging results stemming from such end-to-end evaluations of conversational dialogue systems.</citsent>
<aftsection>
<nextsent>following brief description of the state of the art in examinations of computer-directed language, we describe new experimental paradigm, the first two studies using the paradigm and their corresponding results.
</nextsent>
<nextsent>concluding, we discuss the ensuing implications for the design of successful and felicitous conversational dialogue systems.
</nextsent>
<nextsent>the first studies and descriptions of the particularities of dia logical human-computer interaction, then labeled as computer talk in analogy to baby talk by zoeppritz (1985), focused - much like subsequent ones - on:  proving that regular register for humans conversing with dialogue system exists, e. g., those of krause (1992) and fraser (1993),   describing the regularities and characteristics of that register, as in kritzenberger (1992) or darves and oviatt (2002).the results of these studies clearly show that such register exists and that its regularities can be replicated and observed again and again.
</nextsent>
<nextsent>in general, this work focuses onthe question: what changes happen to human verbal behavior when they talk to computers as opposed to fellow humans?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1282">
<title id=" N04-1027.xml">the tao of chi towards effective human computer interaction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>different iae stemming from the other communication partner, i. e., the computer, are not taken into account neither on practical nor on theoretical level.in the past controlled and restricted interactions between the user and the system increased recognition and understanding accuracies to level that systems became reliable enough for deployment in various real world applications, e. g., transportation or cinema information systems (aust et al, 1995; gorin et al, 1997; gallwitz et al, 1998).
</prevsent>
<prevsent>todays more conversational dialogue systems, e. g., smartkom (wahlster et al, 2001) or match (johnston et al, 2002), <papid> P02-1048 </papid>are able to cope with much less predictable user utterances.</prevsent>
</prevsection>
<citsent citstr=" W03-0903 ">
despite the fact that in these systems recognition and processing have become extremely difficult, the reliability thereof has been pushed towards acceptable degrees by employing an array of highly sophisticated technological advances - such as dynamic lexica for multi-domain speech recognition and flexible pronunciation models (rapp et al., 2000), robust understanding and discourse modeling techniques (johnston, 1998; <papid> P98-1102 </papid>engel, 2002; alexandersson and becker, 2001) combined with onto logical reasoning capabilities (gurevych et al, 2003; <papid> W03-0903 </papid>porzel et al, 2003).however, the usability of such conversational dialogue systems is still unsatisfactory, as shown in usability experiments with real users (beringer, 2003) that employed the promise evaluation framework described in beringer et al (2002), which offers some multimodal extent ions over the paradise framework described in walker et al (2000) . the work described herein constitutes starting point for scientific examination of the whys and where fores of the challenging results stemming from such end-to-end evaluations of conversational dialogue systems.</citsent>
<aftsection>
<nextsent>following brief description of the state of the art in examinations of computer-directed language, we describe new experimental paradigm, the first two studies using the paradigm and their corresponding results.
</nextsent>
<nextsent>concluding, we discuss the ensuing implications for the design of successful and felicitous conversational dialogue systems.
</nextsent>
<nextsent>the first studies and descriptions of the particularities of dia logical human-computer interaction, then labeled as computer talk in analogy to baby talk by zoeppritz (1985), focused - much like subsequent ones - on:  proving that regular register for humans conversing with dialogue system exists, e. g., those of krause (1992) and fraser (1993),   describing the regularities and characteristics of that register, as in kritzenberger (1992) or darves and oviatt (2002).the results of these studies clearly show that such register exists and that its regularities can be replicated and observed again and again.
</nextsent>
<nextsent>in general, this work focuses onthe question: what changes happen to human verbal behavior when they talk to computers as opposed to fellow humans?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1283">
<title id=" N04-1027.xml">the tao of chi towards effective human computer interaction </title>
<section> studies on human-computer dialogues.  </section>
<citcontext>
<prevsection>
<prevsent>smartkom features speech input with prosodic analysis, gesture input via infrared camera, recognition of facial expressions and their emotional states.
</prevsent>
<prevsent>on the output side smartkom employs gesturing and speaking life-like character together with displayed generated text and multimedia graphical output.
</prevsent>
</prevsection>
<citsent citstr=" W03-0811 ">
it currently comprised nearly 50 modules running on parallel virtualmachine-based integration software called multi plat form (herzog et al, 2003).<papid> W03-0811 </papid></citsent>
<aftsection>
<nextsent>as such it is certainly among the most advanced multi-domain conversational dialogue systems.
</nextsent>
<nextsent>to the best of our knowledge, there has not been single publication reporting successful end-to-end evaluation of conversational dialogue system with naive users.
</nextsent>
<nextsent>we claim that, given the state of theart of the dialogue management of todays conversational dialogue systems, evaluation trials with naive user swill continue to uncover severe usability problems resulting in low task completion rates.1 surprisingly, this occurs despite acceptable partial evaluation results.by partial results, we understand evaluations of individual components such as concerning the word-error rate of automatic speech recognition or understanding rates as conducted by cox et al (2000) or reported in diaz-verdejo et al (2000).
</nextsent>
<nextsent>as one of the reasons for the problems thwarting task completion, beringer (2003) points at the problem of turn overtaking, which occurs when users rephrase questions or make second remark to the system, while it is still processing the first one.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1284">
<title id=" N04-1027.xml">the tao of chi towards effective human computer interaction </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>how can help you?
</prevsent>
<prevsent>after three tasks were finished (some successful some not) the assistant simulated the systems break down and entered the line by saying excuse me, something seems to have happened with our system, may assist you from here on and finishing there maining three tasks with the subjects.
</prevsent>
</prevsection>
<citsent citstr=" P97-1035 ">
the paradise framework (walker et al, 1997; <papid> P97-1035 </papid>walker et al, 2000) proposes distinct measurements for dialogue quality, dialogue efficiency and task success met rics.</citsent>
<aftsection>
<nextsent>the remaining criterion, i. e., user satisfaction, is based on question aries and interviews with the subject sand cannot be extracted (sub)automatically from log files.
</nextsent>
<nextsent>the analyses of the experiments described herein focus mainly on dialogue efficency metrics in the senseof walker et al (2000).
</nextsent>
<nextsent>as we will show below, our findings strongly suggest that felicitous dialogue is not only function of dialogue quality, but critically hinges on minimal threshold of efficiency and overall dialogue management as well.
</nextsent>
<nextsent>while these criteria lie orthogonal to the walker et al (2000) criteria for measuring dialogue quality such as recognition rates and the like, we regard them to constitute an integral part of an aggregate view on dialogue quality and efficiency, herein referred to as dialogue felicity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1285">
<title id=" N04-4006.xml">language model adaptation with map estimation and the perceptron algorithm </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>following (bacchiani and roark, 2003), we chose single mixing parameter for each model that we built, i.e. = ? for allstates in the model.
</prevsent>
<prevsent>2.2 perceptron algorithm.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
our discriminative n-gram model training approach uses the perceptron algorithm, as presented in (roark et al, 2004), which follows the general approach presented in (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>for brevity, we present the algorithm, not in full generality, but for the specific case of n-gram model training.
</nextsent>
<nextsent>the training set consists of weighted word lattices produced by the baseline recognizer, and gold-standard transcription for each of the lattices.
</nextsent>
<nextsent>following (roark et al, 2004), we use the lowest wer hypothesis in the lattice as the gold-standard, rather than the reference transcription.
</nextsent>
<nextsent>the perceptron model is linear model with kfeature weights, all of which are initial ized to 0.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1287">
<title id=" N07-1019.xml">worst case synchronous grammar rules </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it has been known since the early days of automata theory (aho and ullman, 1972) that the languages of string pairs generated by synchronous grammar can be arranged inan infinite hierarchy, with each rule size ? 4 producing languages not possible with grammars restricted to smaller rules.
</prevsent>
<prevsent>for any grammar with maximum rule size n, fairly straightforward dynamic programming strategy yields an o(nn+4) algorithm for parsing sentences of length . how ever, this is often not the best achievable complexity, and the exact bounds of the best possible algorithms are not known.
</prevsent>
</prevsection>
<citsent citstr=" H05-1101 ">
satta and peserico (2005) <papid> H05-1101 </papid>showed that permutation can be defined for any length such that tabular parsing strategies must take at least ?(n n), that is, the exponent of the algorithm is proportional to the square root of the rule length.</citsent>
<aftsection>
<nextsent>in this paper, we improve this result, showing that in the worst case the exponent grows linearly with the rule length.
</nextsent>
<nextsent>using probabilistic argument, weshow that the number of easily parsable permutations grows slowly enough that most permutations must be difficult, where by difficult we mean that the exponent in the complexity is greater than constant factor times the rule length.
</nextsent>
<nextsent>thus, not only do there exist permutations that have complexity higher than the square root case of satta and peserico (2005), <papid> H05-1101 </papid>but in fact the probability that randomly chosen permutation will have higher complexity approaches one as the rule length grows.</nextsent>
<nextsent>our approach is to first relate the problem of finding an efficient parsing algorithm to finding the tree width of graph derived from the scfg rules permutation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1289">
<title id=" N03-4001.xml">tips a trans lingual information processing system </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>the on demand smt uses an efficient dynamic programming decoder that achieves reasonable speed for translating web documents.
</prevsent>
<prevsent>morphologically rich languages like arabic (beesley, k. 1996) present significant challenges to many natural language processing applications as the one described above because word often conveys complex meanings decomposable into several morphemes (i.e. prefix, stem, suffix).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
by segmenting words into morphemes, we can improve the performance of natural language systems including machine translation (brown et al . 1993) <papid> J93-2003 </papid>and information retrieval (franz, m. and mccarley, s. 2002).</citsent>
<aftsection>
<nextsent>in this paper, we present cross-lingual english-arabic search engine combined with an on demand arabic english statistical machine translation system that relies on source language analysis for both improved search and translation.
</nextsent>
<nextsent>we developed novel statistical learning algorithms for performing arabic word segmentation (lee, y. et al 2003) into morphemes and morphological source language (arabic) analysis (lee, y. et al 2003b).
</nextsent>
<nextsent>these components improve both monolingual (arabic) search and cross-lingual (english-arabic) search and machine translation.
</nextsent>
<nextsent>in addition, the system supports either document translation or convolutional models for cross-lingual search (franz, m. and mccarley, s. 2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1290">
<title id=" N03-2012.xml">detection of agreement vs disagreement in meetings training with unlabeled data </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>our work builds on (shriberg et al, 1998), which showed that prosodic features are useful for classifying speech acts and lead to increased accuracy when combined with word based cues.
</prevsent>
<prevsent>other studies look at prediction of speech acts primarily from word-based cues, using language models or syntactic structure and discourse history (chu-carroll, 1998; reithinger and klesen, 1997).our work is informed by these studies, but departs significantly by exploring unsupervised training techniques.
</prevsent>
</prevsection>
<citsent citstr=" H01-1051 ">
our experiments are based on subset of meeting recordings collected and transcribed by icsi (morgan et al, 2001).<papid> H01-1051 </papid></citsent>
<aftsection>
<nextsent>seven meetings were segmented (automatically, but with human adjustment) into 9854 total spurts.
</nextsent>
<nextsent>we define spurt?
</nextsent>
<nextsent>as period of speech by one speaker that has no pauses of greater than one half second (shriberg et al., 2001).
</nextsent>
<nextsent>spurts are used here, rather than sentences,because our goal is to use asr outputs and unsupervised training paradigms, where hand-labeled sentence segment ations are not available.we define four categories: positive, back channel, negative, and other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1291">
<title id=" N01-1011.xml">a decision tree of bigrams is an accurate predictor of word sense </title>
<section> building feature set of bigrams.  </section>
<citcontext>
<prevsection>
<prevsent>(cressie and read, 1984) introduce the power divergence family of goodness of statistics.
</prevsent>
<prevsent>a number of well known statistics belong to this family, including the likelihood ratio statist icg 2 and pearson x 2 statistic.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
these measure the divergence of the observed (n ij ) and expected (m ij ) bigram counts, where ijis estimated based on the assumption that the component words in the bigram occur together strictly by chance: ij = i+  +j ++ given this value, 2 and 2 are calculated as: 2 = 2 i;j ij  log ij ij 2 = i;j (n ij  m ij ) 2 ij (dunning, 1993) <papid> J93-1003 </papid>argues in favor of 2 over 2, especially when dealing with very sparse and skewed data distributions.</citsent>
<aftsection>
<nextsent>however, (cressie and read, 1984) suggest that there are cases where pearson statistic is more reliable than the likelihood ratio and that one test should not always be preferred over the other.
</nextsent>
<nextsent>in light of this, (pedersen, 1996) presents fisher exact test as an alternative since it does not relyon the distributional assumptions that underly both pearson test and the likelihood ratio.
</nextsent>
<nextsent>unfortunately it is usually not clear which test is most appropriate for particular sample of data.we take the following approach, based on the observation that all tests should assign approximately thesame measure of statistical signi cance when the bigram counts in the contingency table do not violate any of the distributional assumptions that underly the goodness of statistics.
</nextsent>
<nextsent>we perform tests using 2 , 2 , and fisher exact test for each bigram.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1292">
<title id=" N01-1011.xml">a decision tree of bigrams is an accurate predictor of word sense </title>
<section> building feature set of bigrams.  </section>
<citcontext>
<prevsection>
<prevsent>thus, the maximum pointwise mutual information in given corpus will be assigned to bi grams that occur one time, and whose component words never occur outside that bigram.
</prevsent>
<prevsent>these are usually not the bigrams that prove most useful for disambiguation, yet they will dominate ranked list as determined by pointwise mutual information.
</prevsent>
</prevsection>
<citsent citstr=" J96-1001 ">
the dice coecient overcomes this limitation, and can be de ned as follows: dice(w 1 ; 2 ) = 2  11 +1 + 1+ when 11 = 1+ = +1 the value of dice(w 1 ; 2 ) will be 1 for all values 11 . when the value of n. 11 is less than either of the marginal totals (the more typical case) the rankings produced by the dice co ecient are similar to those of mutual information.the relationship between pointwise mutual information and the dice coecient is also discussed in (smadja et al, 1996).<papid> J96-1001 </papid></citsent>
<aftsection>
<nextsent>we have developed the bigram statistics package to produce ranked lists of bigrams using range of tests.
</nextsent>
<nextsent>this software is written in perl and is freely available from www.d.umn.edu/~tpederse.
</nextsent>
<nextsent>decision trees are among the most widely used machine learning algorithms.
</nextsent>
<nextsent>they perform general to speci search of feature space, adding the most informative features to tree structure as the search proceeds.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1293">
<title id=" N01-1011.xml">a decision tree of bigrams is an accurate predictor of word sense </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>a decision tree with 2 leaf nodes and 1 internal node (2/3) has the structure of decision stump.
</prevsent>
<prevsent>one of our long-term objectives is to identify coreset of features that will be useful for disambiguat ing wide class of words using both supervised and unsupervised methodologies.
</prevsent>
</prevsection>
<citsent citstr=" A00-2009 ">
we have presented an ensemble approach to word sense disambiguation (pedersen, 2000) <papid> A00-2009 </papid>where multiple naive bayesian classi ers, each based on co{ occurrence features from varying sized windows of context, is shown to perform well on the widely studied nouns interest and line.</citsent>
<aftsection>
<nextsent>while the accuracy ofthis approach was as good as any previously published results, the learned models were complex and dicult to interpret, in eect acting as very accurate black boxes.our experience has been that variations in learning algorithms are far less signi cant contributors to disambiguation accuracy than are variations inthe feature set.
</nextsent>
<nextsent>in other words, an informative feature set will result inaccurate disambiguation when used with wide range of learning algorithms, but there is no learning algorithm that can perform well given an uninformative or misleading set of features.therefore, our focus is on developing and discovering feature sets that make distinctions among wordsenses.
</nextsent>
<nextsent>our learning algorithms must not only produce accurate models, but they should also shed new light on the relationships among features and allowus to continue re ning and understanding our feature sets.
</nextsent>
<nextsent>we believe that decision trees meet these criteria.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1294">
<title id=" N01-1011.xml">a decision tree of bigrams is an accurate predictor of word sense </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a wide range of implementations are available, and they are known to be robust and accurate across range of domains.
</prevsent>
<prevsent>most important, their structure is easy to interpret and may provide insights into the relationships that exist among features and more general rules of disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P94-1020 ">
bigrams have been used as features for word sense disambiguation, particularly in the form of collocations where the ambiguous word is one component of the bigram (e.g., (bruce and wiebe, 1994), (<papid> P94-1020 </papid>ng and lee, 1996), (<papid> P96-1006 </papid>yarowsky, 1995)).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>while some of the bigrams we identify are collocations that include the word being disambiguated, there is no requirement that this be the case.decision trees have been used in supervised learning approaches to word sense disambiguation, and have fared well in number of comparative studies (e.g., (mooney, 1996), (<papid> W96-0208 </papid>pedersen and bruce, 1997)).</nextsent>
<nextsent>in the former they were used with the bag of word feature sets and in the latter they were used with mixed feature set that included the part-of-speech of neighboring words, three collocations, and the morphology of the ambiguous word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1295">
<title id=" N01-1011.xml">a decision tree of bigrams is an accurate predictor of word sense </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a wide range of implementations are available, and they are known to be robust and accurate across range of domains.
</prevsent>
<prevsent>most important, their structure is easy to interpret and may provide insights into the relationships that exist among features and more general rules of disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
bigrams have been used as features for word sense disambiguation, particularly in the form of collocations where the ambiguous word is one component of the bigram (e.g., (bruce and wiebe, 1994), (<papid> P94-1020 </papid>ng and lee, 1996), (<papid> P96-1006 </papid>yarowsky, 1995)).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>while some of the bigrams we identify are collocations that include the word being disambiguated, there is no requirement that this be the case.decision trees have been used in supervised learning approaches to word sense disambiguation, and have fared well in number of comparative studies (e.g., (mooney, 1996), (<papid> W96-0208 </papid>pedersen and bruce, 1997)).</nextsent>
<nextsent>in the former they were used with the bag of word feature sets and in the latter they were used with mixed feature set that included the part-of-speech of neighboring words, three collocations, and the morphology of the ambiguous word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1296">
<title id=" N01-1011.xml">a decision tree of bigrams is an accurate predictor of word sense </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a wide range of implementations are available, and they are known to be robust and accurate across range of domains.
</prevsent>
<prevsent>most important, their structure is easy to interpret and may provide insights into the relationships that exist among features and more general rules of disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
bigrams have been used as features for word sense disambiguation, particularly in the form of collocations where the ambiguous word is one component of the bigram (e.g., (bruce and wiebe, 1994), (<papid> P94-1020 </papid>ng and lee, 1996), (<papid> P96-1006 </papid>yarowsky, 1995)).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>while some of the bigrams we identify are collocations that include the word being disambiguated, there is no requirement that this be the case.decision trees have been used in supervised learning approaches to word sense disambiguation, and have fared well in number of comparative studies (e.g., (mooney, 1996), (<papid> W96-0208 </papid>pedersen and bruce, 1997)).</nextsent>
<nextsent>in the former they were used with the bag of word feature sets and in the latter they were used with mixed feature set that included the part-of-speech of neighboring words, three collocations, and the morphology of the ambiguous word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1297">
<title id=" N01-1011.xml">a decision tree of bigrams is an accurate predictor of word sense </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most important, their structure is easy to interpret and may provide insights into the relationships that exist among features and more general rules of disambiguation.
</prevsent>
<prevsent>bigrams have been used as features for word sense disambiguation, particularly in the form of collocations where the ambiguous word is one component of the bigram (e.g., (bruce and wiebe, 1994), (<papid> P94-1020 </papid>ng and lee, 1996), (<papid> P96-1006 </papid>yarowsky, 1995)).<papid> P95-1026 </papid></prevsent>
</prevsection>
<citsent citstr=" W96-0208 ">
while some of the bigrams we identify are collocations that include the word being disambiguated, there is no requirement that this be the case.decision trees have been used in supervised learning approaches to word sense disambiguation, and have fared well in number of comparative studies (e.g., (mooney, 1996), (<papid> W96-0208 </papid>pedersen and bruce, 1997)).</citsent>
<aftsection>
<nextsent>in the former they were used with the bag of word feature sets and in the latter they were used with mixed feature set that included the part-of-speech of neighboring words, three collocations, and the morphology of the ambiguous word.
</nextsent>
<nextsent>we believe thatthe approach in this paper is the rst time that decision trees based strictly on bigram features have been employed.
</nextsent>
<nextsent>the decision list is closely related approach thathas also been applied to word sense disambiguation (e.g., (yarowsky, 1994), (<papid> P94-1013 </papid>wilks and stevenson, 1998), (<papid> P98-2228 </papid>yarowsky, 2000)).</nextsent>
<nextsent>rather than building and traversing tree to perform disambiguation, list isemployed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1298">
<title id=" N01-1011.xml">a decision tree of bigrams is an accurate predictor of word sense </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the former they were used with the bag of word feature sets and in the latter they were used with mixed feature set that included the part-of-speech of neighboring words, three collocations, and the morphology of the ambiguous word.
</prevsent>
<prevsent>we believe thatthe approach in this paper is the rst time that decision trees based strictly on bigram features have been employed.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
the decision list is closely related approach thathas also been applied to word sense disambiguation (e.g., (yarowsky, 1994), (<papid> P94-1013 </papid>wilks and stevenson, 1998), (<papid> P98-2228 </papid>yarowsky, 2000)).</citsent>
<aftsection>
<nextsent>rather than building and traversing tree to perform disambiguation, list isemployed.
</nextsent>
<nextsent>in the general case decision list may suffer from less fragmentation during learning than decision trees; as practical matter this means that the decision list is less likely to be over{trained.
</nextsent>
<nextsent>how ever, we believe that fragmentation also re ects on the feature set used for learning.
</nextsent>
<nextsent>ours consists ofat most approximately 100 binary features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1299">
<title id=" N01-1011.xml">a decision tree of bigrams is an accurate predictor of word sense </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the former they were used with the bag of word feature sets and in the latter they were used with mixed feature set that included the part-of-speech of neighboring words, three collocations, and the morphology of the ambiguous word.
</prevsent>
<prevsent>we believe thatthe approach in this paper is the rst time that decision trees based strictly on bigram features have been employed.
</prevsent>
</prevsection>
<citsent citstr=" P98-2228 ">
the decision list is closely related approach thathas also been applied to word sense disambiguation (e.g., (yarowsky, 1994), (<papid> P94-1013 </papid>wilks and stevenson, 1998), (<papid> P98-2228 </papid>yarowsky, 2000)).</citsent>
<aftsection>
<nextsent>rather than building and traversing tree to perform disambiguation, list isemployed.
</nextsent>
<nextsent>in the general case decision list may suffer from less fragmentation during learning than decision trees; as practical matter this means that the decision list is less likely to be over{trained.
</nextsent>
<nextsent>how ever, we believe that fragmentation also re ects on the feature set used for learning.
</nextsent>
<nextsent>ours consists ofat most approximately 100 binary features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1300">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the development and application of computational models of text structure is central concern in natural language processing.
</prevsent>
<prevsent>document-level analysis of text structure is an important instance of such work.
</prevsent>
</prevsection>
<citsent citstr=" P97-1013 ">
previous research has sought to characterize texts in terms of domain-independent rhetorical elements, such as schema items (mckeown, 1985) or rhetorical relations (mann and thompson, 1988; marcu, 1997).<papid> P97-1013 </papid></citsent>
<aftsection>
<nextsent>the focus of ourwork, however, is on an equally fundamental but domain dependent dimension of the structure of text: content.
</nextsent>
<nextsent>our use of the term content?
</nextsent>
<nextsent>corresponds roughly to the notions of topic and topic change.
</nextsent>
<nextsent>we desire models that can specify, for example, that articles about earthquakes typically contain information about quake strength, location, and casualties, and that descriptions of casualties usually precede those of rescue efforts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1301">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>baseline.the success of content models in these two complementary tasks demonstrates their flexibility and effectiveness, and indicates that they are sufficiently expressive to represent important text properties.
</prevsent>
<prevsent>these observations,taken together with the fact that content models are conceptually intuitive and efficiently learn able from raw document collections, suggest that the formalism can prove useful in an even broader range of applications than wehave considered here; exploring the options is an appealing line of future research.
</prevsent>
</prevsection>
<citsent citstr=" W90-0112 ">
knowledge-rich methods models employing manual crafting of (typically complex) representations of content have generally captured one of three types of knowledge(rambow, 1990; <papid> W90-0112 </papid>kittredge et al, 1991): domain knowledge [e.g., that earthquakes have magnitudes], domain independent communication knowledge [e.g., that describing an event usually entails specifying its location]; and domain communication knowledge [e.g., that reuters earthquake reports often conclude by listing previousquakes2].</citsent>
<aftsection>
<nextsent>formalisms exemplifying each of these knowledge types are dejongs (1982) scripts, mckeowns (1985) schemas, and rambows (1990) domain-specific schemas, respectively.in contrast, because our models are based on distributional view of content, they will freely incorporate information from all three categories as long as such information is manifested as recurrent pattern.
</nextsent>
<nextsent>also, in comparison to the formalisms mentioned above, content models constitute relatively impoverished representa tion; but this actually contributes to the ease with which they can be learned, and our empirical results show that they are quite effective despite their simplicity.
</nextsent>
<nextsent>in recent work, duboue and mckeown (2003) <papid> W03-1016 </papid>proposea method for learning content planner from collection of texts together with domain-specific knowledge base, but our method applies to domains in which no such knowledge base has been supplied.</nextsent>
<nextsent>knowledge-lean approaches distributional models of content have appeared with some frequency in research on text segmentation and topic-based language modeling (hearst, 1994; <papid> P94-1002 </papid>beeferman et al, 1997; <papid> W97-0304 </papid>chen et al, 1998; florian and yarowsky, 1999; <papid> P99-1022 </papid>gildea and hofmann, 1999; 2this does not qualify as domain knowledge because it is not about earthquakes per se.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1302">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>formalisms exemplifying each of these knowledge types are dejongs (1982) scripts, mckeowns (1985) schemas, and rambows (1990) domain-specific schemas, respectively.in contrast, because our models are based on distributional view of content, they will freely incorporate information from all three categories as long as such information is manifested as recurrent pattern.
</prevsent>
<prevsent>also, in comparison to the formalisms mentioned above, content models constitute relatively impoverished representa tion; but this actually contributes to the ease with which they can be learned, and our empirical results show that they are quite effective despite their simplicity.
</prevsent>
</prevsection>
<citsent citstr=" W03-1016 ">
in recent work, duboue and mckeown (2003) <papid> W03-1016 </papid>proposea method for learning content planner from collection of texts together with domain-specific knowledge base, but our method applies to domains in which no such knowledge base has been supplied.</citsent>
<aftsection>
<nextsent>knowledge-lean approaches distributional models of content have appeared with some frequency in research on text segmentation and topic-based language modeling (hearst, 1994; <papid> P94-1002 </papid>beeferman et al, 1997; <papid> W97-0304 </papid>chen et al, 1998; florian and yarowsky, 1999; <papid> P99-1022 </papid>gildea and hofmann, 1999; 2this does not qualify as domain knowledge because it is not about earthquakes per se.</nextsent>
<nextsent>iyer and ostendorf, 1996; wu and khudanpur, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1303">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>also, in comparison to the formalisms mentioned above, content models constitute relatively impoverished representa tion; but this actually contributes to the ease with which they can be learned, and our empirical results show that they are quite effective despite their simplicity.
</prevsent>
<prevsent>in recent work, duboue and mckeown (2003) <papid> W03-1016 </papid>proposea method for learning content planner from collection of texts together with domain-specific knowledge base, but our method applies to domains in which no such knowledge base has been supplied.</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
knowledge-lean approaches distributional models of content have appeared with some frequency in research on text segmentation and topic-based language modeling (hearst, 1994; <papid> P94-1002 </papid>beeferman et al, 1997; <papid> W97-0304 </papid>chen et al, 1998; florian and yarowsky, 1999; <papid> P99-1022 </papid>gildea and hofmann, 1999; 2this does not qualify as domain knowledge because it is not about earthquakes per se.</citsent>
<aftsection>
<nextsent>iyer and ostendorf, 1996; wu and khudanpur, 2002).
</nextsent>
<nextsent>in fact, the methods we employ for learning content models are quite closely related to techniques proposed in that literature (see section 3 for more details).
</nextsent>
<nextsent>however, language-modeling research ? whose goal is to predict text probabilities ? tends to treat topic as useful auxiliary variable rather than central concern; for example, topic-based distributional information is generally interpolated with standard, non-topic-based   -gram models to improve probability estimates.
</nextsent>
<nextsent>our work, in contrast, treats content as primary entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1304">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>also, in comparison to the formalisms mentioned above, content models constitute relatively impoverished representa tion; but this actually contributes to the ease with which they can be learned, and our empirical results show that they are quite effective despite their simplicity.
</prevsent>
<prevsent>in recent work, duboue and mckeown (2003) <papid> W03-1016 </papid>proposea method for learning content planner from collection of texts together with domain-specific knowledge base, but our method applies to domains in which no such knowledge base has been supplied.</prevsent>
</prevsection>
<citsent citstr=" W97-0304 ">
knowledge-lean approaches distributional models of content have appeared with some frequency in research on text segmentation and topic-based language modeling (hearst, 1994; <papid> P94-1002 </papid>beeferman et al, 1997; <papid> W97-0304 </papid>chen et al, 1998; florian and yarowsky, 1999; <papid> P99-1022 </papid>gildea and hofmann, 1999; 2this does not qualify as domain knowledge because it is not about earthquakes per se.</citsent>
<aftsection>
<nextsent>iyer and ostendorf, 1996; wu and khudanpur, 2002).
</nextsent>
<nextsent>in fact, the methods we employ for learning content models are quite closely related to techniques proposed in that literature (see section 3 for more details).
</nextsent>
<nextsent>however, language-modeling research ? whose goal is to predict text probabilities ? tends to treat topic as useful auxiliary variable rather than central concern; for example, topic-based distributional information is generally interpolated with standard, non-topic-based   -gram models to improve probability estimates.
</nextsent>
<nextsent>our work, in contrast, treats content as primary entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1305">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>also, in comparison to the formalisms mentioned above, content models constitute relatively impoverished representa tion; but this actually contributes to the ease with which they can be learned, and our empirical results show that they are quite effective despite their simplicity.
</prevsent>
<prevsent>in recent work, duboue and mckeown (2003) <papid> W03-1016 </papid>proposea method for learning content planner from collection of texts together with domain-specific knowledge base, but our method applies to domains in which no such knowledge base has been supplied.</prevsent>
</prevsection>
<citsent citstr=" P99-1022 ">
knowledge-lean approaches distributional models of content have appeared with some frequency in research on text segmentation and topic-based language modeling (hearst, 1994; <papid> P94-1002 </papid>beeferman et al, 1997; <papid> W97-0304 </papid>chen et al, 1998; florian and yarowsky, 1999; <papid> P99-1022 </papid>gildea and hofmann, 1999; 2this does not qualify as domain knowledge because it is not about earthquakes per se.</citsent>
<aftsection>
<nextsent>iyer and ostendorf, 1996; wu and khudanpur, 2002).
</nextsent>
<nextsent>in fact, the methods we employ for learning content models are quite closely related to techniques proposed in that literature (see section 3 for more details).
</nextsent>
<nextsent>however, language-modeling research ? whose goal is to predict text probabilities ? tends to treat topic as useful auxiliary variable rather than central concern; for example, topic-based distributional information is generally interpolated with standard, non-topic-based   -gram models to improve probability estimates.
</nextsent>
<nextsent>our work, in contrast, treats content as primary entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1309">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> model construction.  </section>
<citcontext>
<prevsection>
<prevsent>0/
</prevsent>
<prevsent>21          3547698   :(+*-,.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
21   ff2    ffi 4following barzilay and lee (2003), <papid> N03-1003 </papid>proper names, numbers and dates are (temporarily) replaced with generic tokens to help ensure that clusters contain sentences describing the same event type, rather than same actual event.</citsent>
<aftsection>
<nextsent>note that the contents of the etcetera?
</nextsent>
<nextsent>cluster are ignored at this stage.
</nextsent>
<nextsent>our state-transition probability estimates arise from considering how sentences from the same article are distributed across the clusters.
</nextsent>
<nextsent>more specifically, for two clusters and  , let =      be the number of documents in which sentence from immediately precedes onefrom  , and let = 2  be the number of documents containing sentences from . then, for any two states
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1310">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> evaluation tasks.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 extractive summarization.
</prevsent>
<prevsent>content models can also be used for single-document summarization.
</prevsent>
</prevsection>
<citsent citstr=" J98-3005 ">
because ordering is not an issue in this application5, this task tests the ability of content models to adequately represent domain topics independently of whether they do well at ordering these topics.the usual strategy employed by domain-specific sum marizers is for humans to determine priori what types of information from the originating documents should be included (e.g., in stories about earthquakes, the number of victims) (radev and mckeown, 1998; <papid> J98-3005 </papid>white et al,2001).<papid> H01-1054 </papid></citsent>
<aftsection>
<nextsent>some systems avoid the need for manual analysis by learning content-selection rules from collection of articles paired with human-authored summaries,but their learning algorithms typically focus on within sentence features or very coarse structural features (such as position within paragraph) (kupiec et al, 1999).our content-model-based summarization algorithm combines the advantages of both approaches; on the one hand, it learns all required information from un-annotated document-summary pairs; on the other hand, it operates on more abstract and global level, making use of the topical structure of the entire document.
</nextsent>
<nextsent>our algorithm is trained as follows.
</nextsent>
<nextsent>given content model acquired from the full articles using the method described in section 3, we need to learn which topics (rep resented by the content models states) should appear inour summaries.
</nextsent>
<nextsent>our first step is to employ the viterbi algorithm to tag all of the summary sentences and all of the sentences from the original articles with viterbi topic label, or v-topic ? the name of the state most likely to have generated them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1311">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> evaluation tasks.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 extractive summarization.
</prevsent>
<prevsent>content models can also be used for single-document summarization.
</prevsent>
</prevsection>
<citsent citstr=" H01-1054 ">
because ordering is not an issue in this application5, this task tests the ability of content models to adequately represent domain topics independently of whether they do well at ordering these topics.the usual strategy employed by domain-specific sum marizers is for humans to determine priori what types of information from the originating documents should be included (e.g., in stories about earthquakes, the number of victims) (radev and mckeown, 1998; <papid> J98-3005 </papid>white et al,2001).<papid> H01-1054 </papid></citsent>
<aftsection>
<nextsent>some systems avoid the need for manual analysis by learning content-selection rules from collection of articles paired with human-authored summaries,but their learning algorithms typically focus on within sentence features or very coarse structural features (such as position within paragraph) (kupiec et al, 1999).our content-model-based summarization algorithm combines the advantages of both approaches; on the one hand, it learns all required information from un-annotated document-summary pairs; on the other hand, it operates on more abstract and global level, making use of the topical structure of the entire document.
</nextsent>
<nextsent>our algorithm is trained as follows.
</nextsent>
<nextsent>given content model acquired from the full articles using the method described in section 3, we need to learn which topics (rep resented by the content models states) should appear inour summaries.
</nextsent>
<nextsent>our first step is to employ the viterbi algorithm to tag all of the summary sentences and all of the sentences from the original articles with viterbi topic label, or v-topic ? the name of the state most likely to have generated them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1312">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> evaluation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 data.
</prevsent>
<prevsent>for evaluation purposes, we created corpora from five domains: earthquakes, clashes between armies and rebel groups, drug-related criminal offenses, financial reports, and summaries of aviation accidents.7 specifically, the first four collections consist of ap articles from the north american news corpus gathered via tdt-style document clustering system.
</prevsent>
</prevsection>
<citsent citstr=" W03-0418 ">
the fifth consists of narratives from the national transportation safety boards database previously employed by jones and thompson (2003) <papid> W03-0418 </papid>for event-identification experiments.</citsent>
<aftsection>
<nextsent>for each such set, 100articles were used for training content model, 100 articles for testing, and 20 for the development set used for parameter tuning.
</nextsent>
<nextsent>table 1 presents information about article length (measured in sentences, as determined by the sentence separator of reynar and ratnaparkhi (1997)), <papid> A97-1004 </papid>vocabulary size, and token/type ratio for each domain.</nextsent>
<nextsent>5.2 parameter estimation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1313">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> evaluation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the fifth consists of narratives from the national transportation safety boards database previously employed by jones and thompson (2003) <papid> W03-0418 </papid>for event-identification experiments.</prevsent>
<prevsent>for each such set, 100articles were used for training content model, 100 articles for testing, and 20 for the development set used for parameter tuning.</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
table 1 presents information about article length (measured in sentences, as determined by the sentence separator of reynar and ratnaparkhi (1997)), <papid> A97-1004 </papid>vocabulary size, and token/type ratio for each domain.</citsent>
<aftsection>
<nextsent>5.2 parameter estimation.
</nextsent>
<nextsent>our training algorithm has four free parameters: two that indirectly control the number of states in the induced content model, and two parameters for smoothing bigramprobabilities.
</nextsent>
<nextsent>all were tuned separately for each domain on the corresponding held-out development set using powells grid search (press et al, 1997).
</nextsent>
<nextsent>the parameter values were selected to optimize system performance 6if there are more than
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1314">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> evaluation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the best possible rank is 0, and the worst is  (   . an additional difficulty we encountered in setting up our evaluation is that while we wanted to compare our algorithms against lapatas (2003) state-of-the-art system, her method doesnt consider all permutations (see below), and so the rank metric cannot be computed for it.
</prevsent>
<prevsent>to compensate, we report the oso prediction rate, which measures the percentage of test cases in which the model under consideration gives highest probability to the oso from among all possible permutations; we expect that good model should predict the oso fair fraction of the time.
</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
furthermore, to provide some assessment of the quality of the predicted orderings themselves, we followlapata (2003) <papid> P03-1069 </papid>in employing ken dalls  , which is measure of how much an ordering differs from the osothe underlying assumption is that most reasonable sentence orderings should be fairly similar to it.</citsent>
<aftsection>
<nextsent>specifically, for permutation  of the sentences in an  -sentence document,     is computed as       )(       where    is the number of swaps of adjacent sentences necessary to re-arrange  into the oso.
</nextsent>
<nextsent>the metric ranges from -1 (inverse orders) to 1 (identical orders).
</nextsent>
<nextsent>8see section 5.5 for discussion of the relation between the ordering and the summarization task.
</nextsent>
<nextsent>5.3.2 results for each of the 500 unseen test texts, we exhaustively enumerated all sentence permutations and ranked them using content model from the corresponding domain.we compared our results against those of bigram language model (the baseline) and an improved version ofthe state-of-the-art probabilistic ordering method of la pata (2003), <papid> P03-1069 </papid>both trained on the same data we used.lapatas method first learns set of pairwise sentence ordering preferences based on features such as noun-verb dependencies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1317">
<title id=" N04-1015.xml">catching the drift probabilistic content models with applications to generation and summarization </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>incorporation of these models in ordering and summarization applications yields substantial improvement over previously-proposed methods.
</prevsent>
<prevsent>these results indicate that distributional approaches widely usedto model various inter-sentential phenomena can be successfully applied to capture text-level relations, empirically validating the long-standing hypothesis that word distribution patterns strongly correlate with discourse patterns within text, at least within specific domains.an important future direction lies in studying the correspondence between our domain-specific model anddomain-independent formalisms, such as rst.
</prevsent>
</prevsection>
<citsent citstr=" N03-1030 ">
by automatically annotating large corpus of texts with discourse relations via rhetorical parser (marcu, 1997;<papid> P97-1013 </papid>soricut and marcu, 2003), <papid> N03-1030 </papid>we may be able to incorporate domain-independent relationships into the transition structure of our content models.</citsent>
<aftsection>
<nextsent>this study could uncover interesting connections between domain-specific stylistic constraints and generic principles of text organization.
</nextsent>
<nextsent>in the literature, discourse is frequently modeled usinga hierarchical structure, which suggests that probabilistic context-free grammars or hierarchical hidden markov models (fine et al, 1998) may also be applied for modeling content structure.
</nextsent>
<nextsent>in the future, we plan to investigate how to bootstrap the induction of hierarchical models using labeled data derived from our content models.
</nextsent>
<nextsent>wewould also like to explore how domain-independent discourse constraints can be used to guide the construction of the hierarchical models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1318">
<title id=" N06-3006.xml">detecting emotion in speech experiments in three domains </title>
<section> completed work.  </section>
<citcontext>
<prevsection>
<prevsent>using all the features combined ? acoustic prosodic, lexical, pragmatic, and contextual ? the resulting classification accuracy was 79%, healthy 8% improvement over baseline performance and 5% improvement over the automatic acoustic-prosodic features alone.
</prevsent>
<prevsent>2.3 itspoke.
</prevsent>
</prevsection>
<citsent citstr=" N04-3002 ">
this section describes more recent research have been conducting with the university of pittsburghs intelligent tutoring spoken dialogue system (itspoke) (lit man and silliman, 2004).<papid> N04-3002 </papid></citsent>
<aftsection>
<nextsent>the goal of this research is towed spoken language technology with instructional technology in order to promote learning gains by enhancing communication richness.
</nextsent>
<nextsent>itspoke is built upon the why2-atlas tutoring back-end (vanlehn et al, 2002), text-based intelligent tutoring system designed to tutor students in the domain of qualitative physics using natural language interaction.
</nextsent>
<nextsent>several corpora have been recorded for development of itspoke, though most of the work presented here involves tutorial data between student and human tutor.
</nextsent>
<nextsent>to date, we have labeled the human human corpus for anger, frustration, and uncertainty.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1319">
<title id=" N06-2019.xml">early deletion of fillers in processing conversational speech </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>this paper evaluates the benefit of deleting fillers(e.g. you know, like) early in parsing conversational speech.
</prevsent>
</prevsection>
<citsent citstr=" N01-1016 ">
readability studies have shown that disfluencies (fillers and speech repairs) may be deleted from transcripts without compromising meaning (jones et al , 2003), and deleting repairs prior to parsing has been shown to improve its accuracy (charniak and johnson, 2001).<papid> N01-1016 </papid></citsent>
<aftsection>
<nextsent>we explore whether this strategy of early deletion is also beneficial with regard to fillers.
</nextsent>
<nextsent>reported experiments measure the effect of early deletion underin-domain and out-of-domain parser training conditions using state-of-the-art parser (charniak, 2000).<papid> A00-2018 </papid></nextsent>
<nextsent>while early deletion is found to yield only modest benefit for in-domain parsing, significant improvement is achieved for out-of-domain adap tation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1322">
<title id=" N06-2019.xml">early deletion of fillers in processing conversational speech </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>readability studies have shown that disfluencies (fillers and speech repairs) may be deleted from transcripts without compromising meaning (jones et al , 2003), and deleting repairs prior to parsing has been shown to improve its accuracy (charniak and johnson, 2001).<papid> N01-1016 </papid></prevsent>
<prevsent>we explore whether this strategy of early deletion is also beneficial with regard to fillers.</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
reported experiments measure the effect of early deletion underin-domain and out-of-domain parser training conditions using state-of-the-art parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>while early deletion is found to yield only modest benefit for in-domain parsing, significant improvement is achieved for out-of-domain adaptation.
</nextsent>
<nextsent>this suggests potentially broader role for dis fluency modeling in adapting text-based tools for processing conversational speech.
</nextsent>
<nextsent>this paper evaluates the benefit of deleting fillers early in parsing conversational speech.
</nextsent>
<nextsent>we follow ldc (2004) conventions in using the term filler to encompass broad set of vocal ized space-fillers that can introduce syntactic (and semantic) ambiguity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1326">
<title id=" N06-2019.xml">early deletion of fillers in processing conversational speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is it, like, that one readings of the first example differ in querying listener knowledge versus speaker action, while readings of the second differ in querying similarity versus exact match.
</prevsent>
<prevsent>though an engaged listener rarely has difficulty distinguishing between such alternatives, studies show that deleting disfluencies from transcripts improves readability with no reduction in reading comprehension (jones et al , 2003).the fact that disfluencies can be completely removed without compromising meaning is important.earlier work had already made this claim regarding speech repairs1 and argued that there was consequently little value in syntactically analyzing repairs or evaluating our ability to do so (charniak and johnson, 2001).<papid> N01-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" H05-1030 ">
moreover, this work showed that collateral damage to parse accuracy caused by repairs could be averted by deleting them prior to parsing, and this finding has been confirmed in subsequent studies (kahn et al , 2005; <papid> H05-1030 </papid>harper et al , 2005).</citsent>
<aftsection>
<nextsent>but whereas speech repairs have received significant attention in the parsing literature, fillers have been relatively neglected.
</nextsent>
<nextsent>while one study has shown that the presence of interject ion and parenthetical constituents in conversational speech reduces parse accuracy (engel et al , 2002), <papid> W02-1007 </papid>these constituent types are defined to cover both fluent and dis fluent speech phenomena (taylor, 1996), leaving the impact of fillers alone unclear.</nextsent>
<nextsent>in our study, dis fluency annotations (taylor, 1995) are leveraged to identify fillers precisely, and these annotations are merged with treebank syntax.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1328">
<title id=" N06-2019.xml">early deletion of fillers in processing conversational speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, this work showed that collateral damage to parse accuracy caused by repairs could be averted by deleting them prior to parsing, and this finding has been confirmed in subsequent studies (kahn et al , 2005; <papid> H05-1030 </papid>harper et al , 2005).</prevsent>
<prevsent>but whereas speech repairs have received significant attention in the parsing literature, fillers have been relatively neglected.</prevsent>
</prevsection>
<citsent citstr=" W02-1007 ">
while one study has shown that the presence of interject ion and parenthetical constituents in conversational speech reduces parse accuracy (engel et al , 2002), <papid> W02-1007 </papid>these constituent types are defined to cover both fluent and dis fluent speech phenomena (taylor, 1996), leaving the impact of fillers alone unclear.</citsent>
<aftsection>
<nextsent>in our study, dis fluency annotations (taylor, 1995) are leveraged to identify fillers precisely, and these annotations are merged with treebank syntax.
</nextsent>
<nextsent>extending the arguments of charniak and johnson with regard to repairs (2001), we argue there is little value in recovering the syntactic structure1see (core and schubert, 1999) <papid> P99-1053 </papid>for prototypical counter example that rarely occurs in practice.</nextsent>
<nextsent>73of fillers, and we relax evaluation metrics accordingly (3.2).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1329">
<title id=" N06-2019.xml">early deletion of fillers in processing conversational speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while one study has shown that the presence of interject ion and parenthetical constituents in conversational speech reduces parse accuracy (engel et al , 2002), <papid> W02-1007 </papid>these constituent types are defined to cover both fluent and dis fluent speech phenomena (taylor, 1996), leaving the impact of fillers alone unclear.</prevsent>
<prevsent>in our study, dis fluency annotations (taylor, 1995) are leveraged to identify fillers precisely, and these annotations are merged with treebank syntax.</prevsent>
</prevsection>
<citsent citstr=" P99-1053 ">
extending the arguments of charniak and johnson with regard to repairs (2001), we argue there is little value in recovering the syntactic structure1see (core and schubert, 1999) <papid> P99-1053 </papid>for prototypical counter example that rarely occurs in practice.</citsent>
<aftsection>
<nextsent>73of fillers, and we relax evaluation metrics accordingly (3.2).
</nextsent>
<nextsent>experiments performed (3.3) use state-of-the-art parser (charniak, 2000) <papid> A00-2018 </papid>to study the impact of early filler deletion under in-domain and out-of-domain (i.e. adaptation) training conditions.in terms of adaptation, there is tremendous potential in applying textual tools and training data to processing transcribed speech (e.g. machine translation, information extraction, etc.), and bleaching speech data to more closely resemble text has been shown to improve accuracy with some text-based processing tasks (rosenfeld et al , 1995).</nextsent>
<nextsent>for our study, state-of-the-art filler detector (johnson et al , 2004) is employed to delete fillers prior to parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1334">
<title id=" N06-2019.xml">early deletion of fillers in processing conversational speech </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>because fillers are annotated only in dis fluency markup, we perform an automatic tree transform to merge these two levels of annotation: each span of contiguous filler words were pruned from their corresponding tree and then reinserted at the same position under flat filler constituent, attached as highly as possible.
</prevsent>
<prevsent>transforms were achieved using tsurgeon2 and lingua::treebank3.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for our out-of-domain training condition, the parser was trained on sections 2-21 of the wall street journal (wsj) corpus (marcus et al , 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>punctuation and capitalization were removed to bleach our our textual training data to more closely resemble speech (rosenfeld et al , 1995).
</nextsent>
<nextsent>we also tried automatically changing numbers, symbols, and abbreviations in the training text to match how they wouldbe read (roark, 2002), <papid> P02-1037 </papid>but this did not improve accuracy and so is not discussed further.</nextsent>
<nextsent>3.2 evaluation metrics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1335">
<title id=" N06-2019.xml">early deletion of fillers in processing conversational speech </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for our out-of-domain training condition, the parser was trained on sections 2-21 of the wall street journal (wsj) corpus (marcus et al , 1993).<papid> J93-2004 </papid></prevsent>
<prevsent>punctuation and capitalization were removed to bleach our our textual training data to more closely resemble speech (rosenfeld et al , 1995).</prevsent>
</prevsection>
<citsent citstr=" P02-1037 ">
we also tried automatically changing numbers, symbols, and abbreviations in the training text to match how they wouldbe read (roark, 2002), <papid> P02-1037 </papid>but this did not improve accuracy and so is not discussed further.</citsent>
<aftsection>
<nextsent>3.2 evaluation metrics.
</nextsent>
<nextsent>as discussed earlier (1), charniak and johnson (2001) <papid> N01-1016 </papid>have argued that speech repairs do not 2http://nlp.stanford.edu/software/tsurgeon.shtml 3http://www.cpan.org 74 contribute to meaning and so there is little value in syntactically analyzing repairs or evaluating our ability to do so.</nextsent>
<nextsent>consequently, they relaxed standard parseval (black et al , 1991) <papid> H91-1060 </papid>to treat edited constituents like punctuation: adjacent edited constituents are merged, and the internal structure and attachment of edited constituents is not evaluated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1337">
<title id=" N06-2019.xml">early deletion of fillers in processing conversational speech </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 evaluation metrics.
</prevsent>
<prevsent>as discussed earlier (1), charniak and johnson (2001) <papid> N01-1016 </papid>have argued that speech repairs do not 2http://nlp.stanford.edu/software/tsurgeon.shtml 3http://www.cpan.org 74 contribute to meaning and so there is little value in syntactically analyzing repairs or evaluating our ability to do so.</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
consequently, they relaxed standard parseval (black et al , 1991) <papid> H91-1060 </papid>to treat edited constituents like punctuation: adjacent edited constituents are merged, and the internal structure and attachment of edited constituents is not evaluated.</citsent>
<aftsection>
<nextsent>we propose generalizing this approach to dis fluency at large, i.e. fillers as well as repairs.
</nextsent>
<nextsent>note that the details of appropriate evaluation metrics for parsed speech data is orthogonal to the parsing methods proposed here: however parsing is performed, we should avoid wasting metric attention evaluating syntax of words that do not contribute toward meaning and instead evaluate only how well such words can be identified.
</nextsent>
<nextsent>relaxed metric treatment of dis fluency was achieved via simple parameterization of the spar seval tool (harper et al , 2005).
</nextsent>
<nextsent>sparse val alsohas the added benefit of calculating dependency based evaluation alongside parse vals bracket based measure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1342">
<title id=" N06-2019.xml">early deletion of fillers in processing conversational speech </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>taken together, the two metrics provide complementary perspective in interpreting results.the trend observed across metrics and edit detection conditions shows that early deletion of system detected fillers improves parsing accuracy 5-10%.
</prevsent>
<prevsent>as seen with in-domain training, early deletion of repairs is again seen to have significant effect.
</prevsent>
</prevsection>
<citsent citstr=" P04-1005 ">
given that state-of-the-art edit detection performs at about 80% f-measure (johnson and charniak, 2004),<papid> P04-1005 </papid>much of the benefit derived here from oracle repair detection should be realizable in practice.</citsent>
<aftsection>
<nextsent>the broader conclusion we draw from these results is that dis fluency modeling has significant potential to improve text-based processing of speech data.
</nextsent>
<nextsent>while early deletion of fillers has limited benefit forin-domain parsing of speech data, it can play an important role in bleaching speech data for more accurate text-based processing.
</nextsent>
<nextsent>alternative methods of integrating detected filler information, such as parse reranking (kahn et al , 2005), <papid> H05-1030 </papid>also merit investigation.</nextsent>
<nextsent>it will also be important to evaluate the interaction with asr error and sentence boundary detection error.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1344">
<title id=" N06-2050.xml">comparing the roles of textual acoustic and spoken language features on spontaneous conversation summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>spontaneous conversations are different from broadcast news in several aspects: (1) spontaneous conversations are often less well formed linguistically, e.g., containing more speech disfluencies and false starts; (2) the distribution of important utterances in spontaneous conversations could be different from that in broadcast news, e.g., the beginning part of news often contains important information, but in conversations, information may be more evenly distributed; (3) conversations often contain discourse clues, e.g., question-answer pairs and speakers?
</prevsent>
<prevsent>information, which can be utilized to keep the summary coherent; (4) word error rates (wers) from speech recognition are usually much higher in spontaneous conversations.
</prevsent>
</prevsection>
<citsent citstr=" C04-1110 ">
previous work on spontaneous-conversation summarization has mainly focused on textual features (zechner, 2001; gurevych and strube, 2004), <papid> C04-1110 </papid>while speech-related features have not been explored for this type of speech source.</citsent>
<aftsection>
<nextsent>this paper explores and compares the effectiveness of both textual features and speech-related features.
</nextsent>
<nextsent>the experiments show that these features incrementally improve summarization performance.
</nextsent>
<nextsent>we also discuss problems (1) and (2) mentioned above.
</nextsent>
<nextsent>for (1), zechner (2001) proposes to detect and remove false starts and speech disfluencies from transcripts, in order to make the text-format summary concise and more readable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1345">
<title id=" N06-2050.xml">comparing the roles of textual acoustic and spoken language features on spontaneous conversation summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we do not discuss problem (3) and (4) in this paper.
</prevsent>
<prevsent>for problem (3), similar idea has been proposed to summarize online blogs and discussions.
</prevsent>
</prevsection>
<citsent citstr=" A00-2025 ">
problem (4) has been partially addressed by (zechner &amp; waibel, 2000); <papid> A00-2025 </papid>but it has not been studied together with acoustic features.</citsent>
<aftsection>
<nextsent>summarization still at its early stage, current research on speech summarization targets less ambitious goal: conducting extractive, single-document, generic, and surface-level-feature-based summarization.
</nextsent>
<nextsent>the pieces to be extracted could correspond to words (koumpis, 2002; hori and furui, 2003).
</nextsent>
<nextsent>the extracts could be utterances, too.
</nextsent>
<nextsent>utterance selection is useful.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1347">
<title id=" N04-1026.xml">predicting emotion in spoken dialogue from multiple knowledge sources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when actors are asked to read the same sentence with different emotions, they are restricted to conveying emotion using only acoustic and prosodic features.
</prevsent>
<prevsent>in natural interactions, however,speakers can convey emotions using other types of features, and can also combine acoustic-prosodic and other feature types.
</prevsent>
</prevsection>
<citsent citstr=" P01-1048 ">
as result of this mismatch, recent work motivated by spoken dialogue applications has started touse naturally-occurring speech to train emotion predictors (litman et al, 2001; <papid> P01-1048 </papid>lee et al, 2001; ang et al, 2002; lee et al, 2002; batliner et al, 2003; devillers etal., 2003; shafran et al, 2003), but often predicts emotions using only acoustic-prosodic features that would be automatically available to dialogue system in real-time.with noisier data and fewer features, it is not surprising that acoustic-prosodic features alone have been found to be of less predictive utility in these studies, leading spoken dialogue researchers to supplement such features with features based on other sources of information (e.g., lexical, syntactic, discourse).</citsent>
<aftsection>
<nextsent>our methodology builds on and generalizes the resultsof this prior work in spoken dialogue emotion prediction, by introducing new linguistic and contextual features, and exploring emotion prediction in the domain of naturally occurring tutoring dialogues.
</nextsent>
<nextsent>we first annotate student turns in our human-human tutoring corpus for emotion.
</nextsent>
<nextsent>we then automatically extract acoustic prosodic and other types of linguistic features from the student utterances in our corpus, and from their local and global dialogue contexts.
</nextsent>
<nextsent>we perform variety of machine learning experiments using different feature combinations to predict our emotion categorizations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1350">
<title id=" N04-1026.xml">predicting emotion in spoken dialogue from multiple knowledge sources </title>
<section> the dialogue system and corpus.  </section>
<citcontext>
<prevsection>
<prevsent>our best learned model achieves prediction accuracy of 84.75%, which is relative improvement of 44% over the baseline error.
</prevsent>
<prevsent>our results provide an empirical basis for enhancing the corresponding spoken dialogue tutoring system we are developing to automatically predict and ultimately to adapt to student model that includes emotional states.
</prevsent>
</prevsection>
<citsent citstr=" N04-3002 ">
we are currently building spoken dialogue tutorial system called itspoke (intelligent tutoring spoken dialogue system) (litman and silliman, 2004), <papid> N04-3002 </papid>with the goalof automatically predicting and adapting to student emo tions.</citsent>
<aftsection>
<nextsent>itspoke uses as its back-end?
</nextsent>
<nextsent>the text-based why2-atlas dialogue tutoring system (vanlehn et al, 2002).
</nextsent>
<nextsent>in itspoke, student types an essay answering qualitative physics problem.
</nextsent>
<nextsent>itspoke then engages the student in spoken dialogue to correct misconceptions and elicit more complete explanations, after which the student revises the essay, thereby ending the tutoring or causing another round of tutoring/essay revision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1351">
<title id=" N04-1026.xml">predicting emotion in spoken dialogue from multiple knowledge sources </title>
<section> annotating student emotion.  </section>
<citcontext>
<prevsection>
<prevsent>to analyze the reliability of our annotation scheme, we randomly selected 10 transcribed dialogues from our human-human tutoring corpus, yielding dataset of 453student turns.
</prevsent>
<prevsent>(turn boundaries were manually annotated prior to emotion annotation by paid transcriber.)the 453 turns were separately annotated by two different annotators as negative, neutral or positive, following the emotion annotation instructions described above.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
the two annotators agreed on the annotations of 385/453 turns, achieving 84.99% agreement, with kappa = 0.68.2this inter-annotator agreement exceeds that of prior studies of emotion annotation in naturally occurring speech 2     ff  (carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>p(a) is the proportion of times the annotators agree, and p(e) is the proportion of agreement expected by chance.
</nextsent>
<nextsent>(e.g., agreement of 71% and kappa of 0.47 in (ang et al., 2002), and kappa ranging between 0.32 and 0.42 in (shafran et al, 2003)).
</nextsent>
<nextsent>as in (lee et al, 2001), the machine learning experiments described below use only those 385 student turns where the two annotators agreed on an emotion label.
</nextsent>
<nextsent>of these turns, 90 were negative, 280 were neutral, and 15 were positive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1355">
<title id=" N04-1026.xml">predicting emotion in spoken dialogue from multiple knowledge sources </title>
<section> feature extraction.  </section>
<citcontext>
<prevsection>
<prevsent>lexical information has been shown to improve speech-based emotion prediction in other domains (litman et al, 2001; <papid> P01-1048 </papid>lee et al, 2002; ang et al., 2002; batliner et al, 2003; devillers et al, 2003; shafran et al, 2003), so our first non-acoustic-prosodic feature represents the transcription3 of each student turn as word occurrence vector (indicating the lexical items that are present in the turn).</prevsent>
<prevsent>the next set of non-acoustic-prosodic features are also automatically derivable from the transcribed dialogue.turn begin and end times4 are retrieved from turn boundaries, as are the decisions as to whether turn is temporal barge-in (i.e., the turn began before the prior tutor turn ended) or temporal overlap (i.e., the turn began and ended within tutor turn).</prevsent>
</prevsection>
<citsent citstr=" E03-1072 ">
these features were motivated by the use of turn position as feature for emotion prediction in (ang et al, 2002), and the fact that measures of dialogue interactivity have been shown to correlate with learning gains in tutoring (core et al, 2003).<papid> E03-1072 </papid></citsent>
<aftsection>
<nextsent>the number of words and syllables in turn provide alternative ways to quantify turn duration (litman et al, 2001).<papid> P01-1048 </papid>the last set of 6 non-acoustic-prosodic features represent additional syntactic, semantic, and dialogue information that had already been manually annotated in our transcriptions, and thus was available for use as predic tors; as future research progresses, this information might one day be computed automatically.</nextsent>
<nextsent>our transcriber labels false starts (e.g., do-dont), syntactic questions, and semantic barge-ins.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1360">
<title id=" N04-1031.xml">paraphrasing predicates from written language to spoken language using the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, the problem can be resolved by paraphrasing ues into suitable expression for spoken language (ses).
</prevsent>
<prevsent>this is new application of paraphrasing.
</prevsent>
</prevsection>
<citsent citstr=" W03-1602 ">
there are no similar attempts, although variety of applications have been discussed so far, for example question-answering (lin and pantel, 2001; hermjakob et al, 2002; duclaye and yvon, 2003) or text-simplification (inui et al, 2003).<papid> W03-1602 </papid></citsent>
<aftsection>
<nextsent>(1) written (2) spoken (3) unnatural figure 1: paraphrasing ues into ses figure 1 illustrates paraphrasing ues into ses.
</nextsent>
<nextsent>in the figure, three types of expressions are shown: (1) expressions used in written language, (2) expressions used in spoken language, and (3) unnatural expressions.
</nextsent>
<nextsent>the overlap between two circles represents expressions used both in written language and spoken language.
</nextsent>
<nextsent>ues isthe shaded portion: unnatural expressions, and expressions used only in written language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1361">
<title id=" N04-1031.xml">paraphrasing predicates from written language to spoken language using the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the reason why unnatural expressions are taken into consideration is that paraphrasing into such expressions should be avoided.in order to paraphrase ues into ses, this paper proposes method of learning paraphrase pairs in the form of ues   ses?.
</prevsent>
<prevsent>the key notion of the method is to distinguish ues and ses based on the occurrence probability in written and spoken language corpora which are automatically collected from the web.
</prevsent>
</prevsection>
<citsent citstr=" P02-1028 ">
the procedure of the method is as follows:1 (step 1) paraphrase pairs of predicates2 are learned from dictionary using method proposed by (kaji et al, 2002).<papid> P02-1028 </papid>step 2) written and spoken language corpora are automatically collected from the web.</citsent>
<aftsection>
<nextsent>(step 3) from the paraphrase pairs learned in step 1, those in the form of ues  ses?
</nextsent>
<nextsent>are selected using the corpora.
</nextsent>
<nextsent>this paper deals with only paraphrase pairs of predicates, although ues includes not only predicates but also other categories such as nouns.
</nextsent>
<nextsent>this paper is organized as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1363">
<title id=" N04-1031.xml">paraphrasing predicates from written language to spoken language using the web </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, there are few paraphrases that have exactly the same meaning, and almost all have subtle differences such as style or formality etc. such difference is called connotational difference.
</prevsent>
<prevsent>this paper addresses one of the connotationaldifferences, that is, the difference of whether an expression is suitable or unsuitable for spoken language.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
although large number of studies have been made on learning paraphrases, for example (barzilay and lee,2003), <papid> N03-1003 </papid>there are only few studies which address the con notational difference of paraphrases.</citsent>
<aftsection>
<nextsent>one of the studies is series of works by edmonds et aland inkpen et al (edmonds and hirst, 2002; <papid> J02-2001 </papid>inkpen and hirst, 2001).</nextsent>
<nextsent>edmonds et al proposed computational model which represents the connotational difference, and inkpen et al. showed that the parameters of the model can be learned from synonym dictionary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1364">
<title id=" N04-1031.xml">paraphrasing predicates from written language to spoken language using the web </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this paper addresses one of the connotationaldifferences, that is, the difference of whether an expression is suitable or unsuitable for spoken language.
</prevsent>
<prevsent>although large number of studies have been made on learning paraphrases, for example (barzilay and lee,2003), <papid> N03-1003 </papid>there are only few studies which address the con notational difference of paraphrases.</prevsent>
</prevsection>
<citsent citstr=" J02-2001 ">
one of the studies is series of works by edmonds et aland inkpen et al (edmonds and hirst, 2002; <papid> J02-2001 </papid>inkpen and hirst, 2001).</citsent>
<aftsection>
<nextsent>edmonds et al proposed computational model which represents the connotational difference, and inkpen et al. showed that the parameters of the model can be learned from synonym dictionary.
</nextsent>
<nextsent>however, it is doubtful whether the connotational difference between paraphrases is sufficiently described in such lexical resource.
</nextsent>
<nextsent>on the other hand, inui et al discussed read 1note that this paper deals with japanese.
</nextsent>
<nextsent>2a predicate is verb or an adjective.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1365">
<title id=" N04-1031.xml">paraphrasing predicates from written language to spoken language using the web </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>how ever, they focused only on syntactic paraphrases.
</prevsent>
<prevsent>this paper deals with lexical paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
there are several works that try to learn paraphrase pairs from parallel or comparable corpora (barzilay and mckeown, 2001; <papid> P01-1008 </papid>shinyama et al, 2002; barzilay and lee, 2003; <papid> N03-1003 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>in our work, paraphrase pairs are not learned from corpora but learned from dictionary.
</nextsent>
<nextsent>our corpora are neither parallel nor comparable, and are used to distinguish ues and ses.
</nextsent>
<nextsent>there are several studies that compare two corpora which have different styles, for example, written and spoken corpora or british and american english corpora, and try to find expressions unique to either of the styles (kilgarriff, 2001).
</nextsent>
<nextsent>however, those studies did not deal with paraphrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1367">
<title id=" N04-1031.xml">paraphrasing predicates from written language to spoken language using the web </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>how ever, they focused only on syntactic paraphrases.
</prevsent>
<prevsent>this paper deals with lexical paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
there are several works that try to learn paraphrase pairs from parallel or comparable corpora (barzilay and mckeown, 2001; <papid> P01-1008 </papid>shinyama et al, 2002; barzilay and lee, 2003; <papid> N03-1003 </papid>pang et al, 2003).<papid> N03-1024 </papid></citsent>
<aftsection>
<nextsent>in our work, paraphrase pairs are not learned from corpora but learned from dictionary.
</nextsent>
<nextsent>our corpora are neither parallel nor comparable, and are used to distinguish ues and ses.
</nextsent>
<nextsent>there are several studies that compare two corpora which have different styles, for example, written and spoken corpora or british and american english corpora, and try to find expressions unique to either of the styles (kilgarriff, 2001).
</nextsent>
<nextsent>however, those studies did not deal with paraphrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1368">
<title id=" N04-1031.xml">paraphrasing predicates from written language to spoken language using the web </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there are several studies that compare two corpora which have different styles, for example, written and spoken corpora or british and american english corpora, and try to find expressions unique to either of the styles (kilgarriff, 2001).
</prevsent>
<prevsent>however, those studies did not deal with paraphrases.
</prevsent>
</prevsection>
<citsent citstr=" N03-2003 ">
bulyko et al also collected spoken language corpora from the web (bulyko et al, 2003).<papid> N03-2003 </papid></citsent>
<aftsection>
<nextsent>the method of bulyko et al used n-grams in training corpus and is different from ours (the detail of our method is described in section 4).
</nextsent>
<nextsent>in respect of automatically collecting corpora which have desired style, tambouratzis et al proposed method of dividing modern greek corpus into demokiti and katharevoua, which are variations of modern greek (tambouratzis et al, 2000).<papid> W00-0906 </papid></nextsent>
<nextsent>kaji et al proposed method of paraphrasing predicates using dictionary (kaji et al, 2002).<papid> P02-1028 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1369">
<title id=" N04-1031.xml">paraphrasing predicates from written language to spoken language using the web </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>bulyko et al also collected spoken language corpora from the web (bulyko et al, 2003).<papid> N03-2003 </papid></prevsent>
<prevsent>the method of bulyko et al used n-grams in training corpus and is different from ours (the detail of our method is described in section 4).</prevsent>
</prevsection>
<citsent citstr=" W00-0906 ">
in respect of automatically collecting corpora which have desired style, tambouratzis et al proposed method of dividing modern greek corpus into demokiti and katharevoua, which are variations of modern greek (tambouratzis et al, 2000).<papid> W00-0906 </papid></citsent>
<aftsection>
<nextsent>kaji et al proposed method of paraphrasing predicates using dictionary (kaji et al, 2002).<papid> P02-1028 </papid></nextsent>
<nextsent>for example, when definition sentence of chiratsuku (to shimmer)is yowaku hikaru (to shine faintly)?, his method paraphrases (1a) into (1b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1371">
<title id=" N04-1031.xml">paraphrasing predicates from written language to spoken language using the web </title>
<section> paraphrase pair selection.  </section>
<citcontext>
<prevsection>
<prevsent>however, generally speaking, the accuracy of japanese parser islow compared with that of japanese morphological an alyzer; the former is about 90% while the latter about 99%.
</prevsent>
<prevsent>therefore, only reliable part of the parse result isused in the same way as kawahara et al did.
</prevsent>
</prevsection>
<citsent citstr=" H01-1043 ">
see (kawa hara and kurohashi, 2001) <papid> H01-1043 </papid>for the details.</citsent>
<aftsection>
<nextsent>kawahara et al. reported that 97% accuracy is achieved in the reliable part.
</nextsent>
<nextsent>occurrence probability in general,   is defined as:       # of expressions in corpus.
</nextsent>
<nextsent>  tends to be small when  contains noun, because only reliable part of the parsed corpus is used to count .
</nextsent>
<nextsent>therefore, the value of the denominator ?# of expressions in corpus?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1372">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>tl], by finding the most likely translation given by: ? = argmax p(t |s).
</prevsent>
<prevsent>1.1 block selection.
</prevsent>
</prevsection>
<citsent citstr=" C00-2163 ">
recent statistical machine translation (smt) algorithms generate such translation by incorporating an inventory of bilingual phrases (och andney, 2000).<papid> C00-2163 </papid></citsent>
<aftsection>
<nextsent>a m-n phrase-pair, or block, is sequence of source words paired with sequence of target words.
</nextsent>
<nextsent>the inventory of blocks incur rent systems is highly redundant.
</nextsent>
<nextsent>we illustrate the redundancy using the example in table 1 which lljnp almrkzyp llhzb al$ywey alsyny the politburo of the central committee of the chinese communist party almktb alsyasy figure 1: example of arabic snipet and alignment to its english translation.
</nextsent>
<nextsent>shows set of phrases that cover the two-wordarabic fragment lljnp almrkzyp?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1373">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>direct modeling for machine translation, we call our current approach dtm2 (direct translation model 2).
</prevsent>
<prevsent>1.2 statistical modeling for translation.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
earlier work in statistical machine translation (brown et al, 1993) <papid> J93-2003 </papid>is based on the noisy-channel?</citsent>
<aftsection>
<nextsent>formulation where ? = arg max p(t |s) = argmax p(t )p(s|t ) (1)where the target language model p(t ) is further decomposed as p(t ) ? ?
</nextsent>
<nextsent>i p(ti|ti1, . . .
</nextsent>
<nextsent>, tik+1) where is the order of the language model and the translation model p(s|t ) has been modeled by sequence of five models with increasing complexity (brown et al, 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>the parameters of each of thetwo components are estimated using maximum likelihood estimation (mle).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1378">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as is well known, improved results are achieved by modifying the bayes factor ization in equation 1 above by weighing each distribution differently as in: p(t |s) ? p?(t )p1??(s|t ) (2) this is the simplest maxent1 model that uses two feature functions.
</prevsent>
<prevsent>the parameter ? is tuned on adevelopment set (usually to improve an error metric instead of mle).
</prevsent>
</prevsection>
<citsent citstr=" P00-1006 ">
this model is special caseof the direct translation model proposed in (pap ineni et al, 1997; papineni et al, 1998) for languageunderstanding; (foster, 2000) <papid> P00-1006 </papid>demostrated perplexity reductions by using direct models; and (och and ney, 2002) <papid> P02-1038 </papid>employed it very successfully for language translation by using about ten feature functions: p(t |s) = 1z exp ? ii(s, ) many of the feature functions used for translation are mle models (or smoothed variants).</citsent>
<aftsection>
<nextsent>for example, if one uses 1 = log(p(t )) and 2 = log(p(s|t )) weget the model described in equation 2.
</nextsent>
<nextsent>most phrase based systems, including the baseline decoder used in this work use feature functions: ? target word n-gram model (e.g., = 5), ? target part-of-speech n-gram model (n ? 5),?
</nextsent>
<nextsent>various translation models such as block inventory with the following three varieties: 1) the unigram block count, 2) model 1 score p(si|ti) on the phrase-pair, and 3)a model 1 score for the other direction p(ti|si), ? target word count penalty feature |t |, ? phrase count feature, ? distortion model (al-onaizan and papineni, 2006).
</nextsent>
<nextsent>the weight vector ? is estimated by tuning on rather small (as compared to the training set used to define the feature functions) development set using the bleu metric (or other translation error met rics).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1379">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as is well known, improved results are achieved by modifying the bayes factor ization in equation 1 above by weighing each distribution differently as in: p(t |s) ? p?(t )p1??(s|t ) (2) this is the simplest maxent1 model that uses two feature functions.
</prevsent>
<prevsent>the parameter ? is tuned on adevelopment set (usually to improve an error metric instead of mle).
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
this model is special caseof the direct translation model proposed in (pap ineni et al, 1997; papineni et al, 1998) for languageunderstanding; (foster, 2000) <papid> P00-1006 </papid>demostrated perplexity reductions by using direct models; and (och and ney, 2002) <papid> P02-1038 </papid>employed it very successfully for language translation by using about ten feature functions: p(t |s) = 1z exp ? ii(s, ) many of the feature functions used for translation are mle models (or smoothed variants).</citsent>
<aftsection>
<nextsent>for example, if one uses 1 = log(p(t )) and 2 = log(p(s|t )) weget the model described in equation 2.
</nextsent>
<nextsent>most phrase based systems, including the baseline decoder used in this work use feature functions: ? target word n-gram model (e.g., = 5), ? target part-of-speech n-gram model (n ? 5),?
</nextsent>
<nextsent>various translation models such as block inventory with the following three varieties: 1) the unigram block count, 2) model 1 score p(si|ti) on the phrase-pair, and 3)a model 1 score for the other direction p(ti|si), ? target word count penalty feature |t |, ? phrase count feature, ? distortion model (al-onaizan and papineni, 2006).
</nextsent>
<nextsent>the weight vector ? is estimated by tuning on rather small (as compared to the training set used to define the feature functions) development set using the bleu metric (or other translation error met rics).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1380">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>various translation models such as block inventory with the following three varieties: 1) the unigram block count, 2) model 1 score p(si|ti) on the phrase-pair, and 3)a model 1 score for the other direction p(ti|si), ? target word count penalty feature |t |, ? phrase count feature, ? distortion model (al-onaizan and papineni, 2006).
</prevsent>
<prevsent>the weight vector ? is estimated by tuning on rather small (as compared to the training set used to define the feature functions) development set using the bleu metric (or other translation error met rics).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
unlike maxent training, the method (och, 2003) <papid> P03-1021 </papid>used for estimating the weight vector for bleu maximization are not computationally scalable for large number of feature functions.</citsent>
<aftsection>
<nextsent>most recent state-of-the-art machine translation decoders have the following aspects that we improve upon in this work: 1) block style, and 2) model parameterization and parameter estimation.
</nextsent>
<nextsent>we discuss each item next.1the sub fields of log-linear models, exponential family, and maxent describe the equivalent techniques from different perspectives.
</nextsent>
<nextsent>58 2.1 block style.
</nextsent>
<nextsent>in order to extract phrases from alignments available in one or both directions, most smt approaches usea heuristic such as union, intersection, inverse projection constraint, etc. as discussed earlier, these approaches result in large overlap between the extracted blocks (longer blocks overlap with all the shorter subcomponents blocks).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1381">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>58 2.1 block style.
</prevsent>
<prevsent>in order to extract phrases from alignments available in one or both directions, most smt approaches usea heuristic such as union, intersection, inverse projection constraint, etc. as discussed earlier, these approaches result in large overlap between the extracted blocks (longer blocks overlap with all the shorter subcomponents blocks).
</prevsent>
</prevsection>
<citsent citstr=" N06-1002 ">
also, slightly restating the advantages of phrase-pairs identified in(quirk and menezes, 2006), <papid> N06-1002 </papid>these blocks are effective at capturing context including the encoding of non-compositional phrase pairs, and capturing local reordering, but they lack variables (e.g. embedding between ne . . .</citsent>
<aftsection>
<nextsent>pas in french), have sparsity problems, and lack strategy for global reordering.
</nextsent>
<nextsent>more recently, (chiang, 2005) <papid> P05-1033 </papid>extended phrase-pairs (or blocks) to hierarchical phrase-pairs where grammar with single non-terminal allows the embedding of phrases-pairs, to allow for arbitrary embedding and capture global reordering though this approach still has the high overlap problem.</nextsent>
<nextsent>however, in (quirkand menezes, 2006), <papid> N06-1002 </papid>the authors investigate minimum translation units (mtu) which is refinement over similar approach by (banchs et al, 2005) to eliminate the overlap issue.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1382">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>also, slightly restating the advantages of phrase-pairs identified in(quirk and menezes, 2006), <papid> N06-1002 </papid>these blocks are effective at capturing context including the encoding of non-compositional phrase pairs, and capturing local reordering, but they lack variables (e.g. embedding between ne . . .</prevsent>
<prevsent>pas in french), have sparsity problems, and lack strategy for global reordering.</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
more recently, (chiang, 2005) <papid> P05-1033 </papid>extended phrase-pairs (or blocks) to hierarchical phrase-pairs where grammar with single non-terminal allows the embedding of phrases-pairs, to allow for arbitrary embedding and capture global reordering though this approach still has the high overlap problem.</citsent>
<aftsection>
<nextsent>however, in (quirkand menezes, 2006), <papid> N06-1002 </papid>the authors investigate minimum translation units (mtu) which is refinement over similar approach by (banchs et al, 2005) to eliminate the overlap issue.</nextsent>
<nextsent>the mtu approach picks all the minimal blocks subject to the condition that no word alignment link crosses distinct blocks.they do not have the notion of block with variable (a special case of the hierarchical phrase-pairs)that we employ in this work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1385">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the are trained using held-out corpus using maximum bleu training (och, 2003).<papid> P03-1021 </papid></prevsent>
<prevsent>this method is only practical for small number of features; typically, the number of features is on the order of 10 to 20.</prevsent>
</prevsection>
<citsent citstr=" P06-1091 ">
recently, there have been several discriminative approaches at training large parameter sets including (tillmann and zhang, 2006) <papid> P06-1091 </papid>and (liang et al, 2006).<papid> P06-1096 </papid></citsent>
<aftsection>
<nextsent>in (tillmann and zhang, 2006) <papid> P06-1091 </papid>the model is optimized to produce block orientation and the target sentence is used only for computing sentence level bleu.</nextsent>
<nextsent>(liang et al, 2006) <papid> P06-1096 </papid>demonstrates dis criminatively trained system for machine translation that has the following characteristics: 1) requires varying update strategy (local vs. bold) depending on whether the reference sentence is reachable?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1387">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the are trained using held-out corpus using maximum bleu training (och, 2003).<papid> P03-1021 </papid></prevsent>
<prevsent>this method is only practical for small number of features; typically, the number of features is on the order of 10 to 20.</prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
recently, there have been several discriminative approaches at training large parameter sets including (tillmann and zhang, 2006) <papid> P06-1091 </papid>and (liang et al, 2006).<papid> P06-1096 </papid></citsent>
<aftsection>
<nextsent>in (tillmann and zhang, 2006) <papid> P06-1091 </papid>the model is optimized to produce block orientation and the target sentence is used only for computing sentence level bleu.</nextsent>
<nextsent>(liang et al, 2006) <papid> P06-1096 </papid>demonstrates dis criminatively trained system for machine translation that has the following characteristics: 1) requires varying update strategy (local vs. bold) depending on whether the reference sentence is reachable?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1398">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>the minimum requirements for the algorithm are (a) parallel corpus of source and target languages and (b) word-alignments.
</prevsent>
<prevsent>while one can use the em algorithm to train this hidden alignment model (the jump step), we use viterbi training, i.e. we use the most likely alignment between target and source words in the training corpus to estimate this model.
</prevsent>
</prevsection>
<citsent citstr=" H05-1012 ">
we assume that each sentence pair in the training corpus is word-aligned (e.g. using maxent aligner (ittycheriah and roukos, 2005) <papid> H05-1012 </papid>or an hmm aligner (ge, 2004)).</citsent>
<aftsection>
<nextsent>the algorithm performs the following steps in order to train the maximum entropy model: (a) block extraction, (b) feature extraction, and (c) parameter estimation.
</nextsent>
<nextsent>each of the first two steps requires pass over the training data and parameter estimation requires typically 5-10 passes over the data.
</nextsent>
<nextsent>(della pietra et al, 1995) documents the improved iterative scaling (iis) algorithm for training maximum entropy models.
</nextsent>
<nextsent>when the system is restricted to 1-n type blocks, the future space includes all the source word positions that are within the skip window and all their corresponding blocks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1399">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> form the maxent polynomials(della pietra et.  </section>
<citcontext>
<prevsection>
<prevsent>and almrkzyp?.
</prevsent>
<prevsent>feature name feature variables src left source left, source word, target word src right source right, source word, target word src tgt left source left, target left, source word, target word src tgt left 2 source left, target left, target left 2, source word, target word table 2: context feature types 4.3.3 arabic segmentation features an arabic segmenter produces morphemes; in arabic, prefixes and suffixes are used as prepositions, pronouns, gender and case markers.
</prevsent>
</prevsection>
<citsent citstr=" P03-1051 ">
this produces segmentation view of the arabic source words (lee et al., 2003).<papid> P03-1051 </papid></citsent>
<aftsection>
<nextsent>the features used in the model are formed from the cartesian product of all segmentation tokens with the english target sequence produced by this source word or words.
</nextsent>
<nextsent>however, prefixes and suffixes which are specific in translation are limited to their english translations.
</nextsent>
<nextsent>for example the prefix al#?
</nextsent>
<nextsent>is only allowed to participate in feature with the english word the?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1400">
<title id=" N07-1008.xml">direct translation model 2 </title>
<section> form the maxent polynomials(della pietra et.  </section>
<citcontext>
<prevsection>
<prevsent>since the model employs binary questions and predominantly the source word to the left is already covered and the right source word is uncovered, these features fire only if the left is open or if the right is closed in order to minimize the number of features in the model.
</prevsent>
<prevsent>5 translation decoder.
</prevsent>
</prevsection>
<citsent citstr=" J03-1005 ">
a beam search decoder similar to phrase-based systems (tillmann and ney, 2003) <papid> J03-1005 </papid>is used to translate the arabic sentence into english.</citsent>
<aftsection>
<nextsent>these decoder shave two parameters that control their search strategy: (a) the skip length (how many positions areal lowed to be untranslated) and (b) the window width, which controls how many words are allowed to be considered for translation.
</nextsent>
<nextsent>since the majority of the blocks employed in this work do not encode local reordering explicitly, the current dtm2 decoder uses large skip (4 source words for arabic) and tries all possible reorderings.
</nextsent>
<nextsent>the primary difference between dtm2 decoder and standard phrase based decoders is that the maximum entropy model provides cost estimate of producing this translation using the features described in previous sections.
</nextsent>
<nextsent>an other difference is that the dtm2 decoder handles blocks with variables.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1401">
<title id=" N03-1016.xml">a parsing fast exact viterbi parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, when dealing withwide-coverage grammars and long sentences, even cubic algorithms can be far too expensive in practice.
</prevsent>
<prevsent>two primary types of methods for accelerating parse selection have been proposed.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
roark (2001) <papid> J01-2004 </papid>and ratnaparkhi (1999) use beam-search strategy, in which only the bestn parses are tracked at any moment.</citsent>
<aftsection>
<nextsent>parsing time is linear and can be made arbitrarily fast by reducing n. thisis greedy strategy, and the actual viterbi (highest proba bility) parse can be pruned from the beam because, whileit is globally optimal, it may not be locally optimal at every parse stage.
</nextsent>
<nextsent>chitrao and grishman (1990), <papid> H90-1053 </papid>caraballo and charniak (1998), <papid> J98-2004 </papid>charniak et al (1998), <papid> W98-1115 </papid>and collins (1999) describe best-first parsing, which is intended for tabular item-based framework.</nextsent>
<nextsent>in best-first parsing, one builds figure-of-merit (fom) over parser items, and uses the fom to decide the order in which agenda items should be processed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1402">
<title id=" N03-1016.xml">a parsing fast exact viterbi parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>roark (2001) <papid> J01-2004 </papid>and ratnaparkhi (1999) use beam-search strategy, in which only the bestn parses are tracked at any moment.</prevsent>
<prevsent>parsing time is linear and can be made arbitrarily fast by reducing n. thisis greedy strategy, and the actual viterbi (highest proba bility) parse can be pruned from the beam because, whileit is globally optimal, it may not be locally optimal at every parse stage.</prevsent>
</prevsection>
<citsent citstr=" H90-1053 ">
chitrao and grishman (1990), <papid> H90-1053 </papid>caraballo and charniak (1998), <papid> J98-2004 </papid>charniak et al (1998), <papid> W98-1115 </papid>and collins (1999) describe best-first parsing, which is intended for tabular item-based framework.</citsent>
<aftsection>
<nextsent>in best-first parsing, one builds figure-of-merit (fom) over parser items, and uses the fom to decide the order in which agenda items should be processed.
</nextsent>
<nextsent>this approach also dramatically reduces the work done during parsing, though it, too, gives no guarantee that the first parse returned is the actual viterbi parse (nor does it maintain worst-case cubic time bound).
</nextsent>
<nextsent>we discuss best-first parsing further in section 3.3.
</nextsent>
<nextsent>both of these speed-up techniques are based on greedy models of parser actions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1403">
<title id=" N03-1016.xml">a parsing fast exact viterbi parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>roark (2001) <papid> J01-2004 </papid>and ratnaparkhi (1999) use beam-search strategy, in which only the bestn parses are tracked at any moment.</prevsent>
<prevsent>parsing time is linear and can be made arbitrarily fast by reducing n. thisis greedy strategy, and the actual viterbi (highest proba bility) parse can be pruned from the beam because, whileit is globally optimal, it may not be locally optimal at every parse stage.</prevsent>
</prevsection>
<citsent citstr=" J98-2004 ">
chitrao and grishman (1990), <papid> H90-1053 </papid>caraballo and charniak (1998), <papid> J98-2004 </papid>charniak et al (1998), <papid> W98-1115 </papid>and collins (1999) describe best-first parsing, which is intended for tabular item-based framework.</citsent>
<aftsection>
<nextsent>in best-first parsing, one builds figure-of-merit (fom) over parser items, and uses the fom to decide the order in which agenda items should be processed.
</nextsent>
<nextsent>this approach also dramatically reduces the work done during parsing, though it, too, gives no guarantee that the first parse returned is the actual viterbi parse (nor does it maintain worst-case cubic time bound).
</nextsent>
<nextsent>we discuss best-first parsing further in section 3.3.
</nextsent>
<nextsent>both of these speed-up techniques are based on greedy models of parser actions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1404">
<title id=" N03-1016.xml">a parsing fast exact viterbi parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>roark (2001) <papid> J01-2004 </papid>and ratnaparkhi (1999) use beam-search strategy, in which only the bestn parses are tracked at any moment.</prevsent>
<prevsent>parsing time is linear and can be made arbitrarily fast by reducing n. thisis greedy strategy, and the actual viterbi (highest proba bility) parse can be pruned from the beam because, whileit is globally optimal, it may not be locally optimal at every parse stage.</prevsent>
</prevsection>
<citsent citstr=" W98-1115 ">
chitrao and grishman (1990), <papid> H90-1053 </papid>caraballo and charniak (1998), <papid> J98-2004 </papid>charniak et al (1998), <papid> W98-1115 </papid>and collins (1999) describe best-first parsing, which is intended for tabular item-based framework.</citsent>
<aftsection>
<nextsent>in best-first parsing, one builds figure-of-merit (fom) over parser items, and uses the fom to decide the order in which agenda items should be processed.
</nextsent>
<nextsent>this approach also dramatically reduces the work done during parsing, though it, too, gives no guarantee that the first parse returned is the actual viterbi parse (nor does it maintain worst-case cubic time bound).
</nextsent>
<nextsent>we discuss best-first parsing further in section 3.3.
</nextsent>
<nextsent>both of these speed-up techniques are based on greedy models of parser actions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1406">
<title id=" N03-1016.xml">a parsing fast exact viterbi parse selection </title>
<section> an a* algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>for example, np:[0,2] might be removed from the agenda, and, if there were rule ? np vp and vp:[2,8] was already entered into the chart, the edge s:[0,8] would be formed, and added to the agenda if it were not in the chart already.
</prevsent>
<prevsent>the way an a* parser differs from classic chart parser is that, like best-first parser, agenda edges are processed according to priority.
</prevsent>
</prevsection>
<citsent citstr=" W97-0302 ">
in best-first parsing, this priority is called figure-of-merit (fom), and isbased on various approximations to (e|s), the fraction of parses of sentence which include an edge (though see goodman (1997) <papid> W97-0302 </papid>for an alternative notion of fom).</citsent>
<aftsection>
<nextsent>edges which seem promising are explored first; others can wait on the agenda indefinitely.
</nextsent>
<nextsent>note that even if we did know (e|s) exactly, we still would notknow whether occurs in any best parse of s. nonetheless, good foms empirically lead quickly to good parses.
</nextsent>
<nextsent>best-first parsing aims to find (hopefully good) parse quickly, but gives no guarantee that the first parse discovered is the viterbi parse, nor does it allow one to recognize the viterbi parse when it is found.
</nextsent>
<nextsent>in a* parsing, we wish to construct priorities which will speed up parsing, yet still guarantee optimality (that the first parse returned is indeed best parse).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1408">
<title id=" N03-1016.xml">a parsing fast exact viterbi parse selection </title>
<section> an a* algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>our parser, like best-first parser, maintains estimates b(e, s) of ?(e, s) which begin at ??, only increase over time, and always represent the score of the best parses of their edges discovered so far.
</prevsent>
<prevsent>optimality means that for any e, b(e, s) will equal g(e, s) when is removed from the agenda.
</prevsent>
</prevsection>
<citsent citstr=" P01-1044 ">
if one uses b(e, s) to prioritize edges, we show in klein and manning (2001<papid> P01-1044 </papid>a), that the parser is optimal over arbitrary pcfgs, and wide range of control strategies.</citsent>
<aftsection>
<nextsent>this is proved using an extension of dijkstras algorithm to certain kind of hypergraph associated with parsing,shown in figure 1(b): parse items are nodes in the hypergraph, hyper arcs take sets of parse items to their result item, and hyper paths map to parses.
</nextsent>
<nextsent>reach ability from start corresponds to parse ability, and shortest paths to viterbi parses.
</nextsent>
<nextsent>1our use of inside score and outside score evokes the same picture as talk about inside and outside probabilities, but note that in this paper inside and outside scores always refer to (a bound on) the maximum (viterbi) probability parse inside or outside some edge, rather than to the sum for all such parses.
</nextsent>
<nextsent>estimate sx sxl sxlr true summary (1,6,np) (1,6,np,vbz) (1,6,np,vbz,?,?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1419">
<title id=" N03-1016.xml">a parsing fast exact viterbi parse selection </title>
<section> a* estimates for parsing </section>
<citcontext>
<prevsection>
<prevsent>nn ? dt nn 0.25 xdt jj ? dt jj 1.0 xdt nn ? dt nn 1.0 figure 5: two trie encodings of rules.
</prevsent>
<prevsent>0 10 20 30 40 50 60 70 80 90 100 nu ll sx sx s1 xl sx sx ml b ed ge bl ck ed o-tries i-tries figure 6: fraction of edges saved by using various estimate methods, for two rule encodings.
</prevsent>
</prevsection>
<citsent citstr=" J97-2003 ">
o-trie is deterministic right-branching trie encoding (leermakers, 1992) with weights pushed left (mohri, 1997).<papid> J97-2003 </papid></citsent>
<aftsection>
<nextsent>i-trie is non-deterministic left branching trie with weights on rule entry as in charniak et al (1998).<papid> W98-1115 </papid></nextsent>
<nextsent>states, such as by annotating nodes with their parent andeven grandparent categories (johnson, 1998).<papid> J98-4004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1421">
<title id=" N03-1016.xml">a parsing fast exact viterbi parse selection </title>
<section> a* estimates for parsing </section>
<citcontext>
<prevsection>
<prevsent>o-trie is deterministic right-branching trie encoding (leermakers, 1992) with weights pushed left (mohri, 1997).<papid> J97-2003 </papid></prevsent>
<prevsent>i-trie is non-deterministic left branching trie with weights on rule entry as in charniak et al (1998).<papid> W98-1115 </papid></prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
states, such as by annotating nodes with their parent andeven grandparent categories (johnson, 1998).<papid> J98-4004 </papid></citsent>
<aftsection>
<nextsent>this annotation multiplies out the state space, giving much larger grammar, and projecting back to the unannotated state set can be used as an outside estimate.
</nextsent>
<nextsent>second, and perhaps more importantly, this technique can be applied to lexical parsing, where the state projections are onto the delexicalized pcfg symbols and/or onto the word-word dependency structures.
</nextsent>
<nextsent>this is particularly effective when the tree model takes certain factored form; see klein and manning (2003) for details.
</nextsent>
<nextsent>3.3 parsing performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1431">
<title id=" N06-1007.xml">acquisition of verb entailment from text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, there is an entailment relation between the verbs buy and belong,which reflects the commonsense notion that if some one has bought an object, this object belongs to that person.
</prevsent>
<prevsent>a lexical resource encoding entailment can serveas useful tool in many tasks where automatic in ferencing over natural language text is required.
</prevsent>
</prevsection>
<citsent citstr=" P01-1052 ">
in question answering, it has been used to establish that certain sentence found in the corpus can serveas suitable, albeit implicit answer to query (cur tis et al, 2005), (girju, 2003), (moldovan andrus, 2001).<papid> P01-1052 </papid></citsent>
<aftsection>
<nextsent>in information extraction, it can similarly help to recognize relations between named entities in cases when the entities in the text are linked bya linguistic construction that entails known extraction pattern, but not by the pattern itself.
</nextsent>
<nextsent>a lexical entailment resource can contribute to information retrieval tasks via integration into textual entailment system that aims to recognize entailment between two larger text fragments (dagan et al, 2005).since entailment is known to systematically interact with the discourse organization of text (hobbs, 1985), an entailment resource can be of interest to tasks that deal with structuring set of individual facts into coherent text.
</nextsent>
<nextsent>in natural language generation (reiter and dale, 2000) and multi-document summarization (barzilay et al, 2002) it can be used to order sentences coming from multiple, possibly unrelated sources to produce coherent document.
</nextsent>
<nextsent>the knowledge is essential for compiling answers for procedural questions in qa system, when sentences containing relevant information are spread across the corpus (curtis et al, 2005).the present paper is concerned with the problem of automatic acquisition of verb entailment from text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1432">
<title id=" N06-1007.xml">acquisition of verb entailment from text </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>after thatwe present results of its experimental evaluation.
</prevsent>
<prevsent>finally, we draw conclusions and outline future work.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
the task of verb entailment acquisition appears tohave much in common with that of paraphrase acquisition (lin and pantel, 2001), (pang et al, 2003), (<papid> N03-1024 </papid>szpektor et al, 2004).<papid> W04-3206 </papid></citsent>
<aftsection>
<nextsent>in both tasks the goal isto discover pairs of related verbs and identify map 49pings between their argument structures.
</nextsent>
<nextsent>the important distinction is that while in paraphrase the two verbs are semantically equivalent, entailment is directional, or asymmetric, relation: one verb entails the other, but the converse does not hold.
</nextsent>
<nextsent>forex ample, the verbs buy and purchase paraphrase each other: either of them can substitute its counterpart in most contexts without altering their meaning.
</nextsent>
<nextsent>the verb buy entails own so that buy can be replaced with own without introducing any contradicting content into the original sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1433">
<title id=" N06-1007.xml">acquisition of verb entailment from text </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>after thatwe present results of its experimental evaluation.
</prevsent>
<prevsent>finally, we draw conclusions and outline future work.
</prevsent>
</prevsection>
<citsent citstr=" W04-3206 ">
the task of verb entailment acquisition appears tohave much in common with that of paraphrase acquisition (lin and pantel, 2001), (pang et al, 2003), (<papid> N03-1024 </papid>szpektor et al, 2004).<papid> W04-3206 </papid></citsent>
<aftsection>
<nextsent>in both tasks the goal isto discover pairs of related verbs and identify map 49pings between their argument structures.
</nextsent>
<nextsent>the important distinction is that while in paraphrase the two verbs are semantically equivalent, entailment is directional, or asymmetric, relation: one verb entails the other, but the converse does not hold.
</nextsent>
<nextsent>forex ample, the verbs buy and purchase paraphrase each other: either of them can substitute its counterpart in most contexts without altering their meaning.
</nextsent>
<nextsent>the verb buy entails own so that buy can be replaced with own without introducing any contradicting content into the original sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1434">
<title id=" N06-1007.xml">acquisition of verb entailment from text </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the verb buy entails own so that buy can be replaced with own without introducing any contradicting content into the original sentence.
</prevsent>
<prevsent>replacing own with buy, however, does convey new meaning.to account for the asymmetric character of entailment, popular approach has been to use lexico syntactic patterns indicative of entailment.
</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
in(chklovski and pantel, 2004) <papid> W04-3205 </papid>different types of semantic relations between verbs are discovered using surface patterns (like x-ed by y-ing?</citsent>
<aftsection>
<nextsent>for enablement1, which would match obtained by bor rowing?, for example) and assessing the strength of asymmetric relations as mutual information between the two verbs.
</nextsent>
<nextsent>(torisawa, 2003) collected pairs of coordinated verbs, i.e. matching patterns like x-ed and y-ed?, and then estimated the probability of entailment using corpus counts.
</nextsent>
<nextsent>(inui et al, 2003) used similar approach exploiting causative expressions such as because, though, and so.
</nextsent>
<nextsent>(girju, 2003) extracted causal relations between nouns like earthquakes generate tsunami?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1443">
<title id=" N06-1007.xml">acquisition of verb entailment from text </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>we attempt to capture local discourse relatedness between clauses by combination of several surface cues.
</prevsent>
<prevsent>in doing so, we do not build full discourse representation of text, nor do we try to identify thetype of particular rhetorical relations between sentences, but rather identify pairs of clauses that are likely to be discourse-related.textual proximity.
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
we start by parsing the corpus with dependency parser (we use conn exors fdg (tapanainen and jarvinen, 1997)), <papid> A97-1011 </papid>treating every verb with its dependent constituents as clause.</citsent>
<aftsection>
<nextsent>for two clauses to be discourse-related, we require that they appear close to each other in the text.
</nextsent>
<nextsent>adjacency of sentences has been previously used to model local coherence (lapata, 2003).<papid> P03-1069 </papid></nextsent>
<nextsent>to capture related clauses within larger text fragments, we experiment with windows of text of various sizes around clause.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1444">
<title id=" N06-1007.xml">acquisition of verb entailment from text </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>we start by parsing the corpus with dependency parser (we use conn exors fdg (tapanainen and jarvinen, 1997)), <papid> A97-1011 </papid>treating every verb with its dependent constituents as clause.</prevsent>
<prevsent>for two clauses to be discourse-related, we require that they appear close to each other in the text.</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
adjacency of sentences has been previously used to model local coherence (lapata, 2003).<papid> P03-1069 </papid></citsent>
<aftsection>
<nextsent>to capture related clauses within larger text fragments, we experiment with windows of text of various sizes around clause.
</nextsent>
<nextsent>paragraph boundaries.
</nextsent>
<nextsent>since locally related sentences tend to be grouped into paragraphs, we further require that the two clauses appear within the same paragraph.common event participant.
</nextsent>
<nextsent>entity-based theories of discourse (e.g., (grosz et al, 1995)) <papid> J95-2003 </papid>claim that coherent text segment tends to focus on specific entity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1445">
<title id=" N06-1007.xml">acquisition of verb entailment from text </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>paragraph boundaries.
</prevsent>
<prevsent>since locally related sentences tend to be grouped into paragraphs, we further require that the two clauses appear within the same paragraph.common event participant.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
entity-based theories of discourse (e.g., (grosz et al, 1995)) <papid> J95-2003 </papid>claim that coherent text segment tends to focus on specific entity.</citsent>
<aftsection>
<nextsent>this intuition has been formalized by (barzilay and lapata, 2005), <papid> P05-1018 </papid>who developed anentity-based statistical representation of local discourse and showed its usefulness for estimating coherence between sentences.</nextsent>
<nextsent>we also impose this as criterion for two clauses to be discourse-related: their arguments need to refer to the same participant, henceforth, anchor.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1446">
<title id=" N06-1007.xml">acquisition of verb entailment from text </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>since locally related sentences tend to be grouped into paragraphs, we further require that the two clauses appear within the same paragraph.common event participant.
</prevsent>
<prevsent>entity-based theories of discourse (e.g., (grosz et al, 1995)) <papid> J95-2003 </papid>claim that coherent text segment tends to focus on specific entity.</prevsent>
</prevsection>
<citsent citstr=" P05-1018 ">
this intuition has been formalized by (barzilay and lapata, 2005), <papid> P05-1018 </papid>who developed anentity-based statistical representation of local discourse and showed its usefulness for estimating coherence between sentences.</citsent>
<aftsection>
<nextsent>we also impose this as criterion for two clauses to be discourse-related: their arguments need to refer to the same participant, henceforth, anchor.
</nextsent>
<nextsent>we identify the anchor as the same noun lemma appearing as an argument to the verbs in both clauses, considering only subject, object, and prepositional object arguments.
</nextsent>
<nextsent>the anchor must not be pronoun, since identical pronouns may refer to different entities and making use of such correspondences is likely to introduce noise.
</nextsent>
<nextsent>4.2 creating templates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1447">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for these language pairs huge portion of phrases encountered at run-time will be unknown.we show how techniques from paraphrasing can be used to deal with these otherwise unknown source language phrases.our results show that augmenting state of-the-art smt system with paraphrases leads to significantly improved coverage and translation quality.
</prevsent>
<prevsent>for training corpus with 10,000 sentence pairs we increase the coverage of unique test set unigrams from 48% to 90%, with more than half of the newly covered items accurately translated, as opposed to none in current approaches.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
as with many other statistical natural language processing tasks, statistical machine translation (brownet al, 1993) <papid> J93-2003 </papid>produces high quality results when ample training data is available.</citsent>
<aftsection>
<nextsent>this is problematic for so called low density?
</nextsent>
<nextsent>language pairs which do not have very large parallel corpora.
</nextsent>
<nextsent>for example, when words occur infrequently in parallel corpus parameter estimates for word-level alignments can be inaccurate, which can in turn lead to inaccurate phrase translations.
</nextsent>
<nextsent>limited amounts of training data can further lead to problem of low coverage in that many phrases encountered at run-time are not observed in the training data and therefore their translations will not be learned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1448">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> the problem of coverage in smt.  </section>
<citcontext>
<prevsection>
<prevsent>argue that while we observe an improvement in bleu score, this metric is particularly poorly suited to measuring the sort of improvements that we achieve.
</prevsent>
<prevsent>present an alternative methodology for targeted manual evaluation that may be useful in other research projects.
</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>by 17 0 10 20 30 40 50 60 70 80 90 100 10000 100000 1e+06 1e+07 e t e i e s i h r n l t o s ( % ) training corpus size (num words) unigramsbigramstrigrams4-gramsfigure 1: percent of unique unigrams, bigrams, trigrams, and 4-grams from the europarl spanish test sentences for which translations were learned in increasingly large training corpora increasing the size of the basic unit of translation, phrase-based machine translation does away with many of the problems associated with the originalword-based formulation of statistical machine translation (brown et al, 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>for instance, with multiword units less re-ordering needs to occur since local dependencies are frequently captured.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1449">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> the problem of coverage in smt.  </section>
<citcontext>
<prevsection>
<prevsent>argue that while we observe an improvement in bleu score, this metric is particularly poorly suited to measuring the sort of improvements that we achieve.
</prevsent>
<prevsent>present an alternative methodology for targeted manual evaluation that may be useful in other research projects.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>by 17 0 10 20 30 40 50 60 70 80 90 100 10000 100000 1e+06 1e+07 e t e i e s i h r n l t o s ( % ) training corpus size (num words) unigramsbigramstrigrams4-gramsfigure 1: percent of unique unigrams, bigrams, trigrams, and 4-grams from the europarl spanish test sentences for which translations were learned in increasingly large training corpora increasing the size of the basic unit of translation, phrase-based machine translation does away with many of the problems associated with the originalword-based formulation of statistical machine translation (brown et al, 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>for instance, with multiword units less re-ordering needs to occur since local dependencies are frequently captured.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1450">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> the problem of coverage in smt.  </section>
<citcontext>
<prevsection>
<prevsent>argue that while we observe an improvement in bleu score, this metric is particularly poorly suited to measuring the sort of improvements that we achieve.
</prevsent>
<prevsent>present an alternative methodology for targeted manual evaluation that may be useful in other research projects.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>by 17 0 10 20 30 40 50 60 70 80 90 100 10000 100000 1e+06 1e+07 e t e i e s i h r n l t o s ( % ) training corpus size (num words) unigramsbigramstrigrams4-gramsfigure 1: percent of unique unigrams, bigrams, trigrams, and 4-grams from the europarl spanish test sentences for which translations were learned in increasingly large training corpora increasing the size of the basic unit of translation, phrase-based machine translation does away with many of the problems associated with the originalword-based formulation of statistical machine translation (brown et al, 1993).<papid> J93-2003 </papid></nextsent>
<nextsent>for instance, with multiword units less re-ordering needs to occur since local dependencies are frequently captured.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1452">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> acquiring paraphrases.  </section>
<citcontext>
<prevsection>
<prevsent>paraphrases are alternative ways of expressing thesame information within one language.
</prevsent>
<prevsent>the automatic generation of paraphrases has been the focus of significant amount of research lately.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
many methods for extracting paraphrases (barzilay and mckeown, 2001; <papid> P01-1008 </papid>pang et al, 2003) <papid> N03-1024 </papid>make use of monolingual parallel corpora, such as multiple translations of classic french novels into english, or the multiple reference translations used by many automatic evaluation metrics for machine translation.bannard and callison-burch (2005) use bilingual parallel corpora to generate paraphrases.</citsent>
<aftsection>
<nextsent>paraphrases are identified by pivoting through phrases in another language.
</nextsent>
<nextsent>the foreign language translations of an english phrase are identified, all occurrences of those foreign phrases are found, and all english phrases that they translate back to are treated as potential paraphrases of the original english phrase.
</nextsent>
<nextsent>figure 2 illustrates how german phrase can beused as point of identification for english paraphrases in this way.the method defined in bannard and callison burch (2005) <papid> P05-1074 </papid>has several features that make it anideal candidate for incorporation into statistical machine translation system.</nextsent>
<nextsent>firstly, it can easily be applied to any language for which we have one or more parallel corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1453">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> acquiring paraphrases.  </section>
<citcontext>
<prevsection>
<prevsent>paraphrases are alternative ways of expressing thesame information within one language.
</prevsent>
<prevsent>the automatic generation of paraphrases has been the focus of significant amount of research lately.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
many methods for extracting paraphrases (barzilay and mckeown, 2001; <papid> P01-1008 </papid>pang et al, 2003) <papid> N03-1024 </papid>make use of monolingual parallel corpora, such as multiple translations of classic french novels into english, or the multiple reference translations used by many automatic evaluation metrics for machine translation.bannard and callison-burch (2005) use bilingual parallel corpora to generate paraphrases.</citsent>
<aftsection>
<nextsent>paraphrases are identified by pivoting through phrases in another language.
</nextsent>
<nextsent>the foreign language translations of an english phrase are identified, all occurrences of those foreign phrases are found, and all english phrases that they translate back to are treated as potential paraphrases of the original english phrase.
</nextsent>
<nextsent>figure 2 illustrates how german phrase can beused as point of identification for english paraphrases in this way.the method defined in bannard and callison burch (2005) <papid> P05-1074 </papid>has several features that make it anideal candidate for incorporation into statistical machine translation system.</nextsent>
<nextsent>firstly, it can easily be applied to any language for which we have one or more parallel corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1454">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> acquiring paraphrases.  </section>
<citcontext>
<prevsection>
<prevsent>paraphrases are identified by pivoting through phrases in another language.
</prevsent>
<prevsent>the foreign language translations of an english phrase are identified, all occurrences of those foreign phrases are found, and all english phrases that they translate back to are treated as potential paraphrases of the original english phrase.
</prevsent>
</prevsection>
<citsent citstr=" P05-1074 ">
figure 2 illustrates how german phrase can beused as point of identification for english paraphrases in this way.the method defined in bannard and callison burch (2005) <papid> P05-1074 </papid>has several features that make it anideal candidate for incorporation into statistical machine translation system.</citsent>
<aftsection>
<nextsent>firstly, it can easily be applied to any language for which we have one or more parallel corpora.
</nextsent>
<nextsent>secondly, it defines paraphrase probability, p(e2|e1), which can be incorporated into the probabilistic framework of smt.
</nextsent>
<nextsent>3.1 paraphrase probabilities.
</nextsent>
<nextsent>the paraphrase probability p(e2|e1) is defined in terms of two translation model probabilities: p(f |e1), the probability that the original english phrase e1 translates as particular phrase in the other language, and p(e2|f), the probability that the candidate paraphrase e2 translates as the foreign language phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1456">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>we used the publicly available europarl multilingual parallel corpus (koehn, 2005) to create six training corpora for the two language pairs, and used the standard europarl development and test sets.
</prevsent>
<prevsent>4.1 baseline.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
for baseline system we produced phrase-based statistical machine translation system based on the log-linear formulation described in (och and ney, 2002) <papid> P02-1038 </papid>e?</citsent>
<aftsection>
<nextsent>= argmax p(e|f) (4) = argmax m?
</nextsent>
<nextsent>m=1 mhm(e, f) (5) the baseline model had total of eight feature functions, hm(e, f): language model probability, phrase translation probability, reverse phrase translation probability, lexical translation probability, reverse lexical translation probability, word penalty, phrase penalty, and distortion cost.
</nextsent>
<nextsent>to set the weights, m, we performed minimum error rate training (och, 2003) <papid> P03-1021 </papid>on the development set using bleu (papineni et al, 2002) <papid> P02-1040 </papid>as the objective func tion.the phrase translation probabilities were determined using maximum likelihood estimation over phrases induced from word-level alignments produced by performing giza++ training on each of the three training corpora.</nextsent>
<nextsent>we used the pharaoh beam search decoder (koehn, 2004) to produce the translations after all of the model parameters had been set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1457">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>= argmax p(e|f) (4) = argmax m?
</prevsent>
<prevsent>m=1 mhm(e, f) (5) the baseline model had total of eight feature functions, hm(e, f): language model probability, phrase translation probability, reverse phrase translation probability, lexical translation probability, reverse lexical translation probability, word penalty, phrase penalty, and distortion cost.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
to set the weights, m, we performed minimum error rate training (och, 2003) <papid> P03-1021 </papid>on the development set using bleu (papineni et al, 2002) <papid> P02-1040 </papid>as the objective func tion.the phrase translation probabilities were determined using maximum likelihood estimation over phrases induced from word-level alignments produced by performing giza++ training on each of the three training corpora.</citsent>
<aftsection>
<nextsent>we used the pharaoh beam search decoder (koehn, 2004) to produce the translations after all of the model parameters had been set.
</nextsent>
<nextsent>when the baseline system encountered unknown words in the test set, its behavior was simply to reproduce the foreign word in the translated output.
</nextsent>
<nextsent>this is the default behavior for many systems, as noted in section 2.1.
</nextsent>
<nextsent>4.2 translation with paraphrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1458">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>= argmax p(e|f) (4) = argmax m?
</prevsent>
<prevsent>m=1 mhm(e, f) (5) the baseline model had total of eight feature functions, hm(e, f): language model probability, phrase translation probability, reverse phrase translation probability, lexical translation probability, reverse lexical translation probability, word penalty, phrase penalty, and distortion cost.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
to set the weights, m, we performed minimum error rate training (och, 2003) <papid> P03-1021 </papid>on the development set using bleu (papineni et al, 2002) <papid> P02-1040 </papid>as the objective func tion.the phrase translation probabilities were determined using maximum likelihood estimation over phrases induced from word-level alignments produced by performing giza++ training on each of the three training corpora.</citsent>
<aftsection>
<nextsent>we used the pharaoh beam search decoder (koehn, 2004) to produce the translations after all of the model parameters had been set.
</nextsent>
<nextsent>when the baseline system encountered unknown words in the test set, its behavior was simply to reproduce the foreign word in the translated output.
</nextsent>
<nextsent>this is the default behavior for many systems, as noted in section 2.1.
</nextsent>
<nextsent>4.2 translation with paraphrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1461">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>previous research on trying to overcome data spar sity issues in statistical machine translation has largely focused on introducing morphological analysis as way of reducing the number of types observed in training text.
</prevsent>
<prevsent>for example, nissen andney (2004) apply morphological analyzers to english and german and are able to reduce the amount of training data needed to reach certain level of translation quality.
</prevsent>
</prevsection>
<citsent citstr=" H05-1085 ">
goldwater and mcclosky (2005) <papid> H05-1085 </papid>find that stemming czech and using lemmas improves the word-to-word correspondences when training czech-english alignment models.</citsent>
<aftsection>
<nextsent>koehn and knight (2003) <papid> E03-1076 </papid>show how monolingual texts and parallel corpora can be used to figure out appropriate places to split german compounds.</nextsent>
<nextsent>still other approaches focus on ways of acquiring data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1462">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for example, nissen andney (2004) apply morphological analyzers to english and german and are able to reduce the amount of training data needed to reach certain level of translation quality.
</prevsent>
<prevsent>goldwater and mcclosky (2005) <papid> H05-1085 </papid>find that stemming czech and using lemmas improves the word-to-word correspondences when training czech-english alignment models.</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
koehn and knight (2003) <papid> E03-1076 </papid>show how monolingual texts and parallel corpora can be used to figure out appropriate places to split german compounds.</citsent>
<aftsection>
<nextsent>still other approaches focus on ways of acquiring data.
</nextsent>
<nextsent>resnik and smith (2003) <papid> J03-3002 </papid>develop method for gathering parallel corpora from the web.</nextsent>
<nextsent>oard et al (2003) <papid> N03-2026 </papid>describe various methods employed for quickly gathering resources to create machine translation system for language with no initial re sources.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1463">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>koehn and knight (2003) <papid> E03-1076 </papid>show how monolingual texts and parallel corpora can be used to figure out appropriate places to split german compounds.</prevsent>
<prevsent>still other approaches focus on ways of acquiring data.</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
resnik and smith (2003) <papid> J03-3002 </papid>develop method for gathering parallel corpora from the web.</citsent>
<aftsection>
<nextsent>oard et al (2003) <papid> N03-2026 </papid>describe various methods employed for quickly gathering resources to create machine translation system for language with no initial re sources.</nextsent>
<nextsent>23</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1464">
<title id=" N06-1003.xml">improved statistical machine translation using paraphrases </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>still other approaches focus on ways of acquiring data.
</prevsent>
<prevsent>resnik and smith (2003) <papid> J03-3002 </papid>develop method for gathering parallel corpora from the web.</prevsent>
</prevsection>
<citsent citstr=" N03-2026 ">
oard et al (2003) <papid> N03-2026 </papid>describe various methods employed for quickly gathering resources to create machine translation system for language with no initial re sources.</citsent>
<aftsection>
<nextsent>23
</nextsent>
<nextsent>in this paper we have shown that significant gains in coverage and translation quality can be had by integrating paraphrases into statistical machine translation.
</nextsent>
<nextsent>in effect, paraphrases introduce some amount of generalization into statistical machine translation.whereas before we relied on having observed particular word or phrase in the training set in order to produce translation of it, we are no longer tied to having seen every word in advance.
</nextsent>
<nextsent>we can exploit knowledge that is external to the translation model about what words have similar meanings and use that in the process of translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1465">
<title id=" N07-1003.xml">avoiding and resolving initiative conflicts in dialogue </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 initiative models.
</prevsent>
<prevsent>researchers have been investigating how people man age dialogue initiative in their conversation.
</prevsent>
</prevsection>
<citsent citstr=" P88-1015 ">
whittaker and stenton (1988) <papid> P88-1015 </papid>proposed rules for tracking initiative based on utterance types; for example, statements, proposals, and questions show initiative, while answers and acknowledgements do not.</citsent>
<aftsection>
<nextsent>smith (1993) proposed four different initiative strategies with differing amounts of control by the system.
</nextsent>
<nextsent>chu-carrol and brown (1998) distinguished dialogue initiative from task initiative, and proposed an evidential model of tracking both of them.cohen et al (1998) proposed presenting initiative in different strengths.
</nextsent>
<nextsent>some researchers related initiative to discourse structure.
</nextsent>
<nextsent>walker and whittaker (1990) <papid> P90-1010 </papid>found correlation between initiative switches and discourse segments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1466">
<title id=" N07-1003.xml">avoiding and resolving initiative conflicts in dialogue </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>chu-carrol and brown (1998) distinguished dialogue initiative from task initiative, and proposed an evidential model of tracking both of them.cohen et al (1998) proposed presenting initiative in different strengths.
</prevsent>
<prevsent>some researchers related initiative to discourse structure.
</prevsent>
</prevsection>
<citsent citstr=" P90-1010 ">
walker and whittaker (1990) <papid> P90-1010 </papid>found correlation between initiative switches and discourse segments.</citsent>
<aftsection>
<nextsent>strayer et al (2003) proposed the restricted initiative model in which the initiator of discourse segment, who introduces the discourse segment purpose, isin control of the segment and shows most of the initiative.
</nextsent>
<nextsent>these models allowed the possibility that multiple conversants will want to show initiative at the same time; however, none of them addressed initiative conflicts.
</nextsent>
<nextsent>guinn (1998) studied another type of initiative, task initiative, which is about directing the problem-solving 17 of domain goal.
</nextsent>
<nextsent>guinn proposed that the person who is more capable of coordinating the current goal is the person who should be leading the dialogue.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1467">
<title id=" N07-1003.xml">avoiding and resolving initiative conflicts in dialogue </title>
<section> corpora and annotations.  </section>
<citcontext>
<prevsection>
<prevsent>the flow of the dialog would not change if non-contributions were removed.hierarchical discourse structure was annotated following strayer et al (2003).
</prevsent>
<prevsent>to determine whether groupof utterances form discourse segment, we took into account whether there exists shared goal introduced by one of the conversants (cf.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
grosz and sidner, 1986).<papid> J86-3001 </papid></citsent>
<aftsection>
<nextsent>3.2 the mtd corpus.
</nextsent>
<nextsent>the mtd corpus contains dialogues in which pair of participants play two games via conversation: an ongoing 18 game that takes relatively long time to finish and an interruption game that can be done in couple turns but has time constraint.
</nextsent>
<nextsent>both games are done on computers.
</nextsent>
<nextsent>players are separated so that they cannot see each other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1469">
<title id=" N07-1003.xml">avoiding and resolving initiative conflicts in dialogue </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>in face-toface conversation, there might be other cues, such as eye contact, head-nodding, and hand gesture, that conversantsuse in initiative conflicts.
</prevsent>
<prevsent>moreover, in multi-party conversation, conversant might talk to different people on different topics, and get interrupted from time to time, 23 which leads to an initiative conflict involving multiplespeakers.
</prevsent>
</prevsection>
<citsent citstr=" W04-2319 ">
in our future work, we plan to examine initiative conflicts in face-to-face multi-party conversation, such as the icsi corpus (shriberg et al, 2004).<papid> W04-2319 </papid>inspired by the findings on human behavior of initiative conflicts, we speculate that conversants might also have mechanism to even minimize unintentional initiative conflicts, which probably includes devices such as volume, pause, and other prosodic features.</citsent>
<aftsection>
<nextsent>the speaker uses these devices, as opposed to explicitly informing each other of their knowledge to evaluate capability (guinn, 1998), to implicitly signal his or her eagerness, confidence and capability.
</nextsent>
<nextsent>the hearer then compares his or her own eagerness with the speakers, and decides whether to just make an acknowledgement (al lowing the speaker to continue the lead) or to take over the initiative when taking the turn to speak.
</nextsent>
<nextsent>in our future work, we plan to build an initiative model to capture this negotiation process.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1470">
<title id=" N06-2004.xml">measuring semantic relatedness using people and wordnet </title>
<section> introduction </section>
<citcontext>
<prevsection>

<prevsent>in this paper, we (1) propose new dataset for testing the degree of relatedness between pairs of words; (2) propose new wordnet-based measure of relatedness, and evaluate it on the new dataset.
</prevsent>
</prevsection>
<citsent citstr=" W97-0703 ">
estimating the degree of semantic relatedness between words in text is deemed important in numerous applications: word-sense disambiguation (banerjee and pedersen, 2003), story segmentation (stokes et al, 2004), error correction (hirst and budanitsky, 2005), summarization (barzilay and elhadad, 1997; <papid> W97-0703 </papid>gurevych and strube, 2004).<papid> C04-1110 </papid></citsent>
<aftsection>
<nextsent>furthermore, budanitsky and hirst (2006) noted that various applications tend to pick the same measures of relatedness, which suggests certain commonality in what is required from such measure by the different applications.
</nextsent>
<nextsent>it thus seems worthwhile to develop such measures intrinsically, before putting them to application-based utility tests.
</nextsent>
<nextsent>the most popular, by-now-standard testbed is rubenstein and good enoughs (1965) list of 65 noun pairs, ranked by similarity of meaning.
</nextsent>
<nextsent>a 30-pairsubset (henceforth, mc) passed number of replications (miller and charles, 1991; resnik, 1995), and is thus highly reliable.rubenstein and goodenough (1965) view similarity of meaning as degree of synonymy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1471">
<title id=" N06-2004.xml">measuring semantic relatedness using people and wordnet </title>
<section> introduction </section>
<citcontext>
<prevsection>

<prevsent>in this paper, we (1) propose new dataset for testing the degree of relatedness between pairs of words; (2) propose new wordnet-based measure of relatedness, and evaluate it on the new dataset.
</prevsent>
</prevsection>
<citsent citstr=" C04-1110 ">
estimating the degree of semantic relatedness between words in text is deemed important in numerous applications: word-sense disambiguation (banerjee and pedersen, 2003), story segmentation (stokes et al, 2004), error correction (hirst and budanitsky, 2005), summarization (barzilay and elhadad, 1997; <papid> W97-0703 </papid>gurevych and strube, 2004).<papid> C04-1110 </papid></citsent>
<aftsection>
<nextsent>furthermore, budanitsky and hirst (2006) noted that various applications tend to pick the same measures of relatedness, which suggests certain commonality in what is required from such measure by the different applications.
</nextsent>
<nextsent>it thus seems worthwhile to develop such measures intrinsically, before putting them to application-based utility tests.
</nextsent>
<nextsent>the most popular, by-now-standard testbed is rubenstein and good enoughs (1965) list of 65 noun pairs, ranked by similarity of meaning.
</nextsent>
<nextsent>a 30-pairsubset (henceforth, mc) passed number of replications (miller and charles, 1991; resnik, 1995), and is thus highly reliable.rubenstein and goodenough (1965) view similarity of meaning as degree of synonymy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1472">
<title id=" N06-2004.xml">measuring semantic relatedness using people and wordnet </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we compare gic to another wordnet-based measure that can handle cross-pos comparisons, proposed by banerjee and pedersen (2003).
</prevsent>
<prevsent>to compare word senses and b, the algorithm compares not only their glosses, but also glosses of items standing in various wordnet relations with and b. forex ample, it compares the gloss of as meronym to that of bs hyponym.
</prevsent>
</prevsection>
<citsent citstr=" N04-3012 ">
we use the default configuration of the measure in wordnet::similarity-0.12 package (pedersen et al, 2004), <papid> N04-3012 </papid>and, with single exception, the measure performed below gic; see bp in table 1.</citsent>
<aftsection>
<nextsent>as mentioned before, taxonomy-based similarity measures cannot fully handle bs data.
</nextsent>
<nextsent>table 2 uses nominal-only subsets of bs data and the mc nominal similarity dataset to show that (a) state-of-the-art wordnet-based similarity measure jc8 (jiang and conrath, 1997; budanitsky and hirst, 2006) does very poorly on the relatedness data, suggesting that nominal similarity and relatedness are rather different things; (b) gic does better on average, and ismore robust; (c) gic yields on mc to gain performance on bs, whereas bp is no more inclined to single word which is relatively rarely used in glosses; (b) the multitude of low-ic items in many of the overlaps that tend to downplay the impact of the few higher-ic members of the overlap.
</nextsent>
<nextsent>7to speed the processing up, we use first 5 wordnet senses of each item for results reported here.
</nextsent>
<nextsent>8see formula in appendix b. we use (pedersen et al., 2004) <papid> N04-3012 </papid>implementation with minor alteration ? see beigman klebanov (2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1474">
<title id=" N06-1043.xml">cross entropy and estimation of probabilistic context free grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we prove an unexpected theoretical property of grammars that are trained in this way, namely, we show that the derivational entropy of the grammar takes the same value as the cross entropy between the input distribution andthe grammar itself.
</prevsent>
<prevsent>we show that the result also holds for the widely applied maximum likelihood estimator on treebanks.
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
probabilistic context-free grammars are able to describe hierarchical, tree-shaped structures underlying sentences, and are widely used in statistical natural language processing; see for instance (collins,2003) <papid> J03-4003 </papid>and references therein.</citsent>
<aftsection>
<nextsent>probabilistic context free grammars seem also more suitable than finite state devices for language modeling, and several language models based on these grammars have been recently proposed in the literature; see for instance (chelba and jelinek, 1998), (<papid> P98-1035 </papid>charniak, 2001) <papid> P01-1017 </papid>and (roark, 2001).<papid> J01-2004 </papid></nextsent>
<nextsent>empirical estimation of probabilistic context-free grammars is usually carried out on treebanks, thatis, finite samples of parse trees, through the maximization of the likelihood of the sample itself.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1475">
<title id=" N06-1043.xml">cross entropy and estimation of probabilistic context free grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that the result also holds for the widely applied maximum likelihood estimator on treebanks.
</prevsent>
<prevsent>probabilistic context-free grammars are able to describe hierarchical, tree-shaped structures underlying sentences, and are widely used in statistical natural language processing; see for instance (collins,2003) <papid> J03-4003 </papid>and references therein.</prevsent>
</prevsection>
<citsent citstr=" P98-1035 ">
probabilistic context free grammars seem also more suitable than finite state devices for language modeling, and several language models based on these grammars have been recently proposed in the literature; see for instance (chelba and jelinek, 1998), (<papid> P98-1035 </papid>charniak, 2001) <papid> P01-1017 </papid>and (roark, 2001).<papid> J01-2004 </papid></citsent>
<aftsection>
<nextsent>empirical estimation of probabilistic context-free grammars is usually carried out on treebanks, thatis, finite samples of parse trees, through the maximization of the likelihood of the sample itself.
</nextsent>
<nextsent>it is well-known that this method also minimizes the cross-entropy between the probability distribution induced by the tree bank, also called the empirical distribution, and the tree probability distribution induced by the estimated grammar.in this paper we generalize the maximum likelihood method, proposing an estimation technique that works on any unrestricted tree distribution defined over an infinite set of trees.
</nextsent>
<nextsent>this generalization is theoretically appealing, and allows us to prove unexpected properties of the already mentioned maximum likelihood estimator for treebanks, that were not previously known in the literature on statistical natural language parsing.
</nextsent>
<nextsent>more specifically, we investigate the following information theoretic quantities ? the cross-entropy between the unrestricted tree distribution given as input and the tree distribution induced by the estimated probabilistic context-free grammar; and?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1476">
<title id=" N06-1043.xml">cross entropy and estimation of probabilistic context free grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that the result also holds for the widely applied maximum likelihood estimator on treebanks.
</prevsent>
<prevsent>probabilistic context-free grammars are able to describe hierarchical, tree-shaped structures underlying sentences, and are widely used in statistical natural language processing; see for instance (collins,2003) <papid> J03-4003 </papid>and references therein.</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
probabilistic context free grammars seem also more suitable than finite state devices for language modeling, and several language models based on these grammars have been recently proposed in the literature; see for instance (chelba and jelinek, 1998), (<papid> P98-1035 </papid>charniak, 2001) <papid> P01-1017 </papid>and (roark, 2001).<papid> J01-2004 </papid></citsent>
<aftsection>
<nextsent>empirical estimation of probabilistic context-free grammars is usually carried out on treebanks, thatis, finite samples of parse trees, through the maximization of the likelihood of the sample itself.
</nextsent>
<nextsent>it is well-known that this method also minimizes the cross-entropy between the probability distribution induced by the tree bank, also called the empirical distribution, and the tree probability distribution induced by the estimated grammar.in this paper we generalize the maximum likelihood method, proposing an estimation technique that works on any unrestricted tree distribution defined over an infinite set of trees.
</nextsent>
<nextsent>this generalization is theoretically appealing, and allows us to prove unexpected properties of the already mentioned maximum likelihood estimator for treebanks, that were not previously known in the literature on statistical natural language parsing.
</nextsent>
<nextsent>more specifically, we investigate the following information theoretic quantities ? the cross-entropy between the unrestricted tree distribution given as input and the tree distribution induced by the estimated probabilistic context-free grammar; and?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1477">
<title id=" N06-1043.xml">cross entropy and estimation of probabilistic context free grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that the result also holds for the widely applied maximum likelihood estimator on treebanks.
</prevsent>
<prevsent>probabilistic context-free grammars are able to describe hierarchical, tree-shaped structures underlying sentences, and are widely used in statistical natural language processing; see for instance (collins,2003) <papid> J03-4003 </papid>and references therein.</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
probabilistic context free grammars seem also more suitable than finite state devices for language modeling, and several language models based on these grammars have been recently proposed in the literature; see for instance (chelba and jelinek, 1998), (<papid> P98-1035 </papid>charniak, 2001) <papid> P01-1017 </papid>and (roark, 2001).<papid> J01-2004 </papid></citsent>
<aftsection>
<nextsent>empirical estimation of probabilistic context-free grammars is usually carried out on treebanks, thatis, finite samples of parse trees, through the maximization of the likelihood of the sample itself.
</nextsent>
<nextsent>it is well-known that this method also minimizes the cross-entropy between the probability distribution induced by the tree bank, also called the empirical distribution, and the tree probability distribution induced by the estimated grammar.in this paper we generalize the maximum likelihood method, proposing an estimation technique that works on any unrestricted tree distribution defined over an infinite set of trees.
</nextsent>
<nextsent>this generalization is theoretically appealing, and allows us to prove unexpected properties of the already mentioned maximum likelihood estimator for treebanks, that were not previously known in the literature on statistical natural language parsing.
</nextsent>
<nextsent>more specifically, we investigate the following information theoretic quantities ? the cross-entropy between the unrestricted tree distribution given as input and the tree distribution induced by the estimated probabilistic context-free grammar; and?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1478">
<title id=" N06-1043.xml">cross entropy and estimation of probabilistic context free grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that these two quantities take the same value whenthe probabilistic context-free grammar is trained using the minimal cross-entropy criterion.
</prevsent>
<prevsent>we then translate back this property to the method of maximum likelihood estimation.
</prevsent>
</prevsection>
<citsent citstr=" C92-2066 ">
our general estimation method also has practical applications in cases one uses probabilistic context-free grammar to approximate strictly more powerful rewriting systems, 335as for instance probabilistic tree adjoining grammars (schabes, 1992).<papid> C92-2066 </papid></citsent>
<aftsection>
<nextsent>not much is found in the literature about the estimation of probabilistic grammars from infinite distributions.
</nextsent>
<nextsent>this line of research was started in (nederhof, 2005), <papid> J05-2002 </papid>investigating the problem of training an input probabilistic finite automaton from an infinite tree distribution specified by means of aninput probabilistic context-free grammar.</nextsent>
<nextsent>the problem we consider in this paper can then be seen asa generalization of the above problem, where the in put model to be trained is probabilistic context-free grammar and the input distribution is an unrestricted tree distribution.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1479">
<title id=" N06-1043.xml">cross entropy and estimation of probabilistic context free grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our general estimation method also has practical applications in cases one uses probabilistic context-free grammar to approximate strictly more powerful rewriting systems, 335as for instance probabilistic tree adjoining grammars (schabes, 1992).<papid> C92-2066 </papid></prevsent>
<prevsent>not much is found in the literature about the estimation of probabilistic grammars from infinite distributions.</prevsent>
</prevsection>
<citsent citstr=" J05-2002 ">
this line of research was started in (nederhof, 2005), <papid> J05-2002 </papid>investigating the problem of training an input probabilistic finite automaton from an infinite tree distribution specified by means of aninput probabilistic context-free grammar.</citsent>
<aftsection>
<nextsent>the problem we consider in this paper can then be seen asa generalization of the above problem, where the in put model to be trained is probabilistic context-free grammar and the input distribution is an unrestricted tree distribution.
</nextsent>
<nextsent>in (chi, 1999) <papid> J99-1004 </papid>an estimator that maximizes the likelihood of probability distribution defined over finite set of trees is introduced,as generalization of the maximum likelihood es timator.</nextsent>
<nextsent>again, the problems we consider here can be thought of as generalizations of such estimator to the case of distributions over infinite sets of trees or sentences.the remainder of this paper is structured as fol lows.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1480">
<title id=" N06-1043.xml">cross entropy and estimation of probabilistic context free grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this line of research was started in (nederhof, 2005), <papid> J05-2002 </papid>investigating the problem of training an input probabilistic finite automaton from an infinite tree distribution specified by means of aninput probabilistic context-free grammar.</prevsent>
<prevsent>the problem we consider in this paper can then be seen asa generalization of the above problem, where the in put model to be trained is probabilistic context-free grammar and the input distribution is an unrestricted tree distribution.</prevsent>
</prevsection>
<citsent citstr=" J99-1004 ">
in (chi, 1999) <papid> J99-1004 </papid>an estimator that maximizes the likelihood of probability distribution defined over finite set of trees is introduced,as generalization of the maximum likelihood es timator.</citsent>
<aftsection>
<nextsent>again, the problems we consider here can be thought of as generalizations of such estimator to the case of distributions over infinite sets of trees or sentences.the remainder of this paper is structured as follows.
</nextsent>
<nextsent>section 2 introduces the basic notation and definitions and section 3 discusses our new estimation method.
</nextsent>
<nextsent>section 4 presents our main result, which is transferred in section 5 to the method of maximum likelihood estimation.
</nextsent>
<nextsent>section 6 discusses some simple examples, and section 7 closes with some further discussion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1482">
<title id=" N06-1043.xml">cross entropy and estimation of probabilistic context free grammars </title>
<section> estimation based on cross-entropy.  </section>
<citcontext>
<prevsection>
<prevsent>also, note that the likelihood of an infinite set of derivations would always be zero and therefore cannot be considered here.
</prevsent>
<prevsent>to be used in the next section, we now show that the pcfg obtained as above is consistent.
</prevsent>
</prevsection>
<citsent citstr=" J98-2005 ">
the line of our argument below follows proof provided in (chi and geman, 1998) <papid> J98-2005 </papid>for the maximum likelihood estimator based on finite tree distributions.</citsent>
<aftsection>
<nextsent>without loss of generality, we assume that in the start symbol is never used in the right-hand side of rule.
</nextsent>
<nextsent>for each ? , let qa be the probability that derivation in rooted in fails to terminate.
</nextsent>
<nextsent>we can then write qa ? ?
</nextsent>
<nextsent>bn qb ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1483">
<title id=" N06-1043.xml">cross entropy and estimation of probabilistic context free grammars </title>
<section> cross-entropy and derivational entropy.  </section>
<citcontext>
<prevsection>
<prevsent>using these relations in (12) we obtain qs ? ept f(s, ) ? qs ? ept fc(s, ), from which we conclude qs = 0, thus implying the consistency of g.
</prevsent>
<prevsent>in this section we present the main result of the paper.
</prevsent>
</prevsection>
<citsent citstr=" C04-1011 ">
we show that, when = (g, pg) is estimated by minimizing the cross-entropy in (5), then suchcross-entropy takes the same value as the deriva tional entropy of g, defined in (3).in (nederhof and satta, 2004) <papid> C04-1011 </papid>relations are derived for the exact computation ofhd(pg).</citsent>
<aftsection>
<nextsent>for late ruse, we report these relations below, under the assumption that is consistent (see section 3).
</nextsent>
<nextsent>we have hd(pg) = ? an outg(a) ha(pg).
</nextsent>
<nextsent>(13) quantities ha(pg), ? , have been defined in (4).
</nextsent>
<nextsent>for eacha ? , quantity outg(a) is the sumof the probabilities of all trees generated by g, having root labeled by and having yield composed of terminal symbols with an un expanded occurrence of nonterminal a. again, we assume that symbol does not appear in any of the right-hand sides of the rules in r. this means that only appears atthe root of the trees in (g).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1490">
<title id=" N04-2007.xml">a preliminary look into the use of named entity information for bioscience text tokenization </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the improvement in performance of bacchant-n over bac chant when normalizing inside ne text indicates that named entity information is useful for bioscience text tokenization tasks, motivating future work in systems that perform tokenization and ne tagging concurrently.
</prevsent>
<prevsent>as noted in habert et al  (1998), standard methods for evaluating the quality of tokens produced by tokenization systems do not exist.
</prevsent>
</prevsection>
<citsent citstr=" W03-1309 ">
though necessary first step to tasks such as document retrieval, sentence boundary finding, parsing, etc., there exists work involving these tasks that take tokenization for granted (e.g. chang, schutze and altman (2002), seki and mostafa (2003)), mention tokenization without detailing the tokenization scheme (e.g. fukuda et al  (1998)), or indicate use of tokenization system without mentioning its performance (e.g. bennet et al  (1999), yamamoto et al  (2003)).<papid> W03-1309 </papid></citsent>
<aftsection>
<nextsent>to the author knowledge, there exists no work analyzing the impact of tokenization performance on bio informatics tasks.
</nextsent>
<nextsent>tokenization methods for bio informatics tasks range from simple to complex.
</nextsent>
<nextsent>bennet et al  (1999) tokenized for noun phrase extraction, tokenizing based on whit espace, with additional modification to take specialized nomenclature?
</nextsent>
<nextsent>into account.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1491">
<title id=" N04-2007.xml">a preliminary look into the use of named entity information for bioscience text tokenization </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to the author knowledge, there exists no work analyzing the performance of normalization systems for bioscience literature.
</prevsent>
<prevsent>named entities are proper names and quantities of interest?
</prevsent>
</prevsection>
<citsent citstr=" M98-1001 ">
(chinchor (1998)) <papid> M98-1001 </papid>in document.</citsent>
<aftsection>
<nextsent>named entity tagging involves discovering and marking these entities in document, e.g. finding all proteins in document and labeling them as such.
</nextsent>
<nextsent>having biomedical documents tagged with nes allows for better information extraction, archival, searching, etc. of those documents.
</nextsent>
<nextsent>the genia corpus (kim et al  (2003)) is corpus of 2000 medline abstracts tagged for parts of speech and hand-tagged fornes.
</nextsent>
<nextsent>ne tags in the genia corpus are based on an ontology, consisting of amino acids, proteins, organisms and their tissues, cells, and other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1492">
<title id=" N04-2007.xml">a preliminary look into the use of named entity information for bioscience text tokenization </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>a system of this type involves  tiering  hidden markov models within each other.
</prevsent>
<prevsent>this model could be used to statistically compute the most likely name for section of text, and then normalize appropriately in one pass.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
as hidden markov models have been used both for name finding (bikel et al  (1997)) <papid> A97-1029 </papid>and tokenization (cutting et al .</citsent>
<aftsection>
<nextsent>(1992)), this seems to be promising research possibility.
</nextsent>
<nextsent>this paper has introduced system to normalize bioscience and health articles based on learning features surrounding punctuation which may need to be removed for normalization.
</nextsent>
<nextsent>the system performed significantly better than the baseline system.
</nextsent>
<nextsent>by analyzing the system performance on named entity data from the genia corpus, it was discovered that named entities seemed to be more difficult to normalize than surrounding non-named text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1493">
<title id=" N06-2009.xml">answering the question you wish they had asked the impact of paraphrasing for question answering </title>
<section> mt-based automatic paraphrasing.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1: example of lexical and syntactical paraphrases via mt-paraphrasing using babelfish.
</prevsent>
<prevsent>to measure the impact of paraphrases on qa systems, we seek to adopt methodology by which paraphrases can be automatically generated from auser question.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
inspired by the use of parallel translations to mine paraphrasing lexicons (barzilay and mckeown, 2001) <papid> P01-1008 </papid>and the use of mt engines forword sense disambiguation (diab, 2000), <papid> W00-0801 </papid>we leverage existing machine translation systems to generate semantically equivalent, albeit lexically and syntactically distinct, questions.figure 1 (a) illustrates how mt-based paraphrasing captures lexical paraphrasing, ranging from obtaining simple synonyms such as hazardous and dangerous to deriving more complex equivalent phrases such as expectant mother and pregnant woman.</citsent>
<aftsection>
<nextsent>in addition to lexical paraphrasing, sometwo-way translations achieve structural paraphrasing, as illustrated by the example in figure 1 (b).
</nextsent>
<nextsent>using multiple mt engines can help paraphrase diversity.
</nextsent>
<nextsent>for example, in figure 1 (b), if we use the@promt translator5 for english-to-spanish translation and babelfish6 for spanish-to-english translation, we get find out on the nuclear armament program of india?
</nextsent>
<nextsent>where both lexical and structural para phrasings are observed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1494">
<title id=" N06-2009.xml">answering the question you wish they had asked the impact of paraphrasing for question answering </title>
<section> mt-based automatic paraphrasing.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1: example of lexical and syntactical paraphrases via mt-paraphrasing using babelfish.
</prevsent>
<prevsent>to measure the impact of paraphrases on qa systems, we seek to adopt methodology by which paraphrases can be automatically generated from auser question.
</prevsent>
</prevsection>
<citsent citstr=" W00-0801 ">
inspired by the use of parallel translations to mine paraphrasing lexicons (barzilay and mckeown, 2001) <papid> P01-1008 </papid>and the use of mt engines forword sense disambiguation (diab, 2000), <papid> W00-0801 </papid>we leverage existing machine translation systems to generate semantically equivalent, albeit lexically and syntactically distinct, questions.figure 1 (a) illustrates how mt-based paraphrasing captures lexical paraphrasing, ranging from obtaining simple synonyms such as hazardous and dangerous to deriving more complex equivalent phrases such as expectant mother and pregnant woman.</citsent>
<aftsection>
<nextsent>in addition to lexical paraphrasing, sometwo-way translations achieve structural paraphrasing, as illustrated by the example in figure 1 (b).
</nextsent>
<nextsent>using multiple mt engines can help paraphrase diversity.
</nextsent>
<nextsent>for example, in figure 1 (b), if we use the@promt translator5 for english-to-spanish translation and babelfish6 for spanish-to-english translation, we get find out on the nuclear armament program of india?
</nextsent>
<nextsent>where both lexical and structural para phrasings are observed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1495">
<title id=" N06-2009.xml">answering the question you wish they had asked the impact of paraphrasing for question answering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, random selection of paraphrases decreased performance to 0.156, clearly showing the importance of selecting good paraphrase.
</prevsent>
<prevsent>8http://translate.google.com 35
</prevsent>
</prevsection>
<citsent citstr=" W03-1604 ">
most of the work in qa and paraphrasing focused on folding paraphrasing knowledge into the question analyzer or the answer locator (rinaldi et al, 2003; <papid> W03-1604 </papid>tomuro, 2003).<papid> W03-1605 </papid></citsent>
<aftsection>
<nextsent>our work, on the contrary, focuses on question paraphrasing as an external component, independent of the qa system architecture.
</nextsent>
<nextsent>some authors (dumais et al, 2002; echihabi etal., 2004) considered the query sent to search engine as paraphrase?
</nextsent>
<nextsent>of the original natural language question.
</nextsent>
<nextsent>for instance, echihabi et al (2004) presented large number of reformulations?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1496">
<title id=" N06-2009.xml">answering the question you wish they had asked the impact of paraphrasing for question answering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, random selection of paraphrases decreased performance to 0.156, clearly showing the importance of selecting good paraphrase.
</prevsent>
<prevsent>8http://translate.google.com 35
</prevsent>
</prevsection>
<citsent citstr=" W03-1605 ">
most of the work in qa and paraphrasing focused on folding paraphrasing knowledge into the question analyzer or the answer locator (rinaldi et al, 2003; <papid> W03-1604 </papid>tomuro, 2003).<papid> W03-1605 </papid></citsent>
<aftsection>
<nextsent>our work, on the contrary, focuses on question paraphrasing as an external component, independent of the qa system architecture.
</nextsent>
<nextsent>some authors (dumais et al, 2002; echihabi etal., 2004) considered the query sent to search engine as paraphrase?
</nextsent>
<nextsent>of the original natural language question.
</nextsent>
<nextsent>for instance, echihabi et al (2004) presented large number of reformulations?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1497">
<title id=" N03-1029.xml">comma restoration using constituency information </title>
<section> commas and constituency.  </section>
<citcontext>
<prevsection>
<prevsent>(figure 1 lists performance figures as model 3.)of course, this result does not provide practical algorithm for comma restoration, as it is based on probabilistic model that requires data from manually constructed parse for the sentence to be restored.
</prevsent>
<prevsent>to make the method practical, we might replace the treebank parse with statistically generated parse.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
in the sequel, we usecollinss statistical parser (collins, 1997) <papid> P97-1003 </papid>as our canonical automated approximation of the treebank.</citsent>
<aftsection>
<nextsent>we can train similar model, but using ec values extracted from 6alternative backoff paths, for instance backing off first to p(yi | yi2yi1), exhibit inferior performance.
</nextsent>
<nextsent>7with = 2 (model 4), precision drops precipitously to 60.4%, recall stays roughly the same at 66.4%.
</nextsent>
<nextsent>in fo so rc es tr in in te st in trigram insertion penalty word class ec,threshold=2 ec,threshold=3 ec,nothreshold stemmer treebank collinsparse,commas collinsparse,nocommas treebank collinsparse,commas collinsparse,nocommas model number precision recall f-measure token accuracy sentence accuracy reductioninsentenceerror?
</nextsent>
<nextsent>1 . 71 1 . 55 2 . 62 1 . 96 3 . 47 0 . 00 0 ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1498">
<title id=" N03-1029.xml">comma restoration using constituency information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(this problem is distinct from the problem of sentence boundary disambiguation, where punctuation is provided, but the categorization of the punctuation as to whether or not 9an alternative method of resolving the data sparsity issues is to back off the model p(yi | yi2yi1eci), for instance to p(yi | yi2yi1) or to p(yi | yi1eci).
</prevsent>
<prevsent>both of these perform less well than the approximation in model 8.
</prevsent>
</prevsection>
<citsent citstr=" A94-1013 ">
it marks sentence boundary is at issue (palmer and hearst, 1994; <papid> A94-1013 </papid>reynar and ratnaparkhi, 1997).)<papid> A97-1004 </papid></citsent>
<aftsection>
<nextsent>stolcke and shriberg (1996) used hmms for the related problem of linguistic segmentation of text, where the segments corresponded to sentences and other self-contained units such as disfluencies and interjections.
</nextsent>
<nextsent>they argue that alinguistic segmentation is useful for improving the performance and utility of language models and speech rec ognizers.
</nextsent>
<nextsent>like the present work, they segment clean text rather than automatically transcribed speech.
</nextsent>
<nextsent>stevenson and gaizauskas (stevenson and gaizauskas, 2000) <papid> A00-1012 </papid>and goto and renals (gotoh and renals, 2000) address the sentence boundary detection problem directly, again using lexical and, in the latter, prosodic cues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1499">
<title id=" N03-1029.xml">comma restoration using constituency information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(this problem is distinct from the problem of sentence boundary disambiguation, where punctuation is provided, but the categorization of the punctuation as to whether or not 9an alternative method of resolving the data sparsity issues is to back off the model p(yi | yi2yi1eci), for instance to p(yi | yi2yi1) or to p(yi | yi1eci).
</prevsent>
<prevsent>both of these perform less well than the approximation in model 8.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
it marks sentence boundary is at issue (palmer and hearst, 1994; <papid> A94-1013 </papid>reynar and ratnaparkhi, 1997).)<papid> A97-1004 </papid></citsent>
<aftsection>
<nextsent>stolcke and shriberg (1996) used hmms for the related problem of linguistic segmentation of text, where the segments corresponded to sentences and other self-contained units such as disfluencies and interjections.
</nextsent>
<nextsent>they argue that alinguistic segmentation is useful for improving the performance and utility of language models and speech rec ognizers.
</nextsent>
<nextsent>like the present work, they segment clean text rather than automatically transcribed speech.
</nextsent>
<nextsent>stevenson and gaizauskas (stevenson and gaizauskas, 2000) <papid> A00-1012 </papid>and goto and renals (gotoh and renals, 2000) address the sentence boundary detection problem directly, again using lexical and, in the latter, prosodic cues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1500">
<title id=" N03-1029.xml">comma restoration using constituency information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they argue that alinguistic segmentation is useful for improving the performance and utility of language models and speech rec ognizers.
</prevsent>
<prevsent>like the present work, they segment clean text rather than automatically transcribed speech.
</prevsent>
</prevsection>
<citsent citstr=" A00-1012 ">
stevenson and gaizauskas (stevenson and gaizauskas, 2000) <papid> A00-1012 </papid>and goto and renals (gotoh and renals, 2000) address the sentence boundary detection problem directly, again using lexical and, in the latter, prosodic cues.</citsent>
<aftsection>
<nextsent>the experiments reported here ? like much of the previous work in comma restoration (beeferman et al, 1998) and sentence boundary disambiguation and restoration(stolcke and shriberg, 1996; shriberg et al, 2001; go toh and renals, 2000; stevenson and gaizauskas, 2000) <papid> A00-1012 </papid>(though not all (christensen et al, 2001; stolcke et al,1998; kim and woodland, 2001)) ? assume an ideal reference transcription of the text.</nextsent>
<nextsent>the performance of the method on automatically transcribed speech with its concomitant error remains to be determined.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1503">
<title id=" N03-1029.xml">comma restoration using constituency information </title>
<section> future work and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>nonetheless, prosodic features were still useful in improving the reconstructed punctuation even in the automatically transcribed case.
</prevsent>
<prevsent>the simple hmm model that we inherit from earlier work dramatically limits the features of the parse that we can easily appeal to in predicting comma locations.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
many alternatives suggest themselves to expand the options, including maximum entropy models, which have been previously successfully applied to, inter alia, sentence boundary detection (reynar and ratnaparkhi, 1997), <papid> A97-1004 </papid>and transformation-based learning, as used in part-of-speech tagging and statistical parsing applications (brill, 1995).<papid> J95-4004 </papid></citsent>
<aftsection>
<nextsent>in addition, all of the methods above are essentiallynonhierarchical, based as they are on hmms.
</nextsent>
<nextsent>an alternative approach would use the statistical parsing model itself as model of comma placement, that is, to select the comma placement for string such that the resulting reconstructed string has maximum likelihood under the statistical parsing model.
</nextsent>
<nextsent>this approach has the benefit that the ramifications of comma placement on all aspects of the syntactic structure are explored, but the disadvantage that the longer distance lexical relationships found in trigram model are eliminated.
</nextsent>
<nextsent>nonetheless, even under these severe constraints and using quite simple features distilled from the parse, we can reduce sentence error by 20%, with the potential of another 8% if statistical parsers were to approach tree bank quality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1504">
<title id=" N06-1033.xml">synchronous binarization for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the complexity is exponential in the size of individual grammar rules due to arbitrary re-orderings between the two languages, and rules extracted from parallel corpora can be quite large.
</prevsent>
<prevsent>we devise linear-time algorithm for factoring syntactic re-orderings by bi narizing synchronous rules when possible and show that the resulting rule set significantly improves the speed and accuracy of state-of-the-art syntax-based machine translation system.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
several recent syntax-based models for machine translation (chiang, 2005; <papid> P05-1033 </papid>galley et al , 2004) <papid> N04-1035 </papid>can be seen as instances of the general framework of synchronous grammars and tree transducers.</citsent>
<aftsection>
<nextsent>in this framework, both alignment (synchronous parsing) and decoding can be thought of as parsing problems, whose complexity is in general exponential in the number of nonterminals on the right hand side of agr ammar rule.
</nextsent>
<nextsent>to alleviate this problem, we investigate bilingual binarization to factor the synchronous grammar to smaller branching factor, although it is not guaranteed to be successful for any synchronous rule with arbitrary permutation.
</nextsent>
<nextsent>in particular:?
</nextsent>
<nextsent>we develop technique called synchronous binarization and devise fast binarization algorithm such that the resulting rule set al ows efficient algorithms for both synchronous parsing and decoding with integrated n-gram language models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1505">
<title id=" N06-1033.xml">synchronous binarization for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the complexity is exponential in the size of individual grammar rules due to arbitrary re-orderings between the two languages, and rules extracted from parallel corpora can be quite large.
</prevsent>
<prevsent>we devise linear-time algorithm for factoring syntactic re-orderings by bi narizing synchronous rules when possible and show that the resulting rule set significantly improves the speed and accuracy of state-of-the-art syntax-based machine translation system.
</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
several recent syntax-based models for machine translation (chiang, 2005; <papid> P05-1033 </papid>galley et al , 2004) <papid> N04-1035 </papid>can be seen as instances of the general framework of synchronous grammars and tree transducers.</citsent>
<aftsection>
<nextsent>in this framework, both alignment (synchronous parsing) and decoding can be thought of as parsing problems, whose complexity is in general exponential in the number of nonterminals on the right hand side of agr ammar rule.
</nextsent>
<nextsent>to alleviate this problem, we investigate bilingual binarization to factor the synchronous grammar to smaller branching factor, although it is not guaranteed to be successful for any synchronous rule with arbitrary permutation.
</nextsent>
<nextsent>in particular:?
</nextsent>
<nextsent>we develop technique called synchronous binarization and devise fast binarization algorithm such that the resulting rule set al ows efficient algorithms for both synchronous parsing and decoding with integrated n-gram language models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1506">
<title id=" N06-1033.xml">synchronous binarization for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we develop technique called synchronous binarization and devise fast binarization algorithm such that the resulting rule set al ows efficient algorithms for both synchronous parsing and decoding with integrated n-gram language models.
</prevsent>
<prevsent>we examine the effect of this binarization method on end-to-end machine translation quality, compared to more typical baseline method.
</prevsent>
</prevsection>
<citsent citstr=" N03-1021 ">
we examine cases of non-binarizable rules in alarge, empirically-derived rule set, and we investigate the effect on translation quality when excluding such rules.melamed (2003) <papid> N03-1021 </papid>discusses binarization of multi text grammars on theoretical level, showing the importance and difficulty of binarization for efficient synchronous parsing.</citsent>
<aftsection>
<nextsent>one way around this difficulty is to stipulate that all rules must be binary from the outset, as in inversion-transduction grammar (itg) (wu, 1997) <papid> J97-3002 </papid>and the binary synchronouscontext-free grammar (scfg) employed by the hi ero system (chiang, 2005) <papid> P05-1033 </papid>to model the hierarchical phrases.</nextsent>
<nextsent>in contrast, the rule extraction method of galley et al  (2004) <papid> N04-1035 </papid>aims to incorporate more syntactic information by providing parse trees for the target language and extracting tree transducer rules that apply to the parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1507">
<title id=" N06-1033.xml">synchronous binarization for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we examine the effect of this binarization method on end-to-end machine translation quality, compared to more typical baseline method.
</prevsent>
<prevsent>we examine cases of non-binarizable rules in alarge, empirically-derived rule set, and we investigate the effect on translation quality when excluding such rules.melamed (2003) <papid> N03-1021 </papid>discusses binarization of multi text grammars on theoretical level, showing the importance and difficulty of binarization for efficient synchronous parsing.</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
one way around this difficulty is to stipulate that all rules must be binary from the outset, as in inversion-transduction grammar (itg) (wu, 1997) <papid> J97-3002 </papid>and the binary synchronouscontext-free grammar (scfg) employed by the hi ero system (chiang, 2005) <papid> P05-1033 </papid>to model the hierarchical phrases.</citsent>
<aftsection>
<nextsent>in contrast, the rule extraction method of galley et al  (2004) <papid> N04-1035 </papid>aims to incorporate more syntactic information by providing parse trees for the target language and extracting tree transducer rules that apply to the parses.</nextsent>
<nextsent>this approach results inrules with many nonterminals, making good bina riz ation techniques critical.suppose we have the following scfg, where su per scripts indicate reorderings (formal definitions of 256 np baoweier pp yu shalong vp juxing le huitan np powell vp held meeting pp with sharon figure 1: pair of synchronous parse trees in thescfg (1).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1511">
<title id=" N06-1033.xml">synchronous binarization for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to do bigram-integrated decoding, we need to augment each chart item (x, i, j) with two target-language 1other parsing strategies like the earley algorithm use an internal binary representation (e.g. dotted-rules) of the original grammar to ensure cubic time complexity.
</prevsent>
<prevsent>boundary words and to produce bigram-item like ( ???
</prevsent>
</prevsection>
<citsent citstr=" P96-1021 ">
vx j ), following the dynamic programming algorithm of wu (1996).<papid> P96-1021 </papid>now the two binarizations have very different ef fects.</citsent>
<aftsection>
<nextsent>in the first case, we first combine np with pp: ( powell ???
</nextsent>
<nextsent>powellnp 1 2 ) : ( with ???
</nextsent>
<nextsent>sharonpp 2 4 ) : ( powell ???
</nextsent>
<nextsent>powell ???
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1512">
<title id=" N06-1033.xml">synchronous binarization for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this scheme generalizes to the case where we have nonterminals in scfg rule, and the decoder conservatively assumes nothing can be done on language model scoring (because target-language spans are non-contiguous in general) until the real nonterminal has been recognized.
</prevsent>
<prevsent>in other words, target language boundary words from each child nonterminal of the rule will be cached in all virtual nonterminals derived from this rule.
</prevsent>
</prevsection>
<citsent citstr=" W05-1507 ">
in the case of m-gram integrated decoding, we have to maintain2(m ? 1) boundary words for each child nonterminal, which leads to prohibitive overall complexity of o(|w|3+2n(m1)), which is exponential in rule size (huang et al , 2005).<papid> W05-1507 </papid></citsent>
<aftsection>
<nextsent>aggressive pruning must be used to make it tractable in practice, which in general introduces many search errors and adversely affects translation quality.
</nextsent>
<nextsent>in the second case, however: ( with ???
</nextsent>
<nextsent>sharonpp 2 4 ) : ( held ???
</nextsent>
<nextsent>meetingvp 4 7 ) : ( held ???
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1516">
<title id=" N06-1033.xml">synchronous binarization for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>np(1) vpp-vp(2), np(1) vpp-vp(2)vpp-vp ? vp(1) pp(2), pp(2) vp(1) in this case m-gram integrated decoding can bedone in o(|w|3+4(m1)) time which is much lower order polynomial and no longer depends on rule size (wu, 1996), <papid> P96-1021 </papid>allowing the search to be much faster and more accurate facing pruning, as is evidenced in the hiero system of chiang (2005) <papid> P05-1033 </papid>where he restricts the hierarchical phrases to be binary scfg.</prevsent>
<prevsent>the benefit of binary grammars also lies in synchronous parsing (alignment).</prevsent>
</prevsection>
<citsent citstr=" H05-1101 ">
wu (1997) <papid> J97-3002 </papid>shows that parsing binary scfg is in o(|w|6) while parsing scfg is np-hard in general (satta and peserico, 2005).<papid> H05-1101 </papid></citsent>
<aftsection>
<nextsent>the same reasoning applies to tree transducer rules.
</nextsent>
<nextsent>suppose we have the following tree-to-string rules, following galley et al  (2004): (<papid> N04-1035 </papid>3) s(x0:np, vp(x2:vp, x1:pp))?</nextsent>
<nextsent>x0 x1 x2np(nnp(powell))?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1518">
<title id=" N06-1033.xml">synchronous binarization for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this system can model non isomorphic transformations on english parse trees to fit?
</prevsent>
<prevsent>another language, for example, learning thatthe (s (v o)) structure in english should be transformed into (v o) structure in arabic, by looking at two-level tree fragments (knight and graehl, 2005).
</prevsent>
</prevsection>
<citsent citstr=" P03-2041 ">
from synchronous rewriting point of view, this is more akin to synchronous tree substitution grammar (stsg) (eisner, 2003).<papid> P03-2041 </papid></citsent>
<aftsection>
<nextsent>this larger locality is linguistically motivated and leads to better parameter estimation.
</nextsent>
<nextsent>by imagining the left-hand-sidetrees as special nonterminals, we can virtually create an scfg with the same generative capacity.
</nextsent>
<nextsent>the technical details will be explained in section 3.2.in general, if we are given an arbitrary synchronous rule with many nonterminals, what are the good decompositions that lead to binary grammar figure 2 suggests that binarization is good if every virtual nonterminal has contiguous spans on both sides.
</nextsent>
<nextsent>we formalize this idea in the next section.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1531">
<title id=" N06-1033.xml">synchronous binarization for machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>figure 7 demonstrates that decoding accuracy is significantly improved after synchronous binarization.
</prevsent>
<prevsent>the number of edges proposed during decoding is used as measure of the size of search space, or time efficiency.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
our system is consistently faster and more accurate than the baseline system.we also compare the top result of our synchronous binarization system with the state-of-the art alignment-template approach (ats) (och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>the results are shown in table 1.
</nextsent>
<nextsent>our system has promising improvement over the ats 262 33.5 34.5 35.5 36.5 37.5 38.5 3e+09 4e+09 5e+09 6e+09 7e+09 bl eu co re # of edges proposed during decoding synchronous binarization monolingual binarization figure 7: comparing the two binarization methods in terms of translation quality against search effort.
</nextsent>
<nextsent>system which is trained on larger data-set but tuned independently.
</nextsent>
<nextsent>modeling reorderings between languages has been major challenge for machine translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1532">
<title id=" N06-1033.xml">synchronous binarization for machine translation </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>our work shows how to convert it back to computationally friendly form without harming much of its expressiveness.
</prevsent>
<prevsent>as result, decoding with n-gram models can be fast and accurate, making it possible for our syntax-basedsystem to overtake comparable phrase-based system in bleu score.
</prevsent>
</prevsection>
<citsent citstr=" C90-3045 ">
we believe that extensions ofour technique to more powerful models such as synchronous tree-adjoining grammar (shieber and schabes, 1990) <papid> C90-3045 </papid>is an interesting area for further work.</citsent>
<aftsection>
<nextsent>acknowledgments much of this work was done when h. zhang and l. huang were visiting usc/isi.
</nextsent>
<nextsent>the authors wish to thank wei wang, jonathan graehl and steven deneefe for help with the experiments.
</nextsent>
<nextsent>we are also grateful to danielmarcu, giorgio satta, and aravind joshi for discussions.
</nextsent>
<nextsent>this work was partially supported by nsf itr iis-09325646 and nsf itr iis-0428020.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1533">
<title id=" N07-1052.xml">approximate factoring for a search </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>search (hart et al, 1968); however, successfully using asearch is challenging in practice.
</prevsent>
<prevsent>the design of admissible (or nearly admissible) heuristics which are both effective (close to actual completion costs) andalso efficient to compute is difficult, open problem in most domains.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
as result, most work on search has focused on non-optimal methods, such as beam search or pruning based on approximate models (collins, 1999), though in certain cases admissible heuristics are known (och and ney, 2000; <papid> P00-1056 </papid>zhang and gildea, 2006).<papid> W06-1627 </papid></citsent>
<aftsection>
<nextsent>for example, klein and manning (2003) show class of projection-based a?
</nextsent>
<nextsent>estimates, but their application is limited to models which have very restrictive kind of score decomposition.
</nextsent>
<nextsent>in this work, we broaden their projection based technique to give a?
</nextsent>
<nextsent>estimates for models which do not factor in this restricted way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1534">
<title id=" N07-1052.xml">approximate factoring for a search </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>search (hart et al, 1968); however, successfully using asearch is challenging in practice.
</prevsent>
<prevsent>the design of admissible (or nearly admissible) heuristics which are both effective (close to actual completion costs) andalso efficient to compute is difficult, open problem in most domains.
</prevsent>
</prevsection>
<citsent citstr=" W06-1627 ">
as result, most work on search has focused on non-optimal methods, such as beam search or pruning based on approximate models (collins, 1999), though in certain cases admissible heuristics are known (och and ney, 2000; <papid> P00-1056 </papid>zhang and gildea, 2006).<papid> W06-1627 </papid></citsent>
<aftsection>
<nextsent>for example, klein and manning (2003) show class of projection-based a?
</nextsent>
<nextsent>estimates, but their application is limited to models which have very restrictive kind of score decomposition.
</nextsent>
<nextsent>in this work, we broaden their projection based technique to give a?
</nextsent>
<nextsent>estimates for models which do not factor in this restricted way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1535">
<title id=" N07-1052.xml">approximate factoring for a search </title>
<section> bitext parsing.  </section>
<citcontext>
<prevsection>
<prevsent>is the length of the longest optimal solution for the original problem.
</prevsent>
<prevsent>then, h(s) ? h?(s) + lmax, ? s. this ?-admissible heuristic (ghallab and allard, 1982) bounds our search error by lmax.3
</prevsent>
</prevsection>
<citsent citstr=" P04-1084 ">
in bitext parsing, one jointly infers synchronous phrase structure tree over sentence ws and its translation wt (melamed et al, 2004; <papid> P04-1084 </papid>wu, 1997).<papid> J97-3002 </papid></citsent>
<aftsection>
<nextsent>bitext parsing is natural candidate task for our approximate factoring technique.
</nextsent>
<nextsent>a synchronous tree projects monolingual phrase structure trees onto each sentence.
</nextsent>
<nextsent>however, the costs assigned by weighted synchronous grammar (wsg) do not typically factor into independent monolingualwcfgs.
</nextsent>
<nextsent>we can, however, produce useful surro gate: pair of monolingual wcfgs with structures projected by and weights that, when combined, underestimate the costs of g.parsing optimally relative to synchronous grammar using dynamic program requires time o(n6) in the length of the sentence (wu, 1997).<papid> J97-3002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1536">
<title id=" N07-1052.xml">approximate factoring for a search </title>
<section> bitext parsing.  </section>
<citcontext>
<prevsection>
<prevsent>is the length of the longest optimal solution for the original problem.
</prevsent>
<prevsent>then, h(s) ? h?(s) + lmax, ? s. this ?-admissible heuristic (ghallab and allard, 1982) bounds our search error by lmax.3
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
in bitext parsing, one jointly infers synchronous phrase structure tree over sentence ws and its translation wt (melamed et al, 2004; <papid> P04-1084 </papid>wu, 1997).<papid> J97-3002 </papid></citsent>
<aftsection>
<nextsent>bitext parsing is natural candidate task for our approximate factoring technique.
</nextsent>
<nextsent>a synchronous tree projects monolingual phrase structure trees onto each sentence.
</nextsent>
<nextsent>however, the costs assigned by weighted synchronous grammar (wsg) do not typically factor into independent monolingualwcfgs.
</nextsent>
<nextsent>we can, however, produce useful surro gate: pair of monolingual wcfgs with structures projected by and weights that, when combined, underestimate the costs of g.parsing optimally relative to synchronous grammar using dynamic program requires time o(n6) in the length of the sentence (wu, 1997).<papid> J97-3002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1540">
<title id=" N07-1052.xml">approximate factoring for a search </title>
<section> bitext parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in each weighted rule, an aligned pair of nonterminals generates two ordered lists of children.
</prevsent>
<prevsent>the non-terminals in each list must align one-to-one to the non-terminals in the other, while the terminals are placed freely on either side.
</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
figure 3(a) shows an example rule.following galley et al (2004), <papid> N04-1035 </papid>we learn grammar by projecting english syntax onto foreign language via word-level alignments, as in figure 3(b).7 we parsed 1200 english-spanish sentences using grammar learned from 40,000 sentence pairs of the english-spanish europarl corpus.8 figure 4(a) shows that a?</citsent>
<aftsection>
<nextsent>expands substantially fewer states while searching for the optimal parse with our op 7the bilingual corpus consists of translation pairs with fixed english parses and word alignments.
</nextsent>
<nextsent>rules were scored by their relative frequencies.
</nextsent>
<nextsent>8rare words were replaced with their parts of speech to limit the memory consumption of the parser.
</nextsent>
<nextsent>(a) ? np(s) np(t) ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1545">
<title id=" N07-1033.xml">using annotator rationales to improve machine learning for text categorization </title>
<section> rationale annotation for movie reviews.  </section>
<citcontext>
<prevsection>
<prevsent>(0, xij) ? 1?
</prevsent>
<prevsent>ij . in our experiments, we optimize ?, c, and ccontrast on held-out data (see section 5.2).
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
in order to demonstrate that annotator rationales help machine learning, we needed annotated data that included rationales for the annotations.we chose dataset that would be enjoyable to re annotate: the movie review dataset of (pang et al, 2002; <papid> W02-1011 </papid>pang and lee, 2004).<papid> P04-1035 </papid>3 the dataset consists of 1000 positive and 1000 negative movie reviews obtained from the internet movie database (imdb) review archive, all written before 2002 by total of 312 authors, with cap of 20 reviews per author per 2taking ccontrast to be constant means that all rationales are equally valuable.</citsent>
<aftsection>
<nextsent>one might instead choose, for example, to reduce ccontrast for examples xi that have many rationales, to prevent xis contrast examples vij from together dominating the optimization.
</nextsent>
<nextsent>however, in this paper we assume that an xi with more rationales really does provide more evidence about the true classifier ~w. 3polarity dataset version 2.0.
</nextsent>
<nextsent>261category.
</nextsent>
<nextsent>pang and lee have divided the 2000 documents into 10 folds, each consisting of 100 positive reviews and 100 negative reviews.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1546">
<title id=" N07-1033.xml">using annotator rationales to improve machine learning for text categorization </title>
<section> rationale annotation for movie reviews.  </section>
<citcontext>
<prevsection>
<prevsent>(0, xij) ? 1?
</prevsent>
<prevsent>ij . in our experiments, we optimize ?, c, and ccontrast on held-out data (see section 5.2).
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
in order to demonstrate that annotator rationales help machine learning, we needed annotated data that included rationales for the annotations.we chose dataset that would be enjoyable to re annotate: the movie review dataset of (pang et al, 2002; <papid> W02-1011 </papid>pang and lee, 2004).<papid> P04-1035 </papid>3 the dataset consists of 1000 positive and 1000 negative movie reviews obtained from the internet movie database (imdb) review archive, all written before 2002 by total of 312 authors, with cap of 20 reviews per author per 2taking ccontrast to be constant means that all rationales are equally valuable.</citsent>
<aftsection>
<nextsent>one might instead choose, for example, to reduce ccontrast for examples xi that have many rationales, to prevent xis contrast examples vij from together dominating the optimization.
</nextsent>
<nextsent>however, in this paper we assume that an xi with more rationales really does provide more evidence about the true classifier ~w. 3polarity dataset version 2.0.
</nextsent>
<nextsent>261category.
</nextsent>
<nextsent>pang and lee have divided the 2000 documents into 10 folds, each consisting of 100 positive reviews and 100 negative reviews.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1549">
<title id=" N07-1033.xml">using annotator rationales to improve machine learning for text categorization </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>however, to simulate real limited-data training conditions, one should then find the ??
</prevsent>
<prevsent>for each {i, ..., j} using separate cross-validation within {i, ..., j} only; this would slow down the experiments considerably.
</prevsent>
</prevsection>
<citsent citstr=" P04-1034 ">
10for optimizing along the dimension, one could use the efficient method of beineke et al (2004), <papid> P04-1034 </papid>but not in svmlight.the lower three curves (s3s5) show that learning is separately helped by the rationale and the non-rationale portions of the documents.</citsent>
<aftsection>
<nextsent>s3s5 are degraded versions of the baseline s2: they are ordinary svm classifiers that perform significantly worse than s2 (p   0.001).removing the rationale phrases from the training documents (s3) made the test documents much harder to discriminate (compared to s2).
</nextsent>
<nextsent>this suggests that annotator a0s rationales often covered most of the usable evidence for the true class.
</nextsent>
<nextsent>however, the pieces to solving the classification puzzle cannot be found solely in the short rationale phrases.
</nextsent>
<nextsent>removing all non-rationale text from the training documents (s5) was even worse than removing the rationales (s3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1550">
<title id=" N06-1061.xml">language model based document clustering using random walks </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>first, the success of language modeling approaches to information retrieval (ponte and croft, 1998) is encouraging for similar twist to document representation for clustering purposes.
</prevsent>
<prevsent>second, graph-based inference techniques to discover hidden?
</prevsent>
</prevsection>
<citsent citstr=" W04-3252 ">
textual relationships like the one we explored in our random walk model have been successfully applied to other nlp problems such as summarization (erkan and radev, 2004; mihalcea and ta rau, 2004; <papid> W04-3252 </papid>zha, 2002), prepositional phrase attachment (toutanova et al, 2004), and word sense disambiguation (mihalcea, 2005).<papid> H05-1052 </papid></citsent>
<aftsection>
<nextsent>unlike our approach, these methods try to exploit the global structure of graph to rank the nodes of the graph.
</nextsent>
<nextsent>for example, erkan and radev (2004) find the stationary distribution of the random walk on agraph of sentences to rank the salience scores of the sentences for extractive summarization.
</nextsent>
<nextsent>their link weight function is based on cosine similarity.
</nextsent>
<nextsent>our graph construction based on generation probabilities is inherited from (kurland and lee, 2005), where authors used similar generation graph to rerank the documents returned by retrieval system based on the stationary distribution of the graph.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1551">
<title id=" N06-1061.xml">language model based document clustering using random walks </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>first, the success of language modeling approaches to information retrieval (ponte and croft, 1998) is encouraging for similar twist to document representation for clustering purposes.
</prevsent>
<prevsent>second, graph-based inference techniques to discover hidden?
</prevsent>
</prevsection>
<citsent citstr=" H05-1052 ">
textual relationships like the one we explored in our random walk model have been successfully applied to other nlp problems such as summarization (erkan and radev, 2004; mihalcea and ta rau, 2004; <papid> W04-3252 </papid>zha, 2002), prepositional phrase attachment (toutanova et al, 2004), and word sense disambiguation (mihalcea, 2005).<papid> H05-1052 </papid></citsent>
<aftsection>
<nextsent>unlike our approach, these methods try to exploit the global structure of graph to rank the nodes of the graph.
</nextsent>
<nextsent>for example, erkan and radev (2004) find the stationary distribution of the random walk on agraph of sentences to rank the salience scores of the sentences for extractive summarization.
</nextsent>
<nextsent>their link weight function is based on cosine similarity.
</nextsent>
<nextsent>our graph construction based on generation probabilities is inherited from (kurland and lee, 2005), where authors used similar generation graph to rerank the documents returned by retrieval system based on the stationary distribution of the graph.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1552">
<title id=" N07-1015.xml">a systematic exploration of the feature space for relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent studies on relation extraction have shown the advantages of discriminative model-based statistical machine learning approach to this problem.
</prevsent>
<prevsent>there are generally two lines of work following thisapproach.
</prevsent>
</prevsection>
<citsent citstr=" P04-3022 ">
the first utilizes set of carefully selected features obtained from different levels of text analysis, from part-of-speech (pos) tagging to full parsing and dependency parsing (kambhatla, 2004; <papid> P04-3022 </papid>zhao and grishman, 2005; <papid> P05-1052 </papid>zhou et al, 2005)<papid> P05-1053 </papid>1.</citsent>
<aftsection>
<nextsent>the second line of work designs kernel functions on some structured representation (sequences or trees)of the relation instances to capture the similarity between two relation instances (zelenko et al, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>bunescu and mooney, 2005<papid> H05-1091 </papid>a; bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al, 2006<papid> P06-1104 </papid>a; zhang et al, 2006<papid> P06-1104 </papid>b).</nextsent>
<nextsent>of particular interest among the various kernels proposed are the convolution kernels (bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al., 2006<papid> P06-1104 </papid>a), because they can efficiently compute the similarity between two instances in huge feature space due to their recursive nature.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1553">
<title id=" N07-1015.xml">a systematic exploration of the feature space for relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent studies on relation extraction have shown the advantages of discriminative model-based statistical machine learning approach to this problem.
</prevsent>
<prevsent>there are generally two lines of work following thisapproach.
</prevsent>
</prevsection>
<citsent citstr=" P05-1052 ">
the first utilizes set of carefully selected features obtained from different levels of text analysis, from part-of-speech (pos) tagging to full parsing and dependency parsing (kambhatla, 2004; <papid> P04-3022 </papid>zhao and grishman, 2005; <papid> P05-1052 </papid>zhou et al, 2005)<papid> P05-1053 </papid>1.</citsent>
<aftsection>
<nextsent>the second line of work designs kernel functions on some structured representation (sequences or trees)of the relation instances to capture the similarity between two relation instances (zelenko et al, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>bunescu and mooney, 2005<papid> H05-1091 </papid>a; bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al, 2006<papid> P06-1104 </papid>a; zhang et al, 2006<papid> P06-1104 </papid>b).</nextsent>
<nextsent>of particular interest among the various kernels proposed are the convolution kernels (bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al., 2006<papid> P06-1104 </papid>a), because they can efficiently compute the similarity between two instances in huge feature space due to their recursive nature.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1555">
<title id=" N07-1015.xml">a systematic exploration of the feature space for relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent studies on relation extraction have shown the advantages of discriminative model-based statistical machine learning approach to this problem.
</prevsent>
<prevsent>there are generally two lines of work following thisapproach.
</prevsent>
</prevsection>
<citsent citstr=" P05-1053 ">
the first utilizes set of carefully selected features obtained from different levels of text analysis, from part-of-speech (pos) tagging to full parsing and dependency parsing (kambhatla, 2004; <papid> P04-3022 </papid>zhao and grishman, 2005; <papid> P05-1052 </papid>zhou et al, 2005)<papid> P05-1053 </papid>1.</citsent>
<aftsection>
<nextsent>the second line of work designs kernel functions on some structured representation (sequences or trees)of the relation instances to capture the similarity between two relation instances (zelenko et al, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>bunescu and mooney, 2005<papid> H05-1091 </papid>a; bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al, 2006<papid> P06-1104 </papid>a; zhang et al, 2006<papid> P06-1104 </papid>b).</nextsent>
<nextsent>of particular interest among the various kernels proposed are the convolution kernels (bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al., 2006<papid> P06-1104 </papid>a), because they can efficiently compute the similarity between two instances in huge feature space due to their recursive nature.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1556">
<title id=" N07-1015.xml">a systematic exploration of the feature space for relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are generally two lines of work following thisapproach.
</prevsent>
<prevsent>the first utilizes set of carefully selected features obtained from different levels of text analysis, from part-of-speech (pos) tagging to full parsing and dependency parsing (kambhatla, 2004; <papid> P04-3022 </papid>zhao and grishman, 2005; <papid> P05-1052 </papid>zhou et al, 2005)<papid> P05-1053 </papid>1.</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
the second line of work designs kernel functions on some structured representation (sequences or trees)of the relation instances to capture the similarity between two relation instances (zelenko et al, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>bunescu and mooney, 2005<papid> H05-1091 </papid>a; bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al, 2006<papid> P06-1104 </papid>a; zhang et al, 2006<papid> P06-1104 </papid>b).</citsent>
<aftsection>
<nextsent>of particular interest among the various kernels proposed are the convolution kernels (bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al., 2006<papid> P06-1104 </papid>a), because they can efficiently compute the similarity between two instances in huge feature space due to their recursive nature.</nextsent>
<nextsent>apart from their computational efficiency, convolution kernels also implicitly correspond to some feature space.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1557">
<title id=" N07-1015.xml">a systematic exploration of the feature space for relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are generally two lines of work following thisapproach.
</prevsent>
<prevsent>the first utilizes set of carefully selected features obtained from different levels of text analysis, from part-of-speech (pos) tagging to full parsing and dependency parsing (kambhatla, 2004; <papid> P04-3022 </papid>zhao and grishman, 2005; <papid> P05-1052 </papid>zhou et al, 2005)<papid> P05-1053 </papid>1.</prevsent>
</prevsection>
<citsent citstr=" H05-1091 ">
the second line of work designs kernel functions on some structured representation (sequences or trees)of the relation instances to capture the similarity between two relation instances (zelenko et al, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>bunescu and mooney, 2005<papid> H05-1091 </papid>a; bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al, 2006<papid> P06-1104 </papid>a; zhang et al, 2006<papid> P06-1104 </papid>b).</citsent>
<aftsection>
<nextsent>of particular interest among the various kernels proposed are the convolution kernels (bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al., 2006<papid> P06-1104 </papid>a), because they can efficiently compute the similarity between two instances in huge feature space due to their recursive nature.</nextsent>
<nextsent>apart from their computational efficiency, convolution kernels also implicitly correspond to some feature space.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1565">
<title id=" N07-1015.xml">a systematic exploration of the feature space for relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are generally two lines of work following thisapproach.
</prevsent>
<prevsent>the first utilizes set of carefully selected features obtained from different levels of text analysis, from part-of-speech (pos) tagging to full parsing and dependency parsing (kambhatla, 2004; <papid> P04-3022 </papid>zhao and grishman, 2005; <papid> P05-1052 </papid>zhou et al, 2005)<papid> P05-1053 </papid>1.</prevsent>
</prevsection>
<citsent citstr=" P06-1104 ">
the second line of work designs kernel functions on some structured representation (sequences or trees)of the relation instances to capture the similarity between two relation instances (zelenko et al, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>bunescu and mooney, 2005<papid> H05-1091 </papid>a; bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al, 2006<papid> P06-1104 </papid>a; zhang et al, 2006<papid> P06-1104 </papid>b).</citsent>
<aftsection>
<nextsent>of particular interest among the various kernels proposed are the convolution kernels (bunescu and mooney, 2005<papid> H05-1091 </papid>b; zhang et al., 2006<papid> P06-1104 </papid>a), because they can efficiently compute the similarity between two instances in huge feature space due to their recursive nature.</nextsent>
<nextsent>apart from their computational efficiency, convolution kernels also implicitly correspond to some feature space.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1611">
<title id=" N07-1015.xml">a systematic exploration of the feature space for relation extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(2006a), (2006b) applied convolution string kernels and tree kernels, respectively, to relation extraction.
</prevsent>
<prevsent>the convolution tree kernels achieved state of-the-art performance.
</prevsent>
</prevsection>
<citsent citstr=" P03-1005 ">
since convolution kernels correspond to some explicit large feature spaces, the feature selection problem still remains.general structural representations of natural language data have been studied in (suzuki et al, 2003; <papid> P03-1005 </papid>cumby and roth, 2003), but these models were not designed specifically for relation extraction.</citsent>
<aftsection>
<nextsent>our feature definition is similar to these models, but more specifically designed for relation extraction and systematic exploration of the feature space.
</nextsent>
<nextsent>compared with (cumby and roth, 2003), our feature space is more compact and provides more guidance on selecting meaningful subspaces.
</nextsent>
<nextsent>given small piece of text that contains two entity mentions, the task of relation extraction is to decide whether the text states some semantic relation between the two entities, and if so, classify the relation into one of set of predefined semantic relation types.
</nextsent>
<nextsent>formally, let = (s, arg1, arg2) denote relation instance, where is sentence, arg1 and arg2 are two entity mentions contained in s, andarg1 precedes arg2 in the text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1681">
<title id=" N07-1015.xml">a systematic exploration of the feature space for relation extraction </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>a combination of features of different levels of complexity and from different sentence representations, coupled with task-oriented feature pruning, gives the best performance.in our future work, we will study how to automatically conduct task-oriented feature search, feature pruning and feature weighting using statistical methods instead of heuristics.
</prevsent>
<prevsent>in this study, we only considered features from the local context, i.e. the sentence that contains the two arguments.
</prevsent>
</prevsection>
<citsent citstr=" P04-1053 ">
some existing studies use corpus-based statistics for relation extraction (hasegawa et al, 2004).<papid> P04-1053 </papid></citsent>
<aftsection>
<nextsent>in the future, we will study the effectiveness of these global features.
</nextsent>
<nextsent>acknowledgments this work was in part supported by the national science foundation under award numbers 0425852 and0428472.
</nextsent>
<nextsent>we thank alessandro moschitti for providing the svm tree kernel package.
</nextsent>
<nextsent>we also thank minzhang for providing the implementation details of the convolution tree kernel for relation extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1682">
<title id=" N03-2016.xml">cognates can improve statistical translation models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ina broad sense, cognates include not only genetically related words and borrowings but also names, numbers, andpunctuation.
</prevsent>
<prevsent>practically all bitexts (bilingual parallel cor pora) contain some kind of cognates.
</prevsent>
</prevsection>
<citsent citstr=" N01-1020 ">
if the languages are represented in different scripts, phonetic transcription or transliteration of one or both parts of the bitext is pre-requisite for identifying cognates.cognates have been employed for number of bitext related tasks, including sentence alignment (simard etal., 1992), inducing translation lexicons (mann and yarowsky, 2001), <papid> N01-1020 </papid>and improving statistical machine translation models (al-onaizan et al, 1999).</citsent>
<aftsection>
<nextsent>cognates are particularly useful when machine-readable bilingual dictionaries are not available.
</nextsent>
<nextsent>al-onaizan et al (1999) experimented with using bilingual dictionaries and cognates in the training of czech english translation models.
</nextsent>
<nextsent>they found that appending probable cognates to the training bitext significantly lowered the perplexity score on the test bitext (in some cases more than when using bilingual dictionary), and observed improvement in word alignments of test sentences.in this paper, we investigate the problem of incorporating the potentially valuable cognate information into the translation models of brown et al (1990), which, intheir original formulation, consider lexical items in abstraction of their form.
</nextsent>
<nextsent>for training of the models, we use the giza program (al-onaizan et al, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1683">
<title id=" N03-2016.xml">cognates can improve statistical translation models </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we induced translation models using ibm model 4 (brown et al, 1990) with the giza toolkit (al-onaizanet al, 1999).
</prevsent>
<prevsent>the maximum sentence length in the training data was set at 30 words.
</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
the actual translations were produced with greedy decoder (germann et al, 2001).<papid> P01-1030 </papid></citsent>
<aftsection>
<nextsent>for the evaluation of translation quality, we used the bleu metric (papineni et al, 2002), <papid> P02-1040 </papid>which measures the n-gram overlap between the translated output and one or more reference translations.</nextsent>
<nextsent>in our experiments, we used only one reference translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1684">
<title id=" N03-2016.xml">cognates can improve statistical translation models </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the maximum sentence length in the training data was set at 30 words.
</prevsent>
<prevsent>the actual translations were produced with greedy decoder (germann et al, 2001).<papid> P01-1030 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for the evaluation of translation quality, we used the bleu metric (papineni et al, 2002), <papid> P02-1040 </papid>which measures the n-gram overlap between the translated output and one or more reference translations.</citsent>
<aftsection>
<nextsent>in our experiments, we used only one reference translation.
</nextsent>
<nextsent>3.1 word alignment quality.
</nextsent>
<nextsent>in order to directly measure the influence of the added cognate information on the word alignment quality, we performed single experiment using set of 500 manually aligned sentences from hansa rds (och and ney, 2000).<papid> P00-1056 </papid></nextsent>
<nextsent>giza was first trained on 50,000 sentences from hansa rds, and then on the same training set augmented with set of cognates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1685">
<title id=" N03-2016.xml">cognates can improve statistical translation models </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in our experiments, we used only one reference translation.
</prevsent>
<prevsent>3.1 word alignment quality.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
in order to directly measure the influence of the added cognate information on the word alignment quality, we performed single experiment using set of 500 manually aligned sentences from hansa rds (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>giza was first trained on 50,000 sentences from hansa rds, and then on the same training set augmented with set of cognates.
</nextsent>
<nextsent>the set consisted of two copies of list produced by applying the threshold of 0:58 to lcsr list.
</nextsent>
<nextsent>the duplication factor was arbitrarily selected on the basis of earlier experiments with different training and test set taken from hansards.
</nextsent>
<nextsent>the incorporation of the cognate information resulted in 10% reduction of the word alignment error rate, from 17.6% to 15.8%, and corresponding improvement in both precision and recall.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1686">
<title id=" N06-1027.xml">learning to detect conversation focus of threaded discussions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>two of the most prominent algorithms are page-rank (brin and page, 1998) and the hits algorithm (kleinberg, 1999).
</prevsent>
<prevsent>although they were initially proposed for analyzing web pages, they proved useful for investigating and ranking structured objects.
</prevsent>
</prevsection>
<citsent citstr=" W04-3252 ">
inspired by the idea of graph based algorithms to collectively rank and select the best candidate, research efforts in the natural language community have applied graph-based approaches on keyword selection (mihalcea and tarau, 2004), <papid> W04-3252 </papid>text summarization (erkan and radev, 2004; mihalcea, 2004), <papid> P04-3020 </papid>word sense disambiguation (mihal cea et al, 2004; <papid> C04-1162 </papid>mihalcea, 2005), <papid> H05-1052 </papid>sentiment analysis (pang and lee, 2004), <papid> P04-1035 </papid>and sentence retrieval for question answering (otterbacher et al, 2005).<papid> H05-1115 </papid></citsent>
<aftsection>
<nextsent>however, until now there has not been any published work on its application to human conversation analysis specifically in the format of threaded discussions.
</nextsent>
<nextsent>in this paper, we focus on using hits to detect conversation focus of threaded discussions.
</nextsent>
<nextsent>rhetorical structure theory (mann and thomson, 1988) based discourse processing has attracted much attention with successful applications in sentence compression and summarization.
</nextsent>
<nextsent>most of the current work on discourse processing focuses on sentence-level text organization (soricut and marcu, 2003) <papid> N03-1030 </papid>or the intermediate step (sporleder and lapata, 2005).<papid> H05-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1687">
<title id=" N06-1027.xml">learning to detect conversation focus of threaded discussions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>two of the most prominent algorithms are page-rank (brin and page, 1998) and the hits algorithm (kleinberg, 1999).
</prevsent>
<prevsent>although they were initially proposed for analyzing web pages, they proved useful for investigating and ranking structured objects.
</prevsent>
</prevsection>
<citsent citstr=" P04-3020 ">
inspired by the idea of graph based algorithms to collectively rank and select the best candidate, research efforts in the natural language community have applied graph-based approaches on keyword selection (mihalcea and tarau, 2004), <papid> W04-3252 </papid>text summarization (erkan and radev, 2004; mihalcea, 2004), <papid> P04-3020 </papid>word sense disambiguation (mihal cea et al, 2004; <papid> C04-1162 </papid>mihalcea, 2005), <papid> H05-1052 </papid>sentiment analysis (pang and lee, 2004), <papid> P04-1035 </papid>and sentence retrieval for question answering (otterbacher et al, 2005).<papid> H05-1115 </papid></citsent>
<aftsection>
<nextsent>however, until now there has not been any published work on its application to human conversation analysis specifically in the format of threaded discussions.
</nextsent>
<nextsent>in this paper, we focus on using hits to detect conversation focus of threaded discussions.
</nextsent>
<nextsent>rhetorical structure theory (mann and thomson, 1988) based discourse processing has attracted much attention with successful applications in sentence compression and summarization.
</nextsent>
<nextsent>most of the current work on discourse processing focuses on sentence-level text organization (soricut and marcu, 2003) <papid> N03-1030 </papid>or the intermediate step (sporleder and lapata, 2005).<papid> H05-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1688">
<title id=" N06-1027.xml">learning to detect conversation focus of threaded discussions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>two of the most prominent algorithms are page-rank (brin and page, 1998) and the hits algorithm (kleinberg, 1999).
</prevsent>
<prevsent>although they were initially proposed for analyzing web pages, they proved useful for investigating and ranking structured objects.
</prevsent>
</prevsection>
<citsent citstr=" C04-1162 ">
inspired by the idea of graph based algorithms to collectively rank and select the best candidate, research efforts in the natural language community have applied graph-based approaches on keyword selection (mihalcea and tarau, 2004), <papid> W04-3252 </papid>text summarization (erkan and radev, 2004; mihalcea, 2004), <papid> P04-3020 </papid>word sense disambiguation (mihal cea et al, 2004; <papid> C04-1162 </papid>mihalcea, 2005), <papid> H05-1052 </papid>sentiment analysis (pang and lee, 2004), <papid> P04-1035 </papid>and sentence retrieval for question answering (otterbacher et al, 2005).<papid> H05-1115 </papid></citsent>
<aftsection>
<nextsent>however, until now there has not been any published work on its application to human conversation analysis specifically in the format of threaded discussions.
</nextsent>
<nextsent>in this paper, we focus on using hits to detect conversation focus of threaded discussions.
</nextsent>
<nextsent>rhetorical structure theory (mann and thomson, 1988) based discourse processing has attracted much attention with successful applications in sentence compression and summarization.
</nextsent>
<nextsent>most of the current work on discourse processing focuses on sentence-level text organization (soricut and marcu, 2003) <papid> N03-1030 </papid>or the intermediate step (sporleder and lapata, 2005).<papid> H05-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1689">
<title id=" N06-1027.xml">learning to detect conversation focus of threaded discussions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>two of the most prominent algorithms are page-rank (brin and page, 1998) and the hits algorithm (kleinberg, 1999).
</prevsent>
<prevsent>although they were initially proposed for analyzing web pages, they proved useful for investigating and ranking structured objects.
</prevsent>
</prevsection>
<citsent citstr=" H05-1052 ">
inspired by the idea of graph based algorithms to collectively rank and select the best candidate, research efforts in the natural language community have applied graph-based approaches on keyword selection (mihalcea and tarau, 2004), <papid> W04-3252 </papid>text summarization (erkan and radev, 2004; mihalcea, 2004), <papid> P04-3020 </papid>word sense disambiguation (mihal cea et al, 2004; <papid> C04-1162 </papid>mihalcea, 2005), <papid> H05-1052 </papid>sentiment analysis (pang and lee, 2004), <papid> P04-1035 </papid>and sentence retrieval for question answering (otterbacher et al, 2005).<papid> H05-1115 </papid></citsent>
<aftsection>
<nextsent>however, until now there has not been any published work on its application to human conversation analysis specifically in the format of threaded discussions.
</nextsent>
<nextsent>in this paper, we focus on using hits to detect conversation focus of threaded discussions.
</nextsent>
<nextsent>rhetorical structure theory (mann and thomson, 1988) based discourse processing has attracted much attention with successful applications in sentence compression and summarization.
</nextsent>
<nextsent>most of the current work on discourse processing focuses on sentence-level text organization (soricut and marcu, 2003) <papid> N03-1030 </papid>or the intermediate step (sporleder and lapata, 2005).<papid> H05-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1690">
<title id=" N06-1027.xml">learning to detect conversation focus of threaded discussions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>two of the most prominent algorithms are page-rank (brin and page, 1998) and the hits algorithm (kleinberg, 1999).
</prevsent>
<prevsent>although they were initially proposed for analyzing web pages, they proved useful for investigating and ranking structured objects.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
inspired by the idea of graph based algorithms to collectively rank and select the best candidate, research efforts in the natural language community have applied graph-based approaches on keyword selection (mihalcea and tarau, 2004), <papid> W04-3252 </papid>text summarization (erkan and radev, 2004; mihalcea, 2004), <papid> P04-3020 </papid>word sense disambiguation (mihal cea et al, 2004; <papid> C04-1162 </papid>mihalcea, 2005), <papid> H05-1052 </papid>sentiment analysis (pang and lee, 2004), <papid> P04-1035 </papid>and sentence retrieval for question answering (otterbacher et al, 2005).<papid> H05-1115 </papid></citsent>
<aftsection>
<nextsent>however, until now there has not been any published work on its application to human conversation analysis specifically in the format of threaded discussions.
</nextsent>
<nextsent>in this paper, we focus on using hits to detect conversation focus of threaded discussions.
</nextsent>
<nextsent>rhetorical structure theory (mann and thomson, 1988) based discourse processing has attracted much attention with successful applications in sentence compression and summarization.
</nextsent>
<nextsent>most of the current work on discourse processing focuses on sentence-level text organization (soricut and marcu, 2003) <papid> N03-1030 </papid>or the intermediate step (sporleder and lapata, 2005).<papid> H05-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1691">
<title id=" N06-1027.xml">learning to detect conversation focus of threaded discussions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>two of the most prominent algorithms are page-rank (brin and page, 1998) and the hits algorithm (kleinberg, 1999).
</prevsent>
<prevsent>although they were initially proposed for analyzing web pages, they proved useful for investigating and ranking structured objects.
</prevsent>
</prevsection>
<citsent citstr=" H05-1115 ">
inspired by the idea of graph based algorithms to collectively rank and select the best candidate, research efforts in the natural language community have applied graph-based approaches on keyword selection (mihalcea and tarau, 2004), <papid> W04-3252 </papid>text summarization (erkan and radev, 2004; mihalcea, 2004), <papid> P04-3020 </papid>word sense disambiguation (mihal cea et al, 2004; <papid> C04-1162 </papid>mihalcea, 2005), <papid> H05-1052 </papid>sentiment analysis (pang and lee, 2004), <papid> P04-1035 </papid>and sentence retrieval for question answering (otterbacher et al, 2005).<papid> H05-1115 </papid></citsent>
<aftsection>
<nextsent>however, until now there has not been any published work on its application to human conversation analysis specifically in the format of threaded discussions.
</nextsent>
<nextsent>in this paper, we focus on using hits to detect conversation focus of threaded discussions.
</nextsent>
<nextsent>rhetorical structure theory (mann and thomson, 1988) based discourse processing has attracted much attention with successful applications in sentence compression and summarization.
</nextsent>
<nextsent>most of the current work on discourse processing focuses on sentence-level text organization (soricut and marcu, 2003) <papid> N03-1030 </papid>or the intermediate step (sporleder and lapata, 2005).<papid> H05-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1692">
<title id=" N06-1027.xml">learning to detect conversation focus of threaded discussions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we focus on using hits to detect conversation focus of threaded discussions.
</prevsent>
<prevsent>rhetorical structure theory (mann and thomson, 1988) based discourse processing has attracted much attention with successful applications in sentence compression and summarization.
</prevsent>
</prevsection>
<citsent citstr=" N03-1030 ">
most of the current work on discourse processing focuses on sentence-level text organization (soricut and marcu, 2003) <papid> N03-1030 </papid>or the intermediate step (sporleder and lapata, 2005).<papid> H05-1033 </papid></citsent>
<aftsection>
<nextsent>analyzing and utilizing discourse information at higher level, e.g., at the paragraph level, still remains challenge to the natural language community.
</nextsent>
<nextsent>in our work, we utilize the discourse information at message level.
</nextsent>
<nextsent>zhou and hovy (2005) <papid> P05-1037 </papid>proposed summarizing threaded discussions in similar fashion to multi document summarization; but then their work does not take into account the relative importance of different messages in thread.</nextsent>
<nextsent>marom and zukerman (2005) generated help-desk responses using clustering techniques, but their corpus is composed of only two-party, two-turn, conversation pairs, which precludes the need to determine relative importance as in multi-ply conversation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1693">
<title id=" N06-1027.xml">learning to detect conversation focus of threaded discussions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we focus on using hits to detect conversation focus of threaded discussions.
</prevsent>
<prevsent>rhetorical structure theory (mann and thomson, 1988) based discourse processing has attracted much attention with successful applications in sentence compression and summarization.
</prevsent>
</prevsection>
<citsent citstr=" H05-1033 ">
most of the current work on discourse processing focuses on sentence-level text organization (soricut and marcu, 2003) <papid> N03-1030 </papid>or the intermediate step (sporleder and lapata, 2005).<papid> H05-1033 </papid></citsent>
<aftsection>
<nextsent>analyzing and utilizing discourse information at higher level, e.g., at the paragraph level, still remains challenge to the natural language community.
</nextsent>
<nextsent>in our work, we utilize the discourse information at message level.
</nextsent>
<nextsent>zhou and hovy (2005) <papid> P05-1037 </papid>proposed summarizing threaded discussions in similar fashion to multi document summarization; but then their work does not take into account the relative importance of different messages in thread.</nextsent>
<nextsent>marom and zukerman (2005) generated help-desk responses using clustering techniques, but their corpus is composed of only two-party, two-turn, conversation pairs, which precludes the need to determine relative importance as in multi-ply conversation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1694">
<title id=" N06-1027.xml">learning to detect conversation focus of threaded discussions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>analyzing and utilizing discourse information at higher level, e.g., at the paragraph level, still remains challenge to the natural language community.
</prevsent>
<prevsent>in our work, we utilize the discourse information at message level.
</prevsent>
</prevsection>
<citsent citstr=" P05-1037 ">
zhou and hovy (2005) <papid> P05-1037 </papid>proposed summarizing threaded discussions in similar fashion to multi document summarization; but then their work does not take into account the relative importance of different messages in thread.</citsent>
<aftsection>
<nextsent>marom and zukerman (2005) generated help-desk responses using clustering techniques, but their corpus is composed of only two-party, two-turn, conversation pairs, which precludes the need to determine relative importance as in multi-ply conversation.
</nextsent>
<nextsent>in our previous work (feng et al, 2006), we implemented discussion-bot to automatically answer student queries in threaded discussion but extract potential answers (the most informative message) using rule-based traverse algorithm that is not optimal for selecting best answer; thus, the result may contain redundant or incorrect information.
</nextsent>
<nextsent>we argue that pragmatic knowledge like speech acts is important in conversation focus analysis.
</nextsent>
<nextsent>however, estimated speech act labeling between messages is not sufficient for detecting 209 human conversation focus without considering other features like author information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1696">
<title id=" N06-1027.xml">learning to detect conversation focus of threaded discussions </title>
<section> 30  </section>
<citcontext>
<prevsection>
<prevsent>table 4 gives the statistics of the numbers of correct messages of our gold standard.
</prevsent>
<prevsent>we experimented with further segmenting the messages so as to narrow down the best-answer text, under the assumption that long messages probably include some less-than-useful information.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
we applied text tiling (hearst, 1994) <papid> P94-1002 </papid>to segment the messages, which is the technique used by zhou and hovy (2005) <papid> P05-1037 </papid>to summarize discussions.</citsent>
<aftsection>
<nextsent>for our corpus, though, the ratio of segments to messages was only 1.03, which indicates that our messages are relatively short and coherent, and that segmenting them would not provide additional benefits.
</nextsent>
<nextsent>5.2 baseline system.
</nextsent>
<nextsent>to compare the effectiveness of our approach with different features, we designed baseline system that uses random guess approach.
</nextsent>
<nextsent>given discussion thread, the baseline system randomly selects the most important message.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1699">
<title id=" N04-1024.xml">evaluating multiple aspects of coherence in student essays </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>in earlier work, foltz, kintsch &amp; landauer (1998),and wiemer-hastings &amp; graesser (2000) have developed systems that also examine coherence in studentwriting.
</prevsent>
<prevsent>their systems measure lexical relatedness between text segments by using vector-based similarity between adjacent sentences.
</prevsent>
</prevsection>
<citsent citstr=" J97-1003 ">
this linear approach to similarity scoring is in line with the text tiling scheme (hearst and plaunt, 1993; hearst, 1997), <papid> J97-1003 </papid>which may be used to identify the sub topic structure of text.miltsakaki and kukich (2000) have also addressed the issue of establishing the coherence of student essays, using the rough shift element of centering theory.</citsent>
<aftsection>
<nextsent>again, this previous work looks at the relatedness of adjacent text segments, and does not explore global aspects of text coherence.
</nextsent>
<nextsent>hierarchical models of discourse have been applied to the question of coherence (mann and thompson, 1986),but so far these have been more useful in language generation than in determining how coherent given text is,or in identifying the specific problem, such as the break down of coherence in document.
</nextsent>
<nextsent>our approach differs in fundamental ways from this earlier work that deals with student writing.
</nextsent>
<nextsent>first, foltz et al (1998), wiemer-hastings and graesser (2000),and miltsakaki and kukich (2000) assume that text coherence is linear.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1700">
<title id=" N04-4011.xml">performance evaluation and error analysis for multimodal reference resolution in a conversation system </title>
<section> introduction*.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P02-1048 ">
multimodal systems enable users to interact with computers through multiple modalities such as speech, gesture, and gaze (bolt 1980; cassell et al, 1999; cohen et al., 1996; chai et al, 2002; johnston et al, 2002).<papid> P02-1048 </papid></citsent>
<aftsection>
<nextsent>one important aspect of building multimodal systems is for the system to understand the meanings of multimodal user inputs.
</nextsent>
<nextsent>a key element of this understanding process is reference resolution.
</nextsent>
<nextsent>reference resolution is process that finds the most proper referents to referring expressions.
</nextsent>
<nextsent>to resolve multimodal references, many approaches have been developed, from the use of focus space model (neal et al, 1998), centering framework (zancanaro et al 1997), contextual factors (huls et al, 1995); <papid> J95-1003 </papid>to recent approaches using unification (johnston, 1998), <papid> P98-1102 </papid>finite state machines (johnston and bangalore 2000), <papid> C00-1054 </papid>and context based rules (kehler 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1701">
<title id=" N04-4011.xml">performance evaluation and error analysis for multimodal reference resolution in a conversation system </title>
<section> introduction*.  </section>
<citcontext>
<prevsection>
<prevsent>a key element of this understanding process is reference resolution.
</prevsent>
<prevsent>reference resolution is process that finds the most proper referents to referring expressions.
</prevsent>
</prevsection>
<citsent citstr=" J95-1003 ">
to resolve multimodal references, many approaches have been developed, from the use of focus space model (neal et al, 1998), centering framework (zancanaro et al 1997), contextual factors (huls et al, 1995); <papid> J95-1003 </papid>to recent approaches using unification (johnston, 1998), <papid> P98-1102 </papid>finite state machines (johnston and bangalore 2000), <papid> C00-1054 </papid>and context based rules (kehler 2000).</citsent>
<aftsection>
<nextsent>given the substantial work in this area; it is important to evaluate the state of the art, understand the limitations, * this work was supported by grant iis-0347548 from the national science foundation and grant irgp-03-42111 from michigan state university.
</nextsent>
<nextsent>and identify directions for future improvement.
</nextsent>
<nextsent>we conducted series of user studies to evaluate the capability of reference resolution in multimodal conversation system.
</nextsent>
<nextsent>in particular, this paper examines two important aspects: (1) algorithm requirements for handling variety of references, and (2) technology requirements for achieving good real-time performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1702">
<title id=" N04-4011.xml">performance evaluation and error analysis for multimodal reference resolution in a conversation system </title>
<section> introduction*.  </section>
<citcontext>
<prevsection>
<prevsent>a key element of this understanding process is reference resolution.
</prevsent>
<prevsent>reference resolution is process that finds the most proper referents to referring expressions.
</prevsent>
</prevsection>
<citsent citstr=" P98-1102 ">
to resolve multimodal references, many approaches have been developed, from the use of focus space model (neal et al, 1998), centering framework (zancanaro et al 1997), contextual factors (huls et al, 1995); <papid> J95-1003 </papid>to recent approaches using unification (johnston, 1998), <papid> P98-1102 </papid>finite state machines (johnston and bangalore 2000), <papid> C00-1054 </papid>and context based rules (kehler 2000).</citsent>
<aftsection>
<nextsent>given the substantial work in this area; it is important to evaluate the state of the art, understand the limitations, * this work was supported by grant iis-0347548 from the national science foundation and grant irgp-03-42111 from michigan state university.
</nextsent>
<nextsent>and identify directions for future improvement.
</nextsent>
<nextsent>we conducted series of user studies to evaluate the capability of reference resolution in multimodal conversation system.
</nextsent>
<nextsent>in particular, this paper examines two important aspects: (1) algorithm requirements for handling variety of references, and (2) technology requirements for achieving good real-time performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1703">
<title id=" N04-4011.xml">performance evaluation and error analysis for multimodal reference resolution in a conversation system </title>
<section> introduction*.  </section>
<citcontext>
<prevsection>
<prevsent>a key element of this understanding process is reference resolution.
</prevsent>
<prevsent>reference resolution is process that finds the most proper referents to referring expressions.
</prevsent>
</prevsection>
<citsent citstr=" C00-1054 ">
to resolve multimodal references, many approaches have been developed, from the use of focus space model (neal et al, 1998), centering framework (zancanaro et al 1997), contextual factors (huls et al, 1995); <papid> J95-1003 </papid>to recent approaches using unification (johnston, 1998), <papid> P98-1102 </papid>finite state machines (johnston and bangalore 2000), <papid> C00-1054 </papid>and context based rules (kehler 2000).</citsent>
<aftsection>
<nextsent>given the substantial work in this area; it is important to evaluate the state of the art, understand the limitations, * this work was supported by grant iis-0347548 from the national science foundation and grant irgp-03-42111 from michigan state university.
</nextsent>
<nextsent>and identify directions for future improvement.
</nextsent>
<nextsent>we conducted series of user studies to evaluate the capability of reference resolution in multimodal conversation system.
</nextsent>
<nextsent>in particular, this paper examines two important aspects: (1) algorithm requirements for handling variety of references, and (2) technology requirements for achieving good real-time performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1704">
<title id=" N03-1013.xml">a categorial variation database for english </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>wordnet is the most well-developed and widely used lexical database of english (fellbaum, 1998).
</prevsent>
<prevsent>in wordnet, both types of lexical relations are specified among words with the same part of speech (verbs, nouns, adjectives and adverbs).
</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
wordnet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as sen sus (knight and luk, 1994) or the lexical conceptual structure verb database (lvd) (green et al, 2001) to the faking of meaning ambiguity as part of system evaluation (bangalore and rambow, 2000).<papid> C00-1007 </papid></citsent>
<aftsection>
<nextsent>in the context of these projects, one criticism of wordnet is its lack of cross categorial links, such as verb-noun or noun-adjective re lations.melcuk approaches lexical relations by defining lexical combinatorial zone that specifies semantically related lexemes through lexical functions (lf).
</nextsent>
<nextsent>these functions define correspondence between key lexical item and set of related lexical items (melcuk, 1988).
</nextsent>
<nextsent>there are two types of functions: paradigmatic and syntagmatic(ramos et al, 1994).
</nextsent>
<nextsent>paradigmatic lfs associate lexical item with related lexical items.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1705">
<title id=" N03-1013.xml">a categorial variation database for english </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>stem mers such as the porter stemmer (porter, 1980) are typical example.
</prevsent>
<prevsent>the latter, or expansionist approaches, over generate possibilities and relyon statistical language model to rank/select among them.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
the morphological generator in nitrogen is an example of such an approximation (langkilde and knight, 1998).<papid> P98-1116 </papid></citsent>
<aftsection>
<nextsent>there are two types of problems with approximations of this type: (1) they are uni-directional and thus limited in usabilitya stemmer cannot be used for generation and morphological over generator cannot be used for stemming; (2) the crude approximating nature ofsuch systems cause many problems in quality and efficiency from over-stemming/under-stemming or over generation/under-generation.
</nextsent>
<nextsent>consider, for example, the porter stemmer, which stems commune
</nextsent>
<nextsent>, communication
</nextsent>
<nextsent>and communism
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1706">
<title id=" N03-1013.xml">a categorial variation database for english </title>
<section> building the catvar.  </section>
<citcontext>
<prevsection>
<prevsent>given these issues, our goal is to build database of categorial variations that can be used with both expansionist and reductionist approaches without the cost of over/under-stemming/generation.
</prevsent>
<prevsent>the research reported herein is relevant to mt, ir, and lexicon construction.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the catvar database was developed using combination of resources and algorithms including the lexical conceptual structure (lcs) verb and preposition databases (dorr, 2001), the brown corpus section of thepenn treebank (marcus et al, 1993), <papid> J93-2004 </papid>an english morphological analysis lexicon developed for pc-kimmo (englex) (antworth, 1990), nomlex (macleod et al, 1998), longman dictionary of contemporary english2for deeper discussion and classification of porter stem mers errors, see (krovetz, 1993).</citsent>
<aftsection>
<nextsent>(ldoce)3 (procter, 1983), wordnet 1.6 (fellbaum, 1998), and the porter stemmer.
</nextsent>
<nextsent>the contribution of each of these sources is clearly labeled in the catvar database,thus enabling the use of different cross-sections of there source for different applications.4 some of these resources were used to extract seed links between different words (englex lexicon, nomlex andldoce).
</nextsent>
<nextsent>others were used to provide large-scale coverage of lexemes.
</nextsent>
<nextsent>in the case of the brown corpus, which doesnt provide lexemes for its words, the englex morphological analyzer was used together with the part of speech specified in the penn tree bank to extract the lex eme form.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1707">
<title id=" N03-1013.xml">a categorial variation database for english </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent> mapping, e.g., the transformation from kick   to lightvb kick
</prevsent>
<prevsent>(corresponding to the english/spanish divergence 6the other conditions on conflatability and some detailed examples are discussed in (habash, 2002) and (habash and dorr, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
7for details about the bleu evaluation metric, see (papineni et al, 2002).<papid> P02-1040 </papid>pair kick/dar patada); and (2) during an automatic markup phase prior to this transformation, where the partic ular</citsent>
<aftsection>
<nextsent>-to
</nextsent>
<nextsent>mapping is selected from set of possibilities based on the 2 input sentences.
</nextsent>
<nextsent>for example, the rule v[catvar=n] -  lightvb is selected for the transformation above by first checking that theverb is associated with word of category in cat var.
</nextsent>
<nextsent>transforming divergent english sentences using this mechanism has been shown to facilitate word-level alignment by reducing the number of unaligned and multiply aligned words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1708">
<title id=" N03-1013.xml">a categorial variation database for english </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>or doer?
</prevsent>
<prevsent>to complement part-of-speech labels.
</prevsent>
</prevsection>
<citsent citstr=" P96-1004 ">
other lexical semantic features such telicity, sentience and change of-state can also be induced from morphological cues (light, 1996).<papid> P96-1004 </papid>additionally, we are interested in measuring the applied contribution of using the catvar in natural-language applications such as information retrieval.</citsent>
<aftsection>
<nextsent>and finally, we intend to incorporate catvar into new applications such as parallel corpus word alignment.
</nextsent>
<nextsent>acknowledgments this work has been supported, in part, by onr muricontract fcpo.810548265, mitre contract 010418 7712, and nsf cise research infrastructure award eia0130422.
</nextsent>
<nextsent>we would like to thank all the annotators who participated in the evaluation of the database.viewed as weak link in our comparison since it does not provide deep analysis as would be produced by morphological analysis systems.
</nextsent>
<nextsent>however, we have found that most morphological analyzers, including ones with large-scale coverage such as the xtag system (karp et al, 1992), <papid> C92-3145 </papid>address inflectional not derivationalmorphology; thus, their basis for comparison is even weaker than would be provided by the porter stemmer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1709">
<title id=" N03-1013.xml">a categorial variation database for english </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>acknowledgments this work has been supported, in part, by onr muricontract fcpo.810548265, mitre contract 010418 7712, and nsf cise research infrastructure award eia0130422.
</prevsent>
<prevsent>we would like to thank all the annotators who participated in the evaluation of the database.viewed as weak link in our comparison since it does not provide deep analysis as would be produced by morphological analysis systems.
</prevsent>
</prevsection>
<citsent citstr=" C92-3145 ">
however, we have found that most morphological analyzers, including ones with large-scale coverage such as the xtag system (karp et al, 1992), <papid> C92-3145 </papid>address inflectional not derivationalmorphology; thus, their basis for comparison is even weaker than would be provided by the porter stemmer.</citsent>
<aftsection>
<nextsent>11this is, in fact, the approach used in the headgen and duster applications described above.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1710">
<title id=" N07-1057.xml">multilingual structural projection across inter linear text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although number of projects have been undertaken to develop annotated resources for non-english languages, e.g., treebanks, the development of these resources has been no small feat, and to date have been limited to very small number of 1we would like to thank dan jinguji for creating the word alignment and source dependency structure goldstandards.
</prevsent>
<prevsent>our thanks also go to three anonymous reviewers for their helpful comments and suggestions.the worlds languages (e.g., chinese, german, arabic, korean, etc.).
</prevsent>
</prevsection>
<citsent citstr=" H05-1107 ">
some notable efforts have been undertaken to develop automated means for creating annotated corpora through the projection of annotations (yarowksy and ngai, 2001; xi and hwa, 2005).<papid> H05-1107 </papid></citsent>
<aftsection>
<nextsent>the resulting methods, however, can only be applied to small number of language pairs due mostly to the need for sizeable parallel corpora.
</nextsent>
<nextsent>unfortunately,most languages do not have parallel corpora of sufficient size, making these methods inapplicable for the vast majority of the worlds languages.
</nextsent>
<nextsent>we describe method for bootstrapping resource creation by tapping the wealth of multilingual data on the web that has been created by linguists.
</nextsent>
<nextsent>of particular note is the linguistic presentation format of inter linear text?, common format used for presenting language data and analysis relevant to particular argument or investigation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1711">
<title id=" N07-1057.xml">multilingual structural projection across inter linear text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of inter linear examples found on the web, when taken together, constitute asignificant multilingual, parallel corpus covering hundreds to thousands of the worlds languages.we do not propose that database of inter lin ear text alone is sufficient to create nlp resources and tools, but rather that it may act as means for more rapidly developing such tools using less data.we contend that such resource allows one to develop computational artifacts, such as grammars and transfer rules, which can be used as seed?
</prevsent>
<prevsent>knowledge for building larger resources.
</prevsent>
</prevsection>
<citsent citstr=" N06-1041 ">
in particular, knowing little about the structure of language can help in developing annotated corpora and tools, since alittle knowledge can go long way in inducing accurate structure and annotations (haghighi and klein, 2006).<papid> N06-1041 </papid>of particular relevance to mt is the issue of struc 452tural divergence (dorr, 1994).<papid> J94-4004 </papid></citsent>
<aftsection>
<nextsent>many mt models implicitly make the so-called direct correspondence assumption (dca) as defined in (hwa et al, 2002).<papid> P02-1050 </papid></nextsent>
<nextsent>however, to what extent that assumption holds is tested only on small number of language pairs using hand aligned data (fox, 2002; <papid> W02-1039 </papid>hwa et al, 2002;<papid> P02-1050 </papid>wellington et al, 2006).<papid> P06-1123 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1712">
<title id=" N07-1057.xml">multilingual structural projection across inter linear text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of inter linear examples found on the web, when taken together, constitute asignificant multilingual, parallel corpus covering hundreds to thousands of the worlds languages.we do not propose that database of inter lin ear text alone is sufficient to create nlp resources and tools, but rather that it may act as means for more rapidly developing such tools using less data.we contend that such resource allows one to develop computational artifacts, such as grammars and transfer rules, which can be used as seed?
</prevsent>
<prevsent>knowledge for building larger resources.
</prevsent>
</prevsection>
<citsent citstr=" J94-4004 ">
in particular, knowing little about the structure of language can help in developing annotated corpora and tools, since alittle knowledge can go long way in inducing accurate structure and annotations (haghighi and klein, 2006).<papid> N06-1041 </papid>of particular relevance to mt is the issue of struc 452tural divergence (dorr, 1994).<papid> J94-4004 </papid></citsent>
<aftsection>
<nextsent>many mt models implicitly make the so-called direct correspondence assumption (dca) as defined in (hwa et al, 2002).<papid> P02-1050 </papid></nextsent>
<nextsent>however, to what extent that assumption holds is tested only on small number of language pairs using hand aligned data (fox, 2002; <papid> W02-1039 </papid>hwa et al, 2002;<papid> P02-1050 </papid>wellington et al, 2006).<papid> P06-1123 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1713">
<title id=" N07-1057.xml">multilingual structural projection across inter linear text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>knowledge for building larger resources.
</prevsent>
<prevsent>in particular, knowing little about the structure of language can help in developing annotated corpora and tools, since alittle knowledge can go long way in inducing accurate structure and annotations (haghighi and klein, 2006).<papid> N06-1041 </papid>of particular relevance to mt is the issue of struc 452tural divergence (dorr, 1994).<papid> J94-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1050 ">
many mt models implicitly make the so-called direct correspondence assumption (dca) as defined in (hwa et al, 2002).<papid> P02-1050 </papid></citsent>
<aftsection>
<nextsent>however, to what extent that assumption holds is tested only on small number of language pairs using hand aligned data (fox, 2002; <papid> W02-1039 </papid>hwa et al, 2002;<papid> P02-1050 </papid>wellington et al, 2006).<papid> P06-1123 </papid></nextsent>
<nextsent>a larger sample of typo logically diverse language data can help test the assumption for hundreds of languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1714">
<title id=" N07-1057.xml">multilingual structural projection across inter linear text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, knowing little about the structure of language can help in developing annotated corpora and tools, since alittle knowledge can go long way in inducing accurate structure and annotations (haghighi and klein, 2006).<papid> N06-1041 </papid>of particular relevance to mt is the issue of struc 452tural divergence (dorr, 1994).<papid> J94-4004 </papid></prevsent>
<prevsent>many mt models implicitly make the so-called direct correspondence assumption (dca) as defined in (hwa et al, 2002).<papid> P02-1050 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
however, to what extent that assumption holds is tested only on small number of language pairs using hand aligned data (fox, 2002; <papid> W02-1039 </papid>hwa et al, 2002;<papid> P02-1050 </papid>wellington et al, 2006).<papid> P06-1123 </papid></citsent>
<aftsection>
<nextsent>a larger sample of typo logically diverse language data can help test the assumption for hundreds of languages.
</nextsent>
<nextsent>we contend that the knowledge garnered from structural projections applied to inter linear text can bootstrap the development of resources and tools across parallel corpora, where such corpora could be of smaller size and the resulting tools more robust,opening the door to the development of tools andre sources for larger number of the worlds languages.
</nextsent>
<nextsent>given the imminent death of half of the worlds 6,000 languages (krauss, 1992), the development of any language specific tools for larger percentage of the worlds languages than is currently possible can aid in both their documentation and preservation.
</nextsent>
<nextsent>the practice of presenting language data in inter lin ear form has long history in the field of linguistics, going back at least to the time of the structuralists(see (swanton, 1912) for early examples).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1716">
<title id=" N07-1057.xml">multilingual structural projection across inter linear text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, knowing little about the structure of language can help in developing annotated corpora and tools, since alittle knowledge can go long way in inducing accurate structure and annotations (haghighi and klein, 2006).<papid> N06-1041 </papid>of particular relevance to mt is the issue of struc 452tural divergence (dorr, 1994).<papid> J94-4004 </papid></prevsent>
<prevsent>many mt models implicitly make the so-called direct correspondence assumption (dca) as defined in (hwa et al, 2002).<papid> P02-1050 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-1123 ">
however, to what extent that assumption holds is tested only on small number of language pairs using hand aligned data (fox, 2002; <papid> W02-1039 </papid>hwa et al, 2002;<papid> P02-1050 </papid>wellington et al, 2006).<papid> P06-1123 </papid></citsent>
<aftsection>
<nextsent>a larger sample of typo logically diverse language data can help test the assumption for hundreds of languages.
</nextsent>
<nextsent>we contend that the knowledge garnered from structural projections applied to inter linear text can bootstrap the development of resources and tools across parallel corpora, where such corpora could be of smaller size and the resulting tools more robust,opening the door to the development of tools andre sources for larger number of the worlds languages.
</nextsent>
<nextsent>given the imminent death of half of the worlds 6,000 languages (krauss, 1992), the development of any language specific tools for larger percentage of the worlds languages than is currently possible can aid in both their documentation and preservation.
</nextsent>
<nextsent>the practice of presenting language data in inter lin ear form has long history in the field of linguistics, going back at least to the time of the structuralists(see (swanton, 1912) for early examples).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1717">
<title id=" N07-1057.xml">multilingual structural projection across inter linear text </title>
<section> the enrichment algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>tain the source syntactic structures using word alignment.
</prevsent>
<prevsent>3.1 parsing english sentences.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
there are many english parsers available to the public, and in this experiment we used charniaks parser (charniak, 1997), which was trained on the english penn treebank (marcus et al, 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>figure 1(a) shows parse tree (in the penn treebank style) for the english translation in ex (1).
</nextsent>
<nextsent>given parse tree, we use head percolation table (magerman, 1995) <papid> P95-1037 </papid>to create the corresponding dependency structure.</nextsent>
<nextsent>figure 2(a) shows the dependency structure derived from the parse tree in figure 1(a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1718">
<title id=" N07-1057.xml">multilingual structural projection across inter linear text </title>
<section> the enrichment algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>there are many english parsers available to the public, and in this experiment we used charniaks parser (charniak, 1997), which was trained on the english penn treebank (marcus et al, 1994).<papid> H94-1020 </papid></prevsent>
<prevsent>figure 1(a) shows parse tree (in the penn treebank style) for the english translation in ex (1).</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
given parse tree, we use head percolation table (magerman, 1995) <papid> P95-1037 </papid>to create the corresponding dependency structure.</citsent>
<aftsection>
<nextsent>figure 2(a) shows the dependency structure derived from the parse tree in figure 1(a).
</nextsent>
<nextsent>3.2 word alignment.
</nextsent>
<nextsent>because most of the 700+ languages in odin arelow-density languages with no on-line bilingual dictionaries or large parallel corpora, aligning the source sentence and its english translation directly would not work well.
</nextsent>
<nextsent>to take advantage of the unique lay out of igt examples, we propose using the gloss line as bridge between the other two lines; that is, we first align the source sentence and the gloss line, and then align the gloss line and the english translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1719">
<title id=" N07-1057.xml">multilingual structural projection across inter linear text </title>
<section> the enrichment algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>we built two align ers for this stage, as described below.
</prevsent>
<prevsent>3.2.1 statistical word aligner we create parallel corpus by using the gloss lines and the translation lines of all the igt examples forall the languages in odin.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we then train ibm models (brown et al, 1993) <papid> J93-2003 </papid>using the giza++ package (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>in addition to the common practice of lower casing words and combining word alignments from both directions, we adopt the following strategies to improve word alignment: breaking words into morphemes: since amulti-morpheme word in gloss line often corresponds to multiple words in the translation line, wesplit each word on the gloss line into morphemes using the standard igt morpheme delimiters (e.g., ? ?).
</nextsent>
<nextsent>for instance, the seven words in the gloss line of ex (1) become nine morphemes.
</nextsent>
<nextsent>adding (x,x) pairs: if word appears in the gloss and the translation lines of the same igt example, it is highly likely that the two copies of the same word should be aligned to each other.
</nextsent>
<nextsent>to help giza++ recognize this property, we first identify and collect all such words and then add single word pairs (x,x) to the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1720">
<title id=" N07-1057.xml">multilingual structural projection across inter linear text </title>
<section> the enrichment algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>we built two align ers for this stage, as described below.
</prevsent>
<prevsent>3.2.1 statistical word aligner we create parallel corpus by using the gloss lines and the translation lines of all the igt examples forall the languages in odin.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we then train ibm models (brown et al, 1993) <papid> J93-2003 </papid>using the giza++ package (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>in addition to the common practice of lower casing words and combining word alignments from both directions, we adopt the following strategies to improve word alignment: breaking words into morphemes: since amulti-morpheme word in gloss line often corresponds to multiple words in the translation line, wesplit each word on the gloss line into morphemes using the standard igt morpheme delimiters (e.g., ? ?).
</nextsent>
<nextsent>for instance, the seven words in the gloss line of ex (1) become nine morphemes.
</nextsent>
<nextsent>adding (x,x) pairs: if word appears in the gloss and the translation lines of the same igt example, it is highly likely that the two copies of the same word should be aligned to each other.
</nextsent>
<nextsent>to help giza++ recognize this property, we first identify and collect all such words and then add single word pairs (x,x) to the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1722">
<title id=" N07-1057.xml">multilingual structural projection across inter linear text </title>
<section> the enrichment algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, fromex (1), we would add sentence pair for each morpheme (excepting -3sg which does not appear in the translation line).
</prevsent>
<prevsent>3.2.2 heuristic word alignerour second word aligner is based on the assumption that if two words (one on the gloss line, the other on the translation line) have the same root form, theyare likely to be aligned to one other.we built simple english morphological analyzer and ran it on the two lines, and then linked the words with the same 454 root form.4 3.3 tree projection.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
we designed two projection algorithms: one which projects ps and the other which projects ds, both from the english to the source language.5 3.3.1 projecting dependency structure our ds projection algorithm is similar to the projection algorithms described in (hwa et al, 2002) <papid> P02-1050 </papid>and (quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>it has four steps: first, we copy the english ds, and remove all the unaligned english words from the ds.6 second, we replace each english word in the ds with the corresponding source words.
</nextsent>
<nextsent>if an english word aligns to several source words, we will make several copies of the node for x, one copy for each such source word.
</nextsent>
<nextsent>the copies will all be siblings in the ds.
</nextsent>
<nextsent>if source word aligns to multiple english words, after step 2 the source word will have several copies in the resulting ds.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1729">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>monty python, pet shop?
</prevsent>
<prevsent>a mechanism for automatically generating multiple paraphrases of given sentence would be of significant practical import for text-to-text generation systems.
</prevsent>
</prevsection>
<citsent citstr=" P79-1016 ">
applications include summarization (knight andmarcu, 2000) and rewriting (chandrasekar and bangalore, 1997): both could employ such mechanism to produce candidate sentence paraphrases that other system components would filter for length, sophistication level, and so forth.1 not surprisingly, therefore, paraphrasing has been focus of generation research for quite some 1another interesting application, somewhat tangential to generation, would be to expand existing corpora by providing time (mckeown, 1979; <papid> P79-1016 </papid>meteer and shaked, 1988; <papid> C88-2088 </papid>dras, 1999).one might initially suppose that sentence-level paraphrasing is simply the result of word-for-word or phraseby-phrase substitution applied in domain- and context independent fashion.</citsent>
<aftsection>
<nextsent>however, in studies of paraphrases across several domains (iordanskaja et al , 1991;robin, 1994; mckeown et al , 1994), <papid> A94-1002 </papid>this was generally not the case.</nextsent>
<nextsent>for instance, consider the following two sentences (similar to examples found in smadja and mckeown (1991)): after the latest fed rate cut, stocks rose across the board.winners strongly outpaced losers after greenspan cut interest rates again.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1730">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>monty python, pet shop?
</prevsent>
<prevsent>a mechanism for automatically generating multiple paraphrases of given sentence would be of significant practical import for text-to-text generation systems.
</prevsent>
</prevsection>
<citsent citstr=" C88-2088 ">
applications include summarization (knight andmarcu, 2000) and rewriting (chandrasekar and bangalore, 1997): both could employ such mechanism to produce candidate sentence paraphrases that other system components would filter for length, sophistication level, and so forth.1 not surprisingly, therefore, paraphrasing has been focus of generation research for quite some 1another interesting application, somewhat tangential to generation, would be to expand existing corpora by providing time (mckeown, 1979; <papid> P79-1016 </papid>meteer and shaked, 1988; <papid> C88-2088 </papid>dras, 1999).one might initially suppose that sentence-level paraphrasing is simply the result of word-for-word or phraseby-phrase substitution applied in domain- and context independent fashion.</citsent>
<aftsection>
<nextsent>however, in studies of paraphrases across several domains (iordanskaja et al , 1991;robin, 1994; mckeown et al , 1994), <papid> A94-1002 </papid>this was generally not the case.</nextsent>
<nextsent>for instance, consider the following two sentences (similar to examples found in smadja and mckeown (1991)): after the latest fed rate cut, stocks rose across the board.winners strongly outpaced losers after greenspan cut interest rates again.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1731">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a mechanism for automatically generating multiple paraphrases of given sentence would be of significant practical import for text-to-text generation systems.
</prevsent>
<prevsent>applications include summarization (knight andmarcu, 2000) and rewriting (chandrasekar and bangalore, 1997): both could employ such mechanism to produce candidate sentence paraphrases that other system components would filter for length, sophistication level, and so forth.1 not surprisingly, therefore, paraphrasing has been focus of generation research for quite some 1another interesting application, somewhat tangential to generation, would be to expand existing corpora by providing time (mckeown, 1979; <papid> P79-1016 </papid>meteer and shaked, 1988; <papid> C88-2088 </papid>dras, 1999).one might initially suppose that sentence-level paraphrasing is simply the result of word-for-word or phraseby-phrase substitution applied in domain- and context independent fashion.</prevsent>
</prevsection>
<citsent citstr=" A94-1002 ">
however, in studies of paraphrases across several domains (iordanskaja et al , 1991;robin, 1994; mckeown et al , 1994), <papid> A94-1002 </papid>this was generally not the case.</citsent>
<aftsection>
<nextsent>for instance, consider the following two sentences (similar to examples found in smadja and mckeown (1991)): after the latest fed rate cut, stocks rose across the board.winners strongly outpaced losers after greenspan cut interest rates again.
</nextsent>
<nextsent>observe that fed?
</nextsent>
<nextsent>(federal reserve) and greenspan?
</nextsent>
<nextsent>are interchangeable only in the domain of us financialmatters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1732">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our work presents novel knowledge-lean algorithm that uses multiple-sequence alignment (msa) to learn to generate sentence-level paraphrases essentially from unannotated corpus data alone.
</prevsent>
<prevsent>in contrast to previous work using msa for generation (barzilay and lee, several versions of their component sentences.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
this could, for example, aid machine-translation evaluation, where it has be come common to evaluate systems by comparing their output against bank of several reference translations for the same sentences (papineni et al , 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>see bangalore et al  (2002) <papid> C02-1134 </papid>and barzilay and lee (2002) <papid> W02-1022 </papid>for other uses of such data.</nextsent>
<nextsent>edmonton, may-june 2003 main papers , pp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1733">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast to previous work using msa for generation (barzilay and lee, several versions of their component sentences.
</prevsent>
<prevsent>this could, for example, aid machine-translation evaluation, where it has be come common to evaluate systems by comparing their output against bank of several reference translations for the same sentences (papineni et al , 2002).<papid> P02-1040 </papid></prevsent>
</prevsection>
<citsent citstr=" C02-1134 ">
see bangalore et al  (2002) <papid> C02-1134 </papid>and barzilay and lee (2002) <papid> W02-1022 </papid>for other uses of such data.</citsent>
<aftsection>
<nextsent>edmonton, may-june 2003 main papers , pp.
</nextsent>
<nextsent>16-23 proceedings of hlt-naacl 20032002), we need neither parallel data nor explicit information about sentence semantics.
</nextsent>
<nextsent>rather, we use two comparable corpora, in our case, collections of articles produced by two different newswire agencies about the same events.
</nextsent>
<nextsent>the use of related corpora is key: we can capture paraphrases that on the surface bear little resemblance but that, by the nature of the data, must be descriptions of the same information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1734">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast to previous work using msa for generation (barzilay and lee, several versions of their component sentences.
</prevsent>
<prevsent>this could, for example, aid machine-translation evaluation, where it has be come common to evaluate systems by comparing their output against bank of several reference translations for the same sentences (papineni et al , 2002).<papid> P02-1040 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-1022 ">
see bangalore et al  (2002) <papid> C02-1134 </papid>and barzilay and lee (2002) <papid> W02-1022 </papid>for other uses of such data.</citsent>
<aftsection>
<nextsent>edmonton, may-june 2003 main papers , pp.
</nextsent>
<nextsent>16-23 proceedings of hlt-naacl 20032002), we need neither parallel data nor explicit information about sentence semantics.
</nextsent>
<nextsent>rather, we use two comparable corpora, in our case, collections of articles produced by two different newswire agencies about the same events.
</nextsent>
<nextsent>the use of related corpora is key: we can capture paraphrases that on the surface bear little resemblance but that, by the nature of the data, must be descriptions of the same information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1735">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous approaches to paraphrase acquisition focused on certain rigid types of paraphrases, for instance, limiting the number of arguments.
</prevsent>
<prevsent>in contrast, our method is not limited to set of priori-specified paraphrase types.use of comparable corpora and minimal use of knowledge resources.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
in addition to the advantages mentioned above, comparable corpora can be easily obtained formany domains, whereas previous approaches to paraphrase acquisition (and the related problem of phrase based machine translation (wang, 1998; och et al , 1999; <papid> W99-0604 </papid>vogel and ney, 2000)) <papid> C00-2172 </papid>required parallel corpora.</citsent>
<aftsection>
<nextsent>we point out that one such approach, recently proposed bypang et al  (2003), <papid> N03-1024 </papid>also represents paraphrases by lattices, similarly to our method, although their lattices are derived using parse information.</nextsent>
<nextsent>moreover, our algorithm does not employ knowledge resources such as parsers or lexical databases, which may not be available or appropriate for all domains ? key issue since paraphrasing is typically domain-dependent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1736">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous approaches to paraphrase acquisition focused on certain rigid types of paraphrases, for instance, limiting the number of arguments.
</prevsent>
<prevsent>in contrast, our method is not limited to set of priori-specified paraphrase types.use of comparable corpora and minimal use of knowledge resources.
</prevsent>
</prevsection>
<citsent citstr=" C00-2172 ">
in addition to the advantages mentioned above, comparable corpora can be easily obtained formany domains, whereas previous approaches to paraphrase acquisition (and the related problem of phrase based machine translation (wang, 1998; och et al , 1999; <papid> W99-0604 </papid>vogel and ney, 2000)) <papid> C00-2172 </papid>required parallel corpora.</citsent>
<aftsection>
<nextsent>we point out that one such approach, recently proposed bypang et al  (2003), <papid> N03-1024 </papid>also represents paraphrases by lattices, similarly to our method, although their lattices are derived using parse information.</nextsent>
<nextsent>moreover, our algorithm does not employ knowledge resources such as parsers or lexical databases, which may not be available or appropriate for all domains ? key issue since paraphrasing is typically domain-dependent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1737">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast, our method is not limited to set of priori-specified paraphrase types.use of comparable corpora and minimal use of knowledge resources.
</prevsent>
<prevsent>in addition to the advantages mentioned above, comparable corpora can be easily obtained formany domains, whereas previous approaches to paraphrase acquisition (and the related problem of phrase based machine translation (wang, 1998; och et al , 1999; <papid> W99-0604 </papid>vogel and ney, 2000)) <papid> C00-2172 </papid>required parallel corpora.</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
we point out that one such approach, recently proposed bypang et al  (2003), <papid> N03-1024 </papid>also represents paraphrases by lattices, similarly to our method, although their lattices are derived using parse information.</citsent>
<aftsection>
<nextsent>moreover, our algorithm does not employ knowledge resources such as parsers or lexical databases, which may not be available or appropriate for all domains ? key issue since paraphrasing is typically domain-dependent.
</nextsent>
<nextsent>nonetheless, our algorithm achieves good performance.
</nextsent>
<nextsent>previous work on automated paraphrasing has considered different levels of paraphrase granularity.
</nextsent>
<nextsent>learning synonyms via distributional similarity hasbeen well-studied (pereira et al , 1993; <papid> P93-1024 </papid>grefenstette, 1994; lin, 1998).<papid> P98-2127 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1738">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>nonetheless, our algorithm achieves good performance.
</prevsent>
<prevsent>previous work on automated paraphrasing has considered different levels of paraphrase granularity.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
learning synonyms via distributional similarity hasbeen well-studied (pereira et al , 1993; <papid> P93-1024 </papid>grefenstette, 1994; lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>jacquemin (1999) <papid> P99-1044 </papid>and barzilay and mckeown (2001) <papid> P01-1008 </papid>identify phrase level paraphrases, while lin and pantel (2001) and shinyama et al  (2002) acquire structural paraphrases encoded as templates.</nextsent>
<nextsent>these latter are the most closely related to the sentence-level paraphrases we desire, and so we focus in this section on template-induction approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1739">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>nonetheless, our algorithm achieves good performance.
</prevsent>
<prevsent>previous work on automated paraphrasing has considered different levels of paraphrase granularity.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
learning synonyms via distributional similarity hasbeen well-studied (pereira et al , 1993; <papid> P93-1024 </papid>grefenstette, 1994; lin, 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>jacquemin (1999) <papid> P99-1044 </papid>and barzilay and mckeown (2001) <papid> P01-1008 </papid>identify phrase level paraphrases, while lin and pantel (2001) and shinyama et al  (2002) acquire structural paraphrases encoded as templates.</nextsent>
<nextsent>these latter are the most closely related to the sentence-level paraphrases we desire, and so we focus in this section on template-induction approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1740">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>previous work on automated paraphrasing has considered different levels of paraphrase granularity.
</prevsent>
<prevsent>learning synonyms via distributional similarity hasbeen well-studied (pereira et al , 1993; <papid> P93-1024 </papid>grefenstette, 1994; lin, 1998).<papid> P98-2127 </papid></prevsent>
</prevsection>
<citsent citstr=" P99-1044 ">
jacquemin (1999) <papid> P99-1044 </papid>and barzilay and mckeown (2001) <papid> P01-1008 </papid>identify phrase level paraphrases, while lin and pantel (2001) and shinyama et al  (2002) acquire structural paraphrases encoded as templates.</citsent>
<aftsection>
<nextsent>these latter are the most closely related to the sentence-level paraphrases we desire, and so we focus in this section on template-induction approaches.
</nextsent>
<nextsent>lin and pantel (2001) extract inference rules, which are related to paraphrases (for example, wrote implies is the author of y), to improve question answering.
</nextsent>
<nextsent>they assume that paths in dependency trees that take similar arguments (leaves) are close in meaning.
</nextsent>
<nextsent>however, only two-argument templates are considered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1741">
<title id=" N03-1003.xml">learning to paraphrase an unsupervised approach using multiple sequence alignment </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>previous work on automated paraphrasing has considered different levels of paraphrase granularity.
</prevsent>
<prevsent>learning synonyms via distributional similarity hasbeen well-studied (pereira et al , 1993; <papid> P93-1024 </papid>grefenstette, 1994; lin, 1998).<papid> P98-2127 </papid></prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
jacquemin (1999) <papid> P99-1044 </papid>and barzilay and mckeown (2001) <papid> P01-1008 </papid>identify phrase level paraphrases, while lin and pantel (2001) and shinyama et al  (2002) acquire structural paraphrases encoded as templates.</citsent>
<aftsection>
<nextsent>these latter are the most closely related to the sentence-level paraphrases we desire, and so we focus in this section on template-induction approaches.
</nextsent>
<nextsent>lin and pantel (2001) extract inference rules, which are related to paraphrases (for example, wrote implies is the author of y), to improve question answering.
</nextsent>
<nextsent>they assume that paths in dependency trees that take similar arguments (leaves) are close in meaning.
</nextsent>
<nextsent>however, only two-argument templates are considered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1746">
<title id=" N06-1012.xml">reducing weight under training in structured discriminative learning </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>such model is less robust, for the highly-indicative features may be noisy or missing in the test data.
</prevsent>
<prevsent>to ameliorate this weight under training, we introduce several new feature bagging methods, in which separate models are trained on subsets of the original features, and combined using mixture model or product of experts.
</prevsent>
</prevsection>
<citsent citstr=" P05-1003 ">
these methods include the logarithmic opinion pools used by smith et al (2005).<papid> P05-1003 </papid></citsent>
<aftsection>
<nextsent>we evaluate feature bagging on linear-chain conditional random fields for two natural-language tasks.
</nextsent>
<nextsent>on both tasks, the feature-bagged crf performs better than simply training single crf on all the features.
</nextsent>
<nextsent>discriminative methods for training probabilistic model shave enjoyed wide popularity in natural language processing, such as in part-of-speech tagging (toutanova etal., 2003), <papid> N03-1033 </papid>chunking (sha and pereira, 2003), <papid> N03-1028 </papid>named entity recognition (florian et al, 2003; <papid> W03-0425 </papid>chieu and ng, 2003), and most recently parsing (taskar et al, 2004).<papid> W04-3201 </papid>a discriminative probabilistic model is trained to maximize the conditional probability p(y|x) of output labels given input variables x, as opposed to modeling the joint probability p(y, x), as in generative models such as the naive bayes classifier and hidden markov models.</nextsent>
<nextsent>the popularity of discriminative models stems from the great flexibility they allow in defining features: because the distribution over input features p(x) is not modeled, it can contain rich, highly overlapping features without making the model intractable for training and inference.in nlp, for example, useful features include word bi grams and trigrams, prefixes and suffixes, membership in domain-specific lexicons, and information from semantic databases such as wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1747">
<title id=" N06-1012.xml">reducing weight under training in structured discriminative learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate feature bagging on linear-chain conditional random fields for two natural-language tasks.
</prevsent>
<prevsent>on both tasks, the feature-bagged crf performs better than simply training single crf on all the features.
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
discriminative methods for training probabilistic model shave enjoyed wide popularity in natural language processing, such as in part-of-speech tagging (toutanova etal., 2003), <papid> N03-1033 </papid>chunking (sha and pereira, 2003), <papid> N03-1028 </papid>named entity recognition (florian et al, 2003; <papid> W03-0425 </papid>chieu and ng, 2003), and most recently parsing (taskar et al, 2004).<papid> W04-3201 </papid>a discriminative probabilistic model is trained to maximize the conditional probability p(y|x) of output labels given input variables x, as opposed to modeling the joint probability p(y, x), as in generative models such as the naive bayes classifier and hidden markov models.</citsent>
<aftsection>
<nextsent>the popularity of discriminative models stems from the great flexibility they allow in defining features: because the distribution over input features p(x) is not modeled, it can contain rich, highly overlapping features without making the model intractable for training and inference.in nlp, for example, useful features include word bi grams and trigrams, prefixes and suffixes, membership in domain-specific lexicons, and information from semantic databases such as wordnet.
</nextsent>
<nextsent>it is not uncommon to have hundreds of thousands or even millions of features.but not all features, even ones that are carefully engineered, improve performance.
</nextsent>
<nextsent>adding more features to model can hurt its accuracy on unseen testing data.
</nextsent>
<nextsent>one well-known reason for this is overfitting: model with more features has more capacity to fit chance regularities in the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1748">
<title id=" N06-1012.xml">reducing weight under training in structured discriminative learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate feature bagging on linear-chain conditional random fields for two natural-language tasks.
</prevsent>
<prevsent>on both tasks, the feature-bagged crf performs better than simply training single crf on all the features.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
discriminative methods for training probabilistic model shave enjoyed wide popularity in natural language processing, such as in part-of-speech tagging (toutanova etal., 2003), <papid> N03-1033 </papid>chunking (sha and pereira, 2003), <papid> N03-1028 </papid>named entity recognition (florian et al, 2003; <papid> W03-0425 </papid>chieu and ng, 2003), and most recently parsing (taskar et al, 2004).<papid> W04-3201 </papid>a discriminative probabilistic model is trained to maximize the conditional probability p(y|x) of output labels given input variables x, as opposed to modeling the joint probability p(y, x), as in generative models such as the naive bayes classifier and hidden markov models.</citsent>
<aftsection>
<nextsent>the popularity of discriminative models stems from the great flexibility they allow in defining features: because the distribution over input features p(x) is not modeled, it can contain rich, highly overlapping features without making the model intractable for training and inference.in nlp, for example, useful features include word bi grams and trigrams, prefixes and suffixes, membership in domain-specific lexicons, and information from semantic databases such as wordnet.
</nextsent>
<nextsent>it is not uncommon to have hundreds of thousands or even millions of features.but not all features, even ones that are carefully engineered, improve performance.
</nextsent>
<nextsent>adding more features to model can hurt its accuracy on unseen testing data.
</nextsent>
<nextsent>one well-known reason for this is overfitting: model with more features has more capacity to fit chance regularities in the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1749">
<title id=" N06-1012.xml">reducing weight under training in structured discriminative learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate feature bagging on linear-chain conditional random fields for two natural-language tasks.
</prevsent>
<prevsent>on both tasks, the feature-bagged crf performs better than simply training single crf on all the features.
</prevsent>
</prevsection>
<citsent citstr=" W03-0425 ">
discriminative methods for training probabilistic model shave enjoyed wide popularity in natural language processing, such as in part-of-speech tagging (toutanova etal., 2003), <papid> N03-1033 </papid>chunking (sha and pereira, 2003), <papid> N03-1028 </papid>named entity recognition (florian et al, 2003; <papid> W03-0425 </papid>chieu and ng, 2003), and most recently parsing (taskar et al, 2004).<papid> W04-3201 </papid>a discriminative probabilistic model is trained to maximize the conditional probability p(y|x) of output labels given input variables x, as opposed to modeling the joint probability p(y, x), as in generative models such as the naive bayes classifier and hidden markov models.</citsent>
<aftsection>
<nextsent>the popularity of discriminative models stems from the great flexibility they allow in defining features: because the distribution over input features p(x) is not modeled, it can contain rich, highly overlapping features without making the model intractable for training and inference.in nlp, for example, useful features include word bi grams and trigrams, prefixes and suffixes, membership in domain-specific lexicons, and information from semantic databases such as wordnet.
</nextsent>
<nextsent>it is not uncommon to have hundreds of thousands or even millions of features.but not all features, even ones that are carefully engineered, improve performance.
</nextsent>
<nextsent>adding more features to model can hurt its accuracy on unseen testing data.
</nextsent>
<nextsent>one well-known reason for this is overfitting: model with more features has more capacity to fit chance regularities in the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1750">
<title id=" N06-1012.xml">reducing weight under training in structured discriminative learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate feature bagging on linear-chain conditional random fields for two natural-language tasks.
</prevsent>
<prevsent>on both tasks, the feature-bagged crf performs better than simply training single crf on all the features.
</prevsent>
</prevsection>
<citsent citstr=" W04-3201 ">
discriminative methods for training probabilistic model shave enjoyed wide popularity in natural language processing, such as in part-of-speech tagging (toutanova etal., 2003), <papid> N03-1033 </papid>chunking (sha and pereira, 2003), <papid> N03-1028 </papid>named entity recognition (florian et al, 2003; <papid> W03-0425 </papid>chieu and ng, 2003), and most recently parsing (taskar et al, 2004).<papid> W04-3201 </papid>a discriminative probabilistic model is trained to maximize the conditional probability p(y|x) of output labels given input variables x, as opposed to modeling the joint probability p(y, x), as in generative models such as the naive bayes classifier and hidden markov models.</citsent>
<aftsection>
<nextsent>the popularity of discriminative models stems from the great flexibility they allow in defining features: because the distribution over input features p(x) is not modeled, it can contain rich, highly overlapping features without making the model intractable for training and inference.in nlp, for example, useful features include word bi grams and trigrams, prefixes and suffixes, membership in domain-specific lexicons, and information from semantic databases such as wordnet.
</nextsent>
<nextsent>it is not uncommon to have hundreds of thousands or even millions of features.but not all features, even ones that are carefully engineered, improve performance.
</nextsent>
<nextsent>adding more features to model can hurt its accuracy on unseen testing data.
</nextsent>
<nextsent>one well-known reason for this is overfitting: model with more features has more capacity to fit chance regularities in the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1753">
<title id=" N06-1012.xml">reducing weight under training in structured discriminative learning </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>in both datasets, the bagged model performs better than the single crf trained with all of the features.
</prevsent>
<prevsent>for the named entity task, bagging improves performance from 85.45% to 86.61%, with substantial error reduction of 8.32%.
</prevsent>
</prevsection>
<citsent citstr=" P05-1001 ">
this is lower than the best reported results for this dataset, which is 89.3% (ando and zhang, 2005), <papid> P05-1001 </papid>using large amount of unlabeled data.</citsent>
<aftsection>
<nextsent>for the chunking task, bagging improved the performance from 94.34% to 94.77%, with an error reduction of 7.60%.
</nextsent>
<nextsent>in both datasets, the improvement is statistically significant (mcne mars test;   0.01).on the chunking task, the bagged model also outperforms the models of kudo and matsumoto (2001) <papid> N01-1025 </papid>andsha and pereira (2003), <papid> N03-1028 </papid>and equals the currently-best results of (ando and zhang, 2005), <papid> P05-1001 </papid>who use large amount of unlabeled data.</nextsent>
<nextsent>although we use lexicons that werenot included in the previous models, the additional features actually do not help the original crf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1756">
<title id=" N06-1012.xml">reducing weight under training in structured discriminative learning </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>this is lower than the best reported results for this dataset, which is 89.3% (ando and zhang, 2005), <papid> P05-1001 </papid>using large amount of unlabeled data.</prevsent>
<prevsent>for the chunking task, bagging improved the performance from 94.34% to 94.77%, with an error reduction of 7.60%.</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
in both datasets, the improvement is statistically significant (mcne mars test;   0.01).on the chunking task, the bagged model also outperforms the models of kudo and matsumoto (2001) <papid> N01-1025 </papid>andsha and pereira (2003), <papid> N03-1028 </papid>and equals the currently-best results of (ando and zhang, 2005), <papid> P05-1001 </papid>who use large amount of unlabeled data.</citsent>
<aftsection>
<nextsent>although we use lexicons that werenot included in the previous models, the additional features actually do not help the original crf.
</nextsent>
<nextsent>only with feature bagging do these lexicons improve performance.finally, we compare the four bagging methods of section 4: pre-transition mixture, pre-transition product of experts, and per-sequence mixture.
</nextsent>
<nextsent>on the named entity data, all four models perform in statistical tie, with no statistically significant difference in their performance(table 1).
</nextsent>
<nextsent>as we mentioned in the last section, the de model f1 per-sequence product of experts 86.61 per-transition product of experts 86.58 per-sequence mixture 86.46 per-transition mixture 86.42 table 1: comparison of various bagging methods on the conll 2003 named entity task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1768">
<title id=" N06-1012.xml">reducing weight under training in structured discriminative learning </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>understanding this particular type of over fitting is useful, because it motivates the choice of feature bags that we explore in this work.
</prevsent>
<prevsent>indeed, one contribution of the present work is demonstrating how careful choice of feature bags can yield state-of-the-art performance.
</prevsent>
</prevsection>
<citsent citstr=" W06-2918 ">
concurrently and independently, smith and osborne (2006) <papid> W06-2918 </papid>present similar experiments on the conll-2003 dataset, examining per-sequence mixture of experts(that is, logarithmic opinion pool), in which the lexicon features are trained separately.</citsent>
<aftsection>
<nextsent>their work presents more detailed error analysis than we do here, while we present results both on other combination methods and on np chunking.
</nextsent>
<nextsent>discriminatively-trained probabilistic models have hadmuch success in applications because of their flexibility in defining features, but sometimes even highly indicative features can fail to increase performance.
</nextsent>
<nextsent>wehave shown that this can be due to feature under train ing, where highly-indicative features prevent training ofmany weaker features.
</nextsent>
<nextsent>one solution to this is feature bagging: repeatedly selecting feature subsets, training separate models on each subset, and averaging the individual models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1769">
<title id=" N04-4010.xml">using nbest lists for named entity recognition from chinese speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>named entity recognition (ner) is the first step for many tasks in the fields of natural language processing and information retrieval.
</prevsent>
<prevsent>it is designated task in number of conferences, including the message understanding conference (muc), the information retrieval and extraction conference (irex), the conferences on natural language learning (conll) and the recent automatic content extraction conference (ace).
</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
there has been considerable amount of work on english ner yielding good performance (tjong kim sang et al 2002, 2003; cucerzan &amp; yarowsky 1999; <papid> W99-0612 </papid>wu et al 2003).<papid> W03-0433 </papid></citsent>
<aftsection>
<nextsent>however, chinese ner is more difficult, especially on speech output, due to two reasons.
</nextsent>
<nextsent>first, chinese has large number of homonyms and the vocabulary used in chinese person names is an open set so more characters/words are unseen in the training data.
</nextsent>
<nextsent>second, there is no standard definition of chinese words.
</nextsent>
<nextsent>word segmentation errors made by recognizers may lead toner errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1770">
<title id=" N04-4010.xml">using nbest lists for named entity recognition from chinese speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>named entity recognition (ner) is the first step for many tasks in the fields of natural language processing and information retrieval.
</prevsent>
<prevsent>it is designated task in number of conferences, including the message understanding conference (muc), the information retrieval and extraction conference (irex), the conferences on natural language learning (conll) and the recent automatic content extraction conference (ace).
</prevsent>
</prevsection>
<citsent citstr=" W03-0433 ">
there has been considerable amount of work on english ner yielding good performance (tjong kim sang et al 2002, 2003; cucerzan &amp; yarowsky 1999; <papid> W99-0612 </papid>wu et al 2003).<papid> W03-0433 </papid></citsent>
<aftsection>
<nextsent>however, chinese ner is more difficult, especially on speech output, due to two reasons.
</nextsent>
<nextsent>first, chinese has large number of homonyms and the vocabulary used in chinese person names is an open set so more characters/words are unseen in the training data.
</nextsent>
<nextsent>second, there is no standard definition of chinese words.
</nextsent>
<nextsent>word segmentation errors made by recognizers may lead toner errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1771">
<title id=" N04-4010.xml">using nbest lists for named entity recognition from chinese speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, there is no standard definition of chinese words.
</prevsent>
<prevsent>word segmentation errors made by recognizers may lead toner errors.
</prevsent>
</prevsection>
<citsent citstr=" W03-1026 ">
previous work on chinese textual ner includes jing et al (2003) <papid> W03-1026 </papid>and sun et al (2003) but there has been no published work on ner in spoken chinese.</citsent>
<aftsection>
<nextsent>named entity recognition for speech is more difficult than for text, since the most reliable features for textual ner (punctuation, capitalization, and syntactic patterns) are often not available in speech output.
</nextsent>
<nextsent>ner on automatically recognized broadcast news was first conducted by mitre in 1997, and was subsequently added to hub-4 evaluation as task.
</nextsent>
<nextsent>palmer et al (1999) used error modeling, and horlock &amp; king (2003) proposed discriminative training to handle ner errors; both used hidden markov model (hmm).
</nextsent>
<nextsent>miller et al (1999) also reported results in english speech ner using an hmm model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1774">
<title id=" N06-2024.xml">ner systems that suit users preferences adjusting the recall precision tradeoff for entity extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this method is evaluated on the task of recognizing personal names in email and newswire text, and proves to be both simple and effective.
</prevsent>
<prevsent>named entity recognition (ner) is the task of identifying named entities in free text typically personal names, organizations, gene-protein entities, and so on.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
recently, sequential learning methods,such as hidden markov models (hmms) and conditional random fields (crfs), have been used successfully for number of applications, including ner (sha and pereira, 2003; <papid> N03-1028 </papid>pinto et al, 2003; mccallum and lee, 2003).<papid> W03-0430 </papid></citsent>
<aftsection>
<nextsent>in practice, these methods provide imperfect performance: precision and recall, even for well-studied problems on clean well written text, reach at most the mid-90s. while performance of ner systems is often evaluated interms of f1 measure (a harmonic mean of precision and recall), this measure may not match user preferences regarding precision and recall.
</nextsent>
<nextsent>further more, learned ner models may be sub-optimal also in terms of f1, as they are trained to optimize other measures (e.g., log likelihood of the training data for crfs).
</nextsent>
<nextsent>obviously, different applications of ner have different requirements for precision and recall.
</nextsent>
<nextsent>a system might require high precision if it is designed to extract entities as one stage of fact-extraction, where facts are stored directly into database.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1775">
<title id=" N06-2024.xml">ner systems that suit users preferences adjusting the recall precision tradeoff for entity extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this method is evaluated on the task of recognizing personal names in email and newswire text, and proves to be both simple and effective.
</prevsent>
<prevsent>named entity recognition (ner) is the task of identifying named entities in free text typically personal names, organizations, gene-protein entities, and so on.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
recently, sequential learning methods,such as hidden markov models (hmms) and conditional random fields (crfs), have been used successfully for number of applications, including ner (sha and pereira, 2003; <papid> N03-1028 </papid>pinto et al, 2003; mccallum and lee, 2003).<papid> W03-0430 </papid></citsent>
<aftsection>
<nextsent>in practice, these methods provide imperfect performance: precision and recall, even for well-studied problems on clean well written text, reach at most the mid-90s. while performance of ner systems is often evaluated interms of f1 measure (a harmonic mean of precision and recall), this measure may not match user preferences regarding precision and recall.
</nextsent>
<nextsent>further more, learned ner models may be sub-optimal also in terms of f1, as they are trained to optimize other measures (e.g., log likelihood of the training data for crfs).
</nextsent>
<nextsent>obviously, different applications of ner have different requirements for precision and recall.
</nextsent>
<nextsent>a system might require high precision if it is designed to extract entities as one stage of fact-extraction, where facts are stored directly into database.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1776">
<title id=" N06-2024.xml">ner systems that suit users preferences adjusting the recall precision tradeoff for entity extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, confidence thresholding of this sort cannot increase recall.
</prevsent>
<prevsent>also, while confidence scores are straightforward to compute in many classification settings, there is no inherent mechanism for computing confidence of sequential extractor.
</prevsent>
</prevsection>
<citsent citstr=" N04-4028 ">
culotta and mccallum (2004) <papid> N04-4028 </papid>suggest several methods for doing this with crfs.</citsent>
<aftsection>
<nextsent>in this paper, we suggest an alternative simple method for exploring and optimizing the relationship between precision and recall for ner systems.
</nextsent>
<nextsent>in particular, we describe and evaluate technique called extractor tweaking?
</nextsent>
<nextsent>that optimizes learned extractor with respect to specific evaluation metric.
</nextsent>
<nextsent>in nutshell, we directly tweak the threasholdterm that is part of any linear classifier, including sequential extractors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1778">
<title id=" N06-2024.xml">ner systems that suit users preferences adjusting the recall precision tradeoff for entity extraction </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>94collection, extracted from the cspace email corpus, which contains email messages sent by mba students taking management course conducted at carnegie mellon university in 1997.
</prevsent>
<prevsent>this data was split such that its test set contains different mix of entity names comparing to training exmaples.
</prevsent>
</prevsection>
<citsent citstr=" H05-1056 ">
further details about these datasets are available else where (minkov et al, 2005).<papid> H05-1056 </papid></citsent>
<aftsection>
<nextsent># documents # names train test # tokens per doc.
</nextsent>
<nextsent>muc-6 347 30 204,071 6.8 enron 833 143 204,423 3.0 mgmt-groups 631 128 104,662 3.7 table 1: summary of the corpora used in the experiment swe used an implementation of collins?
</nextsent>
<nextsent>voted percepton method for discriminatively training hmms (henceforth, vp-hmm) (collins, 2002) <papid> W02-1001 </papid>as well as crf (lafferty et al, 2001) to learn ner.</nextsent>
<nextsent>both vp-hmm and crf were trained for 20 epochs on every dataset, using simple set of features such as word identity and capitalization patterns for awindow of three words around each word being classified.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1779">
<title id=" N06-2024.xml">ner systems that suit users preferences adjusting the recall precision tradeoff for entity extraction </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent># documents # names train test # tokens per doc.
</prevsent>
<prevsent>muc-6 347 30 204,071 6.8 enron 833 143 204,423 3.0 mgmt-groups 631 128 104,662 3.7 table 1: summary of the corpora used in the experiment swe used an implementation of collins?
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
voted percepton method for discriminatively training hmms (henceforth, vp-hmm) (collins, 2002) <papid> W02-1001 </papid>as well as crf (lafferty et al, 2001) to learn ner.</citsent>
<aftsection>
<nextsent>both vp-hmm and crf were trained for 20 epochs on every dataset, using simple set of features such as word identity and capitalization patterns for awindow of three words around each word being classified.
</nextsent>
<nextsent>each word is classified as either inside or out side person name.4 3.2 extractor tweaking results.
</nextsent>
<nextsent>figure 1 evaluates the effectiveness of the optimization process used by extractor tweaking?
</nextsent>
<nextsent>on the enron dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1780">
<title id=" N07-1001.xml">exploiting acoustic and syntactic features for prosody labeling in a maximum entropy framework </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>another source of renewed interest has come from spoken language translation(noth et al, 2000; aguero et al, 2006).
</prevsent>
<prevsent>a prerequisite for all these applications is accurate prosody detection, the topic of the present work.in this paper, we describe our framework for building an automatic prosody labeler for english.
</prevsent>
</prevsection>
<citsent citstr=" P96-1038 ">
we report results on the boston university (bu) radio speech corpus (ostendorf et al, 1995) and boston directions corpus (bdc) (hirschberg and nakatani, 1996), <papid> P96-1038 </papid>two publicly available speech corpora with manual tobi annotations intended for experiments in automatic prosody labeling.</citsent>
<aftsection>
<nextsent>we condition prosody not only on word strings and theirparts-of-speech but also on richer syntactic information encapsulated in the form of supertags (bangalore and joshi, 1999).<papid> J99-2004 </papid></nextsent>
<nextsent>we propose maximum entropy modeling framework for the syntactic features.we model the acoustic-prosodic stream with two different models, maximum entropy model and more traditional hidden markov model (hmm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1781">
<title id=" N07-1001.xml">exploiting acoustic and syntactic features for prosody labeling in a maximum entropy framework </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a prerequisite for all these applications is accurate prosody detection, the topic of the present work.in this paper, we describe our framework for building an automatic prosody labeler for english.
</prevsent>
<prevsent>we report results on the boston university (bu) radio speech corpus (ostendorf et al, 1995) and boston directions corpus (bdc) (hirschberg and nakatani, 1996), <papid> P96-1038 </papid>two publicly available speech corpora with manual tobi annotations intended for experiments in automatic prosody labeling.</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
we condition prosody not only on word strings and theirparts-of-speech but also on richer syntactic information encapsulated in the form of supertags (bangalore and joshi, 1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>we propose maximum entropy modeling framework for the syntactic features.we model the acoustic-prosodic stream with two different models, maximum entropy model and more traditional hidden markov model (hmm).
</nextsent>
<nextsent>in an automatic prosody labeling task, one is essentially try 1 ing to predict the correct prosody label sequence fora given utterance and maximum entropy model offers an elegant solution to this learning problem.
</nextsent>
<nextsent>the framework is also robust in the selection of discriminative features for the classification problem.
</nextsent>
<nextsent>so, given word sequence = {w1, ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1784">
<title id=" N07-1001.xml">exploiting acoustic and syntactic features for prosody labeling in a maximum entropy framework </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the bu corpus is widely used corpus with symbolic representation of prosody.
</prevsent>
<prevsent>thehand-labeled tobi annotations make this an attractive corpus to perform prosody labeling experiments.the main drawback of this corpus is that it comprises only read speech.
</prevsent>
</prevsection>
<citsent citstr=" P04-1086 ">
prosody labeling on spontaneous speech corpora like boston directions corpus(bdc), switchboard (swbd) has garnered attention in (hirschberg and nakatani, 1996; <papid> P96-1038 </papid>gregory and altun, 2004).<papid> P04-1086 </papid></citsent>
<aftsection>
<nextsent>automatic prosody labeling has been achieved through various machine learning techniques, such as decision trees (hirschberg, 1993; wightman and ostendorf, 1994; ma et al, 2003), rule-based systems (shimei and mckeown, 1999), bagging and boosting on cart (sun, 2002), hidden markov models (conkie et al, 1999), neural networks (hasegawa-johnson et al, 2005),maximum-entropymodels (brenier et al, 2005) and conditional random fields (gregory and altun, 2004).<papid> P04-1086 </papid>prosody labeling of the bu corpus has been reported in many studies (hirschberg, 1993; hasegawa johnson et al, 2005; ananthakrishnan and narayanan, 2005).</nextsent>
<nextsent>hirschberg (hirschberg, 1993) used decision-tree based system that achieved 82.4% speaker dependent accent labeling accuracy at the word level on the bu corpus using lexical features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1790">
<title id=" N07-1001.xml">exploiting acoustic and syntactic features for prosody labeling in a maximum entropy framework </title>
<section> syntactic-prosodic model.  </section>
<citcontext>
<prevsection>
<prevsent>i (li|?)
</prevsent>
<prevsent>(6) to estimate the conditional distribution (li|?)
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we use the general technique of choosing the maximum entropy (maxent) distribution that estimates the average of each feature over the training data (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>this can be written in terms of gibbs distribution parameterized with weights ?, where is the size of the prosodic label set.
</nextsent>
<nextsent>hence, (li|?)
</nextsent>
<nextsent>= eli .?
</nextsent>
<nextsent>v l=1 li .?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1791">
<title id=" N03-4005.xml">a spoken dialogue interface to a geologists field assistant </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>a system response is always given, but is usually omitted below forthe sake of brevity.
</prevsent>
<prevsent>when given, the system response appears in italics.
</prevsent>
</prevsection>
<citsent citstr=" P99-1024 ">
this spoken dialogue system shares common architecture with several prior systems: command talk (stent et al., 1999), <papid> P99-1024 </papid>psa (rayner et al, 2000), <papid> A00-1016 </papid>witas (lemon et al., 2001), and the intelligent procedure assistant (aist et al, 2002).</citsent>
<aftsection>
<nextsent>the architecure has been well described in edmonton, may-june 2003 demonstrations , pp.
</nextsent>
<nextsent>9-10 proceedings of hlt-naacl 2003prior work.
</nextsent>
<nextsent>the critical feature of the architecture relevant to this work is the use of grammar-based language model for speech recognition that is automatically derived from the same unification grammar that is used for parsing and interpretation.
</nextsent>
<nextsent>the mobile agents project conducted two field tests in 2002: one week dress rehearsal at jsc in the mars yard in may, and two week field test in the arizona desert in september, split between two sites of geological interest, one near the petrified forest national park, and the other on the ejecta field at meteor crater.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1792">
<title id=" N03-4005.xml">a spoken dialogue interface to a geologists field assistant </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>a system response is always given, but is usually omitted below forthe sake of brevity.
</prevsent>
<prevsent>when given, the system response appears in italics.
</prevsent>
</prevsection>
<citsent citstr=" A00-1016 ">
this spoken dialogue system shares common architecture with several prior systems: command talk (stent et al., 1999), <papid> P99-1024 </papid>psa (rayner et al, 2000), <papid> A00-1016 </papid>witas (lemon et al., 2001), and the intelligent procedure assistant (aist et al, 2002).</citsent>
<aftsection>
<nextsent>the architecure has been well described in edmonton, may-june 2003 demonstrations , pp.
</nextsent>
<nextsent>9-10 proceedings of hlt-naacl 2003prior work.
</nextsent>
<nextsent>the critical feature of the architecture relevant to this work is the use of grammar-based language model for speech recognition that is automatically derived from the same unification grammar that is used for parsing and interpretation.
</nextsent>
<nextsent>the mobile agents project conducted two field tests in 2002: one week dress rehearsal at jsc in the mars yard in may, and two week field test in the arizona desert in september, split between two sites of geological interest, one near the petrified forest national park, and the other on the ejecta field at meteor crater.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1793">
<title id=" N06-2007.xml">semi supervised relation extraction with label propagation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation on the ace corpus showed when only few labeled examples are available, our lp based relation extraction can achieve better performance than svm and another bootstrapping method.
</prevsent>
<prevsent>relation extraction is the task of finding relationships between two entities from text.
</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
for the task,many machine learning methods have been proposed, including supervised methods (miller et al, 2000; <papid> A00-2030 </papid>zelenko et al, 2002; <papid> W02-1010 </papid>culotta and soresen,2004; kambhatla, 2004; <papid> P04-3022 </papid>zhou et al, 2005), semi supervised methods (brin, 1998; agichtein and gravano, 2000; zhang, 2004), and unsupervised method (hasegawa et al, 2004).<papid> P04-1053 </papid>supervised relation extraction achieves good performance, but it requires large amount of manually labeled relation instances.</citsent>
<aftsection>
<nextsent>unsupervised methods do not need the definition of relation types and manually labeled data, but it is difficult to evaluate the clustering result since there is no relation type label for each instance in clusters.
</nextsent>
<nextsent>therefore, semi supervised learning has received attention, which can minimize corpus annotation requirement.
</nextsent>
<nextsent>current works on semi-supervised resolution for relation extraction task mostly use the bootstrapping algorithm, which is based on local consistency assumption: examples close to labeled examples within the same class will have the samelabels.
</nextsent>
<nextsent>such methods ignore considering the similarity between unlabeled examples and do not perform classification from global consistency viewpoint, which may fail to exploit appropriate manifold structure in data when training data is limited.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1794">
<title id=" N06-2007.xml">semi supervised relation extraction with label propagation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation on the ace corpus showed when only few labeled examples are available, our lp based relation extraction can achieve better performance than svm and another bootstrapping method.
</prevsent>
<prevsent>relation extraction is the task of finding relationships between two entities from text.
</prevsent>
</prevsection>
<citsent citstr=" W02-1010 ">
for the task,many machine learning methods have been proposed, including supervised methods (miller et al, 2000; <papid> A00-2030 </papid>zelenko et al, 2002; <papid> W02-1010 </papid>culotta and soresen,2004; kambhatla, 2004; <papid> P04-3022 </papid>zhou et al, 2005), semi supervised methods (brin, 1998; agichtein and gravano, 2000; zhang, 2004), and unsupervised method (hasegawa et al, 2004).<papid> P04-1053 </papid>supervised relation extraction achieves good performance, but it requires large amount of manually labeled relation instances.</citsent>
<aftsection>
<nextsent>unsupervised methods do not need the definition of relation types and manually labeled data, but it is difficult to evaluate the clustering result since there is no relation type label for each instance in clusters.
</nextsent>
<nextsent>therefore, semi supervised learning has received attention, which can minimize corpus annotation requirement.
</nextsent>
<nextsent>current works on semi-supervised resolution for relation extraction task mostly use the bootstrapping algorithm, which is based on local consistency assumption: examples close to labeled examples within the same class will have the samelabels.
</nextsent>
<nextsent>such methods ignore considering the similarity between unlabeled examples and do not perform classification from global consistency viewpoint, which may fail to exploit appropriate manifold structure in data when training data is limited.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1795">
<title id=" N06-2007.xml">semi supervised relation extraction with label propagation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation on the ace corpus showed when only few labeled examples are available, our lp based relation extraction can achieve better performance than svm and another bootstrapping method.
</prevsent>
<prevsent>relation extraction is the task of finding relationships between two entities from text.
</prevsent>
</prevsection>
<citsent citstr=" P04-3022 ">
for the task,many machine learning methods have been proposed, including supervised methods (miller et al, 2000; <papid> A00-2030 </papid>zelenko et al, 2002; <papid> W02-1010 </papid>culotta and soresen,2004; kambhatla, 2004; <papid> P04-3022 </papid>zhou et al, 2005), semi supervised methods (brin, 1998; agichtein and gravano, 2000; zhang, 2004), and unsupervised method (hasegawa et al, 2004).<papid> P04-1053 </papid>supervised relation extraction achieves good performance, but it requires large amount of manually labeled relation instances.</citsent>
<aftsection>
<nextsent>unsupervised methods do not need the definition of relation types and manually labeled data, but it is difficult to evaluate the clustering result since there is no relation type label for each instance in clusters.
</nextsent>
<nextsent>therefore, semi supervised learning has received attention, which can minimize corpus annotation requirement.
</nextsent>
<nextsent>current works on semi-supervised resolution for relation extraction task mostly use the bootstrapping algorithm, which is based on local consistency assumption: examples close to labeled examples within the same class will have the samelabels.
</nextsent>
<nextsent>such methods ignore considering the similarity between unlabeled examples and do not perform classification from global consistency viewpoint, which may fail to exploit appropriate manifold structure in data when training data is limited.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1796">
<title id=" N06-2007.xml">semi supervised relation extraction with label propagation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation on the ace corpus showed when only few labeled examples are available, our lp based relation extraction can achieve better performance than svm and another bootstrapping method.
</prevsent>
<prevsent>relation extraction is the task of finding relationships between two entities from text.
</prevsent>
</prevsection>
<citsent citstr=" P04-1053 ">
for the task,many machine learning methods have been proposed, including supervised methods (miller et al, 2000; <papid> A00-2030 </papid>zelenko et al, 2002; <papid> W02-1010 </papid>culotta and soresen,2004; kambhatla, 2004; <papid> P04-3022 </papid>zhou et al, 2005), semi supervised methods (brin, 1998; agichtein and gravano, 2000; zhang, 2004), and unsupervised method (hasegawa et al, 2004).<papid> P04-1053 </papid>supervised relation extraction achieves good performance, but it requires large amount of manually labeled relation instances.</citsent>
<aftsection>
<nextsent>unsupervised methods do not need the definition of relation types and manually labeled data, but it is difficult to evaluate the clustering result since there is no relation type label for each instance in clusters.
</nextsent>
<nextsent>therefore, semi supervised learning has received attention, which can minimize corpus annotation requirement.
</nextsent>
<nextsent>current works on semi-supervised resolution for relation extraction task mostly use the bootstrapping algorithm, which is based on local consistency assumption: examples close to labeled examples within the same class will have the samelabels.
</nextsent>
<nextsent>such methods ignore considering the similarity between unlabeled examples and do not perform classification from global consistency viewpoint, which may fail to exploit appropriate manifold structure in data when training data is limited.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1797">
<title id=" N06-4001.xml">info magnets making sense of corpus data </title>
<section> an example of use.  </section>
<citcontext>
<prevsection>
<prevsent>using info magnets, the domain expert identified 15 distinct topics such that each student covered between 4 and 11 of these topics either once or multiple times throughout their interaction.
</prevsent>
<prevsent>the topic analysis of the corpus gives us way of quickly getting sense of how tutors divided their instructional time between different topics of conversation.
</prevsent>
</prevsection>
<citsent citstr=" W05-0208 ">
based on this topic analysis of the human-tutoring corpus, the domain expert designed 12 dialogues, which were then implemented using dialogue authoring environment called tutalk (gweon et al, 2005).<papid> W05-0208 </papid></citsent>
<aftsection>
<nextsent>in recent very successful classroom evaluation, we observed the instructional effectiveness of these implemented tutorial dialogue agents, as measured by pre and post tests.
</nextsent>
<nextsent>acknowledgments this work was funded by office of naval research, cognitive and neural science division, grant number n00014-05-1-0043.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1798">
<title id=" N04-1029.xml">comparison of two interactive search refinement techniques </title>
<section> query expansion method 2.  </section>
<citcontext>
<prevsection>
<prevsent>(6) we take top 25 documents from the baseline run, and select 2 sentences per document using the algorithm described above.
</prevsent>
<prevsent>we have not experimented with alternative values for these two parameters.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
we then apply brills rule-based tagger (brill 1995) <papid> J95-4004 </papid>and basenp noun phrase chunker (ramshaw and marcus 1995) <papid> W95-0107 </papid>to extract noun phrases from these sentences.</citsent>
<aftsection>
<nextsent>the phrases are then parsed in okapi to obtain their term weights, removing all stop words and phrases consisting entirely of the original query terms.
</nextsent>
<nextsent>the remaining phrases are ranked by the sum of weights of their constituent terms.
</nextsent>
<nextsent>top 78 phrases are then included in the clarification form for the user to select.
</nextsent>
<nextsent>this is the maximum number of phrases that could fit into the clarification form.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1799">
<title id=" N04-1029.xml">comparison of two interactive search refinement techniques </title>
<section> query expansion method 2.  </section>
<citcontext>
<prevsection>
<prevsent>(6) we take top 25 documents from the baseline run, and select 2 sentences per document using the algorithm described above.
</prevsent>
<prevsent>we have not experimented with alternative values for these two parameters.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
we then apply brills rule-based tagger (brill 1995) <papid> J95-4004 </papid>and basenp noun phrase chunker (ramshaw and marcus 1995) <papid> W95-0107 </papid>to extract noun phrases from these sentences.</citsent>
<aftsection>
<nextsent>the phrases are then parsed in okapi to obtain their term weights, removing all stop words and phrases consisting entirely of the original query terms.
</nextsent>
<nextsent>the remaining phrases are ranked by the sum of weights of their constituent terms.
</nextsent>
<nextsent>top 78 phrases are then included in the clarification form for the user to select.
</nextsent>
<nextsent>this is the maximum number of phrases that could fit into the clarification form.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1800">
<title id=" N06-2031.xml">computational modelling of structural priming in dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the statistical analysis in this paper aims to make headway towards such model.recently, priming phenomena1 have been exploited to aid automated processing, for instance in automatic speech recognition using cache models, but only recently have attempts been made at using1the term priming refers to process that influences linguistic decision-making.
</prevsent>
<prevsent>an instance of priming occurs when syntactic structure or lexical item giving evidence of linguistic choice (prime) influences the recipient to make the same decision, i.e. re-use the structure, at later choice-point (target).
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
them in parsing (charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>in natural language generation, repetition can be used to increase the alignment of human and computers.
</nextsent>
<nextsent>a surface-level approach is possible by biasing the n-gram language model used to select the output string from variety of possible utterances (brock mann et al, 2005).
</nextsent>
<nextsent>priming effects are common and well known.
</nextsent>
<nextsent>for instance, speakers access lexical items more quickly after semantically or phonologically similar prime.recent work demonstrates large effects for particular synonymous alternations (e.g., active vs. passive voice) using traditional laboratory experiments with human subjects (bock, 1986; branigan et al, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1801">
<title id=" N06-2031.xml">computational modelling of structural priming in dialogue </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 dialogue types.
</prevsent>
<prevsent>we examined two corpora.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
switchboard contains 80,000 utterances of spontaneous spoken conversations over the telephone among randomly paired, north american speakers, syntactically annotated with phrase-structure grammar (marcus et al, 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>the hcrc map task corpus comprises more than 110 dialogues with total of 20, 400 utterances (anderson et al, 1991).
</nextsent>
<nextsent>like switchboard, hcrc map task is corpus of spoken, two-person dialogue in english.
</nextsent>
<nextsent>however, map task contains task-oriented dialogue: interlocutors work together to achieve task as quickly and efficiently as possible.
</nextsent>
<nextsent>subjects were asked to give each other directions with the help of map.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1802">
<title id=" N04-4003.xml">example based rescoring of statistical machine translation output </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given such validation filter, defective translations canbe rejected.
</prevsent>
<prevsent>the experiments show drastic improvement in the overall system performance compared to translation selection methods based on statistical scores only.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the statistical machine translation framework (smt) formulates the problem of translating sentence from asource language into target language as the maximization problem of the conditional probability: tmlm = argmaxt p(s|t ) ? p(t ), (1)where p(s|t ) is called translation model (tm ), representing the generation probability from into s, p(t )is called language model (lm ) and represents the likelihood of the target language (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>the tm and lm probabilities are trained automatically froma parallel text corpus (parameter estimation).
</nextsent>
<nextsent>they represent the general translation knowledge used to map asequence of words from the source language into the target language.
</nextsent>
<nextsent>during the translation process (decoding) astatistical score based on the probabilities of the translation and the language models is assigned to each translation candidate and the one with the highest tmlm score is selected as the translation output.
</nextsent>
<nextsent>however, the system might not be able to find good translation due to parameter estimation problems of the statistical models (due to data sparseness during the estimation of the model probabilities) and search errors1the research reported here was supported in part by contract with the telecommunications advancement organization of japan entitled, study of speech dialogue translation technology based on large corpus?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1803">
<title id=" N04-4003.xml">example based rescoring of statistical machine translation output </title>
<section> statistical decoding.  </section>
<citcontext>
<prevsection>
<prevsent>another possibility for obtaining translation examples is simply to utilize available (off-the-shelf) mt systems by pairing the input sentence with the obtained mt out put.
</prevsent>
<prevsent>however, the quality of those translation examples might be much lower than manually created translations.
</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
(germann et al, 2001) <papid> P01-1030 </papid>presents greedy approach to search for the translation that is most likely according to previously learned statitistical models.</citsent>
<aftsection>
<nextsent>an extension ofthis approach that can take advantage of translation examples provided forgiven input sentence is proposed in (watanabe and sumita, 2003).
</nextsent>
<nextsent>instead of decoding and generating an output string word-by-word as is done in the basic concept, this greedy approach slightly modifies the target part of the translation examples so that the pair becomes the actual translation.
</nextsent>
<nextsent>the advantage of the example-based approach is that the search for good translation starts from the retrieved translation example, not guessed translation resulting in fewer search errors.
</nextsent>
<nextsent>however, since it uses the same greedy search algorithm as the basic method, search errors cannot be avoided completely.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1804">
<title id=" N04-4003.xml">example based rescoring of statistical machine translation output </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the experiments described below were carried out on 510 sentences selected randomly as the test set.
</prevsent>
<prevsent>for the evaluation, we used the following automatic scoring measures and human assessment.?
</prevsent>
</prevsection>
<citsent citstr=" C92-2067 ">
word error rate (wer), which penalizes the edit distance against reference translations (su et al, 1992) ? <papid> C92-2067 </papid>bleu: the geometric mean of n-gram precision for the translation results found in reference translations (papineni et al, 2002) ? <papid> P02-1040 </papid>translation accuracy (acc): subjective evaluation ranks ranging from to (a: perfect, b: fair, c: acceptable and d: nonsense), judged blindly by native speaker (sumita et al, 1999) in contrast tower, higher bleu and acc scores indicate better translations.</citsent>
<aftsection>
<nextsent>for the automatic scoring measures we utilized up to 16 human reference translations.
</nextsent>
<nextsent>5.1 downgrading effects during decoding.
</nextsent>
<nextsent>in order to get an idea about how much degradation is to be expected in the translation candidates modified bythe statistical decoder, we conducted an experiment using the reference translations of the test set as the input ofthe example-based decoder.
</nextsent>
<nextsent>these seed sentences areal ready accurate translations, thus simulating the optimal?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1805">
<title id=" N04-4003.xml">example based rescoring of statistical machine translation output </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the experiments described below were carried out on 510 sentences selected randomly as the test set.
</prevsent>
<prevsent>for the evaluation, we used the following automatic scoring measures and human assessment.?
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
word error rate (wer), which penalizes the edit distance against reference translations (su et al, 1992) ? <papid> C92-2067 </papid>bleu: the geometric mean of n-gram precision for the translation results found in reference translations (papineni et al, 2002) ? <papid> P02-1040 </papid>translation accuracy (acc): subjective evaluation ranks ranging from to (a: perfect, b: fair, c: acceptable and d: nonsense), judged blindly by native speaker (sumita et al, 1999) in contrast tower, higher bleu and acc scores indicate better translations.</citsent>
<aftsection>
<nextsent>for the automatic scoring measures we utilized up to 16 human reference translations.
</nextsent>
<nextsent>5.1 downgrading effects during decoding.
</nextsent>
<nextsent>in order to get an idea about how much degradation is to be expected in the translation candidates modified bythe statistical decoder, we conducted an experiment using the reference translations of the test set as the input ofthe example-based decoder.
</nextsent>
<nextsent>these seed sentences areal ready accurate translations, thus simulating the optimal?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1806">
<title id=" N07-1047.xml">applying manytomany alignments and hidden markov models to lettertophoneme conversion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are always exceptional rules that need to be added to cover alarge vocabulary set.
</prevsent>
<prevsent>thus, an automatic l2p system is desirable.
</prevsent>
</prevsection>
<citsent citstr=" J00-2003 ">
many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including pronunciation by analogy (marchand and damper, 2000), <papid> J00-2003 </papid>constraint satisfaction (van den bosch and canisius, 2006), hidden markov model (taylor, 2005), decision trees (black et al, 1998), and neural networks (sejnowski and rosenberg, 1987).</citsent>
<aftsection>
<nextsent>the training data usually consists of written words and their corresponding phonemes, which are not aligned; there is no explicit information indicating individual letter and phoneme relationships.
</nextsent>
<nextsent>these relationships must be postulated before prediction model can be trained.
</nextsent>
<nextsent>previous work has generally assumed one-to-one alignment for simplicity (daelemans and bosch, 1997; black et al, 1998; damper et al, 2005).an expectation maximization (em) based algorithm (dempster et al, 1977) is applied to train the aligners.
</nextsent>
<nextsent>however, there are several problems with this approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1808">
<title id=" N06-2025.xml">syntactic kernels for natural language learning the semantic role labeling case </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiments with svms on the task of predicate argument classification provide empirical data that validates our methods.
</prevsent>
<prevsent>recently, several tree kernels have been applied to natural language learning, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
(collins and duffy, 2002; <papid> P02-1034 </papid>zelenko et al, 2003; cumby and roth, 2003;culotta and sorensen, 2004; <papid> P04-1054 </papid>moschitti, 2004).<papid> P04-1043 </papid></citsent>
<aftsection>
<nextsent>despite their promising results, three general objections against kernel methods are raised: (1) only subset of the dual space features are relevant, thus, it may be possible to design features in the primal space that produce the same accuracy with faster computation time; (2) in some cases the high number of features (substructures) of the dual space can produce over fitting with consequent accuracy decrease (cumby and roth, 2003); and (3) the computation time of kernel functions may be too high and prevent their application in real scenarios.in this paper, we study the impact of the sub tree (st) (vishwanathan and smola, 2002), subset tree (sst) (collins and duffy, 2002) <papid> P02-1034 </papid>and partial tree (pt) kernels on semantic role labeling (srl).</nextsent>
<nextsent>the pt kernel is new function that we have designed to generate larger substructure spaces.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1810">
<title id=" N06-2025.xml">syntactic kernels for natural language learning the semantic role labeling case </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiments with svms on the task of predicate argument classification provide empirical data that validates our methods.
</prevsent>
<prevsent>recently, several tree kernels have been applied to natural language learning, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
(collins and duffy, 2002; <papid> P02-1034 </papid>zelenko et al, 2003; cumby and roth, 2003;culotta and sorensen, 2004; <papid> P04-1054 </papid>moschitti, 2004).<papid> P04-1043 </papid></citsent>
<aftsection>
<nextsent>despite their promising results, three general objections against kernel methods are raised: (1) only subset of the dual space features are relevant, thus, it may be possible to design features in the primal space that produce the same accuracy with faster computation time; (2) in some cases the high number of features (substructures) of the dual space can produce over fitting with consequent accuracy decrease (cumby and roth, 2003); and (3) the computation time of kernel functions may be too high and prevent their application in real scenarios.in this paper, we study the impact of the sub tree (st) (vishwanathan and smola, 2002), subset tree (sst) (collins and duffy, 2002) <papid> P02-1034 </papid>and partial tree (pt) kernels on semantic role labeling (srl).</nextsent>
<nextsent>the pt kernel is new function that we have designed to generate larger substructure spaces.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1812">
<title id=" N06-2025.xml">syntactic kernels for natural language learning the semantic role labeling case </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiments with svms on the task of predicate argument classification provide empirical data that validates our methods.
</prevsent>
<prevsent>recently, several tree kernels have been applied to natural language learning, e.g.
</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
(collins and duffy, 2002; <papid> P02-1034 </papid>zelenko et al, 2003; cumby and roth, 2003;culotta and sorensen, 2004; <papid> P04-1054 </papid>moschitti, 2004).<papid> P04-1043 </papid></citsent>
<aftsection>
<nextsent>despite their promising results, three general objections against kernel methods are raised: (1) only subset of the dual space features are relevant, thus, it may be possible to design features in the primal space that produce the same accuracy with faster computation time; (2) in some cases the high number of features (substructures) of the dual space can produce over fitting with consequent accuracy decrease (cumby and roth, 2003); and (3) the computation time of kernel functions may be too high and prevent their application in real scenarios.in this paper, we study the impact of the sub tree (st) (vishwanathan and smola, 2002), subset tree (sst) (collins and duffy, 2002) <papid> P02-1034 </papid>and partial tree (pt) kernels on semantic role labeling (srl).</nextsent>
<nextsent>the pt kernel is new function that we have designed to generate larger substructure spaces.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1818">
<title id=" N06-2025.xml">syntactic kernels for natural language learning the semantic role labeling case </title>
<section> fast tree kernel functions.  </section>
<citcontext>
<prevsection>
<prevsent>to efficiently build np, we (i) extract the l1 and l2 lists of nodes from t1 and t2, (ii) sort them in alphanumeric order and (iii) scan them to find np.
</prevsent>
<prevsent>step (iii) may require only o(|nt1 |+ |nt2 |) time, but,if label(n1) appears r1 times in t1 and label(n2) is repeated r2 times in t2, we need to consider r1 ? r2 pairs.
</prevsent>
</prevsection>
<citsent citstr=" E06-1015 ">
the formal can be found in (moschitti, 2006).<papid> E06-1015 </papid></citsent>
<aftsection>
<nextsent>in these experiments, we study tree kernel performance in terms of average running time and accuracy on the classification of predicate arguments.
</nextsent>
<nextsent>asshown in (moschitti, 2004), <papid> P04-1043 </papid>we can label semantic roles by classifying the smallest subtree that includes the predicate with one of its arguments, i.e. the so called paf structure.</nextsent>
<nextsent>the experiments were carried out with the svm-light-tk software available at http://ai-nlp.info.uniroma2.it/moschitti/ which encodes the fast tree kernels in the svm-light software (joachims, 1999).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1820">
<title id=" N06-2025.xml">syntactic kernels for natural language learning the semantic role labeling case </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>second ftk-sst naive-sstftk-pt figure 4: average time in seconds for the nave sst kernel, ftk-sst and ftk-pt evaluations.
</prevsent>
<prevsent>4.2 experiments on srl dataset.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we used two different corpora: propbank (www.cis.upenn.edu/ace) along with penn treebank 2 (marcus et al, 1993) <papid> J93-2004 </papid>and framenet.</citsent>
<aftsection>
<nextsent>propbank contains about 53,700 sentences and fixed split between training and testing used in other researches.
</nextsent>
<nextsent>in this split, sections from 02 to 21 are used for training, section 23 for testing and section 22 as development set.
</nextsent>
<nextsent>we considered total of 122,774 and 7,359 arguments (from arg0 to arg5, arga and argm) in training and testing, respectively.
</nextsent>
<nextsent>the tree structures were extracted from the penn treebank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1821">
<title id=" N06-2025.xml">syntactic kernels for natural language learning the semantic role labeling case </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we considered the 18 most frequent roles, for total of 37,948 examples (30% of the sentences for testing and 70% for training/validation).
</prevsent>
<prevsent>the sentences were processed with the collins?
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
parser (collins, 1997) <papid> P97-1003 </papid>to generate automatic parse trees.</citsent>
<aftsection>
<nextsent>we run st, sst and pt kernels along with the linear kernel of standard features (carreras andma`rquez, 2005) on propbank training sets of different size.
</nextsent>
<nextsent>figure 5 illustrates the learning curves associated with the above kernels for the svm mul ticlassifiers.
</nextsent>
<nextsent>the tables 1 and 2 report the results, using all available training data, on propbank and framenet test sets, respectively.
</nextsent>
<nextsent>we note that: (1) the accuracy of pts is almost equal to the one produced by ssts as the pt space is hyper set of ssts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1822">
<title id=" N06-2025.xml">syntactic kernels for natural language learning the semantic role labeling case </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, the learning time of svms using ftk for the classification of one large argument (arg 0)is much lower than the one required by nave algorithm.
</prevsent>
<prevsent>with all the training data ftk terminated in 6 hours whereas the nave approach required more than 1 week.
</prevsent>
</prevsection>
<citsent citstr=" P03-1004 ">
however, the complexity burden of working in the dual space can be alleviated with recent approaches proposed in (kudo and matsumoto, 2003; <papid> P03-1004 </papid>suzuki et al, 2004).<papid> P04-1016 </papid></citsent>
<aftsection>
<nextsent>finally, we carried out some experiments with the combination between linear and tree kernels and we found that tree kernels improve the models based on manually designed features by 2/3 percent points,thus they can be seen as useful tactic to boost system accuracy.
</nextsent>
<nextsent>args linear st sst pt acc.
</nextsent>
<nextsent>87.6 84.6 87.7 86.7 table 1: evaluation of kernels on propbank data and gold parse trees.
</nextsent>
<nextsent>roles linear st sst pt acc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1823">
<title id=" N06-2025.xml">syntactic kernels for natural language learning the semantic role labeling case </title>
<section> the experiments.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, the learning time of svms using ftk for the classification of one large argument (arg 0)is much lower than the one required by nave algorithm.
</prevsent>
<prevsent>with all the training data ftk terminated in 6 hours whereas the nave approach required more than 1 week.
</prevsent>
</prevsection>
<citsent citstr=" P04-1016 ">
however, the complexity burden of working in the dual space can be alleviated with recent approaches proposed in (kudo and matsumoto, 2003; <papid> P03-1004 </papid>suzuki et al, 2004).<papid> P04-1016 </papid></citsent>
<aftsection>
<nextsent>finally, we carried out some experiments with the combination between linear and tree kernels and we found that tree kernels improve the models based on manually designed features by 2/3 percent points,thus they can be seen as useful tactic to boost system accuracy.
</nextsent>
<nextsent>args linear st sst pt acc.
</nextsent>
<nextsent>87.6 84.6 87.7 86.7 table 1: evaluation of kernels on propbank data and gold parse trees.
</nextsent>
<nextsent>roles linear st sst pt acc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1824">
<title id=" N03-1005.xml">automatic acquisition of names using speak and spell mode in spoken dialogue systems </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in (meng et al, 1996), hierarchical approach was used for bi-directional sound-letter generation.
</prevsent>
<prevsent>on the brown corpus, it achieves word accuracies of 65% forspelling-to-pronunciation and 51% for pronunciation-tospelling.
</prevsent>
</prevsection>
<citsent citstr=" J96-3003 ">
rentzepopoulos (rentzepopoulos and kokkinakis, 1996) <papid> J96-3003 </papid>describes hidden markov model approach for phoneme-to-grapheme conversion, in seven european languages on number of corpora.</citsent>
<aftsection>
<nextsent>the algorithm gave high accuracies when applied to correctly transcribed words but was not applied to real recognition output.
</nextsent>
<nextsent>the work of marchand and damper (marchand and damper, 2000) <papid> J00-2003 </papid>addresses both phoneme-to grapheme and grapheme-to-phoneme conversion using fusion of data-driven and pronunciation-by-analogy methods, obtaining word accuracies of 57.7% and 69.1%for phoneme-to-grapheme and grapheme-to-phoneme experiments respectively.</nextsent>
<nextsent>these were performed on corpus of words from general dictionary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1825">
<title id=" N03-1005.xml">automatic acquisition of names using speak and spell mode in spoken dialogue systems </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>rentzepopoulos (rentzepopoulos and kokkinakis, 1996) <papid> J96-3003 </papid>describes hidden markov model approach for phoneme-to-grapheme conversion, in seven european languages on number of corpora.</prevsent>
<prevsent>the algorithm gave high accuracies when applied to correctly transcribed words but was not applied to real recognition output.</prevsent>
</prevsection>
<citsent citstr=" J00-2003 ">
the work of marchand and damper (marchand and damper, 2000) <papid> J00-2003 </papid>addresses both phoneme-to grapheme and grapheme-to-phoneme conversion using fusion of data-driven and pronunciation-by-analogy methods, obtaining word accuracies of 57.7% and 69.1%for phoneme-to-grapheme and grapheme-to-phoneme experiments respectively.</citsent>
<aftsection>
<nextsent>these were performed on corpus of words from general dictionary.
</nextsent>
<nextsent>some work has focused on proper names, since names are particularly challenging open set.
</nextsent>
<nextsent>in (ngan et al., 1998), the problem of generating pronunciations for proper names is addressed.
</nextsent>
<nextsent>a 45.5% word error rate is reported on set of around 4500 names using decision tree method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1826">
<title id=" N07-1002.xml">to memorize or to predict prominence labeling in conversational speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>being able to predict the prominence or pitch accent status of word in conversational speech is important for implementing text-to-speech in dialog systems, as well as in detection of prosody in conversational speech recognition.
</prevsent>
<prevsent>previous investigations of prominence prediction from text have primarily relied on robust surface features with some deeper information structure features.
</prevsent>
</prevsection>
<citsent citstr=" W99-0619 ">
surface features like words part-of-speech(pos) (hirschberg, 1993) and its unigram and bigram probability (pan and mckeown, 1999; <papid> W99-0619 </papid>pan and 0thanks to the edinburgh-stanford link and onr (muri award n000140510388) for generous support.</citsent>
<aftsection>
<nextsent>hirschberg, 2000) are quite useful; content words are much more likely to be accented than function words, and words with higher probability are less likely to be prominent.
</nextsent>
<nextsent>more sophisticated linguistic features have also been used, generally based on information-structural notions of contrast, focus, or given-new.
</nextsent>
<nextsent>(hirschberg, 1993).for example, in the switchboard utterance be low, there is an intrinsic contrast between the words women?
</nextsent>
<nextsent>and men?, making both terms more salient (words in all capital letters represent prominent tokens): you see womenc going off to wars as well as menc.similarly the givenness of word may help determine its prominence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1827">
<title id=" N07-1002.xml">to memorize or to predict prominence labeling in conversational speech </title>
<section> data and features.  </section>
<citcontext>
<prevsection>
<prevsent>9
</prevsent>
<prevsent>for our experiments we use 12 switchboard (godfrey et al, 1992) conversations, 14,555 tokens in total.
</prevsent>
</prevsection>
<citsent citstr=" W05-0307 ">
each word was manually labeled for presence or absence of pitch accent1 , as well as additional features including information status (or givenness), contrast and animacy distinctions, (nissim et al,2004; calhoun et al, 2005; <papid> W05-0307 </papid>zaenen et al, 2004), <papid> W04-0216 </papid>features that linguistic literature suggests are predictive of prominence (bolinger, 1961; chafe, 1976).</citsent>
<aftsection>
<nextsent>all of the features described in detail below have been shown to have statistically significant correlation with prominence (brenier et al, 2006).
</nextsent>
<nextsent>information status the information status (is), or givenness, of discourse entities is important for choosing appropriate reference form (prince, 1992; gundel et al, 1993) and possibly plays role in prominence decisions as well (brown, 1983).
</nextsent>
<nextsent>no previous studies have examined the usefulness of information status in naturally occurring conversational speech.
</nextsent>
<nextsent>the annotation in our corpus is based on the givenness hierarchy of prince: first mentions of entities were marked as new and subsequent mentions as old.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1828">
<title id=" N07-1002.xml">to memorize or to predict prominence labeling in conversational speech </title>
<section> data and features.  </section>
<citcontext>
<prevsection>
<prevsent>9
</prevsent>
<prevsent>for our experiments we use 12 switchboard (godfrey et al, 1992) conversations, 14,555 tokens in total.
</prevsent>
</prevsection>
<citsent citstr=" W04-0216 ">
each word was manually labeled for presence or absence of pitch accent1 , as well as additional features including information status (or givenness), contrast and animacy distinctions, (nissim et al,2004; calhoun et al, 2005; <papid> W05-0307 </papid>zaenen et al, 2004), <papid> W04-0216 </papid>features that linguistic literature suggests are predictive of prominence (bolinger, 1961; chafe, 1976).</citsent>
<aftsection>
<nextsent>all of the features described in detail below have been shown to have statistically significant correlation with prominence (brenier et al, 2006).
</nextsent>
<nextsent>information status the information status (is), or givenness, of discourse entities is important for choosing appropriate reference form (prince, 1992; gundel et al, 1993) and possibly plays role in prominence decisions as well (brown, 1983).
</nextsent>
<nextsent>no previous studies have examined the usefulness of information status in naturally occurring conversational speech.
</nextsent>
<nextsent>the annotation in our corpus is based on the givenness hierarchy of prince: first mentions of entities were marked as new and subsequent mentions as old.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1831">
<title id=" N07-1002.xml">to memorize or to predict prominence labeling in conversational speech </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>all the results that we report are from 10-fold cross-validation on the 12 switchboard conversations.
</prevsent>
<prevsent>some previous studies have reported results on prominence prediction in conversational speech with the switchboard corpus.
</prevsent>
</prevsection>
<citsent citstr=" P04-1086 ">
unfortunately these studies used different parts of the corpus or different label ings (gregory and altun, 2004; <papid> P04-1086 </papid>yuan et al, 2005),so our results are not directly comparable.</citsent>
<aftsection>
<nextsent>bearing this difference in mind, the best reported results to our knowledge are those in (gregory and altun, 2004), <papid> P04-1086 </papid>where conditional random fields were used with both textual, acoustic, and oracle boundary features to yield 76.36% accuracy.</nextsent>
<nextsent>table 1 shows the performance of decision tree classifiers using single feature.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1833">
<title id=" N07-1002.xml">to memorize or to predict prominence labeling in conversational speech </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, the feature is robust to genre, and accent ratio dictionaries can be used for prediction of prominence in read news with very good results.
</prevsent>
<prevsent>of the linguistic features we examined, kontrast is the only one that is helpful beyond what can be gained using shallow features such as n-gram probability, pos or tf.idf.
</prevsent>
</prevsection>
<citsent citstr=" W06-1612 ">
while the improvements from kontrast are relatively small, the consistency of these small improvements suggest that developing automatic methods for approximating the gold-standard annotation we used here, similar to what has been done for information status in (nissim, 2006), <papid> W06-1612 </papid>may be worthwhile.</citsent>
<aftsection>
<nextsent>an automatic predictor for kontrast may also be helpful in other applications such as question answering or textual entailment.
</nextsent>
<nextsent>all of the features in our study were text-based.
</nextsent>
<nextsent>there is wide variety of research investigating phonological or acoustic features as well.
</nextsent>
<nextsent>for example gregory and altun (2004) <papid> P04-1086 </papid>used acoustic features 3this result is comparable with the result of (yuan et al, 2005) who in their experiment with the same corpus report the best result as 83.9% using three features: unigram, bigram and backwards bigram probability.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1835">
<title id=" N06-1049.xml">will pyramids built of nuggets topple over </title>
<section> evaluation of complex questions.  </section>
<citcontext>
<prevsection>
<prevsent>worth of defini tion/other?
</prevsent>
<prevsent>questions.
</prevsent>
</prevsection>
<citsent citstr=" N04-1007 ">
the nugget-based paradigm has been previously detailed in number of papers (voorhees, 2003; hildebrandt et al, 2004; <papid> N04-1007 </papid>lin and demner-fushman, 2005a); here, we present only short summary.</citsent>
<aftsection>
<nextsent>system responses to complex questions consist of an unordered set of passages.
</nextsent>
<nextsent>to evaluate answers,nist pools answer strings from all participants, removes their association with the runs that produced them, and presents them to human assessor.
</nextsent>
<nextsent>using these responses and research performed during the original development of the question, the assessor creates an answer key?
</nextsent>
<nextsent>comprised of list ofnuggetsessentially, facts about the target.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1839">
<title id=" N06-1049.xml">will pyramids built of nuggets topple over </title>
<section> whats vital? whats okay?.  </section>
<citcontext>
<prevsection>
<prevsent>than another even though they may be very different inother salient properties such as length, for example.
</prevsent>
<prevsent>the discriminative power of the present f-score measure is called into question: are present systems that bad, or is the current scoring model insufficient to discriminate between different (poorly perform ing) systems?
</prevsent>
</prevsection>
<citsent citstr=" H05-1038 ">
also, as pointed out by voorhees (2005), <papid> H05-1038 </papid>score distribution heavily skewed towards zero makesmeta-analysis of evaluation stability hard to per form.</citsent>
<aftsection>
<nextsent>since such studies depend on variability in scores, evaluations would appear more stable than they really are.
</nextsent>
<nextsent>while there are obviously shortcomings to the current scheme of labeling nuggets as either vital?
</nextsent>
<nextsent>or okay?, the distinction does start to capture the intuition that not all nuggets are created equal?.
</nextsent>
<nextsent>some nuggets are inherently more important than others, and this should be reflected in the evaluation methodology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1840">
<title id=" N06-1049.xml">will pyramids built of nuggets topple over </title>
<section> building nugget pyramids.  </section>
<citcontext>
<prevsection>
<prevsent>however, given finite resources, it is important to balance the amount of additional manual effort required with the gains derived from those efforts.
</prevsent>
<prevsent>we present the idea of building nugget pyramids?, which addresses the shortcomings noted here, and then assess the implications of this new scoring model against data from trec 2003, 2004, and 2005.
</prevsent>
</prevsection>
<citsent citstr=" W05-0906 ">
as previously pointed out (lin and demnerfushman, 2005<papid> W05-0906 </papid>b), the question answering and summarization communities are converging on the taskof addressing complex information needs from complementary perspectives; see, for example, there cent duc task of query-focused multi-document summarization (amigo?</citsent>
<aftsection>
<nextsent>et al, 2004; dang, 2005).from an evaluation point of view, this provides opportunities for cross-fertilization and exchange offresh ideas.
</nextsent>
<nextsent>as an example of this intellectual discourse, the recently-developed pourpre metric for automatically evaluating answers to complex questions (lin and demner-fushman, 2005a) employsn-gram overlap to compare system responses to reference output, an idea originally implemented in the rouge metric for summarization evaluation (lin and hovy, 2003).<papid> N03-1020 </papid></nextsent>
<nextsent>drawing additional inspiration from research on summarization evaluation, we adapt the pyramid evaluation scheme (nenkova and passonneau, 2004) <papid> N04-1019 </papid>to address the shortcomings of 385the vital/okay distinction in the nugget-based evaluation methodology.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1842">
<title id=" N06-1049.xml">will pyramids built of nuggets topple over </title>
<section> building nugget pyramids.  </section>
<citcontext>
<prevsection>
<prevsent>as previously pointed out (lin and demnerfushman, 2005<papid> W05-0906 </papid>b), the question answering and summarization communities are converging on the taskof addressing complex information needs from complementary perspectives; see, for example, there cent duc task of query-focused multi-document summarization (amigo?</prevsent>
<prevsent>et al, 2004; dang, 2005).from an evaluation point of view, this provides opportunities for cross-fertilization and exchange offresh ideas.</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
as an example of this intellectual discourse, the recently-developed pourpre metric for automatically evaluating answers to complex questions (lin and demner-fushman, 2005a) employsn-gram overlap to compare system responses to reference output, an idea originally implemented in the rouge metric for summarization evaluation (lin and hovy, 2003).<papid> N03-1020 </papid></citsent>
<aftsection>
<nextsent>drawing additional inspiration from research on summarization evaluation, we adapt the pyramid evaluation scheme (nenkova and passonneau, 2004) <papid> N04-1019 </papid>to address the shortcomings of 385the vital/okay distinction in the nugget-based evaluation methodology.</nextsent>
<nextsent>the basic intuition behind the pyramid scheme (nenkova and passonneau, 2004) <papid> N04-1019 </papid>is simple: the importance of fact is directly related to the number of people that recognize it as such (i.e., its popularity).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1843">
<title id=" N06-1049.xml">will pyramids built of nuggets topple over </title>
<section> building nugget pyramids.  </section>
<citcontext>
<prevsection>
<prevsent>et al, 2004; dang, 2005).from an evaluation point of view, this provides opportunities for cross-fertilization and exchange offresh ideas.
</prevsent>
<prevsent>as an example of this intellectual discourse, the recently-developed pourpre metric for automatically evaluating answers to complex questions (lin and demner-fushman, 2005a) employsn-gram overlap to compare system responses to reference output, an idea originally implemented in the rouge metric for summarization evaluation (lin and hovy, 2003).<papid> N03-1020 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1019 ">
drawing additional inspiration from research on summarization evaluation, we adapt the pyramid evaluation scheme (nenkova and passonneau, 2004) <papid> N04-1019 </papid>to address the shortcomings of 385the vital/okay distinction in the nugget-based evaluation methodology.</citsent>
<aftsection>
<nextsent>the basic intuition behind the pyramid scheme (nenkova and passonneau, 2004) <papid> N04-1019 </papid>is simple: the importance of fact is directly related to the number of people that recognize it as such (i.e., its popularity).</nextsent>
<nextsent>the evaluation methodology calls for assessors to annotate semantic content units (scus) found within model reference sum maries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1848">
<title id=" N06-2030.xml">quantitative methods for classifying writing systems </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>the holy grail in this area would be tool that could classify entirely unknown writing systems to assist in attempts at archaeological decipher ment, but more realistic applications do exist, particularly in the realm of managing on-line document collections in heterogeneous scripts or writing systems.
</prevsent>
<prevsent>no previous work exactly addresses this topic.none of the numerous descriptive accounts that catalogue the worlds writing systems, culminating in daniels and brights (1996) outstanding reference on the subject, count as quantitative.
</prevsent>
</prevsection>
<citsent citstr=" W99-0906 ">
the one computational approach that at least claims to consider archaeological decipher ment (knight and yamada, 1999), <papid> W99-0906 </papid>curiously enough, assumes an alphabetic and purely phonographic mapping of graphemes at the outset, and applies an em-style algorithm to whatis probably better described as an interesting variation on learning the letter-to-sound?</citsent>
<aftsection>
<nextsent>mappings that one normally finds in text analysis for text-to-speech synthesizers.
</nextsent>
<nextsent>the cryptographic work in the great wars of the early 20th century applied statistical reasoning to military communications, although this too is very different in character from deciphering naturally developed writing system.
</nextsent>
<nextsent>type of phonography, as it is expressed in sproatsgrid, is not continuous dimension but discrete choice by graphemes among several different phonographic encodings.
</nextsent>
<nextsent>these characterize not only the size of the phonological chunks?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1849">
<title id=" N07-1032.xml">cross instance tuning of unsupervised document clustering algorithms </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we show how to perform such tuning in the context of unsupervised document clustering, by (i) introducing degree of freedom, ?, into two leading information theoretic clustering algorithms, through the use of generalized mutual information quantities; and (ii) selecting the value of ? based on clusterings of similar, but supervised document collections (cross instance tuning).
</prevsent>
<prevsent>one option is to perform tuning that directly minimizes the error on the supervised data sets; another option is to use strapping?
</prevsent>
</prevsection>
<citsent citstr=" H05-1050 ">
(eisner and karakos, 2005), <papid> H05-1050 </papid>which builds classifier that learns to distinguish good from bad clusterings,and then selects the ? with the best predicted clustering on the test set.</citsent>
<aftsection>
<nextsent>experiments from the 20 newsgroups?
</nextsent>
<nextsent>corpus show that, although both techniques improve the performance of the baseline algorithms, strapping?
</nextsent>
<nextsent>is clearly better choice for cross-instance tuning.
</nextsent>
<nextsent>this work was partially supported by the darpa gale program (contract no ? hr0011-06-2-0001) and by the jhu wse/apl partnership fund.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1852">
<title id=" N07-1032.xml">cross instance tuning of unsupervised document clustering algorithms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this work was partially supported by the darpa gale program (contract no ? hr0011-06-2-0001) and by the jhu wse/apl partnership fund.
</prevsent>
<prevsent>the problem of combining labeled and unlabeled examples in learning task (semi-supervised learn ing) has been studied in the literature under various guises.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
a variety of algorithms (e.g., bootstrapping (yarowsky, 1995), <papid> P95-1026 </papid>co-training (blum and mitchell, 1998), alternating structure optimization (ando and zhang, 2005), etc.) have been developed in order to improve the performance of supervised algorithms, by automatically extracting knowledge from lots of unlabeled examples.</citsent>
<aftsection>
<nextsent>of special interest is the work of ando and zhang (2005), where the goal is to build many supervised auxiliary tasks from the unsupervised data, by creating artificial labels; this procedure helps learn transformation of the input space that captures the relatedness of the auxiliary problems to the task at hand.
</nextsent>
<nextsent>in essence, ando and zhang(2005) transform the semi-supervised learning problem to multi-task learning problem; in multi-task learning, (usually large) set of supervised tasks is available for training, and the goal is to build models which can simultaneously do well on all of them(caruana, 1997; ben-david and schuller, 2003; ev geniou and pontil, 2004).
</nextsent>
<nextsent>little work, however, has been devoted to study the situation where lots of labeled examples, of one kind, are used to build model which is tested on unlabeled data of different?
</nextsent>
<nextsent>kind.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1860">
<title id=" N03-1007.xml">an analysis of clarification dialogue for question answering </title>
<section> clarification dialogues in question.  </section>
<citcontext>
<prevsection>
<prevsent>in order to achieve this (see for example harabagiu et al 2002), systems narrow down the search by using information retrieval techniques to select subset of documents, or paragraphs within documents, containing keywords from the question and concept which corresponds to the correct question type (e.g. question starting with the word who??
</prevsent>
<prevsent>would require an answer containing person).
</prevsent>
</prevsection>
<citsent citstr=" P01-1052 ">
the exact answer sentence is then sought by either attempting to unify the answer semantically with the question, through some kind of logical transformation (e.g. moldovan andrus 2001) <papid> P01-1052 </papid>or by some form of pattern matching (e.g. soubbotin 2002; harabagiu et al 1999).<papid> W99-0501 </papid></citsent>
<aftsection>
<nextsent>often, though, single question is not enough to meet users goals and an elaboration or clarification dialogue is required, i.e. dialogue with the user which would enable the answering system to refine its understanding of the questioner needs (for reasons of space we shall not investigate here the difference between elaboration dialogues, clarification dialogues and coherent topical sub dialogues and we shall hence refer to this type of dialogue simply as clarification dialogue?, noting that this may not be entirely satisfactory from theoretical linguistic point of view).
</nextsent>
<nextsent>while number of researchers have looked at clarification dialogue from theoretical point of view (e.g. ginzburg 1998; ginzburg and sag 2000; van beek at al. 1993), or from the point of view of task oriented dialogue within narrow domain (e.g. ardissono and sestero 1996), we are not aware of any work on clarification dialogue for open domain question answering systems such as the ones presented at the trec workshops, apart from the experiments carried out for the (subsequently abandoned) context?
</nextsent>
<nextsent>task in the trec-10 qa workshop (voorhees 2002; harabagiu et al 2002).
</nextsent>
<nextsent>here we seek to partially address this problem by looking at some particular aspect of clarification dialogues in the context of open domain question answering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1861">
<title id=" N03-1007.xml">an analysis of clarification dialogue for question answering </title>
<section> clarification dialogues in question.  </section>
<citcontext>
<prevsection>
<prevsent>in order to achieve this (see for example harabagiu et al 2002), systems narrow down the search by using information retrieval techniques to select subset of documents, or paragraphs within documents, containing keywords from the question and concept which corresponds to the correct question type (e.g. question starting with the word who??
</prevsent>
<prevsent>would require an answer containing person).
</prevsent>
</prevsection>
<citsent citstr=" W99-0501 ">
the exact answer sentence is then sought by either attempting to unify the answer semantically with the question, through some kind of logical transformation (e.g. moldovan andrus 2001) <papid> P01-1052 </papid>or by some form of pattern matching (e.g. soubbotin 2002; harabagiu et al 1999).<papid> W99-0501 </papid></citsent>
<aftsection>
<nextsent>often, though, single question is not enough to meet users goals and an elaboration or clarification dialogue is required, i.e. dialogue with the user which would enable the answering system to refine its understanding of the questioner needs (for reasons of space we shall not investigate here the difference between elaboration dialogues, clarification dialogues and coherent topical sub dialogues and we shall hence refer to this type of dialogue simply as clarification dialogue?, noting that this may not be entirely satisfactory from theoretical linguistic point of view).
</nextsent>
<nextsent>while number of researchers have looked at clarification dialogue from theoretical point of view (e.g. ginzburg 1998; ginzburg and sag 2000; van beek at al. 1993), or from the point of view of task oriented dialogue within narrow domain (e.g. ardissono and sestero 1996), we are not aware of any work on clarification dialogue for open domain question answering systems such as the ones presented at the trec workshops, apart from the experiments carried out for the (subsequently abandoned) context?
</nextsent>
<nextsent>task in the trec-10 qa workshop (voorhees 2002; harabagiu et al 2002).
</nextsent>
<nextsent>here we seek to partially address this problem by looking at some particular aspect of clarification dialogues in the context of open domain question answering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1862">
<title id=" N04-4030.xml">nearly automated meta data hierarchy creation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, we have found that, for some collections, starting with the assumption that there will be small amount of hand-editing done after the automated processing, combined with bottom-up approach that extracts out those parts of the hypernym hierarchy that are relevant to the collection, and compression algorithm that simplifies the hierarchical structure, we can produce structure that is close to the target goals.below we describe related work, the method for converting wordnet into more usable form, and the results of using the algorithm on test collection.
</prevsent>
<prevsent>there has been surprisingly little work on precisely the problem that we tackle in this paper.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
the literature on automated text categorization is enormous, but assumes that set of categories has already been created, whereas the problem here is to determine the categories of interest.there has also been extensive work on finding synonymous terms and word associations, as well as automatic acquisition of is-a (or genus-head) relations from dictionary definitions and glosses (klavans and whitman, 2001) and from free text (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>sanderson and croft (1999) propose method calledsubsumption for building hierarchy for set of documents retrieved for query.
</nextsent>
<nextsent>for two terms and y, is said to subsume if the following conditions hold:       ff . the evaluation consisted.
</nextsent>
<nextsent>of asking people to define the relation that holds between the pairs of words shown; only 23% of the pairs were found to hold parent-child relation; 49% were found to fall into more general related-to category.
</nextsent>
<nextsent>for set of medical texts, the top level consisted of the terms: disease, post polio, serious disease, dengue, infection control, immunology, etc. this kind of listing is not systematic enough to appear on navigation page for website.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1863">
<title id=" N04-4030.xml">nearly automated meta data hierarchy creation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, we have found that, for some collections, starting with the assumption that there will be small amount of hand-editing done after the automated processing, combined with bottom-up approach that extracts out those parts of the hypernym hierarchy that are relevant to the collection, and compression algorithm that simplifies the hierarchical structure, we can produce structure that is close to the target goals.below we describe related work, the method for converting wordnet into more usable form, and the results of using the algorithm on test collection.
</prevsent>
<prevsent>there has been surprisingly little work on precisely the problem that we tackle in this paper.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
the literature on automated text categorization is enormous, but assumes that set of categories has already been created, whereas the problem here is to determine the categories of interest.there has also been extensive work on finding synonymous terms and word associations, as well as automatic acquisition of is-a (or genus-head) relations from dictionary definitions and glosses (klavans and whitman, 2001) and from free text (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>sanderson and croft (1999) propose method calledsubsumption for building hierarchy for set of documents retrieved for query.
</nextsent>
<nextsent>for two terms and y, is said to subsume if the following conditions hold:       ff . the evaluation consisted.
</nextsent>
<nextsent>of asking people to define the relation that holds between the pairs of words shown; only 23% of the pairs were found to hold parent-child relation; 49% were found to fall into more general related-to category.
</nextsent>
<nextsent>for set of medical texts, the top level consisted of the terms: disease, post polio, serious disease, dengue, infection control, immunology, etc. this kind of listing is not systematic enough to appear on navigation page for website.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1864">
<title id=" N04-3001.xml">columbia news blaster multilingual news summarization on the web </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is useful in analysis, monitoring, and browsing settings, where user does not have an priori topic in mind.
</prevsent>
<prevsent>our summarization strategy also differs from the approach taken by must in that we focus our effort on the summarization system, but only target single language, shifting the majority of the multilingual knowledge burden to specialized machine translation systems.
</prevsent>
</prevsection>
<citsent citstr=" C00-1024 ">
the keizei system has the advantage of being able to generate query-specific summaries.chen and lin (chen and lin, 2000) <papid> C00-1024 </papid>describe system that combines multiple monolingual news clustering components, multilingual news clustering component, and news summarization component.</citsent>
<aftsection>
<nextsent>their system clusters news in each language into topics, then the multilingual clustering component relates the clusters that are similar across languages.
</nextsent>
<nextsent>a summary is generated by linking sentences that are similar from the two languages.
</nextsent>
<nextsent>the system has been implemented for chinese and english, and an evaluation over six topics is presented.
</nextsent>
<nextsent>our clustering strategy differs here, as we translate documents before clustering, and cluster documents from all languages at the same time.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1865">
<title id=" N04-3001.xml">columbia news blaster multilingual news summarization on the web </title>
<section> multilingual summarization baseline.  </section>
<citcontext>
<prevsection>
<prevsent>multi gen clusters sentences based on similarity, and then parses and fuses information from similar sentences to form summary.
</prevsent>
<prevsent>the second summarization system used is dems, the dissimilarity engine for multi-document summarization (schiffman et al, 2002), which uses sentence extraction approach to summarization.
</prevsent>
</prevsection>
<citsent citstr=" N03-2024 ">
the resulting summary is then run through named entity recovery tool (nenkovaand mckeown, 2003), <papid> N03-2024 </papid>which repairs named entity references in the summary by making the first reference descriptive, and shortening subsequent reference mentions in the summary.</citsent>
<aftsection>
<nextsent>using an unmodified version of dems,summaries might contain sentences from translated documents which are not grammatically correct.
</nextsent>
<nextsent>the dems summarization system was modified to prefer choosing sentence from an english article if there are sentences that express similar content in multiple languages.
</nextsent>
<nextsent>by setting different weight penalties we can take the quality of the translation system forgiven language pair into figure 2: screen shot comparing summary from english documents to summary from german documents.
</nextsent>
<nextsent>account.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1866">
<title id=" N04-3001.xml">columbia news blaster multilingual news summarization on the web </title>
<section> multilingual summarization baseline.  </section>
<citcontext>
<prevsection>
<prevsent>foreign-language sentences that have high enough similarity to english text are replaced (or augmented with) the similar english sentence.
</prevsent>
<prevsent>this first system using full machine translation overthe sentences and english similarity detection will be extended using simple features for multilingual similarity detection in sim finder multilingual (simfinderml), multilingual version of sim finder (hatzivassiloglou etal., 2001).
</prevsent>
</prevsection>
<citsent citstr=" P99-1044 ">
we also plan an experiment evaluating the usefulness of noun phrase detection and noun phrase variant detection as primitive for multilingual similarity detection, using tools such as christian jacque mins fastr (jacquemin, 1994; jacquemin, 1999).<papid> P99-1044 </papid></citsent>
<aftsection>
<nextsent>4.2 summary presentation.
</nextsent>
<nextsent>multilingual news blaster presents multiple views of acluster of documents to the user, broken down by language and by country.
</nextsent>
<nextsent>summaries are generated for the entire cluster, as well as sub-sets of the articles based onthe country of origin and language of the original articles.
</nextsent>
<nextsent>users are first presented with summary of the entire cluster using all documents, and then have the ability to focus on countries or languages of their choosing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1867">
<title id=" N07-1006.xml">source language features and maximum correlation training for machine translation evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we further improve performance by combining individual evaluation metrics using maximum correlation training, which is shown to be better than the classification-based framework.
</prevsent>
<prevsent>evaluation has long been stumbling block in the development of machine translation systems, due tothe simple fact that there are many correct translations forgiven sentence.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the most commonly used metric, bleu, correlates well over large test sets with human judgments (papineni et al, 2002),<papid> P02-1040 </papid>but does not perform as well on sentence-level evaluation (blatz et al, 2003).</citsent>
<aftsection>
<nextsent>later approaches to im prove sentence-level evaluation performance can be summarized as falling into four types: ? metrics based on common loose sequences of mt outputs and references (lin and och, 2004; <papid> P04-1077 </papid>liu and gildea, 2006).<papid> P06-2070 </papid></nextsent>
<nextsent>such metrics were shown to have better fluency evaluation performance than metrics based on n-grams such bleu and nist (doddington, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1868">
<title id=" N07-1006.xml">source language features and maximum correlation training for machine translation evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation has long been stumbling block in the development of machine translation systems, due tothe simple fact that there are many correct translations forgiven sentence.
</prevsent>
<prevsent>the most commonly used metric, bleu, correlates well over large test sets with human judgments (papineni et al, 2002),<papid> P02-1040 </papid>but does not perform as well on sentence-level evaluation (blatz et al, 2003).</prevsent>
</prevsection>
<citsent citstr=" P04-1077 ">
later approaches to im prove sentence-level evaluation performance can be summarized as falling into four types: ? metrics based on common loose sequences of mt outputs and references (lin and och, 2004; <papid> P04-1077 </papid>liu and gildea, 2006).<papid> P06-2070 </papid></citsent>
<aftsection>
<nextsent>such metrics were shown to have better fluency evaluation performance than metrics based on n-grams such bleu and nist (doddington, 2002).
</nextsent>
<nextsent>metrics based on syntactic similarities such as the head-word chain metric (hwcm) (liu andgildea, 2005).<papid> W05-0904 </papid></nextsent>
<nextsent>such metrics try to improve fluency evaluation performance for mt, but they heavily depend on automatic parsers, which are designed for well-formed sentences and cannot generate robust parse trees for mt outputs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1869">
<title id=" N07-1006.xml">source language features and maximum correlation training for machine translation evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation has long been stumbling block in the development of machine translation systems, due tothe simple fact that there are many correct translations forgiven sentence.
</prevsent>
<prevsent>the most commonly used metric, bleu, correlates well over large test sets with human judgments (papineni et al, 2002),<papid> P02-1040 </papid>but does not perform as well on sentence-level evaluation (blatz et al, 2003).</prevsent>
</prevsection>
<citsent citstr=" P06-2070 ">
later approaches to im prove sentence-level evaluation performance can be summarized as falling into four types: ? metrics based on common loose sequences of mt outputs and references (lin and och, 2004; <papid> P04-1077 </papid>liu and gildea, 2006).<papid> P06-2070 </papid></citsent>
<aftsection>
<nextsent>such metrics were shown to have better fluency evaluation performance than metrics based on n-grams such bleu and nist (doddington, 2002).
</nextsent>
<nextsent>metrics based on syntactic similarities such as the head-word chain metric (hwcm) (liu andgildea, 2005).<papid> W05-0904 </papid></nextsent>
<nextsent>such metrics try to improve fluency evaluation performance for mt, but they heavily depend on automatic parsers, which are designed for well-formed sentences and cannot generate robust parse trees for mt outputs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1871">
<title id=" N07-1006.xml">source language features and maximum correlation training for machine translation evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>later approaches to im prove sentence-level evaluation performance can be summarized as falling into four types: ? metrics based on common loose sequences of mt outputs and references (lin and och, 2004; <papid> P04-1077 </papid>liu and gildea, 2006).<papid> P06-2070 </papid></prevsent>
<prevsent>such metrics were shown to have better fluency evaluation performance than metrics based on n-grams such bleu and nist (doddington, 2002).</prevsent>
</prevsection>
<citsent citstr=" W05-0904 ">
metrics based on syntactic similarities such as the head-word chain metric (hwcm) (liu andgildea, 2005).<papid> W05-0904 </papid></citsent>
<aftsection>
<nextsent>such metrics try to improve fluency evaluation performance for mt, but they heavily depend on automatic parsers, which are designed for well-formed sentences and cannot generate robust parse trees for mt outputs.
</nextsent>
<nextsent>metrics based on word alignment between mt outputs and the references (banerjee and lavie,2005).<papid> W05-0909 </papid></nextsent>
<nextsent>such metrics do well inadequacy evaluation, but are not as good in fluency evaluation, because of their unigram basis (liu and gildea, 2006).<papid> P06-2070 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1872">
<title id=" N07-1006.xml">source language features and maximum correlation training for machine translation evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>metrics based on syntactic similarities such as the head-word chain metric (hwcm) (liu andgildea, 2005).<papid> W05-0904 </papid></prevsent>
<prevsent>such metrics try to improve fluency evaluation performance for mt, but they heavily depend on automatic parsers, which are designed for well-formed sentences and cannot generate robust parse trees for mt outputs.</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
metrics based on word alignment between mt outputs and the references (banerjee and lavie,2005).<papid> W05-0909 </papid></citsent>
<aftsection>
<nextsent>such metrics do well inadequacy evaluation, but are not as good in fluency evaluation, because of their unigram basis (liu and gildea, 2006).<papid> P06-2070 </papid></nextsent>
<nextsent>combination of metrics based on machine learning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1875">
<title id=" N07-1006.xml">source language features and maximum correlation training for machine translation evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their method is based on the assumption that higher classification accuracy in discriminating human- from machine-generated translations will yield closer correlation with human judgment.
</prevsent>
<prevsent>this assumption may not always hold, particularly when classification is difficult.
</prevsent>
</prevsection>
<citsent citstr=" H05-1093 ">
lita et al (2005) <papid> H05-1093 </papid>proposed log-linear model to combine features, but they only did preliminary experiments based on 2 features.</citsent>
<aftsection>
<nextsent>following the track of previous work, to improve evaluation performance, one could either propose new metrics, or find more effective ways to combine the metrics.
</nextsent>
<nextsent>we explore both approaches.
</nextsent>
<nextsent>much work has been done on computing mt scores based 41 on the pair of mt output/reference, and we aim to investigate whether some other information couldbe used in the mt evaluation, such as source sentences.
</nextsent>
<nextsent>we propose two types of source-sentence related features as well as feature based on part ofspeech.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1876">
<title id=" N07-1006.xml">source language features and maximum correlation training for machine translation evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the motivation behind such differentiation isthat different sub-precisions should have different importance in mt evaluation, e.g., sub precision of nouns, verbs, and adjectives should be important for evaluating adequacy, and sub-precision in determiners and conjunctions should mean more in evaluating fluency.
</prevsent>
<prevsent>along the direction of feature combination, since indirect weight training using svms, based on reducing classification error, cannot always yield good performance, we train the weights by directly optimizing the evaluation performance, i.e., maximizing the correlation with the human judgment.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
this type of direct optimization is known as minimum error rate training (och, 2003) <papid> P03-1021 </papid>in the mt community,and is an essential component in building the state of-art mt systems.</citsent>
<aftsection>
<nextsent>it would seem logical to apply similar methods to mt evaluation.
</nextsent>
<nextsent>what is more, maximum correlation training (mct) enables usto train the weights based on human fluency judgments and adequacy judgments respectively, and thus makes it possible to make fluency-oriented or adequacy-oriented metric.
</nextsent>
<nextsent>it surpasses previous mt metrics?
</nextsent>
<nextsent>approach, where a single metric evaluates both fluency and adequacy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1881">
<title id=" N03-3007.xml">word fragments identification using acoustic prosodic features in conversational speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiments show that, by combining few voice quality measures and prosodic features extracted fromthe forced alignments with the human transcriptions, we obtain precision rate of 74.3% and recall rate of 70.1% on the downsampleddata of spontaneous speech.
</prevsent>
<prevsent>the overall accuracy is 72.9%, which is significantly better than chance performance of 50%.
</prevsent>
</prevsection>
<citsent citstr=" J99-4003 ">
word fragments1 occur frequently in spontaneous speech, and are good indicators for speech disfluencies (heeman and allen, 1999; <papid> J99-4003 </papid>nakatani and hirschberg, 1994).</citsent>
<aftsection>
<nextsent>when expressed as percentage of the disfluencies that contain word fragment, levelt found 22% for pattern description task in dutch (levelt, 1983); lickley reported 36% for casual conversations in british english (lickley, 1994); bear et al found 60% for the atis corpus (bearet al, 1992).<papid> P92-1008 </papid></nextsent>
<nextsent>we examined 83 conversations of switchboard corpus (godfrey et al, 1992) and found that about17% of the disfluencies contain word fragments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1882">
<title id=" N03-3007.xml">word fragments identification using acoustic prosodic features in conversational speech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the overall accuracy is 72.9%, which is significantly better than chance performance of 50%.
</prevsent>
<prevsent>word fragments1 occur frequently in spontaneous speech, and are good indicators for speech disfluencies (heeman and allen, 1999; <papid> J99-4003 </papid>nakatani and hirschberg, 1994).</prevsent>
</prevsection>
<citsent citstr=" P92-1008 ">
when expressed as percentage of the disfluencies that contain word fragment, levelt found 22% for pattern description task in dutch (levelt, 1983); lickley reported 36% for casual conversations in british english (lickley, 1994); bear et al found 60% for the atis corpus (bearet al, 1992).<papid> P92-1008 </papid></citsent>
<aftsection>
<nextsent>we examined 83 conversations of switchboard corpus (godfrey et al, 1992) and found that about17% of the disfluencies contain word fragments.
</nextsent>
<nextsent>how ever, accurate identification of word fragments is still an 1a word fragment, also called partial word, happens when speaker cuts off in the middle of word.
</nextsent>
<nextsent>unsolved problem in speech community.
</nextsent>
<nextsent>in most cases, they are simply treated as out-of-vocabulary words or are often incorrectly recognized as words in the vocabulary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1885">
<title id=" N04-3011.xml">use and acquisition of semantic language model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an example based approach is also described here to demonstrate viable approach.
</prevsent>
<prevsent>any spoken language understanding system must deal with two critical issues: how to accurately infer users intention from speech, and how to do it robustly amidst the prevalent spontaneous speech effects where users would inevitably stutter, hesitate, and self correct themselves on regular basis.
</prevsent>
</prevsection>
<citsent citstr=" P94-1004 ">
to address these issues, it has been proposed (miller et al, 1994; <papid> P94-1004 </papid>wang, 2000; esteve et al, 2003) that one can extend the statistical pattern recognition framework commonly used for automatic speech recognition (asr) to the spoken language understanding (slu) problem.</citsent>
<aftsection>
<nextsent>the pattern?
</nextsent>
<nextsent>to be recognized for asr is string of word, and for slu, tree of semantic objects that represent the domain entities and tasks that describe the users intention.
</nextsent>
<nextsent>as is the case for asr where language model plays the pivotal role in guiding the recognizer to compose plausible string hypotheses, pattern recognition based slu relies on what is often called the semantic language model (slm) to detect semantic objects and construct parse tree from the users utterance.
</nextsent>
<nextsent>because the end outcome is parse tree, slm is usually realized using the structured language model techniques so that the semantic structure of the utterance can be included in modeling the language (wang, 2000; erdogan et al, 2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1886">
<title id=" N06-1034.xml">modelling user satisfaction and student learning in a spoken dialogue tutoring system with generic tutoring and user affect parameters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years the development of spoken dialogue tutoring systems has become more prevalent, in an attempt to close the performance gap between human and computer tutors (mostow and aist, 2001; pon-barry et al, 2004; litman et al, 2006).
</prevsent>
<prevsent>student learning is primary metric for evaluating the performance of these systems; it can be measured, e.g., by comparing student pre tests taken prior to system use with post tests taken after system use.
</prevsent>
</prevsection>
<citsent citstr=" H92-1009 ">
in other types of spoken dialogue systems, the users subjective judgments about using the system are often considered primary system performance metric; e.g., user satisfaction has been measured via surveys which ask users to rate systems during use along dimensions such as task ease, speech in put/output quality, user expectations and expertise, and user future use (moller, 2005b; walker et al, 2002; bonneau-maynard et al, 2000; walker et al,2000; shriberg et al, 1992).<papid> H92-1009 </papid></citsent>
<aftsection>
<nextsent>however, it is expensive to run experiments over large numbers of users to obtain reliable system performance measures.the paradise model (walker et al, 1997) <papid> P97-1035 </papid>proposes instead to predict system performance, using parameters representing interaction costs and benefits between system and user, including task success,dialogue efficiency, and dialogue quality.</nextsent>
<nextsent>more formally, set of interaction parameters are measured in spoken dialogue system corpus, then used in multivariate linear regression to predict the target performance variable.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1887">
<title id=" N06-1034.xml">modelling user satisfaction and student learning in a spoken dialogue tutoring system with generic tutoring and user affect parameters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>student learning is primary metric for evaluating the performance of these systems; it can be measured, e.g., by comparing student pre tests taken prior to system use with post tests taken after system use.
</prevsent>
<prevsent>in other types of spoken dialogue systems, the users subjective judgments about using the system are often considered primary system performance metric; e.g., user satisfaction has been measured via surveys which ask users to rate systems during use along dimensions such as task ease, speech in put/output quality, user expectations and expertise, and user future use (moller, 2005b; walker et al, 2002; bonneau-maynard et al, 2000; walker et al,2000; shriberg et al, 1992).<papid> H92-1009 </papid></prevsent>
</prevsection>
<citsent citstr=" P97-1035 ">
however, it is expensive to run experiments over large numbers of users to obtain reliable system performance measures.the paradise model (walker et al, 1997) <papid> P97-1035 </papid>proposes instead to predict system performance, using parameters representing interaction costs and benefits between system and user, including task success,dialogue efficiency, and dialogue quality.</citsent>
<aftsection>
<nextsent>more formally, set of interaction parameters are measured in spoken dialogue system corpus, then used in multivariate linear regression to predict the target performance variable.
</nextsent>
<nextsent>the resulting model is described by the formula below, where there are interaction parameters, pi, each weighted by the anal-ysis with coefficient, wi, which will be negative or positive, depending on whether the model treats pi as cost or benefit, respectively.
</nextsent>
<nextsent>the model canthen be used to estimate performance during system design, with the design goals of minimizing costs and maximizing benefits.
</nextsent>
<nextsent>system performance = ni=1 wi * piwe investigate using paradise to develop predictive models of performance in our spoken dialogue tutoring system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1893">
<title id=" N07-1042.xml">multi document relationship fusion via constraints on probabilistic databases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper presents fusion method which uses probabilistic database model to pick relationships which violate few constraints.
</prevsent>
<prevsent>this model allows improved performance on constructing corporate succession timelines from multiple documents with respect to multi-document fusion baseline.
</prevsent>
</prevsection>
<citsent citstr=" C96-1079 ">
single document information extraction of named entities and relationships has received much attention since the muc evaluations1 in the mid-90s (ap pelt et al, 1993; grishman and sundheim, 1996).<papid> C96-1079 </papid></citsent>
<aftsection>
<nextsent>recently, there has been increased interest in the extraction of named entities and relationships from multiple documents, since the redundancy of information across documents has been shown to be apowerful resource for obtaining high quality information even when the extractors have access to little or no training data (etzioni et al, 2004; hasegawa et al, 2004).<papid> P04-1053 </papid></nextsent>
<nextsent>much of the recent work in multi document relationship extraction has focused on the extraction of isolated relationships (agichtein, 2005; pasca et al, 2006), but often the goal, as in 1http://www.itl.nist.gov/iaui/894.02/related projects/muc/single document tasks like muc, is to extract template or relational database composed of related facts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1894">
<title id=" N07-1042.xml">multi document relationship fusion via constraints on probabilistic databases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this model allows improved performance on constructing corporate succession timelines from multiple documents with respect to multi-document fusion baseline.
</prevsent>
<prevsent>single document information extraction of named entities and relationships has received much attention since the muc evaluations1 in the mid-90s (ap pelt et al, 1993; grishman and sundheim, 1996).<papid> C96-1079 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1053 ">
recently, there has been increased interest in the extraction of named entities and relationships from multiple documents, since the redundancy of information across documents has been shown to be apowerful resource for obtaining high quality information even when the extractors have access to little or no training data (etzioni et al, 2004; hasegawa et al, 2004).<papid> P04-1053 </papid></citsent>
<aftsection>
<nextsent>much of the recent work in multi document relationship extraction has focused on the extraction of isolated relationships (agichtein, 2005; pasca et al, 2006), but often the goal, as in 1http://www.itl.nist.gov/iaui/894.02/related projects/muc/single document tasks like muc, is to extract template or relational database composed of related facts.
</nextsent>
<nextsent>with databases containing multiple relationships, the semantics of the database impose constraints on possible database configurations.
</nextsent>
<nextsent>this paper presents statistical method which picks relationships which violate few constraints as measured by probabilistic database model.
</nextsent>
<nextsent>the constraints are hard constraints, and robust estimates are achieved by accounting for the underlying extraction/fusion uncertainty.this method is applied to the problem of constructing management succession timelines which have rich set of semantic constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1895">
<title id=" N07-1042.xml">multi document relationship fusion via constraints on probabilistic databases </title>
<section> multi-document database fusion.  </section>
<citcontext>
<prevsection>
<prevsent>there are typically two steps in the extraction of single relationships from multiple documents.
</prevsent>
<prevsent>in the first step, relationship extractor goes through the corpus, finds all possible relationships in all sentences and gives them score p(r|s).
</prevsent>
</prevsection>
<citsent citstr=" P05-1061 ">
next, the ity, typically binary relationships are combined (mcdonald et al., 2005).<papid> P05-1061 </papid></citsent>
<aftsection>
<nextsent>relationships are fused across sentences to generate one score for each relationship.
</nextsent>
<nextsent>this paper proposes third step which combines the fusion scores across relationships.
</nextsent>
<nextsent>this section first presents probabilistic database model generated from fusion scores and then shows how to use this model for multi-document fusion.
</nextsent>
<nextsent>3.1 probabilistic database model relationship is defined to be 3-tuple rt,a,b = r(t, a, b), where is the type of the relationship (e.g. start), and and are the arguments of the binary relationship.3 to construct probabilistic database forgiven corpus, the weights generated in relationship fusion are normalized to provide the conditional probability of relationship given its type: p(rt,a,b1 |t1) = rt,a,b1?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1896">
<title id=" N07-1042.xml">multi document relationship fusion via constraints on probabilistic databases </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>using constraints on implicit derived fields (inoffice and precedes) provides additional benefit above constraints strictly on explicit database fields (start, end, ceo).come artificially lower ranked than the unfused relationship type (ceo).
</prevsent>
<prevsent>the best performing con trained probabilistic database approach beats the baseline by 5 points.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
techniques for information extraction from minimally supervised data have been explored by brin (1998), agichtein and gravano (2000), and ravichandran and hovy (2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>those techniques propose methods for estimating extractors from example relationships and corpus which contains instances of those relationships.
</nextsent>
<nextsent>nahm and mooney (2002) explore techniques for extracting multiple relationships in single document extraction.
</nextsent>
<nextsent>they learn rules for predicting certain fields given other extracted fields (i.e. someone who lists windows as specialty is likely to know microsoft word).perhaps the most related work to what is presented here is previous research which uses database information as co-occurrence features for information extraction in multi-document setting.
</nextsent>
<nextsent>mann in office before end (6) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.2 0.4 0.6 0.8 1 baseline ceos only (2)start before end (3)2, in office after start (5) 2,3,5,6 figure 4: precision/recall curve for whole databasereconstruction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1897">
<title id=" N07-1042.xml">multi document relationship fusion via constraints on probabilistic databases </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>mann in office before end (6) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.2 0.4 0.6 0.8 1 baseline ceos only (2)start before end (3)2, in office after start (5) 2,3,5,6 figure 4: precision/recall curve for whole databasereconstruction.
</prevsent>
<prevsent>performance curves using constraints dominate the baseline.and yarowsky (2005) present an incremental approach where co-occurrence with known relationship is feature added in training and test.
</prevsent>
</prevsection>
<citsent citstr=" N06-1038 ">
culotta et al (2006) <papid> N06-1038 </papid>introduce data mining approach where discovered relationships from database are used as features in extracting new relationships.</citsent>
<aftsection>
<nextsent>the database constraints presented in this paper provide more general framework for jointly conditioning multiple relationships.
</nextsent>
<nextsent>additionally, this constraint based approach can be applied without special training of the extraction/fusion system.in the context of information fusion of single relationships across multiple documents, downey et al(2005) propose method that models the probabilities of positive and negative extracted classifications.
</nextsent>
<nextsent>more distantly related, sutton and mccallum (2004) and finkel et al (2005) <papid> P05-1045 </papid>propose graphical models for combining information about given entity from multiple mentions.</nextsent>
<nextsent>in the field of question answering, prager et al(2004) <papid> P04-1073 </papid>answer question about the list of compositions produced by given subject by looking for related information about the subjects birth and death.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1898">
<title id=" N07-1042.xml">multi document relationship fusion via constraints on probabilistic databases </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the database constraints presented in this paper provide more general framework for jointly conditioning multiple relationships.
</prevsent>
<prevsent>additionally, this constraint based approach can be applied without special training of the extraction/fusion system.in the context of information fusion of single relationships across multiple documents, downey et al(2005) propose method that models the probabilities of positive and negative extracted classifications.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
more distantly related, sutton and mccallum (2004) and finkel et al (2005) <papid> P05-1045 </papid>propose graphical models for combining information about given entity from multiple mentions.</citsent>
<aftsection>
<nextsent>in the field of question answering, prager et al(2004) <papid> P04-1073 </papid>answer question about the list of compositions produced by given subject by looking for related information about the subjects birth and death.</nextsent>
<nextsent>their method treats supporting information as fixed hard constraints on the original questions and are applied in an ad-hoc fashion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1899">
<title id=" N07-1042.xml">multi document relationship fusion via constraints on probabilistic databases </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>additionally, this constraint based approach can be applied without special training of the extraction/fusion system.in the context of information fusion of single relationships across multiple documents, downey et al(2005) propose method that models the probabilities of positive and negative extracted classifications.
</prevsent>
<prevsent>more distantly related, sutton and mccallum (2004) and finkel et al (2005) <papid> P05-1045 </papid>propose graphical models for combining information about given entity from multiple mentions.</prevsent>
</prevsection>
<citsent citstr=" P04-1073 ">
in the field of question answering, prager et al(2004) <papid> P04-1073 </papid>answer question about the list of compositions produced by given subject by looking for related information about the subjects birth and death.</citsent>
<aftsection>
<nextsent>their method treats supporting information as fixed hard constraints on the original questions and are applied in an ad-hoc fashion.
</nextsent>
<nextsent>this paper proposes aprobabilistic method for using constraints in the context of database extraction and applies this method over larger set of relations.
</nextsent>
<nextsent>richardson and domingos (2006) propose method for reasoning about databases and logical constraints using markov random fields.
</nextsent>
<nextsent>their 338 model applies reasoning starting from knowndatabase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1900">
<title id=" N06-1036.xml">backoff model training using partially observed data application to dialog act tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>like other tagging tasks, da recognition can also be achieved using conditional random fields (lafferty et al, 2001; sutton et al, 2004) and general discriminative modeling on structured outputs (bartlett et al, 2004).
</prevsent>
<prevsent>inmany sequential data analysis tasks (speech, language, or dna sequence analysis), standard dynamic bayesian networks (dbns) (murphy, 2002) have shown great flexibility and are widely used.
</prevsent>
</prevsection>
<citsent citstr=" N03-2002 ">
in (ji and bilmes, 2005), for example, an analysis of da tagging using dbns is performed, where the models avoid label bias by structural changes and avoid data sparseness by using generalized back off procedures (bilmes and kirchhoff, 2003).<papid> N03-2002 </papid></citsent>
<aftsection>
<nextsent>most da classification procedures assume that within sentence of particular fixed da type,there is fixed word distribution over the entire sentence.
</nextsent>
<nextsent>similar to (ma et al, 2000) (and see citations therein), we have found, however, that intra 280 sentence discourse patterns are inherently dynamic.
</nextsent>
<nextsent>moreover, the patterns are specific to each type ofda, meaning sentence will go through da specific sequence of sub-da phases or states.?
</nextsent>
<nextsent>a generative description of this phenomena is that da is first chosen, and then words are generated according to both theda and to the relative position of the word in that sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1901">
<title id=" N06-1036.xml">backoff model training using partially observed data application to dialog act tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our belief is that explicitly modeling these internal state scan help da-classification system in conversational meetings or dialogs.
</prevsent>
<prevsent>in this work, we describe an approach that is motivated by several aspects of the typical daclassification procedure.
</prevsent>
</prevsection>
<citsent citstr=" W04-2319 ">
first, it is rare to have sub das labeled in training data, and indeed this is true of the corpus (shriberg et al, 2004) <papid> W04-2319 </papid>that we use.</citsent>
<aftsection>
<nextsent>therefore, some form of unsupervised clustering or pre-shallow-parsing of sub-das must be performed.in such model, these sub-das are essentially unknown hidden variables that ideally could be trained with an expectation-maximization (em) procedure.second, when training models of language, it is necessary to employ some form of smoothing methodology since otherwise data-sparseness would render standard maximum-likelihood trained models useless.
</nextsent>
<nextsent>third, discrete conditional probability distributions formed using backoff models that have been smoothed (particularly using modified kneser-ney (chen and goodman, 1998)) have been extremely successful in many language modeling tasks.
</nextsent>
<nextsent>training backoff models, however, requires that all datais observed so that data counts can be formed.
</nextsent>
<nextsent>indeed, our da-specific word models (implementedvia backoff) will also need to condition on the current sub-da, which at training time is unknown.we therefore have developed procedure that allows us to train generalized backoff models (bilmes and kirchhoff, 2003), <papid> N03-2002 </papid>even when some or all of the variables involved in the model are hidden.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1908">
<title id=" N06-1036.xml">backoff model training using partially observed data application to dialog act tagging </title>
<section> hidden backoff models.  </section>
<citcontext>
<prevsection>
<prevsent>accordingly, in this work we do not assume sentences for each dialog act have the same hidden state patterns.
</prevsent>
<prevsent>for instance (and as mentioned above), statement can consist of noun followed by verb phase.a problem, however, is that sub-das are not annotated in our training corpus.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
while clustering and annotation of these phrases is already widely developed research topic (pieraccini and levin, 1991; lee et al, 1997; gildea and jurafsky, 2002), <papid> J02-3001 </papid>in our approach we use an em algorithm to learn these hidden sub-das in data-driven fashion.</citsent>
<aftsection>
<nextsent>pictorially, we add layer of hidden states to our baseline dbn as illustrated in figure 2.
</nextsent>
<nextsent>sentence change da   dialog act word   word prologue chunk epilogue hidden state figure 2: hidden backoff model for da tagging.
</nextsent>
<nextsent>under this model, the joint probability is: (w, s, d) = ? p (dk|dk1) ? ?
</nextsent>
<nextsent>i [p (sk,i|sk,i1, dk) ? (wk,i|wk,i1, sk,i, dk)] , (2) 282 where = {sk,i} is the hidden state sequence, sk,iis the hidden state at the i-th position of the k-th sentence, and other variables are the same as before.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1911">
<title id=" N03-1032.xml">frequency estimates for statistical word similarity measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for two question sets, context for the target word is provided, and we examine number ofword similarity measures that exploit this context.
</prevsent>
<prevsent>our best combination of similarity measure and frequency estimation method answers6-8% more questions than the best results previously reported for the same question sets.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
many different statistical tests have been proposed to measure the strength of word similarity or word association in natural language texts (dunning, 1993; <papid> J93-1003 </papid>church and hanks, 1990; <papid> J90-1003 </papid>dagan et al, 1999).</citsent>
<aftsection>
<nextsent>these tests attempt to measure dependence between words by using statistics taken from large corpus.
</nextsent>
<nextsent>in this context, key assumption is that similarity between words is consequence of word co-occurrence, or that the closeness of the words in text is indicative of some kind of relationship between them, such as synonymy or antonymy.although word sequences in natural language are unlikely to be independent, these statistical tests provide quantitative information that can be used to compare pairs of co-occurring words.
</nextsent>
<nextsent>also, despite the fact that word co-occurrence is simple idea, there are variety of ways to estimate word co-occurrence frequencies from text.
</nextsent>
<nextsent>two words can appear close to each other in the same document, passage, paragraph, sentence orfixed-size window.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1912">
<title id=" N03-1032.xml">frequency estimates for statistical word similarity measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for two question sets, context for the target word is provided, and we examine number ofword similarity measures that exploit this context.
</prevsent>
<prevsent>our best combination of similarity measure and frequency estimation method answers6-8% more questions than the best results previously reported for the same question sets.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
many different statistical tests have been proposed to measure the strength of word similarity or word association in natural language texts (dunning, 1993; <papid> J93-1003 </papid>church and hanks, 1990; <papid> J90-1003 </papid>dagan et al, 1999).</citsent>
<aftsection>
<nextsent>these tests attempt to measure dependence between words by using statistics taken from large corpus.
</nextsent>
<nextsent>in this context, key assumption is that similarity between words is consequence of word co-occurrence, or that the closeness of the words in text is indicative of some kind of relationship between them, such as synonymy or antonymy.although word sequences in natural language are unlikely to be independent, these statistical tests provide quantitative information that can be used to compare pairs of co-occurring words.
</nextsent>
<nextsent>also, despite the fact that word co-occurrence is simple idea, there are variety of ways to estimate word co-occurrence frequencies from text.
</nextsent>
<nextsent>two words can appear close to each other in the same document, passage, paragraph, sentence orfixed-size window.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1913">
<title id=" N03-1032.xml">frequency estimates for statistical word similarity measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, despite the fact that word co-occurrence is simple idea, there are variety of ways to estimate word co-occurrence frequencies from text.
</prevsent>
<prevsent>two words can appear close to each other in the same document, passage, paragraph, sentence orfixed-size window.
</prevsent>
</prevsection>
<citsent citstr=" P98-2124 ">
the boundaries for determining cooccurrence will affect the estimates and as consequence the word similarity measures.statistical word similarity measures play an important role in information retrieval and in many other natural language applications, such as the automatic creation of thesauri (grefenstette, 1993; li and abe, 1998; <papid> P98-2124 </papid>lin, 1998) <papid> P98-2127 </papid>and word sense disambiguation (yarowsky, 1992;<papid> C92-2070 </papid>li and abe, 1998).<papid> P98-2124 </papid></citsent>
<aftsection>
<nextsent>pantel and lin (2002) use word similarity to create groups of related words, in order to discover word senses directly from text.
</nextsent>
<nextsent>recently, tan et al.
</nextsent>
<nextsent>(2002) provide an analysis on different measures of independence in the context of association rules.word similarity is also used in language modeling applications.
</nextsent>
<nextsent>rosenfeld (1996) uses word similarity as constraint in maximum entropy model which reduces the perplexity on test set by 23%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1914">
<title id=" N03-1032.xml">frequency estimates for statistical word similarity measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, despite the fact that word co-occurrence is simple idea, there are variety of ways to estimate word co-occurrence frequencies from text.
</prevsent>
<prevsent>two words can appear close to each other in the same document, passage, paragraph, sentence orfixed-size window.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
the boundaries for determining cooccurrence will affect the estimates and as consequence the word similarity measures.statistical word similarity measures play an important role in information retrieval and in many other natural language applications, such as the automatic creation of thesauri (grefenstette, 1993; li and abe, 1998; <papid> P98-2124 </papid>lin, 1998) <papid> P98-2127 </papid>and word sense disambiguation (yarowsky, 1992;<papid> C92-2070 </papid>li and abe, 1998).<papid> P98-2124 </papid></citsent>
<aftsection>
<nextsent>pantel and lin (2002) use word similarity to create groups of related words, in order to discover word senses directly from text.
</nextsent>
<nextsent>recently, tan et al.
</nextsent>
<nextsent>(2002) provide an analysis on different measures of independence in the context of association rules.word similarity is also used in language modeling applications.
</nextsent>
<nextsent>rosenfeld (1996) uses word similarity as constraint in maximum entropy model which reduces the perplexity on test set by 23%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1915">
<title id=" N03-1032.xml">frequency estimates for statistical word similarity measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, despite the fact that word co-occurrence is simple idea, there are variety of ways to estimate word co-occurrence frequencies from text.
</prevsent>
<prevsent>two words can appear close to each other in the same document, passage, paragraph, sentence orfixed-size window.
</prevsent>
</prevsection>
<citsent citstr=" C92-2070 ">
the boundaries for determining cooccurrence will affect the estimates and as consequence the word similarity measures.statistical word similarity measures play an important role in information retrieval and in many other natural language applications, such as the automatic creation of thesauri (grefenstette, 1993; li and abe, 1998; <papid> P98-2124 </papid>lin, 1998) <papid> P98-2127 </papid>and word sense disambiguation (yarowsky, 1992;<papid> C92-2070 </papid>li and abe, 1998).<papid> P98-2124 </papid></citsent>
<aftsection>
<nextsent>pantel and lin (2002) use word similarity to create groups of related words, in order to discover word senses directly from text.
</nextsent>
<nextsent>recently, tan et al.
</nextsent>
<nextsent>(2002) provide an analysis on different measures of independence in the context of association rules.word similarity is also used in language modeling applications.
</nextsent>
<nextsent>rosenfeld (1996) uses word similarity as constraint in maximum entropy model which reduces the perplexity on test set by 23%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1917">
<title id=" N03-1032.xml">frequency estimates for statistical word similarity measures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2002) provide an analysis on different measures of independence in the context of association rules.word similarity is also used in language modeling applications.
</prevsent>
<prevsent>rosenfeld (1996) uses word similarity as constraint in maximum entropy model which reduces the perplexity on test set by 23%.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
brown et al (1992) <papid> J92-4003 </papid>use word similarity measure for language modeling in an interpolated model, grouping similar words into classes.</citsent>
<aftsection>
<nextsent>dagan et al (1999) use word similarity to assign probabilities to unseen bigrams by using similar bigrams, which reduces perplexity up to 20% in held out data.
</nextsent>
<nextsent>in information retrieval, word similarity can be used to identify terms for pseudo-relevance feedback (harman,1992; buckley et al, 1995; xu and croft, 2000; vechtomova and robertson, 2000).
</nextsent>
<nextsent>xu and croft (2000) expand queries under pseudo-relevance feedback model by using similar words from documents retrieved and improve effectiveness by more than 20% on an 11-point average precision.
</nextsent>
<nextsent>landauer and dumais (1997) applied word similarity measures to answer toefl (test of english as foreign language) synonym questions using latent semantic analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1927">
<title id=" N06-1026.xml">identifying and analyzing judgment opinions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this phenomenon has opened the door for massive opinion collection, which has potential impact on various applications such as public opinion monitoring and product review summary systems.
</prevsent>
<prevsent>although in its infancy, many researchers have worked in various facets of opinion analysis.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
pang et al (2002) <papid> W02-1011 </papid>and turney (2002) <papid> P02-1053 </papid>classified sentiment polarity of reviews at the document level.</citsent>
<aftsection>
<nextsent>wiebe et al (1999) <papid> P99-1032 </papid>classified sentence level subjectivity using syntactic classes such as adjectives, pronouns and modal verbs as features.</nextsent>
<nextsent>riloff and wiebe (2003) <papid> W03-1014 </papid>extracted subjective expressions from sentences using bootstrapping pattern learning process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1928">
<title id=" N06-1026.xml">identifying and analyzing judgment opinions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this phenomenon has opened the door for massive opinion collection, which has potential impact on various applications such as public opinion monitoring and product review summary systems.
</prevsent>
<prevsent>although in its infancy, many researchers have worked in various facets of opinion analysis.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
pang et al (2002) <papid> W02-1011 </papid>and turney (2002) <papid> P02-1053 </papid>classified sentiment polarity of reviews at the document level.</citsent>
<aftsection>
<nextsent>wiebe et al (1999) <papid> P99-1032 </papid>classified sentence level subjectivity using syntactic classes such as adjectives, pronouns and modal verbs as features.</nextsent>
<nextsent>riloff and wiebe (2003) <papid> W03-1014 </papid>extracted subjective expressions from sentences using bootstrapping pattern learning process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1929">
<title id=" N06-1026.xml">identifying and analyzing judgment opinions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although in its infancy, many researchers have worked in various facets of opinion analysis.
</prevsent>
<prevsent>pang et al (2002) <papid> W02-1011 </papid>and turney (2002) <papid> P02-1053 </papid>classified sentiment polarity of reviews at the document level.</prevsent>
</prevsection>
<citsent citstr=" P99-1032 ">
wiebe et al (1999) <papid> P99-1032 </papid>classified sentence level subjectivity using syntactic classes such as adjectives, pronouns and modal verbs as features.</citsent>
<aftsection>
<nextsent>riloff and wiebe (2003) <papid> W03-1014 </papid>extracted subjective expressions from sentences using bootstrapping pattern learning process.</nextsent>
<nextsent>yu and hatzivassiloglou (2003) <papid> W03-1017 </papid>identified the polarity of opinion sentences using semantically oriented words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1930">
<title id=" N06-1026.xml">identifying and analyzing judgment opinions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pang et al (2002) <papid> W02-1011 </papid>and turney (2002) <papid> P02-1053 </papid>classified sentiment polarity of reviews at the document level.</prevsent>
<prevsent>wiebe et al (1999) <papid> P99-1032 </papid>classified sentence level subjectivity using syntactic classes such as adjectives, pronouns and modal verbs as features.</prevsent>
</prevsection>
<citsent citstr=" W03-1014 ">
riloff and wiebe (2003) <papid> W03-1014 </papid>extracted subjective expressions from sentences using bootstrapping pattern learning process.</citsent>
<aftsection>
<nextsent>yu and hatzivassiloglou (2003) <papid> W03-1017 </papid>identified the polarity of opinion sentences using semantically oriented words.</nextsent>
<nextsent>these techniques were applied and examined in different domains, such as customer reviews (hu and liu 2004) and news articles1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1931">
<title id=" N06-1026.xml">identifying and analyzing judgment opinions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wiebe et al (1999) <papid> P99-1032 </papid>classified sentence level subjectivity using syntactic classes such as adjectives, pronouns and modal verbs as features.</prevsent>
<prevsent>riloff and wiebe (2003) <papid> W03-1014 </papid>extracted subjective expressions from sentences using bootstrapping pattern learning process.</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
yu and hatzivassiloglou (2003) <papid> W03-1017 </papid>identified the polarity of opinion sentences using semantically oriented words.</citsent>
<aftsection>
<nextsent>these techniques were applied and examined in different domains, such as customer reviews (hu and liu 2004) and news articles1.
</nextsent>
<nextsent>these researchers use lists of opin ion-bearing clue words and phrases, and then apply various additional techniques and refinements.
</nextsent>
<nextsent>along with many opinion researchers, we participated in large pilot study, sponsored by nist, which concluded that it is very difficult to define what an opinion is in general.
</nextsent>
<nextsent>moreover, an expression that is considered as an opinion in one domain might not be an opinion in another.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1932">
<title id=" N06-1026.xml">identifying and analyzing judgment opinions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the holder of an opinion is the person, organization or group whose opinion is expressed.
</prevsent>
<prevsent>finally, the topic is the event or entity about which the opinion is held.
</prevsent>
</prevsection>
<citsent citstr=" H05-1045 ">
in previous work, choi et al (2005) <papid> H05-1045 </papid>identify opinion holders (sources) using conditional random fields (crf) and extraction patterns.</citsent>
<aftsection>
<nextsent>they define the opinion holder identification problem as sequence tagging task: given sequence of words ( nxxx l21 ) in sentence, they generate sequence of labels ( nyyy l21 ) indicating whether the word is holder or not.
</nextsent>
<nextsent>however, there are many cases where multiple opinions are expressed in sentence each with its own holder.
</nextsent>
<nextsent>in those cases, finding opinion holders for each individual expression is necessary.
</nextsent>
<nextsent>in the corpus they used, 48.5% of the sentences which contain an opinion have more than one opinion expression with multiple opinion holders.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1933">
<title id=" N06-1026.xml">identifying and analyzing judgment opinions </title>
<section> analysis of judgment opinions.  </section>
<citcontext>
<prevsection>
<prevsent>by adding the third class, neutral, we can prevent the classifier from assigning either positive or negative sentiment to weak opinion-bearing words.
</prevsent>
<prevsent>for example, the word central?
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
that hatzivassiloglou and mckeown (1997) <papid> P97-1023 </papid>included as positive adjective is not classified as positive in our system.</citsent>
<aftsection>
<nextsent>instead 201 we mark it as neutral?
</nextsent>
<nextsent>since it is weak clue for an opinion.
</nextsent>
<nextsent>if an unknown word has strong relationship with the neutral class, we can therefore classify it as neutral even if it has some small connotation of positive or negative as well.
</nextsent>
<nextsent>approach: we built word sentiment classifier using wordnet and three sets of positive, negative, and neutral words tagged by hand.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1935">
<title id=" N06-1026.xml">identifying and analyzing judgment opinions </title>
<section> analysis of judgment opinions.  </section>
<citcontext>
<prevsection>
<prevsent>we employ that system in tandem with the one described here.
</prevsent>
<prevsent>to learn opinion holders automatically, we use maximum entropy model.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
maximum entropy models implement the intuition that the best model is the one that is consistent with the set of constraints imposed by the evidence but otherwise is as uniform as possible (berger et al 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>there are two ways to model the problem with me: classification and ranking.
</nextsent>
<nextsent>classification allocates each holder candidate to one of set of predefined classes while ranking selects single candidate as answer.
</nextsent>
<nextsent>this means that classification modeling3 can select many candidates as answers as long as they are marked as true, and does not select any candidate if every one is marked as false.
</nextsent>
<nextsent>in contrast, ranking always selects the most probable candidate as an answer, which suits our task better.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1936">
<title id=" N06-1026.xml">identifying and analyzing judgment opinions </title>
<section> analysis of judgment opinions.  </section>
<citcontext>
<prevsection>
<prevsent>this means that classification modeling3 can select many candidates as answers as long as they are marked as true, and does not select any candidate if every one is marked as false.
</prevsent>
<prevsent>in contrast, ranking always selects the most probable candidate as an answer, which suits our task better.
</prevsent>
</prevsection>
<citsent citstr=" W03-1209 ">
our earlier experiments showed poor performance with classification modeling, an experience also reported for question answering (ravichandran et al. 2003).<papid> W03-1209 </papid></citsent>
<aftsection>
<nextsent>we modeled the problem to choose the most probable candidate that maximizes given conditional probability distribution, given set of holder candidates 1 2 . . .
</nextsent>
<nextsent>h and opinion expression e. the conditional probability h 1 2 . . .
</nextsent>
<nextsent>h , can be calculated based on feature functions k , 1 2 . ..h , . we write decision rule for the ranking as follows: { } { } ]e),hhh(h,f?[= e)],hhh|[p(hh =k nkk n ? = 1 21 21 ...argmax ...argmax each k?
</nextsent>
<nextsent>is model parameter indicating the weight of its feature function.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1937">
<title id=" N06-1026.xml">identifying and analyzing judgment opinions </title>
<section> applying our methodology to german.  </section>
<citcontext>
<prevsection>
<prevsent>to generate opinion bearing words, we ran the word sentiment classifier from section 2.1 on 8011 verbs to classify them into 807 positive, 785 negative, and 6149 neutral.
</prevsent>
<prevsent>for 19748 adjectives, the system classified them into 3254 positive, 303 negative, and 16191 neutral.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
since our opinion bearing words are in english and our target system is in german, we also applied statistical word alignment technique, giza++ 6 (och and ney 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>running it on version two of the european parliament corpus, we obtained statistics for 678,340 german-english word pairs and 577,362 english-german word pairs.
</nextsent>
<nextsent>obtaining these two lists of translation pairs allows us to convert english words to german, and german to english, without full document translation system.
</nextsent>
<nextsent>to utilize our english opinion-bearing words in german opinion analysis system, we developed two models, 5 http://www.qualeg.eupm.net/my_spip/index.php 6 http://www.fjoch.com/giza++.html outlined in table 4, each of which is triggered at different points in the system.
</nextsent>
<nextsent>in both models, however, we still need to decide how to apply opinion-bearing words as clues to determine the sentiment of whole email.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1938">
<title id=" N04-4034.xml">multi speaker language modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wt1, is widely used.
</prevsent>
<prevsent>typically, = 3, which yields trigram model.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
a refinement of this model is the class-based n-gram where the words are partitioned into equivalence classes (brown et al, 1992).<papid> J92-4003 </papid></citsent>
<aftsection>
<nextsent>this work was funded by nsf under grant iis-0121396.
</nextsent>
<nextsent>in general, smoothing techniques are applied to lessen the curse of dimensionality.
</nextsent>
<nextsent>among all methods, modified kneser-ney smoothing (chen and goodman, 1998) is widely used because of its good performance.modeling conversational language is particularly difficult task.
</nextsent>
<nextsent>even though conventional techniques work well on read or prepared speech, situations such as telephone conversations or multi-person meetings pose great research challenges due to disfluencies, and odd syn tactic/discourse patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1941">
<title id=" N04-4034.xml">multi speaker language modeling </title>
<section> multi-speaker language modeling.  </section>
<citcontext>
<prevsection>
<prevsent>is day of the week, there is high probability that c2s response is also day of the week.
</prevsent>
<prevsent>in our model, weonly consider two streams at time, and a. therefore, when considering the probability of c2s words, it is reasonable to collapse words from all other speakers (c0,c1,c3,c4, and c5) into one stream as shown in the figure.
</prevsent>
</prevsection>
<citsent citstr=" N03-2002 ">
this makes available to c2 the rest of the meeting to potentially condition on, although it does not distinguish between different speakers.our model, equation 1, is different from most language modeling systems since our models condition on both previous words and another potential factor a. such model is easily represented using factored language model (flm), an idea introduced in (bilmes and kirchhoff, 2003; <papid> N03-2002 </papid>kirchhoff et al, 2003), and incorporated into the srilm toolkit (stolcke, 2002).</citsent>
<aftsection>
<nextsent>note that form of cross-side modeling was used by bbn (schwartz, 2004),where in multi-pass speech recognition system the out put of first-pass from one speaker is used to prime words in the language model for the other speaker.
</nextsent>
<nextsent>we evaluate mslms on three corpora: switchboard i, switchboard eval-2003, and icsi meeting data.
</nextsent>
<nextsent>in switchboard-i, 6.83% of the words are overlapped in time, where we define w1 and w2 as being overlapped if s(w1) ? s(w2)   e(w1) or s(w2) ? s(w1)   e(w2), where s(?)
</nextsent>
<nextsent>and e(?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1947">
<title id=" N04-4034.xml">multi speaker language modeling </title>
<section> conditional probability clustering.  </section>
<citcontext>
<prevsection>
<prevsent>table 2: three types of class-based mslms on switchboard-i (swbd) and icsi meeting (mr) corpora # of swbd mr classes brown mmi mcmi brown mmi mcmi 100 68.90.3 68.40.3 68.20.3 78.93.0 77.32.8 76.82.8 500 68.90.3 68.30.3 67.90.3 78.73.1 77.12.8 76.72.8 1000 68.90.3 68.20.3 67.90.3 79.03.1 77.22.7 76.92.8 1500 69.00.3 68.20.3 68.00.3 79.63.1 77.42.7 77.42.7 2000 69.00.3 68.30.3 68.00.3 80.13.1 77.62.7 77.92.7 |v | 68.50.3 78.32.7 table 3: class-based mslm on switchboard eval-2003 size 100 500 1000 1500 2000 |v | 3-gram 4-gram ppl 65.8 65.5 65.6 65.7 66.1 67.9 72.1 76.3 % reduction 8.6 8.9 8.8 8.7 8.3 5.8 0 -5.8 class-based language models (brown et al, 1992; <papid> J92-4003 </papid>whittaker and woodland, 2003) yield great benefits when data sparseness abounds.</prevsent>
<prevsent>srilm (stolcke, 2002) can produce classes to maximize the mutual information between the classes i(c(wt);c(wt1)), as described in (brown et al, 1992).<papid> J92-4003 </papid></prevsent>
</prevsection>
<citsent citstr=" P01-1068 ">
more recently, method for clustering words at different positions was developed (ya mamoto et al, 2001; <papid> P01-1068 </papid>gao et al, 2002).<papid> P02-1024 </papid></citsent>
<aftsection>
<nextsent>our goal is to produce classes that improve the scores (wt|ht) = (wt|wt1, wt2, c1(at)), what we call class-based mslms.
</nextsent>
<nextsent>in our case, the vocabulary for is partitioned into classes by either maximizing conditional mutual information (mcmi) i(wt;c(at)|wt1, wt2) or just maximizing mutual information (mmi) i(wt;c(at)).
</nextsent>
<nextsent>while such clusterings can perform poorly under low counts, our results show further consistent improvements.
</nextsent>
<nextsent>our new clustering procedures were implemented into the srilm toolkit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1948">
<title id=" N04-4034.xml">multi speaker language modeling </title>
<section> conditional probability clustering.  </section>
<citcontext>
<prevsection>
<prevsent>table 2: three types of class-based mslms on switchboard-i (swbd) and icsi meeting (mr) corpora # of swbd mr classes brown mmi mcmi brown mmi mcmi 100 68.90.3 68.40.3 68.20.3 78.93.0 77.32.8 76.82.8 500 68.90.3 68.30.3 67.90.3 78.73.1 77.12.8 76.72.8 1000 68.90.3 68.20.3 67.90.3 79.03.1 77.22.7 76.92.8 1500 69.00.3 68.20.3 68.00.3 79.63.1 77.42.7 77.42.7 2000 69.00.3 68.30.3 68.00.3 80.13.1 77.62.7 77.92.7 |v | 68.50.3 78.32.7 table 3: class-based mslm on switchboard eval-2003 size 100 500 1000 1500 2000 |v | 3-gram 4-gram ppl 65.8 65.5 65.6 65.7 66.1 67.9 72.1 76.3 % reduction 8.6 8.9 8.8 8.7 8.3 5.8 0 -5.8 class-based language models (brown et al, 1992; <papid> J92-4003 </papid>whittaker and woodland, 2003) yield great benefits when data sparseness abounds.</prevsent>
<prevsent>srilm (stolcke, 2002) can produce classes to maximize the mutual information between the classes i(c(wt);c(wt1)), as described in (brown et al, 1992).<papid> J92-4003 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1024 ">
more recently, method for clustering words at different positions was developed (ya mamoto et al, 2001; <papid> P01-1068 </papid>gao et al, 2002).<papid> P02-1024 </papid></citsent>
<aftsection>
<nextsent>our goal is to produce classes that improve the scores (wt|ht) = (wt|wt1, wt2, c1(at)), what we call class-based mslms.
</nextsent>
<nextsent>in our case, the vocabulary for is partitioned into classes by either maximizing conditional mutual information (mcmi) i(wt;c(at)|wt1, wt2) or just maximizing mutual information (mmi) i(wt;c(at)).
</nextsent>
<nextsent>while such clusterings can perform poorly under low counts, our results show further consistent improvements.
</nextsent>
<nextsent>our new clustering procedures were implemented into the srilm toolkit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1952">
<title id=" N03-2019.xml">inferring temporal ordering of events in news </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our approach involves mixed-initiative corpus annotation, with automatic tagging to identify clause structure, tense, aspect, and temporal adverbials, as well as tagging of reference times and anchoring of events with respect to reference times.
</prevsent>
<prevsent>we report on machine learning results from event-time anchoring judgments.
</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
linguistic processing the time expression tagger tempex (mani and wilson 2000) <papid> P00-1010 </papid>tags and assigns values to temporal expressions, both absolute?</citsent>
<aftsection>
<nextsent>expressions like june 1, 2001?
</nextsent>
<nextsent>and relative expressions like monday?.
</nextsent>
<nextsent>it was cited in (mani and wilson 2000) <papid> P00-1010 </papid>as achieving .83 f-measure against hand-annotated data.</nextsent>
<nextsent>inter-annotator reliability across 5 annotators on 193 tdt2-documents was .79f for extent and .86f for time values, with tempex scoring .76f (extent) and .82f (value) on these documents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1958">
<title id=" N03-2019.xml">inferring temporal ordering of events in news </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while improvements to the nave algorithm are clearly possible based on the corrected tval, to adequately test the machine learnt rules we use the corrected tval.
</prevsent>
<prevsent>overall, our approach achieves 84.6% accuracy in anchoring events and 75.4% f-measure in partially ordering them.
</prevsent>
</prevsection>
<citsent citstr=" W01-1313 ">
these numbers compare favorably with the previous literature: (filatova and hovy 2001) <papid> W01-1313 </papid>obtained 82% accuracy on anchoring for single type of event/topic on 172 clauses, while (mani and wilson 2000) <papid> P00-1010 </papid>obtained accuracy of 59.4% on anchoring over 663 verb contexts.</citsent>
<aftsection>
<nextsent>our approach is also distinct in its use of human experimentation, machine learning and the variety of linguistically motivated features (includ ing temporal adverbials) that are brought to bear.
</nextsent>
<nextsent>future work will examine the role of aspect ual features, learning from skewed distributions dominated by at (an overwhelming majority of news events occur at the reference times), and the incorporation of unsupervised learning methods.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1962">
<title id=" N04-1028.xml">nonnative users in the lets go spoken dialogue system dealing with linguistic mismatch </title>
<section> overview of the system.  </section>
<citcontext>
<prevsection>
<prevsent>in order to study the use of spoken dialogue systems by non-native speakers in realistic setting, we built letsgo!!, spoken dialogue system that provides bus schedule information for the pittsburgh area(raux et al, 2003).as shown in figure 1, the system is composed of five basic modules: the speech recognizer, the parser, the dialog manager, the language generator, and the speech synthesizer.
</prevsent>
<prevsent>speech recognition is performed by the sphinx ii speech recognizer (huang et al, 1992).
</prevsent>
</prevsection>
<citsent citstr=" H94-1039 ">
the phoenix parser (ward and issar, 1994) <papid> H94-1039 </papid>is in charge of natural language understanding.</citsent>
<aftsection>
<nextsent>the dialogue manager is based on the raven claw framework (bohus and rudnicky, 2003).
</nextsent>
<nextsent>natural language generation is done by simpletemplate-based generation module, and speech synthesis by the festival speech synthesis system (black et al,1998).
</nextsent>
<nextsent>the original system uses high quality limited domain voice recorded especially for the project but for some experiments, lower quality, more flexible voices figure 1: general architecture of the lets go!!
</nextsent>
<nextsent>bus information system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1963">
<title id=" N03-1026.xml">statistical sentence condensation using ambiguity packing and stochastic disambiguation methods for lexical functional grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>tuples.
</prevsent>
<prevsent>depending on the chosen task, such systems either generate single-sentence headlines?
</prevsent>
</prevsection>
<citsent citstr=" A00-1043 ">
for multi-sentence text (witbrock and mittal, 1999), or they provide sentence condensation module designed for combination with sentence extraction systems (knight and marcu, 2000; jing, 2000).<papid> A00-1043 </papid></citsent>
<aftsection>
<nextsent>the challenge for such systems is to guarantee the grammatical ity and summarization quality of the system output, i.e.the generated sentences need to be syntactically well formed and need to retain the most salient information of the original document.
</nextsent>
<nextsent>for example sentence extraction system might choose sentence like: the unix operating system, with implementations from apples to crays, appears to have the advantage.
</nextsent>
<nextsent>from document, which could be condensed as: unix appears to have the advantage.in the approach of witbrock and mittal (1999), selection and ordering of summary terms is based on bag of-words models and n-grams.
</nextsent>
<nextsent>such models may well produce summaries that are indicative of the originals content; however, n-gram models seem to be insufficient to guarantee grammatical well-formedness of the system output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1966">
<title id=" N03-1026.xml">statistical sentence condensation using ambiguity packing and stochastic disambiguation methods for lexical functional grammar </title>
<section> statistical sentence condensation in the.  </section>
<citcontext>
<prevsection>
<prevsent>lfg framework in this section, each of the system components will be described in more detail.
</prevsent>
<prevsent>2.1 parsing and transfer.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
in this project, broad-coverage lfg grammar and parser for english was employed (see riezler et al  (2002)).<papid> P02-1035 </papid></citsent>
<aftsection>
<nextsent>the parser produces set of context-free constituent (c-)structures and associated functional (f -)structures for each input sentence, represented in packed form (see maxwell and kaplan (1989)).
</nextsent>
<nextsent>for sentence condensation we are only interested in the predicate-argument structures encoded in -structures.
</nextsent>
<nextsent>for example, fig.
</nextsent>
<nextsent>1 shows an -structure manually selected out of the 40 -structures for the sentence: prototype is ready for testing, and leary hopes to set requirements for full system by the end of the year.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1967">
<title id=" N03-1026.xml">statistical sentence condensation using ambiguity packing and stochastic disambiguation methods for lexical functional grammar </title>
<section> statistical sentence condensation in the.  </section>
<citcontext>
<prevsection>
<prevsent>in case of fragmentary input to the transfer component, grammaticaliy of the output is guaranteed for the separate fragments.
</prevsent>
<prevsent>in other words, strings generated from reduced fragmentary -structure will be as grammatical as the string that was fed into the parsing component.after filtering by the generator, the remaining structures were weighted by the stochastic disambiguation component.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
similar to stochastic disambiguation for constraint-based parsing (johnson et al , 1999; <papid> P99-1069 </papid>riezler etal., 2002), <papid> P02-1035 </papid>an exponential (a.k.a. log-linear or maximumentropy) probability model on transferred structures is estimated from set of training data.</citsent>
<aftsection>
<nextsent>the data for estimation consists of pairs of original sentences and gold standard summarized -structures which were manually selected from the transfer output for each sentence.for training data {(sj , yj)}mj=1 and set of possible summarized structures s(y) for each sentence y, the objective was to maximize discriminative criterion, namely the conditional likelihood l(?)
</nextsent>
<nextsent>of summarized -structure given the sentence.
</nextsent>
<nextsent>optimization of the function shown below was performed using conjugate gradient optimization routine: l(?)
</nextsent>
<nextsent>= log m?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1972">
<title id=" N03-1026.xml">statistical sentence condensation using ambiguity packing and stochastic disambiguation methods for lexical functional grammar </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>inthe given test set, however, the condensation task restricted to the operation of deletion.
</prevsent>
<prevsent>a creation of additional condensations for the original sentences other than the condensed versions extracted from the human-writtenabstracts would provide more diverse test set, and furthermore make it possible to match each system output against any number of independent human-written con dens ations of the same original sentence.
</prevsent>
</prevsection>
<citsent citstr=" P98-1006 ">
this idea of computing matching scores to multiple reference examples was proposed by alshawi et al  (1998), <papid> P98-1006 </papid>and later by papineni et al  (2001) for evaluation of machine translation systems.</citsent>
<aftsection>
<nextsent>similar to these proposals, an evaluation of condensation quality could consider multiple reference condensations and record the matching score against the most similar example.
</nextsent>
<nextsent>another desideratum for future work is to carry condensation all the way through without unpacking at any stage.
</nextsent>
<nextsent>work on employing packing technique snot only for parsing and transfer, but also for generation and stochastic selection is currently underway (see geman and johnson (2002)).<papid> P02-1036 </papid></nextsent>
<nextsent>this will eventually lead toa system whose components work on packed representations of all or n-best solutions, but completely avoid costly unpacking of representations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1973">
<title id=" N03-1026.xml">statistical sentence condensation using ambiguity packing and stochastic disambiguation methods for lexical functional grammar </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>similar to these proposals, an evaluation of condensation quality could consider multiple reference condensations and record the matching score against the most similar example.
</prevsent>
<prevsent>another desideratum for future work is to carry condensation all the way through without unpacking at any stage.
</prevsent>
</prevsection>
<citsent citstr=" P02-1036 ">
work on employing packing technique snot only for parsing and transfer, but also for generation and stochastic selection is currently underway (see geman and johnson (2002)).<papid> P02-1036 </papid></citsent>
<aftsection>
<nextsent>this will eventually lead toa system whose components work on packed representations of all or n-best solutions, but completely avoid costly unpacking of representations.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1974">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>shallow parsing identifies the non-recursive cores of various phrase types intext, possibly as precursor to full parsing or information extraction (abney, 1991).
</prevsent>
<prevsent>the paradigmatic shallow parsing problem is np chunking, which finds the non recursive cores of noun phrases called base nps.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
the pioneering work of ramshaw and marcus (1995) <papid> W95-0107 </papid>introduced np chunking as machine-learning problem, with standard datasets and evaluation metrics.</citsent>
<aftsection>
<nextsent>the taskwas extended to additional phrase types for the conll 2000 shared task (tjong kim sang and buchholz, 2000), which is now the standard evaluation task for shallow parsing.
</nextsent>
<nextsent>most previous work used two main machine-learningapproaches to sequence labeling.
</nextsent>
<nextsent>the first approach relies on k-order generative probabilistic models of paired input sequences and label sequences, for instance hidden markov models (hmms) (freitag and mccallum, 2000; kupiec, 1992) or multilevel markov models (bikel et al, 1999).
</nextsent>
<nextsent>the second approach views the sequence labeling problem as sequence of classification problems, one foreach of the labels in the sequence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1976">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, it is not practical to make the label at given position depend on window on the in put sequence as well as the surrounding labels, since the inference problem for the corresponding graphical model would be intractable.
</prevsent>
<prevsent>non-independent features of the inputs, such as capitalization, suffixes, and surrounding words, are important in dealing with words unseen in training, but they are difficult to represent in generative models.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the sequential classification approach can handle many correlated features, as demonstrated in work on maximum-entropy (mccallum et al, 2000; ratnaparkhi, 1996) <papid> W96-0213 </papid>and variety of other linear classifiers, including winnow (punyakanok and roth, 2001), ada boost (ab ney et al, 1999), <papid> W99-0606 </papid>and support-vector machines (kudo and matsumoto, 2001).<papid> N01-1025 </papid></citsent>
<aftsection>
<nextsent>furthermore, they are trained to minimize some function related to labeling error, leading to smaller error in practice if enough training data are available.
</nextsent>
<nextsent>in contrast, generative models are trained to maximize the joint probability of the training data, which is 1ramshaw and marcus (1995) <papid> W95-0107 </papid>used transformation-based learning (brill, 1995), <papid> J95-4004 </papid>which for the present purposes can be tought of as classification-based method.</nextsent>
<nextsent>edmonton, may-june 2003 main papers , pp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1977">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, it is not practical to make the label at given position depend on window on the in put sequence as well as the surrounding labels, since the inference problem for the corresponding graphical model would be intractable.
</prevsent>
<prevsent>non-independent features of the inputs, such as capitalization, suffixes, and surrounding words, are important in dealing with words unseen in training, but they are difficult to represent in generative models.
</prevsent>
</prevsection>
<citsent citstr=" W99-0606 ">
the sequential classification approach can handle many correlated features, as demonstrated in work on maximum-entropy (mccallum et al, 2000; ratnaparkhi, 1996) <papid> W96-0213 </papid>and variety of other linear classifiers, including winnow (punyakanok and roth, 2001), ada boost (ab ney et al, 1999), <papid> W99-0606 </papid>and support-vector machines (kudo and matsumoto, 2001).<papid> N01-1025 </papid></citsent>
<aftsection>
<nextsent>furthermore, they are trained to minimize some function related to labeling error, leading to smaller error in practice if enough training data are available.
</nextsent>
<nextsent>in contrast, generative models are trained to maximize the joint probability of the training data, which is 1ramshaw and marcus (1995) <papid> W95-0107 </papid>used transformation-based learning (brill, 1995), <papid> J95-4004 </papid>which for the present purposes can be tought of as classification-based method.</nextsent>
<nextsent>edmonton, may-june 2003 main papers , pp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1978">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, it is not practical to make the label at given position depend on window on the in put sequence as well as the surrounding labels, since the inference problem for the corresponding graphical model would be intractable.
</prevsent>
<prevsent>non-independent features of the inputs, such as capitalization, suffixes, and surrounding words, are important in dealing with words unseen in training, but they are difficult to represent in generative models.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
the sequential classification approach can handle many correlated features, as demonstrated in work on maximum-entropy (mccallum et al, 2000; ratnaparkhi, 1996) <papid> W96-0213 </papid>and variety of other linear classifiers, including winnow (punyakanok and roth, 2001), ada boost (ab ney et al, 1999), <papid> W99-0606 </papid>and support-vector machines (kudo and matsumoto, 2001).<papid> N01-1025 </papid></citsent>
<aftsection>
<nextsent>furthermore, they are trained to minimize some function related to labeling error, leading to smaller error in practice if enough training data are available.
</nextsent>
<nextsent>in contrast, generative models are trained to maximize the joint probability of the training data, which is 1ramshaw and marcus (1995) <papid> W95-0107 </papid>used transformation-based learning (brill, 1995), <papid> J95-4004 </papid>which for the present purposes can be tought of as classification-based method.</nextsent>
<nextsent>edmonton, may-june 2003 main papers , pp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1981">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the sequential classification approach can handle many correlated features, as demonstrated in work on maximum-entropy (mccallum et al, 2000; ratnaparkhi, 1996) <papid> W96-0213 </papid>and variety of other linear classifiers, including winnow (punyakanok and roth, 2001), ada boost (ab ney et al, 1999), <papid> W99-0606 </papid>and support-vector machines (kudo and matsumoto, 2001).<papid> N01-1025 </papid></prevsent>
<prevsent>furthermore, they are trained to minimize some function related to labeling error, leading to smaller error in practice if enough training data are available.</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
in contrast, generative models are trained to maximize the joint probability of the training data, which is 1ramshaw and marcus (1995) <papid> W95-0107 </papid>used transformation-based learning (brill, 1995), <papid> J95-4004 </papid>which for the present purposes can be tought of as classification-based method.</citsent>
<aftsection>
<nextsent>edmonton, may-june 2003 main papers , pp.
</nextsent>
<nextsent>134-141 proceedings of hlt-naacl 2003 not as closely tied to the accuracy metrics of interest if the actual data was not generated by the model, as is always the case in practice.
</nextsent>
<nextsent>however, since sequential classifiers are trained tomake the best local decision, unlike generative models they cannot trade off decisions at different positions against each other.
</nextsent>
<nextsent>in other words, sequential classifiers are myopic about the impact of their current decision on later decisions (bottou, 1991; lafferty et al, 2001).this forced the best sequential classifier systems to resort to heuristic combinations of forward-moving andbackward-moving sequential classifiers (kudo and matsumoto, 2001).<papid> N01-1025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1984">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to obtain these results, we had to abandon the original iterative scaling crf training algorithm for convex optimization algorithms with better convergence properties.
</prevsent>
<prevsent>we provide detailed comparisons between training methods.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
the generalized perceptron proposed by collins(2002) <papid> W02-1001 </papid>is closely related to crfs, but the best crf training methods seem to have slight edge over the generalized perceptron.</citsent>
<aftsection>
<nextsent>we focus here on conditional random fields on sequences,although the notion can be used more generally (laf ferty et al, 2001; taskar et al, 2002).
</nextsent>
<nextsent>such crfs define conditional probability distributions p(y |x) of label sequences given input sequences.
</nextsent>
<nextsent>we assume that the random variable sequences and have the same length, and use = x1 ? ?
</nextsent>
<nextsent>xn and = y1 ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1985">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> training methods.  </section>
<citcontext>
<prevsection>
<prevsent>2 22 + const with gradient l??
</prevsent>
<prevsent>= ? [ (yk, xk) ? ep?(y |xk)f (y , xk) ] ? 2
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
lafferty et al (2001) used iterative scaling algorithms for crf training, following earlier work on maximum entropy models for natural language (berger et al, 1996;<papid> J96-1002 </papid>della pietra et al, 1997).</citsent>
<aftsection>
<nextsent>those methods are very simple and guaranteed to converge, but as minka (2001) and malouf (2002) <papid> W02-2018 </papid>showed for classification, their convergence is much slower than that of general-purpose convex optimization algorithms when many correlated features are involved.</nextsent>
<nextsent>concurrently with the present work, wallach (2002) tested conjugate gradient and second-order methods for crf training, showing significant training speed advantages over iterative scaling on small shallow parsing problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1986">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> training methods.  </section>
<citcontext>
<prevsection>
<prevsent>= ? [ (yk, xk) ? ep?(y |xk)f (y , xk) ] ? 2
</prevsent>
<prevsent>lafferty et al (2001) used iterative scaling algorithms for crf training, following earlier work on maximum entropy models for natural language (berger et al, 1996;<papid> J96-1002 </papid>della pietra et al, 1997).</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
those methods are very simple and guaranteed to converge, but as minka (2001) and malouf (2002) <papid> W02-2018 </papid>showed for classification, their convergence is much slower than that of general-purpose convex optimization algorithms when many correlated features are involved.</citsent>
<aftsection>
<nextsent>concurrently with the present work, wallach (2002) tested conjugate gradient and second-order methods for crf training, showing significant training speed advantages over iterative scaling on small shallow parsing problem.
</nextsent>
<nextsent>our work shows that preconditioned conjugate-gradient (cg) (shewchuk, 1994) or limited-memory quasi-newton (l-bfgs) (nocedal and wright, 1999) perform comparably on very large problems (around 3.8 million features).
</nextsent>
<nextsent>we compare those algorithms to generalized iterative scaling (gis) (dar roch and rat cliff, 1972), non-preconditioned cg, and voted perceptron training (collins, 2002).<papid> W02-1001 </papid></nextsent>
<nextsent>all algorithms except voted perceptron maximize the penalized log likelihood: ??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O1998">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> shallow parsing.  </section>
<citcontext>
<prevsection>
<prevsent>we report scores for comparison with previous work, but we also give statistical significance estimates using mcnemars test for those methods that we evaluated directly.
</prevsent>
<prevsent>testing the significance of scores is tricky because the wrong chunks generated by two chunk ers are not directly comparable.
</prevsent>
</prevsection>
<citsent citstr=" C00-2137 ">
yeh (2000) <papid> C00-2137 </papid>examined randomized tests for estimating the significance of scores, and in particular the bootstrap over the test set (efron and tibshirani, 1993; sang, 2002).</citsent>
<aftsection>
<nextsent>however, bootstrap variances in preliminary experiments were too high to allow any conclusions, so we used instead mcnemar paired test on labeling disagreements (gillick and cox, 1989).
</nextsent>
<nextsent>model score svm combination 94.39% (kudo and matsumoto, 2001) <papid> N01-1025 </papid>crf 94.38% generalized winnow 93.89% (zhang et al, 2002) voted perceptron 94.09% memm 93.70% table 2: np chunking scores</nextsent>
<nextsent>all the experiments were performed with our java implementation of crfs,designed to handle millions of features, on 1.7 ghz pentium iv processors with linux and ibm java 1.3.0.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2008">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>in longer version of this work we will also describe shallow parsing results for other phrase types.
</prevsent>
<prevsent>there is no reason why the same techniques cannot be used equally successfully for the other types or for other related tasks, such as pos tagging or named-entity recognition.on the machine-learning side, it would be interesting to generalize the ideas of large-margin classification to sequence models, strengthening the results of collins (2002) <papid> W02-1001 </papid>and leading to new optimal training algorithms with stronger guarantees against overfitting.</prevsent>
</prevsection>
<citsent citstr=" W97-0301 ">
on the application side, (log-)linear parsing models have the potential to supplant the currently dominant lexicalized pcfg models for parsing by allowing much richer feature sets and simpler smoothing, while avoiding the label bias problem that may have hindered earlier classifier-based parsers (ratnaparkhi, 1997).<papid> W97-0301 </papid></citsent>
<aftsection>
<nextsent>however, work in that direction has so far addressed only parse reranking (collins and duffy, 2002; <papid> P02-1034 </papid>riezler et al, 2002).<papid> P02-1035 </papid>full discriminative parser training faces significant algorithmic challenges in the relationship between parsing alternatives and feature values (geman and johnson, 2002) <papid> P02-1036 </papid>and in computing feature expectations.</nextsent>
<nextsent>acknowledgments john lafferty and andrew mccallum worked with the second author on developing crfs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2009">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>there is no reason why the same techniques cannot be used equally successfully for the other types or for other related tasks, such as pos tagging or named-entity recognition.on the machine-learning side, it would be interesting to generalize the ideas of large-margin classification to sequence models, strengthening the results of collins (2002) <papid> W02-1001 </papid>and leading to new optimal training algorithms with stronger guarantees against overfitting.</prevsent>
<prevsent>on the application side, (log-)linear parsing models have the potential to supplant the currently dominant lexicalized pcfg models for parsing by allowing much richer feature sets and simpler smoothing, while avoiding the label bias problem that may have hindered earlier classifier-based parsers (ratnaparkhi, 1997).<papid> W97-0301 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
however, work in that direction has so far addressed only parse reranking (collins and duffy, 2002; <papid> P02-1034 </papid>riezler et al, 2002).<papid> P02-1035 </papid>full discriminative parser training faces significant algorithmic challenges in the relationship between parsing alternatives and feature values (geman and johnson, 2002) <papid> P02-1036 </papid>and in computing feature expectations.</citsent>
<aftsection>
<nextsent>acknowledgments john lafferty and andrew mccallum worked with the second author on developing crfs.
</nextsent>
<nextsent>mccallum helped by the second author implemented the first conjugate gradient trainer for crfs, which convinced us that training of large crfs on large datasets would be practical.michael collins helped us reproduce his generalized per cepton results and compare his method with ours.
</nextsent>
<nextsent>eriktjong kim sang, who has created the best online resources on shallow parsing, helped us with details of theconll-2000 shared task.
</nextsent>
<nextsent>taku kudo provided the out put of his svm chunker for the significance test.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2010">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>there is no reason why the same techniques cannot be used equally successfully for the other types or for other related tasks, such as pos tagging or named-entity recognition.on the machine-learning side, it would be interesting to generalize the ideas of large-margin classification to sequence models, strengthening the results of collins (2002) <papid> W02-1001 </papid>and leading to new optimal training algorithms with stronger guarantees against overfitting.</prevsent>
<prevsent>on the application side, (log-)linear parsing models have the potential to supplant the currently dominant lexicalized pcfg models for parsing by allowing much richer feature sets and simpler smoothing, while avoiding the label bias problem that may have hindered earlier classifier-based parsers (ratnaparkhi, 1997).<papid> W97-0301 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
however, work in that direction has so far addressed only parse reranking (collins and duffy, 2002; <papid> P02-1034 </papid>riezler et al, 2002).<papid> P02-1035 </papid>full discriminative parser training faces significant algorithmic challenges in the relationship between parsing alternatives and feature values (geman and johnson, 2002) <papid> P02-1036 </papid>and in computing feature expectations.</citsent>
<aftsection>
<nextsent>acknowledgments john lafferty and andrew mccallum worked with the second author on developing crfs.
</nextsent>
<nextsent>mccallum helped by the second author implemented the first conjugate gradient trainer for crfs, which convinced us that training of large crfs on large datasets would be practical.michael collins helped us reproduce his generalized per cepton results and compare his method with ours.
</nextsent>
<nextsent>eriktjong kim sang, who has created the best online resources on shallow parsing, helped us with details of theconll-2000 shared task.
</nextsent>
<nextsent>taku kudo provided the out put of his svm chunker for the significance test.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2011">
<title id=" N03-1028.xml">shallow parsing with conditional random fields </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>there is no reason why the same techniques cannot be used equally successfully for the other types or for other related tasks, such as pos tagging or named-entity recognition.on the machine-learning side, it would be interesting to generalize the ideas of large-margin classification to sequence models, strengthening the results of collins (2002) <papid> W02-1001 </papid>and leading to new optimal training algorithms with stronger guarantees against overfitting.</prevsent>
<prevsent>on the application side, (log-)linear parsing models have the potential to supplant the currently dominant lexicalized pcfg models for parsing by allowing much richer feature sets and simpler smoothing, while avoiding the label bias problem that may have hindered earlier classifier-based parsers (ratnaparkhi, 1997).<papid> W97-0301 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1036 ">
however, work in that direction has so far addressed only parse reranking (collins and duffy, 2002; <papid> P02-1034 </papid>riezler et al, 2002).<papid> P02-1035 </papid>full discriminative parser training faces significant algorithmic challenges in the relationship between parsing alternatives and feature values (geman and johnson, 2002) <papid> P02-1036 </papid>and in computing feature expectations.</citsent>
<aftsection>
<nextsent>acknowledgments john lafferty and andrew mccallum worked with the second author on developing crfs.
</nextsent>
<nextsent>mccallum helped by the second author implemented the first conjugate gradient trainer for crfs, which convinced us that training of large crfs on large datasets would be practical.michael collins helped us reproduce his generalized per cepton results and compare his method with ours.
</nextsent>
<nextsent>eriktjong kim sang, who has created the best online resources on shallow parsing, helped us with details of theconll-2000 shared task.
</nextsent>
<nextsent>taku kudo provided the out put of his svm chunker for the significance test.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2012">
<title id=" N03-2017.xml">word alignment with cohesion constraint </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the (arguably) most striking characteristic of the ibm-style smt models is their total lack of linguistic knowledge.
</prevsent>
<prevsent>the ibm models demonstrated how much one can do with pure statistical techniques,which have inspired whole new generation of nlp research and systems.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
more recently, there have been many proposals to introduce syntactic knowledge into smt models (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>lopez et al, 2002).</citsent>
<aftsection>
<nextsent>a common theme among these approaches is the assumption that the syntactic structures of pair of source-target sentences are isomor phic (or nearly isomorphic).
</nextsent>
<nextsent>this assumption seems toostrong.
</nextsent>
<nextsent>human translators often use non-literal translations, which result in differences in syntactic structures.according to study in (dorr et al, 2002), such translational divergences are quite common, involving 11-31% of the sentences.
</nextsent>
<nextsent>we introduce constraint that uses the dependency tree of the english sentence to maintain phrasal cohesion in the french sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2013">
<title id=" N03-2017.xml">word alignment with cohesion constraint </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the (arguably) most striking characteristic of the ibm-style smt models is their total lack of linguistic knowledge.
</prevsent>
<prevsent>the ibm models demonstrated how much one can do with pure statistical techniques,which have inspired whole new generation of nlp research and systems.
</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
more recently, there have been many proposals to introduce syntactic knowledge into smt models (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>lopez et al, 2002).</citsent>
<aftsection>
<nextsent>a common theme among these approaches is the assumption that the syntactic structures of pair of source-target sentences are isomor phic (or nearly isomorphic).
</nextsent>
<nextsent>this assumption seems toostrong.
</nextsent>
<nextsent>human translators often use non-literal translations, which result in differences in syntactic structures.according to study in (dorr et al, 2002), such translational divergences are quite common, involving 11-31% of the sentences.
</nextsent>
<nextsent>we introduce constraint that uses the dependency tree of the english sentence to maintain phrasal cohesion in the french sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2014">
<title id=" N03-2017.xml">word alignment with cohesion constraint </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the (arguably) most striking characteristic of the ibm-style smt models is their total lack of linguistic knowledge.
</prevsent>
<prevsent>the ibm models demonstrated how much one can do with pure statistical techniques,which have inspired whole new generation of nlp research and systems.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
more recently, there have been many proposals to introduce syntactic knowledge into smt models (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>lopez et al, 2002).</citsent>
<aftsection>
<nextsent>a common theme among these approaches is the assumption that the syntactic structures of pair of source-target sentences are isomor phic (or nearly isomorphic).
</nextsent>
<nextsent>this assumption seems toostrong.
</nextsent>
<nextsent>human translators often use non-literal translations, which result in differences in syntactic structures.according to study in (dorr et al, 2002), such translational divergences are quite common, involving 11-31% of the sentences.
</nextsent>
<nextsent>we introduce constraint that uses the dependency tree of the english sentence to maintain phrasal cohesion in the french sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2015">
<title id=" N03-2017.xml">word alignment with cohesion constraint </title>
<section> cohesion constraint.  </section>
<citcontext>
<prevsection>
<prevsent>we call such pairs links.
</prevsent>
<prevsent>in figure 2, the links in the alignment are represented by dashed lines.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
the reboot causes the host to discover all the devices det subj det subj aux pre det obj comp ? la suite rinitialisation ,  hte repre tous les priphriques 1 2 3 4 5 6 7 8 9 10 1 2 3 4 5 6 7 8 9 10 11 after to the reboot the host locate all the peripherals figure 2: an example pair of aligned sentence the cohesion constraint (fox, 2002) <papid> W02-1039 </papid>uses the dependency tree te (melcuk, 1987) of the english sentence to restrict possible link combinations.</citsent>
<aftsection>
<nextsent>let te(ei) be the subtree of te rooted at ei.
</nextsent>
<nextsent>the phrase span of ei, spanp (ei, te , a), is the image of the english phrase headed by ei in given (partial) alignment a. more precisely, spanp (ei, te , a) = [k1, k2], where k1 = min{j|(u, j) ? a, eu ? te(ei)} k2 = max{j|(u, j) ? a, eu ? te(ei)} the head span is the image of ei itself.
</nextsent>
<nextsent>we define spanh(ei, te , a) = [k1, k2], where k1 = min{j|(i, j) ? a} k2 = max{j|(i, j) ? a} in figure 2, the phrase span of the node discover is [6, 11] and the head span is [8, 8]; the phrase span of the node reboot is [3, 4] and the head span is [4, 4].
</nextsent>
<nextsent>the word cause has phrase span of [3,11] and its head span is the empty set ?.with these definitions of phrase and head spans, we define two notions of overlap, originally introduced in (fox,2002) <papid> W02-1039 </papid>as crossings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2019">
<title id=" N03-2017.xml">word alignment with cohesion constraint </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we will describe the versions without cohesion constraint below.
</prevsent>
<prevsent>for the versions with cohesion constraint, it is understood tha teach new link must also pass the test described in section 2.
</prevsent>
</prevsection>
<citsent citstr=" P97-1063 ">
the first algorithm is similar to competitive linking (melamed, 1997).<papid> P97-1063 </papid></citsent>
<aftsection>
<nextsent>we use sentence-aligned corpus to compute the 2 correlation metric (gale and church, 1991) <papid> H91-1026 </papid>between all english-french word pairs.</nextsent>
<nextsent>forgiven sentence pair, we begin with an empty alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2020">
<title id=" N03-2017.xml">word alignment with cohesion constraint </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>for the versions with cohesion constraint, it is understood tha teach new link must also pass the test described in section 2.
</prevsent>
<prevsent>the first algorithm is similar to competitive linking (melamed, 1997).<papid> P97-1063 </papid></prevsent>
</prevsection>
<citsent citstr=" H91-1026 ">
we use sentence-aligned corpus to compute the 2 correlation metric (gale and church, 1991) <papid> H91-1026 </papid>between all english-french word pairs.</citsent>
<aftsection>
<nextsent>forgiven sentence pair, we begin with an empty alignment.
</nextsent>
<nextsent>we then add links in the order of their 2 scores so that each word participates in at most one link.
</nextsent>
<nextsent>we will refer to this as the 2 method.
</nextsent>
<nextsent>the second algorithm uses best-first search (with fixed beam width and agenda size) to find an alignment that maximizes (a|e,f ).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2021">
<title id=" N03-2017.xml">word alignment with cohesion constraint </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the algorithm then re-aligns the corpus and trains again for three iterations.
</prevsent>
<prevsent>we will refer to this as the (a|e,f ) method.
</prevsent>
</prevsection>
<citsent citstr=" P03-1012 ">
the details of this algorithm are described in (cherry and lin, 2003).<papid> P03-1012 </papid></citsent>
<aftsection>
<nextsent>we trained our alignment programs with the same 50k pairs of sentences as (och and ney, 2000) <papid> P00-1056 </papid>and tested it onthe same 500 manually aligned sentences.</nextsent>
<nextsent>both the training and testing sentences are from the hansard corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2022">
<title id=" N03-2017.xml">word alignment with cohesion constraint </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we will refer to this as the (a|e,f ) method.
</prevsent>
<prevsent>the details of this algorithm are described in (cherry and lin, 2003).<papid> P03-1012 </papid></prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we trained our alignment programs with the same 50k pairs of sentences as (och and ney, 2000) <papid> P00-1056 </papid>and tested it onthe same 500 manually aligned sentences.</citsent>
<aftsection>
<nextsent>both the training and testing sentences are from the hansard corpus.
</nextsent>
<nextsent>we parsed the training and testing corpora with minipar.1 we adopted the evaluation methodology in (och and ney, 2000), <papid> P00-1056 </papid>which defines three metrics: precision, recall and alignment error rate (aer).</nextsent>
<nextsent>table 1 shows the results of our experiments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2030">
<title id=" N06-2049.xml">subwordbased tagging by conditional random fields for chinese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by these techniques we achieved higher f-scores in cityu, pku and msr corpora than the best results from sighan bakeoff 2005.
</prevsent>
<prevsent>the character-based iob?
</prevsent>
</prevsection>
<citsent citstr=" W03-1728 ">
tagging approach has been widely used in chinese word segmentation recently (xue and shen, 2003; <papid> W03-1728 </papid>peng and mccallum, 2004; tseng et al, 2005).<papid> I05-3027 </papid></citsent>
<aftsection>
<nextsent>under the scheme, each character of word is labeled as b? if it is the first character of amultiple-character word, or o? if the character functions as an independent word, or i? otherwise.?
</nextsent>
<nextsent>forex ample, ?
</nextsent>
<nextsent>(whole) (beijing city)?
</nextsent>
<nextsent>is labeled as ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2031">
<title id=" N06-2049.xml">subwordbased tagging by conditional random fields for chinese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by these techniques we achieved higher f-scores in cityu, pku and msr corpora than the best results from sighan bakeoff 2005.
</prevsent>
<prevsent>the character-based iob?
</prevsent>
</prevsection>
<citsent citstr=" I05-3027 ">
tagging approach has been widely used in chinese word segmentation recently (xue and shen, 2003; <papid> W03-1728 </papid>peng and mccallum, 2004; tseng et al, 2005).<papid> I05-3027 </papid></citsent>
<aftsection>
<nextsent>under the scheme, each character of word is labeled as b? if it is the first character of amultiple-character word, or o? if the character functions as an independent word, or i? otherwise.?
</nextsent>
<nextsent>forex ample, ?
</nextsent>
<nextsent>(whole) (beijing city)?
</nextsent>
<nextsent>is labeled as ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2032">
<title id=" N06-2049.xml">subwordbased tagging by conditional random fields for chinese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>? now the second author is affiliated with ntt.
</prevsent>
<prevsent>in addition, we found clear weakness with the iob tagging approach: it yields very low in-vocabulary (iv) rate (r-iv) in return for higher out-of-vocabulary (oov) rate (r-oov).
</prevsent>
</prevsection>
<citsent citstr=" I05-3017 ">
in the results of the closed test in bakeoff 2005 (emerson, 2005), <papid> I05-3017 </papid>the work of (tseng et al, 2005),<papid> I05-3027 </papid>using conditional random fields (crf) for the iob tagging, yielded very high r-oovs in all of the four corpora used, but the r-iv rates were lower.</citsent>
<aftsection>
<nextsent>while oov recognition is very important in word segmentation, higheriv rate is also desired.
</nextsent>
<nextsent>in this work we propose confidence measure approach to lessen the weakness.
</nextsent>
<nextsent>by this approach we can change r-oovs and r-ivs and find an optimal tradeoff.
</nextsent>
<nextsent>this approach will be described in section 2.2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2036">
<title id=" N03-1031.xml">example selection for bootstrapping statistical parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we propose several selection methods based on the criteria of minimizing errors in the data and maximizing training utility.
</prevsent>
<prevsent>we show that incorporating the utility criterion into the selection method results in better parsers for both frameworks.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
current state-of-the-art statistical parsers (collins, 1999; charniak, 2000) <papid> A00-2018 </papid>are trained on large annotated corpora such as the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>how ever, the production of such corpora is expensive andlabor-intensive.
</nextsent>
<nextsent>given this bottleneck, there is considerable interest in (partially) automating the annotation pro cess.to overcome this bottleneck, two approaches from machine learning have been applied to training parsers.
</nextsent>
<nextsent>one is sample selection (thompson et al, 1999; hwa, 2000; <papid> W00-1306 </papid>tang et al, 2002), <papid> P02-1016 </papid>variant of active learning (cohn et al,1994), which tries to identify small set of unlabeled sentences with high training utility for the human to label1.</nextsent>
<nextsent>sentences with high training utility are those most likely to improve the parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2037">
<title id=" N03-1031.xml">example selection for bootstrapping statistical parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we propose several selection methods based on the criteria of minimizing errors in the data and maximizing training utility.
</prevsent>
<prevsent>we show that incorporating the utility criterion into the selection method results in better parsers for both frameworks.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
current state-of-the-art statistical parsers (collins, 1999; charniak, 2000) <papid> A00-2018 </papid>are trained on large annotated corpora such as the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>how ever, the production of such corpora is expensive andlabor-intensive.
</nextsent>
<nextsent>given this bottleneck, there is considerable interest in (partially) automating the annotation pro cess.to overcome this bottleneck, two approaches from machine learning have been applied to training parsers.
</nextsent>
<nextsent>one is sample selection (thompson et al, 1999; hwa, 2000; <papid> W00-1306 </papid>tang et al, 2002), <papid> P02-1016 </papid>variant of active learning (cohn et al,1994), which tries to identify small set of unlabeled sentences with high training utility for the human to label1.</nextsent>
<nextsent>sentences with high training utility are those most likely to improve the parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2038">
<title id=" N03-1031.xml">example selection for bootstrapping statistical parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, the production of such corpora is expensive andlabor-intensive.
</prevsent>
<prevsent>given this bottleneck, there is considerable interest in (partially) automating the annotation pro cess.to overcome this bottleneck, two approaches from machine learning have been applied to training parsers.
</prevsent>
</prevsection>
<citsent citstr=" W00-1306 ">
one is sample selection (thompson et al, 1999; hwa, 2000; <papid> W00-1306 </papid>tang et al, 2002), <papid> P02-1016 </papid>variant of active learning (cohn et al,1994), which tries to identify small set of unlabeled sentences with high training utility for the human to label1.</citsent>
<aftsection>
<nextsent>sentences with high training utility are those most likely to improve the parser.
</nextsent>
<nextsent>the other approach, and the focus of this paper, is co-training (sarkar, 2001), <papid> N01-1023 </papid>mostly unsupervised algorithm that replaces the human by having two (or more) parsers label training examples for eachother.</nextsent>
<nextsent>the goal is for both parsers to improve by bootstrapping off each others strengths.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2040">
<title id=" N03-1031.xml">example selection for bootstrapping statistical parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, the production of such corpora is expensive andlabor-intensive.
</prevsent>
<prevsent>given this bottleneck, there is considerable interest in (partially) automating the annotation pro cess.to overcome this bottleneck, two approaches from machine learning have been applied to training parsers.
</prevsent>
</prevsection>
<citsent citstr=" P02-1016 ">
one is sample selection (thompson et al, 1999; hwa, 2000; <papid> W00-1306 </papid>tang et al, 2002), <papid> P02-1016 </papid>variant of active learning (cohn et al,1994), which tries to identify small set of unlabeled sentences with high training utility for the human to label1.</citsent>
<aftsection>
<nextsent>sentences with high training utility are those most likely to improve the parser.
</nextsent>
<nextsent>the other approach, and the focus of this paper, is co-training (sarkar, 2001), <papid> N01-1023 </papid>mostly unsupervised algorithm that replaces the human by having two (or more) parsers label training examples for eachother.</nextsent>
<nextsent>the goal is for both parsers to improve by bootstrapping off each others strengths.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2041">
<title id=" N03-1031.xml">example selection for bootstrapping statistical parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one is sample selection (thompson et al, 1999; hwa, 2000; <papid> W00-1306 </papid>tang et al, 2002), <papid> P02-1016 </papid>variant of active learning (cohn et al,1994), which tries to identify small set of unlabeled sentences with high training utility for the human to label1.</prevsent>
<prevsent>sentences with high training utility are those most likely to improve the parser.</prevsent>
</prevsection>
<citsent citstr=" N01-1023 ">
the other approach, and the focus of this paper, is co-training (sarkar, 2001), <papid> N01-1023 </papid>mostly unsupervised algorithm that replaces the human by having two (or more) parsers label training examples for eachother.</citsent>
<aftsection>
<nextsent>the goal is for both parsers to improve by bootstrapping off each others strengths.
</nextsent>
<nextsent>because the parsers may label examples incorrectly, only subset of their output, chosen by some selection mechanism, is used in order to minimize errors.
</nextsent>
<nextsent>the choice of selection method significantly affects the quality of the resulting parsers.
</nextsent>
<nextsent>we investigate novel approach of selecting training examples for co-training parsers by incorporating the idea of maximizing training utility from sample selection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2042">
<title id=" N03-1031.xml">example selection for bootstrapping statistical parsers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the selection mechanism is integral to both sample selection and co-training; however, because co-training and sample selection have different goals, their selection methods focus on different criteria: co-training typically favors selecting accurately labeled examples, while sample selection typically favors selecting examples with high training utility, which often are not sentences that the parsers already label accurately.
</prevsent>
<prevsent>in this work, we investigate selection methods for co-training that explore the trade-offbetween maximizing training utility and minimizing errors.
</prevsent>
</prevsection>
<citsent citstr=" W01-0501 ">
empirical studies were conducted to compare selection methods under both co-training and semi-supervised framework called corrected co-training (pierce andcardie, 2001), <papid> W01-0501 </papid>in which the selected examples are manually checked and corrected before being added to the 1in the context of training parsers, labeled example is sentence with its parse tree.</citsent>
<aftsection>
<nextsent>throughout this paper, we use the term label?
</nextsent>
<nextsent>and parse?
</nextsent>
<nextsent>interchangeably.
</nextsent>
<nextsent>edmonton, may-june 2003 main papers , pp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2043">
<title id=" N03-1031.xml">example selection for bootstrapping statistical parsers </title>
<section> co-training.  </section>
<citcontext>
<prevsection>
<prevsent>blum and mitchell prove that, when the two views are conditionally independent given the label, and each view is sufficient for learning the task, co-training can boost an initial weak learner using unlabeled data.
</prevsent>
<prevsent>the theory underlying co-training has been extended by dasgupta et al (2002) to prove that, by maximizing their agreement over the unlabeled data, the two learners make few generalization errors (under the same independence assumption adopted by blum and mitchell).
</prevsent>
</prevsection>
<citsent citstr=" P02-1046 ">
abney (2002) <papid> P02-1046 </papid>argues that this assumption is extremely strong and typically violated in the data, and he proposes weaker independence assumption.goldman and zhou (2000) show that, through careful selection of newly labeled examples, co-training can work even when the classifiers?</citsent>
<aftsection>
<nextsent>views do not satisfy the independence assumption.
</nextsent>
<nextsent>in this paper we investigate methods for selecting labeled examples produced by two statistical parsers.
</nextsent>
<nextsent>we do not explicitly maximize agreement (along the lines of abneys algorithm (2002)) because it is too computationally intensive for training parsers.
</nextsent>
<nextsent>the pseudo code for our co-training framework is givenin figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2044">
<title id=" N03-1031.xml">example selection for bootstrapping statistical parsers </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the total pool of unlabeled sentences was there mainder of sections 2-21 (stripped of their annotations), consisting of about 38,000 sentences.
</prevsent>
<prevsent>the cache size is set at 500 sentences.
</prevsent>
</prevsection>
<citsent citstr=" E03-1008 ">
we have explored using different settings for the seed set size (steedman et al, 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>the parsers were evaluated on unseen test sentences (section 23 of the wsj corpus).
</nextsent>
<nextsent>section 0 was used asa development set for determining parameters.
</nextsent>
<nextsent>the evaluation metric is the parseval f-score over labeled con stituents: f-score = 2lrlplr+lp , where lp and lr are labeled precision and recall rate, respectively.
</nextsent>
<nextsent>both parsers were evaluated, but for brevity, all results reported here are for the collins parser, which received higher parseval scores.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2046">
<title id=" N03-1031.xml">example selection for bootstrapping statistical parsers </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>finally, in terms of reducing human effort, the three selection methods require the human to correct comparable amount of parser errors for the same level of parsing performance, but for sdiff-30% and sint-30%, fewer sentences need to be checked.
</prevsent>
<prevsent>4.3.3 discussion corrected co-training can be seen as form of active learning, whose goal is to identify the smallest set of unlabeled data with high training utility for the human to label.
</prevsent>
</prevsection>
<citsent citstr=" P96-1042 ">
active learning can be applied to single learner(lewis and catlett, 1994) and to multiple learners (fre und et al, 1997; engelson and dagan, 1996; <papid> P96-1042 </papid>ngai and yarowsky, 2000).<papid> P00-1016 </papid></citsent>
<aftsection>
<nextsent>in the context of parsing, all previous work (thompson et al, 1999; hwa, 2000; <papid> W00-1306 </papid>tang etal., 2002) <papid> P02-1016 </papid>has focussed on single learners.</nextsent>
<nextsent>corrected co training is the first application of active learning for multiple parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2047">
<title id=" N03-1031.xml">example selection for bootstrapping statistical parsers </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>finally, in terms of reducing human effort, the three selection methods require the human to correct comparable amount of parser errors for the same level of parsing performance, but for sdiff-30% and sint-30%, fewer sentences need to be checked.
</prevsent>
<prevsent>4.3.3 discussion corrected co-training can be seen as form of active learning, whose goal is to identify the smallest set of unlabeled data with high training utility for the human to label.
</prevsent>
</prevsection>
<citsent citstr=" P00-1016 ">
active learning can be applied to single learner(lewis and catlett, 1994) and to multiple learners (fre und et al, 1997; engelson and dagan, 1996; <papid> P96-1042 </papid>ngai and yarowsky, 2000).<papid> P00-1016 </papid></citsent>
<aftsection>
<nextsent>in the context of parsing, all previous work (thompson et al, 1999; hwa, 2000; <papid> W00-1306 </papid>tang etal., 2002) <papid> P02-1016 </papid>has focussed on single learners.</nextsent>
<nextsent>corrected co training is the first application of active learning for multiple parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2052">
<title id=" N03-4012.xml">automatic extraction of semantic networks from text using leximancer </title>
<section> unsupervised and supervised ontology discovery:.  </section>
<citcontext>
<prevsection>
<prevsent>this process looks for words near the centre of local maxima in the lexical co-occurrence network.
</prevsent>
<prevsent>is used to find the relevant thesaurus words from the text data.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
this iterative optimiser, derived from word disambiguation technique (yarowsky, 1995),<papid> P95-1026 </papid>finds the nearest local maximum in the lexical cooccurrence network from each concept seed.</citsent>
<aftsection>
<nextsent>early results show that this lexical network can be reduced to scale-free and small-world network1.
</nextsent>
<nextsent>4.
</nextsent>
<nextsent>classification: text is tagged with multiple concepts.
</nextsent>
<nextsent>using the thesaurus, to sentence resolution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2053">
<title id=" N03-2034.xml">building lexical semantic representations for natural language instructions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>whereas many nl applications use wordnet (fellbaum, 1998), we were in need of richer lexicon.
</prevsent>
<prevsent>we found corelex (buitelaar, 1998) appropriate for our needs.
</prevsent>
</prevsection>
<citsent citstr=" J91-4003 ">
corelex is based on different theory than levins (that of the generative lexicon (pustejovsky, 1991)), <papid> J91-4003 </papid>but does provide compatible decompositional meaning representation for nouns.</citsent>
<aftsection>
<nextsent>the contribution of our work is to demonstrate that meaning representation based on decompositional lexical semantics can be derived efficiently and effectively.
</nextsent>
<nextsent>we believe there is no other work that attaches semantics of this type to parser for large coverage corpus.
</nextsent>
<nextsent>verb net has been coupled with the tag formalism (kipperet al, 2000b), but no parsing results are available.
</nextsent>
<nextsent>more ( :morphology position :syntax (*or* ((cat n) (root position) (agr 3s) (semtag (*or* lap1 lap2))) ((cat vlex) (root position) (vform bare) (subcat (*or* np np-advp np-pp))(semtag put))) :semantics (put ( put-9.1  (subj agent) (obj patient) (modifier destination) (pred destination))) (lap1 ( lap1 )) (lap2 ( lap2 ))) figure 1: the entry for position in the lcflex lexicon class: put-9.1parent: members: arrange immerse lodge mount place position put set situate sling thematic roles: agt pat dest selectional restrictions: agt[+animate] pat[+concrete] dest[+location -region] frames: transitive with locative pp agt pat prep[+loc] dest cause(agt, e0) ^ motion(during(e0), pat) ^ :located-in(start(e0), pat, dest) ^ located-in(end(e0), pat, dest) transitive with locative adverb agt pat dest[+adv-loc] cause(agt, e0) ^ motion(during(e0), pat) ^ :located-in(start(e0), pat, dest) ^ located-in(end(e0), pat, dest) figure 2: the class put-9.1 from verbnet over, we also show that two lexical resources that focus on verbs and nouns can be successfully integrated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2054">
<title id=" N03-1036.xml">unsupervised methods for developing taxonomies by combining syntactic and statistical information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problem of enriching the lexical information in taxonomy can be posed in two complementary ways.
</prevsent>
<prevsent>firstly, given particular taxonomic class (such as fruit)one could seek members of this class (such as apple, ba nana).
</prevsent>
</prevsection>
<citsent citstr=" W97-0313 ">
this problem is addressed by riloff and shepherd (1997), <papid> W97-0313 </papid>roark and charniak (1998) <papid> P98-2182 </papid>and more recently by widdows and dorow (2002).<papid> C02-1114 </papid></citsent>
<aftsection>
<nextsent>secondly, given particular word (such as apple), one could seek suitable taxonomic classes for describing this object (such as fruit, foodstuff).
</nextsent>
<nextsent>the work in this paper addresses the second of these questions.
</nextsent>
<nextsent>the goal of automatically placing new words into taxonomy has been attempted in various ways for at least ten years (hearst and schutze, 1993).
</nextsent>
<nextsent>the process for placing word in taxonomy using corpus often contains some version of the following stages: ? for word w, find words from the corpus whose occurrences are similar to those of w. consider these the corpus-derived neighbors?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2055">
<title id=" N03-1036.xml">unsupervised methods for developing taxonomies by combining syntactic and statistical information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problem of enriching the lexical information in taxonomy can be posed in two complementary ways.
</prevsent>
<prevsent>firstly, given particular taxonomic class (such as fruit)one could seek members of this class (such as apple, ba nana).
</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
this problem is addressed by riloff and shepherd (1997), <papid> W97-0313 </papid>roark and charniak (1998) <papid> P98-2182 </papid>and more recently by widdows and dorow (2002).<papid> C02-1114 </papid></citsent>
<aftsection>
<nextsent>secondly, given particular word (such as apple), one could seek suitable taxonomic classes for describing this object (such as fruit, foodstuff).
</nextsent>
<nextsent>the work in this paper addresses the second of these questions.
</nextsent>
<nextsent>the goal of automatically placing new words into taxonomy has been attempted in various ways for at least ten years (hearst and schutze, 1993).
</nextsent>
<nextsent>the process for placing word in taxonomy using corpus often contains some version of the following stages: ? for word w, find words from the corpus whose occurrences are similar to those of w. consider these the corpus-derived neighbors?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2056">
<title id=" N03-1036.xml">unsupervised methods for developing taxonomies by combining syntactic and statistical information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problem of enriching the lexical information in taxonomy can be posed in two complementary ways.
</prevsent>
<prevsent>firstly, given particular taxonomic class (such as fruit)one could seek members of this class (such as apple, ba nana).
</prevsent>
</prevsection>
<citsent citstr=" C02-1114 ">
this problem is addressed by riloff and shepherd (1997), <papid> W97-0313 </papid>roark and charniak (1998) <papid> P98-2182 </papid>and more recently by widdows and dorow (2002).<papid> C02-1114 </papid></citsent>
<aftsection>
<nextsent>secondly, given particular word (such as apple), one could seek suitable taxonomic classes for describing this object (such as fruit, foodstuff).
</nextsent>
<nextsent>the work in this paper addresses the second of these questions.
</nextsent>
<nextsent>the goal of automatically placing new words into taxonomy has been attempted in various ways for at least ten years (hearst and schutze, 1993).
</nextsent>
<nextsent>the process for placing word in taxonomy using corpus often contains some version of the following stages: ? for word w, find words from the corpus whose occurrences are similar to those of w. consider these the corpus-derived neighbors?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2057">
<title id=" N03-1036.xml">unsupervised methods for developing taxonomies by combining syntactic and statistical information </title>
<section> finding semantic neighbors: combining.  </section>
<citcontext>
<prevsection>
<prevsent>there are many empirical techniques for recognizing when words are similar in meaning, rooted in the idea that you shall know word by the company it keeps?
</prevsent>
<prevsent>(firth,1957).
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
it is certainly the case that words which repeatedly occur with similar companions often have related meanings, and common features used for determining this similarity include shared collocations (lin, 1999), <papid> P99-1041 </papid>co-occurrence in lists of objects (widdows and dorow,2002) <papid> C02-1114 </papid>and latent semantic analysis (landauer and du mais, 1997; hearst and schutze, 1993).</citsent>
<aftsection>
<nextsent>the method used to obtain semantic neighbors in our experiments was version of latent semantic analysis, descended from that used by hearst and schutze (1993), hearst and schutze (4).
</nextsent>
<nextsent>first, 1000 frequent words were chosen as column labels (after removing stop words (baeza-yates and ribiero-neto, 1999, p. 167)).
</nextsent>
<nextsent>other words were assignedco-ordinates determined by the number of times they occured within the same context-window (15 words) as one of the 1000 column-label words in large corpus.
</nextsent>
<nextsent>this gave matrix where every word is represented by row vector determined by its co-occurence with frequently occuring, meaningful words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2059">
<title id=" N03-1036.xml">unsupervised methods for developing taxonomies by combining syntactic and statistical information </title>
<section> finding class-labels: mapping.  </section>
<citcontext>
<prevsection>
<prevsent>our algorithm finds the hypernyms which subsume asmany as possible of the original nouns, as closely as possible 1.
</prevsent>
<prevsent>the concept is said to be hypernym of if is kind of v. for this reason this sort of taxonomy is sometimes referred to as an is hierarchy?.
</prevsent>
</prevsection>
<citsent citstr=" C96-1005 ">
forex ample, the possible hypernyms given for the word oak in wordnet 1.6 are oak ? wood ? plant material ? material, stuff ? substance, matter ? object, physical object ? entity, something1another method which could be used for class labelling is given by the conceptual density algorithm ofagirre and rigau (1996), <papid> C96-1005 </papid>which those authors applied to word sense disambiguation.</citsent>
<aftsection>
<nextsent>a different but related idea is presented by li and abe (1998), <papid> J98-2002 </papid>who use principle from information theory to model selectional preferences for verbs using different classes from taxonomy.</nextsent>
<nextsent>their algorithm and goals are different from ours: we are looking for single class-label for semantically related words, whereas for modelling selectional preferences several classes may be appropriate.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2060">
<title id=" N03-1036.xml">unsupervised methods for developing taxonomies by combining syntactic and statistical information </title>
<section> finding class-labels: mapping.  </section>
<citcontext>
<prevsection>
<prevsent>the concept is said to be hypernym of if is kind of v. for this reason this sort of taxonomy is sometimes referred to as an is hierarchy?.
</prevsent>
<prevsent>forex ample, the possible hypernyms given for the word oak in wordnet 1.6 are oak ? wood ? plant material ? material, stuff ? substance, matter ? object, physical object ? entity, something1another method which could be used for class labelling is given by the conceptual density algorithm ofagirre and rigau (1996), <papid> C96-1005 </papid>which those authors applied to word sense disambiguation.</prevsent>
</prevsection>
<citsent citstr=" J98-2002 ">
a different but related idea is presented by li and abe (1998), <papid> J98-2002 </papid>who use principle from information theory to model selectional preferences for verbs using different classes from taxonomy.</citsent>
<aftsection>
<nextsent>their algorithm and goals are different from ours: we are looking for single class-label for semantically related words, whereas for modelling selectional preferences several classes may be appropriate.
</nextsent>
<nextsent>fire (string only) fire nn1 fire vvi fire 1.000000 fire nn1 1.000000 fire vvi 1.000000 flames 0.709939 flames nn2 0.700575 guns nn2 0.663820 smoke 0.680601 smoke nn1 0.696028 firing vvg 0.537778 blaze 0.668504 brigade nn1 0.589625 cannon nn0 0.523442 firemen 0.627065 fires nn2 0.584643 gun nn1 0.484106 fires 0.617494 firemen nn2 0.567170 fired vvd 0.478572 explosion 0.572138 explosion nn1 0.551594 detectors nn2 0.477025 burning 0.559897 destroyed vvn 0.547631 artillery nn1 0.469173 destroyed 0.558699 burning aj0 0.533586 attack vvb 0.468767 brigade 0.532248 blaze nn1 0.529126 firing nn1 0.459000 arson 0.528909 arson nn1 0.522844 volley nn1 0.458717 accidental 0.519310 alarms nn2 0.512332 trained vvn 0.447797 chimney 0.489577 destroyed vvd 0.512130 enemy nn1 0.445523 blast 0.488617 burning vvg 0.502052 alert aj0 0.443610 guns 0.487226 burnt vvn 0.500864 shoot vvi 0.443308 damaged 0.484897 blast nn1 0.498635 defenders nn2 0.438886 table 1: semantic neighbors of fire with different parts-of-speech.
</nextsent>
<nextsent>the scores are cosine similarities oak, oak tree ? tree ? woody plant, ligneous plant ? vascular plant, tracheophyte ? plant, flora, plant life ? life form, organism, being, living thing ? entity, something let be set of nouns or verbs.
</nextsent>
<nextsent>if the word ? is recognized by wordnet, the wordnet taxonomy assigns to an ordered set of hypernyms h(w).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2065">
<title id=" N03-2024.xml">references to named entities a corpus study </title>
<section> the corpus.  </section>
<citcontext>
<prevsection>
<prevsent>it is based on markov chains and captures how subsequent mentions are conditioned by earlier mentions.we close with discussion of our evaluation, which measures how well the highest probability path in the model can be used to regenerate the sequence of references.
</prevsent>
<prevsent>we used corpus of news stories, containing 651,000words drawn from six different newswire agencies, in order to study the syntactic form of noun phrases in which references to people have been realized.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
we were interested in the occurrence of features such as type and number of premodifiers, presence and type of post modifiers, and form of name reference for people.we constructed large, automatically annotated corpus by merging the output of charniaks statistical parser (charniak, 2000) <papid> A00-2018 </papid>with that of the ibm named entity recognition system nominator (wacholder et al,1997).<papid> A97-1030 </papid></citsent>
<aftsection>
<nextsent>the corpus contains 6240 references.
</nextsent>
<nextsent>in this section, we describe the features that were annotated.given our focus on references to mentions of people, there are two distinct types of premodifiers, title sand name-external modifiers?.
</nextsent>
<nextsent>the titles are capitalized noun premodifiers that conventionally are recognized as part of the name, such as president?
</nextsent>
<nextsent>in president george w. bush?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2066">
<title id=" N03-2024.xml">references to named entities a corpus study </title>
<section> the corpus.  </section>
<citcontext>
<prevsection>
<prevsent>it is based on markov chains and captures how subsequent mentions are conditioned by earlier mentions.we close with discussion of our evaluation, which measures how well the highest probability path in the model can be used to regenerate the sequence of references.
</prevsent>
<prevsent>we used corpus of news stories, containing 651,000words drawn from six different newswire agencies, in order to study the syntactic form of noun phrases in which references to people have been realized.
</prevsent>
</prevsection>
<citsent citstr=" A97-1030 ">
we were interested in the occurrence of features such as type and number of premodifiers, presence and type of post modifiers, and form of name reference for people.we constructed large, automatically annotated corpus by merging the output of charniaks statistical parser (charniak, 2000) <papid> A00-2018 </papid>with that of the ibm named entity recognition system nominator (wacholder et al,1997).<papid> A97-1030 </papid></citsent>
<aftsection>
<nextsent>the corpus contains 6240 references.
</nextsent>
<nextsent>in this section, we describe the features that were annotated.given our focus on references to mentions of people, there are two distinct types of premodifiers, title sand name-external modifiers?.
</nextsent>
<nextsent>the titles are capitalized noun premodifiers that conventionally are recognized as part of the name, such as president?
</nextsent>
<nextsent>in president george w. bush?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2067">
<title id=" N04-2009.xml">construction of conceptual graph representation of texts </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>the first corpus is the freely available reuters-21578 text categorization test collection (reuters, 1987).
</prevsent>
<prevsent>the other corpus we use is the collection of aviation incident reports provided by the irish air accident investigation unit (aaiu) (2004) . figure 1: general architecture for the graph construction all documents are converted to xml format and sentential boundaries are identified.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the documents are then parsed using eugene charniaks maximum entropy inspired parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>this probabilistic parser produces penn tree-bank style trees and achieves 90.1% average accuracy for sentences not exceeding 40 words long and 89.5% for sentences with length under 100words when trained and tested on the wall street journal treebank.
</nextsent>
<nextsent>the problem of automatic semantic role identification is an important part of many natural language processing systems and while recent syntactic parsers can correctly label over 95% of the constituents of sentence, find inga representation in terms of semantic roles is still unsat isfactory.there are number of quite different existing approaches for identifying semantic roles.
</nextsent>
<nextsent>the traditional parsing approaches, such as hpsg grammars and lexical functional grammars, to certain extent all suggest semantic relationships corresponding to the syntactic ones.
</nextsent>
<nextsent>they rely strongly on manually-developed grammars and lexicons, which must encode all possible realisations ofthe semantic roles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2068">
<title id=" N04-2009.xml">construction of conceptual graph representation of texts </title>
<section> semantic role identification.  </section>
<citcontext>
<prevsection>
<prevsent>developing such grammars is time consuming and tedious process and such systems usually work well within limited domains only.
</prevsent>
<prevsent>the data-driven approach is an alternative approach, based on filling semantic templates.
</prevsent>
</prevsection>
<citsent citstr=" W98-1106 ">
applying such model to information extraction, in auto slog riloff (1993) builds list of patterns for filling in semantic slots in specific domain, as well as method for automatic acquisition of case frames (riloff and schmelzenbach, 1998).<papid> W98-1106 </papid></citsent>
<aftsection>
<nextsent>in the domain of the air traveler information system, miller at al.
</nextsent>
<nextsent>(1996) apply statistical methods to compute the probability of constituent in order to fill in semantic slot within semantic frame.
</nextsent>
<nextsent>gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002) <papid> J02-3001 </papid>describe statistical approach for semantic role labelling using data collected from framenet.</nextsent>
<nextsent>they investigate the influence of the following features for identification of semantic role: phrase type, grammatical function (the relationship of the constituent to the rest of the sentence), position in the sentence, voice and head word, as well as combination of features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2069">
<title id=" N04-2009.xml">construction of conceptual graph representation of texts </title>
<section> semantic role identification.  </section>
<citcontext>
<prevsection>
<prevsent>in the domain of the air traveler information system, miller at al.
</prevsent>
<prevsent>(1996) apply statistical methods to compute the probability of constituent in order to fill in semantic slot within semantic frame.
</prevsent>
</prevsection>
<citsent citstr=" P00-1065 ">
gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002) <papid> J02-3001 </papid>describe statistical approach for semantic role labelling using data collected from framenet.</citsent>
<aftsection>
<nextsent>they investigate the influence of the following features for identification of semantic role: phrase type, grammatical function (the relationship of the constituent to the rest of the sentence), position in the sentence, voice and head word, as well as combination of features.
</nextsent>
<nextsent>they also describe model for estimating the probability phrase to be assigned specific semantic role.the approach we propose for semantic role identification uses information about each verbs behaviour, provided in verbnet, and the wordnet taxonomy when deciding whether phrase can be suitable match for semantic role.
</nextsent>
<nextsent>verbnet (kipper et al, 2000) is computational verb lexicon, based on levins verb classes (levin, 1993), that contains syntactic and semantic information for english verbs.
</nextsent>
<nextsent>each verbnet class defines list of members, list of possible thematic roles, and list of frames (patterns) of how these semantic roles can be realized in sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2070">
<title id=" N04-2009.xml">construction of conceptual graph representation of texts </title>
<section> semantic role identification.  </section>
<citcontext>
<prevsection>
<prevsent>in the domain of the air traveler information system, miller at al.
</prevsent>
<prevsent>(1996) apply statistical methods to compute the probability of constituent in order to fill in semantic slot within semantic frame.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002) <papid> J02-3001 </papid>describe statistical approach for semantic role labelling using data collected from framenet.</citsent>
<aftsection>
<nextsent>they investigate the influence of the following features for identification of semantic role: phrase type, grammatical function (the relationship of the constituent to the rest of the sentence), position in the sentence, voice and head word, as well as combination of features.
</nextsent>
<nextsent>they also describe model for estimating the probability phrase to be assigned specific semantic role.the approach we propose for semantic role identification uses information about each verbs behaviour, provided in verbnet, and the wordnet taxonomy when deciding whether phrase can be suitable match for semantic role.
</nextsent>
<nextsent>verbnet (kipper et al, 2000) is computational verb lexicon, based on levins verb classes (levin, 1993), that contains syntactic and semantic information for english verbs.
</nextsent>
<nextsent>each verbnet class defines list of members, list of possible thematic roles, and list of frames (patterns) of how these semantic roles can be realized in sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2071">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper explores the use of statistical machine translation (smt) methods in natural language generation (nlg), specifically the task of mapping statements informal meaning representation language (mrl) into natural language (nl), i.e. tactical generation.
</prevsent>
<prevsent>given corpus of nl sentences each paired with formal meaning representation (mr),it is easy to use smt to construct tactical generator, i.e. statistical model that translates mrl to nl.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
however, there has been little, if any, research on exploiting recent smt methods for nlg.in this paper we present results on using recent phrase-based smt system, pharaoh (koehnet al, 2003), <papid> N03-1017 </papid>for nlg.1 although moderately effec 1we also tried ibm model 4/rewrite (germann, 2003), <papid> N03-1010 </papid>word-based smt system, but it gave much worse results.tive, the inability of pharaoh to exploit the formal structure and grammar of the mrl limits its ac curacy.</citsent>
<aftsection>
<nextsent>unlike natural languages, mrls typically have simple, formal syntax to support effective automated processing and inference.
</nextsent>
<nextsent>this mrl structure can also be used to improve language generation.
</nextsent>
<nextsent>tactical generation can also be seen as the inverse of semantic parsing, the task of mapping nl sentences to mrs. in this paper, we show how to in vert?
</nextsent>
<nextsent>a recent smt-based semantic parser, wasp (wong and mooney, 2006), <papid> N06-1056 </papid>in order to produce more effective generation system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2072">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper explores the use of statistical machine translation (smt) methods in natural language generation (nlg), specifically the task of mapping statements informal meaning representation language (mrl) into natural language (nl), i.e. tactical generation.
</prevsent>
<prevsent>given corpus of nl sentences each paired with formal meaning representation (mr),it is easy to use smt to construct tactical generator, i.e. statistical model that translates mrl to nl.
</prevsent>
</prevsection>
<citsent citstr=" N03-1010 ">
however, there has been little, if any, research on exploiting recent smt methods for nlg.in this paper we present results on using recent phrase-based smt system, pharaoh (koehnet al, 2003), <papid> N03-1017 </papid>for nlg.1 although moderately effec 1we also tried ibm model 4/rewrite (germann, 2003), <papid> N03-1010 </papid>word-based smt system, but it gave much worse results.tive, the inability of pharaoh to exploit the formal structure and grammar of the mrl limits its ac curacy.</citsent>
<aftsection>
<nextsent>unlike natural languages, mrls typically have simple, formal syntax to support effective automated processing and inference.
</nextsent>
<nextsent>this mrl structure can also be used to improve language generation.
</nextsent>
<nextsent>tactical generation can also be seen as the inverse of semantic parsing, the task of mapping nl sentences to mrs. in this paper, we show how to in vert?
</nextsent>
<nextsent>a recent smt-based semantic parser, wasp (wong and mooney, 2006), <papid> N06-1056 </papid>in order to produce more effective generation system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2073">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this mrl structure can also be used to improve language generation.
</prevsent>
<prevsent>tactical generation can also be seen as the inverse of semantic parsing, the task of mapping nl sentences to mrs. in this paper, we show how to in vert?
</prevsent>
</prevsection>
<citsent citstr=" N06-1056 ">
a recent smt-based semantic parser, wasp (wong and mooney, 2006), <papid> N06-1056 </papid>in order to produce more effective generation system.</citsent>
<aftsection>
<nextsent>wasp exploits the formal syntax of the mrl by learning translator (based on statistical synchronous context free grammar) that maps an nl sentence to lin earized parse-tree of its mr rather than to flat mr string.
</nextsent>
<nextsent>in addition to exploiting the formal mrl grammar, our approach also allows the same learned grammar to be used for both parsing and generation, an elegant property that has been widely advocated (kay, 1975; <papid> T75-1004 </papid>jacobs, 1985; <papid> J85-4002 </papid>shieber, 1988).<papid> C88-2128 </papid>we present experimental results in two domains previously used to test wasps semantic parsing abil ity: mapping nl queries to formal database query language, and mapping nl soccer coaching instructions to formal robot command language.</nextsent>
<nextsent>wasp1 is shown to produce more accurate nl generator than pharaoh.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2075">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a recent smt-based semantic parser, wasp (wong and mooney, 2006), <papid> N06-1056 </papid>in order to produce more effective generation system.</prevsent>
<prevsent>wasp exploits the formal syntax of the mrl by learning translator (based on statistical synchronous context free grammar) that maps an nl sentence to lin earized parse-tree of its mr rather than to flat mr string.</prevsent>
</prevsection>
<citsent citstr=" T75-1004 ">
in addition to exploiting the formal mrl grammar, our approach also allows the same learned grammar to be used for both parsing and generation, an elegant property that has been widely advocated (kay, 1975; <papid> T75-1004 </papid>jacobs, 1985; <papid> J85-4002 </papid>shieber, 1988).<papid> C88-2128 </papid>we present experimental results in two domains previously used to test wasps semantic parsing abil ity: mapping nl queries to formal database query language, and mapping nl soccer coaching instructions to formal robot command language.</citsent>
<aftsection>
<nextsent>wasp1 is shown to produce more accurate nl generator than pharaoh.
</nextsent>
<nextsent>we also show how the idea of generating from linear ized parse-trees rather than flat mrs, used effectively in wasp1, can also be exploited in pharaoh.
</nextsent>
<nextsent>a version of pharaoh that exploits this approach is experimentally shown to produce more accurate generators that are more competitive with wasp1s. finally, we also show how 172 ((bowner our {4}) (do our {6} (pos (left (half our))))) if our player 4 has the ball, then our player 6 should stay in the left side of our half.
</nextsent>
<nextsent>(a) clang answer(state(traverse 1(riverid(ohio?)))) what states does the ohio run through?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2076">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a recent smt-based semantic parser, wasp (wong and mooney, 2006), <papid> N06-1056 </papid>in order to produce more effective generation system.</prevsent>
<prevsent>wasp exploits the formal syntax of the mrl by learning translator (based on statistical synchronous context free grammar) that maps an nl sentence to lin earized parse-tree of its mr rather than to flat mr string.</prevsent>
</prevsection>
<citsent citstr=" J85-4002 ">
in addition to exploiting the formal mrl grammar, our approach also allows the same learned grammar to be used for both parsing and generation, an elegant property that has been widely advocated (kay, 1975; <papid> T75-1004 </papid>jacobs, 1985; <papid> J85-4002 </papid>shieber, 1988).<papid> C88-2128 </papid>we present experimental results in two domains previously used to test wasps semantic parsing abil ity: mapping nl queries to formal database query language, and mapping nl soccer coaching instructions to formal robot command language.</citsent>
<aftsection>
<nextsent>wasp1 is shown to produce more accurate nl generator than pharaoh.
</nextsent>
<nextsent>we also show how the idea of generating from linear ized parse-trees rather than flat mrs, used effectively in wasp1, can also be exploited in pharaoh.
</nextsent>
<nextsent>a version of pharaoh that exploits this approach is experimentally shown to produce more accurate generators that are more competitive with wasp1s. finally, we also show how 172 ((bowner our {4}) (do our {6} (pos (left (half our))))) if our player 4 has the ball, then our player 6 should stay in the left side of our half.
</nextsent>
<nextsent>(a) clang answer(state(traverse 1(riverid(ohio?)))) what states does the ohio run through?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2077">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a recent smt-based semantic parser, wasp (wong and mooney, 2006), <papid> N06-1056 </papid>in order to produce more effective generation system.</prevsent>
<prevsent>wasp exploits the formal syntax of the mrl by learning translator (based on statistical synchronous context free grammar) that maps an nl sentence to lin earized parse-tree of its mr rather than to flat mr string.</prevsent>
</prevsection>
<citsent citstr=" C88-2128 ">
in addition to exploiting the formal mrl grammar, our approach also allows the same learned grammar to be used for both parsing and generation, an elegant property that has been widely advocated (kay, 1975; <papid> T75-1004 </papid>jacobs, 1985; <papid> J85-4002 </papid>shieber, 1988).<papid> C88-2128 </papid>we present experimental results in two domains previously used to test wasps semantic parsing abil ity: mapping nl queries to formal database query language, and mapping nl soccer coaching instructions to formal robot command language.</citsent>
<aftsection>
<nextsent>wasp1 is shown to produce more accurate nl generator than pharaoh.
</nextsent>
<nextsent>we also show how the idea of generating from linear ized parse-trees rather than flat mrs, used effectively in wasp1, can also be exploited in pharaoh.
</nextsent>
<nextsent>a version of pharaoh that exploits this approach is experimentally shown to produce more accurate generators that are more competitive with wasp1s. finally, we also show how 172 ((bowner our {4}) (do our {6} (pos (left (half our))))) if our player 4 has the ball, then our player 6 should stay in the left side of our half.
</nextsent>
<nextsent>(a) clang answer(state(traverse 1(riverid(ohio?)))) what states does the ohio run through?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2078">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> mrls and test domains.  </section>
<citcontext>
<prevsection>
<prevsent>in this work, we consider input mrs with hierarchical structure similar to moore (2002).
</prevsent>
<prevsent>the only restriction on the mrl is that it be defined by an available unambiguous context-free grammar(cfg), which is true for almost all computer languages.
</prevsent>
</prevsection>
<citsent citstr=" J93-1008 ">
we also assume that the order in which mr predicates appear is relevant, i.e. the order can affect the meaning of the mr. note that the order in which predicates appear need not be the same as the word order of the target nl, and therefore, the content planner need not know about the target nl grammar (shieber, 1993).<papid> J93-1008 </papid>to ground our discussion, we consider two application domains which were originally used to demonstrate semantic parsing.</citsent>
<aftsection>
<nextsent>the first domain is robocup.
</nextsent>
<nextsent>in the robocup coach competition (www.robocup.org), teams of agents compete in simulated soccer game and receive coach advice written informal language called clang (chenet al, 2003).
</nextsent>
<nextsent>the task is to build system that translates this formal advice into english.
</nextsent>
<nextsent>figure 1(a) shows piece of sample advice.the second domain is geo query, where functional, variable-free query language is used for querying small database on u.s. geography (kate et al, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2079">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> generation using smt methods.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1(b) shows sample query.
</prevsent>
<prevsent>in this section, we show how smt methods can beused to construct tactical generator.
</prevsent>
</prevsection>
<citsent citstr=" C92-2117 ">
this is in contrast to existing work that focuses on the use of nlg in inter lingual mt (whitelock, 1992), <papid> C92-2117 </papid>in which the roles of nlg and mt are switched.</citsent>
<aftsection>
<nextsent>we first consider using phrase-based smt system, pharaoh, for nlg.
</nextsent>
<nextsent>then we show how to invert an smt-based semantic parser, wasp, to produce more effective generation system.
</nextsent>
<nextsent>3.1 generation using pharaoh.
</nextsent>
<nextsent>pharaoh (koehn et al, 2003) <papid> N03-1017 </papid>is an smt system that uses phrases as basic translation units.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2081">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> generation using smt methods.  </section>
<citcontext>
<prevsection>
<prevsent>during decoding, the source sentence is segmented intoa sequence of phrases.
</prevsent>
<prevsent>these phrases are then reordered and translated into phrases in the target language, which are joined together to form the output sentence.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
compared to earlier word-based methods such as ibm models (brown et al, 1993), <papid> J93-2003 </papid>phrase based methods such as pharaoh are much more effective in producing idiomatic translations, and are currently the best performing methods in smt (koehn and monz, 2006).<papid> W06-3114 </papid></citsent>
<aftsection>
<nextsent>to use pharaoh for nlg, we simply treat the source mrl as an nl, so that phrases in the mrlare sequences of mr tokens.
</nextsent>
<nextsent>note that the grammat icality of mrs is not an issue here, as they are given as input.
</nextsent>
<nextsent>3.2 wasp: the semantic parsing algorithm.
</nextsent>
<nextsent>before showing how generation can be performed by inverting semantic parser, we present brief overview of wasp (wong and mooney, 2006), <papid> N06-1056 </papid>the smt-based semantic parser on which this work is based.to describe wasp, it is best to start with an ex ample.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2082">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> generation using smt methods.  </section>
<citcontext>
<prevsection>
<prevsent>during decoding, the source sentence is segmented intoa sequence of phrases.
</prevsent>
<prevsent>these phrases are then reordered and translated into phrases in the target language, which are joined together to form the output sentence.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
compared to earlier word-based methods such as ibm models (brown et al, 1993), <papid> J93-2003 </papid>phrase based methods such as pharaoh are much more effective in producing idiomatic translations, and are currently the best performing methods in smt (koehn and monz, 2006).<papid> W06-3114 </papid></citsent>
<aftsection>
<nextsent>to use pharaoh for nlg, we simply treat the source mrl as an nl, so that phrases in the mrlare sequences of mr tokens.
</nextsent>
<nextsent>note that the grammat icality of mrs is not an issue here, as they are given as input.
</nextsent>
<nextsent>3.2 wasp: the semantic parsing algorithm.
</nextsent>
<nextsent>before showing how generation can be performed by inverting semantic parser, we present brief overview of wasp (wong and mooney, 2006), <papid> N06-1056 </papid>the smt-based semantic parser on which this work is based.to describe wasp, it is best to start with an ex ample.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2085">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> generation using smt methods.  </section>
<citcontext>
<prevsection>
<prevsent>the meaning of the sentence is then obtained by combining the meanings of the phrases.
</prevsent>
<prevsent>this process can be formalized using synchronous context-free grammar (scfg), originally develop edas grammar formalism that combines syntax analysis and code generation in compilers (aho and ullman, 1972).
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
it has been used in syntax-based smtto model the translation of one nl to another (chi ang, 2005).<papid> P05-1033 </papid></citsent>
<aftsection>
<nextsent>a derivation for scfg gives rise to multiple isomorphic parse trees.
</nextsent>
<nextsent>figure 2 shows apart ial parse of the sample sentence and its corre 173 rule if condition team our player unum 4 has the ball ...
</nextsent>
<nextsent>(a) english rule ( condition (bowner team our { unum 4 }) ...)
</nextsent>
<nextsent>(b) clang figure 2: partial parse trees for the clang statement and its english gloss shown in figure 1(a)sponding clang parse from which an mr is constructed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2091">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> generation using smt methods.  </section>
<citcontext>
<prevsection>
<prevsent>the token (1) denotes word gap of size 1, due to theun aligned word the that comes between has and ball.
</prevsent>
<prevsent>it can be seen as non-terminal that expands to atmost one word, allowing for some flexibility in pattern matching.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
in wasp, giza++ (och and ney, 2003) <papid> J03-1002 </papid>is usedto obtain the best alignments from the training ex amples.</citsent>
<aftsection>
<nextsent>then scfg rules are extracted from these alignments.
</nextsent>
<nextsent>the resulting scfg, however, can be 174 rule ?
</nextsent>
<nextsent>(condition directive) team ? our unum ? 4 if our player 4 has the ball condition ?
</nextsent>
<nextsent>(bowner team {unum}) figure 3: partial word alignment for the clang statement and its english gloss shown in figure 1(a) ambiguous.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2093">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> generation using smt methods.  </section>
<citcontext>
<prevsection>
<prevsent>now we show how to invert wasp to produce wasp1, and use it for nlg.
</prevsent>
<prevsent>we can use the same grammar for both parsing and generation, particularly appealing aspect of using wasp.
</prevsent>
</prevsection>
<citsent citstr=" P96-1027 ">
since anscfg is fully symmetric with respect to both generated strings, the same chart used for parsing can be easily adapted for efficient generation (shieber, 1988; <papid> C88-2128 </papid>kay, 1996).<papid> P96-1027 </papid></citsent>
<aftsection>
<nextsent>given an input mr, , wasp1 finds sentence that maximizes pr(e|f).
</nextsent>
<nextsent>it is difficult to directly model pr(e|f), however, because it has to assign low probabilities to output sentences that are notgrammatical.
</nextsent>
<nextsent>there is no such requirement for parsing, because the use of the mrl grammar ensures the grammaticality of all output mrs. for generation, we need an nl grammar to ensure gram mati cality, but this is not available priori.
</nextsent>
<nextsent>this motivates the noisy-channel model for wasp1, where pr(e|f) is divided into two smaller components: arg max pr(e|f) = arg max pr(e) pr(f |e) (2) pr(e) is the language model, and pr(f |e) is the parsing model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2094">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> generation using smt methods.  </section>
<citcontext>
<prevsection>
<prevsent>there is no such requirement for parsing, because the use of the mrl grammar ensures the grammaticality of all output mrs. for generation, we need an nl grammar to ensure gram mati cality, but this is not available priori.
</prevsent>
<prevsent>this motivates the noisy-channel model for wasp1, where pr(e|f) is divided into two smaller components: arg max pr(e|f) = arg max pr(e) pr(f |e) (2) pr(e) is the language model, and pr(f |e) is the parsing model.
</prevsent>
</prevsection>
<citsent citstr=" P95-1034 ">
the generation task is to find sentence such that (1) is good sentence priori, and (2) its meaning is the same as the input mr. for the language model, we use an n-grammodel, which is remarkably useful in ranking candidate generated sentences (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>bangalore et al, 2000; <papid> W00-1401 </papid>langkilde-geary, 2002).</citsent>
<aftsection>
<nextsent>for the parsing model, we re-use the one from wasp (equa tion 1).
</nextsent>
<nextsent>hence computing (2) means maximizing the following: max pr(e) pr(f |e) ? max dd(f) pr(e(d)) pr?(d|e(d)) = max dd(f) pr(e(d)) ? expi ifi(d) z?(e(d)) (3)where d(f) is the set of derivations that are consistent with , and e(d) is the output sentence thata derivation yields.
</nextsent>
<nextsent>compared to most existing work on generation, wasp1 has the following characteristics: 1.
</nextsent>
<nextsent>it does not require any lexical information in.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2095">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> generation using smt methods.  </section>
<citcontext>
<prevsection>
<prevsent>there is no such requirement for parsing, because the use of the mrl grammar ensures the grammaticality of all output mrs. for generation, we need an nl grammar to ensure gram mati cality, but this is not available priori.
</prevsent>
<prevsent>this motivates the noisy-channel model for wasp1, where pr(e|f) is divided into two smaller components: arg max pr(e|f) = arg max pr(e) pr(f |e) (2) pr(e) is the language model, and pr(f |e) is the parsing model.
</prevsent>
</prevsection>
<citsent citstr=" W00-1401 ">
the generation task is to find sentence such that (1) is good sentence priori, and (2) its meaning is the same as the input mr. for the language model, we use an n-grammodel, which is remarkably useful in ranking candidate generated sentences (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>bangalore et al, 2000; <papid> W00-1401 </papid>langkilde-geary, 2002).</citsent>
<aftsection>
<nextsent>for the parsing model, we re-use the one from wasp (equa tion 1).
</nextsent>
<nextsent>hence computing (2) means maximizing the following: max pr(e) pr(f |e) ? max dd(f) pr(e(d)) pr?(d|e(d)) = max dd(f) pr(e(d)) ? expi ifi(d) z?(e(d)) (3)where d(f) is the set of derivations that are consistent with , and e(d) is the output sentence thata derivation yields.
</nextsent>
<nextsent>compared to most existing work on generation, wasp1 has the following characteristics: 1.
</nextsent>
<nextsent>it does not require any lexical information in.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2100">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> improving the smt-based generators.  </section>
<citcontext>
<prevsection>
<prevsent>together with the language model, the new formulation of pr(e|f) is loglinear model with as parameters.
</prevsent>
<prevsent>the advanta geof this model is that maximization requires no normalization and can be done exactly and efficiently.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the model parameters are trained using minimum error-rate training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>following the phrase extraction phase in pharaoh, we eliminate word gaps by incorporating unaligned words as part of the extracted nl phrases (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>the reason is that while word gaps are useful in dealing with unknown phrases during semantic parsing, for generation, using known phrases generally leads to better fluency.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2105">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>wasp1++: if players 2, 3, 7 and 5 has the ball and the ball is near our goal line ...
</prevsent>
<prevsent>figure 4: sample partial system output in the robocup domain robocup geo query bleu nist bleu nist pharaoh 0.3247 5.0263 0.2070 3.1478 wasp1 0.4357 5.4486 0.4582 5.9900 pharaoh++ 0.4336 5.9185 0.5354 6.3637 wasp1++ 0.6022 6.8976 0.5370 6.4808 table 1: results of automatic evaluation; bold type indicates the best performing system (or systems) forgiven domain-metric pair (p   0.05) 5.1 automatic evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we performed 4 runs of 10-fold cross validation, and measured the performance of the learned generators using the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>and the nist score (doddington, 2002).</citsent>
<aftsection>
<nextsent>both mt metrics measure the precision of translation in terms of the proportion of n-grams that it shares with the reference translations, with the nist score focusing moreon n-grams that are less frequent and more informative.
</nextsent>
<nextsent>both metrics have recently been used to evaluate generators (langkilde-geary, 2002; nakanishi et al, 2005; <papid> W05-1510 </papid>belz and reiter, 2006).<papid> E06-1040 </papid></nextsent>
<nextsent>all systems were able to generate sentences for more than 97% of the input.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2106">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we performed 4 runs of 10-fold cross validation, and measured the performance of the learned generators using the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>and the nist score (doddington, 2002).</prevsent>
<prevsent>both mt metrics measure the precision of translation in terms of the proportion of n-grams that it shares with the reference translations, with the nist score focusing moreon n-grams that are less frequent and more informative.</prevsent>
</prevsection>
<citsent citstr=" W05-1510 ">
both metrics have recently been used to evaluate generators (langkilde-geary, 2002; nakanishi et al, 2005; <papid> W05-1510 </papid>belz and reiter, 2006).<papid> E06-1040 </papid></citsent>
<aftsection>
<nextsent>all systems were able to generate sentences for more than 97% of the input.
</nextsent>
<nextsent>figure 4 shows some sample output of the systems.
</nextsent>
<nextsent>table 1 shows the automatic evaluation results.
</nextsent>
<nextsent>paired t-tests were used to measure statistical significance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2107">
<title id=" N07-1022.xml">generation by inverting a semantic parser that uses statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we performed 4 runs of 10-fold cross validation, and measured the performance of the learned generators using the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>and the nist score (doddington, 2002).</prevsent>
<prevsent>both mt metrics measure the precision of translation in terms of the proportion of n-grams that it shares with the reference translations, with the nist score focusing moreon n-grams that are less frequent and more informative.</prevsent>
</prevsection>
<citsent citstr=" E06-1040 ">
both metrics have recently been used to evaluate generators (langkilde-geary, 2002; nakanishi et al, 2005; <papid> W05-1510 </papid>belz and reiter, 2006).<papid> E06-1040 </papid></citsent>
<aftsection>
<nextsent>all systems were able to generate sentences for more than 97% of the input.
</nextsent>
<nextsent>figure 4 shows some sample output of the systems.
</nextsent>
<nextsent>table 1 shows the automatic evaluation results.
</nextsent>
<nextsent>paired t-tests were used to measure statistical significance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2115">
<title id=" N07-1009.xml">structured local training and biased potential functions for conditional random fields with application to coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>furthermore,we introduce biased potential functions that empirically drive crfs towards performance improvements w.r.t. the preferred evaluation measure forthe learning task.
</prevsent>
<prevsent>we report promising experimental results on two coreference datasets using two task-specific evaluation measures.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
undirected graphical models such as conditional random fields (crfs) (lafferty et al, 2001) have shown great success for problems involving structured output variables (e.g. wellner et al (2004),finkel et al (2005)).<papid> P05-1045 </papid></citsent>
<aftsection>
<nextsent>for many real-world nlp applications, however, the required graph structure canbe very complex, and computing the global normalization factor even approximately can be extremely hard.
</nextsent>
<nextsent>previous approaches for training crfs have either (1) opted for training method that no longer maximizes the likelihood, (e.g. mccallum and wellner (2004), roth and yih (2005)) 1, or (2) opted for 1both mccallum and wellner (2004) and roth and yih (2005) used the voted perceptron algorithm (collins, 2002) <papid> W02-1001 </papid>to train intractable crfs.</nextsent>
<nextsent>simplified graph structure to avoid intractable global normalization (e.g. roth and yih (2005), wellner et al.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2116">
<title id=" N07-1009.xml">structured local training and biased potential functions for conditional random fields with application to coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>undirected graphical models such as conditional random fields (crfs) (lafferty et al, 2001) have shown great success for problems involving structured output variables (e.g. wellner et al (2004),finkel et al (2005)).<papid> P05-1045 </papid></prevsent>
<prevsent>for many real-world nlp applications, however, the required graph structure canbe very complex, and computing the global normalization factor even approximately can be extremely hard.</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
previous approaches for training crfs have either (1) opted for training method that no longer maximizes the likelihood, (e.g. mccallum and wellner (2004), roth and yih (2005)) 1, or (2) opted for 1both mccallum and wellner (2004) and roth and yih (2005) used the voted perceptron algorithm (collins, 2002) <papid> W02-1001 </papid>to train intractable crfs.</citsent>
<aftsection>
<nextsent>simplified graph structure to avoid intractable global normalization (e.g. roth and yih (2005), wellner et al.
</nextsent>
<nextsent>(2004)).
</nextsent>
<nextsent>solutions of the first type replace the computation of the global normalization factor ? p(y|x) with argmaxy p(y|x) during training, since finding anargmax of probability distribution is often an easier problem than finding the entire probability distribution.
</nextsent>
<nextsent>training via the voted perceptron algorithm (collins, 2002) <papid> W02-1001 </papid>or using max-margin criterion also correspond to the first option (e.g. mccallum and wellner (2004), finley and joachims (2005)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2120">
<title id=" N07-1009.xml">structured local training and biased potential functions for conditional random fields with application to coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>solutions of the first type replace the computation of the global normalization factor ? p(y|x) with argmaxy p(y|x) during training, since finding anargmax of probability distribution is often an easier problem than finding the entire probability distribution.
</prevsent>
<prevsent>training via the voted perceptron algorithm (collins, 2002) <papid> W02-1001 </papid>or using max-margin criterion also correspond to the first option (e.g. mccallum and wellner (2004), finley and joachims (2005)).</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
but without the global normalization, the maximum likelihood criterion motivated by the maximum entropy principle (berger et al, 1996) <papid> J96-1002 </papid>is no longer feasible option as an optimization criterion.the second solution simplifies the graph structure for training, and applies complex global inference only for testing.</citsent>
<aftsection>
<nextsent>inspite of the discrepancy between the training model and the testing model, it has been empirically shown that (1) performing global inference only during testing can improve performance (e.g. finkel et al (2005), <papid> P05-1045 </papid>roth and yih(2005)), and (2) full-blown global training can of ten perform worse due to insufficient training data(e.g. punyakanok et al (2005)).</nextsent>
<nextsent>importantly, how ever, attempts to reduce the discrepancy between the training and test models ? by judiciously adding the effect of global inference to the training ? have produced substantial performance improvements over locally trained models (e.g. cohen and carvalho (2005), sutton and mccallum (2005a)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2122">
<title id=" N07-1009.xml">structured local training and biased potential functions for conditional random fields with application to coreference resolution </title>
<section> structured local training.  </section>
<citcontext>
<prevsection>
<prevsent>that can be clustered to the true labeling y?
</prevsent>
<prevsent>[global model (y|h)] for the global model, we assume deterministic clustering algorithm is given.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
in particular, we focus on single-link clustering, as ithas been shown to be effective for coreference resolution (e.g. ng and cardie (2002)<papid> P02-1014 </papid></citsent>
<aftsection>
<nextsent>with single-link clustering, (y|h) = 1 if can be clustered to y, and (y|h) = 0 if cannot be clustered to y.5 [computation of the e-step] the e-step requires computation of the distribution of (h|y, x, ?(t1)), which we will simply denote as (h|y, x), since all our distributions are implicitly conditioned on the model parameters ?.
</nextsent>
<nextsent>p (h|y, x) = (h, y|x) (y|x) ? (y|h) (h|x)notice that when computing (h|y, x), the denominator (y|x) stays as constant for different values of h. the e-step requires enumeration of all possible values of h, but it is intractable with our formulation, because inference for the global model (y|h) does not factor out nicely.
</nextsent>
<nextsent>therefore, we must resort to an 5single-link clustering simply takes the transitive closure, and does not consider the distance metric.
</nextsent>
<nextsent>in pilot study, we also tried variant of stochastic clustering algorithm that takes into account the distance metric (set as the probabilities from the local model) for the global model, but the performance was worse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2124">
<title id=" N07-1009.xml">structured local training and biased potential functions for conditional random fields with application to coreference resolution </title>
<section> experimentsi.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, similar to the viterbi-training in the e-step, we approximate the distribution of by argmaxhp (h|x).
</prevsent>
<prevsent>data set: we evaluate our approach with two coreference data sets: muc6 (muc-6, 1995) and mpqa7(wiebe et al, 2005).
</prevsent>
</prevsection>
<citsent citstr=" W06-1640 ">
for the muc6 dataset, we extract noun phrases (mentions) automatically,but for mpqa, we assume mentions for coreference resolution are given as in stoyanov and cardie (2006).<papid> W06-1640 </papid></citsent>
<aftsection>
<nextsent>for muc6, we use the standard training/test data split.
</nextsent>
<nextsent>for mpqa, we use 150 documents for training, and 50 documents for testing.
</nextsent>
<nextsent>configuration: we follow ng and cardie (2002)<papid> P02-1014 </papid>for feature vector construction for each pair of mentions,8 and finley and joachims (2005) for constructing training/testing instance for each docu ment: training/testing instance consists of all pairs of mentions in document.</nextsent>
<nextsent>then, single pair of mentions is sub-instance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2129">
<title id=" N03-3001.xml">semantic language models for topic detection and tracking </title>
<section> past work.  </section>
<citcontext>
<prevsection>
<prevsent>section 7 ends the discussion with few observations and lays down the path to future work.
</prevsent>
<prevsent>traditionally nlp techniques have not met with much success in their domain.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
however, after several advances in tasks such as automatic tagging of text with high level semantics such as parts-of-speech (ratna parkhi, 1996), <papid> W96-0213 </papid>named-entities (bikel et al , 1999),sentence-parsing (charniak, 1997), etc., there is increasing hope that one could leverage this information into ir techniques.</citsent>
<aftsection>
<nextsent>traditional vector space models (salton et al ., 1975) and the more recent language models (ponte and croft, 1998) tend to ignore any semantic information and consider only word-tokens or word-stems as basic features.we know of no prior work in the language modeling framework that tries to incorporate semantic information into ir models.
</nextsent>
<nextsent>however, in vector space modeling framework, there have been few attempts.
</nextsent>
<nextsent>for example,allan, et al (allan et al , 1999) use an ad-hoc weighting scheme to weight named-entities higher than other tokens in their vector space models for the new event detection task of tdt.
</nextsent>
<nextsent>they do not report any significant improvements in their results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2130">
<title id=" N06-2040.xml">sentence planning for real time navigational instruction </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P02-1048 ">
dialog agents have been developed for variety of navigation domains such as in-car driving directions(dale et al, 2003), tourist information portals (john ston et al, 2002) <papid> P02-1048 </papid>and pedestrian navigation (muller, 2002).</citsent>
<aftsection>
<nextsent>in all these applications, the human partner receives navigation instructions from system.
</nextsent>
<nextsent>for these domains, contextual features of the physical setting must be taken into account for the agent to communicate successfully.in dialog systems, one misunderstanding can of ten lead to additional errors (moratz and tenbrink,2003), so the system must strategically choose instructions and referring expressions that can be clearly understood by the user.
</nextsent>
<nextsent>human cognition studies have found that the in front of/behind axis is easier to perceive than other relations (bryant etal., 1992).
</nextsent>
<nextsent>in navigation tasks, this suggests that describing an object when it is in front of the follower is preferable to using other spatial relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2131">
<title id=" N06-2040.xml">sentence planning for real time navigational instruction </title>
<section> dialog collection procedure.  </section>
<citcontext>
<prevsection>
<prevsent>overall, the corpus contains 1736 mark able items, of which 87 were annotated as vague, 84 abandoned and 228 sets.
</prevsent>
<prevsent>we annotated each referring expression with boolean feature called locate that indicates whether the expression is the first one that allowed the follower to identify the object in the world, in other words, the point at which joint spatial reference was achieved.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
the kappa (carletta, 1996) <papid> J96-2004 </papid>obtained onthis feature was 0.93.</citsent>
<aftsection>
<nextsent>there were 466 referring expressions in the 15-dialog corpus that were annotated true for this feature.
</nextsent>
<nextsent>the dataset used in the experiments is consensus version on which both annotators agreed on the set of markables.
</nextsent>
<nextsent>due to the constraints introduced by the task, referent annotation achieved almost perfect agreement.
</nextsent>
<nextsent>annotators were allowed to look ahead in the dialog to assign the referent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2132">
<title id=" N06-2040.xml">sentence planning for real time navigational instruction </title>
<section> algorithm development.  </section>
<citcontext>
<prevsection>
<prevsent>vis distracts is selected as the most important feature by the tree, suggesting that having large number of objects to contrast makes the description harder, which is in sync with human intuition.
</prevsent>
<prevsent>we note that visible is not selected, but that might be due to the fact that it reduces to angle
</prevsent>
</prevsection>
<citsent citstr=" C92-1038 ">
. in terms of the referring expression generation algorithm described by (reiter and dale, 1992), <papid> C92-1038 </papid>in which the description which eliminates the most dis tractors is selected, our 1http://www.cs.waikato.ac.nz/ml/weka/ 2not all positive examples were visible 159results suggest that the human subjects chose to reduce the size of the dis tractor set before producing adescription, presumably in order to reduce the computational load required to calculate the optimal de scription.</citsent>
<aftsection>
<nextsent>vis distracts  = 3 | angle  = 33 | | distance  =154: describe-id (308/27) | | distance   154: delay (60/20) | angle   33 | | distance  = 90 | | | angle  =83:describe-id(79/20) | | | angle   83: delay (53/9) | | distance  90: delay(158/16) vis distracts   3: delay (114/1) figure 4: the decision tree obtained.
</nextsent>
<nextsent>class precision recall f-measure describe-id 0.822 0.925 0.871 delay 0.914 0.8 0.853 table 1: detailed performance the exact values of features shown in our decision tree are specific to our environment.
</nextsent>
<nextsent>however, the features themselves are domain-independent and are relevant for any spatial direction-giving task, and their relative influence over the final decision may transfer to new domain.
</nextsent>
<nextsent>to incorporate our findings in system, we will monitor the users context and plan description only when our tree predicts it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2133">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>much of the challenge of this lies in extracting the appropriate parsing decisions from textual examples.
</prevsent>
<prevsent>given sufficient labelled data, there are several supervised?
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
techniques of training high-performance parsers (char niak and johnson, 2005; <papid> P05-1022 </papid>collins, 2000; henderson, 2004).<papid> P04-1013 </papid></citsent>
<aftsection>
<nextsent>other methods are semi-supervised?
</nextsent>
<nextsent>where they use some labelled data to annotate unlabeleddata.
</nextsent>
<nextsent>examples of this include self-training (char niak, 1997) and co-training (blum and mitchell,1998; steedman et al, 2003).<papid> E03-1008 </papid></nextsent>
<nextsent>finally, there are un supervised?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2134">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>much of the challenge of this lies in extracting the appropriate parsing decisions from textual examples.
</prevsent>
<prevsent>given sufficient labelled data, there are several supervised?
</prevsent>
</prevsection>
<citsent citstr=" P04-1013 ">
techniques of training high-performance parsers (char niak and johnson, 2005; <papid> P05-1022 </papid>collins, 2000; henderson, 2004).<papid> P04-1013 </papid></citsent>
<aftsection>
<nextsent>other methods are semi-supervised?
</nextsent>
<nextsent>where they use some labelled data to annotate unlabeleddata.
</nextsent>
<nextsent>examples of this include self-training (char niak, 1997) and co-training (blum and mitchell,1998; steedman et al, 2003).<papid> E03-1008 </papid></nextsent>
<nextsent>finally, there are un supervised?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2135">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other methods are semi-supervised?
</prevsent>
<prevsent>where they use some labelled data to annotate unlabeleddata.
</prevsent>
</prevsection>
<citsent citstr=" E03-1008 ">
examples of this include self-training (char niak, 1997) and co-training (blum and mitchell,1998; steedman et al, 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>finally, there are un supervised?
</nextsent>
<nextsent>strategies where no data is labeled and all annotations (including the grammar itself) must be discovered (klein and manning, 2002).<papid> P02-1017 </papid></nextsent>
<nextsent>semi-supervised and unsupervised methods are important because good labeled data is expensive, whereas there is no shortage of unlabeled data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2136">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>examples of this include self-training (char niak, 1997) and co-training (blum and mitchell,1998; steedman et al, 2003).<papid> E03-1008 </papid></prevsent>
<prevsent>finally, there are un supervised?</prevsent>
</prevsection>
<citsent citstr=" P02-1017 ">
strategies where no data is labeled and all annotations (including the grammar itself) must be discovered (klein and manning, 2002).<papid> P02-1017 </papid></citsent>
<aftsection>
<nextsent>semi-supervised and unsupervised methods are important because good labeled data is expensive, whereas there is no shortage of unlabeled data.
</nextsent>
<nextsent>while some domain-language pairs have quite bit of labelled data (e.g. news text in english), many other categories are not as fortunate.
</nextsent>
<nextsent>less unsupervised methods are more likely to be portable to these new domains, since they do not rely as much on existing annotations.
</nextsent>
<nextsent>a simple method of incorporating unlabeled data into new model is self-training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2139">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>this process can be iterated over different sets of unlabeled data if desired.
</prevsent>
<prevsent>it is not surprising that self-training is not normally effective: charniak(1997) and steedman et al (2003) <papid> E03-1008 </papid>report either minor improvements or significant damage from using self-training for parsing.</prevsent>
</prevsection>
<citsent citstr=" W03-0407 ">
clark et al (2003) <papid> W03-0407 </papid>applies self-training to pos-tagging and reports the sameoutcomes.</citsent>
<aftsection>
<nextsent>one would assume that errors in the original model would be amplified in the new model.parser adaptation can be framed as semi supervised or unsupervised learning problem.
</nextsent>
<nextsent>in parser adaptation, one is given annotated training data from source domain and unannotated data from target.
</nextsent>
<nextsent>in some cases, some annotated data from the target domain is available as well.
</nextsent>
<nextsent>the goal is to use the various datasets to produce model that accurately parses the target domain data despite seeing little or no annotated data from that domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2140">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in some cases, some annotated data from the target domain is available as well.
</prevsent>
<prevsent>the goal is to use the various datasets to produce model that accurately parses the target domain data despite seeing little or no annotated data from that domain.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
gildea (2001) <papid> W01-0521 </papid>and bacchiani et al (2006) show thatout-of-domain training data can improve parsing ac 152 curacy.</citsent>
<aftsection>
<nextsent>the unsupervised adaptation experiment by bacchiani et al (2006) is the only successful instance of parsing self-training that we have found.
</nextsent>
<nextsent>our work differs in that all our data is in-domainwhile bacchiani et al uses the brown corpus as labelled data.
</nextsent>
<nextsent>these correspond to different scenarios.
</nextsent>
<nextsent>additionally, we explore the use of reranker.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2141">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>when one learner is confident of its predictions about the data,we apply the predicted label of the data to the training set of the other learners.
</prevsent>
<prevsent>a variation suggested by dasgupta et al (2001) is to add data to the training set when multiple learners agree on the label.
</prevsent>
</prevsection>
<citsent citstr=" N01-1023 ">
if this is the case, we can be more confident that the data was labelled correctly than if only one learner had labelled it.sarkar (2001) <papid> N01-1023 </papid>and steedman et al (2003) <papid> E03-1008 </papid>investigated using co-training for parsing.</citsent>
<aftsection>
<nextsent>these studies suggest that this type of co-training is most effective when small amounts of labelled training data is available.
</nextsent>
<nextsent>additionally, co-training for parsing can be helpful for parser adaptation.
</nextsent>
<nextsent>our parsing model consists of two phases.
</nextsent>
<nextsent>first, we use generative parser to produce list of the top parses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2144">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>nevertheless, the re rankers value comes from its ability to make use of more powerful features.
</prevsent>
<prevsent>3.1 the first-stage 50-best parser.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the first stage of our parser is the lexicalized probabilistic context-free parser described in (charniak, 2000) <papid> A00-2018 </papid>and (charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>the parsers grammar is smoothed third-order markov grammar, enhanced with lexical heads, their partsof speech, and parent and grandparent information.
</nextsent>
<nextsent>the parser uses five probability distributions,one each for heads, their parts-of-speech, head constituent, left-of-head constituents, and right-ofhead constituents.
</nextsent>
<nextsent>as all distributions are conditioned with five or more features, they are all heavily backed off using chen back-off (the average-count method from chen and goodman (1996)).<papid> P96-1041 </papid></nextsent>
<nextsent>also, the statistics are lightly pruned to remove those thatare statistically less reliable/useful.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2146">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the parsers grammar is smoothed third-order markov grammar, enhanced with lexical heads, their partsof speech, and parent and grandparent information.
</prevsent>
<prevsent>the parser uses five probability distributions,one each for heads, their parts-of-speech, head constituent, left-of-head constituents, and right-ofhead constituents.
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
as all distributions are conditioned with five or more features, they are all heavily backed off using chen back-off (the average-count method from chen and goodman (1996)).<papid> P96-1041 </papid></citsent>
<aftsection>
<nextsent>also, the statistics are lightly pruned to remove those thatare statistically less reliable/useful.
</nextsent>
<nextsent>as in (charniak and johnson, 2005) <papid> P05-1022 </papid>the parser has been modified to produce n-best parses.</nextsent>
<nextsent>however, the n-best parsing algorithm described in that paper has been replaced by the much more efficient algorithm described in (jimenez and marzal, 2000; huang and chang, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2149">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the second stage of our parser is maximum entropy reranker, as described in (charniak and johnson, 2005).<papid> P05-1022 </papid></prevsent>
<prevsent>the reranker takes the 50-best parses for each sentence produced by the first-stage 50 best parser and selects the best parse from those50 parses.</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
it does this using the reranking methodology described in collins (2000), using maximum entropy model with gaussian regularization as described in johnson et al (1999).<papid> P99-1069 </papid></citsent>
<aftsection>
<nextsent>our reranker classifies each parse with respect to 1,333,519 features (most of which only occur on few parses).the features consist of those described in (char niak and johnson, 2005), <papid> P05-1022 </papid>together with an additional601,577 features.</nextsent>
<nextsent>these features consist of the parts of-speech, possibly together with the words, that surround (i.e., precede or follow) the left and right edges of each constituent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2152">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>these additional features are largely responsible for improving the re rankers performance on section 23to 91.3% -score (charniak and johnson (2005) <papid> P05-1022 </papid>reported an -score of 91.0% on section 23).</prevsent>
<prevsent>3.3 corpora.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
our labeled data comes from the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>and consists of about 40,000 sentences from wall street journal (wsj) articles 153 annotated with syntactic information.</citsent>
<aftsection>
<nextsent>we use the standard divisions: sections 2 through 21 are used for training, section 24 is held-out development, and section 23 is used for final testing.
</nextsent>
<nextsent>our unlabeled data is the north american news text corpus, nanc(graff, 1995), which is approximately 24 million unlabeled sentences from various news sources.
</nextsent>
<nextsent>nanccontains no syntactic information.
</nextsent>
<nextsent>sentence boundaries in nanc are induced by simple discriminative model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2155">
<title id=" N06-1020.xml">effective self training for parsing </title>
<section> analysis.  </section>
<citcontext>
<prevsection>
<prevsent>conjunctions are about the hardest things in parsing, and we have no grip on exactly what it takes to help parse them.
</prevsent>
<prevsent>conversely, everyone expected improvement son unknown words, as the self-training should dras 157 0 1 2 3 4 5 0 50 0 10 00 15 00 20 00 number of ccs um be o s en te nc es better no change worse figure 5: how self-training improves performance as function of number of conjunctions tically reduce the number of them.
</prevsent>
</prevsection>
<citsent citstr=" J93-1005 ">
it is also the case that we thought pp attachment might be improved because of the increased coverage of preposition noun and preposition-verb combinations that work such as (hindle and rooth, 1993) <papid> J93-1005 </papid>show to be so im portant.</citsent>
<aftsection>
<nextsent>currently, our best conjecture is that unknowns are not improved because the words that are unknown in the wsj are not significantly represented in the la times we used for self-training.
</nextsent>
<nextsent>ccs are difficult for parsers because each conjunct has only one secure boundary.
</nextsent>
<nextsent>this is particularly the case with longer conjunctions, those of vps and ss.one thing we know is that self-training always improves performance of the parsing model when used as language model.
</nextsent>
<nextsent>we think cc improvement is connected with this fact and our earlier point that the probabilities of the 50-best parses are becoming more skewed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2156">
<title id=" N06-1042.xml">learning morphological disambiguation rules for turkish </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 4 presents the experiments and the results.
</prevsent>
<prevsent>there is large body of work on morphological disambiguation and part of speech tagging using variety of rule-based and statistical approaches.
</prevsent>
</prevsection>
<citsent citstr=" P97-1029 ">
in the 329 rule-based approach large number of handcrafted rules are used to select the correct morphological parse or pos tag of given word in given context (karlsson et al, 1995; oflazer and tur, 1997).<papid> P97-1029 </papid></citsent>
<aftsection>
<nextsent>in the statistical approach hand tagged corpus is used to train probabilistic model which is then used to select the best tags in unseen text (church, 1988;<papid> A88-1019 </papid>hakkani-tur et al, 2002).</nextsent>
<nextsent>examples of statistical and machine learning approaches that have been used for tagging include transformation based learning (brill, 1995), <papid> J95-4004 </papid>memory based learning (daele mans et al, 1996), <papid> W96-0102 </papid>and maximum entropy models(ratnaparkhi, 1996).<papid> W96-0213 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2157">
<title id=" N06-1042.xml">learning morphological disambiguation rules for turkish </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there is large body of work on morphological disambiguation and part of speech tagging using variety of rule-based and statistical approaches.
</prevsent>
<prevsent>in the 329 rule-based approach large number of handcrafted rules are used to select the correct morphological parse or pos tag of given word in given context (karlsson et al, 1995; oflazer and tur, 1997).<papid> P97-1029 </papid></prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
in the statistical approach hand tagged corpus is used to train probabilistic model which is then used to select the best tags in unseen text (church, 1988;<papid> A88-1019 </papid>hakkani-tur et al, 2002).</citsent>
<aftsection>
<nextsent>examples of statistical and machine learning approaches that have been used for tagging include transformation based learning (brill, 1995), <papid> J95-4004 </papid>memory based learning (daele mans et al, 1996), <papid> W96-0102 </papid>and maximum entropy models(ratnaparkhi, 1996).<papid> W96-0213 </papid></nextsent>
<nextsent>it is also possible to train statistical models using unlabeled data with the expectation maximization algorithm (cutting et al, 1992).<papid> A92-1018 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2158">
<title id=" N06-1042.xml">learning morphological disambiguation rules for turkish </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the 329 rule-based approach large number of handcrafted rules are used to select the correct morphological parse or pos tag of given word in given context (karlsson et al, 1995; oflazer and tur, 1997).<papid> P97-1029 </papid></prevsent>
<prevsent>in the statistical approach hand tagged corpus is used to train probabilistic model which is then used to select the best tags in unseen text (church, 1988;<papid> A88-1019 </papid>hakkani-tur et al, 2002).</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
examples of statistical and machine learning approaches that have been used for tagging include transformation based learning (brill, 1995), <papid> J95-4004 </papid>memory based learning (daele mans et al, 1996), <papid> W96-0102 </papid>and maximum entropy models(ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>it is also possible to train statistical models using unlabeled data with the expectation maximization algorithm (cutting et al, 1992).<papid> A92-1018 </papid></nextsent>
<nextsent>van halteren (1999) gives comprehensive overview of syntactic word-class tagging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2159">
<title id=" N06-1042.xml">learning morphological disambiguation rules for turkish </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the 329 rule-based approach large number of handcrafted rules are used to select the correct morphological parse or pos tag of given word in given context (karlsson et al, 1995; oflazer and tur, 1997).<papid> P97-1029 </papid></prevsent>
<prevsent>in the statistical approach hand tagged corpus is used to train probabilistic model which is then used to select the best tags in unseen text (church, 1988;<papid> A88-1019 </papid>hakkani-tur et al, 2002).</prevsent>
</prevsection>
<citsent citstr=" W96-0102 ">
examples of statistical and machine learning approaches that have been used for tagging include transformation based learning (brill, 1995), <papid> J95-4004 </papid>memory based learning (daele mans et al, 1996), <papid> W96-0102 </papid>and maximum entropy models(ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>it is also possible to train statistical models using unlabeled data with the expectation maximization algorithm (cutting et al, 1992).<papid> A92-1018 </papid></nextsent>
<nextsent>van halteren (1999) gives comprehensive overview of syntactic word-class tagging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2160">
<title id=" N06-1042.xml">learning morphological disambiguation rules for turkish </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the 329 rule-based approach large number of handcrafted rules are used to select the correct morphological parse or pos tag of given word in given context (karlsson et al, 1995; oflazer and tur, 1997).<papid> P97-1029 </papid></prevsent>
<prevsent>in the statistical approach hand tagged corpus is used to train probabilistic model which is then used to select the best tags in unseen text (church, 1988;<papid> A88-1019 </papid>hakkani-tur et al, 2002).</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
examples of statistical and machine learning approaches that have been used for tagging include transformation based learning (brill, 1995), <papid> J95-4004 </papid>memory based learning (daele mans et al, 1996), <papid> W96-0102 </papid>and maximum entropy models(ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>it is also possible to train statistical models using unlabeled data with the expectation maximization algorithm (cutting et al, 1992).<papid> A92-1018 </papid></nextsent>
<nextsent>van halteren (1999) gives comprehensive overview of syntactic word-class tagging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2161">
<title id=" N06-1042.xml">learning morphological disambiguation rules for turkish </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the statistical approach hand tagged corpus is used to train probabilistic model which is then used to select the best tags in unseen text (church, 1988;<papid> A88-1019 </papid>hakkani-tur et al, 2002).</prevsent>
<prevsent>examples of statistical and machine learning approaches that have been used for tagging include transformation based learning (brill, 1995), <papid> J95-4004 </papid>memory based learning (daele mans et al, 1996), <papid> W96-0102 </papid>and maximum entropy models(ratnaparkhi, 1996).<papid> W96-0213 </papid></prevsent>
</prevsection>
<citsent citstr=" A92-1018 ">
it is also possible to train statistical models using unlabeled data with the expectation maximization algorithm (cutting et al, 1992).<papid> A92-1018 </papid></citsent>
<aftsection>
<nextsent>van halteren (1999) gives comprehensive overview of syntactic word-class tagging.
</nextsent>
<nextsent>previous work on morphological disambiguation of inflectional or agglutinative languages include unsupervised learning for of hebrew (levinger et al, 1995), <papid> J95-3004 </papid>maximum entropy modeling for czech (hajic?</nextsent>
<nextsent>and hladka?, 1998), combination of statistical and rule-based disambiguation methods for basque (ezeiza et al, 1998), <papid> P98-1063 </papid>transformation based tagging for hungarian (megyesi, 1999).early work on turkish used constraint-based approach with handcrafted rules (oflazer and kuruoz,1994).<papid> A94-1024 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2162">
<title id=" N06-1042.xml">learning morphological disambiguation rules for turkish </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>it is also possible to train statistical models using unlabeled data with the expectation maximization algorithm (cutting et al, 1992).<papid> A92-1018 </papid></prevsent>
<prevsent>van halteren (1999) gives comprehensive overview of syntactic word-class tagging.</prevsent>
</prevsection>
<citsent citstr=" J95-3004 ">
previous work on morphological disambiguation of inflectional or agglutinative languages include unsupervised learning for of hebrew (levinger et al, 1995), <papid> J95-3004 </papid>maximum entropy modeling for czech (hajic?</citsent>
<aftsection>
<nextsent>and hladka?, 1998), combination of statistical and rule-based disambiguation methods for basque (ezeiza et al, 1998), <papid> P98-1063 </papid>transformation based tagging for hungarian (megyesi, 1999).early work on turkish used constraint-based approach with handcrafted rules (oflazer and kuruoz,1994).<papid> A94-1024 </papid></nextsent>
<nextsent>a purely statistical morphological disambiguation model was recently introduced (hakkani tur et al, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2163">
<title id=" N06-1042.xml">learning morphological disambiguation rules for turkish </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>van halteren (1999) gives comprehensive overview of syntactic word-class tagging.
</prevsent>
<prevsent>previous work on morphological disambiguation of inflectional or agglutinative languages include unsupervised learning for of hebrew (levinger et al, 1995), <papid> J95-3004 </papid>maximum entropy modeling for czech (hajic?</prevsent>
</prevsection>
<citsent citstr=" P98-1063 ">
and hladka?, 1998), combination of statistical and rule-based disambiguation methods for basque (ezeiza et al, 1998), <papid> P98-1063 </papid>transformation based tagging for hungarian (megyesi, 1999).early work on turkish used constraint-based approach with handcrafted rules (oflazer and kuruoz,1994).<papid> A94-1024 </papid></citsent>
<aftsection>
<nextsent>a purely statistical morphological disambiguation model was recently introduced (hakkani tur et al, 2002).
</nextsent>
<nextsent>to counter the data sparseness problem the morphological parses are split across their derivational boundaries and certain independence assumptions are made in the prediction of each inflectional group.
</nextsent>
<nextsent>a combination of three ideas makes our approach unique in the field: (1) the use of decision lists anda novel learning algorithm that combine the statistical and rule based techniques, (2) the treatment of each individual feature separately to address the data sparseness problem, and (3) the lack of dependence on previous tags and relying on surface attributes alone.
</nextsent>
<nextsent>we introduce new method for morphological disambiguation based on decision lists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2164">
<title id=" N06-1042.xml">learning morphological disambiguation rules for turkish </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>van halteren (1999) gives comprehensive overview of syntactic word-class tagging.
</prevsent>
<prevsent>previous work on morphological disambiguation of inflectional or agglutinative languages include unsupervised learning for of hebrew (levinger et al, 1995), <papid> J95-3004 </papid>maximum entropy modeling for czech (hajic?</prevsent>
</prevsection>
<citsent citstr=" A94-1024 ">
and hladka?, 1998), combination of statistical and rule-based disambiguation methods for basque (ezeiza et al, 1998), <papid> P98-1063 </papid>transformation based tagging for hungarian (megyesi, 1999).early work on turkish used constraint-based approach with handcrafted rules (oflazer and kuruoz,1994).<papid> A94-1024 </papid></citsent>
<aftsection>
<nextsent>a purely statistical morphological disambiguation model was recently introduced (hakkani tur et al, 2002).
</nextsent>
<nextsent>to counter the data sparseness problem the morphological parses are split across their derivational boundaries and certain independence assumptions are made in the prediction of each inflectional group.
</nextsent>
<nextsent>a combination of three ideas makes our approach unique in the field: (1) the use of decision lists anda novel learning algorithm that combine the statistical and rule based techniques, (2) the treatment of each individual feature separately to address the data sparseness problem, and (3) the lack of dependence on previous tags and relying on surface attributes alone.
</nextsent>
<nextsent>we introduce new method for morphological disambiguation based on decision lists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2165">
<title id=" N07-1044.xml">an information retrieval approach to sense ranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word sense disambiguation (wsd), the ability to identify the intended meanings (senses) of words in context, is crucial for accomplishing many nlp tasks that require semantic processing.
</prevsent>
<prevsent>examples include paraphrase acquisition, discourse parsing, or metonymy resolution.
</prevsent>
</prevsection>
<citsent citstr=" H05-1097 ">
applications such as machine translation (vickrey et al , 2005) <papid> H05-1097 </papid>and information retrieval (stokoe, 2005) <papid> H05-1051 </papid>have also been shown to benefit from wsd.</citsent>
<aftsection>
<nextsent>given the importance of wsd for basic nlp tasks and multilingual applications, much work has focused on the computational treatment of sense ambiguity, primarily using data-driven methods.most accurate wsd systems to date are supervised and relyon the availability of training data(see yarowsky and florian 2002; mihalcea and edmonds 2004 and the references therein).
</nextsent>
<nextsent>although supervised methods typically achieve better performance than unsupervised alternatives, their applicability is limited to those words for which sense labeled data exists, and their accuracy is strongly correlated with the amount of labeled data available.
</nextsent>
<nextsent>furthermore, current supervised approaches rarely outperform the simple heuristic of choosing the most common or dominant sense in the training data (henceforth the first sense heuristic?), despite taking local context into account.
</nextsent>
<nextsent>one reason for this is the highly skewed distribution of word senses (mccarthy et al , 2004<papid> W04-0837 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2166">
<title id=" N07-1044.xml">an information retrieval approach to sense ranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word sense disambiguation (wsd), the ability to identify the intended meanings (senses) of words in context, is crucial for accomplishing many nlp tasks that require semantic processing.
</prevsent>
<prevsent>examples include paraphrase acquisition, discourse parsing, or metonymy resolution.
</prevsent>
</prevsection>
<citsent citstr=" H05-1051 ">
applications such as machine translation (vickrey et al , 2005) <papid> H05-1097 </papid>and information retrieval (stokoe, 2005) <papid> H05-1051 </papid>have also been shown to benefit from wsd.</citsent>
<aftsection>
<nextsent>given the importance of wsd for basic nlp tasks and multilingual applications, much work has focused on the computational treatment of sense ambiguity, primarily using data-driven methods.most accurate wsd systems to date are supervised and relyon the availability of training data(see yarowsky and florian 2002; mihalcea and edmonds 2004 and the references therein).
</nextsent>
<nextsent>although supervised methods typically achieve better performance than unsupervised alternatives, their applicability is limited to those words for which sense labeled data exists, and their accuracy is strongly correlated with the amount of labeled data available.
</nextsent>
<nextsent>furthermore, current supervised approaches rarely outperform the simple heuristic of choosing the most common or dominant sense in the training data (henceforth the first sense heuristic?), despite taking local context into account.
</nextsent>
<nextsent>one reason for this is the highly skewed distribution of word senses (mccarthy et al , 2004<papid> W04-0837 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2167">
<title id=" N07-1044.xml">an information retrieval approach to sense ranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although supervised methods typically achieve better performance than unsupervised alternatives, their applicability is limited to those words for which sense labeled data exists, and their accuracy is strongly correlated with the amount of labeled data available.
</prevsent>
<prevsent>furthermore, current supervised approaches rarely outperform the simple heuristic of choosing the most common or dominant sense in the training data (henceforth the first sense heuristic?), despite taking local context into account.
</prevsent>
</prevsection>
<citsent citstr=" W04-0837 ">
one reason for this is the highly skewed distribution of word senses (mccarthy et al , 2004<papid> W04-0837 </papid>a).</citsent>
<aftsection>
<nextsent>a large number of frequent content words is often associated with only one dominant sense.obtaining the first sense via annotation is obviously costly and time consuming.
</nextsent>
<nextsent>sense annotated corpora are not readily available for different languages or indeed sense inventories.
</nextsent>
<nextsent>moreover, words dominant sense will vary across domains and text genres (the word court in legal documents will most likely mean tribunal rather than yard).it is therefore not surprising that recent work (mc carthy et al , 2004<papid> W04-0837 </papid>a; mohammad and hirst, 2006;<papid> E06-1016 </papid>brody et al , 2006) <papid> P06-1013 </papid>attempts to alleviate the annotation bottleneck by inferring the first sense automatically from raw text.</nextsent>
<nextsent>automatically acquired first senses will undoubtedly be noisy when compared tohuman annotations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2173">
<title id=" N07-1044.xml">an information retrieval approach to sense ranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a large number of frequent content words is often associated with only one dominant sense.obtaining the first sense via annotation is obviously costly and time consuming.
</prevsent>
<prevsent>sense annotated corpora are not readily available for different languages or indeed sense inventories.
</prevsent>
</prevsection>
<citsent citstr=" E06-1016 ">
moreover, words dominant sense will vary across domains and text genres (the word court in legal documents will most likely mean tribunal rather than yard).it is therefore not surprising that recent work (mc carthy et al , 2004<papid> W04-0837 </papid>a; mohammad and hirst, 2006;<papid> E06-1016 </papid>brody et al , 2006) <papid> P06-1013 </papid>attempts to alleviate the annotation bottleneck by inferring the first sense automatically from raw text.</citsent>
<aftsection>
<nextsent>automatically acquired first senses will undoubtedly be noisy when compared tohuman annotations.
</nextsent>
<nextsent>nevertheless, they can be usefully employed in two important tasks: (a) to create preliminary annotations, thus supporting the annotate automatically, correct manually?
</nextsent>
<nextsent>methodology used to provide high volume annotation in the penn treebank project; and (b) in combination with supervised wsd methods that take context into account;for instance, such methods could default to the dominant sense for unseen words or words with uninformative contexts.
</nextsent>
<nextsent>this paper focuses on knowledge-lean sense ranking method that exploits sense inventory like wordnet and corpus data to automatically induce dominant senses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2174">
<title id=" N07-1044.xml">an information retrieval approach to sense ranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a large number of frequent content words is often associated with only one dominant sense.obtaining the first sense via annotation is obviously costly and time consuming.
</prevsent>
<prevsent>sense annotated corpora are not readily available for different languages or indeed sense inventories.
</prevsent>
</prevsection>
<citsent citstr=" P06-1013 ">
moreover, words dominant sense will vary across domains and text genres (the word court in legal documents will most likely mean tribunal rather than yard).it is therefore not surprising that recent work (mc carthy et al , 2004<papid> W04-0837 </papid>a; mohammad and hirst, 2006;<papid> E06-1016 </papid>brody et al , 2006) <papid> P06-1013 </papid>attempts to alleviate the annotation bottleneck by inferring the first sense automatically from raw text.</citsent>
<aftsection>
<nextsent>automatically acquired first senses will undoubtedly be noisy when compared tohuman annotations.
</nextsent>
<nextsent>nevertheless, they can be usefully employed in two important tasks: (a) to create preliminary annotations, thus supporting the annotate automatically, correct manually?
</nextsent>
<nextsent>methodology used to provide high volume annotation in the penn treebank project; and (b) in combination with supervised wsd methods that take context into account;for instance, such methods could default to the dominant sense for unseen words or words with uninformative contexts.
</nextsent>
<nextsent>this paper focuses on knowledge-lean sense ranking method that exploits sense inventory like wordnet and corpus data to automatically induce dominant senses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2176">
<title id=" N07-1044.xml">an information retrieval approach to sense ranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the approach is inexpensive, language independent, requires minimal supervision, and uses no additional knowledge other than the word senses proper and morphological query expansions.
</prevsent>
<prevsent>we 348 evaluate our method on two tasks.
</prevsent>
</prevsection>
<citsent citstr=" W04-0811 ">
first, we use the acquired dominant senses to disambiguate the meanings of words in the senseval-2 (palmer et al , 2001) and senseval-3 (snyder and palmer, 2004)<papid> W04-0811 </papid>data sets.</citsent>
<aftsection>
<nextsent>second, we simulate native speakers?
</nextsent>
<nextsent>intuitions about the salience of word meanings and examine whether the estimated sense frequencies correlate with sense production data.
</nextsent>
<nextsent>in all cases our approach outperforms naive baseline and yields performances comparable to state of the art.
</nextsent>
<nextsent>in the following section, we provide an overview of existing work on sense ranking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2368">
<title id=" N07-1020.xml">high performance language independent morphological segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>though very successful, knowledge-based morphological analyzers operate by relying on manually designed segmentation heuristics (e.g. koskenniemi (1983)), which require lot of linguistic expertise and are time-consuming to construct.
</prevsent>
<prevsent>as result, research in morphological analysis has exhibited shift to unsupervised approaches, in which word is typically segmented based on morphemes that are automatically induced from an unannotated corpus.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
unsupervised approaches have achieved considerable success for english and many european languages (e.g. goldsmith (2001), <papid> J01-2001 </papid>schone and jurafsky (2001), <papid> N01-1024 </papid>freitag (2005)).<papid> W05-0617 </papid></citsent>
<aftsection>
<nextsent>the recent pascal challenge on unsupervised segmentation of words into morphemes1 has further intensified interest in this problem, selecting as target languages english as well as two highly agglutinative languages, turkish and finnish.
</nextsent>
<nextsent>however, the evaluation of the challenge reveals that (1) the success of existing unsupervised morphological parsers does not carry over to the two agglutinative languages, and (2) no segmentation algorithm achieves good performance for all three languages.
</nextsent>
<nextsent>motivated by these state-of-the-art results, our goal in this paper is to develop an unsupervised morphological segmentation algorithm that can work well across different languages.
</nextsent>
<nextsent>with this goal in mind, we evaluate our algorithm on four languages with different levels of morphological complexity, namely english, turkish, finnish and bengali.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2369">
<title id=" N07-1020.xml">high performance language independent morphological segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>though very successful, knowledge-based morphological analyzers operate by relying on manually designed segmentation heuristics (e.g. koskenniemi (1983)), which require lot of linguistic expertise and are time-consuming to construct.
</prevsent>
<prevsent>as result, research in morphological analysis has exhibited shift to unsupervised approaches, in which word is typically segmented based on morphemes that are automatically induced from an unannotated corpus.
</prevsent>
</prevsection>
<citsent citstr=" N01-1024 ">
unsupervised approaches have achieved considerable success for english and many european languages (e.g. goldsmith (2001), <papid> J01-2001 </papid>schone and jurafsky (2001), <papid> N01-1024 </papid>freitag (2005)).<papid> W05-0617 </papid></citsent>
<aftsection>
<nextsent>the recent pascal challenge on unsupervised segmentation of words into morphemes1 has further intensified interest in this problem, selecting as target languages english as well as two highly agglutinative languages, turkish and finnish.
</nextsent>
<nextsent>however, the evaluation of the challenge reveals that (1) the success of existing unsupervised morphological parsers does not carry over to the two agglutinative languages, and (2) no segmentation algorithm achieves good performance for all three languages.
</nextsent>
<nextsent>motivated by these state-of-the-art results, our goal in this paper is to develop an unsupervised morphological segmentation algorithm that can work well across different languages.
</nextsent>
<nextsent>with this goal in mind, we evaluate our algorithm on four languages with different levels of morphological complexity, namely english, turkish, finnish and bengali.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2370">
<title id=" N07-1020.xml">high performance language independent morphological segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>though very successful, knowledge-based morphological analyzers operate by relying on manually designed segmentation heuristics (e.g. koskenniemi (1983)), which require lot of linguistic expertise and are time-consuming to construct.
</prevsent>
<prevsent>as result, research in morphological analysis has exhibited shift to unsupervised approaches, in which word is typically segmented based on morphemes that are automatically induced from an unannotated corpus.
</prevsent>
</prevsection>
<citsent citstr=" W05-0617 ">
unsupervised approaches have achieved considerable success for english and many european languages (e.g. goldsmith (2001), <papid> J01-2001 </papid>schone and jurafsky (2001), <papid> N01-1024 </papid>freitag (2005)).<papid> W05-0617 </papid></citsent>
<aftsection>
<nextsent>the recent pascal challenge on unsupervised segmentation of words into morphemes1 has further intensified interest in this problem, selecting as target languages english as well as two highly agglutinative languages, turkish and finnish.
</nextsent>
<nextsent>however, the evaluation of the challenge reveals that (1) the success of existing unsupervised morphological parsers does not carry over to the two agglutinative languages, and (2) no segmentation algorithm achieves good performance for all three languages.
</nextsent>
<nextsent>motivated by these state-of-the-art results, our goal in this paper is to develop an unsupervised morphological segmentation algorithm that can work well across different languages.
</nextsent>
<nextsent>with this goal in mind, we evaluate our algorithm on four languages with different levels of morphological complexity, namely english, turkish, finnish and bengali.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2372">
<title id=" N07-1020.xml">high performance language independent morphological segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as deni?+al?, as is typically done in existing morphological parsers.
</prevsent>
<prevsent>in addition to addressing the aforementioned problems, our segmentation algorithm has two appealing features.
</prevsent>
</prevsection>
<citsent citstr=" P01-1063 ">
first, it can segment words with any number of morphemes, whereas many analyzers can only be applied to words with one root and one suffix (e.g. djean (1998), snover and brent (2001)).<papid> P01-1063 </papid></citsent>
<aftsection>
<nextsent>second, it exhibits robust performance even when inducing morphemes from very large vocabulary, whereas goldsmiths (2001) and frei tags (2005) morphological analyzers perform well only when small vocabulary is employed, showing deteriorating performance as the vocabulary size increases.
</nextsent>
<nextsent>the rest of this paper is organized as follows.
</nextsent>
<nextsent>section 2 presents related work on unsupervised morphological analysis.
</nextsent>
<nextsent>in section 3, we describe our basic morpheme induction algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2374">
<title id=" N07-1020.xml">high performance language independent morphological segmentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>brent et al (1995) are the first to introduce an information theoretic notion of compression to represent the mdl framework.
</prevsent>
<prevsent>goldsmith (2001) <papid> J01-2001 </papid>also adopts the mdl approach, providing new compression system that incorporates signatures when measuring the length of the morphological grammar.</prevsent>
</prevsection>
<citsent citstr=" P03-1036 ">
creutz (2003) <papid> P03-1036 </papid>proposes probabilistic maximum posteriori formulation that uses prior distributions of morpheme length and frequency to measure the goodness of an induced morpheme, achieving better results for finnish but worse results for english in comparison to goldsmiths linguistica.</citsent>
<aftsection>
<nextsent>rithm our unsupervised segmentation algorithm is composed of two steps: (1) inducing prefixes, suffixes and roots from vocabulary that consists of words taken from large corpus, and (2) segmenting word using these induced morphemes.
</nextsent>
<nextsent>this section describes our basic morpheme induction method.
</nextsent>
<nextsent>156 3.1 extracting list of candidate affixes.
</nextsent>
<nextsent>the first step of our morpheme induction method involves extracting list of candidate prefixes and suffixes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2376">
<title id=" N07-1020.xml">high performance language independent morphological segmentation </title>
<section> detecting incorrect attachments using.  </section>
<citcontext>
<prevsection>
<prevsent>this frequency disparity can be an important clue to determining that there is no morphological relation between candidate?
</prevsent>
<prevsent>and candid?.
</prevsent>
</prevsection>
<citsent citstr=" P00-1027 ">
similar observation is also made by yarowsky and wicentowski (2000), <papid> P00-1027 </papid>who successfully employ relative frequency similarity or disparity to rank candidate vbd/vb pairs (e.g. sang?/sing?)</citsent>
<aftsection>
<nextsent>that are irregular in nature.
</nextsent>
<nextsent>unlike yarowsky and wicentowski, however, our goal is to detect incorrect affix attachments and improve morphological analysis.
</nextsent>
<nextsent>our incorrect attachment detection algorithm, which exploits frequency disparity, is based on the following hypothesis: if word is formed by attaching an affix to root word r, then the corpus frequency of is likely to be less than that of (i.e. the frequency ratio of to is less than one).
</nextsent>
<nextsent>in other words, we hypothesize that the inflectional or derivational forms of root word occur less frequently in corpus than the root itself.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2378">
<title id=" N03-1027.xml">supervised and unsupervised pcfg adaptation to novel domains </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>this paper investigates adapting lexicalized probabilistic context-free grammar (pcfg) to novel domain, using maximum posteriori(map) estimation.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
the map framework is general enough to include some previous model adaptation approaches, such as corpus mixing in gildea (2001), <papid> W01-0521 </papid>for example.</citsent>
<aftsection>
<nextsent>other approaches falling within this framework are more effective.
</nextsent>
<nextsent>in contrast to the results in gildea (2001), <papid> W01-0521 </papid>we show f-measure parsing accuracy gains of asmuch as 2.5% for high accuracy lexicalized parsing through the use of out-of-domain treebanks,with the largest gains when the amount of in domain data is small.</nextsent>
<nextsent>map adaptation can also bebased on either supervised or unsupervised adaptation data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2384">
<title id=" N03-1027.xml">supervised and unsupervised pcfg adaptation to novel domains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a fundamental concern for nearly all data-driven approaches to language processing is the sparsity of labeled training data.
</prevsent>
<prevsent>the sparsity of syntactically annotated corpora is widely remarked upon, and some recent papers present approaches to improving performance in the absence of large amounts of annotated training data.
</prevsent>
</prevsection>
<citsent citstr=" A00-2021 ">
johnson and riezler (2000) <papid> A00-2021 </papid>looked at adding features to maximum entropy model for stochastic unification-based grammars (subg), from corpora that are not annotated with the subg, but rather with simpler treebank annotations for which there are much larger treebanks.</citsent>
<aftsection>
<nextsent>hwa (2001) <papid> W01-0710 </papid>demonstrated how active learning techniques can reduce the amount of annotated data required to converge on the best performance, by selecting from among the candidate strings to be annotated in ways which promote more informative examples for earlier annotation.</nextsent>
<nextsent>hwa (1999) <papid> P99-1010 </papid>and gildea (2001) <papid> W01-0521 </papid>looked at adapting parsing models trained on large amounts of annotated data from outside of the domain of interest (out-of-domain), through the use of relatively small amount of in-domain annotated data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2385">
<title id=" N03-1027.xml">supervised and unsupervised pcfg adaptation to novel domains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the sparsity of syntactically annotated corpora is widely remarked upon, and some recent papers present approaches to improving performance in the absence of large amounts of annotated training data.
</prevsent>
<prevsent>johnson and riezler (2000) <papid> A00-2021 </papid>looked at adding features to maximum entropy model for stochastic unification-based grammars (subg), from corpora that are not annotated with the subg, but rather with simpler treebank annotations for which there are much larger treebanks.</prevsent>
</prevsection>
<citsent citstr=" W01-0710 ">
hwa (2001) <papid> W01-0710 </papid>demonstrated how active learning techniques can reduce the amount of annotated data required to converge on the best performance, by selecting from among the candidate strings to be annotated in ways which promote more informative examples for earlier annotation.</citsent>
<aftsection>
<nextsent>hwa (1999) <papid> P99-1010 </papid>and gildea (2001) <papid> W01-0521 </papid>looked at adapting parsing models trained on large amounts of annotated data from outside of the domain of interest (out-of-domain), through the use of relatively small amount of in-domain annotated data.</nextsent>
<nextsent>hwa (1999) <papid> P99-1010 </papid>used variant of the inside-outside algorithm presented in pereira and schabes (1992) <papid> P92-1017 </papid>to exploit partially labeledout-of-domain treebank, and found an advantage to adaptation over direct grammar induction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2386">
<title id=" N03-1027.xml">supervised and unsupervised pcfg adaptation to novel domains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>johnson and riezler (2000) <papid> A00-2021 </papid>looked at adding features to maximum entropy model for stochastic unification-based grammars (subg), from corpora that are not annotated with the subg, but rather with simpler treebank annotations for which there are much larger treebanks.</prevsent>
<prevsent>hwa (2001) <papid> W01-0710 </papid>demonstrated how active learning techniques can reduce the amount of annotated data required to converge on the best performance, by selecting from among the candidate strings to be annotated in ways which promote more informative examples for earlier annotation.</prevsent>
</prevsection>
<citsent citstr=" P99-1010 ">
hwa (1999) <papid> P99-1010 </papid>and gildea (2001) <papid> W01-0521 </papid>looked at adapting parsing models trained on large amounts of annotated data from outside of the domain of interest (out-of-domain), through the use of relatively small amount of in-domain annotated data.</citsent>
<aftsection>
<nextsent>hwa (1999) <papid> P99-1010 </papid>used variant of the inside-outside algorithm presented in pereira and schabes (1992) <papid> P92-1017 </papid>to exploit partially labeledout-of-domain treebank, and found an advantage to adaptation over direct grammar induction.</nextsent>
<nextsent>gildea (2001) <papid> W01-0521 </papid>simply added the out-of-domain treebank to his in-domain training data, and derived very small benefit for his high accuracy, lexicalized parser, concluding that even large amount of out-of-domain data is of little use for lexicalized parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2397">
<title id=" N03-1027.xml">supervised and unsupervised pcfg adaptation to novel domains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hwa (2001) <papid> W01-0710 </papid>demonstrated how active learning techniques can reduce the amount of annotated data required to converge on the best performance, by selecting from among the candidate strings to be annotated in ways which promote more informative examples for earlier annotation.</prevsent>
<prevsent>hwa (1999) <papid> P99-1010 </papid>and gildea (2001) <papid> W01-0521 </papid>looked at adapting parsing models trained on large amounts of annotated data from outside of the domain of interest (out-of-domain), through the use of relatively small amount of in-domain annotated data.</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
hwa (1999) <papid> P99-1010 </papid>used variant of the inside-outside algorithm presented in pereira and schabes (1992) <papid> P92-1017 </papid>to exploit partially labeledout-of-domain treebank, and found an advantage to adaptation over direct grammar induction.</citsent>
<aftsection>
<nextsent>gildea (2001) <papid> W01-0521 </papid>simply added the out-of-domain treebank to his in-domain training data, and derived very small benefit for his high accuracy, lexicalized parser, concluding that even large amount of out-of-domain data is of little use for lexicalized parsing.</nextsent>
<nextsent>statistical model adaptation based on sparse in-domaindata, however, is neither new problem nor unique to parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2414">
<title id=" N03-1027.xml">supervised and unsupervised pcfg adaptation to novel domains </title>
<section> map estimation.  </section>
<citcontext>
<prevsection>
<prevsent>p?(i | a) + c(a? i) c?(a)??
</prevsent>
<prevsent>+ c(a) = c?(a? i) + c(a? i) c?(a) + c(a) (7) 1an additional condition for well-formedness is that the pcfgis consistent or tight, i.e. there is no probability mass lost to infinitely large trees.
</prevsent>
</prevsection>
<citsent citstr=" J98-2005 ">
chi and geman (1998) <papid> J98-2005 </papid>proved that this condition is met if the rule probabilities are estimated using relative frequency estimation from corpus.</citsent>
<aftsection>
<nextsent>2.2 model interpolation.
</nextsent>
<nextsent>if the left-hand side dependent prior weighting parameter is chosen as = { c(a) 1??
</nextsent>
<nextsent>, 0   ?   1 if c(a)   0 1 otherwise (8) the map adaptation reduces to model interpolation using interpolation parameter ?: p?(i | a) = c(a) 1??
</nextsent>
<nextsent>p?(i | a) + c(a? i) c(a) 1??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2415">
<title id=" N03-1027.xml">supervised and unsupervised pcfg adaptation to novel domains </title>
<section> grammar and parser.  </section>
<citcontext>
<prevsection>
<prevsent>we leave the investigation of such approaches to future research.
</prevsent>
<prevsent>before providing empirical results on the count merging and model interpolation approaches, we will introduce the parser and parsing models that were used.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
for the empirical trials, we used top-down, left-to-right (incremental) statistical beam-search parser (roark, 2001<papid> J01-2004 </papid>a;roark, 2003).</citsent>
<aftsection>
<nextsent>we refer readers to the cited papers forde tails on this parsing algorithm.
</nextsent>
<nextsent>briefly, the parser maintains set of candidate analyses, each of which is extended to attempt to incorporate the next word into fully connected partial parse.
</nextsent>
<nextsent>as soon as enough?
</nextsent>
<nextsent>candidate parses have been extended to the next word, all parses that have not yet attached the word are discarded, and the parser moves on to the next word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2416">
<title id=" N03-1027.xml">supervised and unsupervised pcfg adaptation to novel domains </title>
<section> grammar and parser.  </section>
<citcontext>
<prevsection>
<prevsent>it is generative parser that does not require any pre-processing, such as pos tagging or chunking.
</prevsent>
<prevsent>it hasbeen demonstrated in the above papers to perform competitively on standard statistical parsing tasks with full cover age.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
baseline results below will provide comparison with other well known statistical parsers.the pcfg is markov grammar (collins, 1997; <papid> P97-1003 </papid>charniak, 2000), <papid> A00-2018 </papid>i.e. the production probabilities are estimated by decomposing the joint probability of the categories on the right-hand side into product of condition als via the chain rule, and making markov assumption.</citsent>
<aftsection>
<nextsent>thus, for example, first order markov grammar conditions the probability ofthe category of the i-th child of the left-hand side on the category of the left-hand side and the category of the (i-1)-thchild of the left-hand side.
</nextsent>
<nextsent>the benefits of markov grammars for top-down parser of the sort we are using is detailed in roark (2003).
</nextsent>
<nextsent>further, as in roark (2001<papid> J01-2004 </papid>a), as in roark (2003), the production probabilities are conditioned on the label of the left-hand side of the production, as well as on features from the left-context.</nextsent>
<nextsent>the model is smoothed using standard deleted interpolation, wherein mixing parameter ? is estimated using em on held out corpus, such that probability of production ? ?, conditioned on features from the left context, xj1 = x1 . . .</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2417">
<title id=" N03-1027.xml">supervised and unsupervised pcfg adaptation to novel domains </title>
<section> grammar and parser.  </section>
<citcontext>
<prevsection>
<prevsent>it is generative parser that does not require any pre-processing, such as pos tagging or chunking.
</prevsent>
<prevsent>it hasbeen demonstrated in the above papers to perform competitively on standard statistical parsing tasks with full cover age.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
baseline results below will provide comparison with other well known statistical parsers.the pcfg is markov grammar (collins, 1997; <papid> P97-1003 </papid>charniak, 2000), <papid> A00-2018 </papid>i.e. the production probabilities are estimated by decomposing the joint probability of the categories on the right-hand side into product of condition als via the chain rule, and making markov assumption.</citsent>
<aftsection>
<nextsent>thus, for example, first order markov grammar conditions the probability ofthe category of the i-th child of the left-hand side on the category of the left-hand side and the category of the (i-1)-thchild of the left-hand side.
</nextsent>
<nextsent>the benefits of markov grammars for top-down parser of the sort we are using is detailed in roark (2003).
</nextsent>
<nextsent>further, as in roark (2001<papid> J01-2004 </papid>a), as in roark (2003), the production probabilities are conditioned on the label of the left-hand side of the production, as well as on features from the left-context.</nextsent>
<nextsent>the model is smoothed using standard deleted interpolation, wherein mixing parameter ? is estimated using em on held out corpus, such that probability of production ? ?, conditioned on features from the left context, xj1 = x1 . . .</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2420">
<title id=" N03-1027.xml">supervised and unsupervised pcfg adaptation to novel domains </title>
<section> grammar and parser.  </section>
<citcontext>
<prevsection>
<prevsent>deleted interpolation leaves out one feature at time, in the reverse order as they are presented in the table 1.
</prevsent>
<prevsent>the grammar that is used for these trials is pcfg thatis induced using relative frequency estimation from transformed treebank.
</prevsent>
</prevsection>
<citsent citstr=" C00-1052 ">
the trees are transformed with selective left-corner transformation (johnson and roark, 2000) <papid> C00-1052 </papid>that has been flattened as presented in roark (2001<papid> J01-2004 </papid>b).</citsent>
<aftsection>
<nextsent>this transform is only applied to left-recursive productions, i.e. productions of the form ? a?.
</nextsent>
<nextsent>the transformed trees look as in figure 1.
</nextsent>
<nextsent>the transform has the benefit for top down incremental parser of this sort of delaying many ofthe parsing decisions until later in the string, without unduly disrupting the immediate dominance relationships that provide conditioning features for the probabilistic model.
</nextsent>
<nextsent>(a) np  np  np  nnp jim bb pos hhh nn dog pppp pp , in with . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2423">
<title id=" N03-1027.xml">supervised and unsupervised pcfg adaptation to novel domains </title>
<section> c-commanding lexical head </section>
<citcontext>
<prevsection>
<prevsent>let be the number of parses that have incorporated the next word, and let pbe the best probability from among that set.
</prevsent>
<prevsent>then the probability of parse must be above pk 3 10?
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
to avoid being pruned.2see johnson (1998) <papid> J98-4004 </papid>for presentation of the transform/de transform paradigm in parsing.</citsent>
<aftsection>
<nextsent>4 empirical trials.
</nextsent>
<nextsent>the parsing models were trained and tested on treebanks from the penn treebank ii.
</nextsent>
<nextsent>for the wall st. journal portion, we used the standard breakdown: sections 2-21 were kept training data; section 24 was held-out development data; and section 23 was for evaluation.
</nextsent>
<nextsent>for the brown corpus portion, we obtained the training and evaluation sections used in gildea (2001).<papid> W01-0521 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2458">
<title id=" N06-3007.xml">document representation and multilevel measures of document similarity </title>
<section> dimensionality reduction for document.  </section>
<citcontext>
<prevsection>
<prevsent>the availability of large document collections suchas the web offers great resource for statistical approaches.
</prevsent>
<prevsent>recently, co-occurrence based measures of semantic similarity between terms has been shown to improve performance onsuch tasks as the synonymy test, taxonomy induction, etc.
</prevsent>
</prevsection>
<citsent citstr=" N03-1032 ">
(turney, 2001; terra and clarke, 2003; <papid> N03-1032 </papid>chklovski and pantel, 2004).<papid> W04-3205 </papid></citsent>
<aftsection>
<nextsent>on the other hand, many semi-supervised and trans ductive methods based on document vectors cannot yet handle such large document collections.
</nextsent>
<nextsent>while the vocabulary size is still quite large,it is intuitively clear that the intrinsic dimensionality of the vocabulary space is much lower.
</nextsent>
<nextsent>content bearing words are often combined into semantic classes that correspond to particular activities or relations and contain synonyms and semantically related words.
</nextsent>
<nextsent>therefore, itseems very natural to represent terms as low dimensional vectors in the space of semantic concepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2459">
<title id=" N06-3007.xml">document representation and multilevel measures of document similarity </title>
<section> dimensionality reduction for document.  </section>
<citcontext>
<prevsection>
<prevsent>the availability of large document collections suchas the web offers great resource for statistical approaches.
</prevsent>
<prevsent>recently, co-occurrence based measures of semantic similarity between terms has been shown to improve performance onsuch tasks as the synonymy test, taxonomy induction, etc.
</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
(turney, 2001; terra and clarke, 2003; <papid> N03-1032 </papid>chklovski and pantel, 2004).<papid> W04-3205 </papid></citsent>
<aftsection>
<nextsent>on the other hand, many semi-supervised and trans ductive methods based on document vectors cannot yet handle such large document collections.
</nextsent>
<nextsent>while the vocabulary size is still quite large,it is intuitively clear that the intrinsic dimensionality of the vocabulary space is much lower.
</nextsent>
<nextsent>content bearing words are often combined into semantic classes that correspond to particular activities or relations and contain synonyms and semantically related words.
</nextsent>
<nextsent>therefore, itseems very natural to represent terms as low dimensional vectors in the space of semantic concepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2466">
<title id=" N06-3007.xml">document representation and multilevel measures of document similarity </title>
<section> dimensionality reduction for document.  </section>
<citcontext>
<prevsection>
<prevsent>the inner product between the glsa document vectors can be used as input to other algorithms.the language modelling approach (berger and lafferty, 1999) proved very effective for the information retrieval task.
</prevsent>
<prevsent>berger et. al (berger and lafferty, 1999) used translation probabilities between the document and query terms to account for synonymy and polysemy.
</prevsent>
</prevsection>
<citsent citstr=" E06-2017 ">
we proposed to use low dimensional term vectors for inducing the translation probabilities between terms (matveeva and levow, 2006).<papid> E06-2017 </papid></citsent>
<aftsection>
<nextsent>we used the same k-nn classification task asabove.
</nextsent>
<nextsent>with 100 training examples, the k-nn accuracy based on tf-idf document vectors was 0.58 and with the similarity based on the language modelling with glsa term translation probabilities the accuracy was 0.69.
</nextsent>
<nextsent>with larger training sets the difference in performance was less significant.
</nextsent>
<nextsent>these results illustrate that the pair-wise similarities between the glsa term vectors add important semantic information which helps to go beyond term matching and deal with synonymy and polysemy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2467">
<title id=" N06-3007.xml">document representation and multilevel measures of document similarity </title>
<section> work in progress.  </section>
<citcontext>
<prevsection>
<prevsent>this validates our approach to selecting the content bearing terms and shows the advantage of using the glsa framework.
</prevsent>
<prevsent>we are going to extend the set of content bearing words andto include verbs.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
we will take advantage of the flexibility provided by our framework and use syntax based measure of similarity in the computation of the verb vectors, following (lin, 1998).<papid> P98-2127 </papid>currently we are using string matching to compute the named entity based measure of similar ity.</citsent>
<aftsection>
<nextsent>we are planning to integrate more sophisticated techniques in our framework.
</nextsent>
<nextsent>we developed the glsa framework for computing semantically motivated term and document vectors.
</nextsent>
<nextsent>this framework takes advantage of the availability of large document collections and recent research of corpus-based term similarity measures and combines them with dimensionality reduction algorithms.
</nextsent>
<nextsent>different measures of similarity may be required for different groups of terms such as content bearing vocabulary words and named entities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2468">
<title id=" N04-3003.xml">limited domain speechtospeech translation between english and pashto </title>
<section> overall architecture.  </section>
<citcontext>
<prevsection>
<prevsent>spoken input, in either english or pashto, is recognized by sris small-footprint dynaspeak?
</prevsent>
<prevsent>recognizer, and an ordered list of hypotheses is produced.
</prevsent>
</prevsection>
<citsent citstr=" P93-1008 ">
the most likely hypothesis is input to sri gemini natural language parser/generator (dowding et al. 1993), <papid> P93-1008 </papid>which attempts to parse the speech recognition output.</citsent>
<aftsection>
<nextsent>handling of possible errors or failures will be discussed in section 3.
</nextsent>
<nextsent>when successful parse is obtained, gemini creates quasi-logical form representing the meaning of the sentence.
</nextsent>
<nextsent>in general, multiple quasi-logical forms may be created, reflecting differing interpretations of the input sentence.
</nextsent>
<nextsent>these forms, which are domain independent and serve here as an interlingua, can be ordered by heuristic ally assigning preferences or dis preferences to the parsing rules applied to create them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2469">
<title id=" N03-2008.xml">a maximum entropy approach to framenet tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in each framenet sentence, single target predicate is identified and all of its relevant frame elements are tagged with their element-type (e.g., agent, judge), their syntactic phrase type (e.g., np, pp), and their grammatical function (e.g., external argument, object argument).
</prevsent>
<prevsent>figure 1 shows an example of an annotated sentence and its appropriate semantic frame.
</prevsent>
</prevsection>
<citsent citstr=" P00-1065 ">
to our knowledge, gildea and jurafsky (2000)<papid> P00-1065 </papid>is the only work that uses framenet to build statistical semantic classifier.</citsent>
<aftsection>
<nextsent>they split the problem into two distinct sub-tasks: frame element identification and frame element classification.
</nextsent>
<nextsent>in the identification phase, they use syntactic information extracted from parse tree to learn the boundaries of frame elements in sentences.
</nextsent>
<nextsent>the work presented here, focuses only on the second phase: classification.
</nextsent>
<nextsent>gildea and jurafsky (2000)<papid> P00-1065 </papid>describe system that uses completely syntactic features to classify the frame elements in sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2476">
<title id=" N03-2008.xml">a maximum entropy approach to framenet tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, we recast the classification task as tagging problem in which an n-gram model of frame elements is applied to find the most probable tag sequence (as opposed to the most probable individual tags).
</prevsent>
<prevsent>finally, we implement re-ranking system that takes advantage of the sentence-level syntactic patterns of each sequence.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
we analyze our results using syntactic features extracted from parse tree generated by collins parser (collins, 1997) <papid> P97-1003 </papid>and compare those to models built using features extracted from frame nets human annotations.</citsent>
<aftsection>
<nextsent>2.1 2.2 training (32,251 sentences), development (3,491 sentences), and held out test sets (3,398 sentences) were generated from the june 2002 framenet release following the divisions used in gildea and jurafsky (2000)<papid> P00-1065 </papid>1 . because human-annotated syntactic information could only be obtained for subset of their data, the training, development, and test sets used here are approximately 10% smaller than those used in gildea and jurafsky (2000)<papid> P00-1065 </papid>.2 there are on average 2.2 frame elements per sentence, falling into one of 126 unique classes.</nextsent>
<nextsent>maximum entropy me models implement the intuition that the best model will be the one that is consistent with all the evidence, but otherwise, is as uniform as possible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2481">
<title id=" N03-2008.xml">a maximum entropy approach to framenet tagging </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 2.2 training (32,251 sentences), development (3,491 sentences), and held out test sets (3,398 sentences) were generated from the june 2002 framenet release following the divisions used in gildea and jurafsky (2000)<papid> P00-1065 </papid>1 . because human-annotated syntactic information could only be obtained for subset of their data, the training, development, and test sets used here are approximately 10% smaller than those used in gildea and jurafsky (2000)<papid> P00-1065 </papid>.2 there are on average 2.2 frame elements per sentence, falling into one of 126 unique classes.</prevsent>
<prevsent>maximum entropy me models implement the intuition that the best model will be the one that is consistent with all the evidence, but otherwise, is as uniform as possible.</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
(berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>following recent successes using it for many nlp tasks (och and ney, 2002; <papid> P02-1038 </papid>koeling, 2000), <papid> W00-0729 </papid>we use me to implement frame element classifier.</nextsent>
<nextsent>we use the yasmet me package (och, 2002) to train an approximation of the model below: p(r| pt, voice, position, target, gf, h) here indicates the element type, pt the phrase type, gf the grammatical function, the head word, and target the target predicate.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2482">
<title id=" N03-2008.xml">a maximum entropy approach to framenet tagging </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>maximum entropy me models implement the intuition that the best model will be the one that is consistent with all the evidence, but otherwise, is as uniform as possible.
</prevsent>
<prevsent>(berger et al, 1996).<papid> J96-1002 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
following recent successes using it for many nlp tasks (och and ney, 2002; <papid> P02-1038 </papid>koeling, 2000), <papid> W00-0729 </papid>we use me to implement frame element classifier.</citsent>
<aftsection>
<nextsent>we use the yasmet me package (och, 2002) to train an approximation of the model below: p(r| pt, voice, position, target, gf, h) here indicates the element type, pt the phrase type, gf the grammatical function, the head word, and target the target predicate.
</nextsent>
<nextsent>due to data sparsity issues, we do not calculate this model directly, but rather, model various feature combinations as described in gildea and jurafsky (2000)<papid> P00-1065 </papid>.</nextsent>
<nextsent>the classifier was trained, using only features that had frequency in training of one or more, and until performance on the development set ceased to improve.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2483">
<title id=" N03-2008.xml">a maximum entropy approach to framenet tagging </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>maximum entropy me models implement the intuition that the best model will be the one that is consistent with all the evidence, but otherwise, is as uniform as possible.
</prevsent>
<prevsent>(berger et al, 1996).<papid> J96-1002 </papid></prevsent>
</prevsection>
<citsent citstr=" W00-0729 ">
following recent successes using it for many nlp tasks (och and ney, 2002; <papid> P02-1038 </papid>koeling, 2000), <papid> W00-0729 </papid>we use me to implement frame element classifier.</citsent>
<aftsection>
<nextsent>we use the yasmet me package (och, 2002) to train an approximation of the model below: p(r| pt, voice, position, target, gf, h) here indicates the element type, pt the phrase type, gf the grammatical function, the head word, and target the target predicate.
</nextsent>
<nextsent>due to data sparsity issues, we do not calculate this model directly, but rather, model various feature combinations as described in gildea and jurafsky (2000)<papid> P00-1065 </papid>.</nextsent>
<nextsent>the classifier was trained, using only features that had frequency in training of one or more, and until performance on the development set ceased to improve.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2485">
<title id=" N03-2008.xml">a maximum entropy approach to framenet tagging </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>for example, if frame element is tagged as an agent it is highly unlikely that the next element will also be an agent.
</prevsent>
<prevsent>we exploit this dependency by treating the frame element classification task as tagging problem.
</prevsent>
</prevsection>
<citsent citstr=" E03-1055 ">
the yasmet me tagger was used to apply an gram tag model to the classification task (bender et al, 2003).<papid> E03-1055 </papid></citsent>
<aftsection>
<nextsent>the feature set for the training data was 2.3
</nextsent>
<nextsent>1 divisions given by dan gildea via personal communication..
</nextsent>
<nextsent>2 gildea and jurafsky (2000)<papid> P00-1065 </papid>use 36995 training, 4000.</nextsent>
<nextsent>development, and 3865 test sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2491">
<title id=" N03-2008.xml">a maximum entropy approach to framenet tagging </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>the models trained on features extracted from parse trees do not have access to rich grammatical information.
</prevsent>
<prevsent>following gildea and jurafsky (2000)<papid> P00-1065 </papid>, automatic extraction of grammatical information here is limited to the governing category of noun phrase.</prevsent>
</prevsection>
<citsent citstr=" A00-2031 ">
the framenet annotations, however, are much richer and include information about complements, modifiers, etc. we are looking at ways to include such information either by using alternative parsers (hermjakob, 1997) or as postprocessing task (blaheta and charniak, 2000).<papid> A00-2031 </papid></citsent>
<aftsection>
<nextsent>in future work, we will extend the strategies outlined here to incorporate frame element identification into our model.
</nextsent>
<nextsent>by treating semantic classification as single tagging problem, we hope to create unified, practical, and high performance system for frame element tagging.
</nextsent>
<nextsent>76.375.8 74 85.7 83.8 82.6 68 70 72 74 76 78 80 82 84 86 88 me tagger re-rank % co rre ct extracted human acknowledgments the authors would like to thank dan gildea who generously allowed us access to his data files and oliver bender for making the me tagger software publicly available.
</nextsent>
<nextsent>finally, we thank franz och whose help and expertise were invaluable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2492">
<title id=" N04-1038.xml">unsupervised learning of contextual role knowledge for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these knowledge sources determine whether the contexts surrounding an anaphor and antecedent are compatible.babar applies dempster-shafer probabilistic model to make resolutions based on evidence from the contextual role knowledge sources as well as general knowledge sources.
</prevsent>
<prevsent>experiments in two domains showed that the contextual role knowledge improved coreference performance, especially on pronouns.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
the problem of coreference resolution has received considerable attention, including theoretical discourse models (e.g., (grosz et al, 1995; <papid> J95-2003 </papid>grosz and sidner, 1998)),syntactic algorithms (e.g., (hobbs, 1978; lappin and le ass, 1994)), <papid> J94-4002 </papid>and supervised machine learning systems (aone and bennett, 1995; mccarthy and lehnert, 1995;ng and cardie, 2002; <papid> P02-1014 </papid>soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>most computational models for coreference resolution relyon properties of the anaphor and candidate antecedent, such as lexical matching, grammatical and syntactic features, semantic agreement, and positional information.
</nextsent>
<nextsent>the focus of our work is on the use of contextual role knowledge for coreference resolution.
</nextsent>
<nextsent>a contextual role represents the role that noun phrase plays in an eventor relationship.
</nextsent>
<nextsent>our work is motivated by the observation that contextual roles can be critically important in determining the referent of noun phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2493">
<title id=" N04-1038.xml">unsupervised learning of contextual role knowledge for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these knowledge sources determine whether the contexts surrounding an anaphor and antecedent are compatible.babar applies dempster-shafer probabilistic model to make resolutions based on evidence from the contextual role knowledge sources as well as general knowledge sources.
</prevsent>
<prevsent>experiments in two domains showed that the contextual role knowledge improved coreference performance, especially on pronouns.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
the problem of coreference resolution has received considerable attention, including theoretical discourse models (e.g., (grosz et al, 1995; <papid> J95-2003 </papid>grosz and sidner, 1998)),syntactic algorithms (e.g., (hobbs, 1978; lappin and le ass, 1994)), <papid> J94-4002 </papid>and supervised machine learning systems (aone and bennett, 1995; mccarthy and lehnert, 1995;ng and cardie, 2002; <papid> P02-1014 </papid>soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>most computational models for coreference resolution relyon properties of the anaphor and candidate antecedent, such as lexical matching, grammatical and syntactic features, semantic agreement, and positional information.
</nextsent>
<nextsent>the focus of our work is on the use of contextual role knowledge for coreference resolution.
</nextsent>
<nextsent>a contextual role represents the role that noun phrase plays in an eventor relationship.
</nextsent>
<nextsent>our work is motivated by the observation that contextual roles can be critically important in determining the referent of noun phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2494">
<title id=" N04-1038.xml">unsupervised learning of contextual role knowledge for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these knowledge sources determine whether the contexts surrounding an anaphor and antecedent are compatible.babar applies dempster-shafer probabilistic model to make resolutions based on evidence from the contextual role knowledge sources as well as general knowledge sources.
</prevsent>
<prevsent>experiments in two domains showed that the contextual role knowledge improved coreference performance, especially on pronouns.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
the problem of coreference resolution has received considerable attention, including theoretical discourse models (e.g., (grosz et al, 1995; <papid> J95-2003 </papid>grosz and sidner, 1998)),syntactic algorithms (e.g., (hobbs, 1978; lappin and le ass, 1994)), <papid> J94-4002 </papid>and supervised machine learning systems (aone and bennett, 1995; mccarthy and lehnert, 1995;ng and cardie, 2002; <papid> P02-1014 </papid>soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>most computational models for coreference resolution relyon properties of the anaphor and candidate antecedent, such as lexical matching, grammatical and syntactic features, semantic agreement, and positional information.
</nextsent>
<nextsent>the focus of our work is on the use of contextual role knowledge for coreference resolution.
</nextsent>
<nextsent>a contextual role represents the role that noun phrase plays in an eventor relationship.
</nextsent>
<nextsent>our work is motivated by the observation that contextual roles can be critically important in determining the referent of noun phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2496">
<title id=" N04-1038.xml">unsupervised learning of contextual role knowledge for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these knowledge sources determine whether the contexts surrounding an anaphor and antecedent are compatible.babar applies dempster-shafer probabilistic model to make resolutions based on evidence from the contextual role knowledge sources as well as general knowledge sources.
</prevsent>
<prevsent>experiments in two domains showed that the contextual role knowledge improved coreference performance, especially on pronouns.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
the problem of coreference resolution has received considerable attention, including theoretical discourse models (e.g., (grosz et al, 1995; <papid> J95-2003 </papid>grosz and sidner, 1998)),syntactic algorithms (e.g., (hobbs, 1978; lappin and le ass, 1994)), <papid> J94-4002 </papid>and supervised machine learning systems (aone and bennett, 1995; mccarthy and lehnert, 1995;ng and cardie, 2002; <papid> P02-1014 </papid>soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>most computational models for coreference resolution relyon properties of the anaphor and candidate antecedent, such as lexical matching, grammatical and syntactic features, semantic agreement, and positional information.
</nextsent>
<nextsent>the focus of our work is on the use of contextual role knowledge for coreference resolution.
</nextsent>
<nextsent>a contextual role represents the role that noun phrase plays in an eventor relationship.
</nextsent>
<nextsent>our work is motivated by the observation that contextual roles can be critically important in determining the referent of noun phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2498">
<title id=" N04-1038.xml">unsupervised learning of contextual role knowledge for coreference resolution </title>
<section> learning contextual role knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>proper names that match are resolved with each other.
</prevsent>
<prevsent>the second case involves existential noun phrases(allen, 1995), which are noun phrases that uniquely specify an object or concept and therefore do not need prior referent in the discourse.
</prevsent>
</prevsection>
<citsent citstr=" P99-1048 ">
in previous work (beanand riloff, 1999), <papid> P99-1048 </papid>we developed an unsupervised learning algorithm that automatically recognizes definite npsthat are existential without syntactic modification because their meaning is universally understood.</citsent>
<aftsection>
<nextsent>for example, story can mention the fbi?, the white house?, or the weather?
</nextsent>
<nextsent>without any prior referent in the story.although these existential nps do not need prior referent, they may occur multiple times in document.
</nextsent>
<nextsent>by definition, each existential np uniquely specifies an object or concept, so we can infer that all instances of the same existential np are co referent (e.g., the fbi?
</nextsent>
<nextsent>always refers to the same entity).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2500">
<title id=" N04-1038.xml">unsupervised learning of contextual role knowledge for coreference resolution </title>
<section> learning contextual role knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>the cflex and cfnet knowledge sources provide positive evidence that candidate np and anaphor might be coreferent.
</prevsent>
<prevsent>they return value in the range [0,1], where 0 indicates neutrality and 1 indicates the strongest belief that the candidate and anaphor are coreferent.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
babar uses the log-likelihood statistic (dunning, 1993) <papid> J93-1003 </papid>to evaluate the strength of co-occurrence relationship.</citsent>
<aftsection>
<nextsent>for each co-occurrence relation (noun/caseframe for cflex, and caseframe/caseframe for cfnet), babar computes its log-likelihood value and looks it up in the  2 table to obtain confidence level.
</nextsent>
<nextsent>the confidence level is then used as the belief value for the knowledgesource.
</nextsent>
<nextsent>for example, if cflex determines that the log likelihood statistic for the co-occurrence of particular noun and case frame corresponds to the 90% confidence level, then cflex returns .90 as its belief that the anaphor and candidate are coreferent.
</nextsent>
<nextsent>given document to process, babar uses four modules to perform coreference resolution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2502">
<title id=" N04-1038.xml">unsupervised learning of contextual role knowledge for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there are two possible reasons: (1) the knowledge sources are resolving different cases of anaphora, and (2) the knowledge sources provide multiple pieces of evidence in support of (or against) candidate, thereby acting synergistic ally to push the dempster-shafer model over the belief threshold in favor of single candidate.
</prevsent>
<prevsent>many researchers have developed coreference re solvers, so we will only discuss the methods that are most closely related to babar.
</prevsent>
</prevsection>
<citsent citstr=" C90-3063 ">
dagan and itai (dagan and itai, 1990)<papid> C90-3063 </papid>experimented with co-occurrence statistics that are similar to our lexical case frame expectations.</citsent>
<aftsection>
<nextsent>their work used subject-verb, verb-object, and adjective-noun relations to compare the contexts surrounding an anaphor and candidate.
</nextsent>
<nextsent>however their work did not consider other types of lexical expectations (e.g., pp arguments), semantic expectations, or context comparisons like our case frame network.(niyu et al, 1998) used unsupervised learning to acquire gender, number, and animacy information from resolutions produced by statistical pronoun resolver.
</nextsent>
<nextsent>the learned information was recycled back into the re solver to improve its performance.
</nextsent>
<nextsent>this approach is similar tobabar in that they both acquire knowledge from earlier resolutions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2503">
<title id=" N04-1038.xml">unsupervised learning of contextual role knowledge for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the learned information was recycled back into the re solver to improve its performance.
</prevsent>
<prevsent>this approach is similar tobabar in that they both acquire knowledge from earlier resolutions.
</prevsent>
</prevsection>
<citsent citstr=" W97-0319 ">
(kehler, 1997) <papid> W97-0319 </papid>also used dempster shafer model to merge evidence from different sources for template-level coreference.</citsent>
<aftsection>
<nextsent>several coreference re solvers have used supervised learning techniques, such as decision trees and rule learners (aone and bennett, 1995; mccarthy and lehnert, 1995; ng and cardie, 2002; <papid> P02-1014 </papid>soon et al, 2001).<papid> J01-4004 </papid></nextsent>
<nextsent>these systems relyon training corpus that has been manually annotated with coreference links.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2508">
<title id=" N03-2013.xml">automatic expansion of equivalent sentence set based on syntactic substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiments show that 561 sentences on average are correctly generated from 8.48 equivalent sentences.
</prevsent>
<prevsent>sentences can be represented by various expressions even though they have the same meaning.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
paraphrasing that transfer from sentence to sentence (barzilay and mckeown, 2001) <papid> P01-1008 </papid>is technique that generates such various expressions.</citsent>
<aftsection>
<nextsent>in this paper, we propose an automatic quantitative expansion method for sentence set that contains sentences of the same meaning (called an equivalent sentence set), as paraphrasing technique.
</nextsent>
<nextsent>our method is roughly structured from the following two phases.
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>extract phrasal correspondences that have the same.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2509">
<title id=" N03-2013.xml">automatic expansion of equivalent sentence set based on syntactic substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, hierarchical phrase alignment (hpa) (imamura, 2001), whichis an automatic acquisition method for machine translation rules, is applied to acquire the paraphrasing rules.namely, two equivalent sentences are regarded as bilingual sentences, and simplified machine translation is carried out.paraphrasing by our method has the following charac teristics. not only lexical paraphrasing but also phrasal paraphrasing can be generated because our method is based on structural substitution.
</prevsent>
<prevsent> equivalent phrases extracted by hpa are not only semantically but also grammatically equivalent.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
thus, our method rarely generates ungrammatical sentences by substitution.expansion of the equivalent sentence set can be applied to automatic evaluation of machine translation quality (papineni et al, 2002; <papid> P02-1040 </papid>akiba et al, 2001), for example.</citsent>
<aftsection>
<nextsent>these methods evaluate the quality of the translation by measuring the similarity between machine translation results and translations done by humans (called references).
</nextsent>
<nextsent>however, the accuracy increases when multiple references are applied because one source sentence can be translated into multiple target expressions.
</nextsent>
<nextsent>our method generates multiple sentences that are suitable for this purpose.
</nextsent>
<nextsent>hierarchical phrase alignment hierarchical phrase alignment is based on the assumption that an equivalent phrase pair has the same information and the same grammatical role.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2510">
<title id=" N06-2047.xml">a maximum entropy framework that integrates word dependencies and grammatical relations for reading comprehension </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, hirschman et al.
</prevsent>
<prevsent>(1999) have augmented the bow approach with stemming, ne recognition, ne filtering, semantic class identification and pronoun resolution to achieve 36% humsent1 accuracy in the reme dia test set.
</prevsent>
</prevsection>
<citsent citstr=" W00-0603 ">
based on these technologies, riloff and thelen (2000) <papid> W00-0603 </papid>improved the humsent accuracy to 40% by applying set of heuristic rules that as sign handcrafted weights to matching words and ne.</citsent>
<aftsection>
<nextsent>charniak et al (2000) <papid> W00-0601 </papid>used additional strategies for different question types to achieve 41%.</nextsent>
<nextsent>an example strategy for why questions is that if the first word of the matching sentence is this,?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2511">
<title id=" N06-2047.xml">a maximum entropy framework that integrates word dependencies and grammatical relations for reading comprehension </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(1999) have augmented the bow approach with stemming, ne recognition, ne filtering, semantic class identification and pronoun resolution to achieve 36% humsent1 accuracy in the reme dia test set.
</prevsent>
<prevsent>based on these technologies, riloff and thelen (2000) <papid> W00-0603 </papid>improved the humsent accuracy to 40% by applying set of heuristic rules that as sign handcrafted weights to matching words and ne.</prevsent>
</prevsection>
<citsent citstr=" W00-0601 ">
charniak et al (2000) <papid> W00-0601 </papid>used additional strategies for different question types to achieve 41%.</citsent>
<aftsection>
<nextsent>an example strategy for why questions is that if the first word of the matching sentence is this,?
</nextsent>
<nextsent>that,?
</nextsent>
<nextsent>these?
</nextsent>
<nextsent>orthose,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2512">
<title id=" N06-2047.xml">a maximum entropy framework that integrates word dependencies and grammatical relations for reading comprehension </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system should select the previous sentence as an answer.
</prevsent>
<prevsent>light et al (2001) also introduced an approach to estimate the performance upper bound of the bow approach.
</prevsent>
</prevsection>
<citsent citstr=" H05-1076 ">
when we apply the same approach to the remedia test set, we obtained the upper bound of 48.3% humsent accuracy.the state-of-art performance reached 42% with answer patterns derived from web (du et al, 2005).<papid> H05-1076 </papid>this paper investigates the possibility of enhancing rc performance by applying deep?</citsent>
<aftsection>
<nextsent>linguistic analysis for every sentence in the passage.
</nextsent>
<nextsent>we refer to the use of two types of features, namely word dependencies and grammatical relations, that1if the systems answer sentence is identical to the corresponding human marked answer sentence, the question scores one point.
</nextsent>
<nextsent>otherwise, the question scores no point.
</nextsent>
<nextsent>humsent accuracy is the average score across all questions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2513">
<title id=" N06-2047.xml">a maximum entropy framework that integrates word dependencies and grammatical relations for reading comprehension </title>
<section> corpora.  </section>
<citcontext>
<prevsection>
<prevsent>grammatical relations (gr) refer to linkages such as subject, object, modifier, etc. the me framework has shown its effectiveness in solving qa tasks (ittycheriah et al, 1994).
</prevsent>
<prevsent>in comparison with previous approaches mentioned earlier, the current approach involves richer syntactic information that cover longer-distance relationships.
</prevsent>
</prevsection>
<citsent citstr=" P99-1042 ">
we used the remedia corpus (hirschman et al, 1999) <papid> P99-1042 </papid>and chung hwa corpus (xu and meng, 2005) in our experiments.</citsent>
<aftsection>
<nextsent>the remedia corpus contains 55 training stories and 60 testing stories (about 20kwords).
</nextsent>
<nextsent>each story contains 20 sentences on average and is accompanied by five types of questions: who, what, when, where and why.
</nextsent>
<nextsent>the chung hwa corpus contains 50 training stories and 50 test stories (about 18k words).
</nextsent>
<nextsent>each story contains 9 sentences and is accompanied by four questions on average.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2514">
<title id=" N06-2047.xml">a maximum entropy framework that integrates word dependencies and grammatical relations for reading comprehension </title>
<section> the maximum entropy framework.  </section>
<citcontext>
<prevsection>
<prevsent>, cn, the objective of an rc system can be described as: = arg maxcis (ci answers q|q).
</prevsent>
<prevsent>(1) let x? be the question (q) and y? be the answer sentence ci that answers x?.
</prevsent>
</prevsection>
<citsent citstr=" W03-1020 ">
equation 1 can be computed by the me method (zhou et al, 2003): <papid> W03-1020 </papid>p(y|x) = 1z(x) exp ? jfj(x,y), (2) where z(x) = exp ? jfj(x,y) is normalization factor, fj(x, y) is the indicator function for feature fj; fj occurs in the context x, is the weight of fj . forgiven question q, the ci with the highest probability is selected.</citsent>
<aftsection>
<nextsent>if multiple sentences have the maximum probability, the one that occurs the earliest in the passage is returned.
</nextsent>
<nextsent>we used the selective gain computation (sgc) algorithm (zhou et al, 2003) <papid> W03-1020 </papid>to select features and estimate parameters for its fast performance.</nextsent>
<nextsent>question: who wrote the  pledge of allegiance  answer sentence: the pledge was written by frances bellamy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2519">
<title id=" N01-1010.xml">treecut and a lexicon based on systematic polysemy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we compare our lexicon to wordnet cousins, and the inter-annotator disagreement observed between wordnet semcor and dso corpora.
</prevsent>
<prevsent>in recent years, the granularity of word senses for computational lexicons has been discussed frequently in lexical semantics (for example, (kilgar ri, 1998a; palmer, 1998)).
</prevsent>
</prevsection>
<citsent citstr=" W99-0502 ">
this issue emerged as aprominent problem after previous studies and exercises in word sense disambiguation (wsd) reported that, when ne-grained sense de nitions suchas those in wordnet (miller, 1990) were used, entries became very similar and indistinguishable to human annotators, thereby causing disagreement on correct tags (kilgarri, 1998b; veronis, 1998; ng et al., 1999).<papid> W99-0502 </papid></citsent>
<aftsection>
<nextsent>in addition to wsd, the selection of sense inventories is fundamentally critical in other natural language processing (nlp) tasks such as information extraction (ie) and machine translation (mt), as well as in information retrieval (ir), since thedierence in the correct sense assignments aects recall, precision and other evaluation measures.
</nextsent>
<nextsent>in response to this, several approaches have been proposed which group ne-grained word senses in various ways to derive coarse-grained sense groups.some approaches utilize an abstraction hierarchy de ned in dictionary (kilgarri, 1998b), while others utilize surface syntactic patterns of the functional structures (such as predicate-argument structure for verbs) of words (palmer, 1998).
</nextsent>
<nextsent>also, the current version of wordnet (1.6) encodes groupings of sim ilar/related word senses (or synsets) by relation called cousin.
</nextsent>
<nextsent>another approach to grouping word senses is to utilize linguistic phenomenon called systematicpolysemy: set of word senses that are related in systematic and predictable ways.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2520">
<title id=" N01-1010.xml">treecut and a lexicon based on systematic polysemy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus, systematic polysemy can be eectively used in wsd (and wsd evaluation) to accept multiple or alternative sense tags (buitelaar, personal communication).
</prevsent>
<prevsent>second, many systematic relations are observed between senses which belong to dierent semantic categories.so if lexicon is de ned by collection of separate trees/hierarchies (such as the case of wordnet), systematic polysemy can express similarity between senses that are not hierarchically proximate.third, by explicitly representing (inter-)relations between senses, lexicon based on systematic poly semy can facilitate semantic inferences.
</prevsent>
</prevsection>
<citsent citstr=" W00-0802 ">
thus it is useful in knowledge-intensive nlp tasks such as discourse analysis, ie and mt. more recently, (gonzaloet al, 2000) <papid> W00-0802 </papid>also discusses potential usefulness of systematic polysemy for clustering word senses for ir.</citsent>
<aftsection>
<nextsent>however, extracting systematic relations from large sense inventories is dicult task.
</nextsent>
<nextsent>most of ten, this procedure is done manually.
</nextsent>
<nextsent>for example, wordnet cousin relations were identi ed manually by the wordnet lexicographers.
</nextsent>
<nextsent>a similar eort was also made in the euro wordnet project (vossen et 1 systematic polysemy (in the sense we use in this paper) is also referred to as regular polysemy (apresjan, 1973) or logical polysemy (pustejovsky, 1995).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2521">
<title id=" N01-1010.xml">treecut and a lexicon based on systematic polysemy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problem is not only that manual inspection of large, complex lexicon is very time consuming, it is also prone to inconsistencies.
</prevsent>
<prevsent>in this paper, we describes lexicon organized around systematic polysemy.
</prevsent>
</prevsection>
<citsent citstr=" J98-2002 ">
the lexicon is derived by fully automatic extraction method which utilizes clustering technique called tree-cut (li and abe, 1998).<papid> J98-2002 </papid></citsent>
<aftsection>
<nextsent>in our previous work (tomuro, 2000),<papid> W00-0104 </papid>we applied this method to small subset of wordnet nouns and showed potential applicability.</nextsent>
<nextsent>in the current work, we applied the method to all nouns and verbs in wordnet, and built lexicon in which word senses are partitioned by systematic polysemy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2523">
<title id=" N01-1010.xml">treecut and a lexicon based on systematic polysemy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we describes lexicon organized around systematic polysemy.
</prevsent>
<prevsent>the lexicon is derived by fully automatic extraction method which utilizes clustering technique called tree-cut (li and abe, 1998).<papid> J98-2002 </papid></prevsent>
</prevsection>
<citsent citstr=" W00-0104 ">
in our previous work (tomuro, 2000),<papid> W00-0104 </papid>we applied this method to small subset of wordnet nouns and showed potential applicability.</citsent>
<aftsection>
<nextsent>in the current work, we applied the method to all nouns and verbs in wordnet, and built lexicon in which word senses are partitioned by systematic polysemy.
</nextsent>
<nextsent>we report results of comparing our lexicon with the wordnet cousins as well as the inter-annotator disagreement observed between two semantically annotated corpora: wordnet semcor (landes et al, 1998) and dso (ng and lee, 1996).<papid> P96-1006 </papid></nextsent>
<nextsent>the results are quite promising: our extraction method discovered89% of the wordnet cousins, and the sense partitions in our lexicon yielded better  values (car letta, 1996) <papid> J96-2004 </papid>than arbitrary sense groupings on the agreement data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2524">
<title id=" N01-1010.xml">treecut and a lexicon based on systematic polysemy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our previous work (tomuro, 2000),<papid> W00-0104 </papid>we applied this method to small subset of wordnet nouns and showed potential applicability.</prevsent>
<prevsent>in the current work, we applied the method to all nouns and verbs in wordnet, and built lexicon in which word senses are partitioned by systematic polysemy.</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
we report results of comparing our lexicon with the wordnet cousins as well as the inter-annotator disagreement observed between two semantically annotated corpora: wordnet semcor (landes et al, 1998) and dso (ng and lee, 1996).<papid> P96-1006 </papid></citsent>
<aftsection>
<nextsent>the results are quite promising: our extraction method discovered89% of the wordnet cousins, and the sense partitions in our lexicon yielded better  values (car letta, 1996) <papid> J96-2004 </papid>than arbitrary sense groupings on the agreement data.</nextsent>
<nextsent>the tree-cut technique is an unsupervised learning technique which partitions data items organized in tree structure into mutually-disjoint clusters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2526">
<title id=" N01-1010.xml">treecut and a lexicon based on systematic polysemy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the current work, we applied the method to all nouns and verbs in wordnet, and built lexicon in which word senses are partitioned by systematic polysemy.
</prevsent>
<prevsent>we report results of comparing our lexicon with the wordnet cousins as well as the inter-annotator disagreement observed between two semantically annotated corpora: wordnet semcor (landes et al, 1998) and dso (ng and lee, 1996).<papid> P96-1006 </papid></prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
the results are quite promising: our extraction method discovered89% of the wordnet cousins, and the sense partitions in our lexicon yielded better  values (car letta, 1996) <papid> J96-2004 </papid>than arbitrary sense groupings on the agreement data.</citsent>
<aftsection>
<nextsent>the tree-cut technique is an unsupervised learning technique which partitions data items organized in tree structure into mutually-disjoint clusters.
</nextsent>
<nextsent>it was originally proposed in (li and abe, 1998), <papid> J98-2002 </papid>and then adopted in our previous method for automatically extracting systematic polysemy (tomuro, 2000).<papid> W00-0104 </papid></nextsent>
<nextsent>in this section, we give brief summary of this tree-cut technique using examples from (li and abe, 1998) <papid> J98-2002 </papid>original work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2544">
<title id=" N01-1010.xml">treecut and a lexicon based on systematic polysemy </title>
<section> a lexicon based on systematic </section>
<citcontext>
<prevsection>
<prevsent>so the sense partition for \table  becomes f(1 4),(2 3 5),(6)g.table 4 shows the comparison between wordnet and our new lexicon.
</prevsent>
<prevsent>as you can see, our lexicon contains much less ambiguity: the ratio of monosemous words increased from 84% (88,650/105,461.84) to 92% (96,964/105,461.92), and the average number of senses for polysemous words decreased from 2.73 to 2.52 for nouns, and from 3.57 to 2.82 for verbs.
</prevsent>
</prevsection>
<citsent citstr=" W00-0103 ">
as note, our lexicon is similar to corelex (buitelaar, 1998) (or corelex-ii presented in (buitelaar, 2000)), <papid> W00-0103 </papid>in that both lexicons share the same motivation.</citsent>
<aftsection>
<nextsent>however, our lexicon diers from corelex in that corelex looks at all senses of word and groups words that have the same sense distribution pattern, whereas our lexicon groups table 2: examples of automatically extracted systematic polysemy underspeci ed class cluster pair common words action-location [action, point] \drop , \circle , \intersection , \dig , \crossing , \bull eye  artifact-group [structure, people] \house , \convent , \market , \center  artifact-substance [fabric, chemical compound] \acetate , \nylon , \acrylic , \polyester  communication-person [voice, singer] \soprano , \alto , \tenor , \baritone  [writing, religious person] \john , \matthew , \jonah , \joshua , \jeremiah  table 4: wordnet vs. the new lexicon category wordnet new nouns monosemous 82,892 88,977 polysemous 12,243 6,158 total words 95,135 95,135 ave # senses 2.73 2.52 verbs monosemous 5,758 7,987 polysemous 4,568 2,339 total words 10,326 10,326 ave # senses 3.57 2.82 total monosemous 88,650 96,964 polysemous 16,811 8,497 total words 105,461 105,461 word senses that have the same systematic relation.
</nextsent>
<nextsent>thus, our lexicon represents systematic polysemy at ner level than corelex, by pinpointing related senses within each word.
</nextsent>
<nextsent>disagreement to test if the sense partitions in our lexicon constitute an appropriate (or useful) level of granularity, we applied it to the inter-annotator disagreement observed in two semantically annotated cor pora: wordnet semcor (landes et al, 1998) and dso (ng and lee, 1996).<papid> P96-1006 </papid></nextsent>
<nextsent>the agreement between those corpora is previously studied in (ng et al, 1999).<papid> W99-0502 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2564">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the proposed twin-model is tested on the data from the 2005 automatic content extraction (ace)task and the proposed model performs better than thresholding baseline without tuning free parameter.
</prevsent>
<prevsent>coreference resolution aims to find multiple mentions of an entity (e.g., person, organization) in adocument.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
in typical machine learning-based coreference resolution system (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b; yang et al, 2003; <papid> P03-1023 </papid>luo et al, 2004), <papid> P04-1018 </papid>statistical model is learned from training data and isused to measure how likely an anaphor 1 is coreferential to candidate antecedent.</citsent>
<aftsection>
<nextsent>a related, but often overlooked, problem is that the anaphor may be non coreferential to any candidate, which arises from scenarios such as an identified anaphor is truly generic and 1in this paper, anaphor?
</nextsent>
<nextsent>includes all kinds of phrases to be resolved, which can be named, nominal or pronominal phrases.there does not exist an antecedent in the discourse context, or an anaphor is the first mention (relative to processing order) in coreference chain.
</nextsent>
<nextsent>in (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b),the problem is treated by thresholding the scores returned by the coreference model.</nextsent>
<nextsent>that is, if the maximum coreference score is below threshold, then theanaphor is deemed non-referential to any candidate antecedent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2568">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the proposed twin-model is tested on the data from the 2005 automatic content extraction (ace)task and the proposed model performs better than thresholding baseline without tuning free parameter.
</prevsent>
<prevsent>coreference resolution aims to find multiple mentions of an entity (e.g., person, organization) in adocument.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
in typical machine learning-based coreference resolution system (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b; yang et al, 2003; <papid> P03-1023 </papid>luo et al, 2004), <papid> P04-1018 </papid>statistical model is learned from training data and isused to measure how likely an anaphor 1 is coreferential to candidate antecedent.</citsent>
<aftsection>
<nextsent>a related, but often overlooked, problem is that the anaphor may be non coreferential to any candidate, which arises from scenarios such as an identified anaphor is truly generic and 1in this paper, anaphor?
</nextsent>
<nextsent>includes all kinds of phrases to be resolved, which can be named, nominal or pronominal phrases.there does not exist an antecedent in the discourse context, or an anaphor is the first mention (relative to processing order) in coreference chain.
</nextsent>
<nextsent>in (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b),the problem is treated by thresholding the scores returned by the coreference model.</nextsent>
<nextsent>that is, if the maximum coreference score is below threshold, then theanaphor is deemed non-referential to any candidate antecedent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2580">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the proposed twin-model is tested on the data from the 2005 automatic content extraction (ace)task and the proposed model performs better than thresholding baseline without tuning free parameter.
</prevsent>
<prevsent>coreference resolution aims to find multiple mentions of an entity (e.g., person, organization) in adocument.
</prevsent>
</prevsection>
<citsent citstr=" P03-1023 ">
in typical machine learning-based coreference resolution system (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b; yang et al, 2003; <papid> P03-1023 </papid>luo et al, 2004), <papid> P04-1018 </papid>statistical model is learned from training data and isused to measure how likely an anaphor 1 is coreferential to candidate antecedent.</citsent>
<aftsection>
<nextsent>a related, but often overlooked, problem is that the anaphor may be non coreferential to any candidate, which arises from scenarios such as an identified anaphor is truly generic and 1in this paper, anaphor?
</nextsent>
<nextsent>includes all kinds of phrases to be resolved, which can be named, nominal or pronominal phrases.there does not exist an antecedent in the discourse context, or an anaphor is the first mention (relative to processing order) in coreference chain.
</nextsent>
<nextsent>in (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b),the problem is treated by thresholding the scores returned by the coreference model.</nextsent>
<nextsent>that is, if the maximum coreference score is below threshold, then theanaphor is deemed non-referential to any candidate antecedent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2582">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the proposed twin-model is tested on the data from the 2005 automatic content extraction (ace)task and the proposed model performs better than thresholding baseline without tuning free parameter.
</prevsent>
<prevsent>coreference resolution aims to find multiple mentions of an entity (e.g., person, organization) in adocument.
</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
in typical machine learning-based coreference resolution system (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b; yang et al, 2003; <papid> P03-1023 </papid>luo et al, 2004), <papid> P04-1018 </papid>statistical model is learned from training data and isused to measure how likely an anaphor 1 is coreferential to candidate antecedent.</citsent>
<aftsection>
<nextsent>a related, but often overlooked, problem is that the anaphor may be non coreferential to any candidate, which arises from scenarios such as an identified anaphor is truly generic and 1in this paper, anaphor?
</nextsent>
<nextsent>includes all kinds of phrases to be resolved, which can be named, nominal or pronominal phrases.there does not exist an antecedent in the discourse context, or an anaphor is the first mention (relative to processing order) in coreference chain.
</nextsent>
<nextsent>in (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b),the problem is treated by thresholding the scores returned by the coreference model.</nextsent>
<nextsent>that is, if the maximum coreference score is below threshold, then theanaphor is deemed non-referential to any candidate antecedent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2603">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the threshold approach does not model non coreferential events directly, and is by no means the optimal approach to the problem.
</prevsent>
<prevsent>it also introduces free parameter which has to be set by trial-and-error.
</prevsent>
</prevsection>
<citsent citstr=" P04-1020 ">
as an improvement, ng and cardie (2002<papid> P02-1014 </papid>a) and ng (2004) <papid> P04-1020 </papid>train separate model to classify an anaphor as either anaphoric or non-anaphoric.</citsent>
<aftsection>
<nextsent>the output of this classifier can be used either as pre-filter (ng and cardie,2002<papid> P02-1014 </papid>a) so that non-anaphoric anaphors will not be pre cessed in the coreference system, or as set of features in the coreference model (ng, 2004)<papid> P04-1020 </papid></nextsent>
<nextsent>by rejecting anyanaphor classified as non-anaphoric in coreference resolution, the filtering approach is meant to handle non anaphoric phrases (i.e., no antecedent exists in the discourse under consideration), not the first mention in coreference chain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2628">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>training pc(?|et, mt) is covered in the next section.
</prevsent>
<prevsent>3.1 feature structure.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
to implement the twin model, we adopt the loglinear or maximum entropy (maxent) model (berger et al, 1996)<papid> J96-1002 </papid>for its flexibility of combining diverse sources of information.</citsent>
<aftsection>
<nextsent>the two models are of the form: pl(l|ej , mt) = exp ( ? kgk(ej , mt, l) ) (ej , mt) (4) pc(c|et, mt) = exp ( ? ihi(et, mt, c) ) z(et, mt) , (5) where and are binary variables indicating either mt is coreferential with ej , or mt is used to create new entity.
</nextsent>
<nextsent>y (ej , mt) and z(ej , mt) are normalization factors to ensure that pl(?|ej , mt) and pc(?|et, mt) are probabilities; and are the weights for feature gk(ej , mt, l) and hi(et, mt, c), respectively.
</nextsent>
<nextsent>once the set of features functions are selected, algorithm such as improved iterative scaling (berger et al, 1996)<papid> J96-1002 </papid>or sequential conditional generalized iterative scaling (goodman, 2002) <papid> P02-1002 </papid>can be used to find the optimal parameter values of {k} and {i}.</nextsent>
<nextsent>computing features {gk(ej , mt, ?)} for the link model pl(l|ej , mt) 2 is relatively straightforward: given an entity ej and the current mention mt, wejust need to characterize things such as lexical similarity, syntactic relationship, and/or semantic compatibility of the two.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2631">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>the two models are of the form: pl(l|ej , mt) = exp ( ? kgk(ej , mt, l) ) (ej , mt) (4) pc(c|et, mt) = exp ( ? ihi(et, mt, c) ) z(et, mt) , (5) where and are binary variables indicating either mt is coreferential with ej , or mt is used to create new entity.
</prevsent>
<prevsent>y (ej , mt) and z(ej , mt) are normalization factors to ensure that pl(?|ej , mt) and pc(?|et, mt) are probabilities; and are the weights for feature gk(ej , mt, l) and hi(et, mt, c), respectively.
</prevsent>
</prevsection>
<citsent citstr=" P02-1002 ">
once the set of features functions are selected, algorithm such as improved iterative scaling (berger et al, 1996)<papid> J96-1002 </papid>or sequential conditional generalized iterative scaling (goodman, 2002) <papid> P02-1002 </papid>can be used to find the optimal parameter values of {k} and {i}.</citsent>
<aftsection>
<nextsent>computing features {gk(ej , mt, ?)} for the link model pl(l|ej , mt) 2 is relatively straightforward: given an entity ej and the current mention mt, wejust need to characterize things such as lexical similarity, syntactic relationship, and/or semantic compatibility of the two.
</nextsent>
<nextsent>it is, however, very challenging to compute the features {hi(et, mt, ?)} for the creation modelpc(?|et, mt) since its conditioning includes set of entities et, whose size grows as more and more mentions are processed.
</nextsent>
<nextsent>the problem exists because the decision of creating new entity with mt has to be made after examining all preceding entities.
</nextsent>
<nextsent>there is no reason able modeling assumption one can make to drop some entities in the conditioning.to overcome the difficulty, we impose the following constraints on the features of the link and creation 2the link model is actually implemented as: pl(l|ej , mt) ? maxmej pl(l|ej , m?, mt).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2632">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>there is no reason able modeling assumption one can make to drop some entities in the conditioning.to overcome the difficulty, we impose the following constraints on the features of the link and creation 2the link model is actually implemented as: pl(l|ej , mt) ? maxmej pl(l|ej , m?, mt).
</prevsent>
<prevsent>some features are computed on pair of mentions (m?, mt) while some are computed at entity level.
</prevsent>
</prevsection>
<citsent citstr=" H05-1083 ">
see (luo and zitouni, 2005) <papid> H05-1083 </papid>and (daume?</citsent>
<aftsection>
<nextsent>iii and marcu, 2005).
</nextsent>
<nextsent>model: gk(ej , mt, l) =g(1)k (ej , mt)g (2) (l) (6) hi(et, mt, c) =h(1)i ( {g(1)k (e, mt) : ? et} ) ? h(2)i (c), for some k.
</nextsent>
<nextsent>(7) (6) states that feature in the link model is separable and can be written as product of two functions: the first one, g(1)k (?, ?), is binary function depending on the conditioning part only; the second one, g(2)k (?), is an indicator function depending on the prediction part only.
</nextsent>
<nextsent>like g(2)k (?), (2) (?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2684">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>system f-measure ace-value b-opt-f 84.7 87.5 b-opt-av 81.1 88.0 twin-model 84.8 88.4table 2: comparison between the thresholding base line and the twin model: optimal threshold depends on performance metric.
</prevsent>
<prevsent>the proposed twin-model outperforms the baseline without tuning the free parameter.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
some earlier work (lappin and leass, 1994; <papid> J94-4002 </papid>kennedy and boguraev, 1996) <papid> C96-1021 </papid>use heuristic to determine whether phrase is anaphoric or not.</citsent>
<aftsection>
<nextsent>bean and riloff (1999) <papid> P99-1048 </papid>extracts rules from non-anaphoric noun phrases and noun phrases patterns, which are then applied totest data to identify existential noun phrases.</nextsent>
<nextsent>it is intended as as pre-filtering step before coreference resolution system is run.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2685">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>system f-measure ace-value b-opt-f 84.7 87.5 b-opt-av 81.1 88.0 twin-model 84.8 88.4table 2: comparison between the thresholding base line and the twin model: optimal threshold depends on performance metric.
</prevsent>
<prevsent>the proposed twin-model outperforms the baseline without tuning the free parameter.
</prevsent>
</prevsection>
<citsent citstr=" C96-1021 ">
some earlier work (lappin and leass, 1994; <papid> J94-4002 </papid>kennedy and boguraev, 1996) <papid> C96-1021 </papid>use heuristic to determine whether phrase is anaphoric or not.</citsent>
<aftsection>
<nextsent>bean and riloff (1999) <papid> P99-1048 </papid>extracts rules from non-anaphoric noun phrases and noun phrases patterns, which are then applied totest data to identify existential noun phrases.</nextsent>
<nextsent>it is intended as as pre-filtering step before coreference resolution system is run.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2686">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the proposed twin-model outperforms the baseline without tuning the free parameter.
</prevsent>
<prevsent>some earlier work (lappin and leass, 1994; <papid> J94-4002 </papid>kennedy and boguraev, 1996) <papid> C96-1021 </papid>use heuristic to determine whether phrase is anaphoric or not.</prevsent>
</prevsection>
<citsent citstr=" P99-1048 ">
bean and riloff (1999) <papid> P99-1048 </papid>extracts rules from non-anaphoric noun phrases and noun phrases patterns, which are then applied totest data to identify existential noun phrases.</citsent>
<aftsection>
<nextsent>it is intended as as pre-filtering step before coreference resolution system is run.
</nextsent>
<nextsent>ng and cardie (2002<papid> P02-1014 </papid>a) trains aseparate anaphoricity classifier in addition to coreference model.</nextsent>
<nextsent>the anaphoricity classifier is applied as filter and only anaphoric mentions are later considered by the coreference model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2693">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the anaphoricity classifier is applied as filter and only anaphoric mentions are later considered by the coreference model.
</prevsent>
<prevsent>ng (2004) <papid> P04-1020 </papid>studies what is the best way to make use of anaphoricity information and concludes that the constrained-based and globally optimized approach works the best.</prevsent>
</prevsection>
<citsent citstr=" W04-0707 ">
poesio et al (2004) <papid> W04-0707 </papid>contains good summary of recent research work on discourse new or anaphoricity.</citsent>
<aftsection>
<nextsent>luo et al (2004) <papid> P04-1018 </papid>uses start model to determine whether mention is the first one in coreference chain, but it is computed adhoc without training.</nextsent>
<nextsent>nicolae and nicolae (2006) <papid> W06-1633 </papid>constructs graph where mentions are nodes and an edge represents the likelihood two mentions are in an entity, and then graph-cut algorithm is employed to produce final coreference results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2695">
<title id=" N07-1010.xml">coreference or not a twin model for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>poesio et al (2004) <papid> W04-0707 </papid>contains good summary of recent research work on discourse new or anaphoricity.</prevsent>
<prevsent>luo et al (2004) <papid> P04-1018 </papid>uses start model to determine whether mention is the first one in coreference chain, but it is computed adhoc without training.</prevsent>
</prevsection>
<citsent citstr=" W06-1633 ">
nicolae and nicolae (2006) <papid> W06-1633 </papid>constructs graph where mentions are nodes and an edge represents the likelihood two mentions are in an entity, and then graph-cut algorithm is employed to produce final coreference results.</citsent>
<aftsection>
<nextsent>we take the view that determining whether an anaphor is coreferential with any candidate antecedent is part of the coreference process.
</nextsent>
<nextsent>but we do recognize that the disparity between the two types of events: while coreferential relationship can be resolved by examining the local context of the anaphor and its antecedent, it is necessary to compare the anaphor with all the preceding candidates before it can be declared that it is not coreferential with any.
</nextsent>
<nextsent>thus, creation component pc(?|et, mt) is needed to model the second type of events.
</nextsent>
<nextsent>a problem arising from the adoption of the creation model is that it is very expensive to havea conditional model depending on all preceding entities et. to solve this problem, we adopt the maxent model and impose some reasonable constraints on the feature functions, which makes it possible to synthesize features in the creation model from those of the link model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2696">
<title id=" N06-2032.xml">story segmentation of broadcast news in english mandarin and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the nightingale system searches diverse news corpus to return answers to user queries.
</prevsent>
<prevsent>for audio sources, the identification of story boundaries is crucial, to segment material to be searched and to provide interpret able results to the user.
</prevsent>
</prevsection>
<citsent citstr=" P93-1041 ">
previous approaches to story segmentation have largely focused lexical features, such as word sim ilarily (kozima, 1993), <papid> P93-1041 </papid>cue phrases (passonneauand litman, 1997), <papid> J97-1005 </papid>cosine similarity of lexical windows (hearst, 1997; <papid> J97-1003 </papid>galley et al, 2003)<papid> P03-1071 </papid>and adaptive language modeling (beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>segmentation of stories in bn have included some acoustic features (shriberg et al, 2000; tur et al, 2001).<papid> J01-1002 </papid></nextsent>
<nextsent>work on non-english bn, generally use this combination of lexical and acoustic measures, such as (wayne, 2000; levow, 2004) <papid> W04-2906 </papid>on mandarin.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2697">
<title id=" N06-2032.xml">story segmentation of broadcast news in english mandarin and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the nightingale system searches diverse news corpus to return answers to user queries.
</prevsent>
<prevsent>for audio sources, the identification of story boundaries is crucial, to segment material to be searched and to provide interpret able results to the user.
</prevsent>
</prevsection>
<citsent citstr=" J97-1005 ">
previous approaches to story segmentation have largely focused lexical features, such as word sim ilarily (kozima, 1993), <papid> P93-1041 </papid>cue phrases (passonneauand litman, 1997), <papid> J97-1005 </papid>cosine similarity of lexical windows (hearst, 1997; <papid> J97-1003 </papid>galley et al, 2003)<papid> P03-1071 </papid>and adaptive language modeling (beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>segmentation of stories in bn have included some acoustic features (shriberg et al, 2000; tur et al, 2001).<papid> J01-1002 </papid></nextsent>
<nextsent>work on non-english bn, generally use this combination of lexical and acoustic measures, such as (wayne, 2000; levow, 2004) <papid> W04-2906 </papid>on mandarin.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2698">
<title id=" N06-2032.xml">story segmentation of broadcast news in english mandarin and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the nightingale system searches diverse news corpus to return answers to user queries.
</prevsent>
<prevsent>for audio sources, the identification of story boundaries is crucial, to segment material to be searched and to provide interpret able results to the user.
</prevsent>
</prevsection>
<citsent citstr=" J97-1003 ">
previous approaches to story segmentation have largely focused lexical features, such as word sim ilarily (kozima, 1993), <papid> P93-1041 </papid>cue phrases (passonneauand litman, 1997), <papid> J97-1005 </papid>cosine similarity of lexical windows (hearst, 1997; <papid> J97-1003 </papid>galley et al, 2003)<papid> P03-1071 </papid>and adaptive language modeling (beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>segmentation of stories in bn have included some acoustic features (shriberg et al, 2000; tur et al, 2001).<papid> J01-1002 </papid></nextsent>
<nextsent>work on non-english bn, generally use this combination of lexical and acoustic measures, such as (wayne, 2000; levow, 2004) <papid> W04-2906 </papid>on mandarin.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2699">
<title id=" N06-2032.xml">story segmentation of broadcast news in english mandarin and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the nightingale system searches diverse news corpus to return answers to user queries.
</prevsent>
<prevsent>for audio sources, the identification of story boundaries is crucial, to segment material to be searched and to provide interpret able results to the user.
</prevsent>
</prevsection>
<citsent citstr=" P03-1071 ">
previous approaches to story segmentation have largely focused lexical features, such as word sim ilarily (kozima, 1993), <papid> P93-1041 </papid>cue phrases (passonneauand litman, 1997), <papid> J97-1005 </papid>cosine similarity of lexical windows (hearst, 1997; <papid> J97-1003 </papid>galley et al, 2003)<papid> P03-1071 </papid>and adaptive language modeling (beeferman et al, 1999).</citsent>
<aftsection>
<nextsent>segmentation of stories in bn have included some acoustic features (shriberg et al, 2000; tur et al, 2001).<papid> J01-1002 </papid></nextsent>
<nextsent>work on non-english bn, generally use this combination of lexical and acoustic measures, such as (wayne, 2000; levow, 2004) <papid> W04-2906 </papid>on mandarin.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2701">
<title id=" N06-2032.xml">story segmentation of broadcast news in english mandarin and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for audio sources, the identification of story boundaries is crucial, to segment material to be searched and to provide interpret able results to the user.
</prevsent>
<prevsent>previous approaches to story segmentation have largely focused lexical features, such as word sim ilarily (kozima, 1993), <papid> P93-1041 </papid>cue phrases (passonneauand litman, 1997), <papid> J97-1005 </papid>cosine similarity of lexical windows (hearst, 1997; <papid> J97-1003 </papid>galley et al, 2003)<papid> P03-1071 </papid>and adaptive language modeling (beeferman et al, 1999).</prevsent>
</prevsection>
<citsent citstr=" J01-1002 ">
segmentation of stories in bn have included some acoustic features (shriberg et al, 2000; tur et al, 2001).<papid> J01-1002 </papid></citsent>
<aftsection>
<nextsent>work on non-english bn, generally use this combination of lexical and acoustic measures, such as (wayne, 2000; levow, 2004) <papid> W04-2906 </papid>on mandarin.</nextsent>
<nextsent>and (palmer et al, 2004) <papid> N04-4023 </papid>report results from feature selection experiments that include arabic sources, though they do not report on accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2702">
<title id=" N06-2032.xml">story segmentation of broadcast news in english mandarin and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>previous approaches to story segmentation have largely focused lexical features, such as word sim ilarily (kozima, 1993), <papid> P93-1041 </papid>cue phrases (passonneauand litman, 1997), <papid> J97-1005 </papid>cosine similarity of lexical windows (hearst, 1997; <papid> J97-1003 </papid>galley et al, 2003)<papid> P03-1071 </papid>and adaptive language modeling (beeferman et al, 1999).</prevsent>
<prevsent>segmentation of stories in bn have included some acoustic features (shriberg et al, 2000; tur et al, 2001).<papid> J01-1002 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-2906 ">
work on non-english bn, generally use this combination of lexical and acoustic measures, such as (wayne, 2000; levow, 2004) <papid> W04-2906 </papid>on mandarin.</citsent>
<aftsection>
<nextsent>and (palmer et al, 2004) <papid> N04-4023 </papid>report results from feature selection experiments that include arabic sources, though they do not report on accuracy.</nextsent>
<nextsent>trecvid has also identified visual cues to story segmentation of video bn (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2703">
<title id=" N06-2032.xml">story segmentation of broadcast news in english mandarin and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>segmentation of stories in bn have included some acoustic features (shriberg et al, 2000; tur et al, 2001).<papid> J01-1002 </papid></prevsent>
<prevsent>work on non-english bn, generally use this combination of lexical and acoustic measures, such as (wayne, 2000; levow, 2004) <papid> W04-2906 </papid>on mandarin.</prevsent>
</prevsection>
<citsent citstr=" N04-4023 ">
and (palmer et al, 2004) <papid> N04-4023 </papid>report results from feature selection experiments that include arabic sources, though they do not report on accuracy.</citsent>
<aftsection>
<nextsent>trecvid has also identified visual cues to story segmentation of video bn (cf.
</nextsent>
<nextsent>(hsu et al, 2004; hsieh et al, 2003; chaisorn et al, 2003; maybury, 1998)).<papid> P98-2135 </papid></nextsent>
<nextsent>the training data used for nightingale includes the tdt-4 and tdt5 corpora (strassel and glenn, 2003; strassel et al, 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2704">
<title id=" N06-2032.xml">story segmentation of broadcast news in english mandarin and arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>and (palmer et al, 2004) <papid> N04-4023 </papid>report results from feature selection experiments that include arabic sources, though they do not report on accuracy.</prevsent>
<prevsent>trecvid has also identified visual cues to story segmentation of video bn (cf.</prevsent>
</prevsection>
<citsent citstr=" P98-2135 ">
(hsu et al, 2004; hsieh et al, 2003; chaisorn et al, 2003; maybury, 1998)).<papid> P98-2135 </papid></citsent>
<aftsection>
<nextsent>the training data used for nightingale includes the tdt-4 and tdt5 corpora (strassel and glenn, 2003; strassel et al, 2004).
</nextsent>
<nextsent>tdt-4 includes newswire text and broadcast news audio in english, arabic and mandarin; tdt-5 contains only text data, and is therefore not used by our system.
</nextsent>
<nextsent>the tdt-4 audio corpus includes 312.5 hours of english broadcast news from 450 shows, 88.5 hours of arabic news from 109 shows, and 134 hours of mandarin broadcasts from 205 shows.
</nextsent>
<nextsent>this material was drawn from six english news shows ? abc world news tonight?, cnn head line news?, nbc nightly news?, public radio international the world?, ms-nbc news with brian williams?, and voice of america, english three mandarin newscasts ? china national radio, china television system, and voice of america, mandarin chinese ? and two arabic newscasts ? nile tv and voice of america, modern standard arabic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2705">
<title id=" N06-2032.xml">story segmentation of broadcast news in english mandarin and arabic </title>
<section> our features and approach.  </section>
<citcontext>
<prevsection>
<prevsent>the classifier then outputs prediction of whether or not this sentence boundary coincides with story boundary.
</prevsent>
<prevsent>the features we use for story boundary prediction are divided into three types: lexical, acoustic and speaker-dependent.
</prevsent>
</prevsection>
<citsent citstr=" N03-3009 ">
the value of even error ful lexical information in identifying story boundaries has been confirmed formany previous story segmentation systems (beefer manet al, 1999; stokes, 2003)).<papid> N03-3009 </papid></citsent>
<aftsection>
<nextsent>we include some previously-tested types of lexical features in our own system, as well as identifying our own cue-wordfeatures from our training corpus.
</nextsent>
<nextsent>our lexical features are extracted from asr transcripts produced by the nightingale system.
</nextsent>
<nextsent>they include lexical similarity scores calculated from the texttilingalgorithm.(hearst, 1997), <papid> J97-1003 </papid>which determines the lexical similarity of blocks of text by analyzing the cosine similarity of sequence of sentences; this algorithm tests the likelihood of topic boundary between blocks, preferring locations between blocks which have minimal lexical similarity.</nextsent>
<nextsent>for english, we stem the input before calculating these features, using an implementation of the porter stem mer (porter, 1980); we have not yet attempted to identify root forms for mandarin or arabic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2709">
<title id=" N06-2032.xml">story segmentation of broadcast news in english mandarin and arabic </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>we report the results of our system on english, mandarin and arabic in table 5.
</prevsent>
<prevsent>all results use show-specific modeling, which consistently improved our results across all metrics, reducing errors by between 10% and 30%.
</prevsent>
</prevsection>
<citsent citstr=" J02-1002 ">
in these tables, we report the f-measure of identifying the precise location of story boundary as well as three metrics designed specifically for this type of segmentationtask: the pk metric (beeferman et al, 1999), win dowdiff (pevzner and hearst, 2002) <papid> J02-1002 </papid>and cseg (pseg= 0.3) (doddington, 1998).</citsent>
<aftsection>
<nextsent>all three are derived from the pk metric (beeferman et al, 1999), and for all, lower values imply better performance.
</nextsent>
<nextsent>for each of these three metrics we let = 5, as prescribed in (beeferman et al, 1999).
</nextsent>
<nextsent>in every system, the best peforming results are achieved by including all features from the lexical, acoustic and speaker-dependent feature sets.
</nextsent>
<nextsent>across all languages, our precision and false alarm rates?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2711">
<title id=" N04-3009.xml">spoken dialogue for simulation control and conversational tutoring </title>
<section> technical content.  </section>
<citcontext>
<prevsection>
<prevsent>our focus is on the scot-dc spoken language tutor for navy damage control; however, because scot-dc performs reflective tutoring on dc-train simulator sessions, we have also developed speech interface for the existing dc-train damage control simulator, to promote ease of use as well as consistency of interface.
</prevsent>
<prevsent>our tutor is developed within the architecture for conversational intelligence (lemon et al 2001).
</prevsent>
</prevsection>
<citsent citstr=" P93-1008 ">
we use the open agent architecture (martin et al 1999) for communication between agents based on the nuance speech recognizer, the gemini natural language system (dowding et al 1993), <papid> P93-1008 </papid>and festival speech synthesis.</citsent>
<aftsection>
<nextsent>our tutor adds its own dialogue manager agent, for general principles of conversational intelligence, and tutor agent, which uses tutoring strategies and tactics to plan out an appropriate review and react to the student answers to questions and desired topics.
</nextsent>
<nextsent>the scot-dc tutor, in socratic style, asks questions rather than giving explanations.
</nextsent>
<nextsent>the tutor has repertoire of hinting tactics to deploy in response to student answers to questions, and identifies and iscusses repeated mistakes.
</nextsent>
<nextsent>the student is able to ask  why  questions after certain tutor explanations, and to alter the tutorial plan by requesting that the tutor skip discussion of certain topics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2712">
<title id=" N06-1041.xml">prototype driven learning for sequence models </title>
<section> tasks and related work: tagging.  </section>
<citcontext>
<prevsection>
<prevsent>merialdos results most famously show that re-estimation degrades accuracy unless almost no examples are labeled.
</prevsent>
<prevsent>less famously, his results also demonstrate that reestimation can improve tagging accuracies to some degree in the fully unsupervised case.
</prevsent>
</prevsection>
<citsent citstr=" P05-1044 ">
one recent and much more successful approach to part-of-speech learning is contrastive estimation, presented in smith and eisner (2005).<papid> P05-1044 </papid></citsent>
<aftsection>
<nextsent>they utilizetask-specific comparison neighborhoods for part-of speech tagging to alter their objective function.
</nextsent>
<nextsent>both of these works require specification of the legal tags for each word.
</nextsent>
<nextsent>such dictionaries are large and embody great deal of lexical knowledge.
</nextsent>
<nextsent>a prototype list, in contrast, is extremely compact.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2713">
<title id=" N06-1041.xml">prototype driven learning for sequence models </title>
<section> tasks and related work: extraction.  </section>
<citcontext>
<prevsection>
<prevsent>such dictionaries are large and embody great deal of lexical knowledge.
</prevsent>
<prevsent>a prototype list, in contrast, is extremely compact.
</prevsent>
</prevsection>
<citsent citstr=" P05-1046 ">
grenager et al (2005)<papid> P05-1046 </papid>presents an unsupervised approach to an information extraction task, called classifieds here, which involves segmenting classified advertisements into topical sections (see figure 1(c)).</citsent>
<aftsection>
<nextsent>labels in this domain tend to be sticky?
</nextsent>
<nextsent>in that the correct annotation tends to consist ofmulti-element fields of the same label.
</nextsent>
<nextsent>the over all approach of grenager et al (2005)<papid> P05-1046 </papid>typifies the process involved in fully unsupervised learning on new domain: they first alter the structure of their hmm so that diagonal transitions are preferred, then modify the transition structure to explicitly model boundary tokens, and so on.</nextsent>
<nextsent>given enough refine label prototypes roo mates roommate respectful drama restrictions pets smoking dog utilities utilities pays electricity available immediately begin cheaper size 2 br sq photos pictures image link rent $ month *number*15*1 contact *phone* call *time* features kitchen laundry parking neighborhood close near shopping address address carl mont *ordinal*5 boundary ; . !figure 2: prototype list derived from the development set of the classifieds data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2724">
<title id=" N06-1041.xml">prototype driven learning for sequence models </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we may intend that words which are in some sense similar to prototype generally be given the same label(s) as that prototype.
</prevsent>
<prevsent>4.3 distributional similarity.
</prevsent>
</prevsection>
<citsent citstr=" W01-0713 ">
in syntactic distributional clustering, words are grouped on the basis of the vectors of their preceeding and following words (schutze, 1995; clark,2001).<papid> W01-0713 </papid></citsent>
<aftsection>
<nextsent>the underlying linguistic idea is that replacing word with another word of the same syntactic category should preserve syntactic well-formedness(radford, 1988).
</nextsent>
<nextsent>we present more details in section 5, but for now assume that similarity function over word types is given.
</nextsent>
<nextsent>suppose further that for each non-prototype word type w, we have subset of prototypes, sw, which are known to be distributionally similar to (above some threshold).
</nextsent>
<nextsent>we would like our model to relate the tags of to those of sw.one approach to enforcing the distributional assumption in sequence model is by supplementing the training objective (here, data likelihood) with penalty term that encourages parameters for which each ws posterior distribution over tags is compatible with its prototypes sw.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2743">
<title id=" N06-1041.xml">prototype driven learning for sequence models </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 chinese pos tagging.
</prevsent>
<prevsent>we also tested our pos induction system on the chinese pos data in the chinese treebank (ircs, 2002).
</prevsent>
</prevsection>
<citsent citstr=" I05-3005 ">
the model is wholly unmodified from the english version except that the suffix features are removed since, in chinese, suffixes are not reliable indicator of part-of-speech as in english (tseng et al,2005).<papid> I05-3005 </papid></citsent>
<aftsection>
<nextsent>since we did not have access to large auxiliary unlabeled corpus that was segmented, our distributional model was built only from the treebank text, and the distributional similarities are presumably degraded relative to the english.
</nextsent>
<nextsent>on 60k word tokens, base gave an accuracy of 34.4, proto gave 39.0, and proto+sim gave 57.4, similar in order if not magnitude to the english case.we believe the performance for chinese pos tagging is not as high as english for two reasons: the general difficulty of chinese pos tagging (tseng et al., 2005) <papid> I05-3005 </papid>and the lack of larger segmented corpus from which to build distributional models.</nextsent>
<nextsent>nonetheless, the addition of distributional similarity features does reduce the error rate by 35% from base.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2763">
<title id=" N06-2042.xml">word pronunciation disambiguation using the web </title>
<section> discussion on transliteration.  </section>
<citcontext>
<prevsection>
<prevsent>method.
</prevsent>
<prevsent>5
</prevsent>
</prevsection>
<citsent citstr=" J98-4003 ">
transliteration (knight and graehl, 1998) <papid> J98-4003 </papid>is mapping from one system of writing into another, automation of which has been actively studied between english and other languages such as arabic, chinese, korean, thai, and japanese.</citsent>
<aftsection>
<nextsent>if there are multiple translation candidates, by incorporating context in way similar to our proposal, one will be able to disambiguate them.
</nextsent>
<nextsent>this paper proposed new method for reading proper names.
</nextsent>
<nextsent>in our proposed method, using web pages containing kanji and hiragana (or katakana) representations of the same proper names, we can learn how to read proper names with multiple readings via state-of-the-art machine learner.
</nextsent>
<nextsent>thus, the proposed process requires no human intervention.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2764">
<title id=" N07-1031.xml">automating creation of hierarchical faceted meta data structures </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>how ever, that work assumes that the categories of interest are already known, and tries to assign documents to categories.
</prevsent>
<prevsent>in contrast, in this paper we focus on the problem of determining the categories of interest.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
another thread of work is on finding synonymous terms and word associations, as well as automatic acquisition of is-a (or genus-head) relations from dictionary definitions and free text (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>that work focuses on finding the right position for word within lexicon, rather than building up comprehensible and coherent faceted hierarchies.a major class of solutions for creating subject hierarchies uses data clustering.
</nextsent>
<nextsent>the scatter/gather system (cutting et al , 1992) uses greedy global agglomer ative clustering algorithm where an initial set of   clusters is recursively re-clustered until only documents remain.hofmann (1999) proposes the probabilistic latent semantic analysis algorithm (plsa), probabilistic version of clustering that uses latent semantic analysis for grouping words and annealed em for model fitting.
</nextsent>
<nextsent>the greatest advantage of clustering is that it is fullyautomatable and can be easily applied to any text collection.
</nextsent>
<nextsent>clustering can also reveal interesting and potentially unexpected or new trends in group of documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2765">
<title id=" N07-1031.xml">automating creation of hierarchical faceted meta data structures </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>how ever, that work assumes that the categories of interest are already known, and tries to assign documents to categories.
</prevsent>
<prevsent>in contrast, in this paper we focus on the problem of determining the categories of interest.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
another thread of work is on finding synonymous terms and word associations, as well as automatic acquisition of is-a (or genus-head) relations from dictionary definitions and free text (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999).<papid> P99-1016 </papid></citsent>
<aftsection>
<nextsent>that work focuses on finding the right position for word within lexicon, rather than building up comprehensible and coherent faceted hierarchies.a major class of solutions for creating subject hierarchies uses data clustering.
</nextsent>
<nextsent>the scatter/gather system (cutting et al , 1992) uses greedy global agglomer ative clustering algorithm where an initial set of   clusters is recursively re-clustered until only documents remain.hofmann (1999) proposes the probabilistic latent semantic analysis algorithm (plsa), probabilistic version of clustering that uses latent semantic analysis for grouping words and annealed em for model fitting.
</nextsent>
<nextsent>the greatest advantage of clustering is that it is fullyautomatable and can be easily applied to any text collection.
</nextsent>
<nextsent>clustering can also reveal interesting and potentially unexpected or new trends in group of documents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2766">
<title id=" N07-1031.xml">automating creation of hierarchical faceted meta data structures </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>the main idea behind the castanet al orithm1 is to carve out structure from the hypernym (is-a) relations with inthe wordnet (fellbaum, 1998) lexical database.
</prevsent>
<prevsent>the primary unit of representation in wordnet is the synset, which is set of words that are considered synonyms for particular concept.
</prevsent>
</prevsection>
<citsent citstr=" N04-4030 ">
each synset is linked to other synsets via several types of lexical and semantic relations; we only use hypernymy (is-a relations) in this algorithm.1a simpler, un-evaluated version of this algorithm was presented previously in short paper (stoica and hearst, 2004).<papid> N04-4030 </papid></citsent>
<aftsection>
<nextsent>245 4.1 algorithm overview.
</nextsent>
<nextsent>the castanet al orithm assumes that there is text associated with each item in the collection, or at least with arepresentative subset of the items.
</nextsent>
<nextsent>the textual descriptions are used both to build the facet hierarchies and to assign items (documents, images, citations, etc.) to thefacets.
</nextsent>
<nextsent>the text does not need to be particularly coherent for the algorithm to work; we have applied it to fragmented image annotations and short journal titles, but if the text is impoverished, the information items will not be labeled as thoroughly as desirable and additional manual annotation may be needed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2767">
<title id=" N06-1016.xml">an empirical study of the behavior of active learning for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>active learning requires human labeling of the newly selected training data to ensure high quality.
</prevsent>
<prevsent>we focus here on pool-based active learning where there is an abundant supply of unlabeled data, but where the labeling process is expensive.
</prevsent>
</prevsection>
<citsent citstr=" P02-1016 ">
in nlp problems such as text classification (lewis and gale, 1994; mccallum and nigam, 1998), statistical parsing (tang et al, 2002), <papid> P02-1016 </papid>information extraction (thompson et al, 1999), and named entity recognition (shen et al, 2004), <papid> P04-1075 </papid>pool-based active learning has produced promising results.</citsent>
<aftsection>
<nextsent>this paper presents our experiments in applying two active learning methods, min-margin based method and shannon-entropy based one, to the task of the disambiguation of english verb senses.
</nextsent>
<nextsent>the contribution of our work is not only in demonstrating that these methods work well for the active learning of coarse-grained verb senses, but also analyzing the behavior of the active learning process on two levels: the instance level and the feature level.
</nextsent>
<nextsent>the analysis suggests that careful treatment of feature design and feature generation is important for successful application of active learning to wsd.
</nextsent>
<nextsent>we also accounted for the over fitting phenomena that occurred in the learning process based on our data analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2768">
<title id=" N06-1016.xml">an empirical study of the behavior of active learning for word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>active learning requires human labeling of the newly selected training data to ensure high quality.
</prevsent>
<prevsent>we focus here on pool-based active learning where there is an abundant supply of unlabeled data, but where the labeling process is expensive.
</prevsent>
</prevsection>
<citsent citstr=" P04-1075 ">
in nlp problems such as text classification (lewis and gale, 1994; mccallum and nigam, 1998), statistical parsing (tang et al, 2002), <papid> P02-1016 </papid>information extraction (thompson et al, 1999), and named entity recognition (shen et al, 2004), <papid> P04-1075 </papid>pool-based active learning has produced promising results.</citsent>
<aftsection>
<nextsent>this paper presents our experiments in applying two active learning methods, min-margin based method and shannon-entropy based one, to the task of the disambiguation of english verb senses.
</nextsent>
<nextsent>the contribution of our work is not only in demonstrating that these methods work well for the active learning of coarse-grained verb senses, but also analyzing the behavior of the active learning process on two levels: the instance level and the feature level.
</nextsent>
<nextsent>the analysis suggests that careful treatment of feature design and feature generation is important for successful application of active learning to wsd.
</nextsent>
<nextsent>we also accounted for the over fitting phenomena that occurred in the learning process based on our data analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2769">
<title id=" N06-1016.xml">an empirical study of the behavior of active learning for word sense disambiguation </title>
<section> active learning algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>using either method of uncertainty sampling, the computational cost of picking an example from candidates is: o(td) where is the number of model parameters.
</prevsent>
<prevsent>2.3 related work.
</prevsent>
</prevsection>
<citsent citstr=" W02-0817 ">
to our best knowledge, there have been very few attempts to apply active learning to wsd in the literature (fujii and inui, 1999; chklovski and mihalcea, 2002; <papid> W02-0817 </papid>dang, 2004).</citsent>
<aftsection>
<nextsent>fujii and inui (1999) developed an example sampling method for their example-based wsd system in the active learning of verb senses in pool-based setting.
</nextsent>
<nextsent>unlike the uncertainty sampling methods (such as the two methods we used), their method did not select examples for which the system had the minimal certainty.
</nextsent>
<nextsent>rather, it selected the examples such that after training using those examples the system would be most certain about its predictions on the rest of the unlabeled examples in the next iteration.
</nextsent>
<nextsent>this sample selection criterion was enforced by calculating training utility function.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2771">
<title id=" N06-1016.xml">an empirical study of the behavior of active learning for word sense disambiguation </title>
<section> active learning experiments.  </section>
<citcontext>
<prevsection>
<prevsent>122 figure 1 active learning for four verbs both methods outperformed the random sampling method in that they reached the upper bound accuracy earlier and had smoother learning curves.
</prevsent>
<prevsent>for the four verbs add, do, feel and see, their learning curves reached the upper bound at about 200~300 iterations, which means 1/2 or 1/3 of the annotation effort can be saved for these verbs by using active learning, while still achieving the same level of performance as supervised wsd without using active learning.
</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
given the large scale annotation effort currently underway in the ontonotes project (hovy et al, 2006), <papid> N06-2015 </papid>this could provide considerable savings in annotation effort and speed up the process of providing sufficient data for large vocabulary.</citsent>
<aftsection>
<nextsent>the ontonotes project has now provided coarse-grained entries for over 350 verbs, with corresponding double blind annotation and adjudication in progress.
</nextsent>
<nextsent>as this adjudicated data becomes available, we will be able to train our system accordingly.
</nextsent>
<nextsent>preliminary results for 22 of these coarse-grained verbs (with an average grouping polysemy of 4.5) give us an average accuracy of 86.3%.
</nextsent>
<nextsent>this will also provide opportunities for more experiments with active learning, where there are enough instances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2772">
<title id=" N04-4031.xml">computational linkuistics word triggers across hyper links </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since cluster of documents contains subset of an entire language, document model is special case of language model.
</prevsent>
<prevsent>as such, it can be expressed as conditional probability distribution indicating how likely word is to appear in document given some context (e.g., other similar documents, the topic of the document, etc.).
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
language models are usedin speech recognition (chen and goodman, 1996), <papid> P96-1041 </papid>document indexing (bookstein and swanson, 1974; croft and harper, 1979) and information retrieval (ponte and croft, 1998).document models are special class of language mod els.</citsent>
<aftsection>
<nextsent>one property of document models is that they canbe used to predict some lexical properties of textual documents, e.g., the frequency of certain word.
</nextsent>
<nextsent>mos teller and wallace (mosteller and wallace, 1984) discovered that content words are bursty?
</nextsent>
<nextsent>- the appearance of content word significantly increases the probability that the word would appear again.
</nextsent>
<nextsent>church and his colleagues(church and gale, 1995; church, 2000) <papid> C00-1027 </papid>describe document models based on the distribution of the frequencies of individual words over large document collections.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2773">
<title id=" N04-4031.xml">computational linkuistics word triggers across hyper links </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mos teller and wallace (mosteller and wallace, 1984) discovered that content words are bursty?
</prevsent>
<prevsent>- the appearance of content word significantly increases the probability that the word would appear again.
</prevsent>
</prevsection>
<citsent citstr=" C00-1027 ">
church and his colleagues(church and gale, 1995; church, 2000) <papid> C00-1027 </papid>describe document models based on the distribution of the frequencies of individual words over large document collections.</citsent>
<aftsection>
<nextsent>in (church and gale, 1995), church and gale compare document models based on the poisson distribution, the 2-poisson distribution (bookstein and swanson, 1974),as well as generic poisson mixtures.
</nextsent>
<nextsent>a poisson mixture is described by *#+n`o0acb dfe +ng 0ihj+ng   `a0)  , where hj+ng   $0kcmlsnoqpqr 7s forgiven integer non-negative value of ` .church and gale empirically show that poisson mixtures are more accurate model for describing the distribution of words in documents within corpus.
</nextsent>
<nextsent>they obtain the best fits with the negative binomial model and the k-mixture (both special cases of poisson mixtures) (church and gale, 1995).
</nextsent>
<nextsent>in the negative binomial case, +ng0t pquvn l o x uvy l{z|x (which is the gamma distribution) whereas in the k-mixture, +flg0 }+k|h~580k?!+flg0 4 m o?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2774">
<title id=" N04-3006.xml">open text semantic parsing using framenet and wordnet </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>notice also that since this is rule-based approach, the parser does not need large amounts of annotated data, but it works well the same for words for which only one or two sentences are annotated.
</prevsent>
<prevsent>all previous work in semantic parsing has exclusively focused on labeling semantic roles, rather than analyzing the full structure of sentence semantics, and is usually based on statistical models - e.g.
</prevsent>
</prevsection>
<citsent citstr=" P00-1065 ">
(gildea and jurafsky, 2000), (<papid> P00-1065 </papid>fleischman et al, 2003).<papid> W03-1007 </papid></citsent>
<aftsection>
<nextsent>to our knowledge, there was no previous attempt on performing semantic annotations using alternative rule-based algorithms.
</nextsent>
<nextsent>however, rule-based approach is closer to the way humans interpret the semantic structure of sentence.
</nextsent>
<nextsent>moreover, as mentioned earlier, the framenet data is not meant to be statistically representa tive?, but rather illustrative for various language constructs, and therefore rule-based approach is more suitable for this lexical resource.
</nextsent>
<nextsent>we described rule-based approach to open text semantic parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2775">
<title id=" N04-3006.xml">open text semantic parsing using framenet and wordnet </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>notice also that since this is rule-based approach, the parser does not need large amounts of annotated data, but it works well the same for words for which only one or two sentences are annotated.
</prevsent>
<prevsent>all previous work in semantic parsing has exclusively focused on labeling semantic roles, rather than analyzing the full structure of sentence semantics, and is usually based on statistical models - e.g.
</prevsent>
</prevsection>
<citsent citstr=" W03-1007 ">
(gildea and jurafsky, 2000), (<papid> P00-1065 </papid>fleischman et al, 2003).<papid> W03-1007 </papid></citsent>
<aftsection>
<nextsent>to our knowledge, there was no previous attempt on performing semantic annotations using alternative rule-based algorithms.
</nextsent>
<nextsent>however, rule-based approach is closer to the way humans interpret the semantic structure of sentence.
</nextsent>
<nextsent>moreover, as mentioned earlier, the framenet data is not meant to be statistically representa tive?, but rather illustrative for various language constructs, and therefore rule-based approach is more suitable for this lexical resource.
</nextsent>
<nextsent>we described rule-based approach to open text semantic parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2776">
<title id=" N04-1010.xml">acquiring hyponymy relations from web documents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our acquisition algorithm uses clues such as itemization or listing in html documents and statistical measures such as document frequencies and verb-noun co-occurrences.
</prevsent>
<prevsent>the goal of this work is to become able to automatically acquire hyponymy relations for wide range of words or phrases from html documents on the www.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
we donot use particular lexico syntactic patterns, as previous attempts have (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999; <papid> P99-1016 </papid>imasumi, 2001; fleischman et al, 2003; <papid> P03-1001 </papid>morin and jacquemin, 2003; ando et al, 2003).</citsent>
<aftsection>
<nextsent>the frequencies of use for such lexico syntactic patterns are relatively low, and there canbe many words or phrases that do not appear in such patterns even if we look at large number of texts.
</nextsent>
<nextsent>the effort of searching for other clues indicating hyponymy relations is thus significant.
</nextsent>
<nextsent>we try to acquire hyponymy relations by combining three different types of clue obtain able from wide range of words or phrases.
</nextsent>
<nextsent>the first typeof clue is inclusion in itemizations or lists found in typical html documents on the www.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2777">
<title id=" N04-1010.xml">acquiring hyponymy relations from web documents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our acquisition algorithm uses clues such as itemization or listing in html documents and statistical measures such as document frequencies and verb-noun co-occurrences.
</prevsent>
<prevsent>the goal of this work is to become able to automatically acquire hyponymy relations for wide range of words or phrases from html documents on the www.
</prevsent>
</prevsection>
<citsent citstr=" P99-1016 ">
we donot use particular lexico syntactic patterns, as previous attempts have (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999; <papid> P99-1016 </papid>imasumi, 2001; fleischman et al, 2003; <papid> P03-1001 </papid>morin and jacquemin, 2003; ando et al, 2003).</citsent>
<aftsection>
<nextsent>the frequencies of use for such lexico syntactic patterns are relatively low, and there canbe many words or phrases that do not appear in such patterns even if we look at large number of texts.
</nextsent>
<nextsent>the effort of searching for other clues indicating hyponymy relations is thus significant.
</nextsent>
<nextsent>we try to acquire hyponymy relations by combining three different types of clue obtain able from wide range of words or phrases.
</nextsent>
<nextsent>the first typeof clue is inclusion in itemizations or lists found in typical html documents on the www.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2778">
<title id=" N04-1010.xml">acquiring hyponymy relations from web documents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our acquisition algorithm uses clues such as itemization or listing in html documents and statistical measures such as document frequencies and verb-noun co-occurrences.
</prevsent>
<prevsent>the goal of this work is to become able to automatically acquire hyponymy relations for wide range of words or phrases from html documents on the www.
</prevsent>
</prevsection>
<citsent citstr=" P03-1001 ">
we donot use particular lexico syntactic patterns, as previous attempts have (hearst, 1992; <papid> C92-2082 </papid>caraballo, 1999; <papid> P99-1016 </papid>imasumi, 2001; fleischman et al, 2003; <papid> P03-1001 </papid>morin and jacquemin, 2003; ando et al, 2003).</citsent>
<aftsection>
<nextsent>the frequencies of use for such lexico syntactic patterns are relatively low, and there canbe many words or phrases that do not appear in such patterns even if we look at large number of texts.
</nextsent>
<nextsent>the effort of searching for other clues indicating hyponymy relations is thus significant.
</nextsent>
<nextsent>we try to acquire hyponymy relations by combining three different types of clue obtain able from wide range of words or phrases.
</nextsent>
<nextsent>the first typeof clue is inclusion in itemizations or lists found in typical html documents on the www.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2779">
<title id=" N04-1010.xml">acquiring hyponymy relations from web documents </title>
<section> acquisition algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>the similarities are computed through the following steps.
</prevsent>
<prevsent>first, we parse all the texts in the local document set, and check the argument positions of verbs where hyponym candidates appear.
</prevsent>
</prevsection>
<citsent citstr=" C00-1060 ">
(to parse texts, we use downgraded version of an existing parser (kanayama et al, 2000) <papid> C00-1060 </papid>throughout this work.)</citsent>
<aftsection>
<nextsent>let us denote the frequency of the hyponym candidates in an hcs occupying an argument position of verb as fhypo(c, p, v).
</nextsent>
<nextsent>assume that all possible argument positions are denoted as {p1, ? ?
</nextsent>
<nextsent>, pl} and all the verbs as {v1, ? ?
</nextsent>
<nextsent>, vm}.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2780">
<title id=" N03-3006.xml">a low complexity broad coverage probabilistic dependency parser for english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper presents such parsing system.
</prevsent>
<prevsent>its output is hierarchical structure of syntactic relations, functional dependency structures, which are discussed in section 2.the parser differs on the one hand from successful dependency grammar implementations (e.g.
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
(lin, 1998), (tapanainen and jarvinen, 1997)) <papid> A97-1011 </papid>by using statistical base, and on the other hand from state-of-the-art statistical approaches (e.g.</citsent>
<aftsection>
<nextsent>(collins, 1999)) by carefully following an established formal grammar theory, dependency grammar (dg).
</nextsent>
<nextsent>it combines two probabilistic models of language, similar to (collins, 1999), which are discussed in section 3.
</nextsent>
<nextsent>both are supervised and based on maximum likelihood estimation (mle).
</nextsent>
<nextsent>the first one is based on the lexical probabilities of the heads of phrases, similar to (collins and brooks, 1995).<papid> W95-0103 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2781">
<title id=" N03-3006.xml">a low complexity broad coverage probabilistic dependency parser for english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it combines two probabilistic models of language, similar to (collins, 1999), which are discussed in section 3.
</prevsent>
<prevsent>both are supervised and based on maximum likelihood estimation (mle).
</prevsent>
</prevsection>
<citsent citstr=" W95-0103 ">
the first one is based on the lexical probabilities of the heads of phrases, similar to (collins and brooks, 1995).<papid> W95-0103 </papid></citsent>
<aftsection>
<nextsent>it calculates the probability of finding specific syntactic relations (such as subject, sentential object, etc.) between given lexical heads.
</nextsent>
<nextsent>two simple extensions for the interaction between several dependents of the same mother node are also used.
</nextsent>
<nextsent>the second probability model is pcfg for the production of the vp.
</nextsent>
<nextsent>although traditional cfgs are not part of dg, vp pcfg rules can model verb subcategorization frames, an important dg component.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2783">
<title id=" N03-3006.xml">a low complexity broad coverage probabilistic dependency parser for english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the second probability model is pcfg for the production of the vp.
</prevsent>
<prevsent>although traditional cfgs are not part of dg, vp pcfg rules can model verb subcategorization frames, an important dg component.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the parser has been trained, developed and tested on large collection of syntactically analyzed sentences, the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>it is broad-coverage and robust and returns an optimal set of partial structures when it fails to find complete structure for sentence.
</nextsent>
<nextsent>it has been designed to keep complexity as low as possible during the parsing process in order to be fast enough to be useful for parsing large amounts of unrestricted text.
</nextsent>
<nextsent>this has been achieved by observing the following constraints, discussed in section 4: ? using syntactic theory known for its relatively flat structures and lack of empty nodes (see also subsection 2.4) ? relying on finite-state preprocessing ? discarding unlikely readings with beam search?
</nextsent>
<nextsent>using the fast cocke-younger-kasami (cyk) parsing algorithm ? using restrictive hand-written linguistic grammar the parsing system uses divide-and-conquer approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2786">
<title id=" N03-3006.xml">a low complexity broad coverage probabilistic dependency parser for english </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>the parser uses the preprocessed input of finite-state tagger-chunker.
</prevsent>
<prevsent>finite-state technology is fast enough for unlimited amounts of data, taggers and chunk ers are known to be reliable but not error-free, with typical error rates between 2 and 5 %.
</prevsent>
</prevsection>
<citsent citstr=" J97-3003 ">
tagging and chunking is done by standard tagger and chunker, ltpos (mikheev,1997).<papid> J97-3003 </papid></citsent>
<aftsection>
<nextsent>heads are extracted from the chunks and lem matized (minnen et al, 2000).<papid> W00-1427 </papid></nextsent>
<nextsent>parsing takes place only between the heads of phrases, and only using the best tag suggested by the tagger, which leads to reduction in complexity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2787">
<title id=" N03-3006.xml">a low complexity broad coverage probabilistic dependency parser for english </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>finite-state technology is fast enough for unlimited amounts of data, taggers and chunk ers are known to be reliable but not error-free, with typical error rates between 2 and 5 %.
</prevsent>
<prevsent>tagging and chunking is done by standard tagger and chunker, ltpos (mikheev,1997).<papid> J97-3003 </papid></prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
heads are extracted from the chunks and lem matized (minnen et al, 2000).<papid> W00-1427 </papid></citsent>
<aftsection>
<nextsent>parsing takes place only between the heads of phrases, and only using the best tag suggested by the tagger, which leads to reduction in complexity.
</nextsent>
<nextsent>the parser uses the cyk algorithm, which has parsing complexity of o(n3), where is the number of words in word-based, but only chunks in head of-chunk-based model.
</nextsent>
<nextsent>the chunk to word relation is 1.52 for treebank section 0.
</nextsent>
<nextsent>in test with toy np and verb-group grammar parsing was about 4 times slower when using unchunked input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2788">
<title id=" N03-3006.xml">a low complexity broad coverage probabilistic dependency parser for english </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>the grammar therefore makes no distinction and treats all verbal particles as prepositions, which leads to an incorrect but consistent analysis for phrasal verbs.
</prevsent>
<prevsent>a hand-written grammar allows to model complex but important phenomena which overstep manageable ml search spaces, such as discon tinous analysis of questions can be expressed, while on the other hand rare and marginal rules can be left outto free resources.
</prevsent>
</prevsection>
<citsent citstr=" P97-1032 ">
for tagging, (samuelsson and voutilainen, 1997) <papid> P97-1032 </papid>have shown that manually built tagger can equal statistical tagger.</citsent>
<aftsection>
<nextsent>the probabilistic language models have been trained on section 2 to 24 and the parser tested on section 0.
</nextsent>
<nextsent>the percentage values for subject object pp-attach in precision 77 72 67 80 recall 70 75 49 78 table 1: provisional precision and recall values held out training data and the first-ranked reading for each sentence of section 0 are compared for evaluation (lin, 1995).
</nextsent>
<nextsent>parsing the 46527 words of section 0 takes 30 minutes on 800 mhz pentium 3 pc, including about 3 minutes for tagging and chunking.
</nextsent>
<nextsent>current precision and recall values for subject, object and pp-attachment relations, and for the disambiguation between prepositions and complements are in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2789">
<title id=" N03-3006.xml">a low complexity broad coverage probabilistic dependency parser for english </title>
<section> preliminary evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>parsing the 46527 words of section 0 takes 30 minutes on 800 mhz pentium 3 pc, including about 3 minutes for tagging and chunking.
</prevsent>
<prevsent>current precision and recall values for subject, object and pp-attachment relations, and for the disambiguation between prepositions and complements are in table 1.
</prevsent>
</prevsection>
<citsent citstr=" E03-1025 ">
these results, slightly lower than state-of-the-art ((lin, 1998), (preiss, 2003)), <papid> E03-1025 </papid>are least merit figures or proof of concept rather than accurate figures.</citsent>
<aftsection>
<nextsent>on the one hand, the performance of the parser suffers from mistaggings and mischunkings or limited grammar, the price for the speed increase.
</nextsent>
<nextsent>on the other hand, different grammatical assumptions both between the treebank and the chunker,and between the treebank and functional dependency, seriously affect the evaluation.
</nextsent>
<nextsent>for example, the chunker often recognizes units longer than base-nps like [many of the people], or smaller or longer than verbal groups [has] for long time [been], [likely to bring] ? correct chunks which are currently considered as errors.in addition, it is very difficult to avoid tgrep over generating or missing.
</nextsent>
<nextsent>it turns out that the mapping is accurate enough for statistical model but not for reliable evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2790">
<title id=" N07-1018.xml">bayesian inference for pcfgs via markov chain monte carlo </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we illustrate these methods by estimating sparse grammar describing the morphology ofthe bantu language sesotho, demonstrating that with suitable priors bayesian techniques can infer linguistic structure in situations where maximum likelihood methods such as the inside-outside algorithm only produce trivial grammar.
</prevsent>
<prevsent>the standard methods for inferring the parameters of probabilistic models in computational linguistics are based on the principle of maximum-likelihood esti mation; for example, the parameters of probabilisticcontext-free grammars (pcfgs) are typically estimated from strings of terminals using the inside outside (io) algorithm, an instance of the expectation maximization (em) procedure (lari and young, 1990).
</prevsent>
</prevsection>
<citsent citstr=" W06-1673 ">
however, much recent work in machine learning and statistics has turned away from maximum-likelihood in favor of bayesian methods, and there is increasing interest in bayesian methods in computational linguistics as well (finkel et al , 2006).<papid> W06-1673 </papid></citsent>
<aftsection>
<nextsent>this paper presents two markov chain monte carlo (mcmc) algorithms for inferring pcfgs and their parses from strings alone.
</nextsent>
<nextsent>these can be viewed as bayesian alternatives to the io algorithm.
</nextsent>
<nextsent>the goal of bayesian inference is to compute distribution over plausible parameter values.
</nextsent>
<nextsent>this posterior?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2792">
<title id=" N07-1018.xml">bayesian inference for pcfgs via markov chain monte carlo </title>
<section> inferring sparse grammars.  </section>
<citcontext>
<prevsection>
<prevsent>is increasingly concentrated around 0.
</prevsent>
<prevsent>that represent only major phrasal categories ignorea wide variety of lexical and syntactic dependencies in natural language.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
state-of-the-art systems for unsupervised syntactic structure induction system uses models that are very different to these kinds of pcfgs (klein and manning, 2004; <papid> P04-1061 </papid>smith and eisner, 2006).<papid> P06-1072 </papid>1 our goal in this section is modest: we aim merely to provide an illustrative example of bayesian inference using mcmc.</citsent>
<aftsection>
<nextsent>as figure 2 shows, when the dirichlet prior parameter approaches 0 the prior probability pd(r|?)
</nextsent>
<nextsent>becomes increasingly concentrated around 0.
</nextsent>
<nextsent>this ability tobias the sampler toward sparse grammars (i.e., grammars in which many productions have probabilities close to 0) is useful when we attempt to identify relevant productions from much larger set of possible productions via parameter estimation.the bantu language sesotho is richly agglutina tive language, in which verbs consist of sequence of morphemes, including optional subject markers (sm), tense (t), object markers (om), mood (m) and derivational affixes as well as the obligatory verb stem (v), as shown in the following example: re sm -a -di om -bon -a we see them?
</nextsent>
<nextsent>1it is easy to demonstrate that the poor quality of the pcfg models is the cause of these problems rather than search or other algorithmic issues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2793">
<title id=" N07-1018.xml">bayesian inference for pcfgs via markov chain monte carlo </title>
<section> inferring sparse grammars.  </section>
<citcontext>
<prevsection>
<prevsent>is increasingly concentrated around 0.
</prevsent>
<prevsent>that represent only major phrasal categories ignorea wide variety of lexical and syntactic dependencies in natural language.
</prevsent>
</prevsection>
<citsent citstr=" P06-1072 ">
state-of-the-art systems for unsupervised syntactic structure induction system uses models that are very different to these kinds of pcfgs (klein and manning, 2004; <papid> P04-1061 </papid>smith and eisner, 2006).<papid> P06-1072 </papid>1 our goal in this section is modest: we aim merely to provide an illustrative example of bayesian inference using mcmc.</citsent>
<aftsection>
<nextsent>as figure 2 shows, when the dirichlet prior parameter approaches 0 the prior probability pd(r|?)
</nextsent>
<nextsent>becomes increasingly concentrated around 0.
</nextsent>
<nextsent>this ability tobias the sampler toward sparse grammars (i.e., grammars in which many productions have probabilities close to 0) is useful when we attempt to identify relevant productions from much larger set of possible productions via parameter estimation.the bantu language sesotho is richly agglutina tive language, in which verbs consist of sequence of morphemes, including optional subject markers (sm), tense (t), object markers (om), mood (m) and derivational affixes as well as the obligatory verb stem (v), as shown in the following example: re sm -a -di om -bon -a we see them?
</nextsent>
<nextsent>1it is easy to demonstrate that the poor quality of the pcfg models is the cause of these problems rather than search or other algorithmic issues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2794">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also discuss the impact of using publicly available manually annotated verb data to improve the srl accuracy of nouns, exploiting widely-held assumption that verbs and their nominalizations share the same predicate-argument structure.
</prevsent>
<prevsent>finally, we discuss the results of applying reranking techniques to improve srl accuracy fornominalized predicates, which showed insignificant improvement.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
detecting and classifying the arguments of predicates has been an active area of research in recent years, driven by the availability of large-scale semantically annotated corpora such as the framenet (baker et al, 1998) <papid> P98-1013 </papid>and the propbank (palmer etal., 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>it is generally formulated as semantic role labeling (srl) task, where each argument of the predicate is assigned label that represents the semantic role it plays with regard to its predicate (gildea and jurafsky, 2002; <papid> J02-3001 </papid>hacioglu et al, 2003; pradhan et al, 2004<papid> N04-4036 </papid>b; xue and palmer, 2004; <papid> W04-3212 </papid>toutanova et al, 2005; <papid> P05-1073 </papid>koomen et al, 2005).<papid> W05-0625 </papid></nextsent>
<nextsent>it has been the shared task for the conll competition for two consecutive years (carreras and ma`rquez, 2004b; carreras and ma`rquez, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2795">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also discuss the impact of using publicly available manually annotated verb data to improve the srl accuracy of nouns, exploiting widely-held assumption that verbs and their nominalizations share the same predicate-argument structure.
</prevsent>
<prevsent>finally, we discuss the results of applying reranking techniques to improve srl accuracy fornominalized predicates, which showed insignificant improvement.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
detecting and classifying the arguments of predicates has been an active area of research in recent years, driven by the availability of large-scale semantically annotated corpora such as the framenet (baker et al, 1998) <papid> P98-1013 </papid>and the propbank (palmer etal., 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>it is generally formulated as semantic role labeling (srl) task, where each argument of the predicate is assigned label that represents the semantic role it plays with regard to its predicate (gildea and jurafsky, 2002; <papid> J02-3001 </papid>hacioglu et al, 2003; pradhan et al, 2004<papid> N04-4036 </papid>b; xue and palmer, 2004; <papid> W04-3212 </papid>toutanova et al, 2005; <papid> P05-1073 </papid>koomen et al, 2005).<papid> W05-0625 </papid></nextsent>
<nextsent>it has been the shared task for the conll competition for two consecutive years (carreras and ma`rquez, 2004b; carreras and ma`rquez, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2796">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we discuss the results of applying reranking techniques to improve srl accuracy fornominalized predicates, which showed insignificant improvement.
</prevsent>
<prevsent>detecting and classifying the arguments of predicates has been an active area of research in recent years, driven by the availability of large-scale semantically annotated corpora such as the framenet (baker et al, 1998) <papid> P98-1013 </papid>and the propbank (palmer etal., 2005).<papid> J05-1004 </papid></prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
it is generally formulated as semantic role labeling (srl) task, where each argument of the predicate is assigned label that represents the semantic role it plays with regard to its predicate (gildea and jurafsky, 2002; <papid> J02-3001 </papid>hacioglu et al, 2003; pradhan et al, 2004<papid> N04-4036 </papid>b; xue and palmer, 2004; <papid> W04-3212 </papid>toutanova et al, 2005; <papid> P05-1073 </papid>koomen et al, 2005).<papid> W05-0625 </papid></citsent>
<aftsection>
<nextsent>it has been the shared task for the conll competition for two consecutive years (carreras and ma`rquez, 2004b; carreras and ma`rquez, 2005).
</nextsent>
<nextsent>this line of research has also expanded from english to other languages (sun and jurafsky, 2004; <papid> N04-1032 </papid>xue and palmer, 2005).</nextsent>
<nextsent>so far, however, most of the research efforts have focused on analyzing the predicate-argumentstructure of verbs, largely due to absence of annotated data for other predicate types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2798">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we discuss the results of applying reranking techniques to improve srl accuracy fornominalized predicates, which showed insignificant improvement.
</prevsent>
<prevsent>detecting and classifying the arguments of predicates has been an active area of research in recent years, driven by the availability of large-scale semantically annotated corpora such as the framenet (baker et al, 1998) <papid> P98-1013 </papid>and the propbank (palmer etal., 2005).<papid> J05-1004 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-4036 ">
it is generally formulated as semantic role labeling (srl) task, where each argument of the predicate is assigned label that represents the semantic role it plays with regard to its predicate (gildea and jurafsky, 2002; <papid> J02-3001 </papid>hacioglu et al, 2003; pradhan et al, 2004<papid> N04-4036 </papid>b; xue and palmer, 2004; <papid> W04-3212 </papid>toutanova et al, 2005; <papid> P05-1073 </papid>koomen et al, 2005).<papid> W05-0625 </papid></citsent>
<aftsection>
<nextsent>it has been the shared task for the conll competition for two consecutive years (carreras and ma`rquez, 2004b; carreras and ma`rquez, 2005).
</nextsent>
<nextsent>this line of research has also expanded from english to other languages (sun and jurafsky, 2004; <papid> N04-1032 </papid>xue and palmer, 2005).</nextsent>
<nextsent>so far, however, most of the research efforts have focused on analyzing the predicate-argumentstructure of verbs, largely due to absence of annotated data for other predicate types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2804">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we discuss the results of applying reranking techniques to improve srl accuracy fornominalized predicates, which showed insignificant improvement.
</prevsent>
<prevsent>detecting and classifying the arguments of predicates has been an active area of research in recent years, driven by the availability of large-scale semantically annotated corpora such as the framenet (baker et al, 1998) <papid> P98-1013 </papid>and the propbank (palmer etal., 2005).<papid> J05-1004 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
it is generally formulated as semantic role labeling (srl) task, where each argument of the predicate is assigned label that represents the semantic role it plays with regard to its predicate (gildea and jurafsky, 2002; <papid> J02-3001 </papid>hacioglu et al, 2003; pradhan et al, 2004<papid> N04-4036 </papid>b; xue and palmer, 2004; <papid> W04-3212 </papid>toutanova et al, 2005; <papid> P05-1073 </papid>koomen et al, 2005).<papid> W05-0625 </papid></citsent>
<aftsection>
<nextsent>it has been the shared task for the conll competition for two consecutive years (carreras and ma`rquez, 2004b; carreras and ma`rquez, 2005).
</nextsent>
<nextsent>this line of research has also expanded from english to other languages (sun and jurafsky, 2004; <papid> N04-1032 </papid>xue and palmer, 2005).</nextsent>
<nextsent>so far, however, most of the research efforts have focused on analyzing the predicate-argumentstructure of verbs, largely due to absence of annotated data for other predicate types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2805">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we discuss the results of applying reranking techniques to improve srl accuracy fornominalized predicates, which showed insignificant improvement.
</prevsent>
<prevsent>detecting and classifying the arguments of predicates has been an active area of research in recent years, driven by the availability of large-scale semantically annotated corpora such as the framenet (baker et al, 1998) <papid> P98-1013 </papid>and the propbank (palmer etal., 2005).<papid> J05-1004 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1073 ">
it is generally formulated as semantic role labeling (srl) task, where each argument of the predicate is assigned label that represents the semantic role it plays with regard to its predicate (gildea and jurafsky, 2002; <papid> J02-3001 </papid>hacioglu et al, 2003; pradhan et al, 2004<papid> N04-4036 </papid>b; xue and palmer, 2004; <papid> W04-3212 </papid>toutanova et al, 2005; <papid> P05-1073 </papid>koomen et al, 2005).<papid> W05-0625 </papid></citsent>
<aftsection>
<nextsent>it has been the shared task for the conll competition for two consecutive years (carreras and ma`rquez, 2004b; carreras and ma`rquez, 2005).
</nextsent>
<nextsent>this line of research has also expanded from english to other languages (sun and jurafsky, 2004; <papid> N04-1032 </papid>xue and palmer, 2005).</nextsent>
<nextsent>so far, however, most of the research efforts have focused on analyzing the predicate-argumentstructure of verbs, largely due to absence of annotated data for other predicate types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2806">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we discuss the results of applying reranking techniques to improve srl accuracy fornominalized predicates, which showed insignificant improvement.
</prevsent>
<prevsent>detecting and classifying the arguments of predicates has been an active area of research in recent years, driven by the availability of large-scale semantically annotated corpora such as the framenet (baker et al, 1998) <papid> P98-1013 </papid>and the propbank (palmer etal., 2005).<papid> J05-1004 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-0625 ">
it is generally formulated as semantic role labeling (srl) task, where each argument of the predicate is assigned label that represents the semantic role it plays with regard to its predicate (gildea and jurafsky, 2002; <papid> J02-3001 </papid>hacioglu et al, 2003; pradhan et al, 2004<papid> N04-4036 </papid>b; xue and palmer, 2004; <papid> W04-3212 </papid>toutanova et al, 2005; <papid> P05-1073 </papid>koomen et al, 2005).<papid> W05-0625 </papid></citsent>
<aftsection>
<nextsent>it has been the shared task for the conll competition for two consecutive years (carreras and ma`rquez, 2004b; carreras and ma`rquez, 2005).
</nextsent>
<nextsent>this line of research has also expanded from english to other languages (sun and jurafsky, 2004; <papid> N04-1032 </papid>xue and palmer, 2005).</nextsent>
<nextsent>so far, however, most of the research efforts have focused on analyzing the predicate-argumentstructure of verbs, largely due to absence of annotated data for other predicate types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2807">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is generally formulated as semantic role labeling (srl) task, where each argument of the predicate is assigned label that represents the semantic role it plays with regard to its predicate (gildea and jurafsky, 2002; <papid> J02-3001 </papid>hacioglu et al, 2003; pradhan et al, 2004<papid> N04-4036 </papid>b; xue and palmer, 2004; <papid> W04-3212 </papid>toutanova et al, 2005; <papid> P05-1073 </papid>koomen et al, 2005).<papid> W05-0625 </papid></prevsent>
<prevsent>it has been the shared task for the conll competition for two consecutive years (carreras and ma`rquez, 2004b; carreras and ma`rquez, 2005).</prevsent>
</prevsection>
<citsent citstr=" N04-1032 ">
this line of research has also expanded from english to other languages (sun and jurafsky, 2004; <papid> N04-1032 </papid>xue and palmer, 2005).</citsent>
<aftsection>
<nextsent>so far, however, most of the research efforts have focused on analyzing the predicate-argumentstructure of verbs, largely due to absence of annotated data for other predicate types.
</nextsent>
<nextsent>in this paper, we report srl experiments performed on nom inal ized predicates in chinese, taking advantage of newly completed corpus, the chinese nombank (xue, 2006), which we describe in greater detail in section 2.
</nextsent>
<nextsent>the rest of the paper is organized as follows.
</nextsent>
<nextsent>section 3 describes the architecture of our system as well as the features we used in our experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2809">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> the chinese nombank.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 attempts to put our results in perspective in the context of related work.
</prevsent>
<prevsent>section 6 concludes our paper.
</prevsent>
</prevsection>
<citsent citstr=" W04-2705 ">
the chinese nombank extends the general annotation framework of the english proposition bank (palmer et al, 2005) <papid> J05-1004 </papid>and the english nombank(meyers et al, 2004) <papid> W04-2705 </papid>to the annotation of nomi nalized predicates in chinese.</citsent>
<aftsection>
<nextsent>like the english nombank project, the chinese nombank adds alayer of semantic annotation to the chinese tree bank (ctb), syntactically annotated corpus of 500 thousand words.
</nextsent>
<nextsent>the chinese nombank annotates two types of elements that are associated with the nominal ized predicate: argument-like elements thatare expected of this predicate, and adjunct-like elements that modify this predicate.
</nextsent>
<nextsent>arguments are assigned numbered labels (prefixed by arg, e.g., arg0...argn) while adjuncts receive functional tag (e.g., tmp for temporal, loc for locative, mnrfor manner) prefixed by argm.
</nextsent>
<nextsent>a predicate generally has no more than six numbered arguments and the complete list of functional tags for adjuncts and their descriptions can be found in the annotation guidelines of this project.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2830">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we also conducted an experiment that assumes amore realistic scenario in which the input is raw unsegmented text.
</prevsent>
<prevsent>we usefully automatic parser that integrates segmentation, pos tagging and parsing.
</prevsent>
</prevsection>
<citsent citstr=" W03-1025 ">
our parser is similar to (luo, 2003) <papid> W03-1025 </papid>and is trained and tested on the same data partition as the semantic role labeling system.</citsent>
<aftsection>
<nextsent>tested on the held out test data, the labeled precision and recall are 83.06% and 80.15% respectively for all sentences.
</nextsent>
<nextsent>the results are comparable with those reported inluo (luo, 2003), <papid> W03-1025 </papid>but they cannot be directly compared with most of the results reported in the literature, where correct segmentation is assumed.</nextsent>
<nextsent>in addition, in order to account for the differences in segmentation, each character has to be treated as leaf of the parse tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2833">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>when the arguments are given and the input is hand-crafted gold standard parses in the treebank, selecting the top 10propositions yields an oracle score of 97%.
</prevsent>
<prevsent>this initial promise does not pan out, however.
</prevsent>
</prevsection>
<citsent citstr=" W05-0623 ">
performing reranking on the top 10 propositions did not lead to significant improvement, using the five feature classes described in (haghighi et al, 2005).<papid> W05-0623 </papid></citsent>
<aftsection>
<nextsent>these are features that are hard to implement for individual arguments: core argument label sequence, flattened core argument label sequence, core argument labels and phrase type sequence, repeated core argument labels with phrase types, repeated core argument labels with phrase types and adjacency information.
</nextsent>
<nextsent>we speculate that the lack of improvement is due to the fact that the constraint that core (numbered) arguments should not have the same semantic role label for chinese nominal ized predicates is not as rigid as it is for english verbs.
</nextsent>
<nextsent>however further error analysis is needed to substantiate this speculation.
</nextsent>
<nextsent>compared with large body of work on the srlof verbal predicates, there has been relatively little work done in analyzing the predicate-argument structure of nominal ized predicates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2834">
<title id=" N06-1055.xml">semantic role labeling of nominal ized predicates in chinese </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>compared with large body of work on the srlof verbal predicates, there has been relatively little work done in analyzing the predicate-argument structure of nominal ized predicates.
</prevsent>
<prevsent>there are even less work done for the nominal ized predicates for chinese.
</prevsent>
</prevsection>
<citsent citstr=" J02-3004 ">
(hull and comez, 1996) implemented rule-based system for identifying the arguments for nominal predicates and (lapata, 2002) <papid> J02-3004 </papid>has system that interprets the relation between the head of noun compound and its head, but no meaningful comparison can be made between our work and theirs.</citsent>
<aftsection>
<nextsent>perhaps the closest work to that of ours is that of (prad han et al, 2004<papid> N04-4036 </papid>a), where they reported preliminary work for analyzing the predicate-argument structure of chinese nominalizations, using small dataset of 630 proposition for 22 nominalizations taken from the chinese treebank.</nextsent>
<nextsent>since different datasets are used, the results cannot be meaningfully compared.the results reported here for nominal ized predicates are consistent with what xue and palmer (2005) reported for the srl of chinese verbs with regard to the role of the parser in their semantic role labeling system: there is substantial performance drop when the automatic parser is used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2837">
<title id=" N04-4012.xml">ui on the fly generating a multimodal user interface </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we demonstrate it in the context of user interface for mobile personal information manager.
</prevsent>
<prevsent>since bolts (1980) put-that-there system introducedcross-modal coordination in multimodal user input, various projects have investigated multimodal input and output methods.
</prevsent>
</prevsection>
<citsent citstr=" W97-1401 ">
users display preference for the touch screen in map-based positioning acts and object selection (oviatt et al, 1997).<papid> W97-1401 </papid></citsent>
<aftsection>
<nextsent>wip (andre?
</nextsent>
<nextsent>et al, 1993) and other systems (feiner and mckeown, 1990; roth and hefley,1993) generate static multimodal documents.
</nextsent>
<nextsent>in an interactive user interface, however, layout should remain consistent (woods and roth, 1988, perceived stability).smartkom (wahlster, 2002) is recent effort that produces multimodal user interface, using xml/xslttechniques to render the output.
</nextsent>
<nextsent>these are deterministic, which makes soft constraints such as usability hard to implement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2838">
<title id=" N04-4012.xml">ui on the fly generating a multimodal user interface </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these are deterministic, which makes soft constraints such as usability hard to implement.
</prevsent>
<prevsent>supple (gajos and weld, 2004) overcomes this problem in its model of the user and the expected workload for various interfaces, generating unimodal(graphical) user interface without natural language generation elements.
</prevsent>
</prevsection>
<citsent citstr=" P98-1102 ">
on the integration side, johnston (1998)<papid> P98-1102 </papid>presents unification-based grammar that recasts multimodal signal fusion as parsing problem.</citsent>
<aftsection>
<nextsent>our approach employs non-deterministic grammar to derive variants which are evaluated with comparatively simple user and situation model according to their utility (information conveyed) and the projected cognitive load imposed on the user.
</nextsent>
<nextsent>it also removes the requirement inherent in johnstons system of explicitly defining rules to integrate multimodal information.
</nextsent>
<nextsent>in the following, we discuss the grammar formalism used to create output, as well as consistency and adaptation considerations.
</nextsent>
<nextsent>in this section, we will explain how the multimodal functional unification grammar (mug) allows us to generatecontent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2839">
<title id=" N04-4012.xml">ui on the fly generating a multimodal user interface </title>
<section> formalism.  </section>
<citcontext>
<prevsection>
<prevsent>each out put will be faithful to the original input.
</prevsent>
<prevsent>however, onlyone variant will be optimally adapted to the given situation, user, and device (see section 5).
</prevsent>
</prevsection>
<citsent citstr=" P02-1048 ">
our final markup is text for the text to speech system as well as html to be displayed in browser, similar to the match system (johnston et al, 2002).<papid> P02-1048 </papid></citsent>
<aftsection>
<nextsent>the nested attribute-value structures and unification are powerful principles that allow us to cover broad range of planning tasks, including syntactic and lexical choices.
</nextsent>
<nextsent>the declarative nature of the grammar allows usto easily add new ways to express given semantic entity.
</nextsent>
<nextsent>the information that each component has access to is explicitly encapsulated by an fd.a grammar workbench allows us to debug the generation grammar.
</nextsent>
<nextsent>we could improve the debugging process with type-hierarchy, which defines allowed attributes for each type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2842">
<title id=" N06-2041.xml">using the web to disambiguate acronyms </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 reading proper names.
</prevsent>
<prevsent>the contribution of this paper is to propose method to use web pages for disambiguation task.
</prevsent>
</prevsection>
<citsent citstr=" N06-2042 ">
the method is applicable to different problems such as reading japanese proper names (sumita and sugaya, 2006).<papid> N06-2042 </papid></citsent>
<aftsection>
<nextsent>using web page containing name and its syllabary, it is possible to learn how to read proper names with multiple readings in similar way.
</nextsent>
<nextsent>the accuracy in our experiment was around 90% for open data.
</nextsent>
<nextsent>5.2 the web as corpus.
</nextsent>
<nextsent>recently, the web has been used as corpus in the nlp community, where mainly counts of hit pages have been exploited (kilgarriff and grefenstette, 2003).<papid> J03-3001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2843">
<title id=" N06-2041.xml">using the web to disambiguate acronyms </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>the accuracy in our experiment was around 90% for open data.
</prevsent>
<prevsent>5.2 the web as corpus.
</prevsent>
</prevsection>
<citsent citstr=" J03-3001 ">
recently, the web has been used as corpus in the nlp community, where mainly counts of hit pages have been exploited (kilgarriff and grefenstette, 2003).<papid> J03-3001 </papid></citsent>
<aftsection>
<nextsent>however, our proposal, web-based language modeling (sarikaya, 2005), and bootstrapping large sense-tagged corpora (mihalcea, 2002) use the content within the hit pages.
</nextsent>
<nextsent>this paper proposed an automatic method of dis ambiguating an acronym with multiple definitions, considering the context.
</nextsent>
<nextsent>first, the method obtains the web pages that include both the acronym and its definitions.
</nextsent>
<nextsent>second, the method feeds them to the learner for classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2844">
<title id=" N06-1008.xml">acquiring inference rules with temporal constraints by using japanese coordinated sentences and noun verb cooccurrences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a similar idea relying on word co-occurrencewas proposed by geffet and dagan (geffet and da gan, 2005) but our method is simpler and we expect it to be applicable to wider range of vocabularies.
</prevsent>
<prevsent>research on the automatic acquisition of inference rules, paraphrases and ent ailments has received much attention.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
previous attempts have used, for instance,the similarities between case frames (lin and pan 57 tel, 2001), anchor words (barzilay and lee, 2003; <papid> N03-1003 </papid>shinyama et al, 2002; szepektor et al, 2004), and web-based method (szepektor et al, 2004; geffet and dagan, 2005).</citsent>
<aftsection>
<nextsent>there is also workshop devoted to this task (dagan et al, 2005).
</nextsent>
<nextsent>the obtained accuracies have still been low, however, and we think searching for other clues, such as coordinated sentences and the bias we have just mentioned, is necessary.
</nextsent>
<nextsent>in addition, research has also been done on the acquisition of the temporal relations (fujiki et al, 2003; <papid> E03-1061 </papid>chklovski and pantel, 2004) <papid> W04-3205 </papid>by using coordinated sentences as we did, but these works did not consider the implications between events.</nextsent>
<nextsent>in the following, we begin by providing an overview of our algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2845">
<title id=" N06-1008.xml">acquiring inference rules with temporal constraints by using japanese coordinated sentences and noun verb cooccurrences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is also workshop devoted to this task (dagan et al, 2005).
</prevsent>
<prevsent>the obtained accuracies have still been low, however, and we think searching for other clues, such as coordinated sentences and the bias we have just mentioned, is necessary.
</prevsent>
</prevsection>
<citsent citstr=" E03-1061 ">
in addition, research has also been done on the acquisition of the temporal relations (fujiki et al, 2003; <papid> E03-1061 </papid>chklovski and pantel, 2004) <papid> W04-3205 </papid>by using coordinated sentences as we did, but these works did not consider the implications between events.</citsent>
<aftsection>
<nextsent>in the following, we begin by providing an overview of our algorithm.
</nextsent>
<nextsent>we specify the basic steps in the algorithm and the form of the rules to be acquired.
</nextsent>
<nextsent>wealso examine the direction of implications and temporal ordering described by the rules.
</nextsent>
<nextsent>after that, we describe sim plied version of the scoring function that our algorithm uses and then discuss problem related to it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2846">
<title id=" N06-1008.xml">acquiring inference rules with temporal constraints by using japanese coordinated sentences and noun verb cooccurrences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is also workshop devoted to this task (dagan et al, 2005).
</prevsent>
<prevsent>the obtained accuracies have still been low, however, and we think searching for other clues, such as coordinated sentences and the bias we have just mentioned, is necessary.
</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
in addition, research has also been done on the acquisition of the temporal relations (fujiki et al, 2003; <papid> E03-1061 </papid>chklovski and pantel, 2004) <papid> W04-3205 </papid>by using coordinated sentences as we did, but these works did not consider the implications between events.</citsent>
<aftsection>
<nextsent>in the following, we begin by providing an overview of our algorithm.
</nextsent>
<nextsent>we specify the basic steps in the algorithm and the form of the rules to be acquired.
</nextsent>
<nextsent>wealso examine the direction of implications and temporal ordering described by the rules.
</nextsent>
<nextsent>after that, we describe sim plied version of the scoring function that our algorithm uses and then discuss problem related to it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2848">
<title id=" N04-4001.xml">using ngrams to understand the nature of summaries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to meet these expectations, multi-document summary is required to generalize, condense and merge information coming from multiple sources.
</prevsent>
<prevsent>although single-document summarization is well studied task (see mani and maybury, 1999 for an overview), multi-document summarization is only recently being studied closely (marcu &amp; gerber 2001).
</prevsent>
</prevsection>
<citsent citstr=" W00-0405 ">
while close attention has been paid to multi-document summarization technologies (barzilay et al  2002, goldstein et al 2000), <papid> W00-0405 </papid>the inherent properties of human written multi-document summaries have not yet been quantified.</citsent>
<aftsection>
<nextsent>in this paper, we seek to empirically characterize ideal multi-document summaries in part by attempting to answer the questions: can multi-document summaries that are written by humans be characterized as extractive or generative?
</nextsent>
<nextsent>are multi-document summaries less extractive than single-document summaries?
</nextsent>
<nextsent>our aim in answering these questions is to discover how the nature of multi-document summaries will impact our system requirements.
</nextsent>
<nextsent>we have chosen to focus our experiments on the data provided for summarization evaluation during the document understanding conference (duc).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2849">
<title id=" N04-4001.xml">using ngrams to understand the nature of summaries </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 describes new approach for assessing the degree to which summary can be described as extractive, and reports our findings for both single and multiple document summarization tasks.
</prevsent>
<prevsent>we conclude with discussion of our findings in section 4.
</prevsent>
</prevsection>
<citsent citstr=" J02-4006 ">
jing (2002) <papid> J02-4006 </papid>previously examined the degree to which single-document summaries can be characterized as extractive.</citsent>
<aftsection>
<nextsent>based on manual inspection of 15 human written summaries, she proposes that for the task of single-document summarization, human summarizers use cut-and-paste?
</nextsent>
<nextsent>approach in which six main operations are performed: sentence reduction, sentence combination, syntactic transformation, reordering, lexical paraphrasing, and generalization or specification.
</nextsent>
<nextsent>the first four operations are reflected in the construction of an hmm model that can be used to decompose human summaries.
</nextsent>
<nextsent>according to this model, 81% of summary sentences contained in corpus of 300 human-written summaries of news articles on telecommunications were found to fit the cut-and-paste method, with the rest believed to have been composed from scratch.1 another recent study (lin and hovy, 2003) <papid> W03-0510 </papid>investigated the extent to which extractive methods may be sufficient for summarization in the single-document case.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2850">
<title id=" N04-4001.xml">using ngrams to understand the nature of summaries </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>approach in which six main operations are performed: sentence reduction, sentence combination, syntactic transformation, reordering, lexical paraphrasing, and generalization or specification.
</prevsent>
<prevsent>the first four operations are reflected in the construction of an hmm model that can be used to decompose human summaries.
</prevsent>
</prevsection>
<citsent citstr=" W03-0510 ">
according to this model, 81% of summary sentences contained in corpus of 300 human-written summaries of news articles on telecommunications were found to fit the cut-and-paste method, with the rest believed to have been composed from scratch.1 another recent study (lin and hovy, 2003) <papid> W03-0510 </papid>investigated the extent to which extractive methods may be sufficient for summarization in the single-document case.</citsent>
<aftsection>
<nextsent>by computing performance upper-bound for pure sentence extraction, they found that state-of-the-art extraction-based systems are still 15%-24%2 away from this limit, and 10% away from average human performance.
</nextsent>
<nextsent>while this sheds light on how much gain can be achieved by optimizing sentence extraction methods for single-document summarization, to our knowledge, no one has assessed the potential for extraction-based systems when attempting to summarize multiple documents.
</nextsent>
<nextsent>characterize summaries our approach to characterizing summaries is much simpler than what jing has described and is based on the following idea: if human-written summaries are extractive, then we should expect to see long spans of text that have been lifted from the source documents to form summary.
</nextsent>
<nextsent>note that this holds under the assumptions made by jings model of operations that are performed by human summarizers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2854">
<title id=" N04-3008.xml">sense clusters  finding clusters that represent word senses </title>
<section> context representation.  </section>
<citcontext>
<prevsection>
<prevsent>each vector shows if the feature represented by the corresponding index occurs or not in the context of the instance (binary vectors), or how often the feature occurs in the context (frequency vectors).
</prevsent>
<prevsent>this is referred to as first order context vector, since this representation directly indicates which features make up the contexts.
</prevsent>
</prevsection>
<citsent citstr=" W97-0322 ">
here we are following (pedersen and bruce, 1997), <papid> W97-0322 </papid>who likewise took this approach to feature representation.</citsent>
<aftsection>
<nextsent>(schutze, 1998) utilized second order context vectors that represent the context of target word to be discriminated by taking the average of the first order vectors associated with the unigrams that occur in that context.
</nextsent>
<nextsent>in sense clusters we have extended this idea such that these first order vectors can also be based on cooccurrence or bigram features from the training corpus.both the first and second order context vectors represent the given instances as vectors in high dimensional word space.
</nextsent>
<nextsent>this approach suffers from two limitations.first, there may be synonyms represented by separate dimensions in the space.
</nextsent>
<nextsent>second, and conversely, single dimension in the space might be polysemous and associated with several different underlying concepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2856">
<title id=" N04-3008.xml">sense clusters  finding clusters that represent word senses </title>
<section> summary of unique features.  </section>
<citcontext>
<prevsection>
<prevsent>integration sense clusters transparently incorporates several specialized tools, including cluto, the ngram statistics package, and svdpack.
</prevsent>
<prevsent>this provides wide number of options and high efficiency at various steps like feature selection, feature space dimensionality reduction, clustering and evaluation.
</prevsent>
</prevsection>
<citsent citstr=" N03-3004 ">
availability sense clusters is an open source software project that is freely distributed under the gnu public license (gpl) via http://senseclusters.sourceforge.net/senseclusters is an ongoing project, and there areal ready number of published papers based on its use (e.g., (purandare, 2003), (<papid> N03-3004 </papid>purandare and pedersen, 2004)).<papid> W04-2406 </papid></citsent>
<aftsection>
<nextsent>this work has been partially supported by national science foundation faculty early career development award (grant #0092784).
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2857">
<title id=" N04-3008.xml">sense clusters  finding clusters that represent word senses </title>
<section> summary of unique features.  </section>
<citcontext>
<prevsection>
<prevsent>integration sense clusters transparently incorporates several specialized tools, including cluto, the ngram statistics package, and svdpack.
</prevsent>
<prevsent>this provides wide number of options and high efficiency at various steps like feature selection, feature space dimensionality reduction, clustering and evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W04-2406 ">
availability sense clusters is an open source software project that is freely distributed under the gnu public license (gpl) via http://senseclusters.sourceforge.net/senseclusters is an ongoing project, and there areal ready number of published papers based on its use (e.g., (purandare, 2003), (<papid> N03-3004 </papid>purandare and pedersen, 2004)).<papid> W04-2406 </papid></citsent>
<aftsection>
<nextsent>this work has been partially supported by national science foundation faculty early career development award (grant #0092784).
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2858">
<title id=" N04-4005.xml">enhancing linguistically oriented automatic keyword extraction </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the approach taken to the keyword extraction task is that of supervised machine learning.
</prevsent>
<prevsent>this means that set of documents with known keywords is used to train model, which in turn is applied to select keywords to andfrom previously unseen documents.
</prevsent>
</prevsection>
<citsent citstr=" W03-1028 ">
the keyword extraction discussed in this paper is based on work presented in hulth (2003<papid> W03-1028 </papid>a) and hulth (2003<papid> W03-1028 </papid>b).in hulth (2003<papid> W03-1028 </papid>a) an evaluation of three different methods to extract candidate terms from documents is pre sented.</citsent>
<aftsection>
<nextsent>the methods are:   extracting all uni-, bi, and trigrams that do not begin or end with stopword.
</nextsent>
<nextsent>  extracting all noun phrase (np) chunks as judged by partial parser.
</nextsent>
<nextsent>  extracting all part-of-speech (pos) tagged words or sequences of words that match any of set of empirically defined pos patterns.
</nextsent>
<nextsent>the best performing models use four attributes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2939">
<title id=" N04-1040.xml">multiple similarity measures and source pair information in story link detection </title>
<section> background and related work.  </section>
<citcontext>
<prevsection>
<prevsent>(2002), umass found that the clarity similarity measure performed best for the link detection task.
</prevsent>
<prevsent>in this paper, we also examine number of similarity measures,both separately, as in allan et al (2000), and in combination.
</prevsent>
</prevsection>
<citsent citstr=" P98-1029 ">
in the machine learning field, classifier combination has been shown to provide accuracy gains (e.g., belkin etal.(1995); kittler et al (1998); brill and wu (1998); <papid> P98-1029 </papid>dietterich (2000)).</citsent>
<aftsection>
<nextsent>motivated by the performance improvement observed in these studies, we explored the combination of similarity measures for improving story link detection.
</nextsent>
<nextsent>cmu hypothesized that the similarity between pair of stories is influenced by the source of each story.
</nextsent>
<nextsent>for example, sources in language that is translated to english will consistently use the same terminology, resulting in greater similarity between linked documents with the same native language.
</nextsent>
<nextsent>in contrast, sources from radio broadcasts may be transcribed much less consistently than text sources due to recognition errors, so that the expected similarity of radio broadcast and text source is less than that of two text sources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2940">
<title id=" N04-1040.xml">multiple similarity measures and source pair information in story link detection </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>to handle these differences, an asr stoplist?
</prevsent>
<prevsent>was automatically created.
</prevsent>
</prevsection>
<citsent citstr=" N03-2005 ">
chen et al (2003) <papid> N03-2005 </papid>found that the use of an enhanced stop list, formed from the union of base stop list and asr stoplist,was very effective in improving performance and empirically better than normalizing asr abbreviations.</citsent>
<aftsection>
<nextsent>3.1.2 source-specific incremental tf-idf mode lthe training data is used to compute the initial document frequency over the corpus for each term.
</nextsent>
<nextsent>the document frequency of term   ,
</nextsent>
<nextsent>  is defined to be:
</nextsent>
<nextsent>  ff  flfi  ffi
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2941">
<title id=" N03-2029.xml">automatic derivation of surface text patterns for a maximum entropy based question answering system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these patterns are used to generate features for statistical question answering system.
</prevsent>
<prevsent>we report our results on the trec-10 question set.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
several qa systems have investigated the use of text patterns for qa (soubbotin and soubbotin, 2001), (soub botin and soubbotin, 2002), (ravichandran and hovy, 2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>for example, for questions like when was gandhi born??, typical answers are gandhi was born in1869?
</nextsent>
<nextsent>and gandhi (1869-1948)?.
</nextsent>
<nextsent>these examples suggest that the text patterns such as ?  name  was born in birth date  ? and ?  name  (  birth date   death year  )?
</nextsent>
<nextsent>when formulated as regular expressions, can be used to select the answer phrase to questions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2942">
<title id=" N03-2029.xml">automatic derivation of surface text patterns for a maximum entropy based question answering system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when formulated as regular expressions, can be used to select the answer phrase to questions.
</prevsent>
<prevsent>another approach to qa system is learning correspondences between question and answer pairs.
</prevsent>
</prevsection>
<citsent citstr=" N01-1005 ">
ibms statistical qa (ittycheriah et al, 2001<papid> N01-1005 </papid>a) system uses aprobabilistic model trainable from question-answer sentence pairs.</citsent>
<aftsection>
<nextsent>the training is performed under maximum entropy model, using bag of words, syntactic and name entity features.
</nextsent>
<nextsent>this qa system does not employ the use of patterns.
</nextsent>
<nextsent>in this paper, we explore the inclusion of surface text patterns into the framework of statistical question answering system.
</nextsent>
<nextsent>a corpus of question-answer pairs was obtained from knowledge master (1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2944">
<title id=" N06-2027.xml">using semantic authoring for blissymbols communication boards </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>because words are structured from semantic components, the graphic representation by itself provides information on words?
</prevsent>
<prevsent>connectivity 1.
</prevsent>
</prevsection>
<citsent citstr=" W97-0503 ">
in the last decade, several systems that integrate nlg techniques for aac systems have been developed ((mccoy, 1997), (<papid> W97-0503 </papid>vaillant, 1997) for example).these systems share common architecture: telegraphic input sequence (words or symbols) is first parsed, and then grammatical sentence that represents the message is generated.</citsent>
<aftsection>
<nextsent>this paper presents an nlg-aac system that generates messages through controlled process of authoring, where each step in the selection of symbols is controlled by the input specification defined 1see http://www.bci.org for reference on the language 105 for the linguistic realizer.
</nextsent>
<nextsent>a major difficulty when parsing telegraphic sequence of words or symbols, is that many of the hints that are used to capture the structure of the text and, accordingly, the meaning of the utterance,are missing.
</nextsent>
<nextsent>moreover, as an aac device is usually used for real-time conversation, the interpretation of utterances relies heavily on pragmatics ? timeof mentioned events, reference to the immediate en vironment.previous works dealing with translating telegraphic text, such as (grishman and sterling, 1989), (<papid> H89-1034 </papid>lee et al , 1997) <papid> P97-1016 </papid>requires to identify dependency relations among the tokens of the telegraphic input.rich lexical knowledge is needed to identify possible dependencies in given utterance, i.e., to findthe predicate and to apply constraints, such as selectional restrictions to recognize its arguments.similar methods were used for aac applications, compan sion (mccoy, 1997) <papid> W97-0503 </papid>for example?</nextsent>
<nextsent>where the telegraphic text is expanded to full sentences, using word order parser, and semantic parser to build the case frame structure of the verb in the utterance, filling the slots with the rest of the content words given.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2945">
<title id=" N06-2027.xml">using semantic authoring for blissymbols communication boards </title>
<section> generating messages via translation.  </section>
<citcontext>
<prevsection>
<prevsent>this paper presents an nlg-aac system that generates messages through controlled process of authoring, where each step in the selection of symbols is controlled by the input specification defined 1see http://www.bci.org for reference on the language 105 for the linguistic realizer.
</prevsent>
<prevsent>a major difficulty when parsing telegraphic sequence of words or symbols, is that many of the hints that are used to capture the structure of the text and, accordingly, the meaning of the utterance,are missing.
</prevsent>
</prevsection>
<citsent citstr=" H89-1034 ">
moreover, as an aac device is usually used for real-time conversation, the interpretation of utterances relies heavily on pragmatics ? timeof mentioned events, reference to the immediate en vironment.previous works dealing with translating telegraphic text, such as (grishman and sterling, 1989), (<papid> H89-1034 </papid>lee et al , 1997) <papid> P97-1016 </papid>requires to identify dependency relations among the tokens of the telegraphic input.rich lexical knowledge is needed to identify possible dependencies in given utterance, i.e., to findthe predicate and to apply constraints, such as selectional restrictions to recognize its arguments.similar methods were used for aac applications, compan sion (mccoy, 1997) <papid> W97-0503 </papid>for example?</citsent>
<aftsection>
<nextsent>where the telegraphic text is expanded to full sentences, using word order parser, and semantic parser to build the case frame structure of the verb in the utterance, filling the slots with the rest of the content words given.
</nextsent>
<nextsent>the system uses the semantic representation to re-generate fluent text, relying on lexical resources and nlg techniques.
</nextsent>
<nextsent>the main questions at stake in this approach arehow good can semantic parser be, in order to reconstruct the full structure of the sentence from telegraphic input and are pragmatic gaps in the given telegraphic utterances recoverable in general.
</nextsent>
<nextsent>authoring our approach differs from previous nlg-aac systems in that, with the model of semantic authoring (biller et al , 2005), <papid> W05-1602 </papid>we intervene during the process of composing the input sequence, and thus can provide early feedback (in the form of display composition and partial text feedback), while preventing the need for parsing telegraphic sequence.semantic parsing is avoided by constructing semantic structure explicitly while the user inputs the sequence incrementally.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2946">
<title id=" N06-2027.xml">using semantic authoring for blissymbols communication boards </title>
<section> generating messages via translation.  </section>
<citcontext>
<prevsection>
<prevsent>this paper presents an nlg-aac system that generates messages through controlled process of authoring, where each step in the selection of symbols is controlled by the input specification defined 1see http://www.bci.org for reference on the language 105 for the linguistic realizer.
</prevsent>
<prevsent>a major difficulty when parsing telegraphic sequence of words or symbols, is that many of the hints that are used to capture the structure of the text and, accordingly, the meaning of the utterance,are missing.
</prevsent>
</prevsection>
<citsent citstr=" P97-1016 ">
moreover, as an aac device is usually used for real-time conversation, the interpretation of utterances relies heavily on pragmatics ? timeof mentioned events, reference to the immediate en vironment.previous works dealing with translating telegraphic text, such as (grishman and sterling, 1989), (<papid> H89-1034 </papid>lee et al , 1997) <papid> P97-1016 </papid>requires to identify dependency relations among the tokens of the telegraphic input.rich lexical knowledge is needed to identify possible dependencies in given utterance, i.e., to findthe predicate and to apply constraints, such as selectional restrictions to recognize its arguments.similar methods were used for aac applications, compan sion (mccoy, 1997) <papid> W97-0503 </papid>for example?</citsent>
<aftsection>
<nextsent>where the telegraphic text is expanded to full sentences, using word order parser, and semantic parser to build the case frame structure of the verb in the utterance, filling the slots with the rest of the content words given.
</nextsent>
<nextsent>the system uses the semantic representation to re-generate fluent text, relying on lexical resources and nlg techniques.
</nextsent>
<nextsent>the main questions at stake in this approach arehow good can semantic parser be, in order to reconstruct the full structure of the sentence from telegraphic input and are pragmatic gaps in the given telegraphic utterances recoverable in general.
</nextsent>
<nextsent>authoring our approach differs from previous nlg-aac systems in that, with the model of semantic authoring (biller et al , 2005), <papid> W05-1602 </papid>we intervene during the process of composing the input sequence, and thus can provide early feedback (in the form of display composition and partial text feedback), while preventing the need for parsing telegraphic sequence.semantic parsing is avoided by constructing semantic structure explicitly while the user inputs the sequence incrementally.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2948">
<title id=" N06-2027.xml">using semantic authoring for blissymbols communication boards </title>
<section> generating messages via semantic.  </section>
<citcontext>
<prevsection>
<prevsent>the system uses the semantic representation to re-generate fluent text, relying on lexical resources and nlg techniques.
</prevsent>
<prevsent>the main questions at stake in this approach arehow good can semantic parser be, in order to reconstruct the full structure of the sentence from telegraphic input and are pragmatic gaps in the given telegraphic utterances recoverable in general.
</prevsent>
</prevsection>
<citsent citstr=" W05-1602 ">
authoring our approach differs from previous nlg-aac systems in that, with the model of semantic authoring (biller et al , 2005), <papid> W05-1602 </papid>we intervene during the process of composing the input sequence, and thus can provide early feedback (in the form of display composition and partial text feedback), while preventing the need for parsing telegraphic sequence.semantic parsing is avoided by constructing semantic structure explicitly while the user inputs the sequence incrementally.</citsent>
<aftsection>
<nextsent>it combines three aspects into an integrated approach for the design of an aac system: ? semantic authoring drives natural language realization system and provides rich semantic input.
</nextsent>
<nextsent>a display is updated on the fly as the authoring system requires the user to select options.?
</nextsent>
<nextsent>ready-made inputs, corresponding to predefined pragmatic contexts are made available to the user as semantic templates.in this method, each step of input insertion is controlled by set of constraints and rules, which are drawn from an ontology.
</nextsent>
<nextsent>the system offers, at each step, only possible complements to small set ofconcepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2950">
<title id=" N06-2027.xml">using semantic authoring for blissymbols communication boards </title>
<section> generating messages via semantic.  </section>
<citcontext>
<prevsection>
<prevsent>1).
</prevsent>
<prevsent>the lexicon currently includes 2,200 en tries.figure 1: snapshot of the bliss lexicon web application the core of the processing machinery of the aac message generation system is based on saut (biller et al , 2005) ? <papid> W05-1602 </papid>an authoring system for logical forms encoded as conceptual graphs (cg).</prevsent>
</prevsection>
<citsent citstr=" P98-2173 ">
the system belongs to the family of wysiwym (what you see is what you mean) (power and scott, 1998) <papid> P98-2173 </papid>text generation systems: logical forms are entered interactively and the corresponding linguistic realization of the expressions is generated in several languages.the system maintains model of the discourse context corresponding to the authored documents to enable reference planning in the generation process.</citsent>
<aftsection>
<nextsent>generating language from pictorial inputs, and specifically from bliss symbols using semantic authoring in the wysiwym approach is not only pictorial application of the textual version, but it also addresses specific needs of augmentative communication.
</nextsent>
<nextsent>as was mentioned above, generating text from telegraphic message for aac usage must take the context of the conversation into account.
</nextsent>
<nextsent>we address this problem in two manners: (1) adding pre-defined inputs into the system (yet al owing accurate text generation that considers syntactic variations), and (2) enabling the assignment of default values to each conversation (such as participants, tense, mood).
</nextsent>
<nextsent>we also take advantage of the unique properties of the bliss symbols; the set of symbols that are offered in each display can be filtered using their semantic/graphical connectivity; the reduction of the number of possible choices that are to be made by the user in each step of the message generation affects the cognitive load and can affect the rate of communication.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2952">
<title id=" N04-1018.xml">detecting structural meta data with decision trees and transformation based learning </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>however theirs was not truly automatic system as it relied on hand annotated edit signals?
</prevsent>
<prevsent>to locate ips.
</prevsent>
</prevsection>
<citsent citstr=" P92-1008 ">
bear et al  (1992) <papid> P92-1008 </papid>explored pattern matching, parsing and acoustic cues and concluded that multiple sources of information would be needed to detect edit disfluencies.</citsent>
<aftsection>
<nextsent>a decision-tree-basedsystem that took advantage of various acoustic and lexical features to detect ips was developed in (nakatani and hirschberg, 1994).
</nextsent>
<nextsent>shriberg et al  (1997) applied machine prediction of ips with decision trees to the broader switchboard corpus by generating decision trees with variety of prosodic features.
</nextsent>
<nextsent>stolcke et al  (1998) then expanded the prosodic tree model with hidden event language model (lm) to identify sentence boundaries, filled pauses and ips in different types of edit disfluencies.
</nextsent>
<nextsent>the hidden event lm used in their work adapted hidden markov model(hmm) algorithms to an n-gram lm paradigm to represent non-lexical events such as ips and sentence boundaries as hidden states.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2953">
<title id=" N04-1018.xml">detecting structural meta data with decision trees and transformation based learning </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>liu et al  (2003) built on this framework and extended prosodic features and the hidden event lm to predict edit ips on both human transcripts and stt system output.
</prevsent>
<prevsent>their system also detected the onset of the reparandum by employing rule-based pattern matching once edit ips have been detected.
</prevsent>
</prevsection>
<citsent citstr=" N01-1016 ">
edit dis fluency detection systems that rely exclusive lyon word-based information have been presented by heeman et al  (heeman et al , 1996) and charniak and johnson (charniak and johnson, 2001).<papid> N01-1016 </papid></citsent>
<aftsection>
<nextsent>common to both ofthese approaches is focus on repeated or similar sequences of words and information about the words themselves and the length and similarity of the sequences.
</nextsent>
<nextsent>our approach is most similar to (liu et al , 2003), since we also detect boundary events such as ips first and use them as signals?
</nextsent>
<nextsent>when identifying the reparandum in later stage.
</nextsent>
<nextsent>the motivation to detect ips first is that speech ip/supredictionprosodic and lexical feature extraction word boundary event prediction (dt/he-lm) filler/edit word detection (tbl) output figure 1: system diagram speech before an ip is fluent and is likely to be free of any prosodic or lexical irregularities that can indicate the occurrence of an edit disfluency.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2954">
<title id=" N04-1018.xml">detecting structural meta data with decision trees and transformation based learning </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>since inclusion of features that do not contribute to the classification of data can degrade the performance of decision tree, we selected only the prosodic features whose exclusion from the training process led to decrease in boundary event detection accuracy on the development data by utilizing the leave-one-out method.
</prevsent>
<prevsent>lexical features consisted of pos tag groups, word and pos tag pattern matches, and flag indicating existence 1in our work, rhyme was defined to contain the final vowel of word and any consonants following the final vowel.of filler words to the right of the current word boundary.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
the pos tag features were produced by first predicting the tags with ratnaparkhis maximum entropy tagger (ratnaparkhi, 1996) <papid> W96-0213 </papid>and then clustered by hand into smaller number of groups based on their syntactic role.</citsent>
<aftsection>
<nextsent>the clustering was performed to speed up decision tree training as well as to reduce the impact of tagger errors.word pattern match features were generated by comparing words over the range of up to four words across the word boundary in consideration.
</nextsent>
<nextsent>grouped pos tags were compared in similar way, but the range was limited toat most two tags across the boundary since wider comparison range would have resulted in far more matches than would be useful due to the low number of available pos tag groups.
</nextsent>
<nextsent>when words known to be identified frequently as fillers existed after the boundary, they were skipped and the range of pattern matching was extended accordingly.
</nextsent>
<nextsent>another useful cue for boundary event detection is the existence of word fragments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2955">
<title id=" N04-1018.xml">detecting structural meta data with decision trees and transformation based learning </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>4.3 edit and filler detection.
</prevsent>
<prevsent>after sus and ips have been marked, we use transformation-based learning (tbl) to learn rules to detect edit disfluencies and conversational fillers.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
tbl is an automatic rule learning technique that has been successfully applied to variety of problems in natural language processing, including part-of-speech tagging (brill, 1995), <papid> J95-4004 </papid>spelling correction (mangu and brill,1997), error correction in automatic speech recognition (mangu and padmanabhan, 2001), and named entity detection (kim and woodland, 2000).</citsent>
<aftsection>
<nextsent>we selected tbl for our tagging-like meta data detection task since it has been used successfully for these other tagging tasks.
</nextsent>
<nextsent>tbl is an iterative technique for inducing rules from training data.
</nextsent>
<nextsent>a tbl system consists of baseline predictor, set of rule templates, and an objective function for scoring potential rules.
</nextsent>
<nextsent>after tagging the training data using the baseline predictor, the system learns list ofrules to correct errors in these predictions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2956">
<title id=" N04-1018.xml">detecting structural meta data with decision trees and transformation based learning </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>this allows rules which are learned later in the process to fine tune the effects of the earlier rules.
</prevsent>
<prevsent>tbl produces concise, comprehensible rules, and uses the entire corpus to train all of the rules.
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
we used florian and ngais fast tbl system (fntbl) (ngai and florian, 2001) <papid> N01-1006 </papid>to train rules using dis fluency annotated conversational speech data.</citsent>
<aftsection>
<nextsent>the input to our tbl system consists of text divided into utterances, with ips and sus inserted as if they were extra words.
</nextsent>
<nextsent>(for simplicity, these special words are also assigned ip?
</nextsent>
<nextsent>and su?
</nextsent>
<nextsent>as part of speech tags.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2957">
<title id=" N07-1048.xml">analysis of morphbased speech recognition and the modeling of outofvocabulary words across languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lms incorporating morphological knowledge about these languages can be applied.
</prevsent>
<prevsent>a further challenging category comprises languages that are both highly inflecting and compounding,such as the finno-ugric languages finnish andes tonian.morphology modeling aims to reduce the out of-vocabulary (oov) rate as well as data sparsity,thereby producing more effective language models.
</prevsent>
</prevsection>
<citsent citstr=" W06-1646 ">
however, obtaining considerable improvements in speech recognition accuracy seems hard, as is demonstrated by the fairly meager improvements (14 % relative) over standard word-based models accomplished by, e.g., berton et al  (1996), ordelman et al  (2003), kirchhoff et al  (2006), whittaker and woodland (2000), kwon and park (2003),and shafran and hall (2006) <papid> W06-1646 </papid>for dutch, arabic, english, korean, and czech, or even the worse performance reported by larson et al  (2000) for german and byrne et al  (2001) for czech.</citsent>
<aftsection>
<nextsent>nevertheless, clear improvements over word baseline have been achieved for serbo-croatian (geutner et al , 1998),finnish, estonian (kurimo et al , 2006<papid> N06-1062 </papid>b) and turkish (kurimo et al , 2006<papid> N06-1062 </papid>a).</nextsent>
<nextsent>in this paper, subword language models in the recognition of speech of four languages are ana 380 lyzed: finnish, estonian, turkish, and the dialect of arabic spoken in egypt, egyptian colloquial arabic (eca).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2958">
<title id=" N07-1048.xml">analysis of morphbased speech recognition and the modeling of outofvocabulary words across languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a further challenging category comprises languages that are both highly inflecting and compounding,such as the finno-ugric languages finnish andes tonian.morphology modeling aims to reduce the out of-vocabulary (oov) rate as well as data sparsity,thereby producing more effective language models.
</prevsent>
<prevsent>however, obtaining considerable improvements in speech recognition accuracy seems hard, as is demonstrated by the fairly meager improvements (14 % relative) over standard word-based models accomplished by, e.g., berton et al  (1996), ordelman et al  (2003), kirchhoff et al  (2006), whittaker and woodland (2000), kwon and park (2003),and shafran and hall (2006) <papid> W06-1646 </papid>for dutch, arabic, english, korean, and czech, or even the worse performance reported by larson et al  (2000) for german and byrne et al  (2001) for czech.</prevsent>
</prevsection>
<citsent citstr=" N06-1062 ">
nevertheless, clear improvements over word baseline have been achieved for serbo-croatian (geutner et al , 1998),finnish, estonian (kurimo et al , 2006<papid> N06-1062 </papid>b) and turkish (kurimo et al , 2006<papid> N06-1062 </papid>a).</citsent>
<aftsection>
<nextsent>in this paper, subword language models in the recognition of speech of four languages are ana 380 lyzed: finnish, estonian, turkish, and the dialect of arabic spoken in egypt, egyptian colloquial arabic (eca).
</nextsent>
<nextsent>all these languages are considered morphologically rich?, but the benefits of usingsubword-based lms differ across languages.
</nextsent>
<nextsent>we attempt to discover explanations for these differences.
</nextsent>
<nextsent>in particular, the focus is on the analysis of oovs:a perceived strength of subword models, when contrasted with word models, is that subword models can generalize to previously unseen word forms by recognizing them as sequences of shorter familiar word fragments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2962">
<title id=" N07-1048.xml">analysis of morphbased speech recognition and the modeling of outofvocabulary words across languages </title>
<section> morfessor.  </section>
<citcontext>
<prevsection>
<prevsent>sub strings occurring frequently enough in several different word forms are proposed as morphs, and the words in the corpus are then represented as concatenation of morphs, e.g., hand, hand+s,left+hand+ed, hand+ful?.
</prevsent>
<prevsent>through maximum pos teriori optimization (map), an optimal balance is sought between the compactness of the inventory ofmorphs, i.e., the morph lexicon, versus the compactness of the representation of the corpus.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
among others, de marcken (1996), brent (1999), goldsmith (2001), <papid> J01-2001 </papid>creutz and lagus (2002), <papid> W02-0603 </papid>and creutz (2006) have shown that models based onthe above approach produce segment ations that resemble linguistic morpheme segment ations, when formulated mathematically in probabilistic framework or equivalently using the minimum description length (mdl) principle (rissanen, 1989).</citsent>
<aftsection>
<nextsent>similarly, goldwater et al  (2006) <papid> P06-1085 </papid>use hierarchical dirichlet model in combination with morph bigram probabilities.</nextsent>
<nextsent>the morfessor model has been developed over the years, and different model versions exist.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2963">
<title id=" N07-1048.xml">analysis of morphbased speech recognition and the modeling of outofvocabulary words across languages </title>
<section> morfessor.  </section>
<citcontext>
<prevsection>
<prevsent>sub strings occurring frequently enough in several different word forms are proposed as morphs, and the words in the corpus are then represented as concatenation of morphs, e.g., hand, hand+s,left+hand+ed, hand+ful?.
</prevsent>
<prevsent>through maximum pos teriori optimization (map), an optimal balance is sought between the compactness of the inventory ofmorphs, i.e., the morph lexicon, versus the compactness of the representation of the corpus.
</prevsent>
</prevsection>
<citsent citstr=" W02-0603 ">
among others, de marcken (1996), brent (1999), goldsmith (2001), <papid> J01-2001 </papid>creutz and lagus (2002), <papid> W02-0603 </papid>and creutz (2006) have shown that models based onthe above approach produce segment ations that resemble linguistic morpheme segment ations, when formulated mathematically in probabilistic framework or equivalently using the minimum description length (mdl) principle (rissanen, 1989).</citsent>
<aftsection>
<nextsent>similarly, goldwater et al  (2006) <papid> P06-1085 </papid>use hierarchical dirichlet model in combination with morph bigram probabilities.</nextsent>
<nextsent>the morfessor model has been developed over the years, and different model versions exist.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2964">
<title id=" N07-1048.xml">analysis of morphbased speech recognition and the modeling of outofvocabulary words across languages </title>
<section> morfessor.  </section>
<citcontext>
<prevsection>
<prevsent>through maximum pos teriori optimization (map), an optimal balance is sought between the compactness of the inventory ofmorphs, i.e., the morph lexicon, versus the compactness of the representation of the corpus.
</prevsent>
<prevsent>among others, de marcken (1996), brent (1999), goldsmith (2001), <papid> J01-2001 </papid>creutz and lagus (2002), <papid> W02-0603 </papid>and creutz (2006) have shown that models based onthe above approach produce segment ations that resemble linguistic morpheme segment ations, when formulated mathematically in probabilistic framework or equivalently using the minimum description length (mdl) principle (rissanen, 1989).</prevsent>
</prevsection>
<citsent citstr=" P06-1085 ">
similarly, goldwater et al  (2006) <papid> P06-1085 </papid>use hierarchical dirichlet model in combination with morph bigram probabilities.</citsent>
<aftsection>
<nextsent>the morfessor model has been developed over the years, and different model versions exist.
</nextsent>
<nextsent>the model used in the speech recognition experiments ofthe current paper is the original, so-called morfes sor baseline algorithm, which is publicly available for download.1.
</nextsent>
<nextsent>the mathematics of the morfessor baseline model is briefly outlined in the following; consult creutz (2006) for details.
</nextsent>
<nextsent>1http://www.cis.hut.fi/projects/morpho/ 2.1 map optimization criterion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2966">
<title id=" N03-1012.xml">semantic coherence scoring using an ontology </title>
<section> semantic coherence and speech.  </section>
<citcontext>
<prevsection>
<prevsent>9-16 proceedings of hlt-naacl 2003proposed and implemented in various systems.
</prevsent>
<prevsent>frequently the scores provided by the asr system itself are used, e.g. acoustic and language model probabilities.
</prevsent>
</prevsection>
<citsent citstr=" P99-1040 ">
more recently also scores provided by the nlu system have been employed, e.g. parsing scores or discourse scores (litman et al, 1999; <papid> P99-1040 </papid>engel, 2002; alexandersson and becker, 2003).</citsent>
<aftsection>
<nextsent>however, these methods assign higher scores to srhs which are semantically incoherent and lower scores to semantically coherent ones and disagree with other.
</nextsent>
<nextsent>for instance, the acoustic and language model scores of example (1b) are actually better than for example (1a),which results from the fact that the frequencies and corresponding probabilities for important expressions, suchas goodbye, are rather high, thereby ensuring their reliable recognition.
</nextsent>
<nextsent>another phenomenon found in our data consists of hypotheses such as: (2) zeige show mir me alle all vergnugen pleasures (3) zeige show mir me alle all filmen filmsin these cases language model scores are higher forex ample (2) than example (3), as the incorrect inflection on alle filmen was less frequent in the training material than that of the correct inflection on alle vergnugen.our data also shows - as one would intuitively expect - that the understanding-based scores generally reflect how well given srh is covered by the grammar employed.
</nextsent>
<nextsent>in many less well-formed cases these scores do not correspond to the correctness of the srh.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2967">
<title id=" N03-1012.xml">semantic coherence scoring using an ontology </title>
<section> semantic coherence and speech.  </section>
<citcontext>
<prevsection>
<prevsent>we propose an alternative way to rank srhs on the basis of their semantic coherence with respect to given ontology representing the domains of the system.
</prevsent>
<prevsent>2.2 annotation experiments.
</prevsent>
</prevsection>
<citsent citstr=" W02-0207 ">
in previous study (gurevych et al, 2002), <papid> W02-0207 </papid>we tested if human annotators could reliably classify srhs in terms 2as the numbers evident from large vocabulary speech recognition performance (cox et al, 2000), the occurrence ofless well formed and incoherent srhs increases the more conversational system becomes.</citsent>
<aftsection>
<nextsent>of their semantic coherence.
</nextsent>
<nextsent>the task of the annotators was to determine whether given hypothesis representsa internally coherent utterance or not.
</nextsent>
<nextsent>in order to test the reliability of such annotations, we collected corpus of srhs.
</nextsent>
<nextsent>the data collection was conducted by means of hidden operator test.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2968">
<title id=" N03-1012.xml">semantic coherence scoring using an ontology </title>
<section> semantic coherence and speech.  </section>
<citcontext>
<prevsection>
<prevsent>the final corpus consisted of 2.284 srhs.
</prevsent>
<prevsent>all hypotheses were then randomly mixedto avoid contextual influences and given to separate annotators.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
the resulting kappa statistics (carletta, 1996) <papid> J96-2004 </papid>over the annotated data yields  </citsent>
<aftsection>
<nextsent> , which seems to indicate that human annotators can reliably distinguish between coherent samples (as in example (1a)) and incoherent ones (as in example (1b)).the aim of the work presented here, then, was to provide knowledge-based score, that can be employed by any nlu system to select the best hypothesis from given n-best list.
</nextsent>
<nextsent>onto score, the resulting system will be described below, followed by its evaluation against the human gold standard.
</nextsent>
<nextsent>in this section, we provide description of the preexisting knowledge source employed by onto score, as far as it is necessary to understand the empirical data generated by the system.
</nextsent>
<nextsent>it is important to note that the ontology employed in this evaluation existed already and was crafted as general knowledge representation for various processing modules within the system.3 ontologies have traditionally been used to represent general and domain specific knowledge and are employed for various natural language understanding tasks, e.g. semantic interpretation (allen, 1987).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2969">
<title id=" N03-1012.xml">semantic coherence scoring using an ontology </title>
<section> the knowledge base.  </section>
<citcontext>
<prevsection>
<prevsent>the class physical object describes any kind of objects we come in contact with - living as well as non living - having location in space and time in contrast to abstract objects.
</prevsent>
<prevsent>these objects refer to different domains, such as sight and route in the tourism domain, av medium and actor in the tv and cinema domain, etc.,and can be associated with certain relations in the processes via slot constraint definitions.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the modeling of process as kind of event that is continuous and homogeneous in nature, follows the frame semantic analysis used for generating the framenet data (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>currently, there are four groups of processes (see figure 1):  general process, set of the most general processes such as duplication, imitation or repetition processes;  mental process, set of processes such as cognitive, emotional or perceptual processes;   physical process, set of processes such as motion, transaction or controlling processes;   social process, set of processes such as communication or instruction processes.
</nextsent>
<nextsent>let us consider the definition of the information search process in the ontology.
</nextsent>
<nextsent>it is modeled as projects.
</nextsent>
<nextsent>for more detail, see www.w3c.org.subclass of the cognitive process, which is subclass of the mental process and inherits the following slot constraints:   begin time, time expression indicating the starting time point;   end time, time expression indicating the time point when the process is complete;   state, one of the abstract process states, e.g. start, continue, interrupt, etc.;   cognizer, filled with class person including its subclasses.information search process features one additional slot constraint, piece-of-information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2970">
<title id=" N04-1013.xml">speed and accuracy in shallow and deep stochastic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in applications that are sensitive to the meanings expressed by natural language sentences, it has become common in recent years simply to incorporate publicly available statistical parsers.
</prevsent>
<prevsent>a state-of-the-art statistical parsing system that enjoys great popularity in research systems is the parser described in collins (1999) (henceforth the collins parser?).
</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
this system not only is frequently used for off-line data preprocessing, but also is included as black-box component for applications such as document summarization (daume and marcu,2002), information extraction (miller et al, 2000), <papid> A00-2030 </papid>machine translation (yamada and knight, 2001), <papid> P01-1067 </papid>and question answering (harabagiu et al, 2001).<papid> P01-1037 </papid></citsent>
<aftsection>
<nextsent>this is be 1this research has been funded in part by contract # mda904-03-c-0404 awarded from the advanced research and development activity, novel intelligence from massive dataprogram.
</nextsent>
<nextsent>we would like to thank chris culy whose original experiments inspired this research.
</nextsent>
<nextsent>cause the collins parser shares the property of robustness with other statistical parsers, but more than other such parsers, the categories of its parse-trees make grammatical distinctions that presumably are useful for meaning sensitive applications.
</nextsent>
<nextsent>for example, the categories of the model 3 collins parser distinguish between heads,arguments, and adjuncts and they mark some long distance dependency paths; these distinctions can guideapplication-specific post processors in extracting important semantic relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2971">
<title id=" N04-1013.xml">speed and accuracy in shallow and deep stochastic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in applications that are sensitive to the meanings expressed by natural language sentences, it has become common in recent years simply to incorporate publicly available statistical parsers.
</prevsent>
<prevsent>a state-of-the-art statistical parsing system that enjoys great popularity in research systems is the parser described in collins (1999) (henceforth the collins parser?).
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
this system not only is frequently used for off-line data preprocessing, but also is included as black-box component for applications such as document summarization (daume and marcu,2002), information extraction (miller et al, 2000), <papid> A00-2030 </papid>machine translation (yamada and knight, 2001), <papid> P01-1067 </papid>and question answering (harabagiu et al, 2001).<papid> P01-1037 </papid></citsent>
<aftsection>
<nextsent>this is be 1this research has been funded in part by contract # mda904-03-c-0404 awarded from the advanced research and development activity, novel intelligence from massive dataprogram.
</nextsent>
<nextsent>we would like to thank chris culy whose original experiments inspired this research.
</nextsent>
<nextsent>cause the collins parser shares the property of robustness with other statistical parsers, but more than other such parsers, the categories of its parse-trees make grammatical distinctions that presumably are useful for meaning sensitive applications.
</nextsent>
<nextsent>for example, the categories of the model 3 collins parser distinguish between heads,arguments, and adjuncts and they mark some long distance dependency paths; these distinctions can guideapplication-specific post processors in extracting important semantic relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2972">
<title id=" N04-1013.xml">speed and accuracy in shallow and deep stochastic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in applications that are sensitive to the meanings expressed by natural language sentences, it has become common in recent years simply to incorporate publicly available statistical parsers.
</prevsent>
<prevsent>a state-of-the-art statistical parsing system that enjoys great popularity in research systems is the parser described in collins (1999) (henceforth the collins parser?).
</prevsent>
</prevsection>
<citsent citstr=" P01-1037 ">
this system not only is frequently used for off-line data preprocessing, but also is included as black-box component for applications such as document summarization (daume and marcu,2002), information extraction (miller et al, 2000), <papid> A00-2030 </papid>machine translation (yamada and knight, 2001), <papid> P01-1067 </papid>and question answering (harabagiu et al, 2001).<papid> P01-1037 </papid></citsent>
<aftsection>
<nextsent>this is be 1this research has been funded in part by contract # mda904-03-c-0404 awarded from the advanced research and development activity, novel intelligence from massive dataprogram.
</nextsent>
<nextsent>we would like to thank chris culy whose original experiments inspired this research.
</nextsent>
<nextsent>cause the collins parser shares the property of robustness with other statistical parsers, but more than other such parsers, the categories of its parse-trees make grammatical distinctions that presumably are useful for meaning sensitive applications.
</nextsent>
<nextsent>for example, the categories of the model 3 collins parser distinguish between heads,arguments, and adjuncts and they mark some long distance dependency paths; these distinctions can guideapplication-specific post processors in extracting important semantic relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2973">
<title id=" N04-1013.xml">speed and accuracy in shallow and deep stochastic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper reports on some experiments that put this conventional wisdom to an empirical test.
</prevsent>
<prevsent>we investigated the accuracy of recovering semantically-relevantgrammatical dependencies from the tree-structures produced by the collins parser, comparing these dependencies to gold-standard dependencies which are available for subset of 700 sentences randomly drawn from section 23 of the wall street journal (see king et al (2003)).
</prevsent>
</prevsection>
<citsent citstr=" W02-1503 ">
we compared the output of the xle system, deep-grammar-based parsing system using the english lexical-functional grammar previously constructed as part of the pargram project (butt et al, 2002), <papid> W02-1503 </papid>to thesame gold standard.</citsent>
<aftsection>
<nextsent>this system incorporates sophisticated ambiguity-management technology so that all possible syntactic analyses of sentence are computed inan efficient, packed representation (maxwell and kaplan, 1993).<papid> J93-4001 </papid></nextsent>
<nextsent>in accordance with lfg theory, the output includes not only standard context-free phrase-structure trees but also attribute-value matrices (lfgs f(unctional)structures) that explicitly encode predicate-argument relations and other meaningful properties.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2974">
<title id=" N04-1013.xml">speed and accuracy in shallow and deep stochastic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we investigated the accuracy of recovering semantically-relevantgrammatical dependencies from the tree-structures produced by the collins parser, comparing these dependencies to gold-standard dependencies which are available for subset of 700 sentences randomly drawn from section 23 of the wall street journal (see king et al (2003)).
</prevsent>
<prevsent>we compared the output of the xle system, deep-grammar-based parsing system using the english lexical-functional grammar previously constructed as part of the pargram project (butt et al, 2002), <papid> W02-1503 </papid>to thesame gold standard.</prevsent>
</prevsection>
<citsent citstr=" J93-4001 ">
this system incorporates sophisticated ambiguity-management technology so that all possible syntactic analyses of sentence are computed inan efficient, packed representation (maxwell and kaplan, 1993).<papid> J93-4001 </papid></citsent>
<aftsection>
<nextsent>in accordance with lfg theory, the output includes not only standard context-free phrase-structure trees but also attribute-value matrices (lfgs f(unctional)structures) that explicitly encode predicate-argument relations and other meaningful properties.
</nextsent>
<nextsent>xle selects themost probable analysis from the potentially large candidate set by means of stochastic disambiguation component based on log-linear (a.k.a. maximum-entropy)probability model (riezler et al, 2002).<papid> P02-1035 </papid></nextsent>
<nextsent>the stochastic component is also ambiguity-enabled?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2975">
<title id=" N04-1013.xml">speed and accuracy in shallow and deep stochastic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this system incorporates sophisticated ambiguity-management technology so that all possible syntactic analyses of sentence are computed inan efficient, packed representation (maxwell and kaplan, 1993).<papid> J93-4001 </papid></prevsent>
<prevsent>in accordance with lfg theory, the output includes not only standard context-free phrase-structure trees but also attribute-value matrices (lfgs f(unctional)structures) that explicitly encode predicate-argument relations and other meaningful properties.</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
xle selects themost probable analysis from the potentially large candidate set by means of stochastic disambiguation component based on log-linear (a.k.a. maximum-entropy)probability model (riezler et al, 2002).<papid> P02-1035 </papid></citsent>
<aftsection>
<nextsent>the stochastic component is also ambiguity-enabled?
</nextsent>
<nextsent>in the sense that the computations for statistical estimation and selection of the most probable analyses are done efficiently by dynamic programming, avoiding the need to unpack the parse forests and enumerate individual analyses.
</nextsent>
<nextsent>the underlying parsing system also has built-in robustness mechanisms that allow it to parse strings that are outside the scope of the grammar as shortest sequence of well formed fragments?.
</nextsent>
<nextsent>furthermore, performance parameters that bound parsing and disambiguation work can be tuned for efficient but accurate operation.as part of our assessment, we also measured the parsing speed of the two systems, taking into account all stages of processing that each system requires to produce its output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2976">
<title id=" N04-1013.xml">speed and accuracy in shallow and deep stochastic parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the underlying parsing system also has built-in robustness mechanisms that allow it to parse strings that are outside the scope of the grammar as shortest sequence of well formed fragments?.
</prevsent>
<prevsent>furthermore, performance parameters that bound parsing and disambiguation work can be tuned for efficient but accurate operation.as part of our assessment, we also measured the parsing speed of the two systems, taking into account all stages of processing that each system requires to produce its output.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
for example, since the collins parser depends on prior part-of-speech tagger (ratnaparkhi, 1996), <papid> W96-0213 </papid>we included the time for pos tagging in our collins mea surements.</citsent>
<aftsection>
<nextsent>xle incorporates sophisticated finite-state morphology and dictionary lookup component, and its time is part of the measure of xle performance.
</nextsent>
<nextsent>performance parameters of both the collins parser andthe xle system were adjusted on heldout set consisting of random selection of 1/5 of the parc 700 dependency bank; experimental results were then based on the other 560 sentences.
</nextsent>
<nextsent>for model 3 of the collins parser, beam size of 1000, and not the recommended beam size of 10000, was found to optimize parsing speed at little loss inaccuracy.
</nextsent>
<nextsent>on the same heldout set, parameters of the stochastic disambiguation system and parameters for parsing performance were adjusted for core and complete version of the xle system, differing in the size of the constraint-set of the underlying grammar.for both xle and the collins parser we wrote conversion programs to transform the normal (tree or structure) output into the corresponding relations of the dependency bank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2978">
<title id=" N04-1013.xml">speed and accuracy in shallow and deep stochastic parsing </title>
<section> stochastic parsing with lfg.  </section>
<citcontext>
<prevsection>
<prevsent>the advantage of this family of probability distributions is that it allows the user to encode arbitrary properties of the parse trees as feature-functions of the probability model, without the feature-functions needing to be independent and non-overlapping.
</prevsent>
<prevsent>the general form of conditional exponential models is as follows: p?(x|y) = z?(y) 1ef(x) where z?(y) = ? xx(y) ef(x) is normalizing constant over the set x(y) of parses for sentence y, ? isa vector of log-parameters, is vector of feature values, and ? ?
</prevsent>
</prevsection>
<citsent citstr=" P02-1036 ">
f(x) is vector dot product denoting the (log-)weight of parse x.dynamic-programming algorithms that allow the efficient estimation and searching of log-linear models from packed parse representation without enumerating an exponential number of parses have been recently presented by miyao and tsujii (2002) and geman and johnson (2002).<papid> P02-1036 </papid></citsent>
<aftsection>
<nextsent>these algorithms can be readily applied to the packed and/or-forests of maxwell and kaplan (1993), <papid> J93-4001 </papid>provided that each conjunctive node is annotated with feature-values of the loglinear model.</nextsent>
<nextsent>in the notation of miyao and tsujii (2002), such feature forest ? is defined as tuple c,d, r, ?, where is set of conjunctive nodes, is set of disjunctive nodes, ? is the root node, ? : ? 2c is conjunctive daughter function, and ? : ? 2d is disjunctive daughter function.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2981">
<title id=" N04-1013.xml">speed and accuracy in shallow and deep stochastic parsing </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we measured the accuracy of both systems against gold standard derived from the parc 700 dependency bank, and also measured their processing times.contrary to conventional wisdom, we found that the shallow system was not substantially faster than the deep parser operating on core grammar, while the deep system was significantly more accurate.
</prevsent>
<prevsent>furthermore, extending the grammar base of the deep system results in much better accuracy at cost of factor of 5 in speed.our experiment is comparable to recent work on reading off propbank-style (kingsbury and palmer, 2002)predicate-argument relations from gold-standard tree bank trees and automatic parses of the collins parser.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
gildea and palmer (2002) <papid> P02-1031 </papid>report f-score results in the 55% range for argument and boundary recognition based on automatic parses.</citsent>
<aftsection>
<nextsent>from this perspective, the nearly75% f-score that is achieved for our deterministic rewriting of collins?
</nextsent>
<nextsent>trees into dependencies is remarkable, even if the results are not directly comparable.
</nextsent>
<nextsent>our scores and gildea and palmers are both substantially lower than the 90% typically cited for evaluations based on labeled or unlabeled bracketing, suggesting that extracting semantically relevant dependencies is more difficult, but we think more valuable, task.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2982">
<title id=" N06-1035.xml">comparing the utility of state features in spoken dialogue using reinforcement learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these features are not just unique to the tutoring domain but are important to dialogue system sin general.
</prevsent>
<prevsent>our empirical results show that these features all lead to changes in what action the system should take, with concept repetition and frustration having the largest effects.
</prevsent>
</prevsection>
<citsent citstr=" E06-1037 ">
this paper extends our previous work (tetreaultand litman, 2006) <papid> E06-1037 </papid>which first presented methodology for exploring whether adding more complex features to representation of student state will beneficially alter tutor actions with respect to feedback.</citsent>
<aftsection>
<nextsent>here we present an empirical method of comparing the effects of each feature while also generalizing our findings to different action choice of what type of follow-up question should tutor ask the student(as opposed to what type of feedback should the tutor give).
</nextsent>
<nextsent>in complex domains such as tutoring, testing different policies with real or simulated students can be time consuming and costly so it is important to properly choose the best features before testing, which this work allows us to do.
</nextsent>
<nextsent>this in turn aids our long-term goal of improving spoken dialogue system that can effectively adapt to student to maximize their learning.
</nextsent>
<nextsent>we follow past lines of research (such as (levin and pieraccini, 1997) and (singh et al, 1999)) forde scribing dialogue   as trajectory within markov decision process (mdp) (sutton and barto, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2983">
<title id=" N06-1035.xml">comparing the utility of state features in spoken dialogue using reinforcement learning </title>
<section> corpus.  </section>
<citcontext>
<prevsection>
<prevsent>it then performs policy iteration to generate policy and v-values for each state.
</prevsent>
<prevsent>in the following sections, we discuss our corpus, methodology, andre sults.
</prevsent>
</prevsection>
<citsent citstr=" N04-3002 ">
for our study, we used an annotated corpus of20 human-computer spoken dialogue tutoring sessions (for our work we use the itspoke system(litman and silliman, 2004) <papid> N04-3002 </papid>which uses the text based why2-atlas dialogue tutoring system as its back-end?</citsent>
<aftsection>
<nextsent>(vanlehn et al, 2002)).
</nextsent>
<nextsent>the content state feature values certainty certain (cer) uncertain (unc) neutral (neu) frustration frustrated (f) neutral (n), correctness correct (c) partially correct (pc) incorrect (i) percent correct 50-100% (h)igh 0-49% (l)ow concept repetition concept is new (0) concept is repeated (r) table 1: potential student state features in mdp of the system, and all possible dialogue paths, were authored by physics experts.
</nextsent>
<nextsent>each session consists of an interaction with one student over 5 differentcollege-level physics problems, for total of 100 dialogues.
</nextsent>
<nextsent>before each session, the student is asked to read physics material for 30 minutes and then take pretest based on that material.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2987">
<title id=" N01-1025.xml">chunking with support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>tokenization and part-of-speech tagging can also be regarded as chunking task, if we assume each character as token.
</prevsent>
<prevsent>machine learning techniques are often applied to chunking, since the task is formulated as estimating an identifying function from the information (fea tures) available in the surrounding context.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
various machine learning approaches have been proposed for chunking (ramshaw and marcus, 1995; <papid> W95-0107 </papid>tjong kim sang, 2000a; tjong kim sang et al, 2000; tjong kim sang, 2000b; sassano and utsuro, 2000; <papid> C00-2102 </papid>van halteren, 2000).</citsent>
<aftsection>
<nextsent>conventional machine learning techniques, such as hidden markov model (hmm) and maximum entropy model (me), normally require careful feature selection in order to achieve high accuracy.they do not provide method for automatic selection of given feature sets.
</nextsent>
<nextsent>usually, heuristics areused for selecting effective features and their com binations.new statistical learning techniques such as support vector machines (svms) (cortes and vap nik, 1995; vapnik, 1998) and boosting(freund and schapire, 1996) have been proposed.
</nextsent>
<nextsent>these techniques take strategy that maximizes the margin between critical samples and the separating hyperplane.
</nextsent>
<nextsent>in particular, svms achieve high generalization even with training data of very high dimension.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2988">
<title id=" N01-1025.xml">chunking with support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>tokenization and part-of-speech tagging can also be regarded as chunking task, if we assume each character as token.
</prevsent>
<prevsent>machine learning techniques are often applied to chunking, since the task is formulated as estimating an identifying function from the information (fea tures) available in the surrounding context.
</prevsent>
</prevsection>
<citsent citstr=" C00-2102 ">
various machine learning approaches have been proposed for chunking (ramshaw and marcus, 1995; <papid> W95-0107 </papid>tjong kim sang, 2000a; tjong kim sang et al, 2000; tjong kim sang, 2000b; sassano and utsuro, 2000; <papid> C00-2102 </papid>van halteren, 2000).</citsent>
<aftsection>
<nextsent>conventional machine learning techniques, such as hidden markov model (hmm) and maximum entropy model (me), normally require careful feature selection in order to achieve high accuracy.they do not provide method for automatic selection of given feature sets.
</nextsent>
<nextsent>usually, heuristics areused for selecting effective features and their com binations.new statistical learning techniques such as support vector machines (svms) (cortes and vap nik, 1995; vapnik, 1998) and boosting(freund and schapire, 1996) have been proposed.
</nextsent>
<nextsent>these techniques take strategy that maximizes the margin between critical samples and the separating hyperplane.
</nextsent>
<nextsent>in particular, svms achieve high generalization even with training data of very high dimension.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2989">
<title id=" N01-1025.xml">chunking with support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, svms achieve high generalization even with training data of very high dimension.
</prevsent>
<prevsent>furthermore, by introducing the kernel function, svms handle non-linear feature spaces, and carry out the training considering combinations of more than one feature.
</prevsent>
</prevsection>
<citsent citstr=" W00-1303 ">
in the field of natural language processing, svmsare applied to text categorization and syntactic dependency structure analysis, and are reported tohave achieved higher accuracy than previous ap proaches.(joachims, 1998; taira and haruno, 1999; kudo and matsumoto, 2000<papid> W00-1303 </papid>a).</citsent>
<aftsection>
<nextsent>in this paper, we apply support vector machines to the chunking task.
</nextsent>
<nextsent>in addition, in order to achieve higher accuracy, we apply weighted voting of 8svm-based systems which are trained using distinct chunk representations.
</nextsent>
<nextsent>for the weighted voting systems, we introduce new type of weighting strategy which are derived from the theoretical basis of the svms.
</nextsent>
<nextsent>2.1 optimal hyperplane.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O2995">
<title id=" N01-1025.xml">chunking with support vector machines </title>
<section> chunking.  </section>
<citcontext>
<prevsection>
<prevsent>2.
</prevsent>
<prevsent>start/end.
</prevsent>
</prevsection>
<citsent citstr=" P00-1042 ">
this method has been used for the japanese named entity extraction task, and requires the following five tags for representing proper chunks(uchimoto et al, 2000) <papid> P00-1042 </papid>1.</citsent>
<aftsection>
<nextsent>1originally, uchimoto uses c/e/u/o/s representation.
</nextsent>
<nextsent>however we rename them as b/i/o/e/s for our purpose, since iob1 iob2 ioe1 ioe2 start/end in o o early b i trading i e in o o busy b i hong i i kong i e monday b e , o o gold b e was o o table 1: example for each chunk representationb current token is the start of chunk consisting of more than one token.e current token is the end of chunk consisting of more than one token.i current token is middle of chunk consisting of more than two tokens.
</nextsent>
<nextsent>s current token is chunk consisting of only one token.
</nextsent>
<nextsent>o current token is outside of any chunk.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3000">
<title id=" N01-1025.xml">chunking with support vector machines </title>
<section> leave-one-out bound.  </section>
<citcontext>
<prevsection>
<prevsent>base np standard dataset (basenp-s) this dataset was first introduced by (ramshaw and marcus, 1995), <papid> W95-0107 </papid>and taken as the standard dataset for basenp identification task2.</prevsent>
<prevsent>this dataset consists of four sections (15-18) of the wall street journal (wsj) part of the penn treebank for the training data, and one section(20) for the test data.</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
the data has part-ofspeech (pos) tags annotated by the brill tag ger(brill, 1995).<papid> J95-4004 </papid></citsent>
<aftsection>
<nextsent>base np large dataset (basenp-l) this dataset consists of 20 sections (02-21) of the wsj part of the penn treebank for the training data, and one section (00) for the testdata.
</nextsent>
<nextsent>pos tags in this datasets are also annotated by the brill tagger.
</nextsent>
<nextsent>we omit the experiments iob1 and ioe1 representations for this training data since the data size is too large for our current svms learning program.
</nextsent>
<nextsent>in case of iob1 and ioe1, the size of training data for one classifier which estimates the class and becomes much larger compared with iob2 and ioe2 models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3007">
<title id=" N06-2021.xml">initial study on automatic identification of speaker role in broadcast news speech </title>
<section> speaker role identification approaches.  </section>
<citcontext>
<prevsection>
<prevsent>sentence 1sentence 2sentence 3 figure 1: graphical representation of the hmm approach for speaker role labeling.
</prevsent>
<prevsent>this is simple first order hmm.the hmm has been widely used in many tagging problems.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
stolcke et al (stolcke et al, 2000) <papid> J00-3003 </papid>used it for dialog act classification, where each utterance (or dialog act) isused as the observation.</citsent>
<aftsection>
<nextsent>in speaker role detection, the observation is composed of much longer word sequence, i.e., the entire speech from one speaker.
</nextsent>
<nextsent>figure 1 shows the graphical representation of the hmm for speaker role identification, in which the states are the speaker roles, and the observation associated with state consists of the utterances from speaker.
</nextsent>
<nextsent>the most likely role sequence r?
</nextsent>
<nextsent>is: r?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3008">
<title id=" N04-1037.xml">the nonutility of predicate argument frequencies for pronoun interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>assuming that such statistics imply that industries are more likely to be forced in the real world than are initiatives or edges, this information could be taken to establish preference for his industry as the antecedent of it in(1).
</prevsent>
<prevsent>while there will always be cases that require arbitrarily deep knowledge for their interpretation, the empirical question of how far one can go by relying on this sort of selectional information remains.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
our point of departure is the work of lappin and leass (1994, <papid> J94-4002 </papid>henceforth l&l;) and dagan et al .</citsent>
<aftsection>
<nextsent>(1995).
</nextsent>
<nextsent>(see also dagan and itai (1990).)<papid> C90-3063 </papid></nextsent>
<nextsent>l&l; demonstrated with system called rap that a(manually-tuned) weight-based scheme for integrating pronoun interpretation preferences can achieve high performance on real data, in their case, 86%accuracy on corpus of computer training manuals.1 dagan et al  (1995) then developed postpro cessor based on predicate-argument statistics that was used to override raps decision when it failed to express clear preference between two or more antecedents, which resulted in modest rise in per 1kennedy and boguraev (1996, <papid> C96-1021 </papid>henceforth, k&b;)adapted l&ls; algorithm to relyon far less syntactic analysis (noun phrase identification and rudimentary grammatical role marking), with performance in the 75% range on mixed genres.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3009">
<title id=" N04-1037.xml">the nonutility of predicate argument frequencies for pronoun interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our point of departure is the work of lappin and leass (1994, <papid> J94-4002 </papid>henceforth l&l;) and dagan et al .</prevsent>
<prevsent>(1995).</prevsent>
</prevsection>
<citsent citstr=" C90-3063 ">
(see also dagan and itai (1990).)<papid> C90-3063 </papid></citsent>
<aftsection>
<nextsent>l&l; demonstrated with system called rap that a(manually-tuned) weight-based scheme for integrating pronoun interpretation preferences can achieve high performance on real data, in their case, 86%accuracy on corpus of computer training manuals.1 dagan et al  (1995) then developed postpro cessor based on predicate-argument statistics that was used to override raps decision when it failed to express clear preference between two or more antecedents, which resulted in modest rise in per 1kennedy and boguraev (1996, <papid> C96-1021 </papid>henceforth, k&b;)adapted l&ls; algorithm to relyon far less syntactic analysis (noun phrase identification and rudimentary grammatical role marking), with performance in the 75% range on mixed genres.</nextsent>
<nextsent>formance (2.5%).2 because rap is symbolic, thetwo systems were necessarily coupled in black box manner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3010">
<title id=" N04-1037.xml">the nonutility of predicate argument frequencies for pronoun interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(1995).
</prevsent>
<prevsent>(see also dagan and itai (1990).)<papid> C90-3063 </papid></prevsent>
</prevsection>
<citsent citstr=" C96-1021 ">
l&l; demonstrated with system called rap that a(manually-tuned) weight-based scheme for integrating pronoun interpretation preferences can achieve high performance on real data, in their case, 86%accuracy on corpus of computer training manuals.1 dagan et al  (1995) then developed postpro cessor based on predicate-argument statistics that was used to override raps decision when it failed to express clear preference between two or more antecedents, which resulted in modest rise in per 1kennedy and boguraev (1996, <papid> C96-1021 </papid>henceforth, k&b;)adapted l&ls; algorithm to relyon far less syntactic analysis (noun phrase identification and rudimentary grammatical role marking), with performance in the 75% range on mixed genres.</citsent>
<aftsection>
<nextsent>formance (2.5%).2 because rap is symbolic, thetwo systems were necessarily coupled in black box manner.
</nextsent>
<nextsent>they noted, however, that if one had statistically-driven pronoun interpretation system,co-occurrence information could be modeled along side morphosyntactic information: promising direction for future research is the development of an empirically based model for salience criteria analogous to theone that we constructed for lexical preference.
</nextsent>
<nextsent>the integration of these models usinga probabilistic decision procedure will hopefully yield an optimized integrated system for anaphora resolution.?
</nextsent>
<nextsent>(p. 643) in this work we set out to evaluate dagan et al proposal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3011">
<title id=" N04-1037.xml">the nonutility of predicate argument frequencies for pronoun interpretation </title>
<section> learning algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>no difficult attachments are attempted, and the results are errorful.
</prevsent>
<prevsent>there was no human-annotated linguistic information in the input.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the systems are described further below.maximum entropy modeling as previously indicated, the weight-based scheme of l&l; suggestsmaxent modeling (berger et al , 1996) <papid> J96-1002 </papid>as particularly natural choice for machine learning approach.</citsent>
<aftsection>
<nextsent>in maxent, the parameters of an exponential model of the following form are estimated: p(y|x) = ? ifi(x,y) ? e ? ifi(x,y) the variable represents the outcome (coreference or not) and represents the context.
</nextsent>
<nextsent>there is one value for each feature that predicts coreference behavior, represented by the parameters 1, ..., n,which are lagrange multipliers that constrain the expected value of each feature in the model to be the values found in the distribution of the training data.
</nextsent>
<nextsent>(the fi(x, y) are indicator functions which equal 1 when the corresponding feature is present, and 0otherwise.)
</nextsent>
<nextsent>the desired values for these parameters are obtained by maximizing the likelihood of the training data with respect to the model.3 thus, whereas l&ls; rap system uses an additive system of weights that is trained manually, the maxent system learns multiplicative system of weights automatically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3012">
<title id=" N04-1037.xml">the nonutility of predicate argument frequencies for pronoun interpretation </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>these features are likewise more liberal than the number-based hard constraint mentioned above.
</prevsent>
<prevsent>distance (dist): includes features pertaining tothe distance between the pronoun and the potential antecedent.
</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
examples include the number of sentences between them and the hobbs distance?, that is, the number of noun groups that hobbss search algorithm has to skip before the potential antecedent is found (hobbs, 1978; ge et al , 1998).<papid> W98-1119 </papid>grammatical role (pos): includes features pertaining to the syntactic position of the potentialantecedent.</citsent>
<aftsection>
<nextsent>examples include whether the potential antecedent appears to be the subject or object of verb, and whether the potential antecedent is embedded in prepositional phrase.linguistic form (lform): includes features pertaining to the referential form of the potential antecedent, e.g., whether it is proper name, definite description, indefinite np, or pronoun.
</nextsent>
<nextsent>the values of these features ? computed from our systems error ful shallow constituent parses ? comprised the input to the learning algorithms, along with the outcome as indicated by the annotated key.
</nextsent>
<nextsent>with trained statistical model for pronoun interpretation in hand, we can now consider the use ofpredicate-argument statistics to improve it.
</nextsent>
<nextsent>consider sentence (1) again, repeated as (2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3013">
<title id=" N04-1037.xml">the nonutility of predicate argument frequencies for pronoun interpretation </title>
<section> predicate-argument frequencies.  </section>
<citcontext>
<prevsection>
<prevsent>we took two approaches to smoothing.
</prevsent>
<prevsent>first, because dagan et al  used good-turing smoothing in their experiments, we did likewise soas to replicate their work as closely as possible.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
second, we tried an approach based on the distributional clustering method of pereira et al  (1993).<papid> P93-1024 </papid></citsent>
<aftsection>
<nextsent>this method yielded word classes that offered more robust count approximations for their member words.
</nextsent>
<nextsent>however, both methods yielded similar results when embedded in the larger system, and so we will report on the results of using good-turing so as to remain more directly comparable to dagan et al  the smoothed predicate-argument statistics we reemployed in two ways.
</nextsent>
<nextsent>first, we built postprocessing filter modeled directly on dagan et al system.
</nextsent>
<nextsent>their implementation made use of two equations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3014">
<title id=" N04-1037.xml">the nonutility of predicate argument frequencies for pronoun interpretation </title>
<section> error analysis.  </section>
<citcontext>
<prevsection>
<prevsent>there are variety of possible reasons why thepredicate-argument statistics failed to markedly improve performance in each of the system configurations.
</prevsent>
<prevsent>while it could be that such statistics are simply not good predictors for pronoun interpretation, data sparsity in the collected predicate-argument statistics could also be to blame.we carried out an error analysis to gain further in sight into this question.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
to address the data-sparsity issue, we employed the technique used in keller andlapata (2003, <papid> J03-3005 </papid>k&l;) to get more robust approximation of predicate-argument counts.9 we wrote 7these performance results include 64 impossible?</citsent>
<aftsection>
<nextsent>cases in which, due to mis parsing, no correct antecedents were provided to the model; hence 91.6% accuracy is the best that could be achieved.
</nextsent>
<nextsent>the results likewise include errors in which the model selected bogus antecedent that resulted from misparse.8as such, informal post-hoc experiments with gaussian smoothing (chen and rosenfeld, 2000) failed to im prove performance.
</nextsent>
<nextsent>9k&l; use this technique to obtain frequencies for predicate-argument bigrams that were unseen in given corpus, showing that the massive size of the web outweighs the noisy and unbalanced nature of searches performed on it to produce statistics that correlate well with corpus data.
</nextsent>
<nextsent>we are admittedly extending this reasoning to relations between the heads of predicates and arguments without establishing that k&ls; technique so generalizes, but we nonetheless feel that it is sufficient for the purpose of an exploratory error analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3015">
<title id=" N03-1037.xml">a web trained extraction summarization system </title>
<section> 6        7  dow </section>
<citcontext>
<prevsection>
<prevsent>this alignment is done for each sentence of the summary articles.
</prevsent>
<prevsent>finally for each non summary we group together all the aligned sentences to form the pair (extract, text).
</prevsent>
</prevsection>
<citsent citstr=" P93-1001 ">
similarity-based: inspired by sentence alignment for multilingual parallel corpora in machine translation (church, 1993; <papid> P93-1001 </papid>fung and church, 1994; <papid> C94-2178 </papid>melamed, 1999), <papid> J99-1003 </papid>we view the alignment between sentences from summaries and sentences from non summaries as the alignment of monolingual parallel texts at the sentence level.</citsent>
<aftsection>
<nextsent>in every domain of the yfcc, each article is represented as vector in vector space where each dimension is distinct non-stop word appearing in this domain.
</nextsent>
<nextsent>measuring the cosine similarity between two articles, we can decide whether they are close semantically.
</nextsent>
<nextsent>this method has been widely used in information retrieval (salton, 1975).
</nextsent>
<nextsent>to extend this idea, we measure the cosine-similarity between two sentences, one from summary (weekly or monthly article) and the other one from non summary (daily or weekly article).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3016">
<title id=" N03-1037.xml">a web trained extraction summarization system </title>
<section> 6        7  dow </section>
<citcontext>
<prevsection>
<prevsent>this alignment is done for each sentence of the summary articles.
</prevsent>
<prevsent>finally for each non summary we group together all the aligned sentences to form the pair (extract, text).
</prevsent>
</prevsection>
<citsent citstr=" C94-2178 ">
similarity-based: inspired by sentence alignment for multilingual parallel corpora in machine translation (church, 1993; <papid> P93-1001 </papid>fung and church, 1994; <papid> C94-2178 </papid>melamed, 1999), <papid> J99-1003 </papid>we view the alignment between sentences from summaries and sentences from non summaries as the alignment of monolingual parallel texts at the sentence level.</citsent>
<aftsection>
<nextsent>in every domain of the yfcc, each article is represented as vector in vector space where each dimension is distinct non-stop word appearing in this domain.
</nextsent>
<nextsent>measuring the cosine similarity between two articles, we can decide whether they are close semantically.
</nextsent>
<nextsent>this method has been widely used in information retrieval (salton, 1975).
</nextsent>
<nextsent>to extend this idea, we measure the cosine-similarity between two sentences, one from summary (weekly or monthly article) and the other one from non summary (daily or weekly article).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3017">
<title id=" N03-1037.xml">a web trained extraction summarization system </title>
<section> 6        7  dow </section>
<citcontext>
<prevsection>
<prevsent>this alignment is done for each sentence of the summary articles.
</prevsent>
<prevsent>finally for each non summary we group together all the aligned sentences to form the pair (extract, text).
</prevsent>
</prevsection>
<citsent citstr=" J99-1003 ">
similarity-based: inspired by sentence alignment for multilingual parallel corpora in machine translation (church, 1993; <papid> P93-1001 </papid>fung and church, 1994; <papid> C94-2178 </papid>melamed, 1999), <papid> J99-1003 </papid>we view the alignment between sentences from summaries and sentences from non summaries as the alignment of monolingual parallel texts at the sentence level.</citsent>
<aftsection>
<nextsent>in every domain of the yfcc, each article is represented as vector in vector space where each dimension is distinct non-stop word appearing in this domain.
</nextsent>
<nextsent>measuring the cosine similarity between two articles, we can decide whether they are close semantically.
</nextsent>
<nextsent>this method has been widely used in information retrieval (salton, 1975).
</nextsent>
<nextsent>to extend this idea, we measure the cosine-similarity between two sentences, one from summary (weekly or monthly article) and the other one from non summary (daily or weekly article).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3018">
<title id=" N03-1037.xml">a web trained extraction summarization system </title>
<section> 6        7  dow </section>
<citcontext>
<prevsection>
<prevsent>when an unknown text or set of unknown texts come in to be summarized, the system needs to select the most appropriate pair of bigram tables to create the extract.
</prevsent>
<prevsent>the most desirable domain for an unknown text or texts contains articles focusing on the same issues as the unknown ones.
</prevsent>
</prevsection>
<citsent citstr=" C00-1072 ">
two methods are used: ? topic signature (lin and hovy, 2000): <papid> C00-1072 </papid>topic signature is family of related terms {topic, signature}, where topic is the target concept and signature is vecto related ms. the topic in formula is assigned with the domain ame.</citsent>
<aftsection>
<nextsent>to nstruct the set of related words, consider n2 n3 n1 es e2 e3 e1 figure 3.
</nextsent>
<nextsent>lattice.
</nextsent>
<nextsent>th co only nou because major issues discus those issues evolver of are on sed in the d. each ter interested in the ns we ly omain, oun in th e ot in how domain receives tf.idf score.
</nextsent>
<nextsent>30 top-scoring nouns are selected to be the signature representing the domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3019">
<title id=" N03-3004.xml">discriminating among word senses using mcquittys similarity analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, discrimination utilizes features and information that can be easily extracted fromraw corpora, whereas disambiguation often relies on supervised learning from sense tagged training examples.however, the creation of sense tagged data is time consuming and results in knowledge acquisition bottleneck that severely limits the portability and scala bility of techniques that employ it.
</prevsent>
<prevsent>discrimination does not suffer from this problem since there is no expensive preprocessing, nor are any external knowledge sources or manually annotated data required.
</prevsent>
</prevsection>
<citsent citstr=" W97-0322 ">
the objective of this research is to extend previous work in discrimination by (pedersen and bruce, 1997),<papid> W97-0322 </papid>who developed an approach using agglomerative clustering.</citsent>
<aftsection>
<nextsent>their work relied on mcquittys similarity analysis using localized contextual features.
</nextsent>
<nextsent>while the approach in this paper also adopts mcquittys method, it is distinct in that it uses larger number of features that occur both locally and globally in the instance being discriminated.
</nextsent>
<nextsent>it also incorporates several ideas from later work by (schutze, 1998), including the reliance on separate training?
</nextsent>
<nextsent>corpus of raw text from which to identify contextual features, and the use of second order co? occurrences (socs) as feature for discrimination.our near term objectives for this research include determining to what extent different types of features impact the accuracy of unsupervised discrimination.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3021">
<title id=" N03-3004.xml">discriminating among word senses using mcquittys similarity analysis </title>
<section> discrimination features.  </section>
<citcontext>
<prevsection>
<prevsent>we carry out discrimination based on surface lexical features that require little or no preprocessing to identify.
</prevsent>
<prevsent>they consist of unigrams, bigrams, and second order co? occurrences.unigrams are single words that occur in the same context as target word.
</prevsent>
</prevsection>
<citsent citstr=" W96-0208 ">
bagofwords feature sets made up of unigrams have had long history of success in text classification and word sense disambiguation (mooney, 1996), <papid> W96-0208 </papid>and we believe that despite creating quite bit of noise can provide useful information for discrimination.</citsent>
<aftsection>
<nextsent>bigrams are pairs of words which occur together in the same context as the target word.
</nextsent>
<nextsent>they may include the target word, or they may not.
</nextsent>
<nextsent>we specify window of size five for bigrams, meaning that there may be up to three intervening words between the first and last word that make up the bigram.
</nextsent>
<nextsent>as such we are defining bigrams to be non consecutive word sequences, which could also be considered kind of cooccurrence feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3022">
<title id=" N03-3004.xml">discriminating among word senses using mcquittys similarity analysis </title>
<section> discrimination features.  </section>
<citcontext>
<prevsection>
<prevsent>we specify window of size five for bigrams, meaning that there may be up to three intervening words between the first and last word that make up the bigram.
</prevsent>
<prevsent>as such we are defining bigrams to be non consecutive word sequences, which could also be considered kind of cooccurrence feature.
</prevsent>
</prevsection>
<citsent citstr=" N01-1011 ">
bigrams have recently been shown to be very successful features in supervised word sense disambiguation (pedersen, 2001).<papid> N01-1011 </papid></citsent>
<aftsection>
<nextsent>we believe this is because they capture middle distance cooccurrence relations between words that occur in the context of the target word.
</nextsent>
<nextsent>second order cooccurrences are words that occur with co-occurrences of the target word.
</nextsent>
<nextsent>for example, suppose that line is the target word.
</nextsent>
<nextsent>given telephone line and telephone bill, bill would be considered second order co? occurrence of line since it occurs with telephone, first order cooccurrence of line.we define window size of five in identifying second order cooccurrences, meaning that the first order cooccurrence must be within five positions of the target word, and the second order cooccurrence must be within five positions of the first order cooccurrence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3023">
<title id=" N03-3004.xml">discriminating among word senses using mcquittys similarity analysis </title>
<section> experimental methodology.  </section>
<citcontext>
<prevsection>
<prevsent>we follow schutzes strategy and use training?
</prevsent>
<prevsent>corpus only to extract features and ignore the sense tags.
</prevsent>
</prevsection>
<citsent citstr=" H93-1051 ">
in particular, we use subsets of the line data (leacock et al, 1993) <papid> H93-1051 </papid>and the english lexical sample data from the senseval-2 comparative exercise among word sense disambiguation systems (edmonds and cotton, 2001).</citsent>
<aftsection>
<nextsent>the line data contains 4,146 instances, where each consists of two to three sentences where single occurrence of line has been manually tagged with one of six possible senses.
</nextsent>
<nextsent>we randomly select 100 instances of each sense for test data, and 200 instances of each sense for training.
</nextsent>
<nextsent>this gives total of 600 evaluation instances, and 1200 training instances.
</nextsent>
<nextsent>this is done to test the quality of our discrimination method when senses are uniformly distributed and where no particular sense is dominant.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3025">
<title id=" N03-3004.xml">discriminating among word senses using mcquittys similarity analysis </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>as yet we have drawn no conclusions from these results, but it is clearly vital issue to investigate further.
</prevsent>
<prevsent>unsupervised approaches to word sense discrimination have been somewhat less common in the computational linguistics literature, at least when compared to supervised approaches to word sense disambiguation.there is body of work at the intersection of supervised and unsupervised approaches, which involves using small amount of training data in order to automatically create more training data, in effect bootstrapping from the small sample of sense tagged data.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
the best example of such an approach is (yarowsky, 1995), <papid> P95-1026 </papid>who proposes method that automatically identifies collocations that are indicative of the sense of word, and uses those to itera tively label more examples.</citsent>
<aftsection>
<nextsent>while our focus has been on pedersen and bruce, andon schutze, there has been other work in purely unsupervised approaches to word sense discrimination.
</nextsent>
<nextsent>(fukumoto and suzuki, 1999) <papid> E99-1028 </papid>describe method for discriminating among verb senses based on determining which nouns cooccur with the target verb.</nextsent>
<nextsent>collocations are extracted which are indicative of the sense of verb based on similarity measure they derive.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3026">
<title id=" N03-3004.xml">discriminating among word senses using mcquittys similarity analysis </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the best example of such an approach is (yarowsky, 1995), <papid> P95-1026 </papid>who proposes method that automatically identifies collocations that are indicative of the sense of word, and uses those to itera tively label more examples.</prevsent>
<prevsent>while our focus has been on pedersen and bruce, andon schutze, there has been other work in purely unsupervised approaches to word sense discrimination.</prevsent>
</prevsection>
<citsent citstr=" E99-1028 ">
(fukumoto and suzuki, 1999) <papid> E99-1028 </papid>describe method for discriminating among verb senses based on determining which nouns cooccur with the target verb.</citsent>
<aftsection>
<nextsent>collocations are extracted which are indicative of the sense of verb based on similarity measure they derive.
</nextsent>
<nextsent>(pantel and lin, 2002) introduce method known as committee based clustering that discovers word senses.the words in the corpus are clustered based on their distributional similarity under the assumption that semantically similar words will have similar distributional characteristics.
</nextsent>
<nextsent>in particular, they use pointwise mutual information to find how close word is to its context andthen determine how similar the contexts are using the co sine coefficient.
</nextsent>
<nextsent>our long term goal is to develop method that will as sign sense labels to clusters using information found in machine readable dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3027">
<title id=" N03-3004.xml">discriminating among word senses using mcquittys similarity analysis </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>we will treat glosses as found in dictionary as vectors thatwe project into the same space that is populated by instances as we have already described.
</prevsent>
<prevsent>a cluster could be assigned the sense of the gloss whose vector it was most closely located to.
</prevsent>
</prevsection>
<citsent citstr=" C94-1049 ">
this idea is based loosely on work by (niwa and nitta, 1994), <papid> C94-1049 </papid>who compare word cooccurrence vectors derived from large corpora of text with cooccurrence vectors based on the definitions or glosses of words in machine readable dictionary.</citsent>
<aftsection>
<nextsent>a cooccurrence vector indicates how often words are used with each other in large corpora or in dictionary definitions.
</nextsent>
<nextsent>these vectors can be projected into high dimensional space and used to measure the distance between concepts or words.
</nextsent>
<nextsent>niwa andnitta show that while the cooccurrence data from dictionary has different characteristics that cooccurrence vector derived from corpus, both provide useful information about how to categorize word based on its meaning.
</nextsent>
<nextsent>our future work will mostly attempt to merge clusters found from corpora with meanings in dictionaries where presentation techniques like cooccurrence vectors could be useful.there are number of smaller issues that we are investigating.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3028">
<title id=" N06-1044.xml">estimation of consistent probabilistic context free grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it has been conjectured in (wetherell, 1980) that these methods always provide probabilistic context-freegrammars with the consistency property.
</prevsent>
<prevsent>a first result in this direction was presented in (chaudhuri etal., 1983), by showing that probabilistic context free grammar estimated by maximizing the likelihood of sample of parse trees is always consistent.
</prevsent>
</prevsection>
<citsent citstr=" J98-2005 ">
in later work by (sanchez and bened??, 1997)and (chi and geman, 1998), <papid> J98-2005 </papid>the result was independently extended to expectation maximization,which is an unsupervised method exploited to estimate probabilistic context-free grammars by finding local maxima of the likelihood of sample of unannotated sentences.</citsent>
<aftsection>
<nextsent>the proof in (sanchez andbened??, 1997) makes use of spectral analysis of expectation matrices, while the proof in (chi and ge man, 1998) <papid> J98-2005 </papid>is based on simpler counting argument.both these proofs assume restrictions on theun derlying context-free grammars.</nextsent>
<nextsent>more specifically, in (chi and geman, 1998) <papid> J98-2005 </papid>empty rules and unaryrules are not allowed, thus excluding infinite ambiguity, that is, the possibility that some string in the input sample has an infinite number of derivations inthe grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3035">
<title id=" N06-1044.xml">estimation of consistent probabilistic context free grammars </title>
<section> estimation of pcfgs.  </section>
<citcontext>
<prevsection>
<prevsent>thus, by ite rating the growth transformation above, we are guaranteed to reach local maximum for (8), or possibly saddle point.
</prevsent>
<prevsent>we refer to this as the unsupervised mle method.
</prevsent>
</prevsection>
<citsent citstr=" N06-1043 ">
we now discuss third estimation method for pcfgs, which was proposed in (corazza and satta,2006).<papid> N06-1043 </papid></citsent>
<aftsection>
<nextsent>this method can be viewed as generalization of the supervised mle method to probability distributions defined over infinite sets of complete derivations.
</nextsent>
<nextsent>let be an infinite set of complete derivations using nonterminal symbols in , start symbol ? and terminal symbols in ?.
</nextsent>
<nextsent>we assume that the set of rules that are observed in is drawn from some finite set r. let pd be probability distribution defined over d, that is, function from set to interval [0, 1] such that ? dd pd(d) = 1.
</nextsent>
<nextsent>consider the cfg = (n,?,r, s).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3037">
<title id=" N06-1044.xml">estimation of consistent probabilistic context free grammars </title>
<section> re normalization.  </section>
<citcontext>
<prevsection>
<prevsent>(14)this is the supervised mle estimator in (7).
</prevsent>
<prevsent>this reminds us of the well-known fact that maximizing the likelihood of (finite) sample through pcfg distribution amounts to minimizing the cross-entropy between the empirical distribution of the sample and the pcfg distribution itself.
</prevsent>
</prevsection>
<citsent citstr=" P99-1070 ">
in this section we recall re normalization technique for pcfgs that was used before in (abney et al , 1999), (<papid> P99-1070 </papid>chi, 1999) <papid> J99-1004 </papid>and (nederhof and satta, 2003) for different purposes, and is exploited in the next section to prove our main results.</citsent>
<aftsection>
<nextsent>in the remainder of this section, we assume fixed, not necessarily proper pcfg = (g, pg), with = (n,?, s,r).
</nextsent>
<nextsent>we define the re normalization of as the pcfg r(g) = (g, pr) with pr specified by pr(a ? ?)
</nextsent>
<nextsent>= pg(a ? ?)
</nextsent>
<nextsent>d,w pg(?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3038">
<title id=" N06-1044.xml">estimation of consistent probabilistic context free grammars </title>
<section> re normalization.  </section>
<citcontext>
<prevsection>
<prevsent>(14)this is the supervised mle estimator in (7).
</prevsent>
<prevsent>this reminds us of the well-known fact that maximizing the likelihood of (finite) sample through pcfg distribution amounts to minimizing the cross-entropy between the empirical distribution of the sample and the pcfg distribution itself.
</prevsent>
</prevsection>
<citsent citstr=" J99-1004 ">
in this section we recall re normalization technique for pcfgs that was used before in (abney et al , 1999), (<papid> P99-1070 </papid>chi, 1999) <papid> J99-1004 </papid>and (nederhof and satta, 2003) for different purposes, and is exploited in the next section to prove our main results.</citsent>
<aftsection>
<nextsent>in the remainder of this section, we assume fixed, not necessarily proper pcfg = (g, pg), with = (n,?, s,r).
</nextsent>
<nextsent>we define the re normalization of as the pcfg r(g) = (g, pr) with pr specified by pr(a ? ?)
</nextsent>
<nextsent>= pg(a ? ?)
</nextsent>
<nextsent>d,w pg(?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3040">
<title id=" N06-1044.xml">estimation of consistent probabilistic context free grammars </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>our proof technique seems more intuitive than arguments previously used in the literature to prove the consistency property, based on counting arguments or on spectral analysis.
</prevsent>
<prevsent>it is not difficult to see that our proof technique can also be used with probabilistic rewriting formalisms whose underlying derivations can be characterized by means of context-free rewriting.
</prevsent>
</prevsection>
<citsent citstr=" C92-2066 ">
this is for instance the case with probabilistic tree-adjoining grammars (schabes, 1992; <papid> C92-2066 </papid>sarkar, 1998), <papid> P98-2190 </papid>for which consistency results have not yet been shown in the literature.</citsent>
<aftsection>
<nextsent>a cross-entropy minimization in order to make this paper self-contained, we sketch proof of the claim in section 3 that the estimator in (12) minimizes the cross entropy in (11).
</nextsent>
<nextsent>a full proof appears in (corazza and satta, 2006).<papid> N06-1043 </papid></nextsent>
<nextsent>let d, pd and = (n,?,r, s) be defined as in section 3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3041">
<title id=" N06-1044.xml">estimation of consistent probabilistic context free grammars </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>our proof technique seems more intuitive than arguments previously used in the literature to prove the consistency property, based on counting arguments or on spectral analysis.
</prevsent>
<prevsent>it is not difficult to see that our proof technique can also be used with probabilistic rewriting formalisms whose underlying derivations can be characterized by means of context-free rewriting.
</prevsent>
</prevsection>
<citsent citstr=" P98-2190 ">
this is for instance the case with probabilistic tree-adjoining grammars (schabes, 1992; <papid> C92-2066 </papid>sarkar, 1998), <papid> P98-2190 </papid>for which consistency results have not yet been shown in the literature.</citsent>
<aftsection>
<nextsent>a cross-entropy minimization in order to make this paper self-contained, we sketch proof of the claim in section 3 that the estimator in (12) minimizes the cross entropy in (11).
</nextsent>
<nextsent>a full proof appears in (corazza and satta, 2006).<papid> N06-1043 </papid></nextsent>
<nextsent>let d, pd and = (n,?,r, s) be defined as in section 3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3043">
<title id=" N03-3010.xml">cooperative model based language understanding </title>
<section> cooperative model.  </section>
<citcontext>
<prevsection>
<prevsent>we discuss learning models in section 3.2.
</prevsent>
<prevsent>3.2 statistical learning model.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
3.2.1 nave bayes learning nave bayes learning has been widely used in natural language processing with good results such as statistical syntactic parsing (collins, 1997; <papid> P97-1003 </papid>charniak, 1997), hidden language understanding (miller et al, 1994).<papid> P94-1004 </papid></citsent>
<aftsection>
<nextsent>we represent the mappings between words and their potential associated meanings (meaning items including level information and slot-value pairs) with p(m|w).
</nextsent>
<nextsent>w refers to words and refers to meaning items.
</nextsent>
<nextsent>with bayes?
</nextsent>
<nextsent>theorem, we have the formula 3.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3044">
<title id=" N03-3010.xml">cooperative model based language understanding </title>
<section> cooperative model.  </section>
<citcontext>
<prevsection>
<prevsent>we discuss learning models in section 3.2.
</prevsent>
<prevsent>3.2 statistical learning model.
</prevsent>
</prevsection>
<citsent citstr=" P94-1004 ">
3.2.1 nave bayes learning nave bayes learning has been widely used in natural language processing with good results such as statistical syntactic parsing (collins, 1997; <papid> P97-1003 </papid>charniak, 1997), hidden language understanding (miller et al, 1994).<papid> P94-1004 </papid></citsent>
<aftsection>
<nextsent>we represent the mappings between words and their potential associated meanings (meaning items including level information and slot-value pairs) with p(m|w).
</nextsent>
<nextsent>w refers to words and refers to meaning items.
</nextsent>
<nextsent>with bayes?
</nextsent>
<nextsent>theorem, we have the formula 3.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3045">
<title id=" N01-1028.xml">learning optimal dialogue management rules by using reinforcement learning and inductive logic programming </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many of these take user centric approach based on wizard of oz studies and iterative design (bernsen et al, 1998).
</prevsent>
<prevsent>however there are still no precise guidelines about when to use specific techniques such as mixed-initiative.
</prevsent>
</prevsection>
<citsent citstr=" C00-1073 ">
reinforcement learning has been used in several recent approaches to search for the optimal dialogue management strategy for specific dialogue situations (levin and pieraccini, 1997; litman et al, 2000; <papid> C00-1073 </papid>singh et al,2000; walker, 2000).</citsent>
<aftsection>
<nextsent>in these approaches, dialogue is seen as walk through series of states, from an initial state when the dialogue begins until terminal state when the dialogue ends.
</nextsent>
<nextsent>the actions of the dialogue manager as well asthose of the user influence the transitions between states.
</nextsent>
<nextsent>each transition is associated with reward, which expresses how good or bad itwas to make that transition.
</nextsent>
<nextsent>a dialogue strategy is then seen as markov decision process (levin et al, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3048">
<title id=" N01-1028.xml">learning optimal dialogue management rules by using reinforcement learning and inductive logic programming </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>states can usually be collapsed to make this problem less acute.
</prevsent>
<prevsent>the main idea here is to express the state of the dialogue by limited number of features while keeping enough and the right kind of information to be able to learn useful strategies (walker et al, 1998).
</prevsent>
</prevsection>
<citsent citstr=" P00-1013 ">
there has also been new research on how to model the dialogue with partially observable markov models (roy et al, 2000).<papid> P00-1013 </papid></citsent>
<aftsection>
<nextsent>some work has also been done on finding out rules to select dialogue management strategies.for example, litman and pan (2000) use machine learning to learn rules detecting when dialogues go badly.
</nextsent>
<nextsent>the dialogue manager uses strategy predefined by dialogue designer.
</nextsent>
<nextsent>if rule detects bad dialogue, the dialogue strategy is changed to more restrictive, more system guided strategy.
</nextsent>
<nextsent>our approach is different from that work since the strategy is not predefined but based on the optimal strategy found by reinforcement learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3049">
<title id=" N03-2032.xml">latent semantic analysis for dialogue act classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our work has the theoretical goal of assessing whether lsa, an approach based onlyon raw text, can be improved by using additional features of the text.
</prevsent>
<prevsent>dialogue systems need to perform dialog act classification, in order to understand the role the users utterance plays in the dialog (e.g., question for information or are quest to perform an action), and to generate an appropriate next turn.
</prevsent>
</prevsection>
<citsent citstr=" P95-1016 ">
in recent years, variety of empirical techniques have been used to train the dialogue act classifier (reithinger and maier, 1995; <papid> P95-1016 </papid>stolcke et al, 2000; <papid> J00-3003 </papid>walker et al, 2001).<papid> P01-1066 </papid></citsent>
<aftsection>
<nextsent>in this paper, we propose latent semantic analysis (lsa) as method to train the dialogue act classifier.
</nextsent>
<nextsent>lsa can be thought as representing the meaning of aword as kind of average of the meanings of all the passages in which it appears, and the meaning of passage as kind of average of the meaning of all the words it contains (landauer et al, 1998).
</nextsent>
<nextsent>lsa learns from cooccurrence of words in collections of texts.
</nextsent>
<nextsent>it builds semantic space where words and passages are represented as vectors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3050">
<title id=" N03-2032.xml">latent semantic analysis for dialogue act classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our work has the theoretical goal of assessing whether lsa, an approach based onlyon raw text, can be improved by using additional features of the text.
</prevsent>
<prevsent>dialogue systems need to perform dialog act classification, in order to understand the role the users utterance plays in the dialog (e.g., question for information or are quest to perform an action), and to generate an appropriate next turn.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
in recent years, variety of empirical techniques have been used to train the dialogue act classifier (reithinger and maier, 1995; <papid> P95-1016 </papid>stolcke et al, 2000; <papid> J00-3003 </papid>walker et al, 2001).<papid> P01-1066 </papid></citsent>
<aftsection>
<nextsent>in this paper, we propose latent semantic analysis (lsa) as method to train the dialogue act classifier.
</nextsent>
<nextsent>lsa can be thought as representing the meaning of aword as kind of average of the meanings of all the passages in which it appears, and the meaning of passage as kind of average of the meaning of all the words it contains (landauer et al, 1998).
</nextsent>
<nextsent>lsa learns from cooccurrence of words in collections of texts.
</nextsent>
<nextsent>it builds semantic space where words and passages are represented as vectors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3051">
<title id=" N03-2032.xml">latent semantic analysis for dialogue act classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our work has the theoretical goal of assessing whether lsa, an approach based onlyon raw text, can be improved by using additional features of the text.
</prevsent>
<prevsent>dialogue systems need to perform dialog act classification, in order to understand the role the users utterance plays in the dialog (e.g., question for information or are quest to perform an action), and to generate an appropriate next turn.
</prevsent>
</prevsection>
<citsent citstr=" P01-1066 ">
in recent years, variety of empirical techniques have been used to train the dialogue act classifier (reithinger and maier, 1995; <papid> P95-1016 </papid>stolcke et al, 2000; <papid> J00-3003 </papid>walker et al, 2001).<papid> P01-1066 </papid></citsent>
<aftsection>
<nextsent>in this paper, we propose latent semantic analysis (lsa) as method to train the dialogue act classifier.
</nextsent>
<nextsent>lsa can be thought as representing the meaning of aword as kind of average of the meanings of all the passages in which it appears, and the meaning of passage as kind of average of the meaning of all the words it contains (landauer et al, 1998).
</nextsent>
<nextsent>lsa learns from cooccurrence of words in collections of texts.
</nextsent>
<nextsent>it builds semantic space where words and passages are represented as vectors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3053">
<title id=" N03-2032.xml">latent semantic analysis for dialogue act classification </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>1) further investigate the correlation of the performance of (semi)clustered lsa with the size of the corpus and / or of the target classification.
</prevsent>
<prevsent>2) include other features in flsa, e.g. syntactic roles.
</prevsent>
</prevsection>
<citsent citstr=" J97-1002 ">
3) redo our experiments on other corpora, such as map task (carletta et al, 1997).<papid> J97-1002 </papid></citsent>
<aftsection>
<nextsent>map task is appropriate because besides dialogue acts it is annotated for syntactic information, while call home is not.
</nextsent>
<nextsent>4) experiment with flsa on other tasks, such as assessing text coherence.
</nextsent>
<nextsent>acknowledgements this work is supported by grant n00014-00-1-0640 from the office of naval research.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3054">
<title id=" N07-1023.xml">lexicalized markov grammars for sentence compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we evaluate different markov ized models,and find that our selected best model is one that exploits head-modifier bilexicalization to accurately distinguish adjuncts from complements, and that produces sentences that were judged more grammatical than those generated by previous work.
</prevsent>
<prevsent>sentence compression addresses the problem of removing words or phrases that are not necessary in the generated output of, for instance, summarization and question answering systems.
</prevsent>
</prevsection>
<citsent citstr=" A00-1043 ">
given the need to ensure grammatical sentences, number of researchers have used syntax-directed approaches that perform transformations on the out put of syntactic parsers (jing, 2000; <papid> A00-1043 </papid>dorr et al, 2003).<papid> W03-0501 </papid></citsent>
<aftsection>
<nextsent>some of them (knight and marcu, 2000;turner and charniak, 2005) <papid> P05-1036 </papid>take an empirical approach, relying on formalisms equivalent to probabilistic synchronous context-free grammars (scfg) this material is based on research supported in part by the u.s. national science foundation (nsf) under grant no.</nextsent>
<nextsent>iis-05-34871 and the defense advanced research projects agency (darpa) under contract no.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3055">
<title id=" N07-1023.xml">lexicalized markov grammars for sentence compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we evaluate different markov ized models,and find that our selected best model is one that exploits head-modifier bilexicalization to accurately distinguish adjuncts from complements, and that produces sentences that were judged more grammatical than those generated by previous work.
</prevsent>
<prevsent>sentence compression addresses the problem of removing words or phrases that are not necessary in the generated output of, for instance, summarization and question answering systems.
</prevsent>
</prevsection>
<citsent citstr=" W03-0501 ">
given the need to ensure grammatical sentences, number of researchers have used syntax-directed approaches that perform transformations on the out put of syntactic parsers (jing, 2000; <papid> A00-1043 </papid>dorr et al, 2003).<papid> W03-0501 </papid></citsent>
<aftsection>
<nextsent>some of them (knight and marcu, 2000;turner and charniak, 2005) <papid> P05-1036 </papid>take an empirical approach, relying on formalisms equivalent to probabilistic synchronous context-free grammars (scfg) this material is based on research supported in part by the u.s. national science foundation (nsf) under grant no.</nextsent>
<nextsent>iis-05-34871 and the defense advanced research projects agency (darpa) under contract no.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3056">
<title id=" N07-1023.xml">lexicalized markov grammars for sentence compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentence compression addresses the problem of removing words or phrases that are not necessary in the generated output of, for instance, summarization and question answering systems.
</prevsent>
<prevsent>given the need to ensure grammatical sentences, number of researchers have used syntax-directed approaches that perform transformations on the out put of syntactic parsers (jing, 2000; <papid> A00-1043 </papid>dorr et al, 2003).<papid> W03-0501 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1036 ">
some of them (knight and marcu, 2000;turner and charniak, 2005) <papid> P05-1036 </papid>take an empirical approach, relying on formalisms equivalent to probabilistic synchronous context-free grammars (scfg) this material is based on research supported in part by the u.s. national science foundation (nsf) under grant no.</citsent>
<aftsection>
<nextsent>iis-05-34871 and the defense advanced research projects agency (darpa) under contract no.
</nextsent>
<nextsent>hr0011-06-c-0023.
</nextsent>
<nextsent>any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the nsf or darpa.
</nextsent>
<nextsent>(lewis and stearns, 1968; aho and ullman, 1969) to extract compression rules from aligned penn treebank (ptb) trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3057">
<title id=" N07-1023.xml">lexicalized markov grammars for sentence compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while their approach proved successful, their reliance on standard maximum likelihood estimators for scfg productions results inconsiderable sparseness issues, especially given the relative flat structure of ptb trees; in practice, many scfg productions are seen only once.
</prevsent>
<prevsent>this problem is exacerbated for the compression task, which has only scarce training material available.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
in this paper, we present head-driven markov ization of scfg compression rules, an approach that was successfully used in syntactic parsing (collins, 1999; klein and manning, 2003) <papid> P03-1054 </papid>to alleviate issues intrinsic to relative frequency estimation of treebank productions.</citsent>
<aftsection>
<nextsent>markov ization for sentence compression provides several benefits, including the ability to condition deletions on flexible amount of syntactic context, to treat head-modifier dependencies independently, and to lexicalize scfg productions.another part of our effort focuses on better alignment models for extracting scfg compression rules from parallel data, and to improve upon (knight and marcu, 2000), who could only exploit 1.75% ofthe ziff-davis corpus because of stringent assumptions about human abs tractive behavior.
</nextsent>
<nextsent>to alleviate their restrictions, we relyon robust approach for aligning trees of arbitrary document-abstract sentence pairs.
</nextsent>
<nextsent>after accounting for sentence pairs with both substitutions and deletions, we reached retention of more than 25% of the ziff-davis data, which greatly benefited the lexical probabilities incorporated into our markov ized scfgs.
</nextsent>
<nextsent>our work provides three main contributions: 180 (1) our lexicalized head-driven markov ization yields more robust probability estimates, and our compress ions outperform (knight and marcu, 2000) according to automatic and human evaluation.(2) we provide comprehensive analysis of the impact of different markov orders for sentence compression, similarly to study done for pcfgs (klein and manning, 2003).<papid> P03-1054 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3065">
<title id=" N07-1023.xml">lexicalized markov grammars for sentence compression </title>
<section> synchronous grammars for sentence.  </section>
<citcontext>
<prevsection>
<prevsent>at lower level, lexicalization is clearly desirable for pre-terminals.
</prevsent>
<prevsent>indeed, current scfg models such as k&m; have no direct way of preventing highly improbable single word removals, such as deletions of adverbs never?
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
or nowhere?, which may turn negative statement into positive one.4 second type of annotation that can be added to syntactic categories is the so-called parent annotation (johnson, 1998), <papid> J98-4004 </papid>which was effectively used in syntactic parsing to break unreasonable context-free assumptions.</citsent>
<aftsection>
<nextsent>for instance, pp with vp parent is marked as ppvp.
</nextsent>
<nextsent>it is reasonable to assume that, e.g., that constituents deep inside pp have more chances to be removed than otherwise expected, and one may seek to increase the amount of vertical context that is available for conditioning each constituent deletion.
</nextsent>
<nextsent>to achieve the above desiderata for better scfg probability estimatesi.e., reduce the amount of sister annotation within each scfg production, by conditioning deletions on context smaller than an entire right-hand side, and at the same time increase the amount of ancestor and descend ent annotation through parent (or ancestor) annotation and lexicalization we follow the approach of (collins,1999; klein and manning, 2003), <papid> P03-1054 </papid>i.e., factor ize n-ary grammar productions into products of right-hand side probabilities, technique sometimes called markovization.markovization is generally head-driven, i.e., reflects decomposition centered around the head of each cfg production: ? lm ? ?</nextsent>
<nextsent>l1hr1 ? ?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3069">
<title id=" N07-1023.xml">lexicalized markov grammars for sentence compression </title>
<section> tree alignment and synchronous gram-.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we used thesame test data as k&m; for human evaluation purposes (32 sentence pairs).
</prevsent>
<prevsent>mar inference we now describe methods to train scfg models from sentence pairs.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
given tree pair (f , c), whose respective parses (pif , pic) were generated by the parser described in (charniak and johnson, 2005), <papid> P05-1022 </papid>the goal is to transform the tree pair into scfgderivations, in order to build relative frequency estimates for our markov ized models from observed scfg productions.</citsent>
<aftsection>
<nextsent>clearly, the two trees may sometimes be structurally quite different (e.g., agiven pp may attach to an np in pif , while attaching to vp in pic), and it is not always possible to build an scfg derivation given the constraints in (pif , pic).
</nextsent>
<nextsent>the approach taken by k&m; is to analyze both trees and count an scfg rule whenever two nodes are deemed to correspond?, i.e., roots are the same, and is sub-sequence of . this leads to quite restricted number of different production son our base training set (zd-0): 823 different productions were extracted, 593 of which appear only once.
</nextsent>
<nextsent>this first approach has serious limitations;the assumption that sentence compression appropriately models human abs tractive data is particularly problematic.
</nextsent>
<nextsent>this considerably limits the amount of training data that can be exploited in ziff-davis(which contains overall more than 4,000 documents abstract pairs), and this makes it very difficult to train lexicalized models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3071">
<title id=" N07-1023.xml">lexicalized markov grammars for sentence compression </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>after inspection, we found that our parser assigned particularly error ful trees to those inputs, which may partially explain these ungrammatical outputs.
</prevsent>
<prevsent>a relatively large body of work addressed the problem of sentence compression.
</prevsent>
</prevsection>
<citsent citstr=" E06-1038 ">
one successful recent approach (mcdonald, 2006) <papid> E06-1038 </papid>combines discriminative framework with set of features that capture information similar to the k&m; model.</citsent>
<aftsection>
<nextsent>mc 186 input many debugging features, including user-defined break points and variable-watching and message-watching windows, have been added.
</nextsent>
<nextsent>noisyc many debugging features, including user-defined points and variable-watching and message-watching windows, have been added.
</nextsent>
<nextsent>markov many debugging features have been added.
</nextsent>
<nextsent>human many debugging features have been added.input the chemical etching process used for glare protection is effective and will help if your office has the fluorescent-light overkill that typical in offices.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3072">
<title id=" N04-2006.xml">automatic article restoration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we describe methods for more specific task: restoring missing articles.
</prevsent>
<prevsent>the article generation task could be viewed as classification problem, whose input is set of features drawn from the context of an np, and whose output is the most likely article for that np.
</prevsent>
</prevsection>
<citsent citstr=" P98-1085 ">
the context features are typically extracted from the syntactic parse tree of sentence.(heine, 1998) <papid> P98-1085 </papid>takes japanese np as input, and classifies it as either definite or indefinite.</citsent>
<aftsection>
<nextsent>a hierarchy of rules, ordered by their priorities, are hand-crafted.
</nextsent>
<nextsent>these rules involve the presence or absence of honorifics, demon strat ives, possess ives, counting expressions, and set of verbs and post positions that provide strong hints.
</nextsent>
<nextsent>in the appointment scheduling domain, 79.5% of the nps are classified with an accuracy of 98.9%.
</nextsent>
<nextsent>the rest are classified by searching for its referent in the discourse context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3073">
<title id=" N04-2006.xml">automatic article restoration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(knight and chander, 1994) uses decision trees to pick either a/an or the for nps extracted from the wall street journal (wsj).
</prevsent>
<prevsent>there are over 30000 features in the trees, including lexical features (e.g., the two words before and after the np) and abstract features (e.g., the word after the head noun is past tense verb).
</prevsent>
</prevsection>
<citsent citstr=" W00-0708 ">
by classifying the more frequent head nouns with the trees, and guessing the for the rest, the overall accuracy is 78%.(minnen et al, 2000) <papid> W00-0708 </papid>applies memory-based learning approach to choose between a/an, the and null.</citsent>
<aftsection>
<nextsent>their features are drawn from two sources: first, from the penn treebank, such as the np head and its part-of-speech (pos) and functional tags, the category and functional tags of the constituent embedding the np, and other determiners in the np; and second, from japanese-to-english translation system, such as the count ability preference and semantic class of the np head.
</nextsent>
<nextsent>the best result is 83.6% accuracy.
</nextsent>
<nextsent>the article generation task constitutes one component of the article correction task.
</nextsent>
<nextsent>the other component is natural language parser that maps an input sentence to aparse tree, from which context features of nps are extracted.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3094">
<title id=" N04-4026.xml">a unigram orientation model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the orientation model is shown to improve translation performance over two models: 1) no block re-ordering is used, and 2) the block swapping is controlled only by language model.
</prevsent>
<prevsent>we show experimental results on standard arabic-english translation task.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
in recent years, phrase-based systems for statistical machine translation (och et al, 1999; <papid> W99-0604 </papid>koehn et al, 2003; <papid> N03-1017 </papid>venugopal et al, 2003) <papid> P03-1041 </papid>have delivered state-of-the-artperformance on standard translation tasks.</citsent>
<aftsection>
<nextsent>in this paper, we present phrase-based unigram system similar to the one in (tillmann and xia, 2003), <papid> N03-2036 </papid>which is extended by an unigram orientation model.</nextsent>
<nextsent>the units of translation are blocks, pairs of phrases without internalstructure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3095">
<title id=" N04-4026.xml">a unigram orientation model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the orientation model is shown to improve translation performance over two models: 1) no block re-ordering is used, and 2) the block swapping is controlled only by language model.
</prevsent>
<prevsent>we show experimental results on standard arabic-english translation task.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
in recent years, phrase-based systems for statistical machine translation (och et al, 1999; <papid> W99-0604 </papid>koehn et al, 2003; <papid> N03-1017 </papid>venugopal et al, 2003) <papid> P03-1041 </papid>have delivered state-of-the-artperformance on standard translation tasks.</citsent>
<aftsection>
<nextsent>in this paper, we present phrase-based unigram system similar to the one in (tillmann and xia, 2003), <papid> N03-2036 </papid>which is extended by an unigram orientation model.</nextsent>
<nextsent>the units of translation are blocks, pairs of phrases without internalstructure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3096">
<title id=" N04-4026.xml">a unigram orientation model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the orientation model is shown to improve translation performance over two models: 1) no block re-ordering is used, and 2) the block swapping is controlled only by language model.
</prevsent>
<prevsent>we show experimental results on standard arabic-english translation task.
</prevsent>
</prevsection>
<citsent citstr=" P03-1041 ">
in recent years, phrase-based systems for statistical machine translation (och et al, 1999; <papid> W99-0604 </papid>koehn et al, 2003; <papid> N03-1017 </papid>venugopal et al, 2003) <papid> P03-1041 </papid>have delivered state-of-the-artperformance on standard translation tasks.</citsent>
<aftsection>
<nextsent>in this paper, we present phrase-based unigram system similar to the one in (tillmann and xia, 2003), <papid> N03-2036 </papid>which is extended by an unigram orientation model.</nextsent>
<nextsent>the units of translation are blocks, pairs of phrases without internalstructure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3097">
<title id=" N04-4026.xml">a unigram orientation model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show experimental results on standard arabic-english translation task.
</prevsent>
<prevsent>in recent years, phrase-based systems for statistical machine translation (och et al, 1999; <papid> W99-0604 </papid>koehn et al, 2003; <papid> N03-1017 </papid>venugopal et al, 2003) <papid> P03-1041 </papid>have delivered state-of-the-artperformance on standard translation tasks.</prevsent>
</prevsection>
<citsent citstr=" N03-2036 ">
in this paper, we present phrase-based unigram system similar to the one in (tillmann and xia, 2003), <papid> N03-2036 </papid>which is extended by an unigram orientation model.</citsent>
<aftsection>
<nextsent>the units of translation are blocks, pairs of phrases without internalstructure.
</nextsent>
<nextsent>fig.
</nextsent>
<nextsent>1 shows an example block translation using five arabic-english blocks
</nextsent>
<nextsent>  . the unigram.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3098">
<title id=" N04-4026.xml">a unigram orientation model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the arabic words are roman ized.
</prevsent>
<prevsent>section 3, block swapping where only trigram language model is used to compute probabilities between neighbor blocks fails to improve translation performance.
</prevsent>
</prevsection>
<citsent citstr=" P96-1021 ">
(wu, 1996; <papid> P96-1021 </papid>zens and ney, 2003) <papid> P03-1019 </papid>present re-ordering models that make use of straight/inverted orientation model that is related to our work.</citsent>
<aftsection>
<nextsent>here, we investigate in detail the effect of restricting the word re-ordering to neighbor block swapping only.
</nextsent>
<nextsent>in this paper, we assume block generation process that generates block sequences from bottom to top, one block at time.
</nextsent>
<nextsent>the score of successor block   depends on its predecessor block   and on its orientation relative to the block   . in fig.
</nextsent>
<nextsent>1 for example, block.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3099">
<title id=" N04-4026.xml">a unigram orientation model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the arabic words are roman ized.
</prevsent>
<prevsent>section 3, block swapping where only trigram language model is used to compute probabilities between neighbor blocks fails to improve translation performance.
</prevsent>
</prevsection>
<citsent citstr=" P03-1019 ">
(wu, 1996; <papid> P96-1021 </papid>zens and ney, 2003) <papid> P03-1019 </papid>present re-ordering models that make use of straight/inverted orientation model that is related to our work.</citsent>
<aftsection>
<nextsent>here, we investigate in detail the effect of restricting the word re-ordering to neighbor block swapping only.
</nextsent>
<nextsent>in this paper, we assume block generation process that generates block sequences from bottom to top, one block at time.
</nextsent>
<nextsent>the score of successor block   depends on its predecessor block   and on its orientation relative to the block   . in fig.
</nextsent>
<nextsent>1 for example, block.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3100">
<title id=" N04-4026.xml">a unigram orientation model for statistical machine translation </title>
<section> orientation unigram model.  </section>
<citcontext>
<prevsection>
<prevsent>  !87 with right orientation, i.e. it is always involved in swapping.
</prevsent>
<prevsent>this intuition is formalized using unigram counts with orientation.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the orientation model is related to the distortion model in (brown et al, 1993), <papid> J93-2003 </papid>but we do not compute block alignment during training.</citsent>
<aftsection>
<nextsent>we rather enumerate all relevant blocks in some order.
</nextsent>
<nextsent>enumeration does not allow us to capture position dependent distortion probabilities,but we can compute statistics about adjacent block prede cessors.our baseline model is the unigram monotone model described in (tillmann and xia, 2003).<papid> N03-2036 </papid></nextsent>
<nextsent>here, we select blocks   from word-aligned training data and unigram block occurrence counts ffi</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3110">
<title id=" N06-2014.xml">agreement disagreement classification exploiting unlabeled data using contrast classifiers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also obtain performance comparable to the best results reported so far on this task and outperform systems with equivalent feature sets.
</prevsent>
<prevsent>in natural language understanding research with data-driven techniques, data labeling is an essential but time-consuming and costly process.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
to alleviate this effort, various semi-supervised learning algorithms such as self-training (yarowsky, 1995), <papid> P95-1026 </papid>co training (blum and mitchell, 1998; goldman and zhou, 2000), transductive svm (joachims, 1999)and many others have been proposed and successfully applied under different assumptions and settings.</citsent>
<aftsection>
<nextsent>they all aim to improve classification accuracy by exploiting more readily available unlabeled data as well as labeled examples.
</nextsent>
<nextsent>however, these iterative training methods have shortcomings when trained on data with imbalanced class distributions.
</nextsent>
<nextsent>one reason is that most classifiers underlying these methods assume balanced training set, and thus when one of the classes has much larger number of examples than the other classes, the trained classifier will be biased toward the majority class.
</nextsent>
<nextsent>the imbalance will propagate through subsequent iterations, resulting in more skewed dataset upon which further biased classifier will be trained.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3111">
<title id=" N06-2014.xml">agreement disagreement classification exploiting unlabeled data using contrast classifiers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it approximates the posterior class probability given an observation using class-specific contrast classifiers that implicitly model the difference between the distribution of labeled data for that class and the unlabeled data.in this paper, we will explore the applicability of contrast classifiers to the problem of semi supervised learning for identifying agreements and disagreements in multi-party conversational speech.
</prevsent>
<prevsent>these labels represent simple type of speech actthat can be important for understanding the interaction between speakers, or for automatically summarizing or browsing the contents of meeting.
</prevsent>
</prevsection>
<citsent citstr=" N03-2012 ">
this problem was previously studied (hillard et al , 2003;<papid> N03-2012 </papid>galley et al , 2004), <papid> P04-1085 </papid>using subset of icsi meeting recording corpus (janin et al , 2003).</citsent>
<aftsection>
<nextsent>in semi supervised learning, there is challenge due to an imbalanced class distribution: over 60% of the data are associated with the default class and only 5% are with disagreements.
</nextsent>
<nextsent>53
</nextsent>
<nextsent>the contrast classifier approach was developed by peng et aland successfully applied to the problem of identifying protein disorder in protein structure database (outlier detection) and to finding articles about them (single-class detection) (peng et al , 2003).
</nextsent>
<nextsent>a contrast classifier discriminates between the labeled and unlabeled data, and can be used to approximate the posterior class probability of given data instance as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3112">
<title id=" N06-2014.xml">agreement disagreement classification exploiting unlabeled data using contrast classifiers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it approximates the posterior class probability given an observation using class-specific contrast classifiers that implicitly model the difference between the distribution of labeled data for that class and the unlabeled data.in this paper, we will explore the applicability of contrast classifiers to the problem of semi supervised learning for identifying agreements and disagreements in multi-party conversational speech.
</prevsent>
<prevsent>these labels represent simple type of speech actthat can be important for understanding the interaction between speakers, or for automatically summarizing or browsing the contents of meeting.
</prevsent>
</prevsection>
<citsent citstr=" P04-1085 ">
this problem was previously studied (hillard et al , 2003;<papid> N03-2012 </papid>galley et al , 2004), <papid> P04-1085 </papid>using subset of icsi meeting recording corpus (janin et al , 2003).</citsent>
<aftsection>
<nextsent>in semi supervised learning, there is challenge due to an imbalanced class distribution: over 60% of the data are associated with the default class and only 5% are with disagreements.
</nextsent>
<nextsent>53
</nextsent>
<nextsent>the contrast classifier approach was developed by peng et aland successfully applied to the problem of identifying protein disorder in protein structure database (outlier detection) and to finding articles about them (single-class detection) (peng et al , 2003).
</nextsent>
<nextsent>a contrast classifier discriminates between the labeled and unlabeled data, and can be used to approximate the posterior class probability of given data instance as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3124">
<title id=" N06-2014.xml">agreement disagreement classification exploiting unlabeled data using contrast classifiers </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we used two different classifiers, instead of two independent view of the input features as in (goldman and zhou, 2000).table 3 shows that the svm obtained high accuracy, but the measure and the recall of the smallest class, negative, is quite low.
</prevsent>
<prevsent>the bias toward the majority class propagates through each iteration in self training, so that only 5% of the negative tokens were detected after 30 iterations.
</prevsent>
</prevsection>
<citsent citstr=" W01-0501 ">
we observed the same pattern in co-training; its accuracy peaked after two iterations (85.1%) and then performance degraded drastically (68% after five iterations) due in part to an increase in mislabeled data in the training set (as previously observed in (pierce and cardie, 2001)) <papid> W01-0501 </papid>and in part because the data skew is not controlled for.</citsent>
<aftsection>
<nextsent>the contrast classifier performs better than the others in both measure and negative class recall, retaining reasonably good accuracy.
</nextsent>
<nextsent>in summary, our experiments on agreement/disagreement detection show that semi supervised learning using contrast classifiers is an effective method for taking advantage of large unlabeled dataset for problem with imbalancedclasses.
</nextsent>
<nextsent>the contrast classifier approach outperforms co-training and self-training in detecting the infrequent classes.
</nextsent>
<nextsent>we also obtain good performance relative to other methods using simple lexical features and performance comparable to the best result reported.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3127">
<title id=" N07-1056.xml">randomized decoding for selectionandordering problems </title>
<section> problem formulation.  </section>
<citcontext>
<prevsection>
<prevsent>how ever, the requirement that the path be long makes it more similar to the the traveling salesman problem (tsp).
</prevsent>
<prevsent>more precisely, our problem is an instance of the prize collecting traveling salesman problem, in which the salesman is required to visit vertices at best cost (balas, 1989; awerbuch et al, 1995).since our problem is np-hard, we might be pessimistic about finding an exact solution.
</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
but our problem has an important feature: the length ofthe path we want to find is small relative to the number of vertices n. this feature distinguishes our task from other decoding problems, such as decoding in machine translation (germann et al, 2001), <papid> P01-1030 </papid>that are modeled using standard tsp formulation.</citsent>
<aftsection>
<nextsent>in general, the connection between and opens up new range of solutions.
</nextsent>
<nextsent>for example, if we wanted to find the best length-2 path, we could simply try all subsets of 2 vertices in the graph, in all 2 possible orders.
</nextsent>
<nextsent>this is set of only o(n2) possibilities, so we can check all to identify the best in polynomial time.this approach is very limited, however: in general, its runtime of o(nk) for paths of length makes it prohibitive for all but the smallest values of k. we cannot really hope to avoid the exponential dependence on k, because doing so would give us fast solution to an np-hard problem, but there is hope of making the dependence less exponential.?
</nextsent>
<nextsent>this is captured by the definition of xed parametertractability (downey and fellows, 1995).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3128">
<title id=" N07-1056.xml">randomized decoding for selectionandordering problems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a problem is fixed parameter tractable if we can make the exponential dependence on the parameter independent of the polynomial dependence on the problem size n. this is the case for our problem: as we will describe below, an algorithm of alon et alcan be used to achieve running time of roughly o(2kn2).
</prevsent>
<prevsent>in other words, the path length only exponentiates small constant, instead of the problem size n, while the dependence on is in fact quadratic.
</prevsent>
</prevsection>
<citsent citstr=" P00-1041 ">
decoding for selection-and-ordering problems is commonly implemented using beam search (banko et al, 2000; <papid> P00-1041 </papid>corston-oliver et al, 2002; jin and hauptmann, 2001).<papid> H01-1011 </papid></citsent>
<aftsection>
<nextsent>being heuristic in nature, this algorithm is not guaranteed to find an optimal solution.
</nextsent>
<nextsent>however, its simplicity and time efficiency make it decoding algorithm of choice for wide range of nlp applications.
</nextsent>
<nextsent>in applications where beam decoding does not yield sufficient accuracy, researchers employ an alternative heuristic search, a* (jelinek, 1969; germann et al, 2001).<papid> P01-1030 </papid></nextsent>
<nextsent>while in some cases a* is quite effective, in other cases its running time and memory requirements may equal that of an exhaustive search.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3130">
<title id=" N07-1056.xml">randomized decoding for selectionandordering problems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a problem is fixed parameter tractable if we can make the exponential dependence on the parameter independent of the polynomial dependence on the problem size n. this is the case for our problem: as we will describe below, an algorithm of alon et alcan be used to achieve running time of roughly o(2kn2).
</prevsent>
<prevsent>in other words, the path length only exponentiates small constant, instead of the problem size n, while the dependence on is in fact quadratic.
</prevsent>
</prevsection>
<citsent citstr=" H01-1011 ">
decoding for selection-and-ordering problems is commonly implemented using beam search (banko et al, 2000; <papid> P00-1041 </papid>corston-oliver et al, 2002; jin and hauptmann, 2001).<papid> H01-1011 </papid></citsent>
<aftsection>
<nextsent>being heuristic in nature, this algorithm is not guaranteed to find an optimal solution.
</nextsent>
<nextsent>however, its simplicity and time efficiency make it decoding algorithm of choice for wide range of nlp applications.
</nextsent>
<nextsent>in applications where beam decoding does not yield sufficient accuracy, researchers employ an alternative heuristic search, a* (jelinek, 1969; germann et al, 2001).<papid> P01-1030 </papid></nextsent>
<nextsent>while in some cases a* is quite effective, in other cases its running time and memory requirements may equal that of an exhaustive search.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3134">
<title id=" N07-1056.xml">randomized decoding for selectionandordering problems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>nor do they provide bounds on the likelihood of finding the exactsolution.
</prevsent>
<prevsent>newly introduced methods based on local search can effectively examine large areas of search space (eisner and tromble, 2006), but they still suffer from the same limitations.
</prevsent>
</prevsection>
<citsent citstr=" W04-2401 ">
as an alternative to heuristic search algorithms,researchers also employ exact methods from combinatorial optimization, in particular integer linear programming (germann et al, 2001; <papid> P01-1030 </papid>roth and yih,2004).<papid> W04-2401 </papid></citsent>
<aftsection>
<nextsent>while existing ilp solvers find the exact solution eventually, the running time may be too slow for practical applications.our randomized decoder represents an important departure from previous approaches to decoding selection-and-ordering problems.
</nextsent>
<nextsent>the theoretically established bounds on the performance of this algorithm enable us to explicitly control the tradeoff between the quality and the efficiency of the decoding process.
</nextsent>
<nextsent>this property of our decoder sets it apart from existing heuristic algorithms that cannot guarantee an arbitrarily high probability of success.
</nextsent>
<nextsent>color-coding one might hope to solve decoding with dynamic program (like that for shortest paths) that grows an optimal path one vertex at time.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3141">
<title id=" N04-4014.xml">hitiqa a data driven approach to interactive analytical question answering </title>
<section> text framing.  </section>
<citcontext>
<prevsection>
<prevsent>we used both setups under different conditions: the generic frames were used with trec document collection to measure impact of ir precision on qa accuracy (small et al, 2004).
</prevsent>
<prevsent>the domain-adapted frames were used for sessions with intelligence analysts working with the wmd domain (see below).
</prevsent>
</prevsection>
<citsent citstr=" C96-2157 ">
currently, the adaptation process includes manual tuning followed by corpus bootstrapping using an unsupervised learning method (strzalkowski &amp; wang, 1996).<papid> C96-2157 </papid></citsent>
<aftsection>
<nextsent>we generally relyon bbns identifinder for extraction of basic entities, and use bootstrapping to define additional entity types as well as to assign roles to attributes.
</nextsent>
<nextsent>the version of hitiqa reported here and used by analysts during the evaluation has been adapted to the 2 scala bility is certainly an outstanding issue here, and we are work-.
</nextsent>
<nextsent>ing on effective frame acquisition methods, which is outside of the scope of this paper.
</nextsent>
<nextsent>weapons of mass destruction non-proliferation do main (wmd domain, henceforth).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3142">
<title id=" N04-4014.xml">hitiqa a data driven approach to interactive analytical question answering </title>
<section> text framing.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1b contains an example passage from this dataset.
</prevsent>
<prevsent>in the wmd domain, the typed frames were mapped onto wmdtransfer 3-role frame, and two 2-role frames wmdtreaty and wmddevelop.
</prevsent>
</prevsection>
<citsent citstr=" M98-1007 ">
adapting the frames to wmd domain required only minimal modification, such as adding weapon entity to augment identifinder entity set, specializing object attribute in wmdtrans fer to weapon, generating list of international weapon control treaties, etc. hitiqa frames define top-down constraints on how to interpret given text passage, which is quite different from muc3 template filling task (humphreys et al, 1998).<papid> M98-1007 </papid></citsent>
<aftsection>
<nextsent>what were trying to do here is to fit?
</nextsent>
<nextsent>a frame over text passage.
</nextsent>
<nextsent>this means also that multiple frames can be associated with text passage, or to be exact, with cluster of passages.
</nextsent>
<nextsent>since most of the passages that undergo the framing process are part of some cluster of very similar passages, the added redundancy helps to reinforce the most salient features for extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3143">
<title id=" N03-1015.xml">word sense acquisition from bilingual comparable corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the effectiveness of the method has been demonstrated through an experiment using comparable corpus consisting of wall street journal and nihon keizai shimbun corpora together with the edr bilingual dictionary.
</prevsent>
<prevsent>word sense disambiguation (wsd) is an important subtask that is necessary for accomplishing most natural language processing tasks including machine translation and information retrieval.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
a great deal of research on wsd has been done over the past decade (ide and veronis, 1998).<papid> J98-1001 </papid></citsent>
<aftsection>
<nextsent>in contrast, word sense acquisition has been human activity; inventories of word senses have been constructed by lexicographers based on their intuition.
</nextsent>
<nextsent>manually constructing an inventory of word senses has suffered from problems such as high cost, arbitrary division of word senses, and mismatch to application domains.
</nextsent>
<nextsent>we address the problem of word sense acquisition along the lines of the wsd where word senses are defined with sets of translation equivalents in another language.
</nextsent>
<nextsent>bilingual corpora or second-language corpora enable unsupervised wsd (brown, et al, 1991; <papid> P91-1034 </papid>dagan and itai, 1994).<papid> J94-4003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3144">
<title id=" N03-1015.xml">word sense acquisition from bilingual comparable corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>manually constructing an inventory of word senses has suffered from problems such as high cost, arbitrary division of word senses, and mismatch to application domains.
</prevsent>
<prevsent>we address the problem of word sense acquisition along the lines of the wsd where word senses are defined with sets of translation equivalents in another language.
</prevsent>
</prevsection>
<citsent citstr=" P91-1034 ">
bilingual corpora or second-language corpora enable unsupervised wsd (brown, et al, 1991; <papid> P91-1034 </papid>dagan and itai, 1994).<papid> J94-4003 </papid></citsent>
<aftsection>
<nextsent>however, the correspondence between senses of word and its translations is not one-to-one, and therefore we need to prepare an inventory of word senses, each of which is defined with set of synonymous translation equivalents.
</nextsent>
<nextsent>although conventional bilingual dictionaries usually group translations according to their senses, the grouping differs by dictionary.
</nextsent>
<nextsent>in addition, senses specific to domain are often missing while many senses irrelevant to the domain or rare senses are included.
</nextsent>
<nextsent>to overcome these problems, we propose method for producing hierarchy of clusters of translation equivalents from bilingual corpus and bilingual dictionary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3145">
<title id=" N03-1015.xml">word sense acquisition from bilingual comparable corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>manually constructing an inventory of word senses has suffered from problems such as high cost, arbitrary division of word senses, and mismatch to application domains.
</prevsent>
<prevsent>we address the problem of word sense acquisition along the lines of the wsd where word senses are defined with sets of translation equivalents in another language.
</prevsent>
</prevsection>
<citsent citstr=" J94-4003 ">
bilingual corpora or second-language corpora enable unsupervised wsd (brown, et al, 1991; <papid> P91-1034 </papid>dagan and itai, 1994).<papid> J94-4003 </papid></citsent>
<aftsection>
<nextsent>however, the correspondence between senses of word and its translations is not one-to-one, and therefore we need to prepare an inventory of word senses, each of which is defined with set of synonymous translation equivalents.
</nextsent>
<nextsent>although conventional bilingual dictionaries usually group translations according to their senses, the grouping differs by dictionary.
</nextsent>
<nextsent>in addition, senses specific to domain are often missing while many senses irrelevant to the domain or rare senses are included.
</nextsent>
<nextsent>to overcome these problems, we propose method for producing hierarchy of clusters of translation equivalents from bilingual corpus and bilingual dictionary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3146">
<title id=" N03-1015.xml">word sense acquisition from bilingual comparable corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, senses specific to domain are often missing while many senses irrelevant to the domain or rare senses are included.
</prevsent>
<prevsent>to overcome these problems, we propose method for producing hierarchy of clusters of translation equivalents from bilingual corpus and bilingual dictionary.
</prevsent>
</prevsection>
<citsent citstr=" C94-2122 ">
to the best of our knowledge, there are two preceding research papers on word sense acquisition (fu kumoto and tsujii, 1994; <papid> C94-2122 </papid>pantel and lin, 2002).</citsent>
<aftsection>
<nextsent>both proposed distributional word clustering algorithms that are characterized by their capabilities to produce overlapping clusters.
</nextsent>
<nextsent>according to their algorithms, polysemous word is assigned to multiple clusters, each of which represents one of its senses.
</nextsent>
<nextsent>these and our approach differ in how to define the word sense, i.e., set of synonyms in the same language versus set of translation equivalents in another language.
</nextsent>
<nextsent>schuetze (1998) proposed method for dividing occurrences of word into classes, each of which consists of contextually similar occurrences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3147">
<title id=" N03-1015.xml">word sense acquisition from bilingual comparable corpora </title>
<section> basic idea.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 clustering of translation equivalents.
</prevsent>
<prevsent>most work on automatic extraction of synonyms from text corpora rests on the idea that synonyms have edmonton, may-june 2003 main papers , pp.
</prevsent>
</prevsection>
<citsent citstr=" P90-1034 ">
32-39 proceedings of hlt-naacl 2003 similar distribution patterns (hindle, 1990; <papid> P90-1034 </papid>peraira, et al., 1993; grefenstette, 1994).</citsent>
<aftsection>
<nextsent>this idea is also useful for our task, i.e., extracting sets of synonymous translation equivalents, and we adopt the approach to distributional word clustering.
</nextsent>
<nextsent>we need to mention that the singularity of our task makes the problem easier.
</nextsent>
<nextsent>first, we do not have to cluster all words of language, but we only have to cluster small number of translation equivalents for each target word, whose senses are to be extracted, separately.
</nextsent>
<nextsent>as result, the problem of computational efficiency becomes less serious.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3148">
<title id=" N03-1015.xml">word sense acquisition from bilingual comparable corpora </title>
<section> basic idea.  </section>
<citcontext>
<prevsection>
<prevsent>in conventional distributional word clustering, word is characterized by vector or weighted set consisting of words in the same language as that of the word itself.
</prevsent>
<prevsent>in contrast, we propose trans lingual distributional word clustering method, whereby word is characterized by vector or weighted set consisting of words in another language.
</prevsent>
</prevsection>
<citsent citstr=" C02-1058 ">
it is based on the sense-vs.-clue correlation matrix calculation method we originally developed for unsupervised wsd (kaji and morimoto, 2002).<papid> C02-1058 </papid></citsent>
<aftsection>
<nextsent>that method presupposes that each sense of target word is defined with synonym set consisting of the target word itself and one or more translation equivalents which represent the sense.
</nextsent>
<nextsent>it calculates correlations between the senses of and the words statistically related to x, which act as clues for determining the sense of x, on the basis of trans lingual alignment of pairs of related words.
</nextsent>
<nextsent>rows of the resultant correlation matrix are regarded as trans lingual distribution patterns characterizing translation equivalents.
</nextsent>
<nextsent>sense-vs.-clue correlation matrix calculation method *) 1) alignment of pairs of related words *) description of the wild-card pair of related words, which plays an essential role in recovering alignment failure, has been omitted for simplicity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3149">
<title id=" N06-3009.xml">a hybrid approach to biomedical named entity recognition and semantic role labeling </title>
<section> biomedical named entity recognition.  </section>
<citcontext>
<prevsection>
<prevsent>our system outperforms other systems in protein names by an f-score of at least 2.6%.
</prevsent>
<prevsent>for dna names, our performance is very close to that of the best system.
</prevsent>
</prevsection>
<citsent citstr=" W03-1305 ">
bioner system protein dna our system (tsai et al, 2006a) 78.4 66.3 hmm (zhou et al, 2004) 75.8 63.3 two phase svm (lee et al, 2003) <papid> W03-1305 </papid>70.6 66.4 table 1.</citsent>
<aftsection>
<nextsent>performance of protein and dna name recognition on the genia v3.02 corpus we have made every effort to implement variety of linguistic features in our systems crf framework.
</nextsent>
<nextsent>thanks to these features and the nature of crf, our system outperforms state-of-the-art machine-learning-based systems, especially in the recognition of protein names.
</nextsent>
<nextsent>our system still has difficulty recognizing long, complicated nes and coordinated nes and distinguishing between overlapping ne classes, e.g., cell-line and cell-type.
</nextsent>
<nextsent>this is because biomedical texts have complicated sentence structures and involve more expert knowledge than texts from the general newswire domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3150">
<title id=" N06-3009.xml">a hybrid approach to biomedical named entity recognition and semantic role labeling </title>
<section> biomedical semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>our biomedical proposition bank, bioprop, is based on the genia treebank (yuka et al, 2005), which is 491-abstract corpus annotated with syntactic structures.
</prevsent>
<prevsent>the semantic annotation in bio prop is added to the proper constituents in syntactic tree.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
basically, we adopt the definitions in propbank (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>for the verbs not in propbank, such as phosphorylate?, we define their framesets.
</nextsent>
<nextsent>since the annotation is time-consuming, we adopt semi-automatic approach.
</nextsent>
<nextsent>we adapt an srl system trained on propbank (wall street journal corpus) to the biomedical domain.
</nextsent>
<nextsent>we first use this srl system to automatically annotate our corpus, and then human annotators to double check the systems results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3151">
<title id=" N06-3009.xml">a hybrid approach to biomedical named entity recognition and semantic role labeling </title>
<section> biomedical semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, human effort is greatly reduced.
</prevsent>
<prevsent>3.2 biomedical srl system -- serow.
</prevsent>
</prevsection>
<citsent citstr=" C04-1197 ">
245 following (punyakanok et al, 2004), <papid> C04-1197 </papid>we formulate srl as constituent-by-constituent (c-by-c) tagging problem.</citsent>
<aftsection>
<nextsent>we use bioprop to train our biomedical srl system, serow (tsai et al, 2006b), which uses maximum entropy (me) machine learning model.
</nextsent>
<nextsent>we use the basic features described in (xue &amp; palmer, 2004).<papid> W04-3212 </papid></nextsent>
<nextsent>in addition, we automatically generate templates which can be used to improve classification of biomedical argument types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3152">
<title id=" N06-3009.xml">a hybrid approach to biomedical named entity recognition and semantic role labeling </title>
<section> biomedical semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>245 following (punyakanok et al, 2004), <papid> C04-1197 </papid>we formulate srl as constituent-by-constituent (c-by-c) tagging problem.</prevsent>
<prevsent>we use bioprop to train our biomedical srl system, serow (tsai et al, 2006b), which uses maximum entropy (me) machine learning model.</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
we use the basic features described in (xue &amp; palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>in addition, we automatically generate templates which can be used to improve classification of biomedical argument types.
</nextsent>
<nextsent>the details of serow system are described in (tsai et al, 2005) <papid> W05-0638 </papid>and (tsai et al, 2006b).</nextsent>
<nextsent>3.3 experiment and summary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3153">
<title id=" N06-3009.xml">a hybrid approach to biomedical named entity recognition and semantic role labeling </title>
<section> biomedical semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>we use the basic features described in (xue &amp; palmer, 2004).<papid> W04-3212 </papid></prevsent>
<prevsent>in addition, we automatically generate templates which can be used to improve classification of biomedical argument types.</prevsent>
</prevsection>
<citsent citstr=" W05-0638 ">
the details of serow system are described in (tsai et al, 2005) <papid> W05-0638 </papid>and (tsai et al, 2006b).</citsent>
<aftsection>
<nextsent>3.3 experiment and summary.
</nextsent>
<nextsent>our experimental results show that newswire english srl system that achieves an f-score of 86.29% can maintain an f-score of 64.64% when ported to the biomedical domain.
</nextsent>
<nextsent>by using se row, we can increase that f-score by 22.9%.
</nextsent>
<nextsent>adding automatically generated template features further increases overall f-score by 0.47% and adjunct (am) f-score by 1.57%, respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3154">
<title id=" N06-2001.xml">factored neural language models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the resulting model significantly reduces perplexity on sparse-data tasks when compared to standard backoff models, standard neural language models, and factored language models.
</prevsent>
<prevsent>neural language models (nlms) (bengio et al, 2000) map words into continuous representation space and then predict the probability of word given the continuous representations of the preceding words in the history.
</prevsent>
</prevsection>
<citsent citstr=" W03-1021 ">
they have previously been shown to outperform standard back-off models in terms of perplexity and word error rate on medium and large speech recognition tasks (xu et al, 2003; <papid> W03-1021 </papid>emami and jelinek, 2004; schwenk and gauvain, 2004; schwenk, 2005).</citsent>
<aftsection>
<nextsent>their main drawbacks are computational complexity and the fact that only distributional information (word context) is used to generalize over words, whereas other word properties (e.g. spelling, morphology etc.) are ignored for this purpose.
</nextsent>
<nextsent>thus, there is also no principled way of handling out-of-vocabulary (oov) words.
</nextsent>
<nextsent>though this may be sufficient for applications that use closed vocabulary, the current trend of porting systems to wider range of languages (esp. highly inflected languages such as arabic) calls for dynamic dictionary expansion and the capability of assigning probabilities to newly added words without having seen them in the training data.
</nextsent>
<nextsent>here, we introduce novel type of nlm that improves generalization by using vectors of word features (stems, affixes, etc.) as input, and we investigate deriving continuous representations for unknown words from those of known words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3155">
<title id=" N06-2001.xml">factored neural language models </title>
<section> generalization in language models.  </section>
<citcontext>
<prevsection>
<prevsent>however, nlms only have simplistic mechanism for dealing with words that were not observed at all: oovs in the test data are mapped to dedicated class and are assigned the singleton probability when predicted (i.e. at the output layer) and the features of randomly selected singleton word when occurring in the input.
</prevsent>
<prevsent>in standard backoff n-gram models, oovs are handled by reserving small fixed amount of the discount probability mass for the generic oov word and treating it as standard vocabulary item.
</prevsent>
</prevsection>
<citsent citstr=" N03-2002 ">
a more powerful backoff strategy is used in factored language models (flms) (bilmes and kirchhoff, 2003), <papid> N03-2002 </papid>which view word as vector of word features or factors?: = f1, f2, . . .</citsent>
<aftsection>
<nextsent>, fk?
</nextsent>
<nextsent>and predict word jointly from previous words and their factors: generalized backoff procedure uses the factors to provide probability estimates for unseen n-grams, combining estimates derived from different backoff paths.
</nextsent>
<nextsent>this can also be interpreted as generalization of standard class-based models (brown et al, 1992).<papid> J92-4003 </papid></nextsent>
<nextsent>flms have been shown to yield improvements in perplexity and word error rate in speech recognition, particularly on sparse-data tasks (vergyri etal., 2004) and have also outperformed backoff models using linear decomposition of oovs into sequences of morphemes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3156">
<title id=" N06-2001.xml">factored neural language models </title>
<section> generalization in language models.  </section>
<citcontext>
<prevsection>
<prevsent>, fk?
</prevsent>
<prevsent>and predict word jointly from previous words and their factors: generalized backoff procedure uses the factors to provide probability estimates for unseen n-grams, combining estimates derived from different backoff paths.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
this can also be interpreted as generalization of standard class-based models (brown et al, 1992).<papid> J92-4003 </papid></citsent>
<aftsection>
<nextsent>flms have been shown to yield improvements in perplexity and word error rate in speech recognition, particularly on sparse-data tasks (vergyri etal., 2004) and have also outperformed backoff models using linear decomposition of oovs into sequences of morphemes.
</nextsent>
<nextsent>in this study we use factors in the input encoding for nlms.
</nextsent>
<nextsent>nlms define word similarity solely in terms of theircontext: words are assumed to be close in the continuous space if they co-occur with the same (subset of) words.
</nextsent>
<nextsent>but similarity can also be derived from word shape features (affixes, capitalization, hyphenation etc.) or other annotations (e.g. pos classes).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3157">
<title id=" N06-2001.xml">factored neural language models </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>3 1) &amp; 2) 183 169 178 167 790 540 814 555 4 word-based nlm 208 341 204 195 1510 1043 1569 1067.
</prevsent>
<prevsent>5 1) &amp; 4) 178 165 173 162 758 542 782 557 6 word-based nlm 202 194 204 192 1991 1369 2064 1386.
</prevsent>
</prevsection>
<citsent citstr=" C04-1022 ">
7 1) &amp; 6) 175 162 173 160 754 563 772 580 8 hand-optimized flm 187 171 178 166 827 595 854 614 9 1) &amp; 8) 182 167 174 163 805 563 832 581 10 genetic flm 190 188 181 188 761 1181 776 1179 11 1) &amp; 10) 183 166 175 164 706 488 720 498 12 factored nlm 189 173 190 175 1216 808 1249 832 13 1) &amp; 12) 169 155 168 155 724 487 744 500 14 1) &amp; 10) &amp; 12) 165 155 165 154 652 452 664 461 table 2: perplexities for baseline backoff lms, flms, nlms, and lm interpolation scribed in (duh and kirchhoff, 2004) (<papid> C04-1022 </papid>model 6).</citsent>
<aftsection>
<nextsent>rows 7-10 of table 2 display the results.
</nextsent>
<nextsent>finally, we trained fnlms with various combinations of factors and model orders.
</nextsent>
<nextsent>the combination was optimized by hand on the dev set and is therefore most comparable to the hand-optimized flm in row 8.
</nextsent>
<nextsent>the best factored nlm (model 7) has order 6 for both eca and turkish.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3158">
<title id=" N06-1039.xml">preemptive information extraction using unrestricted relation discovery </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>for each row of an extracted table, you can always read it as company hired (or fired) person for post.?
</prevsent>
<prevsent>the relation between these entities is retained throughout the table.
</prevsent>
</prevsection>
<citsent citstr=" A00-1039 ">
there are many existing works on obtaining extraction patterns for pre-defined relations (riloff, 1996; yangarber et al, 2000; <papid> A00-1039 </papid>agichtein and gravano, 2000; sudo et al, 2003).<papid> P03-1029 </papid></citsent>
<aftsection>
<nextsent>unrestricted relation discovery is technique to automatically discover such relations that repeatedly appear in corpus and present them as table, with absolutely no human intervention.
</nextsent>
<nextsent>unlike most existing ie research, user does not specify the type of articles or information wanted.
</nextsent>
<nextsent>instead, system tries to find all the kinds of relations that are reported multiple times and can be reported in tabular form.this technique will open up the possibility of trying new ie scenarios.
</nextsent>
<nextsent>furthermore, the system itself can be used as an ie system, since an obtained relation is already presented as table.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3159">
<title id=" N06-1039.xml">preemptive information extraction using unrestricted relation discovery </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>for each row of an extracted table, you can always read it as company hired (or fired) person for post.?
</prevsent>
<prevsent>the relation between these entities is retained throughout the table.
</prevsent>
</prevsection>
<citsent citstr=" P03-1029 ">
there are many existing works on obtaining extraction patterns for pre-defined relations (riloff, 1996; yangarber et al, 2000; <papid> A00-1039 </papid>agichtein and gravano, 2000; sudo et al, 2003).<papid> P03-1029 </papid></citsent>
<aftsection>
<nextsent>unrestricted relation discovery is technique to automatically discover such relations that repeatedly appear in corpus and present them as table, with absolutely no human intervention.
</nextsent>
<nextsent>unlike most existing ie research, user does not specify the type of articles or information wanted.
</nextsent>
<nextsent>instead, system tries to find all the kinds of relations that are reported multiple times and can be reported in tabular form.this technique will open up the possibility of trying new ie scenarios.
</nextsent>
<nextsent>furthermore, the system itself can be used as an ie system, since an obtained relation is already presented as table.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3160">
<title id=" N06-1039.xml">preemptive information extraction using unrestricted relation discovery </title>
<section> basic idea.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the governments might call for help orsome casualties might have been reported.
</prevsent>
<prevsent>to obtain such relations, we need to choose different entities from the articles.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
several existing works have tried to extract certain type of relation by manually choosing different pairs of entities (brin, 1998; ravichandran and hovy, 2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>hasegawa et al(2004) <papid> P04-1053 </papid>tried to extract multiple relations by choosing entity types.</nextsent>
<nextsent>we assume that we can find such relations by trying all possible combinations from set of entities we have chosen in advance; some combinations might represent hurricane and government relation, and others might represent place and its casualties.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3161">
<title id=" N06-1039.xml">preemptive information extraction using unrestricted relation discovery </title>
<section> basic idea.  </section>
<citcontext>
<prevsection>
<prevsent>to obtain such relations, we need to choose different entities from the articles.
</prevsent>
<prevsent>several existing works have tried to extract certain type of relation by manually choosing different pairs of entities (brin, 1998; ravichandran and hovy, 2002).<papid> P02-1006 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1053 ">
hasegawa et al(2004) <papid> P04-1053 </papid>tried to extract multiple relations by choosing entity types.</citsent>
<aftsection>
<nextsent>we assume that we can find such relations by trying all possible combinations from set of entities we have chosen in advance; some combinations might represent hurricane and government relation, and others might represent place and its casualties.
</nextsent>
<nextsent>to ensure that an article can have several different relations, we let each article belong to several different clusters.
</nextsent>
<nextsent>in real-world situation, only using basic patterns sometimes gives undesired results.
</nextsent>
<nextsent>for example, ?(president) bush flew to texas?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3162">
<title id=" N06-1039.xml">preemptive information extraction using unrestricted relation discovery </title>
<section> basic idea.  </section>
<citcontext>
<prevsection>
<prevsent>we choose predicate-argument structure as natural solution for this problem.
</prevsent>
<prevsent>compared to traditional constituent trees, predicate-argument structure is higher-level representation of sentences that has gained wide acceptance from the natural language community recently.
</prevsent>
</prevsection>
<citsent citstr=" W01-1511 ">
in this paper we used logical feature structure called glarf proposed by meyers et al (2001<papid> W01-1511 </papid>a).</citsent>
<aftsection>
<nextsent>a glarf converter takes syntactic tree as an input and augments it with several 306 katrina hit coast sbj obj louisiana t-pos suffix figure 3: glarf structure of the sentence katrina hit louisianas coast.?
</nextsent>
<nextsent>features.
</nextsent>
<nextsent>figure 3 shows sample glarf structure obtained from the sentence katrina hit louisianas coast.?
</nextsent>
<nextsent>we used glarf for two reasons: first, unlike traditional constituent parsers, glarf hasan ability to regularize several linguistic phenomena such as participial constructions and coordination.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3163">
<title id=" N06-1039.xml">preemptive information extraction using unrestricted relation discovery </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>then we calculated the cosine value of each pair of vectors: sim(a1, a2) = cos(v (a1) ? (a2)) we computed the similarity of all possible pairs of articles from the same day, and selected the pairs 307 whose similarity exceeded certain threshold (0.65 in this experiment) to form basic cluster.
</prevsent>
<prevsent>3.2 parsing and glarfing.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
after getting set of basic clusters, we pass them to an existing statistical parser (charniak, 2000) <papid> A00-2018 </papid>andrule-based tree normalizer to obtain glarf structure for each sentence in every article.</citsent>
<aftsection>
<nextsent>the current implementation of glarf converter gives about 75% f-score using parser output.
</nextsent>
<nextsent>for the details ofglarf representation and its conversion, see meyers et al (2001<papid> W01-1511 </papid>b).</nextsent>
<nextsent>3.3 ne tagging and coreference resolution.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3165">
<title id=" N04-1002.xml">cross document coreference on a large scale corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in news or transcripts (bbn 2001), or for other information organization tasks that might benefit from precise knowledge of how names occur, such as topic detection and tracking (allan 2002).
</prevsent>
<prevsent>cross-document coreference analysis pushes the task into considering whether mentions of name in different documents are the same.
</prevsent>
</prevsection>
<citsent citstr=" W98-0203 ">
the problem becomes more complex because documents might come from different sources, will probably have different authors and different writing conventions and styles(bagga and baldwin,1998), <papid> W98-0203 </papid>and may even be in different languages.</citsent>
<aftsection>
<nextsent>there has been little published work on cross document coreference analysis and that has generally been evaluated on small corpus of documents.
</nextsent>
<nextsent>a major contribution of this work is to develop substantially larger (more than two orders of magnitude) corpus for evaluation.
</nextsent>
<nextsent>we show that the previous approach is effective but that variation on it, agglomerative vector space, provides improved and much more stable results.
</nextsent>
<nextsent>we begin in section 2 by describing how cross document coreference analysis is evaluated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3197">
<title id=" N06-1005.xml">effectively using syntax for recognizing false entailment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recognizing textual entailment, as formulated in the recent pascal challenge 1, is the problem of determining whether some text sentence entails some hypothesis sentence .the motivation for this formulation was to isolate and evaluate the application-independent component of semantic inference shared across many application areas, reflected in the division of the pascal rte dataset into seven distinct tasks: information extraction (ie), comparable documents (cd), reading comprehension (rc), machine translation(mt), information retrieval (ir), question answering (qa), and paraphrase acquisition (pp).1http://www.pascal-network.org/challenges/rte.
</prevsent>
<prevsent>the examples given throughout this paper are from the first pascal rte dataset, described in section 6.
</prevsent>
</prevsection>
<citsent citstr=" H05-1079 ">
the rte problem as presented in the pascal rte dataset is particularly attractive in that it is reasonably simple task for human annotators with high inter-annotator agreement (95.1% in one independent labeling (bos and markert, 2005)), <papid> H05-1079 </papid>but an extremely challenging task for automated systems.</citsent>
<aftsection>
<nextsent>the highest accuracy systems on the rte test set are still much closer in performance to random baseline accuracy of 50% than to the inter-annotator agreement.
</nextsent>
<nextsent>for example, two high-accuracy systems are those described in (tatu and moldovan, 2005),<papid> H05-1047 </papid>achieving 60.4% accuracy with no task-specific information, and (bos and markert, 2005), <papid> H05-1079 </papid>which achieves 61.2% task-dependent accuracy, i.e. when able to use the specific task labels as input.</nextsent>
<nextsent>previous systems for rte have attempted wide variety of strategies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3198">
<title id=" N06-1005.xml">effectively using syntax for recognizing false entailment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the rte problem as presented in the pascal rte dataset is particularly attractive in that it is reasonably simple task for human annotators with high inter-annotator agreement (95.1% in one independent labeling (bos and markert, 2005)), <papid> H05-1079 </papid>but an extremely challenging task for automated systems.</prevsent>
<prevsent>the highest accuracy systems on the rte test set are still much closer in performance to random baseline accuracy of 50% than to the inter-annotator agreement.</prevsent>
</prevsection>
<citsent citstr=" H05-1047 ">
for example, two high-accuracy systems are those described in (tatu and moldovan, 2005),<papid> H05-1047 </papid>achieving 60.4% accuracy with no task-specific information, and (bos and markert, 2005), <papid> H05-1079 </papid>which achieves 61.2% task-dependent accuracy, i.e. when able to use the specific task labels as input.</citsent>
<aftsection>
<nextsent>previous systems for rte have attempted wide variety of strategies.
</nextsent>
<nextsent>many previous approaches have used logical form representation of the text and hypothesis sentences, focusing on deriving proof by which one can infer the hypothesis logical form from the text logical form (bayer et al, 2005; bos and markert, 2005; <papid> H05-1079 </papid>raina et al, 2005; tatu and moldovan, 2005).<papid> H05-1047 </papid></nextsent>
<nextsent>these papers often cite that major obstacle to accurate theorem proving for the task of textual entailment is the lack of world knowledge, which is frequently difficult and costly to obtain and encode.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3204">
<title id=" N06-1005.xml">effectively using syntax for recognizing false entailment </title>
<section> lexical similarity and paraphrase.  </section>
<citcontext>
<prevsection>
<prevsent>discovered phrase template ph in . 3.
</prevsent>
<prevsent>calculate paraphrase similarity as function of.
</prevsent>
</prevsection>
<citsent citstr=" W04-3206 ">
the overlap between the slot-filler sets xt and xh, i.e: score(ph, pt) = |xhxt||xt| . we then incorporate paraphrase similarity within the lexical similarity model by allowing, for some unaligned node ? ph, where ? pt: sim(h, t) = max(mn(h, t), score(ph, pt)) 38 our approach to paraphrase detection is most similar to the te/ase algorithm (szpektor et al, 2004), <papid> W04-3206 </papid>and bears similarity to both dirt (lin and pantel, 2001) and knowitall (etzioni et al, 2004).</citsent>
<aftsection>
<nextsent>the chief difference in our algorithm is that we generate the surface text search strings from the parsed logical forms using the generation capabilities of nlpwin(aikawa et al, 2001), <papid> W01-0808 </papid>and we verify that the syntactic relations in each discovered web snippet areisomorphic to those in the original candidate paraphrase template.</nextsent>
<nextsent>in this section we present the final results of our system on the pascal rte-1 test set, and examine our features in an ablation study.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3205">
<title id=" N06-1005.xml">effectively using syntax for recognizing false entailment </title>
<section> lexical similarity and paraphrase.  </section>
<citcontext>
<prevsection>
<prevsent>calculate paraphrase similarity as function of.
</prevsent>
<prevsent>the overlap between the slot-filler sets xt and xh, i.e: score(ph, pt) = |xhxt||xt| . we then incorporate paraphrase similarity within the lexical similarity model by allowing, for some unaligned node ? ph, where ? pt: sim(h, t) = max(mn(h, t), score(ph, pt)) 38 our approach to paraphrase detection is most similar to the te/ase algorithm (szpektor et al, 2004), <papid> W04-3206 </papid>and bears similarity to both dirt (lin and pantel, 2001) and knowitall (etzioni et al, 2004).</prevsent>
</prevsection>
<citsent citstr=" W01-0808 ">
the chief difference in our algorithm is that we generate the surface text search strings from the parsed logical forms using the generation capabilities of nlpwin(aikawa et al, 2001), <papid> W01-0808 </papid>and we verify that the syntactic relations in each discovered web snippet areisomorphic to those in the original candidate paraphrase template.</citsent>
<aftsection>
<nextsent>in this section we present the final results of our system on the pascal rte-1 test set, and examine our features in an ablation study.
</nextsent>
<nextsent>the pascal rte-1development and test sets consist of 567 and 800 examples, respectively, with the test set split equally between true and false examples.
</nextsent>
<nextsent>6.1 results and performance comparison on.
</nextsent>
<nextsent>the pascal rte-1 test set table 2 displays the accuracy and confidence weighted score6 (cws) of our final system on each of the tasks for both the development and test sets.our overall test set accuracy of 62.50% represents 2.1% absolute improvement over the task-independent system described in (tatu and moldovan, 2005), <papid> H05-1047 </papid>and 20.2% relative improvement inaccuracy over their system with respect to an uninformed baseline accuracy of 50%.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3207">
<title id=" N01-1019.xml">information based machine translation </title>
<section> information-based mt.  </section>
<citcontext>
<prevsection>
<prevsent>2.2.
</prevsent>
<prevsent>linguistic transfer.
</prevsent>
</prevsection>
<citsent citstr=" C00-2152 ">
the linguistic transfer procedure is implemented as rewrite-grammar using the special-purpose grammar programming language (gpl) (duan, et al 2000, franz, et al 2000<papid> C00-2152 </papid>a).</citsent>
<aftsection>
<nextsent>the general role of the transfer grammar is to operate on the input feature structure in recursive manner, and to perform source-to-target transfer by invoking the example matching procedure, and by using the translation examples to construct target-language feature structure.
</nextsent>
<nextsent>the transfer grammar implements the principle of large to small?
</nextsent>
<nextsent>in covering the input feature structure.
</nextsent>
<nextsent>when the transfer procedure invokes the example matching procedure, it implements the principle of specific to general?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3208">
<title id=" N07-1036.xml">an exploration of eye gaze in spoken language processing for multimodal conversational interfaces </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>salience modeling has been used in both natural language and multimodal language processing.
</prevsent>
<prevsent>linguistic salience describes entities with their accessibility in hearers memory and their implications in language production and interpretation.
</prevsent>
</prevsection>
<citsent citstr=" J95-1003 ">
linguistic salience modeling has been used for language interpretations such as reference resolution (huls etal., 1995; <papid> J95-1003 </papid>eisenstein and christoudias, 2004).<papid> N04-1004 </papid></citsent>
<aftsection>
<nextsent>visual salience measures how much attention an entity attracts from user based on its visual properties.
</nextsent>
<nextsent>visual salience can tailor users?
</nextsent>
<nextsent>referring expressions and thus can be used for multimodal reference resolution (kehler, 2000).
</nextsent>
<nextsent>our recent work hasalso investigated salience modeling based on deictic gestures to improve spoken language understanding (chai and qu, 2005; qu and chai, 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3209">
<title id=" N07-1036.xml">an exploration of eye gaze in spoken language processing for multimodal conversational interfaces </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>salience modeling has been used in both natural language and multimodal language processing.
</prevsent>
<prevsent>linguistic salience describes entities with their accessibility in hearers memory and their implications in language production and interpretation.
</prevsent>
</prevsection>
<citsent citstr=" N04-1004 ">
linguistic salience modeling has been used for language interpretations such as reference resolution (huls etal., 1995; <papid> J95-1003 </papid>eisenstein and christoudias, 2004).<papid> N04-1004 </papid></citsent>
<aftsection>
<nextsent>visual salience measures how much attention an entity attracts from user based on its visual properties.
</nextsent>
<nextsent>visual salience can tailor users?
</nextsent>
<nextsent>referring expressions and thus can be used for multimodal reference resolution (kehler, 2000).
</nextsent>
<nextsent>our recent work hasalso investigated salience modeling based on deictic gestures to improve spoken language understanding (chai and qu, 2005; qu and chai, 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3210">
<title id=" N06-1018.xml">understanding temporal expressions in emails </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with increasing demand from ever more sophisticated nlp applications, interest in extracting and understanding temporal information from texts has seen much growth in recent years.
</prevsent>
<prevsent>several work shave addressed the problems of representing temporal information in natural language (setzer, 2001; hobbs and pan, 2004; saur??
</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
et al, 2006), extracting and/or anchoring (normalizing) temporal and event related expressions (wiebe et al, 1998; mani and wilson, 2000; <papid> P00-1010 </papid>schilder and habel, 2001; <papid> W01-1309 </papid>vazov, 2001; <papid> W01-1314 </papid>filatova and hovy, 2001), <papid> W01-1313 </papid>and discovering the ordering of events (mani et al, 2003).<papid> N03-2019 </papid></citsent>
<aftsection>
<nextsent>most of these works have focused on capturing temporal information contained in newswire texts, and whenever both recognition and normalization tasks of temporal expressions were attempted, the latter almost always fell far behind from the former in terms of perfor mance.in this paper we will focus on different combination of the problems: anchoring temporal expressions in scheduling-related emails.
</nextsent>
<nextsent>in our project work of building personal agents capable of scheduling meetings among different users1, understanding temporal expressions is crucial step.
</nextsent>
<nextsent>we have therefore developed and evaluated our system temporal expression anchorer (tea) that is capable of normalizing such expressions in texts.
</nextsent>
<nextsent>as input tea takes english text with temporal expressions already identified, and trans duces the expressions into their representations using time calculus for natural language (tcnl) (han and kohlhase, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3211">
<title id=" N06-1018.xml">understanding temporal expressions in emails </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with increasing demand from ever more sophisticated nlp applications, interest in extracting and understanding temporal information from texts has seen much growth in recent years.
</prevsent>
<prevsent>several work shave addressed the problems of representing temporal information in natural language (setzer, 2001; hobbs and pan, 2004; saur??
</prevsent>
</prevsection>
<citsent citstr=" W01-1309 ">
et al, 2006), extracting and/or anchoring (normalizing) temporal and event related expressions (wiebe et al, 1998; mani and wilson, 2000; <papid> P00-1010 </papid>schilder and habel, 2001; <papid> W01-1309 </papid>vazov, 2001; <papid> W01-1314 </papid>filatova and hovy, 2001), <papid> W01-1313 </papid>and discovering the ordering of events (mani et al, 2003).<papid> N03-2019 </papid></citsent>
<aftsection>
<nextsent>most of these works have focused on capturing temporal information contained in newswire texts, and whenever both recognition and normalization tasks of temporal expressions were attempted, the latter almost always fell far behind from the former in terms of perfor mance.in this paper we will focus on different combination of the problems: anchoring temporal expressions in scheduling-related emails.
</nextsent>
<nextsent>in our project work of building personal agents capable of scheduling meetings among different users1, understanding temporal expressions is crucial step.
</nextsent>
<nextsent>we have therefore developed and evaluated our system temporal expression anchorer (tea) that is capable of normalizing such expressions in texts.
</nextsent>
<nextsent>as input tea takes english text with temporal expressions already identified, and trans duces the expressions into their representations using time calculus for natural language (tcnl) (han and kohlhase, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3212">
<title id=" N06-1018.xml">understanding temporal expressions in emails </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with increasing demand from ever more sophisticated nlp applications, interest in extracting and understanding temporal information from texts has seen much growth in recent years.
</prevsent>
<prevsent>several work shave addressed the problems of representing temporal information in natural language (setzer, 2001; hobbs and pan, 2004; saur??
</prevsent>
</prevsection>
<citsent citstr=" W01-1314 ">
et al, 2006), extracting and/or anchoring (normalizing) temporal and event related expressions (wiebe et al, 1998; mani and wilson, 2000; <papid> P00-1010 </papid>schilder and habel, 2001; <papid> W01-1309 </papid>vazov, 2001; <papid> W01-1314 </papid>filatova and hovy, 2001), <papid> W01-1313 </papid>and discovering the ordering of events (mani et al, 2003).<papid> N03-2019 </papid></citsent>
<aftsection>
<nextsent>most of these works have focused on capturing temporal information contained in newswire texts, and whenever both recognition and normalization tasks of temporal expressions were attempted, the latter almost always fell far behind from the former in terms of perfor mance.in this paper we will focus on different combination of the problems: anchoring temporal expressions in scheduling-related emails.
</nextsent>
<nextsent>in our project work of building personal agents capable of scheduling meetings among different users1, understanding temporal expressions is crucial step.
</nextsent>
<nextsent>we have therefore developed and evaluated our system temporal expression anchorer (tea) that is capable of normalizing such expressions in texts.
</nextsent>
<nextsent>as input tea takes english text with temporal expressions already identified, and trans duces the expressions into their representations using time calculus for natural language (tcnl) (han and kohlhase, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3213">
<title id=" N06-1018.xml">understanding temporal expressions in emails </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with increasing demand from ever more sophisticated nlp applications, interest in extracting and understanding temporal information from texts has seen much growth in recent years.
</prevsent>
<prevsent>several work shave addressed the problems of representing temporal information in natural language (setzer, 2001; hobbs and pan, 2004; saur??
</prevsent>
</prevsection>
<citsent citstr=" W01-1313 ">
et al, 2006), extracting and/or anchoring (normalizing) temporal and event related expressions (wiebe et al, 1998; mani and wilson, 2000; <papid> P00-1010 </papid>schilder and habel, 2001; <papid> W01-1309 </papid>vazov, 2001; <papid> W01-1314 </papid>filatova and hovy, 2001), <papid> W01-1313 </papid>and discovering the ordering of events (mani et al, 2003).<papid> N03-2019 </papid></citsent>
<aftsection>
<nextsent>most of these works have focused on capturing temporal information contained in newswire texts, and whenever both recognition and normalization tasks of temporal expressions were attempted, the latter almost always fell far behind from the former in terms of perfor mance.in this paper we will focus on different combination of the problems: anchoring temporal expressions in scheduling-related emails.
</nextsent>
<nextsent>in our project work of building personal agents capable of scheduling meetings among different users1, understanding temporal expressions is crucial step.
</nextsent>
<nextsent>we have therefore developed and evaluated our system temporal expression anchorer (tea) that is capable of normalizing such expressions in texts.
</nextsent>
<nextsent>as input tea takes english text with temporal expressions already identified, and trans duces the expressions into their representations using time calculus for natural language (tcnl) (han and kohlhase, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3214">
<title id=" N06-1018.xml">understanding temporal expressions in emails </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with increasing demand from ever more sophisticated nlp applications, interest in extracting and understanding temporal information from texts has seen much growth in recent years.
</prevsent>
<prevsent>several work shave addressed the problems of representing temporal information in natural language (setzer, 2001; hobbs and pan, 2004; saur??
</prevsent>
</prevsection>
<citsent citstr=" N03-2019 ">
et al, 2006), extracting and/or anchoring (normalizing) temporal and event related expressions (wiebe et al, 1998; mani and wilson, 2000; <papid> P00-1010 </papid>schilder and habel, 2001; <papid> W01-1309 </papid>vazov, 2001; <papid> W01-1314 </papid>filatova and hovy, 2001), <papid> W01-1313 </papid>and discovering the ordering of events (mani et al, 2003).<papid> N03-2019 </papid></citsent>
<aftsection>
<nextsent>most of these works have focused on capturing temporal information contained in newswire texts, and whenever both recognition and normalization tasks of temporal expressions were attempted, the latter almost always fell far behind from the former in terms of perfor mance.in this paper we will focus on different combination of the problems: anchoring temporal expressions in scheduling-related emails.
</nextsent>
<nextsent>in our project work of building personal agents capable of scheduling meetings among different users1, understanding temporal expressions is crucial step.
</nextsent>
<nextsent>we have therefore developed and evaluated our system temporal expression anchorer (tea) that is capable of normalizing such expressions in texts.
</nextsent>
<nextsent>as input tea takes english text with temporal expressions already identified, and trans duces the expressions into their representations using time calculus for natural language (tcnl) (han and kohlhase, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3217">
<title id=" N06-1014.xml">alignment by agreement </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>compared to the standard practice of intersecting predictions ofindependently-trained models, joint training provides 32% reduction in aer.
</prevsent>
<prevsent>moreover, simple and efficient pair of hmm align ers provides 29% reduction in aer over symmetrized ibm model 4 predictions.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
word alignment is an important component of complete statistical machine translation pipeline(koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the classic approaches to unsupervised word alignment are based on ibm models 15 (brown et al, 1994) and the hmm model (ney and vogel, 1996) (see och and ney (2003) <papid> J03-1002 </papid>for systematic comparison).</nextsent>
<nextsent>one can classify these six models into two groups: sequence-based models (models 1, 2, and hmm) and fertility-based models (models 3, 4, and 5).1 whereas the sequence-based models are tractable and easily implemented, the more accurate fertility-based models are intractable and thus require approximation methods which are 1ibm models 1 and 2 are considered sequence-based models because they are special cases of hmms with transitions that do not depend on previous states.difficult to implement.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3218">
<title id=" N06-1014.xml">alignment by agreement </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, simple and efficient pair of hmm align ers provides 29% reduction in aer over symmetrized ibm model 4 predictions.
</prevsent>
<prevsent>word alignment is an important component of complete statistical machine translation pipeline(koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the classic approaches to unsupervised word alignment are based on ibm models 15 (brown et al, 1994) and the hmm model (ney and vogel, 1996) (see och and ney (2003) <papid> J03-1002 </papid>for systematic comparison).</citsent>
<aftsection>
<nextsent>one can classify these six models into two groups: sequence-based models (models 1, 2, and hmm) and fertility-based models (models 3, 4, and 5).1 whereas the sequence-based models are tractable and easily implemented, the more accurate fertility-based models are intractable and thus require approximation methods which are 1ibm models 1 and 2 are considered sequence-based models because they are special cases of hmms with transitions that do not depend on previous states.difficult to implement.
</nextsent>
<nextsent>as result, many practitioners use the complex giza++ software package (och and ney, 2003) <papid> J03-1002 </papid>as black box, selecting model 4 as good compromise between alignment quality and efficiency.</nextsent>
<nextsent>even though the fertility-based models are more accurate, there are several reasons to consider avenues for improvement based on the simpler and faster sequence-based models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3228">
<title id=" N06-1014.xml">alignment by agreement </title>
<section> training by agreement.  </section>
<citcontext>
<prevsection>
<prevsent>for each model, the overall precision/recall/aer on the development set is given.
</prevsent>
<prevsent>see section 4 for details.
</prevsent>
</prevsection>
<citsent citstr=" P04-1066 ">
this example, cojo is rare word that becomes garbage collector (moore, 2004) <papid> P04-1066 </papid>for the models in both directions.</citsent>
<aftsection>
<nextsent>intersection eliminates the spurious alignments, but at the expense of recall.
</nextsent>
<nextsent>intersection after training produces alignments that both models agree on.
</nextsent>
<nextsent>the joint training procedure we describe below builds on this idea by encouraging the models to agree during training.
</nextsent>
<nextsent>consider the output of the jointly trained hmms in figure 1 (bottom).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3230">
<title id=" N06-1014.xml">alignment by agreement </title>
<section> training by agreement.  </section>
<citcontext>
<prevsection>
<prevsent>the m-step decouples neatly into two independent optimization problems, which lead to single model updates using the expected counts from q(z;x).
</prevsent>
<prevsent>to compute zx in the e-step, we must sum the product of two model posteriors over the set of possible zs with nonzero probability under both models.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
in general, if both posterior distributions over the latent variables decompose in the same tractable manner, as in the context-free grammar induction work of klein and manning (2004), <papid> P04-1061 </papid>the summation could be carried out efficiently, for example using dynamic programming.</citsent>
<aftsection>
<nextsent>in our case, we would have to sum over the set of alignments where each word in english is aligned to at most one word in french and each word in french is aligned to at most one 107 word in english.
</nextsent>
<nextsent>unfortunately, for even very simple models such as ibm 1 or 2, computing the normalization constant over this set of alignments is #p -complete problem, by reduction from counting matchings in bipartite graph (valiant,1979).
</nextsent>
<nextsent>we could perhaps attempt to compute using variety of approximate probabilistic inference techniques, for example, sampling or variational methods.
</nextsent>
<nextsent>with efficiency as our main concern, we opted instead for simple heuristic procedure by letting be product of marginals: q(z;x) := ? i,j p1(zij | x; 1)p2(zij | x; 2), where each pk(zij | x; k) is the posterior marginal probability of the (i, j) edge being present (or ab sent) in the alignment according to each model, which can be computed separately and efficiently.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3231">
<title id=" N06-1014.xml">alignment by agreement </title>
<section> training by agreement.  </section>
<citcontext>
<prevsection>
<prevsent>varying the threshold?
</prevsent>
<prevsent>gives natural way to tradeoff precision and recall.
</prevsent>
</prevsection>
<citsent citstr=" C04-1032 ">
in fact, these posteriors could be used more di 4see matusov et al (2004) <papid> C04-1032 </papid>for an alternative use of these marginals.rectly in extracting phrases for phrase-based translation.</citsent>
<aftsection>
<nextsent>also, when we want to combine two models for prediction, finding the viterbi alignment argmaxz p1(z | x)p2(z | x) is intractable forhmm models (by reduction from quadratic as signment), and hard intersection argmaxz1 p1(z1 | x) ? argmaxz2 p2(z2 | x) might be too sparse.
</nextsent>
<nextsent>on the other hand, we can threshold the product of two edge posteriors quite easily: = {zij = 1 : p1(zij = 1 | x)p2(zij = 1 | x) ? ?}.
</nextsent>
<nextsent>we noticed 5.8% relative reduction in aer (for our best model) by using posterior decoding with validation-set optimized threshold ? instead of using hard intersection of viterbi alignments.
</nextsent>
<nextsent>we tested our approach on the english-french hansa rds data from the naacl 2003 shared task,which includes training set of 1.1 million sentences, validation set of 37 sentences, and test set of 447 sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3235">
<title id=" N06-1014.xml">alignment by agreement </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>by using alignments from our jointly trained hmms instead, we get bleu score of 0.3051.
</prevsent>
<prevsent>while this improvement is very modest, we are currently investigating alternative ways of interfacing with phrase table construction to make larger impact on translation quality.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
our approach is similar in spirit to co-training, where two classifiers, complementary by the virtue of having different views of the data, are trained jointly to encourage agreement (blum and mitchell, 1998; collins and singer, 1999).<papid> W99-0613 </papid></citsent>
<aftsection>
<nextsent>one key difference 110in our work is that we rely exclusively on data likelihood to guide the two models in an unsupervised manner, rather than relying on an initial handful of labeled examples.the idea of exploiting agreement between two latent variable models is not new; there has been substantial previous work on leveraging the strengths of two complementary models.
</nextsent>
<nextsent>klein and manning (2004) <papid> P04-1061 </papid>combine two complementary models for grammar induction, one that models constituency and one that models dependency, in manner broadly similar to the current work.</nextsent>
<nextsent>aside from investigating different domain, one novel aspect of this paper is that we present formal objective and at raining algorithm for combining two generic mod els.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3237">
<title id=" N06-2017.xml">evaluating centering for sentence ordering in two new domains </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P04-1050 ">
this paper builds on recent research investigating sentence ordering in text production by evaluating the centering-based metrics of coherence employed by karamanis et al (2004) <papid> P04-1050 </papid>using the data of barzilay and lapata (2005).<papid> P05-1018 </papid></citsent>
<aftsection>
<nextsent>this is the first time that centering is evaluated empirically as sentence ordering constraint in several domains, verifying the results reported in karamanis et al
</nextsent>
<nextsent>as most literature in text linguistics argues, felicitous text should be coherent which means that the content has to be organised in way that makes the text easy to read and comprehend.
</nextsent>
<nextsent>the easiest way to demonstrate this claim is by arbitrarily reordering the sentences that an understandable text consists of.
</nextsent>
<nextsent>this process very often gives rise to documents that do not make sense although the information content remains the same.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3240">
<title id=" N06-2017.xml">evaluating centering for sentence ordering in two new domains </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P05-1018 ">
this paper builds on recent research investigating sentence ordering in text production by evaluating the centering-based metrics of coherence employed by karamanis et al (2004) <papid> P04-1050 </papid>using the data of barzilay and lapata (2005).<papid> P05-1018 </papid></citsent>
<aftsection>
<nextsent>this is the first time that centering is evaluated empirically as sentence ordering constraint in several domains, verifying the results reported in karamanis et al
</nextsent>
<nextsent>as most literature in text linguistics argues, felicitous text should be coherent which means that the content has to be organised in way that makes the text easy to read and comprehend.
</nextsent>
<nextsent>the easiest way to demonstrate this claim is by arbitrarily reordering the sentences that an understandable text consists of.
</nextsent>
<nextsent>this process very often gives rise to documents that do not make sense although the information content remains the same.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3241">
<title id=" N06-2017.xml">evaluating centering for sentence ordering in two new domains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hence, deciding in which sequence to present set of pre selected information-bearing items is an important problem in automatic text production.
</prevsent>
<prevsent>entity coherence, which arises from the way np referents relate subsequent sentences in the text, is an important aspect of textual felicity.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
centering theory (grosz et al, 1995) <papid> J95-2003 </papid>has been an influential framework for modelling entity coherence in computational linguistics in the last two decades.</citsent>
<aftsection>
<nextsent>karamanis et al (2004) <papid> P04-1050 </papid>were the first to evaluate centering-based metrics of coherence for ordering clauses in subset of the gnome corpus (poesio et al, 2004) <papid> J04-3003 </papid>consisting of 20 artefact descriptions.</nextsent>
<nextsent>they introduced novel experimental methodology that treats the observed ordering of clauses in text as the gold standard, which is scored by each metric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3245">
<title id=" N06-2017.xml">evaluating centering for sentence ordering in two new domains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>entity coherence, which arises from the way np referents relate subsequent sentences in the text, is an important aspect of textual felicity.
</prevsent>
<prevsent>centering theory (grosz et al, 1995) <papid> J95-2003 </papid>has been an influential framework for modelling entity coherence in computational linguistics in the last two decades.</prevsent>
</prevsection>
<citsent citstr=" J04-3003 ">
karamanis et al (2004) <papid> P04-1050 </papid>were the first to evaluate centering-based metrics of coherence for ordering clauses in subset of the gnome corpus (poesio et al, 2004) <papid> J04-3003 </papid>consisting of 20 artefact descriptions.</citsent>
<aftsection>
<nextsent>they introduced novel experimental methodology that treats the observed ordering of clauses in text as the gold standard, which is scored by each metric.
</nextsent>
<nextsent>then, the metric is penalised proportionally to the amount of alternative orderings of the same material that score equally to or better than the gold standard.
</nextsent>
<nextsent>this methodology is very similar to the way barzilay and lapata (2005) <papid> P05-1018 </papid>evaluate automatically another model of coherence called the entity grid using larger collection of 200 articles from the north american news corpus (news) and 200 accident narratives from the national transportation safety board database (accs).</nextsent>
<nextsent>the same data and similar methods were used by barzilay and lee (2004) <papid> N04-1015 </papid>to compare their probabilistic approach for ordering sentences with that of lapata (2003).<papid> P03-1069 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3247">
<title id=" N06-2017.xml">evaluating centering for sentence ordering in two new domains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then, the metric is penalised proportionally to the amount of alternative orderings of the same material that score equally to or better than the gold standard.
</prevsent>
<prevsent>this methodology is very similar to the way barzilay and lapata (2005) <papid> P05-1018 </papid>evaluate automatically another model of coherence called the entity grid using larger collection of 200 articles from the north american news corpus (news) and 200 accident narratives from the national transportation safety board database (accs).</prevsent>
</prevsection>
<citsent citstr=" N04-1015 ">
the same data and similar methods were used by barzilay and lee (2004) <papid> N04-1015 </papid>to compare their probabilistic approach for ordering sentences with that of lapata (2003).<papid> P03-1069 </papid></citsent>
<aftsection>
<nextsent>this paper discusses how the centering-based metrics of coherence employed by karamanis et alcan be evaluated on the data prepared by barzilay and lapata.
</nextsent>
<nextsent>this is the first time that centering is evaluated empirically as sentence ordering constraint in more than one domain, verifying the results reported in karamanis et al the paper also contributes by emphasising the following methodological point: to conduct our experiments, we need to produce several alternative orderings of sentences and compare them with the gold standard.
</nextsent>
<nextsent>as the number of possible orderings grows factorially, enumerating them exhaustively (as barzilay and lee do) becomes impractical.
</nextsent>
<nextsent>in this paper, we make use of the methods of karamanis (2003) which allow us to explore 65 table 1a np referents sentences department trial microsoft ... products brands ...
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3248">
<title id=" N06-2017.xml">evaluating centering for sentence ordering in two new domains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then, the metric is penalised proportionally to the amount of alternative orderings of the same material that score equally to or better than the gold standard.
</prevsent>
<prevsent>this methodology is very similar to the way barzilay and lapata (2005) <papid> P05-1018 </papid>evaluate automatically another model of coherence called the entity grid using larger collection of 200 articles from the north american news corpus (news) and 200 accident narratives from the national transportation safety board database (accs).</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
the same data and similar methods were used by barzilay and lee (2004) <papid> N04-1015 </papid>to compare their probabilistic approach for ordering sentences with that of lapata (2003).<papid> P03-1069 </papid></citsent>
<aftsection>
<nextsent>this paper discusses how the centering-based metrics of coherence employed by karamanis et alcan be evaluated on the data prepared by barzilay and lapata.
</nextsent>
<nextsent>this is the first time that centering is evaluated empirically as sentence ordering constraint in more than one domain, verifying the results reported in karamanis et al the paper also contributes by emphasising the following methodological point: to conduct our experiments, we need to produce several alternative orderings of sentences and compare them with the gold standard.
</nextsent>
<nextsent>as the number of possible orderings grows factorially, enumerating them exhaustively (as barzilay and lee do) becomes impractical.
</nextsent>
<nextsent>in this paper, we make use of the methods of karamanis (2003) which allow us to explore 65 table 1a np referents sentences department trial microsoft ... products brands ...
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3249">
<title id=" N06-2017.xml">evaluating centering for sentence ordering in two new domains </title>
<section> materials and methods.  </section>
<citcontext>
<prevsection>
<prevsent>in (1a), the role with the highest priority (in this case s) is used.
</prevsent>
<prevsent>s, and (table 1b).
</prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
the members of the cf list are ranked according to their grammatical role (brennan et al, 1987) <papid> P87-1022 </papid>and their position in the grid.3 the derived sequence of cf lists can then be used to compute other important centering concepts: ? the cb, i.e. the referent that links the current cf list with the previous one such as microsoft in (b).</citsent>
<aftsection>
<nextsent>transitions (brennan et al, 1987) <papid> P87-1022 </papid>and nocbs, that is, cases in which two subsequent cf lists do not have any referent in common.</nextsent>
<nextsent>violations of cheapness (strube and hahn, 1999), <papid> J99-3001 </papid>coherence and salience (kibble and power, 2000).<papid> W00-1411 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3253">
<title id=" N06-2017.xml">evaluating centering for sentence ordering in two new domains </title>
<section> materials and methods.  </section>
<citcontext>
<prevsection>
<prevsent>the members of the cf list are ranked according to their grammatical role (brennan et al, 1987) <papid> P87-1022 </papid>and their position in the grid.3 the derived sequence of cf lists can then be used to compute other important centering concepts: ? the cb, i.e. the referent that links the current cf list with the previous one such as microsoft in (b).</prevsent>
<prevsent>transitions (brennan et al, 1987) <papid> P87-1022 </papid>and nocbs, that is, cases in which two subsequent cf lists do not have any referent in common.</prevsent>
</prevsection>
<citsent citstr=" J99-3001 ">
violations of cheapness (strube and hahn, 1999), <papid> J99-3001 </papid>coherence and salience (kibble and power, 2000).<papid> W00-1411 </papid></citsent>
<aftsection>
<nextsent>2.2 metrics of coherence.
</nextsent>
<nextsent>karamanis (2003) assumes system which receives an unordered set of cf lists as its input and uses metric to output the highest scoring ordering.
</nextsent>
<nextsent>he discusses how centering can be used to define many different metrics of coherence which might be useful for this task.
</nextsent>
<nextsent>in our experiments we made use of the four metrics employed in karamanis et al (2004): ? <papid> P04-1050 </papid>the baseline metric m.nocb which simply prefers the ordering with the fewest nocbs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3254">
<title id=" N06-2017.xml">evaluating centering for sentence ordering in two new domains </title>
<section> materials and methods.  </section>
<citcontext>
<prevsection>
<prevsent>the members of the cf list are ranked according to their grammatical role (brennan et al, 1987) <papid> P87-1022 </papid>and their position in the grid.3 the derived sequence of cf lists can then be used to compute other important centering concepts: ? the cb, i.e. the referent that links the current cf list with the previous one such as microsoft in (b).</prevsent>
<prevsent>transitions (brennan et al, 1987) <papid> P87-1022 </papid>and nocbs, that is, cases in which two subsequent cf lists do not have any referent in common.</prevsent>
</prevsection>
<citsent citstr=" W00-1411 ">
violations of cheapness (strube and hahn, 1999), <papid> J99-3001 </papid>coherence and salience (kibble and power, 2000).<papid> W00-1411 </papid></citsent>
<aftsection>
<nextsent>2.2 metrics of coherence.
</nextsent>
<nextsent>karamanis (2003) assumes system which receives an unordered set of cf lists as its input and uses metric to output the highest scoring ordering.
</nextsent>
<nextsent>he discusses how centering can be used to define many different metrics of coherence which might be useful for this task.
</nextsent>
<nextsent>in our experiments we made use of the four metrics employed in karamanis et al (2004): ? <papid> P04-1050 </papid>the baseline metric m.nocb which simply prefers the ordering with the fewest nocbs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3259">
<title id=" N06-2006.xml">class model adaptation for speech summarisation </title>
<section> evaluation criteria.  </section>
<citcontext>
<prevsection>
<prevsent>the word accuracy of automatic summarisation is calculated as the summarisation accuracy (sumaccy) using the word network (hori et al, 2003): accuracy = (lensubinsdel)/len100[%], (5) where sub is the number of substitution errors, ins is the number of insertion errors, delis the number of deletion errors, and len is the number of words in the most similar word string in the network.
</prevsent>
<prevsent>3.2 rouge.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
version 1.5.5 of the rouge scoring algorithm (lin, 2004) <papid> W04-1013 </papid>is also used for evaluating results.rouge f-measure scores are given for rouge 2 (bigram), rouge-3 (trigram), and rouge-su4 (skip-bigram), using the model average (average score across all references) metric.</citsent>
<aftsection>
<nextsent>experiments were performed on spontaneous speech, using 9 talks taken from the trans language english database (ted) corpus (lamel et al, 1994; wolfel and burger, 2005), each transcribed and manually summarised by nine different humans for both 10% and 30% summarization ratios.
</nextsent>
<nextsent>speech recognition transcriptions (asr) were obtained for each talk, with an average word error rate of 33.3%.a corpus consisting of around ten years of conference proceedings (17.8m words) on the subject of speech and signal processing is used to generate the limb and word classes using the clustering algorithm in (ney et al, 1994).
</nextsent>
<nextsent>different types of component lim are built and combined for adaptation as described in section 2.
</nextsent>
<nextsent>the first type of component linguistic models are built on the small corpus of hand-made summaries described above, made for the same summarisation ratio as the one we are generating.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3260">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the national science foundation or the office of naval research.though effective, do not take into account explicit syntactic information when measuring translation quality.given that different machine translation (mt) evaluation metrics are useful for capturing different aspects of translation quality, it becomes desirable to create mt systems tuned with respect to each individual criterion.
</prevsent>
<prevsent>in contrast, the maximum likelihood techniques that under lie the decision processes of most current mt systems do not take into account these application specific goals.
</prevsent>
</prevsection>
<citsent citstr=" W02-1019 ">
weapply the minimum bayes-risk (mbr) techniques developed for automatic speech recognition (goel and byrne,2000) and bitext word alignment for statistical mt (kumar and byrne, 2002), <papid> W02-1019 </papid>to the problem of building automatic mt systems tuned for specific metrics.</citsent>
<aftsection>
<nextsent>this is framework that can be used with statistical models of speech and language to develop decision processes optimized for specific loss functions.
</nextsent>
<nextsent>we will show that mbr decoding can be applied to machine translation in two scenarios.
</nextsent>
<nextsent>given an automaticmt metric, we design loss function based on the metric and use mbr decoding to tune mt performance under the metric.
</nextsent>
<nextsent>we also show how mbr decoding can be used to incorporate syntactic structure into statistical mt system by building specialized loss functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3261">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> translation loss functions.  </section>
<citcontext>
<prevsection>
<prevsent>    can be reduced to
</prevsent>
<prevsent>( . we consider three loss functions in this category: the bleu score (papineni et al, 2001), word-error rate, and theposition-independent word-error rate (och, 2002).
</prevsent>
</prevsection>
<citsent citstr=" N03-2021 ">
another example of loss function in this class is the mt eval metric introduced in melamed et al (2003).<papid> N03-2021 </papid></citsent>
<aftsection>
<nextsent>a loss function of this type depends only on information from word strings.
</nextsent>
<nextsent>bleu score (papineni et al, 2001) computes the geometric mean of the precision of ) -grams of various lengths ( )+*-,/.10(0 243 ) between hypothesis and reference translation, and includes brevity penalty ( 56
</nextsent>
<nextsent> 879.
</nextsent>
<nextsent>) if the hypothesis is shorter than the reference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3262">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> translation loss functions.  </section>
<citcontext>
<prevsection>
<prevsent>the second class of translation loss functions uses information only from the parse-trees of the two translations, so that
</prevsent>
<prevsent> %    \:]ffifffl ffiff  . this loss function has no access to any information from the source sentence or the word alignments.
</prevsent>
</prevsection>
<citsent citstr=" P02-1016 ">
examples of such loss functions are tree-edit distances between parse-trees, string-edit distances between event representation of parse-trees (tang et al, 2002), <papid> P02-1016 </papid>and tree kernels (collins and duffy, 2002).<papid> P02-1034 </papid></citsent>
<aftsection>
<nextsent>the computation of tree-edit distance involves an unconstrained alignment ofthe two english parse-trees.
</nextsent>
<nextsent>we can simplify this problem once we have third parse tree (for the chinese sen tence) with node-to-node alignment relative to the two english trees.
</nextsent>
<nextsent>we will introduce such loss function inthe next section.
</nextsent>
<nextsent>we did not perform experiments involving this class of loss functions, but mention them for completeness in the hierarchy of loss functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3263">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> translation loss functions.  </section>
<citcontext>
<prevsection>
<prevsent>the second class of translation loss functions uses information only from the parse-trees of the two translations, so that
</prevsent>
<prevsent> %    \:]ffifffl ffiff  . this loss function has no access to any information from the source sentence or the word alignments.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
examples of such loss functions are tree-edit distances between parse-trees, string-edit distances between event representation of parse-trees (tang et al, 2002), <papid> P02-1016 </papid>and tree kernels (collins and duffy, 2002).<papid> P02-1034 </papid></citsent>
<aftsection>
<nextsent>the computation of tree-edit distance involves an unconstrained alignment ofthe two english parse-trees.
</nextsent>
<nextsent>we can simplify this problem once we have third parse tree (for the chinese sen tence) with node-to-node alignment relative to the two english trees.
</nextsent>
<nextsent>we will introduce such loss function inthe next section.
</nextsent>
<nextsent>we did not perform experiments involving this class of loss functions, but mention them for completeness in the hierarchy of loss functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3264">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> minimum bayes-risk decoding.  </section>
<citcontext>
<prevsection>
<prevsent>n
</prevsent>
<prevsent>  bleu (%) 26.4 26.4 wer (%) 70.6 70.6 per (%) 23.5 23.5 bitree error rate (%) 65.4 92.3 table 2: comparison of the different loss functions for hypothesis and reference translations from figures 1, 2.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
statistical machine translation (brown et al, 1990) <papid> J90-2002 </papid>can be formulated as mapping of word sequence   in asource language to word sequence</citsent>
<aftsection>
<nextsent> in the target language that has word-to-word alignment  relative to   .given the source sentence   , the mt decoder fl   produces target word string
</nextsent>
<nextsent> with word-to-word alignment  . relative to reference translation
</nextsent>
<nextsent>with word alignment  , the decoder performance is measured as
</nextsent>
<nextsent> ffifl   . our goal is to find the decoder that hasthe best performance over all translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3265">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> performance of mbr decoders.  </section>
<citcontext>
<prevsection>
<prevsent>in our experiments, baseline translation model (jhu,2003), trained on chinese-english parallel corpus (nist, 2003) ( .:9mw5; english words and . 59; chinese words), was used to generate 1000-best translation hypotheses for each chinese sentence in the test set.
</prevsent>
<prevsent>the 1000-best lists were then rescored using the different translation loss functions described in section 2.
</prevsent>
</prevsection>
<citsent citstr=" W00-1201 ">
the english sentences in the 2 -best lists were parsed using the collins parser (collins, 1999), and the chinese sentences were parsed using chinese parser provided to us by d. bikel (bikel and chiang, 2000).<papid> W00-1201 </papid></citsent>
<aftsection>
<nextsent>the english parser was trained on the penn treebank and the chinese parser on the penn chinese treebank.under each loss function, the mbr decoding was performed using equation 3.
</nextsent>
<nextsent>we say we have matched condition when the same loss function is used in both the error rate and the decoder design.
</nextsent>
<nextsent>the performance ofthe mbr decoders on the nist 2001+2002 test set is reported in table 3.
</nextsent>
<nextsent>for all performance metrics, we show the 70% confidence interval with respect to the map baseline computed using bootstrap re sampling (press et al., 2002; och, 2003).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3266">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> performance of mbr decoders.  </section>
<citcontext>
<prevsection>
<prevsent>we say we have matched condition when the same loss function is used in both the error rate and the decoder design.
</prevsent>
<prevsent>the performance ofthe mbr decoders on the nist 2001+2002 test set is reported in table 3.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
for all performance metrics, we show the 70% confidence interval with respect to the map baseline computed using bootstrap re sampling (press et al., 2002; och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we note that this significance level does meet the customary criteria for minimum significance intervals of 68.3% (press et al, 2002).
</nextsent>
<nextsent>we observe in most cases that the mbr decoder undera loss function performs the best under the corresponding error metric i.e. matched conditions perform the best.
</nextsent>
<nextsent>the gains from mbr decoding under matched conditions are statistically significant in most cases.
</nextsent>
<nextsent>we note that themap decoder is not optimal in any of the cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3268">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>while we have focused on developing mbr procedures for loss functions that measure various aspects of translation quality, this framework can also be used with loss functions which measure application-specific error criteria.we now describe related training and search procedures for nlp that explicitly take into consideration task specific performance metrics.
</prevsent>
<prevsent>och (2003) <papid> P03-1021 </papid>developed at raining procedure that incorporates various mt evaluation criteria in the training procedure of log-linear mt models.</prevsent>
</prevsection>
<citsent citstr=" W02-1020 ">
foster et al (2002) <papid> W02-1020 </papid>developed text-prediction system for translators that maximizes expected benefit to the translator under statistical user model.</citsent>
<aftsection>
<nextsent>in parsing, goodman (1996) <papid> P96-1024 </papid>developed parsing algorithms that are appropriate for specific parsing metrics.</nextsent>
<nextsent>there has also been recent work that combines 1-best hypotheses from multiple translation systems (bangalore et al, 2002); <papid> C02-1134 </papid>this approach uses string-edit distance to align the hypotheses and re scores the resulting lattice with language model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3269">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>och (2003) <papid> P03-1021 </papid>developed at raining procedure that incorporates various mt evaluation criteria in the training procedure of log-linear mt models.</prevsent>
<prevsent>foster et al (2002) <papid> W02-1020 </papid>developed text-prediction system for translators that maximizes expected benefit to the translator under statistical user model.</prevsent>
</prevsection>
<citsent citstr=" P96-1024 ">
in parsing, goodman (1996) <papid> P96-1024 </papid>developed parsing algorithms that are appropriate for specific parsing metrics.</citsent>
<aftsection>
<nextsent>there has also been recent work that combines 1-best hypotheses from multiple translation systems (bangalore et al, 2002); <papid> C02-1134 </papid>this approach uses string-edit distance to align the hypotheses and re scores the resulting lattice with language model.</nextsent>
<nextsent>in future work we plan to extend the search space of mbr decoders to translation lattices produced by the baseline system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3270">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>foster et al (2002) <papid> W02-1020 </papid>developed text-prediction system for translators that maximizes expected benefit to the translator under statistical user model.</prevsent>
<prevsent>in parsing, goodman (1996) <papid> P96-1024 </papid>developed parsing algorithms that are appropriate for specific parsing metrics.</prevsent>
</prevsection>
<citsent citstr=" C02-1134 ">
there has also been recent work that combines 1-best hypotheses from multiple translation systems (bangalore et al, 2002); <papid> C02-1134 </papid>this approach uses string-edit distance to align the hypotheses and re scores the resulting lattice with language model.</citsent>
<aftsection>
<nextsent>in future work we plan to extend the search space of mbr decoders to translation lattices produced by the baseline system.
</nextsent>
<nextsent>translation lattices (ueffing et al, 2002; <papid> W02-1021 </papid>kumar and byrne, 2003) <papid> N03-1019 </papid>are compact representation of large set of most likely translations generated by an mtsystem.</nextsent>
<nextsent>while an 2 -best list contains only limited reordering of hypotheses, translation lattice will contain hypotheses with vastly greater number of re-orderings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3271">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>there has also been recent work that combines 1-best hypotheses from multiple translation systems (bangalore et al, 2002); <papid> C02-1134 </papid>this approach uses string-edit distance to align the hypotheses and re scores the resulting lattice with language model.</prevsent>
<prevsent>in future work we plan to extend the search space of mbr decoders to translation lattices produced by the baseline system.</prevsent>
</prevsection>
<citsent citstr=" W02-1021 ">
translation lattices (ueffing et al, 2002; <papid> W02-1021 </papid>kumar and byrne, 2003) <papid> N03-1019 </papid>are compact representation of large set of most likely translations generated by an mtsystem.</citsent>
<aftsection>
<nextsent>while an 2 -best list contains only limited reordering of hypotheses, translation lattice will contain hypotheses with vastly greater number of re-orderings.
</nextsent>
<nextsent>we are developing efficient lattice search procedures formbr decoders.
</nextsent>
<nextsent>by extending the search space of the decoder to much larger space than the 2 -best list, we expect further performance improvements.mbr is promising modeling framework for statistical machine translation.
</nextsent>
<nextsent>it is simple model rescoring framework that improves well-trained statistical models performance metrics decoder bleu (%) mwer(%) mper (%) mbitree error rate(%) 70% confidence intervals +/-0.3 +/-0.9 +/-0.6 +/-1.0 map(baseline) 31.2 64.9 41.3 69.0 mbr bleu 31.5 65.1 41.1 68.9 wer 31.3 64.3 40.8 68.5 per 31.3 64.6 40.4 68.6 bitree loss 30.7 64.1 41.1 68.0 table 3: translation performance of the mbr decoder under various loss functions on the nist 2001+2002 test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3272">
<title id=" N04-1022.xml">minimum bayes risk decoding for statistical machine translation </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>there has also been recent work that combines 1-best hypotheses from multiple translation systems (bangalore et al, 2002); <papid> C02-1134 </papid>this approach uses string-edit distance to align the hypotheses and re scores the resulting lattice with language model.</prevsent>
<prevsent>in future work we plan to extend the search space of mbr decoders to translation lattices produced by the baseline system.</prevsent>
</prevsection>
<citsent citstr=" N03-1019 ">
translation lattices (ueffing et al, 2002; <papid> W02-1021 </papid>kumar and byrne, 2003) <papid> N03-1019 </papid>are compact representation of large set of most likely translations generated by an mtsystem.</citsent>
<aftsection>
<nextsent>while an 2 -best list contains only limited reordering of hypotheses, translation lattice will contain hypotheses with vastly greater number of re-orderings.
</nextsent>
<nextsent>we are developing efficient lattice search procedures formbr decoders.
</nextsent>
<nextsent>by extending the search space of the decoder to much larger space than the 2 -best list, we expect further performance improvements.mbr is promising modeling framework for statistical machine translation.
</nextsent>
<nextsent>it is simple model rescoring framework that improves well-trained statistical models performance metrics decoder bleu (%) mwer(%) mper (%) mbitree error rate(%) 70% confidence intervals +/-0.3 +/-0.9 +/-0.6 +/-1.0 map(baseline) 31.2 64.9 41.3 69.0 mbr bleu 31.5 65.1 41.1 68.9 wer 31.3 64.3 40.8 68.5 per 31.3 64.6 40.4 68.6 bitree loss 30.7 64.1 41.1 68.0 table 3: translation performance of the mbr decoder under various loss functions on the nist 2001+2002 test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3273">
<title id=" N06-2010.xml">gesture improves coreference resolution </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>y? is the partitioning that maximizes equation 1 given the set of weights t1.
</prevsent>
<prevsent>as before, average-link clustering with an adaptive cutoff is used to partition the graph.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
the weights are then averaged across all iterations of the perceptron, as in (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>the results of our experiments are computed usingmention-based ceaf scoring (luo, 2005), <papid> H05-1004 </papid>and are reported in table 2.</nextsent>
<nextsent>leave-one-out evaluation was used to form 16 cross-validation folds, one for each document in the corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3274">
<title id=" N06-2010.xml">gesture improves coreference resolution </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>as before, average-link clustering with an adaptive cutoff is used to partition the graph.
</prevsent>
<prevsent>the weights are then averaged across all iterations of the perceptron, as in (collins, 2002).<papid> W02-1001 </papid></prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
the results of our experiments are computed usingmention-based ceaf scoring (luo, 2005), <papid> H05-1004 </papid>and are reported in table 2.</citsent>
<aftsection>
<nextsent>leave-one-out evaluation was used to form 16 cross-validation folds, one for each document in the corpus.
</nextsent>
<nextsent>using planned, one-tailed pairwise t-test, the gesture features improved performance significantly 38 mark able dist the number of markables between the candidate nps exact match true if the candidate nps have identical surface forms str match true if the candidate nps match after removing articles nonpro match true if the candidate nps are not pronouns and have identical surface forms number match true if the candidate nps agree in number pronoun true if the np is pronoun def np true if the np begins with definite article, e.g. the box?
</nextsent>
<nextsent>dem np true if the np is not pronoun and begins with the word this?
</nextsent>
<nextsent>indef np true if the np begins an indefinite article, e.g. box?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3275">
<title id=" N06-2010.xml">gesture improves coreference resolution </title>
<section> focus dist 727.8.  </section>
<citcontext>
<prevsection>
<prevsent>prosody has been shown to improve performance on several nlp problems, such as topic and sentence segmentation (e.g., (shriberg et al, 2000)).
</prevsent>
<prevsent>we are aware ofno equivalent work showing statistically significant improvement on unconstrained speech using hand gesture features.
</prevsent>
</prevsection>
<citsent citstr=" P03-1070 ">
(nakano et al, 2003) <papid> P03-1070 </papid>shows that body posture predicts turn boundaries, but does not show that these features improve performance beyond text-only system.(chen et al, 2004) shows that gesture may improve sentence segmentation; however, in this study, the improvement afforded by gesture is not statistically significant, and evaluation was performed on subset of their original corpus that was chosen to include only the three speakers who gestured most frequently.</citsent>
<aftsection>
<nextsent>still, this work provides avaluable starting point for the integration of gesture feature into nlp systems.
</nextsent>
<nextsent>we have described how gesture features can be used to improve coreference resolution on corpus of unconstrained speech.
</nextsent>
<nextsent>hand position and hand choice correlate significantly with coreference, explaining this gain in performance.
</nextsent>
<nextsent>we believe this is the first example of hand gesture features improving performance by statistically significant margin on unconstrained speech.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3276">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiments show that unrestricted non-projective parsing gives significant improvement inaccuracy, compared to strictly projective baseline, with up to 35% error reduction, leading to state-of-the-art results for the given datasets.
</prevsent>
<prevsent>moreover, by restricting the class of permissible structures to limited degrees of non-projectivity, the parsing time can be reduced by up to 50% without significant decrease inaccuracy.
</prevsent>
</prevsection>
<citsent citstr=" W02-2016 ">
data-driven dependency parsing has been shown to give accurate and efficient parsing for wide rangeof languages, such as japanese (kudo and matsumoto, 2002), <papid> W02-2016 </papid>english (yamada and matsumoto, 2003), swedish (nivre et al, 2004), <papid> W04-2407 </papid>chinese (cheng et al, 2004), and czech (mcdonald et al, 2005).<papid> H05-1066 </papid></citsent>
<aftsection>
<nextsent>whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order.the most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of strictly projective dependency parser, as in pseudo-projective parsing (nivre and nilsson, 2005), <papid> P05-1013 </papid>corrective modeling (hall and novak, 2005), or approximate non-projective parsing (mcdonald and pereira, 2006).<papid> E06-1011 </papid></nextsent>
<nextsent>and it is rare to find parsers that derive non-projective structures directly, the no table exception being the non-projective spanning tree parser proposed by mcdonald et al (2005).<papid> H05-1066 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3277">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiments show that unrestricted non-projective parsing gives significant improvement inaccuracy, compared to strictly projective baseline, with up to 35% error reduction, leading to state-of-the-art results for the given datasets.
</prevsent>
<prevsent>moreover, by restricting the class of permissible structures to limited degrees of non-projectivity, the parsing time can be reduced by up to 50% without significant decrease inaccuracy.
</prevsent>
</prevsection>
<citsent citstr=" W04-2407 ">
data-driven dependency parsing has been shown to give accurate and efficient parsing for wide rangeof languages, such as japanese (kudo and matsumoto, 2002), <papid> W02-2016 </papid>english (yamada and matsumoto, 2003), swedish (nivre et al, 2004), <papid> W04-2407 </papid>chinese (cheng et al, 2004), and czech (mcdonald et al, 2005).<papid> H05-1066 </papid></citsent>
<aftsection>
<nextsent>whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order.the most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of strictly projective dependency parser, as in pseudo-projective parsing (nivre and nilsson, 2005), <papid> P05-1013 </papid>corrective modeling (hall and novak, 2005), or approximate non-projective parsing (mcdonald and pereira, 2006).<papid> E06-1011 </papid></nextsent>
<nextsent>and it is rare to find parsers that derive non-projective structures directly, the no table exception being the non-projective spanning tree parser proposed by mcdonald et al (2005).<papid> H05-1066 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3278">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiments show that unrestricted non-projective parsing gives significant improvement inaccuracy, compared to strictly projective baseline, with up to 35% error reduction, leading to state-of-the-art results for the given datasets.
</prevsent>
<prevsent>moreover, by restricting the class of permissible structures to limited degrees of non-projectivity, the parsing time can be reduced by up to 50% without significant decrease inaccuracy.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
data-driven dependency parsing has been shown to give accurate and efficient parsing for wide rangeof languages, such as japanese (kudo and matsumoto, 2002), <papid> W02-2016 </papid>english (yamada and matsumoto, 2003), swedish (nivre et al, 2004), <papid> W04-2407 </papid>chinese (cheng et al, 2004), and czech (mcdonald et al, 2005).<papid> H05-1066 </papid></citsent>
<aftsection>
<nextsent>whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order.the most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of strictly projective dependency parser, as in pseudo-projective parsing (nivre and nilsson, 2005), <papid> P05-1013 </papid>corrective modeling (hall and novak, 2005), or approximate non-projective parsing (mcdonald and pereira, 2006).<papid> E06-1011 </papid></nextsent>
<nextsent>and it is rare to find parsers that derive non-projective structures directly, the no table exception being the non-projective spanning tree parser proposed by mcdonald et al (2005).<papid> H05-1066 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3279">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, by restricting the class of permissible structures to limited degrees of non-projectivity, the parsing time can be reduced by up to 50% without significant decrease inaccuracy.
</prevsent>
<prevsent>data-driven dependency parsing has been shown to give accurate and efficient parsing for wide rangeof languages, such as japanese (kudo and matsumoto, 2002), <papid> W02-2016 </papid>english (yamada and matsumoto, 2003), swedish (nivre et al, 2004), <papid> W04-2407 </papid>chinese (cheng et al, 2004), and czech (mcdonald et al, 2005).<papid> H05-1066 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order.the most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of strictly projective dependency parser, as in pseudo-projective parsing (nivre and nilsson, 2005), <papid> P05-1013 </papid>corrective modeling (hall and novak, 2005), or approximate non-projective parsing (mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>and it is rare to find parsers that derive non-projective structures directly, the no table exception being the non-projective spanning tree parser proposed by mcdonald et al (2005).<papid> H05-1066 </papid></nextsent>
<nextsent>there are essentially two arguments that have been advanced against using parsing algorithms that derive non-projective dependency structures directly.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3280">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, by restricting the class of permissible structures to limited degrees of non-projectivity, the parsing time can be reduced by up to 50% without significant decrease inaccuracy.
</prevsent>
<prevsent>data-driven dependency parsing has been shown to give accurate and efficient parsing for wide rangeof languages, such as japanese (kudo and matsumoto, 2002), <papid> W02-2016 </papid>english (yamada and matsumoto, 2003), swedish (nivre et al, 2004), <papid> W04-2407 </papid>chinese (cheng et al, 2004), and czech (mcdonald et al, 2005).<papid> H05-1066 </papid></prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order.the most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of strictly projective dependency parser, as in pseudo-projective parsing (nivre and nilsson, 2005), <papid> P05-1013 </papid>corrective modeling (hall and novak, 2005), or approximate non-projective parsing (mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>and it is rare to find parsers that derive non-projective structures directly, the no table exception being the non-projective spanning tree parser proposed by mcdonald et al (2005).<papid> H05-1066 </papid></nextsent>
<nextsent>there are essentially two arguments that have been advanced against using parsing algorithms that derive non-projective dependency structures directly.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3283">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and it is rare to find parsers that derive non-projective structures directly, the no table exception being the non-projective spanning tree parser proposed by mcdonald et al (2005).<papid> H05-1066 </papid></prevsent>
<prevsent>there are essentially two arguments that have been advanced against using parsing algorithms that derive non-projective dependency structures directly.</prevsent>
</prevsection>
<citsent citstr=" P97-1043 ">
the first is that the added expressivity compromises efficiency, since the parsing problem for agr ammar that allows arbitrary non-projective dependency structures has been shown to benp complete (neuhaus and broker, 1997).<papid> P97-1043 </papid></citsent>
<aftsection>
<nextsent>on the other hand,most data-driven approaches do not relyon grammars, and with suitable factor ization of dependency structures, it is possible to achieve parsing of unrestricted non-projective structures ino(n2) time, as shown by mcdonald et al (2005).<papid> H05-1066 </papid>the second argument against non-projective dependency parsing comes from the observation that, even in languages with free or flexible word order, 396 most dependency structures are either projective orvery nearly projective.</nextsent>
<nextsent>this can be seen by considering data from treebanks, such as the prague dependency treebank of czech (bohmova?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3286">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one way of improving efficiency, and potentially also accuracy, in non-projective dependency parsing is to restrict the search to subclass of mildly non projective?
</prevsent>
<prevsent>structures.
</prevsent>
</prevsection>
<citsent citstr=" E06-1010 ">
nivre (2006) <papid> E06-1010 </papid>defines degrees of non-projectivity in terms of the maximum number of intervening constituents in the projection of syntactic head and shows that limited degrees of non projectivity give much better fit with the linguistic data than strict projectivity, but also enables more efficient processing than unrestricted non-projectivity.</citsent>
<aftsection>
<nextsent>however, the results presented by nivre (2006) <papid> E06-1010 </papid>are all based on oracle parsing, which means that they only provide upper bounds on the accuracy that can be achieved.in this paper, we investigate to what extent constraints on non-projective structures can improve accuracy and efficiency in practical parsing, using treebank-induced classifiers to predict the actions ofa deterministic incremental parser.</nextsent>
<nextsent>the parsing algorithm used belongs to the family of algorithms described by covington (2001), and the classifiers are trained using support vector machines (svm) (vap nik, 1995).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3302">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> l : ? r </section>
<citcontext>
<prevsection>
<prevsent>nivre (2006) <papid> E06-1010 </papid>presents an empirical study, based on data from the prague dependency treebank ofczech (bohmova?</prevsent>
<prevsent>et al, 2003) and the danish dependency treebank (kromann, 2003), showing that more than 99.5% of all sentences occurring in thetwo treebanks have dependency graph with maximum degree of 2; about 98% have maximum degree of 1; but only 77% in the czech data and 85% in the danish data have degree 0 (which is equivalent to assuming projectivity).</prevsent>
</prevsection>
<citsent citstr=" P06-2066 ">
this suggests that limited degrees of non-projectivity may allow parser to capture larger class of naturally occurring syntactic structures, while still constraining the search to proper subclass of all possible structures.1 1alternative notions of mildly non-projective dependency structures are explored in kuhlmann and nivre (2006).<papid> P06-2066 </papid></citsent>
<aftsection>
<nextsent>398 3 parsing algorithm.
</nextsent>
<nextsent>covington (2001) describes parsing strategy for dependency representations that has been known since the 1960s but not presented in the literature.
</nextsent>
<nextsent>the left-to-right (or incremental) version of this strategy can be formulated in the following way: parse(x = (w1, . . .
</nextsent>
<nextsent>, wn)) 1 for = 1 up to 2 for = ? 1 down to 0 3 link(i, j).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3304">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> link(i, j).  </section>
<citcontext>
<prevsection>
<prevsent>with low values of d, we will reduce the number of calls to link(i, j), which will reduce the overall parsing time provided that the time required to compute permissible(i, j, d) is insignificant compared to the time needed for link(i, j).
</prevsent>
<prevsent>this is typically the case in data-driven systems,where link(i, j) requires call to trained classifier, while permissible(i, j, d) only needs access to the partially built graph g.2 4 history-based parsing.
</prevsent>
</prevsection>
<citsent citstr=" H92-1026 ">
history-based parsing uses features of the parsing history to predict the next parser action (black et al,1992).<papid> H92-1026 </papid></citsent>
<aftsection>
<nextsent>in the current setup, this involves using features of the partially built dependency graph and the input = (w1, . . .
</nextsent>
<nextsent>, wn) to predict the outcome of the non deterministic link(i, j) operation.
</nextsent>
<nextsent>given that we use deterministic parsing strategy, this reduces to pure classification problem.let ?(i, j, g) = (1,.
</nextsent>
<nextsent>,m) be feature vector representation of the parser history at the timeof performing link(i, j).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3306">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>these three versions of the non-projective parser are compared to strictly projective parser (d = 0),which uses the same parsing algorithm but only considers projective arcs in both training and testing.3 the experiments are based on treebank data from five languages: the danish dependency treebank3an alternative would have been to train all parsers on non projective data, or restrict the training data for each parser according to its parsing restriction.
</prevsent>
<prevsent>preliminary experiments showed that the setup used here gave the best performance for all parsers involved.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
(kromann, 2003), the alpino treebank of dutch (van der beek et al, 2002), the tiger treebank of german (brants et al, 2002), the flor esta sintactica of portuguese (afonso et al, 2002), and the slovene dependency treebank (dzeroski et al, 2006).4 thedata sets used are the training sets from the conll shared task on multilingual dependency parsing (buchholz and marsi, 2006), <papid> W06-2920 </papid>with 20% of the data reserved for testing using pseudo-random split.</citsent>
<aftsection>
<nextsent>table 1 gives an overview of the five datasets, showing the number of tokens and sentences, the presence of different kinds of linguistic annotation, and the amount of non-projectivity.
</nextsent>
<nextsent>the features used in the history-based model for all languages include the following core set of 20 features, where and are the tokens about to be linked and the context stack is stack of root nodes in g(i+1,j1), added from right to left (i.e., with the top node being closest to i): 1.
</nextsent>
<nextsent>word form: i, j, j+1, h(i)..
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3309">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>on the whole, however, the reduction in parsing time with limited degrees of non-projectivity is substantial, especially considering the very marginal drop inaccuracy.
</prevsent>
<prevsent>in order to compare the performance to the state of the art in dependency parsing, we have retrained the non-projective parser on the entire training dataset for each language and evaluated it on the final test set from the conll-x shared task (buchholzand marsi, 2006).<papid> W06-2920 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-2932 ">
thus, table 4 shows labeled attachment scores, the main evaluation metric used in the shared task, in comparison to the two highest scoring systems from the original evaluation (mcdonald et al, 2006; <papid> W06-2932 </papid>nivre et al, 2006).<papid> W06-2933 </papid></citsent>
<aftsection>
<nextsent>the incremental non-projective parser has the best reported score for danish and outperforms at least one of the other two systems for four languages out of five, although most of the differences are probably too small to be statistically significant.
</nextsent>
<nextsent>but whereas the spanning tree parser of mcdonald et al (2006) <papid> W06-2932 </papid>and the pseudo-projective parser of nivre et al (2006) <papid> W06-2933 </papid>achieve this performance only with special pre- orpost-processing,7 the approach presented here derives labeled non-projective graph in single incremental process and hence at least has the advanta geof simplicity.</nextsent>
<nextsent>moreover, it has better time complexity than the approximate second-order spanning tree parsing of mcdonald et al (2006), <papid> W06-2932 </papid>which has exponential complexity in the worst case (although this does not appear to be problem in practice).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3310">
<title id=" N07-1050.xml">incremental non projective dependency parsing </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>on the whole, however, the reduction in parsing time with limited degrees of non-projectivity is substantial, especially considering the very marginal drop inaccuracy.
</prevsent>
<prevsent>in order to compare the performance to the state of the art in dependency parsing, we have retrained the non-projective parser on the entire training dataset for each language and evaluated it on the final test set from the conll-x shared task (buchholzand marsi, 2006).<papid> W06-2920 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-2933 ">
thus, table 4 shows labeled attachment scores, the main evaluation metric used in the shared task, in comparison to the two highest scoring systems from the original evaluation (mcdonald et al, 2006; <papid> W06-2932 </papid>nivre et al, 2006).<papid> W06-2933 </papid></citsent>
<aftsection>
<nextsent>the incremental non-projective parser has the best reported score for danish and outperforms at least one of the other two systems for four languages out of five, although most of the differences are probably too small to be statistically significant.
</nextsent>
<nextsent>but whereas the spanning tree parser of mcdonald et al (2006) <papid> W06-2932 </papid>and the pseudo-projective parser of nivre et al (2006) <papid> W06-2933 </papid>achieve this performance only with special pre- orpost-processing,7 the approach presented here derives labeled non-projective graph in single incremental process and hence at least has the advanta geof simplicity.</nextsent>
<nextsent>moreover, it has better time complexity than the approximate second-order spanning tree parsing of mcdonald et al (2006), <papid> W06-2932 </papid>which has exponential complexity in the worst case (although this does not appear to be problem in practice).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3320">
<title id=" N06-4003.xml">smart notes implicit labeling of meeting data through user note taking and browsing </title>
<section> automatic meeting understanding.  </section>
<citcontext>
<prevsection>
<prevsent>topic detection and segmentation: we are attempting to automatically detect the topics being discussed at meetings.
</prevsent>
<prevsent>this task consists of two sub tasks: discovering the points in meeting when the topic changes, and then associating descriptive label to the segment between two topic shifts.
</prevsent>
</prevsection>
<citsent citstr=" W06-3404 ">
our current strategy for topic shift detection (banerjee and rudnicky, 2006<papid> W06-3404 </papid>a) is to perform an edge detection using such features as speech activity (who spoke when and for how long), the words that each person spoke, etc. for labeling, we are currently simply associating the agenda item names recorded in the notes with the segments they are most relevant to, as decided by tf.idf matching technique.</citsent>
<aftsection>
<nextsent>topic detection is particularly useful during meeting information retrieval; (banerjee et al, 2005) showed that when users wish to retrieve information from past meetings, they are typically interested in specific discussion topic, as opposed to an entire meeting.
</nextsent>
<nextsent>action item detection: an obvious application of meeting understanding is the automatic discovery and recording of action items as they are discussed during meeting.
</nextsent>
<nextsent>arguably one of the most important outcomes of meeting are the action items decided upon, and automatically recording them could be huge benefit especially to those participants that are likely to not note them down and consequently forget about them later on.meeting participant role detection: each meeting participant plays variety of roles in an institution.
</nextsent>
<nextsent>these roles can be based on their function in the institution (managers, assistants, professors, students, etc), or based on their expertise (speechrecognition experts, facilities experts, etc).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3322">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the learning method has been evaluated on three language pairs, yielding significant improvements over input alignments and three heuristic combination methods.
</prevsent>
<prevsent>the impact of word alignment on mt quality is investigated, using phrase-based mt system.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
word alignment detection of corresponding words between two sentences that are translations of eachotheris usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2003), <papid> N03-1017 </papid>but also has been shown useful for other applications such as construction of bilingual lexicons, word-sensedisambiguation, projection of resources, and cross language information retrieval.</citsent>
<aftsection>
<nextsent>maximum entropy (me) models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation (berger et al, 1996),<papid> J96-1002 </papid>parsing, pos tagging and pp attachment (ratna parkhi, 1998), machine translation (och and ney, 2002), <papid> P02-1038 </papid>and framenet classification (fleischman et al., 2003).<papid> W03-1007 </papid></nextsent>
<nextsent>they have also been used to solve the word alignment problem (garcia-varea et al, 2002; ittycheriah and roukos, 2005; <papid> H05-1012 </papid>liu et al, 2005), <papid> P05-1057 </papid>but sentence-level approach to combining knowledge sources is used rather than word-level approach.this paper describes an approach to combining evidence from alignments generated by existing systems to obtain an alignment that is closer to the true alignment than the individual align ments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3323">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the learning method has been evaluated on three language pairs, yielding significant improvements over input alignments and three heuristic combination methods.
</prevsent>
<prevsent>the impact of word alignment on mt quality is investigated, using phrase-based mt system.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
word alignment detection of corresponding words between two sentences that are translations of eachotheris usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2003), <papid> N03-1017 </papid>but also has been shown useful for other applications such as construction of bilingual lexicons, word-sensedisambiguation, projection of resources, and cross language information retrieval.</citsent>
<aftsection>
<nextsent>maximum entropy (me) models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation (berger et al, 1996),<papid> J96-1002 </papid>parsing, pos tagging and pp attachment (ratna parkhi, 1998), machine translation (och and ney, 2002), <papid> P02-1038 </papid>and framenet classification (fleischman et al., 2003).<papid> W03-1007 </papid></nextsent>
<nextsent>they have also been used to solve the word alignment problem (garcia-varea et al, 2002; ittycheriah and roukos, 2005; <papid> H05-1012 </papid>liu et al, 2005), <papid> P05-1057 </papid>but sentence-level approach to combining knowledge sources is used rather than word-level approach.this paper describes an approach to combining evidence from alignments generated by existing systems to obtain an alignment that is closer to the true alignment than the individual align ments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3324">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the learning method has been evaluated on three language pairs, yielding significant improvements over input alignments and three heuristic combination methods.
</prevsent>
<prevsent>the impact of word alignment on mt quality is investigated, using phrase-based mt system.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
word alignment detection of corresponding words between two sentences that are translations of eachotheris usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2003), <papid> N03-1017 </papid>but also has been shown useful for other applications such as construction of bilingual lexicons, word-sensedisambiguation, projection of resources, and cross language information retrieval.</citsent>
<aftsection>
<nextsent>maximum entropy (me) models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation (berger et al, 1996),<papid> J96-1002 </papid>parsing, pos tagging and pp attachment (ratna parkhi, 1998), machine translation (och and ney, 2002), <papid> P02-1038 </papid>and framenet classification (fleischman et al., 2003).<papid> W03-1007 </papid></nextsent>
<nextsent>they have also been used to solve the word alignment problem (garcia-varea et al, 2002; ittycheriah and roukos, 2005; <papid> H05-1012 </papid>liu et al, 2005), <papid> P05-1057 </papid>but sentence-level approach to combining knowledge sources is used rather than word-level approach.this paper describes an approach to combining evidence from alignments generated by existing systems to obtain an alignment that is closer to the true alignment than the individual align ments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3325">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the impact of word alignment on mt quality is investigated, using phrase-based mt system.
</prevsent>
<prevsent>word alignment detection of corresponding words between two sentences that are translations of eachotheris usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2003), <papid> N03-1017 </papid>but also has been shown useful for other applications such as construction of bilingual lexicons, word-sensedisambiguation, projection of resources, and cross language information retrieval.</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
maximum entropy (me) models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation (berger et al, 1996),<papid> J96-1002 </papid>parsing, pos tagging and pp attachment (ratna parkhi, 1998), machine translation (och and ney, 2002), <papid> P02-1038 </papid>and framenet classification (fleischman et al., 2003).<papid> W03-1007 </papid></citsent>
<aftsection>
<nextsent>they have also been used to solve the word alignment problem (garcia-varea et al, 2002; ittycheriah and roukos, 2005; <papid> H05-1012 </papid>liu et al, 2005), <papid> P05-1057 </papid>but sentence-level approach to combining knowledge sources is used rather than word-level approach.this paper describes an approach to combining evidence from alignments generated by existing systems to obtain an alignment that is closer to the true alignment than the individual align ments.</nextsent>
<nextsent>the alignment-combination approach (called acme) operates at the level of alignment links, rather than at the sentence level (as in previous me approaches).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3326">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the impact of word alignment on mt quality is investigated, using phrase-based mt system.
</prevsent>
<prevsent>word alignment detection of corresponding words between two sentences that are translations of eachotheris usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2003), <papid> N03-1017 </papid>but also has been shown useful for other applications such as construction of bilingual lexicons, word-sensedisambiguation, projection of resources, and cross language information retrieval.</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
maximum entropy (me) models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation (berger et al, 1996),<papid> J96-1002 </papid>parsing, pos tagging and pp attachment (ratna parkhi, 1998), machine translation (och and ney, 2002), <papid> P02-1038 </papid>and framenet classification (fleischman et al., 2003).<papid> W03-1007 </papid></citsent>
<aftsection>
<nextsent>they have also been used to solve the word alignment problem (garcia-varea et al, 2002; ittycheriah and roukos, 2005; <papid> H05-1012 </papid>liu et al, 2005), <papid> P05-1057 </papid>but sentence-level approach to combining knowledge sources is used rather than word-level approach.this paper describes an approach to combining evidence from alignments generated by existing systems to obtain an alignment that is closer to the true alignment than the individual align ments.</nextsent>
<nextsent>the alignment-combination approach (called acme) operates at the level of alignment links, rather than at the sentence level (as in previous me approaches).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3327">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the impact of word alignment on mt quality is investigated, using phrase-based mt system.
</prevsent>
<prevsent>word alignment detection of corresponding words between two sentences that are translations of eachotheris usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2003), <papid> N03-1017 </papid>but also has been shown useful for other applications such as construction of bilingual lexicons, word-sensedisambiguation, projection of resources, and cross language information retrieval.</prevsent>
</prevsection>
<citsent citstr=" W03-1007 ">
maximum entropy (me) models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation (berger et al, 1996),<papid> J96-1002 </papid>parsing, pos tagging and pp attachment (ratna parkhi, 1998), machine translation (och and ney, 2002), <papid> P02-1038 </papid>and framenet classification (fleischman et al., 2003).<papid> W03-1007 </papid></citsent>
<aftsection>
<nextsent>they have also been used to solve the word alignment problem (garcia-varea et al, 2002; ittycheriah and roukos, 2005; <papid> H05-1012 </papid>liu et al, 2005), <papid> P05-1057 </papid>but sentence-level approach to combining knowledge sources is used rather than word-level approach.this paper describes an approach to combining evidence from alignments generated by existing systems to obtain an alignment that is closer to the true alignment than the individual align ments.</nextsent>
<nextsent>the alignment-combination approach (called acme) operates at the level of alignment links, rather than at the sentence level (as in previous me approaches).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3328">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word alignment detection of corresponding words between two sentences that are translations of eachotheris usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2003), <papid> N03-1017 </papid>but also has been shown useful for other applications such as construction of bilingual lexicons, word-sensedisambiguation, projection of resources, and cross language information retrieval.</prevsent>
<prevsent>maximum entropy (me) models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation (berger et al, 1996),<papid> J96-1002 </papid>parsing, pos tagging and pp attachment (ratna parkhi, 1998), machine translation (och and ney, 2002), <papid> P02-1038 </papid>and framenet classification (fleischman et al., 2003).<papid> W03-1007 </papid></prevsent>
</prevsection>
<citsent citstr=" H05-1012 ">
they have also been used to solve the word alignment problem (garcia-varea et al, 2002; ittycheriah and roukos, 2005; <papid> H05-1012 </papid>liu et al, 2005), <papid> P05-1057 </papid>but sentence-level approach to combining knowledge sources is used rather than word-level approach.this paper describes an approach to combining evidence from alignments generated by existing systems to obtain an alignment that is closer to the true alignment than the individual align ments.</citsent>
<aftsection>
<nextsent>the alignment-combination approach (called acme) operates at the level of alignment links, rather than at the sentence level (as in previous me approaches).
</nextsent>
<nextsent>acme uses me to decide whether to include/exclude particular alignment link basedon feature functions that are extracted from the in put alignments and linguistic features of the words.
</nextsent>
<nextsent>since alignment combination relies on evidence from existing alignments, we focus on alignment links that exist in at least one input alignment.
</nextsent>
<nextsent>an important challenge in this approach is the selection of appropriate links when two align ers make different alignment choices.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3329">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word alignment detection of corresponding words between two sentences that are translations of eachotheris usually an intermediate step of statistical machine translation (mt) (brown et al, 1993; <papid> J93-2003 </papid>och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2003), <papid> N03-1017 </papid>but also has been shown useful for other applications such as construction of bilingual lexicons, word-sensedisambiguation, projection of resources, and cross language information retrieval.</prevsent>
<prevsent>maximum entropy (me) models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation (berger et al, 1996),<papid> J96-1002 </papid>parsing, pos tagging and pp attachment (ratna parkhi, 1998), machine translation (och and ney, 2002), <papid> P02-1038 </papid>and framenet classification (fleischman et al., 2003).<papid> W03-1007 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1057 ">
they have also been used to solve the word alignment problem (garcia-varea et al, 2002; ittycheriah and roukos, 2005; <papid> H05-1012 </papid>liu et al, 2005), <papid> P05-1057 </papid>but sentence-level approach to combining knowledge sources is used rather than word-level approach.this paper describes an approach to combining evidence from alignments generated by existing systems to obtain an alignment that is closer to the true alignment than the individual align ments.</citsent>
<aftsection>
<nextsent>the alignment-combination approach (called acme) operates at the level of alignment links, rather than at the sentence level (as in previous me approaches).
</nextsent>
<nextsent>acme uses me to decide whether to include/exclude particular alignment link basedon feature functions that are extracted from the in put alignments and linguistic features of the words.
</nextsent>
<nextsent>since alignment combination relies on evidence from existing alignments, we focus on alignment links that exist in at least one input alignment.
</nextsent>
<nextsent>an important challenge in this approach is the selection of appropriate links when two align ers make different alignment choices.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3331">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> monotonicity (mon): the absolute difference.  </section>
<citcontext>
<prevsection>
<prevsent>metrics the alignment combination techniques are evaluated in this paper using data from three language pairs, as shown in table 2.
</prevsent>
<prevsent>lang # of # words source pair sents (en/fl) en-ch 491 13k/13k nist mteval 022 en-ar 450 11k/13k nist mteval 033 en-ro 248 5.5k/5.5k hlt workshop 034 table 2: data used for combination experiments.input alignments are generated using two existing word alignment systems: giza++ (och, 2000) 1in table 1, nc corresponds to the set of (i, j)s neighbors that exist in the alignment ak, and ft represents the set of words that ei (or fj) is aligned to.
</prevsent>
</prevsection>
<citsent citstr=" H05-1009 ">
2from (ayan et al, 2005).<papid> H05-1009 </papid></citsent>
<aftsection>
<nextsent>3from (ittycheriah and roukos, 2005).<papid> H05-1012 </papid></nextsent>
<nextsent>4from (mihalcea and pedersen, 2003).<papid> W03-0301 </papid>and sahmm (lopez and resnik, 2005).<papid> W05-0812 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3334">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> monotonicity (mon): the absolute difference.  </section>
<citcontext>
<prevsection>
<prevsent>2from (ayan et al, 2005).<papid> H05-1009 </papid></prevsent>
<prevsent>3from (ittycheriah and roukos, 2005).<papid> H05-1012 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
4from (mihalcea and pedersen, 2003).<papid> W03-0301 </papid>and sahmm (lopez and resnik, 2005).<papid> W05-0812 </papid></citsent>
<aftsection>
<nextsent>both systems are run in two different directions with default configurations.
</nextsent>
<nextsent>we indicate the two directions using the notation aligner(en ? fl) and aligner(fl ? en), where en is english, fl is either chinese (ch), arabic (ar), or romanian (ro).
</nextsent>
<nextsent>to train both systems, additional data was used for the three language pairs: 107k english-chinese sentence pairs (4.1m/3.3m english/chinese words);44k english-arabic sentence pairs (1.4m/1m english/arabic words); 48k english-romanian sentence pairs (1m/1m english/romanian words).5pos tags were generated using the mxpost tagger (ratnaparkhi, 1998).
</nextsent>
<nextsent>pos tagger for english was trained on sections 0-18 of the penn treebank wall street journal corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3335">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> monotonicity (mon): the absolute difference.  </section>
<citcontext>
<prevsection>
<prevsent>2from (ayan et al, 2005).<papid> H05-1009 </papid></prevsent>
<prevsent>3from (ittycheriah and roukos, 2005).<papid> H05-1012 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-0812 ">
4from (mihalcea and pedersen, 2003).<papid> W03-0301 </papid>and sahmm (lopez and resnik, 2005).<papid> W05-0812 </papid></citsent>
<aftsection>
<nextsent>both systems are run in two different directions with default configurations.
</nextsent>
<nextsent>we indicate the two directions using the notation aligner(en ? fl) and aligner(fl ? en), where en is english, fl is either chinese (ch), arabic (ar), or romanian (ro).
</nextsent>
<nextsent>to train both systems, additional data was used for the three language pairs: 107k english-chinese sentence pairs (4.1m/3.3m english/chinese words);44k english-arabic sentence pairs (1.4m/1m english/arabic words); 48k english-romanian sentence pairs (1m/1m english/romanian words).5pos tags were generated using the mxpost tagger (ratnaparkhi, 1998).
</nextsent>
<nextsent>pos tagger for english was trained on sections 0-18 of the penn treebank wall street journal corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3338">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> monotonicity (mon): the absolute difference.  </section>
<citcontext>
<prevsection>
<prevsent>the input alignments were generated using giza++ and sahmm on 107k (44k) sentence pairs for chinese (arabic).
</prevsent>
<prevsent>acme (with english pos partitioning) combines alignments using model parameters learned from the corresponding manually aligned data.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
mt output is evaluated using the standard mt evaluation metric bleu (papineni et al., 2002).<papid> P02-1040 </papid>10 table 8 presents the bleu scores on10we used the nist script (version 11a) with its default set 101 figure 2: precision and recall scores for giza++ and acme using 2 and 4 input alignments.</citsent>
<aftsection>
<nextsent>mteval03 data for 5 different pharaoh runs, one for each alignment.
</nextsent>
<nextsent>the parameters of the mt system were optimized on mteval02 data using minimum error rate training (och, 2003).<papid> P03-1021 </papid>for the language model, the sri language modeling toolkit was used to train trigram model with modified kneser-ney smoothing on 155m words of english newswire text, mostly from the xinhua portion of the gigaword corpus.</nextsent>
<nextsent>during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3339">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> monotonicity (mon): the absolute difference.  </section>
<citcontext>
<prevsection>
<prevsent>mt output is evaluated using the standard mt evaluation metric bleu (papineni et al., 2002).<papid> P02-1040 </papid>10 table 8 presents the bleu scores on10we used the nist script (version 11a) with its default set 101 figure 2: precision and recall scores for giza++ and acme using 2 and 4 input alignments.</prevsent>
<prevsent>mteval03 data for 5 different pharaoh runs, one for each alignment.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the parameters of the mt system were optimized on mteval02 data using minimum error rate training (och, 2003).<papid> P03-1021 </papid>for the language model, the sri language modeling toolkit was used to train trigram model with modified kneser-ney smoothing on 155m words of english newswire text, mostly from the xinhua portion of the gigaword corpus.</citsent>
<aftsection>
<nextsent>during decoding, the number of english phrases per fl phrase was limited to 100 and the distortion of phrases was limited by 4.
</nextsent>
<nextsent>based on the observations in (koehn et al., 2003), <papid> N03-1017 </papid>we also limited the phrase length to 3 for computational reasons.</nextsent>
<nextsent>alignment chinese arabic giza++(union) 22.66 41.72 giza++(gdf) 23.79 43.82 giza++(int) 23.97 42.76 acme[2] 25.20 44.94 acme[4] 25.59 45.54 table 8: evaluation of pharaoh with different initial alignments using bleu (in percentages) for both languages, acme[2] and acme[4] outperform the other three alignment combination techniques.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3345">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>significant improvements are reported using this approach but the need for large manually aligned data is bottleneck.
</prevsent>
<prevsent>an alternative me approach models alignment directly as log-linear combination of feature functions (liu et al., 2005).<papid> P05-1057 </papid></prevsent>
</prevsection>
<citsent citstr=" H05-1011 ">
moore (2005) <papid> H05-1011 </papid>and taskar et al (2005) <papid> H05-1010 </papid>represent alignments with several feature functions that are then combined in weighted sum to model word alignments.</citsent>
<aftsection>
<nextsent>once confidence score is assigned to all links, non-trivial search is invoked to find the best alignment using the scores associated with the links.
</nextsent>
<nextsent>the major difference between these approaches and that of acme is that we use the memodel to predict the correct class for each alignment link independently using outputs of existing alignment systems, instead of generating them from scratch at the level of the whole sentence, thus eliminating the need for an exhaustive search over all possible alignments, i.e., previous approaches work globally while acme is localized model.
</nextsent>
<nextsent>a discussion of these two contrasting approaches can be found in (tillmann and zhang, 2005).<papid> P05-1069 </papid>a recent attempt to combine outputs of different alignments views the combination problem as classifier ensemble in the neural network framework 102 (ayan et al, 2005).<papid> H05-1009 </papid></nextsent>
<nextsent>however, this method is subject to the unpredictability of random network initialization, whereas acme is guaranteed to find the model that maximizes the likelihood of training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3346">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>significant improvements are reported using this approach but the need for large manually aligned data is bottleneck.
</prevsent>
<prevsent>an alternative me approach models alignment directly as log-linear combination of feature functions (liu et al., 2005).<papid> P05-1057 </papid></prevsent>
</prevsection>
<citsent citstr=" H05-1010 ">
moore (2005) <papid> H05-1011 </papid>and taskar et al (2005) <papid> H05-1010 </papid>represent alignments with several feature functions that are then combined in weighted sum to model word alignments.</citsent>
<aftsection>
<nextsent>once confidence score is assigned to all links, non-trivial search is invoked to find the best alignment using the scores associated with the links.
</nextsent>
<nextsent>the major difference between these approaches and that of acme is that we use the memodel to predict the correct class for each alignment link independently using outputs of existing alignment systems, instead of generating them from scratch at the level of the whole sentence, thus eliminating the need for an exhaustive search over all possible alignments, i.e., previous approaches work globally while acme is localized model.
</nextsent>
<nextsent>a discussion of these two contrasting approaches can be found in (tillmann and zhang, 2005).<papid> P05-1069 </papid>a recent attempt to combine outputs of different alignments views the combination problem as classifier ensemble in the neural network framework 102 (ayan et al, 2005).<papid> H05-1009 </papid></nextsent>
<nextsent>however, this method is subject to the unpredictability of random network initialization, whereas acme is guaranteed to find the model that maximizes the likelihood of training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3347">
<title id=" N06-1013.xml">a maximum entropy approach to combining word alignments </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>once confidence score is assigned to all links, non-trivial search is invoked to find the best alignment using the scores associated with the links.
</prevsent>
<prevsent>the major difference between these approaches and that of acme is that we use the memodel to predict the correct class for each alignment link independently using outputs of existing alignment systems, instead of generating them from scratch at the level of the whole sentence, thus eliminating the need for an exhaustive search over all possible alignments, i.e., previous approaches work globally while acme is localized model.
</prevsent>
</prevsection>
<citsent citstr=" P05-1069 ">
a discussion of these two contrasting approaches can be found in (tillmann and zhang, 2005).<papid> P05-1069 </papid>a recent attempt to combine outputs of different alignments views the combination problem as classifier ensemble in the neural network framework 102 (ayan et al, 2005).<papid> H05-1009 </papid></citsent>
<aftsection>
<nextsent>however, this method is subject to the unpredictability of random network initialization, whereas acme is guaranteed to find the model that maximizes the likelihood of training data.
</nextsent>
<nextsent>we presented new approach, acme, to combining the outputs of different word alignment systems by reducing the combination problem to the level of alignment links and using maximum entropy model to learn whether particular alignment link is included in the final alignment.
</nextsent>
<nextsent>our results indicate that acme yields significant relative error reduction over the input alignment sand their heuristic-based combinations on three different language pairs.
</nextsent>
<nextsent>moreover, acme provides similar relative improvements for different sizes of training data for the input alignment systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3350">
<title id=" N04-1014.xml">training tree transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many conceptual tools exist, such as viterbi decoding (viterbi, 1967) and forward-backward training (baum and eagon, 1967), as well as generic software toolkits.
</prevsent>
<prevsent>moreover, surprising variety of problems are attack able with fsts, from part of-speech tagging to letter-to-sound conversion to name transliteration.however, language problems like machine translation break this mold, because they involve massive reordering of symbols, and because the transformation processes seem sensitive to hierarchical tree structure.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
recently, specific probabilistic tree-based models have been proposed not only for machine translation (wu, 1997; <papid> J97-3002 </papid>alshawi, bangalore, and douglas, 2000; yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003), <papid> P03-2041 </papid>but also forthis work was supported by darpa contract f49620-00 1-0337 and arda contract mda904-02-c-0450.summarization (knight and marcu, 2002), paraphrasing (pang, knight, and marcu, 2003), natural language generation (langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore andrambow, 2000; <papid> C00-1007 </papid>corston-oliver et al, 2002), and language modeling (baker, 1979; lari and young, 1990; collins, 1997; <papid> P97-1003 </papid>chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>it is useful to understand generic algorithms that may support all these tasks and more.
</nextsent>
<nextsent>(rounds, 1970) and (thatcher, 1970) independently introduced tree transducers as generalization of fsts.
</nextsent>
<nextsent>rounds was motivated by natural language.
</nextsent>
<nextsent>the rounds tree transducer is very similar to left-to-right fst, except that it works top-down, pursuing subtrees in parallel, with each subtree transformed depending only on its own passed-down state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3351">
<title id=" N04-1014.xml">training tree transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many conceptual tools exist, such as viterbi decoding (viterbi, 1967) and forward-backward training (baum and eagon, 1967), as well as generic software toolkits.
</prevsent>
<prevsent>moreover, surprising variety of problems are attack able with fsts, from part of-speech tagging to letter-to-sound conversion to name transliteration.however, language problems like machine translation break this mold, because they involve massive reordering of symbols, and because the transformation processes seem sensitive to hierarchical tree structure.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
recently, specific probabilistic tree-based models have been proposed not only for machine translation (wu, 1997; <papid> J97-3002 </papid>alshawi, bangalore, and douglas, 2000; yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003), <papid> P03-2041 </papid>but also forthis work was supported by darpa contract f49620-00 1-0337 and arda contract mda904-02-c-0450.summarization (knight and marcu, 2002), paraphrasing (pang, knight, and marcu, 2003), natural language generation (langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore andrambow, 2000; <papid> C00-1007 </papid>corston-oliver et al, 2002), and language modeling (baker, 1979; lari and young, 1990; collins, 1997; <papid> P97-1003 </papid>chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>it is useful to understand generic algorithms that may support all these tasks and more.
</nextsent>
<nextsent>(rounds, 1970) and (thatcher, 1970) independently introduced tree transducers as generalization of fsts.
</nextsent>
<nextsent>rounds was motivated by natural language.
</nextsent>
<nextsent>the rounds tree transducer is very similar to left-to-right fst, except that it works top-down, pursuing subtrees in parallel, with each subtree transformed depending only on its own passed-down state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3353">
<title id=" N04-1014.xml">training tree transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many conceptual tools exist, such as viterbi decoding (viterbi, 1967) and forward-backward training (baum and eagon, 1967), as well as generic software toolkits.
</prevsent>
<prevsent>moreover, surprising variety of problems are attack able with fsts, from part of-speech tagging to letter-to-sound conversion to name transliteration.however, language problems like machine translation break this mold, because they involve massive reordering of symbols, and because the transformation processes seem sensitive to hierarchical tree structure.
</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
recently, specific probabilistic tree-based models have been proposed not only for machine translation (wu, 1997; <papid> J97-3002 </papid>alshawi, bangalore, and douglas, 2000; yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003), <papid> P03-2041 </papid>but also forthis work was supported by darpa contract f49620-00 1-0337 and arda contract mda904-02-c-0450.summarization (knight and marcu, 2002), paraphrasing (pang, knight, and marcu, 2003), natural language generation (langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore andrambow, 2000; <papid> C00-1007 </papid>corston-oliver et al, 2002), and language modeling (baker, 1979; lari and young, 1990; collins, 1997; <papid> P97-1003 </papid>chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>it is useful to understand generic algorithms that may support all these tasks and more.
</nextsent>
<nextsent>(rounds, 1970) and (thatcher, 1970) independently introduced tree transducers as generalization of fsts.
</nextsent>
<nextsent>rounds was motivated by natural language.
</nextsent>
<nextsent>the rounds tree transducer is very similar to left-to-right fst, except that it works top-down, pursuing subtrees in parallel, with each subtree transformed depending only on its own passed-down state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3354">
<title id=" N04-1014.xml">training tree transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many conceptual tools exist, such as viterbi decoding (viterbi, 1967) and forward-backward training (baum and eagon, 1967), as well as generic software toolkits.
</prevsent>
<prevsent>moreover, surprising variety of problems are attack able with fsts, from part of-speech tagging to letter-to-sound conversion to name transliteration.however, language problems like machine translation break this mold, because they involve massive reordering of symbols, and because the transformation processes seem sensitive to hierarchical tree structure.
</prevsent>
</prevsection>
<citsent citstr=" P03-2041 ">
recently, specific probabilistic tree-based models have been proposed not only for machine translation (wu, 1997; <papid> J97-3002 </papid>alshawi, bangalore, and douglas, 2000; yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003), <papid> P03-2041 </papid>but also forthis work was supported by darpa contract f49620-00 1-0337 and arda contract mda904-02-c-0450.summarization (knight and marcu, 2002), paraphrasing (pang, knight, and marcu, 2003), natural language generation (langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore andrambow, 2000; <papid> C00-1007 </papid>corston-oliver et al, 2002), and language modeling (baker, 1979; lari and young, 1990; collins, 1997; <papid> P97-1003 </papid>chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>it is useful to understand generic algorithms that may support all these tasks and more.
</nextsent>
<nextsent>(rounds, 1970) and (thatcher, 1970) independently introduced tree transducers as generalization of fsts.
</nextsent>
<nextsent>rounds was motivated by natural language.
</nextsent>
<nextsent>the rounds tree transducer is very similar to left-to-right fst, except that it works top-down, pursuing subtrees in parallel, with each subtree transformed depending only on its own passed-down state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3355">
<title id=" N04-1014.xml">training tree transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many conceptual tools exist, such as viterbi decoding (viterbi, 1967) and forward-backward training (baum and eagon, 1967), as well as generic software toolkits.
</prevsent>
<prevsent>moreover, surprising variety of problems are attack able with fsts, from part of-speech tagging to letter-to-sound conversion to name transliteration.however, language problems like machine translation break this mold, because they involve massive reordering of symbols, and because the transformation processes seem sensitive to hierarchical tree structure.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
recently, specific probabilistic tree-based models have been proposed not only for machine translation (wu, 1997; <papid> J97-3002 </papid>alshawi, bangalore, and douglas, 2000; yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003), <papid> P03-2041 </papid>but also forthis work was supported by darpa contract f49620-00 1-0337 and arda contract mda904-02-c-0450.summarization (knight and marcu, 2002), paraphrasing (pang, knight, and marcu, 2003), natural language generation (langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore andrambow, 2000; <papid> C00-1007 </papid>corston-oliver et al, 2002), and language modeling (baker, 1979; lari and young, 1990; collins, 1997; <papid> P97-1003 </papid>chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>it is useful to understand generic algorithms that may support all these tasks and more.
</nextsent>
<nextsent>(rounds, 1970) and (thatcher, 1970) independently introduced tree transducers as generalization of fsts.
</nextsent>
<nextsent>rounds was motivated by natural language.
</nextsent>
<nextsent>the rounds tree transducer is very similar to left-to-right fst, except that it works top-down, pursuing subtrees in parallel, with each subtree transformed depending only on its own passed-down state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3356">
<title id=" N04-1014.xml">training tree transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many conceptual tools exist, such as viterbi decoding (viterbi, 1967) and forward-backward training (baum and eagon, 1967), as well as generic software toolkits.
</prevsent>
<prevsent>moreover, surprising variety of problems are attack able with fsts, from part of-speech tagging to letter-to-sound conversion to name transliteration.however, language problems like machine translation break this mold, because they involve massive reordering of symbols, and because the transformation processes seem sensitive to hierarchical tree structure.
</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
recently, specific probabilistic tree-based models have been proposed not only for machine translation (wu, 1997; <papid> J97-3002 </papid>alshawi, bangalore, and douglas, 2000; yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003), <papid> P03-2041 </papid>but also forthis work was supported by darpa contract f49620-00 1-0337 and arda contract mda904-02-c-0450.summarization (knight and marcu, 2002), paraphrasing (pang, knight, and marcu, 2003), natural language generation (langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore andrambow, 2000; <papid> C00-1007 </papid>corston-oliver et al, 2002), and language modeling (baker, 1979; lari and young, 1990; collins, 1997; <papid> P97-1003 </papid>chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>it is useful to understand generic algorithms that may support all these tasks and more.
</nextsent>
<nextsent>(rounds, 1970) and (thatcher, 1970) independently introduced tree transducers as generalization of fsts.
</nextsent>
<nextsent>rounds was motivated by natural language.
</nextsent>
<nextsent>the rounds tree transducer is very similar to left-to-right fst, except that it works top-down, pursuing subtrees in parallel, with each subtree transformed depending only on its own passed-down state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3357">
<title id=" N04-1014.xml">training tree transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many conceptual tools exist, such as viterbi decoding (viterbi, 1967) and forward-backward training (baum and eagon, 1967), as well as generic software toolkits.
</prevsent>
<prevsent>moreover, surprising variety of problems are attack able with fsts, from part of-speech tagging to letter-to-sound conversion to name transliteration.however, language problems like machine translation break this mold, because they involve massive reordering of symbols, and because the transformation processes seem sensitive to hierarchical tree structure.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
recently, specific probabilistic tree-based models have been proposed not only for machine translation (wu, 1997; <papid> J97-3002 </papid>alshawi, bangalore, and douglas, 2000; yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003), <papid> P03-2041 </papid>but also forthis work was supported by darpa contract f49620-00 1-0337 and arda contract mda904-02-c-0450.summarization (knight and marcu, 2002), paraphrasing (pang, knight, and marcu, 2003), natural language generation (langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore andrambow, 2000; <papid> C00-1007 </papid>corston-oliver et al, 2002), and language modeling (baker, 1979; lari and young, 1990; collins, 1997; <papid> P97-1003 </papid>chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>it is useful to understand generic algorithms that may support all these tasks and more.
</nextsent>
<nextsent>(rounds, 1970) and (thatcher, 1970) independently introduced tree transducers as generalization of fsts.
</nextsent>
<nextsent>rounds was motivated by natural language.
</nextsent>
<nextsent>the rounds tree transducer is very similar to left-to-right fst, except that it works top-down, pursuing subtrees in parallel, with each subtree transformed depending only on its own passed-down state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3358">
<title id=" N04-1014.xml">training tree transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many conceptual tools exist, such as viterbi decoding (viterbi, 1967) and forward-backward training (baum and eagon, 1967), as well as generic software toolkits.
</prevsent>
<prevsent>moreover, surprising variety of problems are attack able with fsts, from part of-speech tagging to letter-to-sound conversion to name transliteration.however, language problems like machine translation break this mold, because they involve massive reordering of symbols, and because the transformation processes seem sensitive to hierarchical tree structure.
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
recently, specific probabilistic tree-based models have been proposed not only for machine translation (wu, 1997; <papid> J97-3002 </papid>alshawi, bangalore, and douglas, 2000; yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003), <papid> P03-2041 </papid>but also forthis work was supported by darpa contract f49620-00 1-0337 and arda contract mda904-02-c-0450.summarization (knight and marcu, 2002), paraphrasing (pang, knight, and marcu, 2003), natural language generation (langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore andrambow, 2000; <papid> C00-1007 </papid>corston-oliver et al, 2002), and language modeling (baker, 1979; lari and young, 1990; collins, 1997; <papid> P97-1003 </papid>chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>it is useful to understand generic algorithms that may support all these tasks and more.
</nextsent>
<nextsent>(rounds, 1970) and (thatcher, 1970) independently introduced tree transducers as generalization of fsts.
</nextsent>
<nextsent>rounds was motivated by natural language.
</nextsent>
<nextsent>the rounds tree transducer is very similar to left-to-right fst, except that it works top-down, pursuing subtrees in parallel, with each subtree transformed depending only on its own passed-down state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3359">
<title id=" N04-1014.xml">training tree transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many conceptual tools exist, such as viterbi decoding (viterbi, 1967) and forward-backward training (baum and eagon, 1967), as well as generic software toolkits.
</prevsent>
<prevsent>moreover, surprising variety of problems are attack able with fsts, from part of-speech tagging to letter-to-sound conversion to name transliteration.however, language problems like machine translation break this mold, because they involve massive reordering of symbols, and because the transformation processes seem sensitive to hierarchical tree structure.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
recently, specific probabilistic tree-based models have been proposed not only for machine translation (wu, 1997; <papid> J97-3002 </papid>alshawi, bangalore, and douglas, 2000; yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003), <papid> P03-2041 </papid>but also forthis work was supported by darpa contract f49620-00 1-0337 and arda contract mda904-02-c-0450.summarization (knight and marcu, 2002), paraphrasing (pang, knight, and marcu, 2003), natural language generation (langkilde and knight, 1998; <papid> P98-1116 </papid>bangalore andrambow, 2000; <papid> C00-1007 </papid>corston-oliver et al, 2002), and language modeling (baker, 1979; lari and young, 1990; collins, 1997; <papid> P97-1003 </papid>chelba and jelinek, 2000; charniak, 2001; <papid> P01-1017 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>it is useful to understand generic algorithms that may support all these tasks and more.
</nextsent>
<nextsent>(rounds, 1970) and (thatcher, 1970) independently introduced tree transducers as generalization of fsts.
</nextsent>
<nextsent>rounds was motivated by natural language.
</nextsent>
<nextsent>the rounds tree transducer is very similar to left-to-right fst, except that it works top-down, pursuing subtrees in parallel, with each subtree transformed depending only on its own passed-down state.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3360">
<title id=" N04-1014.xml">training tree transducers </title>
<section> regular tree grammars.  </section>
<citcontext>
<prevsection>
<prevsent>the weighted regular tree language produced by is lg ? {(t, w) ? t? ? r+ |wg(t) = w}.
</prevsent>
<prevsent>for every weighted context-free grammar, there is an equivalent wrtg that produces its weighted derivation trees with yields being the string produced, and the yields of regular tree grammars are context free string languages (gcseg and steinby, 1984).
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
what is sometimes called forest in natural language generation (langkilde, 2000; <papid> A00-2023 </papid>nederhof and satta, 2002) <papid> P02-1015 </papid>is finite wrtg without loops, i.e., ? n(n, ()) (t, h) =?</citsent>
<aftsection>
<nextsent>pathst({n}) = ?.
</nextsent>
<nextsent>regular tree languages are strictly contained in tree sets of tree adjoining grammars (joshi and schabes, 1997).
</nextsent>
<nextsent>section 1 informally described the root-to-frontier transducer class r. we saw that allows, by use of states,finite look ahead and arbitrary rearrangement of non sibling input subtrees removed by finite distance.
</nextsent>
<nextsent>however, it is often easier to write rules that explicitly represent such look ahead and movement, relieving the burden on the user to produce the requisite intermediary rule sand states.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3361">
<title id=" N04-1014.xml">training tree transducers </title>
<section> regular tree grammars.  </section>
<citcontext>
<prevsection>
<prevsent>the weighted regular tree language produced by is lg ? {(t, w) ? t? ? r+ |wg(t) = w}.
</prevsent>
<prevsent>for every weighted context-free grammar, there is an equivalent wrtg that produces its weighted derivation trees with yields being the string produced, and the yields of regular tree grammars are context free string languages (gcseg and steinby, 1984).
</prevsent>
</prevsection>
<citsent citstr=" P02-1015 ">
what is sometimes called forest in natural language generation (langkilde, 2000; <papid> A00-2023 </papid>nederhof and satta, 2002) <papid> P02-1015 </papid>is finite wrtg without loops, i.e., ? n(n, ()) (t, h) =?</citsent>
<aftsection>
<nextsent>pathst({n}) = ?.
</nextsent>
<nextsent>regular tree languages are strictly contained in tree sets of tree adjoining grammars (joshi and schabes, 1997).
</nextsent>
<nextsent>section 1 informally described the root-to-frontier transducer class r. we saw that allows, by use of states,finite look ahead and arbitrary rearrangement of non sibling input subtrees removed by finite distance.
</nextsent>
<nextsent>however, it is often easier to write rules that explicitly represent such look ahead and movement, relieving the burden on the user to produce the requisite intermediary rule sand states.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3367">
<title id=" N04-1014.xml">training tree transducers </title>
<section> example.  </section>
<citcontext>
<prevsection>
<prevsent>and we have production for every pair of co-occurring english and japanese words: - car ? kuruma - car ? wa - car ? *e* this follows (yamada and knight, 2001) <papid> P01-1067 </papid>in also allowing english words to disappear, or translate to epsilon.every production in the xrs transducer has an associated weight and corresponds to exactly one of the model parameters.</prevsent>
<prevsent>there are several benefits to this xrs formulation.</prevsent>
</prevsection>
<citsent citstr=" N03-1019 ">
first, it clarifies the model, in the same way that (knightand al-onaizan, 1998; kumar and byrne, 2003) <papid> N03-1019 </papid>elucidate other machine translation models in easily-grasped fst terms.</citsent>
<aftsection>
<nextsent>second, the model can be trained with generic, off-the-shelf tools versus the alternative of working out model-specific re-estimation formulae and implementing custom training software.
</nextsent>
<nextsent>third, we can easily extend the model in interesting ways.
</nextsent>
<nextsent>for example, we can add productions for multi-level and lexical re-ordering: - np(x0:np, pp(in(of), x1:np)) ? x1, no, x0 we can add productions for phrasal translations: - np(jj(big), nn(cars)) ? ooki, kuruma this can now include crucial non-constituent phrasal translations: - s(np(pro(there),vp(vb(are), x0:np) ? x0, ga, arimasu we can also eliminate many epsilon word-translation rules in favor of more syntactically-controlled ones, e.g.: - np(dt(the),x0:nn) ? x0 we can make many such changes without modifying the training procedure, as long as we stick to tree automata.
</nextsent>
<nextsent>tree substitution grammars or tsg (schabes, 1990)are equivalent to regular tree grammars.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3369">
<title id=" N06-3005.xml">identifying perspectives at the document and sentence levels using statistical models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>identifying the perspective from which document is written is subtask in the growing area of automatic opinion recognition and extraction.
</prevsent>
<prevsent>subjective language is used to express opinions, emotions, and sentiments.
</prevsent>
</prevsection>
<citsent citstr=" J04-3002 ">
so far research in automatic opinion recognition has primarily addressed learning subjective language (wiebe et al, 2004; <papid> J04-3002 </papid>riloff et al,2003; <papid> W03-0404 </papid>riloff and wiebe, 2003), <papid> W03-1014 </papid>identifying opinionated documents (yu and hatzivassiloglou, 2003) <papid> W03-1017 </papid>and sentences (yu and hatzivassiloglou, 2003; <papid> W03-1017 </papid>riloff etal., 2003; <papid> W03-0404 </papid>riloff and wiebe, 2003), <papid> W03-1014 </papid>and discriminating between positive and negative language (yu and hatzivassiloglou, 2003; <papid> W03-1017 </papid>turney and littman, 2003; pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; nasukawa and yi, 2003; morinaga et al, 2002).</citsent>
<aftsection>
<nextsent>although by its very nature we expect much ofthe language of presenting perspective or point of-view to be subjective, labeling document or sentence as subjective is not enough to identify the perspective from which it is written.
</nextsent>
<nextsent>moreover, the ideology and beliefs authors possess are often expressed in ways more than conspicuous positive or negative language toward specific targets.
</nextsent>
<nextsent>our corpus consists of articles published on the bitter lemons website1.
</nextsent>
<nextsent>the website is set up to contribute to mutual understanding [between palestinians and israels] through the open exchange of ideas?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3370">
<title id=" N06-3005.xml">identifying perspectives at the document and sentence levels using statistical models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>identifying the perspective from which document is written is subtask in the growing area of automatic opinion recognition and extraction.
</prevsent>
<prevsent>subjective language is used to express opinions, emotions, and sentiments.
</prevsent>
</prevsection>
<citsent citstr=" W03-0404 ">
so far research in automatic opinion recognition has primarily addressed learning subjective language (wiebe et al, 2004; <papid> J04-3002 </papid>riloff et al,2003; <papid> W03-0404 </papid>riloff and wiebe, 2003), <papid> W03-1014 </papid>identifying opinionated documents (yu and hatzivassiloglou, 2003) <papid> W03-1017 </papid>and sentences (yu and hatzivassiloglou, 2003; <papid> W03-1017 </papid>riloff etal., 2003; <papid> W03-0404 </papid>riloff and wiebe, 2003), <papid> W03-1014 </papid>and discriminating between positive and negative language (yu and hatzivassiloglou, 2003; <papid> W03-1017 </papid>turney and littman, 2003; pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; nasukawa and yi, 2003; morinaga et al, 2002).</citsent>
<aftsection>
<nextsent>although by its very nature we expect much ofthe language of presenting perspective or point of-view to be subjective, labeling document or sentence as subjective is not enough to identify the perspective from which it is written.
</nextsent>
<nextsent>moreover, the ideology and beliefs authors possess are often expressed in ways more than conspicuous positive or negative language toward specific targets.
</nextsent>
<nextsent>our corpus consists of articles published on the bitter lemons website1.
</nextsent>
<nextsent>the website is set up to contribute to mutual understanding [between palestinians and israels] through the open exchange of ideas?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3371">
<title id=" N06-3005.xml">identifying perspectives at the document and sentence levels using statistical models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>identifying the perspective from which document is written is subtask in the growing area of automatic opinion recognition and extraction.
</prevsent>
<prevsent>subjective language is used to express opinions, emotions, and sentiments.
</prevsent>
</prevsection>
<citsent citstr=" W03-1014 ">
so far research in automatic opinion recognition has primarily addressed learning subjective language (wiebe et al, 2004; <papid> J04-3002 </papid>riloff et al,2003; <papid> W03-0404 </papid>riloff and wiebe, 2003), <papid> W03-1014 </papid>identifying opinionated documents (yu and hatzivassiloglou, 2003) <papid> W03-1017 </papid>and sentences (yu and hatzivassiloglou, 2003; <papid> W03-1017 </papid>riloff etal., 2003; <papid> W03-0404 </papid>riloff and wiebe, 2003), <papid> W03-1014 </papid>and discriminating between positive and negative language (yu and hatzivassiloglou, 2003; <papid> W03-1017 </papid>turney and littman, 2003; pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; nasukawa and yi, 2003; morinaga et al, 2002).</citsent>
<aftsection>
<nextsent>although by its very nature we expect much ofthe language of presenting perspective or point of-view to be subjective, labeling document or sentence as subjective is not enough to identify the perspective from which it is written.
</nextsent>
<nextsent>moreover, the ideology and beliefs authors possess are often expressed in ways more than conspicuous positive or negative language toward specific targets.
</nextsent>
<nextsent>our corpus consists of articles published on the bitter lemons website1.
</nextsent>
<nextsent>the website is set up to contribute to mutual understanding [between palestinians and israels] through the open exchange of ideas?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3374">
<title id=" N06-3005.xml">identifying perspectives at the document and sentence levels using statistical models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>identifying the perspective from which document is written is subtask in the growing area of automatic opinion recognition and extraction.
</prevsent>
<prevsent>subjective language is used to express opinions, emotions, and sentiments.
</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
so far research in automatic opinion recognition has primarily addressed learning subjective language (wiebe et al, 2004; <papid> J04-3002 </papid>riloff et al,2003; <papid> W03-0404 </papid>riloff and wiebe, 2003), <papid> W03-1014 </papid>identifying opinionated documents (yu and hatzivassiloglou, 2003) <papid> W03-1017 </papid>and sentences (yu and hatzivassiloglou, 2003; <papid> W03-1017 </papid>riloff etal., 2003; <papid> W03-0404 </papid>riloff and wiebe, 2003), <papid> W03-1014 </papid>and discriminating between positive and negative language (yu and hatzivassiloglou, 2003; <papid> W03-1017 </papid>turney and littman, 2003; pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; nasukawa and yi, 2003; morinaga et al, 2002).</citsent>
<aftsection>
<nextsent>although by its very nature we expect much ofthe language of presenting perspective or point of-view to be subjective, labeling document or sentence as subjective is not enough to identify the perspective from which it is written.
</nextsent>
<nextsent>moreover, the ideology and beliefs authors possess are often expressed in ways more than conspicuous positive or negative language toward specific targets.
</nextsent>
<nextsent>our corpus consists of articles published on the bitter lemons website1.
</nextsent>
<nextsent>the website is set up to contribute to mutual understanding [between palestinians and israels] through the open exchange of ideas?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3383">
<title id=" N06-3005.xml">identifying perspectives at the document and sentence levels using statistical models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>identifying the perspective from which document is written is subtask in the growing area of automatic opinion recognition and extraction.
</prevsent>
<prevsent>subjective language is used to express opinions, emotions, and sentiments.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
so far research in automatic opinion recognition has primarily addressed learning subjective language (wiebe et al, 2004; <papid> J04-3002 </papid>riloff et al,2003; <papid> W03-0404 </papid>riloff and wiebe, 2003), <papid> W03-1014 </papid>identifying opinionated documents (yu and hatzivassiloglou, 2003) <papid> W03-1017 </papid>and sentences (yu and hatzivassiloglou, 2003; <papid> W03-1017 </papid>riloff etal., 2003; <papid> W03-0404 </papid>riloff and wiebe, 2003), <papid> W03-1014 </papid>and discriminating between positive and negative language (yu and hatzivassiloglou, 2003; <papid> W03-1017 </papid>turney and littman, 2003; pang et al, 2002; <papid> W02-1011 </papid>dave et al, 2003; nasukawa and yi, 2003; morinaga et al, 2002).</citsent>
<aftsection>
<nextsent>although by its very nature we expect much ofthe language of presenting perspective or point of-view to be subjective, labeling document or sentence as subjective is not enough to identify the perspective from which it is written.
</nextsent>
<nextsent>moreover, the ideology and beliefs authors possess are often expressed in ways more than conspicuous positive or negative language toward specific targets.
</nextsent>
<nextsent>our corpus consists of articles published on the bitter lemons website1.
</nextsent>
<nextsent>the website is set up to contribute to mutual understanding [between palestinians and israels] through the open exchange of ideas?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3387">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we propose an integer linear programming (ilp) formulation for coreference resolution which models anaphoricity and coreference as ajoint task, such that each local model informs the other for the final assignments.this joint ilp formulation provides score improvements of 3.7-5.3% over base coreference classifier on the ace datasets.
</prevsent>
<prevsent>the task of coreference resolution involves imposing partition on set of entity mentions in document, where each partition corresponds to some entity in an underlying discourse model.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
most work treats coreference resolution as binary classification task in which each decision is made in pairwise fashion, independently of the others (mccarthy and lehnert, 1995; soon et al, 2001;<papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b; morton, 2000; <papid> P00-1023 </papid>kehler et al, 2004).<papid> N04-1037 </papid>there are two major drawbacks with most systems that make pairwise coreference decisions.</citsent>
<aftsection>
<nextsent>the first is that identification of anaphora is done implicitly as part of the coreference resolution.
</nextsent>
<nextsent>two common types of errors with these systems are caseswhere: (i) the system mistakenly identifies an antecedent for non-anaphoric mentions, and (ii) the system does not try to resolve an actual anaphoric mention.
</nextsent>
<nextsent>to reduce such errors, ng and cardie(2002<papid> P02-1014 </papid>a) and ng (2004) <papid> P04-1020 </papid>use an anaphoricity classifier which has the sole task of saying whether or not any antecedents should be identified for each mention?</nextsent>
<nextsent>as filter for their coreference system.they achieve higher performance by doing so; how ever, their setup uses the two classifiers in cascade.this requires careful determination of an anaphoricity threshold in order to not remove too many mentions from consideration (ng, 2004).<papid> P04-1020 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3389">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we propose an integer linear programming (ilp) formulation for coreference resolution which models anaphoricity and coreference as ajoint task, such that each local model informs the other for the final assignments.this joint ilp formulation provides score improvements of 3.7-5.3% over base coreference classifier on the ace datasets.
</prevsent>
<prevsent>the task of coreference resolution involves imposing partition on set of entity mentions in document, where each partition corresponds to some entity in an underlying discourse model.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
most work treats coreference resolution as binary classification task in which each decision is made in pairwise fashion, independently of the others (mccarthy and lehnert, 1995; soon et al, 2001;<papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b; morton, 2000; <papid> P00-1023 </papid>kehler et al, 2004).<papid> N04-1037 </papid>there are two major drawbacks with most systems that make pairwise coreference decisions.</citsent>
<aftsection>
<nextsent>the first is that identification of anaphora is done implicitly as part of the coreference resolution.
</nextsent>
<nextsent>two common types of errors with these systems are caseswhere: (i) the system mistakenly identifies an antecedent for non-anaphoric mentions, and (ii) the system does not try to resolve an actual anaphoric mention.
</nextsent>
<nextsent>to reduce such errors, ng and cardie(2002<papid> P02-1014 </papid>a) and ng (2004) <papid> P04-1020 </papid>use an anaphoricity classifier which has the sole task of saying whether or not any antecedents should be identified for each mention?</nextsent>
<nextsent>as filter for their coreference system.they achieve higher performance by doing so; how ever, their setup uses the two classifiers in cascade.this requires careful determination of an anaphoricity threshold in order to not remove too many mentions from consideration (ng, 2004).<papid> P04-1020 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3395">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we propose an integer linear programming (ilp) formulation for coreference resolution which models anaphoricity and coreference as ajoint task, such that each local model informs the other for the final assignments.this joint ilp formulation provides score improvements of 3.7-5.3% over base coreference classifier on the ace datasets.
</prevsent>
<prevsent>the task of coreference resolution involves imposing partition on set of entity mentions in document, where each partition corresponds to some entity in an underlying discourse model.
</prevsent>
</prevsection>
<citsent citstr=" P00-1023 ">
most work treats coreference resolution as binary classification task in which each decision is made in pairwise fashion, independently of the others (mccarthy and lehnert, 1995; soon et al, 2001;<papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b; morton, 2000; <papid> P00-1023 </papid>kehler et al, 2004).<papid> N04-1037 </papid>there are two major drawbacks with most systems that make pairwise coreference decisions.</citsent>
<aftsection>
<nextsent>the first is that identification of anaphora is done implicitly as part of the coreference resolution.
</nextsent>
<nextsent>two common types of errors with these systems are caseswhere: (i) the system mistakenly identifies an antecedent for non-anaphoric mentions, and (ii) the system does not try to resolve an actual anaphoric mention.
</nextsent>
<nextsent>to reduce such errors, ng and cardie(2002<papid> P02-1014 </papid>a) and ng (2004) <papid> P04-1020 </papid>use an anaphoricity classifier which has the sole task of saying whether or not any antecedents should be identified for each mention?</nextsent>
<nextsent>as filter for their coreference system.they achieve higher performance by doing so; how ever, their setup uses the two classifiers in cascade.this requires careful determination of an anaphoricity threshold in order to not remove too many mentions from consideration (ng, 2004).<papid> P04-1020 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3396">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we propose an integer linear programming (ilp) formulation for coreference resolution which models anaphoricity and coreference as ajoint task, such that each local model informs the other for the final assignments.this joint ilp formulation provides score improvements of 3.7-5.3% over base coreference classifier on the ace datasets.
</prevsent>
<prevsent>the task of coreference resolution involves imposing partition on set of entity mentions in document, where each partition corresponds to some entity in an underlying discourse model.
</prevsent>
</prevsection>
<citsent citstr=" N04-1037 ">
most work treats coreference resolution as binary classification task in which each decision is made in pairwise fashion, independently of the others (mccarthy and lehnert, 1995; soon et al, 2001;<papid> J01-4004 </papid>ng and cardie, 2002<papid> P02-1014 </papid>b; morton, 2000; <papid> P00-1023 </papid>kehler et al, 2004).<papid> N04-1037 </papid>there are two major drawbacks with most systems that make pairwise coreference decisions.</citsent>
<aftsection>
<nextsent>the first is that identification of anaphora is done implicitly as part of the coreference resolution.
</nextsent>
<nextsent>two common types of errors with these systems are caseswhere: (i) the system mistakenly identifies an antecedent for non-anaphoric mentions, and (ii) the system does not try to resolve an actual anaphoric mention.
</nextsent>
<nextsent>to reduce such errors, ng and cardie(2002<papid> P02-1014 </papid>a) and ng (2004) <papid> P04-1020 </papid>use an anaphoricity classifier which has the sole task of saying whether or not any antecedents should be identified for each mention?</nextsent>
<nextsent>as filter for their coreference system.they achieve higher performance by doing so; how ever, their setup uses the two classifiers in cascade.this requires careful determination of an anaphoricity threshold in order to not remove too many mentions from consideration (ng, 2004).<papid> P04-1020 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3399">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the first is that identification of anaphora is done implicitly as part of the coreference resolution.
</prevsent>
<prevsent>two common types of errors with these systems are caseswhere: (i) the system mistakenly identifies an antecedent for non-anaphoric mentions, and (ii) the system does not try to resolve an actual anaphoric mention.
</prevsent>
</prevsection>
<citsent citstr=" P04-1020 ">
to reduce such errors, ng and cardie(2002<papid> P02-1014 </papid>a) and ng (2004) <papid> P04-1020 </papid>use an anaphoricity classifier which has the sole task of saying whether or not any antecedents should be identified for each mention?</citsent>
<aftsection>
<nextsent>as filter for their coreference system.they achieve higher performance by doing so; how ever, their setup uses the two classifiers in cascade.this requires careful determination of an anaphoricity threshold in order to not remove too many mentions from consideration (ng, 2004).<papid> P04-1020 </papid></nextsent>
<nextsent>this sensitivity is unsurprising, given that the tasks are co dependent.the second problem is that most coreference systems make each decision independently of previous ones in greedy fashion (mccallum and wellner, 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3403">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>clearly, the determination of membership ofa particular mention into partition should be conditioned on how well it matches the entity as whole.since independence between decisions is an unwarranted assumption for the task, models that considera more global context are likely to be more appropriate.
</prevsent>
<prevsent>recent work has examined such models; luo etal.
</prevsent>
</prevsection>
<citsent citstr=" P05-1020 ">
(2004) using bell trees, and mccallum and wellner (2004) using conditional random fields, and ng (2005) <papid> P05-1020 </papid>using rerankers.</citsent>
<aftsection>
<nextsent>in this paper, we propose to recast the task of coreference resolution as an optimization problem,namely an integer linear programming (ilp) problem.
</nextsent>
<nextsent>this framework has several properties that make it highly suitable for addressing the two aforementioned problems.
</nextsent>
<nextsent>the first is that it can utilize existing classifiers; ilp performs global inference based on their output rather than formulating 236 new inference procedure for solving the basic task.
</nextsent>
<nextsent>second, the ilp approach supports inference over multiple classifiers, without having to fiddle with special parameterization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3404">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> base models: coreference classifier.  </section>
<citcontext>
<prevsection>
<prevsent>reaches particular value (typically .5).we use maximum entropy model for the coreference classifier.
</prevsent>
<prevsent>such models are well-suited for coreference, because they are able to handle many different, potentially overlapping learning features without making independence assumptions.
</prevsent>
</prevsection>
<citsent citstr=" W97-0319 ">
previous work on coreference using maximum entropy includes (kehler, 1997; <papid> W97-0319 </papid>morton, 1999; <papid> W99-0212 </papid>morton, 2000).<papid> P00-1023 </papid></citsent>
<aftsection>
<nextsent>the model is defined in standard fashion as follows: pc(coref|i, j?)
</nextsent>
<nextsent>= exp( n?
</nextsent>
<nextsent>k=1 kfk(i, j?, coref)) z(i, j?)
</nextsent>
<nextsent>(1)z(i, j?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3405">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> base models: coreference classifier.  </section>
<citcontext>
<prevsection>
<prevsent>reaches particular value (typically .5).we use maximum entropy model for the coreference classifier.
</prevsent>
<prevsent>such models are well-suited for coreference, because they are able to handle many different, potentially overlapping learning features without making independence assumptions.
</prevsent>
</prevsection>
<citsent citstr=" W99-0212 ">
previous work on coreference using maximum entropy includes (kehler, 1997; <papid> W97-0319 </papid>morton, 1999; <papid> W99-0212 </papid>morton, 2000).<papid> P00-1023 </papid></citsent>
<aftsection>
<nextsent>the model is defined in standard fashion as follows: pc(coref|i, j?)
</nextsent>
<nextsent>= exp( n?
</nextsent>
<nextsent>k=1 kfk(i, j?, coref)) z(i, j?)
</nextsent>
<nextsent>(1)z(i, j?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3407">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> base models: coreference classifier.  </section>
<citcontext>
<prevsection>
<prevsent>(1)z(i, j?)
</prevsent>
<prevsent>is normalization factor over both outcomes (coref and coref).
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
model parameters are estimated using maximum entropy (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>specifically, we estimate parameters withthe limited memory variable metric algorithm implemented in the toolkit for advanced discriminative modeling1 (malouf, 2002).<papid> W02-2018 </papid></nextsent>
<nextsent>we use gaussian prior with variance of 1000 ? no attempt was made to optimize this value.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3408">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> base models: coreference classifier.  </section>
<citcontext>
<prevsection>
<prevsent>is normalization factor over both outcomes (coref and coref).
</prevsent>
<prevsent>model parameters are estimated using maximum entropy (berger et al, 1996).<papid> J96-1002 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
specifically, we estimate parameters withthe limited memory variable metric algorithm implemented in the toolkit for advanced discriminative modeling1 (malouf, 2002).<papid> W02-2018 </papid></citsent>
<aftsection>
<nextsent>we use gaussian prior with variance of 1000 ? no attempt was made to optimize this value.
</nextsent>
<nextsent>training instances for the coreference classifier are constructed based on pairs of mentions of the form i, j?, where and are the descriptions foran anaphor and one of its candidate antecedents, respectively.
</nextsent>
<nextsent>each such pair is assigned either label coref (i.e. positive instance) or label coref (i.e. negative instance) depending on whether ornot the two mentions corefer.
</nextsent>
<nextsent>in generating the training data, we followed the method of (soon et al,2001) <papid> J01-4004 </papid>creating for each anaphor: (i) positive instance for the pair i, j?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3426">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> base model results.  </section>
<citcontext>
<prevsection>
<prevsent>this is because our focus is on evaluating pairwise local approaches versus the global ilp approach rather than on building full coreference resolution system.
</prevsent>
<prevsent>it is worth noting that previous work tends to be vague in both these re spects: details on mention filtering or providing performance figures for mark able identification are rarely given.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
following common practice, results are given interms of recall and precision according to the standard model-theoretic metric (vilain et al, 1995).<papid> M95-1005 </papid></citsent>
<aftsection>
<nextsent>this method operates by comparing the equivalence classes defined by the resolutions produced by the system with the gold standard classes: these are the two models?.
</nextsent>
<nextsent>roughly, the scores are obtained by determining the minimal perturbations brought to one model in order to map it onto the other model.
</nextsent>
<nextsent>recall is computed by trying to map the predicted chains onto the true chains, while precision is computed the other way around.
</nextsent>
<nextsent>we test significant differences with paired t-tests (p   .05).the anaphoricity classifier has an average accuracy of 80.2% on the three ace datasets (using threshold of .5).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3434">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> integer programming formulations.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we define two objective functions for coreference resolution to be optimized withilp.
</prevsent>
<prevsent>the first uses only information from the coreference classifier (coref-ilp) and the second integrates both anaphoricity and coreference in joint formulation (joint-ilp).
</prevsent>
</prevsection>
<citsent citstr=" W04-2401 ">
our problem formulation and use of ilp are based on both (roth and yih, 2004) <papid> W04-2401 </papid>and (barzilay and lapata, 2006).<papid> N06-1046 </papid></citsent>
<aftsection>
<nextsent>for solving the ilp problem, we use lp solve, an open-source linear programming solver which implements the simplex and the branch-and-bound 239methods.3 in practice, each test document is processed to define distinct ilp problem that is then submitted to the solver.
</nextsent>
<nextsent>5.1 coref-ilp: coreference-only formulation.
</nextsent>
<nextsent>barzilay and lapata (2006) <papid> N06-1046 </papid>use ilp for the problem of aggregation in natural language generation: clustering sets of propositions together to create more concise texts.</nextsent>
<nextsent>they cast it as set partitioning prob lem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3435">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> integer programming formulations.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we define two objective functions for coreference resolution to be optimized withilp.
</prevsent>
<prevsent>the first uses only information from the coreference classifier (coref-ilp) and the second integrates both anaphoricity and coreference in joint formulation (joint-ilp).
</prevsent>
</prevsection>
<citsent citstr=" N06-1046 ">
our problem formulation and use of ilp are based on both (roth and yih, 2004) <papid> W04-2401 </papid>and (barzilay and lapata, 2006).<papid> N06-1046 </papid></citsent>
<aftsection>
<nextsent>for solving the ilp problem, we use lp solve, an open-source linear programming solver which implements the simplex and the branch-and-bound 239methods.3 in practice, each test document is processed to define distinct ilp problem that is then submitted to the solver.
</nextsent>
<nextsent>5.1 coref-ilp: coreference-only formulation.
</nextsent>
<nextsent>barzilay and lapata (2006) <papid> N06-1046 </papid>use ilp for the problem of aggregation in natural language generation: clustering sets of propositions together to create more concise texts.</nextsent>
<nextsent>they cast it as set partitioning prob lem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3439">
<title id=" N07-1030.xml">joint determination of anaphoricity and coreference resolution using integer programming </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>all -score differences are significant (p   .05).
</prevsent>
<prevsent>a number of recent global approaches.
</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
luo et al (2004) <papid> P04-1018 </papid>use bell trees to represent the search space of the coreference resolution problem(where each leaf is possible partition).</citsent>
<aftsection>
<nextsent>the problem is thus recast as that of finding the best?
</nextsent>
<nextsent>path through the tree.
</nextsent>
<nextsent>given the rapidly growing size ofbell trees, luo et al resort to beam search algorithm and various pruning strategies, potentially resulting in picking non-optimal solution.
</nextsent>
<nextsent>there sults provided by luo et al are difficult to compare with ours, since they use different evaluation metric.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3449">
<title id=" N07-1027.xml">is question answering better than information retrieval towards a task based evaluation framework for question series </title>
<section> hale bopp comet.  </section>
<citcontext>
<prevsection>
<prevsent>thus, real-world user preferences may erode the advantage that qa has over ir techniques such as passage retrieval, e.g., (zobel et al, 1995; tellex et al, 2003).
</prevsent>
<prevsent>second, the focus of question answering research has shifted away from isolated factoid questions to more complex information needs embedded within broader context (e.g., user scenario).
</prevsent>
</prevsection>
<citsent citstr=" H05-1038 ">
since 2004, the main task at the trec qa tracks has consisted of question series organized around topics(called targets?)which can be people, organizations, entities, or events (voorhees, 2004; voorhees,2005).<papid> H05-1038 </papid></citsent>
<aftsection>
<nextsent>questions in series inquire about different facets of target, but are themselves either factoid or list questions.
</nextsent>
<nextsent>in addition, each series contains an explicit other?
</nextsent>
<nextsent>question (always the last one), which can be paraphrased as tell me other interesting things about this target that dont know enough to ask directly.?
</nextsent>
<nextsent>see table 1 for examples of question series.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3450">
<title id=" N07-1027.xml">is question answering better than information retrieval towards a task based evaluation framework for question series </title>
<section> hale bopp comet.  </section>
<citcontext>
<prevsection>
<prevsent>desire for context and the structure of more complex qa tasks.focusing on question series, we compare the performance of top trec systems to baseline ir engine using this evaluation framework.
</prevsent>
<prevsent>3 an evaluation framework.
</prevsent>
</prevsection>
<citsent citstr=" W04-2509 ">
question series in trec represent an attempt at modeling information-seeking dialogues between user and system (kato et al, 2004).<papid> W04-2509 </papid></citsent>
<aftsection>
<nextsent>primarily because dialogue systems are difficult to evaluate,nist has adopted setup in which individual questions are evaluated in isolation this implicitly models user who types in question, receives an answer, and then moves on to the next question in the series.
</nextsent>
<nextsent>component scores are aggregated using weighted average, and no attempt is made to capture dependencies across different question types.
</nextsent>
<nextsent>simultaneously acknowledging the challenges in evaluating dialogue systems and recognizing the similarities between complex qa and query-focusedsummarization, we propose an alternative framework for qa evaluation that considers the quality of system responses as whole.
</nextsent>
<nextsent>instead of generating individual answers to each question, system might alternatively produce segment of text (i.e., summary) that attempts to answer all the questions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3451">
<title id=" N07-1027.xml">is question answering better than information retrieval towards a task based evaluation framework for question series </title>
<section> hale bopp comet.  </section>
<citcontext>
<prevsection>
<prevsent>instead of generating individual answers to each question, system might alternatively produce segment of text (i.e., summary) that attempts to answer all the questions.
</prevsent>
<prevsent>this slightly different conception of qa brings itinto better alignment with recent trends in multi 213document summarization, which may yield previously untapped synergies (see section 7).
</prevsent>
</prevsection>
<citsent citstr=" N04-1019 ">
to assess the quality of system responses, we adopt the nugget-based methodology used previously for many types of complex questions (voorhees, 2003), which shares similarities with the pyramid evaluation scheme used in summarization (nenkova and passonneau, 2004).<papid> N04-1019 </papid></citsent>
<aftsection>
<nextsent>anugget can be described as anatomic fact?
</nextsent>
<nextsent>that addresses an aspect of an information need.
</nextsent>
<nextsent>instead of the standard nugget f-score, which hides important tradeoffs between precision and recall, we propose to measure nugget recall as function of responselength.
</nextsent>
<nextsent>the goal is to quantify the number of relevant facts that user will have encountered after reading particular amount of text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3452">
<title id=" N07-1027.xml">is question answering better than information retrieval towards a task based evaluation framework for question series </title>
<section> factoid series.  </section>
<citcontext>
<prevsection>
<prevsent>this was accomplished by selecting the first sentence in the source document (drawn from the aquaint corpus) that contains the answer string.2 in our example, this procedure yielded the following text segment: the comet was named after its two observerstwoamateur astronomers in the united states who discovered it on july 22, 1995.
</prevsent>
<prevsent>its visit to the solarsystemjust once every 4,200 years, will give millions of people rare heavenly treat when it reaches its full brightness next year.since projected sentences are simply concatenated, the responses often exhibit readability problems (although by chance this particular response is relatively coherent).
</prevsent>
</prevsection>
<citsent citstr=" P99-1071 ">
nevertheless, one might imagine that such output forms the basis for generating coherent query-focused summaries with sentence rewrite techniques, e.g., (barzilay et al, 1999).<papid> P99-1071 </papid></citsent>
<aftsection>
<nextsent>in this work, we set aside problems with fluency since our evaluation framework is unable to measure this (desirable) characteristic.
</nextsent>
<nextsent>system responses were prepared for four runs from trec 2004 and four runs from trec 2005 in the manner described above.
</nextsent>
<nextsent>as baseline, we employed lucene to retrieve the top 100 documents from the aquaint corpus using the target as the query (in our example, hale bopp comet?).
</nextsent>
<nextsent>from the result set, we retained all sentences that contain at least term from the target.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3453">
<title id=" N07-1027.xml">is question answering better than information retrieval towards a task based evaluation framework for question series </title>
<section> factoid series.  </section>
<citcontext>
<prevsection>
<prevsent>the goodness?
</prevsent>
<prevsent>of answers can only be quantified with respect to task?
</prevsent>
</prevsection>
<citsent citstr=" C04-1189 ">
examples range from winning game show (clarke et al, 2001) to intelligence gathering (small et al, 2004).<papid> C04-1189 </papid></citsent>
<aftsection>
<nextsent>it is impossible to assess the real-world impact of qa technology without considering how such systems will be used to solve human problems.
</nextsent>
<nextsent>our work takes small step in this direction.
</nextsent>
<nextsent>8 conclusion.
</nextsent>
<nextsent>is qa better than ir?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3454">
<title id=" N06-4007.xml">automatic cluster stopping with criterion functions and the gap statistic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the assumption is made that each discovered cluster will represent different sense of word, or the underlying identity of person or organization that has an ambiguous name.existing approaches to this problem usually require that the number of clusters to be discovered(k) be specified ahead of time.
</prevsent>
<prevsent>however, in most realistic settings, the value of is unknown to the user.
</prevsent>
</prevsection>
<citsent citstr=" W04-2406 ">
here we describe various cluster stopping measures that are now implemented in sense clusters (puran dare and pedersen, 2004) <papid> W04-2406 </papid>that will group contexts into clusters, where the value of will be automatically determined.</citsent>
<aftsection>
<nextsent>cluster stopping can be viewed as problem in model selection, since number of different models (i.e., clustering solutions) are created using different values of k, and the one that best fits the observed data is selected based on criterion function.
</nextsent>
<nextsent>this is reminiscent of earlier work on sequential model selection for creating models of word sense disambiguation (e.g., (ohara et al, 2000)), where it was found that forward sequential search strategies were most effective.
</nextsent>
<nextsent>these methods start with simpler models and then add to them in stepwise fashion until no further improvement in model fit is observed.
</nextsent>
<nextsent>this is in fact very similar to what we have done here, where we start with solutions based onone cluster, and steadily increase the number of clusters until we find the best fitting solution.senseclusters supports four cluster stopping measures, each of which is based on interpreting clustering criterion function in some way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3455">
<title id=" N01-1015.xml">reengineering lettertosound rules </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>highly skilled developers are costly resource, the complexity and sheer size of the code involved are difficult to manage.
</prevsent>
<prevsent>a paradigmatic example of this is the letter-to-sound component within the text analysis module of mature large scale text-to-speech system.
</prevsent>
</prevsection>
<citsent citstr=" J94-3001 ">
in the system described in (sproat, 1998) text analysis is performed using finite-state transducers compiled from rewrite rules (kaplan and kay, 1994; <papid> J94-3001 </papid>mohri and sproat, 1996)<papid> P96-1031 </papid>and other high-level descriptions.</citsent>
<aftsection>
<nextsent>while the exclusive use of finite-state technology has advantages, it is not without its shortcomings, both technical and stemming from the use of hand-crafted rule sets and how they are represented: 1.
</nextsent>
<nextsent>extensive rule sets need to be constructed by.
</nextsent>
<nextsent>human experts, which is labor-intensive and expensive (sproat et al, 1998).
</nextsent>
<nextsent>cause of complex interactions between serially composed rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3456">
<title id=" N01-1015.xml">reengineering lettertosound rules </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>highly skilled developers are costly resource, the complexity and sheer size of the code involved are difficult to manage.
</prevsent>
<prevsent>a paradigmatic example of this is the letter-to-sound component within the text analysis module of mature large scale text-to-speech system.
</prevsent>
</prevsection>
<citsent citstr=" P96-1031 ">
in the system described in (sproat, 1998) text analysis is performed using finite-state transducers compiled from rewrite rules (kaplan and kay, 1994; <papid> J94-3001 </papid>mohri and sproat, 1996)<papid> P96-1031 </papid>and other high-level descriptions.</citsent>
<aftsection>
<nextsent>while the exclusive use of finite-state technology has advantages, it is not without its shortcomings, both technical and stemming from the use of hand-crafted rule sets and how they are represented: 1.
</nextsent>
<nextsent>extensive rule sets need to be constructed by.
</nextsent>
<nextsent>human experts, which is labor-intensive and expensive (sproat et al, 1998).
</nextsent>
<nextsent>cause of complex interactions between serially composed rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3458">
<title id=" N01-1015.xml">reengineering lettertosound rules </title>
<section> generality..  </section>
<citcontext>
<prevsection>
<prevsent>spected and converted.the first property addresses the efficiency requirements stated above: if every feature function can be computed in time o(f), where the function does not involve the height of the decision tree h, then the classification function represented by the decision tree can be computed in time o(n. ? f(n)) = o(f) if feature values can be mapped to child nodes in constant time, e. g. through hashing; and similarly for space.
</prevsent>
<prevsent>the other properties justify the use of decision trees as knowledge representation format.
</prevsent>
</prevsection>
<citsent citstr=" P96-1029 ">
in particular, decision trees can be converted into im plicational rules that an expert could inspect and can in principle be compiled back into finite-state machines (sproat and riley, 1996), <papid> P96-1029 </papid>although that would re-introduce the original efficiency problems.</citsent>
<aftsection>
<nextsent>on the other hand, finite-state transducers have the advantage of being invertible, which can be exploited e. g. for testing hand-crafted rule sets.we use standard decision tree learner (quinlan, 1993), since we believe that it would be premature to investigate the implications of different choices of machine learning algorithms while the fundamental question of what any such algorithm should use as training data is still open.
</nextsent>
<nextsent>this topic is explored further in section 5.
</nextsent>
<nextsent>related work is discussed in section 6.
</nextsent>
<nextsent>2 aligning the lexicon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3459">
<title id=" N01-1015.xml">reengineering lettertosound rules </title>
<section> relation to existing research.  </section>
<citcontext>
<prevsection>
<prevsent>since the general problem of learning regular mappings between regular languages is intractable because of the vast hypothesis space, all existing research on automatic methods has imposed restrictions on the class of target functions.
</prevsent>
<prevsent>in almost all cases, this paper included, one only considers functions that are local in the sense that only fixed amount of context is relevant for mapping letter to phoneme.
</prevsent>
</prevsection>
<citsent citstr=" P95-1002 ">
one exception to this is (gildea and jurafsky,1995), <papid> P95-1002 </papid>where the target function space are the subse quential transducers, for which limit-identification algorithm exists (oncina et al, 1993).</citsent>
<aftsection>
<nextsent>however, without additional guidance, that algorithm cannot be directly applied to the phonetic modeling task due to data sparseness and/or lack of sufficient bias (gildea and jurafsky, 1995).<papid> P95-1002 </papid></nextsent>
<nextsent>we would argue that the lack of locality restrictions is at the root of the convergence problems for that approach.our approach effectively restricts the hypothesis space even further to include only the k-local (or strictly k-testable) sequential transducers, where classification decision is made deterministically and based on fixed amount of context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3461">
<title id=" N01-1015.xml">reengineering lettertosound rules </title>
<section> relation to existing research.  </section>
<citcontext>
<prevsection>
<prevsent>(/kjubiz@m/ according to cmudict.0.6) or mutual sim?.
</prevsent>
<prevsent>the problem of finding good alignment has not received its due attention in the literature.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
work on multiple alignments in computational biology cannot be adapted directly because the letter-to sound mapping is between dissimilar alphabets.the alignment problem in statistical machine translation (brown et al, 1990) <papid> J90-2002 </papid>is too general: long distance displacement of large chunks of material may occur frequently when translating whole sentences, but are unlikely to play any role for the letter-to-sound mapping, though local reorderings do occur (sproat, 2000).</citsent>
<aftsection>
<nextsent>ad hoc figures of merit for alignments (daelemans and vanden bosch, 1997) or hand-corrected alignments (black et al, 1998) might give good results in practice, but do not get us any closer to principled solution.
</nextsent>
<nextsent>the present work is another step towards obtaining better alignments by exploiting easily available knowledge in systematic fashion.
</nextsent>
<nextsent>we presented method for building efficient letter to-sound rules from information extractable from, or with the help of, existing hand-crafted rewriterules.
</nextsent>
<nextsent>using decision trees as the new target representation, significant improvements in time and space efficiency could be achieved at the cost of reduction inaccuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3462">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the proposed approach is evaluated on lexicon learning task using the wall street journal (wsj)corpus, and on the senseval-3 word sense disambiguation task.
</prevsent>
<prevsent>in both cases our technique significantly outperforms our baseline systems (label propagation using standard graph construction and discriminatively trained supervised classifiers).
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
several graph-based learning techniques have recently been developed and applied to nlp prob lems: minimum cuts (pang and lee, 2004), <papid> P04-1035 </papid>random walks (mihalcea, 2005; <papid> H05-1052 </papid>otterbacher et al, 2005), <papid> H05-1115 </papid>graph matching (haghighi et al, 2005), <papid> H05-1049 </papid>and label propagation (niu et al, 2005).<papid> P05-1049 </papid></citsent>
<aftsection>
<nextsent>here we focus on label propagation as learning technique.
</nextsent>
<nextsent>2.1 label propagation.
</nextsent>
<nextsent>the basic label propagation (lp) algorithm (zhu and ghahramani, 2002; zhu, 2005) has as inputs: ? labeled set {(x1, y1), (x2, y2), . . .
</nextsent>
<nextsent>, (xn, yn)}, where xi are samples (feature vectors) and yi ? {1, 2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3463">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the proposed approach is evaluated on lexicon learning task using the wall street journal (wsj)corpus, and on the senseval-3 word sense disambiguation task.
</prevsent>
<prevsent>in both cases our technique significantly outperforms our baseline systems (label propagation using standard graph construction and discriminatively trained supervised classifiers).
</prevsent>
</prevsection>
<citsent citstr=" H05-1052 ">
several graph-based learning techniques have recently been developed and applied to nlp prob lems: minimum cuts (pang and lee, 2004), <papid> P04-1035 </papid>random walks (mihalcea, 2005; <papid> H05-1052 </papid>otterbacher et al, 2005), <papid> H05-1115 </papid>graph matching (haghighi et al, 2005), <papid> H05-1049 </papid>and label propagation (niu et al, 2005).<papid> P05-1049 </papid></citsent>
<aftsection>
<nextsent>here we focus on label propagation as learning technique.
</nextsent>
<nextsent>2.1 label propagation.
</nextsent>
<nextsent>the basic label propagation (lp) algorithm (zhu and ghahramani, 2002; zhu, 2005) has as inputs: ? labeled set {(x1, y1), (x2, y2), . . .
</nextsent>
<nextsent>, (xn, yn)}, where xi are samples (feature vectors) and yi ? {1, 2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3464">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the proposed approach is evaluated on lexicon learning task using the wall street journal (wsj)corpus, and on the senseval-3 word sense disambiguation task.
</prevsent>
<prevsent>in both cases our technique significantly outperforms our baseline systems (label propagation using standard graph construction and discriminatively trained supervised classifiers).
</prevsent>
</prevsection>
<citsent citstr=" H05-1115 ">
several graph-based learning techniques have recently been developed and applied to nlp prob lems: minimum cuts (pang and lee, 2004), <papid> P04-1035 </papid>random walks (mihalcea, 2005; <papid> H05-1052 </papid>otterbacher et al, 2005), <papid> H05-1115 </papid>graph matching (haghighi et al, 2005), <papid> H05-1049 </papid>and label propagation (niu et al, 2005).<papid> P05-1049 </papid></citsent>
<aftsection>
<nextsent>here we focus on label propagation as learning technique.
</nextsent>
<nextsent>2.1 label propagation.
</nextsent>
<nextsent>the basic label propagation (lp) algorithm (zhu and ghahramani, 2002; zhu, 2005) has as inputs: ? labeled set {(x1, y1), (x2, y2), . . .
</nextsent>
<nextsent>, (xn, yn)}, where xi are samples (feature vectors) and yi ? {1, 2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3465">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the proposed approach is evaluated on lexicon learning task using the wall street journal (wsj)corpus, and on the senseval-3 word sense disambiguation task.
</prevsent>
<prevsent>in both cases our technique significantly outperforms our baseline systems (label propagation using standard graph construction and discriminatively trained supervised classifiers).
</prevsent>
</prevsection>
<citsent citstr=" H05-1049 ">
several graph-based learning techniques have recently been developed and applied to nlp prob lems: minimum cuts (pang and lee, 2004), <papid> P04-1035 </papid>random walks (mihalcea, 2005; <papid> H05-1052 </papid>otterbacher et al, 2005), <papid> H05-1115 </papid>graph matching (haghighi et al, 2005), <papid> H05-1049 </papid>and label propagation (niu et al, 2005).<papid> P05-1049 </papid></citsent>
<aftsection>
<nextsent>here we focus on label propagation as learning technique.
</nextsent>
<nextsent>2.1 label propagation.
</nextsent>
<nextsent>the basic label propagation (lp) algorithm (zhu and ghahramani, 2002; zhu, 2005) has as inputs: ? labeled set {(x1, y1), (x2, y2), . . .
</nextsent>
<nextsent>, (xn, yn)}, where xi are samples (feature vectors) and yi ? {1, 2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3466">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the proposed approach is evaluated on lexicon learning task using the wall street journal (wsj)corpus, and on the senseval-3 word sense disambiguation task.
</prevsent>
<prevsent>in both cases our technique significantly outperforms our baseline systems (label propagation using standard graph construction and discriminatively trained supervised classifiers).
</prevsent>
</prevsection>
<citsent citstr=" P05-1049 ">
several graph-based learning techniques have recently been developed and applied to nlp prob lems: minimum cuts (pang and lee, 2004), <papid> P04-1035 </papid>random walks (mihalcea, 2005; <papid> H05-1052 </papid>otterbacher et al, 2005), <papid> H05-1115 </papid>graph matching (haghighi et al, 2005), <papid> H05-1049 </papid>and label propagation (niu et al, 2005).<papid> P05-1049 </papid></citsent>
<aftsection>
<nextsent>here we focus on label propagation as learning technique.
</nextsent>
<nextsent>2.1 label propagation.
</nextsent>
<nextsent>the basic label propagation (lp) algorithm (zhu and ghahramani, 2002; zhu, 2005) has as inputs: ? labeled set {(x1, y1), (x2, y2), . . .
</nextsent>
<nextsent>, (xn, yn)}, where xi are samples (feature vectors) and yi ? {1, 2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3470">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the global distance is less relevant since label information will be propagated from labeled points through the entirespace.
</prevsent>
<prevsent>this is why lp works well with local distance measure that might be unsuitable as global distance measure.applications of lp include handwriting recognition (zhu and ghahramani, 2002), image classification (balcan et al, 2005) and retrieval (qin et al., 2005), and protein classification (weston et al, 2003).
</prevsent>
</prevsection>
<citsent citstr=" W06-3808 ">
in nlp, label propagation has been used forword sense disambiguation (niu et al, 2005), <papid> P05-1049 </papid>document classification (zhu, 2005), sentiment analysis (goldberg and zhu, 2006), <papid> W06-3808 </papid>and relation extraction (chen et al, 2006).<papid> P06-1017 </papid></citsent>
<aftsection>
<nextsent>2.2 graph construction.
</nextsent>
<nextsent>one of the main problems in lp, as well as othergraph-based learning techniques, is how to best construct the graph.
</nextsent>
<nextsent>currently, graph construction is more of an art than science?
</nextsent>
<nextsent>(zhu, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3471">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the global distance is less relevant since label information will be propagated from labeled points through the entirespace.
</prevsent>
<prevsent>this is why lp works well with local distance measure that might be unsuitable as global distance measure.applications of lp include handwriting recognition (zhu and ghahramani, 2002), image classification (balcan et al, 2005) and retrieval (qin et al., 2005), and protein classification (weston et al, 2003).
</prevsent>
</prevsection>
<citsent citstr=" P06-1017 ">
in nlp, label propagation has been used forword sense disambiguation (niu et al, 2005), <papid> P05-1049 </papid>document classification (zhu, 2005), sentiment analysis (goldberg and zhu, 2006), <papid> W06-3808 </papid>and relation extraction (chen et al, 2006).<papid> P06-1017 </papid></citsent>
<aftsection>
<nextsent>2.2 graph construction.
</nextsent>
<nextsent>one of the main problems in lp, as well as othergraph-based learning techniques, is how to best construct the graph.
</nextsent>
<nextsent>currently, graph construction is more of an art than science?
</nextsent>
<nextsent>(zhu, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3472">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> tasks.  </section>
<citcontext>
<prevsection>
<prevsent>we have also experimented with shorter suffixes and with prefixes but those features tended to degrade performance.
</prevsent>
<prevsent>4.2 senseval-3 word sense disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" W04-0807 ">
task the second task is word sense disambiguation using the senseval-3 corpus (mihalcea et al, 2004), <papid> W04-0807 </papid>to enable comparison of our method with previously published results.</citsent>
<aftsection>
<nextsent>the goal is to disambiguate the different senses of each of 57 words given the sentences within which they occur.
</nextsent>
<nextsent>there are 7860 samples for training and 3944 for testing.
</nextsent>
<nextsent>in line with existing work (lee and ng, 2002; niu et al, 2005), <papid> P05-1049 </papid>we use the following features: ? integer ? 7: seven features consisting of the pos of the previous three words, the pos of the next three words, and the pos of the worditself.</nextsent>
<nextsent>we used the mxpost tagger (ratna parkhi, 1996) <papid> W96-0213 </papid>for pos annotation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3475">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> tasks.  </section>
<citcontext>
<prevsection>
<prevsent>there are 7860 samples for training and 3944 for testing.
</prevsent>
<prevsent>in line with existing work (lee and ng, 2002; niu et al, 2005), <papid> P05-1049 </papid>we use the following features: ? integer ? 7: seven features consisting of the pos of the previous three words, the pos of the next three words, and the pos of the worditself.</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
we used the mxpost tagger (ratna parkhi, 1996) <papid> W96-0213 </papid>for pos annotation.</citsent>
<aftsection>
<nextsent>integer variable length?: bag of all words in the surrounding context.
</nextsent>
<nextsent>integer ? 15: local collocations cij (i, are the bounds of the collocation window)word combinations from the context of the word to disambiguate.
</nextsent>
<nextsent>in addition to the 11 collocations used in similar work (lee and ng, 2002), we also used c3,1, c3,2, c2,3, c1,3.
</nextsent>
<nextsent>note that syntactic features, which have been used in some previous studies on this dataset (mohammad and pedersen, 2004), <papid> W04-0839 </papid>were not included.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3476">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> tasks.  </section>
<citcontext>
<prevsection>
<prevsent>integer ? 15: local collocations cij (i, are the bounds of the collocation window)word combinations from the context of the word to disambiguate.
</prevsent>
<prevsent>in addition to the 11 collocations used in similar work (lee and ng, 2002), we also used c3,1, c3,2, c2,3, c1,3.
</prevsent>
</prevsection>
<citsent citstr=" W04-0839 ">
note that syntactic features, which have been used in some previous studies on this dataset (mohammad and pedersen, 2004), <papid> W04-0839 </papid>were not included.</citsent>
<aftsection>
<nextsent>we apply asimple feature selection method: feature is selected if the conditional entropy h(y |x) is above fixed threshold (1 bit) in the training set, and if xalso occurs in the test set (note that no label information from the test data is used for this purpose).
</nextsent>
<nextsent>for both tasks we compare the performance of supervised classifier, label propagation using the standard input features and either euclidean or cosine distance, and lp using the output from first-pass supervised classifier.
</nextsent>
<nextsent>5.1 lexicon acquisition task.
</nextsent>
<nextsent>5.1.1 first-pass classifier for this task, the first-pass classifier is multilayer perceptron (mlp) with the topology shownin fig.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3483">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the gain of the best data-driven lp over the knowledge-based lp is significant in the 100% and 75% cases.
</prevsent>
<prevsent># system acc.
</prevsent>
</prevsection>
<citsent citstr=" W04-0831 ">
(%) 1 htsa3 (grozea, 2004) <papid> W04-0831 </papid>72.9 2 irst-kernels (strapparava et al, 2004) <papid> W04-0856 </papid>72.6.</citsent>
<aftsection>
<nextsent>3 nusels (lee et al, 2004) <papid> W04-0834 </papid>72.4 4 senseval-3 contest baseline 55.2.</nextsent>
<nextsent>5 niu et al (niu et al, 2005) <papid> P05-1049 </papid>lp/j-s 70.3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3484">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the gain of the best data-driven lp over the knowledge-based lp is significant in the 100% and 75% cases.
</prevsent>
<prevsent># system acc.
</prevsent>
</prevsection>
<citsent citstr=" W04-0856 ">
(%) 1 htsa3 (grozea, 2004) <papid> W04-0831 </papid>72.9 2 irst-kernels (strapparava et al, 2004) <papid> W04-0856 </papid>72.6.</citsent>
<aftsection>
<nextsent>3 nusels (lee et al, 2004) <papid> W04-0834 </papid>72.4 4 senseval-3 contest baseline 55.2.</nextsent>
<nextsent>5 niu et al (niu et al, 2005) <papid> P05-1049 </papid>lp/j-s 70.3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3485">
<title id=" N07-1026.xml">data driven graph construction for semi supervised graph based learning in nlp </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent># system acc.
</prevsent>
<prevsent>(%) 1 htsa3 (grozea, 2004) <papid> W04-0831 </papid>72.9 2 irst-kernels (strapparava et al, 2004) <papid> W04-0856 </papid>72.6.</prevsent>
</prevsection>
<citsent citstr=" W04-0834 ">
3 nusels (lee et al, 2004) <papid> W04-0834 </papid>72.4 4 senseval-3 contest baseline 55.2.</citsent>
<aftsection>
<nextsent>5 niu et al (niu et al, 2005) <papid> P05-1049 </papid>lp/j-s 70.3.</nextsent>
<nextsent>table 2: accuracy results of other published systems onsenseval-3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3490">
<title id=" N03-2015.xml">unsupervised learning of morphology for english and inuktitut </title>
<section> searching for hubs.  </section>
<citcontext>
<prevsection>
<prevsent>there will be other nodes that are not obvious hubs.
</prevsent>
<prevsent>some may have high out-degree but an in-degree of one; others will have high in-degree but an out-degree of one.
</prevsent>
</prevsection>
<citsent citstr=" W00-0712 ">
many researchers, including schone and jurafsky (2000), <papid> W00-0712 </papid>harris (1958), and djean (1998), suggest looking for nodes with high branching (out-degree) or large number of continuations.</citsent>
<aftsection>
<nextsent>that technique is also used as the first step in goldsmiths (2001) search for signatures.
</nextsent>
<nextsent>however, without further processing, such nodes are not reliable morpheme boundaries.other candidate hubs are those nodes with high out degree that are direct descendants, along single path, of node with high in-degree.
</nextsent>
<nextsent>in essence, these are stretched hubs.
</nextsent>
<nextsent>figure 1 shows an idealized view of hub and stretched hub.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3491">
<title id=" N03-2015.xml">unsupervised learning of morphology for english and inuktitut </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these two techniques, hub searching and simple node merging, were implemented in program called hubmorph?
</prevsent>
<prevsent>(hub-automaton morphology).
</prevsent>
</prevsection>
<citsent citstr=" W99-0904 ">
most previous work in unsupervised learning of morphology has focused on learning the division between roots and suffixes (e.g., sproat, 1992; gaussier, 1999; <papid> W99-0904 </papid>djean, 1996; goldsmith, 2001).<papid> J01-2001 </papid></citsent>
<aftsection>
<nextsent>the hope is that the same techniques will work for extracting prefixes.however, even that will not handle the complex combinations of infixes that are possible in agglutinative languages like turkish or poly synthetic languages like inuktitut.
</nextsent>
<nextsent>this paper presents generalization of one class of techniques that search for signatures or positions in trie with large branching factor.
</nextsent>
<nextsent>goldsmith (2001) <papid> J01-2001 </papid>presents well-developed and robust version of this class and has made his system, linguist ica, freely available (goldsmith, 2002).linguistica applies wide array of techniques including heuristics and the application of the principle of minimum description length (mdl) to find the best division of words into roots and suffixes, as well as prefixes in some cases.</nextsent>
<nextsent>the first of these techniques finds the points in word with the highest number of possible successors in other words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3492">
<title id=" N03-2015.xml">unsupervised learning of morphology for english and inuktitut </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these two techniques, hub searching and simple node merging, were implemented in program called hubmorph?
</prevsent>
<prevsent>(hub-automaton morphology).
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
most previous work in unsupervised learning of morphology has focused on learning the division between roots and suffixes (e.g., sproat, 1992; gaussier, 1999; <papid> W99-0904 </papid>djean, 1996; goldsmith, 2001).<papid> J01-2001 </papid></citsent>
<aftsection>
<nextsent>the hope is that the same techniques will work for extracting prefixes.however, even that will not handle the complex combinations of infixes that are possible in agglutinative languages like turkish or poly synthetic languages like inuktitut.
</nextsent>
<nextsent>this paper presents generalization of one class of techniques that search for signatures or positions in trie with large branching factor.
</nextsent>
<nextsent>goldsmith (2001) <papid> J01-2001 </papid>presents well-developed and robust version of this class and has made his system, linguist ica, freely available (goldsmith, 2002).linguistica applies wide array of techniques including heuristics and the application of the principle of minimum description length (mdl) to find the best division of words into roots and suffixes, as well as prefixes in some cases.</nextsent>
<nextsent>the first of these techniques finds the points in word with the highest number of possible successors in other words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3494">
<title id=" N03-2015.xml">unsupervised learning of morphology for english and inuktitut </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>with all these techniques, linguist ica seeks optimal break points in each word.
</prevsent>
<prevsent>in this case, optimal means the minimal number of bits necessary to encode the whole collection.there are also techniques that attempt to use semantic cues, arguing that knowing the signatures is not sufficient for the task.
</prevsent>
</prevsection>
<citsent citstr=" P00-1027 ">
for example, yarowsky and wicentowski (2000; <papid> P00-1027 </papid>cf.</citsent>
<aftsection>
<nextsent>schone &amp; jurafsky, 2000) <papid> W00-0712 </papid>present method for determining whether singed can be split into sing and ed based on whether singed and sing appear in the same contexts.</nextsent>
<nextsent>adopting technique like this would increase the precision of hubmorph.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3496">
<title id=" N07-1029.xml">combining outputs from multiple machine translation systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years, machine translation systems based on new paradigms have emerged.
</prevsent>
<prevsent>these systems employ more than just the surface-level information used by the state-of-the-art phrase-based translation systems.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
for example, hierarchical (chiang, 2005) <papid> P05-1033 </papid>and syntax-based (galley et al, 2006) <papid> P06-1121 </papid>systems have recently improved in both accuracy and scalability.</citsent>
<aftsection>
<nextsent>combined with the latest advances in phrase-based translation systems, it has become more attractive to take advantage of the various outputs informing consensus translations (frederking and nirenburg, 1994; <papid> A94-1016 </papid>bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006).<papid> E06-1005 </papid>system combination has been successfully applied in state-of-the-art speech recognition evaluation systems for several years (fiscus, 1997).</nextsent>
<nextsent>even though the underlying modeling techniques are similar, many systems produce very different outputs with approximately the same accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3497">
<title id=" N07-1029.xml">combining outputs from multiple machine translation systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years, machine translation systems based on new paradigms have emerged.
</prevsent>
<prevsent>these systems employ more than just the surface-level information used by the state-of-the-art phrase-based translation systems.
</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
for example, hierarchical (chiang, 2005) <papid> P05-1033 </papid>and syntax-based (galley et al, 2006) <papid> P06-1121 </papid>systems have recently improved in both accuracy and scalability.</citsent>
<aftsection>
<nextsent>combined with the latest advances in phrase-based translation systems, it has become more attractive to take advantage of the various outputs informing consensus translations (frederking and nirenburg, 1994; <papid> A94-1016 </papid>bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006).<papid> E06-1005 </papid>system combination has been successfully applied in state-of-the-art speech recognition evaluation systems for several years (fiscus, 1997).</nextsent>
<nextsent>even though the underlying modeling techniques are similar, many systems produce very different outputs with approximately the same accuracy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3498">
<title id=" N07-1029.xml">combining outputs from multiple machine translation systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these systems employ more than just the surface-level information used by the state-of-the-art phrase-based translation systems.
</prevsent>
<prevsent>for example, hierarchical (chiang, 2005) <papid> P05-1033 </papid>and syntax-based (galley et al, 2006) <papid> P06-1121 </papid>systems have recently improved in both accuracy and scalability.</prevsent>
</prevsection>
<citsent citstr=" A94-1016 ">
combined with the latest advances in phrase-based translation systems, it has become more attractive to take advantage of the various outputs informing consensus translations (frederking and nirenburg, 1994; <papid> A94-1016 </papid>bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006).<papid> E06-1005 </papid>system combination has been successfully applied in state-of-the-art speech recognition evaluation systems for several years (fiscus, 1997).</citsent>
<aftsection>
<nextsent>even though the underlying modeling techniques are similar, many systems produce very different outputs with approximately the same accuracy.
</nextsent>
<nextsent>one of the most successful approaches is consensus network decoding (mangu et al, 2000) which assumes that the confidence of word in certain position is based on the sum of confidences from each system output having the word in that position.
</nextsent>
<nextsent>this requires aligning the system outputs to form consensus network and ? during decoding ? simply finding the highest scoring path through this network.
</nextsent>
<nextsent>the alignment of speech recognition outputs is fairly straightforward due to the strict constraint in word order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3499">
<title id=" N07-1029.xml">combining outputs from multiple machine translation systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these systems employ more than just the surface-level information used by the state-of-the-art phrase-based translation systems.
</prevsent>
<prevsent>for example, hierarchical (chiang, 2005) <papid> P05-1033 </papid>and syntax-based (galley et al, 2006) <papid> P06-1121 </papid>systems have recently improved in both accuracy and scalability.</prevsent>
</prevsection>
<citsent citstr=" P05-3026 ">
combined with the latest advances in phrase-based translation systems, it has become more attractive to take advantage of the various outputs informing consensus translations (frederking and nirenburg, 1994; <papid> A94-1016 </papid>bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006).<papid> E06-1005 </papid>system combination has been successfully applied in state-of-the-art speech recognition evaluation systems for several years (fiscus, 1997).</citsent>
<aftsection>
<nextsent>even though the underlying modeling techniques are similar, many systems produce very different outputs with approximately the same accuracy.
</nextsent>
<nextsent>one of the most successful approaches is consensus network decoding (mangu et al, 2000) which assumes that the confidence of word in certain position is based on the sum of confidences from each system output having the word in that position.
</nextsent>
<nextsent>this requires aligning the system outputs to form consensus network and ? during decoding ? simply finding the highest scoring path through this network.
</nextsent>
<nextsent>the alignment of speech recognition outputs is fairly straightforward due to the strict constraint in word order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3500">
<title id=" N07-1029.xml">combining outputs from multiple machine translation systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these systems employ more than just the surface-level information used by the state-of-the-art phrase-based translation systems.
</prevsent>
<prevsent>for example, hierarchical (chiang, 2005) <papid> P05-1033 </papid>and syntax-based (galley et al, 2006) <papid> P06-1121 </papid>systems have recently improved in both accuracy and scalability.</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
combined with the latest advances in phrase-based translation systems, it has become more attractive to take advantage of the various outputs informing consensus translations (frederking and nirenburg, 1994; <papid> A94-1016 </papid>bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006).<papid> E06-1005 </papid>system combination has been successfully applied in state-of-the-art speech recognition evaluation systems for several years (fiscus, 1997).</citsent>
<aftsection>
<nextsent>even though the underlying modeling techniques are similar, many systems produce very different outputs with approximately the same accuracy.
</nextsent>
<nextsent>one of the most successful approaches is consensus network decoding (mangu et al, 2000) which assumes that the confidence of word in certain position is based on the sum of confidences from each system output having the word in that position.
</nextsent>
<nextsent>this requires aligning the system outputs to form consensus network and ? during decoding ? simply finding the highest scoring path through this network.
</nextsent>
<nextsent>the alignment of speech recognition outputs is fairly straightforward due to the strict constraint in word order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3502">
<title id=" N07-1029.xml">combining outputs from multiple machine translation systems </title>
<section> evaluation metrics and discriminative.  </section>
<citcontext>
<prevsection>
<prevsent>        fffiflffi!
</prevsent>
<prevsent># $%ffi!&amp;# )(   * +-,.,0/ (1)where $ is the total number of words in the reference translation    . in the case of multiple references, the edits are counted against all references,   is the average number of words in the reference translations and the final ter is computed using the minimum number of edits.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the nist bleu-4 is avariant of bleu (papineni et al, 2002) <papid> P02-1040 </papid>and is computed as 132 45      6 7 98!: ; + =?  @ acbed figf.hji      6 kml      6 (2) where a   n  6 is the precision of -grams in the hypothesis   given the reference    and   n  6 qp + is brevity penalty.</citsent>
<aftsection>
<nextsent>the -gram counts from multiple references are accumulated in estimating the precisions.
</nextsent>
<nextsent>all system combination methods presented in this paper may be tuned to directly optimize either one of these automatic evaluation metrics.
</nextsent>
<nextsent>the tuning uses  -best lists of hypotheses with various feature scores.
</nextsent>
<nextsent>the feature scores may be combined with tunable weights forming an arbitrary scoring function.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3503">
<title id=" N07-1029.xml">combining outputs from multiple machine translation systems </title>
<section> evaluation metrics and discriminative.  </section>
<citcontext>
<prevsection>
<prevsent>as searching repeatedly through the set of basis vectors is inefficient, the direction of 229the vectors is gradually moved toward larger positive change in the evaluation metric.
</prevsent>
<prevsent>to improve the chances of finding global optimum, the algorithm is repeated with varying initial values.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the modified powells method has been previously used in optimizing the weights of standard feature-based mtdecoder in (och, 2003) <papid> P03-1021 </papid>where more efficient algorithm for log-linear models was proposed.</citsent>
<aftsection>
<nextsent>however, this is specific to log-linear models and cannot be easily extended for more complicated functions.
</nextsent>
<nextsent>the first combination method is based on re-ranking merged  -best list.
</nextsent>
<nextsent>a confidence score from each system is assigned to each unique hypothesis in th emerged list.
</nextsent>
<nextsent>the confidence scores for each hypothesis are used to produce single score which, combined with 5-gram language model score, determines new ranking of the hypotheses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3504">
<title id=" N07-1029.xml">combining outputs from multiple machine translation systems </title>
<section> phrase-level combination.  </section>
<citcontext>
<prevsection>
<prevsent>the phrase-level combination is based on extracting new phrase translation table from each systems target-to-source phrase alignments and re-decoding the source sentence using this new translation table and language model.
</prevsent>
<prevsent>in this work, the target-to source phrase alignments were available from the individual systems.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
if the alignments are not available, they can be automatically generated; e.g., using giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>the phrase translation table is generated for each source sentence using confidence scores derived from sentence poste riors with system-specific total score scaling factors and similarity scores based on the agreement among the phrases from all systems.
</nextsent>
<nextsent>4.1 phrase confidence estimation.
</nextsent>
<nextsent>each phrase has an initial confidence based on the sentence posterior
</nextsent>
<nextsent> estimated from an  -best listin the same fashion as in section 3.2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3506">
<title id=" N06-2011.xml">spectral clustering for example based machine translation </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" C00-1019 ">
prior work has shown that generalization of data in an example based machine translation (ebmt) system, reduces the amount of pre-translated text required to achieve certain level of accuracy (brown, 2000).<papid> C00-1019 </papid></citsent>
<aftsection>
<nextsent>several word clustering algorithms have been suggested to perform these generalizations, such as kmeans clustering or group average clustering.
</nextsent>
<nextsent>the hypothesis is that better contextual clustering can lead to better translation accuracy with limited training data.
</nextsent>
<nextsent>in this paper, we use form of spectral clustering to cluster words, and this isshown to result in as much as 29.08% improvement over the baseline ebmt system.
</nextsent>
<nextsent>in ebmt, the source sentence to be translated is matched against the source language sentences present in corpus of source-target sentence pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3512">
<title id=" N06-2011.xml">spectral clustering for example based machine translation </title>
<section> term vectors for clustering.  </section>
<citcontext>
<prevsection>
<prevsent>sec 41 tion 4 lists results obtained in full evaluation of thealgorithm.
</prevsent>
<prevsent>section 5 concludes and discusses directions for future work.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
using bilingual dictionary, usually created using statistical methods such as those of (brown et. al., 1990) <papid> J90-2002 </papid>or (brown, 1997), and the parallel text, rough mapping between source and target words canbe created.</citsent>
<aftsection>
<nextsent>this word pair is then treated as an indivisible token for future processing.
</nextsent>
<nextsent>for each such word pair we then accumulate counts for each token in the surrounding context of its occurrences (n words, currently 3, immediately prior to and words immediately following).
</nextsent>
<nextsent>the counts are weighted with respect to distance from occurrence,with linear decay (from 1 to 1/n) to give greatest importance to the words immediately adjacent to the word pair being examined.
</nextsent>
<nextsent>these counts form apseudo-document for each pair, which are then converted into term vectors for clustering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3515">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a dependency parse tree encodes useful semantic information for several language processing tasks.
</prevsent>
<prevsent>dependency parsing is simpler task than constituent parsing, since dependency trees do not have extra non-terminal nodes and there is no need for agr ammar to generate them.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
approaches to dependency parsing either generate such trees by considering all possible spanning trees (mcdonald et al, 2005), <papid> H05-1066 </papid>or build single tree on the fly by means of shift-reduce parsing actions (yamada &amp; matsumoto, 2003).</citsent>
<aftsection>
<nextsent>in particular, nivre and scholz (2004) <papid> C04-1010 </papid>and attardi (2006) <papid> W06-2922 </papid>have developed deterministic dependency parsers with linear complexity, suitable for processing large amounts of text, as required, forex ample, in information retrieval applications.</nextsent>
<nextsent>we investigate novel revision approach to dependency parsing related to re-ranking and transformation-based methods (brill, 1993; <papid> P93-1035 </papid>brill, 1995; collins, 2000; charniak &amp; johnson, 2005; <papid> P05-1022 </papid>collins &amp; koo, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3516">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency parsing is simpler task than constituent parsing, since dependency trees do not have extra non-terminal nodes and there is no need for agr ammar to generate them.
</prevsent>
<prevsent>approaches to dependency parsing either generate such trees by considering all possible spanning trees (mcdonald et al, 2005), <papid> H05-1066 </papid>or build single tree on the fly by means of shift-reduce parsing actions (yamada &amp; matsumoto, 2003).</prevsent>
</prevsection>
<citsent citstr=" C04-1010 ">
in particular, nivre and scholz (2004) <papid> C04-1010 </papid>and attardi (2006) <papid> W06-2922 </papid>have developed deterministic dependency parsers with linear complexity, suitable for processing large amounts of text, as required, forex ample, in information retrieval applications.</citsent>
<aftsection>
<nextsent>we investigate novel revision approach to dependency parsing related to re-ranking and transformation-based methods (brill, 1993; <papid> P93-1035 </papid>brill, 1995; collins, 2000; charniak &amp; johnson, 2005; <papid> P05-1022 </papid>collins &amp; koo, 2006).</nextsent>
<nextsent>similarly to re-ranking, the second stage attempts to improve the output of abase parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3518">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency parsing is simpler task than constituent parsing, since dependency trees do not have extra non-terminal nodes and there is no need for agr ammar to generate them.
</prevsent>
<prevsent>approaches to dependency parsing either generate such trees by considering all possible spanning trees (mcdonald et al, 2005), <papid> H05-1066 </papid>or build single tree on the fly by means of shift-reduce parsing actions (yamada &amp; matsumoto, 2003).</prevsent>
</prevsection>
<citsent citstr=" W06-2922 ">
in particular, nivre and scholz (2004) <papid> C04-1010 </papid>and attardi (2006) <papid> W06-2922 </papid>have developed deterministic dependency parsers with linear complexity, suitable for processing large amounts of text, as required, forex ample, in information retrieval applications.</citsent>
<aftsection>
<nextsent>we investigate novel revision approach to dependency parsing related to re-ranking and transformation-based methods (brill, 1993; <papid> P93-1035 </papid>brill, 1995; collins, 2000; charniak &amp; johnson, 2005; <papid> P05-1022 </papid>collins &amp; koo, 2006).</nextsent>
<nextsent>similarly to re-ranking, the second stage attempts to improve the output of abase parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3520">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>approaches to dependency parsing either generate such trees by considering all possible spanning trees (mcdonald et al, 2005), <papid> H05-1066 </papid>or build single tree on the fly by means of shift-reduce parsing actions (yamada &amp; matsumoto, 2003).</prevsent>
<prevsent>in particular, nivre and scholz (2004) <papid> C04-1010 </papid>and attardi (2006) <papid> W06-2922 </papid>have developed deterministic dependency parsers with linear complexity, suitable for processing large amounts of text, as required, forex ample, in information retrieval applications.</prevsent>
</prevsection>
<citsent citstr=" P93-1035 ">
we investigate novel revision approach to dependency parsing related to re-ranking and transformation-based methods (brill, 1993; <papid> P93-1035 </papid>brill, 1995; collins, 2000; charniak &amp; johnson, 2005; <papid> P05-1022 </papid>collins &amp; koo, 2006).</citsent>
<aftsection>
<nextsent>similarly to re-ranking, the second stage attempts to improve the output of abase parser.
</nextsent>
<nextsent>instead of re-ranking n-best candidate parses, our method works by revising single parse tree, either the first-best or the one constructed by deterministic shift-reduce parser, as intransformation-based learning.
</nextsent>
<nextsent>parse trees are revised by applying rules which replace incorrect with correct dependencies.
</nextsent>
<nextsent>these rules are learned by comparing correct parse trees with incorrect trees produced by the base parser on training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3522">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>approaches to dependency parsing either generate such trees by considering all possible spanning trees (mcdonald et al, 2005), <papid> H05-1066 </papid>or build single tree on the fly by means of shift-reduce parsing actions (yamada &amp; matsumoto, 2003).</prevsent>
<prevsent>in particular, nivre and scholz (2004) <papid> C04-1010 </papid>and attardi (2006) <papid> W06-2922 </papid>have developed deterministic dependency parsers with linear complexity, suitable for processing large amounts of text, as required, forex ample, in information retrieval applications.</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
we investigate novel revision approach to dependency parsing related to re-ranking and transformation-based methods (brill, 1993; <papid> P93-1035 </papid>brill, 1995; collins, 2000; charniak &amp; johnson, 2005; <papid> P05-1022 </papid>collins &amp; koo, 2006).</citsent>
<aftsection>
<nextsent>similarly to re-ranking, the second stage attempts to improve the output of abase parser.
</nextsent>
<nextsent>instead of re-ranking n-best candidate parses, our method works by revising single parse tree, either the first-best or the one constructed by deterministic shift-reduce parser, as intransformation-based learning.
</nextsent>
<nextsent>parse trees are revised by applying rules which replace incorrect with correct dependencies.
</nextsent>
<nextsent>these rules are learned by comparing correct parse trees with incorrect trees produced by the base parser on training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3523">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluated our model on the treebanks of english and swedish.
</prevsent>
<prevsent>the experimental results show relative error reduction of, respectively, 16% and 11% with respect to the base parser, achieving state of accuracy on swedish.
</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
detection of dependency relations can be useful in tasks such as information extraction (culotta &amp; sorensen, 2004), <papid> P04-1054 </papid>lexical acquisition (snow et al, 2005), ontology learning (ciaramita et al, 2005), and machine translation (ding &amp; palmer, 2005).<papid> P05-1067 </papid>a dependency parser is trained on corpus annotated with lexical dependencies, which are easier to produce by annotators without deep linguistic knowledge and are becoming available in many languages (buchholz &amp; marsi, 2006).<papid> W06-2920 </papid></citsent>
<aftsection>
<nextsent>recent developments in dependency parsing show that deterministic parsers can achieve good accuracy (nivre &amp; scholz, 2004), <papid> C04-1010 </papid>and high performance, in the range of hundreds of sentences per second (attardi, 2006).<papid> W06-2922 </papid></nextsent>
<nextsent>a dependency parser takes as input sentence and returns dependency graph g. let ={d1, d2, ..., dm} be the set of permissible dependency types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3524">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluated our model on the treebanks of english and swedish.
</prevsent>
<prevsent>the experimental results show relative error reduction of, respectively, 16% and 11% with respect to the base parser, achieving state of accuracy on swedish.
</prevsent>
</prevsection>
<citsent citstr=" P05-1067 ">
detection of dependency relations can be useful in tasks such as information extraction (culotta &amp; sorensen, 2004), <papid> P04-1054 </papid>lexical acquisition (snow et al, 2005), ontology learning (ciaramita et al, 2005), and machine translation (ding &amp; palmer, 2005).<papid> P05-1067 </papid>a dependency parser is trained on corpus annotated with lexical dependencies, which are easier to produce by annotators without deep linguistic knowledge and are becoming available in many languages (buchholz &amp; marsi, 2006).<papid> W06-2920 </papid></citsent>
<aftsection>
<nextsent>recent developments in dependency parsing show that deterministic parsers can achieve good accuracy (nivre &amp; scholz, 2004), <papid> C04-1010 </papid>and high performance, in the range of hundreds of sentences per second (attardi, 2006).<papid> W06-2922 </papid></nextsent>
<nextsent>a dependency parser takes as input sentence and returns dependency graph g. let ={d1, d2, ..., dm} be the set of permissible dependency types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3525">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> dependency parsing.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluated our model on the treebanks of english and swedish.
</prevsent>
<prevsent>the experimental results show relative error reduction of, respectively, 16% and 11% with respect to the base parser, achieving state of accuracy on swedish.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
detection of dependency relations can be useful in tasks such as information extraction (culotta &amp; sorensen, 2004), <papid> P04-1054 </papid>lexical acquisition (snow et al, 2005), ontology learning (ciaramita et al, 2005), and machine translation (ding &amp; palmer, 2005).<papid> P05-1067 </papid>a dependency parser is trained on corpus annotated with lexical dependencies, which are easier to produce by annotators without deep linguistic knowledge and are becoming available in many languages (buchholz &amp; marsi, 2006).<papid> W06-2920 </papid></citsent>
<aftsection>
<nextsent>recent developments in dependency parsing show that deterministic parsers can achieve good accuracy (nivre &amp; scholz, 2004), <papid> C04-1010 </papid>and high performance, in the range of hundreds of sentences per second (attardi, 2006).<papid> W06-2922 </papid></nextsent>
<nextsent>a dependency parser takes as input sentence and returns dependency graph g. let ={d1, d2, ..., dm} be the set of permissible dependency types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3542">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> learning revision model.  </section>
<citcontext>
<prevsection>
<prevsent>(10) the only adjustable parameter in this model is the number of instances to use for training.
</prevsent>
<prevsent>we chose by means of validation on the development data, typically with value around 10 times the size of the training data.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
for regularization purposes we adopt an average perceptron (collins, 2002) <papid> W02-1001 </papid>which returns for each y, = 1t t=1 ? y, the average of all weight vectors ty posited during training.</citsent>
<aftsection>
<nextsent>the perceptron was chosen because outperformed other algorithms we experimented with (maxent, mbl and svm), particularly when including feature pairs, as discussed later.
</nextsent>
<nextsent>5.2 features.
</nextsent>
<nextsent>we used as features for the revision phase the same type of features used for training the parser (de scribed in section 3).
</nextsent>
<nextsent>this does not have to be the case in general.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3543">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> learning revision model.  </section>
<citcontext>
<prevsection>
<prevsent>cases.
</prevsent>
<prevsent>if predicted, y0, similarly to y1, has no effect on the dependency.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
occasionally, in 59 sentences out of 2416 on section 23 of the wall street journal penn tree bank (marcus et al, 1993), <papid> J93-2004 </papid>the shift-reduce parser fails to attach node to head, producing disconnected graph.</citsent>
<aftsection>
<nextsent>the disconnected node will appear as root, having no head.
</nextsent>
<nextsent>the problem occurs most often on punctuations (66/84 on wsj section 23), so it affects only marginally the accuracy scores(uas, las) as computed in the conll-x evaluation (buchholz &amp; marsi, 2006).<papid> W06-2920 </papid></nextsent>
<nextsent>a final step of the revision deals with multiple roots, using heuristic rule it selects one of the disconnected sub-trees as root, verb, and attaches all sub-trees to it.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3548">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this finding suggests that itmay be worth while experimenting with all possible revision-model/base-parser pairs as well as exploring alternative ways for generating data for the revision model; e.g., by cross-validation.table 4 summarizes the results on the penn tree bank.
</prevsent>
<prevsent>revision models are evaluated on the output of desr-mbl.
</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
the table also reports the scores obtained on the same dataset by by the shift reduce parsers of nivre and scholzs (2004) <papid> C04-1010 </papid>and yamada and matsumoto (2003), and mcdonald and pereirassecond-order maximum spanning tree parser (mc donald &amp; pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>however the scores are not directly comparable, since in our experiments we used the settings of the conll-x shared task, which provide correct pos tags to the parser.
</nextsent>
<nextsent>on the swedish treebank collection we trained revision model (revision-me) on the output ofthe maxent base parser.
</nextsent>
<nextsent>we parsed the evaluation data with the svm base parser (desr-svm) which achieves 88.41 uas.
</nextsent>
<nextsent>the revision model achieves 89.76 uas, with relative error reduction of 11.64%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3552">
<title id=" N07-1049.xml">tree revision learning for dependency parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>with respect to transformation-based methods, our method does not attempt to build tree but only to revise it.
</prevsent>
<prevsent>that is, it defines different output space from the base parsers: the possible revisions on the graph.
</prevsent>
</prevsection>
<citsent citstr=" P02-1063 ">
the revision model of nakagawa et al (2002) <papid> P02-1063 </papid>applies second classifier for deciding whether the predictions of base learner are accurate.</citsent>
<aftsection>
<nextsent>however, the model only makes binary decision, which is suitable for the simpler problem of pos tagging.
</nextsent>
<nextsent>the work of hall and novak (hall &amp; novak, 2005)is the closest to ours.
</nextsent>
<nextsent>hall and novak develop corrective model for constituency parsing in order to recover non-projective dependencies, which standard constituent parser does not handle.
</nextsent>
<nextsent>the technique is applied to parsing czech.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3553">
<title id=" N06-4009.xml">sconeedit a text guided domain knowledge editor </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 text view.
</prevsent>
<prevsent>in traditional ontology browser, the user starts looking for concepts of interest by typing words and phrases into search field.
</prevsent>
</prevsection>
<citsent citstr=" W04-3102 ">
this is the model for several existing tools, including the visdic viewer for wordnet (hork and smr?, 2004), the inoh ontology viewer (inoh, 2004), and the gene ontology viewer presented by koike and takagi (2004), <papid> W04-3102 </papid>among others.</citsent>
<aftsection>
<nextsent>sconeedit improves on this browsing paradigm by giving user who is unfamiliar with the knowledge base an easy way to start exploring.
</nextsent>
<nextsent>rather than generating series of guesses at what may be figure 2.
</nextsent>
<nextsent>excerpt from text view, with search and text tabs covered by the kb, the user can load natural language text into sconeedit from file or the system clipboard.
</nextsent>
<nextsent>we take an article from xinhua net news service (xinhuanet, 2006) as an example.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3554">
<title id=" N07-1034.xml">combining re information learning with information state update rules </title>
<section> reinforcement learning (rl).  </section>
<citcontext>
<prevsection>
<prevsent>in the work of levin, pieraccini, and eckert (2000), rl was used to choose between all actions.
</prevsent>
<prevsent>actions that resulted in in felicitous speech act sequences were allowed, such as asking the value of parameter that is already known, asking if parameter can be relaxed when the value of the parameter is not even known, or displaying values when database query has not yet been performed.
</prevsent>
</prevsection>
<citsent citstr=" H05-1127 ">
in other work, rl has been used to choose among subset of the actions in certain states (walker, 2000; singh et al, 2002; scheffler and young, 2002;english and heeman, 2005).<papid> H05-1127 </papid></citsent>
<aftsection>
<nextsent>however, no formal framework is given to specify which actions to choose from.
</nextsent>
<nextsent>270furthermore, none of the approaches used formal specification for updating the rl variables aftera speech action, nor for expressing the user simulation.
</nextsent>
<nextsent>as rl is applied to more complex tasks, with more complex speech actions, this will lead to difficulty in encoding the correct behavior.georgila, henderson, and lemon (2005) advocated the use of is to specify the dialogue context for learning user simulations needed in rl.
</nextsent>
<nextsent>how ever, they did not combine hand-crafted with learned preconditions, and it is unclear whether they used is to update the dialogue context,
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3555">
<title id=" N07-1034.xml">combining re information learning with information state update rules </title>
<section> information state (is).  </section>
<citcontext>
<prevsection>
<prevsent>is has been concerned with capturing how to up date the state of dialogue system in order to build advanced dialogue systems (larsson and traum,2000).
</prevsent>
<prevsent>for example, it has been used to build systems that allow for both system and user initiative, over answering, confirmations, and grounding (e.g.
</prevsent>
</prevsection>
<citsent citstr=" A00-2001 ">
(bohlin et al, 1999; matheson et al, 2000)).<papid> A00-2001 </papid></citsent>
<aftsection>
<nextsent>it usesa set of state variables, whose values are manipulated by update rules, run by control strategy.
</nextsent>
<nextsent>state variables: the state variables specify the knowledge of the system at any point in the dialogue.
</nextsent>
<nextsent>this is similar to the rl variables, except that they must contain everything that is needed to completely specify the action that the system should perform, rather than just enough information to choose between competing actions.
</nextsent>
<nextsent>a number of standard variables are typically used to interface to other modules in the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3556">
<title id=" N06-1029.xml">unsupervised and semi supervised learning of tone and pitch accent </title>
<section> datasets.  </section>
<citcontext>
<prevsection>
<prevsent>using the corresponding anchor scripts, automaticallyword-segmented, as gold standard transcription, audio from the news stories was force-aligned to the text transcripts.
</prevsent>
<prevsent>the forced alignment employed the language porting functionality of the university of speech data described below contains no such instances.
</prevsent>
</prevsection>
<citsent citstr=" H01-1073 ">
2http://www.ldc.upenn.edu colorado sonic speech recognizer (pellom et al, 2001).<papid> H01-1073 </papid></citsent>
<aftsection>
<nextsent>a mapping from the transcriptions to english phone sequences supported by sonic was created using chinese character-pinyin pronunciation dictionary and manually constructed mapping frompinyin sequences to the closest corresponding english phone sequences.3 2.3 acoustic features.
</nextsent>
<nextsent>using praats (boersma, 2001) to pitch?
</nextsent>
<nextsent>and to intensity?
</nextsent>
<nextsent>functions and the alignments generated above, we extract acoustic features for the prosodic region of interest.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3557">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>detecting entities, whether named, nominal or pronominal, in unrestricted text is crucial step toward understanding the text, as it identifies the important conceptual objects in discourse.
</prevsent>
<prevsent>it is also necessary step for identifying the relations present in the text and populatinga knowledge database.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
this task has applications in information extraction and summarization, information retrieval (one can get al hits for washington/person and not the ones for washington/state or washington/city), data mining and question answering.the entity detection and tracking task (edt hence forth) has close ties to the named entity recognition (ner) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (bikel et al, 1997; <papid> A97-1029 </papid>borthwick et al, 1998; <papid> W98-1118 </papid>mikheev et al, 1999; <papid> E99-1001 </papid>miller et al, 1998; aberdeen et al, 1995; <papid> M95-1012 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>soon et al, 2001), <papid> J01-4004 </papid>and have been at the center of several evaluations: muc-6, muc-7,conll02 and conll03 shared tasks.</citsent>
<aftsection>
<nextsent>usually, in computational linguistic literature, named entity represent san instance of name, either location, person, an organization, and the ner task consists of identifying each individual occurrence of such an entity.
</nextsent>
<nextsent>we will instead adopt the nomenclature of the automatic content extraction program1 (nist, 2003a): we will call the instances of textual references to objects or abstractions mentions, which can be either named (e.g. john mayor), nominal (e.g. the president) or pronominal (e.g. she, it).
</nextsent>
<nextsent>an entity consists of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>for instance, in the sentence president john smith said he has no comments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3558">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>detecting entities, whether named, nominal or pronominal, in unrestricted text is crucial step toward understanding the text, as it identifies the important conceptual objects in discourse.
</prevsent>
<prevsent>it is also necessary step for identifying the relations present in the text and populatinga knowledge database.
</prevsent>
</prevsection>
<citsent citstr=" W98-1118 ">
this task has applications in information extraction and summarization, information retrieval (one can get al hits for washington/person and not the ones for washington/state or washington/city), data mining and question answering.the entity detection and tracking task (edt hence forth) has close ties to the named entity recognition (ner) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (bikel et al, 1997; <papid> A97-1029 </papid>borthwick et al, 1998; <papid> W98-1118 </papid>mikheev et al, 1999; <papid> E99-1001 </papid>miller et al, 1998; aberdeen et al, 1995; <papid> M95-1012 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>soon et al, 2001), <papid> J01-4004 </papid>and have been at the center of several evaluations: muc-6, muc-7,conll02 and conll03 shared tasks.</citsent>
<aftsection>
<nextsent>usually, in computational linguistic literature, named entity represent san instance of name, either location, person, an organization, and the ner task consists of identifying each individual occurrence of such an entity.
</nextsent>
<nextsent>we will instead adopt the nomenclature of the automatic content extraction program1 (nist, 2003a): we will call the instances of textual references to objects or abstractions mentions, which can be either named (e.g. john mayor), nominal (e.g. the president) or pronominal (e.g. she, it).
</nextsent>
<nextsent>an entity consists of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>for instance, in the sentence president john smith said he has no comments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3559">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>detecting entities, whether named, nominal or pronominal, in unrestricted text is crucial step toward understanding the text, as it identifies the important conceptual objects in discourse.
</prevsent>
<prevsent>it is also necessary step for identifying the relations present in the text and populatinga knowledge database.
</prevsent>
</prevsection>
<citsent citstr=" E99-1001 ">
this task has applications in information extraction and summarization, information retrieval (one can get al hits for washington/person and not the ones for washington/state or washington/city), data mining and question answering.the entity detection and tracking task (edt hence forth) has close ties to the named entity recognition (ner) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (bikel et al, 1997; <papid> A97-1029 </papid>borthwick et al, 1998; <papid> W98-1118 </papid>mikheev et al, 1999; <papid> E99-1001 </papid>miller et al, 1998; aberdeen et al, 1995; <papid> M95-1012 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>soon et al, 2001), <papid> J01-4004 </papid>and have been at the center of several evaluations: muc-6, muc-7,conll02 and conll03 shared tasks.</citsent>
<aftsection>
<nextsent>usually, in computational linguistic literature, named entity represent san instance of name, either location, person, an organization, and the ner task consists of identifying each individual occurrence of such an entity.
</nextsent>
<nextsent>we will instead adopt the nomenclature of the automatic content extraction program1 (nist, 2003a): we will call the instances of textual references to objects or abstractions mentions, which can be either named (e.g. john mayor), nominal (e.g. the president) or pronominal (e.g. she, it).
</nextsent>
<nextsent>an entity consists of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>for instance, in the sentence president john smith said he has no comments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3560">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>detecting entities, whether named, nominal or pronominal, in unrestricted text is crucial step toward understanding the text, as it identifies the important conceptual objects in discourse.
</prevsent>
<prevsent>it is also necessary step for identifying the relations present in the text and populatinga knowledge database.
</prevsent>
</prevsection>
<citsent citstr=" M95-1012 ">
this task has applications in information extraction and summarization, information retrieval (one can get al hits for washington/person and not the ones for washington/state or washington/city), data mining and question answering.the entity detection and tracking task (edt hence forth) has close ties to the named entity recognition (ner) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (bikel et al, 1997; <papid> A97-1029 </papid>borthwick et al, 1998; <papid> W98-1118 </papid>mikheev et al, 1999; <papid> E99-1001 </papid>miller et al, 1998; aberdeen et al, 1995; <papid> M95-1012 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>soon et al, 2001), <papid> J01-4004 </papid>and have been at the center of several evaluations: muc-6, muc-7,conll02 and conll03 shared tasks.</citsent>
<aftsection>
<nextsent>usually, in computational linguistic literature, named entity represent san instance of name, either location, person, an organization, and the ner task consists of identifying each individual occurrence of such an entity.
</nextsent>
<nextsent>we will instead adopt the nomenclature of the automatic content extraction program1 (nist, 2003a): we will call the instances of textual references to objects or abstractions mentions, which can be either named (e.g. john mayor), nominal (e.g. the president) or pronominal (e.g. she, it).
</nextsent>
<nextsent>an entity consists of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>for instance, in the sentence president john smith said he has no comments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3561">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>detecting entities, whether named, nominal or pronominal, in unrestricted text is crucial step toward understanding the text, as it identifies the important conceptual objects in discourse.
</prevsent>
<prevsent>it is also necessary step for identifying the relations present in the text and populatinga knowledge database.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
this task has applications in information extraction and summarization, information retrieval (one can get al hits for washington/person and not the ones for washington/state or washington/city), data mining and question answering.the entity detection and tracking task (edt hence forth) has close ties to the named entity recognition (ner) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (bikel et al, 1997; <papid> A97-1029 </papid>borthwick et al, 1998; <papid> W98-1118 </papid>mikheev et al, 1999; <papid> E99-1001 </papid>miller et al, 1998; aberdeen et al, 1995; <papid> M95-1012 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>soon et al, 2001), <papid> J01-4004 </papid>and have been at the center of several evaluations: muc-6, muc-7,conll02 and conll03 shared tasks.</citsent>
<aftsection>
<nextsent>usually, in computational linguistic literature, named entity represent san instance of name, either location, person, an organization, and the ner task consists of identifying each individual occurrence of such an entity.
</nextsent>
<nextsent>we will instead adopt the nomenclature of the automatic content extraction program1 (nist, 2003a): we will call the instances of textual references to objects or abstractions mentions, which can be either named (e.g. john mayor), nominal (e.g. the president) or pronominal (e.g. she, it).
</nextsent>
<nextsent>an entity consists of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>for instance, in the sentence president john smith said he has no comments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3562">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>detecting entities, whether named, nominal or pronominal, in unrestricted text is crucial step toward understanding the text, as it identifies the important conceptual objects in discourse.
</prevsent>
<prevsent>it is also necessary step for identifying the relations present in the text and populatinga knowledge database.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
this task has applications in information extraction and summarization, information retrieval (one can get al hits for washington/person and not the ones for washington/state or washington/city), data mining and question answering.the entity detection and tracking task (edt hence forth) has close ties to the named entity recognition (ner) and coreference resolution tasks, which have been the focus of attention of much investigation in the recent past (bikel et al, 1997; <papid> A97-1029 </papid>borthwick et al, 1998; <papid> W98-1118 </papid>mikheev et al, 1999; <papid> E99-1001 </papid>miller et al, 1998; aberdeen et al, 1995; <papid> M95-1012 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>soon et al, 2001), <papid> J01-4004 </papid>and have been at the center of several evaluations: muc-6, muc-7,conll02 and conll03 shared tasks.</citsent>
<aftsection>
<nextsent>usually, in computational linguistic literature, named entity represent san instance of name, either location, person, an organization, and the ner task consists of identifying each individual occurrence of such an entity.
</nextsent>
<nextsent>we will instead adopt the nomenclature of the automatic content extraction program1 (nist, 2003a): we will call the instances of textual references to objects or abstractions mentions, which can be either named (e.g. john mayor), nominal (e.g. the president) or pronominal (e.g. she, it).
</nextsent>
<nextsent>an entity consists of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>for instance, in the sentence president john smith said he has no comments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3563">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we separate the edt task into mention detection part ? the task of finding all mention sin the text ? and an entity tracking part ? the task of combining the detected mentions into groups of references to the same object.the work presented here is motivated by the ace evaluation framework, which has the more general goal of building multilingual systems which detect not only entities, but also relations among them and, more recently,events in which they participate.
</prevsent>
<prevsent>the edt task is arguably harder than traditional named entity recognition,because of the additional complexity involved in extracting non-named mentions (nominals and pronouns) and the requirement of grouping mentions into entities.we present and evaluate empirically statistical models for both mention detection and entity tracking problems.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
for mention detection we use approaches based on maximum entropy (maxent henceforth) (berger et al, 1996) <papid> J96-1002 </papid>and robust risk minimization (rrm henceforth) 1for description of the ace program see http://www.nist.gov/speech/tests/ace/.(zhang et al, 2002).</citsent>
<aftsection>
<nextsent>the task is transformed into sequence classification problem.
</nextsent>
<nextsent>we investigate wide array of lexical, syntactic and semantic features to perform the mention detection and classification task including,for all three languages, features based on pre-existing statistical semantic taggers, even though these taggers have been trained on different corpora and use different semantic categories.
</nextsent>
<nextsent>moreover, the presented approach implicitly learns the correlation between these different semantic types and the desired output types.we propose novel maxent-based model for predicting whether mention should or should not be linked to an existing entity, and show how this model can be used to build entity chains.
</nextsent>
<nextsent>the effectiveness of the approach is tested by applying it on data from the abovementioned languages ? arabic, chinese, english.the framework presented in this paper is language universal ? the classification method does not make any assumption about the type of input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3564">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> mention detection.  </section>
<citcontext>
<prevsection>
<prevsent>results for arabic, chinese and english on the data from the latest ace evaluation (september 2003), an investigation of the effect of using different feature types, as well as discussion of the results.
</prevsent>
<prevsent>the mention detection system identifies the named, nominal and pronominal mentions introduced in the previous section.
</prevsent>
</prevsection>
<citsent citstr=" W94-0111 ">
similarly to classical nlp tasks such as base noun phrase chunking (ramshaw and marcus, 1994), <papid> W94-0111 </papid>text chunking (ramshaw and marcus, 1995) <papid> W95-0107 </papid>or named entity recognition (tjong kim sang, 2002), we formulate the mention detection problem as classification problem, by assigning to each token in the text label, indicating whether it starts specific mention, is inside specific mention, or is outside any mentions.</citsent>
<aftsection>
<nextsent>2.1 the statistical classifiers.
</nextsent>
<nextsent>good performance in many natural language processing tasks, such as part-of-speech tagging, shallow parsing and named entity recognition, has been shown to depend heavily on integrating many sources of information (zhang et al, 2002; jing et al, 2003; <papid> W03-1026 </papid>ittycheriah et al, 2003)<papid> N03-2014 </papid></nextsent>
<nextsent>given the stated focus of integrating many feature types, we are interested in algorithms that can easily integrate and make effective use of diverse input types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3565">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> mention detection.  </section>
<citcontext>
<prevsection>
<prevsent>results for arabic, chinese and english on the data from the latest ace evaluation (september 2003), an investigation of the effect of using different feature types, as well as discussion of the results.
</prevsent>
<prevsent>the mention detection system identifies the named, nominal and pronominal mentions introduced in the previous section.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
similarly to classical nlp tasks such as base noun phrase chunking (ramshaw and marcus, 1994), <papid> W94-0111 </papid>text chunking (ramshaw and marcus, 1995) <papid> W95-0107 </papid>or named entity recognition (tjong kim sang, 2002), we formulate the mention detection problem as classification problem, by assigning to each token in the text label, indicating whether it starts specific mention, is inside specific mention, or is outside any mentions.</citsent>
<aftsection>
<nextsent>2.1 the statistical classifiers.
</nextsent>
<nextsent>good performance in many natural language processing tasks, such as part-of-speech tagging, shallow parsing and named entity recognition, has been shown to depend heavily on integrating many sources of information (zhang et al, 2002; jing et al, 2003; <papid> W03-1026 </papid>ittycheriah et al, 2003)<papid> N03-2014 </papid></nextsent>
<nextsent>given the stated focus of integrating many feature types, we are interested in algorithms that can easily integrate and make effective use of diverse input types.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3566">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> mention detection.  </section>
<citcontext>
<prevsection>
<prevsent>similarly to classical nlp tasks such as base noun phrase chunking (ramshaw and marcus, 1994), <papid> W94-0111 </papid>text chunking (ramshaw and marcus, 1995) <papid> W95-0107 </papid>or named entity recognition (tjong kim sang, 2002), we formulate the mention detection problem as classification problem, by assigning to each token in the text label, indicating whether it starts specific mention, is inside specific mention, or is outside any mentions.</prevsent>
<prevsent>2.1 the statistical classifiers.</prevsent>
</prevsection>
<citsent citstr=" W03-1026 ">
good performance in many natural language processing tasks, such as part-of-speech tagging, shallow parsing and named entity recognition, has been shown to depend heavily on integrating many sources of information (zhang et al, 2002; jing et al, 2003; <papid> W03-1026 </papid>ittycheriah et al, 2003)<papid> N03-2014 </papid></citsent>
<aftsection>
<nextsent>given the stated focus of integrating many feature types, we are interested in algorithms that can easily integrate and make effective use of diverse input types.
</nextsent>
<nextsent>we selected two methods which satisfy these criteria: linear classifier ? the robust risk minimization classifier ? and log-linear classifier ? the maximum entropy classifier.both methods can integrate arbitrary types of information and make classification decision by aggregating all information available forgiven classification.
</nextsent>
<nextsent>before formally describing the methods2, we introduce some notations: let
</nextsent>
<nextsent>    be the set of predicted classes,  be the example space and
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3567">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> mention detection.  </section>
<citcontext>
<prevsection>
<prevsent>similarly to classical nlp tasks such as base noun phrase chunking (ramshaw and marcus, 1994), <papid> W94-0111 </papid>text chunking (ramshaw and marcus, 1995) <papid> W95-0107 </papid>or named entity recognition (tjong kim sang, 2002), we formulate the mention detection problem as classification problem, by assigning to each token in the text label, indicating whether it starts specific mention, is inside specific mention, or is outside any mentions.</prevsent>
<prevsent>2.1 the statistical classifiers.</prevsent>
</prevsection>
<citsent citstr=" N03-2014 ">
good performance in many natural language processing tasks, such as part-of-speech tagging, shallow parsing and named entity recognition, has been shown to depend heavily on integrating many sources of information (zhang et al, 2002; jing et al, 2003; <papid> W03-1026 </papid>ittycheriah et al, 2003)<papid> N03-2014 </papid></citsent>
<aftsection>
<nextsent>given the stated focus of integrating many feature types, we are interested in algorithms that can easily integrate and make effective use of diverse input types.
</nextsent>
<nextsent>we selected two methods which satisfy these criteria: linear classifier ? the robust risk minimization classifier ? and log-linear classifier ? the maximum entropy classifier.both methods can integrate arbitrary types of information and make classification decision by aggregating all information available forgiven classification.
</nextsent>
<nextsent>before formally describing the methods2, we introduce some notations: let
</nextsent>
<nextsent>    be the set of predicted classes,  be the example space and
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3570">
<title id=" N04-1001.xml">a statistical model for multilingual entity detection and tracking </title>
<section> mention detection.  </section>
<citcontext>
<prevsection>
<prevsent>output       table 1: summary of features used by the 3 systems given these observations, we decided to condition?
</prevsent>
<prevsent>the output of the system on the segmented data: the text is first segmented into tokens, and the classification is then performed on tokens.
</prevsent>
</prevsection>
<citsent citstr=" P03-1051 ">
the segmentation model is similar to the one presented by lee et al (2003), <papid> P03-1051 </papid>and obtains an accuracy of about 98%.in addition, special attention is paid to prefixes and suf fixes: in order to reduce the number of spurious token swe re-merge the prefixes or suffixes to their corresponding stem if they are not essential to the classification pro cess.</citsent>
<aftsection>
<nextsent>for this purpose, we collect the following statistics for each prefix/suffix
</nextsent>
<nextsent>l from the ace training data: the frequency of
</nextsent>
<nextsent>#l occurring as mention by itself (
</nextsent>
<nextsent>) and the frequency of
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3586">
<title id=" N01-1017.xml">generating training data for medical dicta tions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>spontaneous telephone speech presents additional challenges that are caused partly by poor acoustic signal and partly by the dis fluent nature of spontaneous speech.
</prevsent>
<prevsent>a number of researchers have noted the effects of disfluencies on speech recognition and have suggested various approaches to dealing with them at language modeling and post-processing stages.
</prevsent>
</prevsection>
<citsent citstr=" P99-1083 ">
(shriberg 1994, shriberg 1996, stolcke and shriberg 1996, stolcke et al 1998, shriberg and stolcke 1996, siu and ostendorf 1996, heeman et al 1996) medical over the-telephone dicta tions can be classified as spontaneous or quasi-spontaneous discourse (pakhomov 1999, <papid> P99-1083 </papid>pakhomov and savova 1999).</citsent>
<aftsection>
<nextsent>most physicians do not read script prepared in advance, instead, they engage in spontaneous monologues that display the full spectrum of disfluencies found in conversational dialogs in addition to other  disfluencies  characteristic of dictated speech.
</nextsent>
<nextsent>an example of the latter is when physician gives instructions to the transcription ist to modify something in the preceding discourse, sometimes as far as several paragraphs back.
</nextsent>
<nextsent>most asr dictation applications focus on desktop users; for example, dragon, ibm, philips and lernout &amp; hauspie all sell desktop dictation recognizers that work on high quality microphone speech.
</nextsent>
<nextsent>typically, the desktop system builds an adapted acoustic model if the talker  enrolls , i.e. reads prepared script that serves as literal transcription.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3588">
<title id=" N04-1007.xml">answering definition questions with multiple knowledge sources </title>
<section> answering definition questions.  </section>
<citcontext>
<prevsection>
<prevsent>in essence, we have automatically constructed an immense relational database containing nuggets distilled from every article in the corpus.
</prevsent>
<prevsent>the task of answering definition questions then becomes simple lookup for the relevant term.
</prevsent>
</prevsection>
<citsent citstr=" P03-1001 ">
this approach is similar in spirit to the work reported by fleischman et al (2003) <papid> P03-1001 </papid>and mann (2002), <papid> W02-1111 </papid>except that our system benefits from greater variety of patterns and answers broader range of questions.</citsent>
<aftsection>
<nextsent>our surface patterns operated both at the word and part-of-speech level.
</nextsent>
<nextsent>rudimentary chunking, such as marking the boundaries of noun phrases, was performed by grouping words based on their part-of-speech tags.
</nextsent>
<nextsent>in total, we applied eleven surface patterns over the entire corpus these are detailed in table 1, with examples in table 2.typically, surface patterns identify nuggets on the order of few words.
</nextsent>
<nextsent>in answering definition questions,however, we decided to return responses that include additional context there is evidence that contextual information results in higher-quality answers (lin et al, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3589">
<title id=" N04-1007.xml">answering definition questions with multiple knowledge sources </title>
<section> answering definition questions.  </section>
<citcontext>
<prevsection>
<prevsent>in essence, we have automatically constructed an immense relational database containing nuggets distilled from every article in the corpus.
</prevsent>
<prevsent>the task of answering definition questions then becomes simple lookup for the relevant term.
</prevsent>
</prevsection>
<citsent citstr=" W02-1111 ">
this approach is similar in spirit to the work reported by fleischman et al (2003) <papid> P03-1001 </papid>and mann (2002), <papid> W02-1111 </papid>except that our system benefits from greater variety of patterns and answers broader range of questions.</citsent>
<aftsection>
<nextsent>our surface patterns operated both at the word and part-of-speech level.
</nextsent>
<nextsent>rudimentary chunking, such as marking the boundaries of noun phrases, was performed by grouping words based on their part-of-speech tags.
</nextsent>
<nextsent>in total, we applied eleven surface patterns over the entire corpus these are detailed in table 1, with examples in table 2.typically, surface patterns identify nuggets on the order of few words.
</nextsent>
<nextsent>in answering definition questions,however, we decided to return responses that include additional context there is evidence that contextual information results in higher-quality answers (lin et al, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3590">
<title id=" N07-1037.xml">extracting semantic orientations of phrases from dictionary </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>empirical evaluation shows that our method works well both for seen and unseen nouns, and thatthe enlarged seed set significantly improves the classification performance of the proposed model.
</prevsent>
<prevsent>the semantic orientation classification of words has been pursued by several researchers.
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
some of them used corpora (hatzivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman, 2003), while others used dictionaries (kobayashi et al , 2001; kamps et al , 2004; takamura et al , 2005; <papid> P05-1017 </papid>esuli and sebastiani, 2005).turney (2002) <papid> P02-1053 </papid>applied an internet-based technique to the semantic orientation classification of phrases, which had originally been developed for word sentiment classification.</citsent>
<aftsection>
<nextsent>in their method, the number of hits returned by search-engine, with query consisting of phrase and seed word (e.g.,phrase near good?)
</nextsent>
<nextsent>is used to determine the orientation.
</nextsent>
<nextsent>baron and hirst (2004) extracted collocations with xtract (smadja, 1993) <papid> J93-1007 </papid>and classified the collocations using the orientations of the words in the neighboring sentences.</nextsent>
<nextsent>their method is similar to turneys in the sense that cooccurrence with seed words is used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3591">
<title id=" N07-1037.xml">extracting semantic orientations of phrases from dictionary </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>empirical evaluation shows that our method works well both for seen and unseen nouns, and thatthe enlarged seed set significantly improves the classification performance of the proposed model.
</prevsent>
<prevsent>the semantic orientation classification of words has been pursued by several researchers.
</prevsent>
</prevsection>
<citsent citstr=" P05-1017 ">
some of them used corpora (hatzivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman, 2003), while others used dictionaries (kobayashi et al , 2001; kamps et al , 2004; takamura et al , 2005; <papid> P05-1017 </papid>esuli and sebastiani, 2005).turney (2002) <papid> P02-1053 </papid>applied an internet-based technique to the semantic orientation classification of phrases, which had originally been developed for word sentiment classification.</citsent>
<aftsection>
<nextsent>in their method, the number of hits returned by search-engine, with query consisting of phrase and seed word (e.g.,phrase near good?)
</nextsent>
<nextsent>is used to determine the orientation.
</nextsent>
<nextsent>baron and hirst (2004) extracted collocations with xtract (smadja, 1993) <papid> J93-1007 </papid>and classified the collocations using the orientations of the words in the neighboring sentences.</nextsent>
<nextsent>their method is similar to turneys in the sense that cooccurrence with seed words is used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3592">
<title id=" N07-1037.xml">extracting semantic orientations of phrases from dictionary </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>empirical evaluation shows that our method works well both for seen and unseen nouns, and thatthe enlarged seed set significantly improves the classification performance of the proposed model.
</prevsent>
<prevsent>the semantic orientation classification of words has been pursued by several researchers.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
some of them used corpora (hatzivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman, 2003), while others used dictionaries (kobayashi et al , 2001; kamps et al , 2004; takamura et al , 2005; <papid> P05-1017 </papid>esuli and sebastiani, 2005).turney (2002) <papid> P02-1053 </papid>applied an internet-based technique to the semantic orientation classification of phrases, which had originally been developed for word sentiment classification.</citsent>
<aftsection>
<nextsent>in their method, the number of hits returned by search-engine, with query consisting of phrase and seed word (e.g.,phrase near good?)
</nextsent>
<nextsent>is used to determine the orientation.
</nextsent>
<nextsent>baron and hirst (2004) extracted collocations with xtract (smadja, 1993) <papid> J93-1007 </papid>and classified the collocations using the orientations of the words in the neighboring sentences.</nextsent>
<nextsent>their method is similar to turneys in the sense that cooccurrence with seed words is used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3593">
<title id=" N07-1037.xml">extracting semantic orientations of phrases from dictionary </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in their method, the number of hits returned by search-engine, with query consisting of phrase and seed word (e.g.,phrase near good?)
</prevsent>
<prevsent>is used to determine the orientation.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
baron and hirst (2004) extracted collocations with xtract (smadja, 1993) <papid> J93-1007 </papid>and classified the collocations using the orientations of the words in the neighboring sentences.</citsent>
<aftsection>
<nextsent>their method is similar to turneys in the sense that cooccurrence with seed words is used.
</nextsent>
<nextsent>in addition to individual seed words,kanayama and nasukawa (2006) <papid> W06-1642 </papid>used more complicated syntactic patterns that were manually created.the four methods above are based on context infor mation.</nextsent>
<nextsent>in contrast, our method exploits the internal structure of the semantic orientations of phrases.wilson et al  (2005) <papid> H05-1044 </papid>worked on phrase-level semantic orientations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3594">
<title id=" N07-1037.xml">extracting semantic orientations of phrases from dictionary </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>baron and hirst (2004) extracted collocations with xtract (smadja, 1993) <papid> J93-1007 </papid>and classified the collocations using the orientations of the words in the neighboring sentences.</prevsent>
<prevsent>their method is similar to turneys in the sense that cooccurrence with seed words is used.</prevsent>
</prevsection>
<citsent citstr=" W06-1642 ">
in addition to individual seed words,kanayama and nasukawa (2006) <papid> W06-1642 </papid>used more complicated syntactic patterns that were manually created.the four methods above are based on context infor mation.</citsent>
<aftsection>
<nextsent>in contrast, our method exploits the internal structure of the semantic orientations of phrases.wilson et al  (2005) <papid> H05-1044 </papid>worked on phrase-level semantic orientations.</nextsent>
<nextsent>they introduced polarity shifter.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3596">
<title id=" N07-1037.xml">extracting semantic orientations of phrases from dictionary </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>their method is similar to turneys in the sense that cooccurrence with seed words is used.
</prevsent>
<prevsent>in addition to individual seed words,kanayama and nasukawa (2006) <papid> W06-1642 </papid>used more complicated syntactic patterns that were manually created.the four methods above are based on context infor mation.</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
in contrast, our method exploits the internal structure of the semantic orientations of phrases.wilson et al  (2005) <papid> H05-1044 </papid>worked on phrase-level semantic orientations.</citsent>
<aftsection>
<nextsent>they introduced polarity shifter.
</nextsent>
<nextsent>they manually created the list of polarity shifters.
</nextsent>
<nextsent>inui (2004) also proposed similar idea.
</nextsent>
<nextsent>takamura et al  (2006) <papid> E06-1026 </papid>proposed to use based on latent variable models for sentiment classification ofnoun-adjective pairs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3597">
<title id=" N07-1037.xml">extracting semantic orientations of phrases from dictionary </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they manually created the list of polarity shifters.
</prevsent>
<prevsent>inui (2004) also proposed similar idea.
</prevsent>
</prevsection>
<citsent citstr=" E06-1026 ">
takamura et al  (2006) <papid> E06-1026 </papid>proposed to use based on latent variable models for sentiment classification ofnoun-adjective pairs.</citsent>
<aftsection>
<nextsent>their model consists of variables respectively representing nouns, adjectives, semantic orientations, and latent clusters, as well as the edges between the nodes.
</nextsent>
<nextsent>the words that are similar in terms of semantic orientations, such as risk?
</nextsent>
<nextsent>and mortality?
</nextsent>
<nextsent>(i.e., the positive orientation emerges when they are low?), make cluster in their model, which can be an automated version of inuis or wilson et al idea above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3598">
<title id=" N07-1037.xml">extracting semantic orientations of phrases from dictionary </title>
<section> potts model.  </section>
<citcontext>
<prevsection>
<prevsent>this potts model with the mean-field approximation has relation to several other models.as is often discussed (mackay, 2003), the minimization of the variational free energy (equa tion (2)) is equivalent to the obtaining the factorizedmodel that is most similar to the maximum likelihood model in terms of the kullback-leibler divergence.
</prevsent>
<prevsent>the second term of equation (2) is the entropy of the factor ized function.
</prevsent>
</prevsection>
<citsent citstr=" P04-3020 ">
hence the optimization problem to be solved here is kind of the maximum entropy model with penalty term, which corresponds to the first term of equation (2).we can find similarity also to the page rank algorithm (brin and page, 1998), which has been applied also to natural language processing tasks (mihalcea, 2004; <papid> P04-3020 </papid>mihalcea, 2005).<papid> H05-1052 </papid></citsent>
<aftsection>
<nextsent>in the page rank algorithm, the page rank score ri is updated as ri = (1?
</nextsent>
<nextsent>d) + ? wijrj , (4) where is constant (0 ? ? 1).
</nextsent>
<nextsent>this update equation consists of the first term corresponding to random jump from an arbitrary node and the second term corresponding to the random walk from the neighboring node.
</nextsent>
<nextsent>let us derive the first order taylor expansion of equation (3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3599">
<title id=" N07-1037.xml">extracting semantic orientations of phrases from dictionary </title>
<section> potts model.  </section>
<citcontext>
<prevsection>
<prevsent>this potts model with the mean-field approximation has relation to several other models.as is often discussed (mackay, 2003), the minimization of the variational free energy (equa tion (2)) is equivalent to the obtaining the factorizedmodel that is most similar to the maximum likelihood model in terms of the kullback-leibler divergence.
</prevsent>
<prevsent>the second term of equation (2) is the entropy of the factor ized function.
</prevsent>
</prevsection>
<citsent citstr=" H05-1052 ">
hence the optimization problem to be solved here is kind of the maximum entropy model with penalty term, which corresponds to the first term of equation (2).we can find similarity also to the page rank algorithm (brin and page, 1998), which has been applied also to natural language processing tasks (mihalcea, 2004; <papid> P04-3020 </papid>mihalcea, 2005).<papid> H05-1052 </papid></citsent>
<aftsection>
<nextsent>in the page rank algorithm, the page rank score ri is updated as ri = (1?
</nextsent>
<nextsent>d) + ? wijrj , (4) where is constant (0 ? ? 1).
</nextsent>
<nextsent>this update equation consists of the first term corresponding to random jump from an arbitrary node and the second term corresponding to the random walk from the neighboring node.
</nextsent>
<nextsent>let us derive the first order taylor expansion of equation (3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3606">
<title id=" N07-1037.xml">extracting semantic orientations of phrases from dictionary </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>future work includes the following:?
</prevsent>
<prevsent>we assumed that each word has semantic orientation.
</prevsent>
</prevsection>
<citsent citstr=" P06-1134 ">
however, word senses and subjectivity have strong interaction (wiebe and mihalcea, 2006).<papid> P06-1134 </papid></citsent>
<aftsection>
<nextsent>the value of ? must be properly set, because lower ? can be better for the seed words added by the classifier,?
</nextsent>
<nextsent>to address word-segmentation problem discussed in section 5.3, we can utilize the fact that the heads of compound nouns often inherit the property determining the semantic orientation when combined with an adjective.
</nextsent>
<nextsent>the semantic orientations of pairs consisting of proper noun will be estimated from the named entity classes of the proper nouns such as person name and organization.
</nextsent>
<nextsent>298
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3607">
<title id=" N06-1038.xml">integrating probabilistic extraction models and data mining to discover relations and patterns in text </title>
<section> george h.w. bushs sister is nancy bush ellis..  </section>
<citcontext>
<prevsection>
<prevsent>our work attempts to more tightly integrate the extraction and mining tasks by learning relational patterns that can be included probabilistically into extraction to improve its accuracy; also, our work focuses on mining from relational graphs, rather than single-table databases.mccallum and jensen (2003) argue the theoretical benefits of an integrated probabilistic model for extraction and mining, but do not construct such system.
</prevsent>
<prevsent>our work is step in the direction of their proposal, using an inference procedure based on aclosed-loop iteration between extraction and relational pattern discovery.
</prevsent>
</prevsection>
<citsent citstr=" P99-1001 ">
most other work in this area mines raw text, rather than database automatically populated via extraction (hearst, 1999; <papid> P99-1001 </papid>craven et al, 1998).</citsent>
<aftsection>
<nextsent>this work can also be viewed as part of trend to perform joint inference across multiple language processing tasks (miller et al, 2000; <papid> A00-2030 </papid>roth and tau yih, 2002; sutton and mccallum, 2004).</nextsent>
<nextsent>finally, using relational paths between entities is also examined in (richards and mooney, 1992) to escape local maxima in first-order learning system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3608">
<title id=" N06-1038.xml">integrating probabilistic extraction models and data mining to discover relations and patterns in text </title>
<section> george h.w. bushs sister is nancy bush ellis..  </section>
<citcontext>
<prevsection>
<prevsent>our work is step in the direction of their proposal, using an inference procedure based on aclosed-loop iteration between extraction and relational pattern discovery.
</prevsent>
<prevsent>most other work in this area mines raw text, rather than database automatically populated via extraction (hearst, 1999; <papid> P99-1001 </papid>craven et al, 1998).</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
this work can also be viewed as part of trend to perform joint inference across multiple language processing tasks (miller et al, 2000; <papid> A00-2030 </papid>roth and tau yih, 2002; sutton and mccallum, 2004).</citsent>
<aftsection>
<nextsent>finally, using relational paths between entities is also examined in (richards and mooney, 1992) to escape local maxima in first-order learning system.
</nextsent>
<nextsent>labeling relation extraction is the task of discovering semantic connections between entities.
</nextsent>
<nextsent>in text, this usually amounts to examining pairs of entities in document and determining (from local language cues) whether relation exists between them.
</nextsent>
<nextsent>common approaches to this problem include pattern matching (brin, 1998; agichtein and gravano, 2000), kernel methods (zelenko et al, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>bunescu and mooney, 2006), logistic regression (kambhatla, 2004), <papid> P04-3022 </papid>and augmented parsing (miller et al, 2000).<papid> A00-2030 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3609">
<title id=" N06-1038.xml">integrating probabilistic extraction models and data mining to discover relations and patterns in text </title>
<section> relation extraction as sequence.  </section>
<citcontext>
<prevsection>
<prevsent>labeling relation extraction is the task of discovering semantic connections between entities.
</prevsent>
<prevsent>in text, this usually amounts to examining pairs of entities in document and determining (from local language cues) whether relation exists between them.
</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
common approaches to this problem include pattern matching (brin, 1998; agichtein and gravano, 2000), kernel methods (zelenko et al, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>bunescu and mooney, 2006), logistic regression (kambhatla, 2004), <papid> P04-3022 </papid>and augmented parsing (miller et al, 2000).<papid> A00-2030 </papid></citsent>
<aftsection>
<nextsent>the pairwise classification approach of kernel methods and logistic regression is commonly two phase method: first the entities in document are identified, then relation type is predicted for each pair of entities.
</nextsent>
<nextsent>this approach presents at least two difficulties: (1) enumerating all pairs of entities, even when restricted to pairs within sentence,results in low density of positive relation exam ples; and (2) errors in the entity recognition phase can propagate to errors in the relation classificationstage.
</nextsent>
<nextsent>as an example of the latter difficulty, if person is mislabeled as company, then the relation classifier will be unsuccessful in finding brother relation, despite local evidence.we avoid these difficulties by restricting our investigation to biographical texts, e.g. encyclopedia articles.
</nextsent>
<nextsent>a biographical text mostly discusses one entity, which we refer to as the principal entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3610">
<title id=" N06-1038.xml">integrating probabilistic extraction models and data mining to discover relations and patterns in text </title>
<section> relation extraction as sequence.  </section>
<citcontext>
<prevsection>
<prevsent>labeling relation extraction is the task of discovering semantic connections between entities.
</prevsent>
<prevsent>in text, this usually amounts to examining pairs of entities in document and determining (from local language cues) whether relation exists between them.
</prevsent>
</prevsection>
<citsent citstr=" P04-3022 ">
common approaches to this problem include pattern matching (brin, 1998; agichtein and gravano, 2000), kernel methods (zelenko et al, 2003; culotta and sorensen, 2004; <papid> P04-1054 </papid>bunescu and mooney, 2006), logistic regression (kambhatla, 2004), <papid> P04-3022 </papid>and augmented parsing (miller et al, 2000).<papid> A00-2030 </papid></citsent>
<aftsection>
<nextsent>the pairwise classification approach of kernel methods and logistic regression is commonly two phase method: first the entities in document are identified, then relation type is predicted for each pair of entities.
</nextsent>
<nextsent>this approach presents at least two difficulties: (1) enumerating all pairs of entities, even when restricted to pairs within sentence,results in low density of positive relation exam ples; and (2) errors in the entity recognition phase can propagate to errors in the relation classificationstage.
</nextsent>
<nextsent>as an example of the latter difficulty, if person is mislabeled as company, then the relation classifier will be unsuccessful in finding brother relation, despite local evidence.we avoid these difficulties by restricting our investigation to biographical texts, e.g. encyclopedia articles.
</nextsent>
<nextsent>a biographical text mostly discusses one entity, which we refer to as the principal entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3612">
<title id=" N06-1038.xml">integrating probabilistic extraction models and data mining to discover relations and patterns in text </title>
<section> relational patterns.  </section>
<citcontext>
<prevsection>
<prevsent>the uncertainty in the bottom-up extraction stepis handled by estimating the confidence of each extraction and pruning the database to remove entries with low confidence.
</prevsent>
<prevsent>one of the benefits of probabilistic extraction model is that confidence estimates can be straight-forwardly obtained.
</prevsent>
</prevsection>
<citsent citstr=" N04-4028 ">
culotta and mccallum (2004) <papid> N04-4028 </papid>describe the constrained forward-backward algorithm to efficiently estimate the conditional probability that segment of text is correctly extracted by crf.</citsent>
<aftsection>
<nextsent>using this algorithm, we associate confidence value with each relation extracted by the crf.
</nextsent>
<nextsent>this confidence value is then used to limit the noise introduced by incorrect extractions.
</nextsent>
<nextsent>this differs from nahm and mooney (2000) and mooney and bunescu (2005), in which standard decision tree rule learners are applied to the unfiltered output of extraction.
</nextsent>
<nextsent>4.3 extracting implicit relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3613">
<title id=" N06-1038.xml">integrating probabilistic extraction models and data mining to discover relations and patterns in text </title>
<section> relational patterns.  </section>
<citcontext>
<prevsection>
<prevsent>a system that can accurately discover knowledge that is only implied by the text will dramatically increase the amount of information usercan uncover, effectively providing access to the implications of corpus.we argue that integrating top-down and bottom up knowledge discovery algorithms discussed in section 4.2 can enable this technology.
</prevsent>
<prevsent>by performing pattern discovery in conjunction with information extraction, we can collate facts from multiple sources to infer new relations.
</prevsent>
</prevsection>
<citsent citstr=" P05-1060 ">
this is an example of cross-document fusion or cross-document information extraction, growing area of research transforming raw extractions into usable knowledge bases (mann and yarowsky, 2005; <papid> P05-1060 </papid>masterson and kushmerik, 2003).</citsent>
<aftsection>
<nextsent>5.1 data.
</nextsent>
<nextsent>we sampled 1127 paragraphs from 271 articles fromthe online encyclopediawikipedia1 and labeled to 1http://www.wikipedia.org 299 george w. bush dick cheney underling yale education republican party president job title george h. w. bush son underlingharken energy executive education party job title prescott bush son education bill clinton rival bob dole rival education democrat party job title hillary clinton husband education party halliburton executive education pres medal of freedom award party nelson rockefeller award elizabeth dole wife wwii participant award party party martin luther king, jr. award figure 3: an example of the connectivity of the entities in the data.
</nextsent>
<nextsent>birthday birth year death day death year nationality visited birthplace death place religion job title member of cousin friend discovered education employer associate opus participant influence award brother wife supported idea executive of political party supported person founder son father rival underling superior role inventor husband grandfather sister brother-in-law nephew mother daughter granddaughter grandson great-grandson grandmother rival organization owner of uncle descendant ancestor great-grandfather aunt table 1: the set of labeled relations.
</nextsent>
<nextsent>tal of 4701 relation instances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3614">
<title id=" N04-4025.xml">automated team discourse annotation and performance prediction using lsa </title>
<section> latent semantic analysis.  </section>
<citcontext>
<prevsection>
<prevsent>lsa has been used for wide range of applications and for simulating knowledge representation, discourse and psycho linguistic phenomena.
</prevsent>
<prevsent>these approaches have included: information retrieval (deerwester et al, 1990), and automated text analysis (foltz, 1996).
</prevsent>
</prevsection>
<citsent citstr=" W01-0514 ">
in addition, lsa has been applied to number of nlp tasks, such as text segmentation (choi et al, 2001).<papid> W01-0514 </papid></citsent>
<aftsection>
<nextsent>more recently serafin et al (2003) <papid> N03-2032 </papid>used lsa for dialogue act classification, finding that lsa can effectively be used for such classification and that adding features to lsa showed promise.</nextsent>
<nextsent>to train lsa we added 2257 documents to the corpus uav transcripts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3615">
<title id=" N04-4025.xml">automated team discourse annotation and performance prediction using lsa </title>
<section> latent semantic analysis.  </section>
<citcontext>
<prevsection>
<prevsent>these approaches have included: information retrieval (deerwester et al, 1990), and automated text analysis (foltz, 1996).
</prevsent>
<prevsent>in addition, lsa has been applied to number of nlp tasks, such as text segmentation (choi et al, 2001).<papid> W01-0514 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-2032 ">
more recently serafin et al (2003) <papid> N03-2032 </papid>used lsa for dialogue act classification, finding that lsa can effectively be used for such classification and that adding features to lsa showed promise.</citsent>
<aftsection>
<nextsent>to train lsa we added 2257 documents to the corpus uav transcripts.
</nextsent>
<nextsent>these documents consisted of training documents and pre- and post-training interviews related to uavs, resulting in total of 22802 documents in the final corpus.
</nextsent>
<nextsent>for the uav-corpus we used 300 dimensional semantic space.
</nextsent>
<nextsent>our goal was to use semantic content of team dialogues to better understand and predict team performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3616">
<title id=" N04-4025.xml">automated team discourse annotation and performance prediction using lsa </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>correlation: predicted and actual team performance.
</prevsent>
<prevsent>overall, the results of the study show that lsa can be used for tagging content as well as predicting team performance based on team dialogues.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
given the limitations of the manual annotations, the results from the tagging portion of the study are still comparable to other efforts of automatic discourse tagging using different methods and different corpora (stolcke et al, 2000), <papid> J00-3003 </papid>which found performance within 15% of the performance of human taggers.</citsent>
<aftsection>
<nextsent>we plan to conduct more rigorous manual annotation study.
</nextsent>
<nextsent>we expect that improved human inter-coder reliability would eliminate the need for corrected tags?
</nextsent>
<nextsent>and allow for sequential analysis of tags within turns.
</nextsent>
<nextsent>it is also anticipated that incorporating additional methods that account for syntax and discourse turns should further improve the overall performance, see also serafin et al (2003).<papid> N03-2032 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3618">
<title id=" N03-2007.xml">active learning for classifying phone sequences from unsupervised phonotactic models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a major barrier to the rapid and cost-effective development of spoken language processing applications is theneed for time-consuming and expensive human transcription and annotation of collected data.
</prevsent>
<prevsent>extensive transcription of audio is generally undertaken to provide word level labeling to train recognition models.
</prevsent>
</prevsection>
<citsent citstr=" N03-1001 ">
applications that use statistically trained classification as component of an understanding system also require this transcribed text to train on, plus an assignment of class labels to each utterance.in recent work by alshawi (2003) <papid> N03-1001 </papid>reported in this conference, new methods for unsupervised training of phone string recognizers have been developed, removing theneed for word-level transcription.</citsent>
<aftsection>
<nextsent>the phone-string out put of such recognizers has been used in classification tasks using the boostexter text classification algorithm, giving utterance classfication accuracy that is surprisingly close to that obtained using conventionally trained word trigram models requiring transcription.
</nextsent>
<nextsent>the only training data required for classification using these recognition methods is assigning class labels to the audio files.
</nextsent>
<nextsent>the aim of the work described in this paper is to amplify this advantage by reducing the amount of effort required to train classifiers for phone-based systems by actively selecting which utterances to assign class labels.
</nextsent>
<nextsent>active learning has been applied to classification problems before (mccallum and nigam, 1998; tur et al, 2003), but not to classifiying phone strings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3624">
<title id=" N07-1021.xml">probabilistic generation of weather forecast texts </title>
<section> introduction and background.  </section>
<citcontext>
<prevsection>
<prevsent>however, this interest does not appear to have translated into practice: of the 30 implemented systems and modules with development starting in or after 2000 that are listed on key nlg website1,only five have any statistical component at all (an other six involve techniques that are in some way corpus-based).
</prevsent>
<prevsent>the likely reasons for this lack of take-up are that (i) many existing statistical nlg techniques are inherently expensive, requiring the set of alternatives to be generated in full before the statistical model is applied to select the most likely; and (ii) statistical nlg techniques have not been shown to produce outputs of high enough quality.
</prevsent>
</prevsection>
<citsent citstr=" W94-0319 ">
there has also been rethinking of the traditional modular nlg architecture (reiter, 1994).<papid> W94-0319 </papid></citsent>
<aftsection>
<nextsent>some research has moved towards more comprehensive view, e.g. construing the generation task as single constraint satisfaction problem.
</nextsent>
<nextsent>precursors to current approaches were hovys pauline which kept track of the satisfaction status of global rhetorical goals?
</nextsent>
<nextsent>(hovy, 1988), and power et al iconoclast which allowed users to fine-tune different combinations of global constraints (power, 2000).<papid> C00-2093 </papid></nextsent>
<nextsent>in recent comprehensive approaches, the focus is on automatic adaptability, e.g. automatically determining degrees of constraint viola bility on the basis of corpus frequencies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3625">
<title id=" N07-1021.xml">probabilistic generation of weather forecast texts </title>
<section> introduction and background.  </section>
<citcontext>
<prevsection>
<prevsent>some research has moved towards more comprehensive view, e.g. construing the generation task as single constraint satisfaction problem.
</prevsent>
<prevsent>precursors to current approaches were hovys pauline which kept track of the satisfaction status of global rhetorical goals?
</prevsent>
</prevsection>
<citsent citstr=" C00-2093 ">
(hovy, 1988), and power et al iconoclast which allowed users to fine-tune different combinations of global constraints (power, 2000).<papid> C00-2093 </papid></citsent>
<aftsection>
<nextsent>in recent comprehensive approaches, the focus is on automatic adaptability, e.g. automatically determining degrees of constraint viola bility on the basis of corpus frequencies.
</nextsent>
<nextsent>examples include langkildes (2005) general approach to generation and parsing based on constraint optimisation, and marciniak andstrubes (2005) integrated, globally optimisable network of classifiers and constraints.
</nextsent>
<nextsent>both probabilistic and recent comprehensive trends have developed at least in part to address two interrelated issues in nlg: the considerable amount 1bateman and zocks list of nlg systems, http://www.fb10.uni-bremen.de/anglistik/ langpro/nlg-table/, 20/01/2006.
</nextsent>
<nextsent>164of time and expense involved in building new systems, and the almost complete lack in the field of reusable systems and modules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3626">
<title id=" N07-1021.xml">probabilistic generation of weather forecast texts </title>
<section> introduction and background.  </section>
<citcontext>
<prevsection>
<prevsent>164of time and expense involved in building new systems, and the almost complete lack in the field of reusable systems and modules.
</prevsent>
<prevsent>both trends have the potential to improve on development time and re usability, but have drawbacks.
</prevsent>
</prevsection>
<citsent citstr=" N01-1001 ">
existing statistical nlg (i) uses corpus statistics to inform heuristic decisions in what is otherwise symbolic generation (varges and mellish, 2001; <papid> N01-1001 </papid>white, 2004; paiva and evans, 2005); (<papid> P05-1008 </papid>ii) applies n-gram models to select the overall most likely realisation after generation (halogen family); or (iii) reuses an existing parsing grammar or treebank for surface realisation (velldal et al , 2004; cahill and van genabith, 2006).<papid> P06-1130 </papid></citsent>
<aftsection>
<nextsent>n -gram models are not linguistically informed, (i) and (iii) come with substantial manual overhead, and (ii) over generates vastly and has high computational cost (see also section 3).existing comprehensive approaches tend to incur manual overhead (finetuning in iconoclast, corpus annotation in langkilde and marciniak &amp; strube).
</nextsent>
<nextsent>handling viola bility of soft constraints is problematic, and converting corpus-derived probabilities into costs associated with constraints(langkilde, marciniak &amp; strube) turns straightforward statistics into an ad hoc search heuristic.
</nextsent>
<nextsent>older approaches are not globally optimisable (pauline) or involve exhaustive search (iconoclast).the pcru language generation framework combines probabilistic generation methodology with comprehensive model of the generation space, where probabilistic choice informs generation as it goes along, instead of after all alternatives have been generated.
</nextsent>
<nextsent>pcru uses existing techniques (belz, 2005), <papid> W05-1601 </papid>but extends these substantially.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3627">
<title id=" N07-1021.xml">probabilistic generation of weather forecast texts </title>
<section> introduction and background.  </section>
<citcontext>
<prevsection>
<prevsent>164of time and expense involved in building new systems, and the almost complete lack in the field of reusable systems and modules.
</prevsent>
<prevsent>both trends have the potential to improve on development time and re usability, but have drawbacks.
</prevsent>
</prevsection>
<citsent citstr=" P05-1008 ">
existing statistical nlg (i) uses corpus statistics to inform heuristic decisions in what is otherwise symbolic generation (varges and mellish, 2001; <papid> N01-1001 </papid>white, 2004; paiva and evans, 2005); (<papid> P05-1008 </papid>ii) applies n-gram models to select the overall most likely realisation after generation (halogen family); or (iii) reuses an existing parsing grammar or treebank for surface realisation (velldal et al , 2004; cahill and van genabith, 2006).<papid> P06-1130 </papid></citsent>
<aftsection>
<nextsent>n -gram models are not linguistically informed, (i) and (iii) come with substantial manual overhead, and (ii) over generates vastly and has high computational cost (see also section 3).existing comprehensive approaches tend to incur manual overhead (finetuning in iconoclast, corpus annotation in langkilde and marciniak &amp; strube).
</nextsent>
<nextsent>handling viola bility of soft constraints is problematic, and converting corpus-derived probabilities into costs associated with constraints(langkilde, marciniak &amp; strube) turns straightforward statistics into an ad hoc search heuristic.
</nextsent>
<nextsent>older approaches are not globally optimisable (pauline) or involve exhaustive search (iconoclast).the pcru language generation framework combines probabilistic generation methodology with comprehensive model of the generation space, where probabilistic choice informs generation as it goes along, instead of after all alternatives have been generated.
</nextsent>
<nextsent>pcru uses existing techniques (belz, 2005), <papid> W05-1601 </papid>but extends these substantially.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3628">
<title id=" N07-1021.xml">probabilistic generation of weather forecast texts </title>
<section> introduction and background.  </section>
<citcontext>
<prevsection>
<prevsent>164of time and expense involved in building new systems, and the almost complete lack in the field of reusable systems and modules.
</prevsent>
<prevsent>both trends have the potential to improve on development time and re usability, but have drawbacks.
</prevsent>
</prevsection>
<citsent citstr=" P06-1130 ">
existing statistical nlg (i) uses corpus statistics to inform heuristic decisions in what is otherwise symbolic generation (varges and mellish, 2001; <papid> N01-1001 </papid>white, 2004; paiva and evans, 2005); (<papid> P05-1008 </papid>ii) applies n-gram models to select the overall most likely realisation after generation (halogen family); or (iii) reuses an existing parsing grammar or treebank for surface realisation (velldal et al , 2004; cahill and van genabith, 2006).<papid> P06-1130 </papid></citsent>
<aftsection>
<nextsent>n -gram models are not linguistically informed, (i) and (iii) come with substantial manual overhead, and (ii) over generates vastly and has high computational cost (see also section 3).existing comprehensive approaches tend to incur manual overhead (finetuning in iconoclast, corpus annotation in langkilde and marciniak &amp; strube).
</nextsent>
<nextsent>handling viola bility of soft constraints is problematic, and converting corpus-derived probabilities into costs associated with constraints(langkilde, marciniak &amp; strube) turns straightforward statistics into an ad hoc search heuristic.
</nextsent>
<nextsent>older approaches are not globally optimisable (pauline) or involve exhaustive search (iconoclast).the pcru language generation framework combines probabilistic generation methodology with comprehensive model of the generation space, where probabilistic choice informs generation as it goes along, instead of after all alternatives have been generated.
</nextsent>
<nextsent>pcru uses existing techniques (belz, 2005), <papid> W05-1601 </papid>but extends these substantially.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3629">
<title id=" N07-1021.xml">probabilistic generation of weather forecast texts </title>
<section> introduction and background.  </section>
<citcontext>
<prevsection>
<prevsent>handling viola bility of soft constraints is problematic, and converting corpus-derived probabilities into costs associated with constraints(langkilde, marciniak &amp; strube) turns straightforward statistics into an ad hoc search heuristic.
</prevsent>
<prevsent>older approaches are not globally optimisable (pauline) or involve exhaustive search (iconoclast).the pcru language generation framework combines probabilistic generation methodology with comprehensive model of the generation space, where probabilistic choice informs generation as it goes along, instead of after all alternatives have been generated.
</prevsent>
</prevsection>
<citsent citstr=" W05-1601 ">
pcru uses existing techniques (belz, 2005), <papid> W05-1601 </papid>but extends these substantially.</citsent>
<aftsection>
<nextsent>this paper describes the pcru framework and reports experiments designed to rigorously test pcru in practice and to determine whether improvements in development time and re usability can be achieved without sacrificing quality of outputs.
</nextsent>
<nextsent>2 pcru language generationpcru (belz, 2006) is probabilistic language generation framework that was developed with the aim of providing the formal underpinnings for creating nlg systems that are driven by comprehensive probabilistic models of the entire generation space (in cluding deep generation).
</nextsent>
<nextsent>nlg systems tend to be composed of generation rules that apply transformations to representations (performing different tasks in different modules).
</nextsent>
<nextsent>the basic idea in pcru is that as long as the generation rules are all of the form relation(arg1, ...argn) ? relation1(arg1, ...argp) ... relationm(arg1, ...argq), ? 1, n, p, ? 0, then the set of all generation rules can be seen as defining context-free language and single probabilistic model can be estimated from raw or annotated text to guide generation processes.pcru uses straightforward context-free technology in combination with under specification techniques, to encode base generator as set of expansion rules composed of n-ary relations with variable and constant arguments (section 2.1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3630">
<title id=" N07-1021.xml">probabilistic generation of weather forecast texts </title>
<section> building and evaluating pcru wind.  </section>
<citcontext>
<prevsection>
<prevsent>the small amount of variation across the five repeats, and the small differences between results for training and test sets (table 2) indicated that five repeats were sufficient.
</prevsent>
<prevsent>3.4 evaluation.
</prevsent>
</prevsection>
<citsent citstr=" E06-1040 ">
3.4.1 evaluation methods the two automatic metrics used in the evaluations, nist and bleu have been shown to correlate highly with expert judgments (pearson correlation coefficients 0.82 and 0.79 respectively) in this do main (belz and reiter, 2006).<papid> E06-1040 </papid></citsent>
<aftsection>
<nextsent>167 input [[1,ssw,16,20,-,-,0600],[2,sse,-,-,-,-,notime],[3,var,04,08,-,-,2400]] corpus ssw 16-20 gradually backing sse then falling variable 4-8 by late evening reference 1 sswly 16-20 gradually backing ssely then decreasing variable 4-8 by late evening reference 2 ssw 16-20 gradually backing sse by 1800 then falling variable 4-8 by late evening sumtime-hyb.
</nextsent>
<nextsent>ssw 16-20 gradually backing sse then becoming variable 10 or less by midnight pcru-greedy ssw 16-20 backing sse for time then falling variable 4-8 by late evening pcru-roulette ssw 16-20 gradually backing sse and variable 4-8 pcru-viterbi ssw 16-20 backing sse variable 4-8 later pcru-2gram ssw 16-20 backing sse variable 4-8 later pcru-random ssw 16-20 at first from midday becoming sse during the afternoon then variable 4-8 table 1: forecast texts (for 05-10-2000) generated by each of the pcru generators, the sumtime-hybrid system and three experts.
</nextsent>
<nextsent>the corresponding input to the generators is shown in the first row.bleu (papineni et al , 2002) <papid> P02-1040 </papid>is precision metric that assesses the quality of translation in terms of the proportion of its word n-grams (n ? 4 has become standard) that it shares with several reference translations.</nextsent>
<nextsent>bleu also incorporates brevitypenalty?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3631">
<title id=" N07-1021.xml">probabilistic generation of weather forecast texts </title>
<section> building and evaluating pcru wind.  </section>
<citcontext>
<prevsection>
<prevsent>167 input [[1,ssw,16,20,-,-,0600],[2,sse,-,-,-,-,notime],[3,var,04,08,-,-,2400]] corpus ssw 16-20 gradually backing sse then falling variable 4-8 by late evening reference 1 sswly 16-20 gradually backing ssely then decreasing variable 4-8 by late evening reference 2 ssw 16-20 gradually backing sse by 1800 then falling variable 4-8 by late evening sumtime-hyb.
</prevsent>
<prevsent>ssw 16-20 gradually backing sse then becoming variable 10 or less by midnight pcru-greedy ssw 16-20 backing sse for time then falling variable 4-8 by late evening pcru-roulette ssw 16-20 gradually backing sse and variable 4-8 pcru-viterbi ssw 16-20 backing sse variable 4-8 later pcru-2gram ssw 16-20 backing sse variable 4-8 later pcru-random ssw 16-20 at first from midday becoming sse during the afternoon then variable 4-8 table 1: forecast texts (for 05-10-2000) generated by each of the pcru generators, the sumtime-hybrid system and three experts.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the corresponding input to the generators is shown in the first row.bleu (papineni et al , 2002) <papid> P02-1040 </papid>is precision metric that assesses the quality of translation in terms of the proportion of its word n-grams (n ? 4 has become standard) that it shares with several reference translations.</citsent>
<aftsection>
<nextsent>bleu also incorporates brevitypenalty?
</nextsent>
<nextsent>to counteract scores increasing as length decreases.
</nextsent>
<nextsent>bleu scores range from 0 to 1.the nist metric (doddington, 2002) is an adaptation of bleu, but where bleu gives equal weight to all n-grams, nist gives more weight to less frequent(hence more informative) n-grams.
</nextsent>
<nextsent>there is evidence that nist correlates better with human judgments than bleu (doddington, 2002; belz andre iter, 2006).<papid> E06-1040 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3636">
<title id=" N07-1024.xml">hybrid models for semantic classification of chinese unknown words </title>
<section> knowledge-based models.  </section>
<citcontext>
<prevsection>
<prevsent>the relationship between the semantic category of an unknown word and those of its component characters can also be captured in more sophisticated way using information-theoretical models.
</prevsent>
<prevsent>we use two statistical measures, mutual information and 2, to compute character-category associations and word-category associations.
</prevsent>
</prevsection>
<citsent citstr=" W04-1106 ">
chen (2004) <papid> W04-1106 </papid>used the 2 measure to compute character-character and word-word associations, but not word-category associations.</citsent>
<aftsection>
<nextsent>we use word-category associations to directly predict the semantic categories of unknown words.
</nextsent>
<nextsent>the mutual information and 2 measures are calculated as in (3) and (4), where asso(c,tj) denotes the association between character and semantic category tj, and p(x) and f(x) denote the probability and frequency of respectively.
</nextsent>
<nextsent>(3) )()( ),( log),( j jmi tpcp tcp tcasso = (4) ),(max ),( ),(2 kk j tc tc tcasso ? ?
</nextsent>
<nextsent>= (5) )()( )],([ ),( 2 j tfcf tcf tc +=?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3639">
<title id=" N07-1024.xml">hybrid models for semantic classification of chinese unknown words </title>
<section> a corpus-based model  </section>
<citcontext>
<prevsection>
<prevsent>the knowledge-based models described above classify unknown words using information about the syntactic and semantic categories of their component characters.
</prevsent>
<prevsent>another useful source of information is the context in which unknown words occur.
</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
while contextual information is the primary source of information used in wsd research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., roark and charniak 1998; <papid> P98-2182 </papid>ci 190 aramita 2003; curran 2005), <papid> P05-1004 </papid>it has been used in only one previous study on semantic classification of chinese unknown words (chen and lin, 2000).<papid> W00-1202 </papid></citsent>
<aftsection>
<nextsent>part of the goal of this study is to investigate whether and how these two different sources of information can be combined to im prove performance on semantic classification of chinese unknown words.
</nextsent>
<nextsent>to this end, we first use the knowledge-based models to propose list of five candidate categories for the target word, then extract generalized context for each category in cilin from corpus, and finally compute the similarity between the context of the target word and the generalized context of each of its candidate categories.
</nextsent>
<nextsent>comparing the context of the target word with generalized contexts of categories instead of contexts of individual words alleviates the data-sparseness problem, as infrequent words have limited contextual information.
</nextsent>
<nextsent>limiting the search space for each target word to the top five candidate categories reduces the computational cost that comes with the full search space.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3640">
<title id=" N07-1024.xml">hybrid models for semantic classification of chinese unknown words </title>
<section> a corpus-based model  </section>
<citcontext>
<prevsection>
<prevsent>the knowledge-based models described above classify unknown words using information about the syntactic and semantic categories of their component characters.
</prevsent>
<prevsent>another useful source of information is the context in which unknown words occur.
</prevsent>
</prevsection>
<citsent citstr=" P05-1004 ">
while contextual information is the primary source of information used in wsd research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., roark and charniak 1998; <papid> P98-2182 </papid>ci 190 aramita 2003; curran 2005), <papid> P05-1004 </papid>it has been used in only one previous study on semantic classification of chinese unknown words (chen and lin, 2000).<papid> W00-1202 </papid></citsent>
<aftsection>
<nextsent>part of the goal of this study is to investigate whether and how these two different sources of information can be combined to im prove performance on semantic classification of chinese unknown words.
</nextsent>
<nextsent>to this end, we first use the knowledge-based models to propose list of five candidate categories for the target word, then extract generalized context for each category in cilin from corpus, and finally compute the similarity between the context of the target word and the generalized context of each of its candidate categories.
</nextsent>
<nextsent>comparing the context of the target word with generalized contexts of categories instead of contexts of individual words alleviates the data-sparseness problem, as infrequent words have limited contextual information.
</nextsent>
<nextsent>limiting the search space for each target word to the top five candidate categories reduces the computational cost that comes with the full search space.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3641">
<title id=" N07-1024.xml">hybrid models for semantic classification of chinese unknown words </title>
<section> a corpus-based model  </section>
<citcontext>
<prevsection>
<prevsent>the knowledge-based models described above classify unknown words using information about the syntactic and semantic categories of their component characters.
</prevsent>
<prevsent>another useful source of information is the context in which unknown words occur.
</prevsent>
</prevsection>
<citsent citstr=" W00-1202 ">
while contextual information is the primary source of information used in wsd research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., roark and charniak 1998; <papid> P98-2182 </papid>ci 190 aramita 2003; curran 2005), <papid> P05-1004 </papid>it has been used in only one previous study on semantic classification of chinese unknown words (chen and lin, 2000).<papid> W00-1202 </papid></citsent>
<aftsection>
<nextsent>part of the goal of this study is to investigate whether and how these two different sources of information can be combined to im prove performance on semantic classification of chinese unknown words.
</nextsent>
<nextsent>to this end, we first use the knowledge-based models to propose list of five candidate categories for the target word, then extract generalized context for each category in cilin from corpus, and finally compute the similarity between the context of the target word and the generalized context of each of its candidate categories.
</nextsent>
<nextsent>comparing the context of the target word with generalized contexts of categories instead of contexts of individual words alleviates the data-sparseness problem, as infrequent words have limited contextual information.
</nextsent>
<nextsent>limiting the search space for each target word to the top five candidate categories reduces the computational cost that comes with the full search space.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3642">
<title id=" N07-1024.xml">hybrid models for semantic classification of chinese unknown words </title>
<section> a corpus-based model  </section>
<citcontext>
<prevsection>
<prevsent>second, to model the effect of frequency on the context words?
</prevsent>
<prevsent>contribution to meaning discrimination, we use two sets of context words: one consists of the 1000 most frequent words in the corpus; the other consists of all words in the corpus.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
window size for wsd, both topical context and micro context have been used (ide and vronis 1998).<papid> J98-1001 </papid></citsent>
<aftsection>
<nextsent>topical context includes substantive words that co-occur with the target word within larger window, whereas micro context includes words in small window around the target word.
</nextsent>
<nextsent>we experiment with topical context and micro context with window sizes of 100 and 6 respectively (i.e., 50 and 3 words to the left and right of the target word respectively).
</nextsent>
<nextsent>context representation we represent the context of category as vector  w1, w2, ..., wn , where is the total number of context words, and wi is the weight of the ith context word.
</nextsent>
<nextsent>to arrive at this representation, we first record the number of times each context word occurs within specified window of each member word of category in the corpus as vector  f1, f2, ..., fn , where fi is the number of times the ith context word co-occurs with member word of the category.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3643">
<title id=" N07-1024.xml">hybrid models for semantic classification of chinese unknown words </title>
<section> a corpus-based model  </section>
<citcontext>
<prevsection>
<prevsent>context representation we represent the context of category as vector  w1, w2, ..., wn , where is the total number of context words, and wi is the weight of the ith context word.
</prevsent>
<prevsent>to arrive at this representation, we first record the number of times each context word occurs within specified window of each member word of category in the corpus as vector  f1, f2, ..., fn , where fi is the number of times the ith context word co-occurs with member word of the category.
</prevsent>
</prevsection>
<citsent citstr=" J05-4002 ">
we then compute the weight of context word in context c, w(w, c), using mutual information and t-test, which were reported by weeds and weir (2005) <papid> J05-4002 </papid>to perform the best on pseudo-disambiguation task.</citsent>
<aftsection>
<nextsent>these weight functions are computed as in (10) and (11), where denotes the size of the corpus.
</nextsent>
<nextsent>(10) )()( ),( log),( cpwp cwp cwwpmi = (11) ncwp cpwpcwp cwwt ),( )()(),( ),( ?= 3.2 contextual similarity measurement.
</nextsent>
<nextsent>we compute the similarity between the context vectors of the unknown word and its candidate categories using cosine.
</nextsent>
<nextsent>the cosine of two dimensional vectors r and r , cos( r , r), is computed as in (12), where xi and yi denote the weight of the ith context word in r and r .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3654">
<title id=" N07-1011.xml">first order probabilistic models for coreference resolution </title>
<section> pairwise model.  </section>
<citcontext>
<prevsection>
<prevsent>given dataset in which noun phrases have been manually clustered, the training data can be created by simply enumerating over each pair of noun phrases xij , where yij is true if xi and xj are in the same cluster.
</prevsent>
<prevsent>however, this approach generatesa highly unbalanced training set, with negative examples outnumbering positive examples.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
instead, soon et al (2001) <papid> J01-4004 </papid>propose the following samplingmethod: scan the document from left to right.</citsent>
<aftsection>
<nextsent>compare each noun phrase xi to each preceding noun phrase xj , scanning from right to left.
</nextsent>
<nextsent>for each pair xi, xj , create training instance xij , yij?, where yijis 1 if xi and xj are coreferent.
</nextsent>
<nextsent>the scan for xj terminates when positive example is constructed, orthe beginning of the document is reached.
</nextsent>
<nextsent>this results in training set that has been pruned of distant noun phrase pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3659">
<title id=" N07-1011.xml">first order probabilistic models for coreference resolution </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we use the true entity segmentation, and parse each sentence in the corpus using phrase-structure grammar, as is common for this task.
</prevsent>
<prevsent>6.2 features.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
we follow soon et al (2001) <papid> J01-4004 </papid>and ng and cardie(2002) <papid> P02-1014 </papid>to generate most of our features for the pairwise model.</citsent>
<aftsection>
<nextsent>these include:?
</nextsent>
<nextsent>match features - check whether gender, number, head text, or entire phrase matches ? mention type (pronoun, name, nominal) ? aliases - heuristic ally decide if one noun is the acronym of the other ? apposition - heuristic ally decide if one noun is in apposition to the other ? relative pronoun - heuristic ally decide if one noun is relative pronoun referring to the other.
</nextsent>
<nextsent>wordnet features - use wordnet to decide if one noun is hypernym, synonym, or antonym of another, or if they share hypernym.
</nextsent>
<nextsent>both speak - true if both contain an adjacent context word that is synonym of said.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3660">
<title id=" N07-1011.xml">first order probabilistic models for coreference resolution </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>(however, we should note that there are also small differences in the feature sets used for error-driven and standard training results.)error analysis indicates that often noun xi iscor rectly not merged with cluster xj when xj has astrong internal coherence.
</prevsent>
<prevsent>for example, if all 5 mentions of france in document are string identical,then the system will be extremely cautious of merging noun that is not equivalent to france into xj ,since this will turn off the all-string-match?
</prevsent>
</prevsection>
<citsent citstr=" P05-1020 ">
feature for cluster xj . to our knowledge, the best results on this dataset were obtained by the meta-classification scheme of ng (2005).<papid> P05-1020 </papid></citsent>
<aftsection>
<nextsent>although our train-test splits may differ slightly, the best b-cubed f1 score reported in ng (2005) <papid> P05-1020 </papid>is 69.3%, which is considerably lower than the 79.3% obtained with our method.</nextsent>
<nextsent>also note that the pairwise baseline obtains results similar to those in ng and cardie (2002).<papid> P02-1014 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3665">
<title id=" N07-1011.xml">first order probabilistic models for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our experiments show the advantages of this ranking-based loss function.
</prevsent>
<prevsent>additionally, we provide an empirical study to quantify the effects of different example generation and loss function decisions.
</prevsent>
</prevsection>
<citsent citstr=" P04-1015 ">
collins and roark (2004) <papid> P04-1015 </papid>present an incremental perceptron algorithm for parsing that uses early update?</citsent>
<aftsection>
<nextsent>to update the parameters when an error is encountered.
</nextsent>
<nextsent>our method uses similar early update?
</nextsent>
<nextsent>in that training examples are only generated for the first mistake made during prediction.
</nextsent>
<nextsent>however, they do not investigate rank-based loss functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3666">
<title id=" N07-1011.xml">first order probabilistic models for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in that training examples are only generated for the first mistake made during prediction.
</prevsent>
<prevsent>however, they do not investigate rank-based loss functions.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
others have attempted to train global scoring functions using gibbs sampling (finkel et al, 2005), <papid> P05-1045 </papid>message propagation, (bunescu and mooney, 2004;<papid> P04-1056 </papid>sutton and mccallum, 2004), and integer linear programming (roth and yih, 2004).<papid> W04-2401 </papid></citsent>
<aftsection>
<nextsent>the main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions.
</nextsent>
<nextsent>there have been number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid>nicolae and nicolae (2006) combine pairwise classification with graph-cut algorithms.</nextsent>
<nextsent>luo et al (2004) <papid> P04-1018 </papid>do enable features between mention-clusterpairs, but do not perform the error-driven and ranking enhancements proposed in our work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3667">
<title id=" N07-1011.xml">first order probabilistic models for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in that training examples are only generated for the first mistake made during prediction.
</prevsent>
<prevsent>however, they do not investigate rank-based loss functions.
</prevsent>
</prevsection>
<citsent citstr=" P04-1056 ">
others have attempted to train global scoring functions using gibbs sampling (finkel et al, 2005), <papid> P05-1045 </papid>message propagation, (bunescu and mooney, 2004;<papid> P04-1056 </papid>sutton and mccallum, 2004), and integer linear programming (roth and yih, 2004).<papid> W04-2401 </papid></citsent>
<aftsection>
<nextsent>the main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions.
</nextsent>
<nextsent>there have been number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid>nicolae and nicolae (2006) combine pairwise classification with graph-cut algorithms.</nextsent>
<nextsent>luo et al (2004) <papid> P04-1018 </papid>do enable features between mention-clusterpairs, but do not perform the error-driven and ranking enhancements proposed in our work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3668">
<title id=" N07-1011.xml">first order probabilistic models for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in that training examples are only generated for the first mistake made during prediction.
</prevsent>
<prevsent>however, they do not investigate rank-based loss functions.
</prevsent>
</prevsection>
<citsent citstr=" W04-2401 ">
others have attempted to train global scoring functions using gibbs sampling (finkel et al, 2005), <papid> P05-1045 </papid>message propagation, (bunescu and mooney, 2004;<papid> P04-1056 </papid>sutton and mccallum, 2004), and integer linear programming (roth and yih, 2004).<papid> W04-2401 </papid></citsent>
<aftsection>
<nextsent>the main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions.
</nextsent>
<nextsent>there have been number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid>nicolae and nicolae (2006) combine pairwise classification with graph-cut algorithms.</nextsent>
<nextsent>luo et al (2004) <papid> P04-1018 </papid>do enable features between mention-clusterpairs, but do not perform the error-driven and ranking enhancements proposed in our work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3671">
<title id=" N07-1011.xml">first order probabilistic models for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the main distinctions of our approach are that it is simple to implement, not computationally intensive, and adaptable to arbitrary loss functions.
</prevsent>
<prevsent>there have been number of machine learning approaches to coreference resolution, traditionally factored into classification decisions over pairs of nouns (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002).<papid> P02-1014 </papid>nicolae and nicolae (2006) combine pairwise classification with graph-cut algorithms.</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
luo et al (2004) <papid> P04-1018 </papid>do enable features between mention-clusterpairs, but do not perform the error-driven and ranking enhancements proposed in our work.</citsent>
<aftsection>
<nextsent>denis and baldridge (2007) use ranking loss function for pronoun coreference; however the examples are still pairs of pronouns, and the example generation is not error driven.
</nextsent>
<nextsent>ng (2005) <papid> P05-1020 </papid>learns meta-classifier to choose the best prediction from the output of several coreference systems.</nextsent>
<nextsent>while in theory meta classifier can flexibly represent features, they do not explore features using the full flexibility of first order logic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3676">
<title id=" N04-1020.xml">inferring sentence internal temporal relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although temporal relations and their interaction with discourse relations (e.g., parallel, result) have received much attention in linguistics (kamp and reyle, 1993; webber, 1991; asher and lascarides, 2003), the automatic interpretation of events and their temporal relations is beyond the capabilities of current open-domainnlp systems.
</prevsent>
<prevsent>while corpus-based methods have accelerated progress in other areas of nlp, they have yet to makea substantial impact on the processing of temporal information.
</prevsent>
</prevsection>
<citsent citstr=" W01-1315 ">
this is partly due to the absence of readily available corpora annotated with temporal information, although efforts are underway to develop treebanks marked with temporal relations (katz and arosio, 2001) <papid> W01-1315 </papid>and devise annotation schemes that are suitable for coding temporal relations (ferro et al, 2000; setzer and gaizauskas, 2001).<papid> W01-1311 </papid></citsent>
<aftsection>
<nextsent>absolute temporal information has received some attention (wilson et al, 2001; <papid> W01-1312 </papid>schilder and habel, 2001; <papid> W01-1309 </papid>wiebe et al, 1998) and systems have been developed for identifying and assigning referents to time expressions.although the treatment of time expressions is an important first step towards the automatic handling of temporal phenomena, much temporal information is not absolute but relative and not overtly expressed but implicit.</nextsent>
<nextsent>consider the examples in (1) taken from katz and arosio (2001).<papid> W01-1315 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3677">
<title id=" N04-1020.xml">inferring sentence internal temporal relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although temporal relations and their interaction with discourse relations (e.g., parallel, result) have received much attention in linguistics (kamp and reyle, 1993; webber, 1991; asher and lascarides, 2003), the automatic interpretation of events and their temporal relations is beyond the capabilities of current open-domainnlp systems.
</prevsent>
<prevsent>while corpus-based methods have accelerated progress in other areas of nlp, they have yet to makea substantial impact on the processing of temporal information.
</prevsent>
</prevsection>
<citsent citstr=" W01-1311 ">
this is partly due to the absence of readily available corpora annotated with temporal information, although efforts are underway to develop treebanks marked with temporal relations (katz and arosio, 2001) <papid> W01-1315 </papid>and devise annotation schemes that are suitable for coding temporal relations (ferro et al, 2000; setzer and gaizauskas, 2001).<papid> W01-1311 </papid></citsent>
<aftsection>
<nextsent>absolute temporal information has received some attention (wilson et al, 2001; <papid> W01-1312 </papid>schilder and habel, 2001; <papid> W01-1309 </papid>wiebe et al, 1998) and systems have been developed for identifying and assigning referents to time expressions.although the treatment of time expressions is an important first step towards the automatic handling of temporal phenomena, much temporal information is not absolute but relative and not overtly expressed but implicit.</nextsent>
<nextsent>consider the examples in (1) taken from katz and arosio (2001).<papid> W01-1315 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3678">
<title id=" N04-1020.xml">inferring sentence internal temporal relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while corpus-based methods have accelerated progress in other areas of nlp, they have yet to makea substantial impact on the processing of temporal information.
</prevsent>
<prevsent>this is partly due to the absence of readily available corpora annotated with temporal information, although efforts are underway to develop treebanks marked with temporal relations (katz and arosio, 2001) <papid> W01-1315 </papid>and devise annotation schemes that are suitable for coding temporal relations (ferro et al, 2000; setzer and gaizauskas, 2001).<papid> W01-1311 </papid></prevsent>
</prevsection>
<citsent citstr=" W01-1312 ">
absolute temporal information has received some attention (wilson et al, 2001; <papid> W01-1312 </papid>schilder and habel, 2001; <papid> W01-1309 </papid>wiebe et al, 1998) and systems have been developed for identifying and assigning referents to time expressions.although the treatment of time expressions is an important first step towards the automatic handling of temporal phenomena, much temporal information is not absolute but relative and not overtly expressed but implicit.</citsent>
<aftsection>
<nextsent>consider the examples in (1) taken from katz and arosio (2001).<papid> W01-1315 </papid></nextsent>
<nextsent>native speakers can infer that john first met and then kissed the girl and that he first left the party and then walked home, even though there are no overt markers signalling the temporal order of the described events.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3679">
<title id=" N04-1020.xml">inferring sentence internal temporal relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while corpus-based methods have accelerated progress in other areas of nlp, they have yet to makea substantial impact on the processing of temporal information.
</prevsent>
<prevsent>this is partly due to the absence of readily available corpora annotated with temporal information, although efforts are underway to develop treebanks marked with temporal relations (katz and arosio, 2001) <papid> W01-1315 </papid>and devise annotation schemes that are suitable for coding temporal relations (ferro et al, 2000; setzer and gaizauskas, 2001).<papid> W01-1311 </papid></prevsent>
</prevsection>
<citsent citstr=" W01-1309 ">
absolute temporal information has received some attention (wilson et al, 2001; <papid> W01-1312 </papid>schilder and habel, 2001; <papid> W01-1309 </papid>wiebe et al, 1998) and systems have been developed for identifying and assigning referents to time expressions.although the treatment of time expressions is an important first step towards the automatic handling of temporal phenomena, much temporal information is not absolute but relative and not overtly expressed but implicit.</citsent>
<aftsection>
<nextsent>consider the examples in (1) taken from katz and arosio (2001).<papid> W01-1315 </papid></nextsent>
<nextsent>native speakers can infer that john first met and then kissed the girl and that he first left the party and then walked home, even though there are no overt markers signalling the temporal order of the described events.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3681">
<title id=" N04-1020.xml">inferring sentence internal temporal relations </title>
<section> the model.  </section>
<citcontext>
<prevsection>
<prevsent>in the testing phase, all occurrences of the relevant temporal markers are removed for the interpretation task and the model must decide which member of the confusion set to choose.
</prevsent>
<prevsent>for the sentence fusion task, it is the temporal order of the two clauses that is unknown and must be inferred.
</prevsent>
</prevsection>
<citsent citstr=" P02-1047 ">
a similar approach hasbeen advocated for the interpretation of discourse relations by marcu and echihabi (2002).<papid> P02-1047 </papid></citsent>
<aftsection>
<nextsent>they train set of naive bayes classifiers on large corpus (in the order of 40 sentences) representative of four rhetorical relations using word bigrams as features.
</nextsent>
<nextsent>the discourse relations are read off from explicit discourse markers thus avoiding time consuming hand coding.
</nextsent>
<nextsent>apart from the fact that we present an alternative model, our work differs from marcu and echihabi (2002) <papid> P02-1047 </papid>in two important ways.</nextsent>
<nextsent>first we explore the contribution of linguistic information to the inference task using considerably smaller datasets and secondly apply the proposed model to generation task, namely information fusion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3683">
<title id=" N04-1020.xml">inferring sentence internal temporal relations </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>levin (1993) focuses on the relation between verbs and their arguments and hypothesizes that verbs which behave similarly with respect to the expression and interpretation of their arguments share certain meaning components and can therefore be organised into semantically coherent classes (200 in total).
</prevsent>
<prevsent>asher and lascarides(2003) argue that these classes provide important information for identifying semantic relationships betweenclauses.
</prevsent>
</prevsection>
<citsent citstr=" W99-0632 ">
verbs in our data were mapped into their corresponding levin classes (feature vl); polysemous verbs were disambiguated by the method proposed in lapata and brew (1999).<papid> W99-0632 </papid></citsent>
<aftsection>
<nextsent>again, for verbs not included in levin, the lemmatised verb form is used.
</nextsent>
<nextsent>noun identity (n) it is not only verbs, but also nouns that can provide important information about the semantic relation between two clauses (see asher and lascarides 2003 for detailed motivation).
</nextsent>
<nextsent>in our domain for example,the noun share is found in main clauses typically preceding the noun market which is often found insubordinate clauses.
</nextsent>
<nextsent>table 3 shows the most frequently attested nouns(excluding proper names) in main (nounm) and subordinate (nouns) clauses for each temporal marker.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3685">
<title id=" N04-1020.xml">inferring sentence internal temporal relations </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>we achieved an accuracy of 70.7% on the interpretation task and 97.4%on the fusion task.
</prevsent>
<prevsent>this performance is significant improvement over the baseline and compares favourably with human performance on the same tasks.
</prevsent>
</prevsection>
<citsent citstr=" N03-2019 ">
previous work on temporal inference has focused on the automatic tagging of temporal expressions (e.g., wilson et al 2001)<papid> W01-1312 </papid>or on learning the ordering of events from manually annotated data (e.g., mani et al 2003).<papid> N03-2019 </papid></citsent>
<aftsection>
<nextsent>our experiments further revealed that not only lexical but also syntactic information is important for both tasks.
</nextsent>
<nextsent>this result is in agreement with soricut and marcu (2003) <papid> N03-1030 </papid>who find that syntax trees encode sufficient information to enable accurate derivation of discourse relations.</nextsent>
<nextsent>an important future direction lies in modelling the temporal relations of events across sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3687">
<title id=" N04-1020.xml">inferring sentence internal temporal relations </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>previous work on temporal inference has focused on the automatic tagging of temporal expressions (e.g., wilson et al 2001)<papid> W01-1312 </papid>or on learning the ordering of events from manually annotated data (e.g., mani et al 2003).<papid> N03-2019 </papid></prevsent>
<prevsent>our experiments further revealed that not only lexical but also syntactic information is important for both tasks.</prevsent>
</prevsection>
<citsent citstr=" N03-1030 ">
this result is in agreement with soricut and marcu (2003) <papid> N03-1030 </papid>who find that syntax trees encode sufficient information to enable accurate derivation of discourse relations.</citsent>
<aftsection>
<nextsent>an important future direction lies in modelling the temporal relations of events across sentences.
</nextsent>
<nextsent>the approach presented in this paper can be used to support the annotate automatically, correct manually?
</nextsent>
<nextsent>methodology used to provide high volume annotation in the penn treebank project.
</nextsent>
<nextsent>an important question for further investigation is the contribution of linguistic and extra-sentential information to modelling temporal relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3690">
<title id=" N03-1009.xml">simpler and more general minimization for weighted finite state automata </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a transducer returns an output string from = ??
</prevsent>
<prevsent>(for some alphabet ?).
</prevsent>
</prevsection>
<citsent citstr=" J97-2003 ">
celebrated algorithms by mohri (1997), <papid> J97-2003 </papid>algorithms by mohri (2000) have recently made it possible to minimize deterministic automata whose weights (outputs) are log-probabilities or strings.</citsent>
<aftsection>
<nextsent>these cases are of central interest in language and speech processing.
</nextsent>
<nextsent>however, automata with other kinds of weights can also be defined.
</nextsent>
<nextsent>the general formulation of weighted automata (berstel and reutenauer, 1988) permits any weight set k, if appropriate operations ? and ? are provided for combining weights from the different arcs of the automaton.
</nextsent>
<nextsent>the triple (k,?,?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3691">
<title id=" N03-1009.xml">simpler and more general minimization for weighted finite state automata </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the question is of practical as well as theoretical interest.
</prevsent>
<prevsent>some nlp automata use the real semi ring (r,+,?), or its log equivalent, to compute unnormalizedprobabilities or other scores outside the range [0, 1] (lafferty et al, 2001; cortes et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P02-1001 ">
expectation semir ings (eisner, 2002) <papid> P02-1001 </papid>are used to handle bookkeeping when training the parameters of probabilistic transducer.</citsent>
<aftsection>
<nextsent>a byproduct of this paper is minimization algorithm that works fully with those semi rings, new result permitting more efficient automaton processing in those situations.
</nextsent>
<nextsent>surprisingly, we will see that minimization is not even well-defined for all weight semirings!
</nextsent>
<nextsent>we will then (nearly) characterize the semi rings where it is well defined, and give recipe for constructing minimization algorithms similar to mohris in such semirings.finally, we follow this recipe to obtain specific, simple and practical algorithm that works for all division semirings.
</nextsent>
<nextsent>all the cases above either fall within this framework or can be forced into it by adding multiplicative in verses to the semiring.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3696">
<title id=" N07-1041.xml">combining probability based rankers for action item detection </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>thus, strives ranking quality varies less with changes to the training set.
</prevsent>
<prevsent>several researchers have considered text classification tasks similar to action-item detection.
</prevsent>
</prevsection>
<citsent citstr=" W04-3240 ">
cohen et al (2004) <papid> W04-3240 </papid>describe an ontology of speech acts?, such as propose meeting?, and attempt to predict when an e-mail contains one of these speech acts.</citsent>
<aftsection>
<nextsent>corston-oliver et al (2004) consider detecting items in e-mail to put on to-do list?
</nextsent>
<nextsent>using sentence-level classifier.
</nextsent>
<nextsent>in earlier work (bennett and carbonell, 2005), we demonstrated that sentence-level classifiers typically out perform document-level classifiers on this problem and examined the underlying reasons why this was 330 the case.
</nextsent>
<nextsent>furthermore, we presented user studies demonstrating that users identify action-items more rapidly when using the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3697">
<title id=" N03-4010.xml">javelin a flexible planner based architecture for question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, lcc (d. moldovan and surdeanu, 2002) has implemented feedback loops which ensure that processing constraints are met by retrieving more documents or expanding question terms.
</prevsent>
<prevsent>the lcc system includes passage retrieval loop, lexico-semantic loop and logic proving loop.
</prevsent>
</prevsection>
<citsent citstr=" N01-1005 ">
the ibm piquant system (carroll et al, 2002) combines knowledge-based agents using predictive annotation with statistical approach based on maximum entropy model (ittycheriah et al, 2001).<papid> N01-1005 </papid></citsent>
<aftsection>
<nextsent>exe domain model planner data repository javelin gui execution manager process history and data javelin operator (action) models question answer ack . . .
</nextsent>
<nextsent>dialog response exe results exe results results question analyzer information extractor answer generator retrieval strategist answer justification web browserfigure 1: the javelin architecture.
</nextsent>
<nextsent>the planner controls execution of the individual components via the execution manager.both the lcc and ibm systems represent departure from the standard pipe lined approach to qa architecture, and both work well for straightforward factoid questions.
</nextsent>
<nextsent>nevertheless, both approaches incorporate pre-determined set of processing steps or strategies, andhave limited ability to reason about new types of questions not previously encountered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3698">
<title id=" N03-1024.xml">syntax based alignment of multiple translations extracting paraphrases and generating new sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the past, paraphrases have come under the scrutiny of many research communities.
</prevsent>
<prevsent>information retrieval researchers have used paraphrasing techniques for query reformulation in order to increase the recall of information retrieval engines (sparck jones and tait, 1984).
</prevsent>
</prevsection>
<citsent citstr=" C94-1051 ">
natural language generation researchers have used paraphrasing to increase the expressive power of generation systems (iordanskaja et al, 1991; lenke, 1994; <papid> C94-1051 </papid>stede, 1999).</citsent>
<aftsection>
<nextsent>and researchers in multi-document text summarization (barzilay et al, 1999), <papid> P99-1071 </papid>information extraction (shinyama et al, 2002), and question answering (lin and pantel,2001; hermjakob et al, 2002) have focused on identifying and exploiting paraphrases in the context of recognizing redundancies, alternative formulations of the same meaning, and improving the performance of question answering systems.</nextsent>
<nextsent>in previous work (barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; shinyama et al, 2002), paraphrases are represented assets or pairs of semantically equivalent words, phrases, and patterns.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3699">
<title id=" N03-1024.xml">syntax based alignment of multiple translations extracting paraphrases and generating new sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>information retrieval researchers have used paraphrasing techniques for query reformulation in order to increase the recall of information retrieval engines (sparck jones and tait, 1984).
</prevsent>
<prevsent>natural language generation researchers have used paraphrasing to increase the expressive power of generation systems (iordanskaja et al, 1991; lenke, 1994; <papid> C94-1051 </papid>stede, 1999).</prevsent>
</prevsection>
<citsent citstr=" P99-1071 ">
and researchers in multi-document text summarization (barzilay et al, 1999), <papid> P99-1071 </papid>information extraction (shinyama et al, 2002), and question answering (lin and pantel,2001; hermjakob et al, 2002) have focused on identifying and exploiting paraphrases in the context of recognizing redundancies, alternative formulations of the same meaning, and improving the performance of question answering systems.</citsent>
<aftsection>
<nextsent>in previous work (barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; shinyama et al, 2002), paraphrases are represented assets or pairs of semantically equivalent words, phrases, and patterns.</nextsent>
<nextsent>although this is adequate in the context of some applications, it is clearly tooweak from generative perspective.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3700">
<title id=" N03-1024.xml">syntax based alignment of multiple translations extracting paraphrases and generating new sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>natural language generation researchers have used paraphrasing to increase the expressive power of generation systems (iordanskaja et al, 1991; lenke, 1994; <papid> C94-1051 </papid>stede, 1999).</prevsent>
<prevsent>and researchers in multi-document text summarization (barzilay et al, 1999), <papid> P99-1071 </papid>information extraction (shinyama et al, 2002), and question answering (lin and pantel,2001; hermjakob et al, 2002) have focused on identifying and exploiting paraphrases in the context of recognizing redundancies, alternative formulations of the same meaning, and improving the performance of question answering systems.</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
in previous work (barzilay and mckeown, 2001; <papid> P01-1008 </papid>lin and pantel, 2001; shinyama et al, 2002), paraphrases are represented assets or pairs of semantically equivalent words, phrases, and patterns.</citsent>
<aftsection>
<nextsent>although this is adequate in the context of some applications, it is clearly tooweak from generative perspective.
</nextsent>
<nextsent>assume, for example, that we know that text pairs (stock market rose, stockmarket gained) and (stock market rose, stock prices rose) have the same meaning.
</nextsent>
<nextsent>if we memorized only these two pairs, it would be impossible to infer that, in fact, consistent with our intuition, any of the following sets of phrases are also semantically equivalent: {stock market rose, stockmarket gained, stock prices rose, stock prices gained } and {stock market, stock prices } in the context of rose or gained; {market rose }, {market gained }, {prices rose } and {prices gained } in the context of stock; and so on.
</nextsent>
<nextsent>in this paper, we propose solutions for two problems: the problem of paraphrase representation and the problem of paraphrase induction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3701">
<title id=" N03-1024.xml">syntax based alignment of multiple translations extracting paraphrases and generating new sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our fsascapture both lexical paraphrases, such as {fighting, bat tle}, {died, were killed} and structural paraphrases such as {last weeks fighting, the battle of last week}.
</prevsent>
<prevsent>the contexts in which these are correct paraphrases are also conveniently captured in the representation.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
in previous work, langkilde and knight (1998) <papid> P98-1116 </papid>used word lattices for language generation, but their method involved hand-crafted rules.</citsent>
<aftsection>
<nextsent>bangalore et al (2001) and barzilay and lee (2002) <papid> W02-1022 </papid>both applied the technique ofmulti-sequence alignment (msa) to align parallel corpora and produced similar fsas.</nextsent>
<nextsent>for their purposes, they mainly need to ensure the correctness of consensus among different translations, so that different constituentorderings in input sentences do not pose serious prob edmonton, may-june 2003 main papers , pp.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3702">
<title id=" N03-1024.xml">syntax based alignment of multiple translations extracting paraphrases and generating new sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the contexts in which these are correct paraphrases are also conveniently captured in the representation.
</prevsent>
<prevsent>in previous work, langkilde and knight (1998) <papid> P98-1116 </papid>used word lattices for language generation, but their method involved hand-crafted rules.</prevsent>
</prevsection>
<citsent citstr=" W02-1022 ">
bangalore et al (2001) and barzilay and lee (2002) <papid> W02-1022 </papid>both applied the technique ofmulti-sequence alignment (msa) to align parallel corpora and produced similar fsas.</citsent>
<aftsection>
<nextsent>for their purposes, they mainly need to ensure the correctness of consensus among different translations, so that different constituentorderings in input sentences do not pose serious prob edmonton, may-june 2003 main papers , pp.
</nextsent>
<nextsent>102-109 proceedings of hlt-naacl 2003 1.
</nextsent>
<nextsent>at least 12 people were killed in the battle last week.
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3703">
<title id=" N03-1024.xml">syntax based alignment of multiple translations extracting paraphrases and generating new sentences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, when given as input the same sentences in figure 1, one instantiation of the msa algorithm produces the fsa in figure 3, which contains many bad?
</prevsent>
<prevsent>paths such as the battle of last weeks fighting took at least 12 people lost their people died in the fighting last weeks fighting (see section 4.2.2 for more quantitative analysis.).
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
its still possible to use msa if, for example, the input is pre-clustered to have the same constituent ordering (barzilay and lee (2003)).<papid> N03-1003 </papid></citsent>
<aftsection>
<nextsent>but we chose to approach this problem from another direction.
</nextsent>
<nextsent>as result, we propose new syntax-based algorithm to produce fsas.in this paper, we first introduce the multiple translation corpus that we use in our experiments (see section 2).
</nextsent>
<nextsent>we then present the algorithms that we developed to induce finite-state paraphrase representations from such data (see section 3).
</nextsent>
<nextsent>an important part of the paper is dedicated to evaluating the quality of the finite-state representations that we derive (see section 4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3706">
<title id=" N03-1010.xml">greedy decoding for statistical machine translation in almost linear time </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent> when applied navely) to practically linear time1 without sacrificing translation quality.
</prevsent>
<prevsent>we achieve this by integrating hypothesis evaluation into hypothesis creation, tiling improvements over the translation hypothesis at the end of each search iteration, and by imposing restrictions on the amount of word reordering during decoding.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
most of the current work in statistical machine translation builds on word replacement models developed at ibm in the early 1990s (brown et al, 1990, <papid> J90-2002 </papid>1993; berger et al, 1994, <papid> H94-1028 </papid>1996).</citsent>
<aftsection>
<nextsent>based on the conventions established in brown et al (1993), <papid> J93-2003 </papid>these models are commonly referred to as the (ibm) models 1-5.one of the big challenges in building actual mt systems within this framework is that of decoding: finding the translation candidate that maximizes the translation probability</nextsent>
<nextsent> for the given input . knight (1999) <papid> J99-4005 </papid>has shown the problem to be np-complete.due to the complexity of the task, practical mt systems usually do not employ optimal decoders (that is, decoders that are guaranteed to find an optimal solution within the constraints of the framework), but relyon approximative algorithms instead.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3707">
<title id=" N03-1010.xml">greedy decoding for statistical machine translation in almost linear time </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent> when applied navely) to practically linear time1 without sacrificing translation quality.
</prevsent>
<prevsent>we achieve this by integrating hypothesis evaluation into hypothesis creation, tiling improvements over the translation hypothesis at the end of each search iteration, and by imposing restrictions on the amount of word reordering during decoding.
</prevsent>
</prevsection>
<citsent citstr=" H94-1028 ">
most of the current work in statistical machine translation builds on word replacement models developed at ibm in the early 1990s (brown et al, 1990, <papid> J90-2002 </papid>1993; berger et al, 1994, <papid> H94-1028 </papid>1996).</citsent>
<aftsection>
<nextsent>based on the conventions established in brown et al (1993), <papid> J93-2003 </papid>these models are commonly referred to as the (ibm) models 1-5.one of the big challenges in building actual mt systems within this framework is that of decoding: finding the translation candidate that maximizes the translation probability</nextsent>
<nextsent> for the given input . knight (1999) <papid> J99-4005 </papid>has shown the problem to be np-complete.due to the complexity of the task, practical mt systems usually do not employ optimal decoders (that is, decoders that are guaranteed to find an optimal solution within the constraints of the framework), but relyon approximative algorithms instead.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3708">
<title id=" N03-1010.xml">greedy decoding for statistical machine translation in almost linear time </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we achieve this by integrating hypothesis evaluation into hypothesis creation, tiling improvements over the translation hypothesis at the end of each search iteration, and by imposing restrictions on the amount of word reordering during decoding.
</prevsent>
<prevsent>most of the current work in statistical machine translation builds on word replacement models developed at ibm in the early 1990s (brown et al, 1990, <papid> J90-2002 </papid>1993; berger et al, 1994, <papid> H94-1028 </papid>1996).</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
based on the conventions established in brown et al (1993), <papid> J93-2003 </papid>these models are commonly referred to as the (ibm) models 1-5.one of the big challenges in building actual mt systems within this framework is that of decoding: finding the translation candidate that maximizes the translation probability</citsent>
<aftsection>
<nextsent> for the given input . knight (1999) <papid> J99-4005 </papid>has shown the problem to be np-complete.due to the complexity of the task, practical mt systems usually do not employ optimal decoders (that is, decoders that are guaranteed to find an optimal solution within the constraints of the framework), but relyon approximative algorithms instead.</nextsent>
<nextsent>empirical evidence suggests that such algorithms can perform resonably well.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3709">
<title id=" N03-1010.xml">greedy decoding for statistical machine translation in almost linear time </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most of the current work in statistical machine translation builds on word replacement models developed at ibm in the early 1990s (brown et al, 1990, <papid> J90-2002 </papid>1993; berger et al, 1994, <papid> H94-1028 </papid>1996).</prevsent>
<prevsent>based on the conventions established in brown et al (1993), <papid> J93-2003 </papid>these models are commonly referred to as the (ibm) models 1-5.one of the big challenges in building actual mt systems within this framework is that of decoding: finding the translation candidate that maximizes the translation probability</prevsent>
</prevsection>
<citsent citstr=" J99-4005 ">
for the given input . knight (1999) <papid> J99-4005 </papid>has shown the problem to be np-complete.due to the complexity of the task, practical mt systems usually do not employ optimal decoders (that is, decoders that are guaranteed to find an optimal solution within the constraints of the framework), but relyon approximative algorithms instead.</citsent>
<aftsection>
<nextsent>empirical evidence suggests that such algorithms can perform resonably well.
</nextsent>
<nextsent>for example, berger et al (1994), <papid> H94-1028 </papid>attribute only 5% of the translation errors of their candide system, which uses 1technically, the complexity is still  . however, the quadratic component has such small coefficient that it does not have any noticable effect on the translation speed for all reasonable inputs.</nextsent>
<nextsent>a restricted stack search, to search errors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3712">
<title id=" N03-1010.xml">greedy decoding for statistical machine translation in almost linear time </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, berger et al (1994), <papid> H94-1028 </papid>attribute only 5% of the translation errors of their candide system, which uses 1technically, the complexity is still  . however, the quadratic component has such small coefficient that it does not have any noticable effect on the translation speed for all reasonable inputs.</prevsent>
<prevsent>a restricted stack search, to search errors.</prevsent>
</prevsection>
<citsent citstr=" P97-1047 ">
using the same evaluation metric (but different evaluation data), wang and waibel (1997) <papid> P97-1047 </papid>report search error rates of 7.9% and 9.3%, respectively, for their decoders.och et al (2001) <papid> W01-1408 </papid>and germann et al (2001) <papid> P01-1030 </papid>both implemented optimal decoders and benchmarked approxi mative algorithms against them.</citsent>
<aftsection>
<nextsent>och et al report word error rates of 68.68% for optimal search (based on variant of the a* algorithm), and 69.65% for the most restricted version of decoder that combines dynamic programming with beam search (tillmann and ney, 2000).<papid> C00-2123 </papid></nextsent>
<nextsent>germann et al (2001) <papid> P01-1030 </papid>compare translations obtained by multi-stack decoder and greedy hill-climbing algorithm against those produced by an optimal integer programming decoder that treats decoding as variant of the traveling-salesman problem (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3713">
<title id=" N03-1010.xml">greedy decoding for statistical machine translation in almost linear time </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, berger et al (1994), <papid> H94-1028 </papid>attribute only 5% of the translation errors of their candide system, which uses 1technically, the complexity is still  . however, the quadratic component has such small coefficient that it does not have any noticable effect on the translation speed for all reasonable inputs.</prevsent>
<prevsent>a restricted stack search, to search errors.</prevsent>
</prevsection>
<citsent citstr=" W01-1408 ">
using the same evaluation metric (but different evaluation data), wang and waibel (1997) <papid> P97-1047 </papid>report search error rates of 7.9% and 9.3%, respectively, for their decoders.och et al (2001) <papid> W01-1408 </papid>and germann et al (2001) <papid> P01-1030 </papid>both implemented optimal decoders and benchmarked approxi mative algorithms against them.</citsent>
<aftsection>
<nextsent>och et al report word error rates of 68.68% for optimal search (based on variant of the a* algorithm), and 69.65% for the most restricted version of decoder that combines dynamic programming with beam search (tillmann and ney, 2000).<papid> C00-2123 </papid></nextsent>
<nextsent>germann et al (2001) <papid> P01-1030 </papid>compare translations obtained by multi-stack decoder and greedy hill-climbing algorithm against those produced by an optimal integer programming decoder that treats decoding as variant of the traveling-salesman problem (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3714">
<title id=" N03-1010.xml">greedy decoding for statistical machine translation in almost linear time </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, berger et al (1994), <papid> H94-1028 </papid>attribute only 5% of the translation errors of their candide system, which uses 1technically, the complexity is still  . however, the quadratic component has such small coefficient that it does not have any noticable effect on the translation speed for all reasonable inputs.</prevsent>
<prevsent>a restricted stack search, to search errors.</prevsent>
</prevsection>
<citsent citstr=" P01-1030 ">
using the same evaluation metric (but different evaluation data), wang and waibel (1997) <papid> P97-1047 </papid>report search error rates of 7.9% and 9.3%, respectively, for their decoders.och et al (2001) <papid> W01-1408 </papid>and germann et al (2001) <papid> P01-1030 </papid>both implemented optimal decoders and benchmarked approxi mative algorithms against them.</citsent>
<aftsection>
<nextsent>och et al report word error rates of 68.68% for optimal search (based on variant of the a* algorithm), and 69.65% for the most restricted version of decoder that combines dynamic programming with beam search (tillmann and ney, 2000).<papid> C00-2123 </papid></nextsent>
<nextsent>germann et al (2001) <papid> P01-1030 </papid>compare translations obtained by multi-stack decoder and greedy hill-climbing algorithm against those produced by an optimal integer programming decoder that treats decoding as variant of the traveling-salesman problem (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3717">
<title id=" N03-1010.xml">greedy decoding for statistical machine translation in almost linear time </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a restricted stack search, to search errors.
</prevsent>
<prevsent>using the same evaluation metric (but different evaluation data), wang and waibel (1997) <papid> P97-1047 </papid>report search error rates of 7.9% and 9.3%, respectively, for their decoders.och et al (2001) <papid> W01-1408 </papid>and germann et al (2001) <papid> P01-1030 </papid>both implemented optimal decoders and benchmarked approxi mative algorithms against them.</prevsent>
</prevsection>
<citsent citstr=" C00-2123 ">
och et al report word error rates of 68.68% for optimal search (based on variant of the a* algorithm), and 69.65% for the most restricted version of decoder that combines dynamic programming with beam search (tillmann and ney, 2000).<papid> C00-2123 </papid></citsent>
<aftsection>
<nextsent>germann et al (2001) <papid> P01-1030 </papid>compare translations obtained by multi-stack decoder and greedy hill-climbing algorithm against those produced by an optimal integer programming decoder that treats decoding as variant of the traveling-salesman problem (cf.</nextsent>
<nextsent>knight, 1999).<papid> J99-4005 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3731">
<title id=" N03-1010.xml">greedy decoding for statistical machine translation in almost linear time </title>
<section> re ducting decoder complexity.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, any swap that involves distortion greater than that limit will result in the minimal (smoothed) distortion probability and most likely not lead to an improvement.
</prevsent>
<prevsent>the question is: how much swapping is enough is there any benefit to it at all?
</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
this is an interesting question since virtually all efficient mt decoders (e.g. tillmann and ney, 2000; <papid> C00-2123 </papid>berger et al, 1994; <papid> H94-1028 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>vidal, 1997) impose limits on word reordering.</citsent>
<aftsection>
<nextsent>in order to determine the effect of swap restrictions on decoder performance, we translated the chinese test corpus 101 times with restrictions on the maximum swap6100 short news texts; 878 text segments; ca.
</nextsent>
<nextsent>25k to kens/words.
</nextsent>
<nextsent>0 1 2 3 4 5 6 7 8 9 10 maximum swap distance 0 1 2 3 4 5 6 7 8 9 10 maximum swap segment size 0.138 0.139 0.140 0.141 0.142 0.143 0.144 0.145 bleu score figure 5: bleu scores for the chinese test set (  de coding) independence of maximum swap distance and maximum swap segment size.
</nextsent>
<nextsent>distance (msd) and the maximum swap segment size(msss) ranging from 0 to 10 and evaluated the translations with the bleu7 metric (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3732">
<title id=" N03-1010.xml">greedy decoding for statistical machine translation in almost linear time </title>
<section> re ducting decoder complexity.  </section>
<citcontext>
<prevsection>
<prevsent>25k to kens/words.
</prevsent>
<prevsent>0 1 2 3 4 5 6 7 8 9 10 maximum swap distance 0 1 2 3 4 5 6 7 8 9 10 maximum swap segment size 0.138 0.139 0.140 0.141 0.142 0.143 0.144 0.145 bleu score figure 5: bleu scores for the chinese test set (  de coding) independence of maximum swap distance and maximum swap segment size.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
distance (msd) and the maximum swap segment size(msss) ranging from 0 to 10 and evaluated the translations with the bleu7 metric (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>the results are plotted in fig.
</nextsent>
<nextsent>5.
</nextsent>
<nextsent>on the one hand, the plot seems to paint pretty clear picture on the low end: score improvements are comparatively large initially but level off quickly.
</nextsent>
<nextsent>furthermore,the slight slope suggests slow but continuous improvements as swap restrictions are eased.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3739">
<title id=" N03-1025.xml">language and task independent text categorization with simple language models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>text categorization concerns the problem of automatically assigning given text passages (paragraphs or documents) into predefined categories.
</prevsent>
<prevsent>due to the rapid explosion of texts in digital form, text categorization has become an important area of research owing to the need to automatically organize and index large text collection sin various ways.
</prevsent>
</prevsection>
<citsent citstr=" J00-4001 ">
such techniques are currently being applied in many areas, including language identification, authorship attribution (stamatatos et al, 2000), <papid> J00-4001 </papid>text genre classification (kesseler et al, 1997; stamatatos et al, 2000), <papid> J00-4001 </papid>topic identification (dumais et al, 1998; lewis,1992; mccallum, 1998; yang, 1999), and subjective sentiment classification (turney, 2002).<papid> P02-1053 </papid></citsent>
<aftsection>
<nextsent>many standard machine learning techniques have been applied to automated text categorization problems, suchas naive-bayes classifiers, support vector machines, linear least squares models, neural networks, and k-nearest neighbor classifiers (yang, 1999; sebastiani, 2002).
</nextsent>
<nextsent>a common aspect of these approaches is that they treat text categorization as standard classification problem, and thereby reduce the learning process to two simple steps: feature engineering, and classification learning over the feature space.
</nextsent>
<nextsent>of these two steps, feature engineering is critical to achieving good performance in text categorization problems.
</nextsent>
<nextsent>once good features are identified, almost any reasonable technique for learning classifier seems to perform well (scott, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3747">
<title id=" N03-1025.xml">language and task independent text categorization with simple language models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>text categorization concerns the problem of automatically assigning given text passages (paragraphs or documents) into predefined categories.
</prevsent>
<prevsent>due to the rapid explosion of texts in digital form, text categorization has become an important area of research owing to the need to automatically organize and index large text collection sin various ways.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
such techniques are currently being applied in many areas, including language identification, authorship attribution (stamatatos et al, 2000), <papid> J00-4001 </papid>text genre classification (kesseler et al, 1997; stamatatos et al, 2000), <papid> J00-4001 </papid>topic identification (dumais et al, 1998; lewis,1992; mccallum, 1998; yang, 1999), and subjective sentiment classification (turney, 2002).<papid> P02-1053 </papid></citsent>
<aftsection>
<nextsent>many standard machine learning techniques have been applied to automated text categorization problems, suchas naive-bayes classifiers, support vector machines, linear least squares models, neural networks, and k-nearest neighbor classifiers (yang, 1999; sebastiani, 2002).
</nextsent>
<nextsent>a common aspect of these approaches is that they treat text categorization as standard classification problem, and thereby reduce the learning process to two simple steps: feature engineering, and classification learning over the feature space.
</nextsent>
<nextsent>of these two steps, feature engineering is critical to achieving good performance in text categorization problems.
</nextsent>
<nextsent>once good features are identified, almost any reasonable technique for learning classifier seems to perform well (scott, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3769">
<title id=" N04-4037.xml">a lightweight semantic chunker based on tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>those arguments are assigned different semantic categories depending on the roles that they play with respect to the predicate.
</prevsent>
<prevsent>researchers have used several different sets of argument labels.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
one possibility are the non mnemonic labels used in the propbank corpus (kingsbury and palmer, 2002): arg0, arg1, ?, argm loc, etc. an alternative set are thematic roles similar to those proposed in (gildea and jurafsky, 2002): <papid> J02-3001 </papid>agent, actor, beneficiary, cause, etc. shallow semantic parsing with the goal of creating domain independent meaning representation based on predicate/argument structure was first explored in detail by (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>since then several variants of the basic approach have been introduced using different features and different classifiers based on various machine-learning methods (gildea and palmer, 2002;.<papid> P02-1031 </papid>gildea and hockenmaier, 2003; <papid> W03-1008 </papid>surdeanu et. al., 2003; <papid> P03-1002 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman and hovy, 2003; <papid> N03-2008 </papid>hacioglu and ward, 2003; <papid> N03-2009 </papid>thompson et. al., 2003 ; pradhan et. al., 2003).</nextsent>
<nextsent>large semantically annotated databases, like framenet (baker et.al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury and palmer, 2002) have been used to train and test the classifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3771">
<title id=" N04-4037.xml">a lightweight semantic chunker based on tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers have used several different sets of argument labels.
</prevsent>
<prevsent>one possibility are the non mnemonic labels used in the propbank corpus (kingsbury and palmer, 2002): arg0, arg1, ?, argm loc, etc. an alternative set are thematic roles similar to those proposed in (gildea and jurafsky, 2002): <papid> J02-3001 </papid>agent, actor, beneficiary, cause, etc. shallow semantic parsing with the goal of creating domain independent meaning representation based on predicate/argument structure was first explored in detail by (gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
since then several variants of the basic approach have been introduced using different features and different classifiers based on various machine-learning methods (gildea and palmer, 2002;.<papid> P02-1031 </papid>gildea and hockenmaier, 2003; <papid> W03-1008 </papid>surdeanu et. al., 2003; <papid> P03-1002 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman and hovy, 2003; <papid> N03-2008 </papid>hacioglu and ward, 2003; <papid> N03-2009 </papid>thompson et. al., 2003 ; pradhan et. al., 2003).</citsent>
<aftsection>
<nextsent>large semantically annotated databases, like framenet (baker et.al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury and palmer, 2002) have been used to train and test the classifiers.</nextsent>
<nextsent>most of these approaches can be divided into two broad classes: constituent-by constituent (c-by-c) or word-by-word (w-by-w) classifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3772">
<title id=" N04-4037.xml">a lightweight semantic chunker based on tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers have used several different sets of argument labels.
</prevsent>
<prevsent>one possibility are the non mnemonic labels used in the propbank corpus (kingsbury and palmer, 2002): arg0, arg1, ?, argm loc, etc. an alternative set are thematic roles similar to those proposed in (gildea and jurafsky, 2002): <papid> J02-3001 </papid>agent, actor, beneficiary, cause, etc. shallow semantic parsing with the goal of creating domain independent meaning representation based on predicate/argument structure was first explored in detail by (gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-1008 ">
since then several variants of the basic approach have been introduced using different features and different classifiers based on various machine-learning methods (gildea and palmer, 2002;.<papid> P02-1031 </papid>gildea and hockenmaier, 2003; <papid> W03-1008 </papid>surdeanu et. al., 2003; <papid> P03-1002 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman and hovy, 2003; <papid> N03-2008 </papid>hacioglu and ward, 2003; <papid> N03-2009 </papid>thompson et. al., 2003 ; pradhan et. al., 2003).</citsent>
<aftsection>
<nextsent>large semantically annotated databases, like framenet (baker et.al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury and palmer, 2002) have been used to train and test the classifiers.</nextsent>
<nextsent>most of these approaches can be divided into two broad classes: constituent-by constituent (c-by-c) or word-by-word (w-by-w) classifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3773">
<title id=" N04-4037.xml">a lightweight semantic chunker based on tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers have used several different sets of argument labels.
</prevsent>
<prevsent>one possibility are the non mnemonic labels used in the propbank corpus (kingsbury and palmer, 2002): arg0, arg1, ?, argm loc, etc. an alternative set are thematic roles similar to those proposed in (gildea and jurafsky, 2002): <papid> J02-3001 </papid>agent, actor, beneficiary, cause, etc. shallow semantic parsing with the goal of creating domain independent meaning representation based on predicate/argument structure was first explored in detail by (gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
since then several variants of the basic approach have been introduced using different features and different classifiers based on various machine-learning methods (gildea and palmer, 2002;.<papid> P02-1031 </papid>gildea and hockenmaier, 2003; <papid> W03-1008 </papid>surdeanu et. al., 2003; <papid> P03-1002 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman and hovy, 2003; <papid> N03-2008 </papid>hacioglu and ward, 2003; <papid> N03-2009 </papid>thompson et. al., 2003 ; pradhan et. al., 2003).</citsent>
<aftsection>
<nextsent>large semantically annotated databases, like framenet (baker et.al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury and palmer, 2002) have been used to train and test the classifiers.</nextsent>
<nextsent>most of these approaches can be divided into two broad classes: constituent-by constituent (c-by-c) or word-by-word (w-by-w) classifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3774">
<title id=" N04-4037.xml">a lightweight semantic chunker based on tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers have used several different sets of argument labels.
</prevsent>
<prevsent>one possibility are the non mnemonic labels used in the propbank corpus (kingsbury and palmer, 2002): arg0, arg1, ?, argm loc, etc. an alternative set are thematic roles similar to those proposed in (gildea and jurafsky, 2002): <papid> J02-3001 </papid>agent, actor, beneficiary, cause, etc. shallow semantic parsing with the goal of creating domain independent meaning representation based on predicate/argument structure was first explored in detail by (gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-1006 ">
since then several variants of the basic approach have been introduced using different features and different classifiers based on various machine-learning methods (gildea and palmer, 2002;.<papid> P02-1031 </papid>gildea and hockenmaier, 2003; <papid> W03-1008 </papid>surdeanu et. al., 2003; <papid> P03-1002 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman and hovy, 2003; <papid> N03-2008 </papid>hacioglu and ward, 2003; <papid> N03-2009 </papid>thompson et. al., 2003 ; pradhan et. al., 2003).</citsent>
<aftsection>
<nextsent>large semantically annotated databases, like framenet (baker et.al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury and palmer, 2002) have been used to train and test the classifiers.</nextsent>
<nextsent>most of these approaches can be divided into two broad classes: constituent-by constituent (c-by-c) or word-by-word (w-by-w) classifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3775">
<title id=" N04-4037.xml">a lightweight semantic chunker based on tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers have used several different sets of argument labels.
</prevsent>
<prevsent>one possibility are the non mnemonic labels used in the propbank corpus (kingsbury and palmer, 2002): arg0, arg1, ?, argm loc, etc. an alternative set are thematic roles similar to those proposed in (gildea and jurafsky, 2002): <papid> J02-3001 </papid>agent, actor, beneficiary, cause, etc. shallow semantic parsing with the goal of creating domain independent meaning representation based on predicate/argument structure was first explored in detail by (gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-2008 ">
since then several variants of the basic approach have been introduced using different features and different classifiers based on various machine-learning methods (gildea and palmer, 2002;.<papid> P02-1031 </papid>gildea and hockenmaier, 2003; <papid> W03-1008 </papid>surdeanu et. al., 2003; <papid> P03-1002 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman and hovy, 2003; <papid> N03-2008 </papid>hacioglu and ward, 2003; <papid> N03-2009 </papid>thompson et. al., 2003 ; pradhan et. al., 2003).</citsent>
<aftsection>
<nextsent>large semantically annotated databases, like framenet (baker et.al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury and palmer, 2002) have been used to train and test the classifiers.</nextsent>
<nextsent>most of these approaches can be divided into two broad classes: constituent-by constituent (c-by-c) or word-by-word (w-by-w) classifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3776">
<title id=" N04-4037.xml">a lightweight semantic chunker based on tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers have used several different sets of argument labels.
</prevsent>
<prevsent>one possibility are the non mnemonic labels used in the propbank corpus (kingsbury and palmer, 2002): arg0, arg1, ?, argm loc, etc. an alternative set are thematic roles similar to those proposed in (gildea and jurafsky, 2002): <papid> J02-3001 </papid>agent, actor, beneficiary, cause, etc. shallow semantic parsing with the goal of creating domain independent meaning representation based on predicate/argument structure was first explored in detail by (gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-2009 ">
since then several variants of the basic approach have been introduced using different features and different classifiers based on various machine-learning methods (gildea and palmer, 2002;.<papid> P02-1031 </papid>gildea and hockenmaier, 2003; <papid> W03-1008 </papid>surdeanu et. al., 2003; <papid> P03-1002 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman and hovy, 2003; <papid> N03-2008 </papid>hacioglu and ward, 2003; <papid> N03-2009 </papid>thompson et. al., 2003 ; pradhan et. al., 2003).</citsent>
<aftsection>
<nextsent>large semantically annotated databases, like framenet (baker et.al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury and palmer, 2002) have been used to train and test the classifiers.</nextsent>
<nextsent>most of these approaches can be divided into two broad classes: constituent-by constituent (c-by-c) or word-by-word (w-by-w) classifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3777">
<title id=" N04-4037.xml">a lightweight semantic chunker based on tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one possibility are the non mnemonic labels used in the propbank corpus (kingsbury and palmer, 2002): arg0, arg1, ?, argm loc, etc. an alternative set are thematic roles similar to those proposed in (gildea and jurafsky, 2002): <papid> J02-3001 </papid>agent, actor, beneficiary, cause, etc. shallow semantic parsing with the goal of creating domain independent meaning representation based on predicate/argument structure was first explored in detail by (gildea and jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
<prevsent>since then several variants of the basic approach have been introduced using different features and different classifiers based on various machine-learning methods (gildea and palmer, 2002;.<papid> P02-1031 </papid>gildea and hockenmaier, 2003; <papid> W03-1008 </papid>surdeanu et. al., 2003; <papid> P03-1002 </papid>chen and rambow, 2003; <papid> W03-1006 </papid>fleischman and hovy, 2003; <papid> N03-2008 </papid>hacioglu and ward, 2003; <papid> N03-2009 </papid>thompson et. al., 2003 ; pradhan et. al., 2003).</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
large semantically annotated databases, like framenet (baker et.al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury and palmer, 2002) have been used to train and test the classifiers.</citsent>
<aftsection>
<nextsent>most of these approaches can be divided into two broad classes: constituent-by constituent (c-by-c) or word-by-word (w-by-w) classifiers.
</nextsent>
<nextsent>in c-by-c classification, the syntactic tree figure 1.
</nextsent>
<nextsent>proposed non-overlapping, shallow lexicalized syntactic/semantic tree structure representation of sentence is linear ized into sequence of its syntactic constituents (non-terminals).
</nextsent>
<nextsent>then each constituent is classified into one of several arguments or semantic roles using number of features derived from its respective context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3780">
<title id=" N04-4037.xml">a lightweight semantic chunker based on tagging </title>
<section> parsing strategy.  </section>
<citcontext>
<prevsection>
<prevsent>the ures are the word/tag pairs and previous phrase iob that appear in the context.
</prevsent>
<prevsent>an svm classifier is to classify the base phrase iob label.
</prevsent>
</prevsection>
<citsent citstr=" W00-0730 ">
this is very ilar to the set up in (kudo and matsu mato, 2000).<papid> W00-0730 </papid></citsent>
<aftsection>
<nextsent>in last stage (the major contribution of the paper) we up the input, context, features and decisions as wn below.
</nextsent>
<nextsent>the input is the base-phrase labels and headwords with their part of speech tags and positions in the phrase.
</nextsent>
<nextsent>the context is 2/+2 window centered at base phrase in question.
</nextsent>
<nextsent>an svm classifies the base ase into semantic role tags in an iob representation a context including the two previous semantic tag isions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3781">
<title id=" N04-4037.xml">a lightweight semantic chunker based on tagging </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>semantics of text is very difficult task and still lot remains to be done to bridge the gap.
</prevsent>
<prevsent>this is partly due to the difficulty of having consistent semantic annotations, partly due to the missing information/features for word senses and usages, partly due to the absence of world knowledge and partly due to the relatively small size of the training set.
</prevsent>
</prevsection>
<citsent citstr=" W04-2416 ">
our other experiments clearly show that with more training data and additional features it is possible to improve the performance by 10-15% absolute (hacioglu et. al., 2004).<papid> W04-2416 </papid></citsent>
<aftsection>
<nextsent>the feature engineering for semantic chunking is open-ended and the discussion of it is beyond the scope of the short paper.
</nextsent>
<nextsent>here, we have illustrated that the by-p approach is promising alternative to the recently proposed w-by-w approach (hacioglu and ward, 2003).<papid> N03-2009 </papid></nextsent>
<nextsent>we have developed novel phrase-by-phrase semantic chunker based on non-overlapping (or chunked) shallow language structure at lexical, syntactic and semantic levels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3783">
<title id=" N07-1007.xml">generating case markers in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>generation of grammatical elements such as inflectional endings and case markers is an important component technology for machine translation (mt).
</prevsent>
<prevsent>statistical machine translation (smt) systems, however, have not yet successfully incorporated components that generate grammatical elements in the target language.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
most stateof-the-art smt systems treat grammatical elements in exactly the same way as content words, and relyon general-purpose phrasal translations and target language models to generate these elements (e.g., och and ney, 2002; <papid> P02-1038 </papid>koehn et al, 2003; <papid> N03-1017 </papid>quirk et al, 2005; <papid> P05-1034 </papid>chiang, 2005; <papid> P05-1033 </papid>galley et al., 2006).<papid> P06-1121 </papid></citsent>
<aftsection>
<nextsent>however, since these grammatical elements in the target language often correspond to long-range dependencies and/or do not have any words corresponding in the source, they may be difficult to model, and the output of an smt system is often ungrammatical.
</nextsent>
<nextsent>for example, figure 1 shows an output from our baseline english-to-japanese smt system on sentence from computer domain.
</nextsent>
<nextsent>the smt system, trained on this domain, produces natural lexical translation for the english word patch as correction program, and translates replace into passive voice, which is more appropriate in japanese.
</nextsent>
<nextsent>1 however, there is problem in the case marker assignment: the accusative marker wo, which was output by the smt system, is completely inappropriate when the main verb is passive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3784">
<title id=" N07-1007.xml">generating case markers in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>generation of grammatical elements such as inflectional endings and case markers is an important component technology for machine translation (mt).
</prevsent>
<prevsent>statistical machine translation (smt) systems, however, have not yet successfully incorporated components that generate grammatical elements in the target language.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
most stateof-the-art smt systems treat grammatical elements in exactly the same way as content words, and relyon general-purpose phrasal translations and target language models to generate these elements (e.g., och and ney, 2002; <papid> P02-1038 </papid>koehn et al, 2003; <papid> N03-1017 </papid>quirk et al, 2005; <papid> P05-1034 </papid>chiang, 2005; <papid> P05-1033 </papid>galley et al., 2006).<papid> P06-1121 </papid></citsent>
<aftsection>
<nextsent>however, since these grammatical elements in the target language often correspond to long-range dependencies and/or do not have any words corresponding in the source, they may be difficult to model, and the output of an smt system is often ungrammatical.
</nextsent>
<nextsent>for example, figure 1 shows an output from our baseline english-to-japanese smt system on sentence from computer domain.
</nextsent>
<nextsent>the smt system, trained on this domain, produces natural lexical translation for the english word patch as correction program, and translates replace into passive voice, which is more appropriate in japanese.
</nextsent>
<nextsent>1 however, there is problem in the case marker assignment: the accusative marker wo, which was output by the smt system, is completely inappropriate when the main verb is passive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3785">
<title id=" N07-1007.xml">generating case markers in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>generation of grammatical elements such as inflectional endings and case markers is an important component technology for machine translation (mt).
</prevsent>
<prevsent>statistical machine translation (smt) systems, however, have not yet successfully incorporated components that generate grammatical elements in the target language.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
most stateof-the-art smt systems treat grammatical elements in exactly the same way as content words, and relyon general-purpose phrasal translations and target language models to generate these elements (e.g., och and ney, 2002; <papid> P02-1038 </papid>koehn et al, 2003; <papid> N03-1017 </papid>quirk et al, 2005; <papid> P05-1034 </papid>chiang, 2005; <papid> P05-1033 </papid>galley et al., 2006).<papid> P06-1121 </papid></citsent>
<aftsection>
<nextsent>however, since these grammatical elements in the target language often correspond to long-range dependencies and/or do not have any words corresponding in the source, they may be difficult to model, and the output of an smt system is often ungrammatical.
</nextsent>
<nextsent>for example, figure 1 shows an output from our baseline english-to-japanese smt system on sentence from computer domain.
</nextsent>
<nextsent>the smt system, trained on this domain, produces natural lexical translation for the english word patch as correction program, and translates replace into passive voice, which is more appropriate in japanese.
</nextsent>
<nextsent>1 however, there is problem in the case marker assignment: the accusative marker wo, which was output by the smt system, is completely inappropriate when the main verb is passive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3786">
<title id=" N07-1007.xml">generating case markers in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>generation of grammatical elements such as inflectional endings and case markers is an important component technology for machine translation (mt).
</prevsent>
<prevsent>statistical machine translation (smt) systems, however, have not yet successfully incorporated components that generate grammatical elements in the target language.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
most stateof-the-art smt systems treat grammatical elements in exactly the same way as content words, and relyon general-purpose phrasal translations and target language models to generate these elements (e.g., och and ney, 2002; <papid> P02-1038 </papid>koehn et al, 2003; <papid> N03-1017 </papid>quirk et al, 2005; <papid> P05-1034 </papid>chiang, 2005; <papid> P05-1033 </papid>galley et al., 2006).<papid> P06-1121 </papid></citsent>
<aftsection>
<nextsent>however, since these grammatical elements in the target language often correspond to long-range dependencies and/or do not have any words corresponding in the source, they may be difficult to model, and the output of an smt system is often ungrammatical.
</nextsent>
<nextsent>for example, figure 1 shows an output from our baseline english-to-japanese smt system on sentence from computer domain.
</nextsent>
<nextsent>the smt system, trained on this domain, produces natural lexical translation for the english word patch as correction program, and translates replace into passive voice, which is more appropriate in japanese.
</nextsent>
<nextsent>1 however, there is problem in the case marker assignment: the accusative marker wo, which was output by the smt system, is completely inappropriate when the main verb is passive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3787">
<title id=" N07-1007.xml">generating case markers in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>generation of grammatical elements such as inflectional endings and case markers is an important component technology for machine translation (mt).
</prevsent>
<prevsent>statistical machine translation (smt) systems, however, have not yet successfully incorporated components that generate grammatical elements in the target language.
</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
most stateof-the-art smt systems treat grammatical elements in exactly the same way as content words, and relyon general-purpose phrasal translations and target language models to generate these elements (e.g., och and ney, 2002; <papid> P02-1038 </papid>koehn et al, 2003; <papid> N03-1017 </papid>quirk et al, 2005; <papid> P05-1034 </papid>chiang, 2005; <papid> P05-1033 </papid>galley et al., 2006).<papid> P06-1121 </papid></citsent>
<aftsection>
<nextsent>however, since these grammatical elements in the target language often correspond to long-range dependencies and/or do not have any words corresponding in the source, they may be difficult to model, and the output of an smt system is often ungrammatical.
</nextsent>
<nextsent>for example, figure 1 shows an output from our baseline english-to-japanese smt system on sentence from computer domain.
</nextsent>
<nextsent>the smt system, trained on this domain, produces natural lexical translation for the english word patch as correction program, and translates replace into passive voice, which is more appropriate in japanese.
</nextsent>
<nextsent>1 however, there is problem in the case marker assignment: the accusative marker wo, which was output by the smt system, is completely inappropriate when the main verb is passive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3788">
<title id=" N07-1007.xml">generating case markers in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that the use of such features results in very high case assignment quality and also leads to notable improvement in mt quality.
</prevsent>
<prevsent>previous work has discussed the building of special-purpose classifiers which generate grammatical elements such as prepositions (haji?
</prevsent>
</prevsection>
<citsent citstr=" P06-1132 ">
et al 2002), determiners (knight and chander, 1994) and case markers (suzuki and toutanova, 2006) <papid> P06-1132 </papid>with an eye toward improving mt output.</citsent>
<aftsection>
<nextsent>how 1 there is strong tendency to avoid transitive sentences with an inanimate subject in japanese.
</nextsent>
<nextsent>49 ever, these components have not actually been integrated in an mt system.
</nextsent>
<nextsent>to our knowledge, this is the first work to integrate grammatical element production model in an smt system and to evaluate its impact in the context of end-to end mt. common approach of integrating new models with statistical mt system is to add them as new feature functions which are used in decoding or in models which re-rank n-best lists from the mt system (och et al, 2004).<papid> N04-1021 </papid></nextsent>
<nextsent>in this paper we propose an extension of the n-best re-ranking approach, where we expand n-best candidate lists with multiple case assignment variations, and define new feature functions on this expanded candidate set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3789">
<title id=" N07-1007.xml">generating case markers in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how 1 there is strong tendency to avoid transitive sentences with an inanimate subject in japanese.
</prevsent>
<prevsent>49 ever, these components have not actually been integrated in an mt system.
</prevsent>
</prevsection>
<citsent citstr=" N04-1021 ">
to our knowledge, this is the first work to integrate grammatical element production model in an smt system and to evaluate its impact in the context of end-to end mt. common approach of integrating new models with statistical mt system is to add them as new feature functions which are used in decoding or in models which re-rank n-best lists from the mt system (och et al, 2004).<papid> N04-1021 </papid></citsent>
<aftsection>
<nextsent>in this paper we propose an extension of the n-best re-ranking approach, where we expand n-best candidate lists with multiple case assignment variations, and define new feature functions on this expanded candidate set.
</nextsent>
<nextsent>we show that expanding the n-best lists significantly outperforms standard n-best reranking.
</nextsent>
<nextsent>we also show that integrating our case prediction model improves the quality of translation according to bleu (papineni et al, 2002) <papid> P02-1040 </papid>and human evaluation.</nextsent>
<nextsent>in this section, we provide necessary background of the current work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3790">
<title id=" N07-1007.xml">generating case markers in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we propose an extension of the n-best re-ranking approach, where we expand n-best candidate lists with multiple case assignment variations, and define new feature functions on this expanded candidate set.
</prevsent>
<prevsent>we show that expanding the n-best lists significantly outperforms standard n-best reranking.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we also show that integrating our case prediction model improves the quality of translation according to bleu (papineni et al, 2002) <papid> P02-1040 </papid>and human evaluation.</citsent>
<aftsection>
<nextsent>in this section, we provide necessary background of the current work.
</nextsent>
<nextsent>2.1 task of case marker prediction.
</nextsent>
<nextsent>our definition of the case marker prediction task follows suzuki and toutanova (2006).<papid> P06-1132 </papid></nextsent>
<nextsent>that is, we assume that we are given source english sentence, and its translation in japanese which does not include case markers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3801">
<title id=" N07-1007.xml">generating case markers in machine translation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>wa topic table 1.
</prevsent>
<prevsent>case markers to be predicted 50 where   are the model parameters and fj(t) is the value of the feature function on the candidate t. there are ten feature functions in the treelet system, including log-probabilities according to inverted and direct channel models estimated by relative frequency, lexical weighting channel models following vogel et al (2003), trigram target language model, an order model, word count, phrase count, average phrase size functions, and whole-sentence ibm model 1 log probabilities in both directions (och et al 2004).<papid> N04-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the weights of these models are determined using the max-bleu method described in och (2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>as we describe in section 4, the case prediction model is integrated into the system as an additional feature function.
</nextsent>
<nextsent>the treelet translation model is estimated using parallel corpus.
</nextsent>
<nextsent>first, the corpus is word aligned using giza++ (och and ney, 2000); <papid> P00-1056 </papid>then the source sentences are parsed into dependency structure, and the dependency is projected onto the target side following the heuristics described in quirk et al (2005).<papid> P05-1034 </papid></nextsent>
<nextsent>figure 2 shows an example of an aligned sentence pair: on the source (english) side, pos tags and word dependency structure are assigned (solid arcs); the word alignments between english and japanese words are indicated by the dotted lines.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3802">
<title id=" N07-1007.xml">generating case markers in machine translation </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>as we describe in section 4, the case prediction model is integrated into the system as an additional feature function.
</prevsent>
<prevsent>the treelet translation model is estimated using parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
first, the corpus is word aligned using giza++ (och and ney, 2000); <papid> P00-1056 </papid>then the source sentences are parsed into dependency structure, and the dependency is projected onto the target side following the heuristics described in quirk et al (2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>figure 2 shows an example of an aligned sentence pair: on the source (english) side, pos tags and word dependency structure are assigned (solid arcs); the word alignments between english and japanese words are indicated by the dotted lines.
</nextsent>
<nextsent>on the target (japanese) side, projected word dependencies (solid arcs) are available.
</nextsent>
<nextsent>additional annotations in figure 2, namely the pos tags and the bunsetsu dependency structure (bold arcs) on the target side, are derived from the treelet system to be used for building case prediction model, which we describe in section 3.
</nextsent>
<nextsent>2.3 data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3812">
<title id=" N07-1007.xml">generating case markers in machine translation </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>this is presumably because the case model does affect the choice of content words as well, but this influence is limited and can be best captured when using small number (n=20) of baseline system candidates.
</prevsent>
<prevsent>based on these results on the dev-1k set, we chose the best model (i.e., 20-best-10case) and evaluated it on the test-2k set against the base line.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
using the pair-wise statistical test design described in collins et al (2005), <papid> P05-1066 </papid>the bleu improvement (35.53 vs. 36.29) was statistically significant (p   .01) according to the wilcox on signed-rank test.</citsent>
<aftsection>
<nextsent>5.3 human evaluation.
</nextsent>
<nextsent>these results demonstrate that the proposed model is effective at improving the translation quality according to the bleu score.
</nextsent>
<nextsent>in this section, we report the results of human evaluation to ensure that the improvements in bleu lead to better translations according to human evaluators.
</nextsent>
<nextsent>we performed human evaluation on the 20best-10case (n=20, k=10) and 1best-40case (n=1, k=40) models against the baseline using our final test set, the test-2k data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3813">
<title id=" N03-2030.xml">a hybrid approach to content analysis for automatic essay grading </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>approaches, namely lsa and naive bayes, as well as purely symbolic approach.
</prevsent>
<prevsent>in this paper we describe carmeltc   , novel automatic essay grading approach using hybrid text classification technique for analyzing essay answers to qualitative physics questions inside the why2 tutorial dialogue system (vanlehn et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P98-1032 ">
in contrast to many previous approaches to automated essay grading (burstein et al., 1998; <papid> P98-1032 </papid>foltz et al, 1998; larkey, 1998), our goal is not to assign letter grade to student essays.</citsent>
<aftsection>
<nextsent>instead, our purpose is totally which set of correct answer aspects are present in student essays.
</nextsent>
<nextsent>previously, tutorial dialogue systems such as auto-tutor (wiemer-hastings et al, 1998) and research methods tutor (malatesta et al, 2002) have used lsa (landauer et al, 1998) to perform the same type of content analysis for student essays that we do in why2.
</nextsent>
<nextsent>while bag of words approaches such aslsa have performed successfully on the content analysis task in domains such as computer literacy (wiemer hastings et al, 1998), they have been demonstrated to perform poorly in causal domains such as research methods (malatesta et al, 2002) because they base their predictions only on the words included in text and not onthe functional relationships between them.
</nextsent>
<nextsent>thus, we propose carmeltc as an alternative.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3814">
<title id=" N01-1024.xml">knowledge free induction of inflectional morphologies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as an example, the conflation set of the word abuse?
</prevsent>
<prevsent>would contain abuse?, abused?, abuses?, abusive?, abusively?, and so forth.
</prevsent>
</prevsection>
<citsent citstr=" W00-0712 ">
our algorithm extends earlier approaches to morphology induction by combining various induced information sources: the semantic relatedness of the affixed forms usinga latent semantic analysis approach to corpus based semantics (schone and jurafsky, 2000), <papid> W00-0712 </papid>affix frequency, syntactic context, and transitive closure.</citsent>
<aftsection>
<nextsent>using the hand-labeled celex lexicon (baayen, et al., 1993) as our gold standard, the current version of our algorithm achieves an f-score of 88.1% on the task of identifying conflation sets in english, outperforming earlier algorithms.
</nextsent>
<nextsent>our algorithm is also applied to german and dutch and evaluated on its ability to find prefixes, suffixes, and circumfixes in these languages.
</nextsent>
<nextsent>to our knowledge, this serves as the first evaluation of complete regular morphological induction of german or dutch (although researchers such as nakisa and hahn (1996) have evaluated induction algorithms on morphological sub-problems in german).
</nextsent>
<nextsent>previous morphology induction approaches have fallen into three categories.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3817">
<title id=" N01-1024.xml">knowledge free induction of inflectional morphologies </title>
<section> previous approaches.  </section>
<citcontext>
<prevsection>
<prevsent>some researchers begin with some initial human labeled source from which they induce other morphological components.
</prevsent>
<prevsent>in particular, xu and croft (1998) use word context derived from corpus to refine porter stemmer output.
</prevsent>
</prevsection>
<citsent citstr=" W99-0904 ">
gaussier (1999) <papid> W99-0904 </papid>induces derivational morphology using an inflectional lexicon which includes part of speech information.</citsent>
<aftsection>
<nextsent>grabar and zweigenbaum (1999) use the snomed corpus of semantically-arranged medical terms to find semantically-motivated morphological relationships.
</nextsent>
<nextsent>also, yarowsky and wicentowski (2000) <papid> P00-1027 </papid>obtained outstanding results at inducing english past tense after beginning with list of the open class roots in the language, table of languages inflectional parts of speech, and the canonical suffixes for each part of speech.</nextsent>
<nextsent>2.2 affix inventories.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3818">
<title id=" N01-1024.xml">knowledge free induction of inflectional morphologies </title>
<section> previous approaches.  </section>
<citcontext>
<prevsection>
<prevsent>gaussier (1999) <papid> W99-0904 </papid>induces derivational morphology using an inflectional lexicon which includes part of speech information.</prevsent>
<prevsent>grabar and zweigenbaum (1999) use the snomed corpus of semantically-arranged medical terms to find semantically-motivated morphological relationships.</prevsent>
</prevsection>
<citsent citstr=" P00-1027 ">
also, yarowsky and wicentowski (2000) <papid> P00-1027 </papid>obtained outstanding results at inducing english past tense after beginning with list of the open class roots in the language, table of languages inflectional parts of speech, and the canonical suffixes for each part of speech.</citsent>
<aftsection>
<nextsent>2.2 affix inventories.
</nextsent>
<nextsent>a second, knowledge-free category of research has focused on obtaining affix inventories.
</nextsent>
<nextsent>brent, et al (1995) used minimum description length (mdl) to find the most data-compressing suffixes.
</nextsent>
<nextsent>kazakov (1997) does something akin to this using mdl as fitness metric for evolutionary computing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3838">
<title id=" N06-2039.xml">unsupervised induction of modern standard arabic verb classes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>inducing such classes automatically allows fora large-scale study of different linguistic phenomena within the msa verb system, as well as cross linguistic comparison with their english counterparts.
</prevsent>
<prevsent>moreover, drawing on generalizations yielded by such classification could potentially be use fulin several nlp problems such as information extraction, event detection, information retrieval andword sense disambiguation, not to mention the facilitation of lexical resource creation such as msa wordnets and ontologies.
</prevsent>
</prevsection>
<citsent citstr=" J01-3003 ">
based on the levin classes, many researchers attempt to induce such classes automatically (merloand stevenson, 2001; <papid> J01-3003 </papid>schulte im walde, 2000) . notably, in the work of merlo and stevenson , they attempt to induce three main english verb classes on alarge scale from parsed corpora, the class of unerga 153tive, unaccusative, and object-drop verbs.</citsent>
<aftsection>
<nextsent>they report results of 69.8% accuracy on task whose base line is 34%, and whose expert-based upper bound is 86.5%.
</nextsent>
<nextsent>in task similar to ours except for its use of english, schulte im walde clusters english verbs semantically by using their alternation behavior, using frames from statistical parser combined with wordnet classes.
</nextsent>
<nextsent>she evaluates against the published levin classes, and reports that 61% of all verbs are clustered into correct classes, with base line of 5%.
</nextsent>
<nextsent>we employ both soft and hard clustering technique sto induce the verb classes, using the clustering algorithms implemented in the library cluster (kaufmanand rousseeuw, 1990) in the statistical computing language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3839">
<title id=" N03-4011.xml">automatically discovering word senses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using word senses versus word forms is useful in many applications such as information retrieval (voorhees 1998), machine translation (hutchins and sommers 1992), and question-answering (pasca and harabagiu 2001).
</prevsent>
<prevsent>the distributional hypothesis (harris 1985) states that words that occur in the same contexts tend to be similar.
</prevsent>
</prevsection>
<citsent citstr=" P90-1034 ">
there have been many approaches to compute the similarity between words based on their distribution in corpus (hindle 1990; <papid> P90-1034 </papid>landauer and dumais 1997; lin 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>the output of these programs is ranked list of similar words to each word.
</nextsent>
<nextsent>for example, lins approach outputs the following similar words for wine and suit: wine: beer, white wine, red wine, chardonnay, champagne, fruit, food, coffee, juice, cabernet, cognac, vinegar, pinot noir, milk, vodka,?
</nextsent>
<nextsent>suit: lawsuit, jacket, shirt, pant, dress, case, sweater, coat, trouser, claim, business suit, blouse, skirt, litigation, ? the similar words of wine represent the meaning of wine.
</nextsent>
<nextsent>however, the similar words of suit represent mixture of its clothing and litigation senses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3840">
<title id=" N03-4011.xml">automatically discovering word senses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using word senses versus word forms is useful in many applications such as information retrieval (voorhees 1998), machine translation (hutchins and sommers 1992), and question-answering (pasca and harabagiu 2001).
</prevsent>
<prevsent>the distributional hypothesis (harris 1985) states that words that occur in the same contexts tend to be similar.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
there have been many approaches to compute the similarity between words based on their distribution in corpus (hindle 1990; <papid> P90-1034 </papid>landauer and dumais 1997; lin 1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>the output of these programs is ranked list of similar words to each word.
</nextsent>
<nextsent>for example, lins approach outputs the following similar words for wine and suit: wine: beer, white wine, red wine, chardonnay, champagne, fruit, food, coffee, juice, cabernet, cognac, vinegar, pinot noir, milk, vodka,?
</nextsent>
<nextsent>suit: lawsuit, jacket, shirt, pant, dress, case, sweater, coat, trouser, claim, business suit, blouse, skirt, litigation, ? the similar words of wine represent the meaning of wine.
</nextsent>
<nextsent>however, the similar words of suit represent mixture of its clothing and litigation senses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3842">
<title id=" N03-4011.xml">automatically discovering word senses </title>
<section> feature representation.  </section>
<citcontext>
<prevsection>
<prevsent>is verb object context.
</prevsent>
<prevsent>if the word wine occurred in this context, the context is feature of wine.
</prevsent>
</prevsection>
<citsent citstr=" C94-1079 ">
these features are obtained by parsing large corpus using minipar (lin 1994), <papid> C94-1079 </papid>broad-coverage english parser.</citsent>
<aftsection>
<nextsent>the value of the feature is the pointwise mutual information (manning and schtze 1999) between the feature and the word.
</nextsent>
<nextsent>let be context and fc(w) be the frequency count of word occurring in context c. the pointwise mutual information, miw,c, between and is defined as: edmonton, may-june 2003 demonstrations , pp.
</nextsent>
<nextsent>21-22 proceedings of hlt-naacl 2003 ( ) ( ) ( ) jf wf wf cw c i mi ???
</nextsent>
<nextsent>=, where is the total frequency counts of all words and their contexts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3843">
<title id=" N04-1008.xml">automatic question answering beyond the factoid </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the definition of the task, however, is generally restricted to answering factoid questions: questions for which complete answer can be given in 50 bytes or less, which is roughly few words.
</prevsent>
<prevsent>even with this limitation in place, factoid question answering is by no means an easy task.
</prevsent>
</prevsection>
<citsent citstr=" P03-1003 ">
the challenges posed by answering factoid question have been addressed using large variety of techniques, such as question parsing (hovy et al , 2001; moldovan et al , 2002), question-type determination (brill et al , 2001; ittycheraih and roukos, 2002; hovy et al , 2001; moldovan et al , 2002), wordnet exploitation (hovy et al ., 2001; pasca and harabagiu, 2001; prager et al , 2001), web exploitation (brill et al , 2001; kwok et al , 2001), noisy-channel transformations (echihabi and marcu, 2003), <papid> P03-1003 </papid>semantic analysis (xu et al , 2002; hovy et al , 2001; moldovan et al , 2002), and inferencing (moldovan et al , 2002).</citsent>
<aftsection>
<nextsent>the obvious limitation of any factoid qa system is that many questions that people want answers for are not factoid questions.
</nextsent>
<nextsent>it is also frequently the case that non factoid questions are the ones for which answers cannot as readily be found by simply using good search engine.
</nextsent>
<nextsent>it follows that there is good economic incentive in moving the qa task to more general level: it is likely that system able to answer complex questions of the type people generally and/or frequently ask has greater potential impact than one restricted to answering only factoid questions.
</nextsent>
<nextsent>a natural move is to recast the question answering task to handling questions people frequently ask or want answers for, as seen in frequently asked questions (faq) lists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3844">
<title id=" N04-1008.xml">automatic question answering beyond the factoid </title>
<section> a qa system architecture  </section>
<citcontext>
<prevsection>
<prevsent>as part of its syntactic and discourse constraints, plus an inherently underspecified unit segmentation problem, which can all confuse the search engine.
</prevsent>
<prevsent>to counterbalance some of these disadvantages, we build statistical chunker that uses dynamic programming algorithm to chunk the question into chunks/phrases.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
the chunker is trained on the answer side of the training corpus in order to learn 2 and 3 word collocations, defined using the likelihood ratio of dunning (1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>note that we are chunking the question using answer-side statistics, precisely as measure for bridging the stylistic gap between questions and answers.
</nextsent>
<nextsent>our chunker uses the extracted collocation statistics to make an optimal chunking using dijkstra-style dynamic programming algorithm.
</nextsent>
<nextsent>in figure 2 we present an example of the results returned by our statistical chunker.
</nextsent>
<nextsent>important cues such as differ from?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3845">
<title id=" N04-1008.xml">automatic question answering beyond the factoid </title>
<section> a qa system architecture  </section>
<citcontext>
<prevsection>
<prevsent>between the question terms and the answer terms.
</prevsent>
<prevsent>berger et al  showed that techniques that did not bridge the lexical chasm were likely to perform worse than techniques that did.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
for comparison purposes, we consider two different algorithms for our answer extraction module: one that does not bridge the lexical chasm, based on n-gram cooccurrences between the question terms and the answer terms; and one that attempts to bridge the lexical chasm using statistical machine translation inspired techniques (brown et al , 1993) <papid> J93-2003 </papid>in order to find the best answer forgiven question.</citsent>
<aftsection>
<nextsent>for both algorithms, each 3 consecutive sentences from the documents provided by the filter module form potential answer.
</nextsent>
<nextsent>the choice of 3 sentences comes from the average number of sentences in the answers from our training corpus.
</nextsent>
<nextsent>the choice of consecutive ness comes from the empirical observation that answers built up from consecutive sentences tend to be more coherent and contain more non-redundant information than answers built up from non-consecutive sentences.
</nextsent>
<nextsent>4.4.1 n-gram co-occurrence statistics for answer extraction n-gram co-occurrence statistics have been successfully used in automatic evaluation (papineni et al  2002, <papid> P02-1040 </papid>lin and hovy 2003), <papid> N03-1020 </papid>and more recently as training criteria in statistical machine translation (och 2003).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3846">
<title id=" N04-1008.xml">automatic question answering beyond the factoid </title>
<section> a qa system architecture  </section>
<citcontext>
<prevsection>
<prevsent>the choice of 3 sentences comes from the average number of sentences in the answers from our training corpus.
</prevsent>
<prevsent>the choice of consecutive ness comes from the empirical observation that answers built up from consecutive sentences tend to be more coherent and contain more non-redundant information than answers built up from non-consecutive sentences.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
4.4.1 n-gram co-occurrence statistics for answer extraction n-gram co-occurrence statistics have been successfully used in automatic evaluation (papineni et al  2002, <papid> P02-1040 </papid>lin and hovy 2003), <papid> N03-1020 </papid>and more recently as training criteria in statistical machine translation (och 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we implemented an answer extraction algorithm using the bleu score of papineni et al  (2002) <papid> P02-1040 </papid>as means of assessing the overlap between the question and the proposed answers.</nextsent>
<nextsent>for each potential answer, the overlap with the question was assessed with bleu (with the brevity penalty set to penalize answers shorter than 3 times the length of the question).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3847">
<title id=" N04-1008.xml">automatic question answering beyond the factoid </title>
<section> a qa system architecture  </section>
<citcontext>
<prevsection>
<prevsent>the choice of 3 sentences comes from the average number of sentences in the answers from our training corpus.
</prevsent>
<prevsent>the choice of consecutive ness comes from the empirical observation that answers built up from consecutive sentences tend to be more coherent and contain more non-redundant information than answers built up from non-consecutive sentences.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
4.4.1 n-gram co-occurrence statistics for answer extraction n-gram co-occurrence statistics have been successfully used in automatic evaluation (papineni et al  2002, <papid> P02-1040 </papid>lin and hovy 2003), <papid> N03-1020 </papid>and more recently as training criteria in statistical machine translation (och 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we implemented an answer extraction algorithm using the bleu score of papineni et al  (2002) <papid> P02-1040 </papid>as means of assessing the overlap between the question and the proposed answers.</nextsent>
<nextsent>for each potential answer, the overlap with the question was assessed with bleu (with the brevity penalty set to penalize answers shorter than 3 times the length of the question).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3848">
<title id=" N04-1008.xml">automatic question answering beyond the factoid </title>
<section> a qa system architecture  </section>
<citcontext>
<prevsection>
<prevsent>the choice of 3 sentences comes from the average number of sentences in the answers from our training corpus.
</prevsent>
<prevsent>the choice of consecutive ness comes from the empirical observation that answers built up from consecutive sentences tend to be more coherent and contain more non-redundant information than answers built up from non-consecutive sentences.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
4.4.1 n-gram co-occurrence statistics for answer extraction n-gram co-occurrence statistics have been successfully used in automatic evaluation (papineni et al  2002, <papid> P02-1040 </papid>lin and hovy 2003), <papid> N03-1020 </papid>and more recently as training criteria in statistical machine translation (och 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we implemented an answer extraction algorithm using the bleu score of papineni et al  (2002) <papid> P02-1040 </papid>as means of assessing the overlap between the question and the proposed answers.</nextsent>
<nextsent>for each potential answer, the overlap with the question was assessed with bleu (with the brevity penalty set to penalize answers shorter than 3 times the length of the question).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3851">
<title id=" N04-1004.xml">a salience based approach to gesture speech alignment </title>
<section> iconic: hand draws trajectory from.  </section>
<citcontext>
<prevsection>
<prevsent>system (bolt, 1980), which allowed users to issue natural language commands and use deictic hand gestures to resolve references from speech.commands were subject to strict grammar and alignment was straightforward: keywords created holes in the semantic frame, and temporally-aligned gestures filled the holes.
</prevsent>
<prevsent>more recent systems have extended this approachsomewhat.
</prevsent>
</prevsection>
<citsent citstr=" C00-1054 ">
johnston and bangalore describe multimodal parsing algorithm that is built using 3-tape, finite state transducer (fst) (johnston and bangalore, 2000).<papid> C00-1054 </papid></citsent>
<aftsection>
<nextsent>the speech and gestures of each multimodal utterance are provided as input to an fst whose output is semantic representation conveying the combined meaning.
</nextsent>
<nextsent>a similar system, based on graph-matching algorithm,is described in (chai et al, 2004).
</nextsent>
<nextsent>these systems perform mutual disambiguation, where each modality helps to correct errors in the others.
</nextsent>
<nextsent>however, both approaches restrict users to predefined grammar and lexicon, and rely heavily on having complete, formal ontology of the domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3852">
<title id=" N04-1004.xml">a salience based approach to gesture speech alignment </title>
<section> iconic: hand draws trajectory from.  </section>
<citcontext>
<prevsection>
<prevsent>anaphora resolution involves linking an anaphor to its corresponding antecedent in the same or previous sentence.
</prevsent>
<prevsent>in many cases, speech/gesture multimodal fusion works in very similar way, with gestures grounding some of the same anaphoric pronouns (e.g., this?, that?, here?).
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
one approach to anaphora resolution is to assign salience value to each noun phrase that is candidate for acting as grounding referent, and then to choose the noun phrase with the greatest salience (lappin andleass, 1994).<papid> J94-4002 </papid></citsent>
<aftsection>
<nextsent>mitkov showed that salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (mitkov,1998).<papid> P98-2143 </papid></nextsent>
<nextsent>salience values are typically computed by applying linguistic knowledge; e.g., recent noun phrases are more salient, gender and number should agree, etc. this knowledge is applied to derive salience value through the application of set of predefined salience weights on each feature.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3853">
<title id=" N04-1004.xml">a salience based approach to gesture speech alignment </title>
<section> iconic: hand draws trajectory from.  </section>
<citcontext>
<prevsection>
<prevsent>in many cases, speech/gesture multimodal fusion works in very similar way, with gestures grounding some of the same anaphoric pronouns (e.g., this?, that?, here?).
</prevsent>
<prevsent>one approach to anaphora resolution is to assign salience value to each noun phrase that is candidate for acting as grounding referent, and then to choose the noun phrase with the greatest salience (lappin andleass, 1994).<papid> J94-4002 </papid></prevsent>
</prevsection>
<citsent citstr=" P98-2143 ">
mitkov showed that salience-based approach can be applied across genres and without complex syntactic, semantic, and discourse analysis (mitkov,1998).<papid> P98-2143 </papid></citsent>
<aftsection>
<nextsent>salience values are typically computed by applying linguistic knowledge; e.g., recent noun phrases are more salient, gender and number should agree, etc. this knowledge is applied to derive salience value through the application of set of predefined salience weights on each feature.
</nextsent>
<nextsent>salience weights may be defined by hand, as in (lappin and leass, 1994), <papid> J94-4002 </papid>or learned from data (mitkov et al, 2002).</nextsent>
<nextsent>anaphora resolution and gesture-speech alignment arevery similar problems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3856">
<title id=" N04-1004.xml">a salience based approach to gesture speech alignment </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>7.3 other anaphora resolution techniques.
</prevsent>
<prevsent>we have based this research on salience values, which is just one of several possible alternative approaches to anaphora resolution.
</prevsent>
</prevsection>
<citsent citstr=" A88-1003 ">
one such alternative is the use of constraints: rules that eliminate candidates from the list of possible antecedents (rich and luperfoy, 1988).<papid> A88-1003 </papid></citsent>
<aftsection>
<nextsent>an example of constraint in anaphora resolution is rule requiring the elimination of all candidates that disagree in gender or number with the referential pronoun.
</nextsent>
<nextsent>constraints may be used in combination with salience metric, to prune away unlikely choices before searching.the advantage is that enforcing constraints could be substantially less computationally expensive than searching through the space of all possible bindings for the one with the highest salience.
</nextsent>
<nextsent>one possible future project would beto develop set of constraints for speech-gesture alignment, and investigate the effect of these constraints on both accuracy and speed.ge, hale, and charniak propose data-driven approach to anaphora resolution (ge et al, 1998).<papid> W98-1119 </papid></nextsent>
<nextsent>forgiven pronoun, their system can compute probability for each candidate antecedent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3857">
<title id=" N04-1004.xml">a salience based approach to gesture speech alignment </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>an example of constraint in anaphora resolution is rule requiring the elimination of all candidates that disagree in gender or number with the referential pronoun.
</prevsent>
<prevsent>constraints may be used in combination with salience metric, to prune away unlikely choices before searching.the advantage is that enforcing constraints could be substantially less computationally expensive than searching through the space of all possible bindings for the one with the highest salience.
</prevsent>
</prevsection>
<citsent citstr=" W98-1119 ">
one possible future project would beto develop set of constraints for speech-gesture alignment, and investigate the effect of these constraints on both accuracy and speed.ge, hale, and charniak propose data-driven approach to anaphora resolution (ge et al, 1998).<papid> W98-1119 </papid></citsent>
<aftsection>
<nextsent>forgiven pronoun, their system can compute probability for each candidate antecedent.
</nextsent>
<nextsent>their approach of seeking to maximize this probability is similar to the salience maximizing approach that we have described.
</nextsent>
<nextsent>however, instead of using parametric salience function, they learn set of conditional probability distributions directly fromthe data.
</nextsent>
<nextsent>if this approach could be applied to gesture speech alignment, it would be advantageous because the binding probabilities could be combined with the output of probabilistic recognizers to produce pipeline architecture, similar to that proposed in (wu et al, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3858">
<title id=" N06-1004.xml">segment choice models feature rich models for global distortion in statistical machine translation </title>
<section> introduction: defining scms.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" N03-1017 ">
the work presented here was done in the context of phrase-based mt (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>distortion in phrase-based mt occurs when the order of phrases in the source-language sentence changes during translation, so the order of corresponding phrases in the target-language translation is different.
</nextsent>
<nextsent>some mt systems allow arbitrary reordering of phrases, but impose distortion penalty proportional to the difference between the new and the original phrase order (koehn, 2004).
</nextsent>
<nextsent>some interesting recent research focuses on reordering within narrow window of phrases (kumar and byrne, 2005; <papid> H05-1021 </papid>tillmann and zhang, 2005; <papid> P05-1069 </papid>tillmann, 2004).<papid> N04-4026 </papid></nextsent>
<nextsent>the (tillmann, 2004) <papid> N04-4026 </papid>paper introduced lexical features for distortion modeling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3859">
<title id=" N06-1004.xml">segment choice models feature rich models for global distortion in statistical machine translation </title>
<section> introduction: defining scms.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J04-4002 ">
the work presented here was done in the context of phrase-based mt (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>distortion in phrase-based mt occurs when the order of phrases in the source-language sentence changes during translation, so the order of corresponding phrases in the target-language translation is different.
</nextsent>
<nextsent>some mt systems allow arbitrary reordering of phrases, but impose distortion penalty proportional to the difference between the new and the original phrase order (koehn, 2004).
</nextsent>
<nextsent>some interesting recent research focuses on reordering within narrow window of phrases (kumar and byrne, 2005; <papid> H05-1021 </papid>tillmann and zhang, 2005; <papid> P05-1069 </papid>tillmann, 2004).<papid> N04-4026 </papid></nextsent>
<nextsent>the (tillmann, 2004) <papid> N04-4026 </papid>paper introduced lexical features for distortion modeling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3860">
<title id=" N06-1004.xml">segment choice models feature rich models for global distortion in statistical machine translation </title>
<section> introduction: defining scms.  </section>
<citcontext>
<prevsection>
<prevsent>distortion in phrase-based mt occurs when the order of phrases in the source-language sentence changes during translation, so the order of corresponding phrases in the target-language translation is different.
</prevsent>
<prevsent>some mt systems allow arbitrary reordering of phrases, but impose distortion penalty proportional to the difference between the new and the original phrase order (koehn, 2004).
</prevsent>
</prevsection>
<citsent citstr=" H05-1021 ">
some interesting recent research focuses on reordering within narrow window of phrases (kumar and byrne, 2005; <papid> H05-1021 </papid>tillmann and zhang, 2005; <papid> P05-1069 </papid>tillmann, 2004).<papid> N04-4026 </papid></citsent>
<aftsection>
<nextsent>the (tillmann, 2004) <papid> N04-4026 </papid>paper introduced lexical features for distortion modeling.</nextsent>
<nextsent>a recent paper (collins et al, 2005) <papid> P05-1066 </papid>shows that major gains can be obtained by constructing parse tree for the source sentence and then applying handcrafted reordering rules to rewrite the source in target-language-like word order prior to mt. our model assumes that the source sentence is completely segmented prior to distortion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3862">
<title id=" N06-1004.xml">segment choice models feature rich models for global distortion in statistical machine translation </title>
<section> introduction: defining scms.  </section>
<citcontext>
<prevsection>
<prevsent>distortion in phrase-based mt occurs when the order of phrases in the source-language sentence changes during translation, so the order of corresponding phrases in the target-language translation is different.
</prevsent>
<prevsent>some mt systems allow arbitrary reordering of phrases, but impose distortion penalty proportional to the difference between the new and the original phrase order (koehn, 2004).
</prevsent>
</prevsection>
<citsent citstr=" P05-1069 ">
some interesting recent research focuses on reordering within narrow window of phrases (kumar and byrne, 2005; <papid> H05-1021 </papid>tillmann and zhang, 2005; <papid> P05-1069 </papid>tillmann, 2004).<papid> N04-4026 </papid></citsent>
<aftsection>
<nextsent>the (tillmann, 2004) <papid> N04-4026 </papid>paper introduced lexical features for distortion modeling.</nextsent>
<nextsent>a recent paper (collins et al, 2005) <papid> P05-1066 </papid>shows that major gains can be obtained by constructing parse tree for the source sentence and then applying handcrafted reordering rules to rewrite the source in target-language-like word order prior to mt. our model assumes that the source sentence is completely segmented prior to distortion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3864">
<title id=" N06-1004.xml">segment choice models feature rich models for global distortion in statistical machine translation </title>
<section> introduction: defining scms.  </section>
<citcontext>
<prevsection>
<prevsent>distortion in phrase-based mt occurs when the order of phrases in the source-language sentence changes during translation, so the order of corresponding phrases in the target-language translation is different.
</prevsent>
<prevsent>some mt systems allow arbitrary reordering of phrases, but impose distortion penalty proportional to the difference between the new and the original phrase order (koehn, 2004).
</prevsent>
</prevsection>
<citsent citstr=" N04-4026 ">
some interesting recent research focuses on reordering within narrow window of phrases (kumar and byrne, 2005; <papid> H05-1021 </papid>tillmann and zhang, 2005; <papid> P05-1069 </papid>tillmann, 2004).<papid> N04-4026 </papid></citsent>
<aftsection>
<nextsent>the (tillmann, 2004) <papid> N04-4026 </papid>paper introduced lexical features for distortion modeling.</nextsent>
<nextsent>a recent paper (collins et al, 2005) <papid> P05-1066 </papid>shows that major gains can be obtained by constructing parse tree for the source sentence and then applying handcrafted reordering rules to rewrite the source in target-language-like word order prior to mt. our model assumes that the source sentence is completely segmented prior to distortion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3867">
<title id=" N06-1004.xml">segment choice models feature rich models for global distortion in statistical machine translation </title>
<section> introduction: defining scms.  </section>
<citcontext>
<prevsection>
<prevsent>some interesting recent research focuses on reordering within narrow window of phrases (kumar and byrne, 2005; <papid> H05-1021 </papid>tillmann and zhang, 2005; <papid> P05-1069 </papid>tillmann, 2004).<papid> N04-4026 </papid></prevsent>
<prevsent>the (tillmann, 2004) <papid> N04-4026 </papid>paper introduced lexical features for distortion modeling.</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
a recent paper (collins et al, 2005) <papid> P05-1066 </papid>shows that major gains can be obtained by constructing parse tree for the source sentence and then applying handcrafted reordering rules to rewrite the source in target-language-like word order prior to mt. our model assumes that the source sentence is completely segmented prior to distortion.</citsent>
<aftsection>
<nextsent>this simplifying assumption requires generation of hypotheses about the segmentation of the complete source sentence during decoding.
</nextsent>
<nextsent>the model also assumes that each translation hypothesis grows in predetermined order.
</nextsent>
<nextsent>e.g., koehns decoder (koehn 2004) builds each new hypothesis by adding phrases to it left-to-right (order is deterministic for the target hypothesis).
</nextsent>
<nextsent>our model doesnt require this order of operation ? it would support right-to-left or inwards-outwards hypothesis construction ? but it does require predictable order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3869">
<title id=" N06-1004.xml">segment choice models feature rich models for global distortion in statistical machine translation </title>
<section> disperp and distortion corpora.  </section>
<citcontext>
<prevsection>
<prevsent>metric for comparing scms offline on test corpus, and show how to construct this corpus.
</prevsent>
<prevsent>2.1 defining disperp.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the ultimate reason for choosing one scm over another will be the performance of an mt system containing it, as measured by metric like bleu (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>however, training and testing large-scale mt system for each new scm would be costly.
</nextsent>
<nextsent>also, the distortion components effect on the total score is muffled by other components (e.g., the phrase translation and target language models).
</nextsent>
<nextsent>can we devise quick standalone metric for comparing scms?
</nextsent>
<nextsent>there is an offline metric for statistical language models: perplexity (jelinek, 1990).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3871">
<title id=" N06-1004.xml">segment choice models feature rich models for global distortion in statistical machine translation </title>
<section> machine translation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>phrase probabilities were based on un smoothed relative frequencies.
</prevsent>
<prevsent>the model used by the decoder was log-linear combination of phrase translation model (only in the p(source|target) direction), trigram language model, word penalty (lexical weighting), an optional segmentation model (in the form of phrase penalty) and distortion model.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
weights on the components were assigned using the (och, 2003) <papid> P03-1021 </papid>method for max-bleu training on the development set.</citsent>
<aftsection>
<nextsent>the decoder uses dynamic programming beam-search, like the one in (koehn, 2004).
</nextsent>
<nextsent>future-cost estimates for all distortion models are assigned using the baseline penalty model.
</nextsent>
<nextsent>5.3 decoding results.
</nextsent>
<nextsent>30 29,40 29,60 29,80 30,00 30,20 30,40 30,60 30,80 31,00 31,20 no pp pp no pp pp dp dt bl eu sc re 1x beam 4x beam figure 9.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3878">
<title id=" N06-1004.xml">segment choice models feature rich models for global distortion in statistical machine translation </title>
<section> summary and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>however, currently there is major problem with dt training: the low proportion of chinese-english sentence pairs that can be fully segment-aligned and thus be used for dt training (about 27%).
</prevsent>
<prevsent>this may result in selection bias that impairs performance.
</prevsent>
</prevsection>
<citsent citstr=" W06-3118 ">
we plan to implement an alignment algorithm with smoothed phrase tables (johnson et al 2006) <papid> W06-3118 </papid>to achieve segment alignment on 100% of the training data.</citsent>
<aftsection>
<nextsent>decoding time with the dt-based distortion model is roughly proportional to the square of the number of tokens in the source sentence.
</nextsent>
<nextsent>thus, long sentences pose challenge, particularly during the weight optimization step.
</nextsent>
<nextsent>in experiments on other language pairs reported elsewhere (johnson et al 2006), <papid> W06-3118 </papid>we applied heuristic: dt training and decoding involved source sentences with 60 or fewer tokens, while longer sentences were handled with the distortion penalty.</nextsent>
<nextsent>a more principled ap 31 proach would be to divide long source sentences into chunks not exceeding 60 or so tokens, within each of which reordering is allowed, but which cannot themselves be reordered.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3882">
<title id=" N03-4006.xml">qcs a tool for querying clustering and summarizing documents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>qcs is software tool and development framework for efficient, organized, and streamlined ir from generic document sets.
</prevsent>
<prevsent>the system is designed to match queryto relevant documents, cluster the resulting subset of documents by topic, and produce single summary for eachtopic.
</prevsent>
</prevsection>
<citsent citstr=" H01-1056 ">
using qcs for ir, the amount of redundant information presented to user is reduced and the results are categorized by content.a survey of previous work using combination of clustering and summarization to improve ir can be found inradev et al (2001<papid> H01-1056 </papid>b).</citsent>
<aftsection>
<nextsent>of existing ir systems employing this combination, qcs most resembles the newsinessence system (radev et al, 2001<papid> H01-1056 </papid>a) in that both systems can produce multi-document summaries from document sets clustered by topic.</nextsent>
<nextsent>however, newsinessence is designed for ir from html-linked document sets and qcs has been designed for ir from generic document sets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3884">
<title id=" N04-1033.xml">improvements in phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentence ei1 = e1 . . .
</prevsent>
<prevsent>ei . . .
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
ei . among all possible target language sentences, we will choose the sentence with the highest probability: ei1 = argmax ei1 {pr(ei1|fj1 ) } (1) = argmax ei1 {pr(ei1) ? pr(fj1 |ei1) } (2)the decomposition into two knowledge sources in equation 2 is known as the source-channel approach to statistical machine translation (brown et al, 1990).<papid> J90-2002 </papid></citsent>
<aftsection>
<nextsent>it allows an independent modeling of target language model pr(ei1) and translation model pr(fj1 |ei1)1.
</nextsent>
<nextsent>the target language 1the notational convention will be as follows: we use the symbol pr(?)
</nextsent>
<nextsent>to denote general probability distributions with (nearly) no specific assumptions.
</nextsent>
<nextsent>in contrast, for model-based probability distributions, we use the generic symbol p(?).model describes the well-formedness of the target language sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3885">
<title id=" N04-1033.xml">improvements in phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the argmax operation denotes the search problem, i.e.the generation of the output sentence in the target language.
</prevsent>
<prevsent>we have to maximize over all possible target language sentences.an alternative to the classical source-channel approach is the direct modeling of the posterior probability pr(ei1|fj1 ).
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
using log-linear model (och and ney, 2002), <papid> P02-1038 </papid>we obtain: pr(ei1|fj1 ) = exp ( m?</citsent>
<aftsection>
<nextsent>m=1 mhm(ei1, fj1 ) ) ? z(fj1 )here, z(fj1 ) denotes the appropriate normalization constant.
</nextsent>
<nextsent>as decision rule, we obtain: ei1 = argmax ei1 { m?
</nextsent>
<nextsent>m=1 mhm(ei1, fj1 ) } this approach is generalization of the source-channel approach.
</nextsent>
<nextsent>it has the advantage that additional models or feature functions can be easily integrated into the overallsystem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3886">
<title id=" N04-1033.xml">improvements in phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it has the advantage that additional models or feature functions can be easily integrated into the overallsystem.
</prevsent>
<prevsent>the model scaling factors m1 are trained according to the maximum entropy principle, e.g. using the gis algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
alternatively, one can train them with respect to the final translation quality measured by some error criterion (och, 2003).<papid> P03-1021 </papid>the remaining part of this work is structured as follows: in the next section, we will describe the base line phrase-based translation model and the extraction of bilingual phrases.</citsent>
<aftsection>
<nextsent>then, we will describe refinements of the baseline model.
</nextsent>
<nextsent>in section 4, we will describe monotone search algorithm.
</nextsent>
<nextsent>its complexity is linear inthe sentence length.
</nextsent>
<nextsent>the next section contains the statistics of the corpora that were used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3889">
<title id=" N04-1033.xml">improvements in phrase based statistical machine translation </title>
<section> phrase-based translation.  </section>
<citcontext>
<prevsection>
<prevsent>this alignment matrix is the starting point for the phrase extraction.
</prevsent>
<prevsent>the following criterion defines the set of bilingual phrases bp of the sentence pair (fj1 ; ei1) and the alignment matrix ? ? that is used in the translation system.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
bp(fj1 , ei1, a) = {( j2j1 , ei2i1 ) : ?(j, i) ? : j1 ? ? j2 ? i1 ? ? i2 ??(j, i) ? : j1 ? ? j2 ? i1 ? ? i2 }this criterion is identical to the alignment template criterion described in (och et al, 1999).<papid> W99-0604 </papid></citsent>
<aftsection>
<nextsent>it means that two phrases are considered to be translations of each other, if the words are aligned only within the phrase pair and not to words outside.
</nextsent>
<nextsent>the phrases have to be contiguous.
</nextsent>
<nextsent>2.3 translation model.
</nextsent>
<nextsent>to use phrases in the translation model, we introduce the hidden variable s. this is segmentation of the sentence pair (fj1 ; ei1) into phrases (fk1 ; ek1 ).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3890">
<title id=" N04-1033.xml">improvements in phrase based statistical machine translation </title>
<section> translation results.  </section>
<citcontext>
<prevsection>
<prevsent>it is only used for the german-english verb mobil task.
</prevsent>
<prevsent>this is justan extremely brief description of these systems.
</prevsent>
</prevsection>
<citsent citstr=" J03-1005 ">
forde tails, see (tillmann and ney, 2003).<papid> J03-1005 </papid>phrase-based system (pb).</citsent>
<aftsection>
<nextsent>for the phrase-based system, we use the following feature functions: trigram language model, the phrase translation model and theword-based lexicon model.
</nextsent>
<nextsent>the latter two feature functions are used for both directions: p(f |e) and p(e|f).additionally, we use the word and phrase penalty feature functions.
</nextsent>
<nextsent>the model scaling factors are optimize don the development corpus with respect to mwer similar to (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>we use the downhill simplex algorithm from (press et al, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3901">
<title id=" N04-1033.xml">improvements in phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>some examples are the alignment template system in (och et al, 1999; <papid> W99-0604 </papid>och and ney, 2002) <papid> P02-1038 </papid>that we used for comparison.</prevsent>
<prevsent>in (zens et al, 2002), simple phrase-based approach is described that served as starting point for the system in this work.</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
(marcu and wong, 2002) <papid> W02-1018 </papid>presents joint probability model forphrase-based translation.</citsent>
<aftsection>
<nextsent>it does not use the word alignment for extracting the phrases, but directly generates phrase alignment.
</nextsent>
<nextsent>in (koehn et al, 2003), <papid> N03-1017 </papid>various aspects of phrase-based systems are compared, e.g. the phrase extraction method, the underlying word alignment model, or the maximum phrase length.</nextsent>
<nextsent>(tomas and casacuberta, 2003) describes linear interpolation of phrase-based and an alignment template-based approach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3902">
<title id=" N04-1033.xml">improvements in phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(marcu and wong, 2002) <papid> W02-1018 </papid>presents joint probability model forphrase-based translation.</prevsent>
<prevsent>it does not use the word alignment for extracting the phrases, but directly generates phrase alignment.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
in (koehn et al, 2003), <papid> N03-1017 </papid>various aspects of phrase-based systems are compared, e.g. the phrase extraction method, the underlying word alignment model, or the maximum phrase length.</citsent>
<aftsection>
<nextsent>(tomas and casacuberta, 2003) describes linear interpolation of phrase-based and an alignment template-based approach.
</nextsent>
<nextsent>we described phrase-based translation approach.
</nextsent>
<nextsent>the basic idea of this approach is to remember all bilingual phrases that have been seen in the word-aligned training corpus.
</nextsent>
<nextsent>as refinements of the baseline model, we described two simple heuristics: the word penalty feature and the phrase penalty feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3903">
<title id=" N04-1035.xml">whats in a translation rule </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we propose theory that gives formal semantics to word-level alignments defined over parallel corpora.
</prevsent>
<prevsent>we use our theory to introduce linear algorithm that can be used to derive from word-aligned, parallel corpora the minimal set of syntactically motivated transformation rules that explain human translation data.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
in very interesting study of syntax in statistical machine translation, fox (2002) <papid> W02-1039 </papid>looks at how well proposed translation models fit actual translation data.</citsent>
<aftsection>
<nextsent>one such model embodies restricted, linguistically-motivated notion of word re-ordering.
</nextsent>
<nextsent>given an english parse tree, children at any node may be reordered prior to translation.
</nextsent>
<nextsent>nodes are processed independently.
</nextsent>
<nextsent>previous to fox (2002), <papid> W02-1039 </papid>it had been observed that this model would prohibit certainre-orderings in certain language pairs (such as subjectvp(verb-object) into verb-subject-object), but fox carried out the first careful empirical study, showing that many other common translation patterns fall outside the scope of the child-reordering model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3907">
<title id=" N04-1035.xml">whats in a translation rule </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the first is to abandon syntax in statistical machine translation, on the grounds that syntactic models are poor fit for the data.
</prevsent>
<prevsent>on this view,adding syntax yields no improvement over robust phrase substitution models, and the only question is how much does syntax hurt performance.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
along this line, (koehn et al , 2003) <papid> N03-1017 </papid>present convincing evidence that restricting phrasal translation to syntactic constituents yields poor translation performance ? the ability to translate non constituent phrases (such as there are?, note that?, and according to?)</citsent>
<aftsection>
<nextsent>turns out to be critical and pervasive.
</nextsent>
<nextsent>another direction is to abandon conventional english syntax and move to more robust grammars that adapt to the parallel training corpus.
</nextsent>
<nextsent>one approach here is that ofwu (1997), <papid> J97-3002 </papid>in which word-movement is modeled by rotations at unlabeled, binary-branching nodes.</nextsent>
<nextsent>at each sentence pair, the parse adapts to explain the translation pat tern.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3908">
<title id=" N04-1035.xml">whats in a translation rule </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>turns out to be critical and pervasive.
</prevsent>
<prevsent>another direction is to abandon conventional english syntax and move to more robust grammars that adapt to the parallel training corpus.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
one approach here is that ofwu (1997), <papid> J97-3002 </papid>in which word-movement is modeled by rotations at unlabeled, binary-branching nodes.</citsent>
<aftsection>
<nextsent>at each sentence pair, the parse adapts to explain the translation pattern.
</nextsent>
<nextsent>if the same unambiguous english sentence were to appear twice in the corpus, with different chinese translations, then it could have different learned parses.
</nextsent>
<nextsent>a third direction is to maintain english syntax and investigate alternate transformation models.
</nextsent>
<nextsent>after all, many conventional translation systems are indeed based on syntactic transformations far more expressive than what has been proposed in syntax-based statistical mt. we take this approach in our paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3912">
<title id=" N04-1035.xml">whats in a translation rule </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of course, the broad statistical mt program is aimed at wider goal thanthe conventional rule-based program ? it seeks to understand and explain human translation data, and automatically learn from it.
</prevsent>
<prevsent>for this reason, we think it is important to learn from the model/data explain ability studies of fox (2002) <papid> W02-1039 </papid>and to extend her results.</prevsent>
</prevsection>
<citsent citstr=" P03-2041 ">
in addition to being motivated by rule-based systems, we also see advantages to english syntax within the statistical framework, suchas marrying syntax-based translation models with syntax based language models (charniak et al , 2003) and other potential benefits described by eisner (2003).<papid> P03-2041 </papid></citsent>
<aftsection>
<nextsent>our basic idea is to create transformation rules that condition on larger fragments of tree structure.
</nextsent>
<nextsent>it is certainly possible to build such rules by hand, and wehave done this to formally explain number of human translation examples.
</nextsent>
<nextsent>but our main interest is in collecting large set of such rules automatically through corpus analysis.
</nextsent>
<nextsent>the search for these rules is driven exactly by the problems raised by fox (2002) <papid> W02-1039 </papid>? cases of crossing and divergence motivate the algorithms to come up with better explanations of the data and better rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3920">
<title id=" N04-1035.xml">whats in a translation rule </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 data.
</prevsent>
<prevsent>we performed experiments with two corpora, the fbisenglish-chinese parallel text and the hansard french english corpus.we parsed the english sentences with state-of-the-art statistical parser (collins, 1999).
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
for the fbis corpus (representing eight million englishwords), we automatically generated word-alignments using giza++ (och and ney, 2003), <papid> J03-1002 </papid>which we trained on much larger dataset (150 million words).</citsent>
<aftsection>
<nextsent>cases other than one-to-one sentence mappings were eliminated.
</nextsent>
<nextsent>for the hansard corpus, we took the human annotation of word alignment described in (och and ney, 2000).<papid> P00-1056 </papid></nextsent>
<nextsent>the corpus contains two kinds of alignments: (sure) for unambiguous cases and (possible) for unclear cases, e.g. idiomatic expressions and missing function words(s ? ).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3921">
<title id=" N04-1035.xml">whats in a translation rule </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for the fbis corpus (representing eight million englishwords), we automatically generated word-alignments using giza++ (och and ney, 2003), <papid> J03-1002 </papid>which we trained on much larger dataset (150 million words).</prevsent>
<prevsent>cases other than one-to-one sentence mappings were eliminated.</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
for the hansard corpus, we took the human annotation of word alignment described in (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>the corpus contains two kinds of alignments: (sure) for unambiguous cases and (possible) for unclear cases, e.g. idiomatic expressions and missing function words(s ? ).
</nextsent>
<nextsent>in order to be able to make legitimate comparisons between the two language pairs, we also used giza++ to obtain machine-generated word alignments for hansard: we trained it with the 500 sentences and additional data representing 13.7 million english words(taken from the hansard and european parliament cor pora).
</nextsent>
<nextsent>3.3 results.
</nextsent>
<nextsent>from theoretical point of view, we have shown that our model can fully explain the transformation of any parse tree of the source language into string of the target language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3922">
<title id=" N04-1035.xml">whats in a translation rule </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for the former, we present results for the three alignments: alignments, alignments, and the alignments computed by giza++.
</prevsent>
<prevsent>each plotted value represents percentage ofparse trees in corpus that can be transformed into target sentence using transformation rules.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
the x-axis represents different restrictions on the size of these rules: if we use model that restrict rules to single expansion of non-terminal into sequence of symbols, we are in the scope of the child-reordering model of (yamada and knight, 2001; <papid> P01-1067 </papid>fox, 2002).<papid> W02-1039 </papid></citsent>
<aftsection>
<nextsent>we see that its explanatory power is quite poor, with only 19.4%, 14.3%, 16.5%, and12.1% (for the respective corpora).
</nextsent>
<nextsent>allowing more expansions logically expands the coverage of the model, until the point where it is total: transformation rules no larger than 17, 18, 23, and 43 (in number of rule expan sions) respectively provide enough coverage to explain the data at 100% for each of the four cases.
</nextsent>
<nextsent>it appears from the plot that the quality of alignments plays an important role.
</nextsent>
<nextsent>if we compare the three kinds of alignments available for the hansard corpus, we see that much more complex transformation rules are extracted from noisy giza++ alignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3929">
<title id=" N04-1035.xml">whats in a translation rule </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>npb dt jj nn the full report will md aux vb be coming in before the fall rb in dt nn npb pp vp-a advp vp le rapport complet sera dpos?
</prevsent>
<prevsent>de ici le automne pro chain input: sera vp-a output: vp vp-a will/md be/ aux vp-a x2 figure 12: crossing due to modal.
</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
the fundamental assumption underlying much recent work in statistical machine translation (yamada and knight, 2001; <papid> P01-1067 </papid>eisner, 2003; <papid> P03-2041 </papid>gildea, 2003) <papid> P03-1011 </papid>is that local transformations (primarily child-node re-orderings) of one-level parent-children substructures are an adequate model for parallel corpora.</citsent>
<aftsection>
<nextsent>our empirical results suggest that this may be too strong of an assumption.
</nextsent>
<nextsent>to explain the data in two parallel corpora, one english-french, and one english-chinese, we are often forced to learn rules involving much larger tree fragments.
</nextsent>
<nextsent>the theory, algorithms, and transformation rules we learn automatically from data have several interesting aspects.
</nextsent>
<nextsent>1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3930">
<title id=" N06-1010.xml">exploiting domain structure for named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ner is fundamental task in many natural language processing applications, such as question answering, machine translation, text mining, and information retrieval (srihari and li, 1999; huang and vogel, 2002).
</prevsent>
<prevsent>existing approaches toner are mostly based on supervised learning.
</prevsent>
</prevsection>
<citsent citstr=" W03-0425 ">
they can often achieve high accuracy provided that large annotated training set similar to the test data is available (borthwick, 1999; zhou and su, 2002; florian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003; <papid> W03-0428 </papid>finkel et al, 2005).</citsent>
<aftsection>
<nextsent>unfortunately, when the test data has some difference from the training data,these approaches tend to not perform well.
</nextsent>
<nextsent>for example, ciaramita and altun (2005) reported performance degradation of named entity recognizer trained on conll 2003 reuters corpus, where the f1 measure dropped from 0.908 when tested on similar reuters set to 0.643 when tested on wall street journal set.
</nextsent>
<nextsent>the degradation can be expected to be worse if the training data and the test data are more different.the performance degradation indicates that existing approaches adapt poorly to new domains.
</nextsent>
<nextsent>we believe one reason for this poor adaptability is that these approaches have not considered the fact that, depending on the genre or domain of the text, the entities to be recognized may have different mor 74 pho logical properties or occur in different contexts.indeed, since most existing learning-based ner approaches explore large feature space, without regularization, learned ne recognizer can easily overfit the training domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3931">
<title id=" N06-1010.xml">exploiting domain structure for named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ner is fundamental task in many natural language processing applications, such as question answering, machine translation, text mining, and information retrieval (srihari and li, 1999; huang and vogel, 2002).
</prevsent>
<prevsent>existing approaches toner are mostly based on supervised learning.
</prevsent>
</prevsection>
<citsent citstr=" W03-0428 ">
they can often achieve high accuracy provided that large annotated training set similar to the test data is available (borthwick, 1999; zhou and su, 2002; florian et al, 2003; <papid> W03-0425 </papid>klein et al, 2003; <papid> W03-0428 </papid>finkel et al, 2005).</citsent>
<aftsection>
<nextsent>unfortunately, when the test data has some difference from the training data,these approaches tend to not perform well.
</nextsent>
<nextsent>for example, ciaramita and altun (2005) reported performance degradation of named entity recognizer trained on conll 2003 reuters corpus, where the f1 measure dropped from 0.908 when tested on similar reuters set to 0.643 when tested on wall street journal set.
</nextsent>
<nextsent>the degradation can be expected to be worse if the training data and the test data are more different.the performance degradation indicates that existing approaches adapt poorly to new domains.
</nextsent>
<nextsent>we believe one reason for this poor adaptability is that these approaches have not considered the fact that, depending on the genre or domain of the text, the entities to be recognized may have different mor 74 pho logical properties or occur in different contexts.indeed, since most existing learning-based ner approaches explore large feature space, without regularization, learned ne recognizer can easily overfit the training domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3932">
<title id=" N06-1010.xml">exploiting domain structure for named entity recognition </title>
<section> logistic regression for ner.  </section>
<citcontext>
<prevsection>
<prevsent>indeed, when the features in maximum entropy model are defined as conjunctions of feature on observations only anda kron ecker delta of class label, which is common practice inner, the maximum entropy model is equivalent to logistic regression model (finkel et al, 2005).
</prevsent>
<prevsent>thus the logistic regression method we use for ner is essentially the same as the maximum entropy models used for ner in previous work.
</prevsent>
</prevsection>
<citsent citstr=" W03-0420 ">
to avoid over fitting, zero mean gaussian prior on the weights is usually used (chen and rosenfeld,1999; bender et al, 2003), <papid> W03-0420 </papid>and maximum posterior (map) estimator is used to maximize the posterior probability: ??</citsent>
<aftsection>
<nextsent>= arg max ? p(?)
</nextsent>
<nextsent>n? j=1 p(yj |xj,?), (4)where yj is the true class label for xj, is the number of training examples, and p(?)
</nextsent>
<nextsent>= |f |?
</nextsent>
<nextsent>i=1 1?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3934">
<title id=" N06-1010.xml">exploiting domain structure for named entity recognition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a possible explanation is that frequent features are in general less likely to be domain-specific, and therefore feature frequency can also be used as criterion to select generalizable features and to filter out domain-specific features, although it is still not as effective as the method we proposed.
</prevsent>
<prevsent>the ner problem has been extensively studied inthe nlp community.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
most existing work has focused on supervised learning approaches, employing models such as hmms (zhou and su, 2002), memms (bender et al, 2003; <papid> W03-0420 </papid>finkel et al, 2005), and crfs (mccallum and li, 2003).<papid> W03-0430 </papid></citsent>
<aftsection>
<nextsent>collins and singer (1999) <papid> W99-0613 </papid>proposed an unsupervised method for named entity classification based on the idea of cotraining.</nextsent>
<nextsent>ando and zhang (2005) <papid> P05-1001 </papid>proposed semi supervised learning method to exploit unlabeled data for building more robust ner systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3935">
<title id=" N06-1010.xml">exploiting domain structure for named entity recognition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the ner problem has been extensively studied inthe nlp community.
</prevsent>
<prevsent>most existing work has focused on supervised learning approaches, employing models such as hmms (zhou and su, 2002), memms (bender et al, 2003; <papid> W03-0420 </papid>finkel et al, 2005), and crfs (mccallum and li, 2003).<papid> W03-0430 </papid></prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
collins and singer (1999) <papid> W99-0613 </papid>proposed an unsupervised method for named entity classification based on the idea of cotraining.</citsent>
<aftsection>
<nextsent>ando and zhang (2005) <papid> P05-1001 </papid>proposed semi supervised learning method to exploit unlabeled data for building more robust ner systems.</nextsent>
<nextsent>in all these studies, the evaluation is conducted on unlabeled data similar to the labeled data.recently there have been some studies on adapting ner systems to new domains employing techniques such as active learning and semi-supervised learning (shen et al, 2004; <papid> P04-1075 </papid>mohit and hwa, 2005), <papid> P05-3015 </papid>80or incorporating external lexical knowledge (cia ramita and altun, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3936">
<title id=" N06-1010.xml">exploiting domain structure for named entity recognition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most existing work has focused on supervised learning approaches, employing models such as hmms (zhou and su, 2002), memms (bender et al, 2003; <papid> W03-0420 </papid>finkel et al, 2005), and crfs (mccallum and li, 2003).<papid> W03-0430 </papid></prevsent>
<prevsent>collins and singer (1999) <papid> W99-0613 </papid>proposed an unsupervised method for named entity classification based on the idea of cotraining.</prevsent>
</prevsection>
<citsent citstr=" P05-1001 ">
ando and zhang (2005) <papid> P05-1001 </papid>proposed semi supervised learning method to exploit unlabeled data for building more robust ner systems.</citsent>
<aftsection>
<nextsent>in all these studies, the evaluation is conducted on unlabeled data similar to the labeled data.recently there have been some studies on adapting ner systems to new domains employing techniques such as active learning and semi-supervised learning (shen et al, 2004; <papid> P04-1075 </papid>mohit and hwa, 2005), <papid> P05-3015 </papid>80or incorporating external lexical knowledge (cia ramita and altun, 2005).</nextsent>
<nextsent>however, there has not been any study on exploiting the domain structure contained in the training examples themselves to build generalizable ner systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3937">
<title id=" N06-1010.xml">exploiting domain structure for named entity recognition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>collins and singer (1999) <papid> W99-0613 </papid>proposed an unsupervised method for named entity classification based on the idea of cotraining.</prevsent>
<prevsent>ando and zhang (2005) <papid> P05-1001 </papid>proposed semi supervised learning method to exploit unlabeled data for building more robust ner systems.</prevsent>
</prevsection>
<citsent citstr=" P04-1075 ">
in all these studies, the evaluation is conducted on unlabeled data similar to the labeled data.recently there have been some studies on adapting ner systems to new domains employing techniques such as active learning and semi-supervised learning (shen et al, 2004; <papid> P04-1075 </papid>mohit and hwa, 2005), <papid> P05-3015 </papid>80or incorporating external lexical knowledge (cia ramita and altun, 2005).</citsent>
<aftsection>
<nextsent>however, there has not been any study on exploiting the domain structure contained in the training examples themselves to build generalizable ner systems.
</nextsent>
<nextsent>we focus on the domain structure in the training data to builda classifier that relies more on features generalizable across different domains to avoid over fitting the training domains.
</nextsent>
<nextsent>as our method is orthogonal tomost of the aforementioned work, they can be combined to further improve the performance.
</nextsent>
<nextsent>named entity recognition is an important problem that can help many text mining and natural language processing tasks such as information extraction and question answering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3938">
<title id=" N06-1010.xml">exploiting domain structure for named entity recognition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>collins and singer (1999) <papid> W99-0613 </papid>proposed an unsupervised method for named entity classification based on the idea of cotraining.</prevsent>
<prevsent>ando and zhang (2005) <papid> P05-1001 </papid>proposed semi supervised learning method to exploit unlabeled data for building more robust ner systems.</prevsent>
</prevsection>
<citsent citstr=" P05-3015 ">
in all these studies, the evaluation is conducted on unlabeled data similar to the labeled data.recently there have been some studies on adapting ner systems to new domains employing techniques such as active learning and semi-supervised learning (shen et al, 2004; <papid> P04-1075 </papid>mohit and hwa, 2005), <papid> P05-3015 </papid>80or incorporating external lexical knowledge (cia ramita and altun, 2005).</citsent>
<aftsection>
<nextsent>however, there has not been any study on exploiting the domain structure contained in the training examples themselves to build generalizable ner systems.
</nextsent>
<nextsent>we focus on the domain structure in the training data to builda classifier that relies more on features generalizable across different domains to avoid over fitting the training domains.
</nextsent>
<nextsent>as our method is orthogonal tomost of the aforementioned work, they can be combined to further improve the performance.
</nextsent>
<nextsent>named entity recognition is an important problem that can help many text mining and natural language processing tasks such as information extraction and question answering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3939">
<title id=" N03-1001.xml">effective utterance classification with unsupervised phonotactic models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a major bottleneck in building data-driven speech processing applications is the need to manually transcribe training utterances into words.
</prevsent>
<prevsent>the resulting corpus of transcribed word strings is then used to train application specific language models for speech recognition, and in some cases also to train the natural language components of the application.
</prevsent>
</prevsection>
<citsent citstr=" W01-1602 ">
some of these speech processing applications make use of utterance classification, for example when assigning call destination to naturally spoken user utterances (gorin et al, 1997; carpenter and chu carroll, 1998), or as an initial step in converting speech to actions in spoken interfaces (alshawi and douglas, 2001).<papid> W01-1602 </papid>in this paper we present an approach to utterance classification that avoids the manual effort of transcribing training utterances into word strings.</citsent>
<aftsection>
<nextsent>instead, only the desired utterance class needs to be associated with each sample utterance.
</nextsent>
<nextsent>the method combines automatic training of application-specific phonotactic models together with token sequence classifiers.
</nextsent>
<nextsent>the accuracy of this phone-string utterance classification method turns out tobe surprisingly close to what can be achieved by conventional methods involving word-trigram language models that require manual transcription.
</nextsent>
<nextsent>to quantify this,we present empirical accuracy results from three different call-routing applications comparing our method with conventional utterance classification using word-trigram recognition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3940">
<title id=" N06-1009.xml">role of local context in automatic deidentification of ungrammatical fragmented text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, this approach targets all phithat appear in medical discharge summaries.
</prevsent>
<prevsent>experiments reported in this paper show that context playsa more important role in deidentification than dictionaries, and that statistical representation of local context contributes more to deidentification than global context.
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
in the literature, named entities such as people,places, and organizations mentioned in news articles have been successfully identified by various approaches (bikel et al, 1999; mccallum et al, 2000; riloff and jones, 1996; collins and singer, 1999; <papid> W99-0613 </papid>hobbs et al, 1996).</citsent>
<aftsection>
<nextsent>most of these approaches are tailored to particular domain, e.g., understanding disaster news; they exploit both the characteristics of the entities they focus on and the contextual clues related to these entities.
</nextsent>
<nextsent>in the biomedical domain, ner has focused on identification of biological entities such as genes and proteins (collier et al, 2000; <papid> C00-1030 </papid>yu et al, 2002).</nextsent>
<nextsent>various statistical approaches, e.g., maximum entropy model (finkel et al, 2004), <papid> W04-1217 </papid>hmms and svms (guodong et al, 2005), have been used with various feature sets including surface and syntactic features, word formation patterns, morphological patterns, part-of-speech tags, head noun triggers, and coreferences.deidentification refers to the removal of identifying information from records.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3941">
<title id=" N06-1009.xml">role of local context in automatic deidentification of ungrammatical fragmented text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the literature, named entities such as people,places, and organizations mentioned in news articles have been successfully identified by various approaches (bikel et al, 1999; mccallum et al, 2000; riloff and jones, 1996; collins and singer, 1999; <papid> W99-0613 </papid>hobbs et al, 1996).</prevsent>
<prevsent>most of these approaches are tailored to particular domain, e.g., understanding disaster news; they exploit both the characteristics of the entities they focus on and the contextual clues related to these entities.</prevsent>
</prevsection>
<citsent citstr=" C00-1030 ">
in the biomedical domain, ner has focused on identification of biological entities such as genes and proteins (collier et al, 2000; <papid> C00-1030 </papid>yu et al, 2002).</citsent>
<aftsection>
<nextsent>various statistical approaches, e.g., maximum entropy model (finkel et al, 2004), <papid> W04-1217 </papid>hmms and svms (guodong et al, 2005), have been used with various feature sets including surface and syntactic features, word formation patterns, morphological patterns, part-of-speech tags, head noun triggers, and coreferences.deidentification refers to the removal of identifying information from records.</nextsent>
<nextsent>some approaches to deidentification have focused on particular categories of phi, e.g., taira et al focused on only patient names (2002), thomas et al focused on proper names including doctors?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3942">
<title id=" N06-1009.xml">role of local context in automatic deidentification of ungrammatical fragmented text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most of these approaches are tailored to particular domain, e.g., understanding disaster news; they exploit both the characteristics of the entities they focus on and the contextual clues related to these entities.
</prevsent>
<prevsent>in the biomedical domain, ner has focused on identification of biological entities such as genes and proteins (collier et al, 2000; <papid> C00-1030 </papid>yu et al, 2002).</prevsent>
</prevsection>
<citsent citstr=" W04-1217 ">
various statistical approaches, e.g., maximum entropy model (finkel et al, 2004), <papid> W04-1217 </papid>hmms and svms (guodong et al, 2005), have been used with various feature sets including surface and syntactic features, word formation patterns, morphological patterns, part-of-speech tags, head noun triggers, and coreferences.deidentification refers to the removal of identifying information from records.</citsent>
<aftsection>
<nextsent>some approaches to deidentification have focused on particular categories of phi, e.g., taira et al focused on only patient names (2002), thomas et al focused on proper names including doctors?
</nextsent>
<nextsent>names (2002).
</nextsent>
<nextsent>for full deidentification, i.e., removal of all phi, gupta et al used complex set of rules, dictionaries, pattern-matching algorithms, and unified medical language system?
</nextsent>
<nextsent>(2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3943">
<title id=" N06-1009.xml">role of local context in automatic deidentification of ungrammatical fragmented text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this system identified 99-100% of all phi inthe test corpus of patient records and letters to physicians (1996).
</prevsent>
<prevsent>we use variety of features to train support vector machine (svm) that can automatically extract local context cues and can recognize phi (even when some phi are ambiguous between phi andnon-phi, and even when phi do not appear in dic tionaries).
</prevsent>
</prevsection>
<citsent citstr=" C02-1151 ">
we compare this approach with three others: heuristic rule-based approach (douglass, 2005), the snow (sparse network of winnows) systems ner component (roth and yih, 2002), <papid> C02-1151 </papid>andidentifinder (bikel et al, 1999).</citsent>
<aftsection>
<nextsent>the heuristic rule based system relies heavily on dictionaries.
</nextsent>
<nextsent>snow and identifinder consider some representation of the local context of words; they also relyon information about global context.
</nextsent>
<nextsent>local context helps them recognize stereotypical names and name structures.global context helps these systems update the probability of observing particular entity type based on the other entity types contained in the sentence.
</nextsent>
<nextsent>we hypothesize that, given the mostly fragmented and ungrammatical nature of discharge summaries, local context will be more important for deidentificationthan global context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3946">
<title id=" N07-1055.xml">a unified local and global model for discourse coherence </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P05-1018 ">
we present model for discourse coherence which combines the local entity based approach of (barzilay and lapata, 2005) <papid> P05-1018 </papid>and the hmm-based content model of (barzilay and lee, 2004).<papid> N04-1015 </papid></citsent>
<aftsection>
<nextsent>unlike the mixture model of (soricut and marcu, 2006), <papid> P06-2103 </papid>we learn local and global features jointly, providing better theoretical explanation of how they are useful.</nextsent>
<nextsent>as the local component of our model we adapt (barzilay and lapata, 2005) <papid> P05-1018 </papid>by relaxing independence assumptions so that it is effective when estimated generatively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3949">
<title id=" N07-1055.xml">a unified local and global model for discourse coherence </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" N04-1015 ">
we present model for discourse coherence which combines the local entity based approach of (barzilay and lapata, 2005) <papid> P05-1018 </papid>and the hmm-based content model of (barzilay and lee, 2004).<papid> N04-1015 </papid></citsent>
<aftsection>
<nextsent>unlike the mixture model of (soricut and marcu, 2006), <papid> P06-2103 </papid>we learn local and global features jointly, providing better theoretical explanation of how they are useful.</nextsent>
<nextsent>as the local component of our model we adapt (barzilay and lapata, 2005) <papid> P05-1018 </papid>by relaxing independence assumptions so that it is effective when estimated generatively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3950">
<title id=" N07-1055.xml">a unified local and global model for discourse coherence </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we present model for discourse coherence which combines the local entity based approach of (barzilay and lapata, 2005) <papid> P05-1018 </papid>and the hmm-based content model of (barzilay and lee, 2004).<papid> N04-1015 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-2103 ">
unlike the mixture model of (soricut and marcu, 2006), <papid> P06-2103 </papid>we learn local and global features jointly, providing better theoretical explanation of how they are useful.</citsent>
<aftsection>
<nextsent>as the local component of our model we adapt (barzilay and lapata, 2005) <papid> P05-1018 </papid>by relaxing independence assumptions so that it is effective when estimated generatively.</nextsent>
<nextsent>our model performs the ordering task competitively with (soricut and marcu, 2006), <papid> P06-2103 </papid>and significantly better than either of the models it is based on.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3957">
<title id=" N07-1055.xml">a unified local and global model for discourse coherence </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the local component of our model we adapt (barzilay and lapata, 2005) <papid> P05-1018 </papid>by relaxing independence assumptions so that it is effective when estimated generatively.</prevsent>
<prevsent>our model performs the ordering task competitively with (soricut and marcu, 2006), <papid> P06-2103 </papid>and significantly better than either of the models it is based on.</prevsent>
</prevsection>
<citsent citstr=" J04-4001 ">
models of coherent discourse are central to several tasks in natural language processing: such models have been used in text generation (kibble and power, 2004) <papid> J04-4001 </papid>and evaluation of human-producedtext in educational applications (miltsakaki and kukich, 2004; higgins et al, 2004).<papid> N04-1024 </papid></citsent>
<aftsection>
<nextsent>moreover, an accurate model can reveal information about document structure, aiding in such tasks as supervised summarization (barzilay and lapata, 2005).<papid> P05-1018 </papid></nextsent>
<nextsent>models of coherence tend to fall into two classes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3958">
<title id=" N07-1055.xml">a unified local and global model for discourse coherence </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the local component of our model we adapt (barzilay and lapata, 2005) <papid> P05-1018 </papid>by relaxing independence assumptions so that it is effective when estimated generatively.</prevsent>
<prevsent>our model performs the ordering task competitively with (soricut and marcu, 2006), <papid> P06-2103 </papid>and significantly better than either of the models it is based on.</prevsent>
</prevsection>
<citsent citstr=" N04-1024 ">
models of coherent discourse are central to several tasks in natural language processing: such models have been used in text generation (kibble and power, 2004) <papid> J04-4001 </papid>and evaluation of human-producedtext in educational applications (miltsakaki and kukich, 2004; higgins et al, 2004).<papid> N04-1024 </papid></citsent>
<aftsection>
<nextsent>moreover, an accurate model can reveal information about document structure, aiding in such tasks as supervised summarization (barzilay and lapata, 2005).<papid> P05-1018 </papid></nextsent>
<nextsent>models of coherence tend to fall into two classes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3962">
<title id=" N07-1055.xml">a unified local and global model for discourse coherence </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, an accurate model can reveal information about document structure, aiding in such tasks as supervised summarization (barzilay and lapata, 2005).<papid> P05-1018 </papid></prevsent>
<prevsent>models of coherence tend to fall into two classes.</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
local models (lapata, 2003; <papid> P03-1069 </papid>barzilay and lapata,2005; <papid> P05-1018 </papid>foltz et al, 1998) attempt to capture the generalization that adjacent sentences often have similar content, and therefore tend to contain related words.</citsent>
<aftsection>
<nextsent>models of this type are good at finding sentences that belong near one another in the document.
</nextsent>
<nextsent>how ever, they have trouble finding the beginning or end of the document, or recovering from sudden shifts in topic (such as occur at paragraph boundaries).
</nextsent>
<nextsent>some local models also have trouble deciding which of pair of related sentences ought to come first.
</nextsent>
<nextsent>in contrast, the global hmm model of barzilay and lee (2004) <papid> N04-1015 </papid>tries to track the predictable change sin topic between sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3974">
<title id=" N07-1055.xml">a unified local and global model for discourse coherence </title>
<section> naive entity grids.  </section>
<citcontext>
<prevsection>
<prevsent>however, mixture models lack explanatory power; since each of the individual component models isknown to be flawed, it is difficult to say that the combination is theoretically more sound than the parts, even if it usually works better.
</prevsent>
<prevsent>moreover, since the model we describe uses strict subset of the features used in the component models of (soricut andmarcu, 2006), <papid> P06-2103 </papid>we suspect that adding it to the mixture would lead to still further improved results.</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
entity grids, first described in (lapata and barzilay,2005), are designed to capture some ideas of centering theory (grosz et al, 1995), <papid> J95-2003 </papid>namely that adjacent utterances in locally coherent discourses are likely to contain the same nouns, and that important nouns often appear in syntactically important roles such as subject or object.</citsent>
<aftsection>
<nextsent>an entity grid representsa document as matrix with column for each entity, and row for each sentence.
</nextsent>
<nextsent>the entry ri,j describes the syntactic role of entity in sentence i: these roles are subject (s), object (o), or some other role (x)1.
</nextsent>
<nextsent>in addition there is special marker (-)for nouns which do not appear at all in given sentence.
</nextsent>
<nextsent>each noun appears only once in given row of the grid; if noun appears multiple times, its grid symbol describes the most important of its syntactic roles: subject if possible, then object, or finallyother.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O3975">
<title id=" N07-1055.xml">a unified local and global model for discourse coherence </title>
<section> naive entity grids.  </section>
<citcontext>
<prevsection>
<prevsent>we condition events involving noun on the frequency of that noun.
</prevsent>
<prevsent>unfortunately, this way of representing salience makes our model slightly deficient, since the model conditions on particular noun occurring e.g. 2 times, but assigns nonzero probabilities to documents where it occurs 3 times.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
this is theo 1roles are determined heuristic ally using trees produced by the parser of (charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>following previous work, we slightly conflate thematic and syntactic roles, marking the subject of passive verb as o. 2the numeric token 1300?
</nextsent>
<nextsent>is removed in preprocessing, and nuevo laredo?
</nextsent>
<nextsent>is marked as proper?.
</nextsent>
<nextsent>0 [the commercial pilot]o , [sole occupant of [the airplane]x]x , was not injured . 1 [the airplane]o was owned and operated by [a private owner]x .2 [visual meteorological conditions]s prevailed for [the personal cross country flight for which [a vfr flight plan]o was filed]x . 3 [the flight]s originated at [nuevo laredo , mexico]x , at [approximately 1300]x . figure 1: section of document, with syntactic roles of noun phrases marked.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4002">
<title id=" N07-1055.xml">a unified local and global model for discourse coherence </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in the sentence ordering task, (lapata, 2003; <papid> P03-1069 </papid>barzilay and lee, 2004; <papid> N04-1015 </papid>barzilay and lapata, 2005; <papid> P05-1018 </papid>soricut and marcu, 2006), <papid> P06-2103 </papid>we view document as an unordered bag of sentences and try to find the ordering of the sentences which maximizes coherence according to our model.</prevsent>
<prevsent>this type of ordering process has applications in natural language generation and multi-document summarization.</prevsent>
</prevsection>
<citsent citstr=" P04-1051 ">
unfortunately,finding the optimal ordering according to probabilistic model with local features is np-completeand non-approximable (althaus et al, 2004).<papid> P04-1051 </papid></citsent>
<aftsection>
<nextsent>moreover, since our model is not markov ian, the relaxation used as heuristic for a?
</nextsent>
<nextsent>search by soricut and marcu (2006)<papid> P06-2103 </papid>is ineffective.</nextsent>
<nextsent>we therefore use simulated annealing to find high-probability ordering, starting from random permutation of the sen tences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4043">
<title id=" N07-1055.xml">a unified local and global model for discourse coherence </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, in longer and less formulaic corpora, the models, inference algorithms and even evaluation metrics used thus far may prove extremely difficult to scale up.
</prevsent>
<prevsent>domains with more natural writing styles will make lexical prediction much more difficult problem.
</prevsent>
</prevsection>
<citsent citstr=" C04-1129 ">
on the other hand, the wider variety of grammatical constructions used may motivate more complex syntactic features, for instance as proposed by (siddharthan et al, 2004) <papid> C04-1129 </papid>in sentence clustering.</citsent>
<aftsection>
<nextsent>finding optimal orderings is difficult task evenfor short documents, and will become exponentially more challenging in longer ones.
</nextsent>
<nextsent>for multi paragraph documents, it is probably impractical touse full-scale coherence models to find optimal or 442derings directly.
</nextsent>
<nextsent>a better approach may be coarse to-fine or hierarchical system which cuts up longer documents into more manageable chunks that can be ordered as unit.
</nextsent>
<nextsent>multi-paragraph documents also pose problem for the ? metric itself.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4044">
<title id=" N03-1023.xml">weakly supervised natural language learning without redundant views </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, we apply co-training, self-training,and em to one such task and find that both self training and fs-em, new variation of em that incorporates feature selection, outperform co training and are comparatively less sensitive to parameter changes.
</prevsent>
<prevsent>multi-view weakly supervised learning paradigms such as co-training (blum and mitchell, 1998) and co-em (nigam and ghani, 2000) learn classification task froma small set of labeled data and large pool of unlabeled data using separate, but redundant, views of the data (i.e. using disjoint feature subsets to represent thedata).
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
multi-view learning has been successfully applied to number of tasks in natural language processing (nlp), including text classification (blum and mitchell,1998; nigam and ghani, 2000), named entity classification (collins and singer, 1999), <papid> W99-0613 </papid>base noun phrase bracketing (pierce and cardie, 2001), <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001; <papid> N01-1023 </papid>steedman et al , 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>the theoretical performance guarantees of multi-view weakly supervised algorithms come with two fairly strong assumptions on the views.
</nextsent>
<nextsent>first, each view must be sufficient to learn the given concept.
</nextsent>
<nextsent>second, the views must be conditionally independent of each other given the class label.
</nextsent>
<nextsent>when both conditions are met, blum and mitchell prove that an initial weak learner can be boosted using unlabeled data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4045">
<title id=" N03-1023.xml">weakly supervised natural language learning without redundant views </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, we apply co-training, self-training,and em to one such task and find that both self training and fs-em, new variation of em that incorporates feature selection, outperform co training and are comparatively less sensitive to parameter changes.
</prevsent>
<prevsent>multi-view weakly supervised learning paradigms such as co-training (blum and mitchell, 1998) and co-em (nigam and ghani, 2000) learn classification task froma small set of labeled data and large pool of unlabeled data using separate, but redundant, views of the data (i.e. using disjoint feature subsets to represent thedata).
</prevsent>
</prevsection>
<citsent citstr=" W01-0501 ">
multi-view learning has been successfully applied to number of tasks in natural language processing (nlp), including text classification (blum and mitchell,1998; nigam and ghani, 2000), named entity classification (collins and singer, 1999), <papid> W99-0613 </papid>base noun phrase bracketing (pierce and cardie, 2001), <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001; <papid> N01-1023 </papid>steedman et al , 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>the theoretical performance guarantees of multi-view weakly supervised algorithms come with two fairly strong assumptions on the views.
</nextsent>
<nextsent>first, each view must be sufficient to learn the given concept.
</nextsent>
<nextsent>second, the views must be conditionally independent of each other given the class label.
</nextsent>
<nextsent>when both conditions are met, blum and mitchell prove that an initial weak learner can be boosted using unlabeled data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4046">
<title id=" N03-1023.xml">weakly supervised natural language learning without redundant views </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, we apply co-training, self-training,and em to one such task and find that both self training and fs-em, new variation of em that incorporates feature selection, outperform co training and are comparatively less sensitive to parameter changes.
</prevsent>
<prevsent>multi-view weakly supervised learning paradigms such as co-training (blum and mitchell, 1998) and co-em (nigam and ghani, 2000) learn classification task froma small set of labeled data and large pool of unlabeled data using separate, but redundant, views of the data (i.e. using disjoint feature subsets to represent thedata).
</prevsent>
</prevsection>
<citsent citstr=" N01-1023 ">
multi-view learning has been successfully applied to number of tasks in natural language processing (nlp), including text classification (blum and mitchell,1998; nigam and ghani, 2000), named entity classification (collins and singer, 1999), <papid> W99-0613 </papid>base noun phrase bracketing (pierce and cardie, 2001), <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001; <papid> N01-1023 </papid>steedman et al , 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>the theoretical performance guarantees of multi-view weakly supervised algorithms come with two fairly strong assumptions on the views.
</nextsent>
<nextsent>first, each view must be sufficient to learn the given concept.
</nextsent>
<nextsent>second, the views must be conditionally independent of each other given the class label.
</nextsent>
<nextsent>when both conditions are met, blum and mitchell prove that an initial weak learner can be boosted using unlabeled data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4047">
<title id=" N03-1023.xml">weakly supervised natural language learning without redundant views </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in particular, we apply co-training, self-training,and em to one such task and find that both self training and fs-em, new variation of em that incorporates feature selection, outperform co training and are comparatively less sensitive to parameter changes.
</prevsent>
<prevsent>multi-view weakly supervised learning paradigms such as co-training (blum and mitchell, 1998) and co-em (nigam and ghani, 2000) learn classification task froma small set of labeled data and large pool of unlabeled data using separate, but redundant, views of the data (i.e. using disjoint feature subsets to represent thedata).
</prevsent>
</prevsection>
<citsent citstr=" E03-1008 ">
multi-view learning has been successfully applied to number of tasks in natural language processing (nlp), including text classification (blum and mitchell,1998; nigam and ghani, 2000), named entity classification (collins and singer, 1999), <papid> W99-0613 </papid>base noun phrase bracketing (pierce and cardie, 2001), <papid> W01-0501 </papid>and statistical parsing (sarkar, 2001; <papid> N01-1023 </papid>steedman et al , 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>the theoretical performance guarantees of multi-view weakly supervised algorithms come with two fairly strong assumptions on the views.
</nextsent>
<nextsent>first, each view must be sufficient to learn the given concept.
</nextsent>
<nextsent>second, the views must be conditionally independent of each other given the class label.
</nextsent>
<nextsent>when both conditions are met, blum and mitchell prove that an initial weak learner can be boosted using unlabeled data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4048">
<title id=" N03-1023.xml">weakly supervised natural language learning without redundant views </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>em, on the other hand, fails to boost performance, andwe attribute this phenomenon to the presence of redundant features in the underlying generative model.
</prevsent>
<prevsent>consequently, we propose wrapper-based feature selection method (john et al , 1994) for em that results in performance improvements comparable to that observed with self-training.
</prevsent>
</prevsection>
<citsent citstr=" P02-1046 ">
overall, our results suggest that single-view1abney (2002) <papid> P02-1046 </papid>argues that the conditional independence assumption is remarkably strong and is rarely satisfied in real datasets, showing that weaker independence assumption suffices.</citsent>
<aftsection>
<nextsent>2mueller et al  (2002) explore heuristic method for view factor ization for the related problem of anaphora resolution, but find that co-training shows no performance improvements for any type of german anaphor except pronouns over baseline classifier trained on small set of labeled data.
</nextsent>
<nextsent>edmonton, may-june 2003 main papers , pp.
</nextsent>
<nextsent>94-101 proceedings of hlt-naacl 2003weakly supervised learning algorithms are viable alternative to multi-view algorithms for datasets where natural feature split into separate, redundant views is not available.
</nextsent>
<nextsent>the remainder of the paper is organized as follows.section 2 presents an overview of the three weakly supervised learning algorithms mentioned previously.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4049">
<title id=" N03-1023.xml">weakly supervised natural language learning without redundant views </title>
<section> weakly supervised algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 self-training.
</prevsent>
<prevsent>self-training is single-view weakly supervised algorithm that has appeared in various forms in the literature.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
the version of the algorithm that we consider here is variation of the one presented in banko and brill (2001).<papid> P01-1005 </papid></citsent>
<aftsection>
<nextsent>initially, we use bagging (breiman, 1996) to train acommittee of classifiers using the labeled data.
</nextsent>
<nextsent>specifically, each classifier is trained on bootstrap sample created by randomly sampling instances with replacement from the labeled data until the size of the bootstrap sample is equal to that of the labeled data.
</nextsent>
<nextsent>then each member of the committee (or bag) predicts the labels of all unlabeled data.
</nextsent>
<nextsent>the algorithm selects an unlabeled instance for adding to the labeled data if and only if all bags agree upon its label.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4050">
<title id=" N03-1023.xml">weakly supervised natural language learning without redundant views </title>
<section> the machine learning framework for.  </section>
<citcontext>
<prevsection>
<prevsent>coreference resolution noun phrase coreference resolution refers to the problem of determining which noun phrases (nps) refer to eachreal-world entity mentioned in document.
</prevsent>
<prevsent>in this section, we give an overview of the coreference resolution system to which the weakly supervised algorithms described in the previous section are applied.
</prevsent>
</prevsection>
<citsent citstr=" W02-1008 ">
the framework underlying the system is standard combination of classification and clustering employed by supervised learning approaches (e.g. ng and cardie(2002); <papid> W02-1008 </papid>soon et al  (2001)).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>specifically, coreference resolution is recast as classification task, in which pairof nps is classified as co-referring or not based on constraints that are learned from an annotated corpus.
</nextsent>
<nextsent>training instances are generated by pairing each np with each of its preceding nps in the document.
</nextsent>
<nextsent>the classification associated with training instance is one of corefer ent or not co referent depending on whether the nps feature type feature description lexical pro str if both nps are pronominal and are the same string; else i. pn str if both nps are proper names and are the same string; else i. soon str nonpro if both nps are non-pronominal and the string of np matches that of np ; else i. grammatical pronoun 1 if np is pronoun; else n. pronoun 2 if np is pronoun; else n. demonstrative 2 if np starts with demonstrative such as this,?
</nextsent>
<nextsent>that,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4051">
<title id=" N03-1023.xml">weakly supervised natural language learning without redundant views </title>
<section> the machine learning framework for.  </section>
<citcontext>
<prevsection>
<prevsent>coreference resolution noun phrase coreference resolution refers to the problem of determining which noun phrases (nps) refer to eachreal-world entity mentioned in document.
</prevsent>
<prevsent>in this section, we give an overview of the coreference resolution system to which the weakly supervised algorithms described in the previous section are applied.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
the framework underlying the system is standard combination of classification and clustering employed by supervised learning approaches (e.g. ng and cardie(2002); <papid> W02-1008 </papid>soon et al  (2001)).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>specifically, coreference resolution is recast as classification task, in which pairof nps is classified as co-referring or not based on constraints that are learned from an annotated corpus.
</nextsent>
<nextsent>training instances are generated by pairing each np with each of its preceding nps in the document.
</nextsent>
<nextsent>the classification associated with training instance is one of corefer ent or not co referent depending on whether the nps feature type feature description lexical pro str if both nps are pronominal and are the same string; else i. pn str if both nps are proper names and are the same string; else i. soon str nonpro if both nps are non-pronominal and the string of np matches that of np ; else i. grammatical pronoun 1 if np is pronoun; else n. pronoun 2 if np is pronoun; else n. demonstrative 2 if np starts with demonstrative such as this,?
</nextsent>
<nextsent>that,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4054">
<title id=" N03-1023.xml">weakly supervised natural language learning without redundant views </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we ran em to convergence and kept track of its test set performance at every iteration.
</prevsent>
<prevsent>4.2 results and discussion.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
results are shown in table 3, where performance is reported in terms of recall, precision, and f-measure using the model-theoretic muc scoring program (vilain et al , 1995).<papid> M95-1005 </papid></citsent>
<aftsection>
<nextsent>the baseline coreference system, which is trained only on the labeled document using naive bayes, achieve san f-measure of 55.5 and 43.8 on the muc-6 and muc 7 datasets, respectively.
</nextsent>
<nextsent>the results shown in row 2 of table 3 correspond to the best f-measure scores achieved by co-training for the two datasets based on co-training runs that comprise all of the parameter combinations described in the previous subsection.
</nextsent>
<nextsent>the parameter settings with which the best experiments muc-6 muc-7 best parameter setting p best parameter setting p baseline ? 58.3 52.9 55.5 ? 52.8 37.4 43.8 co-training v=v5/v6,g=50,p=5000,i=220 47.5 81.9 60.1 v=v5/v6,g=100,p=500,i=260 40.6 77.6 53.3 self-training b=7 54.1 78.6 64.1 b=9 54.6 62.6 58.3 em i=20 64.8 51.8 57.6 i=2 54.1 40.7 46.4 fs-em ? 64.2 66.6 65.4 ? 53.3 70.3 60.5 table 3: comparative results of co-training, self-training, em, and fs-em (to be described in section 5).
</nextsent>
<nextsent>recall,precision, and f-measure are provided.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4059">
<title id=" N04-4023.xml">feature selection for trainable multilingual broadcast news segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we identify several features that are important for all seven sources analyzed, and we discuss the contributions of other features that are important for subset of the seven sources.
</prevsent>
<prevsent>indexing and retrieving stories within large collection of video requires automatic detection of story boundaries, and video story segmentation is an essential step toward providing the means for finding, linking, summarizing, and visualizing related parts of multimedia collections.
</prevsent>
</prevsection>
<citsent citstr=" H01-1029 ">
in many cases, previous story segmentation research has focused on single stream analysis techniques, utilizing only one of the information sources present in news broadcasts: natural language, audio, image, and video (see, for example, (furht et al, 1995),(fiscus and doddington, 2002),(greiff et al, 2001), (<papid> H01-1029 </papid>oconnor et al., 2001)).</citsent>
<aftsection>
<nextsent>some segmentation research has included multimodal approaches that were capable of combining features from multiple information sources (boykin and merlino, 1999),(hauptmann and witbrock, 1998) . while this work was significant improvement over.
</nextsent>
<nextsent>single-stream approaches, they were rarely applied to non-english sources without closed captioning.
</nextsent>
<nextsent>previous work on story segmentation has identified many features useful for finding story boundaries, but feature selection is often model-dependent and does not account for the differences between broadcast sources.
</nextsent>
<nextsent>specific features useful for video story segmentation vary widely from one source to the next, and the degree to which each feature is useful also varies across source sand even from one broadcast to the next within single source.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4060">
<title id=" N06-1006.xml">learning to recognize features of valid textual ent ailments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we report results on data from the 2005 pascal rte challenge which surpass previously reported results for alignment-based systems.
</prevsent>
<prevsent>during the last five years there has been surge in work which aims to provide robust textual inference in arbitrary domains about which the system has no expertise.
</prevsent>
</prevsection>
<citsent citstr=" N03-1022 ">
the best-known such work has occurred within the field of question answering (pasca and harabagiu, 2001; moldovan et al, 2003); <papid> N03-1022 </papid>more recently, such work has continued with greater focusin addressing the pascal recognizing textual entailment (rte) challenge (dagan et al, 2005) and within the u.s. government aquaint program.</citsent>
<aftsection>
<nextsent>substantive progress on this task is key to many text and natural language applications.
</nextsent>
<nextsent>if one could tell that protestors chanted slogans opposing free trade agreement was match for people demonstrating against free trade, then one could offer form of semantic search not available with current keyword based search.
</nextsent>
<nextsent>even greater benefits would flow to richer and more semantically complex nlp tasks.because full, accurate, open-domain natural language understanding lies far beyond current capabilities, nearly all efforts in this area have sought to extract the maximum mileage from quite limited semantic representations.
</nextsent>
<nextsent>some have used simple measures of semantic overlap, but the more interesting work has largely converged on graph alignment approach, operating on semantic graphs derived from syntactic dependency parses, and using locally-decomposable alignment score as proxy for strength of entailment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4061">
<title id=" N06-1006.xml">learning to recognize features of valid textual ent ailments </title>
<section> approaching robust semantics.  </section>
<citcontext>
<prevsection>
<prevsent>mainly in the sophistication of the matching stage.the simplest approach is to base the entailment prediction on the degree of semantic overlap between the text and hypothesis using models based on bagsof words, bags of n-grams, tf-idf scores, or some thing similar (jijkoun and de rijke, 2005).
</prevsent>
<prevsent>such models have serious limitations: semantic overlap is typically symmetric relation, whereas entailment is clearly not, and, because overlap models do not account for syntactic or semantic structure, they are easily fooled by examples like id 2081.
</prevsent>
</prevsection>
<citsent citstr=" H05-1049 ">
a more structured approach is to formulate the entailment prediction as graph matching problem (haghighi et al, 2005; <papid> H05-1049 </papid>de salvo braz et al, 2005).in this formulation, sentences are represented as normalized syntactic dependency graphs (like the one shown in figure 1) and entailment is approximated with an alignment between the graph representing the hypothesis and portion of the correspondinggraph(s) representing the text.</citsent>
<aftsection>
<nextsent>each possible alignment of the graphs has an associated score, and the score of the best alignment is used as an approximation to the strength of the entailment: better aligned hypothesis is assumed to be more likely tobe entailed.
</nextsent>
<nextsent>to enable incremental search, alignment scores are usually factored as combination of local terms, corresponding to the nodes and edges of the two graphs.
</nextsent>
<nextsent>unfortunately, even with factored scores the problem of finding the best alignment of two graphs is np-complete, so exact computation isintractable.
</nextsent>
<nextsent>authors have proposed variety of approximate search techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4064">
<title id=" N06-1006.xml">learning to recognize features of valid textual ent ailments </title>
<section> approaching robust semantics.  </section>
<citcontext>
<prevsection>
<prevsent>authors have proposed variety of approximate search techniques.
</prevsent>
<prevsent>haghighi et al (2005) <papid> H05-1049 </papid>divide the search into two steps: in the first step they consider node scores only, which relaxes the problem to weighted bipartite graph matching that can be solved in polynomial time, and in the second step they add the edges scores and hill climb the alignment via an approximate local search.</prevsent>
</prevsection>
<citsent citstr=" P88-1012 ">
a third approach, exemplified by moldovan et al(2003) <papid> N03-1022 </papid>and raina et al (2005), is to translate dependency parses into neo-davidsonian-style quasi logical forms, and to perform weighted abductive theorem proving in the tradition of (hobbs et al, 1988).<papid> P88-1012 </papid></citsent>
<aftsection>
<nextsent>unless supplemented with knowledge base, this approach is actually isomorphic to the graph matching approach.
</nextsent>
<nextsent>for example, the graph in figure 1 might generate the quasi-lf rose(e1), nsubj(e1, x1), sales(x1), nn(x1, x2), mitsubishi(x2), dobj(e1, x3), percent(x3), num(x3, x4), 46(x4).
</nextsent>
<nextsent>there is term corresponding to each node and arc,and the resolution steps at the core of weighted abduction theorem proving consider matching an individual node of the hypothesis (e.g. rose(e1)) with something from the text (e.g. fell(e1)), just as inthe graph-matching approach.
</nextsent>
<nextsent>the two models become distinct when there is good supply of additional linguistic and world knowledge axiom sas in moldovan et al (2003) <papid> N03-1022 </papid>but not raina et al (2005).then the theorem prover may generate intermediate forms in the proof, but, nevertheless, individual terms are resolved locally without reference to global context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4066">
<title id=" N06-1006.xml">learning to recognize features of valid textual ent ailments </title>
<section> approaching robust semantics.  </section>
<citcontext>
<prevsection>
<prevsent>there is term corresponding to each node and arc,and the resolution steps at the core of weighted abduction theorem proving consider matching an individual node of the hypothesis (e.g. rose(e1)) with something from the text (e.g. fell(e1)), just as inthe graph-matching approach.
</prevsent>
<prevsent>the two models become distinct when there is good supply of additional linguistic and world knowledge axiom sas in moldovan et al (2003) <papid> N03-1022 </papid>but not raina et al (2005).then the theorem prover may generate intermediate forms in the proof, but, nevertheless, individual terms are resolved locally without reference to global context.</prevsent>
</prevsection>
<citsent citstr=" H05-1079 ">
finally, few efforts (akhmatova, 2005; fowler et al, 2005; bos and markert, 2005) <papid> H05-1079 </papid>have tried to 42 translate sentences into formulas of first-order logic, in order to test logical entailment with theorem prover.</citsent>
<aftsection>
<nextsent>while in principle this approach does not suffer from the limitations we describe below, in practice it has not borne much fruit.
</nextsent>
<nextsent>because few problem sentences can be accurately translated to logical form, and because logical entailment is strict standard, recall tends to be poor.
</nextsent>
<nextsent>the simple graph matching formulation of the problem belies three important issues.
</nextsent>
<nextsent>first, the above systems assume form of upward monotonic ity: if good match is found with part of the text, other material in the text is assumed not to affect the validity of the match.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4067">
<title id=" N06-1006.xml">learning to recognize features of valid textual ent ailments </title>
<section> approaching robust semantics.  </section>
<citcontext>
<prevsection>
<prevsent>the way to show that one graph element does not follow from another is to make the cost of aligning them high.
</prevsent>
<prevsent>however, since we are embedded in search for the lowest cost alignment, this will just cause the system to choose an alternate alignment rather than recognizing non-entailment.
</prevsent>
</prevsection>
<citsent citstr=" H05-1047 ">
in id 152, we would like the hypothesis to align with the first part of the text, to 1this is the same problem labeled and addressed as context in tatu and moldovan (2005).<papid> H05-1047 </papid></citsent>
<aftsection>
<nextsent>be able to prove that civilians are not members oflaw enforcement agencies and conclude that the hypothesis does not follow from the text.
</nextsent>
<nextsent>but graph matching system will to try to get non-entailment by making the matching cost between civilians and members of law enforcement agencies be very high.
</nextsent>
<nextsent>however, the likely result of that is that the final part of the hypothesis will align with were civilians atthe end of the text, assuming that we allow an alignment with loose?
</nextsent>
<nextsent>arc correspondence.2 under this candidate alignment, the lexical alignments are perfect, and the only imperfect alignment is the subject arc of were is mismatched in the two.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4068">
<title id=" N06-1006.xml">learning to recognize features of valid textual ent ailments </title>
<section> approaching robust semantics.  </section>
<citcontext>
<prevsection>
<prevsent>arc correspondence.2 under this candidate alignment, the lexical alignments are perfect, and the only imperfect alignment is the subject arc of were is mismatched in the two.
</prevsent>
<prevsent>a robust inference guesser will still likely conclude that there is entailment.we propose that all three problems can be resolved in two-stage architecture, where the alignment phase is followed by separate phase of entailment determination.
</prevsent>
</prevsection>
<citsent citstr=" W05-1201 ">
although developed independently, the same division between alignment and classification has also been proposed by marsi and krahmer (2005), <papid> W05-1201 </papid>whose textual system is developed and evaluated on parallel translations into dutch.</citsent>
<aftsection>
<nextsent>their classification phase features an output spaceof five semantic relations, and performs well at distinguishing entailing sentence pairs.
</nextsent>
<nextsent>finding aligned content can be done by any searchprocedure.
</nextsent>
<nextsent>compared to previous work, we emphasize structural alignment, and seek to ignore issues like polarity and quantity, which can be left to subsequent entailment decision.
</nextsent>
<nextsent>for example, the scoring function is designed to encourage antonym matches, and ignore the negation of verb predicates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4069">
<title id=" N06-1006.xml">learning to recognize features of valid textual ent ailments </title>
<section> system.  </section>
<citcontext>
<prevsection>
<prevsent>this representation contains much of the infor-.
</prevsent>
<prevsent>mation about words and relations between them, and is relatively easy to compute from syntactic parse.however many semantic phenomena are not represented properly; particularly egregious is the inability to represent quantification and modality.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we parse input sentences to phrase structure trees using the stanford parser (klein and manning, 2003), <papid> P03-1054 </papid>statistical syntactic parser trained on thepenn treebank.</citsent>
<aftsection>
<nextsent>to ensure correct parsing, we pre process the sentences to collapse named entities intonew dedicated tokens.
</nextsent>
<nextsent>named entities are identified by crf-based ner system, similar to that described in (mccallum and li, 2003).<papid> W03-0430 </papid></nextsent>
<nextsent>after parsing, contiguous collocations which appear in wordnet (fellbaum, 1998) are identified and grouped.we convert the phrase structure trees to typed dependency graphs using set of deterministic hand coded rules (de marneffe et al, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4070">
<title id=" N06-1006.xml">learning to recognize features of valid textual ent ailments </title>
<section> system.  </section>
<citcontext>
<prevsection>
<prevsent>we parse input sentences to phrase structure trees using the stanford parser (klein and manning, 2003), <papid> P03-1054 </papid>statistical syntactic parser trained on thepenn treebank.</prevsent>
<prevsent>to ensure correct parsing, we pre process the sentences to collapse named entities intonew dedicated tokens.</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
named entities are identified by crf-based ner system, similar to that described in (mccallum and li, 2003).<papid> W03-0430 </papid></citsent>
<aftsection>
<nextsent>after parsing, contiguous collocations which appear in wordnet (fellbaum, 1998) are identified and grouped.we convert the phrase structure trees to typed dependency graphs using set of deterministic hand coded rules (de marneffe et al, 2006).
</nextsent>
<nextsent>in these rules,heads of constituents are first identified using modified version of the collins head rules that favor semantic heads (such as lexical verbs rather than aux iliaries), and dependents of heads are typed usingtregex patterns (levy and andrew, 2006), an extension of the tgrep pattern language.
</nextsent>
<nextsent>the nodes in the final graph are then annotated with their associated word, part-of-speech (given by the parser), lemma(given by finite-state transducer described by min nen et al (2001)) and named-entity tag.
</nextsent>
<nextsent>3.2 alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4073">
<title id=" N03-2025.xml">bootstrapping for named entity tagging using concept based seeds </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>recognizing and classifying proper names is fundamental task for information extraction.
</prevsent>
<prevsent>three types of proper names are defined in the message understanding conference (muc) named entity (ne) standards, namely, person (per), organization (org), and location (loc).
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
[muc-7 1998] there is considerable research on ne tagging using supervised machine learning [e.g. bikel et al  1997; <papid> A97-1029 </papid>borthwick 1998].</citsent>
<aftsection>
<nextsent>to overcome the knowledge bottleneck of supervised learning, unsupervised machine learning has been applied to ne.
</nextsent>
<nextsent>[cucchiarelli &amp; velardi 2001] <papid> J01-1005 </papid>discussed boosting the performance of an existing ne tagger by unsupervised learning based on parsing structures.</nextsent>
<nextsent>[cucerzan &amp; yarowsky 1999], [<papid> W99-0612 </papid>collins &amp; singer 1999] <papid> W99-0613 </papid>and [kim et al  2002] <papid> C02-1088 </papid>presented various techniques using co-training schemes for ne extraction seeded by small list of proper names or hand-crafted ne rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4074">
<title id=" N03-2025.xml">bootstrapping for named entity tagging using concept based seeds </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>[muc-7 1998] there is considerable research on ne tagging using supervised machine learning [e.g. bikel et al  1997; <papid> A97-1029 </papid>borthwick 1998].</prevsent>
<prevsent>to overcome the knowledge bottleneck of supervised learning, unsupervised machine learning has been applied to ne.</prevsent>
</prevsection>
<citsent citstr=" J01-1005 ">
[cucchiarelli &amp; velardi 2001] <papid> J01-1005 </papid>discussed boosting the performance of an existing ne tagger by unsupervised learning based on parsing structures.</citsent>
<aftsection>
<nextsent>[cucerzan &amp; yarowsky 1999], [<papid> W99-0612 </papid>collins &amp; singer 1999] <papid> W99-0613 </papid>and [kim et al  2002] <papid> C02-1088 </papid>presented various techniques using co-training schemes for ne extraction seeded by small list of proper names or hand-crafted ne rules.</nextsent>
<nextsent>ne tagging has two tasks: (i) ne chunking; (ii) ne classification.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4075">
<title id=" N03-2025.xml">bootstrapping for named entity tagging using concept based seeds </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>to overcome the knowledge bottleneck of supervised learning, unsupervised machine learning has been applied to ne.
</prevsent>
<prevsent>[cucchiarelli &amp; velardi 2001] <papid> J01-1005 </papid>discussed boosting the performance of an existing ne tagger by unsupervised learning based on parsing structures.</prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
[cucerzan &amp; yarowsky 1999], [<papid> W99-0612 </papid>collins &amp; singer 1999] <papid> W99-0613 </papid>and [kim et al  2002] <papid> C02-1088 </papid>presented various techniques using co-training schemes for ne extraction seeded by small list of proper names or hand-crafted ne rules.</citsent>
<aftsection>
<nextsent>ne tagging has two tasks: (i) ne chunking; (ii) ne classification.
</nextsent>
<nextsent>parsing supported unsupervised ne learning systems including ours only need to focus on ne classification, assuming the ne chunks have been constructed by the parser.
</nextsent>
<nextsent>this paper presents new bootstrapping approach using successive learning and concept based seeds.
</nextsent>
<nextsent>the successive learning is as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4076">
<title id=" N03-2025.xml">bootstrapping for named entity tagging using concept based seeds </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>to overcome the knowledge bottleneck of supervised learning, unsupervised machine learning has been applied to ne.
</prevsent>
<prevsent>[cucchiarelli &amp; velardi 2001] <papid> J01-1005 </papid>discussed boosting the performance of an existing ne tagger by unsupervised learning based on parsing structures.</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
[cucerzan &amp; yarowsky 1999], [<papid> W99-0612 </papid>collins &amp; singer 1999] <papid> W99-0613 </papid>and [kim et al  2002] <papid> C02-1088 </papid>presented various techniques using co-training schemes for ne extraction seeded by small list of proper names or hand-crafted ne rules.</citsent>
<aftsection>
<nextsent>ne tagging has two tasks: (i) ne chunking; (ii) ne classification.
</nextsent>
<nextsent>parsing supported unsupervised ne learning systems including ours only need to focus on ne classification, assuming the ne chunks have been constructed by the parser.
</nextsent>
<nextsent>this paper presents new bootstrapping approach using successive learning and concept based seeds.
</nextsent>
<nextsent>the successive learning is as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4077">
<title id=" N03-2025.xml">bootstrapping for named entity tagging using concept based seeds </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>to overcome the knowledge bottleneck of supervised learning, unsupervised machine learning has been applied to ne.
</prevsent>
<prevsent>[cucchiarelli &amp; velardi 2001] <papid> J01-1005 </papid>discussed boosting the performance of an existing ne tagger by unsupervised learning based on parsing structures.</prevsent>
</prevsection>
<citsent citstr=" C02-1088 ">
[cucerzan &amp; yarowsky 1999], [<papid> W99-0612 </papid>collins &amp; singer 1999] <papid> W99-0613 </papid>and [kim et al  2002] <papid> C02-1088 </papid>presented various techniques using co-training schemes for ne extraction seeded by small list of proper names or hand-crafted ne rules.</citsent>
<aftsection>
<nextsent>ne tagging has two tasks: (i) ne chunking; (ii) ne classification.
</nextsent>
<nextsent>parsing supported unsupervised ne learning systems including ours only need to focus on ne classification, assuming the ne chunks have been constructed by the parser.
</nextsent>
<nextsent>this paper presents new bootstrapping approach using successive learning and concept based seeds.
</nextsent>
<nextsent>the successive learning is as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4078">
<title id=" N03-2025.xml">bootstrapping for named entity tagging using concept based seeds </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>first, we retrieve all the named entity candidates associated with at least one of the five parsing relationships from the repository.
</prevsent>
<prevsent>after applying the decision list to the retrieved 1,607,709 ne candidates, 33,104 per names, 16,426 loc names, and 11,908 org names are tagged.
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
in order to improve the bootstrapping performance, we use the heuristic one tag per domain for multiword ne in addition to the one sense per discourse principle [gale et al 1992].<papid> H92-1045 </papid></citsent>
<aftsection>
<nextsent>these heuristics are found to be very helpful in both increasing positive instances (i.e. tag propagation) and decreasing the spurious instances (i.e. tag elimination).
</nextsent>
<nextsent>the tag propagation/elimination scheme is adopted from [yarowsky 1995].<papid> P95-1026 </papid></nextsent>
<nextsent>after this step, total of 367,441 proper names are classified, including 134,722 per names, 186,488 loc names, and 46,231 org names.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4079">
<title id=" N03-2025.xml">bootstrapping for named entity tagging using concept based seeds </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>in order to improve the bootstrapping performance, we use the heuristic one tag per domain for multiword ne in addition to the one sense per discourse principle [gale et al 1992].<papid> H92-1045 </papid></prevsent>
<prevsent>these heuristics are found to be very helpful in both increasing positive instances (i.e. tag propagation) and decreasing the spurious instances (i.e. tag elimination).</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
the tag propagation/elimination scheme is adopted from [yarowsky 1995].<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>after this step, total of 367,441 proper names are classified, including 134,722 per names, 186,488 loc names, and 46,231 org names.
</nextsent>
<nextsent>the classified proper name instances lead to the construction of an automatically tagged training corpus, consisting of the ne instances and their two (left and right) neighboring words within the same sentence.
</nextsent>
<nextsent>in the final stage, bi-gram hmm is trained based on the above training corpus.
</nextsent>
<nextsent>the hmm training process follows [bikel 1997].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4080">
<title id=" N06-2051.xml">bridging the inflection morphology gap for arabic statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this inflection gap causes an abundance of surface word forms 1 in the source language compared with relatively few forms in the target language.
</prevsent>
<prevsent>this mismatch aggravates several issues1we use the term surface form to refer to series of characters separated by whitespacefound in natural language processing: more unknown words forms in unseen data, more words occurring only once, more distinct words and lower token-to-type ratios (mean number of occurrences over all distinct words) in the source language than in the target language.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
lexical relationships under the standard ibm models (brown et al, 1993) <papid> J93-2003 </papid>do not account formany-to-many mappings, and phrase extraction relies heavily on the accuracy of the ibm word-toword alignment.</citsent>
<aftsection>
<nextsent>in this work, we propose an approach to bridge the inflectional gap that addresses the issues described above through series of preprocessing steps based on the buckwalter arabic morphological analyzer (bama) tool (buckwalter, 2004).
</nextsent>
<nextsent>while (lee et al, 2003) <papid> P03-1051 </papid>develop accurate segmentation models of arabic surface word forms using manually segmented data, we rely instead onthe translated context in the target language, leveraging the manually constructed lexical gloss from bama to select the appropriate segmented sense for each arabic source word.</nextsent>
<nextsent>our technique, applied as preprocessing to the source corpus, splits and normalizes surface words based on the target sentence context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4081">
<title id=" N06-2051.xml">bridging the inflection morphology gap for arabic statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical relationships under the standard ibm models (brown et al, 1993) <papid> J93-2003 </papid>do not account formany-to-many mappings, and phrase extraction relies heavily on the accuracy of the ibm word-toword alignment.</prevsent>
<prevsent>in this work, we propose an approach to bridge the inflectional gap that addresses the issues described above through series of preprocessing steps based on the buckwalter arabic morphological analyzer (bama) tool (buckwalter, 2004).</prevsent>
</prevsection>
<citsent citstr=" P03-1051 ">
while (lee et al, 2003) <papid> P03-1051 </papid>develop accurate segmentation models of arabic surface word forms using manually segmented data, we rely instead onthe translated context in the target language, leveraging the manually constructed lexical gloss from bama to select the appropriate segmented sense for each arabic source word.</citsent>
<aftsection>
<nextsent>our technique, applied as preprocessing to the source corpus, splits and normalizes surface words based on the target sentence context.
</nextsent>
<nextsent>in contrast to (popovic and ney, 2004) and (nieen and ney, 2004), we do not modify the ibm models, and we leave reordering effects to the decoder.
</nextsent>
<nextsent>statistically significant improvements (zhang and vogel, 2004) in bleu and nist translation score over lightly stemmed baseline are reported on the available andwell known btec iwslt05 arabic-english corpus (eck and hori, 2005).
</nextsent>
<nextsent>201
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4082">
<title id=" N06-2051.xml">bridging the inflection morphology gap for arabic statistical machine translation </title>
<section> arabic morphology in recent work.  </section>
<citcontext>
<prevsection>
<prevsent>word fragments that represent this missing information are misleading in the translation process unless explicitly aligned to the null word on the target side.
</prevsent>
<prevsent>in this step we explicitly remove fragments that correspond to lexical information that is not represented in english.
</prevsent>
</prevsection>
<citsent citstr=" N04-4015 ">
while(lee, 2004) <papid> N04-4015 </papid>builds part of speech models to recognize such elements, we use the fact that their corresponding english translations in the bama lexicon are empty.</citsent>
<aftsection>
<nextsent>examples of such fragments are case and gender markers.
</nextsent>
<nextsent>as an example of corr match removal, we present the arabic sentence ? h?*a la ya zal gayor naziyf ?
</nextsent>
<nextsent>(after bama only) which becomes h?*a la ya zal gayor naziyf?
</nextsent>
<nextsent>after the corr match stage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4083">
<title id=" N06-2051.xml">bridging the inflection morphology gap for arabic statistical machine translation </title>
<section> experimental framework.  </section>
<citcontext>
<prevsection>
<prevsent>translation experiments were conducted using the(vogel et al, 2003) system with reordering and future cost estimation.
</prevsent>
<prevsent>we trained translation parameters for 10 scores (language model, word and phrase count, and 6 translation model scores from (vogel, 2005) ) with minimum error rate training on the development set.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we optimized separately for both the nist (doddington, 2002) and the bleu metrics (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>table 1 and 2 shows the results of each stage of inflectional splitting on the bleu and nist metrics.
</nextsent>
<nextsent>basic orthographic normalization serves as baseline (merging all alif, tar marbuta, ee forms to the base form).
</nextsent>
<nextsent>the test set nist scores show steady improvements of up to 5 percent relative, as more sophisticated splitting techniques are used, ie bama+context+corrmatch.
</nextsent>
<nextsent>these improvements are statistically significant overthe baseline in both metrics as measured by the techniques in (zhang and vogel, 2004).our nist results for all the final stages of inflectional splitting would place us above the top nist scores from the iswlt evaluation on the supplied test set.2 on both devset/test05 and the randomly split data, we see more dramatic improvements in the nist scores than in bleu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4084">
<title id=" N03-1035.xml">toward a task based gold standard for evaluation of np chunks and technical terms </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W95-0107 ">
we propose gold standard for evaluating two types of information extraction output -- noun phrase (np) chunks (abney 1991; ramshaw and marcus 1995) <papid> W95-0107 </papid>and technical terms (justeson and katz 1995; daille 2000; jacquemin 2002).</citsent>
<aftsection>
<nextsent>the gold standard is built around the notion that since different semantic and syntactic variants of terms are arguably correct, fully satisfactory assessment of the quality of the output must include task-based evaluation.
</nextsent>
<nextsent>we conducted an experiment that assessed subjects?
</nextsent>
<nextsent>choice of index terms in an information access task.
</nextsent>
<nextsent>subjects showed significant preference for index terms that are longer, as measured by number of words, and more complex, as measured by number of prepositions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4086">
<title id=" N03-1035.xml">toward a task based gold standard for evaluation of np chunks and technical terms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>but when the satisfactory output can take many different forms, as in summarization and generation, evaluation by precision and recall is not sufficient.
</prevsent>
<prevsent>in these cases, the challenge for system designers and users is to effectively distinguish between systems that provide generally satisfactory output and systems that do not.
</prevsent>
</prevsection>
<citsent citstr=" A94-1006 ">
np chunks (abney 1991; ramshaw and marcus 1995; <papid> W95-0107 </papid>evans and zhai 1996; frantzi and ananiadou 1996) and technical terms (dagan and church 1994; <papid> A94-1006 </papid>justeson and katz 1995; daille 1996; jacquemin 2001; bourigault et al 2002) fall into this difficult-to assess category.</citsent>
<aftsection>
<nextsent>nps are recursive structures.
</nextsent>
<nextsent>for the maximal np large number of recent newspaper articles on biomedical science and clinical practice, full fledged parser would legitimately identify (at least) seven nps in addition to the maximal one: large number; recent newspaper articles; large number of recent newspaper articles; biomedical science; clinical practice; biomedical science and clinical prac tice; and recent newspaper articles on biomedical science and clinical practice.
</nextsent>
<nextsent>to evaluate the performance of parser, np chunks can usefully be evaluated by gold standard; many systems (e.g., ramshaw and marcus 1995 <papid> W95-0107 </papid>and cardie and pierce 1988) use the penn treebank for this type of evalua tion.</nextsent>
<nextsent>but for most applications, output that lists maximal np and each of its component nps is bulky and redundant.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4088">
<title id=" N03-1035.xml">toward a task based gold standard for evaluation of np chunks and technical terms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experimental studies have repeatedly shown that information seekers use many different terms to describe the same concept and few of these terms are used frequently (furnas et al 1987; saracevic et al 1988; bates et al 1998).
</prevsent>
<prevsent>when information seekers are unable to figure out the term used to describe concept in relevant document, electronic indexes are required for successful information access.
</prevsent>
</prevsection>
<citsent citstr=" W98-0610 ">
np chunks and technical terms have been proposed for use in this task (boguraev and kennedy 1997; wacholder 1998).<papid> W98-0610 </papid></citsent>
<aftsection>
<nextsent>np chunks and technical terms have also been used in phrase browsing and phrase hierarchies (jones and staveley 1999; nevill manning et al 1999; witten et al 1999; lawrie and croft 2000) and summarization (e.g., mckeown et al 1999; oakes and paice 2001).
</nextsent>
<nextsent>in fact, the distinction between task-based evaluation of system and preci sion/recall evaluation of the quality of system output is similar to the extrinsic/intrinsic evaluation of summarization (gallier and jones 1993).
</nextsent>
<nextsent>in order to focus on the subjects?
</nextsent>
<nextsent>choice of index terms rather than on other aspects of the information access process, we asked subject to find answers to questions in college level textbook.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4092">
<title id=" N03-1035.xml">toward a task based gold standard for evaluation of np chunks and technical terms </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>2 jim snow prepared the index under the supervision of.
</prevsent>
<prevsent>scils professor james d. anderson.
</prevsent>
</prevsection>
<citsent citstr=" A00-1042 ">
hum hs tt total total number of terms 673 7980 1788 9992 percentage of total number of terms 6.73% 79.86% 17.89% * table 2: number of terms in index by method of identification wacholder et al (2000) <papid> A00-1042 </papid>showed that when experimental subjects were asked to assess the usefulness of terms for an information access task without actually using the terms for information access showed that the terms identified by the technical term algorithm, which are considerably fewer than the terms identified by head sorting, were overall of higher quality than the terms identified by the head sorting method.</citsent>
<aftsection>
<nextsent>however, the fact that subjects assigned high rank to many of the terms identified by head sorting suggested that the technical term algorithm was failing to pick up many potentially useful index terms.
</nextsent>
<nextsent>in preparation for the experiment, all index terms were merged into single list and duplicates were removed, resulting in list of nearly 10,000 index terms.
</nextsent>
<nextsent>2.4 tracking results.
</nextsent>
<nextsent>in the experiment, we logged the terms that subjects searched for (i.e., entered in search box) and selected.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4093">
<title id=" N03-1035.xml">toward a task based gold standard for evaluation of np chunks and technical terms </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>in part, this is because it is much harder to determine in context which single words actually qualify as terms.
</prevsent>
<prevsent>but dictionaries of technical terminology have many one-word terms.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
simplex or complex nps (e.g., church 1988; <papid> A88-1019 </papid>hindle and rooth 1991; wacholder 1998) <papid> W98-0610 </papid>identify simplex or base nps ? nps which do not have any component nps -- at least in part because this bypasses the need to solve the quite difficult attachment problem, i.e., to determine which simpler nps should be combined to output more complex np.</citsent>
<aftsection>
<nextsent>but if people find complex nps more useful than simpler ones, it is important to focus on improvement of techniques to reliably identify more complex terms.
</nextsent>
<nextsent>semantic and syntactic terms variants.
</nextsent>
<nextsent>daille et al (1996), jacquemin (2001) and others address the question of how to identify semantic (synonymous) and syntactic variants.
</nextsent>
<nextsent>but independent of the question of how to recognize variants is the question of which variants are to be preferred for different kinds of uses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4095">
<title id=" N03-1018.xml">a generative probabilistic ocr model for nlp applications </title>
<section> the model.  </section>
<citcontext>
<prevsection>
<prevsent>we model each sub sequence  as being transformed into an ocr sub sequence   , so     %
</prevsent>
<prevsent>  and we assume each  is transformed independently, allowing         #
</prevsent>
</prevsection>
<citsent citstr=" P00-1037 ">
lk  on        any character-level string error model can be used to define       ; for example brill and moore (2000) <papid> P00-1037 </papid>or kolak and resnik (2002).</citsent>
<aftsection>
<nextsent>this is also logical place to make use of confidence values if provided by the ocr system.
</nextsent>
<nextsent>we assume that # is always deleted (modelingmerge errors), and can never be inserted.
</nextsent>
<nextsent>boundary markers at segment boundaries are re-inserted when segments are put together to create   , since they will be part of the ocr output (not as #, but most likely as spaces).
</nextsent>
<nextsent>for our example   , possible result for this step is:   = tlmsis?,   = an?,  jh = cx?,  *i = amp1e.?; % qp d1: d1:f  . the final generated string would there-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4096">
<title id=" N03-1018.xml">a generative probabilistic ocr model for nlp applications </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we used the problem of unsupervised creation of translation lexicons from automatically generated word alignment of parallel text as representative nlp task to evaluate the impact of ocr correction on usability of ocr text.
</prevsent>
<prevsent>we assume that the english side of the parallel text is online and its foreign language translation is generated using an ocr system.8 our goal is to apply our ocr error correcting procedures prior to alignment so there sulting translation lexicon has the same quality as if it had been derived from error-free text.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
we trained an ibm style translation model (brown et al., 1990) <papid> J90-2002 </papid>using giza++ (och and ney, 2000) <papid> P00-1056 </papid>on the 500test lines used in our experiments paired with corresponding english lines from an online bible.</citsent>
<aftsection>
<nextsent>word level alignments generated by giza++ were used to extract cross language word co-occurrence frequencies, and candidate 8alternatively, the english side can be obtained via ocr and corrected.
</nextsent>
<nextsent>translation lexicon entries were scored according to the log likelihood ratio (dunning, 1993) (<papid> J93-1003 </papid>cf.</nextsent>
<nextsent>(resnik and melamed, 1997)).<papid> A97-1050 </papid>we generated three such lexicons by pairing the english with the french ground truth, uncorrected ocr out put, and its corrected version.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4097">
<title id=" N03-1018.xml">a generative probabilistic ocr model for nlp applications </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we used the problem of unsupervised creation of translation lexicons from automatically generated word alignment of parallel text as representative nlp task to evaluate the impact of ocr correction on usability of ocr text.
</prevsent>
<prevsent>we assume that the english side of the parallel text is online and its foreign language translation is generated using an ocr system.8 our goal is to apply our ocr error correcting procedures prior to alignment so there sulting translation lexicon has the same quality as if it had been derived from error-free text.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we trained an ibm style translation model (brown et al., 1990) <papid> J90-2002 </papid>using giza++ (och and ney, 2000) <papid> P00-1056 </papid>on the 500test lines used in our experiments paired with corresponding english lines from an online bible.</citsent>
<aftsection>
<nextsent>word level alignments generated by giza++ were used to extract cross language word co-occurrence frequencies, and candidate 8alternatively, the english side can be obtained via ocr and corrected.
</nextsent>
<nextsent>translation lexicon entries were scored according to the log likelihood ratio (dunning, 1993) (<papid> J93-1003 </papid>cf.</nextsent>
<nextsent>(resnik and melamed, 1997)).<papid> A97-1050 </papid>we generated three such lexicons by pairing the english with the french ground truth, uncorrected ocr out put, and its corrected version.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4098">
<title id=" N03-1018.xml">a generative probabilistic ocr model for nlp applications </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we trained an ibm style translation model (brown et al., 1990) <papid> J90-2002 </papid>using giza++ (och and ney, 2000) <papid> P00-1056 </papid>on the 500test lines used in our experiments paired with corresponding english lines from an online bible.</prevsent>
<prevsent>word level alignments generated by giza++ were used to extract cross language word co-occurrence frequencies, and candidate 8alternatively, the english side can be obtained via ocr and corrected.</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
translation lexicon entries were scored according to the log likelihood ratio (dunning, 1993) (<papid> J93-1003 </papid>cf.</citsent>
<aftsection>
<nextsent>(resnik and melamed, 1997)).<papid> A97-1050 </papid>we generated three such lexicons by pairing the english with the french ground truth, uncorrected ocr out put, and its corrected version.</nextsent>
<nextsent>all text was tokenized, lower cased, and single character tokens and tokens with no letters were removed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4099">
<title id=" N03-1018.xml">a generative probabilistic ocr model for nlp applications </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>word level alignments generated by giza++ were used to extract cross language word co-occurrence frequencies, and candidate 8alternatively, the english side can be obtained via ocr and corrected.
</prevsent>
<prevsent>translation lexicon entries were scored according to the log likelihood ratio (dunning, 1993) (<papid> J93-1003 </papid>cf.</prevsent>
</prevsection>
<citsent citstr=" A97-1050 ">
(resnik and melamed, 1997)).<papid> A97-1050 </papid>we generated three such lexicons by pairing the english with the french ground truth, uncorrected ocr out put, and its corrected version.</citsent>
<aftsection>
<nextsent>all text was tokenized, lower cased, and single character tokens and tokens with no letters were removed.
</nextsent>
<nextsent>this method of generating translation lexicon works well; as table 3 illustrates with the top twenty entries from the lexicon generated using ground truth french.
</nextsent>
<nextsent>and et for car of de if si god dieu ye vous we nous you vous christ christ the le not pas law loi but mais jesus jesus lord seigneur as comme the la that qui is est in dans table 3: translation lexicon entries extracted using ground truth french figure 3 gives the precision-recall curves for the translation lexicons generated from ocr using the english ocr system on french hardcopy input with and without correction, using the top 1000 entries of the lexicon generated from ground truth as the target set.
</nextsent>
<nextsent>since we are interested in the effect of ocr, independent of the performance of the lexicon generation method, the lexiconauto-generated from the ground truth provides reason able target set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4100">
<title id=" N03-1018.xml">a generative probabilistic ocr model for nlp applications </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we also evaluated the impact of error correction in aresource-acquisition scenario involving translation lexicon acquisition from ocr output.
</prevsent>
<prevsent>the results show that our post-ocr correction framework significantly improves performance.
</prevsent>
</prevsection>
<citsent citstr=" H01-1033 ">
we anticipate applying the technique in order to retarget cross-language ir technology ? the results of resnik et al (2001) <papid> H01-1033 </papid>demonstrate that even noisy extensions to dictionary-based translation lexicons, acquired from parallel text, can have positive impact on cross language information retrieval perfor mance.we are currently working on improving the correction performance of the system, and extending our error model implementation to include character context and allow for character merge/split errors.</citsent>
<aftsection>
<nextsent>we also intend to relax the requirement of having word list, so that the model handles valid word errors.we are also exploring the possibility of tuning statistical machine translation model to be used with our model to exploit parallel text.
</nextsent>
<nextsent>if translation of the ocrd text is available, translation model can be used to provide us with candidate-word list that contains most of the correct words, and very few irrelevant words.finally, we plan to challenge our model with other languages, starting with arabic, turkish, and chinese.
</nextsent>
<nextsent>arabic and turkish have phonetic alphabets, but also pose the problem of rich morphology.
</nextsent>
<nextsent>chinese will require more work due to the size of its character set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4101">
<title id=" N07-1013.xml">improving diversity in ranking using absorbing random walks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many natural language processing tasks involve ranking set of items.
</prevsent>
<prevsent>sometimes we want the top items to be not only good individually but also diverse collectively.
</prevsent>
</prevsection>
<citsent citstr=" W00-0405 ">
for example, extractive text summarization generates summary by selecting few good sentences from one or more articles on thesame topic (goldstein et al, 2000).<papid> W00-0405 </papid></citsent>
<aftsection>
<nextsent>this can be formulated as ranking all the sentences, and taking thetop ones.
</nextsent>
<nextsent>a good sentence is one that is representative, i.e., similar to many other sentences, so that it likely conveys the central meaning of the articles.on the other hand, we do not want multiple near identical sentences.
</nextsent>
<nextsent>the top sentences should be diverse.
</nextsent>
<nextsent>as another example, in information retrieval onnews events, an article is often published by multiple newspapers with only minor changes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4102">
<title id=" N07-1013.xml">improving diversity in ranking using absorbing random walks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>if we want list of people that represent various groups, it is important to consider both activity and diversity, and not to fill the list with people from the same active groups.
</prevsent>
<prevsent>given the importance of diversity in ranking,there has been significant research in this area.
</prevsent>
</prevsection>
<citsent citstr=" W00-1009 ">
perhaps the most well-known method is maximum marginal relevance (mmr) (carbonell and goldstein, 1998), as well as cross-sentence informational subsumption (radev, 2000), <papid> W00-1009 </papid>mixture models (zhang et al, 2002), sub topic diversity (zhai et al, 2003), diversity penalty (zhang et al, 2005), and others.</citsent>
<aftsection>
<nextsent>the basic idea is to penalize redundancy by lowering an items rank if it is similar to items already ranked.however, these methods often treat centrality ranking and diversity ranking separately, sometimes with heuristic procedures.
</nextsent>
<nextsent>97 we propose grasshopper (graph random-walk with absorbing states that hops among peaks for ranking), novel ranking algorithm that encourages diversity.
</nextsent>
<nextsent>grasshopper is an alternative to mmr and variants, with principled mathematical model and strong empirical performance.
</nextsent>
<nextsent>it ranks set of items such that: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4103">
<title id=" N07-1013.xml">improving diversity in ranking using absorbing random walks </title>
<section> the grasshopper algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>for example, in text summarization one can create an undirected, fully connected graph on the sentences.
</prevsent>
<prevsent>theedge between sentences i, has weight wij , their co sine similarity.
</prevsent>
</prevsection>
<citsent citstr=" W04-3252 ">
in social network analysis one can create directed graph with wij being the number of phone calls made to j. the graph should be constructed carefully to reflect domain knowledge.for examples, see (erkan and radev, 2004; mihalcea and tarau, 2004; <papid> W04-3252 </papid>pang and lee, 2004).<papid> P04-1035 </papid>the user can optionally supply an arbitrary ranking on the items as prior knowledge.</citsent>
<aftsection>
<nextsent>in this case grasshopper can be viewed as re-ranking method.
</nextsent>
<nextsent>for example, in information retrieval, the prior ranking can be the ranking by relevancescores.
</nextsent>
<nextsent>in text summarization, it can be the position of sentences in the original article.
</nextsent>
<nextsent>(thereis evidence that the first few sentences in an article are likely good summaries.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4104">
<title id=" N07-1013.xml">improving diversity in ranking using absorbing random walks </title>
<section> the grasshopper algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>for example, in text summarization one can create an undirected, fully connected graph on the sentences.
</prevsent>
<prevsent>theedge between sentences i, has weight wij , their co sine similarity.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
in social network analysis one can create directed graph with wij being the number of phone calls made to j. the graph should be constructed carefully to reflect domain knowledge.for examples, see (erkan and radev, 2004; mihalcea and tarau, 2004; <papid> W04-3252 </papid>pang and lee, 2004).<papid> P04-1035 </papid>the user can optionally supply an arbitrary ranking on the items as prior knowledge.</citsent>
<aftsection>
<nextsent>in this case grasshopper can be viewed as re-ranking method.
</nextsent>
<nextsent>for example, in information retrieval, the prior ranking can be the ranking by relevancescores.
</nextsent>
<nextsent>in text summarization, it can be the position of sentences in the original article.
</nextsent>
<nextsent>(thereis evidence that the first few sentences in an article are likely good summaries.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4107">
<title id=" N07-1013.xml">improving diversity in ranking using absorbing random walks </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>isi.edu/cyl/rouge/).
</prevsent>
<prevsent>this is recall-basedmeasure of text co-occurrence between machine generated summary and model summaries manually created by judges.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
rouge metrics exist based on bigram, trigram, and 4-gram overlap, but rouge-1(based on unigram matching) has been found to correlate best with human judgments (lin and hovy, 2003).<papid> N03-1020 </papid></citsent>
<aftsection>
<nextsent>101 using the duc 2003 training data, we tuned ? and ? on small grid (?
</nextsent>
<nextsent>{0.125, 0.25, 0.5, 1.0};?
</nextsent>
<nextsent>{0.0, 0.0625, 0.125, 0.25, 0.5, 0.95}).
</nextsent>
<nextsent>specifically, for each of the 30 duc 2003 task 2 document sets, we computed rouge-1 scores comparing our generated summary to 4 model summaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4108">
<title id=" N03-1011.xml">learning semantic constraints for the automatic discovery of part whole relations </title>
<section> learning semantic constraints.  </section>
<citcontext>
<prevsection>
<prevsent>another 100,000 sentences were extracted from the la times articles of trec 9.
</prevsent>
<prevsent>a corpus a? was thus created from the selected sentences of each text collection.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
each sentence in this corpus was then parsed using the syntactic parser developed by charniak (charniak, 2000).<papid> A00-2018 </papid>focusing only on the sentences containing relations indicated by the three patterns considered, we manually annotated all the noun phrases in the 53,944 relationships matched by these patterns with their corresponding senses in wordnet (with the exception of those from semcor).</citsent>
<aftsection>
<nextsent>6,973 of these relationships were part-whole relations, while 46,971 were not meronymic relations.we used for training corpus of 34,609 positive examples (6,973 pairs of nps in part-whole relation extracted from the corpus a? and 27,636 extracted from word netas selected pairs) and 46,971 negative examples (the non part-whole relations extracted from corpus a?).
</nextsent>
<nextsent>3.4 learning algorithm.
</nextsent>
<nextsent>input: positive and negative meronymic examples of pairs of concepts.
</nextsent>
<nextsent>output: semantic constraints on concepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4109">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using these ideas together, the resulting tagger gives 97.24% accuracy on the penn treebank wsj, an error reduction of 4.4% on the best previous single automatically learned tagging result.
</prevsent>
<prevsent>almost all approaches to sequence problems such as partof-speech tagging take unidirectional approach to conditioning inference along the sequence.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
regardless of whether one is using hmms, maximum entropy conditional sequence models, or other techniques like decision trees, most systems work in one direction through the sequence (normally left to right, but occasionally rightto left, e.g., church (1988)).<papid> A88-1019 </papid></citsent>
<aftsection>
<nextsent>there are few exceptions, such as brills transformation-based learning (brill, 1995),<papid> J95-4004 </papid>but most of the best known and most successful approaches of recent years have been unidirectional.most sequence models can be seen as chaining together the scores or decisions from successive local models to form global model for an entire sequence.</nextsent>
<nextsent>clearly the identity of tag is correlated with both past and future tags?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4110">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>almost all approaches to sequence problems such as partof-speech tagging take unidirectional approach to conditioning inference along the sequence.
</prevsent>
<prevsent>regardless of whether one is using hmms, maximum entropy conditional sequence models, or other techniques like decision trees, most systems work in one direction through the sequence (normally left to right, but occasionally rightto left, e.g., church (1988)).<papid> A88-1019 </papid></prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
there are few exceptions, such as brills transformation-based learning (brill, 1995),<papid> J95-4004 </papid>but most of the best known and most successful approaches of recent years have been unidirectional.most sequence models can be seen as chaining together the scores or decisions from successive local models to form global model for an entire sequence.</citsent>
<aftsection>
<nextsent>clearly the identity of tag is correlated with both past and future tags?
</nextsent>
<nextsent>identities.
</nextsent>
<nextsent>however, in the unidirectional (causal)case, only one direction of influence is explicitly considered at each local point.
</nextsent>
<nextsent>for example, in left-to-right first-order hmm, the current tag t0 is predicted based onthe previous tag t1 (and the current word).1 the backward interaction between t0 and the next tag t+1 shows up implicitly later, when t+1 is generated in turn.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4112">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the model.
</prevsent>
<prevsent>having expressive templates leads to large number of features, but we show that by suitable use of prior (i.e., regularization) in the conditional loglinear model something not used by previous maximum entropy taggers ? many such features can be added with an overall positive effect on the model.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
indeed, as for the voted perceptron of collins (2002), <papid> W02-1001 </papid>we can get performance gainsby reducing the support threshold for features to be included in the model.</citsent>
<aftsection>
<nextsent>combining all these ideas, together with few additional handcrafted unknown word features, gives us part-of-speech tagger with per-position tag accuracy of 97.24%, and whole-sentence correct rate of 56.34% on penn treebank wsj data.
</nextsent>
<nextsent>this is the best automatically learned part-of-speech tagging result known to us, representing an error reduction of 4.4% on the model presented in collins (2002), <papid> W02-1001 </papid>using the same data splits, and larger error reduction of 12.1% from the more similar best previous loglinear model in toutanova and manning (2000).<papid> W00-1308 </papid></nextsent>
<nextsent>when building probabilistic models for tag sequences, we often decompose the global probability of sequences using directed graphical model (e.g., an hmm (brants,2000) <papid> A00-1031 </papid>or conditional markov model (cmm) (ratna parkhi, 1996)).<papid> W96-0213 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4116">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>indeed, as for the voted perceptron of collins (2002), <papid> W02-1001 </papid>we can get performance gainsby reducing the support threshold for features to be included in the model.</prevsent>
<prevsent>combining all these ideas, together with few additional handcrafted unknown word features, gives us part-of-speech tagger with per-position tag accuracy of 97.24%, and whole-sentence correct rate of 56.34% on penn treebank wsj data.</prevsent>
</prevsection>
<citsent citstr=" W00-1308 ">
this is the best automatically learned part-of-speech tagging result known to us, representing an error reduction of 4.4% on the model presented in collins (2002), <papid> W02-1001 </papid>using the same data splits, and larger error reduction of 12.1% from the more similar best previous loglinear model in toutanova and manning (2000).<papid> W00-1308 </papid></citsent>
<aftsection>
<nextsent>when building probabilistic models for tag sequences, we often decompose the global probability of sequences using directed graphical model (e.g., an hmm (brants,2000) <papid> A00-1031 </papid>or conditional markov model (cmm) (ratna parkhi, 1996)).<papid> W96-0213 </papid></nextsent>
<nextsent>in such models, the probability assigned to tagged sequence of words = t, w?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4117">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> bidirectional dependency networks.  </section>
<citcontext>
<prevsection>
<prevsent>combining all these ideas, together with few additional handcrafted unknown word features, gives us part-of-speech tagger with per-position tag accuracy of 97.24%, and whole-sentence correct rate of 56.34% on penn treebank wsj data.
</prevsent>
<prevsent>this is the best automatically learned part-of-speech tagging result known to us, representing an error reduction of 4.4% on the model presented in collins (2002), <papid> W02-1001 </papid>using the same data splits, and larger error reduction of 12.1% from the more similar best previous loglinear model in toutanova and manning (2000).<papid> W00-1308 </papid></prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
when building probabilistic models for tag sequences, we often decompose the global probability of sequences using directed graphical model (e.g., an hmm (brants,2000) <papid> A00-1031 </papid>or conditional markov model (cmm) (ratna parkhi, 1996)).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>in such models, the probability assigned to tagged sequence of words = t, w?
</nextsent>
<nextsent>is the product of sequence of local portions of the graphical model, one from each time slice.
</nextsent>
<nextsent>for example, in the left-to-right cmm shown in figure 1(a), p(t, w) = ? p(ti |ti1, wi ) that is, the replicated structure is local modelp(t0|t1, w0).2 of course, if there are too many conditioned quantities, these local models may have to be estimated in some sophisticated way; it is typical in tagging to populate these models with little maximum entropy models.
</nextsent>
<nextsent>for example, we might populate model for p(t0|t1, w0) with maxent model of the form: p?(t0|t1, w0) = exp(t0,t1?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4118">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> bidirectional dependency networks.  </section>
<citcontext>
<prevsection>
<prevsent>combining all these ideas, together with few additional handcrafted unknown word features, gives us part-of-speech tagger with per-position tag accuracy of 97.24%, and whole-sentence correct rate of 56.34% on penn treebank wsj data.
</prevsent>
<prevsent>this is the best automatically learned part-of-speech tagging result known to us, representing an error reduction of 4.4% on the model presented in collins (2002), <papid> W02-1001 </papid>using the same data splits, and larger error reduction of 12.1% from the more similar best previous loglinear model in toutanova and manning (2000).<papid> W00-1308 </papid></prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
when building probabilistic models for tag sequences, we often decompose the global probability of sequences using directed graphical model (e.g., an hmm (brants,2000) <papid> A00-1031 </papid>or conditional markov model (cmm) (ratna parkhi, 1996)).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>in such models, the probability assigned to tagged sequence of words = t, w?
</nextsent>
<nextsent>is the product of sequence of local portions of the graphical model, one from each time slice.
</nextsent>
<nextsent>for example, in the left-to-right cmm shown in figure 1(a), p(t, w) = ? p(ti |ti1, wi ) that is, the replicated structure is local modelp(t0|t1, w0).2 of course, if there are too many conditioned quantities, these local models may have to be estimated in some sophisticated way; it is typical in tagging to populate these models with little maximum entropy models.
</nextsent>
<nextsent>for example, we might populate model for p(t0|t1, w0) with maxent model of the form: p?(t0|t1, w0) = exp(t0,t1?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4119">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> bidirectional dependency networks.  </section>
<citcontext>
<prevsection>
<prevsent>there are two good formal reasons to expect that model explicitly conditioning on both sides at each position, like figure 1(c) could be advantageous.
</prevsent>
<prevsent>first, because of smoothing effects and interaction with other conditioning features (like the words), left-to-right factors like p(t0|t1, w0)do not always suffice when t0 is implicitly needed to determine t1.
</prevsent>
</prevsection>
<citsent citstr=" W02-1002 ">
for example, consider case of observation bias (klein and manning, 2002) <papid> W02-1002 </papid>for first-order left-to right cmm.</citsent>
<aftsection>
<nextsent>the word to has only one tag (to) in the ptb tag set.
</nextsent>
<nextsent>the to tag is often preceded by nouns, but rarely by modals (md).
</nextsent>
<nextsent>in sequence will to fight, that trend indicates that will should be noun rather than modal verb.
</nextsent>
<nextsent>however, that effect is completely lost in cmm like (a): p(twill |will, star t?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4124">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>7except where otherwise stated, count cutoff of 2 was usedfor common word features and 35 for rare word features (tem plates need support set strictly greater in size than the cutoff before they are included in the model).
</prevsent>
<prevsent>8charniak et al (1993) noted that such simple model got 90.25%, but this was with no unknown word model beyond prior distribution over tags.
</prevsent>
</prevsection>
<citsent citstr=" W99-0606 ">
abney et al (1999) <papid> W99-0606 </papid>raise this baseline to 92.34%, and with our sophisticated unknown word model, it gets even higher.</citsent>
<aftsection>
<nextsent>the large number of unambiguous tokens and ones with very skewed distributions make the base model feature templates?
</nextsent>
<nextsent>features sentence token unkn.
</nextsent>
<nextsent>word accuracy accuracy accuracy baseline ? 56,805 26.74% 93.69% 82.61% t0, t1?
</nextsent>
<nextsent>27,474 41.89% 95.79% 85.49% t0, t+1?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4131">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 lexicalization.
</prevsent>
<prevsent>lexicalization has been key factor in the advance of statistical parsing models, but has been less exploited for tagging.
</prevsent>
</prevsection>
<citsent citstr=" P00-1034 ">
words surrounding the current word have been occasionally used in taggers, such as (ratnaparkhi, 1996), <papid> W96-0213 </papid>brills transformation based tagger (brill, 1995),<papid> J95-4004 </papid>and the hmm model of lee et al (2000), <papid> P00-1034 </papid>but nevertheless, the only lexicalization consistently included in tagging models is the dependence of the part of speech tag of word on the word itself.</citsent>
<aftsection>
<nextsent>in maximum entropy models, joint features which lookat surrounding words and their tags, as well as joint features of the current word and surrounding words are in principle straightforward additions, but have not been incorporated into previous models.
</nextsent>
<nextsent>we have found these features to be very useful.
</nextsent>
<nextsent>we explore here lexicalization both alone and in combination with preceding and following tag histories.
</nextsent>
<nextsent>table 3 shows the development set accuracy of several models with various lexical features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4134">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>most of the models presented here use set of unknown word features basically inherited from (ratnaparkhi, 1996), <papid> W96-0213 </papid>which include using character n-gram prefixes and suffixes (for up to 4), and detectors for few other prominent features of words, such as capitalization, hyphens, and numbers.</prevsent>
<prevsent>doing error analysis on unknown words on simple tagging model (with t0, t1?,t0, t1, t2?, and w0, t0?</prevsent>
</prevsection>
<citsent citstr=" P99-1023 ">
features) suggested several additional specialized features that can usefully improve 9thede and harper (1999) <papid> P99-1023 </papid>use t1, t0, w0?</citsent>
<aftsection>
<nextsent>templates in their full-second order?
</nextsent>
<nextsent>hmm, achieving an accuracy of 96.86%.
</nextsent>
<nextsent>here we can add the opposite tiling and other features.
</nextsent>
<nextsent>smoothed features sentence token unk.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4139">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we describe two sets of experiments aimed at comparing models with and without regularization.
</prevsent>
<prevsent>one is for simple model with relatively small number of features, and the other is for model with large number of features.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
the usefulness of priors in maximum entropy mode lsis not new to this work: gaussian prior smoothing is advocated in chen and rosenfeld (2000), and used in allthe stochastic lfg work (johnson et al, 1999).<papid> P99-1069 </papid></citsent>
<aftsection>
<nextsent>how ever, until recently, its role and importance have not been widely understood.
</nextsent>
<nextsent>for example, zhang and oles (2001)attribute the perceived limited success of logistic regression for text categorization to lack of use of regularization.
</nextsent>
<nextsent>at any rate, regularized conditional loglinear models have not previously been applied to the problem of producing high quality part-of-speech tagger: ratnaparkhi (1996), <papid> W96-0213 </papid>toutanova and manning (2000), <papid> W00-1308 </papid>and collins (2002) <papid> W02-1001 </papid>all present un regularized models.</nextsent>
<nextsent>indeed, the result of collins (2002) <papid> W02-1001 </papid>that including low support features helps voted perceptron model but harms maximum entropy model is undone once the weights of the maximum entropy model are regularized.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4156">
<title id=" N03-1033.xml">feature rich partofspeech tagging with a cyclic dependency network </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>while experience sug 10on 2ghz pc, this is still an important difference: our largest models require about 25 minutes per iteration to train.
</prevsent>
<prevsent>11in practice one notices some wiggling in the curve, but the trend remains upward even beyond our chosen convergence point.
</prevsent>
</prevsection>
<citsent citstr=" P98-1029 ">
gests that the final accuracy number presented here could be slightly improved upon by classifier combination, it is worth noting that not only is this tagger better than any previous single tagger, but it also appears to outperform brill and wu (1998), <papid> P98-1029 </papid>the best-known combination tagger (they report an accuracy of 97.16% over the same wsj data, but using larger training set, which should favor them).</citsent>
<aftsection>
<nextsent>while part-of-speech tagging is now fairly well-worn road, and our ability to win performance increases inthis domain is starting to be limited by the rate of errors and inconsistencies in the penn treebank training data, this work also has broader implications.
</nextsent>
<nextsent>across the many nlp problems which involve sequence models over sparse multinomial distributions, it suggests thatfeature-rich models with extensive lexicalization, bidirectional inference, and effective regularization will be key elements in producing state-of-the-art results.
</nextsent>
<nextsent>acknowledgements this work was supported in part by the advanced research and development activity (arda)s advanced question answering for intelligence (aquaint) program, by the national science foundation under grant no.
</nextsent>
<nextsent>iis-0085896, and by an ibm faculty partnership award.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4157">
<title id=" N06-1046.xml">aggregation via set partitioning for natural language generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>aggregation is an essential component of many natural language generation systems (reiter and dale,2000).
</prevsent>
<prevsent>the task captures mechanism for merging together two or more linguistic structures into single sentence.
</prevsent>
</prevsection>
<citsent citstr=" W00-1425 ">
aggregated texts tend to be more concise, coherent, and more readable overall (dalia nis, 1999; cheng and mellish, 2000).<papid> W00-1425 </papid></citsent>
<aftsection>
<nextsent>compare,for example, sentence (2) in table 1 and its non aggregated counterpart in sentences (1a)?(1d).
</nextsent>
<nextsent>the difference between the fluent aggregated sentence and its abrupt and redundant alternative is striking.
</nextsent>
<nextsent>the benefits of aggregation go beyond making texts less stilted and repetitive.
</nextsent>
<nextsent>researchers in psycho linguistics have shown that by eliminating re (1) a. holocomb had an incompletion in the first quarter.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4158">
<title id=" N06-1046.xml">aggregation via set partitioning for natural language generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>d. holocomb threw to davis for leaping catch.(2) after two in completions in the first quarter, holcomb found davis among four san francisco defenders for leaping catch.
</prevsent>
<prevsent>table 1: aggregation example (in boldface) from corpus of football summariesdundancy, aggregation facilitates text comprehension and recall (see yeung (1999) and the references therein).
</prevsent>
</prevsection>
<citsent citstr=" P05-1007 ">
furthermore, di eugenio et al (2005) <papid> P05-1007 </papid>demonstrate that aggregation can improve learning in the context of an intelligent tutoring application.in existing generation systems, aggregation typically comprises two processes: semantic grouping and sentence structuring (wilkinson, 1995).</citsent>
<aftsection>
<nextsent>the first process involves partitioning semantic content(usually the output of content selection component) into disjoint sets, each corresponding to single sentence.
</nextsent>
<nextsent>the second process is concerned with syntactic or lexical decisions that affect the realization of an aggregated sentence.
</nextsent>
<nextsent>to date, this task has involved human analysis of domain-relevant corpus and manual development of aggregation rules (dalianis, 1999; shaw, 1998).<papid> W98-1415 </papid></nextsent>
<nextsent>the corpus analysis and knowledge engineering work in such an approach is substantial, prohibitively so in 359 large domains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4159">
<title id=" N06-1046.xml">aggregation via set partitioning for natural language generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the first process involves partitioning semantic content(usually the output of content selection component) into disjoint sets, each corresponding to single sentence.
</prevsent>
<prevsent>the second process is concerned with syntactic or lexical decisions that affect the realization of an aggregated sentence.
</prevsent>
</prevsection>
<citsent citstr=" W98-1415 ">
to date, this task has involved human analysis of domain-relevant corpus and manual development of aggregation rules (dalianis, 1999; shaw, 1998).<papid> W98-1415 </papid></citsent>
<aftsection>
<nextsent>the corpus analysis and knowledge engineering work in such an approach is substantial, prohibitively so in 359 large domains.
</nextsent>
<nextsent>but since corpus data is already used in building aggregation components, an appealing alternative is to try and learn the rules of semantic grouping directly from the data.
</nextsent>
<nextsent>clearly, this would greatly reduce the human effort involved and ease porting generation systems to new domains.
</nextsent>
<nextsent>in this paper, we present an automatic method for performing the semantic grouping task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4165">
<title id=" N06-1046.xml">aggregation via set partitioning for natural language generation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the interplay of different constraints is usually captured by set of hand-crafted rules that guide the aggregation process (scott and desouza, 1990;hovy, 1990; dalianis, 1999; shaw, 1998).<papid> W98-1415 </papid></prevsent>
<prevsent>alternatively, these rules can be learned from cor pus.</prevsent>
</prevsection>
<citsent citstr=" N01-1003 ">
for instance, walker et al (2001) <papid> N01-1003 </papid>propose an overgenerate-and-rank approach to aggregation within the context of spoken dialog application.their system relies on preference function for selecting an appropriate aggregation among multiple alternatives and assumes access to large feature space expressing syntactic and pragmatic features of the input representations.</citsent>
<aftsection>
<nextsent>the preference function is learned from corpus of candidate aggregations marked with human ratings.
</nextsent>
<nextsent>another approach is put forward by cheng and mellish (2000) <papid> W00-1425 </papid>who use genetic algorithm in combination with hand-crafted preference function to opportunistically find text that satisfies aggregation and planning constraints.</nextsent>
<nextsent>our approach differs from previous work in two important respects.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4171">
<title id=" N06-1046.xml">aggregation via set partitioning for natural language generation </title>
<section> modeling.  </section>
<citcontext>
<prevsection>
<prevsent>the computational challenge lies in the complexity of such model: we need to find an optimal partition in an exponentially large search space.
</prevsent>
<prevsent>our approach is based on an integer linear programming (ilp) formulation which can be effectively solved using standard optimization tools.
</prevsent>
</prevsection>
<citsent citstr=" W04-2401 ">
ilp models have been successfully applied in several natural language processing tasks, including relation extraction (roth and yih, 2004), <papid> W04-2401 </papid>semantic role labeling (punyakanok et al, 2004) <papid> C04-1197 </papid>and the generation of route directions (marciniak and strube, 2005).<papid> W05-0618 </papid></citsent>
<aftsection>
<nextsent>in the following section, we introduce our local pairwise model and afterward we present our global model for partitioning.
</nextsent>
<nextsent>4.1 learning pairwise similarity.
</nextsent>
<nextsent>our goal is to determine whether two database entries should be aggregated given the similarity of their shared attributes.
</nextsent>
<nextsent>we generate the training data by considering all pairs ei, ej?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4172">
<title id=" N06-1046.xml">aggregation via set partitioning for natural language generation </title>
<section> modeling.  </section>
<citcontext>
<prevsection>
<prevsent>the computational challenge lies in the complexity of such model: we need to find an optimal partition in an exponentially large search space.
</prevsent>
<prevsent>our approach is based on an integer linear programming (ilp) formulation which can be effectively solved using standard optimization tools.
</prevsent>
</prevsection>
<citsent citstr=" C04-1197 ">
ilp models have been successfully applied in several natural language processing tasks, including relation extraction (roth and yih, 2004), <papid> W04-2401 </papid>semantic role labeling (punyakanok et al, 2004) <papid> C04-1197 </papid>and the generation of route directions (marciniak and strube, 2005).<papid> W05-0618 </papid></citsent>
<aftsection>
<nextsent>in the following section, we introduce our local pairwise model and afterward we present our global model for partitioning.
</nextsent>
<nextsent>4.1 learning pairwise similarity.
</nextsent>
<nextsent>our goal is to determine whether two database entries should be aggregated given the similarity of their shared attributes.
</nextsent>
<nextsent>we generate the training data by considering all pairs ei, ej?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4173">
<title id=" N06-1046.xml">aggregation via set partitioning for natural language generation </title>
<section> modeling.  </section>
<citcontext>
<prevsection>
<prevsent>the computational challenge lies in the complexity of such model: we need to find an optimal partition in an exponentially large search space.
</prevsent>
<prevsent>our approach is based on an integer linear programming (ilp) formulation which can be effectively solved using standard optimization tools.
</prevsent>
</prevsection>
<citsent citstr=" W05-0618 ">
ilp models have been successfully applied in several natural language processing tasks, including relation extraction (roth and yih, 2004), <papid> W04-2401 </papid>semantic role labeling (punyakanok et al, 2004) <papid> C04-1197 </papid>and the generation of route directions (marciniak and strube, 2005).<papid> W05-0618 </papid></citsent>
<aftsection>
<nextsent>in the following section, we introduce our local pairwise model and afterward we present our global model for partitioning.
</nextsent>
<nextsent>4.1 learning pairwise similarity.
</nextsent>
<nextsent>our goal is to determine whether two database entries should be aggregated given the similarity of their shared attributes.
</nextsent>
<nextsent>we generate the training data by considering all pairs ei, ej?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4175">
<title id=" N06-1046.xml">aggregation via set partitioning for natural language generation </title>
<section> evaluation set-up.  </section>
<citcontext>
<prevsection>
<prevsent>the model presented in the previous section was evaluated in the context of generating summary reports for american football games.
</prevsent>
<prevsent>in this section we describe the corpus used in our experiments, our procedure for estimating the parameters of our models, and the baseline method used for comparison with our approach.
</prevsent>
</prevsection>
<citsent citstr=" H05-1042 ">
data for training and testing our algorithm, we employed corpus of football game summaries collected by barzilay and lapata (2005).<papid> H05-1042 </papid></citsent>
<aftsection>
<nextsent>the corpus contains 468 game summaries from the official site of the american national football league6 (nfl).each summary has an associated database containing statistics about individual players and events.
</nextsent>
<nextsent>in total, the corpus contains 73,400 database entries,7.1% of which are verbalized; each entry is characterized by type and set of attributes (see table 2).
</nextsent>
<nextsent>database entries are automatically aligned with their corresponding sentences in the game summaries by procedure that considers anchor overlap between entity attributes and sentence tokens.
</nextsent>
<nextsent>although the alignment procedure is relatively accurate, there is unavoidably some noise in the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4178">
<title id=" N07-1016.xml">unsupervised resolution of objects and relations on the web </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>while this is useful information when resolving authors in the citation domain, it is extremely rare to find relations with similar properties in extracted assertions.
</prevsent>
<prevsent>noneof these approaches applies to the problem of resolving relations.
</prevsent>
</prevsection>
<citsent citstr=" W97-0319 ">
see (winkler, 1999) for survey of this area.several supervised learning techniques make entity resolution decisions (kehler, 1997; <papid> W97-0319 </papid>mccallum and wellner, 2004; singla and domingos, 2006), but of course these systems depend on the availability of training data, and often on significant number of labeled examples per relation of interest.</citsent>
<aftsection>
<nextsent>these approaches also depend on complex probabilistic models and learning algorithms, and they have order o(n3) time complexity, or worse.
</nextsent>
<nextsent>they currently do not scale to the amounts of data extracted from the web.
</nextsent>
<nextsent>previous systems were tested on at most few thousand examples, compared with millions or hundreds of millions of extractions from wie systems such as textrunner.
</nextsent>
<nextsent>coreference resolution systems (e.g., (lappin andleass, 1994; <papid> J94-4002 </papid>ng and cardie, 2002)), <papid> P02-1014 </papid>like sr systems, try to merge references to the same object (typ ically pronouns, but potentially other types of noun phrases).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4179">
<title id=" N07-1016.xml">unsupervised resolution of objects and relations on the web </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>they currently do not scale to the amounts of data extracted from the web.
</prevsent>
<prevsent>previous systems were tested on at most few thousand examples, compared with millions or hundreds of millions of extractions from wie systems such as textrunner.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
coreference resolution systems (e.g., (lappin andleass, 1994; <papid> J94-4002 </papid>ng and cardie, 2002)), <papid> P02-1014 </papid>like sr systems, try to merge references to the same object (typ ically pronouns, but potentially other types of noun phrases).</citsent>
<aftsection>
<nextsent>this problem differs from the sr problem in several ways: first, it deals with unstructered text input, possibly with syntactic annotation, rather than relational input.
</nextsent>
<nextsent>second, it deals only with resolving objects.
</nextsent>
<nextsent>finally, it requires local decisions about strings; that is, the same word may appear twice in atext and refer to two different things, so each occurrence of word must be treated separately.
</nextsent>
<nextsent>the pascal recognising textual entailment challenge proposes the task of recognizing when two sentences entail one another, and many authors have submitted responses to this challenge (dagan et al., 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4180">
<title id=" N07-1016.xml">unsupervised resolution of objects and relations on the web </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>they currently do not scale to the amounts of data extracted from the web.
</prevsent>
<prevsent>previous systems were tested on at most few thousand examples, compared with millions or hundreds of millions of extractions from wie systems such as textrunner.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
coreference resolution systems (e.g., (lappin andleass, 1994; <papid> J94-4002 </papid>ng and cardie, 2002)), <papid> P02-1014 </papid>like sr systems, try to merge references to the same object (typ ically pronouns, but potentially other types of noun phrases).</citsent>
<aftsection>
<nextsent>this problem differs from the sr problem in several ways: first, it deals with unstructered text input, possibly with syntactic annotation, rather than relational input.
</nextsent>
<nextsent>second, it deals only with resolving objects.
</nextsent>
<nextsent>finally, it requires local decisions about strings; that is, the same word may appear twice in atext and refer to two different things, so each occurrence of word must be treated separately.
</nextsent>
<nextsent>the pascal recognising textual entailment challenge proposes the task of recognizing when two sentences entail one another, and many authors have submitted responses to this challenge (dagan et al., 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4181">
<title id=" N07-1016.xml">unsupervised resolution of objects and relations on the web </title>
<section> probabilistic model.  </section>
<citcontext>
<prevsection>
<prevsent>it has two sources of evidence: the similarity of the strings themselves (i.e., edit distance) and the similarity of the assertions they appear in.
</prevsent>
<prevsent>this second source of evidence is sometimes referred to as distributional similarity?
</prevsent>
</prevsection>
<citsent citstr=" P90-1034 ">
(hin dle, 1990).<papid> P90-1034 </papid>section 3.2 presents simple model for predicting whether pair of strings co-refer based on string similarity.</citsent>
<aftsection>
<nextsent>section 3.3 then presents model called the extracted shared property (esp) model for predicting whether pair of strings co-refer based on their distributional similarity.
</nextsent>
<nextsent>finally, method is presented for combining these models to come up with an overall prediction for coreference decisions between two clusters of strings.
</nextsent>
<nextsent>3.1 terminology and notation.
</nextsent>
<nextsent>we use the following notation to describe the probabilistic models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4182">
<title id=" N07-1016.xml">unsupervised resolution of objects and relations on the web </title>
<section> probabilistic model.  </section>
<citcontext>
<prevsection>
<prevsent>p (ri)) 124 3.5 comparing clusters of strings.
</prevsent>
<prevsent>our algorithm merges clusters of strings with one another, using one of the above models.
</prevsent>
</prevsection>
<citsent citstr=" P06-1101 ">
however,these models give probabilities for coreference decisions between two individual strings, not two clusters of strings.we follow the work of snow et al (2006) <papid> P06-1101 </papid>in incorporating transitive closure constraints in probabilistic modeling, and make the same independence assumptions.</citsent>
<aftsection>
<nextsent>the benefit of this approach is that the calculation for merging two clusters depends only on coreference decisions between individual strings, which can be calculated independently.let clustering be set of coreference relationships between pairs of strings such that the coreference relationships obey the transitive closure property.
</nextsent>
<nextsent>we let the probability of set of assertions given clustering be: (d|c) = ? rti,jc (di dj |rti,j)?
</nextsent>
<nextsent>rfi,jc (di dj |rfi,j) the metric used to determine if two clusters should be merged is the likelihood ratio, or the probability for the set of assertions given the merged clusters over the probability given the original clustering.
</nextsent>
<nextsent>let ? be clustering that differs from only in that two clusters in have been merged inc ?, and let be the set of coreference relationships in ? that are true, but the corresponding ones in are false.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4183">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J02-3001 ">
in this paper, we propose machine learning algorithm for shallow semantic parsing, extending the work of gildea and jurafsky (2002),<papid> J02-3001 </papid>surdeanu et al  (2003) <papid> P03-1002 </papid>and others.</citsent>
<aftsection>
<nextsent>our algorithm is based on support vector machines which we show give an improvement in performance over earlier classifiers.
</nextsent>
<nextsent>we show performance improvements through number of new features and measure their ability to generalize to new test set drawn from the aquaint corpus.
</nextsent>
<nextsent>automatic, accurate and wide-coverage techniques thatcan annotate naturally occurring text with semantic argument structure can play key role in nlp applications such as information extraction, question answering and summarization.
</nextsent>
<nextsent>shallow semantic parsing ? the process of assigning simple who did what to whom, when, where, why, how, etc. structure to sentences in text,is the process of producing such markup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4184">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P03-1002 ">
in this paper, we propose machine learning algorithm for shallow semantic parsing, extending the work of gildea and jurafsky (2002),<papid> J02-3001 </papid>surdeanu et al  (2003) <papid> P03-1002 </papid>and others.</citsent>
<aftsection>
<nextsent>our algorithm is based on support vector machines which we show give an improvement in performance over earlier classifiers.
</nextsent>
<nextsent>we show performance improvements through number of new features and measure their ability to generalize to new test set drawn from the aquaint corpus.
</nextsent>
<nextsent>automatic, accurate and wide-coverage techniques thatcan annotate naturally occurring text with semantic argument structure can play key role in nlp applications such as information extraction, question answering and summarization.
</nextsent>
<nextsent>shallow semantic parsing ? the process of assigning simple who did what to whom, when, where, why, how, etc. structure to sentences in text,is the process of producing such markup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4188">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when presented with sentence, parser should, for each predicate in the sentence, identify and label the predicates semantic arguments.
</prevsent>
<prevsent>this process entails identifying groups ofwords in sentence that represent these semantic arguments and assigning specific labels to them.
</prevsent>
</prevsection>
<citsent citstr=" P00-1065 ">
in recent work, number of researchers have cast this problem as tagging problem and have applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002); <papid> J02-3001 </papid>blaheta and charniak (2000); <papid> A00-2031 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al  (2003); <papid> P03-1002 </papid>gildea and hockenmaier (2003); <papid> W03-1008 </papid>chen and rambow (2003); <papid> W03-1006 </papid>fleischman and hovy (2003); <papid> N03-2008 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al  (2003); pradhan et al  (2003)).</citsent>
<aftsection>
<nextsent>in this this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 paper, we report on series of experiments exploring this approach.
</nextsent>
<nextsent>for the initial experiments, we adopted the approach described by gildea and jurafsky (2002) (<papid> J02-3001 </papid>g&j;) and evaluated series of modifications to improve its performance.</nextsent>
<nextsent>in the experiments reported here, we first replaced their statistical classification algorithm with one that uses support vector machines and then added to the existing feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4190">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when presented with sentence, parser should, for each predicate in the sentence, identify and label the predicates semantic arguments.
</prevsent>
<prevsent>this process entails identifying groups ofwords in sentence that represent these semantic arguments and assigning specific labels to them.
</prevsent>
</prevsection>
<citsent citstr=" A00-2031 ">
in recent work, number of researchers have cast this problem as tagging problem and have applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002); <papid> J02-3001 </papid>blaheta and charniak (2000); <papid> A00-2031 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al  (2003); <papid> P03-1002 </papid>gildea and hockenmaier (2003); <papid> W03-1008 </papid>chen and rambow (2003); <papid> W03-1006 </papid>fleischman and hovy (2003); <papid> N03-2008 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al  (2003); pradhan et al  (2003)).</citsent>
<aftsection>
<nextsent>in this this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 paper, we report on series of experiments exploring this approach.
</nextsent>
<nextsent>for the initial experiments, we adopted the approach described by gildea and jurafsky (2002) (<papid> J02-3001 </papid>g&j;) and evaluated series of modifications to improve its performance.</nextsent>
<nextsent>in the experiments reported here, we first replaced their statistical classification algorithm with one that uses support vector machines and then added to the existing feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4191">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when presented with sentence, parser should, for each predicate in the sentence, identify and label the predicates semantic arguments.
</prevsent>
<prevsent>this process entails identifying groups ofwords in sentence that represent these semantic arguments and assigning specific labels to them.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
in recent work, number of researchers have cast this problem as tagging problem and have applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002); <papid> J02-3001 </papid>blaheta and charniak (2000); <papid> A00-2031 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al  (2003); <papid> P03-1002 </papid>gildea and hockenmaier (2003); <papid> W03-1008 </papid>chen and rambow (2003); <papid> W03-1006 </papid>fleischman and hovy (2003); <papid> N03-2008 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al  (2003); pradhan et al  (2003)).</citsent>
<aftsection>
<nextsent>in this this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 paper, we report on series of experiments exploring this approach.
</nextsent>
<nextsent>for the initial experiments, we adopted the approach described by gildea and jurafsky (2002) (<papid> J02-3001 </papid>g&j;) and evaluated series of modifications to improve its performance.</nextsent>
<nextsent>in the experiments reported here, we first replaced their statistical classification algorithm with one that uses support vector machines and then added to the existing feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4193">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when presented with sentence, parser should, for each predicate in the sentence, identify and label the predicates semantic arguments.
</prevsent>
<prevsent>this process entails identifying groups ofwords in sentence that represent these semantic arguments and assigning specific labels to them.
</prevsent>
</prevsection>
<citsent citstr=" W03-1008 ">
in recent work, number of researchers have cast this problem as tagging problem and have applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002); <papid> J02-3001 </papid>blaheta and charniak (2000); <papid> A00-2031 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al  (2003); <papid> P03-1002 </papid>gildea and hockenmaier (2003); <papid> W03-1008 </papid>chen and rambow (2003); <papid> W03-1006 </papid>fleischman and hovy (2003); <papid> N03-2008 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al  (2003); pradhan et al  (2003)).</citsent>
<aftsection>
<nextsent>in this this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 paper, we report on series of experiments exploring this approach.
</nextsent>
<nextsent>for the initial experiments, we adopted the approach described by gildea and jurafsky (2002) (<papid> J02-3001 </papid>g&j;) and evaluated series of modifications to improve its performance.</nextsent>
<nextsent>in the experiments reported here, we first replaced their statistical classification algorithm with one that uses support vector machines and then added to the existing feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4194">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when presented with sentence, parser should, for each predicate in the sentence, identify and label the predicates semantic arguments.
</prevsent>
<prevsent>this process entails identifying groups ofwords in sentence that represent these semantic arguments and assigning specific labels to them.
</prevsent>
</prevsection>
<citsent citstr=" W03-1006 ">
in recent work, number of researchers have cast this problem as tagging problem and have applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002); <papid> J02-3001 </papid>blaheta and charniak (2000); <papid> A00-2031 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al  (2003); <papid> P03-1002 </papid>gildea and hockenmaier (2003); <papid> W03-1008 </papid>chen and rambow (2003); <papid> W03-1006 </papid>fleischman and hovy (2003); <papid> N03-2008 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al  (2003); pradhan et al  (2003)).</citsent>
<aftsection>
<nextsent>in this this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 paper, we report on series of experiments exploring this approach.
</nextsent>
<nextsent>for the initial experiments, we adopted the approach described by gildea and jurafsky (2002) (<papid> J02-3001 </papid>g&j;) and evaluated series of modifications to improve its performance.</nextsent>
<nextsent>in the experiments reported here, we first replaced their statistical classification algorithm with one that uses support vector machines and then added to the existing feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4195">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when presented with sentence, parser should, for each predicate in the sentence, identify and label the predicates semantic arguments.
</prevsent>
<prevsent>this process entails identifying groups ofwords in sentence that represent these semantic arguments and assigning specific labels to them.
</prevsent>
</prevsection>
<citsent citstr=" N03-2008 ">
in recent work, number of researchers have cast this problem as tagging problem and have applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002); <papid> J02-3001 </papid>blaheta and charniak (2000); <papid> A00-2031 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al  (2003); <papid> P03-1002 </papid>gildea and hockenmaier (2003); <papid> W03-1008 </papid>chen and rambow (2003); <papid> W03-1006 </papid>fleischman and hovy (2003); <papid> N03-2008 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al  (2003); pradhan et al  (2003)).</citsent>
<aftsection>
<nextsent>in this this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 paper, we report on series of experiments exploring this approach.
</nextsent>
<nextsent>for the initial experiments, we adopted the approach described by gildea and jurafsky (2002) (<papid> J02-3001 </papid>g&j;) and evaluated series of modifications to improve its performance.</nextsent>
<nextsent>in the experiments reported here, we first replaced their statistical classification algorithm with one that uses support vector machines and then added to the existing feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4196">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when presented with sentence, parser should, for each predicate in the sentence, identify and label the predicates semantic arguments.
</prevsent>
<prevsent>this process entails identifying groups ofwords in sentence that represent these semantic arguments and assigning specific labels to them.
</prevsent>
</prevsection>
<citsent citstr=" N03-2009 ">
in recent work, number of researchers have cast this problem as tagging problem and have applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002); <papid> J02-3001 </papid>blaheta and charniak (2000); <papid> A00-2031 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al  (2003); <papid> P03-1002 </papid>gildea and hockenmaier (2003); <papid> W03-1008 </papid>chen and rambow (2003); <papid> W03-1006 </papid>fleischman and hovy (2003); <papid> N03-2008 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al  (2003); pradhan et al  (2003)).</citsent>
<aftsection>
<nextsent>in this this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 paper, we report on series of experiments exploring this approach.
</nextsent>
<nextsent>for the initial experiments, we adopted the approach described by gildea and jurafsky (2002) (<papid> J02-3001 </papid>g&j;) and evaluated series of modifications to improve its performance.</nextsent>
<nextsent>in the experiments reported here, we first replaced their statistical classification algorithm with one that uses support vector machines and then added to the existing feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4198">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> semantic annotation and corpora.  </section>
<citcontext>
<prevsection>
<prevsent>in the experiments reported here, we first replaced their statistical classification algorithm with one that uses support vector machines and then added to the existing feature set.
</prevsent>
<prevsent>we evaluate results using both hand corrected treebank syntactic parses, and actual parses from the charniak parser.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
we will be reporting on results using propbank1 (kingsbury et al , 2002), 300k-word corpus in which predicate argument relations are marked for part of the verbsin the wall street journal (wsj) part of the penn tree bank (marcus et al , 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>the arguments of verb are labeled arg0 to arg5, where arg0 is the proto agent (usually the subject of transitive verb) arg1 is the proto-patient (usually its direct object), etc. propbank attempts to treat semantically related verbs consistently.
</nextsent>
<nextsent>in addition to these core arguments, additional adjunct ive arguments, referred to asargms are also marked.
</nextsent>
<nextsent>some examples are argmloc, for locatives, and argm-tmp, for temporals.
</nextsent>
<nextsent>figure 1 shows the syntax tree representation along with the argument labels for an example structure extracted from the propbank corpus.most of the experiments in this paper, unless specified otherwise, are performed on the july 2002 release of propbank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4199">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> classifier and implementation.  </section>
<citcontext>
<prevsection>
<prevsent>all the nodes are classified directly as null or one of the arguments using the classifier trained in step 2 above.
</prevsent>
<prevsent>we observe no significant performance improvement even if we filter the most likely null nodes in first pass.
</prevsent>
</prevsection>
<citsent citstr=" W00-0730 ">
for our experiments, we used tinysvm2 along with yamcha3 (kudo and matsumoto, 2000) (<papid> W00-0730 </papid>kudo and matsumoto, 2001) <papid> N01-1025 </papid>as the svm training and test software.</citsent>
<aftsection>
<nextsent>the system uses polynomial kernel with degree 2; the cost per unit violation of the margin, c=1; and, tolerance of the termination criterion, e=0.001.
</nextsent>
<nextsent>table 1 shows the baseline performance numbers on the three tasks mentioned earlier; these results are based on syntactic features computed from hand-corrected tree bank (hence ldc hand-corrected) parses.for the argument identification and the combined identification and classification tasks, we report the precision (p), recall (r) and the f14 scores, and for the argument classification task we report the classification accuracy (a).
</nextsent>
<nextsent>this test set and all test sets, unless noted otherwise are section-23 of propbank.
</nextsent>
<nextsent>classes task r f1 (%) (%) (%) all id. 90.9 89.8 90.4 args classification - - - 87.9 id. + classification 83.3 78.5 80.8 core id. 94.7 90.1 92.3 args classification - - - 91.4 id. + classification 88.4 84.1 86.2 table 1: baseline performance on all three tasks using hand-corrected parses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4200">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> classifier and implementation.  </section>
<citcontext>
<prevsection>
<prevsent>all the nodes are classified directly as null or one of the arguments using the classifier trained in step 2 above.
</prevsent>
<prevsent>we observe no significant performance improvement even if we filter the most likely null nodes in first pass.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
for our experiments, we used tinysvm2 along with yamcha3 (kudo and matsumoto, 2000) (<papid> W00-0730 </papid>kudo and matsumoto, 2001) <papid> N01-1025 </papid>as the svm training and test software.</citsent>
<aftsection>
<nextsent>the system uses polynomial kernel with degree 2; the cost per unit violation of the margin, c=1; and, tolerance of the termination criterion, e=0.001.
</nextsent>
<nextsent>table 1 shows the baseline performance numbers on the three tasks mentioned earlier; these results are based on syntactic features computed from hand-corrected tree bank (hence ldc hand-corrected) parses.for the argument identification and the combined identification and classification tasks, we report the precision (p), recall (r) and the f14 scores, and for the argument classification task we report the classification accuracy (a).
</nextsent>
<nextsent>this test set and all test sets, unless noted otherwise are section-23 of propbank.
</nextsent>
<nextsent>classes task r f1 (%) (%) (%) all id. 90.9 89.8 90.4 args classification - - - 87.9 id. + classification 83.3 78.5 80.8 core id. 94.7 90.1 92.3 args classification - - - 91.4 id. + classification 88.4 84.1 86.2 table 1: baseline performance on all three tasks using hand-corrected parses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4206">
<title id=" N04-1030.xml">shallow semantic parsing using support vector machines </title>
<section> system improvements.  </section>
<citcontext>
<prevsection>
<prevsent>atively limited, any real world test set will contain predicates that have not been seen in training.in these cases, we can benefit from some information about the predicate by using predicate cluster as feature.
</prevsent>
<prevsent>the verbs were clustered into 64 classes using the probabilistic co-occurrence modelof hofmann and puzicha (1998).
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
the clustering algorithm uses database of verb-direct-object relations extracted by lin (1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>we then use the verb class of the current predicate as feature.
</nextsent>
<nextsent>4.
</nextsent>
<nextsent>partial path ? for the argument identification task,.
</nextsent>
<nextsent>path is the most salient feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4221">
<title id=" N04-4035.xml">prosody based topic segmentation for mandarin broadcast news </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this structure in turn guides the interpretation of individual utterances and the discourse as whole.
</prevsent>
<prevsent>formal written discourse signals hierarchical, tree-based discourse structure explicitly by the division of the text into chapters, sections, paragraphs, and sentences.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
this structure, in turn, identifies domains for in terpretation; many systems for anaphora resolution relyon some notion of locality (grosz and sidner, 1986).<papid> J86-3001 </papid></citsent>
<aftsection>
<nextsent>similarly, this structure represents topical organization,and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic.
</nextsent>
<nextsent>unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse.
</nextsent>
<nextsent>instead, one must infer the hierarchical structure of spoken discourse from other cues.
</nextsent>
<nextsent>prior research (nakatani et al, 1995; swerts, 1997) has shown that human label ers can more sharply, consistently, and confidently identify discourse structure in aword-level transcription when an original audio recording is available than they can on the basis of the transcribed text alone.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4222">
<title id=" N04-4035.xml">prosody based topic segmentation for mandarin broadcast news </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>not only is the use of prosodic cues to topic segmentation much less well-studied in general than is the use of text cues, but the use of prosodic cues has been largely limited to english and other european languages.
</prevsent>
<prevsent>most prior research on automatic topic segmentation hasbeen applied to clean text only and thus used textual features.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
text-based segmentation approaches have utilizedterm-based similarity measures computed across candidate segments (hearst, 1994) <papid> P94-1002 </papid>and also discourse markers to identify discourse structure (marcu, 2000).</citsent>
<aftsection>
<nextsent>the topic detection and tracking (tdt) evaluations focused on segmentation of both text and speech sources.
</nextsent>
<nextsent>this framework introduced new challenges in dealing with error ful automatic transcriptions as well as new opportunities to exploit cues in the original speech.
</nextsent>
<nextsent>themost successful approach (beeferman et al, 1999) produced automatic segment ations that yielded retrieval results comparable to those with manual segment ations, using text and silence features.
</nextsent>
<nextsent>(tur et al, 2001)<papid> J01-1002 </papid>applied both prosody-only and mixed text-prosody model to segmentation of tdt english broadcast news, with the best results combining text and prosodic features.(hirschberg and nakatani, 1998) also examined automatic topic segmentation based on prosodic cues, in the domain of english broadcast news.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4223">
<title id=" N04-4035.xml">prosody based topic segmentation for mandarin broadcast news </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this framework introduced new challenges in dealing with error ful automatic transcriptions as well as new opportunities to exploit cues in the original speech.
</prevsent>
<prevsent>themost successful approach (beeferman et al, 1999) produced automatic segment ations that yielded retrieval results comparable to those with manual segment ations, using text and silence features.
</prevsent>
</prevsection>
<citsent citstr=" J01-1002 ">
(tur et al, 2001)<papid> J01-1002 </papid>applied both prosody-only and mixed text-prosody model to segmentation of tdt english broadcast news, with the best results combining text and prosodic features.(hirschberg and nakatani, 1998) also examined automatic topic segmentation based on prosodic cues, in the domain of english broadcast news.</citsent>
<aftsection>
<nextsent>work in discourse analysis (nakatani et al, 1995; swerts, 1997) in both english and dutch has identified features such as changes in pitch range, intensity, and speaking rate associated with segment boundaries andwith boundaries of different strengths.
</nextsent>
<nextsent>they also demonstrated that access to acoustic cues improves the ease and quality of human labeling.
</nextsent>
<nextsent>in this paper we focus on topic segmentation in mandarin chinese broadcast news.
</nextsent>
<nextsent>mandarin chinese is tone language in which lexical identity is determined by pitch contour - or tone - associated with each syllable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4226">
<title id=" N06-2037.xml">selecting relevant text subsets from webdata for building topic specific language models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to estimate n-gram language model we require examples of in-domain transcribed utterances, which in absence of readily available relevant corpora have to be collected manually.
</prevsent>
<prevsent>this poses severe constraints in terms of both system turnaround time and cost.
</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
this led to growing interest in using the world wide web (www) as corpus for nlp (lapata, 2005; resnik and smith, 2003).<papid> J03-3002 </papid></citsent>
<aftsection>
<nextsent>the web can serve as good resource for automatically gathering datafor building task-specific language models.
</nextsent>
<nextsent>web pages of interest can be identified by generating query terms either manually or automatically from an initial set of in-domain sentences by measures such as tfidf or relative entropy (r.e).
</nextsent>
<nextsent>these web pages can then be converted to text corpus(which we will refer to as web-data) by appropriate preprocessing.
</nextsent>
<nextsent>however text gathered from the web will rarely fit the demands or the nature of the domain of interest completely.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4227">
<title id=" N06-1037.xml">exploring syntactic features for relation extraction using a convolution tree kernel </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(per) and the united states?
</prevsent>
<prevsent>(gpe: geo-political entity --- an entity with land and government (ace, 2004)).
</prevsent>
</prevsection>
<citsent citstr=" P04-3022 ">
prior feature-based methods for this task (kambhatla 2004; <papid> P04-3022 </papid>zhou et al, 2005) <papid> P05-1053 </papid>employed large amount of diverse linguistic features, varying from lexical knowledge, entity mention information to syntactic parse trees, dependency trees and semantic features.</citsent>
<aftsection>
<nextsent>since parse tree contains rich syntactic structure information, in principle, the features extracted from parse tree should contribute much more to performance improvement for relation extraction.
</nextsent>
<nextsent>however it is reported (zhou et al., 2005; <papid> P05-1053 </papid>kambhatla, 2004) <papid> P04-3022 </papid>that hierarchical structured syntactic features contributes less to performance improvement.</nextsent>
<nextsent>this may be mainly due to the fact that the syntactic structure information in parse tree is hard to explicitly describe by vector of linear features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4228">
<title id=" N06-1037.xml">exploring syntactic features for relation extraction using a convolution tree kernel </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(per) and the united states?
</prevsent>
<prevsent>(gpe: geo-political entity --- an entity with land and government (ace, 2004)).
</prevsent>
</prevsection>
<citsent citstr=" P05-1053 ">
prior feature-based methods for this task (kambhatla 2004; <papid> P04-3022 </papid>zhou et al, 2005) <papid> P05-1053 </papid>employed large amount of diverse linguistic features, varying from lexical knowledge, entity mention information to syntactic parse trees, dependency trees and semantic features.</citsent>
<aftsection>
<nextsent>since parse tree contains rich syntactic structure information, in principle, the features extracted from parse tree should contribute much more to performance improvement for relation extraction.
</nextsent>
<nextsent>however it is reported (zhou et al., 2005; <papid> P05-1053 </papid>kambhatla, 2004) <papid> P04-3022 </papid>that hierarchical structured syntactic features contributes less to performance improvement.</nextsent>
<nextsent>this may be mainly due to the fact that the syntactic structure information in parse tree is hard to explicitly describe by vector of linear features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4231">
<title id=" N06-1037.xml">exploring syntactic features for relation extraction using a convolution tree kernel </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this may be mainly due to the fact that the syntactic structure information in parse tree is hard to explicitly describe by vector of linear features.
</prevsent>
<prevsent>as an alternative, kernel methods (collins and duffy, 2001) provide an elegant solution to implicitly explore tree structure features by directly computing the similarity between two trees.
</prevsent>
</prevsection>
<citsent citstr=" H05-1091 ">
but to our surprise, the sole two-reported dependency tree kernels for relation extraction on the ace corpus (bunescu and mooney, 2005; <papid> H05-1091 </papid>culotta and sorensen, 2004) <papid> P04-1054 </papid>showed much lower performance than the feature-based methods.</citsent>
<aftsection>
<nextsent>one may ask: are the syntactic tree features very useful for relation extraction?
</nextsent>
<nextsent>can tree kernel methods effectively capture the syntactic tree features and other various features that have been proven useful in the feature-based methods?
</nextsent>
<nextsent>in this paper, we demonstrate the effectiveness of the syntactic tree features for relation extraction and study how to capture such features via convolution tree kernel.
</nextsent>
<nextsent>we also study how to select the optimal feature space (e.g. the set of sub-trees to represent relation instances) to optimize the system performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4233">
<title id=" N06-1037.xml">exploring syntactic features for relation extraction using a convolution tree kernel </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this may be mainly due to the fact that the syntactic structure information in parse tree is hard to explicitly describe by vector of linear features.
</prevsent>
<prevsent>as an alternative, kernel methods (collins and duffy, 2001) provide an elegant solution to implicitly explore tree structure features by directly computing the similarity between two trees.
</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
but to our surprise, the sole two-reported dependency tree kernels for relation extraction on the ace corpus (bunescu and mooney, 2005; <papid> H05-1091 </papid>culotta and sorensen, 2004) <papid> P04-1054 </papid>showed much lower performance than the feature-based methods.</citsent>
<aftsection>
<nextsent>one may ask: are the syntactic tree features very useful for relation extraction?
</nextsent>
<nextsent>can tree kernel methods effectively capture the syntactic tree features and other various features that have been proven useful in the feature-based methods?
</nextsent>
<nextsent>in this paper, we demonstrate the effectiveness of the syntactic tree features for relation extraction and study how to capture such features via convolution tree kernel.
</nextsent>
<nextsent>we also study how to select the optimal feature space (e.g. the set of sub-trees to represent relation instances) to optimize the system performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4241">
<title id=" N06-1037.xml">exploring syntactic features for relation extraction using a convolution tree kernel </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we conclude our work in section 5.
</prevsent>
<prevsent>the task of relation extraction was introduced as part of the template element task in muc6 and formulated as the template relation task in muc7 (muc, 1987-1998).
</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
miller et al (2000) <papid> A00-2030 </papid>address the task of relation extraction from the statistical parsing viewpoint.</citsent>
<aftsection>
<nextsent>they integrate various tasks such as pos tagging, ne tagging, template extraction and relation extraction into generative model.
</nextsent>
<nextsent>their results essentially depend on the entire full parse tree.
</nextsent>
<nextsent>kambhatla (2004) <papid> P04-3022 </papid>employs maximum entropy models to combine diverse lexical, syntactic and semantic features derived from the text for relation extraction.</nextsent>
<nextsent>zhou et al (2005) <papid> P05-1053 </papid>explore various features in relation extraction using svm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4270">
<title id=" N06-1037.xml">exploring syntactic features for relation extraction using a convolution tree kernel </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>culotta and sorensen (2004) <papid> P04-1054 </papid>generalize this kernel to estimate similarity between dependency trees.</prevsent>
<prevsent>one may note that their tree kernel requires the match able nodes must be at the same depth counting from the root node.</prevsent>
</prevsection>
<citsent citstr=" P05-1052 ">
this is strong constraint on the matching of syntax so it is not surprising that the model has good precision but very low recall on the ace corpus (zhao and grishman, 2005).<papid> P05-1052 </papid></citsent>
<aftsection>
<nextsent>in addition, according to the top-down node matching mechanism of the kernel, once node is not match able with any node in the same layer in another tree, all the sub-trees below this node are discarded even if some of them are match able to their counterparts in another tree.
</nextsent>
<nextsent>bunescu and mooney (2005) <papid> H05-1091 </papid>propose shortest path dependency kernel for relation extraction.</nextsent>
<nextsent>they argue that the information to model relationship between entities is typically captured by the shortest path between the two entities in the dependency graph.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4277">
<title id=" N06-1037.xml">exploring syntactic features for relation extraction using a convolution tree kernel </title>
<section> tree kernels for relation extraction.  </section>
<citcontext>
<prevsection>
<prevsent>that are the kernels for the decompositions (parts) of the objects.
</prevsent>
<prevsent>convolution kernels are abstract concepts, and the instances of them are determined by the definition of sub-kernels?.
</prevsent>
</prevsection>
<citsent citstr=" P03-1005 ">
the tree kernel (collins and duffy, 2001), string sub sequence kernel (ssk) (lodhi et al, 2002) and graph kernel (hdag kernel) (suzuki et al, 2003) <papid> P03-1005 </papid>are examples of convolution kernels instances in the nlp field.</citsent>
<aftsection>
<nextsent>(4) context-sensitive path tree (cpt): it is the pt extending with the 1st left sibling of the node of entity 1 and the 1st right sibling of the node of entity 2.
</nextsent>
<nextsent>if the sibling is unavailable, then we move to the parent of current node and repeat the same process until the sibling is available or the root is reached.
</nextsent>
<nextsent>(5) context-sensitive chunking tree (cct): it is the ct extending with the 1st left sibling of the node of entity 1 and the 1st right sibling of the node of entity 2.
</nextsent>
<nextsent>if the sibling is unavailable, the same process as generating the cpt is applied.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4278">
<title id=" N06-1037.xml">exploring syntactic features for relation extraction using a convolution tree kernel </title>
<section> tree kernels for relation extraction.  </section>
<citcontext>
<prevsection>
<prevsent>(per) and district?
</prevsent>
<prevsent>(gpe).
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
we use charniaks parser (charniak, 2001) <papid> P01-1017 </papid>to parse the example sentence.</citsent>
<aftsection>
<nextsent>due to space limitation, we do not show the whole parse tree of the entire sentence here.
</nextsent>
<nextsent>tree t1 in figure 1 is the mct of the relation instance example, where the sub-structure circled by dashed line is the pt.
</nextsent>
<nextsent>for clarity, we re-draw the pt as in t2.
</nextsent>
<nextsent>the only difference between the mct and the pt lies in that the mct does not allow the partial production rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4279">
<title id=" N06-1037.xml">exploring syntactic features for relation extraction using a convolution tree kernel </title>
<section> tree kernels for relation extraction.  </section>
<citcontext>
<prevsection>
<prevsent>we want to study if the eliminated small structures are noisy features for relation extraction.
</prevsent>
<prevsent>3.2 the convolution tree kernel.
</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
given the relation instances defined in the previous section, we use the same convolution tree kernel as the parse tree kernel (collins and duffy, 2001) and the semantic kernel (moschitti, 2004).<papid> P04-1043 </papid></citsent>
<aftsection>
<nextsent>generally, we can represent parse tree by vector of integer counts of each sub-tree type (regardless of its ancestors): ( )t? = (# of sub-trees of type 1, ?, # of subtrees of type i, ?, # of sub-trees of type n) this results in very high dimensionality since the number of different sub-trees is exponential in its size.
</nextsent>
<nextsent>thus it is computational infeasible to directly use the feature vector ( )t? . to solve the compu t1): mct t2): pt t3): ct t4):cpt t5):cct t6):fpt t7):fcpt figure 1.
</nextsent>
<nextsent>relation feature spaces of the example sentence ???
</nextsent>
<nextsent>to stop the merger of an estimated 2000 ethnic tutsi in the district of tawba.?, where the phrase type e1-o-per?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4312">
<title id=" N07-1059.xml">automatic assessment of student translations for foreign language tutoring </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>both english and chinese grammars are needed to analyze the source and target sides of each translation pair.
</prevsent>
<prevsent>the grammars have been carefully constructed so that meaning representations derived from both languages are as similar as feasible.
</prevsent>
</prevsection>
<citsent citstr=" J92-1004 ">
we utilized parser (seneff, 1992) <papid> J92-1004 </papid>that is basedon an enhanced probabilistic context-free grammar (pcfg), which captures dependencies beyond context-free rules by conditioning on the external left-context parse categories when predicting the first child of each parent node.</citsent>
<aftsection>
<nextsent>while we use specific grammar for analyzing flight domain sentences, we emphasize domain portability of the grammar by using mainly syntactic information in the majority of the parse tree rules.
</nextsent>
<nextsent>semantics are introduced near the terminals, mostly involving adjectives, verbs, nouns and proper noun classes.
</nextsent>
<nextsent>rules for general semantic concepts such as dates and times are organized into sub-grammars that are easily embedded into any domain.
</nextsent>
<nextsent>we have successfully applied the same strategy in developing both the chinese and english grammars.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4313">
<title id=" N06-1040.xml">probabilistic context free grammar induction based on structural zeros </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>that algorithm has complexity o(n3|p |), where is the length in words of the sentence parsed, and |p | isthe number of grammar productions.
</prevsent>
<prevsent>grammar nonterminals can be split to encode richer dependencies in stochastic model and improve parsing accuracy.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
for example, the parent of the left-hand side (lhs) can be annotated onto the label of the lhs category (johnson, 1998), <papid> J98-4004 </papid>hence differentiating, for instance, between expansions of vp with parent and parent vp.</citsent>
<aftsection>
<nextsent>such annotations, however, tend to substantially increase the number of grammar productions as well as the ambiguity of the grammar,thereby significantly slowing down the parsing algorithm.
</nextsent>
<nextsent>in the case of bilexical grammars, where categories in binary grammars are annotated with their lexical heads, the grammar factor contributes an additional o(n2|vd|3) complexity, leading to an over all o(n5|vd|3) parsing complexity, where |vd| is the number of delexicalized non-terminals (eisner,1997).
</nextsent>
<nextsent>even with special modifications to the basic cyk algorithm, such as those presented by eisner and satta (1999), <papid> P99-1059 </papid>improvements to the stochastic model are obtained at the expense of efficiency.</nextsent>
<nextsent>in addition to the significant cost in efficiency,increasing the non-terminal set impacts parameter estimation for the stochastic model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4314">
<title id=" N06-1040.xml">probabilistic context free grammar induction based on structural zeros </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such annotations, however, tend to substantially increase the number of grammar productions as well as the ambiguity of the grammar,thereby significantly slowing down the parsing algorithm.
</prevsent>
<prevsent>in the case of bilexical grammars, where categories in binary grammars are annotated with their lexical heads, the grammar factor contributes an additional o(n2|vd|3) complexity, leading to an over all o(n5|vd|3) parsing complexity, where |vd| is the number of delexicalized non-terminals (eisner,1997).
</prevsent>
</prevsection>
<citsent citstr=" P99-1059 ">
even with special modifications to the basic cyk algorithm, such as those presented by eisner and satta (1999), <papid> P99-1059 </papid>improvements to the stochastic model are obtained at the expense of efficiency.</citsent>
<aftsection>
<nextsent>in addition to the significant cost in efficiency,increasing the non-terminal set impacts parameter estimation for the stochastic model.
</nextsent>
<nextsent>with more productions, much fewer observations per production are available and one is left with the hope that subsequent smoothing technique can effectively deal with this problem, regardless of the number of non-terminals created.
</nextsent>
<nextsent>klein and manning (2003<papid> P03-1054 </papid>b) showed that, by making certain linguistically-motivated node label annotations, but avoiding certain other kinds of state splits (mainlylexical annotations) models of relatively high accuracy can be built without resorting to smoothing.the resulting grammars were small enough to allow for exhaustive cyk parsing; even so, parsing speed was significantly impacted by the state splits: the test-set parsing time reported was about 3s for average length sentences, with memory usage of 1gb.this paper presents an automatic method forde ciding which state to split in order to create concise and accurate un smoothed probabilistic context-free grammars (pcfgs) for efficient use in early stages of multi-stage parsing technique.</nextsent>
<nextsent>the method is based on the use of statistical tests to determine if non-terminal combination is unobserved due to the limited size of the sample (sampling zero) or because it is grammatically impossible (structural zero).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4315">
<title id=" N06-1040.xml">probabilistic context free grammar induction based on structural zeros </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition to the significant cost in efficiency,increasing the non-terminal set impacts parameter estimation for the stochastic model.
</prevsent>
<prevsent>with more productions, much fewer observations per production are available and one is left with the hope that subsequent smoothing technique can effectively deal with this problem, regardless of the number of non-terminals created.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
klein and manning (2003<papid> P03-1054 </papid>b) showed that, by making certain linguistically-motivated node label annotations, but avoiding certain other kinds of state splits (mainlylexical annotations) models of relatively high accuracy can be built without resorting to smoothing.the resulting grammars were small enough to allow for exhaustive cyk parsing; even so, parsing speed was significantly impacted by the state splits: the test-set parsing time reported was about 3s for average length sentences, with memory usage of 1gb.this paper presents an automatic method forde ciding which state to split in order to create concise and accurate un smoothed probabilistic context-free grammars (pcfgs) for efficient use in early stages of multi-stage parsing technique.</citsent>
<aftsection>
<nextsent>the method is based on the use of statistical tests to determine if non-terminal combination is unobserved due to the limited size of the sample (sampling zero) or because it is grammatically impossible (structural zero).
</nextsent>
<nextsent>this helps introduce relatively small number of new non-terminals with little additional parsing 312 np    @ pp dt jj nn nns np   hh dt np:jj+nn+nns   h jj np:nn+nns  hh nn nns np  hh dt np:jj+nn   h jj np:nn+nns  hh nn nns np  hh dt np:jj  hh jj np:nn  hh nn nns np  hh dt np:  hh jj np:  hh nn nns (a) (b) (c) (d) (e)figure 1: five representations of an n-ary production, = 4.
</nextsent>
<nextsent>(a) original production (b) right-factored production (c) right factored markov order-2 (d) right-factored markov order-1 (e) right-factored markov order-0 overhead.
</nextsent>
<nextsent>experimental results show that, using this method, high accuracies can be achieved with orders of magnitude fewer non-terminals than in typically induced pcfgs, leading to substantial speed-ups inparsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4317">
<title id=" N06-1040.xml">probabilistic context free grammar induction based on structural zeros </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>section 2 gives brief description of pcfg induction from treebanks, including non-terminal label-splitting, factor ization, and relative frequency estimation.
</prevsent>
<prevsent>section 3 discusses the statistical criteria that we explored to determine structural zeros andthus select non-terminals for the factored pcfg.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
finally, section 4 reports the results of parsing experiments using our exhaustive k-best cyk parser withthe concise pcfgs induced from the penn wsj tree bank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>a context-free grammar = (v, t, s?, ), or cfg in short, consists of set of non-terminal symbols , set of terminal symbols , start symbol s?
</nextsent>
<nextsent>v , and set of production of the form: ? ?, where ? and ? ?
</nextsent>
<nextsent>(v ? )?.
</nextsent>
<nextsent>a pcfg is cfg with probability assigned to each production.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4318">
<title id=" N06-1040.xml">probabilistic context free grammar induction based on structural zeros </title>
<section> grammar induction.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 smoothing and factorization.
</prevsent>
<prevsent>pcfgs induced from the penn treebank have many productions with long sequences of non-terminals on the rhs.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
probability estimates of the rhs given the lhs are often smoothed by making markov assumption regarding the conditional independence of category on those more than categories away (collins, 1997; <papid> P97-1003 </papid>charniak, 2000): <papid> A00-2018 </papid>p(x ? y1...yn)= p(y1|x) ny i=2 p(yi|x,y1 ? ?</citsent>
<aftsection>
<nextsent>yi1) ? p(y1|x) ny i=2 p(yi|x,yik ? ?
</nextsent>
<nextsent>yi1).making such markov assumption is closely related to grammar transformations required for certain efficient parsing algorithms.
</nextsent>
<nextsent>for example, the cyk parsing algorithm takes as input chomsky normal form pcfg, i.e., grammar where all productions are of the form ? z or ? a,where , , and are non-terminals and a terminal symbol.1.
</nextsent>
<nextsent>binarized pcfgs are induced from treebank whose trees have been factored so that n-ary productions with 2 become sequences ofn1 binary productions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4319">
<title id=" N06-1040.xml">probabilistic context free grammar induction based on structural zeros </title>
<section> grammar induction.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 smoothing and factorization.
</prevsent>
<prevsent>pcfgs induced from the penn treebank have many productions with long sequences of non-terminals on the rhs.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
probability estimates of the rhs given the lhs are often smoothed by making markov assumption regarding the conditional independence of category on those more than categories away (collins, 1997; <papid> P97-1003 </papid>charniak, 2000): <papid> A00-2018 </papid>p(x ? y1...yn)= p(y1|x) ny i=2 p(yi|x,y1 ? ?</citsent>
<aftsection>
<nextsent>yi1) ? p(y1|x) ny i=2 p(yi|x,yik ? ?
</nextsent>
<nextsent>yi1).making such markov assumption is closely related to grammar transformations required for certain efficient parsing algorithms.
</nextsent>
<nextsent>for example, the cyk parsing algorithm takes as input chomsky normal form pcfg, i.e., grammar where all productions are of the form ? z or ? a,where , , and are non-terminals and a terminal symbol.1.
</nextsent>
<nextsent>binarized pcfgs are induced from treebank whose trees have been factored so that n-ary productions with 2 become sequences ofn1 binary productions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4322">
<title id=" N06-1040.xml">probabilistic context free grammar induction based on structural zeros </title>
<section> grammar induction.  </section>
<citcontext>
<prevsection>
<prevsent>with markov factor ization of orders 2, 1 and 0 we get non-terminal sets of size 2492, 564, and 99, and rule production sets of 11659, 6354, and 3803, respectively.
</prevsent>
<prevsent>these reductions in the size of the non-terminal set from the original factored grammar result in an order of magnitude reduction in complexity of thecyk algorithm.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
one common strategy in statistical parsing is what can be termed an approximate coarse-to-fine approach: simple pcfg is used to prune the search space to which richer and more complex models are applied subsequently (charniak, 2000; <papid> A00-2018 </papid>charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>producing coarse?
</nextsent>
<nextsent>chart as efficiently as possible is thus crucial (charniak et al, 1998; <papid> W98-1115 </papid>blaheta and charniak,1999), <papid> P99-1066 </papid>making these factorizations particularly use ful.</nextsent>
<nextsent>2.2 cyk parser and baselines.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4323">
<title id=" N06-1040.xml">probabilistic context free grammar induction based on structural zeros </title>
<section> grammar induction.  </section>
<citcontext>
<prevsection>
<prevsent>one common strategy in statistical parsing is what can be termed an approximate coarse-to-fine approach: simple pcfg is used to prune the search space to which richer and more complex models are applied subsequently (charniak, 2000; <papid> A00-2018 </papid>charniak and johnson, 2005).<papid> P05-1022 </papid></prevsent>
<prevsent>producing coarse?</prevsent>
</prevsection>
<citsent citstr=" W98-1115 ">
chart as efficiently as possible is thus crucial (charniak et al, 1998; <papid> W98-1115 </papid>blaheta and charniak,1999), <papid> P99-1066 </papid>making these factorizations particularly use ful.</citsent>
<aftsection>
<nextsent>2.2 cyk parser and baselines.
</nextsent>
<nextsent>to illustrate the importance of this reduction in nonterminals for efficient parsing, we will present base line parsing results for development set.
</nextsent>
<nextsent>for these baseline trials, we trained pcfg on sections 2-21 of the penn wsj treebank (40k sentences, 936k words), and evaluated on section 24 (1346 sentences, 32k words).
</nextsent>
<nextsent>the parser takes as input the weighted k-best pos-tag sequences of final nns depends on the preceding nn, despite the markov order-0 factorization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4325">
<title id=" N06-1040.xml">probabilistic context free grammar induction based on structural zeros </title>
<section> grammar induction.  </section>
<citcontext>
<prevsection>
<prevsent>one common strategy in statistical parsing is what can be termed an approximate coarse-to-fine approach: simple pcfg is used to prune the search space to which richer and more complex models are applied subsequently (charniak, 2000; <papid> A00-2018 </papid>charniak and johnson, 2005).<papid> P05-1022 </papid></prevsent>
<prevsent>producing coarse?</prevsent>
</prevsection>
<citsent citstr=" P99-1066 ">
chart as efficiently as possible is thus crucial (charniak et al, 1998; <papid> W98-1115 </papid>blaheta and charniak,1999), <papid> P99-1066 </papid>making these factorizations particularly use ful.</citsent>
<aftsection>
<nextsent>2.2 cyk parser and baselines.
</nextsent>
<nextsent>to illustrate the importance of this reduction in nonterminals for efficient parsing, we will present base line parsing results for development set.
</nextsent>
<nextsent>for these baseline trials, we trained pcfg on sections 2-21 of the penn wsj treebank (40k sentences, 936k words), and evaluated on section 24 (1346 sentences, 32k words).
</nextsent>
<nextsent>the parser takes as input the weighted k-best pos-tag sequences of final nns depends on the preceding nn, despite the markov order-0 factorization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4326">
<title id=" N06-1040.xml">probabilistic context free grammar induction based on structural zeros </title>
<section> grammar induction.  </section>
<citcontext>
<prevsection>
<prevsent>the parser takes as input the weighted k-best pos-tag sequences of final nns depends on the preceding nn, despite the markov order-0 factorization.
</prevsent>
<prevsent>because of our focus on efficient cyk,we accept these higher order dependencies rather than producing unary productions.
</prevsent>
</prevsection>
<citsent citstr=" H05-1099 ">
only n-ary rules 2 are factored.perceptron-trained tagger, using the tagger documented in hollingshead et al (2005).<papid> H05-1099 </papid></citsent>
<aftsection>
<nextsent>the number of tagger candidates for all trials reported in this paper was 0.2n, where is the length of the string.from the weighted k-best list, we derive conditional probability of each tag at position by taking the sum of the exponential of the weights of all candidates with that tag at position (softmax).
</nextsent>
<nextsent>the parser is an exhaustive cyk parser that takes advantage of the fact that, with the grammar fac tor ization method described, factored non-terminalscan only occur as the second child of binary production.
</nextsent>
<nextsent>since the bulk of the non-terminals result from factor ization, this greatly reduces the number of possible combinations given any two cells.
</nextsent>
<nextsent>when parsing with parent-annotated grammar, we use version of the parser that also takes advantage of the partitioning of the non-terminal set, i.e., the fact thatany given non-terminal has already its parent indicated in its label, precluding combination with anynon-terminal that does not have the same parent an notated.table 1 shows baseline results for standard right factor ization and factor ization with markov orders0-2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4328">
<title id=" N06-1040.xml">probabilistic context free grammar induction based on structural zeros </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the non-factored splits provide substantial accuracy improvements at relatively small efficiency cost.table 3 shows the 1-best and reranked 50-best results for the baseline markov order-2 model, andthe best-performing model using factored and non factored non-terminal splits.
</prevsent>
<prevsent>we present the efficiency of the model in terms of words-per-second over the entire dev set, including the longer strings (maximum length 116 words)5.
</prevsent>
</prevsection>
<citsent citstr=" W05-1506 ">
we used the k-best decoding algorithm of huang and chiang (2005)<papid> W05-1506 </papid>with our cyk parser, using on-demand k-best back pointer calculation.</citsent>
<aftsection>
<nextsent>we then trained maxentreranker on sections 2-21, using the approach outlined in charniak and johnson (2005), <papid> P05-1022 </papid>via the publicly available reranking code from that paper.6 weused the default features that come with that pack age.</nextsent>
<nextsent>the processing time in the table includes the time to parse and rerank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4338">
<title id=" N06-1045.xml">a better nbest list practical determinization of weighted finite tree automata </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are, however, also capable of producing lists of runners-up, and such lists have many practical uses: the lists may be inspected to determine the quality of runners-up and motivate model changes.
</prevsent>
<prevsent>the lists may be re-ranked with extra knowledge sources that are difficult to apply during the main search.
</prevsent>
</prevsection>
<citsent citstr=" P04-1015 ">
the lists may be used with annotation and tuning process, such as in (collins and roark, 2004), <papid> P04-1015 </papid>to iteratively alter feature weights and improve results.</citsent>
<aftsection>
<nextsent>figure 1 shows the best 10 english translation parse trees obtained from syntax-based translation system based on (galley, et. al., 2004).<papid> N04-1035 </papid></nextsent>
<nextsent>notice that the same tree occurs multiple times in this list.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4339">
<title id=" N06-1045.xml">a better nbest list practical determinization of weighted finite tree automata </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the lists may be re-ranked with extra knowledge sources that are difficult to apply during the main search.
</prevsent>
<prevsent>the lists may be used with annotation and tuning process, such as in (collins and roark, 2004), <papid> P04-1015 </papid>to iteratively alter feature weights and improve results.</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
figure 1 shows the best 10 english translation parse trees obtained from syntax-based translation system based on (galley, et. al., 2004).<papid> N04-1035 </papid></citsent>
<aftsection>
<nextsent>notice that the same tree occurs multiple times in this list.
</nextsent>
<nextsent>this repetition is quite characteristic of the output of ranked lists.
</nextsent>
<nextsent>it occurs because many systems, such as the ones proposed by (bod, 1992), (<papid> C92-3126 </papid>galley, et. al., 2004), <papid> N04-1035 </papid>and (langkilde and knight, 1998) <papid> W98-1426 </papid>represent their result space in terms of weighted partial results of various sizes that may be assembled in multipleways.</nextsent>
<nextsent>there is in general more than one way to assemble the partial results to derive the same complete result.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4340">
<title id=" N06-1045.xml">a better nbest list practical determinization of weighted finite tree automata </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>notice that the same tree occurs multiple times in this list.
</prevsent>
<prevsent>this repetition is quite characteristic of the output of ranked lists.
</prevsent>
</prevsection>
<citsent citstr=" C92-3126 ">
it occurs because many systems, such as the ones proposed by (bod, 1992), (<papid> C92-3126 </papid>galley, et. al., 2004), <papid> N04-1035 </papid>and (langkilde and knight, 1998) <papid> W98-1426 </papid>represent their result space in terms of weighted partial results of various sizes that may be assembled in multipleways.</citsent>
<aftsection>
<nextsent>there is in general more than one way to assemble the partial results to derive the same complete result.
</nextsent>
<nextsent>thus, the -best list of results is really an -best list of derivations.
</nextsent>
<nextsent>when list-based tasks, such as the ones mentioned above, take as input the top results for some constant , the effect of repetition on these tasks is deleterious.
</nextsent>
<nextsent>a list with many repetitions suffers from lack of useful information, hampering diagnostics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4342">
<title id=" N06-1045.xml">a better nbest list practical determinization of weighted finite tree automata </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>notice that the same tree occurs multiple times in this list.
</prevsent>
<prevsent>this repetition is quite characteristic of the output of ranked lists.
</prevsent>
</prevsection>
<citsent citstr=" W98-1426 ">
it occurs because many systems, such as the ones proposed by (bod, 1992), (<papid> C92-3126 </papid>galley, et. al., 2004), <papid> N04-1035 </papid>and (langkilde and knight, 1998) <papid> W98-1426 </papid>represent their result space in terms of weighted partial results of various sizes that may be assembled in multipleways.</citsent>
<aftsection>
<nextsent>there is in general more than one way to assemble the partial results to derive the same complete result.
</nextsent>
<nextsent>thus, the -best list of results is really an -best list of derivations.
</nextsent>
<nextsent>when list-based tasks, such as the ones mentioned above, take as input the top results for some constant , the effect of repetition on these tasks is deleterious.
</nextsent>
<nextsent>a list with many repetitions suffers from lack of useful information, hampering diagnostics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4343">
<title id=" N06-1045.xml">a better nbest list practical determinization of weighted finite tree automata </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and list of fewer unique trees than expected can cause over fitting when this list is used to tune.
</prevsent>
<prevsent>furthermore, the actual weight of obtaining any particular tree is split among its repetitions, distorting the actual relative weights between trees.
</prevsent>
</prevsection>
<citsent citstr=" J97-2003 ">
(mohri, 1997)<papid> J97-2003 </papid>encountered this problem in speech recognition, and presented solution to the problem of repetition in -best lists of strings that are derived from finite-state automata.</citsent>
<aftsection>
<nextsent>that work described way to use power set construction along 351 34.73: s(np-c(npb(dt(this) nns(cases))) vp(vbd(had) vp-c(vbn(caused) np-c(npb(dt(the) jj(american) nns(protests))))) .(.)) 34.74: s(np-c(npb(dt(this) nns(cases))) vp(vbd(had) vp-c(vbn(aroused) np-c(npb(dt(the) jj(american) nns(protests))))) .(.)) 34.83: s(np-c(npb(dt(this) nns(cases))) vp(vbd(had) vp-c(vbn(caused) np-c(npb(dt(the) jj(american) nns(protests))))) .(.)) 34.83: s(np-c(npb(dt(this) nns(cases))) vp(vbd(had) vp-c(vbn(aroused) np-c(npb(dt(the) jj(american) nns(protests))))) .(.)) 34.84: s(np-c(npb(dt(this) nns(cases))) vp(vbd(had) vp-c(vbn(caused) np-c(npb(dt(the) jj(american) nns(protests))))) .(.)) 34.85: s(np-c(npb(dt(this) nns(cases))) vp(vbd(had) vp-c(vbn(caused) np-c(npb(dt(the) jj(american) nns(protests))))) .(.)) 34.85: s(np-c(npb(dt(this) nns(cases))) vp(vbd(had) vp-c(vbn(aroused) np-c(npb(dt(the) jj(american) nns(protests))))) .(.)) 34.85: s(np-c(npb(dt(this) nns(cases))) vp(vbd(had) vp-c(vbn(aroused) np-c(npb(dt(the) jj(american) nns(protests))))) .(.)) 34.87: s(np-c(npb(dt(this) nns(cases))) vp(vbd(had) vp-c(vb(arouse) np-c(npb(dt(the) jj(american) nns(protests))))) .(.)) 34.92: s(np-c(npb(dt(this) nns(cases))) vp(vbd(had) vp-c(vbn(aroused) np-c(npb(dt(the) jj(american) nns(protests))))) .(.)) figure 1: ranked list of machine translation results with repeated trees.
</nextsent>
<nextsent>scores shown are negative logs of calculated weights, thus lower score indicates higher weight.
</nextsent>
<nextsent>the bulleted sentences indicate identical trees.with an innovative bookkeeping system to deter minize the automaton, resulting in an automaton that preserves the language but provides single, properly weighted derivation for each string in it.
</nextsent>
<nextsent>put an other way, if the input automaton has the ability to generate the same string with different weights, the output automaton generates that string with weight equal to the sum of all of the generations of that string in the input automaton.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4346">
<title id=" N06-1045.xml">a better nbest list practical determinization of weighted finite tree automata </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>inthe world of automata these grammars have as natural dual the finite tree recognizer (doner, 1970).
</prevsent>
<prevsent>like tree grammars and packed forests, they are compact ways of representing very large sets oftrees.
</prevsent>
</prevsection>
<citsent citstr=" W05-1506 ">
we will present an algorithm for determinizing weighted finite tree recognizers, and use variant of the procedure found in (huang and chiang, 2005) <papid> W05-1506 </papid>to obtain -best lists of trees that are weighted correctly and contain no repetition.</citsent>
<aftsection>
<nextsent>section 2 describes related work.
</nextsent>
<nextsent>in section 3, we introduce the formalisms of tree automata, specifically the tree-to-weight transducer.
</nextsent>
<nextsent>in section 4, we present the algorithm.
</nextsent>
<nextsent>finally, in section 5 we show the results of applying weighted determinization to recognizers obtained from the packed forest output of two natural language tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4355">
<title id=" N06-1045.xml">a better nbest list practical determinization of weighted finite tree automata </title>
<section> empirical studies.  </section>
<citcontext>
<prevsection>
<prevsent>we obtain packed-forest english outputs from 116short chinese sentences computed by string-to tree machine translation system based on (galley,et. al., 2004).<papid> N04-1035 </papid></prevsent>
<prevsent>the system is trained on all chinese english parallel data available from the linguistic data consortium.</prevsent>
</prevsection>
<citsent citstr=" P05-3025 ">
the decoder for this system is cky algorithm that negotiates the space described in (deneefe, et. al., 2005).<papid> P05-3025 </papid></citsent>
<aftsection>
<nextsent>no language model was used in this experiment.the forests contain median of english parse trees each.
</nextsent>
<nextsent>we remove cycles from each 355 algorithm 1: weighted determinization of tree automata input: bottom-up tree-to-weight transducer . output: sub sequential bottom-up tree-to-weight transducer . begin1 2 3 priority queue4 5 6 enqueue7 while do8 head9 v10 for each such that do11 if such that then12 s.t.13 14 for each such that do15 v16 v v s.t.17 v v18 /* rank returns the largest hyperedge size that can leave state . combinations returns all possible vectors of length containing members of and at least one member of . */ if is new state then19 for each combinations v rank do 20 if is new vector then21 enqueue u22 v23 dequeue24 end25forest,3 apply our determinization algorithm, and extract the -best trees using variant of (huang and chiang, 2005).<papid> W05-1506 </papid></nextsent>
<nextsent>the effects of weighted determinization on an -best list are obvious to casual inspec tion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4359">
<title id=" N06-1045.xml">a better nbest list practical determinization of weighted finite tree automata </title>
<section> empirical studies.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 data-oriented parsing.
</prevsent>
<prevsent>weighted determinization of tree automata is also useful for parsing.
</prevsent>
</prevsection>
<citsent citstr=" E03-1005 ">
data-oriented parsing (dop)s methodology is to calculate weighted derivations, but as noted in (bod, 2003), <papid> E03-1005 </papid>it is the highest ranking parse, not derivation, that is desired.</citsent>
<aftsection>
<nextsent>since (simaan, 1996) showed that finding the highest ranking parse is an np-complete problem, it has been common to estimate the highest ranking parse by the previously method recall precision f-measure undeterminized 80.23 80.18 80.20 top-500 crunching?
</nextsent>
<nextsent>80.48 80.29 80.39 determinized 81.09 79.72 80.40 figure 8: recall, precision, and f-measure result son dop-style parsing of section 23 of the penn tree bank.
</nextsent>
<nextsent>the use of best derivation (undeterminized),estimate of best tree (top-500), and true best tree (de terminized) for selection of parse output is shown.
</nextsent>
<nextsent>described crunching?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4360">
<title id=" N06-2046.xml">improved affinity graph based multi document summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a variety of multi-document summarization methods have been developed recently.
</prevsent>
<prevsent>in this study, we focus on extractive summarization, which involves assigning saliency scores to some units (e.g. sentences, paragraphs) of the documents and extracting tke sentences with highest scores.
</prevsent>
</prevsection>
<citsent citstr=" P02-1058 ">
mead is an implementation of the centroid-based method (radev et al, 2004) that scores sentences based on sentence-level and inter-sentence features, including cluster centro ids, position, tf*idf, etc. neats (lin and hovy, 2002) <papid> P02-1058 </papid>selects important content using vent ence position, term frequency, topic signature and term clustering, and then uses mmr (goldstein et al, 1999) to remove redun dancy.</citsent>
<aftsection>
<nextsent>xdox (hardy et al, 1998) identifies the most salient themes within the set by passage clustering and then composes an extraction summary, which reflects these main themes.
</nextsent>
<nextsent>harabagiu and lacatusu (2005) investigate different topic representations and extraction methods. graph-based methods have been proposed to rank sentences or passages.
</nextsent>
<nextsent>websumm (mani and bloedorn, 2000) uses graph-connectivity model and operates under the assumption that nodes which are connected to many other nodes are likely to carry salient information.
</nextsent>
<nextsent>lexpagerank (erkan and radev, 2004) <papid> W04-3247 </papid>is an approach for computing sentence importance based on the concept of ei gen vector centrality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4361">
<title id=" N06-2046.xml">improved affinity graph based multi document summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>harabagiu and lacatusu (2005) investigate different topic representations and extraction methods. graph-based methods have been proposed to rank sentences or passages.
</prevsent>
<prevsent>websumm (mani and bloedorn, 2000) uses graph-connectivity model and operates under the assumption that nodes which are connected to many other nodes are likely to carry salient information.
</prevsent>
</prevsection>
<citsent citstr=" W04-3247 ">
lexpagerank (erkan and radev, 2004) <papid> W04-3247 </papid>is an approach for computing sentence importance based on the concept of ei gen vector centrality.</citsent>
<aftsection>
<nextsent>mihalcea and tarau (2005) <papid> I05-2004 </papid>also propose similar algorithms based on pager ank and hits to compute sentence importance for document summarization.</nextsent>
<nextsent>in this study, we extend the above graph-based works by proposing an integrated framework for considering both information richness and information novelty of sentence based on sentence affinity graph.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4362">
<title id=" N06-2046.xml">improved affinity graph based multi document summarization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>websumm (mani and bloedorn, 2000) uses graph-connectivity model and operates under the assumption that nodes which are connected to many other nodes are likely to carry salient information.
</prevsent>
<prevsent>lexpagerank (erkan and radev, 2004) <papid> W04-3247 </papid>is an approach for computing sentence importance based on the concept of ei gen vector centrality.</prevsent>
</prevsection>
<citsent citstr=" I05-2004 ">
mihalcea and tarau (2005) <papid> I05-2004 </papid>also propose similar algorithms based on pager ank and hits to compute sentence importance for document summarization.</citsent>
<aftsection>
<nextsent>in this study, we extend the above graph-based works by proposing an integrated framework for considering both information richness and information novelty of sentence based on sentence affinity graph.
</nextsent>
<nextsent>first, diffusion process is imposed on sentence affinity graph in order to make the affinity graph reflect true semantic relationships between sentences.
</nextsent>
<nextsent>second, intra-document links and inter-document links between sentences are differentiated to attach more importance to inter document links for sentence information richness computation.
</nextsent>
<nextsent>lastly, diversity penalty process is imposed on sentences to penalize redundant sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4363">
<title id=" N06-2046.xml">improved affinity graph based multi document summarization </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>after the affinity rank scores are obtained for all sentences, the sentences with highest affinity rank scores are chosen to produce the summary according to the summary length limit.
</prevsent>
<prevsent>we compare our system with top 3 performing systems and two baseline systems on task 2 of duc 2002 and task 4 of duc 2004 respectively.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
rouge (lin and hovy, 2003) <papid> N03-1020 </papid>metrics is used forevaluation1 and we mainly concern about rouge 1.</citsent>
<aftsection>
<nextsent>the parameters of our system are tuned on duc.
</nextsent>
<nextsent>2001 as follows: ?=7, ?=0.3 and ?=1.we can see from the tables that our system outperforms the top performing systems and baseline systems on both duc 2002 and duc 2004 tasks over all three metrics.
</nextsent>
<nextsent>the performance improvement achieved by our system results from threefactors: diversity penalty imposition, intra document and inter-document link differentiation and diffusion process incorporation.
</nextsent>
<nextsent>the rouge 1 contributions of the above three factors are 0.02200, 0.00268 and 0.00043 respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4364">
<title id=" N06-1001.xml">capitalizing machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments carried out onthree language pairs and variety of experiment conditions show that our model significantly outperforms strong monolingual capitalization model baseline, especially when working with small datasets and/or european language pairs.
</prevsent>
<prevsent>capitalization is the process of recovering case information for texts in lowercase.
</prevsent>
</prevsection>
<citsent citstr=" P03-1020 ">
it is also called true casing (lita et al, 2003).<papid> P03-1020 </papid></citsent>
<aftsection>
<nextsent>usually, capitalization itself tries to improve the legibility of texts.
</nextsent>
<nextsent>it, however, can affect the word choice or order when interacting with other models.
</nextsent>
<nextsent>in natural language processing, good capitalization model has been shown useful for tasks like name entity recognition, automatic content extraction, speech recognition, modern word processors, and machine translation (mt).capitalization can be viewed as sequence labeling process.
</nextsent>
<nextsent>the input to this process is sentence in lowercase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4367">
<title id=" N06-1001.xml">capitalizing machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>into click iu ok au to al save al your al changes al to al /home/doc mx . an?, getting the surface form click ok to save your changes to /home/doc .?.a capitalizer is tagger that recovers the capitalization tag for each input lower cased word, out putting well-capitalized sentence.
</prevsent>
<prevsent>since each lower cased word can have more than one tag, and associating tag with lower cased word can result in more than one surface form (e.g., /home/doc mx can be either /home/doc or /home/doc), we need acapitalization model to solve the capitalization ambiguities.
</prevsent>
</prevsection>
<citsent citstr=" W04-3237 ">
for example, lita et al (2003) <papid> P03-1020 </papid>use trigram language model estimated from corpus with case information; chelba and acero (2004) <papid> W04-3237 </papid>use amaximum entropy markov model (memm) combining features involving words and their cases.capitalization models presented in most previous approaches are monolingual because the models are estimated only from monolingual texts.</citsent>
<aftsection>
<nextsent>how ever, for capitalizing machine translation outputs, using only monolingual capitalization models is not enough.
</nextsent>
<nextsent>for example, if the sentence click ok to save your changes to /home/doc .?
</nextsent>
<nextsent>in the above example is the translation of the french sentencecliquez sur ok pour enregistrer vos modifications dans /home/doc .?, the correct capitalization result should probably be click ok to save your changes to /home/doc .?, where all words are in all upper-case.
</nextsent>
<nextsent>without looking into the case 1of the mt input, we can hardly get the correct capitalization result.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4375">
<title id=" N06-1001.xml">capitalizing machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>ercased sentence e, they find the label sequence tthat maximizes p(t |e).
</prevsent>
<prevsent>they use maximum entropy markov model (memm) to combine features of words, cases and context (i.e., tag transitions).gale et al (1994) report good results on capitalizing 100 words.
</prevsent>
</prevsection>
<citsent citstr=" P99-1021 ">
mikheev (1999) <papid> P99-1021 </papid>performs capitalization using simple positional heuristics.</citsent>
<aftsection>
<nextsent>translation and capitalization are usually performed in two successive steps because removing case information from the training of translation models substantially reduces both the source and target vocabulary sizes.
</nextsent>
<nextsent>smaller vocabularies lead to smaller translation model with fewer parameters to learn.for example, if we do not remove the case information, we will have to deal with at least nine probabilities for the english-french word pair (click, cliquez).
</nextsent>
<nextsent>this is because either click?
</nextsent>
<nextsent>or cliquez?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4376">
<title id=" N06-1001.xml">capitalizing machine translation </title>
<section> bilingual capitalization model.  </section>
<citcontext>
<prevsection>
<prevsent>in figure 3, fj is the j-th phrase of , ei is the i-th phrase of e, and they align to each other.
</prevsent>
<prevsent>we do not require word alignment; instead we find it reason able to think that word in ei can be aligned to any adapted to syntax-based machine translation, too.
</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
to this end,the translational correspondence is described within translation rule, i.e., (galley et al, 2004) (<papid> N04-1035 </papid>or synchronous produc tion), rather than translational phrase pair; and the training data will be derivation forests, instead of the phrase-aligned bilingual corpus.</citsent>
<aftsection>
<nextsent>2the capitalization model p(e|f, a) itself does not require the existence of e. this means that in principle this model can also be viewed as capitalized translation model that performs translation and capitalization in an integrated step.
</nextsent>
<nextsent>in our paper, however, we consider the case where the machine translation output is given, which is reflected by the the fact that gen(e) takes as input in formula 1.
</nextsent>
<nextsent>3 word in fj . probabilistic model defined on this graph is conditional random field.
</nextsent>
<nextsent>therefore, it is natural to formulate the bilingual capitalization model using crfs:3 p?(e|f, a) = 1 z(f, a, ?) exp x i=1 ifi(e, f, a) !
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4377">
<title id=" N06-1001.xml">capitalizing machine translation </title>
<section> bilingual capitalization model.  </section>
<citcontext>
<prevsection>
<prevsent>such that e?
</prevsent>
<prevsent>= arg maxegen(e,f ) ? i=1 ifi(e,f,a) (4) 4.2 parameter estimation.
</prevsent>
</prevsection>
<citsent citstr=" P04-1007 ">
following roark et al (2004), <papid> P04-1007 </papid>lafferty et al (2001) and chen and rosenfeld (1999), we are looking forthe set of feature weights ? maximizing the regularized log-likelihood llr(?)</citsent>
<aftsection>
<nextsent>of the training data {e(n), (n), a(n), = 1, ..., n}.
</nextsent>
<nextsent>llr(?)
</nextsent>
<nextsent>= x n=1 log ? e(n)|f (n), a(n) ? ?
</nextsent>
<nextsent>||?|| 2 22 (5)the second term at the right-hand side of formula 5 is zero-mean gaussian prior on the parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4383">
<title id=" N06-1001.xml">capitalizing machine translation </title>
<section> generating phrase-aligned training.  </section>
<citcontext>
<prevsection>
<prevsent>the input to the npa is word-aligned bilingual corpus.
</prevsent>
<prevsent>the npa stochastic ally chooses for each sentence pair one segmentation and phrase alignment that is consistent with the word alignment.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
an aligned phrase pair is consistent with the word alignment if neither phrase contains any word aligning to word outside the other phrase (och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>the npa chunks the source sentence into phrases according to probabilistic distribution over source phrase lengths.
</nextsent>
<nextsent>this distribution can be obtained from the trace output of phrase-based mt 5 entire corpus (#w) test-bleu languages training dev test-prec.
</nextsent>
<nextsent>(#sents) ef (it) 62m 13k 15k 763 fe (news) 144m 11k 22k 241 ce (news) 50m 8k 17k 919 table 2: corpora used in experiments.
</nextsent>
<nextsent>decoder on small development set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4386">
<title id=" N06-1001.xml">capitalizing machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the unigram-based capitalizer is the usual baseline for capitalization experiments in previous work.
</prevsent>
<prevsent>the trigram-based baseline is similar to the one in (lita et al, 2003) <papid> P03-1020 </papid>except that we used kneser-ney smoothing instead of mixture.</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
a phrase-based smt system (marcu and wong, 2002) <papid> W02-1018 </papid>was trained on the bitext.</citsent>
<aftsection>
<nextsent>the capitalizerwas incorporated into the mt system as postprocessing module ? it capitalizes the lower cased mt output.
</nextsent>
<nextsent>the phrase boundaries and alignments needed by the capitalizer were automatically inferred as part of the decoding process.
</nextsent>
<nextsent>6.2 bleu and precision.
</nextsent>
<nextsent>we measured the impact of our capitalization model in the context of an end-to-end mt system using bleu (papineni et al, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4387">
<title id=" N07-1035.xml">estimating the reliability of mdp policies a confidence interval approach </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the key idea is to take into account the uncertainty in the model parameters (mdp transition probabilities), and use that information to numerically construct confidence interval for the expected cumulative reward for the learned policy.
</prevsent>
<prevsent>this confidence interval approach allows us to: (1)better assess the reliability of the expected cumulative reward forgiven policy, and (2) perform refined comparison between policies derived from different mdp models.
</prevsent>
</prevsection>
<citsent citstr=" N06-1035 ">
we apply the proposed approach to our previous work (tetreault and litman, 2006) <papid> N06-1035 </papid>in using rl to improve spoken dialogue tutoring system.</citsent>
<aftsection>
<nextsent>in that work, dataset of 100 dialogues was used to develop methodology for selecting which user state features should be included in the mdp state-space.
</nextsent>
<nextsent>but are 100 dialogues enough to generate reliablepolicies?
</nextsent>
<nextsent>in this paper we apply our confidence in 276terval approach to the same dataset in an effort to investigate how reliable our previous conclusions are, given the amount of available training data.
</nextsent>
<nextsent>in the following section, we discuss the prior work and its data sparsity issue.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4388">
<title id=" N03-1004.xml">in question answering two heads are better than one </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present our multi-level answer resolution algorithm that combines results from the answering agents at the question, passage, and/or answer levels.
</prevsent>
<prevsent>experiments evaluating the effectiveness of our answer resolution algorithm show 35.0% relative improvement over our baseline system in the number of questions correctly answered, and 32.8% improvement according to the average precision metric.
</prevsent>
</prevsection>
<citsent citstr=" P00-1071 ">
traditional question answering (qa) systems typically employ pipeline approach, consisting roughly of question analysis, document/passage retrieval, and answer selection (see e.g., (prager et al, 2000; moldovan et al, 2000; <papid> P00-1071 </papid>hovy et al, 2001; clarke et al, 2001)).</citsent>
<aftsection>
<nextsent>although typical qa system classifies questions based on expected answer types, it adopts the same strategy for locating potential answers from the same corpus regardless of the question classification.
</nextsent>
<nextsent>in our own earlier work, we developed specialized mechanism called virtual annotation for handling definition questions (e.g., who was galileo??
</nextsent>
<nextsent>and what are antibiotics??)
</nextsent>
<nextsent>that consults, in addition to the standard reference corpus, structured knowledge source (wordnet) for answering such questions (prager et al, 2001).<papid> H01-1006 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4389">
<title id=" N03-1004.xml">in question answering two heads are better than one </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our own earlier work, we developed specialized mechanism called virtual annotation for handling definition questions (e.g., who was galileo??
</prevsent>
<prevsent>and what are antibiotics??)
</prevsent>
</prevsection>
<citsent citstr=" H01-1006 ">
that consults, in addition to the standard reference corpus, structured knowledge source (wordnet) for answering such questions (prager et al, 2001).<papid> H01-1006 </papid></citsent>
<aftsection>
<nextsent>we have shown that better performance is achieved by applying virtual annotation and our general purpose qa strategy in parallel.
</nextsent>
<nextsent>in this paper, we investigate the impact of adopting such multi strategy and multi-source approach to qa in more general fashion.
</nextsent>
<nextsent>our approach to question answering is additionally motivated by the success of ensemble methods in machine learning, where multiple classifiers are employed and their results are combined to produce the final output of the ensemble (for an overview, see (dietterich, 1997)).
</nextsent>
<nextsent>such ensemble methods have recently been adopted in question answering (chu-carroll et al, 2003b; burge ret al, 2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4393">
<title id=" N03-1004.xml">in question answering two heads are better than one </title>
<section> component answering agents.  </section>
<citcontext>
<prevsection>
<prevsent>the answering agent returns the top ranked candidate answers along with confidence score for each answer.
</prevsent>
<prevsent>3.2 statistical answering agent.
</prevsent>
</prevsection>
<citsent citstr=" N01-1005 ">
the second answering agent takes statistical approach to question answering (ittycheriah, 2001; ittycheriah et al., 2001).<papid> N01-1005 </papid></citsent>
<aftsection>
<nextsent>it models the distribution p(c|q, a), which measures the correctness?
</nextsent>
<nextsent>(c) of an answer (a) to question (q), by introducing hidden variable representing the answer type (e) as follows: p(c|q, a) = ? p(c, e|q, a) = ? p(c|e, q, a)p(e|q, a) p(e|q, a) is the answer type model which predicts, from the question and proposed answer, the answer type they both satisfy.
</nextsent>
<nextsent>p(c|e, q, a) is the answer selection model.
</nextsent>
<nextsent>given question, an answer, and the predicted answer type, it seeks to model the correctness of this configuration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4394">
<title id=" N03-1004.xml">in question answering two heads are better than one </title>
<section> component answering agents.  </section>
<citcontext>
<prevsection>
<prevsent>p(c|e, q, a) is the answer selection model.
</prevsent>
<prevsent>given question, an answer, and the predicted answer type, it seeks to model the correctness of this configuration.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
these distributions are modeled using maximum entropy formulation (berger et al, 1996), <papid> J96-1002 </papid>using training data which consists of human judgments of question answer pairs.</citsent>
<aftsection>
<nextsent>for the answer type model, 13k questions were annotated with 31 categories.
</nextsent>
<nextsent>for the answer selection model, 892 questions from the trec 8 and trec 9 qa tracks were used, along with 4k trivia questions.
</nextsent>
<nextsent>during runtime, the question is first analyzed by the answer type model, which selects one out of set of 31types for use by the answer selection model.
</nextsent>
<nextsent>simultaneously, the question is expanded using local context analysis (xu and croft, 1996) with an encyclopedia, and the top 1000 documents are retrieved by the search engine.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4395">
<title id=" N03-1004.xml">in question answering two heads are better than one </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these results represent success rates of 79.9% and 79.4% for our answer-level combination algorithm on the two test sets.
</prevsent>
<prevsent>there has been much work in employing ensemble methods to increase system performance in machine learning.
</prevsent>
</prevsection>
<citsent citstr=" A00-2009 ">
in nlp, such methods have been applied to tasks suchas pos tagging (brill and wu, 1998), word sense disambiguation (pedersen, 2000), <papid> A00-2009 </papid>parsing (henderson and brill, 1999), <papid> W99-0623 </papid>and machine translation (frederking and nirenburg, 1994).<papid> A94-1016 </papid></citsent>
<aftsection>
<nextsent>in question answering, number of researchers have investigated federated systems for identifying answers to questions.
</nextsent>
<nextsent>for example, (clarke et al, 2003) and (lin etal., 2003) employ techniques for utilizing both unstruc 9these cells are not marked as definite because in small number of cases, the two answers are not equivalent.
</nextsent>
<nextsent>for example, for the trec 9 question, who is the emperor of japan??, hirohito, akihito, and taisho are all considered correct answers based on the reference corpus.tured text and structured databases for question answering.
</nextsent>
<nextsent>however, the approaches taken by both these systems differ from ours in that they enforce an order between the two strategies by attempting to locate answers in structured databases first for select question types and falling back to unstructured text when the former fails, while we explore both options in parallel and combine the results from multiple answering agents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4396">
<title id=" N03-1004.xml">in question answering two heads are better than one </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these results represent success rates of 79.9% and 79.4% for our answer-level combination algorithm on the two test sets.
</prevsent>
<prevsent>there has been much work in employing ensemble methods to increase system performance in machine learning.
</prevsent>
</prevsection>
<citsent citstr=" W99-0623 ">
in nlp, such methods have been applied to tasks suchas pos tagging (brill and wu, 1998), word sense disambiguation (pedersen, 2000), <papid> A00-2009 </papid>parsing (henderson and brill, 1999), <papid> W99-0623 </papid>and machine translation (frederking and nirenburg, 1994).<papid> A94-1016 </papid></citsent>
<aftsection>
<nextsent>in question answering, number of researchers have investigated federated systems for identifying answers to questions.
</nextsent>
<nextsent>for example, (clarke et al, 2003) and (lin etal., 2003) employ techniques for utilizing both unstruc 9these cells are not marked as definite because in small number of cases, the two answers are not equivalent.
</nextsent>
<nextsent>for example, for the trec 9 question, who is the emperor of japan??, hirohito, akihito, and taisho are all considered correct answers based on the reference corpus.tured text and structured databases for question answering.
</nextsent>
<nextsent>however, the approaches taken by both these systems differ from ours in that they enforce an order between the two strategies by attempting to locate answers in structured databases first for select question types and falling back to unstructured text when the former fails, while we explore both options in parallel and combine the results from multiple answering agents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4397">
<title id=" N03-1004.xml">in question answering two heads are better than one </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these results represent success rates of 79.9% and 79.4% for our answer-level combination algorithm on the two test sets.
</prevsent>
<prevsent>there has been much work in employing ensemble methods to increase system performance in machine learning.
</prevsent>
</prevsection>
<citsent citstr=" A94-1016 ">
in nlp, such methods have been applied to tasks suchas pos tagging (brill and wu, 1998), word sense disambiguation (pedersen, 2000), <papid> A00-2009 </papid>parsing (henderson and brill, 1999), <papid> W99-0623 </papid>and machine translation (frederking and nirenburg, 1994).<papid> A94-1016 </papid></citsent>
<aftsection>
<nextsent>in question answering, number of researchers have investigated federated systems for identifying answers to questions.
</nextsent>
<nextsent>for example, (clarke et al, 2003) and (lin etal., 2003) employ techniques for utilizing both unstruc 9these cells are not marked as definite because in small number of cases, the two answers are not equivalent.
</nextsent>
<nextsent>for example, for the trec 9 question, who is the emperor of japan??, hirohito, akihito, and taisho are all considered correct answers based on the reference corpus.tured text and structured databases for question answering.
</nextsent>
<nextsent>however, the approaches taken by both these systems differ from ours in that they enforce an order between the two strategies by attempting to locate answers in structured databases first for select question types and falling back to unstructured text when the former fails, while we explore both options in parallel and combine the results from multiple answering agents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4398">
<title id=" N04-1011.xml">sentence internal prosody does not help parsing the way punctuation does </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper evaluates the accuracy of statistical parser whose input includes prosodic cues.
</prevsent>
<prevsent>the purpose of this study to determine if prosodic cues improve parsing accuracy in the same way that punctuation does.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
punctuation is represented in the various penn treebank corpora as independent word-liketokens, with corresponding terminal and pretermi nal nodes, as shown in figure 1 (bies et al, 1995).even though this seems linguistically highly unnatural (e.g., punctuation might indicate supra segmental prosodic properties), statistical parsers generally perform significantly better when their training and test data contains punctuation represented in this way than if the punctuation is stripped outof the training and test data (charniak, 2000; <papid> A00-2018 </papid>engel et al, 2002; <papid> W02-1007 </papid>johnson, 1998).<papid> J98-4004 </papid></citsent>
<aftsection>
<nextsent>on the switchboard treebank dataset using the experimental setup described below we obtained an f-score of 0.882when using punctuation and 0.869 when punctuation was stripped out, replicating previous experiments demonstrating the importance of punctuation.
</nextsent>
<nextsent>(f-score is standard measure of parse accuracy, see e.g., manning and schutze (1999) for details).
</nextsent>
<nextsent>this paper investigates how prosodic cues, when encoded in the parsers input in manner similar tothe way the penn treebanks encode punctuation, affect parser accuracy.
</nextsent>
<nextsent>our starting point is the observation that the penn treebank annotation of punctuation does significantly improve parsing accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4399">
<title id=" N04-1011.xml">sentence internal prosody does not help parsing the way punctuation does </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper evaluates the accuracy of statistical parser whose input includes prosodic cues.
</prevsent>
<prevsent>the purpose of this study to determine if prosodic cues improve parsing accuracy in the same way that punctuation does.
</prevsent>
</prevsection>
<citsent citstr=" W02-1007 ">
punctuation is represented in the various penn treebank corpora as independent word-liketokens, with corresponding terminal and pretermi nal nodes, as shown in figure 1 (bies et al, 1995).even though this seems linguistically highly unnatural (e.g., punctuation might indicate supra segmental prosodic properties), statistical parsers generally perform significantly better when their training and test data contains punctuation represented in this way than if the punctuation is stripped outof the training and test data (charniak, 2000; <papid> A00-2018 </papid>engel et al, 2002; <papid> W02-1007 </papid>johnson, 1998).<papid> J98-4004 </papid></citsent>
<aftsection>
<nextsent>on the switchboard treebank dataset using the experimental setup described below we obtained an f-score of 0.882when using punctuation and 0.869 when punctuation was stripped out, replicating previous experiments demonstrating the importance of punctuation.
</nextsent>
<nextsent>(f-score is standard measure of parse accuracy, see e.g., manning and schutze (1999) for details).
</nextsent>
<nextsent>this paper investigates how prosodic cues, when encoded in the parsers input in manner similar tothe way the penn treebanks encode punctuation, affect parser accuracy.
</nextsent>
<nextsent>our starting point is the observation that the penn treebank annotation of punctuation does significantly improve parsing accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4400">
<title id=" N04-1011.xml">sentence internal prosody does not help parsing the way punctuation does </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper evaluates the accuracy of statistical parser whose input includes prosodic cues.
</prevsent>
<prevsent>the purpose of this study to determine if prosodic cues improve parsing accuracy in the same way that punctuation does.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
punctuation is represented in the various penn treebank corpora as independent word-liketokens, with corresponding terminal and pretermi nal nodes, as shown in figure 1 (bies et al, 1995).even though this seems linguistically highly unnatural (e.g., punctuation might indicate supra segmental prosodic properties), statistical parsers generally perform significantly better when their training and test data contains punctuation represented in this way than if the punctuation is stripped outof the training and test data (charniak, 2000; <papid> A00-2018 </papid>engel et al, 2002; <papid> W02-1007 </papid>johnson, 1998).<papid> J98-4004 </papid></citsent>
<aftsection>
<nextsent>on the switchboard treebank dataset using the experimental setup described below we obtained an f-score of 0.882when using punctuation and 0.869 when punctuation was stripped out, replicating previous experiments demonstrating the importance of punctuation.
</nextsent>
<nextsent>(f-score is standard measure of parse accuracy, see e.g., manning and schutze (1999) for details).
</nextsent>
<nextsent>this paper investigates how prosodic cues, when encoded in the parsers input in manner similar tothe way the penn treebanks encode punctuation, affect parser accuracy.
</nextsent>
<nextsent>our starting point is the observation that the penn treebank annotation of punctuation does significantly improve parsing accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4401">
<title id=" N04-1011.xml">sentence internal prosody does not help parsing the way punctuation does </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>the data used for this study is the transcribed version of the switchboard corpus as released by the linguistic data consortium.
</prevsent>
<prevsent>the switchboard corpus is corpus of telephone conversations between adult speakers of varying dialects.
</prevsent>
</prevsection>
<citsent citstr=" N01-1016 ">
the corpus was split into training and test data as described in charniak and johnson (2001).<papid> N01-1016 </papid></citsent>
<aftsection>
<nextsent>the training data consisted of all files in sections 2 and 3 ofthe switchboard treebank.
</nextsent>
<nextsent>the testing corpus consists of files sw4004.mrg to sw4153.mrg, while filessw4519.mrg to sw4936.mrg were used as development corpus.
</nextsent>
<nextsent>2.1 prosodic variables.
</nextsent>
<nextsent>prosodic information for the corpus was obtained from forced alignments provided by hamaker et al (2003) and ferrer et al (2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4405">
<title id=" N06-1021.xml">multilingual dependency parsing using bayes point machines </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unlike constituency analysis, there are no intervening non-lexical nodes.
</prevsent>
<prevsent>we use the terms child and parent to denote the dependent term and the governing term respectively.parsing has many potential applications, ranging from question answering and information retrieval to grammar checking.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
our intended application is machine translation in the microsoft research treelet translation system (quirk et al ,2005; <papid> P05-1034 </papid>menezes and quirk, 2005).</citsent>
<aftsection>
<nextsent>this system expects an analysis of the source language in which words are related by directed, unlabeled dependencies.
</nextsent>
<nextsent>for the purposes of developing machine translation for several language pairs, we are interested in dependency analyses for multiple languages.
</nextsent>
<nextsent>the contributions of this paper are two-fold: first, we present training algorithm called bayes point machines (herbrich et al , 2001; harrington et al ,2003), which is as easy to implement as the perceptron, yet competitive with large margin methods.
</nextsent>
<nextsent>this algorithm has implications for anyone interested in implementing discriminative training methods for any application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4406">
<title id=" N06-1021.xml">multilingual dependency parsing using bayes point machines </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>for english and chinese, however, no corpus is available that is annotated in terms of dependencies.
</prevsent>
<prevsent>we therefore applied head-finding rules to treebanks that were annotated in terms of constituency.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for english, we used the penn treebank version 3.0 (marcus et al , 1993) <papid> J93-2004 </papid>and extracted dependency relations by applying the head-finding rules of (ya mada and matsumoto, 2003).</citsent>
<aftsection>
<nextsent>these rules are simplification of the head-finding rules of (collins, 1999).
</nextsent>
<nextsent>we trained on sections 02-21, used section 24 for development test and evaluated on section 23.
</nextsent>
<nextsent>the english penn treebank contains approxi-.
</nextsent>
<nextsent>mately one million tokens.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4407">
<title id=" N06-1021.xml">multilingual dependency parsing using bayes point machines </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>mately one million tokens.
</prevsent>
<prevsent>training and evaluation against the development test set was performed using human-annotated part-of-speech labels.
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
evaluation against the blind test set was performed using part-of-speech labels assigned by the tagger described in (toutanova et al , 2003).<papid> N03-1033 </papid>for chinese, we used the chinese treebank version 5.0 (xue et al , 2005).</citsent>
<aftsection>
<nextsent>this corpus contains approximately 500,000 tokens.
</nextsent>
<nextsent>we made an approximate 70%/15%/15% split for training/development test/blind test by sampling whole files.
</nextsent>
<nextsent>as with the english treebank, training and evaluation against the development test set was performed usinghuman-annotated part-of-speech labels.
</nextsent>
<nextsent>for evaluation against the blind test section, we used an implementation of the tagger described in (toutanova et al , 2003).<papid> N03-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4411">
<title id=" N06-1021.xml">multilingual dependency parsing using bayes point machines </title>
<section> parser architecture.  </section>
<citcontext>
<prevsection>
<prevsent>it is not feasible in every instance to do the integration work first and then to evaluate the output.
</prevsent>
<prevsent>table 1 summarizes the data used to train the parsers, giving the number of tokens (excludingtraces and other empty elements) and counts of sen tences.1
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
we take as our starting point re-implementation of mcdonalds state-of-the-art dependency parser (mcdonald et al , 2005<papid> P05-1012 </papid>a).</citsent>
<aftsection>
<nextsent>given sentence x, the goal of the parser is to find the highest-scoring parse y?
</nextsent>
<nextsent>among all possible parses ? : y?
</nextsent>
<nextsent>= arg max yy s(x, y) (1) 1the files in each partition of the chinese and arabic data are given at http://research.microsoft.com/simonco/ hltnaacl2006.
</nextsent>
<nextsent>161 language total training development blind tokens sentences sentences sentences arabic 116,695 2,100 446 449 chinese 527,242 14,735 1,961 2,080 czech 1,595,247 73,088 7,319 7,507 english 1,083,159 39,832 1,346 2,416 table 1: summary of data used to train parsers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4418">
<title id=" N06-1021.xml">multilingual dependency parsing using bayes point machines </title>
<section> parser architecture.  </section>
<citcontext>
<prevsection>
<prevsent>this parser architecture naturally consists of threemodules: (1) decoder that enumerates all possible parses and computes the argmax; (2) training algorithm for adjusting the weights given the training data; and (3) feature representation f(i, j).two decoders will be discussed here; the training algorithm and feature representation are discussed in the following sections.a good decoder should satisfy several proper ties: ideally, it should be able to search through all valid parses of sentence and compute the parse scores efficiently.
</prevsent>
<prevsent>efficiency is significant issue since there are usually an exponential number of parses for any given sentence, and the discriminative training methods we will describe later require repeated decoding at each training iteration.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
we reimplemented eisners decoder (eisner, 1996), <papid> C96-1058 </papid>which searches among all projective parse trees, and the chu-liu-edmonds?</citsent>
<aftsection>
<nextsent>decoder (chu and liu, 1965; edmonds, 1967), which searches in the space ofboth projective and non-projective parses.
</nextsent>
<nextsent>(a projective tree is parse with no crossing dependencylinks.)
</nextsent>
<nextsent>for the english and chinese data, the head finding rules for converting from penn treebank analyses to dependency analyses creates trees thatare guaranteed to be projective, so eisners algorithm suffices.
</nextsent>
<nextsent>for the czech and arabic corpora,a non-projective decoder is necessary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4426">
<title id=" N06-1021.xml">multilingual dependency parsing using bayes point machines </title>
<section> training: the bayes point machine.  </section>
<citcontext>
<prevsection>
<prevsent>it adjusts by updating it with the feature vector when ever misclassification on the current input sampleoccurs.
</prevsent>
<prevsent>it has been shown that such updates converge infinite number of iterations if the data is linearly separable.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
the averaged perceptron (collins, 2002) <papid> W02-1001 </papid>is variant which averages the across all iterations; it has demonstrated good generalization especially with data that is not linearly separable, as in many natural language processing problems.2the chu-liu-edmonds?</citsent>
<aftsection>
<nextsent>decoder, which is based on maximal spanning tree algorithm, can run in o(n2), but our simpler implementation of o(n3) was sufficient.
</nextsent>
<nextsent>162recently, the good generalization properties of support vector machines have prompted researchers to develop large margin methods for the online setting.
</nextsent>
<nextsent>examples include the margin perceptron (duda et al , 2001), alma (gentile, 2001), and mira (which is used to train the parser in (mcdonald et al , 2005<papid> P05-1012 </papid>a)).</nextsent>
<nextsent>conceptually, all these methods attempt to achieve large margin and approximate the maximum margin solution of svms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4456">
<title id=" N06-1021.xml">multilingual dependency parsing using bayes point machines </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>we performed data reduction experiments, training the parsers on five random samples at each size smaller than the entire training set.
</prevsent>
<prevsent>figure 2 shows the dependency accuracy measured on the complete development test set when training with samples of the data.
</prevsent>
</prevsection>
<citsent citstr=" W05-1516 ">
the graph shows the average4(wang et al , 2005) <papid> W05-1516 </papid>report numbers for undirected dependencies on the chinese treebank 3.0.</citsent>
<aftsection>
<nextsent>we cannot meaningfully compare those numbers to the numbers here.
</nextsent>
<nextsent>165 language algorithm da ra cm english avg.
</nextsent>
<nextsent>perceptron 90.6 94.0 36.5 (exc punc) mira 90.9 94.2 37.5 bayes point machine 90.8 93.7 37.6 czech avg.
</nextsent>
<nextsent>perceptron 82.9 88.0 30.3 (inc punc) mira 83.3 88.6 31.3 bayes point machine 84.0 88.8 30.9 table 3: comparison to previous best published results reported in (mcdonald et al , 2005<papid> P05-1012 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4471">
<title id=" N04-4036.xml">parsing arguments of nominalizations in english and chinese </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>in this paper, we use machine learning framework for semantic argument parsing, and apply it to the task of parsing arguments of even tive nominalizations in the framenet database.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
we create baseline system using subset of features introduced by gildea and jurafsky (2002),<papid> J02-3001 </papid>which are directly applicable to nominal pred icates.</citsent>
<aftsection>
<nextsent>we then investigate new features which are designed to capture the novelties in nominal argument structure and show significant performance improvement using these new features.
</nextsent>
<nextsent>we also investigate the parsing performance of nominalizations in chinese and compare the salience of the features for the two languages.
</nextsent>
<nextsent>the field of nlp had seen resurgence of research in shallow semantic analysis.
</nextsent>
<nextsent>the bulk of this recent work views semantic analysis as tagging, or labeling problem, and has applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002);<papid> J02-3001 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al (2003); <papid> P03-1002 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al (2003); pradhan et al (2003)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4472">
<title id=" N04-4036.xml">parsing arguments of nominalizations in english and chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also investigate the parsing performance of nominalizations in chinese and compare the salience of the features for the two languages.
</prevsent>
<prevsent>the field of nlp had seen resurgence of research in shallow semantic analysis.
</prevsent>
</prevsection>
<citsent citstr=" P00-1065 ">
the bulk of this recent work views semantic analysis as tagging, or labeling problem, and has applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002);<papid> J02-3001 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al (2003); <papid> P03-1002 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al (2003); pradhan et al (2003)).</citsent>
<aftsection>
<nextsent>note that, while all of these systems are limited to the analysis of verbal predicates, many underlying semantic relations are expressed via nouns, adjectives, and prepositions.
</nextsent>
<nextsent>this paper presents preliminary investigation into the semantic parsing of eventivenominalizations (grimshaw, 1990) in english and chinese.
</nextsent>
<nextsent>for our experiments, we use the framenet database(baker et al, 1998) <papid> P98-1013 </papid>which contains frame-specific se this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 mantic annotation of number of predicates in english.</nextsent>
<nextsent>predicates are grouped by the semantic frame that they instantiate, depending on the sense of their usage, and their arguments assume one of the frame elements or roles specific to that frame.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4474">
<title id=" N04-4036.xml">parsing arguments of nominalizations in english and chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also investigate the parsing performance of nominalizations in chinese and compare the salience of the features for the two languages.
</prevsent>
<prevsent>the field of nlp had seen resurgence of research in shallow semantic analysis.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
the bulk of this recent work views semantic analysis as tagging, or labeling problem, and has applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002);<papid> J02-3001 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al (2003); <papid> P03-1002 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al (2003); pradhan et al (2003)).</citsent>
<aftsection>
<nextsent>note that, while all of these systems are limited to the analysis of verbal predicates, many underlying semantic relations are expressed via nouns, adjectives, and prepositions.
</nextsent>
<nextsent>this paper presents preliminary investigation into the semantic parsing of eventivenominalizations (grimshaw, 1990) in english and chinese.
</nextsent>
<nextsent>for our experiments, we use the framenet database(baker et al, 1998) <papid> P98-1013 </papid>which contains frame-specific se this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 mantic annotation of number of predicates in english.</nextsent>
<nextsent>predicates are grouped by the semantic frame that they instantiate, depending on the sense of their usage, and their arguments assume one of the frame elements or roles specific to that frame.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4475">
<title id=" N04-4036.xml">parsing arguments of nominalizations in english and chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also investigate the parsing performance of nominalizations in chinese and compare the salience of the features for the two languages.
</prevsent>
<prevsent>the field of nlp had seen resurgence of research in shallow semantic analysis.
</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
the bulk of this recent work views semantic analysis as tagging, or labeling problem, and has applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002);<papid> J02-3001 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al (2003); <papid> P03-1002 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al (2003); pradhan et al (2003)).</citsent>
<aftsection>
<nextsent>note that, while all of these systems are limited to the analysis of verbal predicates, many underlying semantic relations are expressed via nouns, adjectives, and prepositions.
</nextsent>
<nextsent>this paper presents preliminary investigation into the semantic parsing of eventivenominalizations (grimshaw, 1990) in english and chinese.
</nextsent>
<nextsent>for our experiments, we use the framenet database(baker et al, 1998) <papid> P98-1013 </papid>which contains frame-specific se this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 mantic annotation of number of predicates in english.</nextsent>
<nextsent>predicates are grouped by the semantic frame that they instantiate, depending on the sense of their usage, and their arguments assume one of the frame elements or roles specific to that frame.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4476">
<title id=" N04-4036.xml">parsing arguments of nominalizations in english and chinese </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also investigate the parsing performance of nominalizations in chinese and compare the salience of the features for the two languages.
</prevsent>
<prevsent>the field of nlp had seen resurgence of research in shallow semantic analysis.
</prevsent>
</prevsection>
<citsent citstr=" N03-2009 ">
the bulk of this recent work views semantic analysis as tagging, or labeling problem, and has applied various supervised machine learning techniques to it (gildea and jurafsky (2000), <papid> P00-1065 </papid>gildea and jurafsky (2002);<papid> J02-3001 </papid>gildea and palmer (2002); <papid> P02-1031 </papid>surdeanu et al (2003); <papid> P03-1002 </papid>hacioglu and ward (2003); <papid> N03-2009 </papid>thompson et al (2003); pradhan et al (2003)).</citsent>
<aftsection>
<nextsent>note that, while all of these systems are limited to the analysis of verbal predicates, many underlying semantic relations are expressed via nouns, adjectives, and prepositions.
</nextsent>
<nextsent>this paper presents preliminary investigation into the semantic parsing of eventivenominalizations (grimshaw, 1990) in english and chinese.
</nextsent>
<nextsent>for our experiments, we use the framenet database(baker et al, 1998) <papid> P98-1013 </papid>which contains frame-specific se this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 mantic annotation of number of predicates in english.</nextsent>
<nextsent>predicates are grouped by the semantic frame that they instantiate, depending on the sense of their usage, and their arguments assume one of the frame elements or roles specific to that frame.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4477">
<title id=" N04-4036.xml">parsing arguments of nominalizations in english and chinese </title>
<section> semantic annotation and corpora.  </section>
<citcontext>
<prevsection>
<prevsent>note that, while all of these systems are limited to the analysis of verbal predicates, many underlying semantic relations are expressed via nouns, adjectives, and prepositions.
</prevsent>
<prevsent>this paper presents preliminary investigation into the semantic parsing of eventivenominalizations (grimshaw, 1990) in english and chinese.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
for our experiments, we use the framenet database(baker et al, 1998) <papid> P98-1013 </papid>which contains frame-specific se this research was partially supported by the arda aquaint program via contract ocg4423b and by the nsf via grant is-9978025 mantic annotation of number of predicates in english.</citsent>
<aftsection>
<nextsent>predicates are grouped by the semantic frame that they instantiate, depending on the sense of their usage, and their arguments assume one of the frame elements or roles specific to that frame.
</nextsent>
<nextsent>the predicate can be verb, noun, adjective, prepositional phrase, etc. framenet contains about 500 different frame types and about 700distinct frame elements.
</nextsent>
<nextsent>the following example illustrates the general idea.
</nextsent>
<nextsent>here, the predicate complain?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4478">
<title id=" N04-4036.xml">parsing arguments of nominalizations in english and chinese </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 classifier and implementation we formulate the.
</prevsent>
<prevsent>parsing problem as multi-class classification problem and use support vector machine (svm) classifier in the one vs all (ova) formalism, which involves training classifiers for n-class problem ? including the null class.
</prevsent>
</prevsection>
<citsent citstr=" W00-0730 ">
we use tinysvm2 along with yamcha3 (kudo and matsumoto (2000), <papid> W00-0730 </papid>kudo and matsumoto (2001)) <papid> N01-1025 </papid>as the svm training and test software.</citsent>
<aftsection>
<nextsent>3.3 performance we evaluate our system on three.
</nextsent>
<nextsent>tasks: i) argument identification: identifying parse constituents that represent arguments of given predicate, ii) argument classification: labeling the constituents that are known to represent arguments with the most likely roles, and iii) argument identification and classification:finding constituents that represent arguments of predicate, and labeling them with the most likely roles.
</nextsent>
<nextsent>the baseline performance on the three tasks is shown in table 1.
</nextsent>
<nextsent>to improve the baseline performance we investigated additional features that would provide useful information in identifying arguments of nominalizations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4479">
<title id=" N04-4036.xml">parsing arguments of nominalizations in english and chinese </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 classifier and implementation we formulate the.
</prevsent>
<prevsent>parsing problem as multi-class classification problem and use support vector machine (svm) classifier in the one vs all (ova) formalism, which involves training classifiers for n-class problem ? including the null class.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
we use tinysvm2 along with yamcha3 (kudo and matsumoto (2000), <papid> W00-0730 </papid>kudo and matsumoto (2001)) <papid> N01-1025 </papid>as the svm training and test software.</citsent>
<aftsection>
<nextsent>3.3 performance we evaluate our system on three.
</nextsent>
<nextsent>tasks: i) argument identification: identifying parse constituents that represent arguments of given predicate, ii) argument classification: labeling the constituents that are known to represent arguments with the most likely roles, and iii) argument identification and classification:finding constituents that represent arguments of predicate, and labeling them with the most likely roles.
</nextsent>
<nextsent>the baseline performance on the three tasks is shown in table 1.
</nextsent>
<nextsent>to improve the baseline performance we investigated additional features that would provide useful information in identifying arguments of nominalizations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4481">
<title id=" N04-4036.xml">parsing arguments of nominalizations in english and chinese </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>the best system generates an f1 score of 57.3% on the combined task of argument identification and classification using automatically extracted features on test set of about 700 sentences using classifier trained on about 6,000 sentences.
</prevsent>
<prevsent>as noted earlier, the bulk of past research in this area has focused on verbal predicates.
</prevsent>
</prevsection>
<citsent citstr=" J02-3004 ">
two notable exceptions to this include the work of (hull and gomez, 1996) ? rule based system for identifying the semantic arguments of nominal predicates, and the work of (lapata, 2002)<papid> J02-3004 </papid>on interpreting the relation between the head of nom inal ized compound and its modifier noun.</citsent>
<aftsection>
<nextsent>unfortunately, meaningful comparisons to these efforts are difficult due to differing evaluation metrics.
</nextsent>
<nextsent>we would like to thank ralph weischedel and scott miller ofbbn inc. for letting us use bbns named entity tagger ? iden tifinder; ashley thornton for identifying the sentences from framenet with predicates that are even tive nominalizations.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4482">
<title id=" N04-4028.xml">confidence estimation for information extraction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, these constraints are again for singleton tokens only.
</prevsent>
<prevsent>rule-based extraction methods (thompson et al, 1999) estimate confidence based on rules coverage inthe training data.
</prevsent>
</prevsection>
<citsent citstr=" W03-0413 ">
other areas where confidence estimation is used include document classification (bennett et al., 2002), where classifiers are built using meta-features of the document; speech recognition (gunawardana et al,1998), where the confidence of recognized word is estimated by considering list of commonly confused words; and machine translation (gandrabur and foster, 2003), <papid> W03-0413 </papid>where neural networks are used to learn the probability ofa correct word translation using text features and knowledge of alternate translations.</citsent>
<aftsection>
<nextsent>we have shown that cfb is mathematically and empirically sound confidence estimator for finite state information extraction systems, providing strong correlation with correctness and obtaining an average precision of 97.6% for estimating field correctness.
</nextsent>
<nextsent>unlike methods margin maximization methods such as svms and m3ns (taskar et al, 2003), crfs are trained to maximize conditional probability and are thus more naturally appropriate for confidence estimation.
</nextsent>
<nextsent>interestingly, reranking by max ent does not seem to improve performance, despite the benefit collins (2000) has shown discriminative reranking to provide generative parsers.
</nextsent>
<nextsent>we hypothesize this is because crfs are already discriminative (not joint, gen erative) models; furthermore, this may suggest that future discriminative parsing methods will also have the benefits of discriminative reranking built-in directly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4483">
<title id=" N04-2004.xml">a computational framework for nonlexicalist semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>i demonstrate how such framework can be computationally realized with feature-based, agenda-driven chart parser for the minimalist program.
</prevsent>
<prevsent>the understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.
</prevsent>
</prevsection>
<citsent citstr=" P97-1003 ">
due to advances in statistical syntactic parsing techniques (collins, 1997; <papid> P97-1003 </papid>charniak, 2001), <papid> P01-1017 </papid>attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences.a common lexical semantic representation in the computational linguistics literature is frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots).</citsent>
<aftsection>
<nextsent>verbs are viewed as simple predicates over their arguments.
</nextsent>
<nextsent>this approach has its roots in fill mores case grammar (1968), and serves as the foundation for two current large-scale semantic annotation projects: framenet (baker et al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury et al, 2002).underlying the semantic roles approach is lexical ist assumption, that is, each verbs lexical entry completely encodes (more formally, projects) its syntactic and semantic structures.</nextsent>
<nextsent>alternations in argument structure are usually attributed to multiple lexical entries (i.e., verb senses).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4484">
<title id=" N04-2004.xml">a computational framework for nonlexicalist semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>i demonstrate how such framework can be computationally realized with feature-based, agenda-driven chart parser for the minimalist program.
</prevsent>
<prevsent>the understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
due to advances in statistical syntactic parsing techniques (collins, 1997; <papid> P97-1003 </papid>charniak, 2001), <papid> P01-1017 </papid>attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences.a common lexical semantic representation in the computational linguistics literature is frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots).</citsent>
<aftsection>
<nextsent>verbs are viewed as simple predicates over their arguments.
</nextsent>
<nextsent>this approach has its roots in fill mores case grammar (1968), and serves as the foundation for two current large-scale semantic annotation projects: framenet (baker et al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury et al, 2002).underlying the semantic roles approach is lexical ist assumption, that is, each verbs lexical entry completely encodes (more formally, projects) its syntactic and semantic structures.</nextsent>
<nextsent>alternations in argument structure are usually attributed to multiple lexical entries (i.e., verb senses).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4485">
<title id=" N04-2004.xml">a computational framework for nonlexicalist semantics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>due to advances in statistical syntactic parsing techniques (collins, 1997; <papid> P97-1003 </papid>charniak, 2001), <papid> P01-1017 </papid>attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences.a common lexical semantic representation in the computational linguistics literature is frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots).</prevsent>
<prevsent>verbs are viewed as simple predicates over their arguments.</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
this approach has its roots in fill mores case grammar (1968), and serves as the foundation for two current large-scale semantic annotation projects: framenet (baker et al, 1998) <papid> P98-1013 </papid>and propbank (kingsbury et al, 2002).underlying the semantic roles approach is lexical ist assumption, that is, each verbs lexical entry completely encodes (more formally, projects) its syntactic and semantic structures.</citsent>
<aftsection>
<nextsent>alternations in argument structure are usually attributed to multiple lexical entries (i.e., verb senses).
</nextsent>
<nextsent>under the lexical ist approach, the semantics of the verb break might look something like this: (1) break(agent, theme) agent: subject theme: object break(agent, theme, instrument) agent: subject theme: object instrument: oblique(with) break(theme) theme: subject . . .the lexicon explicitly specifies the different subcategorization frames of verb, e.g., the causative frame, the causative instrumental frame, the inchoative frame, etc. the major drawback of this approach, however, is the tremendous amount of redundancy in the lexicon for example, the class of prototypical transitive verbs where the agent appears as the subject and the theme as the direct object must all duplicate this pattern.
</nextsent>
<nextsent>the typical solution to the redundancy problem is to group verbs according to their argument realization patterns (levin, 1993), possibly arranged in an inheritance hierarchy.
</nextsent>
<nextsent>the argument structure and syntax-to semantics mapping would then only need to be specified once for each verb class.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4486">
<title id=" N04-2004.xml">a computational framework for nonlexicalist semantics </title>
<section> event structure.  </section>
<citcontext>
<prevsection>
<prevsent>it has previously been argued that representations based on fixed collection of semantic roles cannot adequately capture natural language semantics.
</prevsent>
<prevsent>the actual inventory of semantic roles, along with precise definitions and diagnostics, remains an unsolved problem; see (levin and rappaport hovav, 1996).
</prevsent>
</prevsection>
<citsent citstr=" J91-4003 ">
fixed roles are too coarse grained to account for certain semantic distinctions the only recourse, to expand the inventory of roles, comes with the price of increased complexity, e.g., in the syntax to-semantics mapping.there is general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure representations grounded in theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity (dowty, 1979; jackendoff, 1983; pustejovsky, 1991<papid> J91-4003 </papid>b; rappaport hovav and levin, 1998).</citsent>
<aftsection>
<nextsent>consider the following example: (2) he sweeps the floor clean.
</nextsent>
<nextsent>[ [ do(he, sweeps(the floor)) ] cause [ become [ clean(the floor) ] ] ] dowty breaks the event described by (2) into two sub events, the activity of sweeping the floor and its result, the state of the floor being clean.
</nextsent>
<nextsent>a more recent approach,advocated by rappaport hovav and levin (1998), describes basic set of event templates corresponding to vendlers event classes (vendler, 1957): (3) a. [ act manner  ] (activity) b. [  state  ] (state) c. [ become [  state  ] ] (achievement) d. [ cause [ become [  state  ] ] ] (accomplishment) e. [ [ act manner  ] cause [ become [  state  ] ] ] (accomplishment) process called template augmentation allows basic event templates to be freely augmented?
</nextsent>
<nextsent>to any other event template.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4488">
<title id=" N04-1021.xml">a smorgasbord of features for statistical machine translation </title>
<section> log-linear models for statistical mt.  </section>
<citcontext>
<prevsection>
<prevsent>sentence = ei1 = e1, . . .
</prevsent>
<prevsent>, ei, . . .
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
, ei among all possible target sentences, we will choose the sentence with the highest probability: ei1 = argmax ei1 {pr(ei1|f 1 )} (1)as an alternative to the often used source-channel approach (brown et al, 1993), <papid> J93-2003 </papid>we directly model the posterior probability pr(ei1|fj1 ) (och and ney, 2002) <papid> P02-1038 </papid>using log-linear combination of feature functions.</citsent>
<aftsection>
<nextsent>in this framework, we have set of feature functions hm(ei1, j 1 ),m = 1, . . .
</nextsent>
<nextsent>,m . for each feature function, there exists model parameter m,m = 1, . . .
</nextsent>
<nextsent>,m . the direct translation probability is given by: pr(ei1|f 1 ) = exp[ m=1 mhm(e 1, j 1 )] ? ei1 exp[ m=1 mhm(e 1, j 1 )] (2) we obtain the following decision rule: ei1 = argmax ei1 { m?
</nextsent>
<nextsent>m=1 mhm(e 1, j 1 ) } (3) the standard criterion for training such log-linearmodel is to maximize the probability of the parallel training corpus consisting of sentence pairs {(fs, es) : =1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4489">
<title id=" N04-1021.xml">a smorgasbord of features for statistical machine translation </title>
<section> log-linear models for statistical mt.  </section>
<citcontext>
<prevsection>
<prevsent>sentence = ei1 = e1, . . .
</prevsent>
<prevsent>, ei, . . .
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
, ei among all possible target sentences, we will choose the sentence with the highest probability: ei1 = argmax ei1 {pr(ei1|f 1 )} (1)as an alternative to the often used source-channel approach (brown et al, 1993), <papid> J93-2003 </papid>we directly model the posterior probability pr(ei1|fj1 ) (och and ney, 2002) <papid> P02-1038 </papid>using log-linear combination of feature functions.</citsent>
<aftsection>
<nextsent>in this framework, we have set of feature functions hm(ei1, j 1 ),m = 1, . . .
</nextsent>
<nextsent>,m . for each feature function, there exists model parameter m,m = 1, . . .
</nextsent>
<nextsent>,m . the direct translation probability is given by: pr(ei1|f 1 ) = exp[ m=1 mhm(e 1, j 1 )] ? ei1 exp[ m=1 mhm(e 1, j 1 )] (2) we obtain the following decision rule: ei1 = argmax ei1 { m?
</nextsent>
<nextsent>m=1 mhm(e 1, j 1 ) } (3) the standard criterion for training such log-linearmodel is to maximize the probability of the parallel training corpus consisting of sentence pairs {(fs, es) : =1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4490">
<title id=" N04-1021.xml">a smorgasbord of features for statistical machine translation </title>
<section> log-linear models for statistical mt.  </section>
<citcontext>
<prevsection>
<prevsent>this is more difficult optimization problem, as the search space is no longer convex.
</prevsent>
<prevsent>figure 1: example segmentation of chinese sentence and its english translation into alignment templates.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
however, certain properties of the bleu metric can be exploited to speed up search, as described in detail by och (2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we use this method of optimizing feature weights throughout this paper.
</nextsent>
<nextsent>2.1 baseline mt system: alignment templates.
</nextsent>
<nextsent>our baseline mt system is the alignment template system described in detail by och, tillmann, and ney (1999) and och and ney (2004).<papid> J04-4002 </papid></nextsent>
<nextsent>in the following, we give short description of this baseline model.the probability model of the alignment template system for translating sentence can be thought of indistinct stages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4491">
<title id=" N04-1021.xml">a smorgasbord of features for statistical machine translation </title>
<section> log-linear models for statistical mt.  </section>
<citcontext>
<prevsection>
<prevsent>we use this method of optimizing feature weights throughout this paper.
</prevsent>
<prevsent>2.1 baseline mt system: alignment templates.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
our baseline mt system is the alignment template system described in detail by och, tillmann, and ney (1999) and och and ney (2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>in the following, we give short description of this baseline model.the probability model of the alignment template system for translating sentence can be thought of indistinct stages.
</nextsent>
<nextsent>first, the source sentence words fj1 are grouped to phrases fk1 . for each phrase f?
</nextsent>
<nextsent>an alignment template is chosen and the sequence of chosen alignment templates is reordered (according to pik1 ).
</nextsent>
<nextsent>then, every phrase fproduces its translation e?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4494">
<title id=" N04-1021.xml">a smorgasbord of features for statistical machine translation </title>
<section> shallow syntactic feature functions.  </section>
<citcontext>
<prevsection>
<prevsent>the total probability is the product over all alignment templates i, either (ati is right-continuous) or 1 ? (ati is right-continuous).in both models, the probabilities have been estimated from the full training data (train).
</prevsent>
<prevsent>by shallow syntax, we mean the output of the part-of speech tagger and chunkers.
</prevsent>
</prevsection>
<citsent citstr=" W03-1002 ">
we hope that such feature scan combine the strengths of tag- and chunk-based translation systems (schafer and yarowsky, 2003) <papid> W03-1002 </papid>with our baseline system.</citsent>
<aftsection>
<nextsent>5.1 projected pos language model.
</nextsent>
<nextsent>this feature uses chinese pos tag sequences as surrogates for chinese words to model movement.
</nextsent>
<nextsent>chinese words are too sparse to model movement, but an attempt to model movement using chinese pos may be more successful.
</nextsent>
<nextsent>we hope that this feature will compensate for weak model of word movement in the baseline system.chinese pos sequences are projected to english using the word alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4495">
<title id=" N04-1021.xml">a smorgasbord of features for statistical machine translation </title>
<section> tree-based feature functions.  </section>
<citcontext>
<prevsection>
<prevsent>the projected pos feature function was one of the strongest performing shallow syntactic feature functions, with %bleu score of 31.8.
</prevsent>
<prevsent>this feature function can be thought of as trade-off between purely word-based models, and full generative models based upon shallow syntax.
</prevsent>
</prevsection>
<citsent citstr=" P98-2230 ">
syntax-based mt has shown promise in the work of, among others, wu and wong (1998) <papid> P98-2230 </papid>and alshawi, bangalore, and douglas (2000).</citsent>
<aftsection>
<nextsent>we hope that adding features based on treebank-based syntactic analyses of the source and target sentences will address grammatical errors in the output of the baseline system.
</nextsent>
<nextsent>6.1 parse tree probability.
</nextsent>
<nextsent>the most straightforward way to integrate statistical parser in the system would be the use of the (log of the) parser probability as feature function.
</nextsent>
<nextsent>unfortunately, this feature function did not help to obtain better results (it actually seems to significantly hurt performance).to analyze the reason for this, we performed an experiment to test if the used statistical parser assigns higher probability to presumably grammatical sentences.the following table shows the average log probability assigned by the collins parser to the 1-best (produced), oracle and the reference translations: hypothesis 1-best oracle reference log(parseprob) -147.2 -148.5 -154.9 we observe that the average parser log-probability of the 1-best translation is higher than the average parse log probability of the oracle or the reference translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4496">
<title id=" N04-1021.xml">a smorgasbord of features for statistical machine translation </title>
<section> tree-based feature functions.  </section>
<citcontext>
<prevsection>
<prevsent>a tree-to-string model is one of several syntax based translation models used.
</prevsent>
<prevsent>the model is conditional probability p(f |t (e)).
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
here, we used model defined by yamada and knight (2001) <papid> P01-1067 </papid>and yamada and knight (2002).<papid> P02-1039 </papid>internally, the model performs three types of operations on each node of parse tree.</citsent>
<aftsection>
<nextsent>first, it re orders the child nodes, such as changing vp ? vb np pp into vp ? np pp vb.
</nextsent>
<nextsent>second, it inserts an optional word at each node.
</nextsent>
<nextsent>third, it translates the leaf english words into chinese words.
</nextsent>
<nextsent>these operations are stochastic and their probabilities are assumed to depend only on the node, and are independent of other operations on the node, or other nodes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4497">
<title id=" N04-1021.xml">a smorgasbord of features for statistical machine translation </title>
<section> tree-based feature functions.  </section>
<citcontext>
<prevsection>
<prevsent>a tree-to-string model is one of several syntax based translation models used.
</prevsent>
<prevsent>the model is conditional probability p(f |t (e)).
</prevsent>
</prevsection>
<citsent citstr=" P02-1039 ">
here, we used model defined by yamada and knight (2001) <papid> P01-1067 </papid>and yamada and knight (2002).<papid> P02-1039 </papid>internally, the model performs three types of operations on each node of parse tree.</citsent>
<aftsection>
<nextsent>first, it re orders the child nodes, such as changing vp ? vb np pp into vp ? np pp vb.
</nextsent>
<nextsent>second, it inserts an optional word at each node.
</nextsent>
<nextsent>third, it translates the leaf english words into chinese words.
</nextsent>
<nextsent>these operations are stochastic and their probabilities are assumed to depend only on the node, and are independent of other operations on the node, or other nodes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4499">
<title id=" N04-1021.xml">a smorgasbord of features for statistical machine translation </title>
<section> tree-based feature functions.  </section>
<citcontext>
<prevsection>
<prevsent>a tree-to-tree translation model makes use of syntactic tree for both the source and target language.
</prevsent>
<prevsent>as in the tree-to-string model, set of operations apply, each with some probability, to transform one tree into another.
</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
however, when training the model, trees for both the source and target languages are provided, in our case from the chinese and english parsers.we began with the tree-to-tree alignment model presented by gildea (2003).<papid> P03-1011 </papid></citsent>
<aftsection>
<nextsent>the model was extended to handle dependency trees, and to make use of the word-level alignments produced by the baseline mt system.
</nextsent>
<nextsent>the probability assigned by the tree-to-tree alignment model, given the word-level alignment with which the candidate translation was generated, was used as feature in our rescoring system.
</nextsent>
<nextsent>we trained the parameters of the tree transformation operations on 42,000 sentence pairs of parallel chinese english data from the foreign broadcast information service (fbis) corpus.
</nextsent>
<nextsent>the lexical translation probabilities pt were trained using ibm model 1 on the 30 million word training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4500">
<title id=" N06-2033.xml">parser combination by re parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we apply this idea to dependency and constituent parsing, generating results that surpass state-of-the art accuracy levels for individual parsers.
</prevsent>
<prevsent>over the past decade, remarkable progress has been made in data-driven parsing.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
much of this work has been fueled by the availability of large corpora annotated with syntactic structures, especially the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>in fact, years of extensive research on training and testing parsers on the wall street journal (wsj) corpus of the penn treebank have resulted in the availability of several high-accuracy parsers.
</nextsent>
<nextsent>we present framework for combining the out put of several different accurate parsers to produce results that are superior to those of each of the individual parsers.
</nextsent>
<nextsent>this is done in two stage process of reparsing.
</nextsent>
<nextsent>in the first stage, different parsers analyze an input sentence, each producing syntactic structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4501">
<title id=" N06-2033.xml">parser combination by re parsing </title>
<section> dependency re parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in the second stage, parsing algorithm is applied to the original sentence, taking into account the analyses produced by each parser in the first stage.
</prevsent>
<prevsent>our approach produces results with accuracy above those of the best individual parsers on both dependency and constituent parsing of the standard wsj test set.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
in dependency re parsing we focus on unlabeled dependencies, as described by eisner (1996).<papid> C96-1058 </papid></citsent>
<aftsection>
<nextsent>in this scheme, the syntactic structure for sentence with words is dependency tree representing head-dependent relations between pairs of words.
</nextsent>
<nextsent>when parsers each output set of dependencies (forming dependency structures) forgiven sentence containing words, the dependencies can be combined in simple word by-word voting scheme, where each parser votes for the head of each of the words in the sentence, and the head with most votes is assigned to each word.
</nextsent>
<nextsent>this very simple scheme guarantees that the final set of dependencies will have as many votes as possible, but it does not guarantee that the final voted set of dependencies will be well-formed dependency tree.
</nextsent>
<nextsent>in fact, the resulting graph may not even be connected.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4502">
<title id=" N06-2033.xml">parser combination by re parsing </title>
<section> dependency re parsing.  </section>
<citcontext>
<prevsection>
<prevsent>as long as at least one of the initial structures is well-formed dependency structure, the directed graph created this way will be connected.
</prevsent>
<prevsent>1 determining the weights is discussed in section 4.1.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
129 once this graph is created, we reparse the sentence using dependency parsing algorithm such as, for example, one of the algorithms described by mcdonald et al (2005).<papid> H05-1066 </papid></citsent>
<aftsection>
<nextsent>finding the optimal dependency structure given the set of weighted dependencies is simply matter of finding the maximum spanning tree (mst) for the directed weighted graph, which can be done using the chu-liu/edmonds directed mst algorithm (chu &amp; liu, 1965; edmonds, 1967).
</nextsent>
<nextsent>the maximum spanning tree maximizes the votes for dependencies given the constraint that the resulting structure must be tree.
</nextsent>
<nextsent>if projectivity (no crossing branches) is desired, eisners (1996) dynamic programming algorithm (similar to cyk) for dependency parsing can be used instead.
</nextsent>
<nextsent>in constituent re parsing we deal with labeled constituent trees, or phrase structure trees, such as those in the penn treebank (after removing traces, empty nodes and function tags).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4503">
<title id=" N06-2033.xml">parser combination by re parsing </title>
<section> constituent re parsing.  </section>
<citcontext>
<prevsection>
<prevsent>intuitively, this should increase precision, since we expect that constituent that appears in the output of more parsers to be more likely to be correct.
</prevsent>
<prevsent>by changing the threshold we can control the precision/recall tradeoff.
</prevsent>
</prevsection>
<citsent citstr=" W99-0623 ">
henderson and brill (1999) <papid> W99-0623 </papid>proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds new tree from constituents from the initial trees.</citsent>
<aftsection>
<nextsent>the latter scheme performed better, producing remarkable results despite its simplicity.
</nextsent>
<nextsent>the combination is done with simple majority vote of whether or not constituents should appear in the combined tree.
</nextsent>
<nextsent>in other words, if constituent appears at least (m + 1)/2 times in the output of the parsers, the constituent is added to the final tree.
</nextsent>
<nextsent>this simple vote resulted in trees with f-score significantly higher than the one of the best parser in the combination.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4505">
<title id=" N06-2033.xml">parser combination by re parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>however, the scheme heavily favors precision over recall.
</prevsent>
<prevsent>their results on wsj section 23 were 92.1 precision and 89.2 recall (90.61 f-score), well above the most accurate parser in their experiments (88.6 f-score).
</prevsent>
</prevsection>
<citsent citstr=" C04-1010 ">
in our dependency parsing experiments we used unlabeled dependencies extracted from the penn 130 treebank using the same head-table as yamada and matsumoto (2003), using sections 02-21 as training data and section 23 as test data, following (mcdonald et al, 2005; <papid> H05-1066 </papid>nivre &amp; scholz, 2004; <papid> C04-1010 </papid>yamada &amp; matsumoto, 2003).</citsent>
<aftsection>
<nextsent>dependencies extracted from section 00 were used as held-out data, and section 22 was used as additional development data.
</nextsent>
<nextsent>for constituent parsing, we used the section splits of the penn treebank as described above, as has become standard in statistical parsing research.
</nextsent>
<nextsent>4.1 dependency re parsing experiments.
</nextsent>
<nextsent>six dependency parsers were used in our combination experiments, as described below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4509">
<title id=" N06-2033.xml">parser combination by re parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>lr 91.0 92.6 rl 90.1 86.3 lrrl 89.6 89.1 mcdonald 90.9 94.2 reparse dep 1 91.8 96.0 reparse dep 2 92.1 95.9 reparse dep 3 92.7 96.6 table 1: dependency accuracy and root accuracy of individual dependency parsers and their combination under three different weighted re parsing settings.
</prevsent>
<prevsent>4.2 constituent re parsing experiments.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
the parsers that were used in the constituent re parsing experiments are: (1) charniak and johnsons (2005) <papid> P05-1022 </papid>reranking parser; (2) hendersons (2004) synchronous neural network parser; (3) bikels (2002) implementation of the collins (1999) model 2 parser; and (4) two versions of sa gae and lavies (2005) <papid> W05-1513 </papid>shift-reduce parser, one using maximum entropy classifier, and one using support vector machines.</citsent>
<aftsection>
<nextsent>henderson and brills voting scheme mentioned in section 3 can be emulated by our re parsing approach by setting all weights to 1.0 and to (m + 1)/2, but better results can be obtained by setting appropriate weights and adjusting the preci sion/recall tradeoff.
</nextsent>
<nextsent>weights for different types of 131constituents from each parser can be set in similar way to configuration 3 in the dependency experiments.
</nextsent>
<nextsent>however, instead of measuring accuracy for each part-of-speech tag of dependents, we measure precision for each non-terminal label.
</nextsent>
<nextsent>the parameter is set using held-out data (from wsj section 22) and simple hill-climbing procedure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4510">
<title id=" N06-2033.xml">parser combination by re parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>lr 91.0 92.6 rl 90.1 86.3 lrrl 89.6 89.1 mcdonald 90.9 94.2 reparse dep 1 91.8 96.0 reparse dep 2 92.1 95.9 reparse dep 3 92.7 96.6 table 1: dependency accuracy and root accuracy of individual dependency parsers and their combination under three different weighted re parsing settings.
</prevsent>
<prevsent>4.2 constituent re parsing experiments.
</prevsent>
</prevsection>
<citsent citstr=" W05-1513 ">
the parsers that were used in the constituent re parsing experiments are: (1) charniak and johnsons (2005) <papid> P05-1022 </papid>reranking parser; (2) hendersons (2004) synchronous neural network parser; (3) bikels (2002) implementation of the collins (1999) model 2 parser; and (4) two versions of sa gae and lavies (2005) <papid> W05-1513 </papid>shift-reduce parser, one using maximum entropy classifier, and one using support vector machines.</citsent>
<aftsection>
<nextsent>henderson and brills voting scheme mentioned in section 3 can be emulated by our re parsing approach by setting all weights to 1.0 and to (m + 1)/2, but better results can be obtained by setting appropriate weights and adjusting the preci sion/recall tradeoff.
</nextsent>
<nextsent>weights for different types of 131constituents from each parser can be set in similar way to configuration 3 in the dependency experiments.
</nextsent>
<nextsent>however, instead of measuring accuracy for each part-of-speech tag of dependents, we measure precision for each non-terminal label.
</nextsent>
<nextsent>the parameter is set using held-out data (from wsj section 22) and simple hill-climbing procedure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4511">
<title id=" N03-1002.xml">japanese named entity extraction with redundant morphological analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1 illustrates the example with english translation.
</prevsent>
<prevsent>some previous works try to cope with the word unit problem: uchimoto (uchimoto et al , 2000) introduces transformation rules to modify the word units given by morphological analyzer.
</prevsent>
</prevsection>
<citsent citstr=" C02-1054 ">
isozaki (isozaki and kazawa,2002) <papid> C02-1054 </papid>controls the parameters of statistical morphological analyzer so as to produce more fine-grained output.</citsent>
<aftsection>
<nextsent>these method are used as preprocessing of chunking.
</nextsent>
<nextsent>by contrast, we propose more straightforward meth odin which we perform the chunking process based on character units.
</nextsent>
<nextsent>each character receives annotations with character type and multiple pos information of the words found by morphological analyzer.
</nextsent>
<nextsent>we make use of redundant outputs of the morphological analysis as the base features for the chunker to introduce more information rich features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4512">
<title id=" N03-1002.xml">japanese named entity extraction with redundant morphological analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>each character receives annotations with character type and multiple pos information of the words found by morphological analyzer.
</prevsent>
<prevsent>we make use of redundant outputs of the morphological analysis as the base features for the chunker to introduce more information rich features.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
we use support vector machine (svm) based chunker yamcha (kudo and matsumoto, 2001) <papid> N01-1025 </papid>for the chunking process.</citsent>
<aftsection>
<nextsent>our method achieves better scor ethan all the systems reported previously for irex ne extraction task.section 2 presents the irex ne extraction task.
</nextsent>
<nextsent>section 3 describes our method in detail.
</nextsent>
<nextsent>in section 4, weshow the results of experiments, and finally we give conclusions in section 5.
</nextsent>
<nextsent>the task of ne extraction in the irex workshop is to recognize eight ne types as shown in table 1 (irexcommittee, editor, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4513">
<title id=" N03-1002.xml">japanese named entity extraction with redundant morphological analysis </title>
<section> irex ne extraction task.  </section>
<citcontext>
<prevsection>
<prevsent>figure 2: examples of ne tag sets table 1: examples of nes in irex ne type examples in english artifact nobel prize in chemistry date may 5th location republic of korea money 2 million dollars organization social democratic party percent 20 %, thirty percents person murayama tomiichi time five in the morning tify word sequences which compose nes.
</prevsent>
<prevsent>the chunking problem is solved by annotation of chunk tags to tokens.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
five chunk tag sets, iob1, iob2, ioe1, ioe2 (ramshaw and marcus, 1995) <papid> W95-0107 </papid>and se (uchimoto et al , 2000), are commonly used.</citsent>
<aftsection>
<nextsent>in iob1 and iob2 models, three tags i, and are used, meaning inside, outside and beginning of chunk.
</nextsent>
<nextsent>in iob1, is used only at the beginning of chunk that immediately follows another chunk, while in iob2, is always used at the beginning of chunk.
</nextsent>
<nextsent>ioe1 and ioe2 use tag instead of and are almost the same as iob1 and iob2 except that the endpoints of chunks are tagged with e. in se model, is tagged only to one symbol chunks, and b, and denote exactly the beginning, intermediate and endpoints of chunk.
</nextsent>
<nextsent>generally, the words given by the single output of morphological analyzer are used as the units for chunking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4516">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we identify problems with the penn treebank that render it imperfect for syntax based machine translation and propose methods of relabeling the syntax trees to improve translation quality.
</prevsent>
<prevsent>we develop asystem incorporating handful of relabeling strategies that yields statistically significant improvement of 2.3 bleu points over baseline syntax-based system.
</prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</citsent>
<aftsection>
<nextsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.
</nextsent>
<nextsent>some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></nextsent>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4517">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we identify problems with the penn treebank that render it imperfect for syntax based machine translation and propose methods of relabeling the syntax trees to improve translation quality.
</prevsent>
<prevsent>we develop asystem incorporating handful of relabeling strategies that yields statistically significant improvement of 2.3 bleu points over baseline syntax-based system.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</citsent>
<aftsection>
<nextsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.
</nextsent>
<nextsent>some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></nextsent>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4518">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we identify problems with the penn treebank that render it imperfect for syntax based machine translation and propose methods of relabeling the syntax trees to improve translation quality.
</prevsent>
<prevsent>we develop asystem incorporating handful of relabeling strategies that yields statistically significant improvement of 2.3 bleu points over baseline syntax-based system.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</citsent>
<aftsection>
<nextsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.
</nextsent>
<nextsent>some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></nextsent>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4519">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</prevsent>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4520">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</prevsent>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.</prevsent>
</prevsection>
<citsent citstr=" J00-1004 ">
some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4521">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</prevsent>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4522">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</prevsent>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4523">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</prevsent>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.</prevsent>
</prevsection>
<citsent citstr=" P03-2041 ">
some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4524">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</prevsent>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.</prevsent>
</prevsection>
<citsent citstr=" P04-1083 ">
some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4525">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</prevsent>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4526">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</prevsent>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4527">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</prevsent>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4528">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work in statistical machine translation (mt)has sought to overcome the limitations of phrase based models (marcu and wong, 2002; <papid> W02-1018 </papid>koehn et al., 2003; <papid> N03-1017 </papid>och and ney, 2004) <papid> J04-4002 </papid>by making useof syntactic information.</prevsent>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</nextsent>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4529">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.
</prevsent>
<prevsent>some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</citsent>
<aftsection>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.
</nextsent>
<nextsent>the source string to translate (
</nextsent>
<nextsent>      .) is shown at the top left.
</nextsent>
<nextsent>rule 1?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4530">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>syntax-based mt offers the potential advantages of enforcing syntax motivated constraints in translation and capturing long-distance/non-contiguous dependencies.
</prevsent>
<prevsent>some approaches have used syntax at the core (wu, 1997; <papid> J97-3002 </papid>alshawi et al, 2000; <papid> J00-1004 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>eisner, 2003; <papid> P03-2041 </papid>hearne and way, 2003;melamed, 2004) <papid> P04-1083 </papid>while others have integrated syntax into existing phrase-based frameworks (xia and mccord, 2004; <papid> C04-1073 </papid>chiang, 2005; <papid> P05-1033 </papid>collins et al, 2005; <papid> P05-1066 </papid>quirk et al, 2005).<papid> P05-1034 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1014 ">
in this work, we employ syntax-based model that applies series of tree/string (xrs) rules (gal ley et al, 2004; <papid> N04-1035 </papid>graehl and knight, 2004) <papid> N04-1014 </papid>to source language string to produce target language phrase structure tree.</citsent>
<aftsection>
<nextsent>figure 1 exemplifies the translation process, which is called derivation, from chinese into english.
</nextsent>
<nextsent>the source string to translate (
</nextsent>
<nextsent>      .) is shown at the top left.
</nextsent>
<nextsent>rule 1?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4531">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is translated as the np-c the gunman by rule 3?.
</prevsent>
<prevsent>finally, rule 4combines the sequence of np-c vp . into an s, denoting complete tree.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the yield of this tree gives the target translation: the gunman was killed by police . the penn english treebank (ptb) (marcus et al, 1993) <papid> J93-2004 </papid>is our source of syntactic information, largely due to the availability of reliable parsers.</citsent>
<aftsection>
<nextsent>it is not clear, however, whether this resource is suitable, as is, for the task of mt. in this paper, we argue that the overly-general tagset of the ptb is problematic formt because it fails to capture important grammatical distinctions that are critical in translation.
</nextsent>
<nextsent>as asolution, we propose methods of relabeling the syntax trees that effectively improve translation quality.
</nextsent>
<nextsent>consider the derivation in figure 2.
</nextsent>
<nextsent>the output translation has two salient errors: determiner/noun number disagreement (*this turkish positions) andauxiliary/verb tense disagreement (*has demon strate).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4532">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> experimental framework.  </section>
<citcontext>
<prevsection>
<prevsent>our training data consists of 164m+167m words of parallel chinese/english text.
</prevsent>
<prevsent>the english half was parsed with re implementation of collins?
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
model2 (collins, 1999) and the two halves were word aligned using giza++ (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>these three components ? chinese strings, english parse trees, and their word alignments ? were inputs to our experimental procedure, which involved fivesteps: (1) tree relabeling, (2) rule extraction, (3) decoding, (4) n-best reranking, (5) evaluation.this paper focuses on step 1, in which the original english parse trees are transformed by one ormore relabeling strategies.
</nextsent>
<nextsent>step 2 involves extracting minimal xrs rules (galley et al, 2004) <papid> N04-1035 </papid>from the set of string/tree/alignments triplets.</nextsent>
<nextsent>these rules are then used in cky-type parser-decoder to translate the 878-sentence 2002 nist mt evaluation testset (step 3).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4534">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> experimental framework.  </section>
<citcontext>
<prevsection>
<prevsent>these rules are then used in cky-type parser-decoder to translate the 878-sentence 2002 nist mt evaluation testset (step 3).
</prevsent>
<prevsent>in step 4, the output 2,500-sentence best list is reranked using an n-gram language model trained on 800m words of english news text.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
in the final step, we score our translations with 4-gram bleu (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>separately for each relabeling method, we ran these five steps and compared the resulting bleu score with that of baseline system with no relabeling.
</nextsent>
<nextsent>to determine if bleu score increase or decrease is meaningful, we calculate statistical significance at 95% using paired bootstrap resam pling (koehn, 2004; <papid> W04-3250 </papid>zhang et al, 2004) on 1,000 samples.figure 3 shows the results from each relabeling experiment.</nextsent>
<nextsent>the second column indicates the change in the number of unique rules from the base line number of 16.7m rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4535">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> experimental framework.  </section>
<citcontext>
<prevsection>
<prevsent>in the final step, we score our translations with 4-gram bleu (papineni et al, 2002).<papid> P02-1040 </papid></prevsent>
<prevsent>separately for each relabeling method, we ran these five steps and compared the resulting bleu score with that of baseline system with no re labeling.</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
to determine if bleu score increase or decrease is meaningful, we calculate statistical significance at 95% using paired bootstrap resam pling (koehn, 2004; <papid> W04-3250 </papid>zhang et al, 2004) on 1,000 samples.figure 3 shows the results from each relabeling experiment.</citsent>
<aftsection>
<nextsent>the second column indicates the change in the number of unique rules from the base line number of 16.7m rules.
</nextsent>
<nextsent>the third column gives the bleu score along with an indication whether itis statistically significant increase (s), statistically significant decrease (t), or neither (?)
</nextsent>
<nextsent>over the baseline bleu score.
</nextsent>
<nextsent>241 figure 2: bad translation fixable by relabeling.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4536">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> relabeling.  </section>
<citcontext>
<prevsection>
<prevsent>242 relabeling variant ? # rules bleu ? baseline ? 20.06 ? lex_prep 1 +301.2k 20.2 2 +254.8k 20.36 3 +188.3k 20.14 lex_dt 1 +36.1k 20.15 2 +29.6k 20.18 lex_aux 1 +5.1k 20.09 2 +8.0k 20.09 ? 3 +1.6k 20.11 4 +13.8k 20.07 ? lex_cc +3.3k 20.03 lex_% +0.3k 20.14 tag_vp +123.6k 20.28 sisterhood 1 +1.1m 21.33 2 +935.5k 20.91 3 +433.1k 20.36 4 +407.0k 20.59 parent 1 +1.1m 19.77 2 +9.0k 20.01 3 +2.9m 15.63 comp_in +17.4k 20.36 rem_npb 3.5k 19.93 rem_-c 143.4k 19.3 rem_sg 9.4k 20.01 figure 3: for each relabeling method and variant, the impact on ruleset size and bleu score over the baseline.
</prevsent>
<prevsent>the small tagset of the ptb has the advantage of being simple to annotate and to parse.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
on the other hand, this can lead to tags that are overly generic.klein and manning (2003) <papid> P03-1054 </papid>discuss this as problem in parsing and demonstrate that annotating additional information onto the ptb tags leads to improved parsing performance.</citsent>
<aftsection>
<nextsent>we similarly propose methods of relabeling ptb trees that notably im prove mt quality.
</nextsent>
<nextsent>in the next two subsections, we explore relabeling strategies that fall under two categories introduced by klein and manning ? internal annotation and external annotation.
</nextsent>
<nextsent>3.1 internal annotation.
</nextsent>
<nextsent>internal annotation reveals information about node and its descendants to its surrounding nodes(ancestors, sisters, and other relatives) that is otherwise hidden.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4540">
<title id=" N06-1031.xml">relabeling syntax trees to improve syntax based machine translation quality </title>
<section> relabeling.  </section>
<citcontext>
<prevsection>
<prevsent>variants 1 and 2 produced the largest gains from relabeling: 1.27 and 0.85 bleu points, respectively.figure 7: rules before and after sisterhood annotation.
</prevsent>
<prevsent>figure 8: rules before and after parent annotation.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
3.2.2 parent annotation another common relabeling method in parsing is parent annotation (johnson, 1998), <papid> J98-4004 </papid>in which node is annotated with its parents label.</citsent>
<aftsection>
<nextsent>typically, thisis done only to nonterminals, but klein and manning (2003) <papid> P03-1054 </papid>found that annotating pre terminals as well was highly effective.</nextsent>
<nextsent>it seemed likely that such contextual information could also benefit mt. let us tackle the bad output from figure 6 with parent annotation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4543">
<title id=" N06-2036.xml">word domain disambiguation via word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, in review of commonly used features in automated translation, mowatt (1999) reports that most of the machine translation systems surveyed made use of word subject domains.
</prevsent>
<prevsent>word subject domains have also been used in information systems.
</prevsent>
</prevsection>
<citsent citstr=" P98-2189 ">
for example, sanfilippo (1998) <papid> P98-2189 </papid>describes summarization system where subject domains provide users with useful conceptual parameters to tailor summary requests to users interest.</citsent>
<aftsection>
<nextsent>successful usage of word domains in applications such as machine translation and summarization is strongly dependent on the ability to assign the appropriate subject domain to word in its context.
</nextsent>
<nextsent>such an assignment requires process of word domain disambiguation (wdd) because the same word can often be assigned different subject domains out of context (e.g. the word partner can potentially be related to finance or marriage).
</nextsent>
<nextsent>interestingly enough, word subject domains have been widely used to improve the performance of word sense disambiguation (wsd) algorithms (wilks and stevenson 1998, <papid> P98-2228 </papid>magnini et al 2001; gliozzo et al 2004).</nextsent>
<nextsent>however, comparatively little effort has been devoted so far to the word domain disambiguation itself.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4544">
<title id=" N06-2036.xml">word domain disambiguation via word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>successful usage of word domains in applications such as machine translation and summarization is strongly dependent on the ability to assign the appropriate subject domain to word in its context.
</prevsent>
<prevsent>such an assignment requires process of word domain disambiguation (wdd) because the same word can often be assigned different subject domains out of context (e.g. the word partner can potentially be related to finance or marriage).
</prevsent>
</prevsection>
<citsent citstr=" P98-2228 ">
interestingly enough, word subject domains have been widely used to improve the performance of word sense disambiguation (wsd) algorithms (wilks and stevenson 1998, <papid> P98-2228 </papid>magnini et al 2001; gliozzo et al 2004).</citsent>
<aftsection>
<nextsent>however, comparatively little effort has been devoted so far to the word domain disambiguation itself.
</nextsent>
<nextsent>the most notable exceptions are the work of magnini and strapparava (2000) <papid> W00-0804 </papid>and suarez &amp; palomar (2002).</nextsent>
<nextsent>both studies propose algorithms specific to the wdd task and have focused on the disambiguation of noun domains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4545">
<title id=" N06-2036.xml">word domain disambiguation via word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>interestingly enough, word subject domains have been widely used to improve the performance of word sense disambiguation (wsd) algorithms (wilks and stevenson 1998, <papid> P98-2228 </papid>magnini et al 2001; gliozzo et al 2004).</prevsent>
<prevsent>however, comparatively little effort has been devoted so far to the word domain disambiguation itself.</prevsent>
</prevsection>
<citsent citstr=" W00-0804 ">
the most notable exceptions are the work of magnini and strapparava (2000) <papid> W00-0804 </papid>and suarez &amp; palomar (2002).</citsent>
<aftsection>
<nextsent>both studies propose algorithms specific to the wdd task and have focused on the disambiguation of noun domains.
</nextsent>
<nextsent>in this paper we explore an alternative approach where word domain disambiguation is achieved via word sense disambiguation.
</nextsent>
<nextsent>more over, we extend the treatment of wdd to verbs and adjectives.
</nextsent>
<nextsent>initial results show that this approach yield very strong results, suggesting that wdd can be addressed in terms of word sense disambiguation with no need of special purpose algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4546">
<title id=" N06-2036.xml">word domain disambiguation via word sense disambiguation </title>
<section> wdd via wsd.  </section>
<citcontext>
<prevsection>
<prevsent>to assign sense to each word in the input text, we used the wsd algorithm presented in sanfilippo et al (2006).
</prevsent>
<prevsent>this wsd algorithm is based on supervised classification approach that uses semcor1 as training corpus.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the algorithm employs the opennlp maxent implementation of the maximum entropy classification algorithm (berger et al 1996) <papid> J96-1002 </papid>to develop word sense recognition signatures for each lemma which predicts the most likely sense for the lemma according to the context in which the lemma occurs.</citsent>
<aftsection>
<nextsent>following dang &amp; palmer (2005) <papid> P05-1006 </papid>and kohomban &amp; lee (2005), <papid> P05-1005 </papid>sanfilippo et al (2006) use contextual, syntactic and semantic information to inform our verb class disambiguation system.</nextsent>
<nextsent>contextual information includes the verb under analysis plus three tokens found on each side of the verb, within sentence boundaries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4547">
<title id=" N06-2036.xml">word domain disambiguation via word sense disambiguation </title>
<section> wdd via wsd.  </section>
<citcontext>
<prevsection>
<prevsent>this wsd algorithm is based on supervised classification approach that uses semcor1 as training corpus.
</prevsent>
<prevsent>the algorithm employs the opennlp maxent implementation of the maximum entropy classification algorithm (berger et al 1996) <papid> J96-1002 </papid>to develop word sense recognition signatures for each lemma which predicts the most likely sense for the lemma according to the context in which the lemma occurs.</prevsent>
</prevsection>
<citsent citstr=" P05-1006 ">
following dang &amp; palmer (2005) <papid> P05-1006 </papid>and kohomban &amp; lee (2005), <papid> P05-1005 </papid>sanfilippo et al (2006) use contextual, syntactic and semantic information to inform our verb class disambiguation system.</citsent>
<aftsection>
<nextsent>contextual information includes the verb under analysis plus three tokens found on each side of the verb, within sentence boundaries.
</nextsent>
<nextsent>tokens included word as well as punctuation.
</nextsent>
<nextsent>syntactic information includes grammatical dependencies (e.g. subject, object) and mor pho-syntactic features such as part of speech, case, number and tense.
</nextsent>
<nextsent>semantic information includes named entity types (e.g. person, location, organization) and hypernyms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4548">
<title id=" N06-2036.xml">word domain disambiguation via word sense disambiguation </title>
<section> wdd via wsd.  </section>
<citcontext>
<prevsection>
<prevsent>this wsd algorithm is based on supervised classification approach that uses semcor1 as training corpus.
</prevsent>
<prevsent>the algorithm employs the opennlp maxent implementation of the maximum entropy classification algorithm (berger et al 1996) <papid> J96-1002 </papid>to develop word sense recognition signatures for each lemma which predicts the most likely sense for the lemma according to the context in which the lemma occurs.</prevsent>
</prevsection>
<citsent citstr=" P05-1005 ">
following dang &amp; palmer (2005) <papid> P05-1006 </papid>and kohomban &amp; lee (2005), <papid> P05-1005 </papid>sanfilippo et al (2006) use contextual, syntactic and semantic information to inform our verb class disambiguation system.</citsent>
<aftsection>
<nextsent>contextual information includes the verb under analysis plus three tokens found on each side of the verb, within sentence boundaries.
</nextsent>
<nextsent>tokens included word as well as punctuation.
</nextsent>
<nextsent>syntactic information includes grammatical dependencies (e.g. subject, object) and mor pho-syntactic features such as part of speech, case, number and tense.
</nextsent>
<nextsent>semantic information includes named entity types (e.g. person, location, organization) and hypernyms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4549">
<title id=" N06-2036.xml">word domain disambiguation via word sense disambiguation </title>
<section> wdd via wsd.  </section>
<citcontext>
<prevsection>
<prevsent>syntactic information includes grammatical dependencies (e.g. subject, object) and mor pho-syntactic features such as part of speech, case, number and tense.
</prevsent>
<prevsent>semantic information includes named entity types (e.g. person, location, organization) and hypernyms.
</prevsent>
</prevsection>
<citsent citstr=" W04-0811 ">
we chose this wsd algorithm as it provides some of the best published results to date, as the comparison with top performing wsd systems in senseval3 presented in table 1 shows---see http://www.senseval.org and snyder &amp; palmer (2004) <papid> W04-0811 </papid>for terms of reference on senseval3.</citsent>
<aftsection>
<nextsent>1 http://www.cs.unt.edu/~rada/downloads.html.
</nextsent>
<nextsent>142 system precision fraction of recall sanfilippo et al 2006 61% 22% gambl 59.0% 21.3% sense learner 56.1% 20.2% baseline 52.9% 19.1% table 1: results for verb sense disambiguation on senseval3 data, adapted from sanfilippo et al (2006).
</nextsent>
<nextsent>to evaluate our wdd approach, we used both the semcor and senseval3 datasets.
</nextsent>
<nextsent>both corpora were stripped of their sense annotations and processed with an extension of the wsd algorithm of sanfilippo et al (2006) to assign wordnet sense to each noun, verb and adjective.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4550">
<title id=" N06-2036.xml">word domain disambiguation via word sense disambiguation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to evaluate our wdd approach, we used both the semcor and senseval3 datasets.
</prevsent>
<prevsent>both corpora were stripped of their sense annotations and processed with an extension of the wsd algorithm of sanfilippo et al (2006) to assign wordnet sense to each noun, verb and adjective.
</prevsent>
</prevsection>
<citsent citstr=" W02-0817 ">
the extension consisted in extending the training dataset so as to include selection of wordnet examples (full sentences containing main verb) and the open mind word expert corpus (chklovski and mihalcea 2002).<papid> W02-0817 </papid></citsent>
<aftsection>
<nextsent>the original hand-coded word sense annotations of the semcor and senseval3 corpora and the word sense annotations assigned by the wsd algorithm used in this study were mapped into subject domain annotations using wordnet domains, as described in the opening paragraph of section 2 above.
</nextsent>
<nextsent>the version of the semcor and senseval3 corpora where subject domain annotations were generated from hand-coded word senses served as gold standard.
</nextsent>
<nextsent>a baseline for both corpora was obtained by assigning to each lemma the subject domain corresponding to sense 1 of the lemma.
</nextsent>
<nextsent>wdd results of tenfold cross-validation for the semcor dataset are given in table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4552">
<title id=" N04-4022.xml">context based speech recognition error detection and correction </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>we describe the contextual analysis in section 2.2.
</prevsent>
<prevsent>from the set of candidate error regions, asr errors are detected using phonetic comparison between the query word and words in the window; this phonetic analysis is described in section 2.3.
</prevsent>
</prevsection>
<citsent citstr=" P98-2182 ">
our approach to asr error detection and correction builds on recent work in statistical lexical and contextual modeling using co-occurrence analysis, such as (roark and charniak, 1998).<papid> P98-2182 </papid></citsent>
<aftsection>
<nextsent>we apply the contextual modeling to speech retrieval task, as in (kupiec et al, 1994).<papid> H94-1074 </papid></nextsent>
<nextsent>inthe earlier work, general mathematical models were developed to measure lexical similarity between words in context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4553">
<title id=" N04-4022.xml">context based speech recognition error detection and correction </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>from the set of candidate error regions, asr errors are detected using phonetic comparison between the query word and words in the window; this phonetic analysis is described in section 2.3.
</prevsent>
<prevsent>our approach to asr error detection and correction builds on recent work in statistical lexical and contextual modeling using co-occurrence analysis, such as (roark and charniak, 1998).<papid> P98-2182 </papid></prevsent>
</prevsection>
<citsent citstr=" H94-1074 ">
we apply the contextual modeling to speech retrieval task, as in (kupiec et al, 1994).<papid> H94-1074 </papid></citsent>
<aftsection>
<nextsent>inthe earlier work, general mathematical models were developed to measure lexical similarity between words in context.
</nextsent>
<nextsent>we seek to develop simple contextual model based on word co-occurrences in order to facilitate the retrieval of spoken documents containing critical word errors.
</nextsent>
<nextsent>our approach has similar goal to that of logan(2002); however, their work focuses primarily on out of-vocabulary words while we focus on in-vocabulary words.
</nextsent>
<nextsent>our work also builds on recent directions in language modeling for speech recognition, in which abroader context beyond n-grams is considered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4554">
<title id=" N03-1022.xml">cogex a logic prover for question answering </title>
<section> integration of logic prover into qa.  </section>
<citcontext>
<prevsection>
<prevsent>edmonton, may-june 2003 main papers , pp.
</prevsent>
<prevsent>87-93 proceedings of hlt-naacl 2003
</prevsent>
</prevsection>
<citsent citstr=" C02-1167 ">
system the qa system includes traditional modules such as question processing, document retrieval, answer extraction, built in ontologies, as well as many tools such as syntactic parser, name entity recognizer, word sense disambiguation (moldovan and noviscki 2002), <papid> C02-1167 </papid>logic representation of text (moldovan andrus 2001) <papid> P01-1052 </papid>and others.the logic prover is integrated in this rich nlp environment and augments the qa system operation.</citsent>
<aftsection>
<nextsent>as shown in figure 1, the inputs to cogex consist oflogic representations of questions, potential answer paragraphs, world knowledge and lexical information.
</nextsent>
<nextsent>the term answer logic form (alf) refers to the candidate answers in logic form.
</nextsent>
<nextsent>candidate answers returned by the answer extraction module are classified as open text dueto the unpredictable nature of their grammatical structure.
</nextsent>
<nextsent>the term question logic form (qlf) refers to the questions posed to the question answering system represented in logic form.the prover also needs world knowledge axioms supplied by the wordnet glosses transformed into logic representations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4555">
<title id=" N03-1022.xml">cogex a logic prover for question answering </title>
<section> integration of logic prover into qa.  </section>
<citcontext>
<prevsection>
<prevsent>edmonton, may-june 2003 main papers , pp.
</prevsent>
<prevsent>87-93 proceedings of hlt-naacl 2003
</prevsent>
</prevsection>
<citsent citstr=" P01-1052 ">
system the qa system includes traditional modules such as question processing, document retrieval, answer extraction, built in ontologies, as well as many tools such as syntactic parser, name entity recognizer, word sense disambiguation (moldovan and noviscki 2002), <papid> C02-1167 </papid>logic representation of text (moldovan andrus 2001) <papid> P01-1052 </papid>and others.the logic prover is integrated in this rich nlp environment and augments the qa system operation.</citsent>
<aftsection>
<nextsent>as shown in figure 1, the inputs to cogex consist oflogic representations of questions, potential answer paragraphs, world knowledge and lexical information.
</nextsent>
<nextsent>the term answer logic form (alf) refers to the candidate answers in logic form.
</nextsent>
<nextsent>candidate answers returned by the answer extraction module are classified as open text dueto the unpredictable nature of their grammatical structure.
</nextsent>
<nextsent>the term question logic form (qlf) refers to the questions posed to the question answering system represented in logic form.the prover also needs world knowledge axioms supplied by the wordnet glosses transformed into logic representations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4561">
<title id=" N03-3009.xml">spoken and written news story segmentation using lexical chains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also examine the differences between spoken and written news styles and how these differences can affect segmentation accuracy.
</prevsent>
<prevsent>text segmentation can be defined as the automatic identification of boundaries between distinct textual units (segments) in textual document.
</prevsent>
</prevsection>
<citsent citstr=" J97-1003 ">
the aim of early segmentation research was to model the discourse structure of text, thus focusing on the detection of fine grained topic shifts, at clausal, sentence or pas sage/subtopic level (hearst 1997).<papid> J97-1003 </papid></citsent>
<aftsection>
<nextsent>more recently with the introduction of the tdt initiative (allan et al  1998) segmentation research has concentrated on the detection of coarse-grained topic shifts resulting in the identification of story boundaries in news feeds.
</nextsent>
<nextsent>in particular, unsegmented broadcast news streams represent challenging real-world application for text segmentation approaches, since the success of other tasks such as topic tracking or first story detection depend heavily on the correct identification of distinct and non-overlapping news stories.
</nextsent>
<nextsent>most approaches to story segmentation use either information extraction techniques (cue phrase extraction), techniques based on lexical cohesion analysis or combination of both (reynar 1998; beeferman et al  1999).
</nextsent>
<nextsent>more recently promising results have also been achieved though the use of hidden markov modeling techniques, which are commonly used in speech recognition applications (mulbregt et al  1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4563">
<title id=" N03-3009.xml">spoken and written news story segmentation using lexical chains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with respect to segmentation, an analysis of lexical cohesion can be used to indicate portions of text that represent single topical units or segments i.e. they contain high number of semantically related words.
</prevsent>
<prevsent>almost all approaches to lexical cohesion based segmentation examine patterns of syntactic repetition in the text e.g.
</prevsent>
</prevsection>
<citsent citstr=" A00-2004 ">
(reynar 1998; hearst 1997; <papid> J97-1003 </papid>choi 2000)<papid> A00-2004 </papid></citsent>
<aftsection>
<nextsent>however, there are four additional types of lexical cohesion present in text: synonymy (car, automobile), specialization/generalization (horse, stallion), part-whole/whole-part (politicians, govern ment) and statistical co-occurrences (osama bin laden, world trade center).
</nextsent>
<nextsent>lexical chaining based approaches to text segmentation, on the other hand, analyse all aspects of lexical cohesion in text.
</nextsent>
<nextsent>lexical chains are defined as groups of semantically related words that represent the lexical cohesive structure of text e.g. {flower, petal, rose, garden, tree}.
</nextsent>
<nextsent>in our lexical chaining implementation, words are clustered based on the existence of statistical relationships and lexico graphical associations (provided by the wordnet online thesaurus) between terms in text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4566">
<title id=" N03-3009.xml">spoken and written news story segmentation using lexical chains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our lexical chaining implementation, words are clustered based on the existence of statistical relationships and lexico graphical associations (provided by the wordnet online thesaurus) between terms in text.
</prevsent>
<prevsent>there have been three previous attempts to tackle text segmentation using lexical chains.
</prevsent>
</prevsection>
<citsent citstr=" W98-1123 ">
the first by okumara and honda (1994) involved an evaluation based on five japanese texts, the second by stairmand (1997) used twelve general interest magazine articles and the third by kan et al  (1998) <papid> W98-1123 </papid>used fifteen wall street journal and five economist articles.</citsent>
<aftsection>
<nextsent>all of these attempts focus on sub-topic rather than story segmentation.
</nextsent>
<nextsent>in contrast, this paper investigates the usefulness of lexical chains as technique for determining story segments in spoken and written broadcast news streams.
</nextsent>
<nextsent>in section 2, we explain how this technique can be refined edmonton, may-june 2003 student research workshop , pp.
</nextsent>
<nextsent>49-54 proceedings of hlt-naacl 2003 to address story segmentation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4572">
<title id=" N03-3009.xml">spoken and written news story segmentation using lexical chains </title>
<section> segmentation evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>however these metrics were deemed insufficiently sensitive when trying to determine system parameters that yield optimal performance.
</prevsent>
<prevsent>the most widely used evaluation metric is beeferman et al (1999) probabilistic error metric pk, which calculates segmentation accuracy with respect to three different types of segmentation error: false positives (falsely detected segments), false negatives (missed segments) and near-misses (very close but not exact boundaries).
</prevsent>
</prevsection>
<citsent citstr=" J02-1002 ">
however, in recent publication pevzner and hearst (2002) <papid> J02-1002 </papid>highlight several faults with the pk metric.</citsent>
<aftsection>
<nextsent>most notable they criticize pk for its unfair penal ization of false negatives over false positives and its over-penalization of near-misses.
</nextsent>
<nextsent>in their paper, the authors proposed an alternative error metric called window diff which rectifies these problems.
</nextsent>
<nextsent>3.3 story segmentation results.
</nextsent>
<nextsent>in this section we present performance results for each segmenter on both the cnn and reuters test sets with respect to the aforementioned evaluation metrics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4578">
<title id=" N03-3009.xml">spoken and written news story segmentation using lexical chains </title>
<section> written and spoken text segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>to look?
</prevsent>
<prevsent>or to try?.
</prevsent>
</prevsection>
<citsent citstr=" W98-0604 ">
to test this observation we re-ran c99 and text tiling experiments on the reuters and cnn b collections, using only nouns, adjectives, nominal ized verbs (provided by the nomlex (meyers et al  1998)), <papid> W98-0604 </papid>and nominal ized adjectives as input.</citsent>
<aftsection>
<nextsent>our results show that there is significant decrease in window diff error for the c99 system on both the cnn collection (a decrease from 0.351 to 0.268) and the reuters collection (a decrease from 0.148 to 0.121).
</nextsent>
<nextsent>similarly, we observe an improvement in the window diff based performance of the text tiling system on the cnn dataset (a decrease from 0.299 to 0.274).
</nextsent>
<nextsent>however, we observe marginal fall in performance on the reuters dataset (an increase from 0.244 to 0.247).
</nextsent>
<nextsent>these results illustrate the increased dominance of verbs in spoken text and the importance of function verb removal by our verb nomi nal ization process for cnn segmentation performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4579">
<title id=" N06-2028.xml">extracting salient keywords from instructional videos using joint text audio and visual cues </title>
<section> a text-based keyword extraction </section>
<citcontext>
<prevsection>
<prevsent>for the system evaluation, we used training and education videos that are freely downloadable from various dhs (department of homeland security) web sites.
</prevsent>
<prevsent>these were selected because 1) dhs has an increasing need for quickly browsing, searching and re-purposing its learning resources across its over twenty diverse agencies; 2) most dhs videos contain closed captions in compliance with federal accessibility requirements such as section 508.
</prevsent>
</prevsection>
<citsent citstr=" C02-1142 ">
system this section describes the text-based keyword extraction system, glossex, which we developed in our earlier work (park et al 2002).<papid> C02-1142 </papid></citsent>
<aftsection>
<nextsent>glossex applies hybrid method, which exploits both linguistic and statistical knowledge,to extract domain-specific keywords in document collection.
</nextsent>
<nextsent>glossex has been successfully used in largescale text analysis applications such as document authoring and indexing, back-of-book indexing, and contact center data analysis.
</nextsent>
<nextsent>an overall outline of the algorithm is given below.
</nextsent>
<nextsent>first, the algorithm identifies candidate glossary items byusing syntactic grammars as well as set of entity recog nizers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4580">
<title id=" N06-1002.xml">do we need phrases challenging the conventional wisdom in statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the last several years have seen phrasal statistical machine translation (smt) systems outperform word-based approaches by wide margin (koehn 2003).
</prevsent>
<prevsent>unfortunately the use of phrases in smt is beset by number of difficult theoretical and practical problems, which we attempt to characterize below.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
recent research into syntax based smt (quirk and menezes 2005; chiang 2005) <papid> P05-1033 </papid>has produced promising results in addressing some of the problems; research motivated by other statistical models has helped to address others (banchs et al 2005).</citsent>
<aftsection>
<nextsent>we refine and unify two threads of research in an attempt to address all of these problems simultaneously.
</nextsent>
<nextsent>such an approach proves both theoretically more desirable and empirically superior.
</nextsent>
<nextsent>in brief, phrasal smt systems employ phrase pairs automatically extracted from parallel corpora.
</nextsent>
<nextsent>to translate, source sentence is first partitioned into sequence of phrases = s1si.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4582">
<title id=" N06-1002.xml">do we need phrases challenging the conventional wisdom in statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>beam search is used to approximate the optimal translation.
</prevsent>
<prevsent>we refer the reader to keohn et al (2003) for detailed description.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
unless otherwise noted, the following discussion is generally applicable to alignment template systems (och and ney 2004) <papid> J04-4002 </papid>as well.</citsent>
<aftsection>
<nextsent>1.1.
</nextsent>
<nextsent>advantages of phrasal smt.
</nextsent>
<nextsent>non-compositionality phrases capture the translations of idiomatic and other non-compositional fixed phrases as unit, side-stepping the need to awkwardly reconstruct them word by word.
</nextsent>
<nextsent>while many words can be translated into single target word, common everyday phrases such as the english password translating as the french mot de passe cannot be easily subdivided.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4583">
<title id=" N06-1002.xml">do we need phrases challenging the conventional wisdom in statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given sentence of words, if the average target phrase length is 4 words (which is unusually high), then there ordering space is reduced from n!
</prevsent>
<prevsent>to only (n/4)!: still impractical for exact search in most sentences.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
systems must therefore impose some limits on phrasal reordering, often hard limits based on distance as in koehn et al (2003) <papid> N03-1017 </papid>or some linguistically motivated constraint, such as itg (zens and ney, 2004).</citsent>
<aftsection>
<nextsent>since these phrases are not bound by or even related to syntactic constituents, linguistic generalizations (such as svo becoming sov, or prepositions becoming postpositions) are not easily incorporated into the movement models.
</nextsent>
<nextsent>probability estimation to estimate the translation probability of phrase pair, several approaches are used, often concurrently as features in log-linear model.
</nextsent>
<nextsent>conditional probabilities can be estimated by maximum likelihood estimation.
</nextsent>
<nextsent>yet the phrases most likely to contribute important translational and ordering information the longest onesare the ones most subject to sparse data issues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4586">
<title id=" N06-1002.xml">do we need phrases challenging the conventional wisdom in statistical machine translation </title>
<section> translation by mtus.  </section>
<citcontext>
<prevsection>
<prevsent>phrasal channel models we can estimate traditional channel models using maximum likelihood or lexical weighting: ? ?
</prevsent>
<prevsent>= = = = )(),( inversem1 )(),( directm1 )(),( inversemle )(),( directmle )|(),,( )|(),,( )(*, ),(),,( ,*)( ),(),,( atreelets t atreelets s atreelets atreelets tspatsf stpatsf catsf catsf ??
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we use word probability tables p(t | s) and p(s | t) estimated by ibm model 1 (brown et al 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>such models can be built over phrases if used in phrasal decoder or over tree lets if used in treelet decoder.
</nextsent>
<nextsent>these models are referred to as set (2).
</nextsent>
<nextsent>word-based models target language model using modified kneser ney smoothing captures fluency; word count feature offsets the target lm preference for shorter selections; and treelet/phrase count helps bias toward translations using fewer phrases.
</nextsent>
<nextsent>these models are referred to as set (3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4588">
<title id=" N06-1002.xml">do we need phrases challenging the conventional wisdom in statistical machine translation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>we parsed the source (english) side of the corpora using nlpwin, broad-coverage rule based parser able to produce syntactic analyses at varying levels of depth (heidorn 2002).
</prevsent>
<prevsent>for the purposes of these experiments we used dependency tree output with part-of-speech tags and un stemmed surface words.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
word alignments were produced by giza++ (och and ney 2003) <papid> J03-1002 </papid>with standard training regimen of five iterations of model 1, five iterations of the hmm model, and five iterations of model 4, in both directions.</citsent>
<aftsection>
<nextsent>these alignments were combined heuristic ally as described in our previous work.
</nextsent>
<nextsent>we then projected the dependency trees and used the aligned dependency tree pairs to extract treelet translation pairs, train the order model, and train mtu models.
</nextsent>
<nextsent>the target language models were trained using only the target side of the corpus.
</nextsent>
<nextsent>finally we trained model weights by maximizing bleu (och 2003) <papid> P03-1021 </papid>and set decoder optimization parameters (n-best list size, time outs 14 etc) on development test set of 200 held-out sentences each with single reference translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4590">
<title id=" N06-1002.xml">do we need phrases challenging the conventional wisdom in statistical machine translation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>we then projected the dependency trees and used the aligned dependency tree pairs to extract treelet translation pairs, train the order model, and train mtu models.
</prevsent>
<prevsent>the target language models were trained using only the target side of the corpus.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
finally we trained model weights by maximizing bleu (och 2003) <papid> P03-1021 </papid>and set decoder optimization parameters (n-best list size, time outs 14 etc) on development test set of 200 held-out sentences each with single reference translation.</citsent>
<aftsection>
<nextsent>parameters were individually estimated for each distinct configuration.
</nextsent>
<nextsent>pharaoh the same giza++ alignments as above were used in the pharaoh decoder (koehn 2004).
</nextsent>
<nextsent>we used the heuristic combination described in (och and ney 2003) <papid> J03-1002 </papid>and extracted phrasal translation pairs from this combined alignment as described in (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>aside from mtu models and syntactic models (pharaoh uses its own ordering approach), the same models were used: mle and lexical weighting channel models, target lm, and phrase and word count.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4596">
<title id=" N03-1019.xml">a weighted finite state transducer implementation of the alignment template model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of the benefits of using this framework is that it obviates the need to develop specialized search procedures, even for the generation of lattices or n-best lists of bitext word alignments and translation hypotheses.
</prevsent>
<prevsent>we evaluate the implementation of the model on the french to-english hansa rds task and report alignment and translation performance.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
the alignment template translation model (attm) (och et al, 1999) <papid> W99-0604 </papid>has emerged as promising modeling framework for statistical machine translation.</citsent>
<aftsection>
<nextsent>the attm attempts to overcome the deficiencies of word-to-word translation models (brown et al, 1993) <papid> J93-2003 </papid>through the use of phrasal translations.</nextsent>
<nextsent>the overall model is based on two-level alignment between the source and the target sentence: phrase-level alignment between source and target phrases and word-level alignment between words in these phrase pairs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4597">
<title id=" N03-1019.xml">a weighted finite state transducer implementation of the alignment template model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate the implementation of the model on the french to-english hansa rds task and report alignment and translation performance.
</prevsent>
<prevsent>the alignment template translation model (attm) (och et al, 1999) <papid> W99-0604 </papid>has emerged as promising modeling framework for statistical machine translation.</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the attm attempts to overcome the deficiencies of word-to-word translation models (brown et al, 1993) <papid> J93-2003 </papid>through the use of phrasal translations.</citsent>
<aftsection>
<nextsent>the overall model is based on two-level alignment between the source and the target sentence: phrase-level alignment between source and target phrases and word-level alignment between words in these phrase pairs.
</nextsent>
<nextsent>the goal of this paper is to reformulate the attmso that the operations we intend to perform under statistical translation model, namely bitext word alignment and translation, can be implementation using standard weighted finite state transducer (wfst) operations.
</nextsent>
<nextsent>our main motivation for wfst modeling framework lies in the resulting simplicity of alignment and translation processes compared to dynamic programming or  decoders.
</nextsent>
<nextsent>the wfst implementation allows us to use standard optimized algorithms available from an off-the-shelf fsm toolkit (mohri et al, 1997).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4598">
<title id=" N03-1019.xml">a weighted finite state transducer implementation of the alignment template model for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the wfst implementation allows us to use standard optimized algorithms available from an off-the-shelf fsm toolkit (mohri et al, 1997).
</prevsent>
<prevsent>this avoids the need to develop specialized search procedures, even for the gen template sequence model permutation model phrase phrasal translation model target language model 2 31v source segmentation model z target language sentence sentence source language source language phrases alignment templates target language phrases f ff f2 3 4 5 6 f7 2 1v 3 z1 2 3 u1 2 e1 e2 1 e4 e5 e6 eee3e 3 7 8 9 aa 2 31 figure 1: attm architecture.
</prevsent>
</prevsection>
<citsent citstr=" N01-1018 ">
eration of lattices or n-best lists of bitext word alignment or translation hypotheses.weighted finite state transducers for statistical machine translation (smt) have been proposed in the literature to implement word-to-word translation models (knight and al-onaizan, 1998) or to perform translation in an application domain such as the call routing task (bangalore and ricardi, 2001).<papid> N01-1018 </papid></citsent>
<aftsection>
<nextsent>one of the objectives of these approaches has been to provide an implementation for smt that uses standard fsm algorithms to perform model computations and therefore make smt techniques accessible to wider community.
</nextsent>
<nextsent>our wfst implementation of the attm has been developed with similar objectives.
</nextsent>
<nextsent>we start off by presenting derivation of the attm that identifies the conditional independence assumptions that underly the model.
</nextsent>
<nextsent>the derivation allows us to specify each component distribution of the model and implement it as weighted finite state transducer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4601">
<title id=" N03-1019.xml">a weighted finite state transducer implementation of the alignment template model for statistical machine translation </title>
<section> for ffij0 141314 =.  </section>
<citcontext>
<prevsection>
<prevsent>1 ffi o#  fi)j )
</prevsent>
<prevsent> 1 fi)1 (16) the term
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
1 #   fi is translation dictionary (och and ney, 2000) <papid> P00-1056 </papid>and  </citsent>
<aftsection>
<nextsent> 1 ffi 0  fi is obtained as
</nextsent>
<nextsent>1 ffi o#  fi ffi 21   ?  1  ? 1 (17) we have assumed that
</nextsent>
<nextsent>1 # y  fi ffi
</nextsent>
<nextsent> 1 #  fi , i.e. that given the template, word alignments do not depend on the source language phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4602">
<title id=" N03-1019.xml">a weighted finite state transducer implementation of the alignment template model for statistical machine translation </title>
<section> for ffij0 141314 =.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 translation and translation lattices.
</prevsent>
<prevsent>the lattice of possible translations of  ff is obtained using the weighted finite state composition:  ffi p ?     z 1 (22)the translation with the highest probability (equa tion 20) can now be computed by obtaining the path with the highest score in  .in terms of at&t; fsm tools, this can be done as follows fsmbestpath  # fsm project  ] #   fsmrmepsilon
</prevsent>
</prevsection>
<citsent citstr=" W02-1021 ">
n a translation lattice (ueffing et al, 2002) <papid> W02-1021 </papid>can be generated by pruning  based on likelihoods or number of states.</citsent>
<aftsection>
<nextsent>similarly, an alignment lattice can be generated by pruning  .
</nextsent>
<nextsent>we now evaluate this implementation of the alignment template translation model.
</nextsent>
<nextsent>4.1 building the alignment template library.
</nextsent>
<nextsent>to create the template library, we follow the procedure reported in och (2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4619">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these features represent knowledge mined from wordnet and wikipedia, as well as information about semantic rolelabels.
</prevsent>
<prevsent>we show that semantic features indeed improve the performance on different referring expression types such as pronouns and common nouns.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
the last years have seen boost of work devoted tothe development of machine learning based coreference resolution systems (soon et al , 2001; <papid> J01-4004 </papid>ng &amp; cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003;<papid> P03-1023 </papid>luo et al , 2004, <papid> P04-1018 </papid>inter alia).</citsent>
<aftsection>
<nextsent>while machine learning has proved to yield performance rates fully competitive with rule based systems, current coreference resolution systems are mostly relying on rather shallow features,such as the distance between the co referent expressions, string matching, and linguistic form.
</nextsent>
<nextsent>however, the literature emphasizes since the very beginning the relevance of world knowledge and inference for coreference resolution (charniak, 1973).this paper explores whether coreference resolution can benefit from semantic knowledge sources.
</nextsent>
<nextsent>more specifically, whether machine learning based approach to coreference resolution can be improved and which phenomena are affected by such information.
</nextsent>
<nextsent>we investigate the use of the wordnet and wikipedia taxonomies for extracting semantic similarity and relatedness measures, as well as semantic parsing information in terms of semantic role labeling (gildea &amp; jurafsky, 2002, <papid> J02-3001 </papid>srl henceforth).we believe that the lack of semantics in the current systems leads to performance bottleneck.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4620">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these features represent knowledge mined from wordnet and wikipedia, as well as information about semantic rolelabels.
</prevsent>
<prevsent>we show that semantic features indeed improve the performance on different referring expression types such as pronouns and common nouns.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
the last years have seen boost of work devoted tothe development of machine learning based coreference resolution systems (soon et al , 2001; <papid> J01-4004 </papid>ng &amp; cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003;<papid> P03-1023 </papid>luo et al , 2004, <papid> P04-1018 </papid>inter alia).</citsent>
<aftsection>
<nextsent>while machine learning has proved to yield performance rates fully competitive with rule based systems, current coreference resolution systems are mostly relying on rather shallow features,such as the distance between the co referent expressions, string matching, and linguistic form.
</nextsent>
<nextsent>however, the literature emphasizes since the very beginning the relevance of world knowledge and inference for coreference resolution (charniak, 1973).this paper explores whether coreference resolution can benefit from semantic knowledge sources.
</nextsent>
<nextsent>more specifically, whether machine learning based approach to coreference resolution can be improved and which phenomena are affected by such information.
</nextsent>
<nextsent>we investigate the use of the wordnet and wikipedia taxonomies for extracting semantic similarity and relatedness measures, as well as semantic parsing information in terms of semantic role labeling (gildea &amp; jurafsky, 2002, <papid> J02-3001 </papid>srl henceforth).we believe that the lack of semantics in the current systems leads to performance bottleneck.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4622">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these features represent knowledge mined from wordnet and wikipedia, as well as information about semantic rolelabels.
</prevsent>
<prevsent>we show that semantic features indeed improve the performance on different referring expression types such as pronouns and common nouns.
</prevsent>
</prevsection>
<citsent citstr=" P03-1023 ">
the last years have seen boost of work devoted tothe development of machine learning based coreference resolution systems (soon et al , 2001; <papid> J01-4004 </papid>ng &amp; cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003;<papid> P03-1023 </papid>luo et al , 2004, <papid> P04-1018 </papid>inter alia).</citsent>
<aftsection>
<nextsent>while machine learning has proved to yield performance rates fully competitive with rule based systems, current coreference resolution systems are mostly relying on rather shallow features,such as the distance between the co referent expressions, string matching, and linguistic form.
</nextsent>
<nextsent>however, the literature emphasizes since the very beginning the relevance of world knowledge and inference for coreference resolution (charniak, 1973).this paper explores whether coreference resolution can benefit from semantic knowledge sources.
</nextsent>
<nextsent>more specifically, whether machine learning based approach to coreference resolution can be improved and which phenomena are affected by such information.
</nextsent>
<nextsent>we investigate the use of the wordnet and wikipedia taxonomies for extracting semantic similarity and relatedness measures, as well as semantic parsing information in terms of semantic role labeling (gildea &amp; jurafsky, 2002, <papid> J02-3001 </papid>srl henceforth).we believe that the lack of semantics in the current systems leads to performance bottleneck.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4624">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these features represent knowledge mined from wordnet and wikipedia, as well as information about semantic rolelabels.
</prevsent>
<prevsent>we show that semantic features indeed improve the performance on different referring expression types such as pronouns and common nouns.
</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
the last years have seen boost of work devoted tothe development of machine learning based coreference resolution systems (soon et al , 2001; <papid> J01-4004 </papid>ng &amp; cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003;<papid> P03-1023 </papid>luo et al , 2004, <papid> P04-1018 </papid>inter alia).</citsent>
<aftsection>
<nextsent>while machine learning has proved to yield performance rates fully competitive with rule based systems, current coreference resolution systems are mostly relying on rather shallow features,such as the distance between the co referent expressions, string matching, and linguistic form.
</nextsent>
<nextsent>however, the literature emphasizes since the very beginning the relevance of world knowledge and inference for coreference resolution (charniak, 1973).this paper explores whether coreference resolution can benefit from semantic knowledge sources.
</nextsent>
<nextsent>more specifically, whether machine learning based approach to coreference resolution can be improved and which phenomena are affected by such information.
</nextsent>
<nextsent>we investigate the use of the wordnet and wikipedia taxonomies for extracting semantic similarity and relatedness measures, as well as semantic parsing information in terms of semantic role labeling (gildea &amp; jurafsky, 2002, <papid> J02-3001 </papid>srl henceforth).we believe that the lack of semantics in the current systems leads to performance bottleneck.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4625">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the literature emphasizes since the very beginning the relevance of world knowledge and inference for coreference resolution (charniak, 1973).this paper explores whether coreference resolution can benefit from semantic knowledge sources.
</prevsent>
<prevsent>more specifically, whether machine learning based approach to coreference resolution can be improved and which phenomena are affected by such information.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
we investigate the use of the wordnet and wikipedia taxonomies for extracting semantic similarity and relatedness measures, as well as semantic parsing information in terms of semantic role labeling (gildea &amp; jurafsky, 2002, <papid> J02-3001 </papid>srl henceforth).we believe that the lack of semantics in the current systems leads to performance bottleneck.</citsent>
<aftsection>
<nextsent>in order to correctly identify the discourse entities which are referred to in text, it seems essential to reason over the lexical semantic relations, as well as the event representations embedded in the text.
</nextsent>
<nextsent>as an example, consider fragment from the automatic content extraction (ace) 2003 data.
</nextsent>
<nextsent>(1) but frequent visitors say that given the sheer weight of the countrys totalitarian ideology and generations of mass indoctrination, changing this countrys course will be something akin to turning huge ship at sea.
</nextsent>
<nextsent>opening north korea up, even modestly, and exposing people to the idea that westerners ? and south koreans ? are not devils, alone represents an extraordinary change.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4630">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>192 in this example, knowing that the interfax newsagency is the agent of the report predicate and itbeing the agent of say could trigger the (seman tic parallelism based) inference required to correctly link the two expressions, in contrast to anchoring the pronoun to moscow.
</prevsent>
<prevsent>srl provides the semantic relationships that constituents have with predicates, thus allowing us to include such document level event descriptive information into the relations holding between referring expressions (res).instead of exploring different kinds of data representations, task definitions or machine learning techniques (ng &amp; cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003;<papid> P03-1023 </papid>luo et al , 2004) <papid> P04-1018 </papid>we focus on few promising semantic features which we evaluate in controlled environment.</prevsent>
</prevsection>
<citsent citstr=" N04-1037 ">
that way we try to overcome the plateauing in performance in coreference resolution observed by kehler et al  (2004).<papid> N04-1037 </papid></citsent>
<aftsection>
<nextsent>vieira &amp; poesio (2000), <papid> J00-4003 </papid>harabagiu et al  (2001), <papid> N01-1008 </papid>and markert &amp; nissim (2005) <papid> J05-3004 </papid>explore the use of wordnet for different coreference resolution subtasks, such as resolving bridging reference, other and definite np anaphora, and muc-style coreference resolution.</nextsent>
<nextsent>all of them present systems which infer coreference relations from set of potential antecedents by means of wordnet search.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4632">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>srl provides the semantic relationships that constituents have with predicates, thus allowing us to include such document level event descriptive information into the relations holding between referring expressions (res).instead of exploring different kinds of data representations, task definitions or machine learning techniques (ng &amp; cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003;<papid> P03-1023 </papid>luo et al , 2004) <papid> P04-1018 </papid>we focus on few promising semantic features which we evaluate in controlled environment.</prevsent>
<prevsent>that way we try to overcome the plateauing in performance in coreference resolution observed by kehler et al  (2004).<papid> N04-1037 </papid></prevsent>
</prevsection>
<citsent citstr=" J00-4003 ">
vieira &amp; poesio (2000), <papid> J00-4003 </papid>harabagiu et al  (2001), <papid> N01-1008 </papid>and markert &amp; nissim (2005) <papid> J05-3004 </papid>explore the use of wordnet for different coreference resolution subtasks, such as resolving bridging reference, other and definite np anaphora, and muc-style coreference resolution.</citsent>
<aftsection>
<nextsent>all of them present systems which infer coreference relations from set of potential antecedents by means of wordnet search.
</nextsent>
<nextsent>our approach to wordnet here is to cast the search resultsin terms of semantic similarity measures.
</nextsent>
<nextsent>their output can be used as features for learner.
</nextsent>
<nextsent>these measures are not specifically developed for coreference resolution but simply taken off-the-shelf?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4633">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>srl provides the semantic relationships that constituents have with predicates, thus allowing us to include such document level event descriptive information into the relations holding between referring expressions (res).instead of exploring different kinds of data representations, task definitions or machine learning techniques (ng &amp; cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003;<papid> P03-1023 </papid>luo et al , 2004) <papid> P04-1018 </papid>we focus on few promising semantic features which we evaluate in controlled environment.</prevsent>
<prevsent>that way we try to overcome the plateauing in performance in coreference resolution observed by kehler et al  (2004).<papid> N04-1037 </papid></prevsent>
</prevsection>
<citsent citstr=" N01-1008 ">
vieira &amp; poesio (2000), <papid> J00-4003 </papid>harabagiu et al  (2001), <papid> N01-1008 </papid>and markert &amp; nissim (2005) <papid> J05-3004 </papid>explore the use of wordnet for different coreference resolution subtasks, such as resolving bridging reference, other and definite np anaphora, and muc-style coreference resolution.</citsent>
<aftsection>
<nextsent>all of them present systems which infer coreference relations from set of potential antecedents by means of wordnet search.
</nextsent>
<nextsent>our approach to wordnet here is to cast the search resultsin terms of semantic similarity measures.
</nextsent>
<nextsent>their output can be used as features for learner.
</nextsent>
<nextsent>these measures are not specifically developed for coreference resolution but simply taken off-the-shelf?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4635">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>srl provides the semantic relationships that constituents have with predicates, thus allowing us to include such document level event descriptive information into the relations holding between referring expressions (res).instead of exploring different kinds of data representations, task definitions or machine learning techniques (ng &amp; cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003;<papid> P03-1023 </papid>luo et al , 2004) <papid> P04-1018 </papid>we focus on few promising semantic features which we evaluate in controlled environment.</prevsent>
<prevsent>that way we try to overcome the plateauing in performance in coreference resolution observed by kehler et al  (2004).<papid> N04-1037 </papid></prevsent>
</prevsection>
<citsent citstr=" J05-3004 ">
vieira &amp; poesio (2000), <papid> J00-4003 </papid>harabagiu et al  (2001), <papid> N01-1008 </papid>and markert &amp; nissim (2005) <papid> J05-3004 </papid>explore the use of wordnet for different coreference resolution subtasks, such as resolving bridging reference, other and definite np anaphora, and muc-style coreference resolution.</citsent>
<aftsection>
<nextsent>all of them present systems which infer coreference relations from set of potential antecedents by means of wordnet search.
</nextsent>
<nextsent>our approach to wordnet here is to cast the search resultsin terms of semantic similarity measures.
</nextsent>
<nextsent>their output can be used as features for learner.
</nextsent>
<nextsent>these measures are not specifically developed for coreference resolution but simply taken off-the-shelf?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4639">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the case of srl, this layer of semantic context abstracts from the specific lexical expressions used, and therefore represents higher level of abstraction than (still related) work involving predicate argument statistics.
</prevsent>
<prevsent>kehler et al  (2004) <papid> N04-1037 </papid>observe no significant improvement due to predicate argument statistics.</prevsent>
</prevsection>
<citsent citstr=" P05-1021 ">
the improvement reported by yang et al  (2005) <papid> P05-1021 </papid>is rather caused by theirtwin-candidate model than by the semantic knowl edge.</citsent>
<aftsection>
<nextsent>employing srl is closer in spirit to ji et al  (2005), <papid> H05-1003 </papid>who explore the employment of the ace 2004 relation ontology as semantic filter.</nextsent>
<nextsent>knowledge sources 3.1 corpora used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4640">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>kehler et al  (2004) <papid> N04-1037 </papid>observe no significant improvement due to predicate argument statistics.</prevsent>
<prevsent>the improvement reported by yang et al  (2005) <papid> P05-1021 </papid>is rather caused by theirtwin-candidate model than by the semantic knowl edge.</prevsent>
</prevsection>
<citsent citstr=" H05-1003 ">
employing srl is closer in spirit to ji et al  (2005), <papid> H05-1003 </papid>who explore the employment of the ace 2004 relation ontology as semantic filter.</citsent>
<aftsection>
<nextsent>knowledge sources 3.1 corpora used.
</nextsent>
<nextsent>to establish competitive coreference re solver, the system was initially proto typed using the muc-6 and muc-7 datasets (chinchor &amp; sundheim, 2003; chinchor, 2001), using the standard partitioning of 30 texts for training and 20-30 texts for testing.
</nextsent>
<nextsent>then, we moved on and developed and tested the system with the ace 2003 training data corpus (mitchell et al , 2003)1.
</nextsent>
<nextsent>both the newswire (nwire) and broadcast news (bnews) sections where split into 60-20-20% document-based partitions for training, development, and testing, and later per-partition merged (merged) for system evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4641">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> coreference resolution using semantic.  </section>
<citcontext>
<prevsection>
<prevsent>the distribution of coreference chains and referring expressions is given in table 1.
</prevsent>
<prevsent>3.2 learning algorithm.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
for learning coreference decisions, we used maximum entropy (berger et al , 1996) <papid> J96-1002 </papid>model.</citsent>
<aftsection>
<nextsent>this was implemented using the mallet library (mccal lum, 2002).
</nextsent>
<nextsent>to prevent the model from overfitting,we employed tunable gaussian prior as smoothing method.
</nextsent>
<nextsent>the best parameter value is found by searching in the [0,10] interval with step value of 0.5 for the variance parameter yielding the highest muc score f-measure on the development data.coreference resolution is viewed as binary classification task: given pair of res, the classifier has to decide whether they are co referent or not.
</nextsent>
<nextsent>themaxent model produces probability for each category (coreferent or not) of candidate pair, conditioned on the context in which the candidate occurs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4650">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> coreference resolution using semantic.  </section>
<citcontext>
<prevsection>
<prevsent>in the baseline system semantic information is limited to wordnet semantic class matching.
</prevsent>
<prevsent>unfortunately, wordnet semantic class lookup exhibits problems such as coverage, sense proliferation and ambiguity4, which make the wn class feature very noisy.
</prevsent>
</prevsection>
<citsent citstr=" N04-3012 ">
we enrich the semantic information available to the classifier by using semantic similarity measures based on the wordnet taxonomy (ped ersen et al , 2004).<papid> N04-3012 </papid></citsent>
<aftsection>
<nextsent>the measures we use include path length based measures (rada et al , 1989; wu &amp; palmer, 1994; <papid> P94-1019 </papid>leacock &amp; chodorow, 1998), as well as ones based on information content (resnik, 1995; jiang &amp; conrath, 1997; lin, 1998).in our case, the measures are obtained by computing the similarity scores between the head lemmata of each potential antecedent-anaphor pair.</nextsent>
<nextsent>in order to overcome the sense disambiguation problem, wefactorise over all possible sense pairs: given candidate pair, we take the cross product of each antecedent and anaphor sense to form pairs of synsets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4651">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> coreference resolution using semantic.  </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, wordnet semantic class lookup exhibits problems such as coverage, sense proliferation and ambiguity4, which make the wn class feature very noisy.
</prevsent>
<prevsent>we enrich the semantic information available to the classifier by using semantic similarity measures based on the wordnet taxonomy (ped ersen et al , 2004).<papid> N04-3012 </papid></prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
the measures we use include path length based measures (rada et al , 1989; wu &amp; palmer, 1994; <papid> P94-1019 </papid>leacock &amp; chodorow, 1998), as well as ones based on information content (resnik, 1995; jiang &amp; conrath, 1997; lin, 1998).in our case, the measures are obtained by computing the similarity scores between the head lemmata of each potential antecedent-anaphor pair.</citsent>
<aftsection>
<nextsent>in order to overcome the sense disambiguation problem, wefactorise over all possible sense pairs: given candidate pair, we take the cross product of each antecedent and anaphor sense to form pairs of synsets.
</nextsent>
<nextsent>for each measure wn similarity, we compute the similarity score for all synset pairs, and create the following features.
</nextsent>
<nextsent>wn similarity best the highest similarity score from all senserei,n, senserej ,m? synset pairs.
</nextsent>
<nextsent>wn similarity avg the average similarity score from all senserei,n, senserej ,m? synset pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4653">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> coreference resolution using semantic.  </section>
<citcontext>
<prevsection>
<prevsent>3.6 semantic role features.
</prevsent>
<prevsent>the last semantic knowledge enhancement for the baseline system uses srl information.
</prevsent>
</prevsection>
<citsent citstr=" N04-1030 ">
in our experiments we use the assert parser (pradhan et al , 2004), <papid> N04-1030 </papid>an svm based semantic role tagger which uses full syntactic analysis to automatically identify all verb predicates in sentence together with their semantic arguments, which are output as propbank arguments (palmer et al , 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>it is of ten the case that the semantic arguments output by the parser do not align with any of the previously identified noun phrases.
</nextsent>
<nextsent>in this case, we pass semantic role label to re only when the two phrases share the same head.
</nextsent>
<nextsent>labels have the form arg1 pred1 . . .
</nextsent>
<nextsent>argn predn?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4654">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> coreference resolution using semantic.  </section>
<citcontext>
<prevsection>
<prevsent>3.6 semantic role features.
</prevsent>
<prevsent>the last semantic knowledge enhancement for the baseline system uses srl information.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
in our experiments we use the assert parser (pradhan et al , 2004), <papid> N04-1030 </papid>an svm based semantic role tagger which uses full syntactic analysis to automatically identify all verb predicates in sentence together with their semantic arguments, which are output as propbank arguments (palmer et al , 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>it is of ten the case that the semantic arguments output by the parser do not align with any of the previously identified noun phrases.
</nextsent>
<nextsent>in this case, we pass semantic role label to re only when the two phrases share the same head.
</nextsent>
<nextsent>labels have the form arg1 pred1 . . .
</nextsent>
<nextsent>argn predn?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4655">
<title id=" N06-1025.xml">exploiting semantic role labeling wordnet and wikipedia for coreference resolution </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>given such level of semantic information available at there level, we introduce two new features6.i semrole the semantic role argument predicate pairs of rei.j semrole the semantic role argument predicate pairs of rej .for the ace 2003 data, 11,406 of 32,502 automatically extracted noun phrases were tagged with 2,801 different argument-predicate pairs.
</prevsent>
<prevsent>4.1 performance metrics.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
we report in the following tables the muc score (vilain et al , 1995).<papid> M95-1005 </papid></citsent>
<aftsection>
<nextsent>scores in table 2 are computed for all noun phrases appearing in either the key or the system response, whereas tables 3and 4 refer to scoring only those phrases which appear in both the key and the response.
</nextsent>
<nextsent>we therefore discard those responses not present in the key, as we are interested in establishing the upper limit of the improvements given by our semantic features.
</nextsent>
<nextsent>thatis, we want to define baseline against which to establish the contribution of the semantic information sources explored here for coreference resolution.
</nextsent>
<nextsent>in addition, we report the accuracy score for all three types of ace mentions, namely pronouns, common nouns and proper names.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4664">
<title id=" N06-1015.xml">word alignment via quadratic assignment </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>recently, discriminative word alignment method shave achieved state-of-the-art accuracies by extending the range of information sources that can be easily incorporated into aligners.
</prevsent>
<prevsent>the chief advantage of discriminative framework is the ability to score alignments based on arbitrary features of the matching word tokens, including orthographic form, predictions of other models, lexical context and so on.
</prevsent>
</prevsection>
<citsent citstr=" H05-1010 ">
however, the proposed bipartite matching model of taskar et al  (2005), <papid> H05-1010 </papid>despite being tractable and effective, has two important limita tions.</citsent>
<aftsection>
<nextsent>first, it is limited by the restriction that words have fertility of at most one.
</nextsent>
<nextsent>more importantly, first order correlations between consecutive words cannot be directly captured by the model.
</nextsent>
<nextsent>inthis work, we address these limitations by enriching the model form.
</nextsent>
<nextsent>we give estimation and inference algorithms for these enhancements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4666">
<title id=" N06-1015.xml">word alignment via quadratic assignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by including predictions of other models as features, we achieve aer of 3.8 on the standard hansa rds dataset.
</prevsent>
<prevsent>word alignment is key component of most end to-end statistical machine translation systems.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
the standard approach to word alignment is to construct directional generative models (brown et al , 1990; <papid> J90-2002 </papid>och and ney, 2003), <papid> J03-1002 </papid>which produce sentence inone language given the sentence in another lan guage.</citsent>
<aftsection>
<nextsent>while these models require sentence-alignedbitexts, they can be trained with no further supervision, using em.
</nextsent>
<nextsent>generative alignment models do, however, have serious drawbacks.
</nextsent>
<nextsent>first, they require extensive tuning and processing of large amounts of data which, for the better-performing models, isa non-trivial resource requirement.
</nextsent>
<nextsent>second, conditioning on arbitrary features of the input is difficult;for example, we would like to condition on the orthographic similarity of word pair (for detectingcognates), the presence of that pair in various dictionaries, the similarity of the frequency of its two words, choices made by other alignment systems, and so on.recently, moore (2005) <papid> H05-1011 </papid>proposed discriminative model in which pairs of sentences (e, f) and proposed alignments are scored using linear combination of arbitrary features computed from the tuples (a, e, f).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4668">
<title id=" N06-1015.xml">word alignment via quadratic assignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by including predictions of other models as features, we achieve aer of 3.8 on the standard hansa rds dataset.
</prevsent>
<prevsent>word alignment is key component of most end to-end statistical machine translation systems.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the standard approach to word alignment is to construct directional generative models (brown et al , 1990; <papid> J90-2002 </papid>och and ney, 2003), <papid> J03-1002 </papid>which produce sentence inone language given the sentence in another lan guage.</citsent>
<aftsection>
<nextsent>while these models require sentence-alignedbitexts, they can be trained with no further supervision, using em.
</nextsent>
<nextsent>generative alignment models do, however, have serious drawbacks.
</nextsent>
<nextsent>first, they require extensive tuning and processing of large amounts of data which, for the better-performing models, isa non-trivial resource requirement.
</nextsent>
<nextsent>second, conditioning on arbitrary features of the input is difficult;for example, we would like to condition on the orthographic similarity of word pair (for detectingcognates), the presence of that pair in various dictionaries, the similarity of the frequency of its two words, choices made by other alignment systems, and so on.recently, moore (2005) <papid> H05-1011 </papid>proposed discriminative model in which pairs of sentences (e, f) and proposed alignments are scored using linear combination of arbitrary features computed from the tuples (a, e, f).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4669">
<title id=" N06-1015.xml">word alignment via quadratic assignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>generative alignment models do, however, have serious drawbacks.
</prevsent>
<prevsent>first, they require extensive tuning and processing of large amounts of data which, for the better-performing models, isa non-trivial resource requirement.
</prevsent>
</prevsection>
<citsent citstr=" H05-1011 ">
second, conditioning on arbitrary features of the input is difficult;for example, we would like to condition on the orthographic similarity of word pair (for detectingcognates), the presence of that pair in various dictionaries, the similarity of the frequency of its two words, choices made by other alignment systems, and so on.recently, moore (2005) <papid> H05-1011 </papid>proposed discriminative model in which pairs of sentences (e, f) and proposed alignments are scored using linear combination of arbitrary features computed from the tuples (a, e, f).</citsent>
<aftsection>
<nextsent>while there are no restrictions onthe form of the model features, the problem of finding the highest scoring alignment is very difficult and involves heuristic search.
</nextsent>
<nextsent>moreover, the parameters of the model must be estimated using averaged perceptron training (collins, 2002), <papid> W02-1001 </papid>which can be unstable.</nextsent>
<nextsent>in contrast, taskar et al  (2005) <papid> H05-1010 </papid>cast word alignment as maximum weighted matching problem, in which each pair of words (ej , fk) in sentence pair (e, f) is associated with score sjk(e, f) reflecting the desirability of the alignment of that pair.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4670">
<title id=" N06-1015.xml">word alignment via quadratic assignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, conditioning on arbitrary features of the input is difficult;for example, we would like to condition on the orthographic similarity of word pair (for detectingcognates), the presence of that pair in various dictionaries, the similarity of the frequency of its two words, choices made by other alignment systems, and so on.recently, moore (2005) <papid> H05-1011 </papid>proposed discriminative model in which pairs of sentences (e, f) and proposed alignments are scored using linear combination of arbitrary features computed from the tuples (a, e, f).</prevsent>
<prevsent>while there are no restrictions onthe form of the model features, the problem of finding the highest scoring alignment is very difficult and involves heuristic search.</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
moreover, the parameters of the model must be estimated using averaged perceptron training (collins, 2002), <papid> W02-1001 </papid>which can be unstable.</citsent>
<aftsection>
<nextsent>in contrast, taskar et al  (2005) <papid> H05-1010 </papid>cast word alignment as maximum weighted matching problem, in which each pair of words (ej , fk) in sentence pair (e, f) is associated with score sjk(e, f) reflecting the desirability of the alignment of that pair.</nextsent>
<nextsent>importantly, this problem is computationally tractable.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4674">
<title id=" N06-1015.xml">word alignment via quadratic assignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the addition of afertility model improves the aer by 0.4.
</prevsent>
<prevsent>modeling first-order interactions improves the aer by 1.8.combining the two extensions results in an improvement in aer of 2.3, yielding alignments of better quality than intersected ibm model 4.
</prevsent>
</prevsection>
<citsent citstr=" N06-1014 ">
moreover, including predictions of bi-directional ibm model 4 and model of liang et al  (2006) <papid> N06-1014 </papid>as features, we achieve an absolute aer of 3.8 on the english french hansa rds alignment taskthe best aer result published on this task to date.</citsent>
<aftsection>
<nextsent>we begin with quick summary of the maximum weight bipartite matching model in (taskar et al ,2005).<papid> H05-1010 </papid></nextsent>
<nextsent>more precisely, nodes = vs ? t correspond to words in the source?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4676">
<title id=" N06-1015.xml">word alignment via quadratic assignment </title>
<section> models.  </section>
<citcontext>
<prevsection>
<prevsent>an even more significant limitation of the modelin eq.
</prevsent>
<prevsent>(1) is that the edges interact only indirectly through the competition induced by the constraints.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
generative alignment models like the hmm model (vogel et al , 1996) <papid> C96-2141 </papid>and ibm models 4 and above (brown et al , 1990; <papid> J90-2002 </papid>och and ney, 2003) <papid> J03-1002 </papid>directly model correlations between alignments of consecutive words (at least on one side).</citsent>
<aftsection>
<nextsent>for example, figure 3 shows bitext fragment whose gold alignment is strictly monotonic.
</nextsent>
<nextsent>this monotonicityis quite common ? 46% of the words in the hand aligned data diagonally follow previous alignment in this way.
</nextsent>
<nextsent>we can model the common local alignment configurations by adding bonuses for pairs of edges.
</nextsent>
<nextsent>for example, strictly monotonic alignments can be encouraged by boosting the scores of edges of the form ?(j, k), (j + 1, + 1)?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4689">
<title id=" N06-1015.xml">word alignment via quadratic assignment </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we are currently investigating whether the improvement inaer results in better translation bleu score.
</prevsent>
<prevsent>allowing higher fertility and optimizing recall biased cost function provide significant increase in recall relative to the intersected ibm model 4 (from 88.1% to 94.4%), with only small degradation in precision.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
we view this as particularly promising aspect of our work, given that phrase-based systems such as pharaoh (koehn et al , 2003) <papid> N03-1017 </papid>perform better with higher recall alignments.</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4690">
<title id=" N04-3004.xml">mitap for sars detection </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>below, mitap capabilities are described briefly along with their contributing component technologies.
</prevsent>
<prevsent>3.1 3.2 3.3 3.4 3.5 information processing after internet news sources are captured and normalized, they are passed through zoner using human-generated rules to identify source, date, and other information such as headline, or title, and content.
</prevsent>
</prevsection>
<citsent citstr=" M95-1012 ">
the alembic natural language analyzer (ab erdeen et al 1995; <papid> M95-1012 </papid>vilain and day 1996) <papid> C96-1047 </papid>processes the zoned messages to identify paragraph, sentence, and word boundaries as well as part-of-speech tags.</citsent>
<aftsection>
<nextsent>the messages then pass through the alembic named entity recognizer for identification and tagging of person, organization, location, and disease names.
</nextsent>
<nextsent>finally, the article is processed by the tempex normalizing time expression tagger (mani and wilson 2000).<papid> P00-1010 </papid></nextsent>
<nextsent>for chinese and other non-english sources, the cyber trans machine translation system (miller et al 2001) is used to translate articles automatically into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4691">
<title id=" N04-3004.xml">mitap for sars detection </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>below, mitap capabilities are described briefly along with their contributing component technologies.
</prevsent>
<prevsent>3.1 3.2 3.3 3.4 3.5 information processing after internet news sources are captured and normalized, they are passed through zoner using human-generated rules to identify source, date, and other information such as headline, or title, and content.
</prevsent>
</prevsection>
<citsent citstr=" C96-1047 ">
the alembic natural language analyzer (ab erdeen et al 1995; <papid> M95-1012 </papid>vilain and day 1996) <papid> C96-1047 </papid>processes the zoned messages to identify paragraph, sentence, and word boundaries as well as part-of-speech tags.</citsent>
<aftsection>
<nextsent>the messages then pass through the alembic named entity recognizer for identification and tagging of person, organization, location, and disease names.
</nextsent>
<nextsent>finally, the article is processed by the tempex normalizing time expression tagger (mani and wilson 2000).<papid> P00-1010 </papid></nextsent>
<nextsent>for chinese and other non-english sources, the cyber trans machine translation system (miller et al 2001) is used to translate articles automatically into english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4692">
<title id=" N04-3004.xml">mitap for sars detection </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>the alembic natural language analyzer (ab erdeen et al 1995; <papid> M95-1012 </papid>vilain and day 1996) <papid> C96-1047 </papid>processes the zoned messages to identify paragraph, sentence, and word boundaries as well as part-of-speech tags.</prevsent>
<prevsent>the messages then pass through the alembic named entity recognizer for identification and tagging of person, organization, location, and disease names.</prevsent>
</prevsection>
<citsent citstr=" P00-1010 ">
finally, the article is processed by the tempex normalizing time expression tagger (mani and wilson 2000).<papid> P00-1010 </papid></citsent>
<aftsection>
<nextsent>for chinese and other non-english sources, the cyber trans machine translation system (miller et al 2001) is used to translate articles automatically into english.
</nextsent>
<nextsent>cyber trans wraps commercial and research translation engines to produce common set of interfaces; the current prototype makes use of the systran chinese-english system.
</nextsent>
<nextsent>rss feeds can provide high volume textual ge stalt.
</nextsent>
<nextsent>weblogs, in particular, are good source of timely text, some of which is topical and all of which is based on personal observations and experiences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4693">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, in most cases, web-based models failto outperform more sophisticated state-of-theart models trained on small corpora.
</prevsent>
<prevsent>we argue that web-based models should therefore be used as baseline for, rather than an alternative to, standard models.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
keller and lapata (2003) <papid> J03-3005 </papid>investigated the validity of web counts for range of predicate-argument bigrams (verb object, adjective-noun, and noun-noun bigrams).</citsent>
<aftsection>
<nextsent>they presented simple method for retrieving bigram counts from the web by querying search engine and demonstrated that web counts (a) correlate with frequencies obtained from carefully edited, balanced corpus such asthe 100m words british national corpus (bnc), (b) correlate with frequencies recreated using smoothing methods in the case of unseen bigrams, (c) reliably predict human plausibility judgments, and (d) yield state-of-the-art performance on pseudo-disambiguation tasks.keller and lapatas (2003) <papid> J03-3005 </papid>results suggest that web based frequencies can be viable alternative to bigram frequencies obtained from smaller corpora or recreated using smoothing.</nextsent>
<nextsent>however, they do not demonstrate that realistic nlp tasks can benefit from web counts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4697">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, it remains to be shown that the web-based approach scales up to larger n-grams (e.g., trigrams), and to combinations of different parts of speech (keller and lapata 2003 <papid> J03-3005 </papid>only tested bigrams involving nouns, verbs, and adjectives).another important question is whether web-based methods, which are by definition unsupervised, can be competitive alternatives to supervised approaches used for most tasks in the literature.</prevsent>
<prevsent>this paper aims to address these questions.</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
we start by using web counts for two generation tasks for which theuse of large datasets has shown promising results: (a) target language candidate selection for machine translation (grefenstette, 1998) and (b) context sensitive spelling correction (banko and brill, 2001<papid> P01-1005 </papid>a,b).</citsent>
<aftsection>
<nextsent>then we investigate the generality of the web-based approach by applying it to range of analysis and generations tasks, involving both syntactic and semantic knowledge: (c) ordering of pre nominal adjectives, (d) compound noun bracketing,(e) compound noun interpretation, and (f) noun count ability detection.
</nextsent>
<nextsent>table 1 gives an overview of these tasks and their properties.
</nextsent>
<nextsent>in all cases, we propose simple, unsupervised n-gram based model whose parameters are estimated using web counts.
</nextsent>
<nextsent>we compare this model both against baseline (same model, but parameters estimated on the bnc) and against state-of-the-art models from the literature, which are either supervised (i.e., use annotated training data) or unsupervised but relyon taxonomies to recreate missing counts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4701">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> candidate selection for machine.  </section>
<citcontext>
<prevsection>
<prevsent>statistical approaches to target word selection relyon bilingual lexica to provide all possible translations of words in the source language.
</prevsent>
<prevsent>once the set of translation candidates is generated, statistical information gathered from target language corpora is used to select the most appropriate alternative (dagan and itai, 1994).
</prevsent>
</prevsection>
<citsent citstr=" C00-2094 ">
the task is somewhat simplified by grefenstette (1998) and prescher et al  (2000) <papid> C00-2094 </papid>who do not produce translation of the entire sentence.</citsent>
<aftsection>
<nextsent>instead, they focus on specific syntactic relations.
</nextsent>
<nextsent>grefenstette translates compounds from german and spanish into english, and uses bnc frequencies as filter for candidate translations.
</nextsent>
<nextsent>he observes that this approach suffers from an acute data sparseness problem and goes on to obtain counts for candidate compounds through web searches, thus achieving translation accuracy of 8687%.
</nextsent>
<nextsent>prescher et al  (2000) <papid> C00-2094 </papid>concentrate on verbs and their objects.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4708">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> context-sensitive spelling correction.  </section>
<citcontext>
<prevsection>
<prevsent>thetask is to infer which word in confusion set is the correct one in given context.
</prevsent>
<prevsent>this choice can be either syntactic (as for {then, than}) or semantic (as for {principal, principle}).a number of machine learning methods have been proposed for context-sensitive spelling correction.
</prevsent>
</prevsection>
<citsent citstr=" W95-0104 ">
these include variety of bayesian classifiers (golding, 1995; <papid> W95-0104 </papid>golding and schabes, 1996), <papid> P96-1010 </papid>decision lists (golding, 1995) <papid> W95-0104 </papid>transformation-based learning (mangu and brill, 1997), latent semantic analysis (lsa) (jones and martin, 1997), <papid> A97-1025 </papid>multiplicative weight update algorithms(golding and roth, 1999), and augmented mixture models (cucerzan and yarowsky, 2002).<papid> W02-1005 </papid></citsent>
<aftsection>
<nextsent>despite their differences, most approaches use two types of features: context words and collocations.
</nextsent>
<nextsent>context word features record the presence of word within fixed window around the target word (bag of words); collocational features capture the syntactic environment of the target word and are usually represented by small number of words and/or part of-speech tags to the left or right of the target word.the results obtained by variety of classification methods are given in table 6.
</nextsent>
<nextsent>all methods use either the full set or subset of 18 confusion sets originally gathered by golding (1995).<papid> W95-0104 </papid></nextsent>
<nextsent>most methods are trained and tested on model alta bnc model alta bnc (t) 72.98 70.00 (w1, t,w2)/ (t) 87.77 76.33 (w1, t) 84.40 83.02 (w1,w2, t)/ (t) 86.27 74.47 (t,w1) 84.89 82.74 (t,w2,w2)/ (t) 84.94 74.23 (w1, t,w2) 89.24#*77.13 (w1, t,w2)/ (w1, t) 80.70 73.69 (w1,w2, t) 87.13 74.89 (w1, t,w2)/ (t,w2) 82.24 75.10 (t,w1,w2) 84.68 75.08 (w1,w2, t)/ (w2, t) 72.11 69.28 (w1, t)/ (t) 82.81 77.84 (t,w1,w2)/ (t,w1) 75.65 72.57 (t,w1)/ (t) 77.49 80.71# table 5: performance of alta vista counts and bnc counts for context sensitive spelling correction (data from cucerzan and yarowsky 2002) <papid> W02-1005 </papid>model accuracy baseline bnc 70.00 baseline alta vista 72.98 best bnc 80.71??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4709">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> context-sensitive spelling correction.  </section>
<citcontext>
<prevsection>
<prevsent>thetask is to infer which word in confusion set is the correct one in given context.
</prevsent>
<prevsent>this choice can be either syntactic (as for {then, than}) or semantic (as for {principal, principle}).a number of machine learning methods have been proposed for context-sensitive spelling correction.
</prevsent>
</prevsection>
<citsent citstr=" P96-1010 ">
these include variety of bayesian classifiers (golding, 1995; <papid> W95-0104 </papid>golding and schabes, 1996), <papid> P96-1010 </papid>decision lists (golding, 1995) <papid> W95-0104 </papid>transformation-based learning (mangu and brill, 1997), latent semantic analysis (lsa) (jones and martin, 1997), <papid> A97-1025 </papid>multiplicative weight update algorithms(golding and roth, 1999), and augmented mixture models (cucerzan and yarowsky, 2002).<papid> W02-1005 </papid></citsent>
<aftsection>
<nextsent>despite their differences, most approaches use two types of features: context words and collocations.
</nextsent>
<nextsent>context word features record the presence of word within fixed window around the target word (bag of words); collocational features capture the syntactic environment of the target word and are usually represented by small number of words and/or part of-speech tags to the left or right of the target word.the results obtained by variety of classification methods are given in table 6.
</nextsent>
<nextsent>all methods use either the full set or subset of 18 confusion sets originally gathered by golding (1995).<papid> W95-0104 </papid></nextsent>
<nextsent>most methods are trained and tested on model alta bnc model alta bnc (t) 72.98 70.00 (w1, t,w2)/ (t) 87.77 76.33 (w1, t) 84.40 83.02 (w1,w2, t)/ (t) 86.27 74.47 (t,w1) 84.89 82.74 (t,w2,w2)/ (t) 84.94 74.23 (w1, t,w2) 89.24#*77.13 (w1, t,w2)/ (w1, t) 80.70 73.69 (w1,w2, t) 87.13 74.89 (w1, t,w2)/ (t,w2) 82.24 75.10 (t,w1,w2) 84.68 75.08 (w1,w2, t)/ (w2, t) 72.11 69.28 (w1, t)/ (t) 82.81 77.84 (t,w1,w2)/ (t,w1) 75.65 72.57 (t,w1)/ (t) 77.49 80.71# table 5: performance of alta vista counts and bnc counts for context sensitive spelling correction (data from cucerzan and yarowsky 2002) <papid> W02-1005 </papid>model accuracy baseline bnc 70.00 baseline alta vista 72.98 best bnc 80.71??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4711">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> context-sensitive spelling correction.  </section>
<citcontext>
<prevsection>
<prevsent>thetask is to infer which word in confusion set is the correct one in given context.
</prevsent>
<prevsent>this choice can be either syntactic (as for {then, than}) or semantic (as for {principal, principle}).a number of machine learning methods have been proposed for context-sensitive spelling correction.
</prevsent>
</prevsection>
<citsent citstr=" A97-1025 ">
these include variety of bayesian classifiers (golding, 1995; <papid> W95-0104 </papid>golding and schabes, 1996), <papid> P96-1010 </papid>decision lists (golding, 1995) <papid> W95-0104 </papid>transformation-based learning (mangu and brill, 1997), latent semantic analysis (lsa) (jones and martin, 1997), <papid> A97-1025 </papid>multiplicative weight update algorithms(golding and roth, 1999), and augmented mixture models (cucerzan and yarowsky, 2002).<papid> W02-1005 </papid></citsent>
<aftsection>
<nextsent>despite their differences, most approaches use two types of features: context words and collocations.
</nextsent>
<nextsent>context word features record the presence of word within fixed window around the target word (bag of words); collocational features capture the syntactic environment of the target word and are usually represented by small number of words and/or part of-speech tags to the left or right of the target word.the results obtained by variety of classification methods are given in table 6.
</nextsent>
<nextsent>all methods use either the full set or subset of 18 confusion sets originally gathered by golding (1995).<papid> W95-0104 </papid></nextsent>
<nextsent>most methods are trained and tested on model alta bnc model alta bnc (t) 72.98 70.00 (w1, t,w2)/ (t) 87.77 76.33 (w1, t) 84.40 83.02 (w1,w2, t)/ (t) 86.27 74.47 (t,w1) 84.89 82.74 (t,w2,w2)/ (t) 84.94 74.23 (w1, t,w2) 89.24#*77.13 (w1, t,w2)/ (w1, t) 80.70 73.69 (w1,w2, t) 87.13 74.89 (w1, t,w2)/ (t,w2) 82.24 75.10 (t,w1,w2) 84.68 75.08 (w1,w2, t)/ (w2, t) 72.11 69.28 (w1, t)/ (t) 82.81 77.84 (t,w1,w2)/ (t,w1) 75.65 72.57 (t,w1)/ (t) 77.49 80.71# table 5: performance of alta vista counts and bnc counts for context sensitive spelling correction (data from cucerzan and yarowsky 2002) <papid> W02-1005 </papid>model accuracy baseline bnc 70.00 baseline alta vista 72.98 best bnc 80.71??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4712">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> context-sensitive spelling correction.  </section>
<citcontext>
<prevsection>
<prevsent>thetask is to infer which word in confusion set is the correct one in given context.
</prevsent>
<prevsent>this choice can be either syntactic (as for {then, than}) or semantic (as for {principal, principle}).a number of machine learning methods have been proposed for context-sensitive spelling correction.
</prevsent>
</prevsection>
<citsent citstr=" W02-1005 ">
these include variety of bayesian classifiers (golding, 1995; <papid> W95-0104 </papid>golding and schabes, 1996), <papid> P96-1010 </papid>decision lists (golding, 1995) <papid> W95-0104 </papid>transformation-based learning (mangu and brill, 1997), latent semantic analysis (lsa) (jones and martin, 1997), <papid> A97-1025 </papid>multiplicative weight update algorithms(golding and roth, 1999), and augmented mixture models (cucerzan and yarowsky, 2002).<papid> W02-1005 </papid></citsent>
<aftsection>
<nextsent>despite their differences, most approaches use two types of features: context words and collocations.
</nextsent>
<nextsent>context word features record the presence of word within fixed window around the target word (bag of words); collocational features capture the syntactic environment of the target word and are usually represented by small number of words and/or part of-speech tags to the left or right of the target word.the results obtained by variety of classification methods are given in table 6.
</nextsent>
<nextsent>all methods use either the full set or subset of 18 confusion sets originally gathered by golding (1995).<papid> W95-0104 </papid></nextsent>
<nextsent>most methods are trained and tested on model alta bnc model alta bnc (t) 72.98 70.00 (w1, t,w2)/ (t) 87.77 76.33 (w1, t) 84.40 83.02 (w1,w2, t)/ (t) 86.27 74.47 (t,w1) 84.89 82.74 (t,w2,w2)/ (t) 84.94 74.23 (w1, t,w2) 89.24#*77.13 (w1, t,w2)/ (w1, t) 80.70 73.69 (w1,w2, t) 87.13 74.89 (w1, t,w2)/ (t,w2) 82.24 75.10 (t,w1,w2) 84.68 75.08 (w1,w2, t)/ (w2, t) 72.11 69.28 (w1, t)/ (t) 82.81 77.84 (t,w1,w2)/ (t,w1) 75.65 72.57 (t,w1)/ (t) 77.49 80.71# table 5: performance of alta vista counts and bnc counts for context sensitive spelling correction (data from cucerzan and yarowsky 2002) <papid> W02-1005 </papid>model accuracy baseline bnc 70.00 baseline alta vista 72.98 best bnc 80.71??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4724">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> context-sensitive spelling correction.  </section>
<citcontext>
<prevsection>
<prevsent>we used the same test set (2056 tokens from the brown corpus) and confusion sets as golding and schabes (1996), <papid> P96-1010 </papid>mangu and brill (1997), and cucerzan and yarowsky (2002).<papid> W02-1005 </papid>table 5 shows that the best result (89.24%) for the web based approach is obtained with context of one word to the left and one word to the right of the target word( (w1, t,w2)).</prevsent>
<prevsent>the bnc-based models perform consistently worse than the web-based models with the exception of (t,w1)/t; the best alta vista model performs significantly better than the best bnc model.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
table 6 shows 3an exception is golding (1995), <papid> W95-0104 </papid>who uses the entire brown corpus for training (1m words) and 3/4 of the wall street journal corpus (marcus et al , 1993) <papid> J93-2004 </papid>for testing.</citsent>
<aftsection>
<nextsent>that both the best alta vista model and the best bnc model outperform their respective baselines.
</nextsent>
<nextsent>a comparison with the literature shows that the best alta vista model outperforms golding (1995), <papid> W95-0104 </papid>jones and martin (1997) <papid> A97-1025 </papid>and performs similar to golding and schabes (1996).<papid> P96-1010 </papid></nextsent>
<nextsent>the highest accuracy on the task is achieved by the class of multiplicative weight-update algorithms such as winnow (golding and roth, 1999).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4730">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> ordering of pre nominal adjectives.  </section>
<citcontext>
<prevsection>
<prevsent>the ordering of pre nominal modifiers is important for natural language generation systems where the text mustbe both fluent and grammatical.
</prevsent>
<prevsent>for example, these quence big fat greek wedding is perfectly acceptable, whereas fat greek big wedding sounds odd.
</prevsent>
</prevsection>
<citsent citstr=" P99-1018 ">
the ordering of pre nominal adjectives has sparked great deal of theoretical debate (see shaw and hatzivassiloglou 1999 <papid> P99-1018 </papid>for an overview) and efforts have concentrated on defining rules based on semantic criteria that account for different orders (e.g., age ? color, value ? dimension).</citsent>
<aftsection>
<nextsent>data intensive approaches to the ordering problem relyon corpora for gathering evidence for the likelihood of different orders.
</nextsent>
<nextsent>they rest on the hypothesis that the relative order of premodifiers is fixed, and independent of context and the noun being modified.
</nextsent>
<nextsent>the simplest strategy is what shaw and hatzivassiloglou (1999) <papid> P99-1018 </papid>call direct evidence.</nextsent>
<nextsent>given an adjective pair {a,b}, they count how many times a,b? and b,a? appear in the corpus and choose the pair with the highest frequency.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4735">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> ordering of pre nominal adjectives.  </section>
<citcontext>
<prevsection>
<prevsent>given an adjective pair {a,b}, they count how many times a,b? and b,a? appear in the corpus and choose the pair with the highest frequency.
</prevsent>
<prevsent>unfortunately the direct evidence method performs poorly when given order is unseen in the training data.
</prevsent>
</prevsection>
<citsent citstr=" P00-1012 ">
to compensate for this, shaw and hatzivassiloglou (1999) <papid> P99-1018 </papid>propose to compute the transitive closure of the ordering relation: if ? and ? b, then ? b. malouf (2000) <papid> P00-1012 </papid>further proposes back-off bigram model of adjective pairs for choosing among alternative orders (p(a,b?|{a,b}) vs. p(b,a?|{a,b})).</citsent>
<aftsection>
<nextsent>he also proposes positional probabilities as means of estimating how likely it is forgiven adjective to appear first in sequence by looking at each pair in the training data that contains the adjective and recording its position.
</nextsent>
<nextsent>finally, he uses memory-based learning as means to encode morphological and semantic similarities among different adjective orders.
</nextsent>
<nextsent>each adjective pair ab is encoded as vector of 16 features (the last eight characters of and the last eight characters of b) and class (a,b? or model alta vista bnc (a1,a2) : (a2,a1) 89.6#6 ? 80.4#?
</nextsent>
<nextsent>f (a1,a2)/ (a2) : (a2,a1)/ (a1) 83.2 77.0 (a1,a2)/ (a1) : (a2,a1)/ (a2) 80.2 80.6 malouf (2000): <papid> P00-1012 </papid>memory-based ? 91.0 table 7: performance of alta vista counts and bnc counts for adjective ordering (data from malouf 2000) <papid> P00-1012 </papid>b,a?).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4739">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> bracketing of compound nouns.  </section>
<citcontext>
<prevsection>
<prevsent>the best alta vista model significantly outperformed the best bnc model, as indicated in table 7.
</prevsent>
<prevsent>we also found that there was no significant difference between the best alta vista model and the best model reported by malouf, supervised method using positional probability estimates from the bnc and morphological variants.
</prevsent>
</prevsection>
<citsent citstr=" J93-2005 ">
the first analysis task we consider is the syntactic disambiguation of compound nouns, which has received fair amount of attention in the nlp literature (pustejovsky et al , 1993; <papid> J93-2005 </papid>resnik, 1993; lauer, 1995).<papid> P95-1007 </papid></citsent>
<aftsection>
<nextsent>the task can be summarized as follows: given three word compound n1 n3 n3, determine the correct binary bracketing of the word sequence (see (3) for an example).
</nextsent>
<nextsent>(3) a. [[backup compiler] disk] b. [backup [compiler disk]]previous approaches typically compare different bracketings and choose the most likely one.
</nextsent>
<nextsent>the adjacency model compares [n1 n2] against [n2 n3] and adopts right branching analysis if [n2 n3] is more likely than [n1 n2].
</nextsent>
<nextsent>the dependency model compares [n1 n2] against [n1 n3] and adopts right branching analysis if [n1 n3] is more likely than [n1 n2].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4740">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> bracketing of compound nouns.  </section>
<citcontext>
<prevsection>
<prevsent>the best alta vista model significantly outperformed the best bnc model, as indicated in table 7.
</prevsent>
<prevsent>we also found that there was no significant difference between the best alta vista model and the best model reported by malouf, supervised method using positional probability estimates from the bnc and morphological variants.
</prevsent>
</prevsection>
<citsent citstr=" P95-1007 ">
the first analysis task we consider is the syntactic disambiguation of compound nouns, which has received fair amount of attention in the nlp literature (pustejovsky et al , 1993; <papid> J93-2005 </papid>resnik, 1993; lauer, 1995).<papid> P95-1007 </papid></citsent>
<aftsection>
<nextsent>the task can be summarized as follows: given three word compound n1 n3 n3, determine the correct binary bracketing of the word sequence (see (3) for an example).
</nextsent>
<nextsent>(3) a. [[backup compiler] disk] b. [backup [compiler disk]]previous approaches typically compare different bracketings and choose the most likely one.
</nextsent>
<nextsent>the adjacency model compares [n1 n2] against [n2 n3] and adopts right branching analysis if [n2 n3] is more likely than [n1 n2].
</nextsent>
<nextsent>the dependency model compares [n1 n2] against [n1 n3] and adopts right branching analysis if [n1 n3] is more likely than [n1 n2].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4807">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> interpretation of compound nouns.  </section>
<citcontext>
<prevsection>
<prevsent>the comparison with the literature in table 11 showed that the best alta vista model significantly outperformed both the baseline and the best model in the literature (lauers word-based model).
</prevsent>
<prevsent>the bnc model, on the other hand, alta vista bnc model count uncount count uncount (n) 87.01 90.13 87.32# 90.39# (det,n) 88.38#6 ? 91.22#6 ? 51.01 50.23 (det,n)/ (n) 83.19 85.38 50.95 50.23 backoff 87.01 89.80 ? ?
</prevsent>
</prevsection>
<citsent citstr=" P03-1059 ">
table 12: performance of alta vista counts and bnc counts for noun count ability detection (data from baldwin and bond 2003) <papid> P03-1059 </papid>achieved performance that is not significantly different from the baseline, and significantly worse than lauers best model.</citsent>
<aftsection>
<nextsent>the next analysis task that we consider is the problem of determining the count ability of nouns.
</nextsent>
<nextsent>count ability is the semantic property that determines whether noun can occur in singular and plural forms, and affects the range of permissible modifiers.
</nextsent>
<nextsent>in english, nouns are typically either countable (e.g., one dog, two dogs) or uncountable (e.g., some peace, *one peace, *two peaces).baldwin and bond (2003) <papid> P03-1059 </papid>propose method for automatically learning the count ability of english nouns fromthe bnc.</nextsent>
<nextsent>they obtain information about noun countabil ity by merging lexical entries from comlex (grishmanet al , 1994) <papid> C94-1042 </papid>and the altj/e japanese-to-english semantic transfer dictionary (ikehara et al , 1991).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4810">
<title id=" N04-1016.xml">the web as a baseline evaluating the performance of unsupervised web based models for a range of nlp tasks </title>
<section> noun count ability detection.  </section>
<citcontext>
<prevsection>
<prevsent>count ability is the semantic property that determines whether noun can occur in singular and plural forms, and affects the range of permissible modifiers.
</prevsent>
<prevsent>in english, nouns are typically either countable (e.g., one dog, two dogs) or uncountable (e.g., some peace, *one peace, *two peaces).baldwin and bond (2003) <papid> P03-1059 </papid>propose method for automatically learning the count ability of english nouns fromthe bnc.</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
they obtain information about noun countabil ity by merging lexical entries from comlex (grishmanet al , 1994) <papid> C94-1042 </papid>and the altj/e japanese-to-english semantic transfer dictionary (ikehara et al , 1991).</citsent>
<aftsection>
<nextsent>words are classified into four classes: countable, uncountable, bi partite (e.g., trousers), and plural only (e.g., goods).
</nextsent>
<nextsent>amemory-based classifier is used to learn the four-way distinction on the basis of several linguistically motivated features such as: number of the head noun, number of the modifier, subject-verb agreement, plural determiners.
</nextsent>
<nextsent>we devised unsupervised models for the countabilitylearning task and evaluated their performance on baldwin and bonds (2003) <papid> P03-1059 </papid>test data.</nextsent>
<nextsent>we concentrated solely on countable and uncountable nouns, as they account for the vast majority of the data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4818">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the idea is to vowelize arabic names by adding appropriate vowels and utilizing phonetic look-up table to provide the spelling inthe target language.
</prevsent>
<prevsent>their framework is strictly applicable within standard arabic morphological rules.
</prevsent>
</prevsection>
<citsent citstr=" P97-1017 ">
knight and graehl (1997) <papid> P97-1017 </papid>introduced finite state transducers that implement back-transliteration from japanese to english, which was then extended to arabic-english in (stalls and knight, 1998).</citsent>
<aftsection>
<nextsent>al-onaizan and knight (2002) transliterated named entities in arabic text to english by combining phonetic-based and spelling-based models, and reranking candidates with full-name web counts, named entities co-reference, and contextual web counts.
</nextsent>
<nextsent>huang (2005) <papid> H05-1055 </papid>proposed specific model for chinese-english name transliteration with clusterings of names?</nextsent>
<nextsent>origins,and appropriate hypotheses are generated given the ori gins.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4819">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>knight and graehl (1997) <papid> P97-1017 </papid>introduced finite state transducers that implement back-transliteration from japanese to english, which was then extended to arabic-english in (stalls and knight, 1998).</prevsent>
<prevsent>al-onaizan and knight (2002) transliterated named entities in arabic text to english by combining phonetic-based and spelling-based models, and reranking candidates with full-name web counts, named entities co-reference, and contextual web counts.</prevsent>
</prevsection>
<citsent citstr=" H05-1055 ">
huang (2005) <papid> H05-1055 </papid>proposed specific model for chinese-english name transliteration with clusterings of names?</citsent>
<aftsection>
<nextsent>origins,and appropriate hypotheses are generated given the origins.
</nextsent>
<nextsent>all of these approaches, however, are not based on smt-framework.
</nextsent>
<nextsent>technologies developed for smtare borrowed in virga and khudanpur (2003) <papid> W03-1508 </papid>and ab duljaleel and larkey (2003).</nextsent>
<nextsent>standard smt alignment models (brown et al, 1993)<papid> J93-2003 </papid>are used to align letter-pairswithin named entity pairs for transliteration.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4820">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>origins,and appropriate hypotheses are generated given the origins.
</prevsent>
<prevsent>all of these approaches, however, are not based on smt-framework.
</prevsent>
</prevsection>
<citsent citstr=" W03-1508 ">
technologies developed for smtare borrowed in virga and khudanpur (2003) <papid> W03-1508 </papid>and ab duljaleel and larkey (2003).</citsent>
<aftsection>
<nextsent>standard smt alignment models (brown et al, 1993)<papid> J93-2003 </papid>are used to align letter-pairswithin named entity pairs for transliteration.</nextsent>
<nextsent>their approach are generative models for letter-to-letter translations, and the letter-alignment is augmented with heuris tics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4821">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>all of these approaches, however, are not based on smt-framework.
</prevsent>
<prevsent>technologies developed for smtare borrowed in virga and khudanpur (2003) <papid> W03-1508 </papid>and ab duljaleel and larkey (2003).</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
standard smt alignment models (brown et al, 1993)<papid> J93-2003 </papid>are used to align letter-pairswithin named entity pairs for transliteration.</citsent>
<aftsection>
<nextsent>their approach are generative models for letter-to-letter translations, and the letter-alignment is augmented with heuristics.
</nextsent>
<nextsent>letter-level contextual information is shown to be very helpful for transliteration.
</nextsent>
<nextsent>oh and choi (2002) <papid> C02-1099 </papid>used conversion units for english-korean transliteration;goto et al (2003) used conversion units, mapping english letter-sequence into japanese katakana character string.</nextsent>
<nextsent>li et al (2004) <papid> P04-1021 </papid>presented framework allowing direct ortho graphical mapping of transliteration units between english and chinese, and an extended model is presented in ekbal et al (2006).<papid> P06-2025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4823">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their approach are generative models for letter-to-letter translations, and the letter-alignment is augmented with heuristics.
</prevsent>
<prevsent>letter-level contextual information is shown to be very helpful for transliteration.
</prevsent>
</prevsection>
<citsent citstr=" C02-1099 ">
oh and choi (2002) <papid> C02-1099 </papid>used conversion units for english-korean transliteration;goto et al (2003) used conversion units, mapping english letter-sequence into japanese katakana character string.</citsent>
<aftsection>
<nextsent>li et al (2004) <papid> P04-1021 </papid>presented framework allowing direct ortho graphical mapping of transliteration units between english and chinese, and an extended model is presented in ekbal et al (2006).<papid> P06-2025 </papid></nextsent>
<nextsent>we propose block-level transliteration framework, asshown in figure 1, to model letter-level context information for transliteration at two levels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4824">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>letter-level contextual information is shown to be very helpful for transliteration.
</prevsent>
<prevsent>oh and choi (2002) <papid> C02-1099 </papid>used conversion units for english-korean transliteration;goto et al (2003) used conversion units, mapping english letter-sequence into japanese katakana character string.</prevsent>
</prevsection>
<citsent citstr=" P04-1021 ">
li et al (2004) <papid> P04-1021 </papid>presented framework allowing direct ortho graphical mapping of transliteration units between english and chinese, and an extended model is presented in ekbal et al (2006).<papid> P06-2025 </papid></citsent>
<aftsection>
<nextsent>we propose block-level transliteration framework, asshown in figure 1, to model letter-level context information for transliteration at two levels.
</nextsent>
<nextsent>first, we propose bi-stream hmm incorporating letter-clusters to better model the vowel and non-vowel transliterationswith position-information, i.e., initial and final, to im prove the letter-level alignment accuracy.
</nextsent>
<nextsent>second, basedon the letter-alignment, we propose letter n-gram (letter sequence) alignment models (block) to automatically learn the mappings from source letter n-grams to target letter n-grams.
</nextsent>
<nextsent>a few features specific for transliterations are explored, and log-linear model is used to combine 364 figure 1: transliteration system structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4825">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>letter-level contextual information is shown to be very helpful for transliteration.
</prevsent>
<prevsent>oh and choi (2002) <papid> C02-1099 </papid>used conversion units for english-korean transliteration;goto et al (2003) used conversion units, mapping english letter-sequence into japanese katakana character string.</prevsent>
</prevsection>
<citsent citstr=" P06-2025 ">
li et al (2004) <papid> P04-1021 </papid>presented framework allowing direct ortho graphical mapping of transliteration units between english and chinese, and an extended model is presented in ekbal et al (2006).<papid> P06-2025 </papid></citsent>
<aftsection>
<nextsent>we propose block-level transliteration framework, asshown in figure 1, to model letter-level context information for transliteration at two levels.
</nextsent>
<nextsent>first, we propose bi-stream hmm incorporating letter-clusters to better model the vowel and non-vowel transliterationswith position-information, i.e., initial and final, to im prove the letter-level alignment accuracy.
</nextsent>
<nextsent>second, basedon the letter-alignment, we propose letter n-gram (letter sequence) alignment models (block) to automatically learn the mappings from source letter n-grams to target letter n-grams.
</nextsent>
<nextsent>a few features specific for transliterations are explored, and log-linear model is used to combine 364 figure 1: transliteration system structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4828">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> bi-stream hmms for transliteration.  </section>
<citcontext>
<prevsection>
<prevsent>standard ibm translation models (brown et al, 1993)<papid> J93-2003 </papid>can be used to obtain letter-to-letter translations.</prevsent>
<prevsent>how ever, these models are not directly suitable, because letter-alignment within nes is strictly left-to-right.</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
this sequential property is well suited to hmms (vogel et al,1996), <papid> C96-2141 </papid>in which the jumps from the current aligned position can only be forward.</citsent>
<aftsection>
<nextsent>3.1 bi-stream hmms.
</nextsent>
<nextsent>we propose bi-stream hmm for letter-alignment withinne pairs.
</nextsent>
<nextsent>for the source ne fj1 and target ne ei1, bi stream hmm is defined as follows: p(fj1 |ei1)= ? aj1 j?
</nextsent>
<nextsent>j=1 p(fj |eaj )p(cfj |ceaj )p(aj |aj1), (2) where aj maps fj to the english letter eaj at the positionaj in the english named entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4829">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> bi-stream hmms for transliteration.  </section>
<citcontext>
<prevsection>
<prevsent>to be in accordance with the monotone nature of the nes alignment mentioned before, we enforce the following constraints in eqn.
</prevsent>
<prevsent>3, so that the transition can only jump forward or stay at the same state: ajaj10 ? [1, ].
</prevsent>
</prevsection>
<citsent citstr=" W05-0804 ">
(3) since the two streams are conditionally independent given the current state, the extended em is straight forward, with only small modifications of the standardforward-backward algorithm (zhao et al, 2005), <papid> W05-0804 </papid>for parameter estimation.</citsent>
<aftsection>
<nextsent>3.2 designing letter-classes.
</nextsent>
<nextsent>pronunciation is typically highly structured.
</nextsent>
<nextsent>for instance, in english the pronunciation structure of cvc?(consonant-vowel-consonant) is common.
</nextsent>
<nextsent>by incorporating letter classes into the proposed two-stream hmm,the models?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4830">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> transliteration blocks.  </section>
<citcontext>
<prevsection>
<prevsent>the goal of transliteration model is to learn high-quality transliteration blocks from the training data in unsupervised fashion.
</prevsent>
<prevsent>specifically, block can be represented by its left and right boundaries in the source and target nes shown in figure 2: = (f j+lj , ei+ki ), (4) where j+lj is the source letter-ngram with (l+1) letter sin source language, and its projection of ei+ki in the english ne with left boundary at the position of i, and right boundary at (i+ k).
</prevsent>
</prevsection>
<citsent citstr=" I05-3011 ">
we formulate the block extraction as local search problem following the work in zhao and waibel (2005):<papid> I05-3011 </papid>given source letter n-gram j+lj , search for the projected boundaries of candidate target letter n-gram ei+kiaccording to weighted combination of the diverse features in log-linear model detailed in 4.3.</citsent>
<aftsection>
<nextsent>the log-linear model serves as performance measure to guide the local search, which, in our setup, is randomized hill-climbing, to extract bilingual letter n-gram transliteration pairs.
</nextsent>
<nextsent>4.1 features for block transliteration.
</nextsent>
<nextsent>three features: fertility, distortion, and lexical translation are investigated for inferring transliteration blocks from the ne pairs.
</nextsent>
<nextsent>each feature corresponds to one aspect of the block within the context of given ne pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4832">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> transliteration blocks.  </section>
<citcontext>
<prevsection>
<prevsent>we count the number of letter-alignment links within the block, and normalize the number by the length of the source letter-ngram.
</prevsent>
<prevsent>note that, we can refine the letter alignment by growing the intersections of the two direction letter-alignments from bi-stream hmm via additional aligned letter-pairs seen in the union of the two.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
in way, this approach is similar to those of refining the word-level alignment for smt in (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>this step is shown in the upper-part in figure 1.overall, our proposed feature functions cover relatively different aspects for transliteration blocks: the block level length relevance probability in eqn.
</nextsent>
<nextsent>5, lexical translation equivalence, and positions?
</nextsent>
<nextsent>distortion from gaussian distribution in eqn.
</nextsent>
<nextsent>8, in both directions; and the average number of letter-alignment links within the block.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4833">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> transliteration blocks.  </section>
<citcontext>
<prevsection>
<prevsent>now if lj and rj+n, i.e. frl is contained within the sourceletter-ngram j+nj , then this block = (f j+nj , erl ) is defined as coherent for the aligned pairs: (f j+nj , erl ) . we accept coherent as gold-standard blocks.
</prevsent>
<prevsent>this block transliteration coherence is generally sound for extracting the gold-blocks mostly because of the the monotone left to-right nature of the letter-alignment for transliteration.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
a related coherence assumption can be found in (fox,2002), <papid> W02-1039 </papid>where their assumption on phrase-pairs for statistical machine translation is shown to be somewhat restrictive for smt.</citsent>
<aftsection>
<nextsent>this is mainly because the word alignment is often non-monotone, especially for lan gauge pairs from different families such as arabic-english and chinese-english.
</nextsent>
<nextsent>4.4 aligning letter-blocks: local search.
</nextsent>
<nextsent>aligning the blocks within ne pairs can be formulated as local search given the heuristic function defined in eqn.
</nextsent>
<nextsent>11.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4834">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>some names from this test set are shown in figure 1.
</prevsent>
<prevsent>these untranslated nes make up only very small fraction of all words in the test set.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
therefore, having correct transliterations would give only small improvements in terms of bleu (papineni et al, 2002) <papid> P02-1040 </papid>and nist scores.</citsent>
<aftsection>
<nextsent>however, successfully translating these unknown nes is very crucial for cross-lingual distillation tasks or question-answering based on the mt-output.
</nextsent>
<nextsent>1the corpus is provided as fouo (for official use only) in the darpa-gale project2ldc2004l02: buckwalter arabic morphological analyzer version 2.0 368 table 1: test set examples.
</nextsent>
<nextsent>to evaluate the transliteration performance, we use edit-distance between the hypothesis against referenceset.
</nextsent>
<nextsent>this is to count the number of insertions, deletions, and substitutions required to correct the hypothesis to match the given reference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4835">
<title id=" N07-1046.xml">a loglinear block transliteration model based on bistream hmms </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we compare the performance of three systems within our proposed framework in figure.1: the baseline block system, system in which we use log-linear combination of alignment features as described in 4.3, we call the the l-block system, and finally system, which also uses the bi-stream hmm alignment model as described in 3.
</prevsent>
<prevsent>this last system will be denoted lcbe system.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
the baseline is based on the refined letter-alignment from the two directions of ibm-model-4, trained with scheme of 15h545 using giza++ (och and ney, 2004).<papid> J04-4002 </papid>the final alignment was obtained by growing the intersections between arabic-to-english (ae) and englishto-arabic (ea) alignments with additional aligned letter pairs seen in the union.</citsent>
<aftsection>
<nextsent>this is to compensate for the inherent asymmetry in alignment models.
</nextsent>
<nextsent>blocks (letter ngram pairs) were collected directly from the refined letter-alignment, using the same algorithm as described in 4.3 for extracting gold-standard letter blocks.
</nextsent>
<nextsent>there is no length restrictions to the letter-ngram extracted in our system.
</nextsent>
<nextsent>all the blocks were then scored using relative frequencies and lexical scores in both directions, similar to the scoring of phrase-pairs in smt (koehn, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4836">
<title id=" N06-2034.xml">using phrasal patterns to identify discourse relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>adding phrasal information improves the system accuracy 12%, from 53% to 65%.
</prevsent>
<prevsent>identifying discourse relations is important for many applications, such as text/conversation understanding, single/multi-document summarization and question answering.
</prevsent>
</prevsection>
<citsent citstr=" P02-1047 ">
(marcu and echihabi 2002) <papid> P02-1047 </papid>proposed method to identify discourse relations between text segments using nave bayes classifiers trained on huge corpus.</citsent>
<aftsection>
<nextsent>they showed that lexical pair information extracted from massive amounts of data can have major impact.
</nextsent>
<nextsent>we developed system which identifies the discourse relation between two successive sentences in japanese.
</nextsent>
<nextsent>on top of the lexical information previously proposed, we added phrasal pattern information.
</nextsent>
<nextsent>a phrasal pattern includes at least three phrases (bunsetsu segments) from two sentences, where function words are mandatory and content words are optional.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4840">
<title id=" N04-1012.xml">ensemble based active learning for parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this result shows that ensemble learning can improve both the underlying model and also the way we select examples for it.
</prevsent>
<prevsent>our domain is parse selection for head-driven phrase structure grammar (hpsg).
</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
although annotated corpora exist for hpsg, such corpora do not exist insignificant volumes and are limited to few small domains (oepen et al, 2002).<papid> C02-2025 </papid></citsent>
<aftsection>
<nextsent>even if it were possible to bootstrap from the penn treebank, it is still unlikely that there would be sufficient quantities of high quality material necessary to improve parse selection for detailed linguistic formalisms such as hpsg.
</nextsent>
<nextsent>there is thus pressing need to efficiently create significant volumes of annotated material.al applied to parse selection is much more challenging than applying it to simpler tasks such as text classification or part-of-speech tagging.
</nextsent>
<nextsent>our labels are complex objects rather than discrete values drawn from small,fixed set.
</nextsent>
<nextsent>furthermore, the fact that sentences are of variable length and have variable numbers of parses potentially adds to the complexity of the task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4844">
<title id=" N04-1012.xml">ensemble based active learning for parse selection </title>
<section> parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>using these trees and the erg, several different views of analyses can be recovered: phrase structures, semantic interpretations, and elementary dependency graphs.
</prevsent>
<prevsent>the phrase structures contain detailed hpsg non-terminals but are otherwise of the variety familiar from context-free grammar, as can be seen in figure 1b.unlike most treebanks, redwoods also provides semantic information for utterances.
</prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
the semantic interpretations are expressed using minimal recur sion semantics (mrs) (copestake et al, 2001), <papid> P01-1019 </papid>which provides the means to represent interpretations with flat, underspecified semantics using terms of the predicate calculus and generalized quantifiers.</citsent>
<aftsection>
<nextsent>an example mrs structure is given in figure 2.an elementary dependency graph is simplified abstraction on full mrs structure which uses no under specification and retains only the major semantic predicates and their relations to one another.
</nextsent>
<nextsent>in this paper, we report results using the third growth of redwoods, which contains 5302 sentences for which there are at least two parses and for which unique preferred parse is identified.
</nextsent>
<nextsent>these sentences have 9.3 word sand 58.0 parses on average.
</nextsent>
<nextsent>due to the small size of redwoods and the underlying complexity of the system, exploring the effect of al techniques for this domain is of practical, as well as theoretical, interest.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4845">
<title id=" N04-1012.xml">ensemble based active learning for parse selection </title>
<section> parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>due to the small size of redwoods and the underlying complexity of the system, exploring the effect of al techniques for this domain is of practical, as well as theoretical, interest.
</prevsent>
<prevsent>2.2 modeling parse selection.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
as is now standard for feature-based grammars, we use log-linear models for parse selection (johnson et al, 1999).<papid> P99-1069 </papid></citsent>
<aftsection>
<nextsent>log-linear models are popular for their ability to incorporate wide variety of features without making assumptions about their independence.1 for log-linear models, the conditional probability of an analysis   given sentence with set of analyses
</nextsent>
<nextsent>    is given as:     fiff ffifl  !# %$ &amp; !  (*) !  +, - (1) where &amp; !  ( returns the number of times feature . occurs in analysis   , ) ! is weight, +/ - is normalization factor for the sentence, and   is model.
</nextsent>
<nextsent>the parse with the highest probability is taken as the preferred parse for the model.
</nextsent>
<nextsent>we use the limited memory variable metric algorithm (malouf, 2002) <papid> W02-2018 </papid>to determine the weights.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4846">
<title id=" N04-1012.xml">ensemble based active learning for parse selection </title>
<section> parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>    is given as:     fiff ffifl  !# %$ &amp; !  (*) !  +, - (1) where &amp; !  ( returns the number of times feature . occurs in analysis   , ) ! is weight, +/ - is normalization factor for the sentence, and   is model.
</prevsent>
<prevsent>the parse with the highest probability is taken as the preferred parse for the model.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
we use the limited memory variable metric algorithm (malouf, 2002) <papid> W02-2018 </papid>to determine the weights.</citsent>
<aftsection>
<nextsent>note that because the erg usually only produces relatively few parses for in-coverage sentences, we can simply enumerate all parses and rank them.
</nextsent>
<nextsent>the previous parse selection model (equation 1) uses single model.
</nextsent>
<nextsent>it is possible to improve performance usingan ensemble parse selection model.
</nextsent>
<nextsent>we create our ensemble model (called product model) using the product-of experts formulation (hinton, 1999):     $ 0123 4 15  6$    fi0 5  +/ - (2) note that each individual model  5is well-defined distribution and is usually taken from fixed set of models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4847">
<title id=" N04-1012.xml">ensemble based active learning for parse selection </title>
<section> parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>a product model effectively averages the contributions made by each of the individual models.
</prevsent>
<prevsent>our product model, although simple, is sufficient to show enhanced performance when using multiple models.
</prevsent>
</prevsection>
<citsent citstr=" W03-0403 ">
of course, other ensemble techniques could be used instead.1we also discussed perceptron models in baldridge and osborne (2003); <papid> W03-0403 </papid>here, we keep the model class fixed to compare different al methods.</citsent>
<aftsection>
<nextsent>fill head wh noptcomp what1 what hcomp hcomp sailr can aux pos can i hadj uns extra comp bse verb infl rule do2 do hcomp for for you you np-wh np-wh what s/np v/np v/np can np vp-nf/np vp-nf/np v/np stem/np do pp for np you (a) (b) figure 1: example erg derivation tree (a) and phrase structure tree (b).
</nextsent>
<nextsent> :which rel(bv:  ,restr:
</nextsent>
<nextsent> ,scope:
</nextsent>
<nextsent> ,dim:  ),
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4851">
<title id=" N04-1012.xml">ensemble based active learning for parse selection </title>
<section> measuring annotation cost.  </section>
<citcontext>
<prevsection>
<prevsent>accordingly, ll-prods accuracy increases to 84.23% when tested on version 1.5, which has 3834 ambiguous sentences with an average length of 7.98 and average ambiguity of 11.05.
</prevsent>
<prevsent>when evaluating al methods, we compare methods based on two metrics: the absolute number of sentences they select (unit cost) and the summed number of decisions needed to select an individual preferred parse from set of possible parses (discriminant cost).
</prevsent>
</prevsection>
<citsent citstr=" P02-1016 ">
unit cost is commonly used in al research (tang et al, 2002), <papid> P02-1016 </papid>but discriminant cost is more fine-grained.3 discriminant cost works as follows.</citsent>
<aftsection>
<nextsent>annotation for redwoods does not consist of actually drawing parse trees, and instead involves picking the correct parse out those produced by the erg.
</nextsent>
<nextsent>to facilitate this task, redwoods presents local discriminants which disambiguate large portions of the parse forest.
</nextsent>
<nextsent>this means that the annotator does not need to inspect all parses when specifying the intended analysis and so possible parses are narrowed down quickly even for sentences with large number of parses.
</nextsent>
<nextsent>more interestingly, it means that the labeling burden is relative to the number of possible parses rather than the number of constituents in parse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4852">
<title id=" N04-1012.xml">ensemble based active learning for parse selection </title>
<section> measuring annotation cost.  </section>
<citcontext>
<prevsection>
<prevsent>the dis criminant cost of the examples we use averages 3.34 per sentence and ranges from 1 to 14.we measure the discriminant cost of annotating sentence  as the number of discriminants whose values were set by the human annotators in labeling that sentence in 2the product model is also better than single model which uses all of the features of ll-config, ll-ngram, and ll conglom.
</prevsent>
<prevsent>the accuracy of the latter is 76.75%, so we achieve 4.3% error reduction over this by using the product model.
</prevsent>
</prevsection>
<citsent citstr=" W00-1306 ">
3hwa (2000) <papid> W00-1306 </papid>measured the number of constituents in parse tree as another annotation cost.</citsent>
<aftsection>
<nextsent>our approach measures the cost of more efficient labelling strategy than hwas (tree drawing).redwoods plus one to reflect the final decision of selecting the preferred parse from the reduced parse forest.
</nextsent>
<nextsent>although we have not measured the cognitive burden on humans, we strongly believe that simply selecting the best parse is far more efficient than drawing the best parse for some sentence (as exemplified by hwa (2000)).<papid> W00-1306 </papid></nextsent>
<nextsent>how ever, an interesting tension here is that we are committed to the erg producing the intended parse within the set of analyses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4855">
<title id=" N04-1012.xml">ensemble based active learning for parse selection </title>
<section> active learning methods.  </section>
<citcontext>
<prevsection>
<prevsent>4.3 lowest best probability selection.
</prevsent>
<prevsent>uncertainty sampling considers the overall shape of distribution to determine how confident model is fora given example.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
a radically simpler way of determining the potential informativity of an example is simply to consider the absolute probability of the most highly 4we experimented with kullback-leibler divergence to the mean (pereira et al, 1993; <papid> P93-1024 </papid>mccallum and nigam, 1998), but it performed no better than the simpler vote entropy metric.ranked parse.</citsent>
<aftsection>
<nextsent>the smaller this probability, the less confident the model is for that example and the more useful it will be to know its true label.
</nextsent>
<nextsent>we call this new method lowest best probability (lbp) selection, and calculate it as follows: &amp;
</nextsent>
<nextsent>fiflffi fi(
</nextsent>
<nextsent>    max     fi   (6) lbp can be extended for use with an ensemble modelin the same manner as uncertainty sampling (that is, replace the single model probability with product).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4859">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>compliant with classical transfer-based mt, target dependency structure snippets are input to agrammar-based generator.
</prevsent>
<prevsent>an experimental evaluation shows that the incorporation of grammar-based generator into ansmt framework provides improved gram maticality while achieving state-of-the-artquality on in-coverage examples, suggesting possible hybrid framework.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
recent approaches to statistical machine translation(smt) piggyback on the central concepts of phrase based smt (och et al , 1999; <papid> W99-0604 </papid>koehn et al , 2003) <papid> N03-1017 </papid>and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process.</citsent>
<aftsection>
<nextsent>phrase-based translation with multi-word units excels at modeling local ordering and short idiomatic expressions, however, itlacks mechanism to learn long-distance dependencies and is unable to generalize to unseen phrases that share non-overt linguistic information.
</nextsent>
<nextsent>publicly available statistical parsers can provide the syntactic information that is necessary for linguistic generalizations and for the resolution of non-local dependencies.
</nextsent>
<nextsent>this information source is deployed in recent work either for pre-ordering source sentences before they are input to to phrase-based system (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al , 2005), <papid> P05-1066 </papid>or for re-ordering the output of translation models by statistical ordering models that access linguistic information on dependencies and part-of-speech (lin, 2004; <papid> C04-1090 </papid>ding and palmer, 2005; <papid> P05-1067 </papid>quirk et al , 2005)<papid> P05-1034 </papid>1 . while these approaches deploy dependency-stylegrammars for parsing source and/or target text, utilization of grammar-based generation on the output of translation models has not yet been attempted independency-based smt.</nextsent>
<nextsent>instead, simple target language realization models that can easily be trained to reflect the ordering of the reference translations in the training corpus are preferred.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4860">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>compliant with classical transfer-based mt, target dependency structure snippets are input to agrammar-based generator.
</prevsent>
<prevsent>an experimental evaluation shows that the incorporation of grammar-based generator into ansmt framework provides improved gram maticality while achieving state-of-the-artquality on in-coverage examples, suggesting possible hybrid framework.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
recent approaches to statistical machine translation(smt) piggyback on the central concepts of phrase based smt (och et al , 1999; <papid> W99-0604 </papid>koehn et al , 2003) <papid> N03-1017 </papid>and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process.</citsent>
<aftsection>
<nextsent>phrase-based translation with multi-word units excels at modeling local ordering and short idiomatic expressions, however, itlacks mechanism to learn long-distance dependencies and is unable to generalize to unseen phrases that share non-overt linguistic information.
</nextsent>
<nextsent>publicly available statistical parsers can provide the syntactic information that is necessary for linguistic generalizations and for the resolution of non-local dependencies.
</nextsent>
<nextsent>this information source is deployed in recent work either for pre-ordering source sentences before they are input to to phrase-based system (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al , 2005), <papid> P05-1066 </papid>or for re-ordering the output of translation models by statistical ordering models that access linguistic information on dependencies and part-of-speech (lin, 2004; <papid> C04-1090 </papid>ding and palmer, 2005; <papid> P05-1067 </papid>quirk et al , 2005)<papid> P05-1034 </papid>1 . while these approaches deploy dependency-stylegrammars for parsing source and/or target text, utilization of grammar-based generation on the output of translation models has not yet been attempted independency-based smt.</nextsent>
<nextsent>instead, simple target language realization models that can easily be trained to reflect the ordering of the reference translations in the training corpus are preferred.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4861">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>phrase-based translation with multi-word units excels at modeling local ordering and short idiomatic expressions, however, itlacks mechanism to learn long-distance dependencies and is unable to generalize to unseen phrases that share non-overt linguistic information.
</prevsent>
<prevsent>publicly available statistical parsers can provide the syntactic information that is necessary for linguistic generalizations and for the resolution of non-local dependencies.
</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
this information source is deployed in recent work either for pre-ordering source sentences before they are input to to phrase-based system (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al , 2005), <papid> P05-1066 </papid>or for re-ordering the output of translation models by statistical ordering models that access linguistic information on dependencies and part-of-speech (lin, 2004; <papid> C04-1090 </papid>ding and palmer, 2005; <papid> P05-1067 </papid>quirk et al , 2005)<papid> P05-1034 </papid>1 . while these approaches deploy dependency-stylegrammars for parsing source and/or target text, utilization of grammar-based generation on the output of translation models has not yet been attempted independency-based smt.</citsent>
<aftsection>
<nextsent>instead, simple target language realization models that can easily be trained to reflect the ordering of the reference translations in the training corpus are preferred.
</nextsent>
<nextsent>the advantage of such models over grammar-based generation seems to be supported, for example, by quirk et al (2005) <papid> P05-1034 </papid>improvements over phrase-based smt as well as over an smt system that deploys grammar-basedgenerator (menezes and richardson, 2001) <papid> W01-1406 </papid>on gram based automatic evaluation scores (papineni et al ., 2001; doddington, 2002).</nextsent>
<nextsent>another data point, however, is given by charniak et al  (2003) whoshow that parsing-based language modeling can im prove grammaticality of translations, even if these improvements are not recorded under n-gram based evaluation measures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4862">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>phrase-based translation with multi-word units excels at modeling local ordering and short idiomatic expressions, however, itlacks mechanism to learn long-distance dependencies and is unable to generalize to unseen phrases that share non-overt linguistic information.
</prevsent>
<prevsent>publicly available statistical parsers can provide the syntactic information that is necessary for linguistic generalizations and for the resolution of non-local dependencies.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
this information source is deployed in recent work either for pre-ordering source sentences before they are input to to phrase-based system (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al , 2005), <papid> P05-1066 </papid>or for re-ordering the output of translation models by statistical ordering models that access linguistic information on dependencies and part-of-speech (lin, 2004; <papid> C04-1090 </papid>ding and palmer, 2005; <papid> P05-1067 </papid>quirk et al , 2005)<papid> P05-1034 </papid>1 . while these approaches deploy dependency-stylegrammars for parsing source and/or target text, utilization of grammar-based generation on the output of translation models has not yet been attempted independency-based smt.</citsent>
<aftsection>
<nextsent>instead, simple target language realization models that can easily be trained to reflect the ordering of the reference translations in the training corpus are preferred.
</nextsent>
<nextsent>the advantage of such models over grammar-based generation seems to be supported, for example, by quirk et al (2005) <papid> P05-1034 </papid>improvements over phrase-based smt as well as over an smt system that deploys grammar-basedgenerator (menezes and richardson, 2001) <papid> W01-1406 </papid>on gram based automatic evaluation scores (papineni et al ., 2001; doddington, 2002).</nextsent>
<nextsent>another data point, however, is given by charniak et al  (2003) whoshow that parsing-based language modeling can im prove grammaticality of translations, even if these improvements are not recorded under n-gram based evaluation measures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4863">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>phrase-based translation with multi-word units excels at modeling local ordering and short idiomatic expressions, however, itlacks mechanism to learn long-distance dependencies and is unable to generalize to unseen phrases that share non-overt linguistic information.
</prevsent>
<prevsent>publicly available statistical parsers can provide the syntactic information that is necessary for linguistic generalizations and for the resolution of non-local dependencies.
</prevsent>
</prevsection>
<citsent citstr=" C04-1090 ">
this information source is deployed in recent work either for pre-ordering source sentences before they are input to to phrase-based system (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al , 2005), <papid> P05-1066 </papid>or for re-ordering the output of translation models by statistical ordering models that access linguistic information on dependencies and part-of-speech (lin, 2004; <papid> C04-1090 </papid>ding and palmer, 2005; <papid> P05-1067 </papid>quirk et al , 2005)<papid> P05-1034 </papid>1 . while these approaches deploy dependency-stylegrammars for parsing source and/or target text, utilization of grammar-based generation on the output of translation models has not yet been attempted independency-based smt.</citsent>
<aftsection>
<nextsent>instead, simple target language realization models that can easily be trained to reflect the ordering of the reference translations in the training corpus are preferred.
</nextsent>
<nextsent>the advantage of such models over grammar-based generation seems to be supported, for example, by quirk et al (2005) <papid> P05-1034 </papid>improvements over phrase-based smt as well as over an smt system that deploys grammar-basedgenerator (menezes and richardson, 2001) <papid> W01-1406 </papid>on gram based automatic evaluation scores (papineni et al ., 2001; doddington, 2002).</nextsent>
<nextsent>another data point, however, is given by charniak et al  (2003) whoshow that parsing-based language modeling can im prove grammaticality of translations, even if these improvements are not recorded under n-gram based evaluation measures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4864">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>phrase-based translation with multi-word units excels at modeling local ordering and short idiomatic expressions, however, itlacks mechanism to learn long-distance dependencies and is unable to generalize to unseen phrases that share non-overt linguistic information.
</prevsent>
<prevsent>publicly available statistical parsers can provide the syntactic information that is necessary for linguistic generalizations and for the resolution of non-local dependencies.
</prevsent>
</prevsection>
<citsent citstr=" P05-1067 ">
this information source is deployed in recent work either for pre-ordering source sentences before they are input to to phrase-based system (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al , 2005), <papid> P05-1066 </papid>or for re-ordering the output of translation models by statistical ordering models that access linguistic information on dependencies and part-of-speech (lin, 2004; <papid> C04-1090 </papid>ding and palmer, 2005; <papid> P05-1067 </papid>quirk et al , 2005)<papid> P05-1034 </papid>1 . while these approaches deploy dependency-stylegrammars for parsing source and/or target text, utilization of grammar-based generation on the output of translation models has not yet been attempted independency-based smt.</citsent>
<aftsection>
<nextsent>instead, simple target language realization models that can easily be trained to reflect the ordering of the reference translations in the training corpus are preferred.
</nextsent>
<nextsent>the advantage of such models over grammar-based generation seems to be supported, for example, by quirk et al (2005) <papid> P05-1034 </papid>improvements over phrase-based smt as well as over an smt system that deploys grammar-basedgenerator (menezes and richardson, 2001) <papid> W01-1406 </papid>on gram based automatic evaluation scores (papineni et al ., 2001; doddington, 2002).</nextsent>
<nextsent>another data point, however, is given by charniak et al  (2003) whoshow that parsing-based language modeling can im prove grammaticality of translations, even if these improvements are not recorded under n-gram based evaluation measures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4865">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>phrase-based translation with multi-word units excels at modeling local ordering and short idiomatic expressions, however, itlacks mechanism to learn long-distance dependencies and is unable to generalize to unseen phrases that share non-overt linguistic information.
</prevsent>
<prevsent>publicly available statistical parsers can provide the syntactic information that is necessary for linguistic generalizations and for the resolution of non-local dependencies.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
this information source is deployed in recent work either for pre-ordering source sentences before they are input to to phrase-based system (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al , 2005), <papid> P05-1066 </papid>or for re-ordering the output of translation models by statistical ordering models that access linguistic information on dependencies and part-of-speech (lin, 2004; <papid> C04-1090 </papid>ding and palmer, 2005; <papid> P05-1067 </papid>quirk et al , 2005)<papid> P05-1034 </papid>1 . while these approaches deploy dependency-stylegrammars for parsing source and/or target text, utilization of grammar-based generation on the output of translation models has not yet been attempted independency-based smt.</citsent>
<aftsection>
<nextsent>instead, simple target language realization models that can easily be trained to reflect the ordering of the reference translations in the training corpus are preferred.
</nextsent>
<nextsent>the advantage of such models over grammar-based generation seems to be supported, for example, by quirk et al (2005) <papid> P05-1034 </papid>improvements over phrase-based smt as well as over an smt system that deploys grammar-basedgenerator (menezes and richardson, 2001) <papid> W01-1406 </papid>on gram based automatic evaluation scores (papineni et al ., 2001; doddington, 2002).</nextsent>
<nextsent>another data point, however, is given by charniak et al  (2003) whoshow that parsing-based language modeling can im prove grammaticality of translations, even if these improvements are not recorded under n-gram based evaluation measures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4867">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this information source is deployed in recent work either for pre-ordering source sentences before they are input to to phrase-based system (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al , 2005), <papid> P05-1066 </papid>or for re-ordering the output of translation models by statistical ordering models that access linguistic information on dependencies and part-of-speech (lin, 2004; <papid> C04-1090 </papid>ding and palmer, 2005; <papid> P05-1067 </papid>quirk et al , 2005)<papid> P05-1034 </papid>1 . while these approaches deploy dependency-stylegrammars for parsing source and/or target text, utilization of grammar-based generation on the output of translation models has not yet been attempted independency-based smt.</prevsent>
<prevsent>instead, simple target language realization models that can easily be trained to reflect the ordering of the reference translations in the training corpus are preferred.</prevsent>
</prevsection>
<citsent citstr=" W01-1406 ">
the advantage of such models over grammar-based generation seems to be supported, for example, by quirk et al (2005) <papid> P05-1034 </papid>improvements over phrase-based smt as well as over an smt system that deploys grammar-basedgenerator (menezes and richardson, 2001) <papid> W01-1406 </papid>on gram based automatic evaluation scores (papineni et al ., 2001; doddington, 2002).</citsent>
<aftsection>
<nextsent>another data point, however, is given by charniak et al  (2003) whoshow that parsing-based language modeling can im prove grammaticality of translations, even if these improvements are not recorded under n-gram based evaluation measures.
</nextsent>
<nextsent>1a notable exception to this kind of approach is chiang (2005) <papid> P05-1033 </papid>who introduces syntactic information into phrase-based smt via hierarchical phrases rather than by external parsing.</nextsent>
<nextsent>248 in this paper we would like to step away from n-gram based automatic evaluation scores for moment, and investigate the possible contributions of incorporating grammar-based generator into dependency-based smt system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4868">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the advantage of such models over grammar-based generation seems to be supported, for example, by quirk et al (2005) <papid> P05-1034 </papid>improvements over phrase-based smt as well as over an smt system that deploys grammar-basedgenerator (menezes and richardson, 2001) <papid> W01-1406 </papid>on gram based automatic evaluation scores (papineni et al ., 2001; doddington, 2002).</prevsent>
<prevsent>another data point, however, is given by charniak et al  (2003) whoshow that parsing-based language modeling can im prove grammaticality of translations, even if these improvements are not recorded under n-gram based evaluation measures.</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
1a notable exception to this kind of approach is chiang (2005) <papid> P05-1033 </papid>who introduces syntactic information into phrase-based smt via hierarchical phrases rather than by external parsing.</citsent>
<aftsection>
<nextsent>248 in this paper we would like to step away from n-gram based automatic evaluation scores for moment, and investigate the possible contributions of incorporating grammar-based generator into dependency-based smt system.
</nextsent>
<nextsent>we present dependency-based smt model that integrates theidea of multi-word translation units from phrase based smt into transfer system for dependency structure snippets.
</nextsent>
<nextsent>the statistical components ofour system are modeled on the phrase-based system of koehn et al  (2003), <papid> N03-1017 </papid>and component weights are adjusted by minimum error rate training (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>in contrast to phrase-based smt and to the above cited dependency-based smt approaches, our system feeds dependency-structure snippets into agrammar-based generator, and determines target language ordering by applying n-gram and distortion models after grammar-based generation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4870">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>248 in this paper we would like to step away from n-gram based automatic evaluation scores for moment, and investigate the possible contributions of incorporating grammar-based generator into dependency-based smt system.
</prevsent>
<prevsent>we present dependency-based smt model that integrates theidea of multi-word translation units from phrase based smt into transfer system for dependency structure snippets.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the statistical components ofour system are modeled on the phrase-based system of koehn et al  (2003), <papid> N03-1017 </papid>and component weights are adjusted by minimum error rate training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>in contrast to phrase-based smt and to the above cited dependency-based smt approaches, our system feeds dependency-structure snippets into agrammar-based generator, and determines target language ordering by applying n-gram and distortion models after grammar-based generation.
</nextsent>
<nextsent>the goal of this ordering model is thus not foremost to reflect the ordering of the reference translations, but to improve the grammaticality of translations.
</nextsent>
<nextsent>since our system uses standard smt techniques to learn about correct lexical choice and idiomatic expressions, it allows us to investigate the contribution of grammar-based generation to dependency based smt2.
</nextsent>
<nextsent>in an experimental evaluation on the test-set that was used in koehn et al  (2003) <papid> N03-1017 </papid>we show that for examples that are in coverage ofthe grammar-based system, we can achieve stateof-the-art quality on n-gram based evaluation mea sures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4877">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> extracting f-structure snippets.  </section>
<citcontext>
<prevsection>
<prevsent>our method for extracting transfer rules for dependency structure snippets operates on the paired sentences of sentence-aligned bilingual corpus.
</prevsent>
<prevsent>similar to phrase-based smt, our approach starts withan improved word-alignment that is created by intersecting alignment matrices for both translation directions, and refining the intersection alignment by adding directly adjacent alignment points, and alignment points that align previously unaligned words(see och et al  (1999)).<papid> W99-0604 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
next, source and target sentences are parsed using source and target lfg grammars to produce set of possible f(unctional) dependency structures for each side (see riezler et al  (2002) <papid> P02-1035 </papid>for the english grammar and parser; butt et al .</citsent>
<aftsection>
<nextsent>(2002) for german).
</nextsent>
<nextsent>the two f-structures that most preserve dependencies are selected for further consideration.
</nextsent>
<nextsent>selecting the most similar instead of the most probable f-structures is advantageous forrule induction since it provides for higher coverage with simpler rules.
</nextsent>
<nextsent>in the third step, the many to-many word alignment created in the first step isused to define many-to-many correspondences between the substructures of the f-structures selected in the second step.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4880">
<title id=" N06-1032.xml">grammatical machine translation </title>
<section> parsing-transfer-generation.  </section>
<citcontext>
<prevsection>
<prevsent>for example, the extraction of phrase-pair that translates zutiefst dankbar into deep appreciation isvalid in the string-based world, but would be prevented in the f-structure world because of the incompatibility of the types and for adjectival dankbar and nominal appreciation.
</prevsent>
<prevsent>similarly, transfer rule translating sein to have could be dis preferred be cause of mismatch in the the verbal types v/a and v/n. however, the transfer of sein zutiefst dankbarto have deep appreciation is licensed by compatible head types v.
</prevsent>
</prevsection>
<citsent citstr=" W02-1503 ">
we use lfg grammars, producing c(onstituent)structures (trees) and f(unctional)-structures (at tribute value matrices) as output, for parsing source and target text (riezler et al , 2002; <papid> P02-1035 </papid>butt et al , 2002).<papid> W02-1503 </papid>to increase robustness, the standard grammar is augmented with fragment grammar.</citsent>
<aftsection>
<nextsent>this allows sentences that are outside the scope of the standard grammar to be parsed as well-formed chunks specified by the grammar, with un parsable tokens possibly interspersed.
</nextsent>
<nextsent>the correct parse is determined by fewest-chunk method.
</nextsent>
<nextsent>transfer converts source into target f-structures by non-deterministically applying all of the induced transfer rules in parallel.
</nextsent>
<nextsent>each fact in the german fstructure must be transferred by exactly one transfer rule.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4891">
<title id=" N03-3005.xml">indexing methods for efficient parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.2 related work.
</prevsent>
<prevsent>an empirical method that addresses the efficiency issue is quick-check (malouf et al, 2000), method that relies on statistical data collected through training.
</prevsent>
</prevsection>
<citsent citstr=" C02-2024 ">
other techniques are focused on implementational aspects (wint ner and francez, 1999), or propose approaches similar to indexing for typed-feature structures (tfs) retrieval(ninomiya et al, 2002).<papid> C02-2024 </papid></citsent>
<aftsection>
<nextsent>an automaton-based indexing for generation is proposed in (penn and popescu,1997), while (penn, 1999b) improves the efficiency by re edmonton, may-june 2003 student research workshop , pp.
</nextsent>
<nextsent>25-30 proceedings of hlt-naacl 2003 ordering of feature encoding.
</nextsent>
<nextsent>a method (similar to the one introduced in section 7) that uses pre-compiled rule filters is presented in (kiefer et al, 1999), <papid> P99-1061 </papid>although the authors did not focus on the indexing potential of the static analysis of mother-daughter relations, nor present the indexing in large experimental context.</nextsent>
<nextsent>the indexing method proposed here can be applied to any chart-based parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4892">
<title id=" N03-3005.xml">indexing methods for efficient parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an automaton-based indexing for generation is proposed in (penn and popescu,1997), while (penn, 1999b) improves the efficiency by re edmonton, may-june 2003 student research workshop , pp.
</prevsent>
<prevsent>25-30 proceedings of hlt-naacl 2003 ordering of feature encoding.
</prevsent>
</prevsection>
<citsent citstr=" P99-1061 ">
a method (similar to the one introduced in section 7) that uses pre-compiled rule filters is presented in (kiefer et al, 1999), <papid> P99-1061 </papid>although the authors did not focus on the indexing potential of the static analysis of mother-daughter relations, nor present the indexing in large experimental context.</citsent>
<aftsection>
<nextsent>the indexing method proposed here can be applied to any chart-based parser.
</nextsent>
<nextsent>we chose for illustration the efd parser implemented in prolog (an extensive presentation of efd can be found in (penn, 1999c)).
</nextsent>
<nextsent>efd is bottom up, right-to-left parser, that needs no active edges.
</nextsent>
<nextsent>it uses chart to store the passive edges.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4893">
<title id=" N03-3005.xml">indexing methods for efficient parsing </title>
<section> preliminaries.  </section>
<citcontext>
<prevsection>
<prevsent>the chart contains   1 entries (n is the number of words in the input sentence), each entry holding edges that have their right margin at position i. 2.1 tfs encoding.
</prevsent>
<prevsent>to ensure that unification is carried through internal pro log unification, we encoded descriptions as prolog terms for parsing tfsgs.
</prevsent>
</prevsection>
<citsent citstr=" J88-1004 ">
from the existing methods that efficiently encode tfs into prolog terms ((mellish, 1988), (<papid> J88-1004 </papid>gerdemann, 1995), (penn, 1999a)), we used embedded prolog lists to represent feature structures.</citsent>
<aftsection>
<nextsent>as shown in (penn, 1999a), if the feature graph is n-colourable, the least number of argument positions in flat encoding is n. types were encoded using the attributed variables from sicstus (sics, 2001).
</nextsent>
<nextsent>in order to close rule, all the rules?
</nextsent>
<nextsent>daughters should be found in the chart as edges.
</nextsent>
<nextsent>looking for matching edge for daughter is accomplished by attempting unifications with edges stored in the chart, resulting in many failed unifications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4894">
<title id=" N04-3012.xml">wordnet similarity  measuring the relatedness of concepts </title>
<section> similarity measures.  </section>
<citcontext>
<prevsection>
<prevsent>the default source for information content for concepts is the sense tagged corpus semcor.
</prevsent>
<prevsent>however, there are also utility programs available with wordnet::similarity that allow user to compute information content values from the brown corpus, the penn treebank, the british national corpus, or any given corpus of raw text.
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
similarity.pl --type wordnet::similarity::lin car#n#2 bus#n#1 car#n#2 bus#n#1 0.530371390319309 # railway car versus motor coach   similarity.pl --type wordnet::similarity::lin car#n bus#n car#n#1 bus#n#1 0.618486790769613 # automobile versus motor coach   similarity.pl --type wordnet::similarity::lin --allsenses car#n bus#n#1 car#n#1 bus#n#1 0.618486790769613 # automobile versus motor coach car#n#2 bus#n#1 0.530371390319309 # railway car versus motor coach car#n#3 bus#n#1 0.208796988315133 # cable car versus motor coach figure 1: command line interface three similarity measures are based on path lengths between pair of concepts: lch (leacock and chodorow, 1998), wup (wu and palmer, 1994), <papid> P94-1019 </papid>and path.</citsent>
<aftsection>
<nextsent>lch finds the shortest path between two concepts, and scales that value by the maximum path length found in the isa hierarchy in which they occur.
</nextsent>
<nextsent>wup finds the depth of the lcs of the concepts, and then scales that by the sum ofthe depths of the individual concepts.
</nextsent>
<nextsent>the depth of concept is simply its distance to the root node.
</nextsent>
<nextsent>the measure path is baseline that is equal to the inverse of the shortest path between two concepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4895">
<title id=" N04-3012.xml">wordnet similarity  measuring the relatedness of concepts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(jarmasz and szpakowicz, 2003) compares measures of similarity derived from wordnet and rogets thesaurus.
</prevsent>
<prevsent>the comparisons are based on correlation with human relatedness values, as well as the toefl synonym identification tasks.
</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
(baldwin et al , 2003) <papid> W03-1812 </papid>use wordnet::similarity to provide an evaluation tool for multiword expressions that are identified via latent semantic analysis.</citsent>
<aftsection>
<nextsent>(diab, 2003) combines number of similarity measures that are then used as feature in the disambiguation of verb senses.
</nextsent>
<nextsent>wordnet::similarity is written in perl and is freely distributed under the gnu public license.
</nextsent>
<nextsent>it is available from the comprehensive perl archive network (http://search.cpan.org/dist/wordnet-similarity) and via source forge, an open source development platform (http://wn-similarity.sourceforge.net).
</nextsent>
<nextsent>wordnet::similarity was preceeded by the distance.pl program, which was released in june 2002.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4896">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we integrate propbank semantic role labels to an existing statistical parsing model producing richer output.
</prevsent>
<prevsent>we show conclusive results on joint learning and inference of syntactic and semantic representations.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
recent successes in statistical syntactic parsing based on supervised techniques trained on large corpus of syntactic trees (collins, 1999; charniak, 2000; <papid> A00-2018 </papid>henderson, 2003) <papid> N03-1014 </papid>have brought the hope thatthe same approach could be applied to the more ambitious goal of recovering the propositional content and the frame semantics of sentence.</citsent>
<aftsection>
<nextsent>moving towards shallow semantic level of representation has immediate applications in question-answering and information extraction.
</nextsent>
<nextsent>for example, an automatic flight reservation system processing the sentence want to book flight from geneva to new york will need to know that from geneva indicates the origin of the flight and to new york the destination.
</nextsent>
<nextsent>(gildea and jurafsky, 2002) <papid> J02-3001 </papid>define this shallow semantic task as classification problem where the semantic role to be assigned to each constituent is inferred on the basis of probability distributions of syntactic features extracted from parse trees.</nextsent>
<nextsent>they use learning features such as phrase type, position, voice, and parse tree path.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4897">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we integrate propbank semantic role labels to an existing statistical parsing model producing richer output.
</prevsent>
<prevsent>we show conclusive results on joint learning and inference of syntactic and semantic representations.
</prevsent>
</prevsection>
<citsent citstr=" N03-1014 ">
recent successes in statistical syntactic parsing based on supervised techniques trained on large corpus of syntactic trees (collins, 1999; charniak, 2000; <papid> A00-2018 </papid>henderson, 2003) <papid> N03-1014 </papid>have brought the hope thatthe same approach could be applied to the more ambitious goal of recovering the propositional content and the frame semantics of sentence.</citsent>
<aftsection>
<nextsent>moving towards shallow semantic level of representation has immediate applications in question-answering and information extraction.
</nextsent>
<nextsent>for example, an automatic flight reservation system processing the sentence want to book flight from geneva to new york will need to know that from geneva indicates the origin of the flight and to new york the destination.
</nextsent>
<nextsent>(gildea and jurafsky, 2002) <papid> J02-3001 </papid>define this shallow semantic task as classification problem where the semantic role to be assigned to each constituent is inferred on the basis of probability distributions of syntactic features extracted from parse trees.</nextsent>
<nextsent>they use learning features such as phrase type, position, voice, and parse tree path.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4899">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moving towards shallow semantic level of representation has immediate applications in question-answering and information extraction.
</prevsent>
<prevsent>for example, an automatic flight reservation system processing the sentence want to book flight from geneva to new york will need to know that from geneva indicates the origin of the flight and to new york the destination.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
(gildea and jurafsky, 2002) <papid> J02-3001 </papid>define this shallow semantic task as classification problem where the semantic role to be assigned to each constituent is inferred on the basis of probability distributions of syntactic features extracted from parse trees.</citsent>
<aftsection>
<nextsent>they use learning features such as phrase type, position, voice, and parse tree path.
</nextsent>
<nextsent>consider, for example,a sentence such as the authority dropped at midnight tuesday to $ 2.80 trillion (taken from section 00 of propbank (palmer et al, 2005)).<papid> J05-1004 </papid></nextsent>
<nextsent>the fact that to $ 2.80 trillion receives direction semantic labelis highly correlated to the fact that it is prepositional phrase (pp), that it follows the verb dropped, verb of change of state requiring an end point, that the verb is in the active voice, and that the pp is in certain tree configuration with the governing verb.all the recent systems proposed for semantic role labelling (srl) follow this same assumption (conll, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4900">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(gildea and jurafsky, 2002) <papid> J02-3001 </papid>define this shallow semantic task as classification problem where the semantic role to be assigned to each constituent is inferred on the basis of probability distributions of syntactic features extracted from parse trees.</prevsent>
<prevsent>they use learning features such as phrase type, position, voice, and parse tree path.</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
consider, for example,a sentence such as the authority dropped at midnight tuesday to $ 2.80 trillion (taken from section 00 of propbank (palmer et al, 2005)).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>the fact that to $ 2.80 trillion receives direction semantic labelis highly correlated to the fact that it is prepositional phrase (pp), that it follows the verb dropped, verb of change of state requiring an end point, that the verb is in the active voice, and that the pp is in certain tree configuration with the governing verb.all the recent systems proposed for semantic role labelling (srl) follow this same assumption (conll, 2005).
</nextsent>
<nextsent>the assumption that syntactic distributions will be predictive of semantic role assignments is basedon linking theory.
</nextsent>
<nextsent>linking theory assumes the existence of hierarchy of semantic roles which are mapped by default on hierarchy of syntactic positions.
</nextsent>
<nextsent>it also shows that regular mappings from the semantic to the syntactic level can be posited even for those verbs whose arguments can take several syntactic positions, such as psychological verbs,locatives, or datives, requiring more complex theory.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4903">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the in directness of the relation is also confirmed by the difficulty in exploiting semantic information forparsing.
</prevsent>
<prevsent>previous attempts have not been successful.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
(klein and manning, 2003) <papid> P03-1054 </papid>report reduction in parsing accuracy of an un lexicalised pcfg from77.8% to 72.9% in using penn treebank function labels in training.</citsent>
<aftsection>
<nextsent>the two existing systems that use function labels sucessfully, either inherit collins?
</nextsent>
<nextsent>modelling of the notion of complement (gabbard, kulick and marcus, 2006) or model function labels directly (musillo and merlo, 2005).<papid> W05-1509 </papid></nextsent>
<nextsent>furthermore,our results indicate that the proposed models are robust.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4905">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(klein and manning, 2003) <papid> P03-1054 </papid>report reduction in parsing accuracy of an un lexicalised pcfg from77.8% to 72.9% in using penn treebank function labels in training.</prevsent>
<prevsent>the two existing systems that use function labels sucessfully, either inherit collins?</prevsent>
</prevsection>
<citsent citstr=" W05-1509 ">
modelling of the notion of complement (gabbard, kulick and marcus, 2006) or model function labels directly (musillo and merlo, 2005).<papid> W05-1509 </papid></citsent>
<aftsection>
<nextsent>furthermore,our results indicate that the proposed models are robust.
</nextsent>
<nextsent>to model our task accurately, additional parameters must be estimated.
</nextsent>
<nextsent>however, given the current limited availability of annotated treebanks, this more complex task will have to be solved with thesame overall amount of data, aggravating the difficulty of estimating the models parameters due to sparse data.
</nextsent>
<nextsent>in this section we describe the augmentations to our base parsing models necessary to tackle the joint learning of parse tree and semantic role labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4906">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> the data and the extended parser.  </section>
<citcontext>
<prevsection>
<prevsent>however, given the current limited availability of annotated treebanks, this more complex task will have to be solved with thesame overall amount of data, aggravating the difficulty of estimating the models parameters due to sparse data.
</prevsent>
<prevsent>in this section we describe the augmentations to our base parsing models necessary to tackle the joint learning of parse tree and semantic role labels.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
propbank encodes propositional information by adding layer of argument structure annotation tothe syntactic structures of the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>verbal predicates in the penn tree bank (ptb) receive label rel and their arguments are annotated with abstract semantic role labels a0 a5 or aa for those complements of the predicativeverb that are considered arguments while those complements of the verb labelled with semantic functional label in the original ptb receive the composite semantic role label am-x , where stands for labels such as loc, tmp or adv, for locative,temporal and adverbial modifiers respectively.
</nextsent>
<nextsent>propbank uses two levels of granularity in its annotation, at least conceptually.
</nextsent>
<nextsent>arguments receiving labels a0-a5 or aa do not express consistent semantic roles and are specific to verb, while arguments receiving an am-x label are supposed to be adjuncts, and the roles they express are consistent across all verbs.to achieve the complex task of assigning semantic role labels while parsing, we use family of state-of-the-art history-based statistical parsers, the simple synch rony network (ssn) parsers (hender son, 2003), <papid> N03-1014 </papid>which use form of left-corner parse strategy to map parse trees to sequences of derivation steps.</nextsent>
<nextsent>these parsers do not impose any priori independence assumptions, but instead smooth their parameters by means of the novel ssn neural network architecture.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4911">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> the data and the extended parser.  </section>
<citcontext>
<prevsection>
<prevsent>, di1) ofa derivation, normalized exponential output function is computed by the ssns to estimate probability distribution over the possible next derivation moves di.
</prevsent>
<prevsent>to exploit the intuition that semantic role labels are predictive of syntactic structure, we must pro 102 vide semantic role information as early as possible to the parser.
</prevsent>
</prevsection>
<citsent citstr=" H05-1078 ">
extending technique presented in (klein and manning, 2003) <papid> P03-1054 </papid>and adopted in (merloand musillo, 2005) <papid> H05-1078 </papid>for function labels with state of-the-art results, we split some part-of-speech tags into tags marked with am-x semantic role labels.</citsent>
<aftsection>
<nextsent>as result, 240 new pos tags were introduced to partition the original tag set which consisted of 45tags.
</nextsent>
<nextsent>our augmented model has total of 613 nonterminals to represent both the ptb and propbank labels, instead of the 33 of the original ssn parser.the 580 newly introduced labels consist of standard ptb label followed by one or more propbank semantic roles, such as pp-am-tmp or np-a0-a1.
</nextsent>
<nextsent>these augmented tags and the new non-terminalsare included in the set , and will influence bottom up projection of structure directly.these newly introduced fine-grained labels fragment our propbank data.
</nextsent>
<nextsent>to alleviate this problem,we enlarge the set with two additional binary features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4914">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>an indirect way of comparing our parser with semantic role labellers suggestsitself.
</prevsent>
<prevsent>2 we merge the partial trees output by semantic role lab eller with the output of the parser on which it was trained, and compute propbank parsing performance measures on the resulting parse trees.
</prevsent>
</prevsection>
<citsent citstr=" W05-0623 ">
the third line, propbank column of table 1 reports such measures summarised for the five best semantic role labelling systems (punyakanok et al, 2005b;haghighi et al, 2005; <papid> W05-0623 </papid>pradhan et al, 2005; <papid> W05-0634 </papid>marquez et al, 2005; surdeanu and turmo, 2005) <papid> W05-0635 </papid>in the conll 2005 shared task.</citsent>
<aftsection>
<nextsent>these systems alluse (charniak, 2000)<papid> A00-2018 </papid>s parse trees both for training and testing, as well as various other information sources including sets of n-best parse trees, chunks, or named entities.</nextsent>
<nextsent>thus, the partial trees output bythese systems were merged with the parse trees returned by charniaks parser (second line, propbank column).3these results jointly confirm our initial hypothe 1(shen and joshi, 2005) <papid> H05-1102 </papid>use propbank labels to extract ltag spinal trees to train an incremental ltag parser, but theydo not parse propbank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4915">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>an indirect way of comparing our parser with semantic role labellers suggestsitself.
</prevsent>
<prevsent>2 we merge the partial trees output by semantic role lab eller with the output of the parser on which it was trained, and compute propbank parsing performance measures on the resulting parse trees.
</prevsent>
</prevsection>
<citsent citstr=" W05-0634 ">
the third line, propbank column of table 1 reports such measures summarised for the five best semantic role labelling systems (punyakanok et al, 2005b;haghighi et al, 2005; <papid> W05-0623 </papid>pradhan et al, 2005; <papid> W05-0634 </papid>marquez et al, 2005; surdeanu and turmo, 2005) <papid> W05-0635 </papid>in the conll 2005 shared task.</citsent>
<aftsection>
<nextsent>these systems alluse (charniak, 2000)<papid> A00-2018 </papid>s parse trees both for training and testing, as well as various other information sources including sets of n-best parse trees, chunks, or named entities.</nextsent>
<nextsent>thus, the partial trees output bythese systems were merged with the parse trees returned by charniaks parser (second line, propbank column).3these results jointly confirm our initial hypothe 1(shen and joshi, 2005) <papid> H05-1102 </papid>use propbank labels to extract ltag spinal trees to train an incremental ltag parser, but theydo not parse propbank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4916">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>an indirect way of comparing our parser with semantic role labellers suggestsitself.
</prevsent>
<prevsent>2 we merge the partial trees output by semantic role lab eller with the output of the parser on which it was trained, and compute propbank parsing performance measures on the resulting parse trees.
</prevsent>
</prevsection>
<citsent citstr=" W05-0635 ">
the third line, propbank column of table 1 reports such measures summarised for the five best semantic role labelling systems (punyakanok et al, 2005b;haghighi et al, 2005; <papid> W05-0623 </papid>pradhan et al, 2005; <papid> W05-0634 </papid>marquez et al, 2005; surdeanu and turmo, 2005) <papid> W05-0635 </papid>in the conll 2005 shared task.</citsent>
<aftsection>
<nextsent>these systems alluse (charniak, 2000)<papid> A00-2018 </papid>s parse trees both for training and testing, as well as various other information sources including sets of n-best parse trees, chunks, or named entities.</nextsent>
<nextsent>thus, the partial trees output bythese systems were merged with the parse trees returned by charniaks parser (second line, propbank column).3these results jointly confirm our initial hypothe 1(shen and joshi, 2005) <papid> H05-1102 </papid>use propbank labels to extract ltag spinal trees to train an incremental ltag parser, but theydo not parse propbank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4918">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the third line, propbank column of table 1 reports such measures summarised for the five best semantic role labelling systems (punyakanok et al, 2005b;haghighi et al, 2005; <papid> W05-0623 </papid>pradhan et al, 2005; <papid> W05-0634 </papid>marquez et al, 2005; surdeanu and turmo, 2005) <papid> W05-0635 </papid>in the conll 2005 shared task.</prevsent>
<prevsent>these systems alluse (charniak, 2000)<papid> A00-2018 </papid>s parse trees both for training and testing, as well as various other information sources including sets of n-best parse trees, chunks, or named entities.</prevsent>
</prevsection>
<citsent citstr=" H05-1102 ">
thus, the partial trees output bythese systems were merged with the parse trees returned by charniaks parser (second line, propbank column).3these results jointly confirm our initial hypothe 1(shen and joshi, 2005) <papid> H05-1102 </papid>use propbank labels to extract ltag spinal trees to train an incremental ltag parser, but theydo not parse propbank.</citsent>
<aftsection>
<nextsent>their results on the ptb are not directly comparable to ours as calculated on dependecy relations and obtained using gold pos.
</nextsent>
<nextsent>2current work aims at extending our parser to recovering the argument structure for each verb, supporting direct comparison to semantic role labellers.
</nextsent>
<nextsent>3because of differences in tokenisations, we retain only 2280 sentences out of the original 2416.
</nextsent>
<nextsent>103 ptb propbank ssn+roles model 89.0 82.8 conll five best - 83.384.1henderson 03 ssn 89.1 table 1: percentage f-measure of our ssn parser onptb and propbank parsing, compared to the original ssn parser and to the best conll 2005 sr la bellers.sis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4919">
<title id=" N06-2026.xml">accurate parsing of the proposition bank </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>this indicates that the model is robust, as it has been extended to richer set of labels successfully, without increase in training data.
</prevsent>
<prevsent>in fact, the limited availability of datais increased further by the high variability of the ar gumental labels a0-a5 whose semantics is specific to given verb or given verb sense.
</prevsent>
</prevsection>
<citsent citstr=" P02-1031 ">
methodologically, these initial results on joint solution to parsing and semantic role labelling provide the first direct test of whether parsing is necessary for semantic role labelling (gildea and palmer,2002; <papid> P02-1031 </papid>punyakanok et al, 2005a).</citsent>
<aftsection>
<nextsent>comparing semantic role labelling based on chunked input to the better semantic role labels retrieved based on parsed trees, (gildea and palmer, 2002) <papid> P02-1031 </papid>conclude that parsing is necessary.</nextsent>
<nextsent>in an extensive experimental investigation of the different learning stages usually involved in semantic role labelling, (punyakanok et al., 2005a) find instead that sophisticated chunking can achieve state-of-the-art results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4921">
<title id=" N04-1042.xml">accurate information extraction from research papers using conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present results on this research paper meta-data extraction task using conditional random field (lafferty et al, 2001), and explore several practical issues in applying crfs to information extraction ingeneral.
</prevsent>
<prevsent>the crf approach draws together the advantages of both finite state hmm and discriminative svm techniques by allowing use of arbitrary, dependent features and joint inference over entire sequences.
</prevsent>
</prevsection>
<citsent citstr=" W03-0430 ">
crfs have been previously applied to other tasks such as name entity extraction (mccallum and li, 2003), <papid> W03-0430 </papid>table extraction (pinto et al, 2003) and shallow parsing (sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>the basic theory of crfs is now well-understood, but the best-practices for applying them to new, real-world data is still in an early-explorationphase.
</nextsent>
<nextsent>here we explore two key practical issues: (1) regularization, with an empirical study of gaussian (chen and rosenfeld, 2000), exponential (goodman, 2003), and hyperbolic-l1 (pinto et al, 2003) priors; (2) exploration of various families of features, including text, lexicons,and layout, as well as proposing method for the beneficial use of zero-count features without incurring large memory penalties.
</nextsent>
<nextsent>we describe large collection of experimental result son two traditional benchmark datasets.
</nextsent>
<nextsent>dramatic improvements are obtained in comparison with previous svm and hmm based results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4922">
<title id=" N04-1042.xml">accurate information extraction from research papers using conditional random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present results on this research paper meta-data extraction task using conditional random field (lafferty et al, 2001), and explore several practical issues in applying crfs to information extraction ingeneral.
</prevsent>
<prevsent>the crf approach draws together the advantages of both finite state hmm and discriminative svm techniques by allowing use of arbitrary, dependent features and joint inference over entire sequences.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
crfs have been previously applied to other tasks such as name entity extraction (mccallum and li, 2003), <papid> W03-0430 </papid>table extraction (pinto et al, 2003) and shallow parsing (sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>the basic theory of crfs is now well-understood, but the best-practices for applying them to new, real-world data is still in an early-explorationphase.
</nextsent>
<nextsent>here we explore two key practical issues: (1) regularization, with an empirical study of gaussian (chen and rosenfeld, 2000), exponential (goodman, 2003), and hyperbolic-l1 (pinto et al, 2003) priors; (2) exploration of various families of features, including text, lexicons,and layout, as well as proposing method for the beneficial use of zero-count features without incurring large memory penalties.
</nextsent>
<nextsent>we describe large collection of experimental result son two traditional benchmark datasets.
</nextsent>
<nextsent>dramatic improvements are obtained in comparison with previous svm and hmm based results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4924">
<title id=" N04-1042.xml">accurate information extraction from research papers using conditional random fields </title>
<section> conditional random fields.  </section>
<citcontext>
<prevsection>
<prevsent>(2)maximizing (2) corresponds to satisfying the following equality, wherein the the empirical count of each feature matches its expected count according to the model p?(y|x).
</prevsent>
<prevsent>i fk(yt1, yt, xi, t) = ? p?(y|x)fk(yt1, yt, xi, t) crfs share many of the advantageous properties of standard maximum entropy models, including their convex likelihood function, which guarantees that the learning procedure converges to the global maximum.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
traditional maximum entropy learning algorithms, such as gis and iis (pietra et al, 1995), can be used to train crfs, however, it has been found that quasi-newton gradient-climber, bfgs, converges much faster (malouf,2002; <papid> W02-2018 </papid>sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>we use bfgs for optimization.
</nextsent>
<nextsent>in our experiments, we shall focus instead ontwo other aspects of crf deployment, namely regularization and selection of different model structure and feature types.
</nextsent>
<nextsent>2.1 regularization in crfs.
</nextsent>
<nextsent>to avoid over-fitting, log-likelihood is often penalized by some prior distribution over the parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4928">
<title id=" N03-1030.xml">sentence level discourse parsing using syntactic and lexical information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a discourse parsing algorithm that implements these models derives discourse parse trees withan error reduction of 18.8% over state-of the-art decision-based discourse parser.
</prevsent>
<prevsent>a setof empirical evaluations shows that our discourse parsing model is sophisticated enough to yield discourse trees at an accuracy level that matches near-human levels of performance.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
by exploiting information encoded in human-producedsyntactic trees (marcus et al, 1993), <papid> J93-2004 </papid>research on probabilistic models of syntax has driven the performance of syntactic parsers to about 90% accuracy (charniak, 2000; <papid> A00-2018 </papid>collins, 2000).</citsent>
<aftsection>
<nextsent>the absence of semantic and discourse annotated corpora prevented similar developments in se mantic/discourse parsing.
</nextsent>
<nextsent>fortunately, recent annotation projects have taken signicant steps towards developing semantic (fillmore et al, 2002; kingsbury and palmer,2002) and discourse (carlson et al, 2003) annotated corpora.
</nextsent>
<nextsent>some of these annotation efforts have already hada computational impact.
</nextsent>
<nextsent>for example, gildea and jurafsky (2002) <papid> J02-3001 </papid>developed statistical models for automatically inducing semantic roles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4929">
<title id=" N03-1030.xml">sentence level discourse parsing using syntactic and lexical information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a discourse parsing algorithm that implements these models derives discourse parse trees withan error reduction of 18.8% over state-of the-art decision-based discourse parser.
</prevsent>
<prevsent>a setof empirical evaluations shows that our discourse parsing model is sophisticated enough to yield discourse trees at an accuracy level that matches near-human levels of performance.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
by exploiting information encoded in human-producedsyntactic trees (marcus et al, 1993), <papid> J93-2004 </papid>research on probabilistic models of syntax has driven the performance of syntactic parsers to about 90% accuracy (charniak, 2000; <papid> A00-2018 </papid>collins, 2000).</citsent>
<aftsection>
<nextsent>the absence of semantic and discourse annotated corpora prevented similar developments in se mantic/discourse parsing.
</nextsent>
<nextsent>fortunately, recent annotation projects have taken signicant steps towards developing semantic (fillmore et al, 2002; kingsbury and palmer,2002) and discourse (carlson et al, 2003) annotated corpora.
</nextsent>
<nextsent>some of these annotation efforts have already hada computational impact.
</nextsent>
<nextsent>for example, gildea and jurafsky (2002) <papid> J02-3001 </papid>developed statistical models for automatically inducing semantic roles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4930">
<title id=" N03-1030.xml">sentence level discourse parsing using syntactic and lexical information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>fortunately, recent annotation projects have taken signicant steps towards developing semantic (fillmore et al, 2002; kingsbury and palmer,2002) and discourse (carlson et al, 2003) annotated corpora.
</prevsent>
<prevsent>some of these annotation efforts have already hada computational impact.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
for example, gildea and jurafsky (2002) <papid> J02-3001 </papid>developed statistical models for automatically inducing semantic roles.</citsent>
<aftsection>
<nextsent>in this paper, we describe probabilistic models and algorithms that exploit the discourse annotated corpus produced by carlson et al (2003).
</nextsent>
<nextsent>a discourse structure is tree whose leaves correspond to elementary discourse units (edu)s, and whose internal nodes correspond to contiguous text spans (called discourse spans).
</nextsent>
<nextsent>an example of discourse structure isthe tree given in figure 1.
</nextsent>
<nextsent>each internal node in discourse tree is characterized by rhetorical relation, such it will use its network the bank also says 1 2 3 [2,3] attribution to channel investments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4931">
<title id=" N03-1030.xml">sentence level discourse parsing using syntactic and lexical information </title>
<section> the discourse segmenter.  </section>
<citcontext>
<prevsection>
<prevsent>discourse segmentation is the process in which given text is broken into non-overlapping segments called elementary discourse units (edus).
</prevsent>
<prevsent>in the present work, elementary discourse units are taken to be clauses or clause like units that are unequivocally the nucleus or satellite of rhetorical relation that holds between two adjacent spans of text (see (carlson et al, 2003) for details).our approach to discourse segmentation breaks the problem further into two sub-problems: sentence segmentation and sentence-level discourse segmentation.
</prevsent>
</prevsection>
<citsent citstr=" J97-2002 ">
the problem of sentence segmentation has been studied extensively, and tools such as those described by palmer and hearst (1997) <papid> J97-2002 </papid>and ratnaparkhi (1998) can handle itwell.</citsent>
<aftsection>
<nextsent>in this section, we present discourse segmentation algorithm that deals with segmenting sentences into elementary discourse units.
</nextsent>
<nextsent>3.1 the discourse segmentation model.
</nextsent>
<nextsent>the discourse segmenter proposed here takes as input asentence and outputs its elementary discourse unit boundaries.
</nextsent>
<nextsent>our statistical approach to sentence segmentation uses two components: statistical model which assignsa probability to the insertion of discourse boundary after each word in sentence, and segmenter, which usesthe probabilities computed by the model for inserting discourse boundaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4932">
<title id=" N03-1030.xml">sentence level discourse parsing using syntactic and lexical information </title>
<section> the discourse segmenter.  </section>
<citcontext>
<prevsection>
<prevsent>boundary, no-boundary @ . because our model is concerned with discourse segmentation at sentence level, we dene 9: boundary   - 8 %(7a+cb , i.e., the sentence boundary is always discourse boundary as well.
</prevsent>
<prevsent>our model uses both lexical and syntactic features for determining the probability of inserting discourse boundaries.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
we apply canonical lexical head projection rules (magerman, 1995) <papid> P95-1037 </papid>in order to lexicalize syntactictrees.</citsent>
<aftsection>
<nextsent>for each word - , the upper-most node with lexical head - which has right sibling node determines the features on the basis of which we decide whether to insert discourse boundary.
</nextsent>
<nextsent>we denote such node dfe , and the features we use are node dge , its parent dih , andthe siblings of dje . in the example in figure 2, we determine whether to insert discourse boundary after the word says using as features node dkha+mlno p!q!r p! and its children e +sltvu p!qr  and djwx+zy!t\[]o_^` aa . we use our corpus to estimate the likelihood of inserting discourse boundary between word - and the next word using formula (1), 9:#;   -k%(7cbed fl#dihkfg24242(dhej*ffd 24242&amp; fl#d fi24227d dhw 2242&amp; (1) where the numerator represents all the counts of the rule h fi2422(d dhw324242 for which discourse boundary hasbeen inserted after word - , and the denominator represents all the counts of the rule.
</nextsent>
<nextsent>because we want to account for boundaries that are motivated lexically as well, the counts used in formula (1) are dened over lexicalized rules.
</nextsent>
<nextsent>without lexicalization,the syntactic context alone is too general and fails to distinguish genuine cases of discourse boundaries from incorrect ones.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="O4933">
<title id=" N03-1030.xml">sentence level discourse parsing using syntactic and lexical information </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we train our discourse parsing model on the training section of the corpus described in section 2, and test it on the test section.
</prevsent>
<prevsent>the training regime uses syntactic trees from the penn treebank.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
the performance is assessed using labeled recall and labeled precision as dened by the standard parseval metric (black et al, 1991).<papid> H91-1060 </papid></citsent>
<aftsection>
<nextsent>as mentioned in section 2, we use both 18 labels and 110 labels for the discourse relations.
</nextsent>
<nextsent>the recall and precision gures are combined into an f-score gure in the usual manner.the discourse parsing model uses syntactic trees produced by charniaks parser (2000) and discourse segments produced by the algorithm described in section 3.
</nextsent>
<nextsent>we compare the performance of our model ( ??up9 ) with the performance of the decision-based discourse parsing model ( pqflpq9 ) proposed by (marcu, 2000), and jpq9 pqflpq9 ? upq9 xpq9 unlabeled 64.0 67.0 70.5 92.8 18 labels 23.4 37.2 49.0 77.0.
</nextsent>
<nextsent>110 labels 20.7 35.5 45.6 71.9.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
</paper>