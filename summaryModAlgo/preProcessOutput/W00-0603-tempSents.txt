11	naturally, our current work on question answering for the reading comprehension task is most related to those of . 
17	as was observed by and , the correct answer sentence often precedes/follows the sentence with the highest number of matching words. 
9	4 evaluation to evaluate our learning approach, we trained aquarea$ on the same development set of stories and tested it on the same test set of stories as those used in all past work on the reading comprehension task . 
6	et al, 1999), , , and are 36.3%, 
2	quarc utilizes manually generated rules that selects a sentence deemed to contain the answer based on a combination of syntactic similarity and semantic correspondence . 
5	as such, all subsequent work uses humsent as the main scoring metric, and it is also the scoring metric that we adopted in this paper. 
18	then and reported improvements to 39.7% and 41%, respectively. 
10	keywords in questions it has been observed in the work of that certain words in a when or where question tend to indicate that the dateline is an ~n~wer sentence to the question. 
1	in addition, a number of researchers have built systems to take reading comprehension examinations designed to evaluate childrenâ€™s reading levels . 
15	based on these technologies, riloff and thelen improved the humsent accuracy to 40% by applying a set of heuristic rules that assign handcrafted weights to matching words and ne. 
19	we also compared our results across various interrogatives with those previously reported in . 
8	it has been observed in prior work that such sentences may be more likely to be the answer sentences to some question type . 
14	the words used in are "happen", "take place" "this", "story". 
4	it is interesting to note that the words automatically determined by out procedure are also part of those words found manually in the prior work of . 
3	in prior work the number and type of information sources used for computation is specific to and rlifferent for each question type. 
13	we designed these 4 features to capture information that will be helpful to the why questions, since it has been observed in prior work that the answer 127 sentence to a why question tends to follow the sentence in the story that has the most number of word matches with the question. 
7	subsequently, the work of and improved the accuracy further to 39.7% and 41%, respectively. 
12	3.1 feature representation our feature representation was designed to capture the information sources that prior work used in their computations or rules. 
16	refer to the readme le of minipar downloaded from http://www.cs.ualberta.ca/ lindek/minipar.htm 5 experimental results we selected the features used in quarc to establish the reference performance level. 
