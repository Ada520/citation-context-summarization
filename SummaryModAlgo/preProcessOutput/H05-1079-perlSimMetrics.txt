4	4	
4	1	0
4	8	0.0206467912231355
4	5	0.291295404868948
4	2	6.82680380392834e-07
4	9	0.00184444826160368
4	3	0.00036091465193732
4	7	0.000980807716280081
4	6	0.000190112577948008
1	4	0
1	1	
1	8	0.0967001767946264
1	5	0
1	2	0
1	9	0.0327306395684998
1	3	0
1	7	0
1	6	0.00398020249199495
8	4	0.0206467912231355
8	1	0.0967001767946264
8	8	
8	5	0.0247213867811797
8	2	0.0294952632656165
8	9	0.101943351817516
8	3	0.000707050492934019
8	7	0.0194226637526994
8	6	0
5	4	0.291295404868948
5	1	0
5	8	0.0247213867811797
5	5	
5	2	2.07705569993524e-05
5	9	0.00485946602016404
5	3	0.00128013881561478
5	7	0.000520728102318902
5	6	0.0347950037943975
2	4	6.82680380392834e-07
2	1	0
2	8	0.0294952632656165
2	5	2.07705569993524e-05
2	2	
2	9	0.000117896101696289
2	3	0.00155220564885453
2	7	0.00225351670674385
2	6	5.55088567303325e-05
9	4	0.00184444826160368
9	1	0.0327306395684998
9	8	0.101943351817516
9	5	0.00485946602016404
9	2	0.000117896101696289
9	9	
9	3	0.427927130852253
9	7	0.499713291013487
9	6	0.236575101514384
3	4	0.00036091465193732
3	1	0
3	8	0.000707050492934019
3	5	0.00128013881561478
3	2	0.00155220564885453
3	9	0.427927130852253
3	3	
3	7	0.616377312367755
3	6	0.468605706883731
7	4	0.000980807716280081
7	1	0
7	8	0.0194226637526994
7	5	0.000520728102318902
7	2	0.00225351670674385
7	9	0.499713291013487
7	3	0.616377312367755
7	7	
7	6	0.452350918788463
6	4	0.000190112577948008
6	1	0.00398020249199495
6	8	0
6	5	0.0347950037943975
6	2	5.55088567303325e-05
6	9	0.236575101514384
6	3	0.468605706883731
6	7	0.452350918788463
6	6	
4	the rte problem as presented in the pascal rte dataset is particularly attractive in that it is a reasonably simple task for human annotators with high inter-annotator agreement ), but an extremely challenging task for automated systems. 
1	 ) applied or utilized lexical based word overlap measures. 
8	we show comparable results from recent systems based on lexical similarity , graph alignment , weighted abduction , and a mixed system including theorem proving . 
5	for example, two high-accuracy systems are those described in , achieving 60.4% accuracy with no task-specific information, and , which achieves 61.2% task-dependent accuracy, i.e. 
2	attempts have been made to remedy this deficit through various techniques, including modelbuilding and the addition of semantic axioms . 
9	 represents a1 and a0 into a first-order logic translation of the drs language used in discourse representation theory and uses a theorem prover and a model builder with some generic, lexical and geographical background knowledge to prove the entailment between the two texts. 
3	many previous approaches have used a logical form representation of the text and hypothesis sentences, focusing on deriving a proof by which one can infer the hypothesis logical form from the text logical form . 
7	finally, a few efforts have tried to 42 translate sentences into formulas of first-order logic, in order to test logical entailment with a theorem prover. 
6	these transformations are logical rules in or sequences of allowed rewrite rules in . 
