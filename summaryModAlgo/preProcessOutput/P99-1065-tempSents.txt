17	in particular, we used the method of collins et al to simplify part-of-speech tags since the rich tags used by czech would have led to a large but rarely seen set of pos features. 
45	used for training and section 23 for testing . 
9	constituency parsing for dependency trees a pragmatic justification for using constituencybased parsers in order to predict dependency structures is that currently the best czech dependencytree parser is a constituency-based parser . 
51	furthermore, we can also see that the mst parsers perform favorably compared to the more powerful lexicalized phrase-structure parsers, such as those presented by collins et al and zeman that use expensive o parsing algorithms. 
36	see appendix a of collins for a description of how the head rules treat phrases involving coordination. 
42	although none of the previous results on labeling accuracy is strictly comparable to ours, it nevertheless seems fair to conclude that the 6this f-measure is based on the recall and precision figures reported in figure 7.15 in collins . 
3	so, collins et al proposed a tag classification for parsing the czech treebank. 
30	this is well illustrated by the collins parser , scrutinized by bikel , where several transformations are applied in order to improve the analysis of noun phrases, coordination and punctuation. 
50	a non-projective example from the czech prague dependency treebank is also shown in figure 2. most previous dependency parsing models have focused on projective trees, including the work of eisner , collins et al , yamada and matsumoto , nivre and scholz , and mcdonald et al . 
53	collins et al applied the parser of collins developed for english, to czech, and found thatthe performance wassubstantially lower when compared to the results for english. 
34	collins et al describe how the models in the current article were applied to parsing czech. 
16	the czech parser of collins et al was run on a different data set and most other dependency parsers are evaluated using english. 
21	czech results for the czech data, we used the predefined training, development and testing split of the prague dependency treebank , and the automatically generated pos tags supplied with the data, which we reduce to the pos tag set from collins et al . 
6	finally the placement of punctuation signs has a major impact on the performance of a parser . 
18	to create dependency structures from the penn treebank, we used the extraction rules of yamada and matsumoto , which are an approximation to the lexicalization rules of collins . 
49	coll1999: the projective lexicalized phrase-structure parser of collins et al . 
29	the part-of-speech tagging used is the hmm tagging distributed with the treebank, with a tagging accuracy of 94.1%, and with the tagset compressed to 61 tags as in collins et al . 
2	dependency fscore reached on the german negra treebank and collins et al 80.0% 
20	we compared our system to the bikel re-implementation of the collins parser trained with the same head rules of our system. 
22	although the best published results for the collins parser is 80% uas , this parser reaches 82% when trained on the entire training data set, and an adapted version of charniak's parser performs at 84% (jan hajiˇc, pers. 
38	for discussion of additional related work, chapter 4 of collins attempts to give a comprehensive review of work on statistical parsing up to around 1998. 
31	more specifically for pdt, collins et al relabel coordinated phrases after converting dependency structures to phrase structures, and zeman uses a kind of pattern matching, based on frequencies of the parts-of-speech of conjuncts and conjunctions. 
24	table 4: parsing accuracy for mcle and mbl models, attachment score per sentence if we compare the results concerning parsing accuracy to those obtained for other languages , we note that the best unlabeled attachment score is lower than for english, where the best results are above 90% , but higher than for czech . 
12	47 feature type id description form f the fully inflected word form as it appears in the data lemma l the morphologically reduced lemma mtag t a subset of the morphological tag as described in pos p major part-of-speech tag parsergov g true if candidate was proposed as governor by parser childcount c the number of children agreement a check for case/number agreement between word x and y table 2: description of the classes of features used in all models, we include features containing the form, the lemma, the morphological tag, and the parsergov feature. 
39	as a preprocessing step, the 14 in collins we erroneously stated that all words occuring less than five times in training data were classified as “unknown.” 
47	we should note that the results in collins et al are different then reported here due to different training and testing data sets. 
52	collins 's parser and its reimplementation and extension by bikel have by now been applied to a variety of languages: english , czech , german , spanish , french , chinese and, according to dan bikel's web page, arabic. 
26	more precisely, parsing accuracy is measured by the attachment score, which is a standard measure used in studies of dependency parsing . 
33	we find lexical heads in penn treebank data using the rules described in appendix a of collins . 
11	the trees are then transformed into penn treebank style constituencies using the technique described in . 
44	for the larger b set, our best parser achieves an f-measure of 96.9% , which can be compared with 97.0% for a similar set of labels in collins .6 
46	we are grateful to yamada and matsumoto for letting us use their rule set, which is a slight modification of the rules used by collins . 
32	dependency-based statistical language modeling and parsing have also become quite popular in statistical natural language processing . 
7	we examine two state-of-the-art constituency-based parsers in this work: the collins czech parser and a version of the charniak parser that was modified to parse czech. 
27	however, since most previous studies instead use the mean attachment score per word , we will give this measure as well. 
5	another strategy that is often used in statistical parsing is markovization : treebanks 1punctuation {$( $” $, $.} 
14	in an attempt to extend a constituency-based parsing model to train on dependency trees, collins transforms the pdt dependency trees into constituency trees . 
28	unlike most previous work on data-driven dependency parsing , we assume that dependency graphs are labeled with dependency types, although the evaluation will give results for both labeled and unlabeled representations. 
35	the appendices of collins give a precise description of the parsing algorithms, an analysis of their computational complexity, and also a description of the pruning methods that are employed. 
41	dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as czech , bulgarian , and turkish . 
40	see collins for a full description of the parsing algorithms. 
13	collins explicitly added features to his parser to improve punctuation dependency parsing accuracy. 
19	the best phrase-structure parsing models represent generatively the joint probability p of sentence x having the structure y . 
4	the usage of special knowledge bases to determine projections of categories would have presupposed language-dependent knowledge, so we investigated two other options: flat rules and binary rules. 
25	thus, the penn treebank of american english has been used to train and evaluate the best available parsers of unrestricted english text . 
1	collins used a lexicalized approach, schiehlen used the manually annotated phrasal categories of the treebank. 
37	we give a 1 much of this article is an edited version of chapters 7 and 8 of collins . 
8	although the results presented in used the reordering technique, we have experimented with his parser using the governor–raising technique and observe an increase in dependency accuracy. 
48	to reduce sparseness, our features rely only on the reduced pos tag set from collins et al . 
10	statistical parsing models have been shown to be successful in recovering labeled constituencies and have also been shown to be adequate in recovering dependency relationships . 
15	it is well known that dependency trees extracted from lexicalized phrase structure parsers typically are more accurate than those produced by pure dependency parsers . 
43	unlabeled attachment score : the proportion of words that are assigned the correct head . 
54	described in . 
23	it is also true of the adaptation of the collins parser for czech and the finite-state dependency parser for turkish by oflazer . 
