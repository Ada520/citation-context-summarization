let us imagine, for instance, that the best metric turns out to be a rouge (lin and hovy, 2003a) variant that only considers unigrams to compute similarity. 
for evaluation, we are using the rouge evaluation toolkit1, which is a method based on ngram statistics, found to be highly correlated with human evaluations (lin and hovy, 2003a). 
unigram co-occurrence metric in a recent study (lin and hovy, 2003a), we showed that the recall-based unigram cooccurrence automatic scoring metric correlates highly with human evaluation and has high recall and precision in predicting the statistical significance of results comparing with its human counterpart. 
these findings are additionally supported by the fact that automatic n-gram-based evaluation measures now being used to assess predominately extractive multi-document summarization systems correlate strongly with human judgments when restricted to the usage of unigrams and bigrams, but correlate weakly when longer n-grams are factored into the equation (lin & hovy, 2003). 
