<paper>
<cited id="ZD0">
<title id=" W07-1603.xml">preplex a lexicon of french prepositions for parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a priori, prepositions may seem to bea closed class, with elements which can be enumerated.
</prevsent>
<prevsent>in practice, however, comparison of the different available resources shows that it is not an easy task to exhaustively list prepositions.
</prevsent>
</prevsection>
<citsent citstr=" J93-1002 ">
besides, they represent more than 14% of french lemma tokens.1 1see for example, on newspaper corpus: complete lexicon for parsing applications should contain subcategorization information forpredicative words (briscoe and carroll, 1993; <papid> J93-1002 </papid>carroll and fang, 2004).</citsent>
<aftsection>
<nextsent>this subcategorization information often refers to prepositions in the description of their arguments.
</nextsent>
<nextsent>arguments are commonly used with particular preposition (for example comptersur [count on]) or set of semantically linked prepositions (such as aller [go] loc, where loc can be any locative preposition).
</nextsent>
<nextsent>for deep parsing, we need to distinguish between indirect complements, required by the verb, and adjuncts which do not appear in the verb valence.
</nextsent>
<nextsent>the following two examples (1a) and (1b) have the same surface structure, in which the two preposition uses for avec can only be distinguished semantically: in the first case, it introduces an oblique complement, whereas in the second case, it introduces an adjunct.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1">
<title id=" W07-1603.xml">preplex a lexicon of french prepositions for parsing </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>however, the syntactic part of the lexicon is still underdevelopment andit provides only few prepositions in verb subcategorization frames.
</prevsent>
<prevsent>besides, some prepositions inlefff are obsolete or rare.
</prevsent>
</prevsection>
<citsent citstr=" C00-2111 ">
the french-unl dictionary (serasset and boitet, 2000) <papid> C00-2111 </papid>also contains prepositions, but its coverage is quite limited and the quality of its entries is not homogeneous.</citsent>
<aftsection>
<nextsent>other sources present prepositions in verb subcategorization frames, but the lists are not quite consistent.
</nextsent>
<nextsent>we thus collected, as first step, prepositions from certain number of resources, lexicons and dictionaries for the garden-variety list, and syntactic lexicons for the argument prepositions list.
</nextsent>
<nextsent>two resources belong to both categories, lefff and french unl dictionary: ? lefff (lexique des formes flechies du francais/french inflected form lexicon (sagot et al, 2006)) is large coverage (more than 110,000 lemmas) french morphological and syntactic lexicon (see table 1 for an example of lefff syntactic entry).in its latest public version, 2.2.1, lefff contains 48 simple prepositions and 164 multiword prepositions.
</nextsent>
<nextsent>it also provides information on verb subcategorization frames, which contain 14 argument prepositions.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3">
<title id=" W07-1519.xml">itu treebank annotation tool </title>
<section> morphological disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>the second stage is the morphological disambiguation where the annotator is asked to choose one ofthe possible analyses for each word.
</prevsent>
<prevsent>the annotator may consult to an automatic analyzer by clicking the check box at the top of the screen in figure 2.
</prevsent>
</prevsection>
<citsent citstr=" N06-1042 ">
in this case we activate the part-of-speech tagger ofyuret and ture (2006) <papid> N06-1042 </papid>which uses some rules automatically derived from training corpus.</citsent>
<aftsection>
<nextsent>the results of this tagger is reflected to the screen by selecting automatically the appropriate radio button for eachword.
</nextsent>
<nextsent>after finishing the disambiguation, the annotator saves the results in xml format (shown at the bottom panel of figure 2) and proceeds trough the syntax analysis.
</nextsent>
<nextsent>the syntactic annotation scheme used in the turkish treebank is the dependency grammar representation.
</nextsent>
<nextsent>the aim of the dependency analysis is to find the binary relationships between dependent and head units.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4">
<title id=" W07-1519.xml">itu treebank annotation tool </title>
<section> syntax analysis.  </section>
<citcontext>
<prevsection>
<prevsent>the syntactic annotation scheme used in the turkish treebank is the dependency grammar representation.
</prevsent>
<prevsent>the aim of the dependency analysis is to find the binary relationships between dependent and head units.
</prevsent>
</prevsection>
<citsent citstr=" J03-4001 ">
the dependency structure of turkish has been mentioned in many studies (oflazer et al, 2003; oflazer, 2003; <papid> J03-4001 </papid>eryigit et al, 2006) and it is argued that for turkish, it is not just enough to determine the relationships between words and one should also determine the relationships between inflectional groups.</citsent>
<aftsection>
<nextsent>figure 3 gives an example of this structure2.
</nextsent>
<nextsent>in this screen, the annotator first selects dependent unit by selecting the check box under it and then head unit and the appropriate dependency relation from the combo box appearing under the constructed dependency.
</nextsent>
<nextsent>in this figure, we see that the adjective eski?
</nextsent>
<nextsent>(old) is connected to the first ig of the word odandaym? since it is the word oda?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD5">
<title id=" W07-1519.xml">itu treebank annotation tool </title>
<section> syntax analysis.  </section>
<citcontext>
<prevsection>
<prevsent>the dependents may only be connected to the igs of other words, thus the check boxes of the igs within the dependent word become passive when selecting head unit.
</prevsent>
<prevsent>similar to the morphological disambiguation stage, the annotator may want to consult to an automatic analyzer.
</prevsent>
</prevsection>
<citsent citstr=" W06-2933 ">
we use the data-driven dependency parser of nivre et al (2006) <papid> W06-2933 </papid>as an external parsing guide which is shown to give the highest accuracy for turkish and for many other languages.</citsent>
<aftsection>
<nextsent>the output of the parser (pre-trained on the turkish treebank) is reflected to the screen by automatically constructing the dependency tree.
</nextsent>
<nextsent>the annotator maythen change the dependencies which he/she finds in correct.
</nextsent>
<nextsent>itu treebank annotation tool is semi-automaticannotation tool tailored for the particular morphological structure of turkish where we need to annotate units smaller than words.
</nextsent>
<nextsent>it has three annotation levels and uses plug gable analyzers in order to automate these levels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD6">
<title id=" W07-0728.xml">rule based translation with statistical phrase based post editing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an implementation of this approach basedon the systran and portage mt systems was used in the shared task of the second workshop on statistical machine translation.
</prevsent>
<prevsent>experimental results on the test data of the previous campaign are presented.
</prevsent>
</prevsection>
<citsent citstr=" N07-1064 ">
simard et al (2007) <papid> N07-1064 </papid>have recently shown how statistical phrase-based machine translation system can be used as an automatic post-editing (ape) layer, on top of rule-based machine translation system.</citsent>
<aftsection>
<nextsent>the motivation for their work is the repetitive nature of the errors typically made by rule-based systems.
</nextsent>
<nextsent>given appropriate training material, statistical mtsystem can be trained to correct these systematic errors, therefore reducing the post-editing effort.
</nextsent>
<nextsent>the statistical system views the output of the rule-basedsystem as the source language, and reference human translations as the target language.
</nextsent>
<nextsent>because the training material for the ape layer will typically be domain-specific, this process can be viewed as way of automatically adapting rule-based system to specific application domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD7">
<title id=" W07-0728.xml">rule based translation with statistical phrase based post editing </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 rule-based translation.
</prevsent>
<prevsent>the initial source-to-target language translation is performed using the systran machine translation system, version 6.
</prevsent>
</prevsection>
<citsent citstr=" W07-0732 ">
a detailed overview of sys tran systems can be found in dugast et al (2007).<papid> W07-0732 </papid></citsent>
<aftsection>
<nextsent>for this shared task, we used the french-to-english and english-to-french configurations of the system.
</nextsent>
<nextsent>although it is possible to provide the system with specialized lexica, we did not relyon this feature, and used the system in its basic out-of-the-box?
</nextsent>
<nextsent>configuration.
</nextsent>
<nextsent>2.2 statistical phrase-based post-editing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD8">
<title id=" W07-0728.xml">rule based translation with statistical phrase based post editing </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the output of the rule-based mt system described above is fed into post-editing layer that performs domain-specific corrections and adaptation.
</prevsent>
<prevsent>this operation is conceptually not very different from target-to-target?
</prevsent>
</prevsection>
<citsent citstr=" W05-0822 ">
translation; for this task, we used the portage system, state-of-the-art statistical phrase-based machine translation system developed at the national research council of canada (nrc).1 general description of portage can be found in (sadat et al, 2005).<papid> W05-0822 </papid>for our participation in this shared task, we decided to configure and train the portage system for post-editing in manner as much as possible similar to the corresponding translation system, the details of which can be found in (ueffing et al, 2007).</citsent>
<aftsection>
<nextsent>the main features of this configuration are:?
</nextsent>
<nextsent>the use of two distinct phrase tables, containing phrase pairs extracted from the europarland the news commentary training corpora respectively.
</nextsent>
<nextsent>multiple phrase-probability feature function sin the log-linear models, including joint prob 1a version of portage is made available by the nrc to canadian universities for research and education purposes.
</nextsent>
<nextsent>ability estimate, standard frequency-based conditional probability estimate, and variants thereof based on different smoothing methods (foster et al, 2006).?<papid> W06-1607 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD9">
<title id=" W07-0728.xml">rule based translation with statistical phrase based post editing </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the use of two distinct phrase tables, containing phrase pairs extracted from the europarland the news commentary training corpora respectively.
</prevsent>
<prevsent>multiple phrase-probability feature function sin the log-linear models, including joint prob 1a version of portage is made available by the nrc to canadian universities for research and education purposes.
</prevsent>
</prevsection>
<citsent citstr=" W06-1607 ">
ability estimate, standard frequency-based conditional probability estimate, and variants thereof based on different smoothing methods (foster et al, 2006).?<papid> W06-1607 </papid></citsent>
<aftsection>
<nextsent>a 4-gram language model trained on the combined europarl and news commentary target language corpora.
</nextsent>
<nextsent>a 3-gram adapted language model: this is trained on mini-corpus of test-relevant target language sentences, extracted from the training material using standard information retrieval techniques.
</nextsent>
<nextsent>a 5-gram true casing model, trained on the combined europarl and news commentary target-language corpora.
</nextsent>
<nextsent>2.3 training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD11">
<title id=" W07-1005.xml">an unsupervised method for extracting domain specific affixes in biological literature </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for each element in an n-gram, the system extracts feature attributes asinput for creating the classification model.
</prevsent>
<prevsent>the extracted feature attributes include word feature pat terns(e.g., greek letters, upper case letters, digits and other symbols), part-of-speech (pos) tag information, prefix and suffix characters.
</prevsent>
</prevsection>
<citsent citstr=" W04-1221 ">
without using other specific domain resources, the system achieves comparable results to some other state-of-the-art systems (finkel et al, 2004; settles, 2004) <papid> W04-1221 </papid>which resort to external knowledge, such as protein dictio naries.</citsent>
<aftsection>
<nextsent>it has been demonstrated (jiampojamarn et al., 2005b) that the part-of-speech tag information is the most effective attribute in aiding the system to annotate biological terms because most biological terms are partial noun phrases.
</nextsent>
<nextsent>the abta system learns the affix feature by recording only the first and the last characters (e.g., = 3) of each word in classification instances, andthe authors claimed that the characters could provide enough affix information for the term annotation task.
</nextsent>
<nextsent>instead of using certain number of characters to provide affix information, however, it ismore likely that specific list of typically used prefixes and suffixes of biological words would provide more accurate information to classifying some biological terms and boundaries.
</nextsent>
<nextsent>we hypothesize that 33a more flexible affix definition will improve the performance of the taks of biological term annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD12">
<title id=" W07-1005.xml">an unsupervised method for extracting domain specific affixes in biological literature </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in fact, the morphological features in abta are learned by recording only the first and the last characters of each word in classification instances.
</prevsent>
<prevsent>this potentially leads to inaccurate affix information for the term annotation task.
</prevsent>
</prevsection>
<citsent citstr=" W03-1307 ">
(shen et al, 2003) <papid> W03-1307 </papid>explored an adaptation of agen eral hidden markov model-based term recognizer to biological domain.</citsent>
<aftsection>
<nextsent>they experimented with pos tags, prefix and suffix information and noun heads as features and reported an 0.661 f-score in overall term annotation on genia corpus.
</nextsent>
<nextsent>100 most frequent prefixes and suffixes are extracted as candidates, and evaluated based on difference in likelihood of part of biological term versus not.
</nextsent>
<nextsent>their method results in modest positive improvement in recognizing biological terms.
</nextsent>
<nextsent>two limitations of this method are: (1) use of only biological corpus, so 1http://www-tsujii.is.s.u-tokyo.ac.jp/genia/ 34 that the general domain-independent affixes are not removed, and (2) supervised process of choosing score threshold that is used in affix selection.(lee et al, 2003) <papid> W03-1305 </papid>used prefix and suffix features coupled with dictionary-based refinement of boundaries of the selected candidates in their experiments for term annotation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD13">
<title id=" W07-1005.xml">an unsupervised method for extracting domain specific affixes in biological literature </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>100 most frequent prefixes and suffixes are extracted as candidates, and evaluated based on difference in likelihood of part of biological term versus not.
</prevsent>
<prevsent>their method results in modest positive improvement in recognizing biological terms.
</prevsent>
</prevsection>
<citsent citstr=" W03-1305 ">
two limitations of this method are: (1) use of only biological corpus, so 1http://www-tsujii.is.s.u-tokyo.ac.jp/genia/ 34 that the general domain-independent affixes are not removed, and (2) supervised process of choosing score threshold that is used in affix selection.(lee et al, 2003) <papid> W03-1305 </papid>used prefix and suffix features coupled with dictionary-based refinement of boundaries of the selected candidates in their experiments for term annotation.</citsent>
<aftsection>
<nextsent>they extracted affix features in similar way with (shen et al, 2003).<papid> W03-1307 </papid></nextsent>
<nextsent>they also reported that affix features made positive effect on improving term annotation accuracy.in this project, we consider the quality of domain specific affix features extracted via an unsupervised method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD15">
<title id=" W07-2086.xml">umnd1 unsupervised word sense disambiguation using contextual semantic relatedness </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system disambiguates target word by usingwordnet-based measures of semantic relatedness to find the sense of the word that is semantically most strongly related to the senses of the words in the context of the target word.
</prevsent>
<prevsent>we briefly describe this system, the configuration options used for the task, and present some analysis of the results.
</prevsent>
</prevsection>
<citsent citstr=" P05-3019 ">
wordnet::senserelate::targetword1 (patwardhanet al, 2005; <papid> P05-3019 </papid>patwardhan et al, 2003) is an unsupervised word sense disambiguation (wsd) system, which is based on the hypothesis that the intended sense of an ambiguous word is related to the words in its context.</citsent>
<aftsection>
<nextsent>for example, if the financial institution?
</nextsent>
<nextsent>sense of bank is intended in context, then it is highly likely the context would contain related words such as money, transaction, interest rate, etc. the algorithm, therefore, determines the intended sense of word (target word) in given context by measuring the relatedness of each sense of that word with the words in its context.
</nextsent>
<nextsent>the sense of the target word that is most related to its context is selected as the intended sense of the target word.
</nextsent>
<nextsent>the system uses wordnet-based 1http://senserelate.sourceforge.net measures of semantic relatedness2 (pedersen et al., 2004) <papid> N04-3012 </papid>to measure the relatedness between the different senses of the target word and the words in its context.this system is completely unsupervised andre quires no annotated data for training.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD16">
<title id=" W07-2086.xml">umnd1 unsupervised word sense disambiguation using contextual semantic relatedness </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sense of bank is intended in context, then it is highly likely the context would contain related words such as money, transaction, interest rate, etc. the algorithm, therefore, determines the intended sense of word (target word) in given context by measuring the relatedness of each sense of that word with the words in its context.
</prevsent>
<prevsent>the sense of the target word that is most related to its context is selected as the intended sense of the target word.
</prevsent>
</prevsection>
<citsent citstr=" N04-3012 ">
the system uses wordnet-based 1http://senserelate.sourceforge.net measures of semantic relatedness2 (pedersen et al., 2004) <papid> N04-3012 </papid>to measure the relatedness between the different senses of the target word and the words in its context.this system is completely unsupervised andre quires no annotated data for training.</citsent>
<aftsection>
<nextsent>the lexical database wordnet (fellbaum, 1998) is the only resource that the system uses to measure the relatedness between words and concepts.
</nextsent>
<nextsent>thus, our system is classified under the closed track of the task.
</nextsent>
<nextsent>our wsd system consists of modular framework, which allows different algorithms for the different subtasks to be plugged into the system.
</nextsent>
<nextsent>we divide the disambiguation task into two primary subtasks: context selection and sense selection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD18">
<title id=" W07-2086.xml">umnd1 unsupervised word sense disambiguation using contextual semantic relatedness </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>, w2n senses, respectively.
</prevsent>
<prevsent>then for each ti score is computed as score(ti) = 2n ? j=1 max k=1 to wj (relatedness(ti, wjk)) where wjk is the kth sense of word wj . the sense ti of target word with the highest score is selected as the intended sense of the target word.the relatedness between two word senses is computed using measure of semantic relatedness defined in the wordnet::similarity software package(pedersen et al, 2004), <papid> N04-3012 </papid>which is suite of perl modules implementing number wordnet-based measures of semantic relatedness.</prevsent>
</prevsection>
<citsent citstr=" W06-2501 ">
for this work, we used the context vector measure (patwardhan and pedersen, 2006).<papid> W06-2501 </papid></citsent>
<aftsection>
<nextsent>the relatedness of concepts is computed based on word co-occurrence statistics derived from wordnet glosses.
</nextsent>
<nextsent>given two wordnet senses, this module returns score between 0 and 1, indicating the relatedness of the two senses.our system relies on wordnet as its sense inventory.
</nextsent>
<nextsent>however, this task used ontonotes (hovy et al., 2006) as the sense inventory.
</nextsent>
<nextsent>ontonotes word senses are groupings of similar wordnet senses.thus, we used the training data answer key to generate mapping between the ontonotes senses of the given lexical elements and their corresponding wordnet senses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD20">
<title id=" W08-0215.xml">psycho computational linguistics a gateway to the computational linguistics curriculum </title>
<section> the course: computational natural.  </section>
<citcontext>
<prevsection>
<prevsent>syntax [1 lecture] this is crash course in syntax using context-free grammar with transformational movement.
</prevsent>
<prevsent>the more difficult topics include topical ization (including null-topic), wh-movement and verb-second phenomena.
</prevsent>
</prevsection>
<citsent citstr=" P03-1053 ">
we make effective use of an in-house database of abstract though linguistically viable cross linguistic sentence patterns and tree structures ? the cuny colag domain (sakas, 2003).<papid> P03-1053 </papid></citsent>
<aftsection>
<nextsent>the point of this lecture is to introduce non-linguistics students to the intricacies of linguistically viable grammatical theory.
</nextsent>
<nextsent>language acquisition [1 lecture] we discuss some of the current debates in l1 (a childs first) language acquisition surrounding no negative evidence?
</nextsent>
<nextsent>(marcus, 1993), poverty of the stimulus (pullum, 1996), and chomskys conceptualization of universal grammar.
</nextsent>
<nextsent>this is the least computational lecture of the semester, although it often generates some of the most energized discussion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD21">
<title id=" W08-0328.xml">using moses to integrate multiple rule based machine translation engines into a hybrid system </title>
<section> introduction </section>
<citcontext>
<prevsection>

<prevsent>based on an architecture that allows to combine statistical machine translation (smt) with rule-based machine translation (rbmt) in multi-engine setup, we present new results that show that this type of system combination can actually increase the lexical coverage of the resulting hybrid system, at least as far as this can be measured via bleu score.
</prevsent>
</prevsection>
<citsent citstr=" W07-0726 ">
(chen et al, 2007) <papid> W07-0726 </papid>describes an architecture that allows to combine statistical machine translation (smt) with one or multiple rule-based machine translation (rbmt) systems in multi-engine setup.</citsent>
<aftsection>
<nextsent>it uses variant of standard smt technology to align translations from one or more rbmt systems with the source text and incorporated phrases extracted from these alignments into the phrase table of the smt system.
</nextsent>
<nextsent>using this approach it is possible to employ vanilla installation of the open-source decoder moses1 (koehn et al, 2007) <papid> P07-2045 </papid>to find good combinations of phrases from smt training data with the phrases derived from rbmt.</nextsent>
<nextsent>a similar method was presented in (rosti et al, 2007).<papid> N07-1029 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD22">
<title id=" W08-0328.xml">using moses to integrate multiple rule based machine translation engines into a hybrid system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(chen et al, 2007) <papid> W07-0726 </papid>describes an architecture that allows to combine statistical machine translation (smt) with one or multiple rule-based machine translation (rbmt) systems in multi-engine setup.</prevsent>
<prevsent>it uses variant of standard smt technology to align translations from one or more rbmt systems with the source text and incorporated phrases extracted from these alignments into the phrase table of the smt system.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
using this approach it is possible to employ vanilla installation of the open-source decoder moses1 (koehn et al, 2007) <papid> P07-2045 </papid>to find good combinations of phrases from smt training data with the phrases derived from rbmt.</citsent>
<aftsection>
<nextsent>a similar method was presented in (rosti et al, 2007).<papid> N07-1029 </papid></nextsent>
<nextsent>this setup provides an elegant solution to the fairly complex task of integrating multiple mt results that may differ in word order using only standard software modules, in particular giza++ (och and ney, 2003) <papid> J03-1002 </papid>for the identification of building blocks and moses for the recombination, but the authors were not able to observe improvements in 1see http://www.statmt.org/moses/terms of bleu score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD23">
<title id=" W08-0328.xml">using moses to integrate multiple rule based machine translation engines into a hybrid system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it uses variant of standard smt technology to align translations from one or more rbmt systems with the source text and incorporated phrases extracted from these alignments into the phrase table of the smt system.
</prevsent>
<prevsent>using this approach it is possible to employ vanilla installation of the open-source decoder moses1 (koehn et al, 2007) <papid> P07-2045 </papid>to find good combinations of phrases from smt training data with the phrases derived from rbmt.</prevsent>
</prevsection>
<citsent citstr=" N07-1029 ">
a similar method was presented in (rosti et al, 2007).<papid> N07-1029 </papid></citsent>
<aftsection>
<nextsent>this setup provides an elegant solution to the fairly complex task of integrating multiple mt results that may differ in word order using only standard software modules, in particular giza++ (och and ney, 2003) <papid> J03-1002 </papid>for the identification of building blocks and moses for the recombination, but the authors were not able to observe improvements in 1see http://www.statmt.org/moses/terms of bleu score.</nextsent>
<nextsent>a closer investigation revealed that the experiments had suffered from couple of technical difficulties, such as mismatches in character encodings generated by different mt engines and similar problems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD24">
<title id=" W08-0328.xml">using moses to integrate multiple rule based machine translation engines into a hybrid system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using this approach it is possible to employ vanilla installation of the open-source decoder moses1 (koehn et al, 2007) <papid> P07-2045 </papid>to find good combinations of phrases from smt training data with the phrases derived from rbmt.</prevsent>
<prevsent>a similar method was presented in (rosti et al, 2007).<papid> N07-1029 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
this setup provides an elegant solution to the fairly complex task of integrating multiple mt results that may differ in word order using only standard software modules, in particular giza++ (och and ney, 2003) <papid> J03-1002 </papid>for the identification of building blocks and moses for the recombination, but the authors were not able to observe improvements in 1see http://www.statmt.org/moses/terms of bleu score.</citsent>
<aftsection>
<nextsent>a closer investigation revealed that the experiments had suffered from couple of technical difficulties, such as mismatches in character encodings generated by different mt engines and similar problems.
</nextsent>
<nextsent>this motivated us tore-do these experiments in somewhat more systematic way for this years shared translation task,paying the required attention to all the technical details and also to try it out on more language pairs.
</nextsent>
<nextsent>for conducting the translations, we use multiengine mt approach based on vanilla?
</nextsent>
<nextsent>moses smt system with modified phrase table as central element.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD25">
<title id=" W08-0328.xml">using moses to integrate multiple rule based machine translation engines into a hybrid system </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>all these columns are given the same default weight initially and thus still need be to be tuned to more meaningful values.
</prevsent>
<prevsent>from this years europarl development data the first 200 sentences of each of the datasets dev2006, test2006, test2007 and devtest2006 were concatenated to build our development set.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
this set of 800 sentences was used for minimum error rate training (och, 2003) <papid> P03-1021 </papid>to tune the weights of our system with respect to bleu score.</citsent>
<aftsection>
<nextsent>in order to be able to evaluate our hybrid approaches in contrast to stand-alone rule-based approaches, we also calculated bleu scores for the translations conducted by the rbmt systems used in the hybrid setup.
</nextsent>
<nextsent>our hybrid system is compared to smt baseline and all the 6 rbmt systems that we used.
</nextsent>
<nextsent>table 1 shows the evaluation of all the systems in terms of bleu score (papineni et al, 2002) <papid> P02-1040 </papid>with the best score highlighted.</nextsent>
<nextsent>the empty cells in the table indicate the language pairs which are not available in the corresponding systems2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD26">
<title id=" W08-0328.xml">using moses to integrate multiple rule based machine translation engines into a hybrid system </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>in order to be able to evaluate our hybrid approaches in contrast to stand-alone rule-based approaches, we also calculated bleu scores for the translations conducted by the rbmt systems used in the hybrid setup.
</prevsent>
<prevsent>our hybrid system is compared to smt baseline and all the 6 rbmt systems that we used.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
table 1 shows the evaluation of all the systems in terms of bleu score (papineni et al, 2002) <papid> P02-1040 </papid>with the best score highlighted.</citsent>
<aftsection>
<nextsent>the empty cells in the table indicate the language pairs which are not available in the corresponding systems2.
</nextsent>
<nextsent>the smt system isthe one upon which we build the hybrid system.
</nextsent>
<nextsent>according to the scores, the hybrid system produces better results than the baseline smt system in all 2the identities of respective rbmt systems are not revealed in this paper.
</nextsent>
<nextsent>rbmt1 is evaluated on the partial results produced due to some technical problems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD27">
<title id=" W08-0328.xml">using moses to integrate multiple rule based machine translation engines into a hybrid system </title>
<section> outlook.  </section>
<citcontext>
<prevsection>
<prevsent>figure 2: german-english translation examples the same phrase pair (with different weight) in the combined phrase table causes the decoder to generate many instances of identical results in different ways, which increases computational effort and significantly decreases the number of distinct cases that are considered during mert.
</prevsent>
<prevsent>we suspect that modification of our scheme that avoids this problem will be able to achieve better results, but experiments in this direction are still ongoing.
</prevsent>
</prevsection>
<citsent citstr=" W07-0728 ">
the approach presented here combines the strengths of multiple systems and is different from recent work on post-correction of rbmt output as presented in (simard et al, 2007; <papid> W07-0728 </papid>dugast et al,2007), <papid> W07-0732 </papid>which focuses on the improvement of single rbmt system by correcting typical errors via smt techniques.</citsent>
<aftsection>
<nextsent>these ideas are independent and suitable combination of them could give rise to even better results.
</nextsent>
<nextsent>acknowledgments this work was supported by the euro matrix project funded by the european commission (6th framework programme).
</nextsent>
<nextsent>we thank martin kay, hans uszkoreit, and silke theison for interesting discussions and practical help, and two anonymous reviewers for hints to improve the paper.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD28">
<title id=" W08-0328.xml">using moses to integrate multiple rule based machine translation engines into a hybrid system </title>
<section> outlook.  </section>
<citcontext>
<prevsection>
<prevsent>figure 2: german-english translation examples the same phrase pair (with different weight) in the combined phrase table causes the decoder to generate many instances of identical results in different ways, which increases computational effort and significantly decreases the number of distinct cases that are considered during mert.
</prevsent>
<prevsent>we suspect that modification of our scheme that avoids this problem will be able to achieve better results, but experiments in this direction are still ongoing.
</prevsent>
</prevsection>
<citsent citstr=" W07-0732 ">
the approach presented here combines the strengths of multiple systems and is different from recent work on post-correction of rbmt output as presented in (simard et al, 2007; <papid> W07-0728 </papid>dugast et al,2007), <papid> W07-0732 </papid>which focuses on the improvement of single rbmt system by correcting typical errors via smt techniques.</citsent>
<aftsection>
<nextsent>these ideas are independent and suitable combination of them could give rise to even better results.
</nextsent>
<nextsent>acknowledgments this work was supported by the euro matrix project funded by the european commission (6th framework programme).
</nextsent>
<nextsent>we thank martin kay, hans uszkoreit, and silke theison for interesting discussions and practical help, and two anonymous reviewers for hints to improve the paper.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD29">
<title id=" W08-0508.xml">fast scalable and reliable generation of controlled natural language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the framework takes as input semantic graph representing set of assertions in description logic (dl) (baader et al, 2003) and transforms itinto tree which encodes the grammar rules, syntactic subcategorisations, orderings and lexical anchors required to construct textual representation of the input data.
</prevsent>
<prevsent>the resulting text is conceptually aligned, by which we mean that each component of the text structure (such as words, clauses or sentences, for example) is linked back to the mediating structure from which the text was generated, and from there back to vertices and edges in the semantic graph received as input.
</prevsent>
</prevsection>
<citsent citstr=" P98-2173 ">
the target context for the framework is the construction of semantic web (berners-lee et al, 2001) resources using natural language generation (nlg) technology which extends the notion of semantic alignment developed in the wysiwym system (power and scott, 1998; <papid> P98-2173 </papid>power et al, 2003).<papid> J03-2003 </papid></citsent>
<aftsection>
<nextsent>in this context the text is ephemeral and is generated on demand, while the document content is fully machine-readable, supporting tasks such as automated consistency checking, inferencing and semantic search/query.
</nextsent>
<nextsent>since the text is fully linked to the underlying semantic representation it supports rich user interface encompassing fast and reliable semantic search, inline syntax or anaphora highlighting, knowledge editing, and so on.
</nextsent>
<nextsent>finally, the text could be generated inmany different natural languages making the information content more widely available.
</nextsent>
<nextsent>we envisage the technology supporting range of different use cases such as information feeds, technical instructions, medical orders or short, factual reports.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD30">
<title id=" W08-0508.xml">fast scalable and reliable generation of controlled natural language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the framework takes as input semantic graph representing set of assertions in description logic (dl) (baader et al, 2003) and transforms itinto tree which encodes the grammar rules, syntactic subcategorisations, orderings and lexical anchors required to construct textual representation of the input data.
</prevsent>
<prevsent>the resulting text is conceptually aligned, by which we mean that each component of the text structure (such as words, clauses or sentences, for example) is linked back to the mediating structure from which the text was generated, and from there back to vertices and edges in the semantic graph received as input.
</prevsent>
</prevsection>
<citsent citstr=" J03-2003 ">
the target context for the framework is the construction of semantic web (berners-lee et al, 2001) resources using natural language generation (nlg) technology which extends the notion of semantic alignment developed in the wysiwym system (power and scott, 1998; <papid> P98-2173 </papid>power et al, 2003).<papid> J03-2003 </papid></citsent>
<aftsection>
<nextsent>in this context the text is ephemeral and is generated on demand, while the document content is fully machine-readable, supporting tasks such as automated consistency checking, inferencing and semantic search/query.
</nextsent>
<nextsent>since the text is fully linked to the underlying semantic representation it supports rich user interface encompassing fast and reliable semantic search, inline syntax or anaphora highlighting, knowledge editing, and so on.
</nextsent>
<nextsent>finally, the text could be generated inmany different natural languages making the information content more widely available.
</nextsent>
<nextsent>we envisage the technology supporting range of different use cases such as information feeds, technical instructions, medical orders or short, factual reports.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD31">
<title id=" W08-0508.xml">fast scalable and reliable generation of controlled natural language </title>
<section> speed and scala bility.  </section>
<citcontext>
<prevsection>
<prevsent>because the atree is ordered and is constructed in order, the system always knows whether an instance is being mentioned for the first time.
</prevsent>
<prevsent>we currently render subsequent mentions by pruning all of the out-going arcs from the abox node, which also allows us to manage cycles in the semantic graph.
</prevsent>
</prevsection>
<citsent citstr=" P89-1009 ">
since the system knows which nodes in the semantic graph have already been mentioned it would also be possible to configure an external call to gre system (dale, 1989) - <papid> P89-1009 </papid>an application which infers the content of referring expression given the current semantic context.</citsent>
<aftsection>
<nextsent>mapping such as the one depicted in figure 4 below.
</nextsent>
<nextsent> frame concept=938b?
</nextsent>
<nextsent>role=any?
</nextsent>
<nextsent>subcat=catclause-33?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD32">
<title id=" W08-0508.xml">fast scalable and reliable generation of controlled natural language </title>
<section> testing and results.  </section>
<citcontext>
<prevsection>
<prevsent>we used this application to verify the independence of the framework, domain and linguistic resources and verified that we could develop linguistic resources offline and plug them into the application effectively.
</prevsent>
<prevsent>the application also served as test harness to test the adaptibil ity of the framework to render the same semantic context in different syntactic structures depending on the target natural language.
</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
for example, we included the examination of body part belonging to person in the domain, and this was expressed through saxon genitive in english but prepositional phrase (with the subsidiary nps in the reverse order) in the other languages.to test our assumptions about efficiency and scal ability we inferred larger tbox, subcategorisation frames and mappings using pre-existing data setof verb frames for english encoded using the com lex subcategorisation frame inventory (grishmanet al, 1994).<papid> C94-1042 </papid></citsent>
<aftsection>
<nextsent>the linguistic resources for the application comprised generative tag grammar basedon x-tag (doran et al, 1994) <papid> C94-2149 </papid>which we wrote our 46selves, the cuv+ lexicon3, and pre-existing morphological generator for english (hardcastle, 2007).</nextsent>
<nextsent>to test the performance of the generation process we used set of randomly-generated aboxes derived from the tbox to produce texts of increasing size.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD33">
<title id=" W08-0508.xml">fast scalable and reliable generation of controlled natural language </title>
<section> testing and results.  </section>
<citcontext>
<prevsection>
<prevsent>the application also served as test harness to test the adaptibil ity of the framework to render the same semantic context in different syntactic structures depending on the target natural language.
</prevsent>
<prevsent>for example, we included the examination of body part belonging to person in the domain, and this was expressed through saxon genitive in english but prepositional phrase (with the subsidiary nps in the reverse order) in the other languages.to test our assumptions about efficiency and scal ability we inferred larger tbox, subcategorisation frames and mappings using pre-existing data setof verb frames for english encoded using the com lex subcategorisation frame inventory (grishmanet al, 1994).<papid> C94-1042 </papid></prevsent>
</prevsection>
<citsent citstr=" C94-2149 ">
the linguistic resources for the application comprised generative tag grammar basedon x-tag (doran et al, 1994) <papid> C94-2149 </papid>which we wrote our 46selves, the cuv+ lexicon3, and pre-existing morphological generator for english (hardcastle, 2007).</citsent>
<aftsection>
<nextsent>to test the performance of the generation process we used set of randomly-generated aboxes derived from the tbox to produce texts of increasing size.
</nextsent>
<nextsent>for the purposes of testing we defined the size of an abox as the total number of nodes and edges in the graph, which is the number of rdf triples required to represent it.
</nextsent>
<nextsent>table 1 shows the size of the out put text in sentences, the time taken to generate it in milliseconds, averaged over 5 runs, and the ratio of the time taken to the size of the output which shows linear scaling4.
</nextsent>
<nextsent>size timing timing/size 31 2 0.065 280 10 0.036 2,800 59 0.021 28,000 479 0.017 table 1: the time, in milliseconds, taken to generate aboxes of increasing size and the ratio of time taken to the size of the output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD34">
<title id=" W07-2001.xml">semeval2007 task 01 evaluating wsd on cross language information retrieval </title>
<section> evaluation and results.  </section>
<citcontext>
<prevsection>
<prevsent>the disambiguation process took aprox.
</prevsent>
<prevsent>12 hours on cluster of 48 machines (dual xeons with 4gb of ram).
</prevsent>
</prevsection>
<citsent citstr=" P00-1064 ">
note that contrary to the specifications, this team returned wordnet 2.1 senses, so we had to map automatically to 1.6 senses (daude et al, 2000).<papid> P00-1064 </papid></citsent>
<aftsection>
<nextsent>uniba this team uses a knowledge-based wsd system that attempts to disambiguate all words in text by exploiting wordnet relations.
</nextsent>
<nextsent>the main assumption is that specific strategy foreach part-of-speech (pos) is better than single strategy.
</nextsent>
<nextsent>nouns are disambiguated basically using hypernymy links.
</nextsent>
<nextsent>verbs are dis ambiguated according to the nouns surrounding them, and adjectives and adverbs use glosses.organizers in addition to the regular participants, and out of the competition, the organizers run regular supervised wsd system trained on semcor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD36">
<title id=" W07-0719.xml">context aware discriminative phrase selection for statistical machine translation </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in this work we revise the application of discriminative learning to the problem of phrase selection in statistical machinetranslation.
</prevsent>
<prevsent>inspired by common techniques used in word sense disambiguation, we train classifiers based on local context to predict possible phrase translations.
</prevsent>
</prevsection>
<citsent citstr=" H05-1097 ">
our work extends that of vickrey et al  (2005) <papid> H05-1097 </papid>in two main aspects.</citsent>
<aftsection>
<nextsent>first, we move from word translation to phrase translation.
</nextsent>
<nextsent>second, we move from the blank-filling?
</nextsent>
<nextsent>task to the full translation?
</nextsent>
<nextsent>task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD39">
<title id=" W07-0719.xml">context aware discriminative phrase selection for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>task.
</prevsent>
<prevsent>we report results on set of highly frequent source phrases, obtain inga significant improvement, specially with respect to adequacy, according to rigorous process of manual evaluation.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
translations tables in phrase-based statistical machine translation (smt) are often built on the basis of maximum-likelihood estimation (mle), being one of the major limitations of this approach that the source sentence context in which phrases occur is completely ignored (koehn et al , 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>in this work, inspired by state-of-the-art word sense disambiguation (wsd) techniques, we suggest using discriminative phrase translation (dpt) models which take into account wider feature context.
</nextsent>
<nextsent>following the approach by vickrey et al (2005), <papid> H05-1097 </papid>we deal with the phrase translation?</nextsent>
<nextsent>problem as classification problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD47">
<title id=" W07-0719.xml">context aware discriminative phrase selection for statistical machine translation </title>
<section> discriminative phrase translation.  </section>
<citcontext>
<prevsection>
<prevsent>we build trigram language models applying linear interpolation and kneser-ney discounting for smoothing.
</prevsent>
<prevsent>translation models are built on top of word-aligned parallel corpora linguistically annotated at the level of shallow syntax (i.e., lemma, part-of-speech, and base phrase chunks) as described by gimenez and ma`rquez (2005).text is automatically annotated, using the svmtool (gimenez and ma`rquez, 2004), free ling (car reras et al , 2004), and phreco (carreras et al , 2005) packages.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we used the giza++ smt toolkit1 (och and ney, 2003) <papid> J03-1002 </papid>to generate word alignments.</citsent>
<aftsection>
<nextsent>we apply the phrase-extract algorithm, as described by och (2002), on the viterbi alignments output by giza++ following the global phrase extraction?
</nextsent>
<nextsent>strategy described by gimenez and ma`rquez (2005) (i.e., single phrase translation table is built on topof the union of alignments corresponding to different linguistic data views).
</nextsent>
<nextsent>we work with the union of source-to-target and target-to-source alignments, with no heuristic refinement.
</nextsent>
<nextsent>phrases up to length five are considered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD51">
<title id=" W07-0719.xml">context aware discriminative phrase selection for statistical machine translation </title>
<section> full translation.  </section>
<citcontext>
<prevsection>
<prevsent>in second place, most conventional automatic evaluation metrics have not been designed for thispurpose.
</prevsent>
<prevsent>for instance, metrics such as bleu (pa pineni et al , 2001) tend to favour longer n-grammatchings, and are, thus, biased towards word ordering.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
we might find better suited metrics, such as meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>which is oriented towards word selection8.</citsent>
<aftsection>
<nextsent>however, new problem arises.
</nextsent>
<nextsent>because different metrics are biased towards different aspects of quality, scores conferred by different metrics are often controversial.
</nextsent>
<nextsent>in order to cope with evaluation difficulties we have applied several complementary actions: 1.
</nextsent>
<nextsent>based on the results from section 3, we focus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD52">
<title id=" W07-0719.xml">context aware discriminative phrase selection for statistical machine translation </title>
<section> full translation.  </section>
<citcontext>
<prevsection>
<prevsent>results on the test set.
</prevsent>
<prevsent>iqmt.
</prevsent>
</prevsection>
<citsent citstr=" P04-1077 ">
the optimal set is: { meteorwnsyn, rougew 1.2 } which includes variants of meteor, and rouge (lin and och, 2004).<papid> P04-1077 </papid></citsent>
<aftsection>
<nextsent>4.2 adjustment of parameters.
</nextsent>
<nextsent>models are combined in log-linear fashion: logp (e|f) ? lmlogp (e) + glogpmle(f |e) + dlogpmle(e|f) + dpt logpdpt (e|f) (e) is the language model probability.
</nextsent>
<nextsent>pmle(f |e) corresponds to the mle-based generative translation model, whereas pmle(e|f) corresponds to the analogous discriminative model.
</nextsent>
<nextsent>pdpt (e|f) corresponds to the dpt model which uses svm-based predictions in wider feature context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD53">
<title id=" W07-0719.xml">context aware discriminative phrase selection for statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the cause underlying these problems is that dpt predictions are available only for subset of phrases.
</prevsent>
<prevsent>thus, during decoding, for these cases our dpt models may be in disadvantage.
</prevsent>
</prevsection>
<citsent citstr=" P05-1048 ">
recently, there is growing interest in the application of wsd technology to mt. for instance, carpuat and wu (2005<papid> P05-1048 </papid>b) suggested integrating wsd predictions into smt system in hard?</citsent>
<aftsection>
<nextsent>manner, either for decoding, by constraining the set of acceptable translation candidates for each given source word, or for post-processing the smt system output, by directly replacing the translation ofeach selected word with the wsd system prediction.
</nextsent>
<nextsent>they did not manage to improve mt quality.
</nextsent>
<nextsent>they encountered several problems inherent to the smt architecture.
</nextsent>
<nextsent>in particular, they described what they called the language model effect?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD64">
<title id=" W07-0719.xml">context aware discriminative phrase selection for statistical machine translation </title>
<section> conclusions and further work.  </section>
<citcontext>
<prevsection>
<prevsent>the crucial issue,in our opinion, is that the metric guiding the optimization is able to capture the changes.
</prevsent>
<prevsent>finally, we argue that, if dpt models considered features from the target side, and from the correspondence between source and target, results could further improve.
</prevsent>
</prevsection>
<citsent citstr=" P06-1091 ">
however, at the short term, the incorporation of these type of features will force us to either build new decoder or extend an existing one, or to move to new mt architecture, for instance,in the fashion of the architectures suggested by tillmann and zhang (2006) <papid> P06-1091 </papid>or liang et al  (2006).<papid> P06-1096 </papid></citsent>
<aftsection>
<nextsent>acknowledgements this research has been funded by the spanish ministry of education and science, projectsopenmt (tin2006-15307-c03-02) and tran 165gram (tin2004-07925-c03-02).
</nextsent>
<nextsent>we are recognized as quality research group (2005 sgr 00130) by dursi, the research department of the catalan government.
</nextsent>
<nextsent>authors are thankful to thetc-star consortium for providing such very valuable datasets.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD65">
<title id=" W07-0719.xml">context aware discriminative phrase selection for statistical machine translation </title>
<section> conclusions and further work.  </section>
<citcontext>
<prevsection>
<prevsent>the crucial issue,in our opinion, is that the metric guiding the optimization is able to capture the changes.
</prevsent>
<prevsent>finally, we argue that, if dpt models considered features from the target side, and from the correspondence between source and target, results could further improve.
</prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
however, at the short term, the incorporation of these type of features will force us to either build new decoder or extend an existing one, or to move to new mt architecture, for instance,in the fashion of the architectures suggested by tillmann and zhang (2006) <papid> P06-1091 </papid>or liang et al  (2006).<papid> P06-1096 </papid></citsent>
<aftsection>
<nextsent>acknowledgements this research has been funded by the spanish ministry of education and science, projectsopenmt (tin2006-15307-c03-02) and tran 165gram (tin2004-07925-c03-02).
</nextsent>
<nextsent>we are recognized as quality research group (2005 sgr 00130) by dursi, the research department of the catalan government.
</nextsent>
<nextsent>authors are thankful to thetc-star consortium for providing such very valuable datasets.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD66">
<title id=" W07-0721.xml">analysis of statistical and morphological classes to generate weigthed reordering hypotheses on a statistical machine translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>satisfactory results are reported in the wmt07 es/en task.
</prevsent>
<prevsent>our system outperforms in terms of bleu the wmt07 official baseline system.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
nowadays, statistical machine translation is mainly basedon phrases (koehn et al , 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>in parallel to this phrase based approach, the use of bilingual n-grams gives comparable results, as shown by crego et al  (2005).
</nextsent>
<nextsent>two basic issues differentiate the n-gram-based system fromthe phrase-based: training data is monotonic ally segmented into bilingual units; and, the model considers gram probabilities rather than relative frequencies.
</nextsent>
<nextsent>then-gram-based system follows maximum entropy approach, in which log-linear combination of multiple models is implemented (marino et al , 2006), as an alternative to the source-channel approach.
</nextsent>
<nextsent>introducing reordering capabilities is important in both systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD67">
<title id=" W07-0721.xml">analysis of statistical and morphological classes to generate weigthed reordering hypotheses on a statistical machine translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then-gram-based system follows maximum entropy approach, in which log-linear combination of multiple models is implemented (marino et al , 2006), as an alternative to the source-channel approach.
</prevsent>
<prevsent>introducing reordering capabilities is important in both systems.
</prevsent>
</prevsection>
<citsent citstr=" W05-0831 ">
recently, new reordering strategies have been proposed such as the reordering of each source sentence to match the word order in the corresponding target sentence, see kanthak et al  (2005) <papid> W05-0831 </papid>and marino et al  (2006).</citsent>
<aftsection>
<nextsent>these approaches are applied in the training set and they lack of reordering generalization.
</nextsent>
<nextsent>applied both in the training and decoding step, coll inset al  (2005) <papid> P05-1066 </papid>describe method for introducing syntactic information for reordering in smt.</nextsent>
<nextsent>this approach is applied as pre-processing step.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD68">
<title id=" W07-0721.xml">analysis of statistical and morphological classes to generate weigthed reordering hypotheses on a statistical machine translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, new reordering strategies have been proposed such as the reordering of each source sentence to match the word order in the corresponding target sentence, see kanthak et al  (2005) <papid> W05-0831 </papid>and marino et al  (2006).</prevsent>
<prevsent>these approaches are applied in the training set and they lack of reordering generalization.</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
applied both in the training and decoding step, coll inset al  (2005) <papid> P05-1066 </papid>describe method for introducing syntactic information for reordering in smt.</citsent>
<aftsection>
<nextsent>this approach is applied as pre-processing step.
</nextsent>
<nextsent>differently, crego et al  (2006) presents reordering approach based on reordering patterns which is coupled with decoding.
</nextsent>
<nextsent>the reordering patterns are learned directly from word alignment and all reorderings have the same probability.
</nextsent>
<nextsent>in our previous work (costa-jussa` and fonollosa, 2006) we presented the smr approach which is basedon using the powerful smt techniques to generate reordered source input for an smt system both in training and decoding steps.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD69">
<title id=" W07-0721.xml">analysis of statistical and morphological classes to generate weigthed reordering hypotheses on a statistical machine translation system </title>
<section> ngram-based smt system.  </section>
<citcontext>
<prevsection>
<prevsent>this feature consists of 4-gram model of words, which is trained from the target side of the bilingual corpus.?
</prevsent>
<prevsent>a class target language model.
</prevsent>
</prevsection>
<citsent citstr=" E99-1010 ">
this feature consists of 5-gram model of words classes, which is trained from the target side of the bilingual corpus using the statistical classes from (och, 1999).<papid> E99-1010 </papid></citsent>
<aftsection>
<nextsent>a word bonus function.
</nextsent>
<nextsent>this feature introducesa bonus based on the number of target words contained in the partial-translation hypothesis.
</nextsent>
<nextsent>it is used to compensate for the systems preference for short output sentences.
</nextsent>
<nextsent>a source-to-target lexicon model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD70">
<title id=" W07-0721.xml">analysis of statistical and morphological classes to generate weigthed reordering hypotheses on a statistical machine translation system </title>
<section> ngram-based smt system.  </section>
<citcontext>
<prevsection>
<prevsent>it is used to compensate for the systems preference for short output sentences.
</prevsent>
<prevsent>a source-to-target lexicon model.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
this feature, which is based on the lexical parameters of the ibm model 1 (brown et al , 1993), <papid> J93-2003 </papid>provides complementary probability for each tuple in the translation table.</citsent>
<aftsection>
<nextsent>these lexicon parameters are obtained from the source-to-target al gnments.
</nextsent>
<nextsent>a target-to-source lexicon model.
</nextsent>
<nextsent>similarly to the previous feature, this feature is based on the lexical parameters of the ibm model 1 but, in this case, these parameters are obtained from target-to-source alignments.
</nextsent>
<nextsent>figure 1: smr block diagram.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD72">
<title id=" W07-1909.xml">design and validation of eca gestures to improve dialogue system robustness </title>
<section> suggesting eca behaviour for each.  </section>
<citcontext>
<prevsection>
<prevsent>this sometimes leads the dialogue to error states that could be avoided.
</prevsent>
<prevsent>the expressive capacity of ecas could be used to reflect with greater clarity the state the system takes the dialogue to be in.
</prevsent>
</prevsection>
<citsent citstr=" P01-1016 ">
dialogue situation variety of studies have been carried out on behavioural strategies for embodied conversational agents (poggi, 2001; cassell et al, 2000; cassell et al., 2001; <papid> P01-1016 </papid>chovil, 1992; kendon, 1990), which deal with behaviour in hypothetical situations and in terms of the informational goals of each particular interaction (be it human-human or human machine).</citsent>
<aftsection>
<nextsent>we direct our attention to the overall dialogue systems dynamics, focussing specifically on typical robustness problems and how to favour smooth sailing through the different stages of the dialogue.
</nextsent>
<nextsent>we draw from existing research undertaken to try to understand the effects different gestures displayed by ecas have on people, and we apply this knowledge to real dialogue system.
</nextsent>
<nextsent>in table 1 we show the basic set of gestures we are using as starting point.
</nextsent>
<nextsent>they are based mainly on descriptions in bickmore (et al, 2004) and cassell (et al, 2000), and on recommendations in cassell and thorisson (1999), cassell (et al, 2001), <papid> P01-1016 </papid>chovil (1992), kendon (1990) and san-segundo (et al, 2001), to which we have added few suggestions of our own.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD74">
<title id=" W08-0115.xml">from gemini to diagen improving development of speech dialogues for embedded systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>having had its roots inthe eu-funded project gemini, fundamental changes were necessary to adopt it to the requirements of the application environment.
</prevsent>
<prevsent>additionally within this paper the basics of embedded speech dialogue systems are covered.
</prevsent>
</prevsection>
<citsent citstr=" W04-2306 ">
the eu funded research project gemini (genericenvironment for multilingual interactive natural interfaces) aimed at the development of an application generation platform (agp) to semiautomati cally generate multimodal dialogue applications for database access (hamerich et al, 2004<papid> W04-2306 </papid>a).</citsent>
<aftsection>
<nextsent>at the end of the project, two telephony applications had been successfully deployed: banking application for agreek bank, and citizen care application for german city.
</nextsent>
<nextsent>the former has been used by several thousand customers (hamerich et al, 2004<papid> W04-2306 </papid>b).</nextsent>
<nextsent>based on the ideas and concepts of gemini new tool named diagen has been developed, which improves the development process for dialogue applications with regard to certain aspects.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD78">
<title id=" W08-0115.xml">from gemini to diagen improving development of speech dialogues for embedded systems </title>
<section> automotive speech dialogues.  </section>
<citcontext>
<prevsection>
<prevsent>the generic dialogue modelling language (gdml) is designed as compiled language to save memory and cpu resources.
</prevsent>
<prevsent>this makes sense, since dialogues within car are still closed applications.
</prevsent>
</prevsection>
<citsent citstr=" H01-1047 ">
speech control for cars is available to the end customer since 1996 (heisterkamp, 2001).<papid> H01-1047 </papid></citsent>
<aftsection>
<nextsent>today many car manufacturers offer speech control systems.
</nextsent>
<nextsent>typical applications in car are voice control of telephone, tuner and navigation system.
</nextsent>
<nextsent>direct control of media files using their meta-data (e.g. id3-tags) by saying e.g. play title bad?
</nextsent>
<nextsent>by michael jackson??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD79">
<title id=" W07-1427.xml">learning alignments and leveraging natural logic </title>
<section> alignment model.  </section>
<citcontext>
<prevsection>
<prevsent>we compared two different update rules: the perceptron update and the mira update.
</prevsent>
<prevsent>in the perceptron update, for an incorrect prediction, the weight vector is modified by adding multiple of the difference between the feature vector of the correct label and the feature vector of the predicted label.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
we use the adaptation of this algorithm to structure prediction, first proposed by (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>themira update is proposed improvement that attempts to make the minimal modification to the weight vector such that the score of the incorrect prediction for the example is lower than the score of the correct label (crammer and singer, 2001).
</nextsent>
<nextsent>we compare the performance of the perceptron and mira algorithms on 10-fold cross-validation on the rte2 dev dataset.
</nextsent>
<nextsent>both algorithms improve with each pass over the dataset.
</nextsent>
<nextsent>most improvement is within the first five passes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD80">
<title id=" W08-0607.xml">recognizing speculative language in biomedical research articles a linguistically motivated perspective </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, the italicized fragment in example (1) below implies factual statement while example (2) contains two hedging cues (indicate and might), which render the factual proposition speculative:(1) each empty cell indicates that the corresponding tpase query was not used at the particular stage of psi-blast analysis.
</prevsent>
<prevsent>(2) these experiments indicated that the rox genes might function as nuclear entry sites for the assembly of the msl proteins on the chromosome.these examples not only illustrate the phenomenon of hedging in the biomedical literature,they also highlight some of the difficulties in recognizing hedges.
</prevsent>
</prevsection>
<citsent citstr=" W04-3103 ">
the word indicate plays different role in each example, acting as hedging cue only in the second.in recent years, there has been increasing interest in the speculative aspect of biomedical language (light et al , 2004, <papid> W04-3103 </papid>wilbur et al , 2006, medlock and briscoe, 2007).<papid> P07-1125 </papid></citsent>
<aftsection>
<nextsent>in general, these studies focus on issues regarding annotating speculation and approach the problem of recognizing speculation as text classification problem, using the well-known bag of words?
</nextsent>
<nextsent>method (light et al  2004, <papid> W04-3103 </papid>medlock and briscoe, 2007) <papid> P07-1125 </papid>or simple substring matching (light et al , 2004).<papid> W04-3103 </papid></nextsent>
<nextsent>while both approaches perform reasonably well, they do not take into account the more complex and strategic ways hedging can occur in biomedical research articles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD81">
<title id=" W08-0607.xml">recognizing speculative language in biomedical research articles a linguistically motivated perspective </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for instance, the italicized fragment in example (1) below implies factual statement while example (2) contains two hedging cues (indicate and might), which render the factual proposition speculative:(1) each empty cell indicates that the corresponding tpase query was not used at the particular stage of psi-blast analysis.
</prevsent>
<prevsent>(2) these experiments indicated that the rox genes might function as nuclear entry sites for the assembly of the msl proteins on the chromosome.these examples not only illustrate the phenomenon of hedging in the biomedical literature,they also highlight some of the difficulties in recognizing hedges.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
the word indicate plays different role in each example, acting as hedging cue only in the second.in recent years, there has been increasing interest in the speculative aspect of biomedical language (light et al , 2004, <papid> W04-3103 </papid>wilbur et al , 2006, medlock and briscoe, 2007).<papid> P07-1125 </papid></citsent>
<aftsection>
<nextsent>in general, these studies focus on issues regarding annotating speculation and approach the problem of recognizing speculation as text classification problem, using the well-known bag of words?
</nextsent>
<nextsent>method (light et al  2004, <papid> W04-3103 </papid>medlock and briscoe, 2007) <papid> P07-1125 </papid>or simple substring matching (light et al , 2004).<papid> W04-3103 </papid></nextsent>
<nextsent>while both approaches perform reasonably well, they do not take into account the more complex and strategic ways hedging can occur in biomedical research articles.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD96">
<title id=" W08-0607.xml">recognizing speculative language in biomedical research articles a linguistically motivated perspective </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>cues using wordnet (fellbaum, 1998) and the umls specialist lexicon (mccray et al , 1994).
</prevsent>
<prevsent>next, we quantified the strength of the hedging cues and patterns through corpus analysis.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
finally, to recognize the syntactic patterns, we used the stanford lexicalized parser (klein and manning, 2003) <papid> P03-1054 </papid>and its dependency parse representation (demarneffe et al , 2006).</citsent>
<aftsection>
<nextsent>we use weights assigned to hedging cues to compute an overall hedging score for each sentence.
</nextsent>
<nextsent>to evaluate the effectiveness of our method, we used basic information retrieval evaluation metrics: precision, recall, accuracy and 1 score.
</nextsent>
<nextsent>in addition, we measure the recall/precision break-even point (bep), which indicates the point at which precision and recall are equal, to provide comparison to results previously reported.
</nextsent>
<nextsent>as baseline, we use the substring matching method, described in light et al  (2004) <papid> W04-3103 </papid>in addition to another substring matching method, which uses terms ranked in top 15 in medlock and briscoe (2007).<papid> P07-1125 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD114">
<title id=" W07-2069.xml">titpi web people search task using semi supervised clustering approach </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>then, in order to disambiguate personal names in web search results, we introduce semi-supervised clustering that uses the seed page to aid the clustering of unlabeled search-result web pages.
</prevsent>
<prevsent>our semi-supervised clustering approach is characterized by controlling the fluctuation of the centro id of cluster.
</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
(mann and yarowsky, 2003) <papid> W03-0405 </papid>first extract biographical information, such as birth dates, birthplaces, occupations, and so on.</citsent>
<aftsection>
<nextsent>then, for each document,they generate feature vector composed of the extracted biographical information, proper nouns, and the tf-idf score computed from the documents inthe search results.
</nextsent>
<nextsent>finally, using this feature vector, they disambiguate personal names by generating clusters based on bottom-up centro id agglomera 318 tive clustering algorithm.
</nextsent>
<nextsent>(wan et al, 2005) employ an approach similar to that of (mann and yarowsky,2003), <papid> W03-0405 </papid>and have developed system called web hawk.</nextsent>
<nextsent>(pedersen et al, 2005) recently proposed method for discriminating names by clustering the instances of given name into groups.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD116">
<title id=" W07-2069.xml">titpi web people search task using semi supervised clustering approach </title>
<section> our proposed approach.  </section>
<citcontext>
<prevsection>
<prevsent># $    denotes each term.
</prevsent>
<prevsent>stop words were eliminated from all web pages in the search results based on the stop word list4, and stemming was performed using porter stemmer5.
</prevsent>
</prevsection>
<citsent citstr=" N01-1004 ">
in our preliminary experiments, we found that gain(papineni, 2001) <papid> N01-1004 </papid>is the most effective term weighting scheme for generating feature vectors for clustering in this kind of task.</citsent>
<aftsection>
<nextsent>using the gain scheme, we also define each element
</nextsent>
<nextsent>% of
</nextsent>
<nextsent>as follows: 4ftp://ftp.cs.cornell.edu/pub/smart/english.stop 5http://www.tartarus.org/martin/porterstemmer/ &amp;   algorithm: agglomerative clustering input: set of search-result web page () *,+-.fi/ 01/324232657 , 8 -9ffi(;:fi/ (#=#/323232(1 ?
</nextsent>
<nextsent>output: clusters that contain the web pages that refer to the same person.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD117">
<title id=" W07-2069.xml">titpi web people search task using semi supervised clustering approach </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, observing the results of each person in detail, we found that the purity values are improved when we use seed page that describes the person using more than about 200 words.
</prevsent>
<prevsent>on the other hand, in the case where seed page describes person with less than 150 words, or describes not only the target person but also some other persons, we could not obtain high purity values.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
in this paper, we described our participating syst emin the semeval-2007 web people search task (artiles et al, 2007).<papid> W07-2012 </papid></citsent>
<aftsection>
<nextsent>our system used semi supervised clustering which controls the fluctuation of the centro id of cluster.
</nextsent>
<nextsent>the evaluation results showed that our proposed method achieves high scores in inverse purity, with the lower scores in purity.
</nextsent>
<nextsent>this fact indicates that our proposed method tends to integrate search-result web pages into seed page.
</nextsent>
<nextsent>this clustering result makes it easier for user to browse the results of person web search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD118">
<title id=" W07-1405.xml">a corpus of fine grained entailment relations </title>
<section> the necessity of finer-grained analysis.  </section>
<citcontext>
<prevsection>
<prevsent>provide gloss of each facets meaning.
</prevsent>
<prevsent>as can be seen in 2b and 2c, the dependencies are augmented by thematic roles (kipper et al, 2000) (e.g., agent, theme, cause, instrument?)
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
produced by semantic role labeling system (c.f., gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>the facets also include those semantic role relations that are not derivable from typical dependency tree.
</nextsent>
<nextsent>forex ample, in the sentence as it freezes the water will expand and crack the glass?, water is not modifier of crack in the dependency tree, but it does play the role of agent in shallow semantic parse.
</nextsent>
<nextsent>(2) long string produces low pitch.
</nextsent>
<nextsent>(2a) nmod(string, long) (2b) agent(produces, string) (2c) product(produces, pitch) (2d) nmod(pitch, low) (2a?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD120">
<title id=" W07-1405.xml">a corpus of fine grained entailment relations </title>
<section> the necessity of finer-grained analysis.  </section>
<citcontext>
<prevsection>
<prevsent>can you assume that they understand the facet even though they did not express it, since it was part of the information given in the question?
</prevsent>
<prevsent>it is clear that, in addition to 2 the goal of most english dependency parsers is to pro-.
</prevsent>
</prevsection>
<citsent citstr=" C04-1010 ">
duce single projective tree structure for each sentence, where each node represents word in the sentence, each link represents functional category relation, usually labeled, between governor (head) and subordinate (modifier), and each node has single governor (c.f., nivre and scholz, 2004).<papid> C04-1010 </papid></citsent>
<aftsection>
<nextsent>breaking the reference answer into fine-grained facets, it is also necessary to break the annotation into finer levels in order to specify more clearly the relationship between the students answer and the reference answer aspect.
</nextsent>
<nextsent>there are many other issues that the system must know to achieve near optimal tutoring, some of which are mentioned later in the discussion section, but these two ? breaking the reference answer into fine-grained facets and utilizing more expressive annotation labels ? are the emphasis of this effort.
</nextsent>
<nextsent>this section describes our current efforts in annotating corpus of answers to science questions from elementary school students.
</nextsent>
<nextsent>4.1 corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD124">
<title id=" W07-1214.xml">the spanish resource grammar preprocessing strategy and lexical acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we describe the development of the spanish resource grammar (srg), an open source 2 medium-coverage grammar for spanish.
</prevsent>
<prevsent>the grammar is grounded in the theoretical framework of hpsg (head-driven phrase structure grammar; pollard and sag, 1994) and uses minimal recur sion semantics (mrs) for these mantic representation (copestake et al 2006).
</prevsent>
</prevsection>
<citsent citstr=" W02-1502 ">
the srg is implemented within the linguistic knowledge building (lkb) system (copestake, 2002), based on the basic components of the grammar matrix, an open source starter-kit for the development of hpsg grammars developed as part of the lingo consortiums multilingual grammar engineering (bender et al, 2002).<papid> W02-1502 </papid></citsent>
<aftsection>
<nextsent>the srg is part of the delph-in open-source repository of linguistic resources and tools for writing (the lkb system), testing (the [incr tsbd()]; oepen and carroll, 2000) and efficiently 1 this research was supported by the spanish ministerio de.
</nextsent>
<nextsent>educacin ciencia: project aaile (hum2004-05111-c0201), ramon cajal, juan de la cierva programmes and pta cte/1370/2003 with fondo social europeo.
</nextsent>
<nextsent>http://www.upf.edu/pdi/iula/montserrat.marimon/.
</nextsent>
<nextsent>processing hpsg grammars (the pet system; callmeier, 2000).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD125">
<title id=" W07-1214.xml">the spanish resource grammar preprocessing strategy and lexical acquisition </title>
<section> see . http://www.delph-in.net/.  </section>
<citcontext>
<prevsection>
<prevsent>the rest of the paper describes the preprocessing strategy we have adopted and on our on-going research on lexical acquisition.
</prevsent>
<prevsent>2 pre-processing in the srg.
</prevsent>
</prevsection>
<citsent citstr=" C02-1071 ">
following previous experiments within the advanced linguistic engineering platform (alep) platform (marimon, 2002), <papid> C02-1071 </papid>we have integrated shallow processing tool, the free ling tool, as pre-processing module of the grammar.</citsent>
<aftsection>
<nextsent>the free ling tool is an open-source4 language analysis tool suite (atserias et al, 2006) perfoming the following functional ities (though disambiguation, named entity classification and the last three functional ities have not been integrated): ? text tokenization (including mwu and contraction splitting).
</nextsent>
<nextsent>sentence splitting.
</nextsent>
<nextsent>morpho-syntactic analysis and disambiguation.
</nextsent>
<nextsent>n. ? named entity detection and classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD126">
<title id=" W07-1214.xml">the spanish resource grammar preprocessing strategy and lexical acquisition </title>
<section> see . http://www.delph-in.net/.  </section>
<citcontext>
<prevsection>
<prevsent>free ling also includes guesser to deal with words which are not found in the lexicon by computing the probability of each possible pos tag given the longest observed termination string for that word.
</prevsent>
<prevsent>smoothing using probabilities of shorter termination strings is also performed.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
details can be found in brants (2000) <papid> A00-1031 </papid>and samuelson (1993).</citsent>
<aftsection>
<nextsent>our system integrates the free ling tool by means of the lkb simple pre processor protocol (sppp; http://wiki.delph-in.net/moin/lkbsppp), which assumes that pre processor runs as an external process to the lkb system, and uses the lkb inflectional rule component to convert the pos tags delivered by the free ling tool into partial descriptions of feature structures.
</nextsent>
<nextsent>2.1 the integration of pos tags.
</nextsent>
<nextsent>the integration of the morpho-syntactic analysis in the lkb system using the sppp protocol means defining inflectional rules that propagate the mor pho-syntactic information associated to full-forms, in the form of pos tags, to the morpho-syntactic features of the lexical items.
</nextsent>
<nextsent>(1) shows the rule propagating the tag aqms (adjective qualitative masculine singular) delivered by freeling.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD127">
<title id=" W07-1214.xml">the spanish resource grammar preprocessing strategy and lexical acquisition </title>
<section> see . http://www.delph-in.net/.  </section>
<citcontext>
<prevsection>
<prevsent>we have investigated machine learning (ml) methods applied to the acquisition of the information contained in the lexicon of the srg.
</prevsent>
<prevsent>ml applied to lexical acquisition is very active area of work linked to deep linguistic analysis due to the central role that lexical information has in lexicalized grammars and the costs of hand crafting them.
</prevsent>
</prevsection>
<citsent citstr=" W05-1008 ">
korhonen (2002), carroll and fang (2004), baldwin (2005), <papid> W05-1008 </papid>blunsom and baldwin (2006), <papid> W06-1620 </papid>and zhang and kordoni (2006) are just few examples of reported research work on deep lexical acquisition.</citsent>
<aftsection>
<nextsent>the most successful systems of lexical acquisition are based on the linguistic idea that the contexts where words occur are associated to particular lexical types.
</nextsent>
<nextsent>although the methods are different, most of the systems work upon the syntactic information on words as collected from corpus, and they develop different techniques to decide whether this information is relevant for type assignment or it is noise, especially when there are just few examples.
</nextsent>
<nextsent>in the lkb grammatical framework, lexical types are defined as combination of grammatical features.
</nextsent>
<nextsent>for our research, we have looked at these morpho-syntactically motivated features that can help in discriminating the different types that we will ultimately use to classify words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD128">
<title id=" W07-1214.xml">the spanish resource grammar preprocessing strategy and lexical acquisition </title>
<section> see . http://www.delph-in.net/.  </section>
<citcontext>
<prevsection>
<prevsent>we have investigated machine learning (ml) methods applied to the acquisition of the information contained in the lexicon of the srg.
</prevsent>
<prevsent>ml applied to lexical acquisition is very active area of work linked to deep linguistic analysis due to the central role that lexical information has in lexicalized grammars and the costs of hand crafting them.
</prevsent>
</prevsection>
<citsent citstr=" W06-1620 ">
korhonen (2002), carroll and fang (2004), baldwin (2005), <papid> W05-1008 </papid>blunsom and baldwin (2006), <papid> W06-1620 </papid>and zhang and kordoni (2006) are just few examples of reported research work on deep lexical acquisition.</citsent>
<aftsection>
<nextsent>the most successful systems of lexical acquisition are based on the linguistic idea that the contexts where words occur are associated to particular lexical types.
</nextsent>
<nextsent>although the methods are different, most of the systems work upon the syntactic information on words as collected from corpus, and they develop different techniques to decide whether this information is relevant for type assignment or it is noise, especially when there are just few examples.
</nextsent>
<nextsent>in the lkb grammatical framework, lexical types are defined as combination of grammatical features.
</nextsent>
<nextsent>for our research, we have looked at these morpho-syntactically motivated features that can help in discriminating the different types that we will ultimately use to classify words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD129">
<title id=" W07-1214.xml">the spanish resource grammar preprocessing strategy and lexical acquisition </title>
<section> see . http://www.delph-in.net/.  </section>
<citcontext>
<prevsection>
<prevsent>=== ? === j vnoxisfpnoxisfz )|,(),,(  ? 3.2 decision tree linguistic motivated features have also been evaluated using c4.5 decision tree (dt) classifier (quinlan, 1993) in the weka implementation (witten and frank, 2005).
</prevsent>
<prevsent>these features correspond to the expected contexts for the different nominal and adjectival lexical types.
</prevsent>
</prevsection>
<citsent citstr=" N07-2002 ">
we have trained the dt with all the vectors of the word occurrences that we had in the different gold-standards, using their encoding for the supervised experiment in 10-fold cross-validation testing (bel et al 2007).<papid> N07-2002 </papid></citsent>
<aftsection>
<nextsent>3.3 evaluation and results.
</nextsent>
<nextsent>for the evaluation, we have applied both methods to the lexical acquisition of nouns and adjectives.
</nextsent>
<nextsent>we have worked with pos tagged corpus of 1,091,314 words.
</nextsent>
<nextsent>datasets of 496 adjectives and 289 nouns were selected among the ones that had occurrences in the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD130">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>the goal of the project is to create an open, high quality phrase-based decoder which can reduce the time and barrier to entry for researchers wishing to do smt research.
</prevsent>
<prevsent>we discuss the major design objective for the moses decoder, its performance relative to other smt decoders, and the steps we are taking to ensure that its success will continue.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
phrase-based translation has been one of the major advances in statistical machine translation (brown et al 1990) <papid> J90-2002 </papid>in recent years and is currently one of the techniques which can claim to be state of-the-art in machine translation.</citsent>
<aftsection>
<nextsent>phrase-based models are development of the word based models as exemplified by the (brown et al 1990).<papid> J90-2002 </papid></nextsent>
<nextsent>in phrase-based translation, contiguous segments of words in the input sentence are mapped to contiguous segments of words in the output sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD132">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>in the space of possible translations t. this search is the task of the decoder, which we will concentrate on in this paper.
</prevsent>
<prevsent>there have been numerous implementations of phrase-based decoders for smt prior to our work.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
early systems such as the alignment template system (ats) (och and ney 2004) <papid> J04-4002 </papid>and pharaoh (koehn 2004) were widely used and accepted by the research community.</citsent>
<aftsection>
<nextsent>ats is perhaps the cross over system, in that word classes were translated as phrases but the surface words were translated word by word.
</nextsent>
<nextsent>pharaoh substituted the word classes with surface words, thereby discarding the use of word classes in decoding altogether.
</nextsent>
<nextsent>there has been other phrase-based decoders such as portage (sadat et al 2005), <papid> W05-0822 </papid>phramer (olteanu et al 2006), <papid> W06-3121 </papid>the mitll/afrl system (shen et al 2005), itc-irst (bertoldi et al 2004), ramses/mood (patry et al 2006) <papid> W06-3116 </papid>to name but few.</nextsent>
<nextsent>other researchers such as (kumar and byrne 2003) <papid> N03-1019 </papid>have also used weighted finite state transducers but they have more difficulty modeling re ordering.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD133">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>ats is perhaps the cross over system, in that word classes were translated as phrases but the surface words were translated word by word.
</prevsent>
<prevsent>pharaoh substituted the word classes with surface words, thereby discarding the use of word classes in decoding altogether.
</prevsent>
</prevsection>
<citsent citstr=" W05-0822 ">
there has been other phrase-based decoders such as portage (sadat et al 2005), <papid> W05-0822 </papid>phramer (olteanu et al 2006), <papid> W06-3121 </papid>the mitll/afrl system (shen et al 2005), itc-irst (bertoldi et al 2004), ramses/mood (patry et al 2006) <papid> W06-3116 </papid>to name but few.</citsent>
<aftsection>
<nextsent>other researchers such as (kumar and byrne 2003) <papid> N03-1019 </papid>have also used weighted finite state transducers but they have more difficulty modeling re ordering.</nextsent>
<nextsent>many early systems came with restrictive li censes; ats has never been publicly released, pharaoh was released in 2003 as pre-compiled binary with documentation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD134">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>ats is perhaps the cross over system, in that word classes were translated as phrases but the surface words were translated word by word.
</prevsent>
<prevsent>pharaoh substituted the word classes with surface words, thereby discarding the use of word classes in decoding altogether.
</prevsent>
</prevsection>
<citsent citstr=" W06-3121 ">
there has been other phrase-based decoders such as portage (sadat et al 2005), <papid> W05-0822 </papid>phramer (olteanu et al 2006), <papid> W06-3121 </papid>the mitll/afrl system (shen et al 2005), itc-irst (bertoldi et al 2004), ramses/mood (patry et al 2006) <papid> W06-3116 </papid>to name but few.</citsent>
<aftsection>
<nextsent>other researchers such as (kumar and byrne 2003) <papid> N03-1019 </papid>have also used weighted finite state transducers but they have more difficulty modeling re ordering.</nextsent>
<nextsent>many early systems came with restrictive li censes; ats has never been publicly released, pharaoh was released in 2003 as pre-compiled binary with documentation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD135">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>ats is perhaps the cross over system, in that word classes were translated as phrases but the surface words were translated word by word.
</prevsent>
<prevsent>pharaoh substituted the word classes with surface words, thereby discarding the use of word classes in decoding altogether.
</prevsent>
</prevsection>
<citsent citstr=" W06-3116 ">
there has been other phrase-based decoders such as portage (sadat et al 2005), <papid> W05-0822 </papid>phramer (olteanu et al 2006), <papid> W06-3121 </papid>the mitll/afrl system (shen et al 2005), itc-irst (bertoldi et al 2004), ramses/mood (patry et al 2006) <papid> W06-3116 </papid>to name but few.</citsent>
<aftsection>
<nextsent>other researchers such as (kumar and byrne 2003) <papid> N03-1019 </papid>have also used weighted finite state transducers but they have more difficulty modeling re ordering.</nextsent>
<nextsent>many early systems came with restrictive li censes; ats has never been publicly released, pharaoh was released in 2003 as pre-compiled binary with documentation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD136">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>pharaoh substituted the word classes with surface words, thereby discarding the use of word classes in decoding altogether.
</prevsent>
<prevsent>there has been other phrase-based decoders such as portage (sadat et al 2005), <papid> W05-0822 </papid>phramer (olteanu et al 2006), <papid> W06-3121 </papid>the mitll/afrl system (shen et al 2005), itc-irst (bertoldi et al 2004), ramses/mood (patry et al 2006) <papid> W06-3116 </papid>to name but few.</prevsent>
</prevsection>
<citsent citstr=" N03-1019 ">
other researchers such as (kumar and byrne 2003) <papid> N03-1019 </papid>have also used weighted finite state transducers but they have more difficulty modeling re ordering.</citsent>
<aftsection>
<nextsent>many early systems came with restrictive li censes; ats has never been publicly released, pharaoh was released in 2003 as pre-compiled binary with documentation.
</nextsent>
<nextsent>this severely limited the extent to which other researchers can study and enhance the decoder.
</nextsent>
<nextsent>without access to the decoder source code research was generally restricted to altering the input, augmenting it with extra information, or modifying the output or re-ranking the n-best list output.
</nextsent>
<nextsent>the main contribution of this paper is to show how we have created an extensible decoder, has acceptable run time performance compared to similar systems, and the ease of use and development that has made it the preferred choice for researchers looking for phrase-based smt decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD137">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>58 as an indication of the take-up of the moses toolkit, out of over 20 competing teams at there cent iwslt 2007 conference1, half used moses.
</prevsent>
<prevsent>as an indication of the extensibility of the decoder, there are currently four language model implementations which has been integrated with the decoder by various researchers.
</prevsent>
</prevsection>
<citsent citstr=" N03-2002 ">
in addition, the framework exists to integrate language models, such as those described in (bilmes and kirchhoff 2003), <papid> N03-2002 </papid>which takes advantage of the factored representation within moses.</citsent>
<aftsection>
<nextsent>it is noted that mood/ramses also supports multiple lm implementations, an internally developed language model, in additional to srilm, to overcome the latters licensing restrictions.
</nextsent>
<nextsent>in addition, there are two built-in phrase table implementations, one which loads all data into memory for fast decoding, and binary phrase table as described in (zens and ney 2007) <papid> N07-1062 </papid>which loads on demand to conserve memory usage.</nextsent>
<nextsent>the moses decoder has the ability to accept simple sentence input, confusion network or lattice networks, in common with smt decoders such as the mitll/afrl or itc-irst systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD138">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>in addition, the framework exists to integrate language models, such as those described in (bilmes and kirchhoff 2003), <papid> N03-2002 </papid>which takes advantage of the factored representation within moses.</prevsent>
<prevsent>it is noted that mood/ramses also supports multiple lm implementations, an internally developed language model, in additional to srilm, to overcome the latters licensing restrictions.</prevsent>
</prevsection>
<citsent citstr=" N07-1062 ">
in addition, there are two built-in phrase table implementations, one which loads all data into memory for fast decoding, and binary phrase table as described in (zens and ney 2007) <papid> N07-1062 </papid>which loads on demand to conserve memory usage.</citsent>
<aftsection>
<nextsent>the moses decoder has the ability to accept simple sentence input, confusion network or lattice networks, in common with smt decoders such as the mitll/afrl or itc-irst systems.
</nextsent>
<nextsent>the decoder also produces diverse types of output, ranging from 1-best, n-best lists and word lattices.
</nextsent>
<nextsent>the moses decoder is designed within strict modular and object-oriented framework for easy maintainability and extensibility.
</nextsent>
<nextsent>in designing the decoder, we modeled the software design methodology and aims on some re search-oriented software libraries outside of the smt and nlp field which is open source, written in c++, have large and diverse user-base, have succeeded in becoming the industry norm in their field.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD139">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> comparison with other projects.  </section>
<citcontext>
<prevsection>
<prevsent>design goals such as robustness, flexibility, ease of use and efficiency are commonality that we share and which we will discuss in more detail in the next section.
</prevsent>
<prevsent>as contrast to cgal and dcmtk whose design we would like to emulate, we also looked at project within the nlp field which contains certain aspect in the design we would like to avoid.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
giza++ (och and ney 2003) <papid> J03-1002 </papid>is very popular system within smt for creating word alignment from parallel corpus, in fact, the moses training scripts uses it.</citsent>
<aftsection>
<nextsent>the system was release under the gpl open source license.
</nextsent>
<nextsent>however, its lack of 2 http://cordis.europa.eu/esprit/src/21957.htm 59 clear design, documentation and obscure coding style makes it difficult for other researcher to contribute or extend the system.
</nextsent>
<nextsent>for long time, it couldnt even be compiled on modern gcc compilers.
</nextsent>
<nextsent>other systems which seeks to improve word alignment and segmentation, such as mttk (deng et al 2006), have been created to replace giza++.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD140">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> design goals.  </section>
<citcontext>
<prevsection>
<prevsent>we steered clear of scripting languages for performance reasons and the fact they often offer even less in the way of cross-platform compatibility.
</prevsent>
<prevsent>java was also avoided for performance reasons but its rich library and multi-platform support would have been useful.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
we note that hiero (chiang 2005) <papid> P05-1033 </papid>is written in scripting language with performance critical components rewritten in compiled language.</citsent>
<aftsection>
<nextsent>this is not the approach we considered as we believed it would have raised the complexity and reduce reliability of the project having to develop (and debug) in two languages and managing the interface between them.
</nextsent>
<nextsent>we also note that the linearb and phramer decoders are implemented in java and have reported significantly worse run time speeds, (olteanu et al 2006).<papid> W06-3121 </papid></nextsent>
<nextsent>c++ can be inelegant and difficult for inexperienced developers but using other object oriented language such as small talk or c# was out of the question as they lack acceptance within the mt research community.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD142">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> design goals.  </section>
<citcontext>
<prevsection>
<prevsent>this transforms the representation of word from string to vector of strings, and phrase or sentence from sequence of words to sequence of vectors.
</prevsent>
<prevsent>such change to the basic data structure of decoder propagated through out the rest of the system, therefore, it was simpler to build the moses decoder from scratch rather than extend an existing decoder such as pharaoh.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
some research into factored machine translation has been published by (koehn and hoang 2007).<papid> D07-1091 </papid></citsent>
<aftsection>
<nextsent>3.3 flexibility.
</nextsent>
<nextsent>flexibility is an important software design goal which will enable researchers to extend the use of the moses decoders to tasks that were not originally envisioned.
</nextsent>
<nextsent>following (fabri et al 2000), we identify four sub-issues which affects flexibility: i. modularity 3 http://www.statmt.org/wmt07/shared-task.html 60 ii.
</nextsent>
<nextsent>adaptability iii.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD143">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> design goals.  </section>
<citcontext>
<prevsection>
<prevsent>we detail some examples of the object-oriented design of moses below.
</prevsent>
<prevsent>the input into the decoder can be one of three types: simple string (sentence), confusion network or lattice network, figure 2.
</prevsent>
</prevsection>
<citsent citstr=" D07-1049 ">
figure 2 input types language models are abstracted to enable different implementations to be used and provide framework for more complex models such as factored lm and the bloom filter language model (talbot and osborne 2007).<papid> D07-1049 </papid></citsent>
<aftsection>
<nextsent>similarly, phrase tables are abstracted to provide support for multiple implementations.
</nextsent>
<nextsent>each component model which contributes to the log-linear hypothesis score inherits from the score producer base class, figure 3.
</nextsent>
<nextsent>figure 3 score producer the moses library provide simple api whose main entry point is the class manager this class is instantiated in the client application, moses-cmd in our case.
</nextsent>
<nextsent>each input is decoded by calling the class method below: processsentence() 3.5 adaptability.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD144">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> supporting infrastructure.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 one-stop shop?
</prevsent>
<prevsent>for phrase-based smt the moses project encompasses the decoder and many of the other components necessary to create translation system which were previously available separately.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
these include scripts for creating alignments from parallel corpus, creating phrase tables and language models, binarizing phrase tables, scripts for weight optimization using mert (och 2003), <papid> P03-1021 </papid>and testing scripts.</citsent>
<aftsection>
<nextsent>steps such as mert and testing which are cpu intensive have been re-engineered to run in parallel using sun grid engine.
</nextsent>
<nextsent>all scripts have also been extended for factored translation.
</nextsent>
<nextsent>63 4.2 ongoing support we assist in the adoption of moses by offering ongoing support to users and developers through the support mailing list 5 . questions relating to moses, phrase-based translation or machine translation in general are often asked, and usually answered.
</nextsent>
<nextsent>the archived emails are publicly available and search able, and have become an important knowledge source for the community.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD146">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>0 20 40 60 80 100 120 140 160 ov 06 ec 06 ja 07 feb 07 ar 07 apr 07 ay 07 ju 07 ju l-0 7 aug 07 sep 07 c t-0 7 ov 07 ec 07 ja 08 feb 08 figure 6 emails to moses support mailing list
</prevsent>
<prevsent>there has been some important developments in phrase-based translation in recent years, including the hierarchical phrase-based model as described in (chiang 2005).<papid> P05-1033 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
research have also been made into alternatives to the current log-linear scoring model such as discriminative models with millions of features (liang et al 2006), <papid> P06-1096 </papid>or kernel based models (wang et al 2007).<papid> N07-2047 </papid></citsent>
<aftsection>
<nextsent>from software engineering point of view, these improvements would require fundamental changes to the structure if they were to be implemented into moses.
</nextsent>
<nextsent>we are also interested in seeing the moses decoder employed in search tasks outside of machine translation; moses has been used for ocr correction, re casing, and transliteration.
</nextsent>
<nextsent>other improvements such as smaller, faster, more efficient phrase tables are also welcomed.
</nextsent>
<nextsent>lastly, we would like to see the training and tuning scripts re-engineered to the same modular 5 moses-support@mit.edu design as the decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD147">
<title id=" W08-0510.xml">design of the moses decoder for statistical machine translation </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>0 20 40 60 80 100 120 140 160 ov 06 ec 06 ja 07 feb 07 ar 07 apr 07 ay 07 ju 07 ju l-0 7 aug 07 sep 07 c t-0 7 ov 07 ec 07 ja 08 feb 08 figure 6 emails to moses support mailing list
</prevsent>
<prevsent>there has been some important developments in phrase-based translation in recent years, including the hierarchical phrase-based model as described in (chiang 2005).<papid> P05-1033 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-2047 ">
research have also been made into alternatives to the current log-linear scoring model such as discriminative models with millions of features (liang et al 2006), <papid> P06-1096 </papid>or kernel based models (wang et al 2007).<papid> N07-2047 </papid></citsent>
<aftsection>
<nextsent>from software engineering point of view, these improvements would require fundamental changes to the structure if they were to be implemented into moses.
</nextsent>
<nextsent>we are also interested in seeing the moses decoder employed in search tasks outside of machine translation; moses has been used for ocr correction, re casing, and transliteration.
</nextsent>
<nextsent>other improvements such as smaller, faster, more efficient phrase tables are also welcomed.
</nextsent>
<nextsent>lastly, we would like to see the training and tuning scripts re-engineered to the same modular 5 moses-support@mit.edu design as the decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD148">
<title id=" W07-1430.xml">a first order semantic approach to adjectival inference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as has often been observed, not all of natural language meaning can be represented by first order logic.
</prevsent>
<prevsent>there are expressions such as, most, former,i didnt whose meaning intuitively involve higher order constructs.
</prevsent>
</prevsection>
<citsent citstr=" P85-1008 ">
nevertheless, as (hobbs, 1985) <papid> P85-1008 </papid>and others have argued, semantic representations for natural language need not be higher-order in that ontologicalpromiscuity can solve the problem.</citsent>
<aftsection>
<nextsent>that is, by reify ing all objects that can be predicated of, it is possible to retain semantic representation scheme for nl that is first-order.this observation is crucial for computational applications for two reasons.
</nextsent>
<nextsent>first, logics that goes beyond first order are highly undecidable.
</nextsent>
<nextsent>second andmore importantly, there is no off the shelf higher order automated reason ers that could be put to use to reason about the meaning of higher-order formulae.in this paper, we present semantics for adjectives that adopts an onto logically promiscuous approach and thereby supports first order inference for all types of adjectives including extensional ones.indeed, traditional semantic classifications of adjectives such as (chierchia and connell-ginet, 1990; kamp, 1975; kamp and partee, 1995) subdivide adjectives into two classes namely extensional vs. intensional adjectives, the latter grouping together adjectives which intuitively denote functions from properties to properties, i.e. second order objects.we present compositional semantics for adjectives which both (i) defines first order representation and (ii) integrates interactions with other sources of linguistic information such as lexical semantics and morpho-derivational relations.
</nextsent>
<nextsent>we then show that the proposed semantics correctly predicts the inferential patterns observed to hold of the various adjective subclasses identified in the literature (chierchia and connell-ginet, 1990; kamp, 1975; kamp and partee, 1995; amoia and gardent, 2006).<papid> W06-1805 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD149">
<title id=" W07-1430.xml">a first order semantic approach to adjectival inference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, logics that goes beyond first order are highly undecidable.
</prevsent>
<prevsent>second andmore importantly, there is no off the shelf higher order automated reason ers that could be put to use to reason about the meaning of higher-order formulae.in this paper, we present semantics for adjectives that adopts an onto logically promiscuous approach and thereby supports first order inference for all types of adjectives including extensional ones.indeed, traditional semantic classifications of adjectives such as (chierchia and connell-ginet, 1990; kamp, 1975; kamp and partee, 1995) subdivide adjectives into two classes namely extensional vs. intensional adjectives, the latter grouping together adjectives which intuitively denote functions from properties to properties, i.e. second order objects.we present compositional semantics for adjectives which both (i) defines first order representation and (ii) integrates interactions with other sources of linguistic information such as lexical semantics and morpho-derivational relations.
</prevsent>
</prevsection>
<citsent citstr=" W06-1805 ">
we then show that the proposed semantics correctly predicts the inferential patterns observed to hold of the various adjective subclasses identified in the literature (chierchia and connell-ginet, 1990; kamp, 1975; kamp and partee, 1995; amoia and gardent, 2006).<papid> W06-1805 </papid></citsent>
<aftsection>
<nextsent>this paper is structured as follows.
</nextsent>
<nextsent>we start by presenting classification of adjectives which is motivated by the different inferential patterns observed.
</nextsent>
<nextsent>we then propose compositional semantics for each class and show that it correctly predicts their inferen tial behaviour.
</nextsent>
<nextsent>we conclude with brief discussion of related work and pointers for further research.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD156">
<title id=" W07-1204.xml">exploiting semantic information for hpsg parse selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recently, significant improvements have been made in combining symbolic and statistical approaches to various natural language processing tasks.
</prevsent>
<prevsent>in parsing, for example, symbolic grammars are combined with stochastic models (oepen et al, 2004; malouf and van noord, 2004).
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
much of the gain in statistical parsing using lexicalized models comes from the use of small set of function words(klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>features based on general relations provide little improvement, presumably because the data is too sparse: in the penn treebank standardly used to train and test statistical parsers stocks and skyrocket never appear together.
</nextsent>
<nextsent>however, the super ordinate concepts capital (?
</nextsent>
<nextsent>stocks) and move upward (?
</nextsent>
<nextsent>sky rocket) frequently appear together, which suggests that using word senses and their hypernyms as features may be useful however, to date, there have been few combinations of sense information together with symbolic grammars and statistical models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD157">
<title id=" W07-1204.xml">exploiting semantic information for hpsg parse selection </title>
<section> the hinoki corpus.  </section>
<citcontext>
<prevsection>
<prevsent>a model trained using syntactic features combined with semantic information outperforms model using purely syntactic information by wide margin (69.4% sentence parse accuracy vs. 63.8% on definition sentences).
</prevsent>
<prevsent>there are now some corpora being built with the syntactic and semantic information necessary to investigate the use of semantic information in parse selection.
</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
in english, the ontonotes project (hovy et al, 2006) <papid> N06-2015 </papid>is combining sense tags with the penntreebank.</citsent>
<aftsection>
<nextsent>we are using japanese data from the hi noki corpus consisting of around 95,000 dictionary definition and example sentences (bond et al, 2007) annotated with both syntactic parses and senses from the same dictionary.
</nextsent>
<nextsent>2.1 syntactic annotation.
</nextsent>
<nextsent>syntactic annotation in hinoki is grammar based corpus annotation done by selecting the best parse(or parses) from the full analyses derived by broad coverage precision grammar.
</nextsent>
<nextsent>the grammar is an hpsg implementation (jacy: siegel and bender,2002), <papid> W02-1210 </papid>which provides high level of detail, marking not only dependency and constituent structure but also detailed semantic relations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD158">
<title id=" W07-1204.xml">exploiting semantic information for hpsg parse selection </title>
<section> the hinoki corpus.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 syntactic annotation.
</prevsent>
<prevsent>syntactic annotation in hinoki is grammar based corpus annotation done by selecting the best parse(or parses) from the full analyses derived by broad coverage precision grammar.
</prevsent>
</prevsection>
<citsent citstr=" W02-1210 ">
the grammar is an hpsg implementation (jacy: siegel and bender,2002), <papid> W02-1210 </papid>which provides high level of detail, marking not only dependency and constituent structure but also detailed semantic relations.</citsent>
<aftsection>
<nextsent>as the grammar is based on monostratal theory of grammar(hpsg: pollard and sag, 1994), annotation by manual disambiguation determines syntactic and semantic structure at the same time.
</nextsent>
<nextsent>using grammar 25helps treebank consistency ? all sentences annotated are guaranteed to have well-formed parses.
</nextsent>
<nextsent>the flip side to this is that any sentences which the parser cannot parse remain unannotated, at least unless we were to fall back on full manual mark-up of their analyses.
</nextsent>
<nextsent>the actual annotation process uses the same tools as the redwoods treebank of english (oepen et al, 2004).a (simplified) example of an entry is given in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD159">
<title id=" W07-1204.xml">exploiting semantic information for hpsg parse selection </title>
<section> parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>to make features in the same way as table 3.
</prevsent>
<prevsent>an advantage of these underspecified semantic classes is that they are more robust to errors in word sense disambiguation ? fine grained sense distinctions can be ignored.
</prevsent>
</prevsection>
<citsent citstr=" W04-2206 ">
3.2.4 valency dictionary compatability the last kind of semantic information we use is valency information, taken from the japanese sideof the goi-taikei japanese-english valency dictionary as extended by fujita and bond (2004).<papid> W04-2206 </papid>this va lency dictionary has detailed information about the argument properties of verbs and adjectives, including subcategorization and selectional restrictions.</citsent>
<aftsection>
<nextsent>a simplified entry of the japanese side for u2 dunten-suru drive?
</nextsent>
<nextsent>is shown in figure 6.
</nextsent>
<nextsent>each entry has predicate and several case-slots.
</nextsent>
<nextsent>each case-slot has information such as grammatical function, case-marker, case-role (n1, n2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD160">
<title id=" W07-1204.xml">exploiting semantic information for hpsg parse selection </title>
<section> evaluation and results.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 maximum entropy rankerlog-linear models provide very flexible framework that has been widely used for range of tasks in nlp, including parse selection and reranking for machine translation.
</prevsent>
<prevsent>we use maximum entropy / minimum divergence (memd) modeler to train the parse selection model.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
specifically, we use the open-source toolkit for advanced discriminative modeling (tadm:2 malouf, 2002) <papid> W02-2018 </papid>for training, using its limited-memory variable metric as the optimization method and determining best-performingconvergence thresholds and prior sizes experimen tally.</citsent>
<aftsection>
<nextsent>a comparison of this learner with the use of support vector machines over similar data found that the svms gave comparable results but were far slower (baldridge and osborne, 2007).
</nextsent>
<nextsent>because weare investigating the effects of various different features, we chose the faster learner.
</nextsent>
<nextsent>2http://tadm.sourceforge.net 30 method definitions examples accuracy features accuracy features (%) (1000) (%) (1000) syn-1 52.8 7 67.6 8 syn-gp 62.7 266 76.0 196 syn-all 63.8 316 76.2 245 syn baseline 16.4 random 22.3 random sem-dep 57.3 1,189 58.7 675 +sem-ws 56.2 1,904 59.0 1,486 +sem-class 57.5 2,018 59.7 1,669 +sem-l2 60.3 808 62.9 823 +sem-l3 59.8 876 62.8 879 +sem-l4 59.9 1,000 62.3 973 +sem-l5 60.4 1,240 61.3 1,202 +sp 59.1 1,218 68.2 819 +sem-all 62.7 3,384 69.1 2,693 syn-sem 69.5 2,476 79.2 2,126 sem baseline 20.3 random 22.8 random table 6: parse selection results 4.2 results.
</nextsent>
<nextsent>the results for most of the models discussed in the previous section are shown in table 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD161">
<title id=" W07-1204.xml">exploiting semantic information for hpsg parse selection </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the learning curves(fig 7) have not yet flattened out.
</prevsent>
<prevsent>we can still im prove by increasing the size of the training data.
</prevsent>
</prevsection>
<citsent citstr=" W00-1320 ">
bikel (2000) <papid> W00-1320 </papid>combined sense information and parse information using subset of semcor (with wordnet senses and penn-ii treebanks) to produce combined model.</citsent>
<aftsection>
<nextsent>this model did not use semantic dependency relations, but only syntactic dependencies augmented with heads, which suggests that the deeper structural semantics provided by the hpsg parser is important.
</nextsent>
<nextsent>xiong et al (2005) achieved only very minor improvement over plain syntactic model, using features based on both the correlation between predicates and their arguments, and between predicates and the hypernyms of their arguments (using hownet).
</nextsent>
<nextsent>however, they do not investigate generalizing to different levels than words immediate hypernym.
</nextsent>
<nextsent>31 pioneering work by toutanova et al (2005) and baldridge and osborne (2007) on parse selection for an english hpsg treebank used simpler semantic features without sense information, and got far less dramatic improvement when they combined syntactic and semantic information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD162">
<title id=" W08-0410.xml">inductive detection of language features via clustering minimal pairs toward feature rich grammars in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we conclude by outlining how the resulting output can then be used in inducing morpho syntactically feature-rich grammar for avenue, modern syntax-based mt system.
</prevsent>
<prevsent>recent trends in machine translation have begun moving toward the incorporation of syntax and structure in translation models in hopes of gaining better translation quality.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
in fact, some structure based systems have already shown that they can out perform phrase-based smt systems (chiang, 2005).<papid> P05-1033 </papid></citsent>
<aftsection>
<nextsent>still, even the best-performing data-driven systems have not fully explored the depth of such linguistic features as morphosyntax.certainly, many have brought linguistically motivated features into their models in the past.
</nextsent>
<nextsent>huang and knight (2006) <papid> N06-1031 </papid>explored relabeling of nonterminal symbols to embed more information directly into the backbone of the grammar.</nextsent>
<nextsent>bonneau maynard et al (2007) argue that incorporation of morpho syntax in the form of part of speech (pos) language model can improve translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD163">
<title id=" W08-0410.xml">inductive detection of language features via clustering minimal pairs toward feature rich grammars in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in fact, some structure based systems have already shown that they can out perform phrase-based smt systems (chiang, 2005).<papid> P05-1033 </papid></prevsent>
<prevsent>still, even the best-performing data-driven systems have not fully explored the depth of such linguistic features as morphosyntax.certainly, many have brought linguistically motivated features into their models in the past.</prevsent>
</prevsection>
<citsent citstr=" N06-1031 ">
huang and knight (2006) <papid> N06-1031 </papid>explored relabeling of nonterminal symbols to embed more information directly into the backbone of the grammar.</citsent>
<aftsection>
<nextsent>bonneau maynard et al (2007) argue that incorporation of morpho syntax in the form of part of speech (pos) language model can improve translation.
</nextsent>
<nextsent>while these approaches do make use of various linguistic features, we have only begun to scratch the surface of what actually occurs in the languages of theworld.
</nextsent>
<nextsent>we wish to address such issues as case marking, subject-verb agreement, and numeral-classifier agreement by providing models with information about which morphemes correspond to which grammatical meanings.
</nextsent>
<nextsent>feature detection is the process of determining from corpus annotated with feature structures (figure 2)which feature values (figure 1) have distinct representation in target language in terms of morphemes (figure 3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD164">
<title id=" W08-0410.xml">inductive detection of language features via clustering minimal pairs toward feature rich grammars in machine translation </title>
<section> task overview.  </section>
<citcontext>
<prevsection>
<prevsent>this, in turn, allows us to in form rule learner about which language features can be clustered and handled by single set of rule sand which must be given special attention.
</prevsent>
<prevsent>however, due to the complexity of this component, describing it is beyond the scope of this paper.
</prevsent>
</prevsection>
<citsent citstr=" W07-1315 ">
we also note that future work will include the integration of amorphology analysis system such as paramor (mon sonet al, 2007) <papid> W07-1315 </papid>to extract and annotate the valuable morphosyntactic information of inflected languages.</citsent>
<aftsection>
<nextsent>an example of this processing pipeline is given in figure 4.
</nextsent>
<nextsent>79 feature value candidate morphemes np-gen el, nino np-gen ella, nina np-gen *unobserved* np-def + el, la, las np-def - una, unas np-num sg el, ella, la, una, come, nino, nina np-num dl-pl las, unas, comen, ninas c-ten past-pres ? c-ten fut *unobserved* figure 3: an example of the output of our system for the above corpus: list of feature-morpheme pairings.
</nextsent>
<nextsent>elicitation corpus inductive feature detection morphosyntactic lexicon generator unsupervised morphology induction grammar rule learner decoder figure 4: an outline of the steps from an input elicitation corpus to the application of morpho syntactically feature rich grammar in mt decoder.
</nextsent>
<nextsent>this paper discusses the highlighted inductive feature detection component.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD165">
<title id=" W08-0410.xml">inductive detection of language features via clustering minimal pairs toward feature rich grammars in machine translation </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>a.sg student named irshad who fish for water in flour throw prog.sg.m be.past.sg.m student named irshad who was throwing flour in the water for the fish . . .
</prevsent>
<prevsent>figure 5: glossed example from parallel text in ldcs urdu-english lctl language pack showing subject-verb agreement being separated by 12 words.
</prevsent>
</prevsection>
<citsent citstr=" P05-1067 ">
ment if it produced target-side dependency tree as in ding and palmer (2005).<papid> P05-1067 </papid></citsent>
<aftsection>
<nextsent>however, we are not aware of any systems that attempt this.
</nextsent>
<nextsent>therefore,the correct hypotheses, which have correct agreement, will likely be produces as hypotheses of traditional beam-search mt systems, but their features might not be able to discern the correct hypothesis, allowing it to fall below the 1-best or out of thebeam entirely.
</nextsent>
<nextsent>by constructing feature-rich grammar in framework that allows unification-based feature constraints such as avenue (carbonell etal., 2002), we can prune these bad hypotheses lacking agreement from the search space.returning to the example of subject-verb agreement, consider the following urdu sentences taken from the urdu-english elicitation corpus in ldcs lctl language pack: danish ne amna ko sza di danish erg amna dat punish give.perf danish punished amna.?
</nextsent>
<nextsent>danish amna ko sza dita hai danish amna dat punish give.hab be.pres danish punishes amna.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD166">
<title id=" W08-0410.xml">inductive detection of language features via clustering minimal pairs toward feature rich grammars in machine translation </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>certainly, unification-based grammars are not the 1if the reader is not familiar with unification grammars, we recommend kaplan (1995)only way in which this rich source of linguistic information could be used to augment structure-based translation system.
</prevsent>
<prevsent>one could also imagine system in which the feature annotations are simply used to improve the discriminative power of model.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
for example, factored translation models (koehn and hoang, 2007) <papid> D07-1091 </papid>retain the simplicity of phrase-basedsmt while adding the ability to incorporate additional features.</citsent>
<aftsection>
<nextsent>similarly, there exists continuum of degrees to which this linguistic information can be used in current syntax-based mt systems.
</nextsent>
<nextsent>as modern systems move toward integrating many features (liang et al, 2006), <papid> P06-1096 </papid>resources such as this will become increasingly important in improving translation quality.</nextsent>
<nextsent>in the following sections, we will describe the process of inductive feature detection by way of running example.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD167">
<title id=" W08-0410.xml">inductive detection of language features via clustering minimal pairs toward feature rich grammars in machine translation </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>for example, factored translation models (koehn and hoang, 2007) <papid> D07-1091 </papid>retain the simplicity of phrase-basedsmt while adding the ability to incorporate additional features.</prevsent>
<prevsent>similarly, there exists continuum of degrees to which this linguistic information can be used in current syntax-based mt systems.</prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
as modern systems move toward integrating many features (liang et al, 2006), <papid> P06-1096 </papid>resources such as this will become increasingly important in improving translation quality.</citsent>
<aftsection>
<nextsent>in the following sections, we will describe the process of inductive feature detection by way of running example.
</nextsent>
<nextsent>5.1 feature specification.
</nextsent>
<nextsent>the first input to our system is feature specification(figure 1).
</nextsent>
<nextsent>the feature specification used for this experiment was written by an expert in language typology and is stored in human-readable xml format.it is intended to cover large number of phenomena that are possible in the languages of the world.note that features beginning with np- are participant (noun) features while features beginning withc- are clause features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD168">
<title id=" W08-0410.xml">inductive detection of language features via clustering minimal pairs toward feature rich grammars in machine translation </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the last two function feature sand their values tell us what possible roles participants and clauses can take in sentences.
</prevsent>
<prevsent>81 5.2 elicitation corpus.
</prevsent>
</prevsection>
<citsent citstr=" N06-2002 ">
as outlined in section 3, feature detection uses an elicitation corpus (see figure 2), corpus that hasbeen carefully constructed to provide large number of minimal pairs of sentences such as he sing sand she sings so that only single feature (e.g. gen der) differs between the two sentences (levin et al,2006; alvarez et al, 2006).<papid> N06-2002 </papid></citsent>
<aftsection>
<nextsent>if two features had varied at once (e.g. it sang) or lexical choice varied (e.g. she reads), then making assertions about which features the language does and does not express becomes much more difficult.
</nextsent>
<nextsent>notice that each input sentence has been tagged with an identifier for lexical cluster as preprocessing step.
</nextsent>
<nextsent>specifying lexical clusters ensures that we dont compare sentences with different content just because their feature structures match.
</nextsent>
<nextsent>for example, we would not want to compare dog bites man and man bites dog nor the student snored and the professor snored.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD169">
<title id=" W07-2057.xml">pnnl a supervised maximum entropy approach to word sense disambiguation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>in our earlier paper (sanfilippo et al, 2006), we reported that the pnnl wsd system exceeded the performance of the best performers for verbs in the senseval-3 english all words task dataset.
</prevsent>
<prevsent>semeval 2007 is our first opportunity to enter word sense disambiguation competition.
</prevsent>
</prevsection>
<citsent citstr=" W04-0811 ">
while many unsupervised word sense disambiguation systems have been created, supervised systems have generally produced superior results (snyder and palmer, 2004; <papid> W04-0811 </papid>mihalcea et al, 2004).<papid> W04-0807 </papid></citsent>
<aftsection>
<nextsent>our system is based on supervised wsd approach that uses maximum entropy classifier to predict wordnet senses.
</nextsent>
<nextsent>we use semcor1, omwe 1.0 (chklovski and mihalcea, 2002), <papid> W02-0817 </papid>and example sentences in wordnet as the training corpus.</nextsent>
<nextsent>we utilize the opennlp maxent implementation2 of the maximum entropy classification algorithm (berger et al., 1996) <papid> J96-1002 </papid>to train classification models for each lemma and part-of-speech combination in the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD170">
<title id=" W07-2057.xml">pnnl a supervised maximum entropy approach to word sense disambiguation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>in our earlier paper (sanfilippo et al, 2006), we reported that the pnnl wsd system exceeded the performance of the best performers for verbs in the senseval-3 english all words task dataset.
</prevsent>
<prevsent>semeval 2007 is our first opportunity to enter word sense disambiguation competition.
</prevsent>
</prevsection>
<citsent citstr=" W04-0807 ">
while many unsupervised word sense disambiguation systems have been created, supervised systems have generally produced superior results (snyder and palmer, 2004; <papid> W04-0811 </papid>mihalcea et al, 2004).<papid> W04-0807 </papid></citsent>
<aftsection>
<nextsent>our system is based on supervised wsd approach that uses maximum entropy classifier to predict wordnet senses.
</nextsent>
<nextsent>we use semcor1, omwe 1.0 (chklovski and mihalcea, 2002), <papid> W02-0817 </papid>and example sentences in wordnet as the training corpus.</nextsent>
<nextsent>we utilize the opennlp maxent implementation2 of the maximum entropy classification algorithm (berger et al., 1996) <papid> J96-1002 </papid>to train classification models for each lemma and part-of-speech combination in the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD171">
<title id=" W07-2057.xml">pnnl a supervised maximum entropy approach to word sense disambiguation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>while many unsupervised word sense disambiguation systems have been created, supervised systems have generally produced superior results (snyder and palmer, 2004; <papid> W04-0811 </papid>mihalcea et al, 2004).<papid> W04-0807 </papid></prevsent>
<prevsent>our system is based on supervised wsd approach that uses maximum entropy classifier to predict wordnet senses.</prevsent>
</prevsection>
<citsent citstr=" W02-0817 ">
we use semcor1, omwe 1.0 (chklovski and mihalcea, 2002), <papid> W02-0817 </papid>and example sentences in wordnet as the training corpus.</citsent>
<aftsection>
<nextsent>we utilize the opennlp maxent implementation2 of the maximum entropy classification algorithm (berger et al., 1996) <papid> J96-1002 </papid>to train classification models for each lemma and part-of-speech combination in the training corpus.</nextsent>
<nextsent>these models are used to predict wordnet senses for words found in natural text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD172">
<title id=" W07-2057.xml">pnnl a supervised maximum entropy approach to word sense disambiguation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>our system is based on supervised wsd approach that uses maximum entropy classifier to predict wordnet senses.
</prevsent>
<prevsent>we use semcor1, omwe 1.0 (chklovski and mihalcea, 2002), <papid> W02-0817 </papid>and example sentences in wordnet as the training corpus.</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we utilize the opennlp maxent implementation2 of the maximum entropy classification algorithm (berger et al., 1996) <papid> J96-1002 </papid>to train classification models for each lemma and part-of-speech combination in the training corpus.</citsent>
<aftsection>
<nextsent>these models are used to predict wordnet senses for words found in natural text.
</nextsent>
<nextsent>for lemma and part-of-speech combinations that are not present in the training corpus, the pnnl wsd system defaults to the most frequent wordnet sense.
</nextsent>
<nextsent>2.1 features.
</nextsent>
<nextsent>we use rich set of features to predict individual word senses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD173">
<title id=" W07-2057.xml">pnnl a supervised maximum entropy approach to word sense disambiguation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>we use rich set of features to predict individual word senses.
</prevsent>
<prevsent>a large number of features are extracted for each word sense instance in the training data.
</prevsent>
</prevsection>
<citsent citstr=" P05-1006 ">
following dang &amp; palmer (2005) <papid> P05-1006 </papid>and kohomban &amp; lee (2005), <papid> P05-1005 </papid>we use contextual, syntactic and semantic information to inform our word 1 http://www.cs.unt.edu/~rada/downloads.html.</citsent>
<aftsection>
<nextsent>2 http://maxent.sourceforge.net/.
</nextsent>
<nextsent>264 sense disambiguation system.
</nextsent>
<nextsent>however, there are significant differences between the specific types of contextual, syntactic and semantic information we use in our system and those proposed by dang &amp; palmer (2005) <papid> P05-1006 </papid>and kohomban &amp; lee (2005).<papid> P05-1005 </papid></nextsent>
<nextsent>more specifically, we employ novel features and feature combinations, as described below.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD175">
<title id=" W07-2057.xml">pnnl a supervised maximum entropy approach to word sense disambiguation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>we use rich set of features to predict individual word senses.
</prevsent>
<prevsent>a large number of features are extracted for each word sense instance in the training data.
</prevsent>
</prevsection>
<citsent citstr=" P05-1005 ">
following dang &amp; palmer (2005) <papid> P05-1006 </papid>and kohomban &amp; lee (2005), <papid> P05-1005 </papid>we use contextual, syntactic and semantic information to inform our word 1 http://www.cs.unt.edu/~rada/downloads.html.</citsent>
<aftsection>
<nextsent>2 http://maxent.sourceforge.net/.
</nextsent>
<nextsent>264 sense disambiguation system.
</nextsent>
<nextsent>however, there are significant differences between the specific types of contextual, syntactic and semantic information we use in our system and those proposed by dang &amp; palmer (2005) <papid> P05-1006 </papid>and kohomban &amp; lee (2005).<papid> P05-1005 </papid></nextsent>
<nextsent>more specifically, we employ novel features and feature combinations, as described below.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD179">
<title id=" W07-2057.xml">pnnl a supervised maximum entropy approach to word sense disambiguation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>syntactic information.
</prevsent>
<prevsent>we include grammatical dependencies (e.g. subject, object) and mor pho-syntactic features such as part of speech, case, number and tense.
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
we use the conn exor parser3 (tapanainen and jrvinen, 1997) <papid> A97-1011 </papid>to extract lemma information, parts of speech, syntactic dependencies, tense, case, and number information.</citsent>
<aftsection>
<nextsent>a sample output of conn exor parse is given in table 1.
</nextsent>
<nextsent>features are extracted for all tokens that are related through no more than 3 levels of dependency to the word to be disambiguated.
</nextsent>
<nextsent>semantic information.
</nextsent>
<nextsent>the semantic information we incorporate includes named entity types (e.g. person, location, organi zation) and hypernyms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD182">
<title id=" W07-2057.xml">pnnl a supervised maximum entropy approach to word sense disambiguation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>upali s. kohomban and wee sun lee provided us with the results file for the simil-prime system (kohomban and lee, 2005).<papid> P05-1005 </papid></prevsent>
<prevsent>as reported in sanfilippo et al (2006) and shown in table 3, our results for verbs rival those of top performers.</prevsent>
</prevsection>
<citsent citstr=" W04-0838 ">
we had significant improvement (p-value 0.05) over the baseline of 52.9%, marginal improvement over the second best performer (senselearner) (mihal cea and faruque, 2004), <papid> W04-0838 </papid>and we were as good as the top performer (gambl) (decadt et al, 2004).<papid> W04-0827 </papid>7 system precision fraction of recall our system 61% 22% gambl 59.0% 21.3% sense learner 56.1% 20.2% baseline 52.9% 19.1% table 3.</citsent>
<aftsection>
<nextsent>results for verb sense disambiguation on senseval-3 data, adapted from sanfilippo et al (2006).
</nextsent>
<nextsent>since then, we have expanded our evaluation to all parts of speech.
</nextsent>
<nextsent>table 4 provides the evaluation 6 http://www.senseval.org/.
</nextsent>
<nextsent>7 the 2% improvement in precision which our system showed as compared to gambl was not statistically significant (p=0.21).of our system as compared to the three topper formers on the senseval-3 data and the baseline.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD183">
<title id=" W07-2057.xml">pnnl a supervised maximum entropy approach to word sense disambiguation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>upali s. kohomban and wee sun lee provided us with the results file for the simil-prime system (kohomban and lee, 2005).<papid> P05-1005 </papid></prevsent>
<prevsent>as reported in sanfilippo et al (2006) and shown in table 3, our results for verbs rival those of top performers.</prevsent>
</prevsection>
<citsent citstr=" W04-0827 ">
we had significant improvement (p-value 0.05) over the baseline of 52.9%, marginal improvement over the second best performer (senselearner) (mihal cea and faruque, 2004), <papid> W04-0838 </papid>and we were as good as the top performer (gambl) (decadt et al, 2004).<papid> W04-0827 </papid>7 system precision fraction of recall our system 61% 22% gambl 59.0% 21.3% sense learner 56.1% 20.2% baseline 52.9% 19.1% table 3.</citsent>
<aftsection>
<nextsent>results for verb sense disambiguation on senseval-3 data, adapted from sanfilippo et al (2006).
</nextsent>
<nextsent>since then, we have expanded our evaluation to all parts of speech.
</nextsent>
<nextsent>table 4 provides the evaluation 6 http://www.senseval.org/.
</nextsent>
<nextsent>7 the 2% improvement in precision which our system showed as compared to gambl was not statistically significant (p=0.21).of our system as compared to the three topper formers on the senseval-3 data and the baseline.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD185">
<title id=" W07-1103.xml">design and implementation of a lexicon of dutch multiword expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mwes are known to be problematic for natural language processing.
</prevsent>
<prevsent>a considerable amount of research has been conducted in this area.
</prevsent>
</prevsection>
<citsent citstr=" W06-1203 ">
most progress has been made especially in the field of multiword identification (villada moiron and tiedemann, 2006; katz and giesbrecht, 2006; <papid> W06-1203 </papid>zhang et al , 2006).<papid> W06-1206 </papid></citsent>
<aftsection>
<nextsent>moreover, interesting papers have been written on the representation of mwes, most of them focusing on single class of mwes, see section 2.
</nextsent>
<nextsent>this paper elaborates on standard lexical representation for dutch mwes developed within the stevin irme project.1 part of the project focused on the design and implementation of an electronic resource of 5,000 dutch expressions that meets the criterion of being highly theory- and implementation-independent, and which can be used in various dutch nlp systems.
</nextsent>
<nextsent>the selection of the lexical entries and their properties is corpus-based.
</nextsent>
<nextsent>work has been conducted on collecting dutch mwes in the past, yielding one commercial printed dictionary (de groot, 1999), and an electronic resource called the referentiebestand nederlands (reference database of the dutch language?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD186">
<title id=" W07-1103.xml">design and implementation of a lexicon of dutch multiword expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mwes are known to be problematic for natural language processing.
</prevsent>
<prevsent>a considerable amount of research has been conducted in this area.
</prevsent>
</prevsection>
<citsent citstr=" W06-1206 ">
most progress has been made especially in the field of multiword identification (villada moiron and tiedemann, 2006; katz and giesbrecht, 2006; <papid> W06-1203 </papid>zhang et al , 2006).<papid> W06-1206 </papid></citsent>
<aftsection>
<nextsent>moreover, interesting papers have been written on the representation of mwes, most of them focusing on single class of mwes, see section 2.
</nextsent>
<nextsent>this paper elaborates on standard lexical representation for dutch mwes developed within the stevin irme project.1 part of the project focused on the design and implementation of an electronic resource of 5,000 dutch expressions that meets the criterion of being highly theory- and implementation-independent, and which can be used in various dutch nlp systems.
</nextsent>
<nextsent>the selection of the lexical entries and their properties is corpus-based.
</nextsent>
<nextsent>work has been conducted on collecting dutch mwes in the past, yielding one commercial printed dictionary (de groot, 1999), and an electronic resource called the referentiebestand nederlands (reference database of the dutch language?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD187">
<title id=" W07-1103.xml">design and implementation of a lexicon of dutch multiword expressions </title>
<section> related research: classes and.  </section>
<citcontext>
<prevsection>
<prevsent>work on this topic has been conducted for other languages, which in most cases focused on single subtype.
</prevsent>
<prevsent>both dor meyer and fischer (1998) and fellbaum et al  (2006) report on work on resource for german verbal idioms, while the representation of german pp-verb collocations is addressed in (krenn, 2000).
</prevsent>
</prevsection>
<citsent citstr=" W04-0411 ">
kuiper et al  (2003) worked on representation of english idioms, and villavicencio et al  (2004) <papid> W04-0411 </papid>proposed lexical encoding of mwes in general, by analysing english idioms and verb-partical constructions.</citsent>
<aftsection>
<nextsent>except for thesaid-database (kuiper et al , 2003), which comprises over 13,000 expression, the created resources contain no more than 1,000 high-frequent expressions.
</nextsent>
<nextsent>both fellbaum et al  and krenn support their lexical annotation with corpus-based investigation.in our approach, we also use data extracted from corpora as empirical material, see section 3.2.in most resources addressed, some kind of syntactic analysis is assigned to individual expressions.
</nextsent>
<nextsent>the most sophisticated syntactic analysis is done in the said-database.
</nextsent>
<nextsent>the approach taken bykuiper et al  (2003) would have been more theory independent, if it included textual description, according to which classes of idioms could be formed.villavicencio et al  (2004) <papid> W04-0411 </papid>defined specific meta type for each particular class of mwes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD191">
<title id=" W07-1502.xml">efficient annotation with the jena annotation environment jane </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>annotation of language resources, however, has become bottleneck since it is performed, with some automatic support (pre-annotation) though, by humans.
</prevsent>
<prevsent>hence, annotation is time-costly and error-prone process.the demands for annotated language data is increasing at different levels.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
after the success in syntactic (penn treebank (marcus et al, 1993)) <papid> J93-2004 </papid>and propositional encodings (penn propbank (palmer et al., 2005)), <papid> J05-1004 </papid>more sophisticated semantic data (suchas temporal (pustejovsky et al, 2003) or opinion annotations (wiebe et al, 2005)) and discourse data(e.g., for anaphora resolution (van deemter and kib ble, 2000) and rhetorical parsing (carlson et al, 2003)) are being generated.</citsent>
<aftsection>
<nextsent>once the ubiquitous area of newswire articles is left behind, different domains (e.g., the life sciences (ohta et al, 2002)) are yet another major concern.
</nextsent>
<nextsent>furthermore, any newhlt application (e.g., information extraction, document summarization) makes it necessary to provide appropriate human annotation products.
</nextsent>
<nextsent>besides these considerations, the whole field of non english languages is desperately seeking to enter into enormous annotation efforts, at virtually all encoding levels, to keep track of methodological requirements imposed by such resource-intensive research activities.given this enormous need for high-quality annotations at virtually all levels the question turns uphow to minimize efforts within an acceptable quality window.
</nextsent>
<nextsent>currently, for most tasks several hundreds of thousands of text tokens (ranging between200,000 to 500,000 text tokens) have to be scrutinized unless valid tagging judgments can be learned.while significant time savings have already been reported on the basis of automatic pre-tagging (e.g.,for pos and parse tree taggings in the penn tree bank (marcus et al, 1993), <papid> J93-2004 </papid>or named entity taggings for the genia corpus (ohta et al, 2002)), this kind of pre-processing does not reduce the number of text tokens actually to be considered.we have developed the jena annotation environment (jane) that allows to reduce annotation efforts by means of the active learning (al) approach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD192">
<title id=" W07-1502.xml">efficient annotation with the jena annotation environment jane </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>annotation of language resources, however, has become bottleneck since it is performed, with some automatic support (pre-annotation) though, by humans.
</prevsent>
<prevsent>hence, annotation is time-costly and error-prone process.the demands for annotated language data is increasing at different levels.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
after the success in syntactic (penn treebank (marcus et al, 1993)) <papid> J93-2004 </papid>and propositional encodings (penn propbank (palmer et al., 2005)), <papid> J05-1004 </papid>more sophisticated semantic data (suchas temporal (pustejovsky et al, 2003) or opinion annotations (wiebe et al, 2005)) and discourse data(e.g., for anaphora resolution (van deemter and kib ble, 2000) and rhetorical parsing (carlson et al, 2003)) are being generated.</citsent>
<aftsection>
<nextsent>once the ubiquitous area of newswire articles is left behind, different domains (e.g., the life sciences (ohta et al, 2002)) are yet another major concern.
</nextsent>
<nextsent>furthermore, any newhlt application (e.g., information extraction, document summarization) makes it necessary to provide appropriate human annotation products.
</nextsent>
<nextsent>besides these considerations, the whole field of non english languages is desperately seeking to enter into enormous annotation efforts, at virtually all encoding levels, to keep track of methodological requirements imposed by such resource-intensive research activities.given this enormous need for high-quality annotations at virtually all levels the question turns uphow to minimize efforts within an acceptable quality window.
</nextsent>
<nextsent>currently, for most tasks several hundreds of thousands of text tokens (ranging between200,000 to 500,000 text tokens) have to be scrutinized unless valid tagging judgments can be learned.while significant time savings have already been reported on the basis of automatic pre-tagging (e.g.,for pos and parse tree taggings in the penn tree bank (marcus et al, 1993), <papid> J93-2004 </papid>or named entity taggings for the genia corpus (ohta et al, 2002)), this kind of pre-processing does not reduce the number of text tokens actually to be considered.we have developed the jena annotation environment (jane) that allows to reduce annotation efforts by means of the active learning (al) approach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD194">
<title id=" W07-1502.xml">efficient annotation with the jena annotation environment jane </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>reduction of efforts for training (semi-) supervised learners on annotated language data has always beenan issue of concern.
</prevsent>
<prevsent>semi-supervised learning provides methods to bootstrap annotated corpora from asmall number of manually labeled examples.
</prevsent>
</prevsection>
<citsent citstr=" W01-0501 ">
how ever, it has been shown (pierce and cardie, 2001) <papid> W01-0501 </papid>that semi-supervised learning is brittle for nlp tasks where typically large amounts of high quality annotations are needed to train appropriate classifiers.</citsent>
<aftsection>
<nextsent>another approach to reducing the human labeling effort is active learning (al) where the learner has direct influence on the examples to be manually labeled.
</nextsent>
<nextsent>in such setting, those examples are taken for annotation which are assumed to be maximally useful for (classifier) training.
</nextsent>
<nextsent>al approaches have already been tried for different nlp tasks (engelson and dagan, 1996; <papid> P96-1042 </papid>hwa, 2000; <papid> W00-1306 </papid>ngai and yarowsky,2000), <papid> P00-1016 </papid>though such studies usually report on simulations rather than on concrete experience with al for real annotation efforts.</nextsent>
<nextsent>in their study on al for base noun phrase chunking, ngai and yarowsky (2000) <papid> P00-1016 </papid>compare the costs of rule-writing with (al-driven) annotation to compile base noun phrase chunker.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD195">
<title id=" W07-1502.xml">efficient annotation with the jena annotation environment jane </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>another approach to reducing the human labeling effort is active learning (al) where the learner has direct influence on the examples to be manually labeled.
</prevsent>
<prevsent>in such setting, those examples are taken for annotation which are assumed to be maximally useful for (classifier) training.
</prevsent>
</prevsection>
<citsent citstr=" P96-1042 ">
al approaches have already been tried for different nlp tasks (engelson and dagan, 1996; <papid> P96-1042 </papid>hwa, 2000; <papid> W00-1306 </papid>ngai and yarowsky,2000), <papid> P00-1016 </papid>though such studies usually report on simulations rather than on concrete experience with al for real annotation efforts.</citsent>
<aftsection>
<nextsent>in their study on al for base noun phrase chunking, ngai and yarowsky (2000) <papid> P00-1016 </papid>compare the costs of rule-writing with (al-driven) annotation to compile base noun phrase chunker.</nextsent>
<nextsent>they conclude that one should rather invest human labor in annotation than in rule writing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD196">
<title id=" W07-1502.xml">efficient annotation with the jena annotation environment jane </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>another approach to reducing the human labeling effort is active learning (al) where the learner has direct influence on the examples to be manually labeled.
</prevsent>
<prevsent>in such setting, those examples are taken for annotation which are assumed to be maximally useful for (classifier) training.
</prevsent>
</prevsection>
<citsent citstr=" W00-1306 ">
al approaches have already been tried for different nlp tasks (engelson and dagan, 1996; <papid> P96-1042 </papid>hwa, 2000; <papid> W00-1306 </papid>ngai and yarowsky,2000), <papid> P00-1016 </papid>though such studies usually report on simulations rather than on concrete experience with al for real annotation efforts.</citsent>
<aftsection>
<nextsent>in their study on al for base noun phrase chunking, ngai and yarowsky (2000) <papid> P00-1016 </papid>compare the costs of rule-writing with (al-driven) annotation to compile base noun phrase chunker.</nextsent>
<nextsent>they conclude that one should rather invest human labor in annotation than in rule writing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD197">
<title id=" W07-1502.xml">efficient annotation with the jena annotation environment jane </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>another approach to reducing the human labeling effort is active learning (al) where the learner has direct influence on the examples to be manually labeled.
</prevsent>
<prevsent>in such setting, those examples are taken for annotation which are assumed to be maximally useful for (classifier) training.
</prevsent>
</prevsection>
<citsent citstr=" P00-1016 ">
al approaches have already been tried for different nlp tasks (engelson and dagan, 1996; <papid> P96-1042 </papid>hwa, 2000; <papid> W00-1306 </papid>ngai and yarowsky,2000), <papid> P00-1016 </papid>though such studies usually report on simulations rather than on concrete experience with al for real annotation efforts.</citsent>
<aftsection>
<nextsent>in their study on al for base noun phrase chunking, ngai and yarowsky (2000) <papid> P00-1016 </papid>compare the costs of rule-writing with (al-driven) annotation to compile base noun phrase chunker.</nextsent>
<nextsent>they conclude that one should rather invest human labor in annotation than in rule writing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD200">
<title id=" W07-1502.xml">efficient annotation with the jena annotation environment jane </title>
<section> experience with real-world annotations.  </section>
<citcontext>
<prevsection>
<prevsent>this amounts to reduction of annotation costs on the order of 75%.
</prevsent>
<prevsent>our real-world annotations revealed that al is especially beneficial when entity mentions are very sparsely distributed in the texts.
</prevsent>
</prevsection>
<citsent citstr=" W04-1221 ">
after an initialization phase needed by al to take off (which can considerably be accelerated when one carefully selects the sentences of the first al round, see section 4.2),al selects, by and large, only sentences which contain at least one entity mention of the type of inter 10the named enatity tagger used throughout in this section is based on conditional random fields and similar to the one presented by (settles, 2004).<papid> W04-1221 </papid></citsent>
<aftsection>
<nextsent>0 500 1000 1500 2000 2500 3000 200 400 600 800 1000 1200 1400 1600 1800 2000 n tit m en tions sentences al annotation gs annotation figure 3: cumulated entity density on aland gs annotations of cytokine receptors.est.
</nextsent>
<nextsent>in contrast, random selection (or in real annotation projects: sequential annotations of abstracts as in our default project mode), may lead to lots of negative training examples with no entity mentions of interest.
</nextsent>
<nextsent>when there is no simulation data at hand, the entity density of al annotations (compared with the respective gs annotation) is good estimate of the effectiveness of al. figure 3 depicts such cumulated entity density plot on aland gs annotations of sub types of cy tokine receptors, really very sparse entity types withone entity mention per pubmed abstract on the average.
</nextsent>
<nextsent>the 250 abstracts of the gs annotation only contain 193 cytokine receptor entity mentions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD201">
<title id=" W07-2101.xml">utdhltcg semantic architecture for metonymy resolution and classification of nominal relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>verbnet2 is broad-coverage, comprehensive verb lexicon created at university of pennsylvania, compatible with wordnet, but with explicitly stated syntactic and semantic information, using levin verb classes(levin, 1993) to systematically construct lexical entities.
</prevsent>
<prevsent>classes are hierarchically organized and each class in the hierarchy has its corresponding syntactic frames, semantic predicates and list of typical verb arguments.
</prevsent>
</prevsection>
<citsent citstr=" W00-0207 ">
the lexical conceptual structure(traum and habash, 2000) <papid> W00-0207 </papid>is compositional abstraction with language-independent properties.</citsent>
<aftsection>
<nextsent>anlcs is directed graph with root.
</nextsent>
<nextsent>each node is associated with certain information, including type, primitive and field.
</nextsent>
<nextsent>an lcs captures the semantics 1http://wordnet.princeton.edu 2http://verbs.colorado.edu/verb-index/verbnet-2.1.tar.gz 454 relation positive example 1.
</nextsent>
<nextsent>cause-effect earplugs relieve the discomfort from traveling with cold allergy or sinus condition..
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD202">
<title id=" W07-2101.xml">utdhltcg semantic architecture for metonymy resolution and classification of nominal relations </title>
<section> semantic tasks.  </section>
<citcontext>
<prevsection>
<prevsent>table 1: examples of semantic relations.
</prevsent>
<prevsent>of lexical item through combination of semantic structure and semantic content.
</prevsent>
</prevsection>
<citsent citstr=" W07-2007 ">
the two semantic tasks addressed in this paper are: classification of semantic relations between nominals (task 4), defined in (girju et al, 2007) and metonymy resolution (task 8), defined in (markert and nissim, 2007).<papid> W07-2007 </papid></citsent>
<aftsection>
<nextsent>please refer to these task description papers for more details.
</nextsent>
<nextsent>both arecast as classification tasks: given an unlabeled instance, system must label it according to one class of set specific to each task.
</nextsent>
<nextsent>the training and testing datasets for the metonymy resolution task are annotated in an xml format.
</nextsent>
<nextsent>there are 1090 training and 842 testing instances for companies, and 941 training and 908 testing instances for locations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD203">
<title id=" W07-2101.xml">utdhltcg semantic architecture for metonymy resolution and classification of nominal relations </title>
<section> semantic architecture.  </section>
<citcontext>
<prevsection>
<prevsent>additionally, for semantic relations classification, the system creates the dependency structures for all the sentences, using the dependency parser built at stanford5 and described in (de marneffe et al, 2006).
</prevsent>
<prevsent>the dependency parser extracts some of 48 grammatical relations for each pair of words in sentence.
</prevsent>
</prevsection>
<citsent citstr=" W05-0635 ">
a second module that is specific only tothis task is (surdeanu and turmo, 2005)<papid> W05-0635 </papid>s semantic role labeler, which extracts the shallow semantic structure for each sentence, that is, the predicates and their arguments.</citsent>
<aftsection>
<nextsent>in order to extract the features for the machine learning algorithm, the modules described above are used, and, in addition, information from wordnet, verbnet and the lcs database is incorporated, 3http://www.cs.jhu.edu/brill/ 4http://people.csail.mit.edu/mcollins/code.html 5http://nlp.stanford.edu/downloads/lex-parser.shtml 455 parser propbank wordnet generation models extraction feature selection feature voting submission generation o de 2 o de 1 o de k verbnet lcs database parser dependency pos tagger tokenizer parser syntactic handcrafted ...
</nextsent>
<nextsent>instances instances annotated figure 1: semantic architecture.
</nextsent>
<nextsent>category feature name feature description syntactic prevpos part of speech of previous word in the sentence nextpos part of speech of next word in the sentence determiner if the word has determiner prep governing if the word is governed by prepositional phrase (pp), we extract the preposition inside quotes if the word is inside quotes lemma post if the word is post modifier for noun, take the lemma of the noun lemma pre if the word is pre modifier for noun, take the lemma of the noun possession if the word is possessor, and what it possesses semantic role the role(s) of the name in the sentence: subject, object, under pp role lemma the combination between the role and the lemma of the verb whose argument the word is rolevn same as above, but using the verbnet class instead of the verbs lemma role levin same as above, but using the levin class instead of the verbs lemma rolelcs same as above, but using lcs primitives from the lcs database instead of the verbs lemma table 2: features for metonymy resolution.along with other features, based on the manual annotations for both the training and testing datasets by the task organizers.
</nextsent>
<nextsent>these other features use the grammatical annotations for the possibly metonymic name, in the case of metonymy resolution, and the query that was used to retrieve that particular instance and the disambiguated wordnet sense for thetwo nominals, in the case of semantic relations classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD204">
<title id=" W07-1109.xml">learning dependency relations of japanese compound functional expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(and) ? ?
</prevsent>
<prevsent>compound functional expression identifying compound functional expression chunking bunsetsu segmentation &amp; dependency analysis bunsetsu segment dependency relation figure 2: overall flow of processing compound functional expressions in japanese sentence lust rated in figure 2.
</prevsent>
</prevsection>
<citsent citstr=" W06-2404 ">
first of all, we assume sequence of morphemes obtained by variant ofchasen with all the compound functional expressions removed from its outputs, as an input to our procedure of identifying compound functional expressions and analyzing their dependency relations.we formalize the task of identifying japanese compound functional expressions in text as machine learning based chunking problem (tsuchiya et al,2006).<papid> W06-2404 </papid></citsent>
<aftsection>
<nextsent>we employ the technique of support vector machines (svms) (vapnik, 1998) as the machine learning technique, which has been successfully applied to various natural language processing tasks including chunking tasks such as phrase chunking and named entity chunking.
</nextsent>
<nextsent>next, against the results of identifying compound functional expressions, we apply the method of dependency analysis based on the cascaded chunking model (kudo and matsumoto, 2002), <papid> W02-2016 </papid>which is simple and efficient because it parses sentence deterministically only deciding whether the current bunsetsu segment modifies the one on its immediate right hand side.</nextsent>
<nextsent>aswe showed in figure 1, identifying compound functional expressions before analyzing dependencies in sentence does actually help deciding dependency relations of compound functional expressions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD205">
<title id=" W07-1109.xml">learning dependency relations of japanese compound functional expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first of all, we assume sequence of morphemes obtained by variant ofchasen with all the compound functional expressions removed from its outputs, as an input to our procedure of identifying compound functional expressions and analyzing their dependency relations.we formalize the task of identifying japanese compound functional expressions in text as machine learning based chunking problem (tsuchiya et al,2006).<papid> W06-2404 </papid></prevsent>
<prevsent>we employ the technique of support vector machines (svms) (vapnik, 1998) as the machine learning technique, which has been successfully applied to various natural language processing tasks including chunking tasks such as phrase chunking and named entity chunking.</prevsent>
</prevsection>
<citsent citstr=" W02-2016 ">
next, against the results of identifying compound functional expressions, we apply the method of dependency analysis based on the cascaded chunking model (kudo and matsumoto, 2002), <papid> W02-2016 </papid>which is simple and efficient because it parses sentence deterministically only deciding whether the current bunsetsu segment modifies the one on its immediate right hand side.</citsent>
<aftsection>
<nextsent>aswe showed in figure 1, identifying compound functional expressions before analyzing dependencies in sentence does actually help deciding dependency relations of compound functional expressions.
</nextsent>
<nextsent>in the experimental evaluation, we focus on 59expressions having balanced distribution of their usages in the newspaper text corpus and are among the most difficult ones in terms of their identification in text.
</nextsent>
<nextsent>we first show that the proposed method of chunking compound functional expressions significantly outperforms existing japanese text processing tools.
</nextsent>
<nextsent>next, we further show that the dependency analysis model of (kudo and matsumoto, 2002) <papid> W02-2016 </papid>applied to the results of identifying compound functional expressions significantly outperforms the one applied to the results without identifying compound functional expressions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD209">
<title id=" W07-1109.xml">learning dependency relations of japanese compound functional expressions </title>
<section> identifying compound functional.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, for examples of compound functional expressions listed in table 2 (a), table 2(b) gives their example sentences as well as the description of their usages.
</prevsent>
<prevsent>expressions by chunking with svms this section describes summaries of formalizing the chunking task using svms (tsuchiya et al, 2006).<papid> W06-2404 </papid></prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
in this paper, we use an svms-based chunking tool yamcha8 (kudo and matsumoto, 2001).<papid> N01-1025 </papid></citsent>
<aftsection>
<nextsent>in the svms-based chunking framework, svms are used as classifiers for assigning labels for representing chunks to each token.
</nextsent>
<nextsent>in our task of chunking japanese compound functional expressions, each 8http://chasen.org/taku/software/ yamcha/ 68 sentence is represented as sequence of morphemes, where morpheme is regarded as token.
</nextsent>
<nextsent>3.1 chunk representation.
</nextsent>
<nextsent>for representing proper chunks, we employ iob2representation, which has been studied well in various chunking tasks of natural language processing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD215">
<title id=" W07-1109.xml">learning dependency relations of japanese compound functional expressions </title>
<section> concluding remarks.  </section>
<citcontext>
<prevsection>
<prevsent>this approach is novel in that it has never been applied to any language so far.
</prevsent>
<prevsent>experimental evaluation showed that the dependency analysis model applied to the results of identifying compound functional expressions significantly outperforms the one applied to the results without identifying compound functional expressions.
</prevsent>
</prevsection>
<citsent citstr=" W04-0405 ">
the proposed framework has advantages over an approach based on manually created rules such as the one in (shudo et al, 2004), <papid> W04-0405 </papid>in that it requires human cost to create manually and maintain those rules.</citsent>
<aftsection>
<nextsent>related works include nivre and nilsson (2004), which reports improvement of swedish parsing when multiword units are manually annotated.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD216">
<title id=" W07-1515.xml">annotating expressions of appraisal in english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the difficulty of the task is assessed by way of an inter-annotator agreement study, based on measures analogous to those used in the muc-7 evaluation.
</prevsent>
<prevsent>the appraisal framework (martin and white, 2005) describes taxonomy of the language employed in communicating evaluation, explaining how users of english convey attitude (emotion, judgement of people and appreciation of objects), engagement (as sess ment of the evaluations of other people) andhow writers may modify the strength of their atti tude/engagement.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
accurate automatic analysis ofthese aspects of language will augment existing research in the fields of sentiment (pang et al, 2002)<papid> W02-1011 </papid>and subjectivity analysis (wiebe et al, 2004), <papid> J04-3002 </papid>but assessing the usefulness of analysis algorithms leveraging the appraisal framework will require test data.</citsent>
<aftsection>
<nextsent>at present there are no machine-readableappraisal-annotated texts publicly available.
</nextsent>
<nextsent>real world instances of appraisal in use are limited to example extracts that demonstrate the theory, coming from wide variety of genres as disparate as news reporting (white, 2002; martin, 2004) and poetry (martin and white, 2005).
</nextsent>
<nextsent>these examples, while useful in demonstrating the various aspects of appraisal, can only be employed in qualitative analysis and would bring about inconsistencies if analysed collectively ? one can expect the writing style to depend upon the genre, resulting insignificantly different syntactic constructions and lexical choices.
</nextsent>
<nextsent>we therefore need to examine appraisal across documents in the same genre and investigate patterns within that particular register.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD217">
<title id=" W07-1515.xml">annotating expressions of appraisal in english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the difficulty of the task is assessed by way of an inter-annotator agreement study, based on measures analogous to those used in the muc-7 evaluation.
</prevsent>
<prevsent>the appraisal framework (martin and white, 2005) describes taxonomy of the language employed in communicating evaluation, explaining how users of english convey attitude (emotion, judgement of people and appreciation of objects), engagement (as sess ment of the evaluations of other people) andhow writers may modify the strength of their atti tude/engagement.
</prevsent>
</prevsection>
<citsent citstr=" J04-3002 ">
accurate automatic analysis ofthese aspects of language will augment existing research in the fields of sentiment (pang et al, 2002)<papid> W02-1011 </papid>and subjectivity analysis (wiebe et al, 2004), <papid> J04-3002 </papid>but assessing the usefulness of analysis algorithms leveraging the appraisal framework will require test data.</citsent>
<aftsection>
<nextsent>at present there are no machine-readableappraisal-annotated texts publicly available.
</nextsent>
<nextsent>real world instances of appraisal in use are limited to example extracts that demonstrate the theory, coming from wide variety of genres as disparate as news reporting (white, 2002; martin, 2004) and poetry (martin and white, 2005).
</nextsent>
<nextsent>these examples, while useful in demonstrating the various aspects of appraisal, can only be employed in qualitative analysis and would bring about inconsistencies if analysed collectively ? one can expect the writing style to depend upon the genre, resulting insignificantly different syntactic constructions and lexical choices.
</nextsent>
<nextsent>we therefore need to examine appraisal across documents in the same genre and investigate patterns within that particular register.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD218">
<title id=" W07-1515.xml">annotating expressions of appraisal in english </title>
<section> measuring inter-annotator agreement.  </section>
<citcontext>
<prevsection>
<prevsent>freedom in this task prohibits meaningful application of this measure.
</prevsent>
<prevsent>for example, consider howword sense annotators are obliged to choose from limited fixed set of senses for each token, whereas judges annotating appraisal are free to select one of thirty-two classes for any contiguous substring of any length within each document; there are 16 ( n2 ? )possible choices in document of tokens (approxi mately 6.5 ? 108 possibilities in this corpus).a wide range of evaluation metrics have been employed by the message understanding conferences (mucs).
</prevsent>
</prevsection>
<citsent citstr=" M98-0023 ">
the muc-7 tasks included extraction of named entities, equivalence classes, attributes, fact sand events (chinchor, 1998).<papid> M98-0023 </papid></citsent>
<aftsection>
<nextsent>the participating systems were evaluated using variety of related measures, defined in table 3.
</nextsent>
<nextsent>these tasks are similar to appraisal annotation in that the units are formed of an arbitrary number of contiguous tokens.in this study the agreement exhibited by an annotator is evaluated as pair-wise comparison against the other annotator b. annotator provides 96 cor number correct inc number incorrect mis number missing spu number spurious pos number possible = cor + inc + mis act number actual = cor + inc + spu fsc f-score = (2 ? rec ? pre) / (rec + pre) rec precision = cor/pos pre recall = cor/act sub substitution = inc/ (cor + inc) err error per response = (inc + spu + mis) / (cor + inc + spu + mis) und under-generation = mis/pos ovg over-generation = spu/act table 3: muc-7 score definitions (chinchor 1998).<papid> M98-0023 </papid></nextsent>
<nextsent>fsc rec pre err und ovg 0.682 0.706 0.660 0.482 0.294 0.340 0.715 0.667 0.770 0.444 0.333 0.230 x?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD221">
<title id=" W07-1515.xml">annotating expressions of appraisal in english </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this highlights problem with the coding scheme, which simplifies the task by assuming only one type of appraisal is conveyed by each unit.
</prevsent>
<prevsent>taboada and grieve (2004) initiated computational experimentation with the appraisal framework, assigning adjectives into one of the three broad attitude classes.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
the authors apply so-pmi-ir (turney,2002) <papid> P02-1053 </papid>to extract and determine the polarity of adjectives.</citsent>
<aftsection>
<nextsent>they then use variant of so-pmi-ir to determine potential?
</nextsent>
<nextsent>value for affect, judgement and appreciation, calculating the mutual information between the adjective and three pronoun-copular pairs:i was (affect); he was (judgement) and it was (appreciation).
</nextsent>
<nextsent>while the pairs seem compelling markers of the respective attitude types, they incorrectly assume that appraisals of affect are limited to the first person whilst judgements are made only of the third person.
</nextsent>
<nextsent>we can expect high degree of overlap between the sets of documents retrieved by queries formed using these pairs (e.g. was happy x?; he was happy x?; it was happy x?).whitelaw et al (2005) use the appraisal framework to specify frames of sentiment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD224">
<title id=" W08-0206.xml">the evolution of a statistical nlp course </title>
<section> reading material.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, nlp papers that apply these algorithm sto nlp tasks often assume that the readers areal ready familiar with the algorithms and consequently do not explain the algorithms in detail.
</prevsent>
<prevsent>because it is hard to find suitable paper to cover all the theoretic and application aspects of learning algorithm, chose several papers for each algorithm and specified the sections that the students should focus on.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
for instance, for maximum entropy, picked (berger et al, 1996; <papid> J96-1002 </papid>ratnaparkhi, 1997) forthe basic theory, (ratnaparkhi, 1996) <papid> W96-0213 </papid>for an application (pos tagging in this case), and (klein and manning, 2003) for more advanced topics such as optimization and smoothing.</citsent>
<aftsection>
<nextsent>for the more sophisticated learning methods (e.g., maxent and svm), it is very important for students to read the assigned papers beforehand.
</nextsent>
<nextsent>however,some students choose not to do so for various rea sons; meanwhile, other students might spend toomuch time trying to understand everything in the papers.
</nextsent>
<nextsent>to address this problem, in year 3 added five reading assignments, one for each of the following topics: information theory, naive bayes, maxent, svm, and tbl.
</nextsent>
<nextsent>each assignment consists of simple questions such as the one in appendix a. students were asked to turn in their answers to the questions before class.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD225">
<title id=" W08-0206.xml">the evolution of a statistical nlp course </title>
<section> reading material.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, nlp papers that apply these algorithm sto nlp tasks often assume that the readers areal ready familiar with the algorithms and consequently do not explain the algorithms in detail.
</prevsent>
<prevsent>because it is hard to find suitable paper to cover all the theoretic and application aspects of learning algorithm, chose several papers for each algorithm and specified the sections that the students should focus on.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
for instance, for maximum entropy, picked (berger et al, 1996; <papid> J96-1002 </papid>ratnaparkhi, 1997) forthe basic theory, (ratnaparkhi, 1996) <papid> W96-0213 </papid>for an application (pos tagging in this case), and (klein and manning, 2003) for more advanced topics such as optimization and smoothing.</citsent>
<aftsection>
<nextsent>for the more sophisticated learning methods (e.g., maxent and svm), it is very important for students to read the assigned papers beforehand.
</nextsent>
<nextsent>however,some students choose not to do so for various rea sons; meanwhile, other students might spend toomuch time trying to understand everything in the papers.
</nextsent>
<nextsent>to address this problem, in year 3 added five reading assignments, one for each of the following topics: information theory, naive bayes, maxent, svm, and tbl.
</nextsent>
<nextsent>each assignment consists of simple questions such as the one in appendix a. students were asked to turn in their answers to the questions before class.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD226">
<title id=" W08-0206.xml">the evolution of a statistical nlp course </title>
<section> implementation issues.  </section>
<citcontext>
<prevsection>
<prevsent>two examples are given below.
</prevsent>
<prevsent>while such tricks are well-known to nlp researchers, they are often new to students and going through them inclass can help students to speed up their code significantly.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
the trainer for tbl as described in (brill, 1995), <papid> J95-4004 </papid>tbl trainer picks one transformation in each iteration, applies it to the training data, and repeats the process until no more good transformations can be found.</citsent>
<aftsection>
<nextsent>to choose thebest transformation, naive approach would enumerate all the possible transformations, for each transformation go through the data once to calculate the net gain, and choose the transformation with the highest net gain.
</nextsent>
<nextsent>this approach is very inefficient as the data have to be scanned through multiple times.3 3let nf be the number of features and nc be the number of classes in classification task, the number of transformations in the form we specified above is o(nfn2c ), which means that the learner has to go through the data o(nfn2c ) times.
</nextsent>
<nextsent>a much better implementation would be to go through the training data only once, and for each feature in each training instance, update the net gains of the corresponding transformations accordingly.4 students were also encouraged to read (ngai and florian, 2001), which proposed another efficient implementation of tbl.
</nextsent>
<nextsent>the decoder for naive bayes in the multi-variate bernoulli event model for the text classification task (mccallum and nigam, 1998), at the test time the class for document is chosen according to eq (1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD231">
<title id=" W08-0315.xml">the talpupc ngrambased statistical machine translation system for aclwmt 2008 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, this system introduces target language model, based on linguistic classes (part-of-speech), morphology reduction for an inflectional language (spanish) and an improved optimization procedure.
</prevsent>
<prevsent>results obtained over the development and test sets on spanish to english (and the other way round) translations for both the traditional europarl and challenging news stories tasks are analyzed and commented.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
over the past few years, the statistical machine translation (smt) group of the talp-upc has been developing the ngram-based smt system (mario et al, 2006).in previous evaluation campaigns the ngram-based approach has proved to be comparable with the state-of the-art phrase-based systems, as shown in koehn and monz(2006), <papid> W06-3114 </papid>callison-burch et al (2007).we present summary of the talp-upc ngrambased smt system used for this shared task.</citsent>
<aftsection>
<nextsent>we discuss the system configuration and novel features, namely linguistically motivated reordering technique, which is applied on the decoding step.
</nextsent>
<nextsent>additionally, the reordering procedure is supported by an ngram language model (lm) of reordered source part-of-speech tags (pos).
</nextsent>
<nextsent>in this years evaluation we submitted systems for spanish-english and english-spanish language pairs for the traditional (europarl) and challenging (news) tasks.in each case, we used only the supplied data for each language pair for models training and optimization.
</nextsent>
<nextsent>this paper is organized as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD232">
<title id=" W08-0315.xml">the talpupc ngrambased statistical machine translation system for aclwmt 2008 </title>
<section> ngram-based smt system.  </section>
<citcontext>
<prevsection>
<prevsent>later on, section 4 reports on the experimental setups of the wmt 2008 evaluation campaign.
</prevsent>
<prevsent>in section 5 we sum up the main conclusions from the paper.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
our translation system implements log-linear model in which foreign language sentence fj1 = f1, f2, ..., fj is translated into another language ei1 = f1, f2, ..., ei by searching for the translation hypothesis ei1 maximizing log-linear combination of several feature models (brown et al, 1990): <papid> J90-2002 </papid>ei1 = argmax ei1 { ? m=1 mhm(ei1, fj1 ) } where the feature functions hm refer to the system models and the set of refers to the weights corresponding to these models.</citsent>
<aftsection>
<nextsent>the core part of the system constructed in that wayis translation model, which is based on bilingual grams.
</nextsent>
<nextsent>it actually constitutes an ngram-based lm of bilingual units (called tuples), which approximates the joint probability between the languages under consideration.
</nextsent>
<nextsent>the procedure of tuples extraction from wordto-word alignment according to certain constraints is explained in detail in mario et al (2006).the ngram-based approach differs from the phrase based smt mainly by distinct represent ating of the bilingual units defined by word alignment and using higher 127 order hmm of the translation process.
</nextsent>
<nextsent>while regularphrase-based smt considers context only for phrase reordering but not for translation, the n-gram based approach conditions translation decisions on previous translation decisions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD233">
<title id=" W08-0315.xml">the talpupc ngrambased statistical machine translation system for aclwmt 2008 </title>
<section> ngram-based smt system.  </section>
<citcontext>
<prevsection>
<prevsent>while regularphrase-based smt considers context only for phrase reordering but not for translation, the n-gram based approach conditions translation decisions on previous translation decisions.
</prevsent>
<prevsent>the talp-upc 2008 translation system, besides the bilingual translation model, which consists of 4-gram lm of tuples with kneser-ney discounting (estimated with sri language modeling toolkit1), implements log-linear combination of five additional feature models: ? target language model (a 4-gram model of words, estimated with kneser-ney smoothing); ? pos target language model (a 4-gram model of tags with good-turing discounting (tpos)); ? word bonus model, which is used to compensate the systems preference for short output sentences;?
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
a source-to-target lexicon model and target-tosource lexicon model, these models use word-to word ibm model 1 probabilities (och and ney, 2004) <papid> J04-4002 </papid>to estimate the lexical weights for each tuple in the translation table.</citsent>
<aftsection>
<nextsent>decisions on the particular lm configuration and smoothing technique were taken on the minimal perplexity and maximal-bleu bases.
</nextsent>
<nextsent>the decoder (called marie), an open source tool2,implementing beam search strategy with distortion capabilities was used in the translation system.given the development set and references, the loglinear combination of weights was adjusted using simplex optimization method (with the optimization criteria of the highest bleu score ) and an n-best re-ranking just as described in http://www.statmt.org/jhuws/.
</nextsent>
<nextsent>this strategy allows for faster and more efficient adjustment of model weights by means of double-loop optimization, which provides significant reduction of the number of translations that should be carried out.
</nextsent>
<nextsent>for great number of translation tasks certain reordering strategy is required.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD234">
<title id=" W08-0315.xml">the talpupc ngrambased statistical machine translation system for aclwmt 2008 </title>
<section> wmt 2008 evaluation framework.  </section>
<citcontext>
<prevsection>
<prevsent>pos tagging.
</prevsent>
<prevsent>pos information for the source and the target languages was considered for both translation tasks that we have participated.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
the software tools available for performing pos-tagging were free ling (carreras etal., 2004) for spanish and tnt (brants, 2000) <papid> A00-1031 </papid>for en glish.</citsent>
<aftsection>
<nextsent>the number of classes for english is 44, while spanish is considered as more inflectional language, and the tag set contains 376 different tags.word alignment.
</nextsent>
<nextsent>the word alignment is automatically computed by using giza++4(och and ney, 2000) <papid> P00-1056 </papid>in both directions, which are symmetrized by using the union operation.</nextsent>
<nextsent>instead of aligning words themselves, stems are used for aligning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD235">
<title id=" W08-0315.xml">the talpupc ngrambased statistical machine translation system for aclwmt 2008 </title>
<section> wmt 2008 evaluation framework.  </section>
<citcontext>
<prevsection>
<prevsent>the software tools available for performing pos-tagging were free ling (carreras etal., 2004) for spanish and tnt (brants, 2000) <papid> A00-1031 </papid>for en glish.</prevsent>
<prevsent>the number of classes for english is 44, while spanish is considered as more inflectional language, and the tag set contains 376 different tags.word alignment.</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
the word alignment is automatically computed by using giza++4(och and ney, 2000) <papid> P00-1056 </papid>in both directions, which are symmetrized by using the union operation.</citsent>
<aftsection>
<nextsent>instead of aligning words themselves, stems are used for aligning.
</nextsent>
<nextsent>afterwards case sensitive words are recovered.
</nextsent>
<nextsent>spanish morphology reduction.
</nextsent>
<nextsent>we implemented amorphology reduction of the spanish language as preprocessing step.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD236">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic word alignment can be defined as the problem of determining translational correspondences at word level given parallel corpus of aligned sentences.
</prevsent>
<prevsent>bilingual word alignment is afundamental component of most approaches to statistical machine translation (smt).
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
dominant approaches to word alignment can be classified into two main schools: generative and discriminative word alignment models.generative word alignment models, initially developed at ibm (brown et al, 1993), <papid> J93-2003 </papid>and then augmented by an hmm-based model (vogel et al, 1996), <papid> C96-2141 </papid>have provided powerful modeling capability for word alignment.</citsent>
<aftsection>
<nextsent>however, it is very difficult to incorporate new features into these models.
</nextsent>
<nextsent>discriminative word alignment models, based on discriminative training of set of features (liu et al, 2005; <papid> P05-1057 </papid>moore, 2005), <papid> H05-1011 </papid>on the other hand, are more flexible to incorporate new features, and feature selection is essential to the performance of the system.</nextsent>
<nextsent>syntactic annotation of bilingual corpora, which can be obtained more efficiently and accurately with the advances in monolingual language processing,is potential information source for word alignment tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD237">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic word alignment can be defined as the problem of determining translational correspondences at word level given parallel corpus of aligned sentences.
</prevsent>
<prevsent>bilingual word alignment is afundamental component of most approaches to statistical machine translation (smt).
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
dominant approaches to word alignment can be classified into two main schools: generative and discriminative word alignment models.generative word alignment models, initially developed at ibm (brown et al, 1993), <papid> J93-2003 </papid>and then augmented by an hmm-based model (vogel et al, 1996), <papid> C96-2141 </papid>have provided powerful modeling capability for word alignment.</citsent>
<aftsection>
<nextsent>however, it is very difficult to incorporate new features into these models.
</nextsent>
<nextsent>discriminative word alignment models, based on discriminative training of set of features (liu et al, 2005; <papid> P05-1057 </papid>moore, 2005), <papid> H05-1011 </papid>on the other hand, are more flexible to incorporate new features, and feature selection is essential to the performance of the system.</nextsent>
<nextsent>syntactic annotation of bilingual corpora, which can be obtained more efficiently and accurately with the advances in monolingual language processing,is potential information source for word alignment tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD238">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dominant approaches to word alignment can be classified into two main schools: generative and discriminative word alignment models.generative word alignment models, initially developed at ibm (brown et al, 1993), <papid> J93-2003 </papid>and then augmented by an hmm-based model (vogel et al, 1996), <papid> C96-2141 </papid>have provided powerful modeling capability for word alignment.</prevsent>
<prevsent>however, it is very difficult to incorporate new features into these models.</prevsent>
</prevsection>
<citsent citstr=" P05-1057 ">
discriminative word alignment models, based on discriminative training of set of features (liu et al, 2005; <papid> P05-1057 </papid>moore, 2005), <papid> H05-1011 </papid>on the other hand, are more flexible to incorporate new features, and feature selection is essential to the performance of the system.</citsent>
<aftsection>
<nextsent>syntactic annotation of bilingual corpora, which can be obtained more efficiently and accurately with the advances in monolingual language processing,is potential information source for word alignment tasks.
</nextsent>
<nextsent>for example, part-of-speech (pos) tags of source and target words can be used to tackle the data sparseness problem in discriminative word alignment (liu et al, 2005; <papid> P05-1057 </papid>blunsom and cohn,2006).<papid> P06-1009 </papid></nextsent>
<nextsent>shallow parsing has also been used to provide relevant information for alignment (ren et al, 2007; sun et al, 2000).<papid> W00-1314 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD241">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dominant approaches to word alignment can be classified into two main schools: generative and discriminative word alignment models.generative word alignment models, initially developed at ibm (brown et al, 1993), <papid> J93-2003 </papid>and then augmented by an hmm-based model (vogel et al, 1996), <papid> C96-2141 </papid>have provided powerful modeling capability for word alignment.</prevsent>
<prevsent>however, it is very difficult to incorporate new features into these models.</prevsent>
</prevsection>
<citsent citstr=" H05-1011 ">
discriminative word alignment models, based on discriminative training of set of features (liu et al, 2005; <papid> P05-1057 </papid>moore, 2005), <papid> H05-1011 </papid>on the other hand, are more flexible to incorporate new features, and feature selection is essential to the performance of the system.</citsent>
<aftsection>
<nextsent>syntactic annotation of bilingual corpora, which can be obtained more efficiently and accurately with the advances in monolingual language processing,is potential information source for word alignment tasks.
</nextsent>
<nextsent>for example, part-of-speech (pos) tags of source and target words can be used to tackle the data sparseness problem in discriminative word alignment (liu et al, 2005; <papid> P05-1057 </papid>blunsom and cohn,2006).<papid> P06-1009 </papid></nextsent>
<nextsent>shallow parsing has also been used to provide relevant information for alignment (ren et al, 2007; sun et al, 2000).<papid> W00-1314 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD245">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>discriminative word alignment models, based on discriminative training of set of features (liu et al, 2005; <papid> P05-1057 </papid>moore, 2005), <papid> H05-1011 </papid>on the other hand, are more flexible to incorporate new features, and feature selection is essential to the performance of the system.</prevsent>
<prevsent>syntactic annotation of bilingual corpora, which can be obtained more efficiently and accurately with the advances in monolingual language processing,is potential information source for word alignment tasks.</prevsent>
</prevsection>
<citsent citstr=" P06-1009 ">
for example, part-of-speech (pos) tags of source and target words can be used to tackle the data sparseness problem in discriminative word alignment (liu et al, 2005; <papid> P05-1057 </papid>blunsom and cohn,2006).<papid> P06-1009 </papid></citsent>
<aftsection>
<nextsent>shallow parsing has also been used to provide relevant information for alignment (ren et al, 2007; sun et al, 2000).<papid> W00-1314 </papid></nextsent>
<nextsent>deeper syntax, e.g. phrase or dependency structures, has been shown useful in generative models (wang and zhou, 2004; <papid> W04-3226 </papid>lopez and resnik, 2005), <papid> W05-0812 </papid>heuristic-based models (ayan etal., 2004; ozdowska, 2004) <papid> W04-2207 </papid>and even for syntactically motivated models such as itg (wu, 1997; <papid> J97-3002 </papid>cherry and lin, 2006).<papid> P06-2014 </papid>in this paper, we introduce an approach to improve word alignment by incorporating syntactic de pendencies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD246">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>syntactic annotation of bilingual corpora, which can be obtained more efficiently and accurately with the advances in monolingual language processing,is potential information source for word alignment tasks.
</prevsent>
<prevsent>for example, part-of-speech (pos) tags of source and target words can be used to tackle the data sparseness problem in discriminative word alignment (liu et al, 2005; <papid> P05-1057 </papid>blunsom and cohn,2006).<papid> P06-1009 </papid></prevsent>
</prevsection>
<citsent citstr=" W00-1314 ">
shallow parsing has also been used to provide relevant information for alignment (ren et al, 2007; sun et al, 2000).<papid> W00-1314 </papid></citsent>
<aftsection>
<nextsent>deeper syntax, e.g. phrase or dependency structures, has been shown useful in generative models (wang and zhou, 2004; <papid> W04-3226 </papid>lopez and resnik, 2005), <papid> W05-0812 </papid>heuristic-based models (ayan etal., 2004; ozdowska, 2004) <papid> W04-2207 </papid>and even for syntactically motivated models such as itg (wu, 1997; <papid> J97-3002 </papid>cherry and lin, 2006).<papid> P06-2014 </papid>in this paper, we introduce an approach to improve word alignment by incorporating syntactic de pendencies.</nextsent>
<nextsent>our approach is motivated by the fact that words tend to be dependent on each other.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD247">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, part-of-speech (pos) tags of source and target words can be used to tackle the data sparseness problem in discriminative word alignment (liu et al, 2005; <papid> P05-1057 </papid>blunsom and cohn,2006).<papid> P06-1009 </papid></prevsent>
<prevsent>shallow parsing has also been used to provide relevant information for alignment (ren et al, 2007; sun et al, 2000).<papid> W00-1314 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-3226 ">
deeper syntax, e.g. phrase or dependency structures, has been shown useful in generative models (wang and zhou, 2004; <papid> W04-3226 </papid>lopez and resnik, 2005), <papid> W05-0812 </papid>heuristic-based models (ayan etal., 2004; ozdowska, 2004) <papid> W04-2207 </papid>and even for syntactically motivated models such as itg (wu, 1997; <papid> J97-3002 </papid>cherry and lin, 2006).<papid> P06-2014 </papid>in this paper, we introduce an approach to improve word alignment by incorporating syntactic de pendencies.</citsent>
<aftsection>
<nextsent>our approach is motivated by the fact that words tend to be dependent on each other.
</nextsent>
<nextsent>if 69 we can first obtain set of reliable anchor links, we could take advantage of the syntactic dependencies relating unaligned words to aligned anchor words to expand the alignment.
</nextsent>
<nextsent>figure 1 gives an illustratingexample.
</nextsent>
<nextsent>note that the link (2), that the link (4) can be easily identified, but the link involving the fourth chinese word (a function word denoting time?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD248">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, part-of-speech (pos) tags of source and target words can be used to tackle the data sparseness problem in discriminative word alignment (liu et al, 2005; <papid> P05-1057 </papid>blunsom and cohn,2006).<papid> P06-1009 </papid></prevsent>
<prevsent>shallow parsing has also been used to provide relevant information for alignment (ren et al, 2007; sun et al, 2000).<papid> W00-1314 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-0812 ">
deeper syntax, e.g. phrase or dependency structures, has been shown useful in generative models (wang and zhou, 2004; <papid> W04-3226 </papid>lopez and resnik, 2005), <papid> W05-0812 </papid>heuristic-based models (ayan etal., 2004; ozdowska, 2004) <papid> W04-2207 </papid>and even for syntactically motivated models such as itg (wu, 1997; <papid> J97-3002 </papid>cherry and lin, 2006).<papid> P06-2014 </papid>in this paper, we introduce an approach to improve word alignment by incorporating syntactic de pendencies.</citsent>
<aftsection>
<nextsent>our approach is motivated by the fact that words tend to be dependent on each other.
</nextsent>
<nextsent>if 69 we can first obtain set of reliable anchor links, we could take advantage of the syntactic dependencies relating unaligned words to aligned anchor words to expand the alignment.
</nextsent>
<nextsent>figure 1 gives an illustratingexample.
</nextsent>
<nextsent>note that the link (2), that the link (4) can be easily identified, but the link involving the fourth chinese word (a function word denoting time?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD249">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, part-of-speech (pos) tags of source and target words can be used to tackle the data sparseness problem in discriminative word alignment (liu et al, 2005; <papid> P05-1057 </papid>blunsom and cohn,2006).<papid> P06-1009 </papid></prevsent>
<prevsent>shallow parsing has also been used to provide relevant information for alignment (ren et al, 2007; sun et al, 2000).<papid> W00-1314 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-2207 ">
deeper syntax, e.g. phrase or dependency structures, has been shown useful in generative models (wang and zhou, 2004; <papid> W04-3226 </papid>lopez and resnik, 2005), <papid> W05-0812 </papid>heuristic-based models (ayan etal., 2004; ozdowska, 2004) <papid> W04-2207 </papid>and even for syntactically motivated models such as itg (wu, 1997; <papid> J97-3002 </papid>cherry and lin, 2006).<papid> P06-2014 </papid>in this paper, we introduce an approach to improve word alignment by incorporating syntactic de pendencies.</citsent>
<aftsection>
<nextsent>our approach is motivated by the fact that words tend to be dependent on each other.
</nextsent>
<nextsent>if 69 we can first obtain set of reliable anchor links, we could take advantage of the syntactic dependencies relating unaligned words to aligned anchor words to expand the alignment.
</nextsent>
<nextsent>figure 1 gives an illustratingexample.
</nextsent>
<nextsent>note that the link (2), that the link (4) can be easily identified, but the link involving the fourth chinese word (a function word denoting time?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD250">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, part-of-speech (pos) tags of source and target words can be used to tackle the data sparseness problem in discriminative word alignment (liu et al, 2005; <papid> P05-1057 </papid>blunsom and cohn,2006).<papid> P06-1009 </papid></prevsent>
<prevsent>shallow parsing has also been used to provide relevant information for alignment (ren et al, 2007; sun et al, 2000).<papid> W00-1314 </papid></prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
deeper syntax, e.g. phrase or dependency structures, has been shown useful in generative models (wang and zhou, 2004; <papid> W04-3226 </papid>lopez and resnik, 2005), <papid> W05-0812 </papid>heuristic-based models (ayan etal., 2004; ozdowska, 2004) <papid> W04-2207 </papid>and even for syntactically motivated models such as itg (wu, 1997; <papid> J97-3002 </papid>cherry and lin, 2006).<papid> P06-2014 </papid>in this paper, we introduce an approach to improve word alignment by incorporating syntactic de pendencies.</citsent>
<aftsection>
<nextsent>our approach is motivated by the fact that words tend to be dependent on each other.
</nextsent>
<nextsent>if 69 we can first obtain set of reliable anchor links, we could take advantage of the syntactic dependencies relating unaligned words to aligned anchor words to expand the alignment.
</nextsent>
<nextsent>figure 1 gives an illustratingexample.
</nextsent>
<nextsent>note that the link (2), that the link (4) can be easily identified, but the link involving the fourth chinese word (a function word denoting time?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD251">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, part-of-speech (pos) tags of source and target words can be used to tackle the data sparseness problem in discriminative word alignment (liu et al, 2005; <papid> P05-1057 </papid>blunsom and cohn,2006).<papid> P06-1009 </papid></prevsent>
<prevsent>shallow parsing has also been used to provide relevant information for alignment (ren et al, 2007; sun et al, 2000).<papid> W00-1314 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-2014 ">
deeper syntax, e.g. phrase or dependency structures, has been shown useful in generative models (wang and zhou, 2004; <papid> W04-3226 </papid>lopez and resnik, 2005), <papid> W05-0812 </papid>heuristic-based models (ayan etal., 2004; ozdowska, 2004) <papid> W04-2207 </papid>and even for syntactically motivated models such as itg (wu, 1997; <papid> J97-3002 </papid>cherry and lin, 2006).<papid> P06-2014 </papid>in this paper, we introduce an approach to improve word alignment by incorporating syntactic de pendencies.</citsent>
<aftsection>
<nextsent>our approach is motivated by the fact that words tend to be dependent on each other.
</nextsent>
<nextsent>if 69 we can first obtain set of reliable anchor links, we could take advantage of the syntactic dependencies relating unaligned words to aligned anchor words to expand the alignment.
</nextsent>
<nextsent>figure 1 gives an illustratingexample.
</nextsent>
<nextsent>note that the link (2), that the link (4) can be easily identified, but the link involving the fourth chinese word (a function word denoting time?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD253">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> word alignment model.  </section>
<citcontext>
<prevsection>
<prevsent>given source sentence cj1 and target sentence ei1, we seek to find the optimum alignment a?
</prevsent>
<prevsent>such that: a?
</prevsent>
</prevsection>
<citsent citstr=" H05-1012 ">
= argmax p (a|cj1 , ei1) (1)we use model (2) that directly models the linkage between source and target words similarly to (it tycheriah and roukos, 2005).<papid> H05-1012 </papid></citsent>
<aftsection>
<nextsent>we decompose this model into an anchor alignment model (3) and asyntax-enhanced model (4) by distinguishing the anchor alignment from the non-anchor alignment.
</nextsent>
<nextsent>p(a|cj1 , ei1) = ? j=0 p(aj |cj1 , ei1, aj11 ) (2) = 1z ? p?(a?|c 1 , ei1) ?
</nextsent>
<nextsent>(3) ? j???
</nextsent>
<nextsent>p(aj|cj1 , ei1, aj11 , a?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD254">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> word alignment model.  </section>
<citcontext>
<prevsection>
<prevsent>various approaches can be used for this purpose.
</prevsent>
<prevsent>in this paper we adopted the following two approaches.
</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
2.3.1 heuristics-based approach the problem of word alignment is regarded as aprocess of word linkage disambiguation, i.e. choosing the correct links between words from all competing hypothesis (melamed, 2000; <papid> J00-2004 </papid>deng and gao, 2007).<papid> P07-1001 </papid></citsent>
<aftsection>
<nextsent>70 we constrain the link probabilities in such way that: i? ? {1, ..., i}, i?
</nextsent>
<nextsent>6= : p((j, i))p((j, i?))   1 (5) j? ? {1, ..., j}, j?
</nextsent>
<nextsent>6= : p((j, i))p((j?, i))   2 (6) condition (5) implies that for the source word cj , the link with the target word ei is more probable (with reliability threshold 1) than the link with any other target word.
</nextsent>
<nextsent>condition (6) guarantees that for the target word ei, cj is the only most probable (with threshold 2) source word to be linked to.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD256">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> word alignment model.  </section>
<citcontext>
<prevsection>
<prevsent>various approaches can be used for this purpose.
</prevsent>
<prevsent>in this paper we adopted the following two approaches.
</prevsent>
</prevsection>
<citsent citstr=" P07-1001 ">
2.3.1 heuristics-based approach the problem of word alignment is regarded as aprocess of word linkage disambiguation, i.e. choosing the correct links between words from all competing hypothesis (melamed, 2000; <papid> J00-2004 </papid>deng and gao, 2007).<papid> P07-1001 </papid></citsent>
<aftsection>
<nextsent>70 we constrain the link probabilities in such way that: i? ? {1, ..., i}, i?
</nextsent>
<nextsent>6= : p((j, i))p((j, i?))   1 (5) j? ? {1, ..., j}, j?
</nextsent>
<nextsent>6= : p((j, i))p((j?, i))   2 (6) condition (5) implies that for the source word cj , the link with the target word ei is more probable (with reliability threshold 1) than the link with any other target word.
</nextsent>
<nextsent>condition (6) guarantees that for the target word ei, cj is the only most probable (with threshold 2) source word to be linked to.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD257">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> feature function for syntax-enhanced.  </section>
<citcontext>
<prevsection>
<prevsent>3.1.1 ibm model 1 score ibm model 1 is position-independent word alignment model which is often used to bootstrap parameters for more complex models.
</prevsent>
<prevsent>model 1 models the conditional distribution and uses uniform distribution for the dependencies between source word positions and target word positions.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
pr(cj1 , aj1 |ei1) = p(j |i) (i + 1)j ? j=1 p(cj |eaj ) (8) 3.1.2 log-likelihood ratio the log-likelihood ratio statistic has been found to be accurate for modeling the associations between rare events (dunning, 1993).<papid> J93-1003 </papid></citsent>
<aftsection>
<nextsent>it has also been successfully used to measure the associations between word pairs (melamed, 2000; <papid> J00-2004 </papid>moore, 2005).<papid> H05-1011 </papid></nextsent>
<nextsent>given the following contingency table: cj cj ei b ei d the log-likelihood ratio can be defined as: g2(cj , ei) = 2log b(a|a + b, p1)b(c|c + d, p2) b(a|a+ b, p)b(c|c + d, p) where b(k|n, p) = (nk )pk(1 ? p)nk are binomialprobabilities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD265">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> feature function for syntax-enhanced.  </section>
<citcontext>
<prevsection>
<prevsent>given cj1 , ei1 and their syntactic dependency trees tcj1 , tei1 , if ei is aligned to cj and ei?
</prevsent>
<prevsent>aligned tocj?
</prevsent>
</prevsection>
<citsent citstr=" P02-1050 ">
, according to the dependency correspondence assumption (hwa et al, 2002), <papid> P02-1050 </papid>there exists triple  cj , rc, cj? .while we are not aiming to justify the feasibility of the dependency correspondence assumption by proving to what extent re = rc under the condition described above, we do believe that cj and cj?</citsent>
<aftsection>
<nextsent>are likely to be dependent on each other.
</nextsent>
<nextsent>given the anchor alignment a?, candidate link (j, i) and the dependency trees, we can design four classes of feature functions.
</nextsent>
<nextsent>3.2.1 agreement features the agreement features can be further classified into dependency agreement features and dependency label agreement features.
</nextsent>
<nextsent>given candidate link (j, i) and the anchor alignment a?, the dependency agreement (da) feature function is defined as follows: hda1 = ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD266">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>the experiments were carried out using the chinese english datasets provided within the iwslt 2007 evaluation campaign (fordyce, 2007), extracted from the basic travel expression corpus (btec) (takezawa et al, 2002).
</prevsent>
<prevsent>this multilingual speech corpus contains sentences similar to those that are usually found in phrase-books for tourists going abroad.we tagged all the sentences in the training and de vset3 using maximum entropy-based pos tagger?
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
mxpost (ratnaparkhi, 1996), <papid> W96-0213 </papid>trained on the penn english and chinese treebanks.</citsent>
<aftsection>
<nextsent>both chinese and english sentences are parsed using the malt dependency parser (nivre et al, 2007), which achieved84% and 88% labelled attachment scores for chinese and english respectively.
</nextsent>
<nextsent>4.1.1 word alignment we manually annotated word alignments on devset3.
</nextsent>
<nextsent>since manual word alignment is an ambiguous task, we also explicitly allow for ambiguous alignments, i.e. the links are marked as sure (s) or possible (p) (och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>iwslt devset3 consists of 502 sentence pairs after cleaning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD267">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>both chinese and english sentences are parsed using the malt dependency parser (nivre et al, 2007), which achieved84% and 88% labelled attachment scores for chinese and english respectively.
</prevsent>
<prevsent>4.1.1 word alignment we manually annotated word alignments on devset3.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
since manual word alignment is an ambiguous task, we also explicitly allow for ambiguous alignments, i.e. the links are marked as sure (s) or possible (p) (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>iwslt devset3 consists of 502 sentence pairs after cleaning.
</nextsent>
<nextsent>weused the first 300 sentence pairs for training, the following 50 sentence pairs as validation set and the last 152 sentence pairs for testing.
</nextsent>
<nextsent>4.1.2 machine translation training was performed using the default training set (39,952 sentence pairs), to which we added the set devset1 (506 sentence pairs).2 we used devset2 (506 sentence pairs, 16 references) to tune various parameters in the mt system and iwslt 2007 test set (489 sentence pairs, 6 references) for testing.
</nextsent>
<nextsent>4.2 alignment training and search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD271">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>since we performed precision-oriented alignment for the anchor alignment model, the errors in anchor alignment will not bring much noise into the syntax-enhanced model.
</prevsent>
<prevsent>4http://svmlight.joachims.org/ 5more specifically, we performed 5 iterations of model 1, 5 iterations of hmm, 3 iterations of model 3, and 3 iterations of model 4.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
73 ment and phrase-extraction heuristics described in (koehn et al, 2003), <papid> N03-1017 </papid>minimum-error-rate training(och, 2003), <papid> P03-1021 </papid>trigram language model with kneser ney smoothing trained with srilm (stolcke, 2002) on the english side of the training data, and moses (koehn et al, 2007) <papid> P07-2045 </papid>to decode.</citsent>
<aftsection>
<nextsent>4.4 evaluation.
</nextsent>
<nextsent>we evaluate the intrinsic quality of predicted alignment with precision, recall and alignment error rate (aer).
</nextsent>
<nextsent>slightly differently from (och and ney,2003), <papid> J03-1002 </papid>we use possible alignments in computing re call.</nextsent>
<nextsent>recall = |a ? ||p | , precision = |a ? | |a| (20) aer(s,p ;a) = 1?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD272">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>since we performed precision-oriented alignment for the anchor alignment model, the errors in anchor alignment will not bring much noise into the syntax-enhanced model.
</prevsent>
<prevsent>4http://svmlight.joachims.org/ 5more specifically, we performed 5 iterations of model 1, 5 iterations of hmm, 3 iterations of model 3, and 3 iterations of model 4.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
73 ment and phrase-extraction heuristics described in (koehn et al, 2003), <papid> N03-1017 </papid>minimum-error-rate training(och, 2003), <papid> P03-1021 </papid>trigram language model with kneser ney smoothing trained with srilm (stolcke, 2002) on the english side of the training data, and moses (koehn et al, 2007) <papid> P07-2045 </papid>to decode.</citsent>
<aftsection>
<nextsent>4.4 evaluation.
</nextsent>
<nextsent>we evaluate the intrinsic quality of predicted alignment with precision, recall and alignment error rate (aer).
</nextsent>
<nextsent>slightly differently from (och and ney,2003), <papid> J03-1002 </papid>we use possible alignments in computing re call.</nextsent>
<nextsent>recall = |a ? ||p | , precision = |a ? | |a| (20) aer(s,p ;a) = 1?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD273">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>since we performed precision-oriented alignment for the anchor alignment model, the errors in anchor alignment will not bring much noise into the syntax-enhanced model.
</prevsent>
<prevsent>4http://svmlight.joachims.org/ 5more specifically, we performed 5 iterations of model 1, 5 iterations of hmm, 3 iterations of model 3, and 3 iterations of model 4.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
73 ment and phrase-extraction heuristics described in (koehn et al, 2003), <papid> N03-1017 </papid>minimum-error-rate training(och, 2003), <papid> P03-1021 </papid>trigram language model with kneser ney smoothing trained with srilm (stolcke, 2002) on the english side of the training data, and moses (koehn et al, 2007) <papid> P07-2045 </papid>to decode.</citsent>
<aftsection>
<nextsent>4.4 evaluation.
</nextsent>
<nextsent>we evaluate the intrinsic quality of predicted alignment with precision, recall and alignment error rate (aer).
</nextsent>
<nextsent>slightly differently from (och and ney,2003), <papid> J03-1002 </papid>we use possible alignments in computing re call.</nextsent>
<nextsent>recall = |a ? ||p | , precision = |a ? | |a| (20) aer(s,p ;a) = 1?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD275">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>recall = |a ? ||p | , precision = |a ? | |a| (20) aer(s,p ;a) = 1?
</prevsent>
<prevsent>|a ? s|+ |a ? ||a| + |s| (21) we also extrinsic ally measure the word alignment quality via chinese english translation task.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the translation output is measured using bleu (pap ineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>5.1 word alignment.
</nextsent>
<nextsent>we performed word alignment bidirectionally using our approach to obtain the union and compared our results with two strong baselines based on generative word alignment models.
</nextsent>
<nextsent>the results are shown in table 1.
</nextsent>
<nextsent>we can see that both the syntax-enhancedmodel based on hmm intersection anchors (syntax hmm) and on ibm model 4 anchors (syntax-model 4) are better than the pure generative word alignment models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD276">
<title id=" W08-0409.xml">improving word alignment using syntactic dependencies </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>dependency.
</prevsent>
<prevsent>weight model 1 score 0.1416 pos 0.0540 log-likelihood ratio 0.0856 relative distortion 0.0606 da-1 0.0227 dla-2 0.0927 tgt-1-prd 0.0961 tgt-2-amod 0.0621 table 5: weights of some informative features 5.2 machine translation.
</prevsent>
</prevsection>
<citsent citstr=" N06-1014 ">
research has shown that an increase in aer does not necessarily imply an improvement in translation quality (liang et al, 2006) <papid> N06-1014 </papid>and vice-versa (vilar et al., 2006).</citsent>
<aftsection>
<nextsent>hereafter, we used chinese english mt task to extrinsic ally evaluate the quality of our word alignment.table 6 shows the influence of our word alignment approach on mt quality.6 on development set, we achieved statistically significant improvement using both our syntax-enhanced models syntax hmm (p 0.002) and syntax-model 4 (p 0.008).
</nextsent>
<nextsent>on the test set, we observed that the mt output based on our alignment model tends to be shorter than the reference translations and the bleu score is considerably penalized.
</nextsent>
<nextsent>if we ignore the length penalty (bp?
</nextsent>
<nextsent>in table 6) insignificance testing, the improvement on test set is also statistically significant: 0.04 for both syntax-hmm and syntax model 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD279">
<title id=" W08-0332.xml">a smorgasbord of features for automatic mt evaluation </title>
<section> what is new?.  </section>
<citcontext>
<prevsection>
<prevsent>apart from individual metrics, we have also applied simple integration scheme based on uniformly-averaged linear metric combinations (gimenez and ma`rquez, 2008a).
</prevsent>
<prevsent>the main novelty, with respect to the set of metrics presented last year (gimenez and ma`rquez, 2007), is the incorporation of novel family of metric sat the properly semantic level.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
dr metrics analyze similarities between automatic and reference translations by comparing their respective discourse representation structures (drs), as provided by the the c&c; tools (clark and curran, 2004).<papid> P04-1014 </papid></citsent>
<aftsection>
<nextsent>drs are essentially variation of first-order predicate calculus which can be seen as semantic trees.
</nextsent>
<nextsent>we use three different kinds of metrics: dr-stm semantic tree matching, la liu and gildea (2005), <papid> W05-0904 </papid>but over drs instead of over constituency trees.</nextsent>
<nextsent>dr-or-?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD280">
<title id=" W08-0332.xml">a smorgasbord of features for automatic mt evaluation </title>
<section> what is new?.  </section>
<citcontext>
<prevsection>
<prevsent>dr metrics analyze similarities between automatic and reference translations by comparing their respective discourse representation structures (drs), as provided by the the c&c; tools (clark and curran, 2004).<papid> P04-1014 </papid></prevsent>
<prevsent>drs are essentially variation of first-order predicate calculus which can be seen as semantic trees.</prevsent>
</prevsection>
<citsent citstr=" W05-0904 ">
we use three different kinds of metrics: dr-stm semantic tree matching, la liu and gildea (2005), <papid> W05-0904 </papid>but over drs instead of over constituency trees.</citsent>
<aftsection>
<nextsent>dr-or-?
</nextsent>
<nextsent>lexical overlapping over drs.
</nextsent>
<nextsent>dr-orp-?
</nextsent>
<nextsent>morphosyntactic overlapping on drs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD281">
<title id=" W08-0332.xml">a smorgasbord of features for automatic mt evaluation </title>
<section> what is new?.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 uniform linear metric combinations.
</prevsent>
<prevsent>we have simulated non-parametric combination scheme based on human acceptability by working on uniformly averaged linear combinations (ulc)of metrics (gimenez and ma`rquez, 2008a).
</prevsent>
</prevsection>
<citsent citstr=" N07-1006 ">
our approach is similar to that of liu and gildea (2007)<papid> N07-1006 </papid>except that in our case the contribution of each metric to the overall score is not adjusted.optimal metric sets are determined by maximizing the correlation with human assessments, either at the document or sentence level.</citsent>
<aftsection>
<nextsent>however, because exploring all possible combinations was not viable, we have used simple algorithm which performs an approximate search.
</nextsent>
<nextsent>first, metrics are ranked according to their individual quality.
</nextsent>
<nextsent>then, following that order, metrics are added to the optimal set only if in doing so the global quality increases.
</nextsent>
<nextsent>we use all into-english test beds from the 2006 and 2007 editions of the smt workshop (koehn and monz, 2006; <papid> W06-3114 </papid>callison-burch et al, 2007).these include the translation of three different language-pairs: german-to-english (de-en), spanish-to-english (es-en), and french-to-english(fr-en), over two different scenarios: in-domain (eu ropean parliament proceedings) and out-of-domain (news commentary corpus)1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD282">
<title id=" W08-0332.xml">a smorgasbord of features for automatic mt evaluation </title>
<section> experimental work.  </section>
<citcontext>
<prevsection>
<prevsent>first, metrics are ranked according to their individual quality.
</prevsent>
<prevsent>then, following that order, metrics are added to the optimal set only if in doing so the global quality increases.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
we use all into-english test beds from the 2006 and 2007 editions of the smt workshop (koehn and monz, 2006; <papid> W06-3114 </papid>callison-burch et al, 2007).these include the translation of three different language-pairs: german-to-english (de-en), spanish-to-english (es-en), and french-to-english(fr-en), over two different scenarios: in-domain (eu ropean parliament proceedings) and out-of-domain (news commentary corpus)1.</citsent>
<aftsection>
<nextsent>in all cases, single reference translation is available.
</nextsent>
<nextsent>in addition, human assessments on adequacy and fluency are available for subset of systems and sentences.
</nextsent>
<nextsent>each sentence has been evaluated at least by two different judges.
</nextsent>
<nextsent>a brief numerical description of these test beds is available in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD283">
<title id=" W07-1526.xml">multiple step treebank conversion from dependency to penn format </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, it isan explicit comparison among formats and linguistic frameworks.
</prevsent>
<prevsent>therefore, conversion is crucial for overcoming the limits imposed by data in formats that realize different grammatical theories to very important activities such as parsing evaluation and comparative testing of the adequate ness of representation for particular linguistic phenomena, languages and/or tasks.
</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
for instance, the availability of parallel annotations, and among them one in penn format, can be of some aid in investigating the irreproducibility of the state-of-the-art results on treebanks or languages other than penn and english, as empirically demonstrated by, e.g., (collins et al 1999) on czech, (dubey and keller, 2003) <papid> P03-1013 </papid>on german, (corazza et al  2004) on italian.the paper, first, presents methodology for the conversion, then an application of the methodology to the conversion of dependency-based treebank into penn-like format, and finally some remarks on the implementation.</citsent>
<aftsection>
<nextsent>the conversion of treebank, annotated with some format a, into format consists in simple filtering 164and string manipulation only when and both follow the same linguistic framework.
</nextsent>
<nextsent>elsewhere the conversion and development of parallel annotations is challenging task, which involves grammatical rules and linguistic knowledge to be incorporated into the converter programs (see e.g.(musillo andsimaan, 2002) (bick, 2006)).
</nextsent>
<nextsent>nevertheless, parallel annotations which employ different linguistic frameworks may serve as suitable infrastructure for comparisons among them.
</nextsent>
<nextsent>in fact, the definition of conversion process is in itself comparison between and b, since it involves explicit assumptions about how and relate, and virtually complete and correct mapping which translates every analysis in into the corresponding analysis in (musillo and simaan, 2002).we propose methodology that consists in organizing the conversion in steps to be performed incas cade.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD284">
<title id=" W07-1606.xml">inferring the semantics of temporal prepositions in italian </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the corpus study described in this paper led to the development of preliminary set of heuristics for automatic annotation of temporal relations in text/discourse.
</prevsent>
<prevsent>in this work we report on the preliminary results of corpus study, of contemporary italian, on temporal relations that hold between temporal adjunct and an event as way to determine the semantics of temporal prepositions.
</prevsent>
</prevsection>
<citsent citstr=" W01-1309 ">
we claim, following schilder and habel (2001), <papid> W01-1309 </papid>that the semantics of temporal prepositions is rel (e, t), where rel is used to indicate the temporal relation associated with certain preposition, represents the meaning of the temporal expression (timex), and the meaning of the event description involved.</citsent>
<aftsection>
<nextsent>prepositions introducing temporal adjunct are explicit signals of temporal relations.
</nextsent>
<nextsent>the ability to determine temporal relations between timexes introduced by prepositions and events is fundamental for several nlp tasks like open-domain question answering systems (hartrumpf et al 2006, <papid> W06-2105 </papid>and pustejovsky et al 2002) and for textual entailment and reasoning.</nextsent>
<nextsent>the corpus data collected seems to support our hypothesis that each temporal preposition can be associated with one prototypical temporal relation, and that deviations from the prototype can be explained as determined the occurrences of different semantic pattern.the work described in this paper is part of larger project we are conducting on temporal discourse processing in italian, as proposed in mani and pustejovsky (2004).<papid> W04-0208 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD285">
<title id=" W07-1606.xml">inferring the semantics of temporal prepositions in italian </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we claim, following schilder and habel (2001), <papid> W01-1309 </papid>that the semantics of temporal prepositions is rel (e, t), where rel is used to indicate the temporal relation associated with certain preposition, represents the meaning of the temporal expression (timex), and the meaning of the event description involved.</prevsent>
<prevsent>prepositions introducing temporal adjunct are explicit signals of temporal relations.</prevsent>
</prevsection>
<citsent citstr=" W06-2105 ">
the ability to determine temporal relations between timexes introduced by prepositions and events is fundamental for several nlp tasks like open-domain question answering systems (hartrumpf et al 2006, <papid> W06-2105 </papid>and pustejovsky et al 2002) and for textual entailment and reasoning.</citsent>
<aftsection>
<nextsent>the corpus data collected seems to support our hypothesis that each temporal preposition can be associated with one prototypical temporal relation, and that deviations from the prototype can be explained as determined the occurrences of different semantic pattern.the work described in this paper is part of larger project we are conducting on temporal discourse processing in italian, as proposed in mani and pustejovsky (2004).<papid> W04-0208 </papid></nextsent>
<nextsent>this section presents brief overview of the ti meml specification language (pustejovsky et al 2005), which has been used as the starting point for this work, and some theoretical issues on italian prepositions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD286">
<title id=" W07-1606.xml">inferring the semantics of temporal prepositions in italian </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>prepositions introducing temporal adjunct are explicit signals of temporal relations.
</prevsent>
<prevsent>the ability to determine temporal relations between timexes introduced by prepositions and events is fundamental for several nlp tasks like open-domain question answering systems (hartrumpf et al 2006, <papid> W06-2105 </papid>and pustejovsky et al 2002) and for textual entailment and reasoning.</prevsent>
</prevsection>
<citsent citstr=" W04-0208 ">
the corpus data collected seems to support our hypothesis that each temporal preposition can be associated with one prototypical temporal relation, and that deviations from the prototype can be explained as determined the occurrences of different semantic pattern.the work described in this paper is part of larger project we are conducting on temporal discourse processing in italian, as proposed in mani and pustejovsky (2004).<papid> W04-0208 </papid></citsent>
<aftsection>
<nextsent>this section presents brief overview of the ti meml specification language (pustejovsky et al 2005), which has been used as the starting point for this work, and some theoretical issues on italian prepositions.
</nextsent>
<nextsent>2.1 timeml.
</nextsent>
<nextsent>the timeml specification language (pustejovsky et al 2005) offers guideline for annotation of timexes, events and their relations.
</nextsent>
<nextsent>like other annotation schemes1, timeml keeps separated temporal expressions and events, tagged, respectively, with timex3 and event.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD287">
<title id=" W07-1606.xml">inferring the semantics of temporal prepositions in italian </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>like other annotation schemes1, timeml keeps separated temporal expressions and events, tagged, respectively, with timex3 and event.
</prevsent>
<prevsent>in addition, two other tags are used: signal and link.
</prevsent>
</prevsection>
<citsent citstr=" W01-1313 ">
the event tag is used to annotate events, defined as something which occur or happen, and 1 filatova and hovy (2001), <papid> W01-1313 </papid>schilder and habel (2001),.<papid> W01-1309 </papid></citsent>
<aftsection>
<nextsent>setzer (2001).
</nextsent>
<nextsent>38 states, defined as situations in which something holds true.
</nextsent>
<nextsent>temporal expressions, or timexes, like day times (noon, the evening, 1p.m?), dates of different granularity (yesterday, february 2 2007, last week, last spring, last centuries?), durations (five hours, in recent years?)
</nextsent>
<nextsent>and sets (twice day?), are annotated with the timex3 tag.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD289">
<title id=" W07-0813.xml">smoothing a lexicon based pos tagger for arabic and hebrew </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we propose an enhanced part-of-speech (pos) tagger of semitic languages that treats modern standard arabic (hence forth arabic) and modern hebrew (henceforth hebrew) using the same probabilistic model and architectural setting.
</prevsent>
<prevsent>we start out by porting an existing hidden markov model pos tagger for hebrew to arabic by exchanging morphological analyzer for hebrew with buckwalter (2002) morphological analyzer for arabic.
</prevsent>
</prevsection>
<citsent citstr=" P05-1071 ">
this gives state-of-theart accuracy (96.12%), comparable to habash and rambows (2005) <papid> P05-1071 </papid>analyzer based pos tagger on the same arabic datasets.</citsent>
<aftsection>
<nextsent>however, further improvement of such analyzer-based tagging methods is hindered by the incomplete coverage of standard morphological analyzer (bar haim et al , 2005).
</nextsent>
<nextsent>to overcome this coverage problem we supplement the output of buckwalter analyzer with synthetically constructed analyses that are proposed by model which uses character information (diab et al , 2004) <papid> N04-4038 </papid>in way that is similar to nakagawa (2004) <papid> C04-1067 </papid>system for chinese and japanese.</nextsent>
<nextsent>a version of this extended model that (unlike nakagawa) incorporates synthetically constructed analyses also for known words achieves 96.28% accuracy on the standard arabic test set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD290">
<title id=" W07-0813.xml">smoothing a lexicon based pos tagger for arabic and hebrew </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this gives state-of-theart accuracy (96.12%), comparable to habash and rambows (2005) <papid> P05-1071 </papid>analyzer based pos tagger on the same arabic datasets.</prevsent>
<prevsent>however, further improvement of such analyzer-based tagging methods is hindered by the incomplete coverage of standard morphological analyzer (bar haim et al , 2005).</prevsent>
</prevsection>
<citsent citstr=" N04-4038 ">
to overcome this coverage problem we supplement the output of buckwalter analyzer with synthetically constructed analyses that are proposed by model which uses character information (diab et al , 2004) <papid> N04-4038 </papid>in way that is similar to nakagawa (2004) <papid> C04-1067 </papid>system for chinese and japanese.</citsent>
<aftsection>
<nextsent>a version of this extended model that (unlike nakagawa) incorporates synthetically constructed analyses also for known words achieves 96.28% accuracy on the standard arabic test set.
</nextsent>
<nextsent>part-of-speech tagging for semitic languages has been an active topic of research in recent years.
</nextsent>
<nextsent>(diab et al , 2004; <papid> N04-4038 </papid>habash and rambow, 2005; <papid> P05-1071 </papid>bar-haim et al , 2005) are some examples for this line of work on modern standard arabic and modern hebrew.</nextsent>
<nextsent>pos tagging systems aim at classifying input sequences of lexemes by assigning each such sequence corresponding sequence of most probable pos tags.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD292">
<title id=" W07-0813.xml">smoothing a lexicon based pos tagger for arabic and hebrew </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this gives state-of-theart accuracy (96.12%), comparable to habash and rambows (2005) <papid> P05-1071 </papid>analyzer based pos tagger on the same arabic datasets.</prevsent>
<prevsent>however, further improvement of such analyzer-based tagging methods is hindered by the incomplete coverage of standard morphological analyzer (bar haim et al , 2005).</prevsent>
</prevsection>
<citsent citstr=" C04-1067 ">
to overcome this coverage problem we supplement the output of buckwalter analyzer with synthetically constructed analyses that are proposed by model which uses character information (diab et al , 2004) <papid> N04-4038 </papid>in way that is similar to nakagawa (2004) <papid> C04-1067 </papid>system for chinese and japanese.</citsent>
<aftsection>
<nextsent>a version of this extended model that (unlike nakagawa) incorporates synthetically constructed analyses also for known words achieves 96.28% accuracy on the standard arabic test set.
</nextsent>
<nextsent>part-of-speech tagging for semitic languages has been an active topic of research in recent years.
</nextsent>
<nextsent>(diab et al , 2004; <papid> N04-4038 </papid>habash and rambow, 2005; <papid> P05-1071 </papid>bar-haim et al , 2005) are some examples for this line of work on modern standard arabic and modern hebrew.</nextsent>
<nextsent>pos tagging systems aim at classifying input sequences of lexemes by assigning each such sequence corresponding sequence of most probable pos tags.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD310">
<title id=" W07-0813.xml">smoothing a lexicon based pos tagger for arabic and hebrew </title>
<section> relation to previous works.  </section>
<citcontext>
<prevsection>
<prevsent>section 6 concludes.
</prevsent>
<prevsent>quite few works have dealt with extending given pos tagger, mainly by smoothing it using extra-information about untreated words.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
forex ample, (church, 1988) <papid> A88-1019 </papid>uses the simple heuristic of predicting proper nouns from capitalization.</citsent>
<aftsection>
<nextsent>this method is not applicable to arabic and hebrew, which lack typographical marking of proper nouns.
</nextsent>
<nextsent>more advanced methods like those described by weischedel et al  (1993) <papid> J93-2006 </papid>incorporate the treatment of unknown words within the probability model.</nextsent>
<nextsent>weischedel et al  use derivational and inflectional endings to infer pos tags of unknown words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD311">
<title id=" W07-0813.xml">smoothing a lexicon based pos tagger for arabic and hebrew </title>
<section> relation to previous works.  </section>
<citcontext>
<prevsection>
<prevsent>forex ample, (church, 1988) <papid> A88-1019 </papid>uses the simple heuristic of predicting proper nouns from capitalization.</prevsent>
<prevsent>this method is not applicable to arabic and hebrew, which lack typographical marking of proper nouns.</prevsent>
</prevsection>
<citsent citstr=" J93-2006 ">
more advanced methods like those described by weischedel et al  (1993) <papid> J93-2006 </papid>incorporate the treatment of unknown words within the probability model.</citsent>
<aftsection>
<nextsent>weischedel et al  use derivational and inflectional endings to infer pos tags of unknown words.
</nextsent>
<nextsent>nakagawa (2004) <papid> C04-1067 </papid>addresses the problem of unknown words for japanese and chinese, and uses hybrid method of word-level and character-level information.</nextsent>
<nextsent>in his model, nakagawa uses character information (only) when handling unknown words, claiming that in word-level methods information about known words helps to achieve higher accuracy compared to character-level models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD315">
<title id=" W08-0301.xml">an empirical study in source word deletion for phrase based statistical machine translation </title>
<section> literature review.  </section>
<citcontext>
<prevsection>
<prevsent>research work in smt seldom treats swd asa problem separated from other factors in translation.
</prevsent>
<prevsent>however, it can be found in different smt paradigms the mechanism of handling swd.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
as to the pioneering ibm word-basedsmt models (brown et al, 1990), <papid> J90-2002 </papid>ibm models 3, 4 and 5 handle spurious source words by considering them as corresponding to particular empty word token on the english side, and by the fertility model which allows the english empty to generate certain number of foreign words.as to the hierarchical phrase-based approach (chiang, 2007), its hierarchical rules are more powerful in swd than the phrase pairs in conventional phrase-based approach.</citsent>
<aftsection>
<nextsent>for instance, the according-to/??
</nextsent>
<nextsent>np ex press/,+?
</nextsent>
<nextsent>example in the last section can be handled easily by the hierarchical rule ? ??
</nextsent>
<nextsent>x,+, according to   . in general, if the deletion of source word depends on some context cues, then the hierarchical approach is, at least in principle, capable of handling it correctly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD316">
<title id=" W08-0301.xml">an empirical study in source word deletion for phrase based statistical machine translation </title>
<section> source word deletion models.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 model 1: uniform probability.
</prevsent>
<prevsent>the first model assumes uniform probability of translation to ?.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
this model is inspired by the hmm-based alignment model (och and ney,2000<papid> P00-1056 </papid>a), which posits probability p0 for alignment of some source word to the empty word on the target language side, and weighs all other alignment probabilities by the factor 1 ? p0.</citsent>
<aftsection>
<nextsent>in the same style, swd model 1 posits probability (?)
</nextsent>
<nextsent>for the translation of any source word to ?.
</nextsent>
<nextsent>the probabilities of normal phrase pairs should be weighed accordingly.
</nextsent>
<nextsent>for source phrase containing only one word, its weight is simplyp (??)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD318">
<title id=" W08-0301.xml">an empirical study in source word deletion for phrase based statistical machine translation </title>
<section> source word deletion models.  </section>
<citcontext>
<prevsection>
<prevsent>example in section 1.
</prevsent>
<prevsent>an obvious solution to this limitation is more powerful tagging model augmented with context sensitive feature templates.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
inspired by research work like (lafferty et al, 2001) and (sha and pereira, 2003), <papid> N03-1028 </papid>our swd model 3 uses first-order conditional random field (crf) to tackle the tagging task.1 the crf model uses the following feature templates: 1.</citsent>
<aftsection>
<nextsent>the lexical form and the pos of the foreign word itself; 2.
</nextsent>
<nextsent>the lexical forms and the poss of f2, f1, f+1, and f+2, where f2 and f1 are the two words to the left of , and f+1 and f+2 are the two words to the right of ; 3.
</nextsent>
<nextsent>the lexical form and the pos of the head word of ;4.
</nextsent>
<nextsent>the lexical forms and the poss of the dependent words of .the lexical forms are the major source of information whereas the poss are employed to alleviate data sparseness.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD319">
<title id=" W08-0301.xml">an empirical study in source word deletion for phrase based statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>as non-spurious.
</prevsent>
<prevsent>4.1 experiment settings.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
a series of experiments were run to compare the performance of the three swd models against the baseline, which is the standard phrase-based approach to smt as elaborated in (koehn et al,2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the experiments are about chinese-to english translation.
</nextsent>
<nextsent>the bilingual training data is the one for nist mt-2006.
</nextsent>
<nextsent>the gigaword corpus is used for training language model.
</nextsent>
<nextsent>the development/test corpora are based on the test sets for nist mt-2005/6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD323">
<title id=" W08-0301.xml">an empirical study in source word deletion for phrase based statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the subsequent construction of translation table was done in exactly the same way as explained 4 in (koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
<prevsent>for swd model 2,the phrase enumeration step is modified as described in section 3.2.</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we used the stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>with its default chinese grammar for its pos-tagging as well as finding the head/dependent words of all source words.</citsent>
<aftsection>
<nextsent>the crf toolkit used for model 3 is crf++2.
</nextsent>
<nextsent>the training data for the crf model should be the same as that for translation table construction.
</nextsent>
<nextsent>however, since there are too many instances (every single word in the training datais an instance) with huge feature space, no publicly available crf toolkit can handle the entire training set of nist mt-2006.3 therefore, we can use at most only about one-third of the nist training set (comprising the fbis, b1, and t10 sections) for crf training.the decoder in the experiments is our re implementation of hiero (chiang, 2007), augmented with 5-gram language model andre ordering model based on (zhang et al, 2007).<papid> D07-1056 </papid>note that no hierarchical rule is used with the de coder; the phrase pairs used are still those used in conventional phrase-based smt.</nextsent>
<nextsent>note also that the decoder does not translate oov at all even in the baseline case, and thus the swd models do not improve performance simply by removing oovs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD324">
<title id=" W08-0301.xml">an empirical study in source word deletion for phrase based statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the crf toolkit used for model 3 is crf++2.
</prevsent>
<prevsent>the training data for the crf model should be the same as that for translation table construction.
</prevsent>
</prevsection>
<citsent citstr=" D07-1056 ">
however, since there are too many instances (every single word in the training datais an instance) with huge feature space, no publicly available crf toolkit can handle the entire training set of nist mt-2006.3 therefore, we can use at most only about one-third of the nist training set (comprising the fbis, b1, and t10 sections) for crf training.the decoder in the experiments is our re implementation of hiero (chiang, 2007), augmented with 5-gram language model andre ordering model based on (zhang et al, 2007).<papid> D07-1056 </papid>note that no hierarchical rule is used with the de coder; the phrase pairs used are still those used in conventional phrase-based smt.</citsent>
<aftsection>
<nextsent>note also that the decoder does not translate oov at all even in the baseline case, and thus the swd models do not improve performance simply by removing oovs.
</nextsent>
<nextsent>in order to test the effect of training data size onthe performance of the swd models, three variations of training data were used: fbis only the fbis section of the nist training set is used as training data (for both translation table and the crf model in model 3).this section constitutes about 10% of the entire nist training set.
</nextsent>
<nextsent>the purpose of this variation is to test the performance of each model when very small amount of data are available.
</nextsent>
<nextsent>bft only the b1, fbis, and t10 sections of the nist training set are used as training data.these sections are about one-third of the entire nist training set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD325">
<title id=" W08-0301.xml">an empirical study in source word deletion for phrase based statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>data baseline model 1 model 2 model 3 fbis 28.01 29.71 29.48 29.64 bft 29.82 31.55 31.61 31.75 nist 29.77 31.39 31.33 31.71 table 2: bleu scores in experiment 1: nist05 as dev and nist06 as test variation is to test each model when medium size of data are available.4 nist all the sections of the nist training set are used.
</prevsent>
<prevsent>the purpose of this variation is to test each model when large amount of data are available.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
(case-insensitive) bleu-4 (papineni et al, 2002) <papid> P02-1040 </papid>is used as the evaluation metric.</citsent>
<aftsection>
<nextsent>in each test in our experiments, maximum bleu training were run 10 times, and thus there are 10 bleu scores for the test set.
</nextsent>
<nextsent>in the following we will report the mean scores only.
</nextsent>
<nextsent>4.2 experiment results and analysis.
</nextsent>
<nextsent>table 2 shows the results of the first experiment,which uses the nist mt-2005 test set as development data and the nist mt-2006 test set as test data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD326">
<title id=" W08-0301.xml">an empirical study in source word deletion for phrase based statistical machine translation </title>
<section> experiments using meteor.  </section>
<citcontext>
<prevsection>
<prevsent>it is also observed, however, that the three swd models give rise to roughly the same bleu scores, indicating that the swd training data do not fit the test/development data very well as even the more sophisticated models are not benefited from more data.
</prevsent>
<prevsent>the results in the last section are all evaluated using the bleu metric only.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
it is dubious whether swd is useful regarding recall-oriented metrics like meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>since swd removes information in source sentences.</citsent>
<aftsection>
<nextsent>this suspicion is to certain extent confirmed by our application of meteor to the translation outputs of experiment 1 (c.f. table 7), which shows that all swd models achieve lower meteor scores than the baseline.
</nextsent>
<nextsent>however, swd isnot entirely harmful to meteor: if swd is applied to parameter tuning only but not for the test set, (i.e. experiment 2), even higher meteor scores can be obtained.
</nextsent>
<nextsent>this puzzling observation may be because the parameters of the decoder are optimized with respect to bleu score,and swd benefits parameter tuning by improving bleu score.
</nextsent>
<nextsent>in future experiments, maximum meteor training should be used instead of maximum bleu training so as to examine if swd is really useful for parameter tuning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD327">
<title id=" W07-1906.xml">coordination in conversation and rapport </title>
<section> background &amp; theory.  </section>
<citcontext>
<prevsection>
<prevsent>inspired by this approach, work by clark and collaborators on grounding and conversation as joint action has made demonstrated coordination and cooperation as defining characteristics of conversation (clark, 1996; clark &amp; brennan, 1991; clark &amp; wilkes-gibbs, 1986).
</prevsent>
<prevsent>this work has in turn, received significant amount of attention in computational linguistics, specifically in the study of dialogue (matheson, poesio, &amp; traum, 2000; nakano, reinstein, stocky, &amp; cassell, 2003; traum, 1994; traum &amp; dillen bourg, 1998).
</prevsent>
</prevsection>
<citsent citstr=" P03-1070 ">
to develop model of nonverbal grounding, nakano et al (2003) <papid> P03-1070 </papid>stud early late time of interaction im o rt n ce o r p o rt mutual attention positivity coordination figure 1.</citsent>
<aftsection>
<nextsent>three component model of rapport (from tickle-degen &amp; rosenthal, 1990).
</nextsent>
<nextsent>42 ied people giving directions with respect to map placed in between them.
</nextsent>
<nextsent>in that study, we observed that when direction-receiver looked up from the map while the direction-giver was still giving directions, the giver would initiate grounding behavior such as repeat or rephrase.
</nextsent>
<nextsent>the literature reviewed above leads us to believe that there is an integral relationship between social and knowledge coordination.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD334">
<title id=" W07-1906.xml">coordination in conversation and rapport </title>
<section> towards computational model.  </section>
<citcontext>
<prevsection>
<prevsent>using this task history, it is able to generate shorter directions at later stages in the dialogue.
</prevsent>
<prevsent>in our implementation, however, the very style of the interaction is modified by the shared history of the user and the system.
</prevsent>
</prevsection>
<citsent citstr=" W06-1405 ">
in the sense that we are modifying the linguistic style of the dialogue based on psychological attributes, our approach is similar to work by mairesse &amp; walker (2007) and isard et al (2006).<papid> W06-1405 </papid></citsent>
<aftsection>
<nextsent>in both cases, broad set of natural language generation parameters is employed to generate language that differs along personality dimension, based on number of previous empirical studies.
</nextsent>
<nextsent>in the current approach, however, the features that are modified derive from the interde figure 6.
</nextsent>
<nextsent>proposed architecture for modeling coordination within and across conversation 48 pend ence of the system with particular user.
</nextsent>
<nextsent>some of the features that are present in the conversations of friends, such as interjections and completion of one anothers utterances, are still beyond current computational abilities, as they would require online, real-time processing and understanding of utterances with incremental planning and generation of responses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD335">
<title id=" W07-1306.xml">can corpus based measures be used for comparative study of languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as result, semi-automatic cross lin gual comparison of languages is also becominga fruitful area of study.
</prevsent>
<prevsent>among the fundamental tools for cross lingual comparison are measures of inter-language distances.
</prevsent>
</prevsection>
<citsent citstr=" P06-1035 ">
in linguistics, the study of inter-language distances, especially for language classification, has long history (swadesh, 1952; ellison and kirby, 2006).<papid> P06-1035 </papid></citsent>
<aftsection>
<nextsent>basically, the work on this problem has been along linguistic, archaeological and computational streams.
</nextsent>
<nextsent>likein other disciplines, computational methods are increasingly being combined with other more conventional approaches (dyen et al, 1992; nerbonne and heeringa, 1997; <papid> W97-1102 </papid>kondrak, 2002; ellison and kirby,2006).<papid> P06-1035 </papid></nextsent>
<nextsent>the work being presented in this paper belongs to the computational stream.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD337">
<title id=" W07-1306.xml">can corpus based measures be used for comparative study of languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in linguistics, the study of inter-language distances, especially for language classification, has long history (swadesh, 1952; ellison and kirby, 2006).<papid> P06-1035 </papid></prevsent>
<prevsent>basically, the work on this problem has been along linguistic, archaeological and computational streams.</prevsent>
</prevsection>
<citsent citstr=" W97-1102 ">
likein other disciplines, computational methods are increasingly being combined with other more conventional approaches (dyen et al, 1992; nerbonne and heeringa, 1997; <papid> W97-1102 </papid>kondrak, 2002; ellison and kirby,2006).<papid> P06-1035 </papid></citsent>
<aftsection>
<nextsent>the work being presented in this paper belongs to the computational stream.
</nextsent>
<nextsent>even in the computational stream, most of the previous work on inter-language distances had strong linguistic dimension.
</nextsent>
<nextsent>for example, mostof the quantitative measures of inter-language distance have been applied on handcrafted word lists (swadesh, 1952; dyen et al, 1992).
</nextsent>
<nextsent>however, with increasing use of computational techniques andthe availability of electronic data, natural question arises: can languages be linguistically compared based on word lists extracted from corpora.a natural counter-question is whether such comparison will be valid from linguistic and psycho linguistic points of view.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD340">
<title id=" W07-1306.xml">can corpus based measures be used for comparative study of languages </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>typology or history of languages can be studied using spoken data or text.
</prevsent>
<prevsent>there has been work on the former (remmel, 1980; kondrak, 2002), but we 40 will focus only on text.
</prevsent>
</prevsection>
<citsent citstr=" W06-1107 ">
an example of major work on text based similarity is the paper by kondrak and sherif (kondrak and sherif, 2006).<papid> W06-1107 </papid></citsent>
<aftsection>
<nextsent>they have evaluated various phonetic similarity algorithms for aligning cognates.
</nextsent>
<nextsent>they found that learning based algorithms outperform manually constructed schemes, but only when large training data is used.
</nextsent>
<nextsent>a recent work on applications of such techniques for linguistic study is by heeringa et al (heeringaet al, 2006).<papid> W06-1108 </papid></nextsent>
<nextsent>they performed study on different variations of string distance algorithms for di alectology and concluded that order sensitivity is important while scaling with length is not.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD341">
<title id=" W07-1306.xml">can corpus based measures be used for comparative study of languages </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they have evaluated various phonetic similarity algorithms for aligning cognates.
</prevsent>
<prevsent>they found that learning based algorithms outperform manually constructed schemes, but only when large training data is used.
</prevsent>
</prevsection>
<citsent citstr=" W06-1108 ">
a recent work on applications of such techniques for linguistic study is by heeringa et al (heeringaet al, 2006).<papid> W06-1108 </papid></citsent>
<aftsection>
<nextsent>they performed study on different variations of string distance algorithms for di alectology and concluded that order sensitivity is important while scaling with length is not.
</nextsent>
<nextsent>it may be noted that ellison and kirby (ellison and kirby, 2006) <papid> P06-1035 </papid>have shown that scaling by distance does give significantly better results.</nextsent>
<nextsent>nakleh et al (naklehet al, 2005) have written about using phylogenetic techniques in historical linguistics as mentioned by nerbonne (nerbonne, 2005) in the review of the book titled language classification bynum bers?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD351">
<title id=" W07-1306.xml">can corpus based measures be used for comparative study of languages </title>
<section> symmetric cross entropy (sce).  </section>
<citcontext>
<prevsection>
<prevsent>the two cognate based measures described in sections 9 and 10 are an attempt at this.
</prevsent>
<prevsent>but first we describe simple n-gram based measure.
</prevsent>
</prevsection>
<citsent citstr=" W06-1109 ">
the first measure is purely letter n-gram based measure similar to the one used by singh (singh, 2006<papid> W06-1109 </papid>b) for language and encoding identification.</citsent>
<aftsection>
<nextsent>to calculate the distance, we first prepare letter 5-grammodels from the corpora of the languages to be compared.
</nextsent>
<nextsent>then we combine n-grams of all orders andrank them according to their probability in descending order.
</nextsent>
<nextsent>only the top n-grams are retained and the rest are pruned.
</nextsent>
<nextsent>1 now we have two probability distributions which can be compared by measure of distributional similarity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD354">
<title id=" W07-1306.xml">can corpus based measures be used for comparative study of languages </title>
<section> symmetric cross entropy (sce).  </section>
<citcontext>
<prevsection>
<prevsent>we have used symmetric cross entropy as such measure: dsce = ? gl=gm (p(gl) log q(gm) + q(gm) log p(gl)) (1) where and are the probability distributions forthe two languages and gland gm are n-grams in languages and m, respectively.
</prevsent>
<prevsent>the disadvantage of this measure is that it does not use any linguistic (e.g., phonetic) information,but the advantage is that it can measure the similarity of distributions of n-grams.
</prevsent>
</prevsection>
<citsent citstr=" W97-0907 ">
such measures have proved to be very effective in automatically identifying languages of text, with accuracies nearing 100% for fairly small amounts of training and test data (adams and resnik, 1997; <papid> W97-0907 </papid>singh, 2006<papid> W06-1109 </papid>b).</citsent>
<aftsection>
<nextsent>1this is based on the results obtained by cavnar (cavnar and trenkle, 1994) and our own studies, which show that the top (300 according to cavnar) n-grams have high correlation with the identity of the language.
</nextsent>
<nextsent>42
</nextsent>
<nextsent>the other two measures are based on cognates, inherited as well as borrowed.
</nextsent>
<nextsent>both of them use an algorithm for identification of cognates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD367">
<title id=" W07-2207.xml">efficiency in unification based nbest parsing </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>the new algorithm empirically exhibits linear relationship between processing time and the number of analyses unpacked at all degrees of me feature nonlocality; in addition, compared with agenda driven best-first parsing and exhaustive parsing with post-hoc parse selection it leads to improved parsing speed, coverage, and ac curacy.?
</prevsent>
<prevsent>technology for natural language analysis using linguistically precise grammars has matured to level of coverage and efficiency that enables parsing of large amounts of running text.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
research groups working within grammatical frameworks like ccg (clark &amp; curran, 2004), <papid> P04-1014 </papid>lfg (riezler et al, 2002), <papid> P02-1035 </papid>and hpsg (malouf &amp; van noord, 2004; oepen, flickinger, toutanova, &amp; manning, 2004; miyao,ninomiya, &amp; tsujii, 2005) have successfully integrated broad-coverage computational grammars with sophisticated statistical parse selection models.the former delineate the space of possible analyses, while the latter provide probability distribu the first author warmly acknowledges the guidance of hisphd advisors, valia kordoni and hans uszkoreit.</citsent>
<aftsection>
<nextsent>we are grateful to ulrich callmeier, berthold crysmann, dan flickinger, and erik velldal for many discussions and their support.
</nextsent>
<nextsent>wethank ron kaplan, martin kay, and bob moore for providing insightful information about related approaches, notably the xle and cle parsers.tion over competing hypotheses.
</nextsent>
<nextsent>parse selection approaches for these frameworks often use discriminative maximum entropy (me) models, where the probability of each parse tree, given an input string, is estimated on the basis of select properties (calledfeatures) of the tree (abney, 1997; <papid> J97-4005 </papid>johnson, ge man, canon, chi, &amp; riezler, 1999).</nextsent>
<nextsent>such features, in principle, are not restricted in their domain of locality, and enable the parse selection process totake into account properties that extend beyond local contexts (i.e. sub-trees of depth one).there is trade-off in this set-up between the accuracy of the parse selection model, on the one hand,and the efficiency of the search for the best solu tion(s), on the other hand.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD368">
<title id=" W07-2207.xml">efficiency in unification based nbest parsing </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>the new algorithm empirically exhibits linear relationship between processing time and the number of analyses unpacked at all degrees of me feature nonlocality; in addition, compared with agenda driven best-first parsing and exhaustive parsing with post-hoc parse selection it leads to improved parsing speed, coverage, and ac curacy.?
</prevsent>
<prevsent>technology for natural language analysis using linguistically precise grammars has matured to level of coverage and efficiency that enables parsing of large amounts of running text.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
research groups working within grammatical frameworks like ccg (clark &amp; curran, 2004), <papid> P04-1014 </papid>lfg (riezler et al, 2002), <papid> P02-1035 </papid>and hpsg (malouf &amp; van noord, 2004; oepen, flickinger, toutanova, &amp; manning, 2004; miyao,ninomiya, &amp; tsujii, 2005) have successfully integrated broad-coverage computational grammars with sophisticated statistical parse selection models.the former delineate the space of possible analyses, while the latter provide probability distribu the first author warmly acknowledges the guidance of hisphd advisors, valia kordoni and hans uszkoreit.</citsent>
<aftsection>
<nextsent>we are grateful to ulrich callmeier, berthold crysmann, dan flickinger, and erik velldal for many discussions and their support.
</nextsent>
<nextsent>wethank ron kaplan, martin kay, and bob moore for providing insightful information about related approaches, notably the xle and cle parsers.tion over competing hypotheses.
</nextsent>
<nextsent>parse selection approaches for these frameworks often use discriminative maximum entropy (me) models, where the probability of each parse tree, given an input string, is estimated on the basis of select properties (calledfeatures) of the tree (abney, 1997; <papid> J97-4005 </papid>johnson, ge man, canon, chi, &amp; riezler, 1999).</nextsent>
<nextsent>such features, in principle, are not restricted in their domain of locality, and enable the parse selection process totake into account properties that extend beyond local contexts (i.e. sub-trees of depth one).there is trade-off in this set-up between the accuracy of the parse selection model, on the one hand,and the efficiency of the search for the best solu tion(s), on the other hand.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD369">
<title id=" W07-2207.xml">efficiency in unification based nbest parsing </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>we are grateful to ulrich callmeier, berthold crysmann, dan flickinger, and erik velldal for many discussions and their support.
</prevsent>
<prevsent>wethank ron kaplan, martin kay, and bob moore for providing insightful information about related approaches, notably the xle and cle parsers.tion over competing hypotheses.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
parse selection approaches for these frameworks often use discriminative maximum entropy (me) models, where the probability of each parse tree, given an input string, is estimated on the basis of select properties (calledfeatures) of the tree (abney, 1997; <papid> J97-4005 </papid>johnson, ge man, canon, chi, &amp; riezler, 1999).</citsent>
<aftsection>
<nextsent>such features, in principle, are not restricted in their domain of locality, and enable the parse selection process totake into account properties that extend beyond local contexts (i.e. sub-trees of depth one).there is trade-off in this set-up between the accuracy of the parse selection model, on the one hand,and the efficiency of the search for the best solu tion(s), on the other hand.
</nextsent>
<nextsent>extending the context sizeof me features, within the bounds of available training data, enables increased parse selection accuracy.however, the interplay of the core parsing algorithm and the probabilistic ranking of alternate (sub )hypotheses becomes considerably more complex and costly when the feature size exceeds the domain of locality (of depth-one trees) that is characteristic of phrase structure grammar-based formalisms.
</nextsent>
<nextsent>one current line of research focuses on finding the best balance between parsing efficiency and parse selection techniques of increasing complexity, aiming to identify the most probable solution(s) with minimal effort.this paper explores range of techniques, combining broad-coverage, high-efficiency hpsg parser with series of parse selection models with varying context size of features.
</nextsent>
<nextsent>we sketch three general scenarios for the integration: (a) baseline sequential configuration, where all results are enumerated first, and subsequently ranked; (b) an interleaved but approximative solution, performing greedy search for an n-best list of results; and (c) atwo-phase approach, where complete packed for 48 est is created and combined with specialized graph search procedure to selectively enumerate results in(globally) correct rank order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD370">
<title id=" W07-2207.xml">efficiency in unification based nbest parsing </title>
<section> overall set-up.  </section>
<citcontext>
<prevsection>
<prevsent>thus, unpacking effectively needs to deterministically replay unifications, but this extra expense in our experience is negligible when compared to the decreased cost of constructing the forest under subsumption.
</prevsent>
<prevsent>in section 3 we argue that this very property, in addition to increasing parsing efficiency, interacts beneficially with parse selection and on-demand enumeration of results in rank order.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
following (johnson et al, 1999), <papid> P99-1069 </papid>conditional me model of the probabilities of trees {t1 . . .</citsent>
<aftsection>
<nextsent>tn} for string s, and assuming set of feature functions {f1 . . .
</nextsent>
<nextsent>fm} with corresponding weights {1 . . .
</nextsent>
<nextsent>m}, is defined as: p(ti|s) = expj jfj(ti) k=1 exp ? jfj(tk) (1) 2this property of parse forests is not prerequisite of the chart parsing framework.
</nextsent>
<nextsent>the basic cky procedure (kasami,1965), for example, as well as many unification-based adaptations (e.g. the core language engine; moore &amp; alshawi, 1992)merely record the local category of each edge, which is sufficient for the recognition task and simplifies the search.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD371">
<title id=" W07-2207.xml">efficiency in unification based nbest parsing </title>
<section> inter leaving parsing and ranking.  </section>
<citcontext>
<prevsection>
<prevsent>another mode of operation is to organize the parsers search according to an agenda (i.e. priority queue) that assigns numeric scores to parsing moves (erbach, 1991).
</prevsent>
<prevsent>each such move is an application of the fundamental rule of chart parsing, combining an active and passive edge, and the scores represent the expected figure of merit?
</prevsent>
</prevsection>
<citsent citstr=" J98-2004 ">
(caraballo &amp; charniak, 1998) <papid> J98-2004 </papid>of the resulting structure.</citsent>
<aftsection>
<nextsent>assuming aparse selection model of the type sketched in section 2, we can determine the agenda priority for parsing move according to the (unnormalized) me score of the derivation (sub-)tree that would result from its successful execution.
</nextsent>
<nextsent>note that, unlike in probabilistic context-free grammars (pcfgs), me scores of partial trees do not necessarily decrease as the tree size increases; instead, the distribution of feature weights is in the range (??,+?), centered around 0, where negative weights intuitively correspond to dis-preferred properties.
</nextsent>
<nextsent>this lack of monotonicity in the scores associated with sub-trees, on the one hand, is beneficial, in that performing greedy best-first search becomes practical: in contrast, with pcfgs and their monoton ically decreasing probabilities on larger sub-trees,once the parser finds the first full tree the chart necessarily has been instantiated almost completely.
</nextsent>
<nextsent>onthe other hand, the same property prohibits the application of exact best-first techniques like a?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD372">
<title id=" W07-2207.xml">efficiency in unification based nbest parsing </title>
<section> inter leaving parsing and ranking.  </section>
<citcontext>
<prevsection>
<prevsent>this lack of monotonicity in the scores associated with sub-trees, on the one hand, is beneficial, in that performing greedy best-first search becomes practical: in contrast, with pcfgs and their monoton ically decreasing probabilities on larger sub-trees,once the parser finds the first full tree the chart necessarily has been instantiated almost completely.
</prevsent>
<prevsent>onthe other hand, the same property prohibits the application of exact best-first techniques like a?
</prevsent>
</prevsection>
<citsent citstr=" N03-1016 ">
search, because there is no reliable future cost estimate; in this respect, our set-up differs fundamentally from that of klein &amp; manning (2003) <papid> N03-1016 </papid>and related pcfg parsing work.</citsent>
<aftsection>
<nextsent>using the un normalized sum of me weights on partial solution as its agenda score, effectively, means that sub-trees with low scores sink?
</nextsent>
<nextsent>to the bottom of the agenda; highly-ranked partial constituents, in turn, instigate the immediate creation of larger structures, and ideally the bottom-up agenda-driven search will greedily steer the parser towards full analyses with high scores.
</nextsent>
<nextsent>given its heuristic nature, this procedure cannot guarantee that its n-best list of results corresponds to the globally correct rank order, but it may in practice come reasonably close to it.
</nextsent>
<nextsent>while conceptually simple, greedy best-first search does not combine easily with ambiguity packing in the chart: (a) at least when packing under subsumption, it is not obvious how to accurately compute the agenda score of packed nodes, and (b) to the extent that the greedy search avoids exploration of dis-preferred local ambiguity, the need for packing should be greatly reduced.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD373">
<title id=" W07-2207.xml">efficiency in unification based nbest parsing </title>
<section> generalizing the algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>accordingly, when evaluating candidate decompositions of 4 , the number of hypotheses that need to be considered is doubled; as an immediate consequence, there can be up toeight distinct lexicalized variants for the decomposition 1 4 3 ? further up in the tree.
</prevsent>
<prevsent>it may look as if combinatorics will cross-multiply throughout the treein the worst case returning us to an exponential number of hypotheses but this is fortunately not the case: regarding the external bi-grams of 1 , node 6 no longer participates in its left- or rightmost periphery, so variation internal to 6 is nota multiplicative factor at this level.
</prevsent>
</prevsection>
<citsent citstr=" A00-2023 ">
this is essentially the observation of langkilde (2000), <papid> A00-2023 </papid>and herbottom-up factoring of n-gram computation is easily incorporated into our top-down selective unpacking control structure.</citsent>
<aftsection>
<nextsent>at the point where hypothesize edge() invokes itself recursively (line 23 in figure 3), its return value is now set of lexicalized alternates,and hypothesis creation (in line 26) can take into account the local cross-product of all such alternation.including additional properties from non-local subtrees (for example higher-order n-grams and head lexicalization) is straightforward extension of this scheme, replacing our per-edge left- and rightmost periphery symbols with generalized vector of externally relevant, internal properties.
</nextsent>
<nextsent>in addition to traditional (head) lexicalization as we have just discussed it, such extended downward?
</nextsent>
<nextsent>properties on decompositionspercolated from daughters to mothers and cross-multiplied as appropriatecouldinclude metrics of constituent weight too, for example to enable the me model to prefer balanced?
</nextsent>
<nextsent>coordination structures.however, given that toutanova et al (2005) obtain only marginally improved parse selection accuracy from the inclusion of n-gram (and other lexical)me features, we have left the implementation of lexicalization and empirical evaluation for future work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD374">
<title id=" W07-2207.xml">efficiency in unification based nbest parsing </title>
<section> empirical results.  </section>
<citcontext>
<prevsection>
<prevsent>indicates that with our selective unpacking algorithm, these expensive operations on typed feature structures are significantly reduced.
</prevsent>
<prevsent>in return for increased processing time (andmarginal loss in coverage) when using grand parenting features, table 3 shows some large improvements in parse selection accuracy (although the picture is less clear-cut at higher-order levels of grand parenting5).
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
a balance point between efficiency5the models were trained using the open-source tadm package (malouf, 2002), <papid> W02-2018 </papid>using default hyper-parameters for all configurations, viz.</citsent>
<aftsection>
<nextsent>a convergence threshold of 108, variance of the prior of 104, and frequency cut-off of 5.
</nextsent>
<nextsent>it is likely that 56 configuration gp unifications copies space unpack total(#) (#) (kbyte) (s) (s) ? 15 greedy best-first 0 1845 527 2328 ? 0.12 words exhaustive unpacking 0 2287 795 8907 0.01 0.12 selective unpacking 0 1912 589 8109 0.00 0.12 1 1913 589 8109 0.01 0.12 2 1914 589 8109 0.01 0.12 3 1914 589 8110 0.01 0.12 4 1914 589 8110 0.02 0.13   15 greedy best-first 0 25233 5602 24646 ? 1.66 words exhaustive unpacking 0 39095 15685 80832 0.85 1.95 selective unpacking 0 17489 4422 33326 0.03 1.17 1 17493 4421 33318 0.05 1.21 2 17493 4421 33318 0.09 1.25 3 17495 4422 33321 0.13 1.27 4 17495 4422 33320 0.21 1.34 table 4: contrasting the efficiency of various (un-)packing settings in use with erg on short (top) and medium-length (bottom) inputs; in each configuration, up to ten trees are extracted.
</nextsent>
<nextsent>unification and copies is the count of top-level fs operations, where only successful unifications require subsequent copy (when creating new edge).
</nextsent>
<nextsent>unpack and total are unpacking and total parse time, respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD375">
<title id=" W07-2207.xml">efficiency in unification based nbest parsing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>trees that ultimately turn out to be incoherent.
</prevsent>
<prevsent>dynamic programming of instantiationfailures makes this approach tractable, while retaining the general breadth-first characteristic of these lective unpacking regime.further optimization of hyper-parameters for individual configurations would moderately improve model performance, especially for higher-order grand parenting levels with large numbers of features.
</prevsent>
</prevsection>
<citsent citstr=" W05-1506 ">
the approach to n-best parsing described in this paper takes as its point of departure recent work of carroll &amp; oepen (2005), which describes an efficient algorithm for unpacking n-best trees from forest produced by chart-based sentence generator and containing local me properties with associated weights.in an almost contemporaneous study, but in the context of parsing with treebank grammars, huang &chiang; (2005) <papid> W05-1506 </papid>develop series of increasingly efficient algorithms for unpacking n-best results from weighted hypergraph representing parse forest.</citsent>
<aftsection>
<nextsent>the algorithm of carroll &amp; oepen (2005) and the final one of huang &amp; chiang (2005) <papid> W05-1506 </papid>are essentially equivalent, and turn out to be reformulations of an approach originally described by jimenez &amp; marzal (2000) (although expressed there only for grammars in chomsky normal form).</nextsent>
<nextsent>in this paper we have considered me properties that extend beyond immediate dominance relations,extending up to 4 levels of grandparenting.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD377">
<title id=" W07-2207.xml">efficiency in unification based nbest parsing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the algorithm of carroll &amp; oepen (2005) and the final one of huang &amp; chiang (2005) <papid> W05-1506 </papid>are essentially equivalent, and turn out to be reformulations of an approach originally described by jimenez &amp; marzal (2000) (although expressed there only for grammars in chomsky normal form).</prevsent>
<prevsent>in this paper we have considered me properties that extend beyond immediate dominance relations,extending up to 4 levels of grandparenting.</prevsent>
</prevsection>
<citsent citstr=" P02-1036 ">
previous work has either assumed properties that are restricted to the minimal parse fragments (i.e. subtrees of depth one) that make up the packed representation (geman &amp; johnson, 2002), <papid> P02-1036 </papid>or has taken amore relaxed approach by allowing non-local prop 57 configuration unifications copies hypotheses space unpack total(#) (#) (#) (kbyte) (ms) (ms) greedy best-first 5980 1447 ? 9202 ? 400 selective, no caching 5535 1523 1245 27188 70 410 selective, with cache 4915 1522 382 27176 10 350 table 5: efficiency effects of the instantiation failure caching and propagation with gg, without grandparenting.</citsent>
<aftsection>
<nextsent>all statistics are averages over the 1941 items that complete within the resource bounds in all three configurations.
</nextsent>
<nextsent>unification, copies, unpack, and total have the same interpretation as in table 4, and hypotheses is the average count of hypothesized sub-trees.
</nextsent>
<nextsent>erties but without addressing the problem of how to efficiently extract the top-ranked trees from packed forest (miyao &amp; tsujii, 2002).
</nextsent>
<nextsent>probably the work closest in spirit to our approach is that of malouf &amp; van noord (2004), who use an hpsg grammar comparable to the erg and gg,non-local me features, and two-phase parse forest creation and unpacking approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD378">
<title id=" W07-0811.xml">an arabic slot grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we focus on the integration of bama with asg, and on new, expressive sg grammar formalism, sgf, and illustrate how sgf is used to advantage in asg.
</prevsent>
<prevsent>in this paper we describe an initial version of slot grammar parser, asg, for arabic.
</prevsent>
</prevsection>
<citsent citstr=" J80-1003 ">
slot grammar (sg) (mccord, 1980.<papid> J80-1003 </papid></citsent>
<aftsection>
<nextsent>1993) is dependency oriented, and has the feature that deep structure (via logical predicate arguments) and surface structure are both shown in parse trees.
</nextsent>
<nextsent>a new formalism sgf (slot grammar formal ism) for sg syntax rules has been developed (mccord, 2006), and the asg syntax rules are written in sgf.
</nextsent>
<nextsent>sgf is largely declarative, and can be called object-oriented?
</nextsent>
<nextsent>in sense we will explain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD379">
<title id=" W07-0811.xml">an arabic slot grammar parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>no information is provided regarding the coverage of the grammar or the performance of the parser.
</prevsent>
<prevsent>more performance data is available for two related statistical parsers trained on arabic treebank data.
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
bikel (2004) implementation of the collins (2003) <papid> J03-4003 </papid>parser, trained on the arabic treebank 1 (atb1), reached recall/precision = 75.4/76.0 on sentences of 40 words or less and 72.5/73.4 on all sentences.</citsent>
<aftsection>
<nextsent>kulick et al (2006) used the bikel parser on revised version of the atb1 with results comparable to bikel, and then on atb3, where initial performance dropped slightly.
</nextsent>
<nextsent>a number of successive improvements allowed the parser to achieve recall/precision = 78.14/80.26 on sentences of 40 words or less and 73.61/75.64 on all sentences.
</nextsent>
<nextsent>the two most substantial improvements were obtained by changing the handling of punctuation and choosing tagset that preserves bit more information than the severely reduced one distributed with the atb segments.
</nextsent>
<nextsent>other statistical parsers that have been used with arabic include one trained on segment of the prague arabic dependency treebank (! #$% et al, 87 2004) and then used to assist in the annotation of the remainder, but little seems to be published about its performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD380">
<title id=" W07-0811.xml">an arabic slot grammar parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>edu/downloads/ lex-parser.shtml), but no specific performance information could be found.
</prevsent>
<prevsent>it is based on the ideas that there are advantages in factoring out the phrase structure tree and the lexical dependency tree models and estimating them separately, and that significant improvements can be achieved without including any lexical dependency information by adding few linguistically motivated annotations to phrase structure tree models (klein and manning, 2002, 2003).
</prevsent>
</prevsection>
<citsent citstr=" E06-1047 ">
finally chiang et al (2006) <papid> E06-1047 </papid>used both bikel (2002) and chiang (2000) <papid> P00-1058 </papid>parsers to develop different approaches to parsing text in levantine arabic based on the arabic treebank data.</citsent>
<aftsection>
<nextsent>even less information was found for parsing of other semitic languages (with the exception of http://www.cs.technion.ac.il/~winter/corpus project/project-description.html) and wintner (1998) <papid> W98-1011 </papid>discussion of hebrew syntax form computational perspective.</nextsent>
<nextsent>however, while the authors are not very familiar with this language, known similarities with arabic give us reason to believe that some of our work on asg could be readily reusable for hebrew sg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD381">
<title id=" W07-0811.xml">an arabic slot grammar parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>edu/downloads/ lex-parser.shtml), but no specific performance information could be found.
</prevsent>
<prevsent>it is based on the ideas that there are advantages in factoring out the phrase structure tree and the lexical dependency tree models and estimating them separately, and that significant improvements can be achieved without including any lexical dependency information by adding few linguistically motivated annotations to phrase structure tree models (klein and manning, 2002, 2003).
</prevsent>
</prevsection>
<citsent citstr=" P00-1058 ">
finally chiang et al (2006) <papid> E06-1047 </papid>used both bikel (2002) and chiang (2000) <papid> P00-1058 </papid>parsers to develop different approaches to parsing text in levantine arabic based on the arabic treebank data.</citsent>
<aftsection>
<nextsent>even less information was found for parsing of other semitic languages (with the exception of http://www.cs.technion.ac.il/~winter/corpus project/project-description.html) and wintner (1998) <papid> W98-1011 </papid>discussion of hebrew syntax form computational perspective.</nextsent>
<nextsent>however, while the authors are not very familiar with this language, known similarities with arabic give us reason to believe that some of our work on asg could be readily reusable for hebrew sg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD382">
<title id=" W07-0811.xml">an arabic slot grammar parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>it is based on the ideas that there are advantages in factoring out the phrase structure tree and the lexical dependency tree models and estimating them separately, and that significant improvements can be achieved without including any lexical dependency information by adding few linguistically motivated annotations to phrase structure tree models (klein and manning, 2002, 2003).
</prevsent>
<prevsent>finally chiang et al (2006) <papid> E06-1047 </papid>used both bikel (2002) and chiang (2000) <papid> P00-1058 </papid>parsers to develop different approaches to parsing text in levantine arabic based on the arabic treebank data.</prevsent>
</prevsection>
<citsent citstr=" W98-1011 ">
even less information was found for parsing of other semitic languages (with the exception of http://www.cs.technion.ac.il/~winter/corpus project/project-description.html) and wintner (1998) <papid> W98-1011 </papid>discussion of hebrew syntax form computational perspective.</citsent>
<aftsection>
<nextsent>however, while the authors are not very familiar with this language, known similarities with arabic give us reason to believe that some of our work on asg could be readily reusable for hebrew sg.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD383">
<title id=" W08-0325.xml">tectomt highly modular mt system with tectogrammatics used as transfer layer </title>
<section> translation procedure.  </section>
<citcontext>
<prevsection>
<prevsent>b1: segment the source english text into sentences.
</prevsent>
<prevsent>b2: split the sentences into sequences of tokens, roughly according to penn treebank (ptb for short; (marcus et al, 1994)) conventions.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
b3: tag the tokens with ptb-style pos tags using tagger(brants, 2000).<papid> A00-1031 </papid></citsent>
<aftsection>
<nextsent>b4: fix some tagging errors systematically made by the tagger using rule-based corrector.
</nextsent>
<nextsent>b5: lemmatize the tokens using morpha, (minnen et al, 2000).<papid> W00-1427 </papid></nextsent>
<nextsent>2.2 from english m-layer to english p-layer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD384">
<title id=" W08-0325.xml">tectomt highly modular mt system with tectogrammatics used as transfer layer </title>
<section> translation procedure.  </section>
<citcontext>
<prevsection>
<prevsent>b3: tag the tokens with ptb-style pos tags using tagger(brants, 2000).<papid> A00-1031 </papid></prevsent>
<prevsent>b4: fix some tagging errors systematically made by the tagger using rule-based corrector.</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
b5: lemmatize the tokens using morpha, (minnen et al, 2000).<papid> W00-1427 </papid></citsent>
<aftsection>
<nextsent>2.2 from english m-layer to english p-layer.
</nextsent>
<nextsent>b6: build ptb-style phrase-structure tree for each sentence using parser (collins, 1999).
</nextsent>
<nextsent>2.3 from english p-layer to english a-layer.
</nextsent>
<nextsent>b7: in each phrase, mark the head node (using set of heuristic rules).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD385">
<title id=" W08-0325.xml">tectomt highly modular mt system with tectogrammatics used as transfer layer </title>
<section> translation procedure.  </section>
<citcontext>
<prevsection>
<prevsent>information about aspect (perfec tive/imperfective) is necessary for making decisions about forming complex future tense in czech.
</prevsent>
<prevsent>b39: apply rule-based correction of translated date/time expressions (several templates such as 1970s, july 1, etc.).
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
b40: fix grammateme values in places where the english-czech grammateme correspondence is not trivial (e.g., if an english gerund expression is translated using czech subordinating clause, the 2the translation mapping from english formemes to czechformemes was obtained as follows: we analyzed 10,000 sentence pairs from the wmt08 training data up to the t-layer (using tagger shipped with the pdt and parser (mcdonald et al., 2005) <papid> H05-1066 </papid>for czech), added formemes to t-trees on both sides,aligned the t-trees (using set of weighted heuristic rules, similarly to (menezes and richardson, 2001)), <papid> W01-1406 </papid>and from the alignedt-node pairs extracted for each english formeme its most frequent czech counterpart.3the dictionary was created by merging the translation dictionary from pcedt ((curn and others, 2004)) and translation dictionary extracted from part of the parallel corpus czeng ((bojar and zabokrtsky?, 2006)) aligned at word-level by giza++ ((och and ney, 2003)).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>4czech nouns have grammatical gender which is (among others) important for resolving grammatical agreement.
</nextsent>
<nextsent>tense grammateme has to be filled).
</nextsent>
<nextsent>b41: negate verb forms where some arguments of the verbs bear negative meaning (double negation in czech).
</nextsent>
<nextsent>b42:verb t-nodes inactive voice that have transitive tlemma and no accusative object, are turned to re flexives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD386">
<title id=" W08-0325.xml">tectomt highly modular mt system with tectogrammatics used as transfer layer </title>
<section> translation procedure.  </section>
<citcontext>
<prevsection>
<prevsent>information about aspect (perfec tive/imperfective) is necessary for making decisions about forming complex future tense in czech.
</prevsent>
<prevsent>b39: apply rule-based correction of translated date/time expressions (several templates such as 1970s, july 1, etc.).
</prevsent>
</prevsection>
<citsent citstr=" W01-1406 ">
b40: fix grammateme values in places where the english-czech grammateme correspondence is not trivial (e.g., if an english gerund expression is translated using czech subordinating clause, the 2the translation mapping from english formemes to czechformemes was obtained as follows: we analyzed 10,000 sentence pairs from the wmt08 training data up to the t-layer (using tagger shipped with the pdt and parser (mcdonald et al., 2005) <papid> H05-1066 </papid>for czech), added formemes to t-trees on both sides,aligned the t-trees (using set of weighted heuristic rules, similarly to (menezes and richardson, 2001)), <papid> W01-1406 </papid>and from the alignedt-node pairs extracted for each english formeme its most frequent czech counterpart.3the dictionary was created by merging the translation dictionary from pcedt ((curn and others, 2004)) and translation dictionary extracted from part of the parallel corpus czeng ((bojar and zabokrtsky?, 2006)) aligned at word-level by giza++ ((och and ney, 2003)).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>4czech nouns have grammatical gender which is (among others) important for resolving grammatical agreement.
</nextsent>
<nextsent>tense grammateme has to be filled).
</nextsent>
<nextsent>b41: negate verb forms where some arguments of the verbs bear negative meaning (double negation in czech).
</nextsent>
<nextsent>b42:verb t-nodes inactive voice that have transitive tlemma and no accusative object, are turned to re flexives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD387">
<title id=" W08-0325.xml">tectomt highly modular mt system with tectogrammatics used as transfer layer </title>
<section> translation procedure.  </section>
<citcontext>
<prevsection>
<prevsent>information about aspect (perfec tive/imperfective) is necessary for making decisions about forming complex future tense in czech.
</prevsent>
<prevsent>b39: apply rule-based correction of translated date/time expressions (several templates such as 1970s, july 1, etc.).
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
b40: fix grammateme values in places where the english-czech grammateme correspondence is not trivial (e.g., if an english gerund expression is translated using czech subordinating clause, the 2the translation mapping from english formemes to czechformemes was obtained as follows: we analyzed 10,000 sentence pairs from the wmt08 training data up to the t-layer (using tagger shipped with the pdt and parser (mcdonald et al., 2005) <papid> H05-1066 </papid>for czech), added formemes to t-trees on both sides,aligned the t-trees (using set of weighted heuristic rules, similarly to (menezes and richardson, 2001)), <papid> W01-1406 </papid>and from the alignedt-node pairs extracted for each english formeme its most frequent czech counterpart.3the dictionary was created by merging the translation dictionary from pcedt ((curn and others, 2004)) and translation dictionary extracted from part of the parallel corpus czeng ((bojar and zabokrtsky?, 2006)) aligned at word-level by giza++ ((och and ney, 2003)).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>4czech nouns have grammatical gender which is (among others) important for resolving grammatical agreement.
</nextsent>
<nextsent>tense grammateme has to be filled).
</nextsent>
<nextsent>b41: negate verb forms where some arguments of the verbs bear negative meaning (double negation in czech).
</nextsent>
<nextsent>b42:verb t-nodes inactive voice that have transitive tlemma and no accusative object, are turned to re flexives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD388">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>without it, ac cept/fail grammar rules must either be overly strong or admit very large numbers of parses.
</prevsent>
<prevsent>symbolic parsers have recently been augmented by stochastic post-processors for output disambiguation, which reduces their independence from corpora.
</prevsent>
</prevsection>
<citsent citstr=" N04-1013 ">
both the lfg xle parser (kaplan et.al. 2004), <papid> N04-1013 </papid>and the hpsg lingo erg parser (tou tanova et al 2005) have such additions.</citsent>
<aftsection>
<nextsent>this paper examines significant aspects of purely symbolic alternative: the preference and pruning system of the rh (retro-hybrid) parser (newman, 2007).<papid> N07-2031 </papid></nextsent>
<nextsent>the parser combines preexisting, efficient shallow parser with an overlay parser that builds on the emitted chunks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD389">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>symbolic parsers have recently been augmented by stochastic post-processors for output disambiguation, which reduces their independence from corpora.
</prevsent>
<prevsent>both the lfg xle parser (kaplan et.al. 2004), <papid> N04-1013 </papid>and the hpsg lingo erg parser (tou tanova et al 2005) have such additions.</prevsent>
</prevsection>
<citsent citstr=" N07-2031 ">
this paper examines significant aspects of purely symbolic alternative: the preference and pruning system of the rh (retro-hybrid) parser (newman, 2007).<papid> N07-2031 </papid></citsent>
<aftsection>
<nextsent>the parser combines preexisting, efficient shallow parser with an overlay parser that builds on the emitted chunks.
</nextsent>
<nextsent>the over lay parser is  retro  in that the grammar is related to atns (augmented transition networks) originated by woods (1970).
</nextsent>
<nextsent>rh delivers single  best  parses providing syntactic categories, syntactic functions, head features, and other information (figure 1).
</nextsent>
<nextsent>the parent he sized numbers following the category labels in the figure are preference scores, and are explained further on.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD391">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the parent he sized numbers following the category labels in the figure are preference scores, and are explained further on.
</prevsent>
<prevsent>while the parses are not quite as detailed as those obtained using  deep  grammars, the missing information, mostly relating to long distance dependencies, can be added at far less cost in post-parse phase that operates only on single best parse.
</prevsent>
</prevsection>
<citsent citstr=" P02-1018 ">
methods for doing so, for stochastic parser output, are described by johnson (2002) <papid> P02-1018 </papid>and cahill et al(2004).<papid> P04-1041 </papid></citsent>
<aftsection>
<nextsent>the hybrid parser exceeds most stochastic parsers in speed, and approaches them inaccuracy, even based on limited manual  training  on particular idiom, so the preference system is successful one (see section 6), and continues to im prove.
</nextsent>
<nextsent>the rh preference system builds on earlier methods.
</nextsent>
<nextsent>the major difference is far simpler scoring system, which has considerably facilitated overlay parser development.
</nextsent>
<nextsent>also, the architecture allows the use of large numbers of preference tests without impacting parser speed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD392">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the parent he sized numbers following the category labels in the figure are preference scores, and are explained further on.
</prevsent>
<prevsent>while the parses are not quite as detailed as those obtained using  deep  grammars, the missing information, mostly relating to long distance dependencies, can be added at far less cost in post-parse phase that operates only on single best parse.
</prevsent>
</prevsection>
<citsent citstr=" P04-1041 ">
methods for doing so, for stochastic parser output, are described by johnson (2002) <papid> P02-1018 </papid>and cahill et al(2004).<papid> P04-1041 </papid></citsent>
<aftsection>
<nextsent>the hybrid parser exceeds most stochastic parsers in speed, and approaches them inaccuracy, even based on limited manual  training  on particular idiom, so the preference system is successful one (see section 6), and continues to im prove.
</nextsent>
<nextsent>the rh preference system builds on earlier methods.
</nextsent>
<nextsent>the major difference is far simpler scoring system, which has considerably facilitated overlay parser development.
</nextsent>
<nextsent>also, the architecture allows the use of large numbers of preference tests without impacting parser speed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD393">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> background: symbolic preference.  </section>
<citcontext>
<prevsection>
<prevsent>one of the earliest works in the area is by wilks (1975), which presented view of preference as based on semantic templates.
</prevsent>
<prevsent>throughout the 1980 there was considerable amount of work devoted to finding general principles, often cognitively oriented, for preference rules, and then to devise mechanisms for using them in practical systems.
</prevsent>
</prevsection>
<citsent citstr=" C90-3029 ">
hobbs and bear (1990) <papid> C90-3029 </papid>provide useful summary of the evolved principles.</citsent>
<aftsection>
<nextsent>slightly restated, these principles are: 1.
</nextsent>
<nextsent>prefer attachments in the  most restrictive.
</nextsent>
<nextsent>context .
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD397">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> background: symbolic preference.  </section>
<citcontext>
<prevsection>
<prevsent>+ crs (cn |c, cc1,?.ccn-1) where each crs (cci|_ ) evaluates cci in the context of the prior content of the constituent cc and the category c..
</prevsent>
<prevsent>few publications specify details of how preference scores are assigned and combined.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
for example, hobbs and bear (1990) <papid> C90-3029 </papid>say only that  when 1 the idea has also been used directly in stochastic parsers that consider all possible attachments, for example, by mcdonald et al (2005).<papid> H05-1066 </papid></citsent>
<aftsection>
<nextsent>84 non-terminal node of parse tree is constructed, it is given an initial score which is the sum of the scores of its child nodes.
</nextsent>
<nextsent>various conditions are checked during the construction of the node and, as result, score of 20, 10, 3, -3, -10, or -20 may be added to the initial score.
</nextsent>
<nextsent>mccord (1993), <papid> H93-1025 </papid>however, carefully describes how the elements of trs are computed in his slot grammar system.</nextsent>
<nextsent>each element value is the sum of the results of up to 8 optional, typed tests, relating to structural, syntactic, and semantic conditions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD398">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> background: symbolic preference.  </section>
<citcontext>
<prevsection>
<prevsent>84 non-terminal node of parse tree is constructed, it is given an initial score which is the sum of the scores of its child nodes.
</prevsent>
<prevsent>various conditions are checked during the construction of the node and, as result, score of 20, 10, 3, -3, -10, or -20 may be added to the initial score.
</prevsent>
</prevsection>
<citsent citstr=" H93-1025 ">
mccord (1993), <papid> H93-1025 </papid>however, carefully describes how the elements of trs are computed in his slot grammar system.</citsent>
<aftsection>
<nextsent>each element value is the sum of the results of up to 8 optional, typed tests, relating to structural, syntactic, and semantic conditions.
</nextsent>
<nextsent>one of these tests, relating to coordination, is complex test involving 7 factors assessing parallelism.
</nextsent>
<nextsent>2.3 multi-level contexted scoring.
</nextsent>
<nextsent>the scores assigned by symbolic preference systems to particular relationships or combinations usually indicate not just whether they are preferred or dis preferred, but to what degree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD399">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> background: symbolic preference.  </section>
<citcontext>
<prevsection>
<prevsent>2.4 corpus-based preference.
</prevsent>
<prevsent>in the early 1990 s, the increasing availability and use of corpora, together with sense that multilevel symbolic preference scores were based on ad hoc judgments, led to experiments and systems that used empirical methods to obtain preference weights.
</prevsent>
</prevsection>
<citsent citstr=" J93-1005 ">
examples of this work include system by liu et al(1990), and experiments by hindle and rooth (1993), <papid> J93-1005 </papid>and resnik and hearst (1993).<papid> W93-0307 </papid>2 these efforts had mixed success, suggesting that while multi-level preference scores are problematic, integrating some corpus data does not solve the problems.</citsent>
<aftsection>
<nextsent>in light of later developments, this might be expected.
</nextsent>
<nextsent>full-scale contemporary stochastic parsers use broad range of interacting features to obtain their fine-grained results; frequencies of particular relationships are just one aspect.
</nextsent>
<nextsent>2.5 ot-based preference.
</nextsent>
<nextsent>a more recent approach to symbolic preference adapts optimality theory to parser and generator preference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD400">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> background: symbolic preference.  </section>
<citcontext>
<prevsection>
<prevsent>2.4 corpus-based preference.
</prevsent>
<prevsent>in the early 1990 s, the increasing availability and use of corpora, together with sense that multilevel symbolic preference scores were based on ad hoc judgments, led to experiments and systems that used empirical methods to obtain preference weights.
</prevsent>
</prevsection>
<citsent citstr=" W93-0307 ">
examples of this work include system by liu et al(1990), and experiments by hindle and rooth (1993), <papid> J93-1005 </papid>and resnik and hearst (1993).<papid> W93-0307 </papid>2 these efforts had mixed success, suggesting that while multi-level preference scores are problematic, integrating some corpus data does not solve the problems.</citsent>
<aftsection>
<nextsent>in light of later developments, this might be expected.
</nextsent>
<nextsent>full-scale contemporary stochastic parsers use broad range of interacting features to obtain their fine-grained results; frequencies of particular relationships are just one aspect.
</nextsent>
<nextsent>2.5 ot-based preference.
</nextsent>
<nextsent>a more recent approach to symbolic preference adapts optimality theory to parser and generator preference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD403">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> background: the rh parser.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 shallow parser.
</prevsent>
<prevsent>the shallow parser used, xip, was developed by xrce (xerox research center europe).
</prevsent>
</prevsection>
<citsent citstr=" W04-2007 ">
it is actually full parser, whose per-sentence output consists of single tree of basic chunks, together with identifications of (sometimes alternative) typed dependences among the chunk heads (ait mokhtar et al 2002, gala 2004).<papid> W04-2007 </papid></citsent>
<aftsection>
<nextsent>but because the xip dependency analysis for english was not mature at the time that work on rh began, and because classic parse tree annotated by syntactic functions is more convenient for some applications, we focused on the output chunks.
</nextsent>
<nextsent>xip is astonishingly fast, contributing very little to parse times (about 20%).
</nextsent>
<nextsent>it consists of the xip processor, plus grammars for number of languages.
</nextsent>
<nextsent>the grammar for particular language consists of: (a) finite-state lexicon producing alternative part-of-speech and morphological analyses for each token, together with bit-expressed subcategorization and control features, and (some) semantic features, (b) substitutable tagger identifying the most probable part of speech for each token, and (c) sequentially applied rule sets that extend and modify lexical information, disambiguate tags, identify named entities and other multi words, and produce output chunks and inter-chunk head dependences (the latter not used in the hybrid).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD406">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> training the preference system.  </section>
<citcontext>
<prevsection>
<prevsent>an example is the person and number of syntactic subjects, allowing contexted preference tests for finite verb phrases to check for subject consistency.
</prevsent>
<prevsent>5.1 relationship to  supervised  training.
</prevsent>
</prevsection>
<citsent citstr=" P04-1015 ">
to illustrate the relationship between the above symbolic training method for preference scoring and corpus-based methods, perhaps the easiest way is to compare it to an adaptation (collins and roark, 2004) <papid> P04-1015 </papid>of the perceptron training method to the problem of obtaining best parse (either directly, or for parse reranking), because the two methods are analogous in number of ways.</citsent>
<aftsection>
<nextsent>the basic adapted perceptron training assumes generator function producing parses for inputs.
</nextsent>
<nextsent>each such parse is associated with vector of feature values that express the number of times the feature appears in the input or parse.
</nextsent>
<nextsent>the features used are those identified by roark (2001) <papid> J01-2004 </papid>for top down stochastic parser.</nextsent>
<nextsent>the training method obtains weight vector (initially 0) for the feature values, by ite rating multiple times over pairs  xi, yi  where xi is training input, and yi is the correct parse for xi.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD407">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> training the preference system.  </section>
<citcontext>
<prevsection>
<prevsent>the basic adapted perceptron training assumes generator function producing parses for inputs.
</prevsent>
<prevsent>each such parse is associated with vector of feature values that express the number of times the feature appears in the input or parse.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
the features used are those identified by roark (2001) <papid> J01-2004 </papid>for top down stochastic parser.</citsent>
<aftsection>
<nextsent>the training method obtains weight vector (initially 0) for the feature values, by ite rating multiple times over pairs  xi, yi  where xi is training input, and yi is the correct parse for xi.
</nextsent>
<nextsent>for each pair, the best current parse zi for xi produced by the generator, with feature value vector v(zi), is selected based on the current value of (w ? v(zi)).
</nextsent>
<nextsent>then if zi ? yi, is incremented by v(yi), and dec 89 remented by v(zi).
</nextsent>
<nextsent>after training, the weights in are divided by the number of training steps (# inputs * # iterations).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD408">
<title id=" W07-2211.xml">symbolic preference using simple scoring </title>
<section> some experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>table 2 compares speed and coverage for rh and collins model3 (collins, 1999) run on the same cpu.
</prevsent>
<prevsent>the table also extrapolates the results to two other parsers, based on reported comparisons with collins.
</prevsent>
</prevsection>
<citsent citstr=" W05-1513 ">
one extrapolation is to very fast stochastic parser by sagae and lavie (2005).<papid> W05-1513 </papid></citsent>
<aftsection>
<nextsent>the comparison indicates that the rh parser speed is close to that of the best contemporary parsers.
</nextsent>
<nextsent>the second extrapolation is to the lfg xle parser (kaplan et al 2004) <papid> N04-1013 </papid>for english, consisting of highly developed symbolic parser and grammar, an ot-based preference component, and stochastic back end to select among remaining alternative parser outputs.</nextsent>
<nextsent>two sets of values are given for xle, one obtained using the full english grammar, and one obtained using reduced grammar ignoring less-frequently applicable rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD411">
<title id=" W08-0304.xml">regularization and search for minimum error rate training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is shown that the stochastic method obtains test set gains of +0.98 bleu on mt03 and +0.61 bleu on mt05.
</prevsent>
<prevsent>we also pre senta method for regularizing the mert objective that achieves statistically significant gains when combined with both powells method and coordinate descent.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
och (2003)<papid> P03-1021 </papid>introduced minimum error rate training(mert) as an alternative training regime to the conditional likelihood objective previously used with log-linear translation models (och &amp; ney, 2002).<papid> P02-1038 </papid>this approach attempts to improve translation quality by optimizing an automatic translation evaluation metric, such as the bleu score (papineni et al,2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>this is accomplished by either directly walking the error surface provided by an evaluation metric w.r.t. the model weights or by using gradient based techniques on continuous approximation ofsuch surface.
</nextsent>
<nextsent>while the former is piece wise constant and thus cannot be optimized using gradient techniques, och (2003)<papid> P03-1021 </papid>provides an approach that performs such training efficiently.</nextsent>
<nextsent>in this paper we explore number of variations on mert.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD416">
<title id=" W08-0304.xml">regularization and search for minimum error rate training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is shown that the stochastic method obtains test set gains of +0.98 bleu on mt03 and +0.61 bleu on mt05.
</prevsent>
<prevsent>we also pre senta method for regularizing the mert objective that achieves statistically significant gains when combined with both powells method and coordinate descent.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
och (2003)<papid> P03-1021 </papid>introduced minimum error rate training(mert) as an alternative training regime to the conditional likelihood objective previously used with log-linear translation models (och &amp; ney, 2002).<papid> P02-1038 </papid>this approach attempts to improve translation quality by optimizing an automatic translation evaluation metric, such as the bleu score (papineni et al,2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>this is accomplished by either directly walking the error surface provided by an evaluation metric w.r.t. the model weights or by using gradient based techniques on continuous approximation ofsuch surface.
</nextsent>
<nextsent>while the former is piece wise constant and thus cannot be optimized using gradient techniques, och (2003)<papid> P03-1021 </papid>provides an approach that performs such training efficiently.</nextsent>
<nextsent>in this paper we explore number of variations on mert.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD417">
<title id=" W08-0304.xml">regularization and search for minimum error rate training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is shown that the stochastic method obtains test set gains of +0.98 bleu on mt03 and +0.61 bleu on mt05.
</prevsent>
<prevsent>we also pre senta method for regularizing the mert objective that achieves statistically significant gains when combined with both powells method and coordinate descent.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
och (2003)<papid> P03-1021 </papid>introduced minimum error rate training(mert) as an alternative training regime to the conditional likelihood objective previously used with log-linear translation models (och &amp; ney, 2002).<papid> P02-1038 </papid>this approach attempts to improve translation quality by optimizing an automatic translation evaluation metric, such as the bleu score (papineni et al,2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>this is accomplished by either directly walking the error surface provided by an evaluation metric w.r.t. the model weights or by using gradient based techniques on continuous approximation ofsuch surface.
</nextsent>
<nextsent>while the former is piece wise constant and thus cannot be optimized using gradient techniques, och (2003)<papid> P03-1021 </papid>provides an approach that performs such training efficiently.</nextsent>
<nextsent>in this paper we explore number of variations on mert.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD435">
<title id=" W08-0304.xml">regularization and search for minimum error rate training </title>
<section> minimum error rate training.  </section>
<citcontext>
<prevsection>
<prevsent>in this section, we review two search strategies that, in conjunction with the line search just described, can be used to drive mert.
</prevsent>
<prevsent>the first, powells method, was advocated by och (2003)<papid> P03-1021 </papid>when mertwas first introduced for statistical machine transla tion.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the second, which we call koehn-coordinatedescent (kcd)6, is used by the mert utility packaged with the popular moses statistical machine translation system (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>6moses uses david chiangs cmert package.
</nextsent>
<nextsent>within the source file mert.c, the function that implements the overall search strategy, optimize koehn(), is based on philipp koehns perl script for mert optimization that was distributed with pharaoh.
</nextsent>
<nextsent>29 2.2.1 powells method powells method (press et al, 2007) attempts to efficiently search the objective by constructing set of mutually non-interfering search directions.
</nextsent>
<nextsent>the basic procedure is as follows: (i) collection of search directions is initial ized to be the coordinates of the space being searched; (ii) the objective is minimized by looping through the search directions and performing line minimization for each; (iii) new search direction is constructed that summarizes the cumulative direction of the progress made during step (ii) (i.e., dnew = wpreii wpostii).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD442">
<title id=" W08-0304.xml">regularization and search for minimum error rate training </title>
<section> extensions.  </section>
<citcontext>
<prevsection>
<prevsent>one candidate for performing such regularization is the continuous approximation of the mert objective, = epw(`).
</prevsent>
<prevsent>och (2003)<papid> P03-1021 </papid>claimed that this approximation achieved essentially equivalent performance to that obtained when directly using the loss as the objective, = `.</prevsent>
</prevsection>
<citsent citstr=" D07-1055 ">
however, zens et al (2007) <papid> D07-1055 </papid>found that = epw(`) achieved substantially better test set performance than = `, even though it performs slightly worse on the data used to train theparameters.</citsent>
<aftsection>
<nextsent>similarly, smith and eisner (2006) <papid> P06-2101 </papid>reported test set gains for the related technique of minimum risk annealing, which incorporates temper8however, we speculate that similar results could be obtained using uniform distribution over (1), uniform distribution over (1)ature parameter that trades off between the smoothness of the objective and the degree it reflects the underlying piece wise constant error surface.</nextsent>
<nextsent>how ever, the most straightforward implementation of such methods requires loss that can be applied atthe sentence level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD443">
<title id=" W08-0304.xml">regularization and search for minimum error rate training </title>
<section> extensions.  </section>
<citcontext>
<prevsection>
<prevsent>och (2003)<papid> P03-1021 </papid>claimed that this approximation achieved essentially equivalent performance to that obtained when directly using the loss as the objective, = `.</prevsent>
<prevsent>however, zens et al (2007) <papid> D07-1055 </papid>found that = epw(`) achieved substantially better test set performance than = `, even though it performs slightly worse on the data used to train theparameters.</prevsent>
</prevsection>
<citsent citstr=" P06-2101 ">
similarly, smith and eisner (2006) <papid> P06-2101 </papid>reported test set gains for the related technique of minimum risk annealing, which incorporates temper8however, we speculate that similar results could be obtained using uniform distribution over (1), uniform distribution over (1)ature parameter that trades off between the smoothness of the objective and the degree it reflects the underlying piece wise constant error surface.</citsent>
<aftsection>
<nextsent>how ever, the most straightforward implementation of such methods requires loss that can be applied atthe sentence level.
</nextsent>
<nextsent>if the evaluation metric of interest does not have this property (e.g. bleu), the loss must be approximated using some surrogate, with successful learning then being tied to how well the surrogate captures the critical properties of theun derlying loss.
</nextsent>
<nextsent>the techniques of zens et al (2007) <papid> D07-1055 </papid>&amp; smit hand eisner (2006) <papid> P06-2101 </papid>regularize by implicitly smoothing over nearby plateaus in the error surface.</nextsent>
<nextsent>we propose an alternative scheme that operates direct lyon the piece wise constant objective and that mitigates the problem of spurious local minima by explicitly smoothing over adjacent plateaus during theline search.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD447">
<title id=" W08-0304.xml">regularization and search for minimum error rate training </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>ideally, sizable number of random restarts should be used in order to minimize the degree to which the results are influenced by some runs receiving starting points that are better in genera lor perhaps better/worse w.r.t. their specific optimization strategy.
</prevsent>
<prevsent>method dev test test mt02 mt03 mt05 kcd 30.967 30.778 29.580 powell 30.638 30.692 29.780 random 31.681 31.754 30.191 table 3: bleu scores obtained by models trained using the three different parameter search strategies: powells method, kcd, and stochastic search.data.
</prevsent>
</prevsection>
<citsent citstr=" I05-3027 ">
the chinese data was word segmented using the gale y2 retest release of the stanford crf segmenter (tseng et al, 2005).<papid> I05-3027 </papid></citsent>
<aftsection>
<nextsent>phrases were extracted using the typical approach described in koehn et al (2003) <papid> N03-1017 </papid>of running giza++ (och &amp; ney, 2003) <papid> J03-1002 </papid>in both directions and then merging the alignments using the grow-diag-final heuristic.from the merged alignments we also extracted bidirectional lexical reordering model conditioned on the source and the target phrases (tillmann, 2004) (<papid> N04-4026 </papid>koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>a 5-gram language model was created using the sri language modeling toolkit(stolcke, 2002) and trained using the gigaword corpus and english sentences from the parallel data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD448">
<title id=" W08-0304.xml">regularization and search for minimum error rate training </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>method dev test test mt02 mt03 mt05 kcd 30.967 30.778 29.580 powell 30.638 30.692 29.780 random 31.681 31.754 30.191 table 3: bleu scores obtained by models trained using the three different parameter search strategies: powells method, kcd, and stochastic search.data.
</prevsent>
<prevsent>the chinese data was word segmented using the gale y2 retest release of the stanford crf segmenter (tseng et al, 2005).<papid> I05-3027 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
phrases were extracted using the typical approach described in koehn et al (2003) <papid> N03-1017 </papid>of running giza++ (och &amp; ney, 2003) <papid> J03-1002 </papid>in both directions and then merging the alignments using the grow-diag-final heuristic.from the merged alignments we also extracted bidirectional lexical reordering model conditioned on the source and the target phrases (tillmann, 2004) (<papid> N04-4026 </papid>koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>a 5-gram language model was created using the sri language modeling toolkit(stolcke, 2002) and trained using the gigaword corpus and english sentences from the parallel data.
</nextsent>
<nextsent>as illustrated in table 3, powells method and kcd achieve very similar level of performance, with kcd modestly outperforming powell on the mt03test set while powell modestly outperforms coordinate descent on the mt05 test set.
</nextsent>
<nextsent>moreover, the fact that powells algorithm did not perform better than kcd on the training data10, and in fact actually performed modestly worse, suggests that powells additional search machinery does not provide much benefit for mert objectives.similarly, the fact that the stochastic search obtains much higher dev set score than either powell or kcd indicates that it is doing better job of optimizing the objective than either of the two alternatives.
</nextsent>
<nextsent>these gains suggest that stochastic search does make better use of the global minimum line search than the alternative methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD449">
<title id=" W08-0304.xml">regularization and search for minimum error rate training </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>method dev test test mt02 mt03 mt05 kcd 30.967 30.778 29.580 powell 30.638 30.692 29.780 random 31.681 31.754 30.191 table 3: bleu scores obtained by models trained using the three different parameter search strategies: powells method, kcd, and stochastic search.data.
</prevsent>
<prevsent>the chinese data was word segmented using the gale y2 retest release of the stanford crf segmenter (tseng et al, 2005).<papid> I05-3027 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
phrases were extracted using the typical approach described in koehn et al (2003) <papid> N03-1017 </papid>of running giza++ (och &amp; ney, 2003) <papid> J03-1002 </papid>in both directions and then merging the alignments using the grow-diag-final heuristic.from the merged alignments we also extracted bidirectional lexical reordering model conditioned on the source and the target phrases (tillmann, 2004) (<papid> N04-4026 </papid>koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>a 5-gram language model was created using the sri language modeling toolkit(stolcke, 2002) and trained using the gigaword corpus and english sentences from the parallel data.
</nextsent>
<nextsent>as illustrated in table 3, powells method and kcd achieve very similar level of performance, with kcd modestly outperforming powell on the mt03test set while powell modestly outperforms coordinate descent on the mt05 test set.
</nextsent>
<nextsent>moreover, the fact that powells algorithm did not perform better than kcd on the training data10, and in fact actually performed modestly worse, suggests that powells additional search machinery does not provide much benefit for mert objectives.similarly, the fact that the stochastic search obtains much higher dev set score than either powell or kcd indicates that it is doing better job of optimizing the objective than either of the two alternatives.
</nextsent>
<nextsent>these gains suggest that stochastic search does make better use of the global minimum line search than the alternative methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD450">
<title id=" W08-0304.xml">regularization and search for minimum error rate training </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>method dev test test mt02 mt03 mt05 kcd 30.967 30.778 29.580 powell 30.638 30.692 29.780 random 31.681 31.754 30.191 table 3: bleu scores obtained by models trained using the three different parameter search strategies: powells method, kcd, and stochastic search.data.
</prevsent>
<prevsent>the chinese data was word segmented using the gale y2 retest release of the stanford crf segmenter (tseng et al, 2005).<papid> I05-3027 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-4026 ">
phrases were extracted using the typical approach described in koehn et al (2003) <papid> N03-1017 </papid>of running giza++ (och &amp; ney, 2003) <papid> J03-1002 </papid>in both directions and then merging the alignments using the grow-diag-final heuristic.from the merged alignments we also extracted bidirectional lexical reordering model conditioned on the source and the target phrases (tillmann, 2004) (<papid> N04-4026 </papid>koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>a 5-gram language model was created using the sri language modeling toolkit(stolcke, 2002) and trained using the gigaword corpus and english sentences from the parallel data.
</nextsent>
<nextsent>as illustrated in table 3, powells method and kcd achieve very similar level of performance, with kcd modestly outperforming powell on the mt03test set while powell modestly outperforms coordinate descent on the mt05 test set.
</nextsent>
<nextsent>moreover, the fact that powells algorithm did not perform better than kcd on the training data10, and in fact actually performed modestly worse, suggests that powells additional search machinery does not provide much benefit for mert objectives.similarly, the fact that the stochastic search obtains much higher dev set score than either powell or kcd indicates that it is doing better job of optimizing the objective than either of the two alternatives.
</nextsent>
<nextsent>these gains suggest that stochastic search does make better use of the global minimum line search than the alternative methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD453">
<title id=" W08-0304.xml">regularization and search for minimum error rate training </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the none entry for each search strategy represents the baseline where no regularization is used.
</prevsent>
<prevsent>statistically significant test set gains,   0.01, over the respective baselines are in bold face.of powells method, diagonal search, with coordinate descents robustness to the sudden jumps between regions that result from global line minimization.
</prevsent>
</prevsection>
<citsent citstr=" W05-0908 ">
using an approximate randomization test for statistical significance (riezler &amp; maxwell, 2005), <papid> W05-0908 </papid>and with kcd as baseline, the gains obtained by stochastic search on mt03 are statistically significant (p = 0.002), as are the gains on mt05 (p = 0.005).</citsent>
<aftsection>
<nextsent>table 4 indicates that performing regularization by either averaging or taking the maximum of adjacent plateaus during the line search leads to gains forboth powells method and kcd.
</nextsent>
<nextsent>however, no reliable additional gains appear to be had when stochastic search is combined with regularization.
</nextsent>
<nextsent>it may seem surprising that the regularization gains for powell &amp; kcd are seen not only in the test sets but on the dev set as well.
</nextsent>
<nextsent>that is, in typical applications, regularization slightly decreases performance on the data used to train the model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD456">
<title id=" W07-1406.xml">recognizing textual entailment using sentence similarity based on dependency tree skeletons </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one is triple similarity function applied on top of the local dependency relations of and h; the other is simple bag-of-words (bow) approach that calculates the overlapping ratio of and t. together, these three methods deal with different entailment cases in practice.
</prevsent>
<prevsent>36
</prevsent>
</prevsection>
<citsent citstr=" W05-1203 ">
conventional methods for rte define measures for the similarity between and either by assuming an independence between words (corley and mihalcea, 2005) <papid> W05-1203 </papid>in bow fashion or by exploiting syntactic interpretations.</citsent>
<aftsection>
<nextsent>(kouylekov and magnini, 2006) explore syntactic tree editing distance to detect entailment relations.
</nextsent>
<nextsent>since they calculate the similarity between the two dependency trees of and directly, the noisy information may decrease accuracy.
</nextsent>
<nextsent>this observation actually motivated us to start from towards the most relevant information in t. logic rules (as proposed by (bos and markert, 2005)) or sequences of allowed rewrite rules (as in (de salvo braz et al, 2005)) are another fashion of tackling rte.
</nextsent>
<nextsent>one the best two teams in rte-2 (tatu et al, 2006) proposed knowledge representation model which achieved about 10% better performance than the third (zanzotto and moschitti, 2006) <papid> P06-1051 </papid>based on their logic prover.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD457">
<title id=" W07-1406.xml">recognizing textual entailment using sentence similarity based on dependency tree skeletons </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>since they calculate the similarity between the two dependency trees of and directly, the noisy information may decrease accuracy.
</prevsent>
<prevsent>this observation actually motivated us to start from towards the most relevant information in t. logic rules (as proposed by (bos and markert, 2005)) or sequences of allowed rewrite rules (as in (de salvo braz et al, 2005)) are another fashion of tackling rte.
</prevsent>
</prevsection>
<citsent citstr=" P06-1051 ">
one the best two teams in rte-2 (tatu et al, 2006) proposed knowledge representation model which achieved about 10% better performance than the third (zanzotto and moschitti, 2006) <papid> P06-1051 </papid>based on their logic prover.</citsent>
<aftsection>
<nextsent>the other best team in rte-2 (hickl et al, 2006) automatically acquired extra training data, enabling them to achieve about 10% better accuracy than the third as well.
</nextsent>
<nextsent>consequently, obtaining more training data and embedding deeper knowledge were expected to be the two main directions pointed out for future research in the rte-2 summary statement.
</nextsent>
<nextsent>how ever, except for the positive cases of sum, t-h pairs are normally not very easy to collect automatically.
</nextsent>
<nextsent>multi-annotator agreement is difficult to reach on most of the cases as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD462">
<title id=" W07-1406.xml">recognizing textual entailment using sentence similarity based on dependency tree skeletons </title>
<section> 1 0 a </section>
<citcontext>
<prevsection>
<prevsent>4 workflow of the main approach.
</prevsent>
<prevsent>our structure similarity function is based on the hypothesis that some particular differences between and will block or change the entailment relationship.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
initially we assume when judging the entailment relation that it holds for each t-h pair 1 we are using minipar (lin, 1998) and stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>as pre processors, see also sec.</citsent>
<aftsection>
<nextsent>5.2.
</nextsent>
<nextsent>2 note that henceforth and will represent either the original texts or the dependency structures.
</nextsent>
<nextsent>(using the default value yes?).
</nextsent>
<nextsent>the major steps are as follows (see also figure 2): 4.1 tree skeleton extractor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD463">
<title id=" W08-0112.xml">what are meeting summaries an analysis of human extractive summaries in meeting corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this study is expected to help better define the speech summarization problem.
</prevsent>
<prevsent>with the fast development of recording and storage techniques in recent years, speech summarization has received more attention.
</prevsent>
</prevsection>
<citsent citstr=" W06-1643 ">
a variety of approaches have been investigated for speech summarization, for example, maximum entropy, conditional random fields, latent semantic analysis, support vector machines, maximum marginal relevance (maskey and hirschberg, 2003; hori et al, 2003; buist et al, 2005; galley, 2006; <papid> W06-1643 </papid>murray et al., 2005; <papid> W05-0905 </papid>zhang et al, 2007; xie and liu, 2008).</citsent>
<aftsection>
<nextsent>these studies used different domains, such as broadcast news,lectures, and meetings.
</nextsent>
<nextsent>in these approaches, different information sources have been examined from both text and speech related features (e.g., prosody, speaker activity, turn-taking, discourse).how to evaluate speech summaries has also been studied recently, but so far there is no consensus on evaluation yet.
</nextsent>
<nextsent>often the goal in evaluation is to develop an automatic metric to have high correlation with human evaluation scores.
</nextsent>
<nextsent>different methods have been used in the above summarization research to compare system generated summaries with human annotation, such as measure, rouge, pyramid, sumaccy (lin and hovy, 2003; <papid> N03-1020 </papid>nenkova and passonneau, 2004; <papid> N04-1019 </papid>hori et al, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD464">
<title id=" W08-0112.xml">what are meeting summaries an analysis of human extractive summaries in meeting corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this study is expected to help better define the speech summarization problem.
</prevsent>
<prevsent>with the fast development of recording and storage techniques in recent years, speech summarization has received more attention.
</prevsent>
</prevsection>
<citsent citstr=" W05-0905 ">
a variety of approaches have been investigated for speech summarization, for example, maximum entropy, conditional random fields, latent semantic analysis, support vector machines, maximum marginal relevance (maskey and hirschberg, 2003; hori et al, 2003; buist et al, 2005; galley, 2006; <papid> W06-1643 </papid>murray et al., 2005; <papid> W05-0905 </papid>zhang et al, 2007; xie and liu, 2008).</citsent>
<aftsection>
<nextsent>these studies used different domains, such as broadcast news,lectures, and meetings.
</nextsent>
<nextsent>in these approaches, different information sources have been examined from both text and speech related features (e.g., prosody, speaker activity, turn-taking, discourse).how to evaluate speech summaries has also been studied recently, but so far there is no consensus on evaluation yet.
</nextsent>
<nextsent>often the goal in evaluation is to develop an automatic metric to have high correlation with human evaluation scores.
</nextsent>
<nextsent>different methods have been used in the above summarization research to compare system generated summaries with human annotation, such as measure, rouge, pyramid, sumaccy (lin and hovy, 2003; <papid> N03-1020 </papid>nenkova and passonneau, 2004; <papid> N04-1019 </papid>hori et al, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD465">
<title id=" W08-0112.xml">what are meeting summaries an analysis of human extractive summaries in meeting corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in these approaches, different information sources have been examined from both text and speech related features (e.g., prosody, speaker activity, turn-taking, discourse).how to evaluate speech summaries has also been studied recently, but so far there is no consensus on evaluation yet.
</prevsent>
<prevsent>often the goal in evaluation is to develop an automatic metric to have high correlation with human evaluation scores.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
different methods have been used in the above summarization research to compare system generated summaries with human annotation, such as measure, rouge, pyramid, sumaccy (lin and hovy, 2003; <papid> N03-1020 </papid>nenkova and passonneau, 2004; <papid> N04-1019 </papid>hori et al, 2003).</citsent>
<aftsection>
<nextsent>typically multiple reference human summaries are used in evaluation in order to account for the inconsistency among human annotations.while there have been efforts on speech summarization approaches and evaluation, some fundamental problems are still unclear.
</nextsent>
<nextsent>for example, what are speech sum maries?
</nextsent>
<nextsent>do humans agree with each other on summaryextraction?
</nextsent>
<nextsent>in this paper, we focus on the meeting domain, one of the most challenging speech genre, to analyze human summary annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD466">
<title id=" W08-0112.xml">what are meeting summaries an analysis of human extractive summaries in meeting corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in these approaches, different information sources have been examined from both text and speech related features (e.g., prosody, speaker activity, turn-taking, discourse).how to evaluate speech summaries has also been studied recently, but so far there is no consensus on evaluation yet.
</prevsent>
<prevsent>often the goal in evaluation is to develop an automatic metric to have high correlation with human evaluation scores.
</prevsent>
</prevsection>
<citsent citstr=" N04-1019 ">
different methods have been used in the above summarization research to compare system generated summaries with human annotation, such as measure, rouge, pyramid, sumaccy (lin and hovy, 2003; <papid> N03-1020 </papid>nenkova and passonneau, 2004; <papid> N04-1019 </papid>hori et al, 2003).</citsent>
<aftsection>
<nextsent>typically multiple reference human summaries are used in evaluation in order to account for the inconsistency among human annotations.while there have been efforts on speech summarization approaches and evaluation, some fundamental problems are still unclear.
</nextsent>
<nextsent>for example, what are speech sum maries?
</nextsent>
<nextsent>do humans agree with each other on summaryextraction?
</nextsent>
<nextsent>in this paper, we focus on the meeting domain, one of the most challenging speech genre, to analyze human summary annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD467">
<title id=" W08-0112.xml">what are meeting summaries an analysis of human extractive summaries in meeting corpus </title>
<section> corpus description.  </section>
<citcontext>
<prevsection>
<prevsent>we use three different metrics to evaluate the variation among human summaries, including kappa statistic, rouge score, and new proposed divergence distance score to reflect the coherence and quality of an annotation.
</prevsent>
<prevsent>we use the icsi meeting corpus (janin et al, 2003) which contains 75 naturally-occurred meetings, each about anhour long.
</prevsent>
</prevsection>
<citsent citstr=" W04-2319 ">
all of them have been transcribed and annotated with dialog acts (da) (shriberg et al, 2004), <papid> W04-2319 </papid>topics, and abs tractive and extractive summaries in the ami project (murray et al, 2005).<papid> W05-0905 </papid>we selected 27 meetings from this corpus.</citsent>
<aftsection>
<nextsent>three annotators (undergraduate students) were recruited to extract summary sentences on topic basis using the topic segments from the ami annotation.
</nextsent>
<nextsent>each sentence corresponds to one da annotated in the corpus.
</nextsent>
<nextsent>the annotators were told to use their own judgment to pick summary sentences that are informative and can preserve discussion flow.
</nextsent>
<nextsent>the recommended percentages for the selected summary sentences and words were set to 8.0% and 16.0% respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD473">
<title id=" W08-0112.xml">what are meeting summaries an analysis of human extractive summaries in meeting corpus </title>
<section> analysis results.  </section>
<citcontext>
<prevsection>
<prevsent>dataset iv: the extractive summaries are from the ami annotation (murray et al, 2005).<papid> W05-0905 </papid></prevsent>
<prevsent>3.1 kappa statistic.</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
kappa coefficient (carletta, 1996) <papid> J96-2004 </papid>is commonly usedas standard to reflect inter-annotator agreement.</citsent>
<aftsection>
<nextsent>table 1 shows the average kappa results, calculated for each meeting using the datasets described in section 2.
</nextsent>
<nextsent>compared to kappa score on text summarization, which is reported to be 0.38 by (mani et al, 2002) on set of trec documents, the inter-annotator agreement on meeting corpus is lower.
</nextsent>
<nextsent>this is likely due to the difference between the meeting style and written text.
</nextsent>
<nextsent>dataset ii iii iv avg-kappa 0.261 0.245 0.335 0.290 table 1: average kappa scores on different datasets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD475">
<title id=" W08-0404.xml">generalizing local translation models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments with features derived from the output of chinese and arabic parsers and an arabic lemmatizer show significant improvements over strong baseline.
</prevsent>
<prevsent>effective handling of large and diverse inventories of feature functions is one of the most pressing open problems in machine translation.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
while minimum error training (och, 2003) <papid> P03-1021 </papid>has by now become standard tool for interpol ating small number of aggregate scores, it is not well suited for learning in high-dimensional feature spaces.</citsent>
<aftsection>
<nextsent>at thesame time, although recent years have seen considerable progress in development of general methods for large-scale prediction of complex outputs (bakret al , 2007), their application to language translation has presented considerable challenges.
</nextsent>
<nextsent>several studies have shown that large-margin methods can be adapted to the special complexities of the task (liang et al , 2006; <papid> P06-1096 </papid>tillmann and zhang, 2006; <papid> P06-1091 </papid>cowan et al , 2006) . <papid> W06-1628 </papid>however, the capacity of these algorithms to improve over state-of-the-art baseline sis currently limited by their lack of robust dimensionality reduction.</nextsent>
<nextsent>performance gains are closely tied to the number and variety of candidate features that enter into the model, and increasing the size of the feature space not only slows down training interms of the number of iterations required for convergence, but can also considerably reduce decoding speed, leading to run-time costs that may be unacceptable in industrial settings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD476">
<title id=" W08-0404.xml">generalizing local translation models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while minimum error training (och, 2003) <papid> P03-1021 </papid>has by now become standard tool for interpol ating small number of aggregate scores, it is not well suited for learning in high-dimensional feature spaces.</prevsent>
<prevsent>at thesame time, although recent years have seen considerable progress in development of general methods for large-scale prediction of complex outputs (bakret al , 2007), their application to language translation has presented considerable challenges.</prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
several studies have shown that large-margin methods can be adapted to the special complexities of the task (liang et al , 2006; <papid> P06-1096 </papid>tillmann and zhang, 2006; <papid> P06-1091 </papid>cowan et al , 2006) . <papid> W06-1628 </papid>however, the capacity of these algorithms to improve over state-of-the-art baseline sis currently limited by their lack of robust dimensionality reduction.</citsent>
<aftsection>
<nextsent>performance gains are closely tied to the number and variety of candidate features that enter into the model, and increasing the size of the feature space not only slows down training interms of the number of iterations required for convergence, but can also considerably reduce decoding speed, leading to run-time costs that may be unacceptable in industrial settings.
</nextsent>
<nextsent>vector space regression has shown impressive performance in other tasks involving string-to-string mappings (cortes etal., 2007), but its application to language translation presents different set of open problems (wang et al , 2007).<papid> N07-2047 </papid></nextsent>
<nextsent>other promising formalisms, which have not yet produced end-to-end systems competitive with standard baselines, include the approach due to turian et al (2006), the hidden-state synchronous grammar-based exponential model studied by blunsom et al (2008), and similar model incorporating target-side n-gram features proposed in subotin (2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD477">
<title id=" W08-0404.xml">generalizing local translation models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while minimum error training (och, 2003) <papid> P03-1021 </papid>has by now become standard tool for interpol ating small number of aggregate scores, it is not well suited for learning in high-dimensional feature spaces.</prevsent>
<prevsent>at thesame time, although recent years have seen considerable progress in development of general methods for large-scale prediction of complex outputs (bakret al , 2007), their application to language translation has presented considerable challenges.</prevsent>
</prevsection>
<citsent citstr=" P06-1091 ">
several studies have shown that large-margin methods can be adapted to the special complexities of the task (liang et al , 2006; <papid> P06-1096 </papid>tillmann and zhang, 2006; <papid> P06-1091 </papid>cowan et al , 2006) . <papid> W06-1628 </papid>however, the capacity of these algorithms to improve over state-of-the-art baseline sis currently limited by their lack of robust dimensionality reduction.</citsent>
<aftsection>
<nextsent>performance gains are closely tied to the number and variety of candidate features that enter into the model, and increasing the size of the feature space not only slows down training interms of the number of iterations required for convergence, but can also considerably reduce decoding speed, leading to run-time costs that may be unacceptable in industrial settings.
</nextsent>
<nextsent>vector space regression has shown impressive performance in other tasks involving string-to-string mappings (cortes etal., 2007), but its application to language translation presents different set of open problems (wang et al , 2007).<papid> N07-2047 </papid></nextsent>
<nextsent>other promising formalisms, which have not yet produced end-to-end systems competitive with standard baselines, include the approach due to turian et al (2006), the hidden-state synchronous grammar-based exponential model studied by blunsom et al (2008), and similar model incorporating target-side n-gram features proposed in subotin (2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD478">
<title id=" W08-0404.xml">generalizing local translation models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while minimum error training (och, 2003) <papid> P03-1021 </papid>has by now become standard tool for interpol ating small number of aggregate scores, it is not well suited for learning in high-dimensional feature spaces.</prevsent>
<prevsent>at thesame time, although recent years have seen considerable progress in development of general methods for large-scale prediction of complex outputs (bakret al , 2007), their application to language translation has presented considerable challenges.</prevsent>
</prevsection>
<citsent citstr=" W06-1628 ">
several studies have shown that large-margin methods can be adapted to the special complexities of the task (liang et al , 2006; <papid> P06-1096 </papid>tillmann and zhang, 2006; <papid> P06-1091 </papid>cowan et al , 2006) . <papid> W06-1628 </papid>however, the capacity of these algorithms to improve over state-of-the-art baseline sis currently limited by their lack of robust dimensionality reduction.</citsent>
<aftsection>
<nextsent>performance gains are closely tied to the number and variety of candidate features that enter into the model, and increasing the size of the feature space not only slows down training interms of the number of iterations required for convergence, but can also considerably reduce decoding speed, leading to run-time costs that may be unacceptable in industrial settings.
</nextsent>
<nextsent>vector space regression has shown impressive performance in other tasks involving string-to-string mappings (cortes etal., 2007), but its application to language translation presents different set of open problems (wang et al , 2007).<papid> N07-2047 </papid></nextsent>
<nextsent>other promising formalisms, which have not yet produced end-to-end systems competitive with standard baselines, include the approach due to turian et al (2006), the hidden-state synchronous grammar-based exponential model studied by blunsom et al (2008), and similar model incorporating target-side n-gram features proposed in subotin (2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD479">
<title id=" W08-0404.xml">generalizing local translation models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several studies have shown that large-margin methods can be adapted to the special complexities of the task (liang et al , 2006; <papid> P06-1096 </papid>tillmann and zhang, 2006; <papid> P06-1091 </papid>cowan et al , 2006) . <papid> W06-1628 </papid>however, the capacity of these algorithms to improve over state-of-the-art baseline sis currently limited by their lack of robust dimensionality reduction.</prevsent>
<prevsent>performance gains are closely tied to the number and variety of candidate features that enter into the model, and increasing the size of the feature space not only slows down training interms of the number of iterations required for convergence, but can also considerably reduce decoding speed, leading to run-time costs that may be unacceptable in industrial settings.</prevsent>
</prevsection>
<citsent citstr=" N07-2047 ">
vector space regression has shown impressive performance in other tasks involving string-to-string mappings (cortes etal., 2007), but its application to language translation presents different set of open problems (wang et al , 2007).<papid> N07-2047 </papid></citsent>
<aftsection>
<nextsent>other promising formalisms, which have not yet produced end-to-end systems competitive with standard baselines, include the approach due to turian et al (2006), the hidden-state synchronous grammar-based exponential model studied by blunsom et al (2008), and similar model incorporating target-side n-gram features proposed in subotin (2008).
</nextsent>
<nextsent>taken together the results of these studies point to striking overarching conclusion: the humble relative frequency estimate of phrase-based models makes for surprisingly strong baseline.
</nextsent>
<nextsent>the present paper investigates family of models that 28 capitalize on this practical insight to allow efficient optimization of weights for virtually unlimited number of features.
</nextsent>
<nextsent>we take as point of departure the observation that the essential translation model scores comprising standard decoding decision rules can be recovered as special cases of amore general family of models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD480">
<title id=" W08-0404.xml">generalizing local translation models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a further attractive property of locally normalized models is the modest computational cost of their training and ease of its parallelization.
</prevsent>
<prevsent>this is particularly so for the models we concentrate on in this paper, defined so that parameter estimation decomposes into large number of small optimization sub problems which can be solved independently.several variants of these models beyond relative frequencies have appeared in the literature before.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
maximum entropy estimation for translation of individual words dates back to berger etal (1996), <papid> J96-1002 </papid>and the idea of using multi-class classifiers to sharpen predictions normally made through relative frequency estimates has been recently reintroduced under the rubric of word sense disambiguation and generalized to sub strings (chan et al 2007; <papid> P07-1005 </papid>carpuat and wu 2007<papid> D07-1007 </papid>a; carpuat and wu 2007<papid> D07-1007 </papid>b).maximum entropy models for non-lexicalized reordering rules for phrase-based system with cky decoding has been described by xiong et al (2006).<papid> P06-1066 </papid></citsent>
<aftsection>
<nextsent>some of our experiments, where exponential models conditioned on the source sentence and its parse annotation are associated with all rewrite rules in hierarchical phrase-based system (chiang, 2007) andall word-level probabilities in standard lexical models, may be seen as synthesis of these ideas.
</nextsent>
<nextsent>the broader perspective of viewing the product ofsuch local probabilities as particular approximation of sentence-level likelihood points the way beyond multi-class classification, and this type of generalization is the main original contribution of the present work.
</nextsent>
<nextsent>training classifier to predict the target phrase for every source phrase is equivalent to con joining all contextual features of the model with an indicator function for the surface form of some rule in the grammar.
</nextsent>
<nextsent>we can also use features basedon less specific representation of rule.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD481">
<title id=" W08-0404.xml">generalizing local translation models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a further attractive property of locally normalized models is the modest computational cost of their training and ease of its parallelization.
</prevsent>
<prevsent>this is particularly so for the models we concentrate on in this paper, defined so that parameter estimation decomposes into large number of small optimization sub problems which can be solved independently.several variants of these models beyond relative frequencies have appeared in the literature before.
</prevsent>
</prevsection>
<citsent citstr=" P07-1005 ">
maximum entropy estimation for translation of individual words dates back to berger etal (1996), <papid> J96-1002 </papid>and the idea of using multi-class classifiers to sharpen predictions normally made through relative frequency estimates has been recently reintroduced under the rubric of word sense disambiguation and generalized to sub strings (chan et al 2007; <papid> P07-1005 </papid>carpuat and wu 2007<papid> D07-1007 </papid>a; carpuat and wu 2007<papid> D07-1007 </papid>b).maximum entropy models for non-lexicalized reordering rules for phrase-based system with cky decoding has been described by xiong et al (2006).<papid> P06-1066 </papid></citsent>
<aftsection>
<nextsent>some of our experiments, where exponential models conditioned on the source sentence and its parse annotation are associated with all rewrite rules in hierarchical phrase-based system (chiang, 2007) andall word-level probabilities in standard lexical models, may be seen as synthesis of these ideas.
</nextsent>
<nextsent>the broader perspective of viewing the product ofsuch local probabilities as particular approximation of sentence-level likelihood points the way beyond multi-class classification, and this type of generalization is the main original contribution of the present work.
</nextsent>
<nextsent>training classifier to predict the target phrase for every source phrase is equivalent to con joining all contextual features of the model with an indicator function for the surface form of some rule in the grammar.
</nextsent>
<nextsent>we can also use features basedon less specific representation of rule.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD482">
<title id=" W08-0404.xml">generalizing local translation models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a further attractive property of locally normalized models is the modest computational cost of their training and ease of its parallelization.
</prevsent>
<prevsent>this is particularly so for the models we concentrate on in this paper, defined so that parameter estimation decomposes into large number of small optimization sub problems which can be solved independently.several variants of these models beyond relative frequencies have appeared in the literature before.
</prevsent>
</prevsection>
<citsent citstr=" D07-1007 ">
maximum entropy estimation for translation of individual words dates back to berger etal (1996), <papid> J96-1002 </papid>and the idea of using multi-class classifiers to sharpen predictions normally made through relative frequency estimates has been recently reintroduced under the rubric of word sense disambiguation and generalized to sub strings (chan et al 2007; <papid> P07-1005 </papid>carpuat and wu 2007<papid> D07-1007 </papid>a; carpuat and wu 2007<papid> D07-1007 </papid>b).maximum entropy models for non-lexicalized reordering rules for phrase-based system with cky decoding has been described by xiong et al (2006).<papid> P06-1066 </papid></citsent>
<aftsection>
<nextsent>some of our experiments, where exponential models conditioned on the source sentence and its parse annotation are associated with all rewrite rules in hierarchical phrase-based system (chiang, 2007) andall word-level probabilities in standard lexical models, may be seen as synthesis of these ideas.
</nextsent>
<nextsent>the broader perspective of viewing the product ofsuch local probabilities as particular approximation of sentence-level likelihood points the way beyond multi-class classification, and this type of generalization is the main original contribution of the present work.
</nextsent>
<nextsent>training classifier to predict the target phrase for every source phrase is equivalent to con joining all contextual features of the model with an indicator function for the surface form of some rule in the grammar.
</nextsent>
<nextsent>we can also use features basedon less specific representation of rule.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD486">
<title id=" W08-0404.xml">generalizing local translation models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a further attractive property of locally normalized models is the modest computational cost of their training and ease of its parallelization.
</prevsent>
<prevsent>this is particularly so for the models we concentrate on in this paper, defined so that parameter estimation decomposes into large number of small optimization sub problems which can be solved independently.several variants of these models beyond relative frequencies have appeared in the literature before.
</prevsent>
</prevsection>
<citsent citstr=" P06-1066 ">
maximum entropy estimation for translation of individual words dates back to berger etal (1996), <papid> J96-1002 </papid>and the idea of using multi-class classifiers to sharpen predictions normally made through relative frequency estimates has been recently reintroduced under the rubric of word sense disambiguation and generalized to sub strings (chan et al 2007; <papid> P07-1005 </papid>carpuat and wu 2007<papid> D07-1007 </papid>a; carpuat and wu 2007<papid> D07-1007 </papid>b).maximum entropy models for non-lexicalized reordering rules for phrase-based system with cky decoding has been described by xiong et al (2006).<papid> P06-1066 </papid></citsent>
<aftsection>
<nextsent>some of our experiments, where exponential models conditioned on the source sentence and its parse annotation are associated with all rewrite rules in hierarchical phrase-based system (chiang, 2007) andall word-level probabilities in standard lexical models, may be seen as synthesis of these ideas.
</nextsent>
<nextsent>the broader perspective of viewing the product ofsuch local probabilities as particular approximation of sentence-level likelihood points the way beyond multi-class classification, and this type of generalization is the main original contribution of the present work.
</nextsent>
<nextsent>training classifier to predict the target phrase for every source phrase is equivalent to con joining all contextual features of the model with an indicator function for the surface form of some rule in the grammar.
</nextsent>
<nextsent>we can also use features basedon less specific representation of rule.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD488">
<title id=" W08-0404.xml">generalizing local translation models </title>
<section> local exponential translation models.  </section>
<citcontext>
<prevsection>
<prevsent>unlike inference in piecewise-trained graphical models, where all parameters forgiven output are added together without normalization, features that enter into the score for translation hypothesis are restricted to be consistent with single synchronous parse and the local probabilities are normalized in decoding as in training.
</prevsent>
<prevsent>3.3 lexical models.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the use of conditional probabilities in standard lexical models also gives us straightforward way to generalize them in the same way as phrase models.consider the lexical model pw(ry|rx), defined following koehn et al (2003), <papid> N03-1017 </papid>with denoting the most frequent word alignment observed for the rule in the training set.</citsent>
<aftsection>
<nextsent>pw(r y|rx) = n?
</nextsent>
<nextsent>i=1 1 |j|(i, j) ? a| ?
</nextsent>
<nextsent>(i,j)a p(wyi |w j ) (5) we replace p(wyi |w j ) with context-conditioned probabilities, computed similarly to eq.
</nextsent>
<nextsent>4, but at the level of individual words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD489">
<title id=" W08-0404.xml">generalizing local translation models </title>
<section> local exponential translation models.  </section>
<citcontext>
<prevsection>
<prevsent>this also defines probabilities for arabic words whose surface forms have not been observed in training, although we do not take advantage of estimates for out-of-vocabulary words 32 in the experiments below.
</prevsent>
<prevsent>3.5 regularization.
</prevsent>
</prevsection>
<citsent citstr=" P07-1104 ">
we apply `1 regularization (ng, 2004; gao et al , 2007) <papid> P07-1104 </papid>to make learning more robust to noise and control the effective dimensionality of the feature space by subtracting weighted sum of absolute values of parameter weights from the log-likelihood of the training data w?</citsent>
<aftsection>
<nextsent>= argmax ll(w) ? ?
</nextsent>
<nextsent>i ci|wi| (6) we optimize the objective using variant of theorthant-wise limited-memory quasi-newton algorithm proposed by andrew &amp; gao (2007).3 all values ci are set to 1 in most of the experiments below, although we apply stronger regularization (ci = 3)to reordering features.
</nextsent>
<nextsent>tuning regularization tradeoffs individually for different feature types is an attractive option, but our experiments suggest that using cross-entropy on held-out portion of training data for that purpose does not help performance.
</nextsent>
<nextsent>we leave investigation of the alternatives for future work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD492">
<title id=" W08-0113.xml">a simple method for resolution of definite reference in a shared visual context </title>
<section> components.  </section>
<citcontext>
<prevsection>
<prevsent>name description examples lexical reference t,piece,cross r topological direction top left corner s topological distance outer left n numeric second column g group (perceptually active) from the left column s synthetic group the three pieces on the left landmark field in the middle prepositional relation in the middle grad grading function exactly right table 1: visual lexical functions of words the cross from the second column from left at the top r n g d d (a) - annotation of spatial lexical functions r lm lm lm lm (b) - segmentation of visual spatial parts table 2: example annotation / parse?
</prevsent>
<prevsent>given the requirement for robustness, we decided against hand-written grammar for deriving such annotations; the moderate size of our corpus onthe other hand made for example markov model based approaches difficult to apply.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
we hence chosetransformation-based learning to create this (shallow) segmentation grammar, converting the segmentation task into tagging task (as is done in 85(ramshaw and marcus, 1995), <papid> W95-0107 </papid>inter alia).</citsent>
<aftsection>
<nextsent>in our approach, each token that is to be tagged is itself represented in three different forms or layers: lemmatised word, as pos-tag, and by its spatial-functional tag (as in table 1; added by simple look-up).
</nextsent>
<nextsent>all these layers can be accessed in the learned rules.
</nextsent>
<nextsent>apart from this, the module is straightforward implementation of (ramshaw and marcus, 1995), <papid> W95-0107 </papid>which in turn adapts (brill, 1993) for syntactic chunking.</nextsent>
<nextsent>3.2 visual word semantics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD496">
<title id=" W07-1522.xml">annotating a japanese text corpus with predicate argument and coreference relations </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>for this reason, we discuss issues in annotating these two types of relations, and propose new specification for each.
</prevsent>
<prevsent>in accordance with the specification, we built large-scaled annotated corpus, and examined its reliability.
</prevsent>
</prevsection>
<citsent citstr=" P06-1079 ">
as result of our current work, we have released an annotated corpus named the naist text corpus1, which is used as the evaluation dataset inthe coreference and zero-anaphora resolution tasks in iida et al (2005) and iida et al (2006).<papid> P06-1079 </papid></citsent>
<aftsection>
<nextsent>coreference resolution and predicate-argument structure analysis has recently been growing fieldof research due to the demands from nlp application such as information extraction and machine translation.
</nextsent>
<nextsent>with the research focus placed on these tasks, the specification of annotating corpora and the 1the naist text corpus is downloadable from http://cl.naist.jp/nldata/corpus/, and it has already been downloaded by 102 unique users.
</nextsent>
<nextsent>datasets used in supervised techniques (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002, <papid> P02-1014 </papid>etc.) have also grown in sophistication.for english, several annotation schemes have already been proposed for both coreference relation and argument structure, and annotated corpora have been developed accordingly (hirschman, 1997; poesio et al, 2004; <papid> P04-1019 </papid>doddington et al, 2004).</nextsent>
<nextsent>for instance, in the coreference task on message understanding conference (muc) and the entity detection and tracking (edt) task in the automatic content extraction (ace) program, which is the successor of muc, the details of specification of annotating coreference relation have been discussed for several years.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD497">
<title id=" W07-1522.xml">annotating a japanese text corpus with predicate argument and coreference relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>coreference resolution and predicate-argument structure analysis has recently been growing fieldof research due to the demands from nlp application such as information extraction and machine translation.
</prevsent>
<prevsent>with the research focus placed on these tasks, the specification of annotating corpora and the 1the naist text corpus is downloadable from http://cl.naist.jp/nldata/corpus/, and it has already been downloaded by 102 unique users.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
datasets used in supervised techniques (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002, <papid> P02-1014 </papid>etc.) have also grown in sophistication.for english, several annotation schemes have already been proposed for both coreference relation and argument structure, and annotated corpora have been developed accordingly (hirschman, 1997; poesio et al, 2004; <papid> P04-1019 </papid>doddington et al, 2004).</citsent>
<aftsection>
<nextsent>for instance, in the coreference task on message understanding conference (muc) and the entity detection and tracking (edt) task in the automatic content extraction (ace) program, which is the successor of muc, the details of specification of annotating coreference relation have been discussed for several years.
</nextsent>
<nextsent>on the other hand, the specification of predicate-argument structure analysis has mainly been discussed in the context of the conll shared task2 on the basis of the propbank (palmer et al, 2005).<papid> J05-1004 </papid></nextsent>
<nextsent>in parallel with these efforts, there have also been research activities for building japanese text corpora annotated with coreference and predicate-argument relations such as the kyoto text corpus version 4.0(kawahara et al, 2002) and the gda3-tagged corpus (hasida, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD498">
<title id=" W07-1522.xml">annotating a japanese text corpus with predicate argument and coreference relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>coreference resolution and predicate-argument structure analysis has recently been growing fieldof research due to the demands from nlp application such as information extraction and machine translation.
</prevsent>
<prevsent>with the research focus placed on these tasks, the specification of annotating corpora and the 1the naist text corpus is downloadable from http://cl.naist.jp/nldata/corpus/, and it has already been downloaded by 102 unique users.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
datasets used in supervised techniques (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002, <papid> P02-1014 </papid>etc.) have also grown in sophistication.for english, several annotation schemes have already been proposed for both coreference relation and argument structure, and annotated corpora have been developed accordingly (hirschman, 1997; poesio et al, 2004; <papid> P04-1019 </papid>doddington et al, 2004).</citsent>
<aftsection>
<nextsent>for instance, in the coreference task on message understanding conference (muc) and the entity detection and tracking (edt) task in the automatic content extraction (ace) program, which is the successor of muc, the details of specification of annotating coreference relation have been discussed for several years.
</nextsent>
<nextsent>on the other hand, the specification of predicate-argument structure analysis has mainly been discussed in the context of the conll shared task2 on the basis of the propbank (palmer et al, 2005).<papid> J05-1004 </papid></nextsent>
<nextsent>in parallel with these efforts, there have also been research activities for building japanese text corpora annotated with coreference and predicate-argument relations such as the kyoto text corpus version 4.0(kawahara et al, 2002) and the gda3-tagged corpus (hasida, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD499">
<title id=" W07-1522.xml">annotating a japanese text corpus with predicate argument and coreference relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>coreference resolution and predicate-argument structure analysis has recently been growing fieldof research due to the demands from nlp application such as information extraction and machine translation.
</prevsent>
<prevsent>with the research focus placed on these tasks, the specification of annotating corpora and the 1the naist text corpus is downloadable from http://cl.naist.jp/nldata/corpus/, and it has already been downloaded by 102 unique users.
</prevsent>
</prevsection>
<citsent citstr=" P04-1019 ">
datasets used in supervised techniques (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002, <papid> P02-1014 </papid>etc.) have also grown in sophistication.for english, several annotation schemes have already been proposed for both coreference relation and argument structure, and annotated corpora have been developed accordingly (hirschman, 1997; poesio et al, 2004; <papid> P04-1019 </papid>doddington et al, 2004).</citsent>
<aftsection>
<nextsent>for instance, in the coreference task on message understanding conference (muc) and the entity detection and tracking (edt) task in the automatic content extraction (ace) program, which is the successor of muc, the details of specification of annotating coreference relation have been discussed for several years.
</nextsent>
<nextsent>on the other hand, the specification of predicate-argument structure analysis has mainly been discussed in the context of the conll shared task2 on the basis of the propbank (palmer et al, 2005).<papid> J05-1004 </papid></nextsent>
<nextsent>in parallel with these efforts, there have also been research activities for building japanese text corpora annotated with coreference and predicate-argument relations such as the kyoto text corpus version 4.0(kawahara et al, 2002) and the gda3-tagged corpus (hasida, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD500">
<title id=" W07-1522.xml">annotating a japanese text corpus with predicate argument and coreference relations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>datasets used in supervised techniques (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002, <papid> P02-1014 </papid>etc.) have also grown in sophistication.for english, several annotation schemes have already been proposed for both coreference relation and argument structure, and annotated corpora have been developed accordingly (hirschman, 1997; poesio et al, 2004; <papid> P04-1019 </papid>doddington et al, 2004).</prevsent>
<prevsent>for instance, in the coreference task on message understanding conference (muc) and the entity detection and tracking (edt) task in the automatic content extraction (ace) program, which is the successor of muc, the details of specification of annotating coreference relation have been discussed for several years.</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
on the other hand, the specification of predicate-argument structure analysis has mainly been discussed in the context of the conll shared task2 on the basis of the propbank (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>in parallel with these efforts, there have also been research activities for building japanese text corpora annotated with coreference and predicate-argument relations such as the kyoto text corpus version 4.0(kawahara et al, 2002) and the gda3-tagged corpus (hasida, 2005).
</nextsent>
<nextsent>however, as we discuss in this paper, there is still much room for arguing and refining the specification of such sorts of semantic annotation.
</nextsent>
<nextsent>in fact, for neither of the above two corpora, the adequacy and reliability of the annotation scheme has been deeply examined.in this paper, we discuss how to annotate coreference and predicate-argument relations in japanese 2http://www.lsi.upc.edu/srlconll/ 3the global document annotation 132text.
</nextsent>
<nextsent>in section 2 to section 4, we examine the annotation issues of coreference, predicate-argumentrelations, and event-nouns and their argument relations respectively, and define adequate specification of each annotation task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD504">
<title id=" W07-1522.xml">annotating a japanese text corpus with predicate argument and coreference relations </title>
<section> annotating predicate-argument relations.  </section>
<citcontext>
<prevsection>
<prevsent>in japanese, the mapping from syntactic cases to semantic roles tends to be reasonably straightforward if semantically rich lexicon of verbs like the verbnet (kipper et al, 2000) is available.
</prevsent>
<prevsent>furthermore, we have not yet found many nlp applications for which the utility of semantic roles is actually demonstrated.
</prevsent>
</prevsection>
<citsent citstr=" P06-2105 ">
one may think of using semantic roles in textual inference as exemplified by, for example, tatu and moldovan (2006).<papid> P06-2105 </papid></citsent>
<aftsection>
<nextsent>however, similar sort of inference may well be realized with syntactic cases as demonstrated in the information extraction and question answering literature.
</nextsent>
<nextsent>taking these respects into account, we choose tolabel predicate-argument relations in terms of syntactic cases, which follows the annotation scheme adopted in the kyoto corpus.
</nextsent>
<nextsent>3.2 syntactic case alternation.
</nextsent>
<nextsent>once the level of syntactic cases is chosen for our annotation, another issue immediately arises, alteration of syntactic cases by syntactic transformations such as passivization and causativization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD505">
<title id=" W07-1522.xml">annotating a japanese text corpus with predicate argument and coreference relations </title>
<section> statistics of the new corpus.  </section>
<citcontext>
<prevsection>
<prevsent>the results are evaluated by calculating recall and precision in which one annotation result is regarded as correct and the others as the output of system.
</prevsent>
<prevsent>note that only the predicates annotated by both annotators areused in calculating recall and precision.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
for evaluation of coreference relations, we calculated recall and precision based on the muc score (vilain et al, 1995).<papid> M95-1005 </papid></citsent>
<aftsection>
<nextsent>the results are shown in table 4, where we can see that most annotating work was done with high quality except for the ni-argument of event-nouns.
</nextsent>
<nextsent>the most common source of error was caused by verb alternation, and we will discuss this table 3: data size of each corpus corpus size propbank 7,891 sentences nombank 0.8 24,311 sentences ace (2005 english) 269 articles gda corpus 2,177 articles kyoto corpus 555 articles (5,127 sentences) naist corpus (ours) 2,929 articles (38,384 sentences) table 4: agreement of annotating each relation recall precision predicate 0.947 (6512/6880) 0.941 (6512/6920) ga (nom) 0.861 (5638/6549) 0.856 (5638/6567) (acc) 0.943 (2447/2595) 0.919 (2447/2664) ni (dat) 0.892 (1060/1189) 0.817 (1060/1298) event-noun 0.905 (1281/1415) 0.810 (1281/1582) ga (nom) 0.798 (1038/1300) 0.804 (1038/1291) (acc) 0.893 (469/525) 0.765 (469/613) ni (dat) 0.717 (66/92) 0.606 (66/109) coreference 0.893 (1802/2019) 0.831 (1802/2168) issue in detail in section 6.
</nextsent>
<nextsent>such investigation of the reliability of annotation has not been reported for either the kyoto corpus or the gda-tagged corpus.
</nextsent>
<nextsent>however, our results also show that each annotating task still leaves room for improvement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD506">
<title id=" W07-2213.xml">are very large context free grammars tractable </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>indeed, we aim to deal with grammars that have, say, over million symbol occurrences and several hundred thousands rules.
</prevsent>
<prevsent>traditional parsers are not usually prepared to handle them, either because these grammars are simply too big (the parsers internal structures blow up) or the time spent to analyze sentence becomes prohibitive.this paper will concentrate on context-free grammars (cfg) and their associated parsers.
</prevsent>
</prevsection>
<citsent citstr=" C88-2121 ">
however, virtually all tree adjoining grammars (tag, seee.g., (schabes et al, 1988)) <papid> C88-2121 </papid>used in nlp applications can (almost) be seen as lexicalized tree insertion grammars (tig), which can be converted into strongly equivalent cfgs (schabes and waters,1995).<papid> J95-4002 </papid></citsent>
<aftsection>
<nextsent>hence, the parsing techniques and tools described here can be applied to most tags used for nlp, with, in the worst case, light over-generation which can be easily and efficiently eliminated in complementary pass.
</nextsent>
<nextsent>this is indeed what we have achieved with tag automatically extracted from (villemonte de la clergerie, 2005)s large-coverage factor ized french tag, as we will see in section 4.
</nextsent>
<nextsent>even (some kinds of) non cfgs may benefit from the ideas described in this paper.
</nextsent>
<nextsent>the reason why the run-time of context-free (cf)parsers for large cfgs is damaged relies on theoretical result.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD507">
<title id=" W07-2213.xml">are very large context free grammars tractable </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>indeed, we aim to deal with grammars that have, say, over million symbol occurrences and several hundred thousands rules.
</prevsent>
<prevsent>traditional parsers are not usually prepared to handle them, either because these grammars are simply too big (the parsers internal structures blow up) or the time spent to analyze sentence becomes prohibitive.this paper will concentrate on context-free grammars (cfg) and their associated parsers.
</prevsent>
</prevsection>
<citsent citstr=" J95-4002 ">
however, virtually all tree adjoining grammars (tag, seee.g., (schabes et al, 1988)) <papid> C88-2121 </papid>used in nlp applications can (almost) be seen as lexicalized tree insertion grammars (tig), which can be converted into strongly equivalent cfgs (schabes and waters,1995).<papid> J95-4002 </papid></citsent>
<aftsection>
<nextsent>hence, the parsing techniques and tools described here can be applied to most tags used for nlp, with, in the worst case, light over-generation which can be easily and efficiently eliminated in complementary pass.
</nextsent>
<nextsent>this is indeed what we have achieved with tag automatically extracted from (villemonte de la clergerie, 2005)s large-coverage factor ized french tag, as we will see in section 4.
</nextsent>
<nextsent>even (some kinds of) non cfgs may benefit from the ideas described in this paper.
</nextsent>
<nextsent>the reason why the run-time of context-free (cf)parsers for large cfgs is damaged relies on theoretical result.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD509">
<title id=" W07-2213.xml">are very large context free grammars tractable </title>
<section> filtering strategies.  </section>
<citcontext>
<prevsection>
<prevsent>is terminal symbol that can terminate (the terminal strings generated by) xp, there is no transition on that can follow transition on a?
</prevsent>
<prevsent>in the dag w, the production xp1 ? pxpp can be erased if it is not valid in another context.in order to formalize these notions we define several binary relations together with their (reflexive) transitive closure.
</prevsent>
</prevsection>
<citsent citstr=" E93-1036 ">
within cfg = (n,t, p, s), we first define left-corner noted x. left-corner (nederhof, 1993;<papid> E93-1036 </papid>moore, 2000), hereafter lc, is well-known relation since many parsing strategies are based upon it.</citsent>
<aftsection>
<nextsent>we say that is in the lc of and we write x iff (a,x) ? {(b,y ) | ? ? ?
</nextsent>
<nextsent>p ? ?
</nextsent>
<nextsent>g ?}.
</nextsent>
<nextsent>we can write x axx to enforce how the couple (a,x) may be produced.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD510">
<title id=" W07-2213.xml">are very large context free grammars tractable </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, in nlp, (van noord, 1997)and (satta and stock, 1994) propose bidirectional algorithms.
</prevsent>
<prevsent>these parsers have the reputation to have better efficiency than their left-to-right counterpart.
</prevsent>
</prevsection>
<citsent citstr=" A00-2036 ">
this reputation is not only based upon experimental results (van noord, 1997) but also upon mathematical arguments in (nederhof and satta, 2000).<papid> A00-2036 </papid></citsent>
<aftsection>
<nextsent>this is specially true when the productions of the cfg strongly depend on lexical information.
</nextsent>
<nextsent>in that casethe parsing search space is reduced because the constraints associated to lexical elements are evaluated as early as possible.
</nextsent>
<nextsent>we can note that our filtering strategies try to reach the same purpose by totally different mean: we reduce the parsing search spaceby eliminating as many productions as possible, including possibly non-lexicalized productions whose irrelevance to parse the current input can not be directly deduced from that input.we can also remark that our results are not in contradiction with the claims of (nederhof and satta, 2000) <papid> A00-2036 </papid>in which they argue that earley algorithm and related standard parsing techniques [.</nextsent>
<nextsent>] can not be directly extended to allow left-to-right and correct-prefix-property parsing in acceptable time bound?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD513">
<title id=" W07-2065.xml">srcbwsd supervised chinese word sense disambiguation with key features </title>
<section> maximum entropy.  </section>
<citcontext>
<prevsection>
<prevsent>maximum entropy modelling is framework for integrating information from many heterogeneous information sources for classification (manning and schutze, 1999).
</prevsent>
<prevsent>it has been successfully applied to wide range of nlp tasks, including sentence boundary detection, pos tagging, and parsing (ratnaparkhi, 1998) . the system estimates the conditional probability that an ambiguous word has sensex given that it occurs in context y, where is conjunction of features.
</prevsent>
</prevsection>
<citsent citstr=" C02-1143 ">
the estimated probability is derived from feature weights which are determined automatically from training data so as to produce probability distribution that has maximum entropy,under the constraint that it is consistent with observed evidence (dang et al, 2002).<papid> C02-1143 </papid></citsent>
<aftsection>
<nextsent>we used the implementation of maximum entropy framework with opennlp maxent1, where each nominal feature was represented as feature code=value?.
</nextsent>
<nextsent>based onthis framework, we defined the feature set and implemented the interface of feature extraction.
</nextsent>
<nextsent>for the convenient of evaluation, the default parameters 1http://maxent.sourceforge.net/ 300 of training model were used.
</nextsent>
<nextsent>many research (stevenson and wilks, 2001; <papid> J01-3001 </papid>lee and ng, 2002) <papid> W02-1006 </papid>have indicated that combination of knowledge sources improves wsd accuracy, but notany kind of knowledge source contributes the improvement of chinese wsd (dang et al, 2002).<papid> C02-1143 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD515">
<title id=" W07-2065.xml">srcbwsd supervised chinese word sense disambiguation with key features </title>
<section> used features.  </section>
<citcontext>
<prevsection>
<prevsent>based onthis framework, we defined the feature set and implemented the interface of feature extraction.
</prevsent>
<prevsent>for the convenient of evaluation, the default parameters 1http://maxent.sourceforge.net/ 300 of training model were used.
</prevsent>
</prevsection>
<citsent citstr=" J01-3001 ">
many research (stevenson and wilks, 2001; <papid> J01-3001 </papid>lee and ng, 2002) <papid> W02-1006 </papid>have indicated that combination of knowledge sources improves wsd accuracy, but notany kind of knowledge source contributes the improvement of chinese wsd (dang et al, 2002).<papid> C02-1143 </papid></citsent>
<aftsection>
<nextsent>for multilingual chinese-english lexical sample task, some basic features can be obtained directly.
</nextsent>
<nextsent>also,we extracted other syntactic features through shallow parsing.
</nextsent>
<nextsent>in addition, we used word category information for verb disambiguation.
</nextsent>
<nextsent>3.1 basic features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD516">
<title id=" W07-2065.xml">srcbwsd supervised chinese word sense disambiguation with key features </title>
<section> used features.  </section>
<citcontext>
<prevsection>
<prevsent>based onthis framework, we defined the feature set and implemented the interface of feature extraction.
</prevsent>
<prevsent>for the convenient of evaluation, the default parameters 1http://maxent.sourceforge.net/ 300 of training model were used.
</prevsent>
</prevsection>
<citsent citstr=" W02-1006 ">
many research (stevenson and wilks, 2001; <papid> J01-3001 </papid>lee and ng, 2002) <papid> W02-1006 </papid>have indicated that combination of knowledge sources improves wsd accuracy, but notany kind of knowledge source contributes the improvement of chinese wsd (dang et al, 2002).<papid> C02-1143 </papid></citsent>
<aftsection>
<nextsent>for multilingual chinese-english lexical sample task, some basic features can be obtained directly.
</nextsent>
<nextsent>also,we extracted other syntactic features through shallow parsing.
</nextsent>
<nextsent>in addition, we used word category information for verb disambiguation.
</nextsent>
<nextsent>3.1 basic features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD519">
<title id=" W07-1307.xml">inducing sound segment differences using pair hidden markov models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there have been many attempts to incorporate more sensitive segment differences, which do not necessarily perform worse invalidation, but they fail to show significant improvement (heeringa, 2004).
</prevsent>
<prevsent>instead of using segment distances as these are(incompletely) suggested by phonetic or phonological theory, we can also attempt to acquire theseautomatically.
</prevsent>
</prevsection>
<citsent citstr=" W05-0606 ">
mackay and kondrak (2005) <papid> W05-0606 </papid>introduce pair hidden markov models (pairhmms) to language studies, applying them to the problem of recognising cognates?</citsent>
<aftsection>
<nextsent>in the sense of machine translation, i.e. pairs of words in different languages that are similar enough in sound and meaning to serve as translation equivalents.
</nextsent>
<nextsent>such words may be cognate in the sense of historical linguistics, but they may also be borrowings from third language.
</nextsent>
<nextsent>we apply pairhmms to dialect data for the first time in this paper.
</nextsent>
<nextsent>like mackay and kondrak (2005) <papid> W05-0606 </papid>we evaluate the results both on specific task, in our case, dialect classification, and also via examination of the segment substitution probabilities induced bythe pairhmm training procedures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD542">
<title id=" W07-1307.xml">inducing sound segment differences using pair hidden markov models </title>
<section> the levenshtein distance.  </section>
<citcontext>
<prevsection>
<prevsent>as in mackay and kondrak (2005) <papid> W05-0606 </papid>and described above, we use the forward and viterbi algorithms in both their regular (normalised for length) and log-odds form to calculate similarity scores for every wordpair.</prevsent>
<prevsent>subsequently, the distance between two dialec tal varieties can be obtained by calculating all word pair scores and averaging them.</prevsent>
</prevsection>
<citsent citstr=" E95-1009 ">
the levenshtein distance was introduced by kessler (1995) <papid> E95-1009 </papid>as tool for measuring linguistic distances between language varieties and has been successfully applied in dialect comparison (nerbonne et al, 1996; heeringa, 2004).</citsent>
<aftsection>
<nextsent>for this comparison we usea slightly modified version of the levenshtein distance algorithm, which enforces linguistic syllabicity constraint: only vowels may match with vowels, and consonants with consonants.
</nextsent>
<nextsent>the specific details of this modification are described in more detail in wieling et al (2007).
</nextsent>
<nextsent>we do not normalise the levenshtein distance measurement for length, because heeringa et al (2006) showed that results based on raw levenshteindistances are better approximation of dialect differences as perceived by the dialect speakers than results based on the normalised levenshtein distances.
</nextsent>
<nextsent>finally, all substitutions, insertions and deletions have the same weight.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD547">
<title id=" W08-0323.xml">using syntactic coupling features for discriminating phrase based translations wmt08 shared translation task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we report results comparing different feature combinations.
</prevsent>
<prevsent>our goal is to try to improve the fluency and adequacy of baseline phrase-based smt system byusing variety of syntactic coupling features?, extracted from parses for the source and target strings.these features are used for reranking the n-best candidates of the baseline system.the phrase-based smt system matrax, developed at xrce, is used as the baseline in the experiments.
</prevsent>
</prevsection>
<citsent citstr=" H05-1095 ">
matrax is based on fairly standard loglinear model, but one original aspect of the system is the use of non-contiguous bi-phrases such as ne ... plus / not ... anymore, where words in the source and target phrases may be separated by gaps, to be filled at translation time by lexical material provided by some other such pairs (simard et al, 2005).<papid> H05-1095 </papid></citsent>
<aftsection>
<nextsent>for parsing, we use the xerox incremental parser xip (at-mokhtar et al, 2002), which is robust dependency parser developed at the xerox research centre europe.
</nextsent>
<nextsent>xip is fast (around 2000 words per second for english) and is well adapted to situation, like the one we have here, were we need toparse on the order of few hundred target candidates on the fly.
</nextsent>
<nextsent>also of interest to us is the fact that xip produces labelled dependencies, feature that we use in some of our experiments.
</nextsent>
<nextsent>1.1 decoding and training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD548">
<title id=" W08-0323.xml">using syntactic coupling features for discriminating phrase based translations wmt08 shared translation task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.1 decoding and training.
</prevsent>
<prevsent>we resort to standard reranking approach in which we produce an n-best list of matrax candidate translations (with = 100 in our experiments), and then rerank this list with linear combination of ourparse-dependent features.
</prevsent>
</prevsection>
<citsent citstr=" P04-1007 ">
in order to train the feature weights, we use an averaged structured perceptron approach (roark et al, 2004), <papid> P04-1007 </papid>where we try to learn weights such that the first candidate to emer geis equal to the oracle?</citsent>
<aftsection>
<nextsent>candidate, that is, the candidate that is closest to the reference in terms of nist score.
</nextsent>
<nextsent>1.2 coupling features.
</nextsent>
<nextsent>our general approach to computing coupling features between the dependency structure of the source and that of candidate translation produced by ma trax is the following: we start by aligning the words between the source and the candidate translation, we parse both sides, and we count (possi bly according to weighting scheme) the number of configurations (rectangles?)
</nextsent>
<nextsent>that are of the following type: ((s1, s12, s2), (t1, t12, t2)), where s12 is an edge between s1 and s2, t12 is an edge between t1 and t2, s1 is aligned with t1 and s2 is aligned with t2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD550">
<title id=" W08-0610.xml">species disambiguation for biomedical term identification </title>
<section> term identification.  </section>
<citcontext>
<prevsection>
<prevsent>this task is more difficult than the original bio creative gntasks due to the additional ambiguity caused by multiple model organisms.we first carried out experiments on species disambiguation.
</prevsent>
<prevsent>in addition to the txm (i.e., the system uses ml(eppi+te)+rule model) and the majority vote taggers, we trained the species tagger on dataset comprising of the devtest sets from the bio creative &amp; ii gn tasks.
</prevsent>
</prevsection>
<citsent citstr=" W07-1009 ">
in more detail, we firstpre-processed the dataset and marked up gene entities with an ner system (alex et al, 2007; <papid> W07-1009 </papid>grover et al., 2007).16 the entities were also tagged with the 15this assumption is not strictly true because each dataset may contain genes of other species, and it would be hard to assess how true it is as abstracts in the bio creative gn datasets are not normalised to an entity level.16the ner system was trained on bio creative ii gm training and test datasets.</citsent>
<aftsection>
<nextsent>77 species as indicated by the source dataset where they were drawn from, which were used as the gold?
</nextsent>
<nextsent>species.
</nextsent>
<nextsent>using the same algorithm and feature set as described in section 3.3.2, bc model was trained.
</nextsent>
<nextsent>human fly mouse yeast majority vote 82.35 78.43 71.69 85.12 bc model 70.23 89.24 75.41 87.64 txm model 93.35 3.27 31.89 3.49 table 6: accuracy (%) of the species disambiguation systems as tested on the bio creative &amp; ii test data.the bc model?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD551">
<title id=" W08-0628.xml">adaptive information extraction for complex biomedical tasks </title>
<section> feedback integration.  </section>
<citcontext>
<prevsection>
<prevsent>for sentence level fields labeling, the performance of f1 score is around 0.79 (feng et al, 2008).
</prevsent>
<prevsent>1 http://www.neuroscholar.org/ 120we here show how the adaptive information extraction framework is applied to labeling individual sentences.
</prevsent>
</prevsection>
<citsent citstr=" D07-1088 ">
please see feng et al (2007) <papid> D07-1088 </papid>for the details of segmenting data records.</citsent>
<aftsection>
<nextsent>2.1 choosing learning approach via f1.
</nextsent>
<nextsent>a natural way to label sentences is to obtain (by hand or learning) patterns characterizing each field (feng et al, 2006; ravichandran and hovy, 2002).<papid> P02-1006 </papid></nextsent>
<nextsent>we tried to annotate field values for the biomedical data, but we found few intuitive clues that rich surface text patterns could be learned with this corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD552">
<title id=" W08-0628.xml">adaptive information extraction for complex biomedical tasks </title>
<section> feedback integration.  </section>
<citcontext>
<prevsection>
<prevsent>please see feng et al (2007) <papid> D07-1088 </papid>for the details of segmenting data records.</prevsent>
<prevsent>2.1 choosing learning approach via f1.</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
a natural way to label sentences is to obtain (by hand or learning) patterns characterizing each field (feng et al, 2006; ravichandran and hovy, 2002).<papid> P02-1006 </papid></citsent>
<aftsection>
<nextsent>we tried to annotate field values for the biomedical data, but we found few intuitive clues that rich surface text patterns could be learned with this corpus.
</nextsent>
<nextsent>this insight, feedback f1, caused us to give up the idea of learning surface text patterns as usual, and switch to the conditional random fields (crf) (lafferty et al, 2001) for labeling sentences instead.
</nextsent>
<nextsent>in contrast to fixed-order patterns, the crf model provides compact way to integrate different types of features for sequential labeling problems and can reach state-of-the-art level performance.
</nextsent>
<nextsent>2.2 determining knowledge schema via f2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD553">
<title id=" W07-2206.xml">improving the efficiency of a wide coverage ccg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we propose partial beam search to further reduce the search space.
</prevsent>
<prevsent>overall, the parsing speed is improved by over 35% with negligible loss of accuracy or coverage.
</prevsent>
</prevsection>
<citsent citstr=" N04-1013 ">
a recent theme in parsing research has been the application of statistical methods to linguistically motivated grammars, for example lfg (kaplan et al., 2004; <papid> N04-1013 </papid>cahill et al, 2004), <papid> P04-1041 </papid>hpsg (toutanova et al, 2002; malouf and van noord, 2004), tag (sarkar and joshi, 2003) and ccg (hockenmaier and steedman, 2002; clark and curran, 2004<papid> P04-1014 </papid>b).</citsent>
<aftsection>
<nextsent>the attraction of linguistically motivated parsers is the potential to produce rich output, in particular thepredicate-argument structure representing the under lying meaning of sentence.
</nextsent>
<nextsent>the disadvantage ofsuch parsers is that they are typically not very efficient, parsing few sentences per second on commodity hardware (kaplan et al, 2004).<papid> N04-1013 </papid></nextsent>
<nextsent>the c&c; ccg parser (clark and curran, 2004<papid> P04-1014 </papid>b) is an order of magnitude faster, but is still limited to around 25 sentences per second.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD554">
<title id=" W07-2206.xml">improving the efficiency of a wide coverage ccg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we propose partial beam search to further reduce the search space.
</prevsent>
<prevsent>overall, the parsing speed is improved by over 35% with negligible loss of accuracy or coverage.
</prevsent>
</prevsection>
<citsent citstr=" P04-1041 ">
a recent theme in parsing research has been the application of statistical methods to linguistically motivated grammars, for example lfg (kaplan et al., 2004; <papid> N04-1013 </papid>cahill et al, 2004), <papid> P04-1041 </papid>hpsg (toutanova et al, 2002; malouf and van noord, 2004), tag (sarkar and joshi, 2003) and ccg (hockenmaier and steedman, 2002; clark and curran, 2004<papid> P04-1014 </papid>b).</citsent>
<aftsection>
<nextsent>the attraction of linguistically motivated parsers is the potential to produce rich output, in particular thepredicate-argument structure representing the under lying meaning of sentence.
</nextsent>
<nextsent>the disadvantage ofsuch parsers is that they are typically not very efficient, parsing few sentences per second on commodity hardware (kaplan et al, 2004).<papid> N04-1013 </papid></nextsent>
<nextsent>the c&c; ccg parser (clark and curran, 2004<papid> P04-1014 </papid>b) is an order of magnitude faster, but is still limited to around 25 sentences per second.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD555">
<title id=" W07-2206.xml">improving the efficiency of a wide coverage ccg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we propose partial beam search to further reduce the search space.
</prevsent>
<prevsent>overall, the parsing speed is improved by over 35% with negligible loss of accuracy or coverage.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
a recent theme in parsing research has been the application of statistical methods to linguistically motivated grammars, for example lfg (kaplan et al., 2004; <papid> N04-1013 </papid>cahill et al, 2004), <papid> P04-1041 </papid>hpsg (toutanova et al, 2002; malouf and van noord, 2004), tag (sarkar and joshi, 2003) and ccg (hockenmaier and steedman, 2002; clark and curran, 2004<papid> P04-1014 </papid>b).</citsent>
<aftsection>
<nextsent>the attraction of linguistically motivated parsers is the potential to produce rich output, in particular thepredicate-argument structure representing the under lying meaning of sentence.
</nextsent>
<nextsent>the disadvantage ofsuch parsers is that they are typically not very efficient, parsing few sentences per second on commodity hardware (kaplan et al, 2004).<papid> N04-1013 </papid></nextsent>
<nextsent>the c&c; ccg parser (clark and curran, 2004<papid> P04-1014 </papid>b) is an order of magnitude faster, but is still limited to around 25 sentences per second.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD568">
<title id=" W07-2206.xml">improving the efficiency of a wide coverage ccg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the disadvantage ofsuch parsers is that they are typically not very efficient, parsing few sentences per second on commodity hardware (kaplan et al, 2004).<papid> N04-1013 </papid></prevsent>
<prevsent>the c&c; ccg parser (clark and curran, 2004<papid> P04-1014 </papid>b) is an order of magnitude faster, but is still limited to around 25 sentences per second.</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
the key to efficient ccg parsing is finite-state super tagger which performs much of the parsing work (bangalore and joshi, 1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>ccg is lexicalised grammar formalism, in which elementary syntactic structures ? in ccgs case lexical categories expressing subcategorisation information are assigned to the words in sentence.
</nextsent>
<nextsent>ccg super tagging can be performed accurately and efficiently by maximum entropy tagger (clark and curran, 2004<papid> P04-1014 </papid>a).</nextsent>
<nextsent>since the lexical categories contain so much grammatical information, assigning them with low average ambiguity leaves the parser, which combines them together, with much less work to do at parse time.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD584">
<title id=" W07-2206.xml">improving the efficiency of a wide coverage ccg parser </title>
<section> the ccg parser.  </section>
<citcontext>
<prevsection>
<prevsent>we use the normal-formmodel, which assigns probabilities to single derivations based on the normal-form derivations in ccg bank.
</prevsent>
<prevsent>the features in the model are defined over local parts of the derivation and include word-word dependencies.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
a packed chart representation allows efficient decoding, with the viterbi algorithm finding the most probable derivation.the super tagger uses log-linear model to define distribution over the lexical category set foreach word and the previous two categories (ratna parkhi, 1996) <papid> W96-0213 </papid>and the forward backward algorithm efficiently sums over all histories to give distribution for each word.</citsent>
<aftsection>
<nextsent>these distributions are then used to assign set of lexical categories to each word (?).
</nextsent>
<nextsent>the number of categories in each set is determined by parameter ?: all categories are assigned whose forward-backward probabilities are within ? of the highest probability category (?).
</nextsent>
<nextsent>if the parser can not then find spanning analysis, the value of ? is reduced ? so that more lexical categories are assigned ? and the parser tries again.
</nextsent>
<nextsent>this process repeats until an analysis spanning the whole sentence is found.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD585">
<title id=" W07-2206.xml">improving the efficiency of a wide coverage ccg parser </title>
<section> constraints.  </section>
<citcontext>
<prevsection>
<prevsent>chunk tags were used to create constraints.
</prevsent>
<prevsent>we experimented with both gold standard chunks from the penn treebank and also chunker output from the c&c; chunk tagger.
</prevsent>
</prevsection>
<citsent citstr=" E03-1071 ">
the tagger is very similar to the maximum entropy pos tagger described in curr anand clark (2003).<papid> E03-1071 </papid></citsent>
<aftsection>
<nextsent>only np chunks were used be cause the accuracy of the tagger for other chunks islower.
</nextsent>
<nextsent>the penn treebank chunks required modification because ccgbank analyses some constructions differently.
</nextsent>
<nextsent>we also created longer nps by con catenating adjacent base nps, for example in the case of possessives.
</nextsent>
<nextsent>a number of punctuation constraints were used and had significant impact especially for longer sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD586">
<title id=" W07-2206.xml">improving the efficiency of a wide coverage ccg parser </title>
<section> selective beam search.  </section>
<citcontext>
<prevsection>
<prevsent>adding constraints alsohas the potential to increase coverage because there duced search space means that longer sentences can be parsed without exceeding the pre-defined limits on chart size.
</prevsent>
<prevsent>beam search involves greedy elimination of low probability partial derivations before they can form complete derivations.
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
it is used in many parsers to reduce the search space, for example collins (2003).<papid> J03-4003 </papid></citsent>
<aftsection>
<nextsent>we use variable width beam where all categories in particular cell that satisfy score(c)  max{score(x)|x ? c} ? b, for some beam cut off b, are removed.
</nextsent>
<nextsent>the category scores score(c) are log probabilities.in the c&c; parser, the entire packed chart is constructed first and then the spanning derivations are marked.
</nextsent>
<nextsent>only the partial derivations that form part of spanning derivations are scored to select the best parse, which is small fraction of the categories in the chart.
</nextsent>
<nextsent>because the categories are scored with complex statistical model with large number of features, the time spent calculating scores is significant.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD587">
<title id=" W07-2206.xml">improving the efficiency of a wide coverage ccg parser </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>constraints and chart repair both manipulate the chart for more efficient parsing.
</prevsent>
<prevsent>adding categories one at time using chart repair is almost form of agenda-based parsing.
</prevsent>
</prevsection>
<citsent citstr=" N03-1016 ">
we intend to explore other methods for pruning the space and agenda-basedparsing, in particular a* parsing (klein and manning, 2003), <papid> N03-1016 </papid>which will allow only the most probable parts of the chart to be built, improving efficiency while still ensuring the optimal derivation is found.</citsent>
<aftsection>
<nextsent>when all of our modifications are used parsing speed increases by 35-40% and the failure rate decreases by 40-65%, both for sentences of length 1-40and 41+, with negligible accuracy penalty.
</nextsent>
<nextsent>there sult is an even faster state-of-the-art wide-coverage ccg parser.
</nextsent>
<nextsent>acknowledgements we would like to thank the anonymous reviewers for their feedback.
</nextsent>
<nextsent>james curran was funded under arc discovery grants dp0453131 and dp0665973.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD588">
<title id=" W08-0119.xml">training and evaluation of the his pomdp dialogue system in noise </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the key idea of the pomdp is that the underlying dialogue state is hidden and dialogue management policies must therefore be based not on single state estimate but on distribution over allstates.
</prevsent>
<prevsent>whilst pomdps are attractive theoretically, in practice, they are notoriously intractable for any thing other than small state/action spaces.
</prevsent>
</prevsection>
<citsent citstr=" P00-1013 ">
hence,practical examples of their use were initially restricted to very simple domains (roy et al, 2000;<papid> P00-1013 </papid>zhang et al, 2001).</citsent>
<aftsection>
<nextsent>more recently, however, number of techniques have been suggested which do allow pomdps to be scaled to handle real world tasks.
</nextsent>
<nextsent>the two generic mechanisms which facilitate this scaling are factoring the state space and performing policy optimisation in reduced summary state space (williams and young, 2007a; williams and young, 2007b).
</nextsent>
<nextsent>based on these ideas, number of real-world pomdp-based systems have recently emerged.
</nextsent>
<nextsent>the most complex entity which must be represented in the state space is the users goal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD589">
<title id=" W08-0119.xml">training and evaluation of the his pomdp dialogue system in noise </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the resulting system is then modelled as dynamic bayesian network (thomson et al, 2008).
</prevsent>
<prevsent>a similar approach is also developed in 112(bui et al, 2007a; bui et al, 2007b).
</prevsent>
</prevsection>
<citsent citstr=" W07-0302 ">
an alternative approach taken in the hidden information state (his) system is to retain complete representation of the users goal, but partition states into equivalence classes and prune away very low probability partitions (young et al, 2007; thomson et al, 2007; <papid> W07-0302 </papid>williams and young, 2007b).</citsent>
<aftsection>
<nextsent>whichever approach is taken, key issue in real pomdp-based dialogue system is its ability to be robust to noise and that is the issue that is addressed in this paper.
</nextsent>
<nextsent>using the his system as an exemplar, evaluation results are presented for real-world tourist information task using both simulated and real users.
</nextsent>
<nextsent>the results show that pomdp system can learn noise robust policies and that n-best outputs from the speech understanding component can be exploited to further improve robustness.the paper is structured as follows.
</nextsent>
<nextsent>firstly, in section 2 brief overview of the his system is given.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD590">
<title id=" W07-2062.xml">rtv tree kernels for thematic role classification </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>and the charter?
</prevsent>
<prevsent>in figure 1 may be assigned role: ? if more than two nodes are involved, i. e. node and two or more of its descendants ni are classified as arguments, then assume that isnot an argument.
</prevsent>
</prevsection>
<citsent citstr=" W06-2909 ">
this choice is justified by previous studies (moschitti et al, 2006<papid> W06-2909 </papid>b) showing that the accuracy of classification is higher for lower nodes;?</citsent>
<aftsection>
<nextsent>if only two nodes are involved, i. e. they dominate each other, then keep the one with the highest classification score.
</nextsent>
<nextsent>we explicitly represent as attribute-value pairs the following features of each fp,a pair:?
</nextsent>
<nextsent>phrase type, predicate word, head word, position and voice as defined in (gildea and juras fky, 2002); ? partial path, no direction path, head word pos, first and last word/pos in constituent and subcategorization as proposed in (pradhan et al, 2005); a) np dt the nn charter vp aux was vp vbn approved pp in by np dt the nnp ec nnp commission pp in on np nnp sept. cd 21 . . b) np-b dt the nn charter vp vp vbn-p approved vp vbn-p approved pp-b in by np dt the nnp ec nnp commission cause experiencer argm-tmp figure 1: sentence parse tree (a) and two example astm1 structures relative to the predicate approve (b).
</nextsent>
<nextsent>set props t+ t?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD598">
<title id=" W07-2062.xml">rtv tree kernels for thematic role classification </title>
<section> features for semantic role labeling.  </section>
<citcontext>
<prevsection>
<prevsent>set props t+ t?
</prevsent>
<prevsent>train 15,838 793,104 45,157 747,947 dev 1,606 75,302 4,291 71,011 train - dev 14,232 717,802 40,866 676,936 table 1: composition of the dataset in terms of: number of annotations (props); number of candidate argument nodes (t ); positive (t+) and negative (t?) boundary classifier examples.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
syntactic frame as designed in (xue and palmer, 2004).<papid> W04-3212 </papid></citsent>
<aftsection>
<nextsent>we also employ structured features derived by the full parses in an attempt to capture relevant aspects that may not be emphasized by the explicit featurerepresentation.
</nextsent>
<nextsent>(moschitti et al, 2006<papid> W06-2909 </papid>a) and (moschitti et al, 2006<papid> W06-2909 </papid>b) defined several classes of structured features that were successfully employed with tree kernels for the different stages of an srl process.</nextsent>
<nextsent>figure 1 shows an example of the astm1 structures that we used for both the boundary detection and the role classification stages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD615">
<title id=" W07-2062.xml">rtv tree kernels for thematic role classification </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in order to build development set (dev), we sampled about one tenth, i. e. 1,606 annotations, of the original training set.
</prevsent>
<prevsent>for the final evaluation on the test set (test),consisting of 3,094 annotations, we trained our classifiers on the whole training data.
</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
statistics on the dataset composition are shown in table 1.the evaluations were carried out with the svmlight-tk2 software (moschitti, 2004) <papid> P04-1043 </papid>which extends the svm-light package (joachims, 1999) with tree kernel functions.</citsent>
<aftsection>
<nextsent>we used the default polynomial kernel (degree=3) for the linear features and subset tree (sst) kernel (collins and duffy,2002) <papid> P02-1034 </papid>for the comparison of astm1 structured fea tures.</nextsent>
<nextsent>the kernels are normalized and summed by assigning weight of 0.3 to the tk contribution.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD616">
<title id=" W07-2062.xml">rtv tree kernels for thematic role classification </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for the final evaluation on the test set (test),consisting of 3,094 annotations, we trained our classifiers on the whole training data.
</prevsent>
<prevsent>statistics on the dataset composition are shown in table 1.the evaluations were carried out with the svmlight-tk2 software (moschitti, 2004) <papid> P04-1043 </papid>which extends the svm-light package (joachims, 1999) with tree kernel functions.</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
we used the default polynomial kernel (degree=3) for the linear features and subset tree (sst) kernel (collins and duffy,2002) <papid> P02-1034 </papid>for the comparison of astm1 structured fea tures.</citsent>
<aftsection>
<nextsent>the kernels are normalized and summed by assigning weight of 0.3 to the tk contribution.
</nextsent>
<nextsent>training all the 50 boundary classifiers and the 619 role classifiers on the whole dataset took about 4 hours on 64 bits machine (2.2ghz, 1gb ram)3.
</nextsent>
<nextsent>4.2 evaluation.
</nextsent>
<nextsent>all the evaluations were carried out using the conll2005 evaluator tool available at http://www.lsi.upc.es/srlconll/soft.html.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD625">
<title id=" W08-0320.xml">improving english spanish statistical machine translation experiments in domain adaptation sentence paraphrasing tokenization and re casing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>modern statistical machine translation (smt) systems are trained on sentence-aligned bilingual corpora, typically from single domain.
</prevsent>
<prevsent>when tested on text from that same domain, they demonstrate after january 2008 at the linguistic modeling department, institute for parallel processing, bulgarian academy of sciences, nakov@lml.bas.bg state-of-the art performance, but on out-of-domain test data the results can get significantly worse.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
for example, on the wmt06 shared translation task, the scores for french to english translation dropped from about 30 to about 20 bleu points for nearly all systems when tested on news commentary rather than europarl text, which was used on training (koehn and monz, 2006).<papid> W06-3114 </papid></citsent>
<aftsection>
<nextsent>therefore, in 2007 the shared task organizers provided 1m words of bilingual news commentary training data in addition to the 30m europarl data,thus inviting interest in domain adaptation experiments.
</nextsent>
<nextsent>given the success of the idea, the same taskwas offered this year with slightly larger training bi texts: 1.3m and 32m words, respectively.
</nextsent>
<nextsent>the team of the university of california at berkeley(ucb) participated in the wmt08 shared translation task with two systems, english spanish andspanishenglish, applied to translating news commentary text, for which very limited amount of training data was provided.
</nextsent>
<nextsent>we experimented with domain adaptation, combining the provided small in-domain bi-text and the large out-of-domain onefrom the europarl corpus, building two phrase translation models and two language models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD626">
<title id=" W08-0320.xml">improving english spanish statistical machine translation experiments in domain adaptation sentence paraphrasing tokenization and re casing </title>
<section> system parameters.  </section>
<citcontext>
<prevsection>
<prevsent>we then pair each paraphrased sentence with the foreign translation associated with the original sentence in the training data.
</prevsent>
<prevsent>the resulting augmented bi-text is used to train an smt system, which learns many useful new phrases.
</prevsent>
</prevsection>
<citsent citstr=" W07-0730 ">
the idea was introduced in (nakov and hearst, 2007), <papid> W07-0730 </papid>and is described in more detail in (nakov, 2007).unfortunately, using multiple paraphrased versions of the same sentence changes the word frequencies in the training bi-text, thus causing worse maximum likelihood estimates, which results in bad system performance.</citsent>
<aftsection>
<nextsent>however, real improvements can still be achieved by merging the phrase tables of the two systems, giving priority to the original.
</nextsent>
<nextsent>2.2 domain adaptation.
</nextsent>
<nextsent>in our previous findings (nakov and hearst, 2007), <papid> W07-0730 </papid>we found that using in-domain and out-of-domainlanguage models is the best way to perform do main adaptation.</nextsent>
<nextsent>following (koehn and schroeder, 2007), <papid> W07-0733 </papid>we further used two phrase tables.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD630">
<title id=" W08-0320.xml">improving english spanish statistical machine translation experiments in domain adaptation sentence paraphrasing tokenization and re casing </title>
<section> system parameters.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 domain adaptation.
</prevsent>
<prevsent>in our previous findings (nakov and hearst, 2007), <papid> W07-0730 </papid>we found that using in-domain and out-of-domainlanguage models is the best way to perform do main adaptation.</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
following (koehn and schroeder, 2007), <papid> W07-0733 </papid>we further used two phrase tables.</citsent>
<aftsection>
<nextsent>2.3 improving the recaser.
</nextsent>
<nextsent>one problem we noticed with the default recasingis that unknown words are left in lowercase.
</nextsent>
<nextsent>however, many unknown words are in fact named entities (persons, organization, or locations), which should be spelled capitalized.
</nextsent>
<nextsent>therefore, we prepared new re casing script, which makes sure that all unknown words keep their original case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD631">
<title id=" W08-0320.xml">improving english spanish statistical machine translation experiments in domain adaptation sentence paraphrasing tokenization and re casing </title>
<section> the ucb system.  </section>
<citcontext>
<prevsection>
<prevsent>149 we further merged rnews, reuro, and rpar in similar manner: we first kept all phrases from rnews, then we added those from reuro which were not present in rnews, and finally those from rpar which were not in rnews nor in reuro.
</prevsent>
<prevsent>we used two language models with kneser-neysmoothing: 3-gram model trained on news commentary, and 5-gram model trained on europarl.we then trained log-linear model using the following feature functions: language model probabilities, word penalty, distortion cost, and the parameters from the phrase table.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we set the feature weights by optimizing the bleu score directly using minimum error rate training (och, 2003) <papid> P03-1021 </papid>on the development set.</citsent>
<aftsection>
<nextsent>we used these weights in beam search decoder to produce translations for the test sentences, which we compared to the wmt07 gold standard using bleu (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
<nextsent>table 1 shows the evaluation results using the wmt07 news commentary test data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD632">
<title id=" W08-0320.xml">improving english spanish statistical machine translation experiments in domain adaptation sentence paraphrasing tokenization and re casing </title>
<section> the ucb system.  </section>
<citcontext>
<prevsection>
<prevsent>we used two language models with kneser-neysmoothing: 3-gram model trained on news commentary, and 5-gram model trained on europarl.we then trained log-linear model using the following feature functions: language model probabilities, word penalty, distortion cost, and the parameters from the phrase table.
</prevsent>
<prevsent>we set the feature weights by optimizing the bleu score directly using minimum error rate training (och, 2003) <papid> P03-1021 </papid>on the development set.</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we used these weights in beam search decoder to produce translations for the test sentences, which we compared to the wmt07 gold standard using bleu (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>table 1 shows the evaluation results using the wmt07 news commentary test data.
</nextsent>
<nextsent>our best english spanish system news10euro10par10(see the table caption for explanation of the nota tion), which is also our submission, achieved 35.09bleu score with the improved recaser; with the default recaser, the score drops to 34.85.
</nextsent>
<nextsent>due to space limitations, our spanish english results are not in table 1.
</nextsent>
<nextsent>this time, we did not use paraphrases, and our best system news10euro10achieved 35.78 and 35.17 bleu score with the improved and the default recaser, respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD633">
<title id=" W07-0905.xml">the latin dependency treebank in a cultural heritage digital library </title>
<section> the influence of digital library.  </section>
<citcontext>
<prevsection>
<prevsent>modern treebanks also differ from historical ones inthe fluency of their annotators.
</prevsent>
<prevsent>the efficient annotation of historical languages is hindered by the fact that no native speakers exist, and this is especially true of latin, difficult language with high degree of non-projectivity.
</prevsent>
</prevsection>
<citsent citstr=" H01-1026 ">
while the penn treebank can report productivity rate of between 750 and 1000 words per hour for their annotators after four months of training (taylor et al, 2003) and the penn chinese treebank can report rate of 240-480 words per hour (chiou et al, 2001), <papid> H01-1026 </papid>our annotation speeds are significantly slower, ranging from 90 words perhour to 281.</citsent>
<aftsection>
<nextsent>our best approach for latin is to develop strategies that can speed up the annotation process, and here the resources found in digital library are crucial.
</nextsent>
<nextsent>there are three varieties of contextual resources in our digital library that aid in theun derstanding of text: translations, commentaries, and dictionaries.
</nextsent>
<nextsent>these resources shed light on text, from the level of sentences to that of individual words.translations.
</nextsent>
<nextsent>translations provide reading support on large scale: while loose translations may not be able to inform readers about the meaning and syntactic role of any single word, they do provide broad description of the action taking place, andthis can often help to establish the semantic structure of the sentence ? who did what to whom, and how.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD634">
<title id=" W07-2022.xml">clac and clacnb knowledge based and corpus based approaches to sentiment tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, an ideal system for sentiment tagging of headlines has to usea large set of features with dependable sentiment annotations and to be able to reliably deduce the sentiment of the headline from the sentiment of its components.
</prevsent>
<prevsent>the valence labeling subtask of the affective text task requires ternary ? positive vs. negative vs. neutral ? classification of headlines.
</prevsent>
</prevsection>
<citsent citstr=" I05-2011 ">
while such categorization at the sentence level remains relatively unexplored1 , the two related sentence-level, binary classification tasks ? positive vs. negative and subjective vs. objective ? have attracted considerable attention in the recent years (hu and liu,2004; kim and hovy, 2005; <papid> I05-2011 </papid>riloff et al, 2006; <papid> W06-1652 </papid>tur ney and littman, 2003; yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>unsupervised knowledge-based methods are the preferred approach to classification of sentences into positive and negative, mostly due to the lack of adequate amounts of labeled training data (gamon and aue, 2005).<papid> W05-0408 </papid></nextsent>
<nextsent>these approaches relyon presence and scores of sentiment-bearing words that have been acquired from dictionaries (kim and hovy, 2005) <papid> I05-2011 </papid>or corpora (yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD635">
<title id=" W07-2022.xml">clac and clacnb knowledge based and corpus based approaches to sentiment tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, an ideal system for sentiment tagging of headlines has to usea large set of features with dependable sentiment annotations and to be able to reliably deduce the sentiment of the headline from the sentiment of its components.
</prevsent>
<prevsent>the valence labeling subtask of the affective text task requires ternary ? positive vs. negative vs. neutral ? classification of headlines.
</prevsent>
</prevsection>
<citsent citstr=" W06-1652 ">
while such categorization at the sentence level remains relatively unexplored1 , the two related sentence-level, binary classification tasks ? positive vs. negative and subjective vs. objective ? have attracted considerable attention in the recent years (hu and liu,2004; kim and hovy, 2005; <papid> I05-2011 </papid>riloff et al, 2006; <papid> W06-1652 </papid>tur ney and littman, 2003; yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>unsupervised knowledge-based methods are the preferred approach to classification of sentences into positive and negative, mostly due to the lack of adequate amounts of labeled training data (gamon and aue, 2005).<papid> W05-0408 </papid></nextsent>
<nextsent>these approaches relyon presence and scores of sentiment-bearing words that have been acquired from dictionaries (kim and hovy, 2005) <papid> I05-2011 </papid>or corpora (yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD636">
<title id=" W07-2022.xml">clac and clacnb knowledge based and corpus based approaches to sentiment tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, an ideal system for sentiment tagging of headlines has to usea large set of features with dependable sentiment annotations and to be able to reliably deduce the sentiment of the headline from the sentiment of its components.
</prevsent>
<prevsent>the valence labeling subtask of the affective text task requires ternary ? positive vs. negative vs. neutral ? classification of headlines.
</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
while such categorization at the sentence level remains relatively unexplored1 , the two related sentence-level, binary classification tasks ? positive vs. negative and subjective vs. objective ? have attracted considerable attention in the recent years (hu and liu,2004; kim and hovy, 2005; <papid> I05-2011 </papid>riloff et al, 2006; <papid> W06-1652 </papid>tur ney and littman, 2003; yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>unsupervised knowledge-based methods are the preferred approach to classification of sentences into positive and negative, mostly due to the lack of adequate amounts of labeled training data (gamon and aue, 2005).<papid> W05-0408 </papid></nextsent>
<nextsent>these approaches relyon presence and scores of sentiment-bearing words that have been acquired from dictionaries (kim and hovy, 2005) <papid> I05-2011 </papid>or corpora (yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD638">
<title id=" W07-2022.xml">clac and clacnb knowledge based and corpus based approaches to sentiment tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the valence labeling subtask of the affective text task requires ternary ? positive vs. negative vs. neutral ? classification of headlines.
</prevsent>
<prevsent>while such categorization at the sentence level remains relatively unexplored1 , the two related sentence-level, binary classification tasks ? positive vs. negative and subjective vs. objective ? have attracted considerable attention in the recent years (hu and liu,2004; kim and hovy, 2005; <papid> I05-2011 </papid>riloff et al, 2006; <papid> W06-1652 </papid>tur ney and littman, 2003; yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-0408 ">
unsupervised knowledge-based methods are the preferred approach to classification of sentences into positive and negative, mostly due to the lack of adequate amounts of labeled training data (gamon and aue, 2005).<papid> W05-0408 </papid></citsent>
<aftsection>
<nextsent>these approaches relyon presence and scores of sentiment-bearing words that have been acquired from dictionaries (kim and hovy, 2005) <papid> I05-2011 </papid>or corpora (yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></nextsent>
<nextsent>their accuracy on news sentences is between 65 and 68%.sentence-level subjectivity detection, where training data is easier to obtain than for positive vs. negative classification, has been successfully performed using supervised statistical methods alone (pang andlee, 2004) <papid> P04-1035 </papid>or in combination with knowledge based approach (riloff et al, 2006).<papid> W06-1652 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD642">
<title id=" W07-2022.xml">clac and clacnb knowledge based and corpus based approaches to sentiment tagging </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised knowledge-based methods are the preferred approach to classification of sentences into positive and negative, mostly due to the lack of adequate amounts of labeled training data (gamon and aue, 2005).<papid> W05-0408 </papid></prevsent>
<prevsent>these approaches relyon presence and scores of sentiment-bearing words that have been acquired from dictionaries (kim and hovy, 2005) <papid> I05-2011 </papid>or corpora (yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
their accuracy on news sentences is between 65 and 68%.sentence-level subjectivity detection, where training data is easier to obtain than for positive vs. negative classification, has been successfully performed using supervised statistical methods alone (pang andlee, 2004) <papid> P04-1035 </papid>or in combination with knowledge based approach (riloff et al, 2006).<papid> W06-1652 </papid></citsent>
<aftsection>
<nextsent>since the extant literature does not provide clear evidence for the choice between supervised machine learning methods and unsupervised knowledge based approaches for the task of ternary sentiment classification of sentences or headlines, we developed two systems for the affective text task at semeval-2007.
</nextsent>
<nextsent>the first system (clac) relies onthe knowledge-rich approach that takes into consid1to our knowledge, the only work that attempted such classification at the sentence level is (gamon and aue, 2005) <papid> W05-0408 </papid>that classified product reviews.</nextsent>
<nextsent>117eration multiple clues, such as list of sentiment bearing unigrams and valence shift ers, and makes use of sentence structure in order to combine these clues into an overall sentiment of the headline.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD645">
<title id=" W07-2022.xml">clac and clacnb knowledge based and corpus based approaches to sentiment tagging </title>
<section> clac system: syntax-aware.  </section>
<citcontext>
<prevsection>
<prevsent>the system uses three main knowledge inputs: list of sentiment-bearing unigrams, list of valence shift ers (polanyi and zaenen, 2006), and set ofrules that define the scope and results of combination of sentiment-bearing words with valence shifters.
</prevsent>
<prevsent>2.1 list of sentiment-bearing words.
</prevsent>
</prevsection>
<citsent citstr=" E06-1027 ">
the unigrams used for sentence/headline classification were learned from wordnet (fellbaum, 1998) dictionary entries using the step system described in (andreevskaia and bergler, 2006<papid> E06-1027 </papid>b).</citsent>
<aftsection>
<nextsent>in order to take advantage of the special properties of wordnet glosses and relations, we developed system that used the human-annotated adjectives from (hatzi vassiloglou and mckeown, 1997) <papid> P97-1023 </papid>as seed list and learned additional unigrams from wordnet synsets and glosses.</nextsent>
<nextsent>the step algorithm starts with small set of manually annotated seed words thatis expanded using synonymy and antonymy relations in wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD646">
<title id=" W07-2022.xml">clac and clacnb knowledge based and corpus based approaches to sentiment tagging </title>
<section> clac system: syntax-aware.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 list of sentiment-bearing words.
</prevsent>
<prevsent>the unigrams used for sentence/headline classification were learned from wordnet (fellbaum, 1998) dictionary entries using the step system described in (andreevskaia and bergler, 2006<papid> E06-1027 </papid>b).</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
in order to take advantage of the special properties of wordnet glosses and relations, we developed system that used the human-annotated adjectives from (hatzi vassiloglou and mckeown, 1997) <papid> P97-1023 </papid>as seed list and learned additional unigrams from wordnet synsets and glosses.</citsent>
<aftsection>
<nextsent>the step algorithm starts with small set of manually annotated seed words thatis expanded using synonymy and antonymy relations in wordnet.
</nextsent>
<nextsent>then the system searches all wordnet glosses and selects the synsets that contain sentiment-bearing words from the expanded seed list in their glosses.
</nextsent>
<nextsent>in order to eliminate errors produced by part-of-speech ambiguity of some of the seed words, the glosses are processed by brills part-of-speech tagger (brill, 1995) <papid> J95-4004 </papid>and only the seed words with matching part-of-speech tags are consid ered.</nextsent>
<nextsent>headwords with sentiment-bearing seed words in their definitions are then added to the positive or negative categories depending on the seed-word sentiment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD647">
<title id=" W07-2022.xml">clac and clacnb knowledge based and corpus based approaches to sentiment tagging </title>
<section> clac system: syntax-aware.  </section>
<citcontext>
<prevsection>
<prevsent>the step algorithm starts with small set of manually annotated seed words thatis expanded using synonymy and antonymy relations in wordnet.
</prevsent>
<prevsent>then the system searches all wordnet glosses and selects the synsets that contain sentiment-bearing words from the expanded seed list in their glosses.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
in order to eliminate errors produced by part-of-speech ambiguity of some of the seed words, the glosses are processed by brills part-of-speech tagger (brill, 1995) <papid> J95-4004 </papid>and only the seed words with matching part-of-speech tags are consid ered.</citsent>
<aftsection>
<nextsent>headwords with sentiment-bearing seed words in their definitions are then added to the positive or negative categories depending on the seed-word sentiment.
</nextsent>
<nextsent>finally, words that were assigned contradicting ? positive and negative ? sentiment with inthe same run were eliminated.
</nextsent>
<nextsent>the average accuracy of 60 runs with non-intersecting seed lists when compared to general inquirer (stone et al, 1966) was 74%.
</nextsent>
<nextsent>in order to improve the list coverage, the words annotated as positiv?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD651">
<title id=" W07-1426.xml">machine learning based semantic inference experiments and observations at rte3 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>wordnet::similarity package: perl module that implements variety of semantic similarity and relatedness measures based on wordnet (pedersen et al, 2005).
</prevsent>
<prevsent>this package is used for deriving lss and dist features in feature extraction module.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
c&c; parser: powerful ccg parser (clark and curran 2004).<papid> P04-1014 </papid></citsent>
<aftsection>
<nextsent>we use c&c; parser to obtain dependent content word pairs in dependency parsing module.
</nextsent>
<nextsent>weka: the widely used data mining software (witten&frank; 2005).
</nextsent>
<nextsent>we have experimented with several machine learning algorithms implemented in weka at the second stage.
</nextsent>
<nextsent>in this section, we explain the seven features that we employ in our rte-3 system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD653">
<title id=" W07-2006.xml">semeval2007 task 07 coarse grained english all words task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we present the results of participating systems and discuss future directions.
</prevsent>
<prevsent>it is commonly thought that one of the major obstacles to high-performance word sense disambiguation (wsd) is the fine granularity of sense inventories.
</prevsent>
</prevsection>
<citsent citstr=" W04-0811 ">
state-of-the-art systems attained disambiguation accuracy around 65% in the senseval-3 all-words task (snyder and palmer, 2004), <papid> W04-0811 </papid>where wordnet (fellbaum, 1998) was adopted as reference sense inventory.</citsent>
<aftsection>
<nextsent>unfortunately, wordnet is fine-grained resource, encoding sense distinctions that are difficult to recognize even for human annotators (edmonds and kilgarriff, 2002).
</nextsent>
<nextsent>making wsd an enabling technique for end-to-end applications clearly depends on the ability to deal with reasonable sense distinctions.
</nextsent>
<nextsent>the aim of this task was to explicitly tackle the granularity issue and study the performance of wsd systems on an all-words basis when coarser set of senses is provided for the target words.
</nextsent>
<nextsent>given the need of the nlp community to work on freely available resources, the solution of adopting different computational lexicon is not viable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD655">
<title id=" W07-2006.xml">semeval2007 task 07 coarse grained english all words task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main issue is certainly the subjectivity of sense clusters.
</prevsent>
<prevsent>to overcome this problem, different strategies can be adopted.
</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
for instance, in the ontonotes project (hovy et al, 2006) <papid> N06-2015 </papid>senses are grouped until 90% inter-annotator agreement is achieved.</citsent>
<aftsection>
<nextsent>in contrast, as we describe in this paper, our approach is based on mapping to previously existing inventory which encodes sense distinctions at different levels of granularity, thus allowing to induce sense clustering for the mapped senses.we would like to mention that another semeval 2007 task dealt with the issue of sense granularityfor wsd, namely task 17 (subtask #1): coarse grained english lexical sample wsd.
</nextsent>
<nextsent>in this paper, we report our experience in organizing task 07.
</nextsent>
<nextsent>the task required participating systems to annotate open-class words (i.e. nouns, verbs, adjectives, and adverbs) in test corpus with the most appropriate sense from coarse-grained version of the wordnet sense inventory.
</nextsent>
<nextsent>2.1 test corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD656">
<title id=" W07-2006.xml">semeval2007 task 07 coarse grained english all words task </title>
<section> task setup.  </section>
<citcontext>
<prevsection>
<prevsent>we observe that articles d003 and d004 are the largest in the corpus (they constitute 51.87% of it).
</prevsent>
<prevsent>2.2 creation of coarse-grained sense.
</prevsent>
</prevsection>
<citsent citstr=" P06-1014 ">
inventory to tackle the granularity issue, we produced acoarser-grained version of the wordnet sense inven tory3 based on the procedure described by navigli(2006).<papid> P06-1014 </papid></citsent>
<aftsection>
<nextsent>the method consists of automatically mapping wordnet senses to top level, numbered entries in the oxford dictionary of english (ode, (soanesand stevenson, 2003)).
</nextsent>
<nextsent>the semantic mapping between wordnet and ode entries was obtained intwo steps: first, we disambiguated with the ssi algorithm (navigli and velardi, 2005) the definitions ofthe two dictionaries, together with additional information (hypernyms and domain labels); second, foreach wordnet sense, we determined the best matching ode coarse entry.
</nextsent>
<nextsent>as result, wordnet senses mapped to the same ode entry were assigned to the same sense cluster.
</nextsent>
<nextsent>wordnet senses with no match were associated with singleton sense.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD658">
<title id=" W07-2006.xml">semeval2007 task 07 coarse grained english all words task </title>
<section> task setup.  </section>
<citcontext>
<prevsection>
<prevsent>of 6.18.
</prevsent>
<prevsent>2.4 inter-annotator agreement.
</prevsent>
</prevsection>
<citsent citstr=" W02-0817 ">
recent estimations of the inter-annotator agreement when using the wordnet inventory report figures of 72.5% agreement in the preparation of the english all-words test set at senseval-3 (snyder and palmer,2004) <papid> W04-0811 </papid>and 67.3% on the open mind word expert annotation exercise (chklovski and mihalcea, 2002).<papid> W02-0817 </papid>as the inter-annotator agreement is often considered an upper bound for wsd systems, it was desirable to have much higher number for our task, given its coarse-grained nature.</citsent>
<aftsection>
<nextsent>to this end, beside the expert lexicographer, second author independently performed part of the manual sense mapping (590 word senses) described in section 2.2.
</nextsent>
<nextsent>the pairwise agreement was 86.44%.
</nextsent>
<nextsent>we repeated the same agreement evaluation onthe sense annotation task of the test corpus.
</nextsent>
<nextsent>a second author independently annotated part of the test set (710 word instances).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD659">
<title id=" W07-2006.xml">semeval2007 task 07 coarse grained english all words task </title>
<section> baselines.  </section>
<citcontext>
<prevsection>
<prevsent>the accuracy of the mfs baseline was calculated as: blmfs = 1|t | |t |?
</prevsent>
<prevsent>i=1 ?(wi, 1) where ?(wi, k) equals 1 when the k-th sense ofword wi belongs to the cluster(s) manually associated by the lexicographer to word wi (0 otherwise).
</prevsent>
</prevsection>
<citsent citstr=" H93-1061 ">
notice that our calculation of the mfs is based on the frequencies in the semcor corpus (miller et al, 1993), <papid> H93-1061 </papid>as we exploit wordnet sense rankings.</citsent>
<aftsection>
<nextsent>12 teams submitted 14 systems overall (plus two systems from 13th withdrawn team that we will not report).
</nextsent>
<nextsent>according to the semeval policy for task organizers, we remark that the system labelled as uor-ssi was submitted by the first author (thesystem is based on the structural semantic interconnections algorithm (navigli and velardi, 2005)with lexical knowledge base composed by wordnet and approximately 70,000 relatedness edges).even though we did not specifically enrich the algorithms knowledge base on the task at hand, we list the system separately from the overall ranking.the results are shown in table 3.
</nextsent>
<nextsent>we calculated mfs baseline of 78.89% and random baseline of 52.43%.
</nextsent>
<nextsent>in table 4 we report the f1 measures for all systems where we used the mfs as aback off strategy when no sense assignment was attempted (this possibly reranked 6 systems - marked in bold in the table - which did not assign sense to all word instances in the test set).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD662">
<title id=" W07-1704.xml">lemmatization of polish person names </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>proper names constitute significant part of natural language texts (estimated to about 10% in newspaper articles) and are important for nlp applications,such as information extraction, which relyon automatic text understanding.1 in particular, coreference resolution (e.g., identifying several name variants as referring to the same entity) plays crucial role in such systems.
</prevsent>
<prevsent>although automatic recognition of proper names in english, french and other major languages has been in the research focus forover decade now, cf.
</prevsent>
</prevsection>
<citsent citstr=" A97-1029 ">
(bikel et al, 1997), (<papid> A97-1029 </papid>borthwick, 1999), (li et al, 2003), only few efforts have been reported for slavic languages, cf.</citsent>
<aftsection>
<nextsent>(cunningham et al, 2003) (russian and bulgarian), (piskorski, 2005) (polish).
</nextsent>
<nextsent>rich inflection and more relaxed word order make recognition of proper names in slavic more difficult than for other languages.
</nextsent>
<nextsent>moreover, inflection of proper names is usually 1the research presented in this paper was partially founded by the ministry of education and science (poland), grant number 3t11c00727.quite different from common nouns, which complicates the lemmatization process necessary for correct coreference resolution.
</nextsent>
<nextsent>in this paper, we focus on lemmatization of polish person names, the most idiosyncratic class of proper names in this language.first, we report results of rule-based symbolic approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD663">
<title id=" W07-1211.xml">a task based comparison of information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>muslea (1999) reviewed the approaches which were used at the time and found that the most common techniques relied on lexico syntactic patterns being applied to text which has undergone relatively shallow linguistic processing.
</prevsent>
<prevsent>for example, the extraction rules used by soderland(1999) and riloff (1996) match text in which syntactic chunks have been identified.
</prevsent>
</prevsection>
<citsent citstr=" A00-1039 ">
more recently researchers have begun to employ deeper syntactic analysis, such as dependency parsing (yangarber et al., 2000; <papid> A00-1039 </papid>stevenson and greenwood, 2005; <papid> P05-1047 </papid>sudo et al., 2001; <papid> H01-1009 </papid>sudo et al, 2003; <papid> P03-1029 </papid>yangarber, 2003).<papid> P03-1044 </papid></citsent>
<aftsection>
<nextsent>in these approaches extraction patterns are essentially parts of the dependency tree.
</nextsent>
<nextsent>to perform extraction they are compared against the dependency analysis of sentence to determine whether it contains the pattern.
</nextsent>
<nextsent>each of these approaches relies on pattern model to define which parts of the dependency treecan be used to form the extraction patterns.
</nextsent>
<nextsent>a variety of pattern models have been proposed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD664">
<title id=" W07-1211.xml">a task based comparison of information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>muslea (1999) reviewed the approaches which were used at the time and found that the most common techniques relied on lexico syntactic patterns being applied to text which has undergone relatively shallow linguistic processing.
</prevsent>
<prevsent>for example, the extraction rules used by soderland(1999) and riloff (1996) match text in which syntactic chunks have been identified.
</prevsent>
</prevsection>
<citsent citstr=" P05-1047 ">
more recently researchers have begun to employ deeper syntactic analysis, such as dependency parsing (yangarber et al., 2000; <papid> A00-1039 </papid>stevenson and greenwood, 2005; <papid> P05-1047 </papid>sudo et al., 2001; <papid> H01-1009 </papid>sudo et al, 2003; <papid> P03-1029 </papid>yangarber, 2003).<papid> P03-1044 </papid></citsent>
<aftsection>
<nextsent>in these approaches extraction patterns are essentially parts of the dependency tree.
</nextsent>
<nextsent>to perform extraction they are compared against the dependency analysis of sentence to determine whether it contains the pattern.
</nextsent>
<nextsent>each of these approaches relies on pattern model to define which parts of the dependency treecan be used to form the extraction patterns.
</nextsent>
<nextsent>a variety of pattern models have been proposed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD665">
<title id=" W07-1211.xml">a task based comparison of information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>muslea (1999) reviewed the approaches which were used at the time and found that the most common techniques relied on lexico syntactic patterns being applied to text which has undergone relatively shallow linguistic processing.
</prevsent>
<prevsent>for example, the extraction rules used by soderland(1999) and riloff (1996) match text in which syntactic chunks have been identified.
</prevsent>
</prevsection>
<citsent citstr=" H01-1009 ">
more recently researchers have begun to employ deeper syntactic analysis, such as dependency parsing (yangarber et al., 2000; <papid> A00-1039 </papid>stevenson and greenwood, 2005; <papid> P05-1047 </papid>sudo et al., 2001; <papid> H01-1009 </papid>sudo et al, 2003; <papid> P03-1029 </papid>yangarber, 2003).<papid> P03-1044 </papid></citsent>
<aftsection>
<nextsent>in these approaches extraction patterns are essentially parts of the dependency tree.
</nextsent>
<nextsent>to perform extraction they are compared against the dependency analysis of sentence to determine whether it contains the pattern.
</nextsent>
<nextsent>each of these approaches relies on pattern model to define which parts of the dependency treecan be used to form the extraction patterns.
</nextsent>
<nextsent>a variety of pattern models have been proposed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD666">
<title id=" W07-1211.xml">a task based comparison of information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>muslea (1999) reviewed the approaches which were used at the time and found that the most common techniques relied on lexico syntactic patterns being applied to text which has undergone relatively shallow linguistic processing.
</prevsent>
<prevsent>for example, the extraction rules used by soderland(1999) and riloff (1996) match text in which syntactic chunks have been identified.
</prevsent>
</prevsection>
<citsent citstr=" P03-1029 ">
more recently researchers have begun to employ deeper syntactic analysis, such as dependency parsing (yangarber et al., 2000; <papid> A00-1039 </papid>stevenson and greenwood, 2005; <papid> P05-1047 </papid>sudo et al., 2001; <papid> H01-1009 </papid>sudo et al, 2003; <papid> P03-1029 </papid>yangarber, 2003).<papid> P03-1044 </papid></citsent>
<aftsection>
<nextsent>in these approaches extraction patterns are essentially parts of the dependency tree.
</nextsent>
<nextsent>to perform extraction they are compared against the dependency analysis of sentence to determine whether it contains the pattern.
</nextsent>
<nextsent>each of these approaches relies on pattern model to define which parts of the dependency treecan be used to form the extraction patterns.
</nextsent>
<nextsent>a variety of pattern models have been proposed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD667">
<title id=" W07-1211.xml">a task based comparison of information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>muslea (1999) reviewed the approaches which were used at the time and found that the most common techniques relied on lexico syntactic patterns being applied to text which has undergone relatively shallow linguistic processing.
</prevsent>
<prevsent>for example, the extraction rules used by soderland(1999) and riloff (1996) match text in which syntactic chunks have been identified.
</prevsent>
</prevsection>
<citsent citstr=" P03-1044 ">
more recently researchers have begun to employ deeper syntactic analysis, such as dependency parsing (yangarber et al., 2000; <papid> A00-1039 </papid>stevenson and greenwood, 2005; <papid> P05-1047 </papid>sudo et al., 2001; <papid> H01-1009 </papid>sudo et al, 2003; <papid> P03-1029 </papid>yangarber, 2003).<papid> P03-1044 </papid></citsent>
<aftsection>
<nextsent>in these approaches extraction patterns are essentially parts of the dependency tree.
</nextsent>
<nextsent>to perform extraction they are compared against the dependency analysis of sentence to determine whether it contains the pattern.
</nextsent>
<nextsent>each of these approaches relies on pattern model to define which parts of the dependency treecan be used to form the extraction patterns.
</nextsent>
<nextsent>a variety of pattern models have been proposed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD675">
<title id=" W07-1211.xml">a task based comparison of information extraction pattern models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a variety of pattern models have been proposed.
</prevsent>
<prevsent>forex ample the patterns used by yangarber et al (2000)<papid> A00-1039 </papid>are the subject-verb-object tuples from the dependency tree (the remainder of the dependency parse isdiscarded) while sudo et al (2003) <papid> P03-1029 </papid>allow any subtree within the dependency parse to act as an extraction pattern.</prevsent>
</prevsection>
<citsent citstr=" W06-0202 ">
stevenson and greenwood (2006)<papid> W06-0202 </papid>showed that the choice of pattern model has important implications for ie algorithms including significant differences between the various models in terms of their ability to identify information of interest in text.however, there has been little comparison between the various pattern models.</citsent>
<aftsection>
<nextsent>those which have been carried out have been limited by the fact that they used indirect tasks to evaluate the various models and did not compare them in an ie scenario.we address this limitation here by presenting direct comparison of four previously described pattern models using an unsupervised learning method applied to commonly used ie scenario.the remainder of the paper is organised as follows.
</nextsent>
<nextsent>the next section presents four pattern models which have been previously introduced in the litera 81 ture.
</nextsent>
<nextsent>section 3 describes two previous studies which compared these models and their limitations.
</nextsent>
<nextsent>section 4 describes an experiment which compares the four models on an ie task, the results of which are described in section 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD711">
<title id=" W07-1211.xml">a task based comparison of information extraction pattern models </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the rightmost extension algorithm is most suited to finding subtrees which occur multiple times and, even using this efficient approach, we were unable to generate subtrees which occurred fewer than four times in the muc-6 texts in reasonable time.
</prevsent>
<prevsent>similar restrictions have been encountered within other approaches which have relied on the generation ofa comprehensive set of subtrees from parse forest.
</prevsent>
</prevsection>
<citsent citstr=" P05-1024 ">
for example, kudo et al (2005) <papid> P05-1024 </papid>used subtrees for parse ranking but could only generate subtrees which appear at least ten times in 40,000 sentence corpus.</citsent>
<aftsection>
<nextsent>they comment that the size of their dataset meant that it would have been difficult to complete the experiments with less restrictive parameters.
</nextsent>
<nextsent>in addition, sudo et al (2003) <papid> P03-1029 </papid>only generated subtrees which appeared in at least three documents.</nextsent>
<nextsent>kudo et al (2005) <papid> P05-1024 </papid>and sudo et al (2003) <papid> P03-1029 </papid>both used the rightmost extension algorithm to generate subtrees.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD731">
<title id=" W08-0401.xml">imposing constraints from the source tree on itg constraints for smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>approaches used to resolve this problem are categorized into two types.
</prevsent>
<prevsent>the first type is linguistically syntax-based.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
in this approach, source (quirk et al, 2005; <papid> P05-1034 </papid>liu et al, 2006;<papid> P06-1077 </papid>huang et al, 2006), target (yamada et al, 2000; galley et al, 2006; <papid> P06-1121 </papid>marcu et al, 2006), <papid> W06-1606 </papid>or both side (melamed 2004; ding et al, 2005) tree structures are used for model training.</citsent>
<aftsection>
<nextsent>the second type is formal constraints on word permutations.
</nextsent>
<nextsent>ibm constraints (berger et al, 1996), lexical word reordering model (tillmann, 2004), <papid> N04-4026 </papid>and inversion transduction grammar (itg) constraints (wu, 1995; wu, 1997) <papid> J97-3002 </papid>belong to this type of approach.</nextsent>
<nextsent>our approach is an extension of itg constraints and is hybrid of the first and second type of approach.we propose imposing source tree on itg?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD732">
<title id=" W08-0401.xml">imposing constraints from the source tree on itg constraints for smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>approaches used to resolve this problem are categorized into two types.
</prevsent>
<prevsent>the first type is linguistically syntax-based.
</prevsent>
</prevsection>
<citsent citstr=" P06-1077 ">
in this approach, source (quirk et al, 2005; <papid> P05-1034 </papid>liu et al, 2006;<papid> P06-1077 </papid>huang et al, 2006), target (yamada et al, 2000; galley et al, 2006; <papid> P06-1121 </papid>marcu et al, 2006), <papid> W06-1606 </papid>or both side (melamed 2004; ding et al, 2005) tree structures are used for model training.</citsent>
<aftsection>
<nextsent>the second type is formal constraints on word permutations.
</nextsent>
<nextsent>ibm constraints (berger et al, 1996), lexical word reordering model (tillmann, 2004), <papid> N04-4026 </papid>and inversion transduction grammar (itg) constraints (wu, 1995; wu, 1997) <papid> J97-3002 </papid>belong to this type of approach.</nextsent>
<nextsent>our approach is an extension of itg constraints and is hybrid of the first and second type of approach.we propose imposing source tree on itg?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD733">
<title id=" W08-0401.xml">imposing constraints from the source tree on itg constraints for smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>approaches used to resolve this problem are categorized into two types.
</prevsent>
<prevsent>the first type is linguistically syntax-based.
</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
in this approach, source (quirk et al, 2005; <papid> P05-1034 </papid>liu et al, 2006;<papid> P06-1077 </papid>huang et al, 2006), target (yamada et al, 2000; galley et al, 2006; <papid> P06-1121 </papid>marcu et al, 2006), <papid> W06-1606 </papid>or both side (melamed 2004; ding et al, 2005) tree structures are used for model training.</citsent>
<aftsection>
<nextsent>the second type is formal constraints on word permutations.
</nextsent>
<nextsent>ibm constraints (berger et al, 1996), lexical word reordering model (tillmann, 2004), <papid> N04-4026 </papid>and inversion transduction grammar (itg) constraints (wu, 1995; wu, 1997) <papid> J97-3002 </papid>belong to this type of approach.</nextsent>
<nextsent>our approach is an extension of itg constraints and is hybrid of the first and second type of approach.we propose imposing source tree on itg?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD734">
<title id=" W08-0401.xml">imposing constraints from the source tree on itg constraints for smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>approaches used to resolve this problem are categorized into two types.
</prevsent>
<prevsent>the first type is linguistically syntax-based.
</prevsent>
</prevsection>
<citsent citstr=" W06-1606 ">
in this approach, source (quirk et al, 2005; <papid> P05-1034 </papid>liu et al, 2006;<papid> P06-1077 </papid>huang et al, 2006), target (yamada et al, 2000; galley et al, 2006; <papid> P06-1121 </papid>marcu et al, 2006), <papid> W06-1606 </papid>or both side (melamed 2004; ding et al, 2005) tree structures are used for model training.</citsent>
<aftsection>
<nextsent>the second type is formal constraints on word permutations.
</nextsent>
<nextsent>ibm constraints (berger et al, 1996), lexical word reordering model (tillmann, 2004), <papid> N04-4026 </papid>and inversion transduction grammar (itg) constraints (wu, 1995; wu, 1997) <papid> J97-3002 </papid>belong to this type of approach.</nextsent>
<nextsent>our approach is an extension of itg constraints and is hybrid of the first and second type of approach.we propose imposing source tree on itg?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD735">
<title id=" W08-0401.xml">imposing constraints from the source tree on itg constraints for smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this approach, source (quirk et al, 2005; <papid> P05-1034 </papid>liu et al, 2006;<papid> P06-1077 </papid>huang et al, 2006), target (yamada et al, 2000; galley et al, 2006; <papid> P06-1121 </papid>marcu et al, 2006), <papid> W06-1606 </papid>or both side (melamed 2004; ding et al, 2005) tree structures are used for model training.</prevsent>
<prevsent>the second type is formal constraints on word permutations.</prevsent>
</prevsection>
<citsent citstr=" N04-4026 ">
ibm constraints (berger et al, 1996), lexical word reordering model (tillmann, 2004), <papid> N04-4026 </papid>and inversion transduction grammar (itg) constraints (wu, 1995; wu, 1997) <papid> J97-3002 </papid>belong to this type of approach.</citsent>
<aftsection>
<nextsent>our approach is an extension of itg constraints and is hybrid of the first and second type of approach.we propose imposing source tree on itg?
</nextsent>
<nextsent>(istitg) constraints for directly introducing source sentence structure into our set of constraints.
</nextsent>
<nextsent>in istitg, itg constraints under the given source sentence tree structure are used as stronger constraints than the original itg.
</nextsent>
<nextsent>for example, ist-itg allows only eight word orderings for four-word sentence, even though twenty-two word orderings are possible with respect of in the original itg constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD736">
<title id=" W08-0401.xml">imposing constraints from the source tree on itg constraints for smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this approach, source (quirk et al, 2005; <papid> P05-1034 </papid>liu et al, 2006;<papid> P06-1077 </papid>huang et al, 2006), target (yamada et al, 2000; galley et al, 2006; <papid> P06-1121 </papid>marcu et al, 2006), <papid> W06-1606 </papid>or both side (melamed 2004; ding et al, 2005) tree structures are used for model training.</prevsent>
<prevsent>the second type is formal constraints on word permutations.</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
ibm constraints (berger et al, 1996), lexical word reordering model (tillmann, 2004), <papid> N04-4026 </papid>and inversion transduction grammar (itg) constraints (wu, 1995; wu, 1997) <papid> J97-3002 </papid>belong to this type of approach.</citsent>
<aftsection>
<nextsent>our approach is an extension of itg constraints and is hybrid of the first and second type of approach.we propose imposing source tree on itg?
</nextsent>
<nextsent>(istitg) constraints for directly introducing source sentence structure into our set of constraints.
</nextsent>
<nextsent>in istitg, itg constraints under the given source sentence tree structure are used as stronger constraints than the original itg.
</nextsent>
<nextsent>for example, ist-itg allows only eight word orderings for four-word sentence, even though twenty-two word orderings are possible with respect of in the original itg constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD737">
<title id=" W08-0401.xml">imposing constraints from the source tree on itg constraints for smt </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>4
</prevsent>
<prevsent>5.1 evaluation measures.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we evaluated the proposed method using four evaluation measures, bleu (papineni et al, 2002), <papid> P02-1040 </papid>nist (doddington 2002), wer(word error rate),and per(position independent word error rate).</citsent>
<aftsection>
<nextsent>before discussing the evaluation, the characteristics of each one are analyzed.
</nextsent>
<nextsent>bleu: this evaluation measure takes into account middle range word order, but does not take into account global word order.
</nextsent>
<nextsent>when the translation result is[w1, w2, ..., wj1, x,wj+1, ..., wn] for reference translation [w1, w2, ..., wn], both werand bleu scores will be high.
</nextsent>
<nextsent>for translation result [wj+1, ..., wn, x,w1, w2, ..., wj1], the bleu score will be the same as the previous result since bleu only takes into account 4grams.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD738">
<title id=" W08-0401.xml">imposing constraints from the source tree on itg constraints for smt </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for language model training, the sri language model toolkit (stolcke 2002)was used.
</prevsent>
<prevsent>the language model type was word 5 gram smoothed by kneser-ney discounting (kneser1995).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
for tuning of decoder parameters, we conducted minimum error training (och 2003) <papid> P03-1021 </papid>with respect to the bleu score using 916 development sentence pairs.</citsent>
<aftsection>
<nextsent>for extraction of source sentence tree structure, we used the charniak parser (char niak 2000).<papid> A00-2018 </papid></nextsent>
<nextsent>we used chasen for segmentation of the japanese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD739">
<title id=" W08-0401.xml">imposing constraints from the source tree on itg constraints for smt </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the language model type was word 5 gram smoothed by kneser-ney discounting (kneser1995).
</prevsent>
<prevsent>for tuning of decoder parameters, we conducted minimum error training (och 2003) <papid> P03-1021 </papid>with respect to the bleu score using 916 development sentence pairs.</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
for extraction of source sentence tree structure, we used the charniak parser (char niak 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>we used chasen for segmentation of the japanese.
</nextsent>
<nextsent>the numbers of entries in the language models were 0.1 m, 2.1 m, 4.3 m, 6.2 m, and 6.9 for 1, 2, 3, 4, and 5grams respectively.
</nextsent>
<nextsent>the number of entries in the phrase-table was 76 m. for decoding, we used an in-house decoder that is close relative to the moses decoder.
</nextsent>
<nextsent>the performance of this decoder was configured to be the same as moses.another conditions are the same as the default conditions of moses decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD740">
<title id=" W07-2104.xml">uva language modeling techniques for web people search </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our main aim in participating was to adapt language modeling tools for the task, and to experiment with various document representations.
</prevsent>
<prevsent>our main finding is that single pass clustering, using title, snippet and body to represent documents, is the most effective setting.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
the goal of the web people search task at semeval 2007 was to disambiguate person names in web searching scenario (artiles et al, 2007).<papid> W07-2012 </papid></citsent>
<aftsection>
<nextsent>participants were presented with the following setting: given list of documents retrieved from web search engine using persons name as query, group documents that refer to the same individual.our aim with the participation was to adapt language modeling techniques to this task.
</nextsent>
<nextsent>to thisend, we employed two methods: single pass clustering (spc) and probabilistic latent semantic analysis (plsa).
</nextsent>
<nextsent>our main finding is that the former leads tohigh purity, while the latter leads to high inverse purity scores.
</nextsent>
<nextsent>furthermore, we experimented with various document representations, based on the snippets and body text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD741">
<title id=" W07-1707.xml">unsupervised methods of topical text segmentation for polish </title>
<section> approaches to topical segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>out of empirical statistical rules some authors make use of heuristics resulting form heaps?
</prevsent>
<prevsent>law fornew-words-based topical segment boundary detection.
</prevsent>
</prevsection>
<citsent citstr=" W97-0304 ">
however, the most important theoretical foundations in quantitative methods are related to strong probabilistic frameworks including hidden markov models (mulbregt et al, 1998) and maximal entropy theory (beeferman et al, 1997).<papid> W97-0304 </papid></citsent>
<aftsection>
<nextsent>2.2 basic methods.
</nextsent>
<nextsent>the most simple but also the most frequently used methods of topical text segmentation do notre quire training (thus they are domain-independent) nor make use of any complex linguistic resources orutilities.
</nextsent>
<nextsent>apart from methods based on new vocabulary analysis, this category of algorithms applies widely the simplest form of lexical cohesion i.e. re iterations of the same word.
</nextsent>
<nextsent>52 the first classical text segmentation algorithm of this type is text tiling described in (hearst andplaunt, 1993).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD742">
<title id=" W07-1707.xml">unsupervised methods of topical text segmentation for polish </title>
<section> approaches to topical segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>at any position the window is decomposed into two six-pseudo-sentences blocks and their similarity is calculated by means of cosine measure.
</prevsent>
<prevsent>measurements for all consecutive window positions (understood as positions of centre of the window) form lexical cohesion curve local minima of which correspond to segments boundaries.
</prevsent>
</prevsection>
<citsent citstr=" P99-1077 ">
the original algorithm was further enhanced in several ways including use of words similarity measurement based on co-occurrences (kaufmann, 1999).<papid> P99-1077 </papid></citsent>
<aftsection>
<nextsent>another group of basic algorithms makes use of technique of dot plotting, originally proposed by raynar in (reynar, 1994).<papid> P94-1050 </papid></nextsent>
<nextsent>in this approach 2d chart is used for lexical cohesion analysis with both axes corresponding to positions (in words) in the text; on the chart points are drawn at coordinates (x, y) and (y, x) iff words at positions and are equal.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD743">
<title id=" W07-1707.xml">unsupervised methods of topical text segmentation for polish </title>
<section> approaches to topical segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>measurements for all consecutive window positions (understood as positions of centre of the window) form lexical cohesion curve local minima of which correspond to segments boundaries.
</prevsent>
<prevsent>the original algorithm was further enhanced in several ways including use of words similarity measurement based on co-occurrences (kaufmann, 1999).<papid> P99-1077 </papid></prevsent>
</prevsection>
<citsent citstr=" P94-1050 ">
another group of basic algorithms makes use of technique of dot plotting, originally proposed by raynar in (reynar, 1994).<papid> P94-1050 </papid></citsent>
<aftsection>
<nextsent>in this approach 2d chart is used for lexical cohesion analysis with both axes corresponding to positions (in words) in the text; on the chart points are drawn at coordinates (x, y) and (y, x) iff words at positions and are equal.
</nextsent>
<nextsent>in this settings coherent text segments correspond visually to squares with high density of points.
</nextsent>
<nextsent>dotplottingimage is than segmented using one of two strategies: minimization of points density at the boundaries (minimization of external incoherence) or maximization of density of segments (maximization of internal coherence) (reynar, 1998).
</nextsent>
<nextsent>the original dot plotting algorithm requires to explicitly provide expected number of segments as input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD744">
<title id=" W07-1707.xml">unsupervised methods of topical text segmentation for polish </title>
<section> approaches to topical segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>dotplottingimage is than segmented using one of two strategies: minimization of points density at the boundaries (minimization of external incoherence) or maximization of density of segments (maximization of internal coherence) (reynar, 1998).
</prevsent>
<prevsent>the original dot plotting algorithm requires to explicitly provide expected number of segments as input.
</prevsent>
</prevsection>
<citsent citstr=" A00-2004 ">
improved version of dot plotting algorithm calledc99 (choi, 2000) <papid> A00-2004 </papid>uses dot plotting chart for visualization of similarity measurements at consecutive point of the text (thus resulting in point with different levels of intensity) instead of words cooccurences.</citsent>
<aftsection>
<nextsent>afterwards, mask-based ranking technique is used for image enhancement.
</nextsent>
<nextsent>for actual segmentation, dynamic programming technique similar to dot plotting maximization algorithm is used; an optional automatic termination strategy isalso implemented thus allowing the algorithm to assess number of boundaries.
</nextsent>
<nextsent>in further work of the same and other authors several enhancements of c99 algorithm were proposed.
</nextsent>
<nextsent>2.3 methods requiring external resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD746">
<title id=" W07-1707.xml">unsupervised methods of topical text segmentation for polish </title>
<section> approaches to topical segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 methods requiring external resources.
</prevsent>
<prevsent>still not requiring training and domain independent, some methods make use of linguistic resources more sophisticated than stop-list.
</prevsent>
</prevsection>
<citsent citstr=" J91-1002 ">
two classes of such solution described in existing work are solutions using lexical chains (morris and hirst, 1991; <papid> J91-1002 </papid>minyen kan, 1998) (which require to use some the saurus) and based on spreading activation (kozima, 1993) (<papid> P93-1041 </papid>which depend on weights-based semantic network constructed from thesaurus).</citsent>
<aftsection>
<nextsent>in both cases the effort put in algorithm enactment is quite high; however in principle no additional resources need tobe developed for new texts (even from different do mains).
</nextsent>
<nextsent>2.4 methods requiring training.
</nextsent>
<nextsent>last group of methods includes supervised methods with generally strong mathematical foundations.they perform very well; however they require training that possibly needs to be repeated when new domain needs to be addressed.
</nextsent>
<nextsent>the methods in this group use probabilistic frameworks including maximal entropy (beeferman et al, 1997), <papid> W97-0304 </papid>hidden markov models (mulbregt et al, 1998) and probabilistic latent semantic analysis (blei and moreno, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD747">
<title id=" W07-1707.xml">unsupervised methods of topical text segmentation for polish </title>
<section> approaches to topical segmentation.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 methods requiring external resources.
</prevsent>
<prevsent>still not requiring training and domain independent, some methods make use of linguistic resources more sophisticated than stop-list.
</prevsent>
</prevsection>
<citsent citstr=" P93-1041 ">
two classes of such solution described in existing work are solutions using lexical chains (morris and hirst, 1991; <papid> J91-1002 </papid>minyen kan, 1998) (which require to use some the saurus) and based on spreading activation (kozima, 1993) (<papid> P93-1041 </papid>which depend on weights-based semantic network constructed from thesaurus).</citsent>
<aftsection>
<nextsent>in both cases the effort put in algorithm enactment is quite high; however in principle no additional resources need tobe developed for new texts (even from different do mains).
</nextsent>
<nextsent>2.4 methods requiring training.
</nextsent>
<nextsent>last group of methods includes supervised methods with generally strong mathematical foundations.they perform very well; however they require training that possibly needs to be repeated when new domain needs to be addressed.
</nextsent>
<nextsent>the methods in this group use probabilistic frameworks including maximal entropy (beeferman et al, 1997), <papid> W97-0304 </papid>hidden markov models (mulbregt et al, 1998) and probabilistic latent semantic analysis (blei and moreno, 2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD751">
<title id=" W07-1707.xml">unsupervised methods of topical text segmentation for polish </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>manual tagging by two authors of this paper was performed.
</prevsent>
<prevsent>the instructions wereto put segment boundaries in the places of potential section titles.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
obtained percent agreement of 0.988 and ? coefficient (carletta, 1996) <papid> J96-2004 </papid>of 0.975suggest high convergence of both annotations.</citsent>
<aftsection>
<nextsent>further, in places where the two annotators opinions differed (one marked boundary and the other did not),negotiation-based approach (flejter, 2006) was applied in order to develop reference segmentation.
</nextsent>
<nextsent>3.2 selected algorithms.
</nextsent>
<nextsent>in our experiment we used chois publicly available implementation of several text segmentation algorithms not requiring training (with several adapta sentences tokens avg std avg std ac 6.8 1.7 122.6 33.4 sc 15.0 3.8 267.6 64.0 dc 28.5 9.9 300.0 110.2 table 2: the average length of reference segments tion concerning pre-processing stages).
</nextsent>
<nextsent>specifically we used chois implementation of text tiling algorithm (tt ), c99 algorithm for both known (c99l) and unknown (c99) number of boundaries as wellas dot plotting maximization (dp ) and minimization (dpmin) algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD752">
<title id=" W07-1707.xml">unsupervised methods of topical text segmentation for polish </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the stop-lists (inflected and lemmatized versions contained 616 and 350 tokens respectively) were prepared manually by analysing frequency lists of previously used text corpus.
</prevsent>
<prevsent>3.4 evaluation metrics.
</prevsent>
</prevsection>
<citsent citstr=" J97-1005 ">
a number of different measurement methods were applied to topical texts segmentation includingrecall-precision pair (hearst and plaunt, 1993; passonneau and litman, 1997), <papid> J97-1005 </papid>edit distance (ponte and croft, 1997), p?</citsent>
<aftsection>
<nextsent>(beeferman et al, 1997), <papid> W97-0304 </papid>pk (beeferman et al, 1999) and window diff (pevzner and hearst, 2002).<papid> J02-1002 </papid></nextsent>
<nextsent>pk is simplified version of probabilistic measure p?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD755">
<title id=" W07-1707.xml">unsupervised methods of topical text segmentation for polish </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>3.4 evaluation metrics.
</prevsent>
<prevsent>a number of different measurement methods were applied to topical texts segmentation includingrecall-precision pair (hearst and plaunt, 1993; passonneau and litman, 1997), <papid> J97-1005 </papid>edit distance (ponte and croft, 1997), p?</prevsent>
</prevsection>
<citsent citstr=" J02-1002 ">
(beeferman et al, 1997), <papid> W97-0304 </papid>pk (beeferman et al, 1999) and window diff (pevzner and hearst, 2002).<papid> J02-1002 </papid></citsent>
<aftsection>
<nextsent>pk is simplified version of probabilistic measure p?
</nextsent>
<nextsent>based on assumption that any two consecutive boundaries are at distance of sentences (k being parameter normally set to half of length of average segment in reference segmentation).
</nextsent>
<nextsent>after some simplifications pk is defined by the following formula (flejter, 2006): pk(r, h) = 1 ? 1 n?
</nextsent>
<nextsent>k nk? i=1 (|r(i, k) ? h(i, k)|) where x(i, k) equals to one if ith and (i + k)th sentences are in the same segment of segmentation , otherwise it is equal to zero; = corresponds to reference segmentation and = corresponds to hypothetical (algorithm-generated) segmentation.in most publication instead of performance measurement using pk, probabilistic error metric (p = 1 ? pk(r, h)) is applied.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD758">
<title id=" W07-1313.xml">emergence of community structures in vowel inventories an analysis based on complex networks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we observe that in the assortative vowel communities the constituent nodes (read vowels) are largely un correlated in terms of their features indicating that they are formed basedon the principle of maximal perceptual contrast.
</prevsent>
<prevsent>however, in the rest of the communities, strong correlations are reflected among the constituent vowels with respect to their features indicating that it is the principle of feature economy that binds them together.
</prevsent>
</prevsection>
<citsent citstr=" P06-2017 ">
linguistic research has documented wide range of regularities across the sound systems of the worlds languages (liljencrants and lind blom, 1972; lind blom, 1986; de boer, 2000; choudhury et al, 2006; <papid> P06-2017 </papid>mukherjee et al, 2006a; mukherjee et al, 2006b).functional phonologists argue that such regularities are the consequences of certain general principles like maximal perceptual contrast (liljencrants and lind blom, 1972), which is desirable between the phonemes of language for proper perception of each individual phoneme in noisy environment, ease of articulation (lindblom and mad dieson, 1988; de boer, 2000), which requires that the sound systems of all languages are formed of certain universal (and highly frequent) sounds, andease of learn ability (de boer, 2000), which is required so that speaker can learn the sounds of language with minimum effort.</citsent>
<aftsection>
<nextsent>in the study of vowel systems the optimizing principle, which has long tradition (jakobson, 1941; wang, 1968) in linguistics, is maximal perceptual contrast.
</nextsent>
<nextsent>a number of numerical studies based on this principle have been reported in literature (liljencrants and lind blom, 1972; lind blom, 1986; schwartz et al, 1997).
</nextsent>
<nextsent>of late, there have been some attempts to explain the vowel systems through multi agent simulations (de boer, 2000) and genetic algorithms (ke et al, 2003);<papid> J03-1001 </papid>all of these experiments also use the principle of perceptual contrast for optimization purposes.</nextsent>
<nextsent>an exception to the above trend is school of linguists (boersma, 1998; clements, 2004) who argue that perceptual contrast-based theories fail to account for certain fundamental aspects such as the patterns of co-occurrence of vowels based on similar acoustic/articulatory features1 observed across 1in linguistics, features are the elements, which distinguish one phoneme from another.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD760">
<title id=" W07-1313.xml">emergence of community structures in vowel inventories an analysis based on complex networks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the study of vowel systems the optimizing principle, which has long tradition (jakobson, 1941; wang, 1968) in linguistics, is maximal perceptual contrast.
</prevsent>
<prevsent>a number of numerical studies based on this principle have been reported in literature (liljencrants and lind blom, 1972; lind blom, 1986; schwartz et al, 1997).
</prevsent>
</prevsection>
<citsent citstr=" J03-1001 ">
of late, there have been some attempts to explain the vowel systems through multi agent simulations (de boer, 2000) and genetic algorithms (ke et al, 2003);<papid> J03-1001 </papid>all of these experiments also use the principle of perceptual contrast for optimization purposes.</citsent>
<aftsection>
<nextsent>an exception to the above trend is school of linguists (boersma, 1998; clements, 2004) who argue that perceptual contrast-based theories fail to account for certain fundamental aspects such as the patterns of co-occurrence of vowels based on similar acoustic/articulatory features1 observed across 1in linguistics, features are the elements, which distinguish one phoneme from another.
</nextsent>
<nextsent>the features that describe the vowles can be broadly categorized into three different classes namely the height, the back ness and the roundedness.
</nextsent>
<nextsent>height refers to the vertical position of the tongue relative to either the roof of the mouth or the aperture of the jaw.
</nextsent>
<nextsent>back ness refers to the horizontal tongue position during the articulation of vowel relative to the back of the mouth.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD763">
<title id=" W08-0804.xml">small statistical models by random feature mixing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we emphasize that even when using an extremely large feature space to avoid collisions, alphabet storage is eliminated.
</prevsent>
<prevsent>for the experiments in this paper we use javas hashcodefunction modulo the intended size rather than random function.
</prevsent>
</prevsection>
<citsent citstr=" P07-1056 ">
we evaluated the effect of random feature mixing on four popular learning methods: perceptron, mira (crammer et al, 2006), svm and maximum entropy; with 4 nlp datasets: 20 newsgroups1, reuters (lewis et al, 2004), sentiment (blitzer et al, 2007) <papid> P07-1056 </papid>and spam (bickel, 2006).</citsent>
<aftsection>
<nextsent>for each dataset we extracted binary unigram features and sentiment was prepared according to blitzer et al (2007).<papid> P07-1056 </papid></nextsent>
<nextsent>from 20 news groups we created 3 binary decision tasks to differentiate between two similar 1 http://people.csail.mit.edu/jrennie/20newsgroups/ 19 70 75 80 85 90 0 10 2 0 30 40 50 60 70 80 9 0 thousands of features feature mixing no feature ixing 70 75 80 85 90 0 10 2 0 30 40 50 60 70 80 9 0 thousands of features feature mixing no feature ixingfigure 1: kitchen appliance reviews.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD765">
<title id=" W07-2072.xml">uazbsa a headline emotion classification through web information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our approach is based on the hypothesis that group of words which co-occur together across many documents with given emotion are highly probable to express the same emotion.
</prevsent>
<prevsent>the subjective analysis of text is becoming important for many natural language processing (nlp)applications such as question answering, information extraction, text categorization among others(shanahan et al, 2006).
</prevsent>
</prevsection>
<citsent citstr=" W05-0308 ">
the resolution of this problem can lead to complete, realistic and coherent analysis of the natural language, therefore major attention is drawn to the opinion, sentiment an demotion analysis, and to the identification of beliefs, thoughts, feelings and judgments (quirk et al, 1985), (wilson and wiebe, 2005).<papid> W05-0308 </papid>the aim of the affective text task is to classify set of news headlines into six types of emo tions: anger?, disgust?, fear?, joy?, sadness?</citsent>
<aftsection>
<nextsent>and surprise?.
</nextsent>
<nextsent>in order to be able to conduct such multi-category analysis, we believe that first we need comprehensive theory of what human emotion is, and then we need to understand how the emotion is expressed and transmitted within the natural language.
</nextsent>
<nextsent>these aspects rise the need of syntactic, semantic, textual and pragmatic analysis of text (polanyi and zaenen, 2006).
</nextsent>
<nextsent>however, some of the major drawbacks in this field are related tothe manual or automatic acquisition of subjective expressions, as well as to the lack of resources in terms of coverage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD766">
<title id=" W07-2072.xml">uazbsa a headline emotion classification through web information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in section 2 we review some of the related work, in section 3 we describe our web-based emotion classification approach for which we show walk-through example in section 4.
</prevsent>
<prevsent>a discussion of the obtained results can be found in section 5 and finally we conclude in section 6.
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
our approach for emotion classification is based on the idea of (hatzivassiloglou and mckeown, 1997)<papid> P97-1023 </papid>and is similar to those of (turney, 2002) <papid> P02-1053 </papid>and (turney and littman, 2003).</citsent>
<aftsection>
<nextsent>according to hatzivassiloglou and mckeown (1997), <papid> P97-1023 </papid>adjectives with thesame polarity tended to appear together.</nextsent>
<nextsent>for example the negative adjectives corrupt and brutal?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD767">
<title id=" W07-2072.xml">uazbsa a headline emotion classification through web information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in section 2 we review some of the related work, in section 3 we describe our web-based emotion classification approach for which we show walk-through example in section 4.
</prevsent>
<prevsent>a discussion of the obtained results can be found in section 5 and finally we conclude in section 6.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
our approach for emotion classification is based on the idea of (hatzivassiloglou and mckeown, 1997)<papid> P97-1023 </papid>and is similar to those of (turney, 2002) <papid> P02-1053 </papid>and (turney and littman, 2003).</citsent>
<aftsection>
<nextsent>according to hatzivassiloglou and mckeown (1997), <papid> P97-1023 </papid>adjectives with thesame polarity tended to appear together.</nextsent>
<nextsent>for example the negative adjectives corrupt and brutal?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD820">
<title id=" W07-2072.xml">uazbsa a headline emotion classification through web information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there are other emotion classification approaches that use the web as source of information.
</prevsent>
<prevsent>for instance, (taboada et al, 2006) extracted from the web co-occurrences of adverbs, adjectives, nouns and verbs.
</prevsent>
</prevsection>
<citsent citstr=" W05-0408 ">
gamon and aue (2005) <papid> W05-0408 </papid>were looking for adjectives that did not co-occur at sentence level.</citsent>
<aftsection>
<nextsent>(baroni and vegnaduzzo, 2004) and (grefenstette et al, 2004) gathered subjective adjectives from the web calculating the mutual information score.
</nextsent>
<nextsent>other important works on sentiment analysis are those of (wilson et al, 2005) <papid> H05-1044 </papid>and (wiebe et al, 2005; wilson and wiebe, 2005), <papid> W05-0308 </papid>who used linguistic information such as syntax and neg ations to determine polarity.</nextsent>
<nextsent>kim and hovy (2006) <papid> W06-0301 </papid>integrated verb information from framenet and incorporated it into semantic role labeling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD821">
<title id=" W07-2072.xml">uazbsa a headline emotion classification through web information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>gamon and aue (2005) <papid> W05-0408 </papid>were looking for adjectives that did not co-occur at sentence level.</prevsent>
<prevsent>(baroni and vegnaduzzo, 2004) and (grefenstette et al, 2004) gathered subjective adjectives from the web calculating the mutual information score.</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
other important works on sentiment analysis are those of (wilson et al, 2005) <papid> H05-1044 </papid>and (wiebe et al, 2005; wilson and wiebe, 2005), <papid> W05-0308 </papid>who used linguistic information such as syntax and neg ations to determine polarity.</citsent>
<aftsection>
<nextsent>kim and hovy (2006) <papid> W06-0301 </papid>integrated verb information from framenet and incorporated it into semantic role labeling.</nextsent>
<nextsent>in order to determine the emotions of ahead line, we measure the pointwise mutual information (mi) of ei and cwj as mi(ei, cwj) = log2 hits(ei,cwj)hits(ei)hits(cwj) , where ei ? {anger, disgust, fear, joy, sadness, surprise} and cwj are the content words of the headline j. for each headline, we have six mi scores which indicate the presence of the emotion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD823">
<title id=" W07-2072.xml">uazbsa a headline emotion classification through web information </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(baroni and vegnaduzzo, 2004) and (grefenstette et al, 2004) gathered subjective adjectives from the web calculating the mutual information score.
</prevsent>
<prevsent>other important works on sentiment analysis are those of (wilson et al, 2005) <papid> H05-1044 </papid>and (wiebe et al, 2005; wilson and wiebe, 2005), <papid> W05-0308 </papid>who used linguistic information such as syntax and neg ations to determine polarity.</prevsent>
</prevsection>
<citsent citstr=" W06-0301 ">
kim and hovy (2006) <papid> W06-0301 </papid>integrated verb information from framenet and incorporated it into semantic role labeling.</citsent>
<aftsection>
<nextsent>in order to determine the emotions of ahead line, we measure the pointwise mutual information (mi) of ei and cwj as mi(ei, cwj) = log2 hits(ei,cwj)hits(ei)hits(cwj) , where ei ? {anger, disgust, fear, joy, sadness, surprise} and cwj are the content words of the headline j. for each headline, we have six mi scores which indicate the presence of the emotion.
</nextsent>
<nextsent>mi is used in our experiments because it provides information about the independence of an emotion and bag of words.
</nextsent>
<nextsent>to collect the frequency and co-occurrence counts of the headline words, we need large and massive 335 data repositories.
</nextsent>
<nextsent>to surmount the data sparsity problem, we used as corpus the world wide web which is constantly growing and daily updated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD825">
<title id=" W07-2210.xml">nbest dependency parsing with linguistically rich models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the course of left-to-right parsing, when further context is seen, the previous decisions may be wrong but deterministic parser cannot correct it.
</prevsent>
<prevsent>the usual way of preventing early error commitment?
</prevsent>
</prevsection>
<citsent citstr=" W05-1506 ">
is to enable k-best or beam-search strategy (huang and chiang 2005, <papid> W05-1506 </papid>sagae and lavie 2006).<papid> P06-2089 </papid></citsent>
<aftsection>
<nextsent>(2) classifier based approach (e.g. using svm or memory based learning) is usually linguistically nave, to make it applicable to multiple languages.
</nextsent>
<nextsent>however, few studies (collins 1999, charniak et al  2003, galley et al 2006) <papid> P06-1121 </papid>have shown that linguistically sophisticated models can have better accuracy at parsing, language modeling, and machine translation, among others.</nextsent>
<nextsent>in this paper we explore ways to improve on the above-mentioned deterministic parsing model to overcome the two problems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD827">
<title id=" W07-2210.xml">nbest dependency parsing with linguistically rich models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the course of left-to-right parsing, when further context is seen, the previous decisions may be wrong but deterministic parser cannot correct it.
</prevsent>
<prevsent>the usual way of preventing early error commitment?
</prevsent>
</prevsection>
<citsent citstr=" P06-2089 ">
is to enable k-best or beam-search strategy (huang and chiang 2005, <papid> W05-1506 </papid>sagae and lavie 2006).<papid> P06-2089 </papid></citsent>
<aftsection>
<nextsent>(2) classifier based approach (e.g. using svm or memory based learning) is usually linguistically nave, to make it applicable to multiple languages.
</nextsent>
<nextsent>however, few studies (collins 1999, charniak et al  2003, galley et al 2006) <papid> P06-1121 </papid>have shown that linguistically sophisticated models can have better accuracy at parsing, language modeling, and machine translation, among others.</nextsent>
<nextsent>in this paper we explore ways to improve on the above-mentioned deterministic parsing model to overcome the two problems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD828">
<title id=" W07-2210.xml">nbest dependency parsing with linguistically rich models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is to enable k-best or beam-search strategy (huang and chiang 2005, <papid> W05-1506 </papid>sagae and lavie 2006).<papid> P06-2089 </papid></prevsent>
<prevsent>(2) classifier based approach (e.g. using svm or memory based learning) is usually linguistically nave, to make it applicable to multiple languages.</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
however, few studies (collins 1999, charniak et al  2003, galley et al 2006) <papid> P06-1121 </papid>have shown that linguistically sophisticated models can have better accuracy at parsing, language modeling, and machine translation, among others.</citsent>
<aftsection>
<nextsent>in this paper we explore ways to improve on the above-mentioned deterministic parsing model to overcome the two problems.
</nextsent>
<nextsent>the rest of the paper is organized as follows.
</nextsent>
<nextsent>section 2 argues for search strategy better at finding the optimal solution.
</nextsent>
<nextsent>in section 3 we built series of linguistically richer models and show experimental results demonstrating their practical consequences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD832">
<title id=" W07-1022.xml">basenps that contain gene names domain specificity and genericity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also report an inter-annotator agreement score of 98.8 kappa on the task of basenp annotation of new dataset.
</prevsent>
<prevsent>base noun phrases (basenps), broadly the initial portions of non-recursive noun phrases up to the head?
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
(ramshaw and marcus, 1995), <papid> W95-0107 </papid>are valuable pieces of linguistic structure which minimally extend beyond the scope of named entities.</citsent>
<aftsection>
<nextsent>in this paper, we explore the integration of different techniques for detecting basenps that contain named entity, using domain-trained named entity recognition (ner) system but in combination with other linguistic components that are general purpose?.
</nextsent>
<nextsent>the rationale is simply that domain-trained ner is clearly necessity for the task; but one might expect to be able to secure good coverage at the higher syntactic level by intelligent integration of general purpose syntactic processing without having to undergo further round of domain specific annotation andtraining.
</nextsent>
<nextsent>we present number of experiments exploring different ways of integrating ner into general purpose linguistic processing.
</nextsent>
<nextsent>of course, good results can also be used subsequently to help reduce the effort required in data annotation for use in dedicated domain-specific machine learning systems for basenp detection.first, however, we motivate the task itself.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD833">
<title id=" W07-1022.xml">basenps that contain gene names domain specificity and genericity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this often enables them to predict the possible relevance of the name occurrence to the cur ation task and thus begin ordering their exploration of the paper.
</prevsent>
<prevsent>consequently,our technical goal of basenp detection is linked directly to valuable application task.
</prevsent>
</prevsection>
<citsent citstr=" W06-3316 ">
we also use the basenp identification in order to type the occurrence semantically and use this information in an anaphora resolution process (gasperin, 2006).<papid> W06-3316 </papid></citsent>
<aftsection>
<nextsent>the detection of basenps that contain named entity is super-task of ner, as well as sub-task of np-chunking.
</nextsent>
<nextsent>given that ner is clearly domain specific task, it is an interesting question what performance levels are achievable using domain trained ner in combination with general purpose linguistic processing modules.there is further motivation for the task.
</nextsent>
<nextsent>the distinction between named entity and an embedding noun phrase is one with critical importance even for the sub-task of ner.
</nextsent>
<nextsent>dingare et al(2005) conclude,from their analysis of multi-feature maximum entropy ner module, that increases in performance of biomedical ner systems will depend as much upon qualitative improvements in annotated data as in the technology underlying the systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD835">
<title id=" W07-1022.xml">basenps that contain gene names domain specificity and genericity </title>
<section> scope of the data.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1 contains an example screenshot.
</prevsent>
<prevsent>complex nominals have long been held to be common feature in scientific text.
</prevsent>
</prevsection>
<citsent citstr=" W06-3328 ">
the corpus of vlachos and gasperin (2006) <papid> W06-3328 </papid>contains 80 abstracts (600 sen tences) annotated with gene names.</citsent>
<aftsection>
<nextsent>in this data-set, noun phrases that contain gene names (excluding post-modifiers) of 3 words or more comprise more than 40% of the data and exhibit primarily: strings of premodifiers tudor mutant females, zygotic dnop5 expression; genitives: robo cytoplasmic domain,the rdgb protein amino terminal 281 residues; coordination the copia and mdg-1 elements and parenthetical apposition the female-specic gene sex lethal ( sxl ), and the suur (suppressor of underreplication) gene.
</nextsent>
<nextsent>only 41% of the basenps containing gene name consist of one token only.
</nextsent>
<nextsent>16% have two tokens.
</nextsent>
<nextsent>the two token basenps include large numbers of combinations of gene names with more general words such as ras activity, vnd mutants, xiro expression, iap localization and vasaprotein.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD848">
<title id=" W07-1022.xml">basenps that contain gene names domain specificity and genericity </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>in principle, each token is examined; in practice variable number is examined.
</prevsent>
<prevsent>if we count all tokens classified into nps plus one token of context either side, then both annotators annotated over 930 tokens.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
2http://www.gate.ac.uk 3http://nlp.stanford.edu/software/tagger.shtml 166we adopted similar strategy with the domain independent full parsing system rasp (briscoe et al, 2006).<papid> P06-4020 </papid></citsent>
<aftsection>
<nextsent>rasp includes simple 1st order hmm pos tagger using 149 of the claws-2 tagset.
</nextsent>
<nextsent>the tagger is trained on the manually corrected subsets of the (general english) susanne, lob and bnc corpora.the output of the tagger is distribution of possible tags per token (all tags that are at least 1/50 as probable as the top tag; but only the top tag if more than 90% probable).
</nextsent>
<nextsent>the tagger also includes an unknown word handling module for guessing the possible tags of unknown words.
</nextsent>
<nextsent>the rasp parser is probabilistic lalr(1) parser over the claws-2tags, or, more precisely, unification grammar formalism whose lexical categories are feature based descriptions of those tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD854">
<title id=" W07-1022.xml">basenps that contain gene names domain specificity and genericity </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>vlachos and gasperin (2006) <papid> W06-3328 </papid>claim that their name versus mention distinction was helpful in understanding disagreements over gene name extents and this led, through greater clarity of intended coverage, to improved ner.</prevsent>
<prevsent>basenp detectors have also been used more directly in building ner systems.</prevsent>
</prevsection>
<citsent citstr=" W03-1309 ">
yamamoto et al(2003) <papid> W03-1309 </papid>describe an svm approach to protein name recognition, one of whose features isthe output of basenp recognizer.</citsent>
<aftsection>
<nextsent>basenp recognition supplies top-down constraint for the search for protein names within basenp.
</nextsent>
<nextsent>a similar approach albeit in crf framework is described in song et al.
</nextsent>
<nextsent>(2005).
</nextsent>
<nextsent>the concept of basenp has undergone number of revisions (ramshaw and marcus, 1995; <papid> W95-0107 </papid>tjong kim sang and buchholz, 2000) but has previously always been tied to extraction from more completely annotated treebank, whose annotations are subject to other pressures than just initial material up to the head?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD856">
<title id=" W08-0313.xml">first steps towards a general purpose french english statistical machine translation system </title>
<section> architecture of the system.  </section>
<citcontext>
<prevsection>
<prevsent>in the final version, these systems will not only be trained on all available mono- and bilingual data, but also will include additional resources from systran like high quality dictionaries, named entity transliteration and rule-based translation of expressions like numbers and dates.our ultimate goal is to combine the power of data driven approaches and the concentrated knowledge present in rbmt resources.
</prevsent>
<prevsent>in this paper, we describe an initial version of an french/english system and analyze its performance on the test corpora of the wmt08 workshop.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the goal of statistical machine translation (smt) isto produce target sentence from source sentence . it is today common practice to use phrases as translation units (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2003) <papid> J03-1002 </papid>and loglinear framework in order to introduce several models explaining the translation process: e?</citsent>
<aftsection>
<nextsent>= arg max p(e|f) = arg max {exp( ? ihi(e, f))} (1) the feature functions hi are the system models and the weights are typically optimized to maximize scoring function on development set (och andney, 2002).<papid> P02-1038 </papid></nextsent>
<nextsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD857">
<title id=" W08-0313.xml">first steps towards a general purpose french english statistical machine translation system </title>
<section> architecture of the system.  </section>
<citcontext>
<prevsection>
<prevsent>in the final version, these systems will not only be trained on all available mono- and bilingual data, but also will include additional resources from systran like high quality dictionaries, named entity transliteration and rule-based translation of expressions like numbers and dates.our ultimate goal is to combine the power of data driven approaches and the concentrated knowledge present in rbmt resources.
</prevsent>
<prevsent>in this paper, we describe an initial version of an french/english system and analyze its performance on the test corpora of the wmt08 workshop.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the goal of statistical machine translation (smt) isto produce target sentence from source sentence . it is today common practice to use phrases as translation units (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2003) <papid> J03-1002 </papid>and loglinear framework in order to introduce several models explaining the translation process: e?</citsent>
<aftsection>
<nextsent>= arg max p(e|f) = arg max {exp( ? ihi(e, f))} (1) the feature functions hi are the system models and the weights are typically optimized to maximize scoring function on development set (och andney, 2002).<papid> P02-1038 </papid></nextsent>
<nextsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD858">
<title id=" W08-0313.xml">first steps towards a general purpose french english statistical machine translation system </title>
<section> architecture of the system.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we describe an initial version of an french/english system and analyze its performance on the test corpora of the wmt08 workshop.
</prevsent>
<prevsent>the goal of statistical machine translation (smt) isto produce target sentence from source sentence . it is today common practice to use phrases as translation units (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2003) <papid> J03-1002 </papid>and loglinear framework in order to introduce several models explaining the translation process: e?</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
= arg max p(e|f) = arg max {exp( ? ihi(e, f))} (1) the feature functions hi are the system models and the weights are typically optimized to maximize scoring function on development set (och andney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).
</nextsent>
<nextsent>the system is based on the moses smt toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and constructed as follows.</nextsent>
<nextsent>119 first, giza++ is used to perform word alignment sin both directions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD859">
<title id=" W08-0313.xml">first steps towards a general purpose french english statistical machine translation system </title>
<section> architecture of the system.  </section>
<citcontext>
<prevsection>
<prevsent>= arg max p(e|f) = arg max {exp( ? ihi(e, f))} (1) the feature functions hi are the system models and the weights are typically optimized to maximize scoring function on development set (och andney, 2002).<papid> P02-1038 </papid></prevsent>
<prevsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the system is based on the moses smt toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and constructed as follows.</citsent>
<aftsection>
<nextsent>119 first, giza++ is used to perform word alignment sin both directions.
</nextsent>
<nextsent>second, phrases and lexical reorderings are extracted using the default settings of the moses smt toolkit.
</nextsent>
<nextsent>a 4-gram target lm is then constructed as detailed in section 2.2.
</nextsent>
<nextsent>the translation itself is performed in two passes: first, moses is run and 1000-best list is generated for each sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD860">
<title id=" W08-0313.xml">first steps towards a general purpose french english statistical machine translation system </title>
<section> architecture of the system.  </section>
<citcontext>
<prevsection>
<prevsent>these 1000-best lists are then rescored with continuous space 5-gram lm and the weights of the feature functions are optimized again using the numerical optimization toolkit condor (berghen and bersini, 2005).
</prevsent>
<prevsent>note that this step operates only on the 1000-best lists, no re-decoding is performed.
</prevsent>
</prevsection>
<citsent citstr=" W07-0725 ">
this basic architecture of the system is identical to the one used in the 2007 wmt evaluation(schwenk, 2007<papid> W07-0725 </papid>a).</citsent>
<aftsection>
<nextsent>2.1 translation model.
</nextsent>
<nextsent>in the framework of the 2008 wmt shared task, two parallel corpora were provided: the europarl corpus (about 33m words) and the news commentary corpus (about 1.2m words).
</nextsent>
<nextsent>it is known that the minutes of the debates of the european parliament use particular jargon and these texts alone do not seem to be the appropriate to build french/english smt system for other texts.
</nextsent>
<nextsent>themore general news-commentary corpus is unfortunately rather small in size.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD864">
<title id=" W08-0329.xml">incremental hypothesis alignment for building confusion networks with application to machine translation system combination </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>confusion network decoding has been applied in combining outputs from multiple machine translation systems.
</prevsent>
<prevsent>the earliest approach in (bangalore et al, 2001) used edit distance based multiple string alignment (msa) (durbin et al, 1988) to build the confusion networks.
</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
the recent approaches used pair-wise alignment algorithms based on symmetric alignments from hmm alignment model (matusov et al, 2006) <papid> E06-1005 </papid>or edit distance alignments allowing shifts (rosti et al, 2007).<papid> P07-1040 </papid></citsent>
<aftsection>
<nextsent>the alignment method described in this paper extends the latter by incrementally aligning the hypotheses as in msa but also allowing shifts as in the ter alignment.the confusion networks are built around skele ton?
</nextsent>
<nextsent>hypothesis.
</nextsent>
<nextsent>the skeleton hypothesis defines the word order of the decoding output.
</nextsent>
<nextsent>usually, the 1-best hypotheses from each system are consider edas possible skeletons.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD865">
<title id=" W08-0329.xml">incremental hypothesis alignment for building confusion networks with application to machine translation system combination </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>confusion network decoding has been applied in combining outputs from multiple machine translation systems.
</prevsent>
<prevsent>the earliest approach in (bangalore et al, 2001) used edit distance based multiple string alignment (msa) (durbin et al, 1988) to build the confusion networks.
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
the recent approaches used pair-wise alignment algorithms based on symmetric alignments from hmm alignment model (matusov et al, 2006) <papid> E06-1005 </papid>or edit distance alignments allowing shifts (rosti et al, 2007).<papid> P07-1040 </papid></citsent>
<aftsection>
<nextsent>the alignment method described in this paper extends the latter by incrementally aligning the hypotheses as in msa but also allowing shifts as in the ter alignment.the confusion networks are built around skele ton?
</nextsent>
<nextsent>hypothesis.
</nextsent>
<nextsent>the skeleton hypothesis defines the word order of the decoding output.
</nextsent>
<nextsent>usually, the 1-best hypotheses from each system are consider edas possible skeletons.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD870">
<title id=" W08-0329.xml">incremental hypothesis alignment for building confusion networks with application to machine translation system combination </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to the tight schedule for the wmt08, there was no time to experiment with many configurations.
</prevsent>
<prevsent>as more extensive experiments have been conducted in the context of the darpa gale program, results on the arabic gale phase 2 evaluation setup are first presented.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the translation quality is measured by three mt evaluation metrics: ter (snover et al, 2006), bleu (papineni et al, 2002), <papid> P02-1040 </papid>and meteor (lavie and agarwal, 2007).<papid> W07-0734 </papid></citsent>
<aftsection>
<nextsent>3.1 results on arabic gale outputs.
</nextsent>
<nextsent>for the arabic gale phase 2 evaluation, nine systems were combined.
</nextsent>
<nextsent>five systems were phrase based, two hierarchical, one syntax-based, and one rule-based.
</nextsent>
<nextsent>all statistical systems were trained on common parallel data, tuned on common genre specific development set, and common english tokenization was used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD871">
<title id=" W08-0329.xml">incremental hypothesis alignment for building confusion networks with application to machine translation system combination </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to the tight schedule for the wmt08, there was no time to experiment with many configurations.
</prevsent>
<prevsent>as more extensive experiments have been conducted in the context of the darpa gale program, results on the arabic gale phase 2 evaluation setup are first presented.
</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
the translation quality is measured by three mt evaluation metrics: ter (snover et al, 2006), bleu (papineni et al, 2002), <papid> P02-1040 </papid>and meteor (lavie and agarwal, 2007).<papid> W07-0734 </papid></citsent>
<aftsection>
<nextsent>3.1 results on arabic gale outputs.
</nextsent>
<nextsent>for the arabic gale phase 2 evaluation, nine systems were combined.
</nextsent>
<nextsent>five systems were phrase based, two hierarchical, one syntax-based, and one rule-based.
</nextsent>
<nextsent>all statistical systems were trained on common parallel data, tuned on common genre specific development set, and common english tokenization was used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD874">
<title id=" W08-0512.xml">reengineering a domain independent framework for spoken dialogue systems </title>
<section> reengineering framework.  </section>
<citcontext>
<prevsection>
<prevsent>cases like hard-coded word replacement, used both to provide richer interpretation of the user utterances and to allow giving natural response to the user.
</prevsent>
<prevsent>in such cases, we either isolated the domain specific portions of the code or deleted them, even ifthe interpretation or generation processes were degraded.
</prevsent>
</prevsection>
<citsent citstr=" N07-3007 ">
it can be recovered in the future by including the domain specific knowledge in the dynamic configuration of the interpretation and generation managers as suggested by paulo pardal (2007)<papid> N07-3007 </papid>an example of this process is the splitting of the parser specific code into severalparsers: some domain-dependent, some domain independent, while creating mechanism to combine them in configurable chain (through pipes and filters architecture).</citsent>
<aftsection>
<nextsent>this allows the building of smaller data-type specific parsers that the interpretation manager selects to achieve the best parsing result, according to the expectations of the system (martins et al, 2008).
</nextsent>
<nextsent>these expectations are created according to the assumption that the user will follow the mixed-initiative dialogue flow thatthe system suggests?
</nextsent>
<nextsent>during its turn in the interaction.
</nextsent>
<nextsent>the strategy also handles those cases were the user does not keep up with those expectations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD876">
<title id=" W07-2031.xml">fuh fern universitat in hagen metonymy recognition using different kinds of context for a memory based learner </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the semeval submission, an accuracy of 79.8% on the coarse, 79.5% on the medium, and 78.5% on the fine level is achieved (the baseline accuracy is 79.4%).
</prevsent>
<prevsent>metonymy is typically defined as figure of speech in which speaker uses one entity to refer to an other that is related to it (lakoff and johnson, 1980).
</prevsent>
</prevsection>
<citsent citstr=" P93-1012 ">
the identification of metonymy becomes important for nlp tasks such as question answering (stallard, 1993) <papid> P93-1012 </papid>or geographic information retrieval (leveling and hartrumpf, 2006).</citsent>
<aftsection>
<nextsent>for regular cases of metonymy for locations and organizations, markert and nissim have proposed set of metonymy classes.
</nextsent>
<nextsent>annotating subset of the bnc (british national corpus), they extracted set of metonymic proper nouns from two categories:country names (markert and nissim, 2002) and organization names (nissim and markert, 2003).<papid> P03-1008 </papid>in the metonymy resolution task at semeval 2007, the goal was to identify metonymic names in subset of the bnc.</nextsent>
<nextsent>the task consists of two subtasks for company and country names, which are further divided into classification on coarse level (recog nizing literal and non-literal readings), on medium level (differentiating non-literal readings into mixed and metonymic readings), and on fine level (iden tifying classes of regular metonymy, such as name referring to the population, place-for-people).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD877">
<title id=" W07-2031.xml">fuh fern universitat in hagen metonymy recognition using different kinds of context for a memory based learner </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the identification of metonymy becomes important for nlp tasks such as question answering (stallard, 1993) <papid> P93-1012 </papid>or geographic information retrieval (leveling and hartrumpf, 2006).</prevsent>
<prevsent>for regular cases of metonymy for locations and organizations, markert and nissim have proposed set of metonymy classes.</prevsent>
</prevsection>
<citsent citstr=" P03-1008 ">
annotating subset of the bnc (british national corpus), they extracted set of metonymic proper nouns from two categories:country names (markert and nissim, 2002) and organization names (nissim and markert, 2003).<papid> P03-1008 </papid>in the metonymy resolution task at semeval 2007, the goal was to identify metonymic names in subset of the bnc.</citsent>
<aftsection>
<nextsent>the task consists of two subtasks for company and country names, which are further divided into classification on coarse level (recog nizing literal and non-literal readings), on medium level (differentiating non-literal readings into mixed and metonymic readings), and on fine level (iden tifying classes of regular metonymy, such as name referring to the population, place-for-people).
</nextsent>
<nextsent>thetask is described in more detail by markert and nissim (2007).<papid> W07-2007 </papid></nextsent>
<nextsent>2.1 tools and resources.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD878">
<title id=" W07-2031.xml">fuh fern universitat in hagen metonymy recognition using different kinds of context for a memory based learner </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>annotating subset of the bnc (british national corpus), they extracted set of metonymic proper nouns from two categories:country names (markert and nissim, 2002) and organization names (nissim and markert, 2003).<papid> P03-1008 </papid>in the metonymy resolution task at semeval 2007, the goal was to identify metonymic names in subset of the bnc.</prevsent>
<prevsent>the task consists of two subtasks for company and country names, which are further divided into classification on coarse level (recog nizing literal and non-literal readings), on medium level (differentiating non-literal readings into mixed and metonymic readings), and on fine level (iden tifying classes of regular metonymy, such as name referring to the population, place-for-people).</prevsent>
</prevsection>
<citsent citstr=" W07-2007 ">
thetask is described in more detail by markert and nissim (2007).<papid> W07-2007 </papid></citsent>
<aftsection>
<nextsent>2.1 tools and resources.
</nextsent>
<nextsent>the following tools and resources are used for the metonymy classification: ? timbl 5.1 (daelemans et al, 2004), amemory-based learner for classification is em 153 ployed for training the classifiers (supervised learning).1 ? mascara 2.0 ? metonymy annotation scheme and robust analysis (markert and nissim, 2003; nissim and markert, 2003; <papid> P03-1008 </papid>markert and nissim, 2002) contains annotated data for metonymic names from subset of the the bnc.?</nextsent>
<nextsent>wordnet 2.0 (fellbaum, 1998) serves as linguistic resource for assigning synset ids and for looking up subordination information and frequency of readings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD880">
<title id=" W07-2031.xml">fuh fern universitat in hagen metonymy recognition using different kinds of context for a memory based learner </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>wordnet 2.0 (fellbaum, 1998) serves as linguistic resource for assigning synset ids and for looking up subordination information and frequency of readings.
</prevsent>
<prevsent>the tree tagger (schmid, 1994) is utilized for sentence boundary detection, lemmatization,and part-of-speech tagging.
</prevsent>
</prevsection>
<citsent citstr=" C92-3145 ">
the english tagger was trained on the penn treebank and uses the english morphological database from thextag project (karp et al, 1992).<papid> C92-3145 </papid></citsent>
<aftsection>
<nextsent>the parameter files were obtained from the web site.2 2.2 different kinds of context.
</nextsent>
<nextsent>following the assumption that metonymic location names can be identified from the context, there are different kinds of context to consider.
</nextsent>
<nextsent>at most, the context comprises single sentence in this setup.three kinds of context were employed to extract features for the memory-based learner timbl: ? c1: subordination (hyponymy) information for nouns and verbs from the left and right context of the possibly metonymic name.
</nextsent>
<nextsent>c2: the sentence context for modal verbs, main verbs, prepositions, and articles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD881">
<title id=" W07-2031.xml">fuh fern universitat in hagen metonymy recognition using different kinds of context for a memory based learner </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the trial data provided (a subset of the mascara data) contained 188 non-literal location names (of925 samples total).
</prevsent>
<prevsent>for supervised learning approach, this is too few data.
</prevsent>
</prevsection>
<citsent citstr=" E06-3009 ">
therefore, the full mascara data was converted to form training data consisting of feature values for context c1, c2, and1peirsman (2006) <papid> E06-3009 </papid>also employs timbl for metonymy resolution, but trains single classifier.2http://www.ims.uni-stuttgart.de/projek te/corplex/treetagger/c3.</citsent>
<aftsection>
<nextsent>the training data contained 509 metonymic annotations (of 2797 samples total).
</nextsent>
<nextsent>some cases in the mascara corpus are filtered during processing, including cases annotated as homonyms and cases whose metonymy class could not be agreed upon.the test data had majority baseline of 82.8% accuracy for country names.
</nextsent>
<nextsent>2.3 features.
</nextsent>
<nextsent>the mascara data was processed to extract the following features (no hand-annotated data from mascara was employed for feature values, i.e. no grammatical roles): ? for c1 (wordnet context): from context of n1 verbs and nouns in the same sentence, their distance to the location name is calculated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD882">
<title id=" W08-0509.xml">parallel implementations of word alignment tool </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>training state-of-the-art phrase-based statistical machine translation (smt) systems requires several steps.
</prevsent>
<prevsent>first, word alignment models are trained on the bilingual parallel training corpora.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the most widely used tool to perform this training step is thewell-known giza++(och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>there sulting word alignment is then used to extract phrase pairs and perhaps other information to be used in translation systems, such as block reordering models.
</nextsent>
<nextsent>among the procedures, more than 2/3 of the time is consumed by word alignment (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>speeding up the word alignment step can dramatically reduces the overall training time, and in turn accelerates the development of smt systems.with the rapid development of computing hardware, multi-processor servers and clusters become widely available.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD885">
<title id=" W08-0509.xml">parallel implementations of word alignment tool </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the most widely used tool to perform this training step is thewell-known giza++(och and ney, 2003).<papid> J03-1002 </papid></prevsent>
<prevsent>there sulting word alignment is then used to extract phrase pairs and perhaps other information to be used in translation systems, such as block reordering mod els.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
among the procedures, more than 2/3 of the time is consumed by word alignment (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>speeding up the word alignment step can dramatically reduces the overall training time, and in turn accelerates the development of smt systems.with the rapid development of computing hardware, multi-processor servers and clusters become widely available.
</nextsent>
<nextsent>with parallel computing, processing time (wall time) can often be cut down by one or two orders of magnitude.
</nextsent>
<nextsent>tasks, which require several weeks on single cpu machine may take only few hours on cluster.
</nextsent>
<nextsent>however, giza++ was designed to be single-process and single-thread.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD887">
<title id=" W08-0509.xml">parallel implementations of word alignment tool </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, giza++ was designed to be single-process and single-thread.
</prevsent>
<prevsent>to make more efficient use of available computing resources and thereby speed up the training of our smt system, we decided to modify giza++ so that it can run in parallel on multiple cpus.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the word alignment models implemented in giza++, the so-called ibm (brown et al, 1993) <papid> J93-2003 </papid>andhmm alignment models (vogel et al, 1996) are typical implementation of the em algorithm (dempsteret al, 1977).</citsent>
<aftsection>
<nextsent>that is to say that each of these models run for number of iterations.
</nextsent>
<nextsent>in each iteration it first calculates the best word alignment for each sentence pairs in the corpus, accumulating various counts, and then normalizes the counts to generate the model parameters for the next iteration.
</nextsent>
<nextsent>the word alignment stage is the most time-consuming part, especially when the size of training corpus is large.
</nextsent>
<nextsent>during the aligning stage, all sentences can be aligned independently of each other, as model parameters are only updated after all sentence pairs have been aligned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD902">
<title id=" W08-0509.xml">parallel implementations of word alignment tool </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the scheduler assigns 11 cpus on average to the tasks.
</prevsent>
<prevsent>we ran 5 iterations of model 1 training, 5 iteration of hmm, 3 model 3 iterations and 3 model 4 iterations.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
to compare the performance of system, we recorded the total training time and the bleu score, which is standard automatic measurement of the translation quality(papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>the training time and bleu scores are shown in table 4: 5 running (tune) (test) time mt03 mt06 cpus giza++ 169h 32.34 29.43 2 pgiza++ 39h 32.20 30.14 11 table 4: comparison of giza++ and pgiza++the results show similar bleu scores when using giza++ and pgiza++, and 4 times speed up.also, we calculated the time used in normalization.
</nextsent>
<nextsent>the average time of each normalization step is shown in table 5.
</nextsent>
<nextsent>per-iteration (avg) total model 1 47.0min 235min (3.9h) hmm 31.8min 159min (2.6h) model 3/4 25.2 min 151min (2.5h) table 5: normalization time in each stage as we can see, if we rule out the time spent in normalization, the speed up is almost linear.
</nextsent>
<nextsent>higher order models require less time in the normalization step mainly due to the fact that the lexicon becomes smaller and smaller with each models (see table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD903">
<title id=" W08-0124.xml">modeling vocal interaction for text independent participant characterization in multiparty conversation </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>these three sets are not disjoint in participants, and the number of instrumented participants varies from meeting to meeting, between 3 and 9.
</prevsent>
<prevsent>the corpus is accompanied by meta data specifying the gender, age, and education levelof each participant.
</prevsent>
</prevsection>
<citsent citstr=" W04-2319 ">
we use only the forced alignments of these meetings, available in the accompanying mrda corpus (shriberg et al 2004).<papid> W04-2319 </papid></citsent>
<aftsection>
<nextsent>our observation space is the complete k-participant vocal interaction on-off pattern description for meeting c, discretized version of which we denot eas qt ? {0, 1}k for 1tt , where is the duration of in terms of the number of 100 ms frames.
</nextsent>
<nextsent>details regarding the discretization (and subsequent feature computation) can be found in (laskowski, ostendorf and schultz, 2007).
</nextsent>
<nextsent>we compute from qt the following features4which are the elements of f: fv ik , the pro babil 4feature type super scripts indicate talk spurt initiation (i) or continuation (c), for either single-participant vocal ization (v ) or vocal ization overlap (o).
</nextsent>
<nextsent>150 ity that participant initiates vocal ization at time when no-one else was speaking at ? 1; fv ck , the probability that participant continues vocal ization at time when no-one else was speaking at ? 1;foik,j , the probability that participant initiates vo cal ization at time when participant was speaking at ? 1; and fock,j the probability that participant continues vocal ization at time when participant was speaking at t?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD904">
<title id=" W07-2099.xml">uspibm1 and uspibm2 the ilp based systems for lexical sample wsd in semeval2007 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the systems make use of inductive logic programming for supervised learning in two different ways: (a) to build word sense disambiguation (wsd) models from rich set of background knowledge sources; and (b) to build interesting features from the same knowledge sources, which are then used by standard model-builder for wsd,namely, support vector machines.
</prevsent>
<prevsent>both systems achieved comparable accuracy (0.851 and 0.857), which outperforms considerably the most frequent sense baseline (0.787).
</prevsent>
</prevsection>
<citsent citstr=" W04-0807 ">
word sense disambiguation (wsd) aims to identify the correct sense of ambiguous words in context.results from the last edition of the senseval competition (mihalcea et al, 2004) <papid> W04-0807 </papid>have shown that, for supervised learning, the best accuracies are obtained with combination of various types of features, together with traditional machine learning algorithms based on feature-value vectors, such as support vector machines (svms) and naive bayes.</citsent>
<aftsection>
<nextsent>while the features employed by these approaches are mostly considered to be shallow?, that is, extracted from corpus or provided by shallow syntactic tools like part-of-speech taggers, it is generally thought that significant progress in automatic wsd would require deep?
</nextsent>
<nextsent>approach in which access to substantial body of linguistic and world knowledge could assist in resolving ambiguities.
</nextsent>
<nextsent>although the access to large amounts of knowledge is now possible due to the availability of lexicons like wordnet, parsers, etc., the incorporation of such knowledge has been hampered by the limitations of the modelling techniques usually employed for wsd.
</nextsent>
<nextsent>using certain sources of information, mainly relational information, is beyond the capabilities of such techniques, which are based on feature-value vectors.arguably, inductive logic programming (ilp) systems provide an appropriate framework for dealing with such data: they make explicit provisions for the inclusion of background knowledge of any form; the richer representation language used, based on first order logic, is powerful enough to capture contextual relationships; and the modelling is not restricted to being of particular form (e.g., classification).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD905">
<title id=" W07-1518.xml">xara an xml and rule based semantic role labeler </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such an instance base can be used totrain machine learning algorithms for automatic semantic role labeling (srl).
</prevsent>
<prevsent>in my semantic role labeling research, used the tilburg memory learner (timbl) for this purpose.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
ever since the pioneering article of gildea and jurafsky (2002), <papid> J02-3001 </papid>there has been an increasing interest in automatic semantic role labeling (srl).</citsent>
<aftsection>
<nextsent>in general, classification algorithms (a supervised machine learning strategy) are used for this purpose.
</nextsent>
<nextsent>manual annotated corpora provide gold standard for such classifiers.
</nextsent>
<nextsent>starting manual annotation from scratch is very time consuming and therefore expensive.
</nextsent>
<nextsent>a possible solution is to start from (partially) automatically annotated corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD906">
<title id=" W07-2220.xml">data driven dependency parsing across languages and domains perspectives from the conll2007 shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, summarize the main findings from the 2007 shared task and try to identify major challenges for the parsing community based on these findings.
</prevsent>
<prevsent>the annual conference on computational natural language learning (conll) has for the past nine years organized shared task, where participants train and test their learning systems on the same data sets.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
in 2006, the shared task was multilingual dependency parsing, where participants had totrain and test parser on data from thirteen different languages (buchholz and marsi, 2006).<papid> W06-2920 </papid></citsent>
<aftsection>
<nextsent>in 2007, the task was extended by adding second track for (monolingual) domain adaptation.
</nextsent>
<nextsent>the conll 2007 shared task on dependency parsing featured two tracks: ? in the multilingual track, the task was to train parser using labeled data from arabic, basque,catalan, chinese, czech, english, greek, hungarian, italian, and turkish.
</nextsent>
<nextsent>in the domain adaptation track, the task was to adapt parser for english news text to other domains using unlabeled data from the target domains: biomedical and chemical abstracts, parent-child dialogues.1 in the closed class, the base parser had to be trained using the english training set for the multilingual track and no external resources were allowed.
</nextsent>
<nextsent>in the open class, any base parser could be used and any external resources were allowed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD907">
<title id=" W07-2220.xml">data driven dependency parsing across languages and domains perspectives from the conll2007 shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>output: head (word-id), dependency label.
</prevsent>
<prevsent>the main evaluation metric for both tracks was the labeled attachment score (las), i.e., the percentage of words that have been assigned the correct head and dependency label.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
for more information about the setup, see nivre et al (2007) <papid> D07-1096 </papid>in this paper, will summarize the main findings from the conll 2007 shared task, starting with characterization of the different approaches used (section 2), and moving on to the most interesting results in the multilingual track (section 3) and the domain adaptation track (section 4).</citsent>
<aftsection>
<nextsent>finally, basedon these findings, will try to identify some important challenges for the wider parsing community (section 5).
</nextsent>
<nextsent>1the biomedical domain was the development domain, which means that small labeled development set was available for this domain.
</nextsent>
<nextsent>the final testing was only done on chemical abstracts and (optionally) parent-child dialogues.
</nextsent>
<nextsent>168
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD908">
<title id=" W07-2220.xml">data driven dependency parsing across languages and domains perspectives from the conll2007 shared task </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>168
</prevsent>
<prevsent>in total, test runs were submitted for twenty-three systems in the multilingual track, and ten systems inthe domain adaptation track (six of which also participated in the multilingual track).
</prevsent>
</prevsection>
<citsent citstr=" D07-1013 ">
the majority of these systems used models belonging to one of the two dominant approaches in data-driven dependency parsing in recent years (mcdonald and nivre, 2007):?<papid> D07-1013 </papid></citsent>
<aftsection>
<nextsent>in graph-based models, every possible dependency graph forgiven input sentence is given score that decomposes into scores for the arcs of the graph.
</nextsent>
<nextsent>the optimal parse can be found using spanning tree algorithm (eisner, 1996; <papid> C96-1058 </papid>mcdonald et al, 2005).<papid> H05-1066 </papid></nextsent>
<nextsent>in transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD909">
<title id=" W07-2220.xml">data driven dependency parsing across languages and domains perspectives from the conll2007 shared task </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>the majority of these systems used models belonging to one of the two dominant approaches in data-driven dependency parsing in recent years (mcdonald and nivre, 2007):?<papid> D07-1013 </papid></prevsent>
<prevsent>in graph-based models, every possible dependency graph forgiven input sentence is given score that decomposes into scores for the arcs of the graph.</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
the optimal parse can be found using spanning tree algorithm (eisner, 1996; <papid> C96-1058 </papid>mcdonald et al, 2005).<papid> H05-1066 </papid></citsent>
<aftsection>
<nextsent>in transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them.
</nextsent>
<nextsent>the search for an optimal parse is often deterministic and guided by classifiers (yamada and matsumoto, 2003; nivre, 2003).
</nextsent>
<nextsent>the majority of graph-based parsers in the shared task were based on what mcdonald and pereira (2006) <papid> E06-1011 </papid>call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-ordermodels, either with exact inference limited to projective dependency graphs (carreras, 2007), or with approximate inference (nakagawa, 2007).</nextsent>
<nextsent>another innovation was the use of k-best spanning tree algorithms for inference with non-projective first-order model (hall et al, 2007<papid> D07-1102 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD910">
<title id=" W07-2220.xml">data driven dependency parsing across languages and domains perspectives from the conll2007 shared task </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>the majority of these systems used models belonging to one of the two dominant approaches in data-driven dependency parsing in recent years (mcdonald and nivre, 2007):?<papid> D07-1013 </papid></prevsent>
<prevsent>in graph-based models, every possible dependency graph forgiven input sentence is given score that decomposes into scores for the arcs of the graph.</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
the optimal parse can be found using spanning tree algorithm (eisner, 1996; <papid> C96-1058 </papid>mcdonald et al, 2005).<papid> H05-1066 </papid></citsent>
<aftsection>
<nextsent>in transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them.
</nextsent>
<nextsent>the search for an optimal parse is often deterministic and guided by classifiers (yamada and matsumoto, 2003; nivre, 2003).
</nextsent>
<nextsent>the majority of graph-based parsers in the shared task were based on what mcdonald and pereira (2006) <papid> E06-1011 </papid>call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-ordermodels, either with exact inference limited to projective dependency graphs (carreras, 2007), or with approximate inference (nakagawa, 2007).</nextsent>
<nextsent>another innovation was the use of k-best spanning tree algorithms for inference with non-projective first-order model (hall et al, 2007<papid> D07-1102 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD911">
<title id=" W07-2220.xml">data driven dependency parsing across languages and domains perspectives from the conll2007 shared task </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>in transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them.
</prevsent>
<prevsent>the search for an optimal parse is often deterministic and guided by classifiers (yamada and matsumoto, 2003; nivre, 2003).
</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
the majority of graph-based parsers in the shared task were based on what mcdonald and pereira (2006) <papid> E06-1011 </papid>call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-ordermodels, either with exact inference limited to projective dependency graphs (carreras, 2007), or with approximate inference (nakagawa, 2007).</citsent>
<aftsection>
<nextsent>another innovation was the use of k-best spanning tree algorithms for inference with non-projective first-order model (hall et al, 2007<papid> D07-1102 </papid>b).</nextsent>
<nextsent>for transition-based parsers, the trend was clearly to move away from deterministic parsing by adding probability model for scoring set of candidate parses typically derived using heuristic searchstrategy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD912">
<title id=" W07-2220.xml">data driven dependency parsing across languages and domains perspectives from the conll2007 shared task </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>the search for an optimal parse is often deterministic and guided by classifiers (yamada and matsumoto, 2003; nivre, 2003).
</prevsent>
<prevsent>the majority of graph-based parsers in the shared task were based on what mcdonald and pereira (2006) <papid> E06-1011 </papid>call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-ordermodels, either with exact inference limited to projective dependency graphs (carreras, 2007), or with approximate inference (nakagawa, 2007).</prevsent>
</prevsection>
<citsent citstr=" D07-1102 ">
another innovation was the use of k-best spanning tree algorithms for inference with non-projective first-order model (hall et al, 2007<papid> D07-1102 </papid>b).</citsent>
<aftsection>
<nextsent>for transition-based parsers, the trend was clearly to move away from deterministic parsing by adding probability model for scoring set of candidate parses typically derived using heuristic searchstrategy.
</nextsent>
<nextsent>the probability model may be either conditional (duan et al, 2007) <papid> D07-1098 </papid>or generative (titov and henderson, 2007).<papid> D07-1099 </papid></nextsent>
<nextsent>an interesting way of combining the two main approaches is to use graph-based model to buildan ensemble of transition-based parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD916">
<title id=" W07-2220.xml">data driven dependency parsing across languages and domains perspectives from the conll2007 shared task </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>another innovation was the use of k-best spanning tree algorithms for inference with non-projective first-order model (hall et al, 2007<papid> D07-1102 </papid>b).</prevsent>
<prevsent>for transition-based parsers, the trend was clearly to move away from deterministic parsing by adding probability model for scoring set of candidate parses typically derived using heuristic searchstrategy.</prevsent>
</prevsection>
<citsent citstr=" D07-1098 ">
the probability model may be either conditional (duan et al, 2007) <papid> D07-1098 </papid>or generative (titov and henderson, 2007).<papid> D07-1099 </papid></citsent>
<aftsection>
<nextsent>an interesting way of combining the two main approaches is to use graph-based model to buildan ensemble of transition-based parsers.
</nextsent>
<nextsent>this technique, first proposed by sagae and lavie (2006), <papid> N06-2033 </papid>wasused in the highest scoring system in both the multilingual track (hall et al, 2007<papid> D07-1102 </papid>a) and the domain adaptation track (sagae and tsujii, 2007).<papid> D07-1111 </papid></nextsent>
<nextsent>the ten languages involved in the multilingual track can be grouped into three classes with respect to the best parsing accuracy achieved: ? low (las = 76.376.9): arabic, basque, greek ? medium (las = 79.280.2): czech, hungarian, turkish ? high (las = 84.489.6): catalan, chinese, english, italian to large extent, these classes appear to be definable from typo logical properties.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD917">
<title id=" W07-2220.xml">data driven dependency parsing across languages and domains perspectives from the conll2007 shared task </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>another innovation was the use of k-best spanning tree algorithms for inference with non-projective first-order model (hall et al, 2007<papid> D07-1102 </papid>b).</prevsent>
<prevsent>for transition-based parsers, the trend was clearly to move away from deterministic parsing by adding probability model for scoring set of candidate parses typically derived using heuristic searchstrategy.</prevsent>
</prevsection>
<citsent citstr=" D07-1099 ">
the probability model may be either conditional (duan et al, 2007) <papid> D07-1098 </papid>or generative (titov and henderson, 2007).<papid> D07-1099 </papid></citsent>
<aftsection>
<nextsent>an interesting way of combining the two main approaches is to use graph-based model to buildan ensemble of transition-based parsers.
</nextsent>
<nextsent>this technique, first proposed by sagae and lavie (2006), <papid> N06-2033 </papid>wasused in the highest scoring system in both the multilingual track (hall et al, 2007<papid> D07-1102 </papid>a) and the domain adaptation track (sagae and tsujii, 2007).<papid> D07-1111 </papid></nextsent>
<nextsent>the ten languages involved in the multilingual track can be grouped into three classes with respect to the best parsing accuracy achieved: ? low (las = 76.376.9): arabic, basque, greek ? medium (las = 79.280.2): czech, hungarian, turkish ? high (las = 84.489.6): catalan, chinese, english, italian to large extent, these classes appear to be definable from typo logical properties.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD918">
<title id=" W07-2220.xml">data driven dependency parsing across languages and domains perspectives from the conll2007 shared task </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>the probability model may be either conditional (duan et al, 2007) <papid> D07-1098 </papid>or generative (titov and henderson, 2007).<papid> D07-1099 </papid></prevsent>
<prevsent>an interesting way of combining the two main approaches is to use graph-based model to buildan ensemble of transition-based parsers.</prevsent>
</prevsection>
<citsent citstr=" N06-2033 ">
this technique, first proposed by sagae and lavie (2006), <papid> N06-2033 </papid>wasused in the highest scoring system in both the multilingual track (hall et al, 2007<papid> D07-1102 </papid>a) and the domain adaptation track (sagae and tsujii, 2007).<papid> D07-1111 </papid></citsent>
<aftsection>
<nextsent>the ten languages involved in the multilingual track can be grouped into three classes with respect to the best parsing accuracy achieved: ? low (las = 76.376.9): arabic, basque, greek ? medium (las = 79.280.2): czech, hungarian, turkish ? high (las = 84.489.6): catalan, chinese, english, italian to large extent, these classes appear to be definable from typo logical properties.
</nextsent>
<nextsent>the class with the highest top scores contains languages with rather impoverished morphology.
</nextsent>
<nextsent>medium scores are reached by the two agglutinative languages, hungarian and turkish, as well as by czech.
</nextsent>
<nextsent>the most difficult languages are those that combine relatively free word order with high degree of inflection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD923">
<title id=" W07-2220.xml">data driven dependency parsing across languages and domains perspectives from the conll2007 shared task </title>
<section> approaches.  </section>
<citcontext>
<prevsection>
<prevsent>the probability model may be either conditional (duan et al, 2007) <papid> D07-1098 </papid>or generative (titov and henderson, 2007).<papid> D07-1099 </papid></prevsent>
<prevsent>an interesting way of combining the two main approaches is to use graph-based model to buildan ensemble of transition-based parsers.</prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
this technique, first proposed by sagae and lavie (2006), <papid> N06-2033 </papid>wasused in the highest scoring system in both the multilingual track (hall et al, 2007<papid> D07-1102 </papid>a) and the domain adaptation track (sagae and tsujii, 2007).<papid> D07-1111 </papid></citsent>
<aftsection>
<nextsent>the ten languages involved in the multilingual track can be grouped into three classes with respect to the best parsing accuracy achieved: ? low (las = 76.376.9): arabic, basque, greek ? medium (las = 79.280.2): czech, hungarian, turkish ? high (las = 84.489.6): catalan, chinese, english, italian to large extent, these classes appear to be definable from typo logical properties.
</nextsent>
<nextsent>the class with the highest top scores contains languages with rather impoverished morphology.
</nextsent>
<nextsent>medium scores are reached by the two agglutinative languages, hungarian and turkish, as well as by czech.
</nextsent>
<nextsent>the most difficult languages are those that combine relatively free word order with high degree of inflection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD928">
<title id=" W07-2010.xml">semeval2007 task 11 english lexical sample task via english chinese parallel text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>past research has shown that supervised learning is one of the most successful approaches to wsd.
</prevsent>
<prevsent>however, this approach involves the collection of large text corpus in which each ambiguous word has been annotated with the correct sense to serve as training data.
</prevsent>
</prevsection>
<citsent citstr=" W02-0817 ">
due to the expensive annotation process, only handful of manually sense-tagged corpora are available.an effort to alleviate the training data bottle neck is the open mind word expert (omwe) project (chklovski and mihalcea, 2002) <papid> W02-0817 </papid>to collectsense-tagged data from internet users.</citsent>
<aftsection>
<nextsent>data gathered through the omwe project were used in the senseval-3 english lexical sample task.
</nextsent>
<nextsent>in that task, wordnet-1.7.1 was used as the sense inventory for nouns and adjectives, while wordsmyth1 was used as the sense inventory for verbs.another source of potential training data is parallel texts.
</nextsent>
<nextsent>our past research in (ng et al, 2003;<papid> P03-1058 </papid>chan and ng, 2005) has shown that examples gathered from parallel texts are useful for wsd.</nextsent>
<nextsent>briefly,after manually assigning appropriate chinese translations to each sense of an english word, the english side of word-aligned parallel text can then serve as the training data, as they are considered to have beendisambiguated and sense-tagged?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD929">
<title id=" W07-2010.xml">semeval2007 task 11 english lexical sample task via english chinese parallel text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data gathered through the omwe project were used in the senseval-3 english lexical sample task.
</prevsent>
<prevsent>in that task, wordnet-1.7.1 was used as the sense inventory for nouns and adjectives, while wordsmyth1 was used as the sense inventory for verbs.another source of potential training data is parallel texts.
</prevsent>
</prevsection>
<citsent citstr=" P03-1058 ">
our past research in (ng et al, 2003;<papid> P03-1058 </papid>chan and ng, 2005) has shown that examples gathered from parallel texts are useful for wsd.</citsent>
<aftsection>
<nextsent>briefly,after manually assigning appropriate chinese translations to each sense of an english word, the english side of word-aligned parallel text can then serve as the training data, as they are considered to have beendisambiguated and sense-tagged?
</nextsent>
<nextsent>by the appropriate chinese translations.using the above approach, we gathered the training and test examples for our task from parallel texts.note that our examples are collected without manually annotating each individual ambiguous word occurrence, allowing us to gather our examples in much shorter time.
</nextsent>
<nextsent>this contrasts with the setting ofthe english lexical sample task in previous senseval evaluations.
</nextsent>
<nextsent>in the english lexical sample taskof senseval-2, the sense tagged data were created through manual annotation by trained lexicog raphers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD931">
<title id=" W07-2010.xml">semeval2007 task 11 english lexical sample task via english chinese parallel text </title>
<section> gathering examples from parallel.  </section>
<citcontext>
<prevsection>
<prevsent>in section 4, we present the results obtained by the participants, before concluding in section 5.
</prevsent>
<prevsent>corpor ato gather examples from parallel corpora, we followed the approach in (ng et al, 2003).<papid> P03-1058 </papid></prevsent>
</prevsection>
<citsent citstr=" I05-3025 ">
briefly, after ensuring the corpora were sentence-aligned, we tokenized the english texts and performed word segmentation on the chinese texts (low et al, 2005).<papid> I05-3025 </papid></citsent>
<aftsection>
<nextsent>we then made use of the giza++ software (och andney, 2000) <papid> P00-1056 </papid>to perform word alignment on the parallel corpora.</nextsent>
<nextsent>then, we assigned some possible chinese translations to each sense of an english word w. from the word alignment output of giza++, we selected those occurrences of which were aligned to one of the chinese translations chosen.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD932">
<title id=" W07-2010.xml">semeval2007 task 11 english lexical sample task via english chinese parallel text </title>
<section> gathering examples from parallel.  </section>
<citcontext>
<prevsection>
<prevsent>corpor ato gather examples from parallel corpora, we followed the approach in (ng et al, 2003).<papid> P03-1058 </papid></prevsent>
<prevsent>briefly, after ensuring the corpora were sentence-aligned, we tokenized the english texts and performed word segmentation on the chinese texts (low et al, 2005).<papid> I05-3025 </papid></prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we then made use of the giza++ software (och andney, 2000) <papid> P00-1056 </papid>to perform word alignment on the parallel corpora.</citsent>
<aftsection>
<nextsent>then, we assigned some possible chinese translations to each sense of an english word w. from the word alignment output of giza++, we selected those occurrences of which were aligned to one of the chinese translations chosen.
</nextsent>
<nextsent>the english side of these occurrences served as training data for w, as they were considered to have been dis ambiguated and sense-tagged?
</nextsent>
<nextsent>by the appropriate chinese translations.
</nextsent>
<nextsent>the english half of the parallel texts (each ambiguous english word and its 3 sentence context) were used as the training and test material to set up our english lexical sample task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD933">
<title id=" W07-2010.xml">semeval2007 task 11 english lexical sample task via english chinese parallel text </title>
<section> gathering examples from parallel.  </section>
<citcontext>
<prevsection>
<prevsent>the english half of the parallel texts (each ambiguous english word and its 3 sentence context) were used as the training and test material to set up our english lexical sample task.
</prevsent>
<prevsent>note that in our approach, the sense distinction is decided by the different chinese translations assigned to each sense of word.
</prevsent>
</prevsection>
<citsent citstr=" W04-0802 ">
this is thus similar to the multilingual lexical sample task in senseval-3 (chklovski et al, 2004), <papid> W04-0802 </papid>except thatour training and test examples are collected with out manually annotating each individual ambiguous word occurrence.</citsent>
<aftsection>
<nextsent>the average time needed to assign chinese translations for one noun and one adjective is 20 minutes and 25 minutes respectively.
</nextsent>
<nextsent>this isa relatively short time, compared to the effort otherwise needed to manually sense annotate individual word occurrences.
</nextsent>
<nextsent>also, once the chinese translations are assigned, more examples can be automatically gathered as more parallel texts become avail able.we note that frequently occurring words are usually highly polysemous and hard to disambiguate.
</nextsent>
<nextsent>to maximize the benefits of our work, we gathered training data from parallel texts for set of most frequently occurring noun and adjective types in the brown corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD934">
<title id=" W07-2010.xml">semeval2007 task 11 english lexical sample task via english chinese parallel text </title>
<section> gathering examples from parallel.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, each noun has an average of 197.6 training and 98.5 test examples and these examples represent an average of 5.2 senses per noun.2 participants taking part in this track need to have access to this ldc corpus in order to access the training and test material in this track.
</prevsent>
<prevsent>2.2 web corpus.
</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
since not all interested participants may have access to the ldc corpus described in the previous subsection, the second track of this task makes use of english-chinese documents gathered from the url pairs given by the strand bilingual databases.3 strand (resnik and smith, 2003) <papid> J03-3002 </papid>is system that acquires document pairs in parallel translation automatically from the web.</citsent>
<aftsection>
<nextsent>using this corpus, we gathered examples for 40 english words (20 nouns and 2only senses present in the examples are counted.
</nextsent>
<nextsent>3http://www.umiacs.umd.edu/resnik/strand 55 20 adjectives).
</nextsent>
<nextsent>the rows web noun and web adjective in table 1 show that we selected an average of 182.0 training and 91.3 test examples for each noun and these examples represent an average of 3.5 senses per noun.
</nextsent>
<nextsent>we note that the average number of senses per word for the web corpus is slightly lower than that of the ldc corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD939">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the czech morphological system (hajic?, 2004) defines 4,000 tags in theory and 2,000 were actually seen in big tagged corpus.
</prevsent>
<prevsent>(for comparison, the english penn treebank tagset contains just about 50 tags.)
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
in our parallel corpus (see section 3 below), the english vocabulary size is 35k distinct token types but more than twice as big in czech, 83k distinct token types.to further emphasize the importance of morphology in mt to czech, we compare the standard bleu (papineni et al, 2002) <papid> P02-1040 </papid>of baseline phrase based translation with bleu which disregards word forms (lemmatized mt output is compared to lemmatized reference translation).</citsent>
<aftsection>
<nextsent>the theoretical margin for improving mt quality is about 9 bleupoints: the same mt output scores 12 points in standard bleu and 21 points in lemmatized bleu.
</nextsent>
<nextsent>in statistical mt, the goal is to translate source (foreign) language sentence fj1 = f1 . . .
</nextsent>
<nextsent>fj . . .
</nextsent>
<nextsent>fj into target language (czech) sentence ci1 =c1 . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD940">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> overview of factored smt.  </section>
<citcontext>
<prevsection>
<prevsent>f} to subset of target factors ? {1 . . .
</prevsent>
<prevsent>c} is the standard phrase-based model (see e.g.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
(koehn, 2004<papid> W04-3250 </papid>a)) and introduces feature in the following form: hmap:stm (ck, fk) = log p(fsk |ctk ) (4) the conditional probability of fsk , i.e. the phrase fk restricted to factors s, given ctk , i.e. the phrase ck restricted to factors is estimated from relative frequencies: p(fsk |ctk ) = n(fs, ct )/n(ct ) where n(fs, ct ) denotes the number of co-occurrences of phrase pair (fs, ct ) that are consistent with the word alignment.</citsent>
<aftsection>
<nextsent>the marginal count n(ct ) is the number of occurrences of the target phrase ct in the training corpus.
</nextsent>
<nextsent>for each mapping step, the model is included in the log-linear combination in source-to-target and target-to-source directions: p(ft |cs) and p(cs |ft ).
</nextsent>
<nextsent>in addition, statistical single word based lexica are used in both directions.
</nextsent>
<nextsent>they are included to smooth the relative frequencies used as estimates of the phrase probabilities.a generation step maps subset of target factors t1 to disjoint subset of target factors t2, t1,2 ? {1 . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD942">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> data used.  </section>
<citcontext>
<prevsection>
<prevsent>we use the designated additional tuning and evaluation sections consisting of 1023, resp.
</prevsent>
<prevsent>964 sentences.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
in all experiments, word alignment was obtained using the grow-diag-final heuristic for symmetriz ing giza++ (och and ney, 2003) <papid> J03-1002 </papid>alignments.</citsent>
<aftsection>
<nextsent>to reduce data sparseness, the english text was lower cased and czech was lemmatized for alignment estimation.
</nextsent>
<nextsent>language models are based on the target 4http://www.statmt.org/wmt07/5our preliminary experiments with the prague czech english dependency treebank, pcedt v.1.0 ( cmejrek et al, 2004), 20k sentences, gave similar results, although with lower level of significance due to smaller evaluation set.side of the parallel corpus only, unless stated otherwise.
</nextsent>
<nextsent>3.1 evaluation measure and mert.
</nextsent>
<nextsent>we evaluate our experiments using the (lowercase,tokenized) bleu metric and estimate the empirical confidence using the bootstrapping method described in koehn (2004<papid> W04-3250 </papid>b).6 we report the scores obtained on the test section with model parameters tuned using the tuning section for minimum error rate training (mert, (och, 2003)).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD944">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> data used.  </section>
<citcontext>
<prevsection>
<prevsent>language models are based on the target 4http://www.statmt.org/wmt07/5our preliminary experiments with the prague czech english dependency treebank, pcedt v.1.0 ( cmejrek et al, 2004), 20k sentences, gave similar results, although with lower level of significance due to smaller evaluation set.side of the parallel corpus only, unless stated otherwise.
</prevsent>
<prevsent>3.1 evaluation measure and mert.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we evaluate our experiments using the (lowercase,tokenized) bleu metric and estimate the empirical confidence using the bootstrapping method described in koehn (2004<papid> W04-3250 </papid>b).6 we report the scores obtained on the test section with model parameters tuned using the tuning section for minimum error rate training (mert, (och, 2003)).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>englishczechwe experimented with the following factored translation scenarios.
</nextsent>
<nextsent>the baseline scenario (labelled for translation) is single-factored: input (english) lowercase word forms are directly translated to target (czech) lowercase forms.
</nextsent>
<nextsent>a 3-gram language model (or more models based on various corpora) checks the stream of output word forms.
</nextsent>
<nextsent>the baseline scenario thus corresponds to plain phrase-based smt system: english czech lowercase lowercase +lm lemma lemma morphology morphology in order to check the output not only for word level coherence but also for morphological coherence, we add single generation step: input word forms are first translated to output word forms andeach output word form then generates its morphological tag.two types of language models can be used simul taneously: (3-gram) lm over word forms and (7-gram) lm over morphological tags.we used tags with various levels of detail, see section 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD945">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>a more appropriate treatment 237 is to disregard the dummy tokens in the language model at all and use an n-gram language model that looks at last n?
</prevsent>
<prevsent>1 non-dummy items.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
class-based lms (brown et al, 1992) <papid> J92-4003 </papid>or factored lms (bilmes and kirchhoff, 2003) <papid> N03-2002 </papid>are very similar to our t+c scenario.</citsent>
<aftsection>
<nextsent>given the small differences in all t+.
</nextsent>
<nextsent>scenarios?
</nextsent>
<nextsent>performance, class-based lm might bring equivalent improvement.
</nextsent>
<nextsent>yang and kirchhoff (2006) <papid> E06-1006 </papid>have recently documented minor bleu improvement using factored lms in single factored smt to english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD946">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>a more appropriate treatment 237 is to disregard the dummy tokens in the language model at all and use an n-gram language model that looks at last n?
</prevsent>
<prevsent>1 non-dummy items.
</prevsent>
</prevsection>
<citsent citstr=" N03-2002 ">
class-based lms (brown et al, 1992) <papid> J92-4003 </papid>or factored lms (bilmes and kirchhoff, 2003) <papid> N03-2002 </papid>are very similar to our t+c scenario.</citsent>
<aftsection>
<nextsent>given the small differences in all t+.
</nextsent>
<nextsent>scenarios?
</nextsent>
<nextsent>performance, class-based lm might bring equivalent improvement.
</nextsent>
<nextsent>yang and kirchhoff (2006) <papid> E06-1006 </papid>have recently documented minor bleu improvement using factored lms in single factored smt to english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD947">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>scenarios?
</prevsent>
<prevsent>performance, class-based lm might bring equivalent improvement.
</prevsent>
</prevsection>
<citsent citstr=" E06-1006 ">
yang and kirchhoff (2006) <papid> E06-1006 </papid>have recently documented minor bleu improvement using factored lms in single factored smt to english.</citsent>
<aftsection>
<nextsent>the multi-factored approach to smt of moses is however more general.many researchers have tried to employ morphology in improving word alignment techniques(e.g.
</nextsent>
<nextsent>(popovic?
</nextsent>
<nextsent>and ney, 2004)) or machine translation quality (nieen and ney (2001), koehn and knight (2003), <papid> E03-1076 </papid>zollmann et al (2006), <papid> N06-2051 </papid>among others, for various languages; goldwater and mcclosky (2005), <papid> H05-1085 </papid>bojar et al (2006) and talbot and osborne(2006) <papid> P06-1122 </papid>for czech), however, they focus on translating from the highly inflectional language.durgar el-kahlout and oflazer (2006) report preliminary experiments in english to turkish single factored phrase-based translation, gaining significant improvements by splitting root words and their morphemes into sequence of tokens.</nextsent>
<nextsent>in might be interesting to explore multi-factored scenarios for different turkish morphology representation suggested the paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD948">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>the multi-factored approach to smt of moses is however more general.many researchers have tried to employ morphology in improving word alignment techniques(e.g.
</prevsent>
<prevsent>(popovic?
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
and ney, 2004)) or machine translation quality (nieen and ney (2001), koehn and knight (2003), <papid> E03-1076 </papid>zollmann et al (2006), <papid> N06-2051 </papid>among others, for various languages; goldwater and mcclosky (2005), <papid> H05-1085 </papid>bojar et al (2006) and talbot and osborne(2006) <papid> P06-1122 </papid>for czech), however, they focus on translating from the highly inflectional language.durgar el-kahlout and oflazer (2006) report preliminary experiments in english to turkish single factored phrase-based translation, gaining significant improvements by splitting root words and their morphemes into sequence of tokens.</citsent>
<aftsection>
<nextsent>in might be interesting to explore multi-factored scenarios for different turkish morphology representation suggested the paper.
</nextsent>
<nextsent>de gispert et al (2005) generalize over verb form sand generate phrase translations even for unseen target verb forms.
</nextsent>
<nextsent>the t+t+g scenario allows similar extension if the described generation step is replaced by (probabilistic) morphological generator.nguyen and shimazu (2006) translate from english to vietnamese but the morphological richness of vietnamese is comparable to english.
</nextsent>
<nextsent>in fact the vietnamese vocabulary size is even smaller than english vocabulary size in one of their corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD949">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>the multi-factored approach to smt of moses is however more general.many researchers have tried to employ morphology in improving word alignment techniques(e.g.
</prevsent>
<prevsent>(popovic?
</prevsent>
</prevsection>
<citsent citstr=" N06-2051 ">
and ney, 2004)) or machine translation quality (nieen and ney (2001), koehn and knight (2003), <papid> E03-1076 </papid>zollmann et al (2006), <papid> N06-2051 </papid>among others, for various languages; goldwater and mcclosky (2005), <papid> H05-1085 </papid>bojar et al (2006) and talbot and osborne(2006) <papid> P06-1122 </papid>for czech), however, they focus on translating from the highly inflectional language.durgar el-kahlout and oflazer (2006) report preliminary experiments in english to turkish single factored phrase-based translation, gaining significant improvements by splitting root words and their morphemes into sequence of tokens.</citsent>
<aftsection>
<nextsent>in might be interesting to explore multi-factored scenarios for different turkish morphology representation suggested the paper.
</nextsent>
<nextsent>de gispert et al (2005) generalize over verb form sand generate phrase translations even for unseen target verb forms.
</nextsent>
<nextsent>the t+t+g scenario allows similar extension if the described generation step is replaced by (probabilistic) morphological generator.nguyen and shimazu (2006) translate from english to vietnamese but the morphological richness of vietnamese is comparable to english.
</nextsent>
<nextsent>in fact the vietnamese vocabulary size is even smaller than english vocabulary size in one of their corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD950">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>the multi-factored approach to smt of moses is however more general.many researchers have tried to employ morphology in improving word alignment techniques(e.g.
</prevsent>
<prevsent>(popovic?
</prevsent>
</prevsection>
<citsent citstr=" H05-1085 ">
and ney, 2004)) or machine translation quality (nieen and ney (2001), koehn and knight (2003), <papid> E03-1076 </papid>zollmann et al (2006), <papid> N06-2051 </papid>among others, for various languages; goldwater and mcclosky (2005), <papid> H05-1085 </papid>bojar et al (2006) and talbot and osborne(2006) <papid> P06-1122 </papid>for czech), however, they focus on translating from the highly inflectional language.durgar el-kahlout and oflazer (2006) report preliminary experiments in english to turkish single factored phrase-based translation, gaining significant improvements by splitting root words and their morphemes into sequence of tokens.</citsent>
<aftsection>
<nextsent>in might be interesting to explore multi-factored scenarios for different turkish morphology representation suggested the paper.
</nextsent>
<nextsent>de gispert et al (2005) generalize over verb form sand generate phrase translations even for unseen target verb forms.
</nextsent>
<nextsent>the t+t+g scenario allows similar extension if the described generation step is replaced by (probabilistic) morphological generator.nguyen and shimazu (2006) translate from english to vietnamese but the morphological richness of vietnamese is comparable to english.
</nextsent>
<nextsent>in fact the vietnamese vocabulary size is even smaller than english vocabulary size in one of their corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD951">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>the multi-factored approach to smt of moses is however more general.many researchers have tried to employ morphology in improving word alignment techniques(e.g.
</prevsent>
<prevsent>(popovic?
</prevsent>
</prevsection>
<citsent citstr=" P06-1122 ">
and ney, 2004)) or machine translation quality (nieen and ney (2001), koehn and knight (2003), <papid> E03-1076 </papid>zollmann et al (2006), <papid> N06-2051 </papid>among others, for various languages; goldwater and mcclosky (2005), <papid> H05-1085 </papid>bojar et al (2006) and talbot and osborne(2006) <papid> P06-1122 </papid>for czech), however, they focus on translating from the highly inflectional language.durgar el-kahlout and oflazer (2006) report preliminary experiments in english to turkish single factored phrase-based translation, gaining significant improvements by splitting root words and their morphemes into sequence of tokens.</citsent>
<aftsection>
<nextsent>in might be interesting to explore multi-factored scenarios for different turkish morphology representation suggested the paper.
</nextsent>
<nextsent>de gispert et al (2005) generalize over verb form sand generate phrase translations even for unseen target verb forms.
</nextsent>
<nextsent>the t+t+g scenario allows similar extension if the described generation step is replaced by (probabilistic) morphological generator.nguyen and shimazu (2006) translate from english to vietnamese but the morphological richness of vietnamese is comparable to english.
</nextsent>
<nextsent>in fact the vietnamese vocabulary size is even smaller than english vocabulary size in one of their corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD952">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>in fact the vietnamese vocabulary size is even smaller than english vocabulary size in one of their corpora.
</prevsent>
<prevsent>the observed improvement due to explicit modelling of morphology might not scale up beyond small-data setting.
</prevsent>
</prevsection>
<citsent citstr=" P98-1035 ">
as an alternative option to our verb-modifier experiments, structured language models (chelba and jelinek, 1998) <papid> P98-1035 </papid>might be considered to improve clause coherence, until full-featured syntax-based mt models (yamada and knight (2002), <papid> P02-1039 </papid>eisner (2003), <papid> P03-2041 </papid>chiang (2005) <papid> P05-1033 </papid>among many others) are tested when translating to morphologically rich lan guages.</citsent>
<aftsection>
<nextsent>we experimented with multi-factored phrase-basedtranslation aimed at improving morphological coherence in mt output.
</nextsent>
<nextsent>we varied the setup of additional factors (translation scenario) and the level of detail in morphological tags.
</nextsent>
<nextsent>our results onenglish-to-czech translation demonstrate significant improvement in bleu scores by explicit modelling of morphology and using separate morphological language model to ensure the coherence.
</nextsent>
<nextsent>to our knowledge, this is one of the first experiments showing the advantages of using multiple factors in mt.verb-modifier errors have been studied and factor capturing verb-modifier dependencies has been proposed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD953">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>in fact the vietnamese vocabulary size is even smaller than english vocabulary size in one of their corpora.
</prevsent>
<prevsent>the observed improvement due to explicit modelling of morphology might not scale up beyond small-data setting.
</prevsent>
</prevsection>
<citsent citstr=" P02-1039 ">
as an alternative option to our verb-modifier experiments, structured language models (chelba and jelinek, 1998) <papid> P98-1035 </papid>might be considered to improve clause coherence, until full-featured syntax-based mt models (yamada and knight (2002), <papid> P02-1039 </papid>eisner (2003), <papid> P03-2041 </papid>chiang (2005) <papid> P05-1033 </papid>among many others) are tested when translating to morphologically rich lan guages.</citsent>
<aftsection>
<nextsent>we experimented with multi-factored phrase-basedtranslation aimed at improving morphological coherence in mt output.
</nextsent>
<nextsent>we varied the setup of additional factors (translation scenario) and the level of detail in morphological tags.
</nextsent>
<nextsent>our results onenglish-to-czech translation demonstrate significant improvement in bleu scores by explicit modelling of morphology and using separate morphological language model to ensure the coherence.
</nextsent>
<nextsent>to our knowledge, this is one of the first experiments showing the advantages of using multiple factors in mt.verb-modifier errors have been studied and factor capturing verb-modifier dependencies has been proposed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD954">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>in fact the vietnamese vocabulary size is even smaller than english vocabulary size in one of their corpora.
</prevsent>
<prevsent>the observed improvement due to explicit modelling of morphology might not scale up beyond small-data setting.
</prevsent>
</prevsection>
<citsent citstr=" P03-2041 ">
as an alternative option to our verb-modifier experiments, structured language models (chelba and jelinek, 1998) <papid> P98-1035 </papid>might be considered to improve clause coherence, until full-featured syntax-based mt models (yamada and knight (2002), <papid> P02-1039 </papid>eisner (2003), <papid> P03-2041 </papid>chiang (2005) <papid> P05-1033 </papid>among many others) are tested when translating to morphologically rich lan guages.</citsent>
<aftsection>
<nextsent>we experimented with multi-factored phrase-basedtranslation aimed at improving morphological coherence in mt output.
</nextsent>
<nextsent>we varied the setup of additional factors (translation scenario) and the level of detail in morphological tags.
</nextsent>
<nextsent>our results onenglish-to-czech translation demonstrate significant improvement in bleu scores by explicit modelling of morphology and using separate morphological language model to ensure the coherence.
</nextsent>
<nextsent>to our knowledge, this is one of the first experiments showing the advantages of using multiple factors in mt.verb-modifier errors have been studied and factor capturing verb-modifier dependencies has been proposed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD955">
<title id=" W07-0735.xml">englishtoczech factored machine translation </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>in fact the vietnamese vocabulary size is even smaller than english vocabulary size in one of their corpora.
</prevsent>
<prevsent>the observed improvement due to explicit modelling of morphology might not scale up beyond small-data setting.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
as an alternative option to our verb-modifier experiments, structured language models (chelba and jelinek, 1998) <papid> P98-1035 </papid>might be considered to improve clause coherence, until full-featured syntax-based mt models (yamada and knight (2002), <papid> P02-1039 </papid>eisner (2003), <papid> P03-2041 </papid>chiang (2005) <papid> P05-1033 </papid>among many others) are tested when translating to morphologically rich lan guages.</citsent>
<aftsection>
<nextsent>we experimented with multi-factored phrase-basedtranslation aimed at improving morphological coherence in mt output.
</nextsent>
<nextsent>we varied the setup of additional factors (translation scenario) and the level of detail in morphological tags.
</nextsent>
<nextsent>our results onenglish-to-czech translation demonstrate significant improvement in bleu scores by explicit modelling of morphology and using separate morphological language model to ensure the coherence.
</nextsent>
<nextsent>to our knowledge, this is one of the first experiments showing the advantages of using multiple factors in mt.verb-modifier errors have been studied and factor capturing verb-modifier dependencies has been proposed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD956">
<title id=" W07-0909.xml">cross lingual and semantic retrieval for cultural heritage appreciation </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>in order to answer the question who wrote incidental music??.
</prevsent>
<prevsent>this type of reasoning has been identified as core semantic inference task by the generic textual entailment framework (dagan et al, 2006; bar-haim et al, 2006).
</prevsent>
</prevsection>
<citsent citstr=" C02-1161 ">
the typical way to address variability in ir is to use lexical query expansion (lytinen et al, 2000; zukerman and raskutti, 2002).<papid> C02-1161 </papid></citsent>
<aftsection>
<nextsent>however, there are variability patterns that cannot be described using just constant phrase to phrase entailment.
</nextsent>
<nextsent>another important type of knowledge representation is entailment rules and paraphrases.
</nextsent>
<nextsent>an entailment rule is directional relation between two templates, text patterns with variables, e.g., compose x write ?.
</nextsent>
<nextsent>the left hand side is assumed to entail the right hand side in certain contexts, under the same variable instantiation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD957">
<title id=" W07-0909.xml">cross lingual and semantic retrieval for cultural heritage appreciation </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>in the above example.
</prevsent>
<prevsent>this need sparked intensive research on automatic acquisition of paraphrase and entailment rules.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
although knowledge-bases of entailment-rules and paraphrases learned by acquisition algorithms were used in other nlp applications, such as qa (lin and pantel, 2001; ravichandran and hovy, 2002) <papid> P02-1006 </papid>and ie (sudo et al, 2003;<papid> P03-1029 </papid>romano et al, 2006), <papid> E06-1052 </papid>to the best of our knowledge the output of such algorithms was never applied to ir before.</citsent>
<aftsection>
<nextsent>2.2 cross lingual information retrieval.
</nextsent>
<nextsent>the difficulties caused by variability are amplified when the user is not native speaker of the language in which the retrieved texts are written.
</nextsent>
<nextsent>for example, while most israelis can read english documents,fewer are comfortable with the specification of english queries.
</nextsent>
<nextsent>in museum setting, some visitors maybe able to read hebrew documents but still be relatively poor at searching for them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD958">
<title id=" W07-0909.xml">cross lingual and semantic retrieval for cultural heritage appreciation </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>in the above example.
</prevsent>
<prevsent>this need sparked intensive research on automatic acquisition of paraphrase and entailment rules.
</prevsent>
</prevsection>
<citsent citstr=" P03-1029 ">
although knowledge-bases of entailment-rules and paraphrases learned by acquisition algorithms were used in other nlp applications, such as qa (lin and pantel, 2001; ravichandran and hovy, 2002) <papid> P02-1006 </papid>and ie (sudo et al, 2003;<papid> P03-1029 </papid>romano et al, 2006), <papid> E06-1052 </papid>to the best of our knowledge the output of such algorithms was never applied to ir before.</citsent>
<aftsection>
<nextsent>2.2 cross lingual information retrieval.
</nextsent>
<nextsent>the difficulties caused by variability are amplified when the user is not native speaker of the language in which the retrieved texts are written.
</nextsent>
<nextsent>for example, while most israelis can read english documents,fewer are comfortable with the specification of english queries.
</nextsent>
<nextsent>in museum setting, some visitors maybe able to read hebrew documents but still be relatively poor at searching for them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD960">
<title id=" W07-0909.xml">cross lingual and semantic retrieval for cultural heritage appreciation </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>in the above example.
</prevsent>
<prevsent>this need sparked intensive research on automatic acquisition of paraphrase and entailment rules.
</prevsent>
</prevsection>
<citsent citstr=" E06-1052 ">
although knowledge-bases of entailment-rules and paraphrases learned by acquisition algorithms were used in other nlp applications, such as qa (lin and pantel, 2001; ravichandran and hovy, 2002) <papid> P02-1006 </papid>and ie (sudo et al, 2003;<papid> P03-1029 </papid>romano et al, 2006), <papid> E06-1052 </papid>to the best of our knowledge the output of such algorithms was never applied to ir before.</citsent>
<aftsection>
<nextsent>2.2 cross lingual information retrieval.
</nextsent>
<nextsent>the difficulties caused by variability are amplified when the user is not native speaker of the language in which the retrieved texts are written.
</nextsent>
<nextsent>for example, while most israelis can read english documents,fewer are comfortable with the specification of english queries.
</nextsent>
<nextsent>in museum setting, some visitors maybe able to read hebrew documents but still be relatively poor at searching for them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD962">
<title id=" W07-0909.xml">cross lingual and semantic retrieval for cultural heritage appreciation </title>
<section> coping with semantic variability in ir.  </section>
<citcontext>
<prevsection>
<prevsent>we would like to retrieve only documents that describe an occurrence of that predicate, but possibly in words different than the ones used in the query.
</prevsent>
<prevsent>in this section we describe in detail how we learn entailment rules and how we apply them in query expansion.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
automatically learning entailment rules fromthe web many algorithms for automatically learning paraphrases and entailment rules have been explored in recent years (lin and pantel, 2001; 1http://jakarta.apache.org/lucene/docs/index.html 67 ravichandran and hovy, 2002; <papid> P02-1006 </papid>shinyama et al, 2002; barzilay and lee, 2003; <papid> N03-1003 </papid>sudo et al, 2003;<papid> P03-1029 </papid>szpektor et al, 2004; <papid> W04-3206 </papid>satoshi, 2005).</citsent>
<aftsection>
<nextsent>in this paper we use tease (szpektor et al, 2004), <papid> W04-3206 </papid>state of-the-art unsupervised acquisition algorithm for lexical-syntactic entailment rules.</nextsent>
<nextsent>tease acquires entailment relations forgiven input template from the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD964">
<title id=" W07-0909.xml">cross lingual and semantic retrieval for cultural heritage appreciation </title>
<section> coping with semantic variability in ir.  </section>
<citcontext>
<prevsection>
<prevsent>we would like to retrieve only documents that describe an occurrence of that predicate, but possibly in words different than the ones used in the query.
</prevsent>
<prevsent>in this section we describe in detail how we learn entailment rules and how we apply them in query expansion.
</prevsent>
</prevsection>
<citsent citstr=" W04-3206 ">
automatically learning entailment rules fromthe web many algorithms for automatically learning paraphrases and entailment rules have been explored in recent years (lin and pantel, 2001; 1http://jakarta.apache.org/lucene/docs/index.html 67 ravichandran and hovy, 2002; <papid> P02-1006 </papid>shinyama et al, 2002; barzilay and lee, 2003; <papid> N03-1003 </papid>sudo et al, 2003;<papid> P03-1029 </papid>szpektor et al, 2004; <papid> W04-3206 </papid>satoshi, 2005).</citsent>
<aftsection>
<nextsent>in this paper we use tease (szpektor et al, 2004), <papid> W04-3206 </papid>state of-the-art unsupervised acquisition algorithm for lexical-syntactic entailment rules.</nextsent>
<nextsent>tease acquires entailment relations forgiven input template from the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD966">
<title id=" W07-2096.xml">upvsi word sense induction using self term expansion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>different other approaches have made use of similar procedure.
</prevsent>
<prevsent>by using dictionaries, the proposals presented in (lesk, 1986; wilks et al., 1990; nancy and veronis, 1990) are the most sucessful in wsd.
</prevsent>
</prevsection>
<citsent citstr=" C92-2070 ">
yarowsky (yarowsky, 1992)<papid> C92-2070 </papid>used instead thesauri for their experiments.</citsent>
<aftsection>
<nextsent>finally, in (sussna, 1993; resnik, 1995; <papid> W95-0105 </papid>banerjee and pedersen, 2002) the use of lexicons in wsd has been investigated.</nextsent>
<nextsent>although in some cases the knowledge resource seems not to be used strictly for term expansion, the aplicationof co-occurrence terms is included in their algorithms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD967">
<title id=" W07-2096.xml">upvsi word sense induction using self term expansion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by using dictionaries, the proposals presented in (lesk, 1986; wilks et al., 1990; nancy and veronis, 1990) are the most sucessful in wsd.
</prevsent>
<prevsent>yarowsky (yarowsky, 1992)<papid> C92-2070 </papid>used instead thesauri for their experiments.</prevsent>
</prevsection>
<citsent citstr=" W95-0105 ">
finally, in (sussna, 1993; resnik, 1995; <papid> W95-0105 </papid>banerjee and pedersen, 2002) the use of lexicons in wsd has been investigated.</citsent>
<aftsection>
<nextsent>although in some cases the knowledge resource seems not to be used strictly for term expansion, the aplicationof co-occurrence terms is included in their algorithms.
</nextsent>
<nextsent>like in information retrieval, the application of term expansion in wsd by using co related terms has shown to improve the baseline results if we carefully select the external resource to use, with priori knowledge of the domain and the broadness of the corpus (wide or narrow domain).
</nextsent>
<nextsent>even more, we have to be sure that the lexical database (ldb) has been suitable constructed.
</nextsent>
<nextsent>due to the last facts, we consider that the use of self automatically constructed ldb (using the same test corpora), may be of high benefit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD968">
<title id=" W07-2096.xml">upvsi word sense induction using self term expansion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>due to the last facts, we consider that the use of self automatically constructed ldb (using the same test corpora), may be of high benefit.
</prevsent>
<prevsent>this assumption is based on the intrinsic properties extracted from the corpus it self.
</prevsent>
</prevsection>
<citsent citstr=" W04-2406 ">
our proposal is related somehow with the investigations presented in (schutze, 1998) and (purandare and pedersen, 2004), <papid> W04-2406 </papid>where words are also expanded with co-ocurrence terms for word sense discrimination.</citsent>
<aftsection>
<nextsent>the main difference consists in the use of the same corpora for constructing the co-ocurrence list.following we describe the self term expansion method used and, thereafter, the results obtained in the task #2 of semeval 2007 competition.
</nextsent>
<nextsent>in literature, co-ocurrence terms is the most common technique used for automatic construction of ldbs (grefenstette, 1994; frakes and baeza-yates, 1992).
</nextsent>
<nextsent>a simple approach may use n-grams, which allows to predict word from previous words in sample of text.
</nextsent>
<nextsent>the frequency of each n-gram is calculated and then filtered according to some threshold.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD969">
<title id=" W07-2096.xml">upvsi word sense induction using self term expansion </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the first measure is called unsupervised one, and it is based on the fscore measure.
</prevsent>
<prevsent>whereas the second measure is called supervised recall.
</prevsent>
</prevsection>
<citsent citstr=" W06-3814 ">
for further information on how these measures are calculated refer to (agirre et al,2006<papid> W06-3814 </papid>a; agirre et al, 2006<papid> W06-3814 </papid>b).</citsent>
<aftsection>
<nextsent>since these measures give conflicting information, two different evaluation results are reported in this paper.in table 2 we may see our ranking and the fs core measure obtained (upv-si).
</nextsent>
<nextsent>we also show the best and worst team fscores; as well as the total average and two baselines proposed by the task organizers.
</nextsent>
<nextsent>the first baseline (baseline1) assumes that each ambiguous word has only one sense, whereas the second baseline (baseline2) is random assignation of senses.
</nextsent>
<nextsent>we are ranked as third place and our results are better scored than the other teams except for the best team score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD973">
<title id=" W07-1529.xml">shared corpora working group report </title>
<section> the wikipedia xml corpus.  </section>
<citcontext>
<prevsection>
<prevsent>the articles are multilingual (cf.
</prevsent>
<prevsent>section 3.4) 5.
</prevsent>
</prevsection>
<citsent citstr=" W07-0201 ">
and the corpus has various other properties that many researchers feel would be interesting to exploit.to date research in computational linguistics using wikipedia includes: automatic derivation of taxonomy information (strube and ponzetto, 2006; suchanek et al, 2007; zesch and gurevych, 2007; <papid> W07-0201 </papid>ponzetto, 2007); <papid> N07-3003 </papid>automatic recognition of pairs of similar sentences in two languages (adafre and de rijke, 2006); corpus mining (rudiger gleim and alexander mehler and matthias dehmer, 2007), named entity recognition (toral and noz, 2007; bunescu and pasca, 2007) and relation extraction (nguyen et al, 2007).<papid> N07-2032 </papid></citsent>
<aftsection>
<nextsent>in addition several shared tasks have been set up using wikipedia as the target corpus including question answering (cf.
</nextsent>
<nextsent>(d. ahn and v. jijkoun and g. mishne and k. muller and m. de rijke and s. schlobach, 2004) and http://ilps.science.uva.nl/wiqa/); and information retrieval (fuhr et al, 2006).
</nextsent>
<nextsent>some other interesting properties of wikipedia that have yet to be explored to our knowledge include: (1) most main articles have talk pages which discuss them ? perhaps this relation can be exploited by systems which try to detect discussions about topics, e.g., searches for discussions about current events topics; (2) there are various meta tags, many of which are not included in the wikipedia xml (see below), but nevertheless are retrievable from the original htmlfiles.
</nextsent>
<nextsent>some of these may be useful for various applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD974">
<title id=" W07-1529.xml">shared corpora working group report </title>
<section> the wikipedia xml corpus.  </section>
<citcontext>
<prevsection>
<prevsent>the articles are multilingual (cf.
</prevsent>
<prevsent>section 3.4) 5.
</prevsent>
</prevsection>
<citsent citstr=" N07-3003 ">
and the corpus has various other properties that many researchers feel would be interesting to exploit.to date research in computational linguistics using wikipedia includes: automatic derivation of taxonomy information (strube and ponzetto, 2006; suchanek et al, 2007; zesch and gurevych, 2007; <papid> W07-0201 </papid>ponzetto, 2007); <papid> N07-3003 </papid>automatic recognition of pairs of similar sentences in two languages (adafre and de rijke, 2006); corpus mining (rudiger gleim and alexander mehler and matthias dehmer, 2007), named entity recognition (toral and noz, 2007; bunescu and pasca, 2007) and relation extraction (nguyen et al, 2007).<papid> N07-2032 </papid></citsent>
<aftsection>
<nextsent>in addition several shared tasks have been set up using wikipedia as the target corpus including question answering (cf.
</nextsent>
<nextsent>(d. ahn and v. jijkoun and g. mishne and k. muller and m. de rijke and s. schlobach, 2004) and http://ilps.science.uva.nl/wiqa/); and information retrieval (fuhr et al, 2006).
</nextsent>
<nextsent>some other interesting properties of wikipedia that have yet to be explored to our knowledge include: (1) most main articles have talk pages which discuss them ? perhaps this relation can be exploited by systems which try to detect discussions about topics, e.g., searches for discussions about current events topics; (2) there are various meta tags, many of which are not included in the wikipedia xml (see below), but nevertheless are retrievable from the original htmlfiles.
</nextsent>
<nextsent>some of these may be useful for various applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD975">
<title id=" W07-1529.xml">shared corpora working group report </title>
<section> the wikipedia xml corpus.  </section>
<citcontext>
<prevsection>
<prevsent>the articles are multilingual (cf.
</prevsent>
<prevsent>section 3.4) 5.
</prevsent>
</prevsection>
<citsent citstr=" N07-2032 ">
and the corpus has various other properties that many researchers feel would be interesting to exploit.to date research in computational linguistics using wikipedia includes: automatic derivation of taxonomy information (strube and ponzetto, 2006; suchanek et al, 2007; zesch and gurevych, 2007; <papid> W07-0201 </papid>ponzetto, 2007); <papid> N07-3003 </papid>automatic recognition of pairs of similar sentences in two languages (adafre and de rijke, 2006); corpus mining (rudiger gleim and alexander mehler and matthias dehmer, 2007), named entity recognition (toral and noz, 2007; bunescu and pasca, 2007) and relation extraction (nguyen et al, 2007).<papid> N07-2032 </papid></citsent>
<aftsection>
<nextsent>in addition several shared tasks have been set up using wikipedia as the target corpus including question answering (cf.
</nextsent>
<nextsent>(d. ahn and v. jijkoun and g. mishne and k. muller and m. de rijke and s. schlobach, 2004) and http://ilps.science.uva.nl/wiqa/); and information retrieval (fuhr et al, 2006).
</nextsent>
<nextsent>some other interesting properties of wikipedia that have yet to be explored to our knowledge include: (1) most main articles have talk pages which discuss them ? perhaps this relation can be exploited by systems which try to detect discussions about topics, e.g., searches for discussions about current events topics; (2) there are various meta tags, many of which are not included in the wikipedia xml (see below), but nevertheless are retrievable from the original htmlfiles.
</nextsent>
<nextsent>some of these may be useful for various applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD976">
<title id=" W07-1317.xml">creating a comparative dictionary of totonactepehua </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our objective is to provide tools for rapid construction of comparative dictionaries for relatively unfamiliar language families.
</prevsent>
<prevsent>identification of cognates and recurrent sound correspondences is component of two principal tasksof historical linguistics: demonstrating the relatedness of languages, and reconstructing the histories of language families.
</prevsent>
</prevsection>
<citsent citstr=" J94-3004 ">
manually compiling the list of cognates is an error-prone and time-consuming task.several methods for constructing comparative dictionaries have been proposed and applied to specific language families: algonquian (hewson, 1974), yuman (johnson, 1985), tamang (lowe and mazaudon, 1994), <papid> J94-3004 </papid>and malayo-javanic (oakes, 2000).most of those methods crucially depend on previously determined regular sound correspondences; each of them was both developed and tested on single language family.</citsent>
<aftsection>
<nextsent>kondrak (2002) proposes number of algorithms for automatically detecting and quantifying three characteristics of cognates: recurrent sound correspondences, phonetic similarity, and semantic affinity.
</nextsent>
<nextsent>the algorithms were tested on two well-studied language families: indo-european and algonquian.in this paper, we apply them instead to set of languages whose mutual relationship is still being investigated.
</nextsent>
<nextsent>this is consistent with the original research goal of providing tools for the analysis of relatively unfamiliar languages represented by word lists.
</nextsent>
<nextsent>we show that by combining expert linguistic knowledge with computational analysis, it is possible to quickly identify large number of cognate sets within relatively little-studied language family.the experiments reported in this paper were performed in the context of the upper necaxa totonac project (beck, 2005), of which one of the authors isthe principal investigator.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD977">
<title id=" W07-1317.xml">creating a comparative dictionary of totonactepehua </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>the similarity value is normalized by the length of the longer word.1for the determination of recurrent sound correspondences we employ the method of inducing translation model between phonemes in two wordlists.
</prevsent>
<prevsent>the idea is to relate recurrent sound correspondences in word lists to translational equivalences inbitexts.
</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
the translation model is induced by combining the maximum similarity alignment with the competitive linking algorithm of melamed (2000).<papid> J00-2004 </papid>mela meds approach is based on the one-to-one assumption, which implies that every word in the bi text is aligned with at most one word on the other side of the bitext.</citsent>
<aftsection>
<nextsent>in the context of the bilingual word lists, the correspondences determined under the one-to-one assumption are restricted to link single phonemes to single phonemes.
</nextsent>
<nextsent>nevertheless, the method is powerful enough to determine valid correspondences in word lists in which the fraction of cognate pairs is well below 50%.
</nextsent>
<nextsent>1another possibility is normalization by the length of the longest alignment (heeringa et al, 2006).<papid> W06-1108 </papid></nextsent>
<nextsent>136 because of the lack of totonac gold standard, the approach to computing semantic similarity of glosses was much simpler than in (kondrak, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD978">
<title id=" W07-1317.xml">creating a comparative dictionary of totonactepehua </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>in the context of the bilingual word lists, the correspondences determined under the one-to-one assumption are restricted to link single phonemes to single phonemes.
</prevsent>
<prevsent>nevertheless, the method is powerful enough to determine valid correspondences in word lists in which the fraction of cognate pairs is well below 50%.
</prevsent>
</prevsection>
<citsent citstr=" W06-1108 ">
1another possibility is normalization by the length of the longest alignment (heeringa et al, 2006).<papid> W06-1108 </papid></citsent>
<aftsection>
<nextsent>136 because of the lack of totonac gold standard, the approach to computing semantic similarity of glosses was much simpler than in (kondrak, 2002).
</nextsent>
<nextsent>the keyword selection heuristic was simply to pick the first word of the gloss, which in spanish glosses is often noun followed by modifiers.
</nextsent>
<nextsent>a complete gloss match was given double the weight of key word match.
</nextsent>
<nextsent>more complex semantic relations were not considered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD979">
<title id=" W08-0127.xml">evaluation understudy for dialogue coherence models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this allows developers to use the automatic metric as stand-in for human evaluation.
</prevsent>
<prevsent>although it cannot replace the finesse of human evaluation, it can provide crude idea of progress which can later be validated.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
e.g. bleu (papineni et al, 2001) for machine translation, rouge (lin, 2004) <papid> W04-1013 </papid>for summarization.recently, the discourse coherence modeling community has started using the information ordering task as testbed to test their discourse coherence models (barzilay and lapata, 2005; <papid> P05-1018 </papid>soricut andmarcu, 2006).<papid> P06-2103 </papid></citsent>
<aftsection>
<nextsent>lapata (2006) has proposed an au 172tomatic evaluation measure for the information ordering task.
</nextsent>
<nextsent>we propose to use the same task as atestbed for dialogue coherence modeling.
</nextsent>
<nextsent>we evaluate the reliability of the information ordering task as applied to dialogues and propose an evaluation understudy for dialogue coherence models.
</nextsent>
<nextsent>in the next section, we look at related work in evaluation of dialogue systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD980">
<title id=" W08-0127.xml">evaluation understudy for dialogue coherence models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this allows developers to use the automatic metric as stand-in for human evaluation.
</prevsent>
<prevsent>although it cannot replace the finesse of human evaluation, it can provide crude idea of progress which can later be validated.
</prevsent>
</prevsection>
<citsent citstr=" P05-1018 ">
e.g. bleu (papineni et al, 2001) for machine translation, rouge (lin, 2004) <papid> W04-1013 </papid>for summarization.recently, the discourse coherence modeling community has started using the information ordering task as testbed to test their discourse coherence models (barzilay and lapata, 2005; <papid> P05-1018 </papid>soricut andmarcu, 2006).<papid> P06-2103 </papid></citsent>
<aftsection>
<nextsent>lapata (2006) has proposed an au 172tomatic evaluation measure for the information ordering task.
</nextsent>
<nextsent>we propose to use the same task as atestbed for dialogue coherence modeling.
</nextsent>
<nextsent>we evaluate the reliability of the information ordering task as applied to dialogues and propose an evaluation understudy for dialogue coherence models.
</nextsent>
<nextsent>in the next section, we look at related work in evaluation of dialogue systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD981">
<title id=" W08-0127.xml">evaluation understudy for dialogue coherence models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this allows developers to use the automatic metric as stand-in for human evaluation.
</prevsent>
<prevsent>although it cannot replace the finesse of human evaluation, it can provide crude idea of progress which can later be validated.
</prevsent>
</prevsection>
<citsent citstr=" P06-2103 ">
e.g. bleu (papineni et al, 2001) for machine translation, rouge (lin, 2004) <papid> W04-1013 </papid>for summarization.recently, the discourse coherence modeling community has started using the information ordering task as testbed to test their discourse coherence models (barzilay and lapata, 2005; <papid> P05-1018 </papid>soricut andmarcu, 2006).<papid> P06-2103 </papid></citsent>
<aftsection>
<nextsent>lapata (2006) has proposed an au 172tomatic evaluation measure for the information ordering task.
</nextsent>
<nextsent>we propose to use the same task as atestbed for dialogue coherence modeling.
</nextsent>
<nextsent>we evaluate the reliability of the information ordering task as applied to dialogues and propose an evaluation understudy for dialogue coherence models.
</nextsent>
<nextsent>in the next section, we look at related work in evaluation of dialogue systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD982">
<title id=" W08-0127.xml">evaluation understudy for dialogue coherence models </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>other efforts in saving human involvement in evaluation include using simulated users for testing (eckert et al, 1997).
</prevsent>
<prevsent>this has become popular tool for systems employing reinforcement learning (levin et al, 1997; williams and young, 2006).
</prevsent>
</prevsection>
<citsent citstr=" N07-2038 ">
some of the methods involved in user simulation are as complex as building dialogue systems themselves (schatzmann et al, 2007).<papid> N07-2038 </papid></citsent>
<aftsection>
<nextsent>user simulations also need to be evaluated as how closely they model human behavior (georgila et al, 2006) or as howgood predictor they are of dialogue system performance (williams, 2007).some researchers have proposed metrics for evaluating dialogue model in task-oriented system.
</nextsent>
<nextsent>(henderson et al, 2005) used the number of slots in frame filled and/or confirmed.
</nextsent>
<nextsent>roque et al (2006)proposed hand-annotating information-states in dialogue to evaluate the accuracy of information state updates.
</nextsent>
<nextsent>such measures make assumptions about the underlying dialogue model being used (e.g., form-based or information-state based etc.).we are more interested in evaluating types of dialogue systems that do not follow these task-basedassumptions: systems designed to imitate human human conversations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD983">
<title id=" W08-0127.xml">evaluation understudy for dialogue coherence models </title>
<section> information ordering.  </section>
<citcontext>
<prevsection>
<prevsent>the information ordering task consists of choosing presentation sequence for set of information bearing elements.
</prevsent>
<prevsent>this task is well suited for text to-text generation like in single or multi-document summarization (barzilay et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
recently there has been lot of work in discourse coherence modeling (lapata, 2003; <papid> P03-1069 </papid>barzilay and lap ata, 2005; <papid> P05-1018 </papid>soricut and marcu, 2006) <papid> P06-2103 </papid>that has used 173information ordering to test the coherence models.</citsent>
<aftsection>
<nextsent>the information-bearing elements here are sentences rather than high-level concepts.
</nextsent>
<nextsent>this frees the models from having to depend on hard to get training corpus which has been hand-authored for concepts.
</nextsent>
<nextsent>most of the dialogue models still work at the higher abstraction level of dialogue acts and intentions.
</nextsent>
<nextsent>but with an increasing number of dialogue systems finding use in non-traditional applications such as simulation training, games, etc.; there is need for dialogue models which do not depend on hand-authored corpora or rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD987">
<title id=" W08-0127.xml">evaluation understudy for dialogue coherence models </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>? seems to overestimate the coherence even in the absence of immediate local coherence (see third entry in table 1).
</prevsent>
<prevsent>itseems that local context is more important for dialogues than for discourse, which may follow from the fact that dialogues are produced by two speakers who must react to each other, while discourse can be planned by one speaker from the beginning.
</prevsent>
</prevsection>
<citsent citstr=" P94-1001 ">
trauma nd allen (1994) <papid> P94-1001 </papid>point out that such social obligations to respond and address the contributions of the other should be an important factor in building dialogue systems.</citsent>
<aftsection>
<nextsent>the information ordering paradigm does not take into account the content of the information-bearing items, e.g. the fact that turns like yes?, agree?,5this value is calculated by considering all 14400 permutations as equally likely.
</nextsent>
<nextsent>177(a) histogram of ken dalls ? for reordered se quences(b) histogram of fraction of bigrams &amp; trigrams values for reordered sequences figure 3: experiment 3 - upper baseline for information ordering task (human performance) okay?
</nextsent>
<nextsent>perform the same function and should be treated as replaceable.
</nextsent>
<nextsent>this may suggest need to modify some of the objective measures to evaluate the information ordering specially for dialogue systems that involve more of such utterances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD988">
<title id=" W08-0127.xml">evaluation understudy for dialogue coherence models </title>
<section> conclusion &amp; future work.  </section>
<citcontext>
<prevsection>
<prevsent>it will also be interesting to see the role cohesive devices play incoherence ratings.
</prevsent>
<prevsent>we would like to see if there are any other measures or certain modifications to the current ones that correlate better with human judgments.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we also plan to employ this evaluation metric as feedback in building dialogue coherence models as is done in machine translation (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>acknowledgments the effort described here has been sponsored by the u.s. army research, development, and engineering command (rde com).
</nextsent>
<nextsent>statements and opinions expressed do not necessarily reflect the position or the policy of the united states government, and no official endorsement should be inferred.
</nextsent>
<nextsent>we would like to thank radu soricut, ron artstein, and the anonymous sigdial reviewers for helpful comments.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD989">
<title id=" W07-1215.xml">extracting a verb lexicon for deep parsing from framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we identify range of constructions for which current annotation practice leads to problems in deriving appropriate lexical entries,for example imperatives, pass ives and control, and discuss potential solutions.
</prevsent>
<prevsent>although the lexicon is the primary source of information in lexicalised formalisms such as hpsg orccg, constructing one manually is highly labour intensive task.
</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
syntactic lexicons have been derived from other resources ? the lingo erg lexicon (copestake and flickinger, 2000) contains entries extracted from comlex (grishman et al, 1994), <papid> C94-1042 </papid>and hockenmaier and steedman (2002) acquire ccg lexicon from the penn treebank.</citsent>
<aftsection>
<nextsent>however, one thing these resources lack is information on how the syntactic subcategorisation frames correspond to meaning.
</nextsent>
<nextsent>the output representation of many deep?
</nextsent>
<nextsent>wide coverage parsers is therefore limited with respect to argument structure ? sense distinctions are strictly determined by syntactic generalisations, and arenot always consistent.
</nextsent>
<nextsent>for example, in the logical form produced by the lingo erg grammar,the verb end can have one of two senses depending on its subcategorisation frame: end 1 relor end cause rel, corresponding to the celebrations ended and the storm ended the celebrations respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD990">
<title id=" W07-1215.xml">extracting a verb lexicon for deep parsing from framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, in the logical form produced by the lingo erg grammar,the verb end can have one of two senses depending on its subcategorisation frame: end 1 relor end cause rel, corresponding to the celebrations ended and the storm ended the celebrations respectively.
</prevsent>
<prevsent>yet very similar verb, stop, hasa single sense, stop 1 rel, for both the celebrations stopped and the storm stopped the celebrations.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
there is no direct connection between these different verbs in the erg lexicon, even though they are intuitively related and are listed as belonging to the same or related word classes in semantic lexicons/ontologies such as verbnet (kipper et al, 2000) and framenet (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>if the output of deep parser is to be used witha knowledge representation and reasoning component, for example in dialogue system, then we needa more consistent set of word senses, linked by specified semantic relations.
</nextsent>
<nextsent>in this paper, we investigate how straightforward it is to harvest computational lexicon containing this kind of information from framenet, semantically annotated corpus of english.
</nextsent>
<nextsent>in addition, we consider how the framenet annotation system could be made more transparent for lexical harvesting.
</nextsent>
<nextsent>section 2 introduces the framenet corpus, and section 3 discusses the lexical information required by frame-based nlu systems, with particular emphasis on linking syntactic and semantic structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD991">
<title id=" W07-1215.xml">extracting a verb lexicon for deep parsing from framenet </title>
<section> implementation and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>this lexicon has been successfully used with the trips parser, but additional work remains to be done before the conversion process is complete.
</prevsent>
<prevsent>for example, we need more sophisticated approach to resolving the complement-modifier distinction, along with means of integrating the framenet semantic types with the trips ontology so the parser can use selectional restrictions to disambiguate.the discussion in this paper has been mainly focused on extracting entries for deep lexicons using frame-based nlu, but similar issues have been faced also by the developers of shallow semantic parsers from semantically annotated corpora.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
for example, gildea and jurafsky (2002) <papid> J02-3001 </papid>found that identifying pass ives was important in training semantic role classifier from framenet, using parser trained on the penn treebank along with set of templates to distinguish passive constructions from active ones.</citsent>
<aftsection>
<nextsent>similarly, chen and rambow (2003) <papid> W03-1006 </papid>argue that the kind of deep linguistic features we harvest from framenet is beneficial for the successful assignment of propbank roles to constituents, in this case using tags generated from propbank to generate the relevant features.</nextsent>
<nextsent>from this perspective, our harvested lexicon can be seen as providing acleaned-up?, filtered version of framenet for training semantic interpreters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD992">
<title id=" W07-1215.xml">extracting a verb lexicon for deep parsing from framenet </title>
<section> implementation and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>for example, we need more sophisticated approach to resolving the complement-modifier distinction, along with means of integrating the framenet semantic types with the trips ontology so the parser can use selectional restrictions to disambiguate.the discussion in this paper has been mainly focused on extracting entries for deep lexicons using frame-based nlu, but similar issues have been faced also by the developers of shallow semantic parsers from semantically annotated corpora.
</prevsent>
<prevsent>for example, gildea and jurafsky (2002) <papid> J02-3001 </papid>found that identifying pass ives was important in training semantic role classifier from framenet, using parser trained on the penn treebank along with set of templates to distinguish passive constructions from active ones.</prevsent>
</prevsection>
<citsent citstr=" W03-1006 ">
similarly, chen and rambow (2003) <papid> W03-1006 </papid>argue that the kind of deep linguistic features we harvest from framenet is beneficial for the successful assignment of propbank roles to constituents, in this case using tags generated from propbank to generate the relevant features.</citsent>
<aftsection>
<nextsent>from this perspective, our harvested lexicon can be seen as providing acleaned-up?, filtered version of framenet for training semantic interpreters.
</nextsent>
<nextsent>it may also be utilised to provide information for separate lexical interpretation and disambiguation module to be built on top of syntactic parser.
</nextsent>
<nextsent>we have developed both procedure and framework-independent representation schema for harvesting lexical information for deep nlp systems from the framenet semantically annotated corpus.in examining the feasibility of this approach to increasing lexical coverage, we have identified number of constructions for which current framenet annotation practice leads to problems in deriving appropriate lexical entries, for example imperatives, pass ives and control.
</nextsent>
<nextsent>the work reported here was supported by grantsn000140510043 and n000140510048 from the office of naval research.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD993">
<title id=" W07-1017.xml">automatic code assignment to medical text </title>
<section> code assignment system.  </section>
<citcontext>
<prevsection>
<prevsent>a feature indicating each n-gram sequence that appears in both the impression and clinical his tory; the conjunction of certain terms where one appears in the history and the other in the impression (e.g. cough in history and pneumonia in impression?).
</prevsent>
<prevsent>3.1.2 learning technique using these feature representations, we now learn weight vector that scores the correct labelings of the data higher than incorrect labelings.
</prevsent>
</prevsection>
<citsent citstr=" H05-1124 ">
we used k-best version of the mira algorithm (crammer, 2004; mcdonald et al, 2005).<papid> H05-1124 </papid></citsent>
<aftsection>
<nextsent>mira is an online learning algorithm that for each training document updates the weight vector according to the rule: wnew = argmin w ? wold?
</nextsent>
<nextsent>s.t. ? yk,wold(x) : ? f(x, y?(x)) ? ? f(x, y) ? l(y?(x), y)where l(y?(x), y) is measure of the loss of labeling with respect to the correct labeling y?(x).
</nextsent>
<nextsent>for our experiments, we set to 30 and iterated over the training data 10 times.
</nextsent>
<nextsent>two standard modifications to this approach also helped.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD994">
<title id=" W08-0130.xml">making grammar based generation easier to deploy in dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in terms of adequacy of coverage, in principle,grammar-based generation offers significant advantages over template-based or canned text output by providing productive coverage and greater variety.however, realizing these advantages can require significant development costs.
</prevsent>
<prevsent>specifying the necessary connections between lexico-syntactic resource sand the flat, domain-specific semantic representations that are typically available in implemented systems is subtle, labor-intensive, and knowledge intensive process for which attractive methodologies do not yet exist (reiter et al, 2003).one strategy is to hand-build an application specific grammar.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
however, in our experience, this process requires painstaking, time-consuming effort by developer who has detailed linguistic knowledge as well as detailed domain knowledge, and the resulting coverage is inevitably limited.wide-coverage generators that aim for applicabil 198 ity across application domains (white et al, 2007; zhong and stent, 2005; langkilde-geary, 2002;langkilde and knight, 1998; <papid> P98-1116 </papid>elhadad, 1991) provide grammar (or language model) for free.</citsent>
<aftsection>
<nextsent>however, it is harder to tailor output to the desired wording and style for specific dialogue system, and these generators demand specific input format that is otherwise foreign to an existing dialogue system.
</nextsent>
<nextsent>unfortunately, in our experience, the development burden of implementing the translation between the systems available meaning representations and the generators required input format is quite substantial.
</nextsent>
<nextsent>indeed, implementing the translation might require as much effort as would be required to build asimple custom generator; cf.
</nextsent>
<nextsent>(callaway, 2003; busemann and horacek, 1998).<papid> W98-1425 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD995">
<title id=" W08-0130.xml">making grammar based generation easier to deploy in dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, in our experience, the development burden of implementing the translation between the systems available meaning representations and the generators required input format is quite substantial.
</prevsent>
<prevsent>indeed, implementing the translation might require as much effort as would be required to build asimple custom generator; cf.
</prevsent>
</prevsection>
<citsent citstr=" W98-1425 ">
(callaway, 2003; busemann and horacek, 1998).<papid> W98-1425 </papid></citsent>
<aftsection>
<nextsent>this development cost is exacerbated when dialogue systems native meaning representation scheme is under revision.in this paper, we survey new example-based approach (devault et al, 2008) that we have developed in order to mitigate these difficulties, so that grammar-based generation can be deployed more widely in implemented dialogue systems.
</nextsent>
<nextsent>our development pipeline requires system developer to create set of training examples which directly connect desired output texts to available application semantic forms.
</nextsent>
<nextsent>this is achieved through astreamlined authoring task that does not require detailed linguistic knowledge.
</nextsent>
<nextsent>our approach then processes these training examples to automatically construct all the resources needed for fast, high quality, run-time grammar-based generation component.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD996">
<title id=" W08-0130.xml">making grammar based generation easier to deploy in dialogue systems </title>
<section> technical approach.  </section>
<citcontext>
<prevsection>
<prevsent>suggests the output utterance = we dont have medical supplies here captain.
</prevsent>
<prevsent>each utterance is accompanied by syntax(u), syntactic analysis in penn treebank format (marcus et al, 1994).
</prevsent>
</prevsection>
<citsent citstr=" P01-1017 ">
in this example, the syntax is hand-corrected version of the output of the charniak parser (charniak, 2001; <papid> P01-1017 </papid>charniak, 2005) on this sentence; we discuss this hand correction in section 4.to represent the meaning of utterances, our approach assumes that the system provides some set = {m1, ...,mj} of semantic representations.</citsent>
<aftsection>
<nextsent>the meaning of any individual utterance is then identified with some subset of . for doctor perez, comprises the 232 distinct key-value pairs that appear in the systems various generation frames.
</nextsent>
<nextsent>in this example, the utterances meaning is captured by the 8 key-value pairs indicated in the figure.
</nextsent>
<nextsent>our approach requires the generation content author to link these 8 key-value pairs to contiguous surface expressions within the utterance.the technique is flexible about which surface expressions are chosen (e.g. they need not correspond to constituent boundaries); however, they do need to be compatible with the way the syntactic analysis tokenizes the utterance, as follows.
</nextsent>
<nextsent>lett(u) = t1, ..., tn?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD997">
<title id=" W08-0130.xml">making grammar based generation easier to deploy in dialogue systems </title>
<section> technical approach.  </section>
<citcontext>
<prevsection>
<prevsent>our algorithm for selecting features and weights is based on the search optimization algorithm of (daum?
</prevsent>
<prevsent>and marcu, 2005), which decides to update feature weights when mistakes are made during search on training examples.
</prevsent>
</prevsection>
<citsent citstr=" J05-1003 ">
we use the boosting approach of (collins and koo, 2005) <papid> J05-1003 </papid>to perform feature selection and identify good weight values.</citsent>
<aftsection>
<nextsent>in the introduction, we identified run-time speed, adequacy of coverage, authoring burdens, and nlg request specification as important factors in the selection of technology for dialogue systems nlgcomponent.
</nextsent>
<nextsent>in this section, we evaluate our technique along these four dimensions.hand-authored utterances.
</nextsent>
<nextsent>we collected sample of 220 instances of frames that doctor perezs dialogue manager had requested of the generation component in previous dialogues with users.
</nextsent>
<nextsent>some frames occurred more than once in this sample.each frame was associated with single hand authored utterance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD998">
<title id=" W08-0130.xml">making grammar based generation easier to deploy in dialogue systems </title>
<section> empirical evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>for each training set, we trained our generator on the 198 training examples.we then generated single (highest-ranked) utterance for each example in both the test and trainingsets.
</prevsent>
<prevsent>the generator sometimes failed to find successful utterance within the 200ms timeout; the success rate of our generator was 95% for training ex 202 amples and 80% for test examples.
</prevsent>
</prevsection>
<citsent citstr=" W06-1303 ">
the successful utterances were rated by our judges.sentence retriever is based on the cross language information retrieval techniques described in (leuski et al, 2006), <papid> W06-1303 </papid>and is currently in use for doctor perezs nlg problem.</citsent>
<aftsection>
<nextsent>sentence retriever does not exploit any hierarchical syntactic analysis of utterances.
</nextsent>
<nextsent>instead, sentence retriever views nlg as an information retrieval task in which setof training utterances are the documents?
</nextsent>
<nextsent>to be retrieved, and the frame to be expressed is the query.
</nextsent>
<nextsent>at run-time, the algorithm functions essentially as classifier: it uses relative entropy metric to select the highest ranking training utterance for the frame that doctor perez wishes to express.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD999">
<title id=" W07-2073.xml">uazsa web page clustering on the basis of name disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the basis of this information, the web pages can be clustered together and organized in hierarchical structure which can ease the documents?
</prevsent>
<prevsent>browsing.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
this is also the objective of the web people search (weps) task (artiles et al, 2007).<papid> W07-2012 </papid></citsent>
<aftsection>
<nextsent>what makes the wepstask even more challenging is the fact that in contrast to wsd where the number of senses of word are predefined, in weps we do not know the exact number of different individuals.for the resolution of the weps task, we have developed web page clustering approach using the title and the body content of the web pages.
</nextsent>
<nextsent>in addition, we group together the documents that share many location, person and organization names, as well as those that point out to the same sub-links.
</nextsent>
<nextsent>the rest of the paper is organized as follows.
</nextsent>
<nextsent>in section 2 we describe various approaches for name disambiguation and discrimination.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1000">
<title id=" W07-2073.xml">uazsa web page clustering on the basis of name disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in section 2 we describe various approaches for name disambiguation and discrimination.
</prevsent>
<prevsent>our approach is shown in section 3, the obtained results and discussion are provided in section 4 and finally we conclude in section 5.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
early work in the field of name disambiguation is that of (bagga and baldwin, 1998) <papid> P98-1012 </papid>who proposed cross-document coreference resolution algorithm which uses vector space model to resolve the ambiguities between people sharing the same name.</citsent>
<aftsection>
<nextsent>the approach is evaluated on 35 different mentions of john smith and reaches 85% f-score.mann and yarowski (2003) <papid> W03-0405 </papid>developed an unsu 338</nextsent>
<nextsent>html/xml cleaning search web retrieved documents preprocessing title context information body text proper names links clusters k-means cluster analysis weka lsa matrix transformation clustering on the basis of name disambiguation matrix from context figure 1: architecture of the weps systempervised approach to name discrimination where biographical features (age, date of birth), familiar relationships (wife, son, daughter) and associations (country, company, organization) are considered.therefore, in our approach we use person, organization and location names in order to construct social similarity network between two documents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1001">
<title id=" W07-2073.xml">uazsa web page clustering on the basis of name disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our approach is shown in section 3, the obtained results and discussion are provided in section 4 and finally we conclude in section 5.
</prevsent>
<prevsent>early work in the field of name disambiguation is that of (bagga and baldwin, 1998) <papid> P98-1012 </papid>who proposed cross-document coreference resolution algorithm which uses vector space model to resolve the ambiguities between people sharing the same name.</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
the approach is evaluated on 35 different mentions of john smith and reaches 85% f-score.mann and yarowski (2003) <papid> W03-0405 </papid>developed an unsu 338</citsent>
<aftsection>
<nextsent>html/xml cleaning search web retrieved documents preprocessing title context information body text proper names links clusters k-means cluster analysis weka lsa matrix transformation clustering on the basis of name disambiguation matrix from context figure 1: architecture of the weps systempervised approach to name discrimination where biographical features (age, date of birth), familiar relationships (wife, son, daughter) and associations (country, company, organization) are considered.therefore, in our approach we use person, organization and location names in order to construct social similarity network between two documents.
</nextsent>
<nextsent>another unsupervised clustering technique forname discrimination of web pages is that of pedersen and kulkarni (2007).
</nextsent>
<nextsent>they used contextual vectors derived from bigrams, and measured the impact of several association measures.
</nextsent>
<nextsent>during the evaluation, some names were easily discriminable compared to others categories for which was even difficult to find and obtain discriminative feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1002">
<title id=" W07-2049.xml">melbkb nominal classification as noun compound interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goal of the nominal classification task is to identify the compatibility of given semantic relation with each of set of test nominal pairs, e.g. between climate and forest in the fragment the climate in the forest with respect to the content container relation.
</prevsent>
<prevsent>semantic relations (or srs) in nominals represent the underlying interpretation of the nominal, in the form of the directed relation between the two nominals.
</prevsent>
</prevsection>
<citsent citstr=" C94-2125 ">
the proposed task is generalisation of the more conventional task of interpreting noun compounds (ncs), in which we take nc such as cookie jar and interpret it according to pre-defined inventory of semantic relations (levi, 1979; vanderwende, 1994;<papid> C94-2125 </papid>barker and szpakowicz, 1998).<papid> P98-1015 </papid></citsent>
<aftsection>
<nextsent>examples of semantic relations are make,1, as exemplified in apple pie where the pie is made from apple(s), and possessor, as exemplified in family car where the car is possessed by family.
</nextsent>
<nextsent>in the semeval-2007 task, sr interpretation takes the form of binary decision forgiven nominal pair in context and given sr, in judging whether that nominal pair conforms to the sr. seven relations were used in the task: cause-effect, instrument-agency,product-producer, origin-entity, theme tool, part-whole and content-container.
</nextsent>
<nextsent>our approach to the task was to: (1) naively treat all nominal pairs as ncs (e.g. the climate in the forest is treated as an instance of climate forest); and (2) translate the individual binary classification tasks into single multiclass classification task, in the interests of benchmarking existing sr interpretation methods over common dataset.
</nextsent>
<nextsent>that is, we take all positive training instances for each sr and pool them together into single training dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1003">
<title id=" W07-2049.xml">melbkb nominal classification as noun compound interpretation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goal of the nominal classification task is to identify the compatibility of given semantic relation with each of set of test nominal pairs, e.g. between climate and forest in the fragment the climate in the forest with respect to the content container relation.
</prevsent>
<prevsent>semantic relations (or srs) in nominals represent the underlying interpretation of the nominal, in the form of the directed relation between the two nominals.
</prevsent>
</prevsection>
<citsent citstr=" P98-1015 ">
the proposed task is generalisation of the more conventional task of interpreting noun compounds (ncs), in which we take nc such as cookie jar and interpret it according to pre-defined inventory of semantic relations (levi, 1979; vanderwende, 1994;<papid> C94-2125 </papid>barker and szpakowicz, 1998).<papid> P98-1015 </papid></citsent>
<aftsection>
<nextsent>examples of semantic relations are make,1, as exemplified in apple pie where the pie is made from apple(s), and possessor, as exemplified in family car where the car is possessed by family.
</nextsent>
<nextsent>in the semeval-2007 task, sr interpretation takes the form of binary decision forgiven nominal pair in context and given sr, in judging whether that nominal pair conforms to the sr. seven relations were used in the task: cause-effect, instrument-agency,product-producer, origin-entity, theme tool, part-whole and content-container.
</nextsent>
<nextsent>our approach to the task was to: (1) naively treat all nominal pairs as ncs (e.g. the climate in the forest is treated as an instance of climate forest); and (2) translate the individual binary classification tasks into single multiclass classification task, in the interests of benchmarking existing sr interpretation methods over common dataset.
</nextsent>
<nextsent>that is, we take all positive training instances for each sr and pool them together into single training dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1005">
<title id=" W07-2049.xml">melbkb nominal classification as noun compound interpretation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>we then describe and discuss the performance of our methods in section 5 and conclude the paper in section 6.
</prevsent>
<prevsent>we used two basic nc interpretation methods.
</prevsent>
</prevsection>
<citsent citstr=" W04-2609 ">
the first method uses sense collocations as proposed by moldovan et al (2004), <papid> W04-2609 </papid>and the second method uses the lexical similarity of the component words in the nc as proposed by kim and baldwin (2005).</citsent>
<aftsection>
<nextsent>note that neither method uses the context of usage of the nc, i.e. the only features are the words contained in the nc.
</nextsent>
<nextsent>2.1 sense collocation method.
</nextsent>
<nextsent>moldovan et al (2004) <papid> W04-2609 </papid>proposed method called semantic scattering for interpreting ncs.</nextsent>
<nextsent>the intuition behind this method is that when the sense collocation of ncs is the same, their sr is most likely thesame.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1007">
<title id=" W07-2049.xml">melbkb nominal classification as noun compound interpretation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>?)s2 + s2)) 2 (3) where s1 is the modifier similarity (i.e. s(ni,1, bj1)) and s2 is head noun similarity 232 (i.e. s(ni,2, bj2)); ? ?
</prevsent>
<prevsent>[0, 1] is weighting factor.
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
the similarity scores are calculated using the method of wu and palmer (1994) <papid> P94-1019 </papid>as implemented in wordnet::similarity (patwardhan et al, 2003).</citsent>
<aftsection>
<nextsent>this is done for each pairing of wordnet senses of each of the two words in question, and the overall lexical similarity is calculated as the average across the pairwise sense similarities.
</nextsent>
<nextsent>the final classification is derived from the training instance which has the highest lexical similarity with the test instance in question.
</nextsent>
<nextsent>as with many semantic annotation tasks, sr tagging is time-consuming and expensive process.
</nextsent>
<nextsent>at the same time, due to the inherent complexity of the sr interpretation task, we require large amounts of training data in order for our methods to perform well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1008">
<title id=" W07-1601.xml">a corpus based analysis of geometric constraints on projective prepositions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the literature, we find two paradigms for defining spatial orientation relations: the orthogonal projection paradigm and the angular deviation paradigm.
</prevsent>
<prevsent>for each paradigm we review simple model and define different levels of granularity.
</prevsent>
</prevsection>
<citsent citstr=" A92-1008 ">
the limitations of these simple models have been discussed at length, and more complex models have been proposed (kelleher, 2003; schmidtke, 2001; crawford et al, 2000; mats akis and wend ling, 1999; fuhr et al, 1995; abella and kender, 1993; wazinski, 1992).<papid> A92-1008 </papid></citsent>
<aftsection>
<nextsent>nonetheless, it will turn out that ro s nenw e sesw(a) orthogonal projection model.
</nextsent>
<nextsent>e n s(b) angular deviation model.
</nextsent>
<nextsent>figure 2: definition of directions.we can find for each simple model level of granu larity which covers more than 96% of the data.
</nextsent>
<nextsent>orthogonal projection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1009">
<title id=" W07-0812.xml">improved arabic base phrase chunking with a new enriched pos tag set </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using the erts pos tagset, bpc achieves the highest overall f?=1 of 96.33% on 10 different chunk types outperforming the use of the standard pos tag set even when explicit morphological features are present.
</prevsent>
<prevsent>base phrase chunking (bpc), also known as shallow syntactic parsing, is the process by which adjacent words are grouped together to form non recursive chunks in sentence.
</prevsent>
</prevsection>
<citsent citstr=" N03-2009 ">
the base chunks form phrases such as verb phrases, noun phrases and adjective phrases, etc. an english example of base phrases is [i]np [would eat]v [red lusciousapples]np [on sundays]pp . the bpc task is proving to be an enabling step that is useful to many natural language processing (nlp) applications suchas information extraction and semantic role labeling (hacioglu &amp; ward, 2003).<papid> N03-2009 </papid></citsent>
<aftsection>
<nextsent>in english, these applications have shown robust relative performance when exploiting bpc when compared to using full syntactic parses.
</nextsent>
<nextsent>in general, bpc is appealing asan enabling technology since state of the art performance for bpc is higher (f?=1 95.48%) than that for full syntactic parsing (f?=1 90.02% ) in english(collins, 2000; kudo &amp; matsu mato, 2000).
</nextsent>
<nextsent>more over, since bpc had been cast as classification problem by ramshaw and marcus (1995), <papid> W95-0107 </papid>the task is performed with greater efficiency and is easily portable to new languages in supervised manner (diab et al , 2004; <papid> N04-4038 </papid>diab et al , 2007).</nextsent>
<nextsent>for arabic,bpc is especially interesting as it constitutes viable alternative to full syntactic parsing due to thelow performance in arabic full syntactic parsing (la beled f?=1 = 80% compared to f?=1=91.44% for bpc) (bikel, 2004; <papid> J04-4004 </papid>diab et al , 2007; kulick et al , 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1011">
<title id=" W07-0812.xml">improved arabic base phrase chunking with a new enriched pos tag set </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in english, these applications have shown robust relative performance when exploiting bpc when compared to using full syntactic parses.
</prevsent>
<prevsent>in general, bpc is appealing asan enabling technology since state of the art performance for bpc is higher (f?=1 95.48%) than that for full syntactic parsing (f?=1 90.02% ) in english(collins, 2000; kudo &amp; matsu mato, 2000).
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
more over, since bpc had been cast as classification problem by ramshaw and marcus (1995), <papid> W95-0107 </papid>the task is performed with greater efficiency and is easily portable to new languages in supervised manner (diab et al , 2004; <papid> N04-4038 </papid>diab et al , 2007).</citsent>
<aftsection>
<nextsent>for arabic,bpc is especially interesting as it constitutes viable alternative to full syntactic parsing due to thelow performance in arabic full syntactic parsing (la beled f?=1 = 80% compared to f?=1=91.44% for bpc) (bikel, 2004; <papid> J04-4004 </papid>diab et al , 2007; kulick et al , 2006).</nextsent>
<nextsent>in this paper, we present support vector machine (svm) based supervised method for arabic bpc.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1015">
<title id=" W07-0812.xml">improved arabic base phrase chunking with a new enriched pos tag set </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in english, these applications have shown robust relative performance when exploiting bpc when compared to using full syntactic parses.
</prevsent>
<prevsent>in general, bpc is appealing asan enabling technology since state of the art performance for bpc is higher (f?=1 95.48%) than that for full syntactic parsing (f?=1 90.02% ) in english(collins, 2000; kudo &amp; matsu mato, 2000).
</prevsent>
</prevsection>
<citsent citstr=" N04-4038 ">
more over, since bpc had been cast as classification problem by ramshaw and marcus (1995), <papid> W95-0107 </papid>the task is performed with greater efficiency and is easily portable to new languages in supervised manner (diab et al , 2004; <papid> N04-4038 </papid>diab et al , 2007).</citsent>
<aftsection>
<nextsent>for arabic,bpc is especially interesting as it constitutes viable alternative to full syntactic parsing due to thelow performance in arabic full syntactic parsing (la beled f?=1 = 80% compared to f?=1=91.44% for bpc) (bikel, 2004; <papid> J04-4004 </papid>diab et al , 2007; kulick et al , 2006).</nextsent>
<nextsent>in this paper, we present support vector machine (svm) based supervised method for arabic bpc.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1016">
<title id=" W07-0812.xml">improved arabic base phrase chunking with a new enriched pos tag set </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in general, bpc is appealing asan enabling technology since state of the art performance for bpc is higher (f?=1 95.48%) than that for full syntactic parsing (f?=1 90.02% ) in english(collins, 2000; kudo &amp; matsu mato, 2000).
</prevsent>
<prevsent>more over, since bpc had been cast as classification problem by ramshaw and marcus (1995), <papid> W95-0107 </papid>the task is performed with greater efficiency and is easily portable to new languages in supervised manner (diab et al , 2004; <papid> N04-4038 </papid>diab et al , 2007).</prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
for arabic,bpc is especially interesting as it constitutes viable alternative to full syntactic parsing due to thelow performance in arabic full syntactic parsing (la beled f?=1 = 80% compared to f?=1=91.44% for bpc) (bikel, 2004; <papid> J04-4004 </papid>diab et al , 2007; kulick et al , 2006).</citsent>
<aftsection>
<nextsent>in this paper, we present support vector machine (svm) based supervised method for arabic bpc.
</nextsent>
<nextsent>the new bpc system achieves an f?=1 of 96.33% across 10 base phrase chunk types.
</nextsent>
<nextsent>we vary the feature sets along two different factors: the usage of explicit morphological features, and the use of different part of speech (pos) tag sets.
</nextsent>
<nextsent>we introduce new enriched pos set for arabic which comprises 75 pos tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1021">
<title id=" W07-0812.xml">improved arabic base phrase chunking with a new enriched pos tag set </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most successful approaches are based on machine learning technique sand sequence modeling of the different labels associated with the chunks.
</prevsent>
<prevsent>both generative algorithms such as hmms and multilevel markov models, as well as, discriminative methods such as support vector machines (svm) and conditional random fields have been used for the bpc task.
</prevsent>
</prevsection>
<citsent citstr=" W00-0730 ">
the closest relevant approach to the current investigation is the work of kudo and matsu mato (2000) (<papid> W00-0730 </papid>km00) on using svms and sequence model for chunking.</citsent>
<aftsection>
<nextsent>a la ramshaw and marcus (1995), <papid> W95-0107 </papid>they represent the words as sequence of labeled words with iobannotations, where the marks word at the beginning of chunk, marks word inside chunk, ando marks those words (and punctuation) that are outside chunks.</nextsent>
<nextsent>the iob annotation scheme for the english example described earlier is illustrated in table 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1036">
<title id=" W07-0812.xml">improved arabic base phrase chunking with a new enriched pos tag set </title>
<section> current approach.  </section>
<citcontext>
<prevsection>
<prevsent>it maintains voice and tense for verbs, and some number information for nouns, namely, marking plural vs. singular for nouns and proper nouns.
</prevsent>
<prevsent>therefore, in the process it masks duality for nouns and number for all adjectives.
</prevsent>
</prevsection>
<citsent citstr=" P05-1071 ">
it should be noted, however, that it is extremely useful to have these morphological tags in order to induce features.there exists system that produces the full morphological pos tag set, mada, with very high accuracy, 96% (habash &amp; rambow, 2005).<papid> P05-1071 </papid>in this work, we introduce new tag set that explicitly marks gender, number, and definite ness for nominals (namely, nouns, proper nouns, adjective sand pronouns).</citsent>
<aftsection>
<nextsent>verbs, particles, as well as, the person feature on pronouns, are not affected by this enrichment process, since neither person nor mood are 2dan bikel, personal communication.
</nextsent>
<nextsent>explicitly encoded.
</nextsent>
<nextsent>morphological case is also not explicitly encoded in erts.
</nextsent>
<nextsent>the new tag set, erts, is derived from the full tag set where there is an explicit specification in the tag itself for the different features to be encoded.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1041">
<title id=" W07-0812.xml">improved arabic base phrase chunking with a new enriched pos tag set </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 data.
</prevsent>
<prevsent>the dev, test and training data are obtained from atb1v3, atb2v2 and atb3v2 (maamouri etal., 2004).
</prevsent>
</prevsection>
<citsent citstr=" E06-1047 ">
we adopt the same data splits introduced by chiang et. al (2006).<papid> E06-1047 </papid></citsent>
<aftsection>
<nextsent>the corpora are all news genre.
</nextsent>
<nextsent>the total development data comprises 2304 sentences and 70188 tokens, the total training data comprises 18970 sentences and 594683 tokens, and the total test data comprises 2337 sentences and 69665 tokens.
</nextsent>
<nextsent>we use the unvocalized buckwalter transliterated version of the atb.
</nextsent>
<nextsent>for both pos tagging and bpc, we use the gold annotations of the training and test data for preprocessing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1045">
<title id=" W07-0727.xml">the isl phrase based mt system for the 2007 acl workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>interactive systems laboratories participated in the english ? spanish europarl and news commentary task as well as in the english ? german eu roparl task.
</prevsent>
<prevsent>this paper describes the phrase-based machine translation (mt) system that was applied to these tasks.
</prevsent>
</prevsection>
<citsent citstr=" W07-0731 ">
we also investigate the feasibility of combining the isl syntax-augmented mt system(zollmann et al, 2007) <papid> W07-0731 </papid>with our phrase-based system by combining and rescoring the n-best lists produced by both systems for the spanish ? englisheuroparl task.</citsent>
<aftsection>
<nextsent>furthermore, we apply the same combination technique to combine two of our phrase based systems that operate on different source languages (spanish and german), but share the same target language (english).
</nextsent>
<nextsent>the paper is organized as follows.
</nextsent>
<nextsent>in section 2 wegive general description of our phrase-based statistical machine translation system.
</nextsent>
<nextsent>section 3 gives an overview of the data and of the final systems used for the english ? spanish europarl and news commentary tasks, along with corresponding performance numbers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1046">
<title id=" W07-0727.xml">the isl phrase based mt system for the 2007 acl workshop on statistical machine translation </title>
<section> the isl phrase-based mt system.  </section>
<citcontext>
<prevsection>
<prevsent>in section 5, we present our experiments involving combination of the syntax-augmented mt system with the phrase-based mt system and combination of the spanish ? english and german ? english phrase-based systems.
</prevsent>
<prevsent>2.1 word and phrase alignment.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
phrase-to-phrase translation pairs are extracted by training ibm model-4 word alignments in both directions, using the giza++ toolkit (och and ney, 2000), <papid> P00-1056 </papid>and then extracting phrase pair candidates which are consistent with these alignments, starting from the intersection of both alignments.</citsent>
<aftsection>
<nextsent>this is done with the help of phrase model training code provided by university of edinburgh during the naacl 2006 workshop on statistical machine translation (koehn and monz, 2006).<papid> W06-3114 </papid></nextsent>
<nextsent>the raw rel 197ative frequency estimates found in the phrase translation tables are then smoothed by applying modified kneser-ney discounting as explained in (foster et al, 2006).<papid> W06-1607 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1047">
<title id=" W07-0727.xml">the isl phrase based mt system for the 2007 acl workshop on statistical machine translation </title>
<section> the isl phrase-based mt system.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 word and phrase alignment.
</prevsent>
<prevsent>phrase-to-phrase translation pairs are extracted by training ibm model-4 word alignments in both directions, using the giza++ toolkit (och and ney, 2000), <papid> P00-1056 </papid>and then extracting phrase pair candidates which are consistent with these alignments, starting from the intersection of both alignments.</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
this is done with the help of phrase model training code provided by university of edinburgh during the naacl 2006 workshop on statistical machine translation (koehn and monz, 2006).<papid> W06-3114 </papid></citsent>
<aftsection>
<nextsent>the raw rel 197ative frequency estimates found in the phrase translation tables are then smoothed by applying modified kneser-ney discounting as explained in (foster et al, 2006).<papid> W06-1607 </papid></nextsent>
<nextsent>the resulting phrase translation tables are pruned by using the combined translation model score as determined by minimum error rate (mer) optimization on the development set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1048">
<title id=" W07-0727.xml">the isl phrase based mt system for the 2007 acl workshop on statistical machine translation </title>
<section> the isl phrase-based mt system.  </section>
<citcontext>
<prevsection>
<prevsent>phrase-to-phrase translation pairs are extracted by training ibm model-4 word alignments in both directions, using the giza++ toolkit (och and ney, 2000), <papid> P00-1056 </papid>and then extracting phrase pair candidates which are consistent with these alignments, starting from the intersection of both alignments.</prevsent>
<prevsent>this is done with the help of phrase model training code provided by university of edinburgh during the naacl 2006 workshop on statistical machine translation (koehn and monz, 2006).<papid> W06-3114 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-1607 ">
the raw rel 197ative frequency estimates found in the phrase translation tables are then smoothed by applying modified kneser-ney discounting as explained in (foster et al, 2006).<papid> W06-1607 </papid></citsent>
<aftsection>
<nextsent>the resulting phrase translation tables are pruned by using the combined translation model score as determined by minimum error rate (mer) optimization on the development set.
</nextsent>
<nextsent>2.2 word reordering.
</nextsent>
<nextsent>we apply part-of-speech (pos) based reordering scheme (j. m. crego et al, 2006) <papid> W06-3125 </papid>to the pos-tagged source sentences before decoding.</nextsent>
<nextsent>for this, we use the giza++ alignments and the pos-tagged source side of the training corpus to learn reordering rules that achieve (locally) monotone alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1049">
<title id=" W07-0727.xml">the isl phrase based mt system for the 2007 acl workshop on statistical machine translation </title>
<section> the isl phrase-based mt system.  </section>
<citcontext>
<prevsection>
<prevsent>the resulting phrase translation tables are pruned by using the combined translation model score as determined by minimum error rate (mer) optimization on the development set.
</prevsent>
<prevsent>2.2 word reordering.
</prevsent>
</prevsection>
<citsent citstr=" W06-3125 ">
we apply part-of-speech (pos) based reordering scheme (j. m. crego et al, 2006) <papid> W06-3125 </papid>to the pos-tagged source sentences before decoding.</citsent>
<aftsection>
<nextsent>for this, we use the giza++ alignments and the pos-tagged source side of the training corpus to learn reordering rules that achieve (locally) monotone alignment.
</nextsent>
<nextsent>figure 1 shows an example in which three reordering rules are extracted from the pos tags of an english source sentence and its corresponding spanish giza++ alignment.
</nextsent>
<nextsent>before translation, we construct lattices for every source sentence.
</nextsent>
<nextsent>the lattices include the original source sentence along with all the reorderings that are consistent with the learnedrules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1050">
<title id=" W07-0727.xml">the isl phrase based mt system for the 2007 acl workshop on statistical machine translation </title>
<section> the isl phrase-based mt system.  </section>
<citcontext>
<prevsection>
<prevsent>first, all available word and phrase translations are found and inserted into so-called translation lattice.
</prevsent>
<prevsent>then the best combination of these partial translations is found by doing best path search through the translation lattice, where we also allow for word reorderings within predefined local reordering window.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
to optimize the system towards maximal bleu or nist score, we use minimum error rate (mer) training as described in (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>for each model weight, mer applies multi-linear search on the development set n-best list produced by the system.
</nextsent>
<nextsent>due to the limited numbers of translation sin the n-best list, these new model weights are suboptimal.
</nextsent>
<nextsent>to compensate for this, new full translation is done.
</nextsent>
<nextsent>the resulting new n-best list is then merged with the old n-best list and the optimization process is repeated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1051">
<title id=" W07-0727.xml">the isl phrase based mt system for the 2007 acl workshop on statistical machine translation </title>
<section> english? german europarl task.  </section>
<citcontext>
<prevsection>
<prevsent>however, we used only the europarl task development set during optimization.
</prevsent>
<prevsent>to achieve further improvements on the german ? english task, we applied compound splitting technique.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
the compound splitting was based on (koehn and knight, 2003) <papid> E03-1076 </papid>and was applied on the lower cased source sentences.</citsent>
<aftsection>
<nextsent>the words generated by the compound splitting were afterwards true-cased.
</nextsent>
<nextsent>instead of replacing compound by its separate parts, we added parallel path into the source sentence lattices used for translation.
</nextsent>
<nextsent>the source sentence lattices were augmented with score son their edges indicating whether each edge represents word of the original text or if it was generated during compound splitting.
</nextsent>
<nextsent>table 5 shows the case-sensitive bleu scores for the final german ? english systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1052">
<title id=" W07-0727.xml">the isl phrase based mt system for the 2007 acl workshop on statistical machine translation </title>
<section> system combination via n-best list.  </section>
<citcontext>
<prevsection>
<prevsent>in this evaluation, we used several features computed from different information sources such as features from the translation system, additional language models, ibm-1 word lexica and the n-best list itself.
</prevsent>
<prevsent>we calculated 4 features from the ibm-1 word lexica: the word probability sum as well as the maximum word probability in both language directions.
</prevsent>
</prevsection>
<citsent citstr=" H05-1096 ">
from the n-best list itself, we calculated three different sets of scores.a position-dependent word agreement score as described in (ueffing and ney, 2005) <papid> H05-1096 </papid>with position window instead of the levenshtein alignment, the n-best list n-gram probability as described in (zens and ney, 2006) <papid> W06-3110 </papid>and position-independent n-gram agreement, which is variation on the first two.</citsent>
<aftsection>
<nextsent>to tune the feature combination weights, we used mer optimization.rescoring the n-best lists from our individual systems did not give significant improvements on the available unseen development-test data.
</nextsent>
<nextsent>for this reason, we did not apply n-best list rescoring to the individual systems.
</nextsent>
<nextsent>however, we investigated the feasibility of combining two different systems by rescoring the joint n-best lists of both systems.
</nextsent>
<nextsent>the corresponding results are described in the following sections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1053">
<title id=" W07-0727.xml">the isl phrase based mt system for the 2007 acl workshop on statistical machine translation </title>
<section> system combination via n-best list.  </section>
<citcontext>
<prevsection>
<prevsent>in this evaluation, we used several features computed from different information sources such as features from the translation system, additional language models, ibm-1 word lexica and the n-best list itself.
</prevsent>
<prevsent>we calculated 4 features from the ibm-1 word lexica: the word probability sum as well as the maximum word probability in both language directions.
</prevsent>
</prevsection>
<citsent citstr=" W06-3110 ">
from the n-best list itself, we calculated three different sets of scores.a position-dependent word agreement score as described in (ueffing and ney, 2005) <papid> H05-1096 </papid>with position window instead of the levenshtein alignment, the n-best list n-gram probability as described in (zens and ney, 2006) <papid> W06-3110 </papid>and position-independent n-gram agreement, which is variation on the first two.</citsent>
<aftsection>
<nextsent>to tune the feature combination weights, we used mer optimization.rescoring the n-best lists from our individual systems did not give significant improvements on the available unseen development-test data.
</nextsent>
<nextsent>for this reason, we did not apply n-best list rescoring to the individual systems.
</nextsent>
<nextsent>however, we investigated the feasibility of combining two different systems by rescoring the joint n-best lists of both systems.
</nextsent>
<nextsent>the corresponding results are described in the following sections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1055">
<title id=" W07-0810.xml">arabic to french sentence alignment exploration of a cross language information retrieval approach </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>sentence alignment consists in mapping sentences of the source language with their translations in the target language.
</prevsent>
<prevsent>automatic sentence alignment approaches face two kinds of difficulties: robustness and accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P91-1023 ">
a number of automatic sentence alignment techniques have been proposed (kay and rscheisen, 1993; gale and church, 1991; <papid> P91-1023 </papid>brown et al, 1991; <papid> P91-1022 </papid>debili and samouda, 1992; papageorgiou et al, 1994; <papid> P94-1051 </papid>gaussier, 1995; melamed, 1996; <papid> W96-0201 </papid>fluhr et al, 2000).</citsent>
<aftsection>
<nextsent>73 the method proposed in (kay and rscheisen, 1993) is based on the assumption that in order for the sentences in translation to correspond, the words in them must correspond.
</nextsent>
<nextsent>in other words, all necessary information (and in particular, lexical mapping) is derived from the to-be-aligned texts themselves.
</nextsent>
<nextsent>in (gale and church, 1991) <papid> P91-1023 </papid>and (brown et al, 1991), <papid> P91-1022 </papid>the authors start from the fact that the length of source text sentence is highly correlated with the length of its target text translation: short sentences tend to have short translations, and long sentences tend to have long translations.</nextsent>
<nextsent>the method proposed in (debili and sammouda, 1992) is based on the preliminary alignment of words using conventional bilingual lexicon and the method described in (papageorgiou et al, 1994) <papid> P94-1051 </papid>added grammatical labeling based on the assumption that the same parts of speech tend to be employed in the translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1056">
<title id=" W07-0810.xml">arabic to french sentence alignment exploration of a cross language information retrieval approach </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>sentence alignment consists in mapping sentences of the source language with their translations in the target language.
</prevsent>
<prevsent>automatic sentence alignment approaches face two kinds of difficulties: robustness and accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P91-1022 ">
a number of automatic sentence alignment techniques have been proposed (kay and rscheisen, 1993; gale and church, 1991; <papid> P91-1023 </papid>brown et al, 1991; <papid> P91-1022 </papid>debili and samouda, 1992; papageorgiou et al, 1994; <papid> P94-1051 </papid>gaussier, 1995; melamed, 1996; <papid> W96-0201 </papid>fluhr et al, 2000).</citsent>
<aftsection>
<nextsent>73 the method proposed in (kay and rscheisen, 1993) is based on the assumption that in order for the sentences in translation to correspond, the words in them must correspond.
</nextsent>
<nextsent>in other words, all necessary information (and in particular, lexical mapping) is derived from the to-be-aligned texts themselves.
</nextsent>
<nextsent>in (gale and church, 1991) <papid> P91-1023 </papid>and (brown et al, 1991), <papid> P91-1022 </papid>the authors start from the fact that the length of source text sentence is highly correlated with the length of its target text translation: short sentences tend to have short translations, and long sentences tend to have long translations.</nextsent>
<nextsent>the method proposed in (debili and sammouda, 1992) is based on the preliminary alignment of words using conventional bilingual lexicon and the method described in (papageorgiou et al, 1994) <papid> P94-1051 </papid>added grammatical labeling based on the assumption that the same parts of speech tend to be employed in the translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1057">
<title id=" W07-0810.xml">arabic to french sentence alignment exploration of a cross language information retrieval approach </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>sentence alignment consists in mapping sentences of the source language with their translations in the target language.
</prevsent>
<prevsent>automatic sentence alignment approaches face two kinds of difficulties: robustness and accuracy.
</prevsent>
</prevsection>
<citsent citstr=" P94-1051 ">
a number of automatic sentence alignment techniques have been proposed (kay and rscheisen, 1993; gale and church, 1991; <papid> P91-1023 </papid>brown et al, 1991; <papid> P91-1022 </papid>debili and samouda, 1992; papageorgiou et al, 1994; <papid> P94-1051 </papid>gaussier, 1995; melamed, 1996; <papid> W96-0201 </papid>fluhr et al, 2000).</citsent>
<aftsection>
<nextsent>73 the method proposed in (kay and rscheisen, 1993) is based on the assumption that in order for the sentences in translation to correspond, the words in them must correspond.
</nextsent>
<nextsent>in other words, all necessary information (and in particular, lexical mapping) is derived from the to-be-aligned texts themselves.
</nextsent>
<nextsent>in (gale and church, 1991) <papid> P91-1023 </papid>and (brown et al, 1991), <papid> P91-1022 </papid>the authors start from the fact that the length of source text sentence is highly correlated with the length of its target text translation: short sentences tend to have short translations, and long sentences tend to have long translations.</nextsent>
<nextsent>the method proposed in (debili and sammouda, 1992) is based on the preliminary alignment of words using conventional bilingual lexicon and the method described in (papageorgiou et al, 1994) <papid> P94-1051 </papid>added grammatical labeling based on the assumption that the same parts of speech tend to be employed in the translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1058">
<title id=" W07-0810.xml">arabic to french sentence alignment exploration of a cross language information retrieval approach </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>sentence alignment consists in mapping sentences of the source language with their translations in the target language.
</prevsent>
<prevsent>automatic sentence alignment approaches face two kinds of difficulties: robustness and accuracy.
</prevsent>
</prevsection>
<citsent citstr=" W96-0201 ">
a number of automatic sentence alignment techniques have been proposed (kay and rscheisen, 1993; gale and church, 1991; <papid> P91-1023 </papid>brown et al, 1991; <papid> P91-1022 </papid>debili and samouda, 1992; papageorgiou et al, 1994; <papid> P94-1051 </papid>gaussier, 1995; melamed, 1996; <papid> W96-0201 </papid>fluhr et al, 2000).</citsent>
<aftsection>
<nextsent>73 the method proposed in (kay and rscheisen, 1993) is based on the assumption that in order for the sentences in translation to correspond, the words in them must correspond.
</nextsent>
<nextsent>in other words, all necessary information (and in particular, lexical mapping) is derived from the to-be-aligned texts themselves.
</nextsent>
<nextsent>in (gale and church, 1991) <papid> P91-1023 </papid>and (brown et al, 1991), <papid> P91-1022 </papid>the authors start from the fact that the length of source text sentence is highly correlated with the length of its target text translation: short sentences tend to have short translations, and long sentences tend to have long translations.</nextsent>
<nextsent>the method proposed in (debili and sammouda, 1992) is based on the preliminary alignment of words using conventional bilingual lexicon and the method described in (papageorgiou et al, 1994) <papid> P94-1051 </papid>added grammatical labeling based on the assumption that the same parts of speech tend to be employed in the translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1062">
<title id=" W07-0810.xml">arabic to french sentence alignment exploration of a cross language information retrieval approach </title>
<section> the cross-language search engine.  </section>
<citcontext>
<prevsection>
<prevsent>if the word is not found in the general dictionary, it is given default set of morpho-syntactic tags based on its typography.
</prevsent>
<prevsent>for arabic, we added to the morphological analyzer new processing step: clitic stemmer (larkey et al, 2002) which splits aggluti nated words into proclitics, simple forms and enclitics.
</prevsent>
</prevsection>
<citsent citstr=" W02-0506 ">
if the simple form computed by the clitic stemmer does not exist in the general dictionary, re-write rules are applied (darwish, 2002).<papid> W02-0506 </papid></citsent>
<aftsection>
<nextsent>for example, consider the token ?
</nextsent>
<nextsent>(with their ballon) and the included clitics ???
</nextsent>
<nextsent>(with) and ??
</nextsent>
<nextsent>(their), the computed simple form ????
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1063">
<title id=" W07-0810.xml">arabic to french sentence alignment exploration of a cross language information retrieval approach </title>
<section> the cross-language search engine.  </section>
<citcontext>
<prevsection>
<prevsent>non-contiguous expressions such as phrasal verbs in english:  switch on  or  tomber vague ment dans les pommes  in french are recognized too.
</prevsent>
<prevsent>a part-of-speech (pos) tagger which searches valid paths through all the possible tags paths using attested trigrams and bigrams sequences.
</prevsent>
</prevsection>
<citsent citstr=" W05-0705 ">
the trigram and bigram matrices are generated from manually annotated training corpus (grefen stette et al, 2005).<papid> W05-0705 </papid></citsent>
<aftsection>
<nextsent>they are extracted from hand-tagged corpora of 13 200 words for arabic and 25 000 words for french.
</nextsent>
<nextsent>if no continuous trigram full path is found, the pos tagger tries to use bigrams at the points where the trigrams were not found in the matrix.
</nextsent>
<nextsent>the accuracy of the part-of speech tagger is around 91% for arabic and 94% for french.
</nextsent>
<nextsent>a syntactic analyzer which is used to split word graph into nominal and verbal chain and recognize dependency relations (espe cially those within compounds) by using set of syntactic rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1064">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we explore the augmentation of statistical machine translation models with features of the context of each phrase to be translated.
</prevsent>
</prevsection>
<citsent citstr=" P07-1005 ">
this work extends several existing threads of research in statistical mt, including the use of context in example-based machine translation (carl and way, 2003) and the incorporation of word sense disambiguation into translation model (chan et al, 2007).<papid> P07-1005 </papid></citsent>
<aftsection>
<nextsent>the context features we consider use surrounding words and part-of-speech tags, local syntactic structure, and other properties of the source language sentence to help predict each phrases translation.
</nextsent>
<nextsent>our approach requires very little computation beyond the standard phrase extraction algorithm and scales well to large data scenarios.
</nextsent>
<nextsent>we report significant improvement sin automatic evaluation scores for chinese to-english and english-to-german translation, and also describe our entry in the wmt-08 shared task based on this approach.
</nextsent>
<nextsent>machine translation (mt) by statistical modeling of bilingual phrases is one of the most successful approaches in the past few years.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1065">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we report significant improvement sin automatic evaluation scores for chinese to-english and english-to-german translation, and also describe our entry in the wmt-08 shared task based on this approach.
</prevsent>
<prevsent>machine translation (mt) by statistical modeling of bilingual phrases is one of the most successful approaches in the past few years.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
phrase-based mt systems are straightforward to train from parallel corpora (koehn et al, 2003) <papid> N03-1017 </papid>and, like the original ibm models (brown et al, 1990), <papid> J90-2002 </papid>benefit from standard language models built on large monolingual, target-language corpora (brants et al, 2007).<papid> D07-1090 </papid></citsent>
<aftsection>
<nextsent>many of these systems perform well in competitive evaluations and scale well to large-data situations(nist, 2006; callison-burch et al, 2007).
</nextsent>
<nextsent>end-to end phrase-based mt systems can be built entirely from freely-available tools (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>we follow the approach of koehn et al (2003), <papid> N03-1017 </papid>in which we translate source-language sentence into the target-language sentence e?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1066">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we report significant improvement sin automatic evaluation scores for chinese to-english and english-to-german translation, and also describe our entry in the wmt-08 shared task based on this approach.
</prevsent>
<prevsent>machine translation (mt) by statistical modeling of bilingual phrases is one of the most successful approaches in the past few years.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
phrase-based mt systems are straightforward to train from parallel corpora (koehn et al, 2003) <papid> N03-1017 </papid>and, like the original ibm models (brown et al, 1990), <papid> J90-2002 </papid>benefit from standard language models built on large monolingual, target-language corpora (brants et al, 2007).<papid> D07-1090 </papid></citsent>
<aftsection>
<nextsent>many of these systems perform well in competitive evaluations and scale well to large-data situations(nist, 2006; callison-burch et al, 2007).
</nextsent>
<nextsent>end-to end phrase-based mt systems can be built entirely from freely-available tools (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>we follow the approach of koehn et al (2003), <papid> N03-1017 </papid>in which we translate source-language sentence into the target-language sentence e?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1067">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we report significant improvement sin automatic evaluation scores for chinese to-english and english-to-german translation, and also describe our entry in the wmt-08 shared task based on this approach.
</prevsent>
<prevsent>machine translation (mt) by statistical modeling of bilingual phrases is one of the most successful approaches in the past few years.
</prevsent>
</prevsection>
<citsent citstr=" D07-1090 ">
phrase-based mt systems are straightforward to train from parallel corpora (koehn et al, 2003) <papid> N03-1017 </papid>and, like the original ibm models (brown et al, 1990), <papid> J90-2002 </papid>benefit from standard language models built on large monolingual, target-language corpora (brants et al, 2007).<papid> D07-1090 </papid></citsent>
<aftsection>
<nextsent>many of these systems perform well in competitive evaluations and scale well to large-data situations(nist, 2006; callison-burch et al, 2007).
</nextsent>
<nextsent>end-to end phrase-based mt systems can be built entirely from freely-available tools (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>we follow the approach of koehn et al (2003), <papid> N03-1017 </papid>in which we translate source-language sentence into the target-language sentence e?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1068">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>phrase-based mt systems are straightforward to train from parallel corpora (koehn et al, 2003) <papid> N03-1017 </papid>and, like the original ibm models (brown et al, 1990), <papid> J90-2002 </papid>benefit from standard language models built on large monolingual, target-language corpora (brants et al, 2007).<papid> D07-1090 </papid></prevsent>
<prevsent>many of these systems perform well in competitive evaluations and scale well to large-data situations(nist, 2006; callison-burch et al, 2007).</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
end-to end phrase-based mt systems can be built entirely from freely-available tools (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we follow the approach of koehn et al (2003), <papid> N03-1017 </papid>in which we translate source-language sentence into the target-language sentence e?</nextsent>
<nextsent>that maximizes linear combination of features and weights:1 e?, a??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1071">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>= argmax e,a? score(e,a,f) (1) = argmax e,a? m?
</prevsent>
<prevsent>m=1 mhm(e,a,f) (2) where represents the segmentation of and into phrases and correspondence between phrases, and each hm is r-valued feature with learned weight m. the translation is typically found using beam search (koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the weights1, ..., ? are typically learned to directly minimize standard evaluation criterion on development data (e.g., the bleu score; papineni et al, (2002)) <papid> P02-1040 </papid>using numerical search (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>many features are used in phrase-based mt, but nearly ubiquitous are estimates of the conditional translation probabilities p(eji | ` k) and p(f ` | j ) for each phrase pair eji ,f lk?
</nextsent>
<nextsent>in the candidate sentence pair.2 in this paper, we add and evaluate fea 1in the statistical mt literature, this is often referred to as alog-linear model,?
</nextsent>
<nextsent>but since the score is normalized during neither parameter training nor decoding, and is never interpreted as log-probability, it is essentially linear combination of feature functions.
</nextsent>
<nextsent>since many of the features are actually probabilities, this linear combination is closer to mixture model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1072">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>= argmax e,a? score(e,a,f) (1) = argmax e,a? m?
</prevsent>
<prevsent>m=1 mhm(e,a,f) (2) where represents the segmentation of and into phrases and correspondence between phrases, and each hm is r-valued feature with learned weight m. the translation is typically found using beam search (koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the weights1, ..., ? are typically learned to directly minimize standard evaluation criterion on development data (e.g., the bleu score; papineni et al, (2002)) <papid> P02-1040 </papid>using numerical search (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>many features are used in phrase-based mt, but nearly ubiquitous are estimates of the conditional translation probabilities p(eji | ` k) and p(f ` | j ) for each phrase pair eji ,f lk?
</nextsent>
<nextsent>in the candidate sentence pair.2 in this paper, we add and evaluate fea 1in the statistical mt literature, this is often referred to as alog-linear model,?
</nextsent>
<nextsent>but since the score is normalized during neither parameter training nor decoding, and is never interpreted as log-probability, it is essentially linear combination of feature functions.
</nextsent>
<nextsent>since many of the features are actually probabilities, this linear combination is closer to mixture model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1074">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>stroppa et al (2007) added souce-side context features to phrase-based translation system, including conditional probabilities of the same form that we use.
</prevsent>
<prevsent>they consider up to two words and/or pos tagsof context on either side.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
because of the aforementioned data sparseness problem, they use decision3an illustrative example is the debate over the use of bilex icalized grammar rules in statistical parsing (gildea, 2001; <papid> W01-0521 </papid>bikel, 2004).<papid> W04-3224 </papid>tree classifier that implicitly smooths relative frequency estimates.</citsent>
<aftsection>
<nextsent>the method improved over standard phrase-based baseline trained on small amounts of data (  50k sentence pairs) for italian?
</nextsent>
<nextsent>english and chinese ? english.
</nextsent>
<nextsent>we explore significantly larger space of context features, smoothing method that more naturally fits into the widely used, error driven linear model, and report more comprehensive experimental evaluation (including feature comparison and scaling up to very large datasets).recent research on the use of word-sense disambiguation in machine translation also points toward our approach.
</nextsent>
<nextsent>for example, vickrey et al (2005) <papid> H05-1097 </papid>built classifiers inspired by those used in word sense disambiguation to fill in blanks in partially-completed translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1075">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>stroppa et al (2007) added souce-side context features to phrase-based translation system, including conditional probabilities of the same form that we use.
</prevsent>
<prevsent>they consider up to two words and/or pos tagsof context on either side.
</prevsent>
</prevsection>
<citsent citstr=" W04-3224 ">
because of the aforementioned data sparseness problem, they use decision3an illustrative example is the debate over the use of bilex icalized grammar rules in statistical parsing (gildea, 2001; <papid> W01-0521 </papid>bikel, 2004).<papid> W04-3224 </papid>tree classifier that implicitly smooths relative frequency estimates.</citsent>
<aftsection>
<nextsent>the method improved over standard phrase-based baseline trained on small amounts of data (  50k sentence pairs) for italian?
</nextsent>
<nextsent>english and chinese ? english.
</nextsent>
<nextsent>we explore significantly larger space of context features, smoothing method that more naturally fits into the widely used, error driven linear model, and report more comprehensive experimental evaluation (including feature comparison and scaling up to very large datasets).recent research on the use of word-sense disambiguation in machine translation also points toward our approach.
</nextsent>
<nextsent>for example, vickrey et al (2005) <papid> H05-1097 </papid>built classifiers inspired by those used in word sense disambiguation to fill in blanks in partially-completed translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1076">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>english and chinese ? english.
</prevsent>
<prevsent>we explore significantly larger space of context features, smoothing method that more naturally fits into the widely used, error driven linear model, and report more comprehensive experimental evaluation (including feature comparison and scaling up to very large datasets).recent research on the use of word-sense disambiguation in machine translation also points toward our approach.
</prevsent>
</prevsection>
<citsent citstr=" H05-1097 ">
for example, vickrey et al (2005) <papid> H05-1097 </papid>built classifiers inspired by those used in word sense disambiguation to fill in blanks in partially-completed translation.</citsent>
<aftsection>
<nextsent>gimenez and ma`rquez (2007) extended the work by considering phrases and moved to full translation instead of filling in target-side blanks.
</nextsent>
<nextsent>they trained an svm for each source language phrase using local features of the sentences in which the phrases appear.
</nextsent>
<nextsent>carpuat and wu (2007) <papid> D07-1007 </papid>and chan et al (2007) <papid> P07-1005 </papid>embedded state-of-the-art word sense disambiguation modules into statistical mt systems, achieving performance improvements under several automatic measures for chinese ? english translation.our approach is also reminiscent of example based machine translation (nagao, 1984; somers, 1999; carl and way, 2003), which has for many years emphasized use of the context in which source phrases appear when translating them.</nextsent>
<nextsent>indeed, like the example-based community, we do not begin with any set of assumptions about which kinds of phrases require additional disambiguation (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1077">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>gimenez and ma`rquez (2007) extended the work by considering phrases and moved to full translation instead of filling in target-side blanks.
</prevsent>
<prevsent>they trained an svm for each source language phrase using local features of the sentences in which the phrases appear.
</prevsent>
</prevsection>
<citsent citstr=" D07-1007 ">
carpuat and wu (2007) <papid> D07-1007 </papid>and chan et al (2007) <papid> P07-1005 </papid>embedded state-of-the-art word sense disambiguation modules into statistical mt systems, achieving performance improvements under several automatic measures for chinese ? english translation.our approach is also reminiscent of example based machine translation (nagao, 1984; somers, 1999; carl and way, 2003), which has for many years emphasized use of the context in which source phrases appear when translating them.</citsent>
<aftsection>
<nextsent>indeed, like the example-based community, we do not begin with any set of assumptions about which kinds of phrases require additional disambiguation (cf.
</nextsent>
<nextsent>the application of word-sense disambiguation, which is motivated by lexical ambiguity).
</nextsent>
<nextsent>our feature-rich approach is omnivorous and can exploit any linguistic analysis of an input sentence.
</nextsent>
<nextsent>adding features to the linear model (equation 2) that consider more of the source sentence requires changing the decoder very little, if at all.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1083">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>man translation tasks.
</prevsent>
<prevsent>dataset details are given in appendices (chinese) and (german).
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
baseline we use the moses mt system (koehn etal., 2007) <papid> P07-2045 </papid>as baseline and closely follow the example training procedure given for the wmt-07 and wmt-08 shared tasks.4 in particular, we perform word alignment in each direction using giza++(och and ney, 2003), <papid> J03-1002 </papid>apply the grow-diag-finaland?</citsent>
<aftsection>
<nextsent>heuristic for symmetrization and use maximum phrase length of 7.
</nextsent>
<nextsent>in addition to the two phrase translation condition als p(e | f) and p(f | e), we use lexical translation probabilities in each direction, word penalty, phrase penalty, length based reordering model, lexicalized reordering model, and an n-gram language model, srilm implementation (stolcke, 2002) with modified kneserney smoothing (chen and goodman, 1998).
</nextsent>
<nextsent>minimum error-rate (mer) training (och, 2003) <papid> P03-1021 </papid>was applied to obtain weights (m in equation 2) for these features.</nextsent>
<nextsent>a recaser is trained on the target side of the parallel corpus using the script provided withmoses.all output is recased and detokenized prior to evalu ation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1087">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>minimum error-rate (mer) training (och, 2003) <papid> P03-1021 </papid>was applied to obtain weights (m in equation 2) for these features.</prevsent>
<prevsent>a recaser is trained on the target side of the parallel corpus using the script provided withmoses.all output is recased and detokenized prior to evalu ation.</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
evaluation we evaluate translation output using three automatic evaluation measures: bleu (pap ineni et al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002), and meteor (banerjee and lavie, 2005, <papid> W05-0909 </papid>version 0.6).5all measures used were the case-sensitive, corpus level versions.</citsent>
<aftsection>
<nextsent>the version of bleu used was that provided by nist.
</nextsent>
<nextsent>significance was tested using paired bootstrap (koehn, 2004) <papid> W04-3250 </papid>with 1000 samples (p   0.05).6 4http://www.statmt.org/wmt08 5meteor details: for english, we use exact matching,porter stemming, and wordnet synonym matching.</nextsent>
<nextsent>forger man, we use exact matching and porter stemming.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1088">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>evaluation we evaluate translation output using three automatic evaluation measures: bleu (pap ineni et al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002), and meteor (banerjee and lavie, 2005, <papid> W05-0909 </papid>version 0.6).5all measures used were the case-sensitive, corpus level versions.</prevsent>
<prevsent>the version of bleu used was that provided by nist.</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
significance was tested using paired bootstrap (koehn, 2004) <papid> W04-3250 </papid>with 1000 samples (p   0.05).6 4http://www.statmt.org/wmt08 5meteor details: for english, we use exact matching,porter stemming, and wordnet synonym matching.</citsent>
<aftsection>
<nextsent>forger man, we use exact matching and porter stemming.
</nextsent>
<nextsent>these are thesame settings that were used to evaluate systems for the wmt 07 shared task.
</nextsent>
<nextsent>6code implementing this test for these metrics can be freely downloaded at http://www.ark.cs.cmu.edu/mt. 13 chinese ? english testing on un testing on news (nist 2005) context features bleu nist meteor bleu nist meteor training on in-domain data only: none 0.3715 7.918 0.6486 0.2700 7.986 0.5314 training on all data: none 0.3615 7.797 0.6414 0.2593 7.697 0.5200 lexical 0.3898 8.231 0.6697 0.2522 7.852 0.5273 shallow: ? 1 pos tag 0.3611 7.713 0.6430 0.2669 8.243 0.5526 shallow: ? 2 pos tags 0.3657 7.808 0.6455 0.2591 7.843 0.5288 lexical + shallow 0.3886 8.245 0.6675 0.2628 7.881 0.5290 syntactic 0.3717 7.899 0.6531 0.2653 8.123 0.5403 lexical + syntactic 0.3926 8.224 0.6636 0.2572 7.774 0.5234 positional 0.3647 7.766 0.6469 0.2648 7.891 0.5275 all 0.3772 8.176 0.6582 0.2566 7.775 0.5225 feature selection (see sec.
</nextsent>
<nextsent>6.4) 0.3843 8.079 0.6594 0.2730 8.059 0.5343 table 3: chinese ? english experiments: first row shows baseline performance when training only on in-domain data for each task; all other rows show results when training on all data (un and news).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1089">
<title id=" W08-0302.xml">rich source side context for statistical machine translation </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>uses the top-performing feature set {2 pos on left, 1 word on right}.
</prevsent>
<prevsent>boldface marks scores that are significantly higher than the baseline.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
models, including the lexicalized reordering model and the lexical translation model in the moses mt system, or hierarchical or syntactic models (chiang,2005).<papid> P05-1033 </papid></citsent>
<aftsection>
<nextsent>additional linguistic analysis (e.g., morphological disambiguation, named entity recognition, semantic role labeling) can be used to define new context features.
</nextsent>
<nextsent>we have described straightforward, scalable method for improving phrase translation models by modeling features of phrases source-side context.
</nextsent>
<nextsent>our method allows incorporation of features from any kind of source-side annotation and barely affects the decoding algorithm.
</nextsent>
<nextsent>experiments show performance rivaling or exceeding strong, state-of-the-art baselines on standard translation tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1090">
<title id=" W07-2032.xml">gplsi word coarse grained disambiguation aided by basic level concepts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it seems that many word sense distinctions are too subtle to be captured by automatic systems with the current small volumes of word sense annotated examples.
</prevsent>
<prevsent>possibly, building class-based classifiers would allow to avoid the data sparseness problem of the word-based approach.thus, some research has been focused on deriving different sense groupings to overcome the fine?
</prevsent>
</prevsection>
<citsent citstr=" W97-0811 ">
grained distinctions of wn (hearst and schutze,1993) (peters et al, 1998) (mihalcea and moldovan, 2001) (agirre et al, 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for wsd (segond et al, 1997) (<papid> W97-0811 </papid>ciaramita and johnson, 2003) (<papid> W03-1022 </papid>villarejo et al, 2005) (curran, 2005) (<papid> P05-1004 </papid>ciaramita and altun, 2006).<papid> W06-1670 </papid></citsent>
<aftsection>
<nextsent>however, mostof the later approaches used the original lexico graphical files of wn (more recently called super 1http://www.illc.uva.nl/eurowordnet/ 2http://www.ceid.upatras.gr/balkanet 3http://www.lsi.upc.es/ nlp/meaning 157 senses) as very coarse grained sense distinctions.
</nextsent>
<nextsent>however, not so much attention has been paid on learning class-based classifiers from other availablesensegroupings such as wordnet domains (mag nini and cavaglia, 2000), sumo labels (niles and pease, 2001), euro wordnet base concepts or top concept ontology labels (atserias et al, 2004).
</nextsent>
<nextsent>obviously, these resources relate senses at some level of abstraction using different semantic criteria and properties that could be of interest for wsd.
</nextsent>
<nextsent>possibly, their combination could improve the overall results since they offer different semantic perspectives of the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1091">
<title id=" W07-2032.xml">gplsi word coarse grained disambiguation aided by basic level concepts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it seems that many word sense distinctions are too subtle to be captured by automatic systems with the current small volumes of word sense annotated examples.
</prevsent>
<prevsent>possibly, building class-based classifiers would allow to avoid the data sparseness problem of the word-based approach.thus, some research has been focused on deriving different sense groupings to overcome the fine?
</prevsent>
</prevsection>
<citsent citstr=" W03-1022 ">
grained distinctions of wn (hearst and schutze,1993) (peters et al, 1998) (mihalcea and moldovan, 2001) (agirre et al, 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for wsd (segond et al, 1997) (<papid> W97-0811 </papid>ciaramita and johnson, 2003) (<papid> W03-1022 </papid>villarejo et al, 2005) (curran, 2005) (<papid> P05-1004 </papid>ciaramita and altun, 2006).<papid> W06-1670 </papid></citsent>
<aftsection>
<nextsent>however, mostof the later approaches used the original lexico graphical files of wn (more recently called super 1http://www.illc.uva.nl/eurowordnet/ 2http://www.ceid.upatras.gr/balkanet 3http://www.lsi.upc.es/ nlp/meaning 157 senses) as very coarse grained sense distinctions.
</nextsent>
<nextsent>however, not so much attention has been paid on learning class-based classifiers from other availablesensegroupings such as wordnet domains (mag nini and cavaglia, 2000), sumo labels (niles and pease, 2001), euro wordnet base concepts or top concept ontology labels (atserias et al, 2004).
</nextsent>
<nextsent>obviously, these resources relate senses at some level of abstraction using different semantic criteria and properties that could be of interest for wsd.
</nextsent>
<nextsent>possibly, their combination could improve the overall results since they offer different semantic perspectives of the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1092">
<title id=" W07-2032.xml">gplsi word coarse grained disambiguation aided by basic level concepts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it seems that many word sense distinctions are too subtle to be captured by automatic systems with the current small volumes of word sense annotated examples.
</prevsent>
<prevsent>possibly, building class-based classifiers would allow to avoid the data sparseness problem of the word-based approach.thus, some research has been focused on deriving different sense groupings to overcome the fine?
</prevsent>
</prevsection>
<citsent citstr=" P05-1004 ">
grained distinctions of wn (hearst and schutze,1993) (peters et al, 1998) (mihalcea and moldovan, 2001) (agirre et al, 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for wsd (segond et al, 1997) (<papid> W97-0811 </papid>ciaramita and johnson, 2003) (<papid> W03-1022 </papid>villarejo et al, 2005) (curran, 2005) (<papid> P05-1004 </papid>ciaramita and altun, 2006).<papid> W06-1670 </papid></citsent>
<aftsection>
<nextsent>however, mostof the later approaches used the original lexico graphical files of wn (more recently called super 1http://www.illc.uva.nl/eurowordnet/ 2http://www.ceid.upatras.gr/balkanet 3http://www.lsi.upc.es/ nlp/meaning 157 senses) as very coarse grained sense distinctions.
</nextsent>
<nextsent>however, not so much attention has been paid on learning class-based classifiers from other availablesensegroupings such as wordnet domains (mag nini and cavaglia, 2000), sumo labels (niles and pease, 2001), euro wordnet base concepts or top concept ontology labels (atserias et al, 2004).
</nextsent>
<nextsent>obviously, these resources relate senses at some level of abstraction using different semantic criteria and properties that could be of interest for wsd.
</nextsent>
<nextsent>possibly, their combination could improve the overall results since they offer different semantic perspectives of the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1093">
<title id=" W07-2032.xml">gplsi word coarse grained disambiguation aided by basic level concepts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it seems that many word sense distinctions are too subtle to be captured by automatic systems with the current small volumes of word sense annotated examples.
</prevsent>
<prevsent>possibly, building class-based classifiers would allow to avoid the data sparseness problem of the word-based approach.thus, some research has been focused on deriving different sense groupings to overcome the fine?
</prevsent>
</prevsection>
<citsent citstr=" W06-1670 ">
grained distinctions of wn (hearst and schutze,1993) (peters et al, 1998) (mihalcea and moldovan, 2001) (agirre et al, 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for wsd (segond et al, 1997) (<papid> W97-0811 </papid>ciaramita and johnson, 2003) (<papid> W03-1022 </papid>villarejo et al, 2005) (curran, 2005) (<papid> P05-1004 </papid>ciaramita and altun, 2006).<papid> W06-1670 </papid></citsent>
<aftsection>
<nextsent>however, mostof the later approaches used the original lexico graphical files of wn (more recently called super 1http://www.illc.uva.nl/eurowordnet/ 2http://www.ceid.upatras.gr/balkanet 3http://www.lsi.upc.es/ nlp/meaning 157 senses) as very coarse grained sense distinctions.
</nextsent>
<nextsent>however, not so much attention has been paid on learning class-based classifiers from other availablesensegroupings such as wordnet domains (mag nini and cavaglia, 2000), sumo labels (niles and pease, 2001), euro wordnet base concepts or top concept ontology labels (atserias et al, 2004).
</nextsent>
<nextsent>obviously, these resources relate senses at some level of abstraction using different semantic criteria and properties that could be of interest for wsd.
</nextsent>
<nextsent>possibly, their combination could improve the overall results since they offer different semantic perspectives of the data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1094">
<title id=" W07-0809.xml">arabic tokenization system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we will show different levels of implementation of the arabic tokenizer, according to the levels of linguistic depth involved.
</prevsent>
<prevsent>arabic tokenization has been described in various researches and implemented in many solutions as it is required preliminary stage for further processing.
</prevsent>
</prevsection>
<citsent citstr=" W05-0711 ">
these solutions include morphological analysis (beesley 2001; buckwalter 2002), diacri tization (nelken and shieber 2005), <papid> W05-0711 </papid>information retrieval (larkey and connell 2002), and pos tagging (diab et al 2004; <papid> N04-4038 </papid>habash and rambow 2005).<papid> P05-1071 </papid></citsent>
<aftsection>
<nextsent>none of these projects, however, show how multiword expressions are treated, or how ambiguity is filtered out.
</nextsent>
<nextsent>in our research, tokenization is handled in rule-based system as an independent process.
</nextsent>
<nextsent>weshow how the tokenizer interacts with other transducers, and how multiword expressions are identified and delimited.
</nextsent>
<nextsent>we also show how incorrect tokenizations are filtered out, and how undesired tokenizations are marked.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1095">
<title id=" W07-0809.xml">arabic tokenization system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we will show different levels of implementation of the arabic tokenizer, according to the levels of linguistic depth involved.
</prevsent>
<prevsent>arabic tokenization has been described in various researches and implemented in many solutions as it is required preliminary stage for further processing.
</prevsent>
</prevsection>
<citsent citstr=" N04-4038 ">
these solutions include morphological analysis (beesley 2001; buckwalter 2002), diacri tization (nelken and shieber 2005), <papid> W05-0711 </papid>information retrieval (larkey and connell 2002), and pos tagging (diab et al 2004; <papid> N04-4038 </papid>habash and rambow 2005).<papid> P05-1071 </papid></citsent>
<aftsection>
<nextsent>none of these projects, however, show how multiword expressions are treated, or how ambiguity is filtered out.
</nextsent>
<nextsent>in our research, tokenization is handled in rule-based system as an independent process.
</nextsent>
<nextsent>weshow how the tokenizer interacts with other transducers, and how multiword expressions are identified and delimited.
</nextsent>
<nextsent>we also show how incorrect tokenizations are filtered out, and how undesired tokenizations are marked.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1096">
<title id=" W07-0809.xml">arabic tokenization system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we will show different levels of implementation of the arabic tokenizer, according to the levels of linguistic depth involved.
</prevsent>
<prevsent>arabic tokenization has been described in various researches and implemented in many solutions as it is required preliminary stage for further processing.
</prevsent>
</prevsection>
<citsent citstr=" P05-1071 ">
these solutions include morphological analysis (beesley 2001; buckwalter 2002), diacri tization (nelken and shieber 2005), <papid> W05-0711 </papid>information retrieval (larkey and connell 2002), and pos tagging (diab et al 2004; <papid> N04-4038 </papid>habash and rambow 2005).<papid> P05-1071 </papid></citsent>
<aftsection>
<nextsent>none of these projects, however, show how multiword expressions are treated, or how ambiguity is filtered out.
</nextsent>
<nextsent>in our research, tokenization is handled in rule-based system as an independent process.
</nextsent>
<nextsent>weshow how the tokenizer interacts with other transducers, and how multiword expressions are identified and delimited.
</nextsent>
<nextsent>we also show how incorrect tokenizations are filtered out, and how undesired tokenizations are marked.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1098">
<title id=" W07-0809.xml">arabic tokenization system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also show how incorrect tokenizations are filtered out, and how undesired tokenizations are marked.
</prevsent>
<prevsent>all tools in this research are developed infinite state technology (beesley and karttunen 2003).
</prevsent>
</prevsection>
<citsent citstr=" W02-1503 ">
these tools have been developed to serve an arabic lexical functional grammar parser using xle (xerox linguistics envi ronment) platform as part of the pargram project (butt et al 2002).<papid> W02-1503 </papid></citsent>
<aftsection>
<nextsent>65
</nextsent>
<nextsent>a token is the minimal syntactic unit; it can be word, part of word (or clitic), multiword expression, or punctuation mark.
</nextsent>
<nextsent>a tokenizer needs to know list of all word boundaries, such as white spaces and punctuation marks, and also information about the token boundaries inside words when word is composed of stem and cli tics.
</nextsent>
<nextsent>throughout this research full form words, i.e. stems with or without clitics, as well as numbers will be termed main tokens.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1101">
<title id=" W07-0809.xml">arabic tokenization system </title>
<section> tokenization solutions.  </section>
<citcontext>
<prevsection>
<prevsent>(sag et al 2001).
</prevsent>
<prevsent>mwes cover expressions that are traditionally classified as idioms (e.g. down the drain), prepositional verbs (e.g. rely on), verbs with particles (e.g. give up), compound nouns (e.g. traffic lights) and collocations (e.g. do favour).
</prevsent>
</prevsection>
<citsent citstr=" W04-0409 ">
with regard to syntactic and morphological flexibility, mwes are classified into three types: fixed, semi-fixed and syntactically flexible expressions (baldwin 2004; oflazer et al 2004; <papid> W04-0409 </papid>sag et al  2001).</citsent>
<aftsection>
<nextsent>a. fixed expressions.
</nextsent>
<nextsent>these expressions are lexically, syntactically and morphologically rigid.
</nextsent>
<nextsent>an expression of this type is considered as word with spaces (a single word that happens to contain 68 spaces), such as ???????
</nextsent>
<nextsent>al-sharq al-awsat (the middle east) and ???
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1102">
<title id=" W07-1607.xml">automatically acquiring models of preposition use </title>
<section> contextual features.  </section>
<citcontext>
<prevsection>
<prevsent>despite this apparently idiosyncratic behaviour, we believe that prepositional choice is governed by combination of several syntactic and semantic features.
</prevsent>
<prevsent>contexts of occurrence can be represented by vectors; machine learning algorithm trained on them can predict with some confidence, given new occurrence of acontext vector, whether certain preposition is appropriate in that context or not.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
we consider the following macro-categories of features to be relevant: pos being modified; pos of the prepositions complement; given rasp-style grammatical relation output (gr; see e.g. briscoe et al 2006), <papid> P06-4020 </papid>what grs the preposition occurs in;named entity (ne) information - whether the modified or complement items are nes; wordnet information - to which of the wordnet lexicographer 45 classes1 the modified and complement nouns and verbs belong; immediate context - pos tags of 2 word window around the preposition.</citsent>
<aftsection>
<nextsent>for example, given sentence such as john drove to cambridge,we would note that this occurrence of the preposition to modifies verb, its complement is location ne noun, the verb it modifies is verb of motion?, the tags surrounding it are nnp, vbd, nnp2, and it occurs in the relation iobj?
</nextsent>
<nextsent>with the verb, and dobj?
</nextsent>
<nextsent>with the complement noun.
</nextsent>
<nextsent>our 307-feature set aims to capture all the salient elements of sentence which we believe could be involved in governing preposition choice, and which can be accurately recognised automatically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1103">
<title id=" W07-1607.xml">automatically acquiring models of preposition use </title>
<section> evaluation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this case the challenge is finding work which is roughly comparable: there are myriad of variables in this field, from the characteristics of the learner (age, l1, education...)
</prevsent>
<prevsent>to the approach used to the types of errors considered.
</prevsent>
</prevsection>
<citsent citstr=" A00-2019 ">
with this in mind, all we can do is mention some work which we feel is closest in spirit to our approach, but stress that the figures are for reference only, and cannot be compared directly to ours.chodorow and leacock (2000) <papid> A00-2019 </papid>try to identify errors on the basis of context, as we do here, and more specifically 2 word window around theword of interest, from which they consider function words and pos tags.</citsent>
<aftsection>
<nextsent>mutual information is used to determine more or less likely sequences ofwords, so that less likely sequences suggest the presence of an error.
</nextsent>
<nextsent>unlike ours, their work focuses on content words rather than function words; theyre port precision of 78% and recall of 20%.
</nextsent>
<nextsent>our precision is comparable to this, and our recall is much higher, which is an important factor in errordetection: user is likely to lose trust in system which cannot spot his/her errors very often6.izumi et al (2004) work with corpus of english spoken by japanese students; they attempt to identify errors using various contextual features and maximum entropy based-methods.
</nextsent>
<nextsent>they report results for omission errors (precision 75.7%, recall 45.67%) and for replacement errors (p 31.17%, 8%).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1104">
<title id=" W07-0730.xml">ucb system description for the wmt 2007 shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>modern statistical machine translation (smt) systems are trained on aligned sentences of bilingual corpora, typically from one domain.
</prevsent>
<prevsent>when tested ontext from that same domain, such systems demonstrate state-of-the art performance; however, on out-of-domain text the results can get significantly worse.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
for example, on the wmt 2006 shared task evaluation, the french to english translation bleu scores dropped from about 30 to about 20 for nearly all systems, when tested on news commentary rather than europarl (koehn and monz, 2006).<papid> W06-3114 </papid></citsent>
<aftsection>
<nextsent>therefore, this year the shared task organizer shave provided 1m words of bilingual news commentary training data in addition to the europarldata (about 30m words), thus challenging the participants to experiment with domain adaptation.below we describe our domain adaptation experiments, trying to achieve better results on the news commentary data.
</nextsent>
<nextsent>in addition to training on both datasets, we make use of monolingual syntactic paraphrases of the english side of the data.
</nextsent>
<nextsent>in many cases, the testing text contains phrases?
</nextsent>
<nextsent>that are equivalent, but syntactically different from the phrases learned on training, and the potential for high-quality translation is missed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1105">
<title id=" W07-0730.xml">ucb system description for the wmt 2007 shared task </title>
<section> monolingual syntactic paraphrasing.  </section>
<citcontext>
<prevsection>
<prevsent>this augmented training corpus can then be used to train an smt system.
</prevsent>
<prevsent>alternatively, we can paraphrase the test sentences making them closer to the target language syntax.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
given an english sentence, we parse it with the stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>and then generate paraphrases using the following syntactic transformations: 1.</citsent>
<aftsection>
<nextsent>[np np1 np2]?
</nextsent>
<nextsent>[np np2 np1].
</nextsent>
<nextsent>inequality in income?
</nextsent>
<nextsent>income inequality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1106">
<title id=" W07-0730.xml">ucb system description for the wmt 2007 shared task </title>
<section> npnc ? nppp ..  </section>
<citcontext>
<prevsection>
<prevsent>the algorithm must determine whether possessive marker is feasible for (5) and must choose the correct preposition for (6).
</prevsent>
<prevsent>in either case, for noun compounds (ncs) of length 3 or more, it also needs to choose the position to modify, e.g., inquirys committee chairman vs. inquiry committees chairman.
</prevsent>
</prevsection>
<citsent citstr=" N04-1016 ">
in order to ensure accuracy of the paraphrases, we use statistics gathered from the web, using variation of the approaches presented in lapata and keller (2004) <papid> N04-1016 </papid>and nakov and hearst (2005).<papid> W05-0603 </papid></citsent>
<aftsection>
<nextsent>we use patterns to generate possible prepositional or copula paraphrases in the context of the preceding and the following word in the sentence, first we split the nc into two parts n1 and n2 in all possible ways, e.g., beef import ban lifting would be split as: (a) n1=beef?, n2=import ban lifting?, (b) n1=beef import?, n2=ban lifting?, and (c) n1=beef import ban?, n2=lifting?.
</nextsent>
<nextsent>for every split, we issue exact phrase queries to the google search engine using the following patterns:  lt n1 poss n2 rt   lt n2 prep det 1 rt   lt n2 that be det 1 rt   lt n2 that be prep det 1 rt  where: lt is the word preceding n1 in the original sentence or empty if none, rt is the word following n2 in the original sentence or empty if none, poss is possessive marker (s or ?), that is that, which or who, be is is or are, det is determiner (the, a, an, or none), prep is one of the 8 prepositions used by lauer (1995) <papid> P95-1007 </papid>for semantic interpretation of ncs: about, at, for, from, in, of, on, and with, and 1 can be either n1, or n1 with the number of its last word changed from singular/plural to plural/singular.</nextsent>
<nextsent>for all splits, we collect the number of page hits for each instantiation of each pattern, filtering out the paraphrases whose page hit count is less than 10.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1107">
<title id=" W07-0730.xml">ucb system description for the wmt 2007 shared task </title>
<section> npnc ? nppp ..  </section>
<citcontext>
<prevsection>
<prevsent>the algorithm must determine whether possessive marker is feasible for (5) and must choose the correct preposition for (6).
</prevsent>
<prevsent>in either case, for noun compounds (ncs) of length 3 or more, it also needs to choose the position to modify, e.g., inquirys committee chairman vs. inquiry committees chairman.
</prevsent>
</prevsection>
<citsent citstr=" W05-0603 ">
in order to ensure accuracy of the paraphrases, we use statistics gathered from the web, using variation of the approaches presented in lapata and keller (2004) <papid> N04-1016 </papid>and nakov and hearst (2005).<papid> W05-0603 </papid></citsent>
<aftsection>
<nextsent>we use patterns to generate possible prepositional or copula paraphrases in the context of the preceding and the following word in the sentence, first we split the nc into two parts n1 and n2 in all possible ways, e.g., beef import ban lifting would be split as: (a) n1=beef?, n2=import ban lifting?, (b) n1=beef import?, n2=ban lifting?, and (c) n1=beef import ban?, n2=lifting?.
</nextsent>
<nextsent>for every split, we issue exact phrase queries to the google search engine using the following patterns:  lt n1 poss n2 rt   lt n2 prep det 1 rt   lt n2 that be det 1 rt   lt n2 that be prep det 1 rt  where: lt is the word preceding n1 in the original sentence or empty if none, rt is the word following n2 in the original sentence or empty if none, poss is possessive marker (s or ?), that is that, which or who, be is is or are, det is determiner (the, a, an, or none), prep is one of the 8 prepositions used by lauer (1995) <papid> P95-1007 </papid>for semantic interpretation of ncs: about, at, for, from, in, of, on, and with, and 1 can be either n1, or n1 with the number of its last word changed from singular/plural to plural/singular.</nextsent>
<nextsent>for all splits, we collect the number of page hits for each instantiation of each pattern, filtering out the paraphrases whose page hit count is less than 10.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1108">
<title id=" W07-0730.xml">ucb system description for the wmt 2007 shared task </title>
<section> npnc ? nppp ..  </section>
<citcontext>
<prevsection>
<prevsent>in order to ensure accuracy of the paraphrases, we use statistics gathered from the web, using variation of the approaches presented in lapata and keller (2004) <papid> N04-1016 </papid>and nakov and hearst (2005).<papid> W05-0603 </papid></prevsent>
<prevsent>we use patterns to generate possible prepositional or copula paraphrases in the context of the preceding and the following word in the sentence, first we split the nc into two parts n1 and n2 in all possible ways, e.g., beef import ban lifting would be split as: (a) n1=beef?, n2=import ban lifting?, (b) n1=beef import?, n2=ban lifting?, and (c) n1=beef import ban?, n2=lifting?.</prevsent>
</prevsection>
<citsent citstr=" P95-1007 ">
for every split, we issue exact phrase queries to the google search engine using the following patterns:  lt n1 poss n2 rt   lt n2 prep det 1 rt   lt n2 that be det 1 rt   lt n2 that be prep det 1 rt  where: lt is the word preceding n1 in the original sentence or empty if none, rt is the word following n2 in the original sentence or empty if none, poss is possessive marker (s or ?), that is that, which or who, be is is or are, det is determiner (the, a, an, or none), prep is one of the 8 prepositions used by lauer (1995) <papid> P95-1007 </papid>for semantic interpretation of ncs: about, at, for, from, in, of, on, and with, and 1 can be either n1, or n1 with the number of its last word changed from singular/plural to plural/singular.</citsent>
<aftsection>
<nextsent>for all splits, we collect the number of page hits for each instantiation of each pattern, filtering out the paraphrases whose page hit count is less than 10.
</nextsent>
<nextsent>we then calculate the total number of page hitsh for all paraphrases (for all splits and all patterns), and retain those ones whose page hits count is at least10% of . note that this allows for multiple paraphrases of an nc.
</nextsent>
<nextsent>if no paraphrases are retained, we 213 repeat the above procedure with lt set to the empty string.
</nextsent>
<nextsent>if there are still no good paraphrases, we setthe rt to the empty string.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1109">
<title id=" W07-0730.xml">ucb system description for the wmt 2007 shared task </title>
<section> npnc ? nppp ..  </section>
<citcontext>
<prevsection>
<prevsent>cognates.
</prevsent>
<prevsent>previous research has found that using cognates can help get better word alignments (and ultimately better mt results), especially in case of small training set.
</prevsent>
</prevsection>
<citsent citstr=" N03-2016 ">
we used the method described in (kondrak et al, 2003) <papid> N03-2016 </papid>in order to extract cognates from the two data sets.</citsent>
<aftsection>
<nextsent>we then added them as sentence pairs to the news commentary corpus before training the word alignment models1 for ucb3, ucb4 and ucb5.
</nextsent>
<nextsent>1following (kondrak et al, 2003), <papid> N03-2016 </papid>we considered words of length 4 or more, we required the length ratio to be between 7 10 and 10 7 , and we accepted as potential cognates all pairs for which the longest common sub sequence ratio (lcsr) was 0.58 or more.</nextsent>
<nextsent>we repeated 3 times the cognate pairs extracted from the europarl, and 4 times the ones from news commentary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1111">
<title id=" W07-0730.xml">ucb system description for the wmt 2007 shared task </title>
<section> npnc ? nppp ..  </section>
<citcontext>
<prevsection>
<prevsent>we trained two separate mt systems: one on the original corpus, and another one on the paraphrased version.
</prevsent>
<prevsent>we then used both resulting lexicalized re-orderingmodels and merged phrase table with extra para meters: if phrase appeared in both phrase tables, it now had 9 instead of 5 parameters (4 from each table, plus phrase penalty), and if it was in one of the phrase tables only, the 4 missing parameters were filled with 1e-40.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the ucb5 system is also trained on europarl, yielding third lexicalized re-ordering model and adding 4 new parameters to the phrase table entries.unfortunately, longer sentences (up to 100 tokens, rather than 40), longer phrases (up to 10 tokens, rather than 7), two lms (rather than just one), higher-order lms (order 7, rather than 3),multiple higher-order lexicalized re-ordering models (up to 3), etc. all contributed to increased systems complexity, and, as result, time limitations prevented us from performing minimum-error-rate training (mert) (och, 2003) <papid> P03-1021 </papid>for ucb3, ucb4 anducb5.</citsent>
<aftsection>
<nextsent>therefore, we used the mert parameter values from ucb1 instead, e.g. the first 4 phrase weights of ucb1 were divided by two, copied twice and used in ucb3 as the first 8 phrase-table parameters.
</nextsent>
<nextsent>the extra 4 parameters of ucb5 came from training separate mt system on the europarl data (scaled ac cordingly).
</nextsent>
<nextsent>3.3 paraphrasing the test set.
</nextsent>
<nextsent>in some of our experiments (ucb2 and ucb4), given test sentence, we generated the single most-likely paraphrase, which makes it syntactically closer to spanish and french.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1112">
<title id=" W07-0730.xml">ucb system description for the wmt 2007 shared task </title>
<section> npnc ? nppp ..  </section>
<citcontext>
<prevsection>
<prevsent>3.4 other non-standard settings.
</prevsent>
<prevsent>below we discuss some non-standard settings that differ from the ones suggested by the organizers in their baseline system.
</prevsent>
</prevsection>
<citsent citstr=" W06-3123 ">
first, following birch et al(2006), <papid> W06-3123 </papid>who found that higher-order lms give better results2, we used 5-gram lm for news commentary, and 7-gram lm for europarl (as opposed to 3-gram, as done normally).</citsent>
<aftsection>
<nextsent>second, for all runs we trained our systems on all sentences of length up to 100 (rather than 40, as suggested in the baseline system).
</nextsent>
<nextsent>third, we used maximum phrase length limit of 10 (rather than 7, as typically done).
</nextsent>
<nextsent>fourth,we used both lexicalized and distance-based reordering models (as opposed to lexicalized only, as in the baseline system).
</nextsent>
<nextsent>finally, while we did not use any resources other than the ones provided bythe shared task organizers, we made use of web frequencies when paraphrasing the training corpus, as explained above.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1113">
<title id=" W07-2098.xml">usfd preliminary exploration of features and classifiers for the tempeval2007 task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we used the weka ml workbench to facilitate experimenting with different ml algorithms.
</prevsent>
<prevsent>the paper describes our system and supplies preliminary answers to the above questions.
</prevsent>
</prevsection>
<citsent citstr=" P06-1095 ">
the sheffield team were involved in tempe val asco-proposers/co-organisers of the task.1 for our participation in the task, we decided to pursue an mlbased approach, the benefits of which have been explored elsewhere (boguraev and ando, 2005; mani et al, 2006).<papid> P06-1095 </papid></citsent>
<aftsection>
<nextsent>for the tempe val tasks, this is easily done by treating the assignment of temporal relation types as simple classification task, using readily available information for the instance features.
</nextsent>
<nextsent>more specifically, the features used were ones provided as 1we maintained strict separation between persons assisting in annotation of the test corpus and those involved in system development.
</nextsent>
<nextsent>attributes in the tempe val data annotation for theevents/times being related, plus some additional features that could be straightforwardly computed from documents, i.e. without the use of more heavily en gineered?
</nextsent>
<nextsent>nlp components.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1114">
<title id=" W07-2098.xml">usfd preliminary exploration of features and classifiers for the tempeval2007 task </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the tempe val competition also uses relaxed?
</prevsent>
<prevsent>metric which gives partial credit when one (or both) label is disjunctive and there is apart ial match, e.g. between labels after and overlap-or after.
</prevsent>
</prevsection>
<citsent citstr=" W07-2014 ">
see (verhagen et al, 2007) <papid> W07-2014 </papid>for details.</citsent>
<aftsection>
<nextsent>440 task task task fs fr fs fr fs fr usfd 0.59 0.60 0.73 0.74 0.54 0.59 ave. 0.56 0.59 0.74 0.75 0.51 0.60 max.
</nextsent>
<nextsent>0.62 0.64 0.80 0.81 0.55 0.66table 3: competition task scores for sheffield system (usfd), plus average/max scores across all competing systems method, which gives the best performance for task a, gives rather middling?
</nextsent>
<nextsent>performance for task b. similarly, the svm method that gives the best results for task falls quite way below the performance of kstar on task a. more extreme case is seen with the results for rules.jrip (wekas implementation of the ripper algorithm),whose score for task is close to that of the best performing system, but which scores only slightly above baseline on task a. the competition scores for our system are given in table 3, shown as (harmonic) f-measures under both strict (fs) and relaxed (fr) metrics (see foot note 2).
</nextsent>
<nextsent>the table also shows the average score for each task/metric across all systems taking part in the competition, as well as the maximum score returned by any system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1123">
<title id=" W07-0907.xml">dynamic path prediction and recommendation in a museum environment </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>for each word in the keyword set of each exhibit, the wordnet (fellbaum, 1998) similarity is calculated against each word in another exhibit.
</prevsent>
<prevsent>the similarity is the sum of the wordnet similarities between all attribute keywords in the two exhibits (k1, k2), normalised over the length of both keyword sets: ? k1k1 ? k2k2 wnsim(k1, k2) |k1||k2| for the purposes of this experiment we have chosen to use three wordnet similarity/relatedness measures to simulate the conceptual connections that visitors make between exhibits.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
the lin (lin, 1998) <papid> P98-2127 </papid>and leacock-chodorow (leacock et al,1998) <papid> J98-1006 </papid>similarity measures and the banerjee pedersen (patwardhan and pedersen, 2003) relatedness measures were used.</citsent>
<aftsection>
<nextsent>the similarities were normalised and transformed into probability matrices such that ? pwnsim(e|cj) = 1 for each next exhibit ci.
</nextsent>
<nextsent>the use of wordnet measures is intended to simulate the mental connections that visitors make between exhibit content, given that each visit can interpret content in number of different ways.
</nextsent>
<nextsent>the history of the visitor at any given time is essential in keeping the visitors conceptual model of the exhibit space current.
</nextsent>
<nextsent>the recency of given exhibit within visitors history is inversely proportional to how long ago the exhibit was encountered.to take into account the visitor history, the collaborative data, proximity, document vectors, and conceptual wordnet similarity, we adapt the naive bayes approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1124">
<title id=" W07-0907.xml">dynamic path prediction and recommendation in a museum environment </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>for each word in the keyword set of each exhibit, the wordnet (fellbaum, 1998) similarity is calculated against each word in another exhibit.
</prevsent>
<prevsent>the similarity is the sum of the wordnet similarities between all attribute keywords in the two exhibits (k1, k2), normalised over the length of both keyword sets: ? k1k1 ? k2k2 wnsim(k1, k2) |k1||k2| for the purposes of this experiment we have chosen to use three wordnet similarity/relatedness measures to simulate the conceptual connections that visitors make between exhibits.
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
the lin (lin, 1998) <papid> P98-2127 </papid>and leacock-chodorow (leacock et al,1998) <papid> J98-1006 </papid>similarity measures and the banerjee pedersen (patwardhan and pedersen, 2003) relatedness measures were used.</citsent>
<aftsection>
<nextsent>the similarities were normalised and transformed into probability matrices such that ? pwnsim(e|cj) = 1 for each next exhibit ci.
</nextsent>
<nextsent>the use of wordnet measures is intended to simulate the mental connections that visitors make between exhibit content, given that each visit can interpret content in number of different ways.
</nextsent>
<nextsent>the history of the visitor at any given time is essential in keeping the visitors conceptual model of the exhibit space current.
</nextsent>
<nextsent>the recency of given exhibit within visitors history is inversely proportional to how long ago the exhibit was encountered.to take into account the visitor history, the collaborative data, proximity, document vectors, and conceptual wordnet similarity, we adapt the naive bayes approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1125">
<title id=" W07-2012.xml">the semeval2007 weps evaluation establishing a benchmark for the web people search task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is also strong relation of our proposed task with the co-reference resolution problem, focused on linking mentions (including pronouns) ina text.
</prevsent>
<prevsent>our task can be seen as co-reference resolution problem where the focus is on solving inter document co-reference, disregarding the linking of all the mentions of an entity inside each document.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
an early work in name disambiguation (baggaand baldwin, 1998) <papid> P98-1012 </papid>uses the similarity between documents in vector space using bag of words?</citsent>
<aftsection>
<nextsent>representation.
</nextsent>
<nextsent>an alternative approach by mann and yarowsky (2003) <papid> W03-0405 </papid>is based on rich feature space of automatically extracted biographic information.</nextsent>
<nextsent>fleischman and hovy (2004) <papid> W04-0701 </papid>propose maximum entropy model trained to give the probability that 64 two names refer to the same individual 1.the paper is organized as follows.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1126">
<title id=" W07-2012.xml">the semeval2007 weps evaluation establishing a benchmark for the web people search task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an early work in name disambiguation (baggaand baldwin, 1998) <papid> P98-1012 </papid>uses the similarity between documents in vector space using bag of words?</prevsent>
<prevsent>representation.</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
an alternative approach by mann and yarowsky (2003) <papid> W03-0405 </papid>is based on rich feature space of automatically extracted biographic information.</citsent>
<aftsection>
<nextsent>fleischman and hovy (2004) <papid> W04-0701 </papid>propose maximum entropy model trained to give the probability that 64 two names refer to the same individual 1.the paper is organized as follows.</nextsent>
<nextsent>section 2 provides description of the experimental methodology, the training and test data provided to the participants, the evaluation measures, baseline system sand the campaign design.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1127">
<title id=" W07-2012.xml">the semeval2007 weps evaluation establishing a benchmark for the web people search task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>representation.
</prevsent>
<prevsent>an alternative approach by mann and yarowsky (2003) <papid> W03-0405 </papid>is based on rich feature space of automatically extracted biographic information.</prevsent>
</prevsection>
<citsent citstr=" W04-0701 ">
fleischman and hovy (2004) <papid> W04-0701 </papid>propose maximum entropy model trained to give the probability that 64 two names refer to the same individual 1.the paper is organized as follows.</citsent>
<aftsection>
<nextsent>section 2 provides description of the experimental methodology, the training and test data provided to the participants, the evaluation measures, baseline system sand the campaign design.
</nextsent>
<nextsent>section 3 gives description of the participant systems and provides the evaluation results.
</nextsent>
<nextsent>finally, section 4 presents some conclusions.
</nextsent>
<nextsent>2.1 data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1128">
<title id=" W07-2055.xml">oe wsd using optimal ensembling oe method </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 machine (mach) selection.
</prevsent>
<prevsent>we selected support vector machine (svm) (vapnik, 1995) and naive bayes (nb) (john et al 1995) as classifiers for our base systems to be optimally ensembled.
</prevsent>
</prevsection>
<citsent citstr=" W04-0807 ">
this was mainly because of their attested strength at earlier senseval evaluations (edmonds et al 2002, mihalcea et al 2004) <papid> W04-0807 </papid>and mutual complementarity discovered by us (saarikoski et al., 2007).</citsent>
<aftsection>
<nextsent>original batch of candidate machines that we tested for oe using senseval-2 dataset included the following classifiers: decision stump, decision tree with various values of confidence (c) parameter 0.05, 0.15, 0.25 and instance-based classifier with values ranging from 1..15 at intervals of two 1.
</nextsent>
<nextsent>after cross-validation runs against current dataset (see below), however, svm and nb proved again to be overall strongest regardless of training input, so we built oe around those two classifiers.
</nextsent>
<nextsent>2.2 feature set (fset) selection.
</nextsent>
<nextsent>we extracted three contextual feature sets from training data for all words to train the machines: 1 grams (1g) and sequential 2-grams both from whole instance (2g) as well as part-of-speech tags from local 1-word window around and including target word (pos3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1130">
<title id=" W07-2055.xml">oe wsd using optimal ensembling oe method </title>
<section> system descriptions.  </section>
<citcontext>
<prevsection>
<prevsent>in case of  multifsets , each single fset had equal probability based vote in disambiguating the test instances of 2 syntalex code (mohammad and pedersen, 2002,.
</prevsent>
<prevsent>http://www.d.umn.edu/~tpederse/syntalex.html) was used for extracting n-grams and carrying out disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
brill tagger (brill, 1995) <papid> J95-4004 </papid>was used for extracting pos tags.</citsent>
<aftsection>
<nextsent>weka library of classifiers (witten, 2005) was used to run cross-vali dations and best-system predictors.
</nextsent>
<nextsent>258 that word.
</nextsent>
<nextsent>as usual, the sense with highest probability was chosen as answer for each instance.
</nextsent>
<nextsent>here are the results: system name gross gain net gain accuracy3 oe1 +3.0 (+7.8) +0.5 (+4.4) 83.8 oe2 +2.3 (+7.0) +2.0 (+5.8) 85.3 table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1133">
<title id=" W08-0334.xml">dynamic model interpolation for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the technique was thoroughly evaluated on data from 17 language pairs using 6 machine translation evaluation metrics.
</prevsent>
<prevsent>we found the results were corpus-dependent, but in most cases our system was able to improve translation performance, and for some languages the improvements were substantial.
</prevsent>
</prevsection>
<citsent citstr=" A94-1010 ">
topic-dependent modeling has proven to be an effective way to improve quality the quality of models in speech recognition (iyer and osendorf, 1994; carter, 1994).<papid> A94-1010 </papid></citsent>
<aftsection>
<nextsent>recently, experiments in the field of machine translation (hasan and ney, 2005; yamamoto and sumita, 2007; <papid> D07-1054 </papid>finch et al 2007, foster and kuhn, 2007) <papid> W07-0717 </papid>have shown that class specific models are also useful for translation.in the method proposed by yamamoto and sumita (2007), <papid> D07-1054 </papid>topic dependency was implemented by partitioning the data into sets before the decoding process commenced, and subsequently decoding these sets independently using different models that were specific to the class predicted for the source sentence by classifier that was run over the source sentences in pre-processing pass.</nextsent>
<nextsent>our approach is in many ways generalization of this work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1134">
<title id=" W08-0334.xml">dynamic model interpolation for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we found the results were corpus-dependent, but in most cases our system was able to improve translation performance, and for some languages the improvements were substantial.
</prevsent>
<prevsent>topic-dependent modeling has proven to be an effective way to improve quality the quality of models in speech recognition (iyer and osendorf, 1994; carter, 1994).<papid> A94-1010 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1054 ">
recently, experiments in the field of machine translation (hasan and ney, 2005; yamamoto and sumita, 2007; <papid> D07-1054 </papid>finch et al 2007, foster and kuhn, 2007) <papid> W07-0717 </papid>have shown that class specific models are also useful for translation.in the method proposed by yamamoto and sumita (2007), <papid> D07-1054 </papid>topic dependency was implemented by partitioning the data into sets before the decoding process commenced, and subsequently decoding these sets independently using different models that were specific to the class predicted for the source sentence by classifier that was run over the source sentences in pre-processing pass.</citsent>
<aftsection>
<nextsent>our approach is in many ways generalization of this work.
</nextsent>
<nextsent>our technique allows the use of multiple model sets within the decoding process itself.
</nextsent>
<nextsent>the contributions of each model set can be controlled dynamically during the decoding through set of interpolation weights.
</nextsent>
<nextsent>these weights can be changed on sentence-by-sentence basis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1135">
<title id=" W08-0334.xml">dynamic model interpolation for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we found the results were corpus-dependent, but in most cases our system was able to improve translation performance, and for some languages the improvements were substantial.
</prevsent>
<prevsent>topic-dependent modeling has proven to be an effective way to improve quality the quality of models in speech recognition (iyer and osendorf, 1994; carter, 1994).<papid> A94-1010 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-0717 ">
recently, experiments in the field of machine translation (hasan and ney, 2005; yamamoto and sumita, 2007; <papid> D07-1054 </papid>finch et al 2007, foster and kuhn, 2007) <papid> W07-0717 </papid>have shown that class specific models are also useful for translation.in the method proposed by yamamoto and sumita (2007), <papid> D07-1054 </papid>topic dependency was implemented by partitioning the data into sets before the decoding process commenced, and subsequently decoding these sets independently using different models that were specific to the class predicted for the source sentence by classifier that was run over the source sentences in pre-processing pass.</citsent>
<aftsection>
<nextsent>our approach is in many ways generalization of this work.
</nextsent>
<nextsent>our technique allows the use of multiple model sets within the decoding process itself.
</nextsent>
<nextsent>the contributions of each model set can be controlled dynamically during the decoding through set of interpolation weights.
</nextsent>
<nextsent>these weights can be changed on sentence-by-sentence basis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1142">
<title id=" W08-0334.xml">dynamic model interpolation for statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this reduced the memory overhead considerably when loading multiple models, without noticeably affecting decoding time.
</prevsent>
<prevsent>moreover, it is also possible to pre compute the interpolated probabilities for most of the models for each sentence before the search commences, reducing both search memory and processing time.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
decoding conditions for tuning of the decoder parameters, minimum error training (och 2003) <papid> P03-1021 </papid>with respect to the bleu score using was conducted using the respective development corpus.</citsent>
<aftsection>
<nextsent>a 5-gram language model, built using the sri language modeling toolkit (stolcke, 1999) with witten-bell smoothing was used.
</nextsent>
<nextsent>the model included length model, and also the simple distance-based distortion model used by the pharaoh decoder (koehn, 2004).
</nextsent>
<nextsent>source baseline no classifier hard proposed ar 0.4457 (0.00) 0.4457 (0.00) 0.4457 (0.00) 0.4457 da 0.6598 (0.64) 0.6647 (-0.11) 0.6591 (0.74) 0.664 de 0.6590 (0.79) 0.6651 (-0.14) 0.6634 (0.12) 0.6642 es 0.7345 (0.00) 0.7345 (0.00) 0.7345 (0.00) 0.7345 fr 0.6603 (0.95) 0.6594 (1.09) 0.6605 (0.92) 0.6666 id 0.4833 (9.56) 0.5029 (5.29) 0.5276 (0.36) 0.5295 it 0.6635 (1.01) 0.6660 (0.63) 0.6644 (0.87) 0.6702 ja 0.5771 (3.47) 0.5796 (3.02) 0.5667 (5.36) 0.5971 ko 0.5795 (1.78) 0.5837 (1.05) 0.5922 (-0.41) 0.5898 ms 0.4630 (10.19) 0.5015 (1.73) 0.5057 (0.89) 0.5102 nl 0.6734 (2.55) 0.6902 (0.06) 0.6879 (0.39) 0.6906 pt 0.6600 (0.35) 0.6643 (-0.30) 0.6598 (0.38) 0.6623 ru 0.5857 (0.34) 0.5885 (-0.14) 0.5844 (0.56) 0.5877 th 0.4785 (1.50) 0.4815 (0.87) 0.4831 (0.54) 0.4857 vi 0.5084 (0.67) 0.5095 (0.45) 0.5041 (1.53) 0.5118 zh 0.5742 (0.00) 0.5742 (0.00) 0.5742 (0.00) 0.5742 table 4.
</nextsent>
<nextsent>performance results coma paring our proposes method with other techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1143">
<title id=" W08-0334.xml">dynamic model interpolation for statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>models with respect to their weight parameter.
</prevsent>
<prevsent>evaluation scheme sto obtain balanced view of the merits of our proposed approach, in our experiments we used 6 evaluation techniques to evaluate our systems.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
these were: bleu (papineni, 2001), nist (dod dington, 2002), wer (word error rate), per (position-independent wer), gtm (general text matcher), and meteor (banerjee and lavie, 2005).<papid> W05-0909 </papid></citsent>
<aftsection>
<nextsent>4.2 classification accuracy.
</nextsent>
<nextsent>the performance of the classifier (from 10-fold cross-validation on the training set) is shown in table 2.
</nextsent>
<nextsent>we give classification accuracy figures for predicting both source (same language) and target (english) punctuation.
</nextsent>
<nextsent>unsurprisingly, all systems were better at predicting their own punctuation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1145">
<title id=" W07-1106.xml">pulling their weight exploiting syntactic forms for the automatic identification of idiomatic expressions in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mostmwes need to be treated as single units of meaning, e.g., make decision roughly means decide?.
</prevsent>
<prevsent>nonetheless, the components of an mwe can be separated, making it hard for an nlp system to identify the expression as whole.
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
many researchers have recently developed methods for the automatic acquisition of various properties of mwes from corpora (lin, 1999; <papid> P99-1041 </papid>krenn and evert, 2001; baldwin et al., 2003; <papid> W03-1812 </papid>mccarthy et al, 2003; <papid> W03-1810 </papid>venkatapathy and joshi, 2005; <papid> H05-1113 </papid>villada moiron and tiedemann, 2006; fazly and stevenson, 2006).<papid> E06-1043 </papid></citsent>
<aftsection>
<nextsent>these studies look into properties, such as the collocational behaviour of mwes, their semantic non-compositionality, and their lexico syntactic fixed ness, in order to distinguish them from similar-on-the-surface literal com binations.most of these methods have been aimed at recognizing mwe types; less attention has been paid to the identification of instances (tokens) of mwes in context.
</nextsent>
<nextsent>for example, most such techniques (ifsuccessful) would identify make face as potential mwe.
</nextsent>
<nextsent>this expression is, however, ambiguous between an idiom, as in the little girl made funny face at her mother, and literal combination, as in she made face on the snowman using carrot and two buttons.
</nextsent>
<nextsent>despite the common perception that phrases that can be idioms are mainly used in their idiomatic sense, our analysis of 60 idioms has shownotherwise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1147">
<title id=" W07-1106.xml">pulling their weight exploiting syntactic forms for the automatic identification of idiomatic expressions in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mostmwes need to be treated as single units of meaning, e.g., make decision roughly means decide?.
</prevsent>
<prevsent>nonetheless, the components of an mwe can be separated, making it hard for an nlp system to identify the expression as whole.
</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
many researchers have recently developed methods for the automatic acquisition of various properties of mwes from corpora (lin, 1999; <papid> P99-1041 </papid>krenn and evert, 2001; baldwin et al., 2003; <papid> W03-1812 </papid>mccarthy et al, 2003; <papid> W03-1810 </papid>venkatapathy and joshi, 2005; <papid> H05-1113 </papid>villada moiron and tiedemann, 2006; fazly and stevenson, 2006).<papid> E06-1043 </papid></citsent>
<aftsection>
<nextsent>these studies look into properties, such as the collocational behaviour of mwes, their semantic non-compositionality, and their lexico syntactic fixed ness, in order to distinguish them from similar-on-the-surface literal com binations.most of these methods have been aimed at recognizing mwe types; less attention has been paid to the identification of instances (tokens) of mwes in context.
</nextsent>
<nextsent>for example, most such techniques (ifsuccessful) would identify make face as potential mwe.
</nextsent>
<nextsent>this expression is, however, ambiguous between an idiom, as in the little girl made funny face at her mother, and literal combination, as in she made face on the snowman using carrot and two buttons.
</nextsent>
<nextsent>despite the common perception that phrases that can be idioms are mainly used in their idiomatic sense, our analysis of 60 idioms has shownotherwise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1148">
<title id=" W07-1106.xml">pulling their weight exploiting syntactic forms for the automatic identification of idiomatic expressions in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mostmwes need to be treated as single units of meaning, e.g., make decision roughly means decide?.
</prevsent>
<prevsent>nonetheless, the components of an mwe can be separated, making it hard for an nlp system to identify the expression as whole.
</prevsent>
</prevsection>
<citsent citstr=" W03-1810 ">
many researchers have recently developed methods for the automatic acquisition of various properties of mwes from corpora (lin, 1999; <papid> P99-1041 </papid>krenn and evert, 2001; baldwin et al., 2003; <papid> W03-1812 </papid>mccarthy et al, 2003; <papid> W03-1810 </papid>venkatapathy and joshi, 2005; <papid> H05-1113 </papid>villada moiron and tiedemann, 2006; fazly and stevenson, 2006).<papid> E06-1043 </papid></citsent>
<aftsection>
<nextsent>these studies look into properties, such as the collocational behaviour of mwes, their semantic non-compositionality, and their lexico syntactic fixed ness, in order to distinguish them from similar-on-the-surface literal com binations.most of these methods have been aimed at recognizing mwe types; less attention has been paid to the identification of instances (tokens) of mwes in context.
</nextsent>
<nextsent>for example, most such techniques (ifsuccessful) would identify make face as potential mwe.
</nextsent>
<nextsent>this expression is, however, ambiguous between an idiom, as in the little girl made funny face at her mother, and literal combination, as in she made face on the snowman using carrot and two buttons.
</nextsent>
<nextsent>despite the common perception that phrases that can be idioms are mainly used in their idiomatic sense, our analysis of 60 idioms has shownotherwise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1150">
<title id=" W07-1106.xml">pulling their weight exploiting syntactic forms for the automatic identification of idiomatic expressions in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mostmwes need to be treated as single units of meaning, e.g., make decision roughly means decide?.
</prevsent>
<prevsent>nonetheless, the components of an mwe can be separated, making it hard for an nlp system to identify the expression as whole.
</prevsent>
</prevsection>
<citsent citstr=" H05-1113 ">
many researchers have recently developed methods for the automatic acquisition of various properties of mwes from corpora (lin, 1999; <papid> P99-1041 </papid>krenn and evert, 2001; baldwin et al., 2003; <papid> W03-1812 </papid>mccarthy et al, 2003; <papid> W03-1810 </papid>venkatapathy and joshi, 2005; <papid> H05-1113 </papid>villada moiron and tiedemann, 2006; fazly and stevenson, 2006).<papid> E06-1043 </papid></citsent>
<aftsection>
<nextsent>these studies look into properties, such as the collocational behaviour of mwes, their semantic non-compositionality, and their lexico syntactic fixed ness, in order to distinguish them from similar-on-the-surface literal com binations.most of these methods have been aimed at recognizing mwe types; less attention has been paid to the identification of instances (tokens) of mwes in context.
</nextsent>
<nextsent>for example, most such techniques (ifsuccessful) would identify make face as potential mwe.
</nextsent>
<nextsent>this expression is, however, ambiguous between an idiom, as in the little girl made funny face at her mother, and literal combination, as in she made face on the snowman using carrot and two buttons.
</nextsent>
<nextsent>despite the common perception that phrases that can be idioms are mainly used in their idiomatic sense, our analysis of 60 idioms has shownotherwise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1151">
<title id=" W07-1106.xml">pulling their weight exploiting syntactic forms for the automatic identification of idiomatic expressions in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mostmwes need to be treated as single units of meaning, e.g., make decision roughly means decide?.
</prevsent>
<prevsent>nonetheless, the components of an mwe can be separated, making it hard for an nlp system to identify the expression as whole.
</prevsent>
</prevsection>
<citsent citstr=" E06-1043 ">
many researchers have recently developed methods for the automatic acquisition of various properties of mwes from corpora (lin, 1999; <papid> P99-1041 </papid>krenn and evert, 2001; baldwin et al., 2003; <papid> W03-1812 </papid>mccarthy et al, 2003; <papid> W03-1810 </papid>venkatapathy and joshi, 2005; <papid> H05-1113 </papid>villada moiron and tiedemann, 2006; fazly and stevenson, 2006).<papid> E06-1043 </papid></citsent>
<aftsection>
<nextsent>these studies look into properties, such as the collocational behaviour of mwes, their semantic non-compositionality, and their lexico syntactic fixed ness, in order to distinguish them from similar-on-the-surface literal com binations.most of these methods have been aimed at recognizing mwe types; less attention has been paid to the identification of instances (tokens) of mwes in context.
</nextsent>
<nextsent>for example, most such techniques (ifsuccessful) would identify make face as potential mwe.
</nextsent>
<nextsent>this expression is, however, ambiguous between an idiom, as in the little girl made funny face at her mother, and literal combination, as in she made face on the snowman using carrot and two buttons.
</nextsent>
<nextsent>despite the common perception that phrases that can be idioms are mainly used in their idiomatic sense, our analysis of 60 idioms has shownotherwise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1154">
<title id=" W07-1106.xml">pulling their weight exploiting syntactic forms for the automatic identification of idiomatic expressions in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we found that close to half of these idioms also have clear literal meaning; and of the expressions with literal meaning, on average around 40% of their usages are literal.
</prevsent>
<prevsent>distinguishing token phrases as mwes or literal combinations of words is thus essential for nlp applications that require the identification of multiword semantic units, such as semantic parsing and machine translation.recent studies addressing mwe token classification mainly perform the task as one of word sense disambiguation, and draw on the local context of an expression to disambiguate it.
</prevsent>
</prevsection>
<citsent citstr=" E06-1042 ">
such techniques either do not use any information regarding the linguistic properties of mwes (birkeand sarkar, 2006), <papid> E06-1042 </papid>or mainly focus on their noncompositionality (katz and giesbrecht, 2006).<papid> W06-1203 </papid></citsent>
<aftsection>
<nextsent>pre 41 vious work on the identification of mwe types, however, has found other properties of mwes, such as their syntactic fixed ness, to be relevant to their identification (evert et al, 2004; fazly and stevenson, 2006).<papid> E06-1043 </papid></nextsent>
<nextsent>in this paper, we propose techniques that draw on this property to classify individual tokens of potentially idiomatic phrase as literal or idiomatic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1155">
<title id=" W07-1106.xml">pulling their weight exploiting syntactic forms for the automatic identification of idiomatic expressions in context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we found that close to half of these idioms also have clear literal meaning; and of the expressions with literal meaning, on average around 40% of their usages are literal.
</prevsent>
<prevsent>distinguishing token phrases as mwes or literal combinations of words is thus essential for nlp applications that require the identification of multiword semantic units, such as semantic parsing and machine translation.recent studies addressing mwe token classification mainly perform the task as one of word sense disambiguation, and draw on the local context of an expression to disambiguate it.
</prevsent>
</prevsection>
<citsent citstr=" W06-1203 ">
such techniques either do not use any information regarding the linguistic properties of mwes (birkeand sarkar, 2006), <papid> E06-1042 </papid>or mainly focus on their noncompositionality (katz and giesbrecht, 2006).<papid> W06-1203 </papid></citsent>
<aftsection>
<nextsent>pre 41 vious work on the identification of mwe types, however, has found other properties of mwes, such as their syntactic fixed ness, to be relevant to their identification (evert et al, 2004; fazly and stevenson, 2006).<papid> E06-1043 </papid></nextsent>
<nextsent>in this paper, we propose techniques that draw on this property to classify individual tokens of potentially idiomatic phrase as literal or idiomatic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1188">
<title id=" W07-1106.xml">pulling their weight exploiting syntactic forms for the automatic identification of idiomatic expressions in context </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>here, we focus on different class of english mwes, verb+noun combinations.
</prevsent>
<prevsent>moreover, by making more direct use of their syntactic behaviour, we develop unsupervised token classification methods that perform well.
</prevsent>
</prevsection>
<citsent citstr=" P06-2046 ">
the unsupervised token classifier of hashimoto et al (2006) <papid> P06-2046 </papid>uses manually-encoded information about allowable and non-allowable syntactic transformations of japanese idioms that are roughly equivalent to our notions of canonical and non-canonical forms.</citsent>
<aftsection>
<nextsent>the rule-based classifier of uchiyama et al (2005) incorporates syntactic information about japanese compound verbs (jcvs), type of mwe composed of two verbs.
</nextsent>
<nextsent>in both cases, although the classifiers incorporate syntactic information about mwes, their manual development limits the scala bility of the approaches.
</nextsent>
<nextsent>uchiyama et al (2005) also propose statistical token classification method for jcvs.
</nextsent>
<nextsent>this method is similar to ours, in that it also uses type-based knowledge to determine the class of each token in context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1189">
<title id=" W07-1002.xml">determining the syntactic structure of medical terms in clinical notes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>last, we present the results of preliminary validation of the method and discuss several possible future directions.
</prevsent>
<prevsent>the problem of resolving structural ambiguity hasbeen previously addressed in the computational linguistics literature.
</prevsent>
</prevsection>
<citsent citstr=" J93-1005 ">
there are multiple approaches ranging from purely statistical (ratnaparkhi, 1998),to hybrid approaches that take into account the lexical semantics of the verb (hindle and rooth, 1993), <papid> J93-1005 </papid>to corpus-based, which is the approach discussed in this paper.</citsent>
<aftsection>
<nextsent>(marcus, 1980) presents an early example of corpus-based approach to syntactic ambiguity resolution.
</nextsent>
<nextsent>one type of structural ambiguity that has received much attention has to do with nominal compounds as seen in the work of (resnik, 1993), (resnik and hearst, 1993), (pustejovsky et al., 1993), <papid> J93-2005 </papid>and (lauer, 1995).(<papid> P95-1007 </papid>lauer, 1995) <papid> P95-1007 </papid>points out that the existing approaches to resolving the ambiguity of noun phrases fall roughly into two camps: adjacency and de pendency.</nextsent>
<nextsent>the proponents of the adjacency model ((liberman and sproat, 1992), (resnik, 1993) and (pustejovsky et al, 1993)) <papid> J93-2005 </papid>argue that, given three word noun phrase xyz, there are two possible analyzes [[xy]z] and [x[yz]].</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1190">
<title id=" W07-1002.xml">determining the syntactic structure of medical terms in clinical notes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>there are multiple approaches ranging from purely statistical (ratnaparkhi, 1998),to hybrid approaches that take into account the lexical semantics of the verb (hindle and rooth, 1993), <papid> J93-1005 </papid>to corpus-based, which is the approach discussed in this paper.</prevsent>
<prevsent>(marcus, 1980) presents an early example of corpus-based approach to syntactic ambiguity resolution.</prevsent>
</prevsection>
<citsent citstr=" J93-2005 ">
one type of structural ambiguity that has received much attention has to do with nominal compounds as seen in the work of (resnik, 1993), (resnik and hearst, 1993), (pustejovsky et al., 1993), <papid> J93-2005 </papid>and (lauer, 1995).(<papid> P95-1007 </papid>lauer, 1995) <papid> P95-1007 </papid>points out that the existing approaches to resolving the ambiguity of noun phrases fall roughly into two camps: adjacency and de pendency.</citsent>
<aftsection>
<nextsent>the proponents of the adjacency model ((liberman and sproat, 1992), (resnik, 1993) and (pustejovsky et al, 1993)) <papid> J93-2005 </papid>argue that, given three word noun phrase xyz, there are two possible analyzes [[xy]z] and [x[yz]].</nextsent>
<nextsent>the correct analysis is chosen based on the acceptability?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1191">
<title id=" W07-1002.xml">determining the syntactic structure of medical terms in clinical notes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>there are multiple approaches ranging from purely statistical (ratnaparkhi, 1998),to hybrid approaches that take into account the lexical semantics of the verb (hindle and rooth, 1993), <papid> J93-1005 </papid>to corpus-based, which is the approach discussed in this paper.</prevsent>
<prevsent>(marcus, 1980) presents an early example of corpus-based approach to syntactic ambiguity resolution.</prevsent>
</prevsection>
<citsent citstr=" P95-1007 ">
one type of structural ambiguity that has received much attention has to do with nominal compounds as seen in the work of (resnik, 1993), (resnik and hearst, 1993), (pustejovsky et al., 1993), <papid> J93-2005 </papid>and (lauer, 1995).(<papid> P95-1007 </papid>lauer, 1995) <papid> P95-1007 </papid>points out that the existing approaches to resolving the ambiguity of noun phrases fall roughly into two camps: adjacency and de pendency.</citsent>
<aftsection>
<nextsent>the proponents of the adjacency model ((liberman and sproat, 1992), (resnik, 1993) and (pustejovsky et al, 1993)) <papid> J93-2005 </papid>argue that, given three word noun phrase xyz, there are two possible analyzes [[xy]z] and [x[yz]].</nextsent>
<nextsent>the correct analysis is chosen based on the acceptability?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1205">
<title id=" W07-1002.xml">determining the syntactic structure of medical terms in clinical notes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>(lapata and keller, 2004) results also support this assertion.
</prevsent>
<prevsent>the difference between the approaches within thetwo models is the computation of acceptability.
</prevsent>
</prevsection>
<citsent citstr=" P96-1003 ">
proposals for computing acceptability (or preference) include raw frequency counts ((evans and zhai,1996) <papid> P96-1003 </papid>and (lapata and keller, 2004)), latent semantic indexing ((buckeridge and sutcliffe, 2002)) <papid> W02-1401 </papid>and statistical measures of association ((lapata et al., 1999) <papid> E99-1005 </papid>and (nakov and hearst, 2005)).<papid> W05-0603 </papid></citsent>
<aftsection>
<nextsent>one of the main problems with using frequency counts or statistical methods for structural ambiguity resolution is the sparseness of data; however,(resnik and hearst, 1993) used conceptual associations (associations between groups of terms deemed to form conceptual units) in order to alleviate thisproblem.
</nextsent>
<nextsent>(lapata and keller, 2004) use the document counts returned by www search engines.
</nextsent>
<nextsent>(nakov and hearst, 2005) <papid> W05-0603 </papid>use the 2 measure based on statistics obtained from www search engines to compute values to determine acceptability of syntactic analysis for nominal compounds.</nextsent>
<nextsent>this method is tested using set of general english nominal compounds developed by (lauer, 1995) <papid> P95-1007 </papid>as well as set of nominal compounds extracted from medline abstracts.the novel contribution of our study is in demonstrating and validating corpus-based method for determining the syntactic structure of medical terms that relies on using the statistical measure of association, the log likelihood ratio, described in the following section.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1206">
<title id=" W07-1002.xml">determining the syntactic structure of medical terms in clinical notes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>(lapata and keller, 2004) results also support this assertion.
</prevsent>
<prevsent>the difference between the approaches within thetwo models is the computation of acceptability.
</prevsent>
</prevsection>
<citsent citstr=" W02-1401 ">
proposals for computing acceptability (or preference) include raw frequency counts ((evans and zhai,1996) <papid> P96-1003 </papid>and (lapata and keller, 2004)), latent semantic indexing ((buckeridge and sutcliffe, 2002)) <papid> W02-1401 </papid>and statistical measures of association ((lapata et al., 1999) <papid> E99-1005 </papid>and (nakov and hearst, 2005)).<papid> W05-0603 </papid></citsent>
<aftsection>
<nextsent>one of the main problems with using frequency counts or statistical methods for structural ambiguity resolution is the sparseness of data; however,(resnik and hearst, 1993) used conceptual associations (associations between groups of terms deemed to form conceptual units) in order to alleviate thisproblem.
</nextsent>
<nextsent>(lapata and keller, 2004) use the document counts returned by www search engines.
</nextsent>
<nextsent>(nakov and hearst, 2005) <papid> W05-0603 </papid>use the 2 measure based on statistics obtained from www search engines to compute values to determine acceptability of syntactic analysis for nominal compounds.</nextsent>
<nextsent>this method is tested using set of general english nominal compounds developed by (lauer, 1995) <papid> P95-1007 </papid>as well as set of nominal compounds extracted from medline abstracts.the novel contribution of our study is in demonstrating and validating corpus-based method for determining the syntactic structure of medical terms that relies on using the statistical measure of association, the log likelihood ratio, described in the following section.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1207">
<title id=" W07-1002.xml">determining the syntactic structure of medical terms in clinical notes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>(lapata and keller, 2004) results also support this assertion.
</prevsent>
<prevsent>the difference between the approaches within thetwo models is the computation of acceptability.
</prevsent>
</prevsection>
<citsent citstr=" E99-1005 ">
proposals for computing acceptability (or preference) include raw frequency counts ((evans and zhai,1996) <papid> P96-1003 </papid>and (lapata and keller, 2004)), latent semantic indexing ((buckeridge and sutcliffe, 2002)) <papid> W02-1401 </papid>and statistical measures of association ((lapata et al., 1999) <papid> E99-1005 </papid>and (nakov and hearst, 2005)).<papid> W05-0603 </papid></citsent>
<aftsection>
<nextsent>one of the main problems with using frequency counts or statistical methods for structural ambiguity resolution is the sparseness of data; however,(resnik and hearst, 1993) used conceptual associations (associations between groups of terms deemed to form conceptual units) in order to alleviate thisproblem.
</nextsent>
<nextsent>(lapata and keller, 2004) use the document counts returned by www search engines.
</nextsent>
<nextsent>(nakov and hearst, 2005) <papid> W05-0603 </papid>use the 2 measure based on statistics obtained from www search engines to compute values to determine acceptability of syntactic analysis for nominal compounds.</nextsent>
<nextsent>this method is tested using set of general english nominal compounds developed by (lauer, 1995) <papid> P95-1007 </papid>as well as set of nominal compounds extracted from medline abstracts.the novel contribution of our study is in demonstrating and validating corpus-based method for determining the syntactic structure of medical terms that relies on using the statistical measure of association, the log likelihood ratio, described in the following section.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1208">
<title id=" W07-1002.xml">determining the syntactic structure of medical terms in clinical notes </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>(lapata and keller, 2004) results also support this assertion.
</prevsent>
<prevsent>the difference between the approaches within thetwo models is the computation of acceptability.
</prevsent>
</prevsection>
<citsent citstr=" W05-0603 ">
proposals for computing acceptability (or preference) include raw frequency counts ((evans and zhai,1996) <papid> P96-1003 </papid>and (lapata and keller, 2004)), latent semantic indexing ((buckeridge and sutcliffe, 2002)) <papid> W02-1401 </papid>and statistical measures of association ((lapata et al., 1999) <papid> E99-1005 </papid>and (nakov and hearst, 2005)).<papid> W05-0603 </papid></citsent>
<aftsection>
<nextsent>one of the main problems with using frequency counts or statistical methods for structural ambiguity resolution is the sparseness of data; however,(resnik and hearst, 1993) used conceptual associations (associations between groups of terms deemed to form conceptual units) in order to alleviate thisproblem.
</nextsent>
<nextsent>(lapata and keller, 2004) use the document counts returned by www search engines.
</nextsent>
<nextsent>(nakov and hearst, 2005) <papid> W05-0603 </papid>use the 2 measure based on statistics obtained from www search engines to compute values to determine acceptability of syntactic analysis for nominal compounds.</nextsent>
<nextsent>this method is tested using set of general english nominal compounds developed by (lauer, 1995) <papid> P95-1007 </papid>as well as set of nominal compounds extracted from medline abstracts.the novel contribution of our study is in demonstrating and validating corpus-based method for determining the syntactic structure of medical terms that relies on using the statistical measure of association, the log likelihood ratio, described in the following section.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1215">
<title id=" W07-1002.xml">determining the syntactic structure of medical terms in clinical notes </title>
<section> log likelihood ratio.  </section>
<citcontext>
<prevsection>
<prevsent>the log likelihood ratio (g2) is goodness of fit?
</prevsent>
<prevsent>statistic first proposed by (wilks, 1938) to test if given piece of data is sample from set of data with specific distribution described by hypothesized model.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
it was later applied by (dunning, 1993)<papid> J93-1003 </papid>as way to determine if sequence of words (ngram) came from an independently distributed sam ple.(pedersen et al, 1996) pointed out that there exists theoretical assumptions underlying the g2 measure that were being violated therefore making them unreliable for significance testing.</citsent>
<aftsection>
<nextsent>(moore, 2004) <papid> W04-3243 </papid>provided additional evidence that although g2 may not be useful for determining the significance of an event, its near equivalence to mutual information makes it an appropriate measure of word association.</nextsent>
<nextsent>(mcinnes, 2004) applied g2 to the task of extracting three and four word collocations from raw text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1216">
<title id=" W07-1002.xml">determining the syntactic structure of medical terms in clinical notes </title>
<section> log likelihood ratio.  </section>
<citcontext>
<prevsection>
<prevsent>statistic first proposed by (wilks, 1938) to test if given piece of data is sample from set of data with specific distribution described by hypothesized model.
</prevsent>
<prevsent>it was later applied by (dunning, 1993)<papid> J93-1003 </papid>as way to determine if sequence of words (ngram) came from an independently distributed sam ple.(pedersen et al, 1996) pointed out that there exists theoretical assumptions underlying the g2 measure that were being violated therefore making them unreliable for significance testing.</prevsent>
</prevsection>
<citsent citstr=" W04-3243 ">
(moore, 2004) <papid> W04-3243 </papid>provided additional evidence that although g2 may not be useful for determining the significance of an event, its near equivalence to mutual information makes it an appropriate measure of word association.</citsent>
<aftsection>
<nextsent>(mcinnes, 2004) applied g2 to the task of extracting three and four word collocations from raw text.
</nextsent>
<nextsent>g2, formally defined for trigrams in equation 4, compares the observed frequency counts with the counts that would be expected if the words in the trigram (3-gram; sequence of three words) corresponded to the hypothesized model.
</nextsent>
<nextsent>g2 = 2 ? ?
</nextsent>
<nextsent>x,y,z nxyz ? log( nxyz mxyz ) (4) the parameter nxyz is the observed frequency of the trigram where x, y, and respectively represent the occurrence of the first, second and third words in the trigram.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1219">
<title id=" W07-1002.xml">determining the syntactic structure of medical terms in clinical notes </title>
<section> limitations.  </section>
<citcontext>
<prevsection>
<prevsent>this is an example based on informal observations; however, it does suggest utility in constructing frame-based representation of at least some clinical terms.
</prevsent>
<prevsent>the main limitation of the g2 method is the exponential growth in the number of models to be evaluated with the growth in the length of the term.
</prevsent>
</prevsection>
<citsent citstr=" A97-1056 ">
this limitation can be partly alleviated by either only considering adjacent models and limiting the length to5-6 words, or using forward or backward sequential search proposed by (pedersen et al, 1997) <papid> A97-1056 </papid>for the problem of selecting models for the word sense disambiguation task.</citsent>
<aftsection>
<nextsent>this paper presented simple but effective method based on g2 to determine the internal structure ofthree-word noun phrase medical terms.
</nextsent>
<nextsent>the ability to determine the syntactic structure that gives rise to particular semantic interpretation of medical term may enable accurate mapping of unstructured medical text to standardized terminologies andnomenclatures.
</nextsent>
<nextsent>future directions to improve the accuracy of our method include determining how other measures of association, such as dice coefficient and2, perform on this task.
</nextsent>
<nextsent>we feel that there is possibility that no single measure performs best over all types of terms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1220">
<title id=" W07-1009.xml">recognising nested named entities in biomedical text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>corpora in other domains, for example the ace1 data, also contain nested entities.
</prevsent>
<prevsent>this paper compares techniques for recognising nested entities in biomedical text.
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
the difficulty ofthis task is that the standard method for converting ner to sequence tagging problem with bio encoding (ramshaw and marcus, 1995), <papid> W95-0107 </papid>where each 1http://www.nist.gov/speech/tests/ace/ index.htm token is assigned tag to indicate whether it is at the beginning (b), inside (i), or outside (o) of an entity, is not directly applicable when tokens belong to more than one entity.</citsent>
<aftsection>
<nextsent>here we explore methods of reducing the nested ner problem to one or more bio problems so that existing ner tools can be used.
</nextsent>
<nextsent>this paper is organised as follows.
</nextsent>
<nextsent>in section 2,the problem of nested entities is introduced and motivated with examples from genia and our eppi (enriched protein-protein interaction) data.
</nextsent>
<nextsent>related work is reviewed in section 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1221">
<title id=" W07-1009.xml">recognising nested named entities in biomedical text </title>
<section> coordinated entities. coordinated nes account.  </section>
<citcontext>
<prevsection>
<prevsent>3 related work.
</prevsent>
<prevsent>in previous work addressing nested entities, shen et al.
</prevsent>
</prevsection>
<citsent citstr=" W06-3318 ">
(2003), zhang et al (2004), zhou et al (2004), zhou (2006), and gu (2006) <papid> W06-3318 </papid>considered the genia2both corpora are represented in xml with standoff annotation, potentionally allowing overlapping nes.</citsent>
<aftsection>
<nextsent>66 corpus, where nested entities are relatively frequent.all these studies ignore embedded entities occur ring in coordinated structures and only retain their outermost annotation.
</nextsent>
<nextsent>shen et al (2003), <papid> W03-1307 </papid>zhang etal.</nextsent>
<nextsent>(2004), and zhou et al (2004) all report on rule based approach to dealing with nested nes in the genia corpus (version 3.0) in combination with hidden markov model (hmm) that first recognises innermost nes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1223">
<title id=" W07-1009.xml">recognising nested named entities in biomedical text </title>
<section> coordinated entities. coordinated nes account.  </section>
<citcontext>
<prevsection>
<prevsent>(2003), zhang et al (2004), zhou et al (2004), zhou (2006), and gu (2006) <papid> W06-3318 </papid>considered the genia2both corpora are represented in xml with standoff annotation, potentionally allowing overlapping nes.</prevsent>
<prevsent>66 corpus, where nested entities are relatively frequent.all these studies ignore embedded entities occur ring in coordinated structures and only retain their outermost annotation.</prevsent>
</prevsection>
<citsent citstr=" W03-1307 ">
shen et al (2003), <papid> W03-1307 </papid>zhang etal.</citsent>
<aftsection>
<nextsent>(2004), and zhou et al (2004) all report on rule based approach to dealing with nested nes in the genia corpus (version 3.0) in combination with hidden markov model (hmm) that first recognises innermost nes.
</nextsent>
<nextsent>they use four basic hand-craftedpatterns and combination thereof to generate nesting rules from the training data and thereby derive nes containing the innermost nes.
</nextsent>
<nextsent>the experimental setup of these studies differs slightly.
</nextsent>
<nextsent>while shen et al (2003) <papid> W03-1307 </papid>and zhang et al (2004) report results testing on 4% of the abstracts in the genia corpus, zhou et al (2004) report 10-fold cross-validation scores.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1230">
<title id=" W07-1009.xml">recognising nested named entities in biomedical text </title>
<section> coordinated entities. coordinated nes account.  </section>
<citcontext>
<prevsection>
<prevsent>gu (2006) <papid> W06-3318 </papid>reports results on recognising nested entities in the genia corpus (version 3.02) when training an svm-light binary classifier to recognise either proteins or dna.</prevsent>
<prevsent>training with the outermost labelling yields better performance on recognising outermost entities and, conversely, using the inner labelling results in highest scores for recognising inner entities.</prevsent>
</prevsection>
<citsent citstr=" H05-1124 ">
the best exact match f1-scores of 73.0and 47.5 for proteins and dna, respectively, are obtained when training on data with inner labelling and evaluating on the inner entities.mcdonald et al (2005) <papid> H05-1124 </papid>propose structured multil abel classification as opposed to sequential labelling for dealing with nested, discontinuous, and overlapping nes.</citsent>
<aftsection>
<nextsent>this approach uses novel text segment representation in preference to the bio-encoding.
</nextsent>
<nextsent>their corpus contains medline abstracts on the inhibition of the enzyme cyp450 (kulick et al, 2004), <papid> W04-3111 </papid>specifically those abstracts that contain atleast one overlapping and one discontinuous anno tation.</nextsent>
<nextsent>while this data does not contain nested nes, discontinuous and overlapping nes make up 6% of all nes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1231">
<title id=" W07-1009.xml">recognising nested named entities in biomedical text </title>
<section> coordinated entities. coordinated nes account.  </section>
<citcontext>
<prevsection>
<prevsent>the best exact match f1-scores of 73.0and 47.5 for proteins and dna, respectively, are obtained when training on data with inner labelling and evaluating on the inner entities.mcdonald et al (2005) <papid> H05-1124 </papid>propose structured multil abel classification as opposed to sequential labelling for dealing with nested, discontinuous, and overlapping nes.</prevsent>
<prevsent>this approach uses novel text segment representation in preference to the bio-encoding.</prevsent>
</prevsection>
<citsent citstr=" W04-3111 ">
their corpus contains medline abstracts on the inhibition of the enzyme cyp450 (kulick et al, 2004), <papid> W04-3111 </papid>specifically those abstracts that contain atleast one overlapping and one discontinuous anno tation.</citsent>
<aftsection>
<nextsent>while this data does not contain nested nes, discontinuous and overlapping nes make up 6% of all nes.
</nextsent>
<nextsent>the classifier performs competitively with sequential tagging models on continuous and nonoverlapping entities for ner and noun phrase chunking.
</nextsent>
<nextsent>on discontinuous and overlapping nes in the biomedical data alone, its best performance is 56.25 f1.
</nextsent>
<nextsent>as the corpus does not contain nested nes, it would be of interest to investigate the algorithms performance on the genia corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1232">
<title id=" W07-1009.xml">recognising nested named entities in biomedical text </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>thiscan result in data sparsity which may have detrimental effect on performance.
</prevsent>
<prevsent>5.1 corpora.
</prevsent>
</prevsection>
<citsent citstr=" W05-1306 ">
genia (v3.02), large publicly available biomedical corpus annotated with biomedical nes, is widely used in the text mining community (cohen et al,2005).<papid> W05-1306 </papid></citsent>
<aftsection>
<nextsent>this dataset consists of 2,000 medline abstracts in the domain of molecular biology (0.5m tokens).
</nextsent>
<nextsent>the annotations used for the experiments 68 reported here are based on the genia ontology,published in ohta et al (2002).
</nextsent>
<nextsent>it contains the following classes: amino acid monomer, atom, body part, carbohydrate, cell component, cell line, cell type, dna, inorganic, lipid, mono-cell, multi-cell, nucleotide, other name, other artificial source, other organic compound, peptide, poly nucleotide, protein, rna, tissue, and virus.
</nextsent>
<nextsent>in this work, protein, dna and rna sub-types are collapsed to their super-type, as done in previous studies (e.g. zhou 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1233">
<title id=" W07-1009.xml">recognising nested named entities in biomedical text </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the experiments described here involve the eppi train and devtest sets.
</prevsent>
<prevsent>5.2 pre-processing.
</prevsent>
</prevsection>
<citsent citstr=" W06-2703 ">
all documents are passed through sequence of preprocessing steps implemented using the lt-xml2and lt-ttt2 tools (grover et al, 2006) <papid> W06-2703 </papid>with the output of each step encoded in xml mark-up.</citsent>
<aftsection>
<nextsent>token isation and sentence splitting is followed by part-of speech tagging with the maximum entropy markov model (memm) tagger developed by curran and clark (2003) (<papid> W03-0424 </papid>hereafter referred to as c&c; ) for the conll-2003 shared task (tjong kim sang and de meulder, 2003), trained on the medpost data(smith et al, 2004).</nextsent>
<nextsent>information on lemma tisa tion, as well as abbreviations and their long forms, is added using the morpha lemmatiser (minnen et al, 2000) <papid> W00-1427 </papid>and the extractabbrev script of schwartz and hearst (2003), respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1234">
<title id=" W07-1009.xml">recognising nested named entities in biomedical text </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 pre-processing.
</prevsent>
<prevsent>all documents are passed through sequence of preprocessing steps implemented using the lt-xml2and lt-ttt2 tools (grover et al, 2006) <papid> W06-2703 </papid>with the output of each step encoded in xml mark-up.</prevsent>
</prevsection>
<citsent citstr=" W03-0424 ">
token isation and sentence splitting is followed by part-of speech tagging with the maximum entropy markov model (memm) tagger developed by curran and clark (2003) (<papid> W03-0424 </papid>hereafter referred to as c&c; ) for the conll-2003 shared task (tjong kim sang and de meulder, 2003), trained on the medpost data(smith et al, 2004).</citsent>
<aftsection>
<nextsent>information on lemma tisa tion, as well as abbreviations and their long forms, is added using the morpha lemmatiser (minnen et al, 2000) <papid> W00-1427 </papid>and the extractabbrev script of schwartz and hearst (2003), respectively.</nextsent>
<nextsent>a lookup step uses onto logical information to identify scientific and common english names of species.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1235">
<title id=" W07-1009.xml">recognising nested named entities in biomedical text </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>all documents are passed through sequence of preprocessing steps implemented using the lt-xml2and lt-ttt2 tools (grover et al, 2006) <papid> W06-2703 </papid>with the output of each step encoded in xml mark-up.</prevsent>
<prevsent>token isation and sentence splitting is followed by part-of speech tagging with the maximum entropy markov model (memm) tagger developed by curran and clark (2003) (<papid> W03-0424 </papid>hereafter referred to as c&c; ) for the conll-2003 shared task (tjong kim sang and de meulder, 2003), trained on the medpost data(smith et al, 2004).</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
information on lemma tisa tion, as well as abbreviations and their long forms, is added using the morpha lemmatiser (minnen et al, 2000) <papid> W00-1427 </papid>and the extractabbrev script of schwartz and hearst (2003), respectively.</citsent>
<aftsection>
<nextsent>a lookup step uses onto logical information to identify scientific and common english names of species.
</nextsent>
<nextsent>finally, rule-based chunker marks up noun and verb groups and their heads (grover and tobin, 2006).
</nextsent>
<nextsent>5.3 named entity tagging.
</nextsent>
<nextsent>the c&c; tagger, referred to earlier, forms the basis of the ner component of the txm natural language processing (nlp) pipeline designed to detect entity relations and normalisations (grover et al, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1237">
<title id=" W07-2108.xml">wvali temporal relation identification by syntacticosemantic analysis </title>
<section> task a.  </section>
<citcontext>
<prevsection>
<prevsent>for all tasks, the set of temporal relations to be predicted includes: overlap, before, after, 484 before-or-overlap, overlap-or-after and vague.
</prevsent>
<prevsent>figure 1 depicts the processing stages involved in the identification of the temporal relation given the event, the te and the sentence they arein.
</prevsent>
</prevsection>
<citsent citstr=" A97-1011 ">
the sentence is first annotated with morphosyntactic and functional dependency information by employing con exors fdg parser (tapanainen and jaervinen, 1997).<papid> A97-1011 </papid></citsent>
<aftsection>
<nextsent>figure 1: task processing stages clause splitter previously developed by the author is then used to detect clause boundaries and to establish the dependencies between the resulting clauses by relying on formal indicators of coordination and subordination and, in their absence, on the functional dependency relation predicted by the fdg parser.
</nextsent>
<nextsent>on the basis of the morpho-syntactic information we identify in each clause set of temporally-relevant constituents (verb phrase vp, noun phrases nps, prepositional phrases pps, non-finite verbs and adverbial tes).
</nextsent>
<nextsent>the identified constituents and the syntactic tree of the corresponding clause are afterwards employed in recursive bottom-up process of finding the temporal order between directly linked constituents.
</nextsent>
<nextsent>each constituent is linked only with the constituent it syntactically depends on with one of the predefined temporal relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1238">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, we devise afast training algorithm to achieve such improved models based on tree kernel methods.
</prevsent>
<prevsent>experiments on an english-to-chinese task demonstrate that our proposed models outperformed the baseline formally syntax based models, while both of them achieved significant improvements over state-of-the art phrase-based smt system.
</prevsent>
</prevsection>
<citsent citstr=" P06-1077 ">
in recent years, syntax-based translation models (chiang, 2007; galley et al, 2004; liu et al, 2006)<papid> P06-1077 </papid>have shown promising progress in improving translation quality.</citsent>
<aftsection>
<nextsent>there are two major elements accounting for such an improvement: namely the incorporation of phrasal translation structures adopted from widely applied phrase-based models (och and ney, 2004) <papid> J04-4002 </papid>to handle local fluency, and the engagement of synchronous context-free grammars (scfg), which enhances the generative capacity of the underlying model that is limited by finite-state machinery.</nextsent>
<nextsent>approaches to syntax-based translation models using scfg can be further categorized into two classes, based on their dependency on annotated cor pus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1239">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments on an english-to-chinese task demonstrate that our proposed models outperformed the baseline formally syntax based models, while both of them achieved significant improvements over state-of-the art phrase-based smt system.
</prevsent>
<prevsent>in recent years, syntax-based translation models (chiang, 2007; galley et al, 2004; liu et al, 2006)<papid> P06-1077 </papid>have shown promising progress in improving translation quality.</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
there are two major elements accounting for such an improvement: namely the incorporation of phrasal translation structures adopted from widely applied phrase-based models (och and ney, 2004) <papid> J04-4002 </papid>to handle local fluency, and the engagement of synchronous context-free grammars (scfg), which enhances the generative capacity of the underlying model that is limited by finite-state machinery.</citsent>
<aftsection>
<nextsent>approaches to syntax-based translation models using scfg can be further categorized into two classes, based on their dependency on annotated corpus.
</nextsent>
<nextsent>following chiang (chiang, 2007), we note the following distinction between these two classes: ? linguistically syntax-based: models that utilize structures defined over linguistic theory and annotations (e.g., penn treebank), and scfg rules are derived from parallel corpus that is guided by explicitly parsing on at least one side of the parallel corpus.
</nextsent>
<nextsent>examples among others are (yamada and knight, 2001) <papid> P01-1067 </papid>and (galley et al., 2004).</nextsent>
<nextsent>formally syntax-based: models are based on hierarchical structures of natural language but synchronous grammars are automatically extracted from parallel corpus without any usageof linguistic knowledge or annotations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1240">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>approaches to syntax-based translation models using scfg can be further categorized into two classes, based on their dependency on annotated corpus.
</prevsent>
<prevsent>following chiang (chiang, 2007), we note the following distinction between these two classes: ? linguistically syntax-based: models that utilize structures defined over linguistic theory and annotations (e.g., penn treebank), and scfg rules are derived from parallel corpus that is guided by explicitly parsing on at least one side of the parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
examples among others are (yamada and knight, 2001) <papid> P01-1067 </papid>and (galley et al., 2004).</citsent>
<aftsection>
<nextsent>formally syntax-based: models are based on hierarchical structures of natural language but synchronous grammars are automatically extracted from parallel corpus without any usageof linguistic knowledge or annotations.
</nextsent>
<nextsent>examples include wus (wu, 1997) <papid> J97-3002 </papid>itg and chiangs hierarchical models (chiang, 2007).</nextsent>
<nextsent>while these two often resemble in appearance,from practical viewpoints, there are some distinctions in training and decoding procedures differentiating formally syntax-based models from linguistically syntax-based models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1241">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>examples among others are (yamada and knight, 2001) <papid> P01-1067 </papid>and (galley et al., 2004).</prevsent>
<prevsent>formally syntax-based: models are based on hierarchical structures of natural language but synchronous grammars are automatically extracted from parallel corpus without any usageof linguistic knowledge or annotations.</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
examples include wus (wu, 1997) <papid> J97-3002 </papid>itg and chiangs hierarchical models (chiang, 2007).</citsent>
<aftsection>
<nextsent>while these two often resemble in appearance,from practical viewpoints, there are some distinctions in training and decoding procedures differentiating formally syntax-based models from linguistically syntax-based models.
</nextsent>
<nextsent>first, the former has no dependency on available linguistic theory and annotations for targeting language pairs, and thus the training and rule extraction are more efficient.
</nextsent>
<nextsent>secondly, the decoding complexity of the former is lower 1, especially when integrating n-gram based 1the complexity is dominated by synchronous parsing and boundary words keeping.
</nextsent>
<nextsent>thus binary scfg employed informally syntax-based systems help to maintain efficient cky decoding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1242">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>secondly, the decoding complexity of the former is lower 1, especially when integrating n-gram based 1the complexity is dominated by synchronous parsing and boundary words keeping.
</prevsent>
<prevsent>thus binary scfg employed informally syntax-based systems help to maintain efficient cky decoding.
</prevsent>
</prevsection>
<citsent citstr=" N06-1033 ">
recent work by (zhang et al, 2006) <papid> N06-1033 </papid>shows practically efficient approach that binarizes linguistically scfg rules when possible.</citsent>
<aftsection>
<nextsent>19 language model, which is key element to ensure translation output quality.
</nextsent>
<nextsent>on the other hand, available linguistic theory and annotations could provide invaluable benefits in grammar induction and scoring, as shown by recent progress on such models (galley et al, 2006).<papid> P06-1121 </papid></nextsent>
<nextsent>in contrast, formally syntax-based grammars often lack explicit linguistic constraints.in this paper, we propose scheme to enrich formally syntax-based models with linguistically syntactic knowledge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1243">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent work by (zhang et al, 2006) <papid> N06-1033 </papid>shows practically efficient approach that binarizes linguistically scfg rules when possible.</prevsent>
<prevsent>19 language model, which is key element to ensure translation output quality.</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
on the other hand, available linguistic theory and annotations could provide invaluable benefits in grammar induction and scoring, as shown by recent progress on such models (galley et al, 2006).<papid> P06-1121 </papid></citsent>
<aftsection>
<nextsent>in contrast, formally syntax-based grammars often lack explicit linguistic constraints.in this paper, we propose scheme to enrich formally syntax-based models with linguistically syntactic knowledge.
</nextsent>
<nextsent>in other words, we maintain our grammar to be based on formal syntax on surface,but incorporate linguistic knowledge into our models to leverage syntax theory and annotations.
</nextsent>
<nextsent>our goal is two-fold.
</nextsent>
<nextsent>first, how to score scfg rules whose general abstraction forms are unseen in the training data is an important question to answer.in hierarchical models, chiang (chiang, 2007) utilizes heuristics where certain assumptions are made on rule distributions to obtain relative frequencycounts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1244">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this framework, prior derivation models can be viewed as smoothing of rule translation models, addressing the weakness of the baseline model estimation that relies on relative counts obtained from heuristics.
</prevsent>
<prevsent>first, we apply automatic parsers to obtain syntax annotations on the english side of the parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" E06-1015 ">
next, we extract tree fragments associated with phrase pairs, and measure similarity between such tree fragments using kernel methods (collins and duffy, 2002; moschitti, 2006).<papid> E06-1015 </papid></citsent>
<aftsection>
<nextsent>finally, we score and rank rules based on their minimal cluster similarity of their nonterminals, which is used to compute the prior distribution of hypothesis derivations during decoding for improved translation.the remainder of the paper is organized as follows.
</nextsent>
<nextsent>we start with brief review of some related work in sec.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>in sec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1247">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, sec.
</prevsent>
<prevsent>6 summarized our contributions with discussions and future work.
</prevsent>
</prevsection>
<citsent citstr=" P03-1011 ">
syntax-based translation models engaged withscfg have been actively investigated in the literature (wu, 1997; <papid> J97-3002 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>galley et al, 2004; satta and peserico, 2005).<papid> H05-1101 </papid></citsent>
<aftsection>
<nextsent>recent work by (chiang, 2007; galley et al, 2006) <papid> P06-1121 </papid>shows promising improvements compared tophrase-based models for large-scale tasks.</nextsent>
<nextsent>however, few previous work directly applied linguistically syntactic information into formally syntax based models, which is explored in this paper.kernel methods leverage the fact that the only operation in procedure is the evaluation of inner dot products between pairs of observations, where the inner product is thus replaced with mercer kernel that provides an efficient way to carry out computation when original feature dimension is large or even infinite.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1248">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, sec.
</prevsent>
<prevsent>6 summarized our contributions with discussions and future work.
</prevsent>
</prevsection>
<citsent citstr=" H05-1101 ">
syntax-based translation models engaged withscfg have been actively investigated in the literature (wu, 1997; <papid> J97-3002 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>gildea, 2003; <papid> P03-1011 </papid>galley et al, 2004; satta and peserico, 2005).<papid> H05-1101 </papid></citsent>
<aftsection>
<nextsent>recent work by (chiang, 2007; galley et al, 2006) <papid> P06-1121 </papid>shows promising improvements compared tophrase-based models for large-scale tasks.</nextsent>
<nextsent>however, few previous work directly applied linguistically syntactic information into formally syntax based models, which is explored in this paper.kernel methods leverage the fact that the only operation in procedure is the evaluation of inner dot products between pairs of observations, where the inner product is thus replaced with mercer kernel that provides an efficient way to carry out computation when original feature dimension is large or even infinite.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1252">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> formally syntax-based models.  </section>
<citcontext>
<prevsection>
<prevsent>for example, some english-to-chinese production rules can be represented as follows: ? x1enjoy readingx2, (2) x1xihuan(enjoy) yuedu(reading)x2?
</prevsent>
<prevsent>x ? x1enjoy readingx2, x1xihuan(enjoy)x2yuedu(reading)the set of rules, denoted as r, are automatically extracted from sentence-aligned parallel corpus (chiang, 2007).
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
first, bidirectional word-level alignment is carried out on the parallel corpus runninggiza++ (och and ney, 2000).<papid> P00-1056 </papid></citsent>
<aftsection>
<nextsent>based on the resulting viterbi alignments ae2f and af2e, the union, au = ae2f ? af2e, is taken as the symmetrizedword-level alignment.
</nextsent>
<nextsent>next, bilingual phrase pairs consistent with word alignments are extracted fromau (och and ney, 2004).<papid> J04-4002 </papid></nextsent>
<nextsent>specifically, any pairof consecutive sequences of words below maximum length is considered to be phrase pair if its component words are aligned only within the phrase pair and not to any words outside.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1254">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> formally syntax-based models.  </section>
<citcontext>
<prevsection>
<prevsent>i ? x? ?,? i(x ?  ?, ?  )i , (4) where the set of i(x ?  ?, ?  ) are features defined over given production rule, and plm (e) isthe language model score on hypothesized output, the is the feature weight.our baseline model follows chiangs hierarchical model (chiang, 2007) in conjunction with additional features: ? conditional probabilities in both directions: (?|?)
</prevsent>
<prevsent>and (?|?);?
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
lexical weights (koehn et al, 2003) <papid> N03-1017 </papid>in both di rections: pw(?|?)</citsent>
<aftsection>
<nextsent>and pw(?|?); 21 ? word counts |e|; ? rule counts |d|; ? target n-gram language model plm (e);?
</nextsent>
<nextsent>glue rule penalty to learn preference of nonterminal rewriting over serial combination through eq.
</nextsent>
<nextsent>3; moreover, we propose an additional feature, namely the abstraction penalty, to account for the accumulated number of nonterminals applied in d: ? abstraction penalty exp(na), where na = ? x? ?,? n(?)
</nextsent>
<nextsent>where n(?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1257">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in both cases, there are about 15k running words on english side.
</prevsent>
<prevsent>all chinese sentences in training, dev and test sets are all automatically segmented into words.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
minimum-error-rate training (och, 2003) <papid> P03-1021 </papid>are conducted on dev-set to optimize feature weights maximizing the bleu score up to 4 grams, and the obtained feature weights are blindly applied on the test-set.</citsent>
<aftsection>
<nextsent>to compare performances excluding tokenization effects, all bleu scores are optimized (on dev-set) and reported (on test-set) at chinese character-level.
</nextsent>
<nextsent>from training data, we extracted an initial phrase pair set with 3.7m entries for phrases up to 8 words on chinese side.
</nextsent>
<nextsent>we trained 4-gram language model for chinese at word level, which is shared by all translation systems reported in this paper, using the chinese side of the parallel corpus that contains around 2m segmented words.we compare the proposed models with two base lines: state-of-the-art phrase-based system and formal syntax-based system as described in sec.
</nextsent>
<nextsent>3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1258">
<title id=" W08-0403.xml">prior derivation models for formally syntax based translation using linguistically syntactic parsing and tree kernels </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, the rule ?  x1ax2, ?   comes with more than 100ktrees for the x1.table 2: english-to-chinese bleu score result on test set (character-based) models bleu(4-gram) phrase-based 42.11 formally syntax-based 43.75 formally syntax-based with prior derivation 44.51 translation results are presented in table 2with character-based bleu scores using 2 references.
</prevsent>
<prevsent>our baseline formally syntax-based models achieved the bleu score of 43.75, an absolute improvement of 1.6 point improvement overphrase-based models.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
the improvement is statistically significant with   0.01 using the sign-test described by (collins et al, 2005).<papid> P05-1066 </papid></citsent>
<aftsection>
<nextsent>applying the prior derivation model into the syntax-based system, bleu score is further improved to 44.51, obtained an another absolute improvement of 0.8 point, whichis also significantly better than our baseline syntax based models (p   0.05).
</nextsent>
<nextsent>we introduced prior derivation model to enhance formally syntax-based scfg for translation.
</nextsent>
<nextsent>our approach links prior rule distribution with the syntactic variations of abstracted sub-phrases, which is modeled by distance measuring of linguistically syntax parsing tree fragments using kernel methods.
</nextsent>
<nextsent>the proposed model has improved translation performance over both phrase-based and formallysyntax-based models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1259">
<title id=" W08-0110.xml">speaking without knowing what to say or when to end </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the version based on human behaviour was rated as more human-like, polite and intelligent.
</prevsent>
<prevsent>1.1 human language production.
</prevsent>
</prevsection>
<citsent citstr=" P00-1001 ">
humans produce speech incrementally and on-line as the dialogue progresses using information from several different sources in parallel (brennan, 2000; <papid> P00-1001 </papid>aist et al, 2006).</citsent>
<aftsection>
<nextsent>we anticipate what the other person is about to say in advance and start planning our next move while this person is still speaking.
</nextsent>
<nextsent>when starting to speak, we typically do not have complete plan of how to say something or even what to say.
</nextsent>
<nextsent>yet, we manage to rapidly integrate information from different sources in parallel and simultaneously plan and realize new dialogue contributions.
</nextsent>
<nextsent>pauses, corrections and repetitions are used to stepwise refine, alter and revise our plans as we speak (clark &amp; wasow, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1260">
<title id=" W08-0110.xml">speaking without knowing what to say or when to end </title>
<section> data analysis.  </section>
<citcontext>
<prevsection>
<prevsent>the classification is likely based on their prosodic realization.
</prevsent>
<prevsent>acoustic analysis is needed in order to see if and how they differ in prosodic contour.
</prevsent>
</prevsection>
<citsent citstr=" J93-3003 ">
in hirschberg &amp; litman (1993) <papid> J93-3003 </papid>prosodic analysis is used to distinguish between discourse and sentential use of cue phrases.</citsent>
<aftsection>
<nextsent>table 4 presents how the different cue phrases were distributed over speaker turns, at initial, middle or end position.
</nextsent>
<nextsent>0% 20% 40% 60% 80% 100% o r ca cc rd rn re ef c ca al end middle initial table 4: turn position distribution
</nextsent>
<nextsent>the collected and labelled data is valuable resource of information for what cue phrases signal in the deal domain as well as how they are lexically and prosodically realized.
</nextsent>
<nextsent>to keep there 74 sponse times constant and without unnaturally long delays, deal needs to be capable of grabbing the turn, hold it while the system is producing the rest of the message, and release it after completion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1261">
<title id=" W08-0314.xml">the university of washington machine translation system for acl wmt 2008 </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>for language modeling, we additionally used about 82m words of spanish newswire text from the linguistic data consortium (ldc), dating from 1995 to 1998.
</prevsent>
<prevsent>3.1 translation model.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the system developed for this years shared taskis state-of-the-art, two-pass phrase-based statistical machine translation system based on log-lineartranslation model (koehn et al 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the translation models and training method follow the standard moses (koehn et al 2007) <papid> P07-2045 </papid>setup distributed as part of the shared task.</nextsent>
<nextsent>we used the training method suggested in the moses documentation, with lexicalized reordering (the msd-bidirectional-feoption) enabled.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1262">
<title id=" W08-0314.xml">the university of washington machine translation system for acl wmt 2008 </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 translation model.
</prevsent>
<prevsent>the system developed for this years shared taskis state-of-the-art, two-pass phrase-based statistical machine translation system based on log-lineartranslation model (koehn et al 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the translation models and training method follow the standard moses (koehn et al 2007) <papid> P07-2045 </papid>setup distributed as part of the shared task.</citsent>
<aftsection>
<nextsent>we used the training method suggested in the moses documentation, with lexicalized reordering (the msd-bidirectional-feoption) enabled.
</nextsent>
<nextsent>the system was tuned via minimum error rate training (mert) on the first 500 sentences of the devtest2006 dataset.
</nextsent>
<nextsent>123 3.2 decoding.
</nextsent>
<nextsent>our system used the moses decoder to generate 2000 output hypotheses per input sentence during the first translation pass.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1263">
<title id=" W08-0314.xml">the university of washington machine translation system for acl wmt 2008 </title>
<section> german ? spanish preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>we therefore applied two operations: (a) splitting of compound words and (b) stemming.
</prevsent>
<prevsent>after basic preprocessing, the german half of the training corpus was first tagged by the german version of tree tagger (schmid, 1994), to identify part of-speech tags.
</prevsent>
</prevsection>
<citsent citstr=" E06-1006 ">
all nouns were then collected into noun list, which was used by simple compound splitter, as described in (yang and kirchhoff, 2006).<papid> E06-1006 </papid>this splitter scans the compound word, hypothesiz ing segment ations, and selects the first segmentation that produces two nouns that occur individually in the corpus.</citsent>
<aftsection>
<nextsent>after splitting the compound nouns in the filtered corpus, we used the tree tagger again, only this time to lemmatize the (filtered) training corpus.
</nextsent>
<nextsent>the stemmed version of the german text was used to train the translation systems word alignments (through the end of step 3 in the moses trainingscript).
</nextsent>
<nextsent>after training the alignments, they were projected back onto the un stemmed corpus.
</nextsent>
<nextsent>the parallel phrases were then extracted using the standard procedure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1264">
<title id=" W08-0324.xml">statistical transfer systems for french english and german english machine translation </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 lexicon.
</prevsent>
<prevsent>the bilingual lexicon is automatically extracted from automatically parsed and word-aligned parallel corpora.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
to obtain high-quality statistical word alignments, we run giza++ (och and ney, 2003)<papid> J03-1002 </papid>in both the source-to-target and target-to-source directions, then combine the resulting alignments withthe sym2 symmetric alignment heuristic of ortiz martnez et al (2005)1.</citsent>
<aftsection>
<nextsent>from this data, we extract alex icon of both word-to-word and syntactic phrase to-phrase translation equivalents.the word-level correspondences are extracted directly from the word alignments: parts of speech for these lexical entries are obtained from the preter 1we use sym2 over more well-known heuristics such as grow-diag-final?
</nextsent>
<nextsent>because sym2 has been shown to give the best results for the node-alignment subtask that is part of our processing chain.
</nextsent>
<nextsent>163 ws cs wt ct paru appeared 0.2054 paru seemed 0.1429 paru found 0.0893 paru published 0.0804 paru felt 0.0714 . . .
</nextsent>
<nextsent>paru already adv 0.0089 paru appear 0.0089 paru authoritative adj 0.0089 table 1: part of the lexical entry distribution for the french (source) word paru.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1265">
<title id=" W08-0324.xml">statistical transfer systems for french english and german english machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>when enabled, it constrains the search of translation hypotheses to the space of hypotheses whose structure satisfies the consituent structure of source-side parse.
</prevsent>
<prevsent>we trained our model parameters on subset ofthe provided dev2006?
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
development set, optimizing for case-insensitive ibm-style bleu (papineni et al, 2002) <papid> P02-1040 </papid>with several iterations of minimum error rate training on n-best lists.</citsent>
<aftsection>
<nextsent>in each iterations list, we also included the lists from previous iterations in order to maintain diversity of hypothesis types and scores.
</nextsent>
<nextsent>the provided test2007?
</nextsent>
<nextsent>and nc-test2007?
</nextsent>
<nextsent>datasets, identical with the test data from the 2007 workshop on statistical machine translation shared task, were used as internal development tests.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1266">
<title id=" W08-0324.xml">statistical transfer systems for french english and german english machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>datasets, identical with the test data from the 2007 workshop on statistical machine translation shared task, were used as internal development tests.
</prevsent>
<prevsent>tables 2, 3, and 4 report scores on these data setsfor our primary french, secondary french, and german systems.
</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
we report case-insensitive scores for version 0.6 of meteor (lavie and agarwal, 2007) <papid> W07-0734 </papid>with all modules enabled, version 1.04 of ibm-style bleu (papineni et al, 2002), <papid> P02-1040 </papid>and version 5 of ter (snover et al, 2006).</citsent>
<aftsection>
<nextsent>dataset meteor bleu ter dev2006 0.5332 0.2063 64.81 test2007 0.5358 0.2078 64.75 nc-test2007 0.5369 0.1719 69.83 table 2: results for the primary french english system on provided development and development test sets.
</nextsent>
<nextsent>dataset meteor bleu ter dev2006 0.5330 0.2086 65.02 test2007 0.5386 0.2129 64.29 nc-test2007 0.5311 0.1680 70.90table 3: results for the secondary french english system on provided development and development test sets.
</nextsent>
<nextsent>from the development test results in section 3, wenote that the stat-xfer systems?
</nextsent>
<nextsent>performance currently lags behind the state-of-the-art scores on the 2007 test data3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1268">
<title id=" W07-1007.xml">mining a lexicon of technical terms and lay equivalents </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our work belongs to the field of paraphrase identification.
</prevsent>
<prevsent>much work has been done to build lexicons of semantically equivalent phrases.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
in generation systems, lexicon is built manually (robin, 1994) or by relying on an electronic thesaurus like wordnet (langkilde and knight, 1998) <papid> P98-1116 </papid>and setting constraints on the type of accepted paraphrases (for instance, accepting only synonyms as paraphrases, and not hypernyms).</citsent>
<aftsection>
<nextsent>building paraphrase lexicons from corpus has also been investigated.
</nextsent>
<nextsent>jacquemin and colleagues (1997) identify morphological and syntactic variants of technical terms.
</nextsent>
<nextsent>barzilay and mckeown (2001) <papid> P01-1008 </papid>identify multi-word paraphrases from sentence-aligned corpus of monolingual parallel texts.</nextsent>
<nextsent>one interesting finding of this work is that the mined paraphrases were distributed across different semantic links in wordnet: some paraphrases had hypernym relation, while others were synonyms, and others had no semantic links at all.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1269">
<title id=" W07-1007.xml">mining a lexicon of technical terms and lay equivalents </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>building paraphrase lexicons from corpus has also been investigated.
</prevsent>
<prevsent>jacquemin and colleagues (1997) identify morphological and syntactic variants of technical terms.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
barzilay and mckeown (2001) <papid> P01-1008 </papid>identify multi-word paraphrases from sentence-aligned corpus of monolingual parallel texts.</citsent>
<aftsection>
<nextsent>one interesting finding of this work is that the mined paraphrases were distributed across different semantic links in wordnet: some paraphrases had hypernym relation, while others were synonyms, and others had no semantic links at all.
</nextsent>
<nextsent>the composition of our gold standard confirms this finding, since half of the semantically equivalent terms had different cuis (see table 3 for examples of such pairs).
</nextsent>
<nextsent>if we consider technical and lay writing styles astwo sublanguages, it is easy to see an analogy between our task and that of machine translation.
</nextsent>
<nextsent>identifying translations for words or phrases has been deeply investigated in the field of statistical machine translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1270">
<title id=" W07-1007.xml">mining a lexicon of technical terms and lay equivalents </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>of course, our task is easier than the one of machine translation, since we focus on translating?
</prevsent>
<prevsent>only technical terms, rather than every single word in technical document.
</prevsent>
</prevsection>
<citsent citstr=" H91-1026 ">
gale and church (1991) <papid> H91-1026 </papid>do not follow the em model, but rather find french translations of english words using 2-like measure of association.</citsent>
<aftsection>
<nextsent>their corpus is the parallel, sentence-aligned hansard corpus.
</nextsent>
<nextsent>our method differs from theirs, as we do build the contingency table based on document frequencies.
</nextsent>
<nextsent>gale and church employ sentence-level frequencies.
</nextsent>
<nextsent>our corpus is much smaller, and the sentences are not aligned (for comparison, we have 367 document-pairs, while they have nearly 900,000sentence pairs).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1271">
<title id=" W07-2060.xml">putop turning predominant senses into a topic model for word sense disambiguation </title>
<section> generative model of wsd.  </section>
<citcontext>
<prevsection>
<prevsent>word sense disambiguation (wsd) is the problem of labeling text with the appropriate semantic labels automatically.
</prevsent>
<prevsent>although wsd is claimed to be an essential step in information retrieval and machine translation, it has not seen effective practical application because the dearth of labeled data has prevented the use of established supervised statistical methods that have been successfully applied to other natural language problems.
</prevsent>
</prevsection>
<citsent citstr=" J04-3004 ">
unsupervised methods have been developed forwsd, but despite modest success have not always been well understood statistically (abney,2004).<papid> J04-3004 </papid></citsent>
<aftsection>
<nextsent>unsupervised methods are particularly appealing because they do not require expensive sense annotated data and can use the ever-increasingamount of raw text freely available.
</nextsent>
<nextsent>this paper expands on an effective unsupervised method for wsd and embeds it into topic model, thus allowing an algorithm trained on single, monolithic corpora to instead hand-pick relevant documents in choosing disambiguation.
</nextsent>
<nextsent>after developing this generative statistical model, we present its performance on number of tasks.
</nextsent>
<nextsent>1.1 the intersection of syntactic and semantic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1272">
<title id=" W07-2060.xml">putop turning predominant senses into a topic model for word sense disambiguation </title>
<section> generative model of wsd.  </section>
<citcontext>
<prevsection>
<prevsent>after developing this generative statistical model, we present its performance on number of tasks.
</prevsent>
<prevsent>1.1 the intersection of syntactic and semantic.
</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
similarity mccarthy et al  (2004) <papid> P04-1036 </papid>outlined method for learning words most-used sense given an untagged corpus that ranks each sense wsi using distributional syntactic similarity ? and wordnet-derived semantic similarity ?.</citsent>
<aftsection>
<nextsent>this process for word uses its distributional neighbors nw, the possible senses of not only the word in question, sw, and also those of the distributionally similar words, snj . thus, (wsi) = ? njnw ?(w, nj) wnss(wsi, nj) ? wsjsw wnss(wsj , nj) , (1) where wnss(s, c) = max asc ?(a, s).
</nextsent>
<nextsent>(2) one can view finding the appropriate sense as search in two types of space.
</nextsent>
<nextsent>in determining how good particular synset wsi is, ? guides the search in the semantic space and ? drives the search in the syntactic space.
</nextsent>
<nextsent>we consider all of the words usedin syntactically similar contexts, which we call cor roborators,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1273">
<title id=" W07-2060.xml">putop turning predominant senses into a topic model for word sense disambiguation </title>
<section> evaluations.  </section>
<citcontext>
<prevsection>
<prevsent>as an initial evaluation, we learned lda topics on the british national corpus with paragraphs as the underlying document?
</prevsent>
<prevsent>(this allowed for more uniform document length).
</prevsent>
</prevsection>
<citsent citstr=" H93-1061 ">
these documents were then used to infer topic probabilities for each of the wordsin semcor (miller et al , 1993), <papid> H93-1061 </papid>and the model described in the previous section was run to determine the most likely synset.</citsent>
<aftsection>
<nextsent>the results of this procedure are shown in table 1.
</nextsent>
<nextsent>accuracy is determined as the percentage of words for which the most likely sense was the one tagged in the corpus.while the method does roughly recreate mccarthy et al result for single topic, it only offers one percent improvement over mccarthy et al . on five topics and then falls below mccarthy for all greater numbers of topics tried.
</nextsent>
<nextsent>thus, for all subsequent experiments we used five topic model trained on the bnc.
</nextsent>
<nextsent>2.2 semeval-2007 task 1: clir.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1274">
<title id=" W07-2109.xml">xrcem a hybrid system for named entity metonymy resolution </title>
<section> description of our system.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W07-2007 ">
semeval 2007 introduces task aiming at resolving metonymy for named entities, for location and organization names (markert and nissim 2007).<papid> W07-2007 </papid></citsent>
<aftsection>
<nextsent>our system addresses this task by combining symbolic approach based on robust deep parsing and lexical semantic information, with distributional method using syntactic context similarities calculated on large corpora.
</nextsent>
<nextsent>our system is completely unsupervised, as opposed to state-of-the-art systems (see (market and nissim, 2005)).
</nextsent>
<nextsent>1.1 robust and deep parsing using xip.
</nextsent>
<nextsent>we use the xerox incremental parser (xip, (at et al., 2002)) to perform robust and deep syntactic analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1275">
<title id=" W07-2109.xml">xrcem a hybrid system for named entity metonymy resolution </title>
<section> description of our system.  </section>
<citcontext>
<prevsection>
<prevsent>we prepared the corpus by lemmatizing and then parsing with the same robust parser than for the symbolic approach (xip, see section 3.1).
</prevsent>
<prevsent>it allows us to identify triple instances.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
each triple have the form w1.r.w2 where w1 and w2 are lexical units and is syntactic relation (lin, 1998; <papid> P98-2127 </papid>kilgarriff &amp; al. 2004).</citsent>
<aftsection>
<nextsent>our approach can be distinguished from classical distributional approach by different points.
</nextsent>
<nextsent>first, we use triple occurrences to build distributional space (one triple implies two contexts and two lexical units), but we use the transpose of the classical space: each point xi of this space is syntactical context (with the form r.w.), each dimension is lexical units, and each value xi(j) is the frequency of corresponding triple occurrences.
</nextsent>
<nextsent>sec 489 ond, our lexical units are words but also complex nominal groups or verbal groups.
</nextsent>
<nextsent>third, contexts can be simple contexts or composed contexts6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1276">
<title id=" W08-0504.xml">evaluating the effects of treebank size in a practical application for parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this issue, however, is of great practical importance in the effective design and engineering of complex software systems that deal with natural language.
</prevsent>
<prevsent>in this paper we explore some of these issues empirically in an information extraction task in the biomedical domain, the identification of protein- protein interactions (ppi) mentioned in papers abstracts from medline, large database of biomedical papers.
</prevsent>
</prevsection>
<citsent citstr=" W04-3111 ">
due in large part to the creation of biomedical treebanks (kulick et al , 2004; <papid> W04-3111 </papid>tateisi et al , 2005) <papid> I05-2038 </papid>and rapid progress of data-driven parsers (lease and charniak, 2005; nivre et al , 2007), <papid> D07-1096 </papid>there are now fast, robust and accurate syntactic parsers for text in the biomedical domain.</citsent>
<aftsection>
<nextsent>recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (clegg and shepherd, 2007; pyysalo et al , 2007; <papid> W07-1004 </papid>sagae et al , 2008).</nextsent>
<nextsent>intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1277">
<title id=" W08-0504.xml">evaluating the effects of treebank size in a practical application for parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this issue, however, is of great practical importance in the effective design and engineering of complex software systems that deal with natural language.
</prevsent>
<prevsent>in this paper we explore some of these issues empirically in an information extraction task in the biomedical domain, the identification of protein- protein interactions (ppi) mentioned in papers abstracts from medline, large database of biomedical papers.
</prevsent>
</prevsection>
<citsent citstr=" I05-2038 ">
due in large part to the creation of biomedical treebanks (kulick et al , 2004; <papid> W04-3111 </papid>tateisi et al , 2005) <papid> I05-2038 </papid>and rapid progress of data-driven parsers (lease and charniak, 2005; nivre et al , 2007), <papid> D07-1096 </papid>there are now fast, robust and accurate syntactic parsers for text in the biomedical domain.</citsent>
<aftsection>
<nextsent>recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (clegg and shepherd, 2007; pyysalo et al , 2007; <papid> W07-1004 </papid>sagae et al , 2008).</nextsent>
<nextsent>intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1278">
<title id=" W08-0504.xml">evaluating the effects of treebank size in a practical application for parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this issue, however, is of great practical importance in the effective design and engineering of complex software systems that deal with natural language.
</prevsent>
<prevsent>in this paper we explore some of these issues empirically in an information extraction task in the biomedical domain, the identification of protein- protein interactions (ppi) mentioned in papers abstracts from medline, large database of biomedical papers.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
due in large part to the creation of biomedical treebanks (kulick et al , 2004; <papid> W04-3111 </papid>tateisi et al , 2005) <papid> I05-2038 </papid>and rapid progress of data-driven parsers (lease and charniak, 2005; nivre et al , 2007), <papid> D07-1096 </papid>there are now fast, robust and accurate syntactic parsers for text in the biomedical domain.</citsent>
<aftsection>
<nextsent>recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (clegg and shepherd, 2007; pyysalo et al , 2007; <papid> W07-1004 </papid>sagae et al , 2008).</nextsent>
<nextsent>intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1279">
<title id=" W08-0504.xml">evaluating the effects of treebank size in a practical application for parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper we explore some of these issues empirically in an information extraction task in the biomedical domain, the identification of protein- protein interactions (ppi) mentioned in papers abstracts from medline, large database of biomedical papers.
</prevsent>
<prevsent>due in large part to the creation of biomedical treebanks (kulick et al , 2004; <papid> W04-3111 </papid>tateisi et al , 2005) <papid> I05-2038 </papid>and rapid progress of data-driven parsers (lease and charniak, 2005; nivre et al , 2007), <papid> D07-1096 </papid>there are now fast, robust and accurate syntactic parsers for text in the biomedical domain.</prevsent>
</prevsection>
<citsent citstr=" W07-1004 ">
recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (clegg and shepherd, 2007; pyysalo et al , 2007; <papid> W07-1004 </papid>sagae et al , 2008).</citsent>
<aftsection>
<nextsent>intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text.
</nextsent>
<nextsent>recent ppi extraction systems have confirmed this intuition (erkan et al , 2007; <papid> D07-1024 </papid>street al , 2007; katrenko and adriaans, 2006).</nextsent>
<nextsent>while it is now relatively clear that syntactic parsing is useful in practical tasks that use natural language corpora in bio informatics, several ques 14 tions remain as to research issues that affect the design and testing of end-user applications, including how syntactic analyses should be used in practical setting, whether further improvements in parsing technologies will result in further improvements in practical systems, whether it is important to continue the development of treebanks and parser adaptation techniques for the biomedical domain, and how much effort should be spent on comparing and benchmarking parsers for biomedical data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1281">
<title id=" W08-0504.xml">evaluating the effects of treebank size in a practical application for parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>recent research shows that parsing accuracy of biomedical corpora is now between 80% and 90% (clegg and shepherd, 2007; pyysalo et al , 2007; <papid> W07-1004 </papid>sagae et al , 2008).</prevsent>
<prevsent>intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text.</prevsent>
</prevsection>
<citsent citstr=" D07-1024 ">
recent ppi extraction systems have confirmed this intuition (erkan et al , 2007; <papid> D07-1024 </papid>street al , 2007; katrenko and adriaans, 2006).</citsent>
<aftsection>
<nextsent>while it is now relatively clear that syntactic parsing is useful in practical tasks that use natural language corpora in bio informatics, several ques 14 tions remain as to research issues that affect the design and testing of end-user applications, including how syntactic analyses should be used in practical setting, whether further improvements in parsing technologies will result in further improvements in practical systems, whether it is important to continue the development of treebanks and parser adaptation techniques for the biomedical domain, and how much effort should be spent on comparing and benchmarking parsers for biomedical data.
</nextsent>
<nextsent>we attempt to shed some light on these matters by presenting experiments that show the relationship of the accuracy of dependency parser and the accuracy of the larger ppi system that includes the parser.
</nextsent>
<nextsent>we investigate the effects of domain-specific treebank size (the amount of available manually annotated training data for syntactic parsers) and final system performance, and obtain results that should be informative to researchers in bio informatics who relyon existing nlp resources to design information extraction systems, as well as to members of the parsing community who are interested in the practical impact of parsing research.
</nextsent>
<nextsent>in section 2 we discuss our motivation andre lated efforts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1286">
<title id=" W08-0504.xml">evaluating the effects of treebank size in a practical application for parsing </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>clegg and shepherd (2007) mention that available statistical parsers appear to overfit to the newswire domain, because of their extensive use of the wall street journal portion of the penn treebank (marcus et al , 1994) during development and training.
</prevsent>
<prevsent>while this claim is supported by convincing evaluations that show that parsers trained on the wsj penn treebank alone perform poorly on biomedical text in terms of accuracy of dependencies or bracketing of phrase structure, the benefits of using domain specific data in terms of practical system performance have not been quantified.
</prevsent>
</prevsection>
<citsent citstr=" W07-2202 ">
these expected benefits drive the development of domain-specific resources, such as the genia treebank (tateisi et al ., 2005), <papid> I05-2038 </papid>and parser domain adaption (hara et al , 2007), <papid> W07-2202 </papid>which are of clear importance in parsing research, but of largely unconfirmed impact on practical systems.</citsent>
<aftsection>
<nextsent>quirk and corston-oliver (2006) examine similar issue, the relationship between parser accuracy and overall system accuracy in syntax informed machine translation.
</nextsent>
<nextsent>their research is similar to the work presented here, but they focused on the use of varying amounts of out-of domain training data for the parser, measuring how translation system for technical text performed when its syntactic parser was trained with varying amounts of wall street journal text.
</nextsent>
<nextsent>our work, in contrast, investigates the use of domain-specific training material in parsers for biomedical text, domain where significant amounts of effort are allocated for development of domain-specific nlp resources in hope that such resources will result in better overall performance in practical systems.
</nextsent>
<nextsent>tactic parsing ppi extraction is an nlp task to identify protein pairs that are mentioned as interacting in biomedical papers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1289">
<title id=" W08-0504.xml">evaluating the effects of treebank size in a practical application for parsing </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>4 data-driven dependency parser for biomedical text the parser we used as component of our ppi extraction system was shift-reduce dependency parser that uses maximum entropy models to determine the parsers actions.
</prevsent>
<prevsent>our overall parsing approach uses best-first probabilistic shift-reduce algorithm, working left-to right to find labeled dependencies one at time.
</prevsent>
</prevsection>
<citsent citstr=" P06-2089 ">
the algorithm is essentially dependency version of the constituent parsing algorithm for probabilistic parsing with lr-like data-driven models described by sagae and lavie (2006).<papid> P06-2089 </papid></citsent>
<aftsection>
<nextsent>this dependency parser has been shown to have state-of-the-art accuracy in the conll shared tasks on dependency parsing (buchholz and marsi, 2006; nivre, 2007).
</nextsent>
<nextsent>sagae and tsujii (2007) present detailed description of the parsing approach used in our work, including the parsing algorithm and the features used to classify parser actions.
</nextsent>
<nextsent>in summary, the parser uses an algorithm similar to the lr parsing algorithm (knuth, 1965), keeping stack of partially built syntactic structures, and queue of remaining in put tokens.
</nextsent>
<nextsent>at each step in the parsing process, the parser can apply shift action (remove token from the front of the queue and place it on top of the stack), or reduce action (pop the two topmost this study demonstrates that il-8 recognizes and activates cxcr1, cxcr2, and the duffy antigen by distinct mechanisms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1290">
<title id=" W08-0504.xml">evaluating the effects of treebank size in a practical application for parsing </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>the molar ratio of serum retinol-binding protein (rbp) to transthyretin (ttr) is not useful to assess vitamin status during infection in hospitalized children.
</prevsent>
<prevsent>figure 2: example sentences with protein names figure 1: dependency tree root il-8 recognizes and activates cxcr1 root sbj obj coord cc entity1(il-8) recognizes entity2(cxcr1) figure 3: dependency path between protein names sbj obj 16 stack items, and push new item composed of the two popped items combined in single structure).
</prevsent>
</prevsection>
<citsent citstr=" W06-2933 ">
this parsing approach is very similar to the one used successfully by nivre et al  (2006), <papid> W06-2933 </papid>but we use maximum entropy classifier (berger et al , 1996) <papid> J96-1002 </papid>to determine parser actions, which makes parsing considerably faster.</citsent>
<aftsection>
<nextsent>in addition, our parsing approach performs search over the space of possible parser actions, while nivre et al approach is deterministic.
</nextsent>
<nextsent>the parser was trained using 8,000 sentences from the genia treebank (tateisi et al , 2005), <papid> I05-2038 </papid>which contains abstracts of papers taken from medline, annotated with syntactic structures.</nextsent>
<nextsent>to determine the effects of training set size on the parser, and consequently on the ppi extraction system, we trained several parsing models with different amounts of genia treebank data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1291">
<title id=" W08-0504.xml">evaluating the effects of treebank size in a practical application for parsing </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>the molar ratio of serum retinol-binding protein (rbp) to transthyretin (ttr) is not useful to assess vitamin status during infection in hospitalized children.
</prevsent>
<prevsent>figure 2: example sentences with protein names figure 1: dependency tree root il-8 recognizes and activates cxcr1 root sbj obj coord cc entity1(il-8) recognizes entity2(cxcr1) figure 3: dependency path between protein names sbj obj 16 stack items, and push new item composed of the two popped items combined in single structure).
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
this parsing approach is very similar to the one used successfully by nivre et al  (2006), <papid> W06-2933 </papid>but we use maximum entropy classifier (berger et al , 1996) <papid> J96-1002 </papid>to determine parser actions, which makes parsing considerably faster.</citsent>
<aftsection>
<nextsent>in addition, our parsing approach performs search over the space of possible parser actions, while nivre et al approach is deterministic.
</nextsent>
<nextsent>the parser was trained using 8,000 sentences from the genia treebank (tateisi et al , 2005), <papid> I05-2038 </papid>which contains abstracts of papers taken from medline, annotated with syntactic structures.</nextsent>
<nextsent>to determine the effects of training set size on the parser, and consequently on the ppi extraction system, we trained several parsing models with different amounts of genia treebank data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1293">
<title id=" W07-1018.xml">interpreting comparative constructions in biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 comparative structures in english.
</prevsent>
<prevsent>the range of comparative expressions in english is extensive and complex.
</prevsent>
</prevsection>
<citsent citstr=" P81-1003 ">
several linguistic studies have investigated their characteristics, with differing assumptions about syntax and semantics (for example [ryan, 1981; <papid> P81-1003 </papid>rayner and banks, 1990; <papid> J90-2003 </papid>staab and hahn, 1997; huddleston and pullum, 2002]).</citsent>
<aftsection>
<nextsent>our study concentrates on 137 structures in which two drugs are compared with respect to shared attribute (e.g. how well they treat some disease).
</nextsent>
<nextsent>an assessment of their relative merit in this regard is indicated by their positions on scale.
</nextsent>
<nextsent>the compared terms are expressed as noun phrases, which can be considered to be conjoined.
</nextsent>
<nextsent>the shared characteristic focused on is expressed as predicate outside the comparative structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1294">
<title id=" W07-1018.xml">interpreting comparative constructions in biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 comparative structures in english.
</prevsent>
<prevsent>the range of comparative expressions in english is extensive and complex.
</prevsent>
</prevsection>
<citsent citstr=" J90-2003 ">
several linguistic studies have investigated their characteristics, with differing assumptions about syntax and semantics (for example [ryan, 1981; <papid> P81-1003 </papid>rayner and banks, 1990; <papid> J90-2003 </papid>staab and hahn, 1997; huddleston and pullum, 2002]).</citsent>
<aftsection>
<nextsent>our study concentrates on 137 structures in which two drugs are compared with respect to shared attribute (e.g. how well they treat some disease).
</nextsent>
<nextsent>an assessment of their relative merit in this regard is indicated by their positions on scale.
</nextsent>
<nextsent>the compared terms are expressed as noun phrases, which can be considered to be conjoined.
</nextsent>
<nextsent>the shared characteristic focused on is expressed as predicate outside the comparative structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1295">
<title id=" W07-1018.xml">interpreting comparative constructions in biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>(7) sodium valproate was significantly less effective than prochlorperazine in reducing pain or nausea.
</prevsent>
<prevsent>in examples (3) through (7), the characteristic the compared drugs have in common is treatment of some disorder, for example treatment of pertussis in children in (5).
</prevsent>
</prevsection>
<citsent citstr=" P89-1020 ">
few studies describe an implemented automatic analysis of comparatives; however, friedman [friedman, 1989] <papid> P89-1020 </papid>is notable exception.</citsent>
<aftsection>
<nextsent>jindal and liu [jindal and liu, 2006] use machine learning to identify some comparative structures, but do not provide semantic interpretation.
</nextsent>
<nextsent>we exploit semrep machinery to interpret the aspects of comparative structures just described.
</nextsent>
<nextsent>2.2 semrep.
</nextsent>
<nextsent>semrep [rindflesch and fiszman, 2003; rindflesch et al, 2005] recovers underspecified semantic propositions in biomedical text based on partial syntactic analysis and structured domain knowledge from the umls.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1296">
<title id=" W07-1018.xml">interpreting comparative constructions in biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>semrep [rindflesch and fiszman, 2003; rindflesch et al, 2005] recovers underspecified semantic propositions in biomedical text based on partial syntactic analysis and structured domain knowledge from the umls.
</prevsent>
<prevsent>several systems that extract entities and relations are underdevelopment in both the clinical and molecular biology domains.
</prevsent>
</prevsection>
<citsent citstr=" W02-0305 ">
examples of systems for clinical text are described in [friedman et al, 1994], [johnson et al, 1993], [hahn et al, 2002], and [christensen et al, 2002].<papid> W02-0305 </papid></citsent>
<aftsection>
<nextsent>in molecular biology, examples include [yen et al, 2006], [chun et al, 2006], [blaschke et al, 1999], [leroy et al, 2003], [rindflesch et al, 2005], [friedman et al, 2001], and [lussier et al, 2006].
</nextsent>
<nextsent>during semrep processing, partial syntactic parse is produced that depends on lexical look-up in the specialist lexicon [mccray et al, 1994] and part-of-speech tagger [smith et al, 2004].
</nextsent>
<nextsent>metamap [aronson, 2001] then matches noun phrases to concepts in the metathesaurus?
</nextsent>
<nextsent>and determines the semantic type for each concept.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1297">
<title id=" W07-1018.xml">interpreting comparative constructions in biomedical text </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the micro-average score for 287 comparative sentences is 0.5.
</prevsent>
<prevsent>in examining semrep errors, we determined that more than 60% of the false negatives (for both comp1 and comp2) were due to empty heads?
</prevsent>
</prevsection>
<citsent citstr=" P85-1037 ">
[chodorow et al, 1985; <papid> P85-1037 </papid>guthrie et al, 1990], <papid> C90-3025 </papid>in which the syntactic head of noun phrase does not reflect semantic thrust.</citsent>
<aftsection>
<nextsent>such heads prevent semrep from accurately determining the semantic type and group of the noun phrase.
</nextsent>
<nextsent>in our sample, expressions interpreted as empty heads include those referring to drug dosage and formulations, such as extended release (the latter often abbreviated as xr).
</nextsent>
<nextsent>examples of missed interpretations are in sentences (28) and (29), where the empty heads are in bold.
</nextsent>
<nextsent>ahlers et al [ahlers et al, 2007] discuss enhancements to semrep for accommodating empty heads.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1298">
<title id=" W07-1018.xml">interpreting comparative constructions in biomedical text </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the micro-average score for 287 comparative sentences is 0.5.
</prevsent>
<prevsent>in examining semrep errors, we determined that more than 60% of the false negatives (for both comp1 and comp2) were due to empty heads?
</prevsent>
</prevsection>
<citsent citstr=" C90-3025 ">
[chodorow et al, 1985; <papid> P85-1037 </papid>guthrie et al, 1990], <papid> C90-3025 </papid>in which the syntactic head of noun phrase does not reflect semantic thrust.</citsent>
<aftsection>
<nextsent>such heads prevent semrep from accurately determining the semantic type and group of the noun phrase.
</nextsent>
<nextsent>in our sample, expressions interpreted as empty heads include those referring to drug dosage and formulations, such as extended release (the latter often abbreviated as xr).
</nextsent>
<nextsent>examples of missed interpretations are in sentences (28) and (29), where the empty heads are in bold.
</nextsent>
<nextsent>ahlers et al [ahlers et al, 2007] discuss enhancements to semrep for accommodating empty heads.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1299">
<title id=" W07-1528.xml">igtxml an xml format for interlinearized glossed text </title>
<section> igt-xml.  </section>
<citcontext>
<prevsection>
<prevsent>the glosses in  gloss  refer to individual morphemes, hence their idref attributes point to id attributes of the  morphemes  block.
</prevsent>
<prevsent>meta data information in the file head eras suggested in figure 3, igt-xml is easily extended with meta data for each text.
</prevsent>
</prevsection>
<citsent citstr=" W01-1506 ">
we adopt the olac meta data set which uses the fifteen elements defined in the dublin core meta data standard (bird and simons, 2003a; bird and simons, 2001).<papid> W01-1506 </papid></citsent>
<aftsection>
<nextsent>these elements provide framework for specifying key information such as annotators, format, and language of the text.
</nextsent>
<nextsent>in addition, the olac standard incorporates number of qualifiers specific to the language resource community, such as discourse types (story,conversation, etc.) and linguistic data types (lexi con, language description, primary text, etc.), and process for adopting further extensions.
</nextsent>
<nextsent>in addition to the meta data block at the head of the document, it would be possible to intersperse additional meta data blocks throughout the document, if for example we wanted to indicate change of speaker from one phrase to another in recorded conversation.
</nextsent>
<nextsent>discussion feature overview.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1300">
<title id=" W07-2044.xml">ku word sense disambiguation by substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the training data is costly to generate and inter-annotator agreement is difficult to achieve.
</prevsent>
<prevsent>thus there is very little training data available: the largest single corpus of sense tagged text, semcor, has 41,497 sense tagged words.
</prevsent>
</prevsection>
<citsent citstr=" W04-0864 ">
(yuret, 2004) <papid> W04-0864 </papid>observed that approximately half of the test instances do not match any of the contextual features learned from the training data for an all words disambiguation task.</citsent>
<aftsection>
<nextsent>(yarowsky and florian, 2002) found that each successive doubling of the training data only leads to 3-4% error reduction within their experimental range.humans do not seem to be cursed with an exponential training data requirement to become proficient with the use of word.
</nextsent>
<nextsent>dictionaries typically contain definition and one or two examples of us age for each sense.
</nextsent>
<nextsent>this seems to be sufficient for human to use the word correctly in contexts that share no surface features with the dictionary examples.
</nextsent>
<nextsent>the 108 waking seconds it takes person to become proficient in language does not seem sufficient to master all the words and their different senses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1301">
<title id=" W07-2044.xml">ku word sense disambiguation by substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper will describe system that judges potential substitutions in given context using statistical language model as surrogate for the linguistic ear?.
</prevsent>
<prevsent>the likelihoods of the various substitutes are used to select the best sense for target word.the use of substitutes for wsd is not new.
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
(lea cock et al, 1998) <papid> J98-1006 </papid>demonstrated the use of relatedmonosemous words (monosemous relatives) to collect examples forgiven sense from the internet.</citsent>
<aftsection>
<nextsent>(mihalcea, 2002) used the monosemous relatives technique for bootstrapping the automatic acquisition of large sense tagged corpora.
</nextsent>
<nextsent>in both cases, the focus was on collecting more labeled examples to be subsequently used with supervised machine learning techniques.
</nextsent>
<nextsent>(martinez et al, 2006) extended the method to make use of polysemous relatives.
</nextsent>
<nextsent>more importantly, their method places these relatives inthe context of the target word to query search engine and uses the search results to predict the best sense in an unsupervised manner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1302">
<title id=" W07-2044.xml">ku word sense disambiguation by substitution </title>
<section> english lexical substitution.  </section>
<citcontext>
<prevsection>
<prevsent>the loocv gain from using the optimized substitute sets instead of the initial union of wordnet and roget substitutes was significant.
</prevsent>
<prevsent>for example the average gainwas 9.4% and the maximum was 38% for the english lexical sample wsd task.
</prevsent>
</prevsection>
<citsent citstr=" W07-2009 ">
the english lexical substitution task (mccarthy and navigli, 2007), <papid> W07-2009 </papid>for both human annotators and systems is to replace target word in sentence with as close word as possible.</citsent>
<aftsection>
<nextsent>it is different from the standard wsd tasks in that there is no sense repository used, and even the identification of discrete sense is not necessary.
</nextsent>
<nextsent>the task used lexical sample of 171 words with 10 instances each.
</nextsent>
<nextsent>for each instance the human annotators selected several substitutes.
</nextsent>
<nextsent>there were three subtasks: best: scoring the best substitute forgiven item, oot: scoring the best ten substitutes forgiven item, and mw: detection and identification of multi-words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1305">
<title id=" W07-2044.xml">ku word sense disambiguation by substitution </title>
<section> english lexical sample wsd.  </section>
<citcontext>
<prevsection>
<prevsent>relying on repositories like roget for the purpose of substitute selection seems ad-hoc and better methods are needed.
</prevsent>
<prevsent>the coarse-grained english lexical sample wsd task (palmer et al, 2007), provided training and test data for sense disambiguation of 65 verbs and 35 nouns.
</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
on average there were 223 training and 49 testing instances for each word tagged with an ontonote sense tag (hovy et al, 2006).<papid> N06-2015 </papid></citsent>
<aftsection>
<nextsent>ontonote sense tags are groupings of wordnet senses that are more coarse-grained than traditional wn entries,and which have achieved on average 90% inter annotator agreement.
</nextsent>
<nextsent>the number of senses for word ranged from 1 to 13 with an average of 3.6.
</nextsent>
<nextsent>i used substitute sets optimized for each word as described in section 3.
</nextsent>
<nextsent>then single best sense for each test instance was selected based on the model given in section 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1306">
<title id=" W07-2044.xml">ku word sense disambiguation by substitution </title>
<section> english lexical sample wsd.  </section>
<citcontext>
<prevsection>
<prevsent>then single best sense for each test instance was selected based on the model given in section 2.
</prevsent>
<prevsent>the system achieved 85.05% accuracy, which is 6.39% above the baseline of picking the most frequent sense and 3.65% below the top score.these numbers seem higher than previous senseval lexical sample tasks.
</prevsent>
</prevsection>
<citsent citstr=" W04-0807 ">
the best system in senseval-3 (mihalcea et al, 2004; <papid> W04-0807 </papid>grozea, 2004) <papid> W04-0831 </papid>achieved 72.9% fine grained, 79.3% coarse grained accuracy.</citsent>
<aftsection>
<nextsent>many factors may have played role butthe most important one is probably the sense inventory.
</nextsent>
<nextsent>the nouns and verbs in senseval-3 had 6.1 fine grained and 4.5 coarse grained senses on average.
</nextsent>
<nextsent>the leave-one-out cross-validation result of my system on the training set was 83.21% with theun filtered union of roget and wordnet substitutes, and 90.69% with the optimized subset.
</nextsent>
<nextsent>clearly there issome over-fitting in the substitute optimization process which needs to be improved.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1307">
<title id=" W07-2044.xml">ku word sense disambiguation by substitution </title>
<section> english lexical sample wsd.  </section>
<citcontext>
<prevsection>
<prevsent>then single best sense for each test instance was selected based on the model given in section 2.
</prevsent>
<prevsent>the system achieved 85.05% accuracy, which is 6.39% above the baseline of picking the most frequent sense and 3.65% below the top score.these numbers seem higher than previous senseval lexical sample tasks.
</prevsent>
</prevsection>
<citsent citstr=" W04-0831 ">
the best system in senseval-3 (mihalcea et al, 2004; <papid> W04-0807 </papid>grozea, 2004) <papid> W04-0831 </papid>achieved 72.9% fine grained, 79.3% coarse grained accuracy.</citsent>
<aftsection>
<nextsent>many factors may have played role butthe most important one is probably the sense inventory.
</nextsent>
<nextsent>the nouns and verbs in senseval-3 had 6.1 fine grained and 4.5 coarse grained senses on average.
</nextsent>
<nextsent>the leave-one-out cross-validation result of my system on the training set was 83.21% with theun filtered union of roget and wordnet substitutes, and 90.69% with the optimized subset.
</nextsent>
<nextsent>clearly there issome over-fitting in the substitute optimization process which needs to be improved.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1308">
<title id=" W07-2044.xml">ku word sense disambiguation by substitution </title>
<section> wsd of prepositions.  </section>
<citcontext>
<prevsection>
<prevsent>thus the difficulty of each word may be the overriding factor in determining performance.
</prevsent>
<prevsent>a more detailed study similar to (yarowsky and florian, 2002) is needed to explore the relationship in more detail.
</prevsent>
</prevsection>
<citsent citstr=" W07-2005 ">
the word sense disambiguation of prepositions task (litkowski and hargraves, 2007), <papid> W07-2005 </papid>provided training and test data for sense disambiguation of34 prepositions.</citsent>
<aftsection>
<nextsent>on average there were 486 training and 234 test instances for each preposition.
</nextsent>
<nextsent>the number of senses for word ranged from 1 to 20 with an average of 7.4.
</nextsent>
<nextsent>the system described in sections 2 and 3 were applied to this task as well.
</nextsent>
<nextsent>wordnet does not have information about prepositions, so most of the candidate substitutes were obtained from roget and the preposition project (litkowski, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1309">
<title id=" W07-2044.xml">ku word sense disambiguation by substitution </title>
<section> contributions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>the data consists of mostly english words that have been tokenized and sentence tagged.
</prevsent>
<prevsent>to 212 kens that appear less than 200 times and ngrams that appear less than 40 times have been filtered out.
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
i used smoothing method loosely based on the one-count method given in (chen and goodman,1996).<papid> P96-1041 </papid></citsent>
<aftsection>
<nextsent>because ngrams with low counts are not included in the data used ngrams with missing counts instead of ngrams with one counts.
</nextsent>
<nextsent>the missing count is defined as: m(wi1in+1) = c(wi1in+1) ? ?
</nextsent>
<nextsent>wi c(wiin+1)where wiin+1 indicates the n-word sequence ending with wi, and c(wiin+1) is the count of this sequence.
</nextsent>
<nextsent>the corresponding smoothing formula is: (wi|wi1in+1) = c(wiin+1) + (1 + n)m(wi1in+1)p (wi|wi1in+2) c(wi1in+1) + nm(wi1in+1)the parameters   0 for = 2 . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1310">
<title id=" W07-2043.xml">jusknsb extended wordnet based wsd on the english all words task at semeval1 </title>
<section> extended wordnet.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we explore variants of the lesk algorithm on the english all words semeval 2007 test data (465 instances), as well as on the first 10 semcor 2.0 files (9642 instances).
</prevsent>
<prevsent>the proposed wsd algorithm is pos-sense-tagged gloss (from extended wordnet) based and is major modification of the original lesk algorithm.
</prevsent>
</prevsection>
<citsent citstr=" W99-0501 ">
the extended wordnet (harabagiu et al, 1999) <papid> W99-0501 </papid>project aims to transform the wordnet glosses into format that allows the derivation of additional semantic and logic relations.</citsent>
<aftsection>
<nextsent>it intends to syntactically parse the glosses, transform glosses into logical forms and tag semantically the nouns, verbs, adjectives and adverbs of the glosses automatically.
</nextsent>
<nextsent>the last release of the extended wordnet is based on wordnet 2.0 and has three stages: pos tagging and parsing, logic form transformation, and semantic disambiguation.
</nextsent>
<nextsent>banerjee and pedersen (2002) reports an adaptation of lesks dictionary-based wsd algorithm which makes use of wordnet glosses and tests on english lexical sample from senseval-2.
</nextsent>
<nextsent>they define overlap as the longest sequence of one or more consecutive content words that occurs in both glosses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1311">
<title id=" W07-1702.xml">implementation of croatian nerc system </title>
<section> strategies.  </section>
<citcontext>
<prevsection>
<prevsent>they can be useful when list of names is not complete ? an external evidence is taking the role of an additional proof.
</prevsent>
<prevsent>they can also reduce the need for elaborated internal evidence checking when rules are being build.
</prevsent>
</prevsection>
<citsent citstr=" E99-1001 ">
the internal and external evidence is being used by all nerc systems such as ltg (mikheev et al  1999), <papid> E99-1001 </papid>fastus (hobbs et al  1997), proteus (yangarber, grishman, 1998).</citsent>
<aftsection>
<nextsent>3.2 dynamic lexicon.
</nextsent>
<nextsent>sometimes during the processing there is need for storing information which are relevant only for current text/discourse/document.
</nextsent>
<nextsent>such information are usually stored in dynamic lexicon where temporarily relevant information are stored and used for the processing of current document.
</nextsent>
<nextsent>dy 12 namic lexicon entries are being collected from the confident contexts and usually are being used for tagging words which could benes but there is not enough external evidences for that.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1313">
<title id=" W07-1702.xml">implementation of croatian nerc system </title>
<section> strategies.  </section>
<citcontext>
<prevsection>
<prevsent>in such cases all tokens forming an ne and all their combinations are stored in the dynamic lexicon (mikheev et al  1999:<papid> E99-1001 </papid>5).</prevsent>
<prevsent>in our case it would be also investicijsko komercijalna, komercijalna banka, investicijska banka, and also an acronym derived from the first letters of all tokens (ikb).</prevsent>
</prevsection>
<citsent citstr=" M98-1021 ">
dynamic lexicon are used by numer of nerc systems such as ones described in (mikheev et al  1998), (<papid> M98-1021 </papid>mcdonald 1996) and (piskorski et al  2000).</citsent>
<aftsection>
<nextsent>3.3 global word sequence checking.
</nextsent>
<nextsent>this strategy is used for solving complex ambiguities (mikheev, 1999).<papid> P99-1021 </papid></nextsent>
<nextsent>the initial position in the sentence is one of such ambiguous spots.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1314">
<title id=" W07-1702.xml">implementation of croatian nerc system </title>
<section> strategies.  </section>
<citcontext>
<prevsection>
<prevsent>dynamic lexicon are used by numer of nerc systems such as ones described in (mikheev et al  1998), (<papid> M98-1021 </papid>mcdonald 1996) and (piskorski et al  2000).</prevsent>
<prevsent>3.3 global word sequence checking.</prevsent>
</prevsection>
<citsent citstr=" P99-1021 ">
this strategy is used for solving complex ambiguities (mikheev, 1999).<papid> P99-1021 </papid></citsent>
<aftsection>
<nextsent>the initial position in the sentence is one of such ambiguous spots.
</nextsent>
<nextsent>if the ne is complex e.g. has conjuncted structure, its solving can be quite difficult task.
</nextsent>
<nextsent>the following example from the newspaper can explain this: e4: osiguranje zagreb primo ten potpisali su ugovor suradnji.
</nextsent>
<nextsent>(in surance zagreb and primo ten countersigned an agreement on cooperation.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1318">
<title id=" W07-1429.xml">biology based alignments of paraphrases for sentence compression </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>1 in this paper, we present study for extracting and aligning paraphrases in the context of sentence compression.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
first, we justify the application of new measure for the automatic extraction of paraphrase corpora.second, we discuss the work done by (barzilay &amp; lee, 2003) <papid> N03-1003 </papid>who use clustering of paraphrases to induce rewriting rules.</citsent>
<aftsection>
<nextsent>we willsee, through classical visualization methodologies (kruskal &amp; wish, 1977) and exhaustive experiments, that clustering may not bethe best approach for automatic pattern identification.
</nextsent>
<nextsent>finally, we will provide some results of different biology based methodologies for pairwise paraphrase alignment.
</nextsent>
<nextsent>sentence compression can be seen as the removal of redundant words or phrases from an input sentence by creating new sentence in which the gistof the original meaning of the sentence remains unchanged.
</nextsent>
<nextsent>sentence compression takes an important place for natural language processing (nlp) tasks where specific constraints must be satisfied, such as length in summarization (barzilay &amp; lee, 2002; <papid> W02-1022 </papid>knight &amp; marcu, 2002; shinyama et al, 2002; barzilay &amp; lee, 2003; <papid> N03-1003 </papid>le nguyen &amp; ho, 2004; unno et al, 2006), <papid> P06-2109 </papid>style in text simplification (marsi &amp; krahmer, 2005) <papid> W05-1612 </papid>or sentence simplification for sub titling (daelemans et al, 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1328">
<title id=" W07-1429.xml">biology based alignments of paraphrases for sentence compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we will provide some results of different biology based methodologies for pairwise paraphrase alignment.
</prevsent>
<prevsent>sentence compression can be seen as the removal of redundant words or phrases from an input sentence by creating new sentence in which the gistof the original meaning of the sentence remains unchanged.
</prevsent>
</prevsection>
<citsent citstr=" W02-1022 ">
sentence compression takes an important place for natural language processing (nlp) tasks where specific constraints must be satisfied, such as length in summarization (barzilay &amp; lee, 2002; <papid> W02-1022 </papid>knight &amp; marcu, 2002; shinyama et al, 2002; barzilay &amp; lee, 2003; <papid> N03-1003 </papid>le nguyen &amp; ho, 2004; unno et al, 2006), <papid> P06-2109 </papid>style in text simplification (marsi &amp; krahmer, 2005) <papid> W05-1612 </papid>or sentence simplification for sub titling (daelemans et al, 2004).</citsent>
<aftsection>
<nextsent>1project partially funded by portuguese fct (reference: posc/plp/57438/2004)generally, sentence compression involves performing the following three steps: (1) extraction of paraphrases from comparable corpora, (2) alignment of paraphrases and (3) induction of rewritingrules.
</nextsent>
<nextsent>obviously, each of these steps can be performed in many different ways going from totally unsupervised to totally supervised.
</nextsent>
<nextsent>in this paper, we will focus on the first two steps.
</nextsent>
<nextsent>in particular, we will first justify the application ofa new measure for the automatic extraction of paraphrase corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1332">
<title id=" W07-1429.xml">biology based alignments of paraphrases for sentence compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we will provide some results of different biology based methodologies for pairwise paraphrase alignment.
</prevsent>
<prevsent>sentence compression can be seen as the removal of redundant words or phrases from an input sentence by creating new sentence in which the gistof the original meaning of the sentence remains unchanged.
</prevsent>
</prevsection>
<citsent citstr=" P06-2109 ">
sentence compression takes an important place for natural language processing (nlp) tasks where specific constraints must be satisfied, such as length in summarization (barzilay &amp; lee, 2002; <papid> W02-1022 </papid>knight &amp; marcu, 2002; shinyama et al, 2002; barzilay &amp; lee, 2003; <papid> N03-1003 </papid>le nguyen &amp; ho, 2004; unno et al, 2006), <papid> P06-2109 </papid>style in text simplification (marsi &amp; krahmer, 2005) <papid> W05-1612 </papid>or sentence simplification for sub titling (daelemans et al, 2004).</citsent>
<aftsection>
<nextsent>1project partially funded by portuguese fct (reference: posc/plp/57438/2004)generally, sentence compression involves performing the following three steps: (1) extraction of paraphrases from comparable corpora, (2) alignment of paraphrases and (3) induction of rewritingrules.
</nextsent>
<nextsent>obviously, each of these steps can be performed in many different ways going from totally unsupervised to totally supervised.
</nextsent>
<nextsent>in this paper, we will focus on the first two steps.
</nextsent>
<nextsent>in particular, we will first justify the application ofa new measure for the automatic extraction of paraphrase corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1333">
<title id=" W07-1429.xml">biology based alignments of paraphrases for sentence compression </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we will provide some results of different biology based methodologies for pairwise paraphrase alignment.
</prevsent>
<prevsent>sentence compression can be seen as the removal of redundant words or phrases from an input sentence by creating new sentence in which the gistof the original meaning of the sentence remains unchanged.
</prevsent>
</prevsection>
<citsent citstr=" W05-1612 ">
sentence compression takes an important place for natural language processing (nlp) tasks where specific constraints must be satisfied, such as length in summarization (barzilay &amp; lee, 2002; <papid> W02-1022 </papid>knight &amp; marcu, 2002; shinyama et al, 2002; barzilay &amp; lee, 2003; <papid> N03-1003 </papid>le nguyen &amp; ho, 2004; unno et al, 2006), <papid> P06-2109 </papid>style in text simplification (marsi &amp; krahmer, 2005) <papid> W05-1612 </papid>or sentence simplification for sub titling (daelemans et al, 2004).</citsent>
<aftsection>
<nextsent>1project partially funded by portuguese fct (reference: posc/plp/57438/2004)generally, sentence compression involves performing the following three steps: (1) extraction of paraphrases from comparable corpora, (2) alignment of paraphrases and (3) induction of rewritingrules.
</nextsent>
<nextsent>obviously, each of these steps can be performed in many different ways going from totally unsupervised to totally supervised.
</nextsent>
<nextsent>in this paper, we will focus on the first two steps.
</nextsent>
<nextsent>in particular, we will first justify the application ofa new measure for the automatic extraction of paraphrase corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1443">
<title id=" W07-2080.xml">ucb system description for semeval task 4 </title>
<section> instrument-agency laser-printer, ax-murderer.  </section>
<citcontext>
<prevsection>
<prevsent>lauer (1995) proposes that eight prepositions are enough to characterize the relation between nouns in noun-noun compound: of, for, in, at, on, from, with or about.
</prevsent>
<prevsent>lapata and keller (2005) improve on his results by using web statistics.
</prevsent>
</prevsection>
<citsent citstr=" P02-1032 ">
rosario et al(2002) <papid> P02-1032 </papid>use descent of hierarchy?, which characterizes the relation based on the semantic category ofthe two nouns.</citsent>
<aftsection>
<nextsent>girju et al (2005) apply svm, decision trees, semantic scattering and iterative seman 366tic specialization, using wordnet, word sense disambiguation, and linguistic features.
</nextsent>
<nextsent>barker and szpakowicz (1998) <papid> P98-1015 </papid>propose two-level hierarchy with 5 classes at the upper level and 30 at the lower level.</nextsent>
<nextsent>turney (2005) introduces latent relational analysis, which uses the web, synonyms, patterns like fory ?, such as ?, etc., and singular value decomposition to smooth the frequencies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1444">
<title id=" W07-2080.xml">ucb system description for semeval task 4 </title>
<section> instrument-agency laser-printer, ax-murderer.  </section>
<citcontext>
<prevsection>
<prevsent>rosario et al(2002) <papid> P02-1032 </papid>use descent of hierarchy?, which characterizes the relation based on the semantic category ofthe two nouns.</prevsent>
<prevsent>girju et al (2005) apply svm, decision trees, semantic scattering and iterative seman 366tic specialization, using wordnet, word sense disambiguation, and linguistic features.</prevsent>
</prevsection>
<citsent citstr=" P98-1015 ">
barker and szpakowicz (1998) <papid> P98-1015 </papid>propose two-level hierarchy with 5 classes at the upper level and 30 at the lower level.</citsent>
<aftsection>
<nextsent>turney (2005) introduces latent relational analysis, which uses the web, synonyms, patterns like fory ?, such as ?, etc., and singular value decomposition to smooth the frequencies.
</nextsent>
<nextsent>turney (2006) <papid> P06-1040 </papid>induces patterns from the web, e.g. cause is best characterized by * causes x?, and in * earlyx?</nextsent>
<nextsent>is the best pattern for temporal.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1445">
<title id=" W07-2080.xml">ucb system description for semeval task 4 </title>
<section> instrument-agency laser-printer, ax-murderer.  </section>
<citcontext>
<prevsection>
<prevsent>barker and szpakowicz (1998) <papid> P98-1015 </papid>propose two-level hierarchy with 5 classes at the upper level and 30 at the lower level.</prevsent>
<prevsent>turney (2005) introduces latent relational analysis, which uses the web, synonyms, patterns like fory ?, such as ?, etc., and singular value decomposition to smooth the frequencies.</prevsent>
</prevsection>
<citsent citstr=" P06-1040 ">
turney (2006) <papid> P06-1040 </papid>induces patterns from the web, e.g. cause is best characterized by * causes x?, and in * earlyx?</citsent>
<aftsection>
<nextsent>is the best pattern for temporal.
</nextsent>
<nextsent>kim and baldwin (2006) <papid> P06-2064 </papid>propose to use predefined set of seed verbs and multiple resources: wordnet, corelex,and mobys thesaurus.</nextsent>
<nextsent>finally, in previous publication (nakov and hearst, 2006), we make the claim that the relation between the nouns in noun-nouncompound can be characterized by the set of intervening verbs extracted from the web.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1446">
<title id=" W07-2080.xml">ucb system description for semeval task 4 </title>
<section> instrument-agency laser-printer, ax-murderer.  </section>
<citcontext>
<prevsection>
<prevsent>turney (2006) <papid> P06-1040 </papid>induces patterns from the web, e.g. cause is best characterized by * causes x?, and in * earlyx?</prevsent>
<prevsent>is the best pattern for temporal.</prevsent>
</prevsection>
<citsent citstr=" P06-2064 ">
kim and baldwin (2006) <papid> P06-2064 </papid>propose to use predefined set of seed verbs and multiple resources: wordnet, corelex,and mobys thesaurus.</citsent>
<aftsection>
<nextsent>finally, in previous publication (nakov and hearst, 2006), we make the claim that the relation between the nouns in noun-nouncompound can be characterized by the set of intervening verbs extracted from the web.
</nextsent>
<nextsent>given an entity-annotated example sentence, we reduce the target entities e1 and e2 to single nouns noun1 and noun2, by keeping their last nouns only, which we assume to be the heads.
</nextsent>
<nextsent>we then mine the web for sentences containing both noun1and noun2, from which we extract features, consisting of word(s), part of speech (verb, preposition, verb+preposition, coordinating conjunction), and whether noun1 precedes noun2.
</nextsent>
<nextsent>table 2 shows some example features and their frequencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1448">
<title id=" W07-1033.xml">reranking for biomedical named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is common for practical protein or gene databases to contain hundreds of thousands of items.
</prevsent>
<prevsent>such large variety of vocabulary naturally leads to long names with productive use of general words, making the task difficult to be solved by systems with naive markov assumption of label sequences, because such systems must perform their prediction without seeing the entire string of the entities.
</prevsent>
</prevsection>
<citsent citstr=" W04-1219 ">
importance of the treatment of long names mightbe implicitly indicated in the performance comparison of the participants of jnlpba shared task (kim et al , 2004), where the best performing system (zhou and su, 2004) <papid> W04-1219 </papid>attains their scores by extensive post-processing, which enabled the system to make use of global information of the entity labels.</citsent>
<aftsection>
<nextsent>after the shared task, many researchers tackled the task by using conditional random fields (crfs) (lafferty et al , 2001), which seemed to promise improvement over locally optimized models like maximum entropy markov models (memms) (mccallum et al , 2000).
</nextsent>
<nextsent>however, many of the crf systems developed after the shared task failed to reach the best performance achieved by zhou et al  one of the reasons may be the deficiency of the dynamic programming-based systems, that the global information of sequences cannot be incorporated as features of the models.
</nextsent>
<nextsent>another reason may be that the computational complexity ofthe models prevented the developers to invent effective features for the task.
</nextsent>
<nextsent>we had to wait until tsai et al  (2006), who combine pattern-based postprocessing with crfs, for crf-based systems to achieve the same level of performance as zhou et al as such, key to further improvement of the performance of bio-entity recognition has been to employ global features, which are effective to capture the features of long names appearing in the bio domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1450">
<title id=" W07-1033.xml">reranking for biomedical named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>though it is impossible to observe clear correlation between the performance and classification models or resources used, an important characteristic of the best system by zhou et al .
</prevsent>
<prevsent>(2004) seems to be extensive use of rule-basedpost processing they apply to the output of their clas sifier.after the shared task, several researchers tackled the problem using the crfs and their extensions.
</prevsent>
</prevsection>
<citsent citstr=" P06-1059 ">
okanohara et al  (2006) <papid> P06-1059 </papid>applied semi crfs (sarawagi and cohen, 2004), which can treat multiple words as corresponding to single state.</citsent>
<aftsection>
<nextsent>friedrich et al  (2006) used crfs with features from the external gazetteer.
</nextsent>
<nextsent>current state-of-the-art for the shared-task is achieved by tsai et al  (2006), whose improvement depends on careful design of features including the normalization of numeric expressions, and use of post-processing by automatically extracted patterns.
</nextsent>
<nextsent>210 il-2 gene expression requires reactive oxygen production by 5-lipoxygenase . b-dna i-dna o o o b-protein figure 1: example sentence from the training data.
</nextsent>
<nextsent>state name possible next state bos b-* or b-protein i-protein, b-* or b-cell type i-cell type, b-* or b-dna i-dna, b-* or b-cell line i-cell line, b-* or b-rna i-rna, b-* or i-protein i-protein, b-* or i-cell type i-cell type, b-* or i-dna i-dna, b-* or i-cell line i-cell line, b-* or i-rna i-rna, b-* or o b-* or table 1: state transition of memm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1452">
<title id=" W07-1033.xml">reranking for biomedical named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>probability of state transition to the i-th label of sentence is calculated by the following formula: (li|li1, s) = exp(j jfj(li, li1, s)) ? exp( ? jfj(l, li1, s)) .
</prevsent>
<prevsent>(1) features used forward tagging backward tagging unigrams, bigrams and previous labels (62.43/71.77/66.78) (66.02/74.73/70.10) unigrams and bigrams (61.64/71.73/66.30) (65.38/74.87/69.80) unigrams and previous labels (62.17/71.67/66.58) (65.59/74.77/69.88) unigrams (61.31/71.81/66.15) (65.61/75.25/70.10) table 2: (recall/precision/f-score) of forward and backward tagging.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
where li is the next bio tag, li1 is the previous bio tag, is the target sentence, and fj and lj are feature functions and parameters of log-linear model (berger et al , 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>as first order memm,the probability of label li is dependent on the previous label li1, and when we calculate the normalization constantin the right hand side (i.e. the denominator of the fraction), we limit the range of to the possible successors of the previous label.
</nextsent>
<nextsent>this probability is multiplied to obtain the probability of label sequence for sentence: (l1...n|s) = ? p (li|li1).
</nextsent>
<nextsent>(2) the probability in eq.
</nextsent>
<nextsent>1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1458">
<title id=" W07-1033.xml">reranking for biomedical named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our system showed clear improvement over many of the machine-learning-based systems reported to date,and also proved comparable to the existing state-of the-art systems that use rule-based post-processing.
</prevsent>
<prevsent>our future plans include further sophistication of features, such as the use of external gazette ers which is reported to improve the f-score by 1.0 and 2.7 points in (zhou and su, 2004) <papid> W04-1219 </papid>and (friedrich et al ., 2006), respectively.</prevsent>
</prevsection>
<citsent citstr=" N06-1020 ">
we expect that reranking architecture can readily accommodate dictionary based features, because we can apply elaboratedstring-matching algorithms to the qualified candidate strings available at reranking phase.we also plan to apply self-training of n-best tagger which successfully boosted the performance of one of the best existing english syntactic parser (mcclosky et al , 2006).<papid> N06-1020 </papid></citsent>
<aftsection>
<nextsent>since the test data of the shared-task consists of articles that represent the different publication years, the effects of the publication years of the texts used for self-training would be interesting to study.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1459">
<title id=" W08-0331.xml">ranking vs regression in machine translation evaluation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>successful methods such as bleu work supported by an nsf graduate research fellowship.(papineni et al, 2002) work by comparing mt out put with one or more human reference translations and generating similarity score.
</prevsent>
<prevsent>methods differ by the definition of similarity.
</prevsent>
</prevsection>
<citsent citstr=" P04-1077 ">
for instance, bleu and rouge (lin and och, 2004) <papid> P04-1077 </papid>are based on n-gram precis ions, meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and stm (liu and gildea, 2005) <papid> W05-0904 </papid>use word-class or structural information, kauchak (2006) leverages on paraphrases, and ter (snover et al, 2006) usesedit-distances.</citsent>
<aftsection>
<nextsent>currently, bleu is the most popular metric; it has been shown that it correlates well with human judgments on the corpus level.
</nextsent>
<nextsent>however, finding metric that correlates well with human judgments on the sentence-level is still an open challenge (blatz and others, 2003).
</nextsent>
<nextsent>machine learning approaches have been proposed to address the problem of sentence-level evaluation.
</nextsent>
<nextsent>(corston-oliver et al, 2001) and (kuleszaand shieber, 2004) train classifiers to discriminate between human-like translations and automatic translations, using features from the aforementioned metrics (e.g. n-gram precisions).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1460">
<title id=" W08-0331.xml">ranking vs regression in machine translation evaluation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>successful methods such as bleu work supported by an nsf graduate research fellowship.(papineni et al, 2002) work by comparing mt out put with one or more human reference translations and generating similarity score.
</prevsent>
<prevsent>methods differ by the definition of similarity.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
for instance, bleu and rouge (lin and och, 2004) <papid> P04-1077 </papid>are based on n-gram precis ions, meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and stm (liu and gildea, 2005) <papid> W05-0904 </papid>use word-class or structural information, kauchak (2006) leverages on paraphrases, and ter (snover et al, 2006) usesedit-distances.</citsent>
<aftsection>
<nextsent>currently, bleu is the most popular metric; it has been shown that it correlates well with human judgments on the corpus level.
</nextsent>
<nextsent>however, finding metric that correlates well with human judgments on the sentence-level is still an open challenge (blatz and others, 2003).
</nextsent>
<nextsent>machine learning approaches have been proposed to address the problem of sentence-level evaluation.
</nextsent>
<nextsent>(corston-oliver et al, 2001) and (kuleszaand shieber, 2004) train classifiers to discriminate between human-like translations and automatic translations, using features from the aforementioned metrics (e.g. n-gram precisions).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1461">
<title id=" W08-0331.xml">ranking vs regression in machine translation evaluation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>successful methods such as bleu work supported by an nsf graduate research fellowship.(papineni et al, 2002) work by comparing mt out put with one or more human reference translations and generating similarity score.
</prevsent>
<prevsent>methods differ by the definition of similarity.
</prevsent>
</prevsection>
<citsent citstr=" W05-0904 ">
for instance, bleu and rouge (lin and och, 2004) <papid> P04-1077 </papid>are based on n-gram precis ions, meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and stm (liu and gildea, 2005) <papid> W05-0904 </papid>use word-class or structural information, kauchak (2006) leverages on paraphrases, and ter (snover et al, 2006) usesedit-distances.</citsent>
<aftsection>
<nextsent>currently, bleu is the most popular metric; it has been shown that it correlates well with human judgments on the corpus level.
</nextsent>
<nextsent>however, finding metric that correlates well with human judgments on the sentence-level is still an open challenge (blatz and others, 2003).
</nextsent>
<nextsent>machine learning approaches have been proposed to address the problem of sentence-level evaluation.
</nextsent>
<nextsent>(corston-oliver et al, 2001) and (kuleszaand shieber, 2004) train classifiers to discriminate between human-like translations and automatic translations, using features from the aforementioned metrics (e.g. n-gram precisions).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1462">
<title id=" W08-0331.xml">ranking vs regression in machine translation evaluation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>machine learning approaches have been proposed to address the problem of sentence-level evaluation.
</prevsent>
<prevsent>(corston-oliver et al, 2001) and (kuleszaand shieber, 2004) train classifiers to discriminate between human-like translations and automatic translations, using features from the aforementioned metrics (e.g. n-gram precisions).
</prevsent>
</prevsection>
<citsent citstr=" P07-1111 ">
in contrast, (albrecht and hwa, 2007) <papid> P07-1111 </papid>argues for regression approach that directly predicts human ad equecy/fluency scores.</citsent>
<aftsection>
<nextsent>all the above methods are score-based in the sense that they generate score for each mt systemoutput.
</nextsent>
<nextsent>when the evaluation goal is to compare multiple mt systems, scores are first generated independently for each system, then systems are ranked by their respective scores.
</nextsent>
<nextsent>we think that this two step process may be unnecessarily complex.
</nextsent>
<nextsent>why solve more difficult problem of predicting the quality of mt system outputs, when the goal is simply 191 to compare systems?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1463">
<title id=" W08-0331.xml">ranking vs regression in machine translation evaluation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>why solve more difficult problem of predicting the quality of mt system outputs, when the goal is simply 191 to compare systems?
</prevsent>
<prevsent>in this regard, we propose ranking-based approach that directly ranks set of mt systems without going through the intermediary of system-specific scores.
</prevsent>
</prevsection>
<citsent citstr=" W07-0713 ">
our approach requires (a) training data in terms of human ranking judgments of mt outputs, and (b) machine learning algorithm for learning and predicting rankings.1 the advantages of ranking approach are: ? it is often easier for human judges to rank mt outputs by preference than to assign absolute scores (vilar et al, 2007).<papid> W07-0713 </papid></citsent>
<aftsection>
<nextsent>this is because it is difficult to quantify the quality of translation accurately, but relative easy to tell which oneof several translations is better.
</nextsent>
<nextsent>thus human annotated data based on ranking may be less costly to acquire.
</nextsent>
<nextsent>the inter- and intra-annotator agreement for ranking is much more reasonable than that of scoring.
</nextsent>
<nextsent>for instance, callison-burch (2007) found the inter-annotator agreement (kappa) for scoring fluency/adequency to be around .22-.25, whereas the kappa for ranking is around .37-.56.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1464">
<title id=" W07-1524.xml">standoff coordination for multi tool annotation in a dialogue corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present the corpus and its paula-based architecture.1
</prevsent>
<prevsent>xml standoff markup (thompson and mckelvie,1997; dybkjr et al, 1998) is emerging as the cleanest way to organize multi-level annotations of corpora.
</prevsent>
</prevsection>
<citsent citstr=" N03-4009 ">
in many of the current annotation efforts based on standoff single multi-purpose tool such as thenite xml toolkit (carletta et al, 2003) or word freak (morton and lacivita, 2003) <papid> N03-4009 </papid>is used to anno1the members of the luna project consortium are: piedmont consortium for information systems (it), university oftrento (it), loquendo spa (it), rwth-aachen (de), university of avignon (fr), france telecom r&d; division s.a.</citsent>
<aftsection>
<nextsent>(fr), polish-japanese institute of information technology (pl) and the institute for computer science of the polish academy of sciences (pl), http://www.ist-luna.eu.
</nextsent>
<nextsent>this research was performed in the luna project funded by theec, dg infso, unit e1 and in the collaborative research center 632 information structure?, funded by the german science foundation, http://www.sfb632.uni-potsdam.de.
</nextsent>
<nextsent>tate as well as maintain all annotation levels (cf.
</nextsent>
<nextsent>the sammie annotation effort (kruijff-korbayova?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1465">
<title id=" W07-1524.xml">standoff coordination for multi tool annotation in a dialogue corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even in these cases, however, it may still be useful, or even necessary, to be able to visualize more than one level at once, or to knit?
</prevsent>
<prevsent>together2 multiple levels to create file that can be used to train model for particular type of annotation.
</prevsent>
</prevsection>
<citsent citstr=" W03-0804 ">
the linguistic annotation framework by (ide et al, 2003) <papid> W03-0804 </papid>was proposed as unifying markup format tobe used to synchronize heterogeneous markup formats for such purposes.in this paper, we discuss how the paula representation format, standoff format inspired by the linguistic annotation framework, is being used to synchronize multiple levels of annotation in the luna corpus, corpus of spoken dialogues in multiple languages and multiple domains that is being created to support the development of robust spoken language understanding models for multilingual dialogue ser vices.</citsent>
<aftsection>
<nextsent>the corpus is richly annotated with linguistic information that is considered relevant for research on dialogue, including chunks, named entities, argument structure, coreference, and dialogue acts.
</nextsent>
<nextsent>we chose to adopt specialized tools for each level: e.g., 2in the sense of the knit tool of the lt-xml suite.
</nextsent>
<nextsent>148transcription using transcriber, coreference using mmax, attributes using semantizer, etc. to synchronize the annotation and allow cross-layer operations, the annotations are mapped to common representation format, paula.the structure of the paper is as follows.
</nextsent>
<nextsent>in section 2, we present the luna project and the luna corpus with its main annotation levels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1466">
<title id=" W07-1524.xml">standoff coordination for multi tool annotation in a dialogue corpus </title>
<section> the luna project.  </section>
<citcontext>
<prevsection>
<prevsent>a semantic segment is unit that corresponds unambiguously to concept of the dictionary.
</prevsent>
<prevsent>(1) buongiorno lei [puo` iscriversi]concept1 [agli esami]concept2 [oppure]concept3 [ottenere delle informazioni]concept4 come la posso aiutare4  concept1 action:inscription   concept2 objectdb:examen   concept3 conjunctor:alternative   concept4 action:obtain info  2.3.4 predicate structure the annotation of predicate structure facilitates the interpretation of the relation between entities and events occurring in the dialogue.there are different approaches to annotate predicate structure.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
some of them are based upon syntactic structure, with propbank (kingsbury and palmer, 2003) being one of the most relevant, building the annotation upon the syntactic representation of the treebank corpus (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>an alternative to syntax-driven approaches is the annotation using semantic roles as in framenet (baker et al, 1998).<papid> P98-1013 </papid></nextsent>
<nextsent>for the annotation of predicate structure in the luna corpus, we decided to use framenet-like approach, rather than syntax-based approach: 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1467">
<title id=" W07-1524.xml">standoff coordination for multi tool annotation in a dialogue corpus </title>
<section> the luna project.  </section>
<citcontext>
<prevsection>
<prevsent>(1) buongiorno lei [puo` iscriversi]concept1 [agli esami]concept2 [oppure]concept3 [ottenere delle informazioni]concept4 come la posso aiutare4  concept1 action:inscription   concept2 objectdb:examen   concept3 conjunctor:alternative   concept4 action:obtain info  2.3.4 predicate structure the annotation of predicate structure facilitates the interpretation of the relation between entities and events occurring in the dialogue.there are different approaches to annotate predicate structure.
</prevsent>
<prevsent>some of them are based upon syntactic structure, with propbank (kingsbury and palmer, 2003) being one of the most relevant, building the annotation upon the syntactic representation of the treebank corpus (marcus et al, 1993).<papid> J93-2004 </papid></prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
an alternative to syntax-driven approaches is the annotation using semantic roles as in framenet (baker et al, 1998).<papid> P98-1013 </papid></citsent>
<aftsection>
<nextsent>for the annotation of predicate structure in the luna corpus, we decided to use framenet-like approach, rather than syntax-based approach: 1.
</nextsent>
<nextsent>annotation of dialogue interaction has to deal.
</nextsent>
<nextsent>with disfluencies, non-complete sentences, un grammaticality, etc., which complicates the use of deep syntactic representations.
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1470">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also demonstrate that the features induced by the isbns latent variables are crucial to this success, and show that the proposed model is particularly good on long dependencies.
</prevsent>
<prevsent>dependency parsing has been topic of active research in natural language processing during the last several years.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
the conll-x shared task (buch holz and marsi, 2006) <papid> W06-2920 </papid>made wide selection of standardized treebanks for different languages available for the research community and allowed foreasy comparison between various statistical methods on standardized benchmark.</citsent>
<aftsection>
<nextsent>one of the surprising things discovered by this evaluation is that the best results are achieved by methods which are quite different from state-of-the-art models for constituent parsing, e.g. the deterministic parsing method of (nivre et al, 2006) <papid> W06-2933 </papid>and the minimum spanning tree parser of (mcdonald et al, 2006).<papid> W06-2932 </papid></nextsent>
<nextsent>all the most accurate dependency parsing models are fully discriminative, unlike constituent parsing where all the state of the art methods have generative component (charniak and johnson, 2005; <papid> P05-1022 </papid>henderson, 2004; <papid> P04-1013 </papid>collins, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1471">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency parsing has been topic of active research in natural language processing during the last several years.
</prevsent>
<prevsent>the conll-x shared task (buch holz and marsi, 2006) <papid> W06-2920 </papid>made wide selection of standardized treebanks for different languages available for the research community and allowed foreasy comparison between various statistical methods on standardized benchmark.</prevsent>
</prevsection>
<citsent citstr=" W06-2933 ">
one of the surprising things discovered by this evaluation is that the best results are achieved by methods which are quite different from state-of-the-art models for constituent parsing, e.g. the deterministic parsing method of (nivre et al, 2006) <papid> W06-2933 </papid>and the minimum spanning tree parser of (mcdonald et al, 2006).<papid> W06-2932 </papid></citsent>
<aftsection>
<nextsent>all the most accurate dependency parsing models are fully discriminative, unlike constituent parsing where all the state of the art methods have generative component (charniak and johnson, 2005; <papid> P05-1022 </papid>henderson, 2004; <papid> P04-1013 </papid>collins, 2000).</nextsent>
<nextsent>another surprising thing is the lack of latent variable models among the methods used in the shared task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1476">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency parsing has been topic of active research in natural language processing during the last several years.
</prevsent>
<prevsent>the conll-x shared task (buch holz and marsi, 2006) <papid> W06-2920 </papid>made wide selection of standardized treebanks for different languages available for the research community and allowed foreasy comparison between various statistical methods on standardized benchmark.</prevsent>
</prevsection>
<citsent citstr=" W06-2932 ">
one of the surprising things discovered by this evaluation is that the best results are achieved by methods which are quite different from state-of-the-art models for constituent parsing, e.g. the deterministic parsing method of (nivre et al, 2006) <papid> W06-2933 </papid>and the minimum spanning tree parser of (mcdonald et al, 2006).<papid> W06-2932 </papid></citsent>
<aftsection>
<nextsent>all the most accurate dependency parsing models are fully discriminative, unlike constituent parsing where all the state of the art methods have generative component (charniak and johnson, 2005; <papid> P05-1022 </papid>henderson, 2004; <papid> P04-1013 </papid>collins, 2000).</nextsent>
<nextsent>another surprising thing is the lack of latent variable models among the methods used in the shared task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1477">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the conll-x shared task (buch holz and marsi, 2006) <papid> W06-2920 </papid>made wide selection of standardized treebanks for different languages available for the research community and allowed foreasy comparison between various statistical methods on standardized benchmark.</prevsent>
<prevsent>one of the surprising things discovered by this evaluation is that the best results are achieved by methods which are quite different from state-of-the-art models for constituent parsing, e.g. the deterministic parsing method of (nivre et al, 2006) <papid> W06-2933 </papid>and the minimum spanning tree parser of (mcdonald et al, 2006).<papid> W06-2932 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
all the most accurate dependency parsing models are fully discriminative, unlike constituent parsing where all the state of the art methods have generative component (charniak and johnson, 2005; <papid> P05-1022 </papid>henderson, 2004; <papid> P04-1013 </papid>collins, 2000).</citsent>
<aftsection>
<nextsent>another surprising thing is the lack of latent variable models among the methods used in the shared task.
</nextsent>
<nextsent>latent variable models would allow complex features to be induced automatically, which would be highly desirable in multilingual parsing, where manual feature selection might be very difficult and time consuming, especially for languages unknown to the parser developer.in this paper we propose generative latent variable model for dependency parsing.
</nextsent>
<nextsent>it is based on incremental sigmoid belief networks (isbns), aclass of directed graphical model for structure prediction problems recently proposed in (titov and henderson, 2007),<papid> P07-1080 </papid>where they were demonstrated to achieve competitive results on the constituent parsing task.</nextsent>
<nextsent>as discussed in (titov and henderson, 2007),<papid> P07-1080 </papid>computing the conditional probabilities which we need for parsing is in general intractable with isbns, but they can be approximated efficiently in several ways.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1478">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the conll-x shared task (buch holz and marsi, 2006) <papid> W06-2920 </papid>made wide selection of standardized treebanks for different languages available for the research community and allowed foreasy comparison between various statistical methods on standardized benchmark.</prevsent>
<prevsent>one of the surprising things discovered by this evaluation is that the best results are achieved by methods which are quite different from state-of-the-art models for constituent parsing, e.g. the deterministic parsing method of (nivre et al, 2006) <papid> W06-2933 </papid>and the minimum spanning tree parser of (mcdonald et al, 2006).<papid> W06-2932 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1013 ">
all the most accurate dependency parsing models are fully discriminative, unlike constituent parsing where all the state of the art methods have generative component (charniak and johnson, 2005; <papid> P05-1022 </papid>henderson, 2004; <papid> P04-1013 </papid>collins, 2000).</citsent>
<aftsection>
<nextsent>another surprising thing is the lack of latent variable models among the methods used in the shared task.
</nextsent>
<nextsent>latent variable models would allow complex features to be induced automatically, which would be highly desirable in multilingual parsing, where manual feature selection might be very difficult and time consuming, especially for languages unknown to the parser developer.in this paper we propose generative latent variable model for dependency parsing.
</nextsent>
<nextsent>it is based on incremental sigmoid belief networks (isbns), aclass of directed graphical model for structure prediction problems recently proposed in (titov and henderson, 2007),<papid> P07-1080 </papid>where they were demonstrated to achieve competitive results on the constituent parsing task.</nextsent>
<nextsent>as discussed in (titov and henderson, 2007),<papid> P07-1080 </papid>computing the conditional probabilities which we need for parsing is in general intractable with isbns, but they can be approximated efficiently in several ways.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1479">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>another surprising thing is the lack of latent variable models among the methods used in the shared task.
</prevsent>
<prevsent>latent variable models would allow complex features to be induced automatically, which would be highly desirable in multilingual parsing, where manual feature selection might be very difficult and time consuming, especially for languages unknown to the parser developer.in this paper we propose generative latent variable model for dependency parsing.
</prevsent>
</prevsection>
<citsent citstr=" P07-1080 ">
it is based on incremental sigmoid belief networks (isbns), aclass of directed graphical model for structure prediction problems recently proposed in (titov and henderson, 2007),<papid> P07-1080 </papid>where they were demonstrated to achieve competitive results on the constituent parsing task.</citsent>
<aftsection>
<nextsent>as discussed in (titov and henderson, 2007),<papid> P07-1080 </papid>computing the conditional probabilities which we need for parsing is in general intractable with isbns, but they can be approximated efficiently in several ways.</nextsent>
<nextsent>in particular, the neural network constituent parsers in (henderson, 2003)<papid> N03-1014 </papid>and (henderson, 2004) <papid> P04-1013 </papid>can be regarded as coarse approximations to their corresponding isbn model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1485">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is based on incremental sigmoid belief networks (isbns), aclass of directed graphical model for structure prediction problems recently proposed in (titov and henderson, 2007),<papid> P07-1080 </papid>where they were demonstrated to achieve competitive results on the constituent parsing task.</prevsent>
<prevsent>as discussed in (titov and henderson, 2007),<papid> P07-1080 </papid>computing the conditional probabilities which we need for parsing is in general intractable with isbns, but they can be approximated efficiently in several ways.</prevsent>
</prevsection>
<citsent citstr=" N03-1014 ">
in particular, the neural network constituent parsers in (henderson, 2003)<papid> N03-1014 </papid>and (henderson, 2004) <papid> P04-1013 </papid>can be regarded as coarse approximations to their corresponding isbn model.</citsent>
<aftsection>
<nextsent>isbns use history-based probability models.
</nextsent>
<nextsent>the most common approach to handling the unbounded nature of the parse histories in these models is to choose pre-defined set of features which can be unambiguously derived from the history (e.g.
</nextsent>
<nextsent>(charniak, 2000; <papid> A00-2018 </papid>collins, 1999; nivre et al, 2004)).<papid> W04-2407 </papid></nextsent>
<nextsent>decision probabilities are then assumed to be independent of all information not represented by this finite set of features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1489">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>isbns use history-based probability models.
</prevsent>
<prevsent>the most common approach to handling the unbounded nature of the parse histories in these models is to choose pre-defined set of features which can be unambiguously derived from the history (e.g.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
(charniak, 2000; <papid> A00-2018 </papid>collins, 1999; nivre et al, 2004)).<papid> W04-2407 </papid></citsent>
<aftsection>
<nextsent>decision probabilities are then assumed to be independent of all information not represented by this finite set of features.
</nextsent>
<nextsent>isbns instead use vector of binary 144 latent variables to encode the information about the parser history.
</nextsent>
<nextsent>this history vector is similar to the hidden state of hidden markov model.
</nextsent>
<nextsent>but unlike the graphical model for an hmm, which specifies conditional dependency edges only between adjacent states in the sequence, the isbn graphical model can specify conditional dependency edges between states which are arbitrarily far apart in the parse history.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1490">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>isbns use history-based probability models.
</prevsent>
<prevsent>the most common approach to handling the unbounded nature of the parse histories in these models is to choose pre-defined set of features which can be unambiguously derived from the history (e.g.
</prevsent>
</prevsection>
<citsent citstr=" W04-2407 ">
(charniak, 2000; <papid> A00-2018 </papid>collins, 1999; nivre et al, 2004)).<papid> W04-2407 </papid></citsent>
<aftsection>
<nextsent>decision probabilities are then assumed to be independent of all information not represented by this finite set of features.
</nextsent>
<nextsent>isbns instead use vector of binary 144 latent variables to encode the information about the parser history.
</nextsent>
<nextsent>this history vector is similar to the hidden state of hidden markov model.
</nextsent>
<nextsent>but unlike the graphical model for an hmm, which specifies conditional dependency edges only between adjacent states in the sequence, the isbn graphical model can specify conditional dependency edges between states which are arbitrarily far apart in the parse history.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1518">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>additional experiments suggest that both feature induction abilities and use of the beam search contribute to this improvement.
</prevsent>
<prevsent>the fact that our model defines probability model over parse trees, unlike the previous state-of the-art methods (nivre et al, 2006; <papid> W06-2933 </papid>mcdonald et al,2006), <papid> W06-2932 </papid>makes it easier to use this model in applications which require probability estimates, e.g. in language processing pipelines.</prevsent>
</prevsection>
<citsent citstr=" P05-1023 ">
also, as with any generative model, it may be easy to improve the parsers accuracy by using discriminative retraining techniques (henderson, 2004) <papid> P04-1013 </papid>or data-defined kernels (henderson and titov, 2005), <papid> P05-1023 </papid>with or even with out introduction of any additional linguistic features.in addition, there are some applications, such aslan guage modeling, which require generative models.</citsent>
<aftsection>
<nextsent>another advantage of generative models is that theydo not suffer from the label bias problems (bottou, 1991), which is potential problem for conditional or deterministic history-based models, such as (nivre et al, 2004).<papid> W04-2407 </papid></nextsent>
<nextsent>in the remainder of this paper, we will first review general isbns and how they can be approximated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1583">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>roughly, the model considered the whole sentence at time, with the dbn being used to decide which words correspond to leaves of the tree.
</prevsent>
<prevsent>the chosen words are then removed from the sentence and the model is recursively applied to the reduced sentence.
</prevsent>
</prevsection>
<citsent citstr=" H05-1064 ">
recently several latent variable models for constituent parsing have been proposed (koo and collins, 2005; <papid> H05-1064 </papid>matsuzaki et al, 2005; <papid> P05-1010 </papid>prescher, 2005; <papid> W05-1512 </papid>riezler et al, 2002).<papid> P02-1035 </papid>in (matsuzaki et al, 2005) <papid> P05-1010 </papid>non-terminals in standard pcfg model are augmented with latent vari ables.</citsent>
<aftsection>
<nextsent>a similar model of (prescher, 2005) <papid> W05-1512 </papid>uses ahead-driven pcfg with latent heads, thus restricting the flexibility of the latent-variable model by using explicit linguistic constraints.</nextsent>
<nextsent>while the model of (matsuzaki et al, 2005) <papid> P05-1010 </papid>significantly outperforms the constrained model of (prescher, 2005), <papid> W05-1512 </papid>they both are well below the state-of-the-art in constituent parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1584">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>roughly, the model considered the whole sentence at time, with the dbn being used to decide which words correspond to leaves of the tree.
</prevsent>
<prevsent>the chosen words are then removed from the sentence and the model is recursively applied to the reduced sentence.
</prevsent>
</prevsection>
<citsent citstr=" P05-1010 ">
recently several latent variable models for constituent parsing have been proposed (koo and collins, 2005; <papid> H05-1064 </papid>matsuzaki et al, 2005; <papid> P05-1010 </papid>prescher, 2005; <papid> W05-1512 </papid>riezler et al, 2002).<papid> P02-1035 </papid>in (matsuzaki et al, 2005) <papid> P05-1010 </papid>non-terminals in standard pcfg model are augmented with latent vari ables.</citsent>
<aftsection>
<nextsent>a similar model of (prescher, 2005) <papid> W05-1512 </papid>uses ahead-driven pcfg with latent heads, thus restricting the flexibility of the latent-variable model by using explicit linguistic constraints.</nextsent>
<nextsent>while the model of (matsuzaki et al, 2005) <papid> P05-1010 </papid>significantly outperforms the constrained model of (prescher, 2005), <papid> W05-1512 </papid>they both are well below the state-of-the-art in constituent parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1585">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>roughly, the model considered the whole sentence at time, with the dbn being used to decide which words correspond to leaves of the tree.
</prevsent>
<prevsent>the chosen words are then removed from the sentence and the model is recursively applied to the reduced sentence.
</prevsent>
</prevsection>
<citsent citstr=" W05-1512 ">
recently several latent variable models for constituent parsing have been proposed (koo and collins, 2005; <papid> H05-1064 </papid>matsuzaki et al, 2005; <papid> P05-1010 </papid>prescher, 2005; <papid> W05-1512 </papid>riezler et al, 2002).<papid> P02-1035 </papid>in (matsuzaki et al, 2005) <papid> P05-1010 </papid>non-terminals in standard pcfg model are augmented with latent vari ables.</citsent>
<aftsection>
<nextsent>a similar model of (prescher, 2005) <papid> W05-1512 </papid>uses ahead-driven pcfg with latent heads, thus restricting the flexibility of the latent-variable model by using explicit linguistic constraints.</nextsent>
<nextsent>while the model of (matsuzaki et al, 2005) <papid> P05-1010 </papid>significantly outperforms the constrained model of (prescher, 2005), <papid> W05-1512 </papid>they both are well below the state-of-the-art in constituent parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1586">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>roughly, the model considered the whole sentence at time, with the dbn being used to decide which words correspond to leaves of the tree.
</prevsent>
<prevsent>the chosen words are then removed from the sentence and the model is recursively applied to the reduced sentence.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
recently several latent variable models for constituent parsing have been proposed (koo and collins, 2005; <papid> H05-1064 </papid>matsuzaki et al, 2005; <papid> P05-1010 </papid>prescher, 2005; <papid> W05-1512 </papid>riezler et al, 2002).<papid> P02-1035 </papid>in (matsuzaki et al, 2005) <papid> P05-1010 </papid>non-terminals in standard pcfg model are augmented with latent vari ables.</citsent>
<aftsection>
<nextsent>a similar model of (prescher, 2005) <papid> W05-1512 </papid>uses ahead-driven pcfg with latent heads, thus restricting the flexibility of the latent-variable model by using explicit linguistic constraints.</nextsent>
<nextsent>while the model of (matsuzaki et al, 2005) <papid> P05-1010 </papid>significantly outperforms the constrained model of (prescher, 2005), <papid> W05-1512 </papid>they both are well below the state-of-the-art in constituent parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1594">
<title id=" W07-2218.xml">a latent variable model for generative dependency parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while the model of (matsuzaki et al, 2005) <papid> P05-1010 </papid>significantly outperforms the constrained model of (prescher, 2005), <papid> W05-1512 </papid>they both are well below the state-of-the-art in constituent parsing.</prevsent>
<prevsent>in (koo and collins, 2005), <papid> H05-1064 </papid>an undirected graphical model for constituent parse reranking uses dependency relations to define the edges.</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
thus, it should be easy to apply similar method to reranking dependency trees.undirected graphical models, in particular conditional random fields, are the standard tools for shallow parsing (sha and pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>however, shallow parsing is effectively sequence labeling problem and therefore differs significantly from full parsing.
</nextsent>
<nextsent>as discussed in (titov and henderson, 2007),<papid> P07-1080 </papid>undirected graphical models do not seem to be suit able for history-based parsing models.sigmoid belief networks (sbns) were used originally for character recognition tasks, but later dynamic modification of this model was applied to the reinforcement learning task (sallans, 2002).</nextsent>
<nextsent>how ever, their graphical model, approximation method, and learning method differ significantly from those of this paper.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1599">
<title id=" W08-0606.xml">the bio scope corpus annotation for negation uncertainty and their scope in biomedical texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>elkin et al (2005) use list of negation words and list of negation scope-ending words in order to identify negated statements and their scope.
</prevsent>
<prevsent>although fair amount of literature on uncertainty (or hedging) in scientific texts has been produced since the 1990s (e.g. hyland, 1994), speculative language from natural language processing perspective has only been studied in the past few years.
</prevsent>
</prevsection>
<citsent citstr=" W04-3103 ">
previous studies (light et al, 2004) <papid> W04-3103 </papid>showed that the detection of hedging can be solved effectively by looking for specific keywords which imply speculative content.</citsent>
<aftsection>
<nextsent>another possibility is to treat the problem as classification task and train statistical model to discriminate speculative and non-speculative assertions.
</nextsent>
<nextsent>this approach requires the availability of labeled instances to train the models on.
</nextsent>
<nextsent>medlock and briscoe (2007) <papid> P07-1125 </papid>proposed weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data.</nextsent>
<nextsent>their system focuses on locating hedge cues in text and thus they do not determine the scopes (in other words in text they define the scope to be whole sentence).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1600">
<title id=" W08-0606.xml">the bio scope corpus annotation for negation uncertainty and their scope in biomedical texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>another possibility is to treat the problem as classification task and train statistical model to discriminate speculative and non-speculative assertions.
</prevsent>
<prevsent>this approach requires the availability of labeled instances to train the models on.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
medlock and briscoe (2007) <papid> P07-1125 </papid>proposed weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data.</citsent>
<aftsection>
<nextsent>their system focuses on locating hedge cues in text and thus they do not determine the scopes (in other words in text they define the scope to be whole sentence).
</nextsent>
<nextsent>1.2 related resources.
</nextsent>
<nextsent>even though the problems of negation (mainly in the medical domain) and hedging (mainly in the scientific domain) have received much interest in the past few years, open access annotated resources for training, testing and comparison are rare and relatively small in size.
</nextsent>
<nextsent>our corpus is the first one with an annotation of negative/speculative keywords and their scope.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1603">
<title id=" W08-0606.xml">the bio scope corpus annotation for negation uncertainty and their scope in biomedical texts </title>
<section> corpus details.  </section>
<citcontext>
<prevsection>
<prevsent>a major part of the corpus consists of clinical free-texts.
</prevsent>
<prevsent>we chose to add medical texts to the corpus in order to facilitate research on nega tion/hedge detection in the clinical domain.
</prevsent>
</prevsection>
<citsent citstr=" W07-1013 ">
the radiology report corpus that was used for the clinical coding challenge (pestian et al, 2007) <papid> W07-1013 </papid>organised by the computational medicine center in cincinatti, ohio in 2007 was annotated for nega tions and uncertainty along with the scopes of each phenomenon.</citsent>
<aftsection>
<nextsent>this part contains 1954 documents, each having clinical history and an impression part, the latter being denser in negated and speculative parts.
</nextsent>
<nextsent>another part of the corpus consists of full scientific articles.
</nextsent>
<nextsent>5 articles from flybase (the same data were used by medlock and briscoe (2007) <papid> P07-1125 </papid>for evaluating sentence-level hedge classifiers) and 4 articles from the open access bmc bio informatics website were downloaded and annotated for nega tions, uncertainty and their scopes.</nextsent>
<nextsent>full papers are particularly useful for evaluating negation/hedge classifiers as different parts of an article display different properties in the use of speculative or negated phrases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1606">
<title id=" W08-0606.xml">the bio scope corpus annotation for negation uncertainty and their scope in biomedical texts </title>
<section> corpus details.  </section>
<citcontext>
<prevsection>
<prevsent>scientific abstracts are the main targets for various text mining applications like protein protein interaction mining due to their public accessibility (e.g. through pubmed).
</prevsent>
<prevsent>we therefore decided to include quite lot of texts from the abstracts of scientific papers.
</prevsent>
</prevsection>
<citsent citstr=" E99-1043 ">
this is why we included the abstracts of the genia corpus (collier et al., 1999).<papid> E99-1043 </papid></citsent>
<aftsection>
<nextsent>this decision was straightforward for two reasons.
</nextsent>
<nextsent>first, the genia corpus contains syntax tree annotation, which allows comparison between scope annotation and syntactic structure.
</nextsent>
<nextsent>being syntactic in nature, scopes should align with the bracket structure of syntax trees, while scope resolution algorithms that exploit treebank data can be used as theoretical upper bound for the evaluation of parsers for resolving negative/hedge scopes.
</nextsent>
<nextsent>the other reason was that scope annotation can mutually benefit from the rich annotations of the genia corpus, such as term annotation (evalua tion) and event annotation (comparison with the biologist uncertainty labeling of events).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1607">
<title id=" W07-1104.xml">semantics based multiword expression extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our approach has been tested on dutch, and automatically evaluated using dutch lexical resources.
</prevsent>
<prevsent>mwes are expressions whose linguistic behaviour is not predictable from the linguistic behaviour of their component words.
</prevsent>
</prevsection>
<citsent citstr=" W06-1201 ">
baldwin (2006) <papid> W06-1201 </papid>characterizes the idiosyncratic behavior of mwes as lack of com positionality manifest at different levels of analysis,namely, lexical, morphological, syntactic, semantic, pragmatic and statistical?.</citsent>
<aftsection>
<nextsent>some mwes show productive morphology and/or syntactic flexibility.therefore, these two aspects are not sufficient conditions to discriminate actual mwes from productiveexpressions.
</nextsent>
<nextsent>nonetheless, the mentioned characteristics are useful indicators to distinguish literal and idiomatic expressions (fazly and stevenson, 2006).<papid> E06-1043 </papid></nextsent>
<nextsent>one property that seems to affect mwes the mostis semantic non-compositionality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1608">
<title id=" W07-1104.xml">semantics based multiword expression extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>baldwin (2006) <papid> W06-1201 </papid>characterizes the idiosyncratic behavior of mwes as lack of com positionality manifest at different levels of analysis,namely, lexical, morphological, syntactic, semantic, pragmatic and statistical?.</prevsent>
<prevsent>some mwes show productive morphology and/or syntactic flexibility.therefore, these two aspects are not sufficient conditions to discriminate actual mwes from productiveexpressions.</prevsent>
</prevsection>
<citsent citstr=" E06-1043 ">
nonetheless, the mentioned characteristics are useful indicators to distinguish literal and idiomatic expressions (fazly and stevenson, 2006).<papid> E06-1043 </papid></citsent>
<aftsection>
<nextsent>one property that seems to affect mwes the mostis semantic non-compositionality.
</nextsent>
<nextsent>mwes are typically non-compositional.
</nextsent>
<nextsent>as consequence, it is not possible to replace the noun of mwe by semantically related nouns.
</nextsent>
<nextsent>take for example the expressions in (1) and (2): (1) a. break the vase b. break the cup c. break the dish (2) a. break the ice b. *break the snow c. *break the hail expression (1-a) is fully compositional.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1609">
<title id=" W07-1104.xml">semantics based multiword expression extraction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>25
</prevsent>
<prevsent>recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies.
</prevsent>
</prevsection>
<citsent citstr=" W06-1202 ">
approaches evaluated so far make use of dictionaries with semantic annotation (piaoet al, 2006), <papid> W06-1202 </papid>wordnet (pearce, 2001), automatically generated thesauri (lin, 1999; <papid> P99-1041 </papid>mccarthy et al., 2003; <papid> W03-1810 </papid>fazly and stevenson, 2006), <papid> E06-1043 </papid>vector-based methods that measure semantic distance (baldwin et al., 2003; <papid> W03-1812 </papid>katz and giesbrecht, 2006), <papid> W06-1203 </papid>translations extracted from parallel corpora (villada moiron and tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (venkata pathy and joshi, 2005).<papid> H05-1113 </papid>pearce (2001) describes method to extract collocations from corpora by measuring semantic compo sitionality.</citsent>
<aftsection>
<nextsent>the underlying assumption is that fully compositional expression allows synonym replacement of its component words, whereas collocation does not.
</nextsent>
<nextsent>pearce measures to what degree collocation candidate allows synonym replacement.
</nextsent>
<nextsent>the measurement is used to rank candidates relative to their compositionality.
</nextsent>
<nextsent>building on lin (1998), <papid> P98-2127 </papid>mccarthy et al (2003)<papid> W03-1810 </papid>measure the semantic similarity between expressions (verb particles) as whole and their component words (verb).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1610">
<title id=" W07-1104.xml">semantics based multiword expression extraction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>25
</prevsent>
<prevsent>recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies.
</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
approaches evaluated so far make use of dictionaries with semantic annotation (piaoet al, 2006), <papid> W06-1202 </papid>wordnet (pearce, 2001), automatically generated thesauri (lin, 1999; <papid> P99-1041 </papid>mccarthy et al., 2003; <papid> W03-1810 </papid>fazly and stevenson, 2006), <papid> E06-1043 </papid>vector-based methods that measure semantic distance (baldwin et al., 2003; <papid> W03-1812 </papid>katz and giesbrecht, 2006), <papid> W06-1203 </papid>translations extracted from parallel corpora (villada moiron and tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (venkata pathy and joshi, 2005).<papid> H05-1113 </papid>pearce (2001) describes method to extract collocations from corpora by measuring semantic compo sitionality.</citsent>
<aftsection>
<nextsent>the underlying assumption is that fully compositional expression allows synonym replacement of its component words, whereas collocation does not.
</nextsent>
<nextsent>pearce measures to what degree collocation candidate allows synonym replacement.
</nextsent>
<nextsent>the measurement is used to rank candidates relative to their compositionality.
</nextsent>
<nextsent>building on lin (1998), <papid> P98-2127 </papid>mccarthy et al (2003)<papid> W03-1810 </papid>measure the semantic similarity between expressions (verb particles) as whole and their component words (verb).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1611">
<title id=" W07-1104.xml">semantics based multiword expression extraction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>25
</prevsent>
<prevsent>recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies.
</prevsent>
</prevsection>
<citsent citstr=" W03-1810 ">
approaches evaluated so far make use of dictionaries with semantic annotation (piaoet al, 2006), <papid> W06-1202 </papid>wordnet (pearce, 2001), automatically generated thesauri (lin, 1999; <papid> P99-1041 </papid>mccarthy et al., 2003; <papid> W03-1810 </papid>fazly and stevenson, 2006), <papid> E06-1043 </papid>vector-based methods that measure semantic distance (baldwin et al., 2003; <papid> W03-1812 </papid>katz and giesbrecht, 2006), <papid> W06-1203 </papid>translations extracted from parallel corpora (villada moiron and tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (venkata pathy and joshi, 2005).<papid> H05-1113 </papid>pearce (2001) describes method to extract collocations from corpora by measuring semantic compo sitionality.</citsent>
<aftsection>
<nextsent>the underlying assumption is that fully compositional expression allows synonym replacement of its component words, whereas collocation does not.
</nextsent>
<nextsent>pearce measures to what degree collocation candidate allows synonym replacement.
</nextsent>
<nextsent>the measurement is used to rank candidates relative to their compositionality.
</nextsent>
<nextsent>building on lin (1998), <papid> P98-2127 </papid>mccarthy et al (2003)<papid> W03-1810 </papid>measure the semantic similarity between expressions (verb particles) as whole and their component words (verb).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1613">
<title id=" W07-1104.xml">semantics based multiword expression extraction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>25
</prevsent>
<prevsent>recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies.
</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
approaches evaluated so far make use of dictionaries with semantic annotation (piaoet al, 2006), <papid> W06-1202 </papid>wordnet (pearce, 2001), automatically generated thesauri (lin, 1999; <papid> P99-1041 </papid>mccarthy et al., 2003; <papid> W03-1810 </papid>fazly and stevenson, 2006), <papid> E06-1043 </papid>vector-based methods that measure semantic distance (baldwin et al., 2003; <papid> W03-1812 </papid>katz and giesbrecht, 2006), <papid> W06-1203 </papid>translations extracted from parallel corpora (villada moiron and tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (venkata pathy and joshi, 2005).<papid> H05-1113 </papid>pearce (2001) describes method to extract collocations from corpora by measuring semantic compo sitionality.</citsent>
<aftsection>
<nextsent>the underlying assumption is that fully compositional expression allows synonym replacement of its component words, whereas collocation does not.
</nextsent>
<nextsent>pearce measures to what degree collocation candidate allows synonym replacement.
</nextsent>
<nextsent>the measurement is used to rank candidates relative to their compositionality.
</nextsent>
<nextsent>building on lin (1998), <papid> P98-2127 </papid>mccarthy et al (2003)<papid> W03-1810 </papid>measure the semantic similarity between expressions (verb particles) as whole and their component words (verb).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1614">
<title id=" W07-1104.xml">semantics based multiword expression extraction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>25
</prevsent>
<prevsent>recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies.
</prevsent>
</prevsection>
<citsent citstr=" W06-1203 ">
approaches evaluated so far make use of dictionaries with semantic annotation (piaoet al, 2006), <papid> W06-1202 </papid>wordnet (pearce, 2001), automatically generated thesauri (lin, 1999; <papid> P99-1041 </papid>mccarthy et al., 2003; <papid> W03-1810 </papid>fazly and stevenson, 2006), <papid> E06-1043 </papid>vector-based methods that measure semantic distance (baldwin et al., 2003; <papid> W03-1812 </papid>katz and giesbrecht, 2006), <papid> W06-1203 </papid>translations extracted from parallel corpora (villada moiron and tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (venkata pathy and joshi, 2005).<papid> H05-1113 </papid>pearce (2001) describes method to extract collocations from corpora by measuring semantic compo sitionality.</citsent>
<aftsection>
<nextsent>the underlying assumption is that fully compositional expression allows synonym replacement of its component words, whereas collocation does not.
</nextsent>
<nextsent>pearce measures to what degree collocation candidate allows synonym replacement.
</nextsent>
<nextsent>the measurement is used to rank candidates relative to their compositionality.
</nextsent>
<nextsent>building on lin (1998), <papid> P98-2127 </papid>mccarthy et al (2003)<papid> W03-1810 </papid>measure the semantic similarity between expressions (verb particles) as whole and their component words (verb).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1615">
<title id=" W07-1104.xml">semantics based multiword expression extraction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>25
</prevsent>
<prevsent>recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies.
</prevsent>
</prevsection>
<citsent citstr=" H05-1113 ">
approaches evaluated so far make use of dictionaries with semantic annotation (piaoet al, 2006), <papid> W06-1202 </papid>wordnet (pearce, 2001), automatically generated thesauri (lin, 1999; <papid> P99-1041 </papid>mccarthy et al., 2003; <papid> W03-1810 </papid>fazly and stevenson, 2006), <papid> E06-1043 </papid>vector-based methods that measure semantic distance (baldwin et al., 2003; <papid> W03-1812 </papid>katz and giesbrecht, 2006), <papid> W06-1203 </papid>translations extracted from parallel corpora (villada moiron and tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (venkata pathy and joshi, 2005).<papid> H05-1113 </papid>pearce (2001) describes method to extract collocations from corpora by measuring semantic compo sitionality.</citsent>
<aftsection>
<nextsent>the underlying assumption is that fully compositional expression allows synonym replacement of its component words, whereas collocation does not.
</nextsent>
<nextsent>pearce measures to what degree collocation candidate allows synonym replacement.
</nextsent>
<nextsent>the measurement is used to rank candidates relative to their compositionality.
</nextsent>
<nextsent>building on lin (1998), <papid> P98-2127 </papid>mccarthy et al (2003)<papid> W03-1810 </papid>measure the semantic similarity between expressions (verb particles) as whole and their component words (verb).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1616">
<title id=" W07-1104.xml">semantics based multiword expression extraction </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>pearce measures to what degree collocation candidate allows synonym replacement.
</prevsent>
<prevsent>the measurement is used to rank candidates relative to their compositionality.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
building on lin (1998), <papid> P98-2127 </papid>mccarthy et al (2003)<papid> W03-1810 </papid>measure the semantic similarity between expressions (verb particles) as whole and their component words (verb).</citsent>
<aftsection>
<nextsent>they exploit contextual feature sand frequency information in order to assess meaning overlap.
</nextsent>
<nextsent>they established that human compositionality judgements correlate well with those measures that take into account the semantics of the particle.
</nextsent>
<nextsent>contrary to these measures, standard association measures poorly correlate with human judgements.
</nextsent>
<nextsent>a different approach proposed by villada moironand tiedemann (2006) measures translational entropy as sign of meaning predictability, and therefore non-compositionality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1623">
<title id=" W07-1104.xml">semantics based multiword expression extraction </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>the cell frequencies are replaced by pointwise mutual information scores(church et al, 1991), so that more informative features get higher weight.
</prevsent>
<prevsent>the noun vectors are then clustered into 1,000 clusters using simple k-means clustering algorithm (macqueen, 1967) with cosinesimilarity.
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
during development, several other clustering algorithms and parameters have been tested, but the settings described above gave us the best euro wordnet similarity score (using wu and palmer (1994)).<papid> P94-1019 </papid>note that our clustering algorithm is hard clustering algorithm, which means that certain noun 1the lowest frequency verb-preposition combination (with regard to the 10,000 nouns) appears 3 times.2e.g. dependency relations that qualify apple might be object of eat?</citsent>
<aftsection>
<nextsent>and adjective red?.
</nextsent>
<nextsent>this gives us dependency triples like   apple, obj, eat  .
</nextsent>
<nextsent>can only be assigned to one cluster.
</nextsent>
<nextsent>this may pose problem for polysemous nouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1628">
<title id=" W07-1216.xml">fips a deep linguistic multilingual parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this papers describes the fips project, which aims at developing robust, multilingual deep?
</prevsent>
<prevsent>linguistic parsing system efficient enough for wide-range of nlp applications.
</prevsent>
</prevsection>
<citsent citstr=" P06-4016 ">
the system is currently available for six languages (english, french, german, italian, spanish and greek), andhas been extensively used for terminology extraction (seretan &amp; wehrli, 2006), <papid> P06-4016 </papid>as well as for terminology assistance and translation (wehrli, 2004, 2006).</citsent>
<aftsection>
<nextsent>this paper is organized as follows.
</nextsent>
<nextsent>the next section gives an overview of the fips parser, describing some of its linguistic properties and its main processes.
</nextsent>
<nextsent>in section 3, we present the object-oriented design adopted for the project.
</nextsent>
<nextsent>section 4 discusses some cases of cross-linguistic syntactic variation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1630">
<title id=" W08-0608.xml">cascaded classifiers for confidence based chemical named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to refer to systems estimate of the probability that potential named entity iscor rect named entity.
</prevsent>
<prevsent>system has assigned the named entities is likely to be useful in range of different applications.named entities of relevance to biomedical science include not only genes and proteins but also other chemical substances which can be of interest as drugs, metabolites, nutrients, enzyme cofac tors, experimental reagents and in many other roles.
</prevsent>
</prevsection>
<citsent citstr=" W07-1008 ">
we have recently investigated the issue of chemical named entities (corbett et al, 2007), <papid> W07-1008 </papid>by compiling set of manual annotation guidelines, demonstrating93% inter annotator agreement and manually annotating set of 42 chemistry papers.</citsent>
<aftsection>
<nextsent>in this paper we demonstrate named entity recogniser that assigns confidence score to each named entity, allowing it to be tuned for high precision or recall.
</nextsent>
<nextsent>our review of the methods of chemical named entity recognition showed consistent theme: theuse of character-based n-grams to identify chemical names via their constituent sub strings (wilbur et al., 1999; vasserman, 2004; <papid> N04-2002 </papid>townsend et al, 2005).</nextsent>
<nextsent>this can be powerful technique, due to systematic and semi systematic chemical names and additional conventions in drug names.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1632">
<title id=" W08-0608.xml">cascaded classifiers for confidence based chemical named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we have recently investigated the issue of chemical named entities (corbett et al, 2007), <papid> W07-1008 </papid>by compiling set of manual annotation guidelines, demonstrating93% inter annotator agreement and manually annotating set of 42 chemistry papers.</prevsent>
<prevsent>in this paper we demonstrate named entity recogniser that assigns confidence score to each named entity, allowing it to be tuned for high precision or recall.</prevsent>
</prevsection>
<citsent citstr=" N04-2002 ">
our review of the methods of chemical named entity recognition showed consistent theme: theuse of character-based n-grams to identify chemical names via their constituent sub strings (wilbur et al., 1999; vasserman, 2004; <papid> N04-2002 </papid>townsend et al, 2005).</citsent>
<aftsection>
<nextsent>this can be powerful technique, due to systematic and semi systematic chemical names and additional conventions in drug names.
</nextsent>
<nextsent>however this technique does not cover all aspects of chemical nomenclature.
</nextsent>
<nextsent>much current named entity work uses approaches which combine the structured prediction abilities of hmms and their derivatives with techniques which enable the use of large, diverse feature sets such as maximum entropy (also known as logistic regression).
</nextsent>
<nextsent>maximum entropy markov models, (memms) (mccallum et al, 2000) provide relatively simple framework for this.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1633">
<title id=" W08-0608.xml">cascaded classifiers for confidence based chemical named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in confidence-based operation, potential entities (witha probability above threshold) are identified directly, without directly seeking single optimal labelling for the entire sentence.
</prevsent>
<prevsent>this is done by examining the probability of the label transitions within the entity, and the forward and backward probabilities at the start and end of the entity.
</prevsent>
</prevsection>
<citsent citstr=" N04-4028 ">
this mode has been termed the constrained forward backward algorithm (culotta and mccallum, 2004).<papid> N04-4028 </papid>where single unambiguous non-overlapping labelling is required, it can be obtained by identifying cases where the entities overlap, and discarding those with lower probabilities.confidence-based extraction has two main advan tages.</citsent>
<aftsection>
<nextsent>first, it enables the balance between precision and recall to be controlled by varying the probability threshold.
</nextsent>
<nextsent>second, confidence-based ner avoids over-commitment in systems where it is used as pre processor, since multiple overlapping options can be used as input to later components.the optimum balance between recall and precision depends on the application of the ner and on the other components in the system.
</nextsent>
<nextsent>high precision is useful in search even when recall is low when there is large degree of redundancy in the information in the original documents.
</nextsent>
<nextsent>high precision ner may also be useful in contexts such as the extraction of seed terms for clustering algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1634">
<title id=" W08-0608.xml">cascaded classifiers for confidence based chemical named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in other cases, the parser will filter the ner results.hence it makes sense to emphasise recall over precision.
</prevsent>
<prevsent>we also hypothesise that we will be able to incorporate the ner confidence scores as features in the parse ranking model.
</prevsent>
</prevsection>
<citsent citstr=" P07-2012 ">
another example of the use of high-recall ner inan integrated system is shown in the editing work flows used by the royal society of chemistry intheir project prospect system (batchelor and corbett, 2007), <papid> P07-2012 </papid>where chemical named entity recognition is used to produce semantically-enriched journal articles.</citsent>
<aftsection>
<nextsent>in this situation, high recall is desirable, as false positives can be removed in two ways; by removing entities where chemical structure cannot be assigned, and by having them checked by technical editor.
</nextsent>
<nextsent>false negatives are harder to correct.
</nextsent>
<nextsent>the use of confidence-based recognition has been demonstrated with crfs in the domain of contact details (culotta and mccallum, 2004), <papid> N04-4028 </papid>and usinghmms in the domain of gene annotation (carpen 55 ter, 2007).</nextsent>
<nextsent>in the latter case, the ling pipe toolkit was used in the bio creative 2 evaluation without significant adaptation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1636">
<title id=" W08-0608.xml">cascaded classifiers for confidence based chemical named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>information obtained about these entities throughout the document (or corpus) that they occur in can then be used in further classifiers.
</prevsent>
<prevsent>we are not aware of examples of rescoring being applied to confidence-based ner, but there are precedents using other modes of operations.
</prevsent>
</prevsection>
<citsent citstr=" P06-1141 ">
for example, krishnan and manning (2006) <papid> P06-1141 </papid>describe system where first-best crf is used to analyse acorpus, the results of which are then used to generate additional features to use in second first-bestcrf.</citsent>
<aftsection>
<nextsent>similarly, yoshida and tsujii (2007) <papid> W07-1033 </papid>use an nbest memm to generate multiple analyses for sentence, and re-rank the analyses based on information extracted from neighbouring sentences.therefore, to explore the potential of these techniques, we have produced chemical ner system that uses memm for confidence-based extraction of named entities, with an emphasis on the use of character-level n-grams, and rescoring system.</nextsent>
<nextsent>previously, we have produced set of annotation guidelines for chemical named entities, and used them to annotate set of 42 chemistry papers (cor bett et al, 2007).<papid> W07-1008 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1637">
<title id=" W08-0608.xml">cascaded classifiers for confidence based chemical named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we are not aware of examples of rescoring being applied to confidence-based ner, but there are precedents using other modes of operations.
</prevsent>
<prevsent>for example, krishnan and manning (2006) <papid> P06-1141 </papid>describe system where first-best crf is used to analyse acorpus, the results of which are then used to generate additional features to use in second first-bestcrf.</prevsent>
</prevsection>
<citsent citstr=" W07-1033 ">
similarly, yoshida and tsujii (2007) <papid> W07-1033 </papid>use an nbest memm to generate multiple analyses for sentence, and re-rank the analyses based on information extracted from neighbouring sentences.therefore, to explore the potential of these techniques, we have produced chemical ner system that uses memm for confidence-based extraction of named entities, with an emphasis on the use of character-level n-grams, and rescoring system.</citsent>
<aftsection>
<nextsent>previously, we have produced set of annotation guidelines for chemical named entities, and used them to annotate set of 42 chemistry papers (cor bett et al, 2007).<papid> W07-1008 </papid></nextsent>
<nextsent>inter-annotator agreement was tested on 14 of these, and found to be 93%.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1643">
<title id=" W07-1423.xml">an extensible probabilistic transformation based approach to the third recognizing textual entailment challenge </title>
<section> details.  </section>
<citcontext>
<prevsection>
<prevsent>becomes june 5?.
</prevsent>
<prevsent>we then split the text string into sentences simply by splitting at all locations containing dot followed by space.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
the resulting strings are fed to the stanford parser (de marneffe et al, 2006; klein and manning, 2003) <papid> P03-1054 </papid>with its included pre trained model and options ?-retaintmpsubcategories?</citsent>
<aftsection>
<nextsent>and ?-splittmp 1?.
</nextsent>
<nextsent>this allows us to generate dependency trees the nodes of which contain single stemmed word, itspart-of-speech tag and its dependency tag (as produced using the parsers output options word sand tags?
</nextsent>
<nextsent>and typeddependencies?, see (de marneffe et al., 2006)).
</nextsent>
<nextsent>for the stemming we apply the function morphy?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1644">
<title id=" W07-2024.xml">cucomsem exploring rich features for unsupervised web personal name disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the paper, we present an approach that combines unsupervised clustering methods with rich feature extractions to automatically cluster returned web pages according to which named entity in reality the ambiguous personal name in web page refers to.
</prevsent>
<prevsent>we make two contributions to approaches to web personal name disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
first, we seek to go beyond the kind of bag-of words features employed in earlier systems (bagga &amp; baldwin, 1998; <papid> P98-1012 </papid>gooi &amp; allan, 2004; <papid> N04-1002 </papid>pedersen et al, 2005), and attempt to exploit deep semantic features beyond the work of mann &amp; yarowsky (2003).<papid> W03-0405 </papid></citsent>
<aftsection>
<nextsent>second, we exploit some features that are available only in web corpus, such as url information and related web pages.
</nextsent>
<nextsent>the paper is organized as follows.
</nextsent>
<nextsent>section 2 introduces our rich feature extractions along with their corresponding similarity matrix learning.
</nextsent>
<nextsent>in section 3, we analyze the performance of our system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1646">
<title id=" W07-2024.xml">cucomsem exploring rich features for unsupervised web personal name disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the paper, we present an approach that combines unsupervised clustering methods with rich feature extractions to automatically cluster returned web pages according to which named entity in reality the ambiguous personal name in web page refers to.
</prevsent>
<prevsent>we make two contributions to approaches to web personal name disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" N04-1002 ">
first, we seek to go beyond the kind of bag-of words features employed in earlier systems (bagga &amp; baldwin, 1998; <papid> P98-1012 </papid>gooi &amp; allan, 2004; <papid> N04-1002 </papid>pedersen et al, 2005), and attempt to exploit deep semantic features beyond the work of mann &amp; yarowsky (2003).<papid> W03-0405 </papid></citsent>
<aftsection>
<nextsent>second, we exploit some features that are available only in web corpus, such as url information and related web pages.
</nextsent>
<nextsent>the paper is organized as follows.
</nextsent>
<nextsent>section 2 introduces our rich feature extractions along with their corresponding similarity matrix learning.
</nextsent>
<nextsent>in section 3, we analyze the performance of our system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1647">
<title id=" W07-2024.xml">cucomsem exploring rich features for unsupervised web personal name disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the paper, we present an approach that combines unsupervised clustering methods with rich feature extractions to automatically cluster returned web pages according to which named entity in reality the ambiguous personal name in web page refers to.
</prevsent>
<prevsent>we make two contributions to approaches to web personal name disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
first, we seek to go beyond the kind of bag-of words features employed in earlier systems (bagga &amp; baldwin, 1998; <papid> P98-1012 </papid>gooi &amp; allan, 2004; <papid> N04-1002 </papid>pedersen et al, 2005), and attempt to exploit deep semantic features beyond the work of mann &amp; yarowsky (2003).<papid> W03-0405 </papid></citsent>
<aftsection>
<nextsent>second, we exploit some features that are available only in web corpus, such as url information and related web pages.
</nextsent>
<nextsent>the paper is organized as follows.
</nextsent>
<nextsent>section 2 introduces our rich feature extractions along with their corresponding similarity matrix learning.
</nextsent>
<nextsent>in section 3, we analyze the performance of our system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1648">
<title id=" W07-2024.xml">cucomsem exploring rich features for unsupervised web personal name disambiguation </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>for example, sentence should finish when it meets ? table ?
</prevsent>
<prevsent>tag.
</prevsent>
</prevsection>
<citsent citstr=" N04-4037 ">
then each clean document continues to be preprocessed with mxterminator (a sentence segmenter), 2 the penn treebank to kenization,3 syntactic phrase chunker (hacioglu, 2004), <papid> N04-4037 </papid>and named-entity detection and coreference system for the ace project4 called ex 1 http://www.crummy.com/software/beautifulsoup 2http://www.id.cbs.dk/~dh/corpus/tools/mxterminator.</citsent>
<aftsection>
<nextsent>html 3 http://www.cis.upenn.edu/~treebank/tokenization.html 4 http://www.nist.gov/speech/tests/ace 125 ert5 (hacioglu et al 2005; <papid> H05-1048 </papid>chen &amp; hacioglu, 2006).</nextsent>
<nextsent>2.1 the detection of ambiguous objects.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1649">
<title id=" W07-2024.xml">cucomsem exploring rich features for unsupervised web personal name disambiguation </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>tag.
</prevsent>
<prevsent>then each clean document continues to be preprocessed with mxterminator (a sentence segmenter), 2 the penn treebank to kenization,3 syntactic phrase chunker (hacioglu, 2004), <papid> N04-4037 </papid>and named-entity detection and coreference system for the ace project4 called ex 1 http://www.crummy.com/software/beautifulsoup 2http://www.id.cbs.dk/~dh/corpus/tools/mxterminator.</prevsent>
</prevsection>
<citsent citstr=" H05-1048 ">
html 3 http://www.cis.upenn.edu/~treebank/tokenization.html 4 http://www.nist.gov/speech/tests/ace 125 ert5 (hacioglu et al 2005; <papid> H05-1048 </papid>chen &amp; hacioglu, 2006).</citsent>
<aftsection>
<nextsent>2.1 the detection of ambiguous objects.
</nextsent>
<nextsent>forgiven ambiguous personal name, for each web page, we try to extract all mentions of the ambiguous personal name, using three possible varieties of the personal name.
</nextsent>
<nextsent>for example, the three regular expression patterns for alexander markham?
</nextsent>
<nextsent>are alexander markham,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1656">
<title id=" W07-2024.xml">cucomsem exploring rich features for unsupervised web personal name disambiguation </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>2.2.2 phrase-based features since considerable information related to the ambiguous object resides in the noun phrases in web page, such as the persons job and the persons location, we attempt to capture this noun phrase information.
</prevsent>
<prevsent>the following section briefly describes how to extract and use the noun phrase information.
</prevsent>
</prevsection>
<citsent citstr=" D07-1020 ">
for more detail, see chen &amp; martin (2007).<papid> D07-1020 </papid></citsent>
<aftsection>
<nextsent>contextual base noun phrase feature: with the syntactic phrase chunker, we extract all base noun phrases (non-overlapping syntactic phrases) occurring in the local sentences, which usually include some useful information about the ambiguous object.
</nextsent>
<nextsent>a base noun phrase of interest serves as an element in the feature vector.
</nextsent>
<nextsent>document named-entity feature: given the exert system, direct and simple way to use the semantic information is to extract all named entities in web page.
</nextsent>
<nextsent>since given entity can be represented by many mentions in document, we choose single representative mention to represent each entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1659">
<title id=" W08-0318.xml">towards better machine translation quality for the german english language pairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>edinburgh university participated in the shared taskof the third workshop on statistical machine translation (wmt-2008), which is partly funded by the euro matrix project, which also funds our work.in this project, we set out to build machine translation systems for all language pairs of official eu languages.
</prevsent>
<prevsent>hence, we also participated in the shared task in all language pairs.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
for all language pairs, we used the moses decoder (koehn et al, 2007), <papid> P07-2045 </papid>which follows the phrase-based statistical machine translation approach (koehn et al, 2003), <papid> N03-1017 </papid>with default settings as startingpoint.</citsent>
<aftsection>
<nextsent>we recently added minimum bayes risk decoding and reordering constraints to the decoder.
</nextsent>
<nextsent>we achieved consistent increase in bleu scores with these improvements, showing gains of up to 0.9% bleu on the 2008 news test set.
</nextsent>
<nextsent>most of our efforts were focused on the language pairs german english and englishgerman.
</nextsent>
<nextsent>for both language pairs, we explored language-specific and more general improvements, resulting in gains of up to 1.5% bleu for german english and 1.4% bleu for englishgerman.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1660">
<title id=" W08-0318.xml">towards better machine translation quality for the german english language pairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>edinburgh university participated in the shared taskof the third workshop on statistical machine translation (wmt-2008), which is partly funded by the euro matrix project, which also funds our work.in this project, we set out to build machine translation systems for all language pairs of official eu languages.
</prevsent>
<prevsent>hence, we also participated in the shared task in all language pairs.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
for all language pairs, we used the moses decoder (koehn et al, 2007), <papid> P07-2045 </papid>which follows the phrase-based statistical machine translation approach (koehn et al, 2003), <papid> N03-1017 </papid>with default settings as startingpoint.</citsent>
<aftsection>
<nextsent>we recently added minimum bayes risk decoding and reordering constraints to the decoder.
</nextsent>
<nextsent>we achieved consistent increase in bleu scores with these improvements, showing gains of up to 0.9% bleu on the 2008 news test set.
</nextsent>
<nextsent>most of our efforts were focused on the language pairs german english and englishgerman.
</nextsent>
<nextsent>for both language pairs, we explored language-specific and more general improvements, resulting in gains of up to 1.5% bleu for german english and 1.4% bleu for englishgerman.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1661">
<title id=" W08-0318.xml">towards better machine translation quality for the german english language pairs </title>
<section> recent improvements.  </section>
<citcontext>
<prevsection>
<prevsent>all reported bleu scores are not case sensitive, computed using the nist tool.
</prevsent>
<prevsent>2.1 minimum bayes risk decoding.
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
minimum bayes risk decoding was proposed by kumar and byrne (2004).<papid> N04-1022 </papid></citsent>
<aftsection>
<nextsent>instead of selecting the translation with the highest probability, minimum bayes risk decoding selects the translation that is most similar to the highest scoring translations.
</nextsent>
<nextsent>intuitively,this avoid the selection of an outlier as the best translation, since the decision rule prefers translations that are similar to other high-scoring translations.
</nextsent>
<nextsent>minimum bayes risk decoding is defined as: embr = argmaxe ? e? l(e, e?)
</nextsent>
<nextsent>p(e?|f) as similarity function l, we use sentence-level bleu with add-one smoothing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1662">
<title id=" W08-0318.xml">towards better machine translation quality for the german english language pairs </title>
<section> recent improvements.  </section>
<citcontext>
<prevsection>
<prevsent>allowing any kind of reordering typically reduces translation performance, so reordering is limited to window of (in our case) six words.
</prevsent>
<prevsent>one noticeable weakness is that the current model frequently re orders words beyond clause boundaries, which is almost never well-motivated, and leads to confusing translations.
</prevsent>
</prevsection>
<citsent citstr=" J03-1005 ">
since clause boundaries are often indicated by punctuation such as comma, colon, or semicolon, it is straight-forward to introduce reordering constraint that addresses this problem.our implementation of monotone-at-punc tuation reordering constraint (tillmann and ney,2003) <papid> J03-1005 </papid>requires that all input words before clause separating punctuation have be translated, before words afterwards are covered.</citsent>
<aftsection>
<nextsent>note that this constraint does not limit in any way phrase translations that span punctuation.
</nextsent>
<nextsent>2.3 results.
</nextsent>
<nextsent>table 1 summarizes the impact of minimum bayes risk decoding (mbr) and the monotone at-punctuation reordering constraint (mp).
</nextsent>
<nextsent>scores show higher gains for out-of-domain news test sets (+0.46) than for in-domain europarl sets (+0.08).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1663">
<title id=" W08-0318.xml">towards better machine translation quality for the german english language pairs </title>
<section> german english.  </section>
<citcontext>
<prevsection>
<prevsent>translating between german and english is surprisingly difficult, given that the languages are closely related.
</prevsent>
<prevsent>the main sources for this difficulty is the different syntactic structure at the clause level and the rich german morphology, including the merging of noun compounds.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
in prior work, we addressed reordering with apre-order model that transforms german for training and testing according to set of hand-crafted rules (collins et al, 2005).<papid> P05-1066 </papid></citsent>
<aftsection>
<nextsent>employing this method to our baseline system leads to an improvement of +0.8 bleu on the nc-test2007 set and +0.5 bleu on the test2007 set.
</nextsent>
<nextsent>140 german english nc-test2007 test2007 baseline 20.3 27.6 tokenize hyphens 20.1 (0.2) 27.6 (0.0) tok.
</nextsent>
<nextsent>hyph.
</nextsent>
<nextsent>+ true case 20.7 (+0.4) 27.8 (+0.2) table 2: impact of true casing on case-sensitive bleuin more integrated approach, factored translation models (koehn and hoang, 2007) <papid> D07-1091 </papid>allow us to consider grammatical coherence in form of part of-speech language models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1664">
<title id=" W08-0318.xml">towards better machine translation quality for the german english language pairs </title>
<section> german english.  </section>
<citcontext>
<prevsection>
<prevsent>140 german english nc-test2007 test2007 baseline 20.3 27.6 tokenize hyphens 20.1 (0.2) 27.6 (0.0) tok.
</prevsent>
<prevsent>hyph.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
+ true case 20.7 (+0.4) 27.8 (+0.2) table 2: impact of true casing on case-sensitive bleuin more integrated approach, factored translation models (koehn and hoang, 2007) <papid> D07-1091 </papid>allow us to consider grammatical coherence in form of part of-speech language models.</citsent>
<aftsection>
<nextsent>when translating into output words, we also generate part-of-speech tag along with each output word.
</nextsent>
<nextsent>since there are only 46 pos tags in english, we are able to train high-ordern-gram models of these sequences.
</nextsent>
<nextsent>in our experiments, we used 7-gram model, yielding improvements of +0.2/0.1.
</nextsent>
<nextsent>we obtained the pos tags using brills tagger (brill, 1995).<papid> J95-4004 </papid>next, we considered the problem of unknown in put words, which is partly due to hyphenated words,noun compounds, and morphological variants.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1665">
<title id=" W08-0318.xml">towards better machine translation quality for the german english language pairs </title>
<section> german english.  </section>
<citcontext>
<prevsection>
<prevsent>since there are only 46 pos tags in english, we are able to train high-ordern-gram models of these sequences.
</prevsent>
<prevsent>in our experiments, we used 7-gram model, yielding improvements of +0.2/0.1.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
we obtained the pos tags using brills tagger (brill, 1995).<papid> J95-4004 </papid>next, we considered the problem of unknown in put words, which is partly due to hyphenated words,noun compounds, and morphological variants.</citsent>
<aftsection>
<nextsent>using the baseline model, 907 words (1.78%) in nc test2007 and 262 (0.47%) in test2007 are unknown.
</nextsent>
<nextsent>first we separate our hyphens by tokenizing words such as high-risk into high @-@ risk.
</nextsent>
<nextsent>this reduces the number of unknown words to 791/224.
</nextsent>
<nextsent>unfortunately, it hurts us in terms of bleu (0.1/0.1).second, we split compounds using the frequency based method (koehn and knight, 2003), <papid> E03-1076 </papid>reducing the number of unknown words to than half, 424/94, improving bleu on nc-test2007 (+0.5/0.2).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1666">
<title id=" W08-0318.xml">towards better machine translation quality for the german english language pairs </title>
<section> german english.  </section>
<citcontext>
<prevsection>
<prevsent>first we separate our hyphens by tokenizing words such as high-risk into high @-@ risk.
</prevsent>
<prevsent>this reduces the number of unknown words to 791/224.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
unfortunately, it hurts us in terms of bleu (0.1/0.1).second, we split compounds using the frequency based method (koehn and knight, 2003), <papid> E03-1076 </papid>reducing the number of unknown words to than half, 424/94, improving bleu on nc-test2007 (+0.5/0.2).</citsent>
<aftsection>
<nextsent>a final modification to the data preparation is truecasing.
</nextsent>
<nextsent>traditionally, we lowercase all training and test data, but especially in german, case marks important distinctions.
</nextsent>
<nextsent>german nouns are capitalized, and keeping case allows us to make the distinction between, say, the noun wissen (knowledge) and the verb wissen (to know).
</nextsent>
<nextsent>by true casing, we only change the case of the first word of sentence to its most common form.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1667">
<title id=" W07-2088.xml">uniba jigsaw algorithm for word sense disambiguation </title>
<section> the jigsaw algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>jigsaw is wsd algorithm based on the idea of combining three different strategies to disambiguate nouns, verbs, adjectives and adverbs.
</prevsent>
<prevsent>the main motivation behind our approach is that 1http://wordnet.princeton.edu/ 2http://www.senseval.org/ the effectiveness of wsd algorithm is strongly influenced by the pos tag of the target word.
</prevsent>
</prevsection>
<citsent citstr=" W95-0105 ">
an adaptation of lesk dictionary-based wsd algorithm has been used to disambiguate adjectives and ad verbs (banerjee and pedersen, 2002), an adaptation of the resnik algorithm has been used to disambiguate nouns (resnik, 1995), <papid> W95-0105 </papid>while the algorithm we developed for disambiguating verbs exploits the nouns in the context of the verb as well as the nouns both in the glosses and in the phrases that wordnet utilizes to describe the usage of verb.</citsent>
<aftsection>
<nextsent>jigsaw takes as input document = {w 1 , 2 , . . .
</nextsent>
<nextsent>, h } and returns list of wordnet synsets = {s 1 , 2 , . . .
</nextsent>
<nextsent>, k } in which each element iis obtained by disam biguating the target word ibased on the information obtained from wordnet about few immediately surrounding words.
</nextsent>
<nextsent>we define the context of the target word to be window of words to the left and another words to the right, for total of 2n surrounding words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1672">
<title id=" W07-2088.xml">uniba jigsaw algorithm for word sense disambiguation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>score is computed by counting the words that occur both in target gloss ik and in context gloss . if ties.
</prevsent>
<prevsent>occur, the most common synset in wordnet is chosen.
</prevsent>
</prevsection>
<citsent citstr=" W07-2001 ">
we performed the experiment following the instructions for semeval-2007 task 1 (agirre et al, 2007).<papid> W07-2001 </papid></citsent>
<aftsection>
<nextsent>jigsaw is implemented in java, by using jwnl library3 in order to access wordnet 1.6 dictionary.
</nextsent>
<nextsent>we ran the experiment on linux-based pc with intel pentium processor having speed of 3 ghz and 2 gb of ram.
</nextsent>
<nextsent>the dataset consists of 29,681documents, including 300 topics.
</nextsent>
<nextsent>results are reported in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1673">
<title id=" W08-0802.xml">a wearable headset speechtospeech translation system </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>humanitarian personnel, military personnel, and visitors in foreign countries often need to communicate with residents of host country.
</prevsent>
<prevsent>human interpreters are inevitably in short supply, and training personnel to speak new language is difficult.
</prevsent>
</prevsection>
<citsent citstr=" N03-4015 ">
under the darpa tran stac and babylon programs, various teams have developed systems that enable two-way communication over language barrier (waibel et al, 2003; <papid> N03-4015 </papid>zhou et al, 2004; stallard et al, 2006).</citsent>
<aftsection>
<nextsent>the two-way speechto-speech (s2s) translation systems seek, in principle, to translate any utterance, by using general statistical models trained on large amounts of speech and text data.
</nextsent>
<nextsent>the performance and usability of such two-way speech-to-speech (s2s) translation systems is heavily dependent on the computational resources, such as processing power and memory, of the platform they are running on.
</nextsent>
<nextsent>to enable open-ended conversation these s2s systems employ powerful but highly memory- and computation-intensive statistical speech recognition and machine translation models.
</nextsent>
<nextsent>thus, at the very minimum theyre quire the processing and memory configuration of common-of-the-shelf (cots) laptops.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1674">
<title id=" W07-2030.xml">fico web person disambiguation via weighted similarity of entity contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>entity disambiguation inherently involves resolving many-to-many relationships.
</prevsent>
<prevsent>multiple distinct strings may refer to the same entity.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
simultaneously, multiple identical mentions refer to distinct entities (bagga and baldwin, 1998).<papid> P98-1012 </papid></citsent>
<aftsection>
<nextsent>fair isaacs entity disambiguation software is based largely on language-independent algorithms that resolve mentions in the context of the entire corpus.
</nextsent>
<nextsent>the system utilizes multiple types of context as evidence for determining whether two mentions correspond to the same entity and it automatically learns the weight of evidence of each context item via corpus statistics.
</nextsent>
<nextsent>the goal of the web people search task (artiles et al 2007) <papid> W07-2012 </papid>is to assign web pages to groups, where each group contains all (and only those) pages that refer to one unique entity.</nextsent>
<nextsent>a page is assigned to multiple groups if it mentions multiple entities, for example john f. kennedy?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1675">
<title id=" W07-2030.xml">fico web person disambiguation via weighted similarity of entity contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>fair isaacs entity disambiguation software is based largely on language-independent algorithms that resolve mentions in the context of the entire corpus.
</prevsent>
<prevsent>the system utilizes multiple types of context as evidence for determining whether two mentions correspond to the same entity and it automatically learns the weight of evidence of each context item via corpus statistics.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
the goal of the web people search task (artiles et al 2007) <papid> W07-2012 </papid>is to assign web pages to groups, where each group contains all (and only those) pages that refer to one unique entity.</citsent>
<aftsection>
<nextsent>a page is assigned to multiple groups if it mentions multiple entities, for example john f. kennedy?
</nextsent>
<nextsent>and the john f. kennedy library?.
</nextsent>
<nextsent>the pages were selected via set of keyword queries, and the disambiguation is evaluated only on those query entities.
</nextsent>
<nextsent>this differs from fair isaacs system in few key ways: our system deals with mentions rather than documents, our system does not require filter on mentions, and our system is generally used for large collections of documents containing very many names rather than small sets of highly ambiguous documents dealing with one specific name.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1676">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>empirical results show that these methods improve the performance of atts transducer based on the standard bleu 4 metric.
</prevsent>
<prevsent>we also experiment with semantic labels in tts transducer, and achieve improvement over our baseline system.
</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
syntax-based statistical machine translation (ssmt) has achieved significant progress during recent years, with two threads developing simul taneously: the synchronous parsing-based ssmt (galley et al, 2006; <papid> P06-1121 </papid>may and knight, 2007) <papid> D07-1038 </papid>and the tree-to-string (tts) transducer (liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006).<papid> W06-3601 </papid></citsent>
<aftsection>
<nextsent>synchronous ssmt here denotes the systems which accept source sentence as the input and generate the translation and the syntactic structure for both the source and the translation simultaneously.
</nextsent>
<nextsent>such systems are sometimes also called tts transducers, but in this paper, tts transducer refers to the system which starts with the syntax tree of source sentence and recursively transforms the tree to the target language based on tts templates.
</nextsent>
<nextsent>in synchronous ssmt, tts templates are used similar to the context free grammar used in the standard cyk parser, thus the syntax is part of the output and can be thought of as constraint on the translation process.
</nextsent>
<nextsent>in the tts transducer, since the parse tree is given, syntax can be thought of as an additional feature of the input to be used in the translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1677">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>empirical results show that these methods improve the performance of atts transducer based on the standard bleu 4 metric.
</prevsent>
<prevsent>we also experiment with semantic labels in tts transducer, and achieve improvement over our baseline system.
</prevsent>
</prevsection>
<citsent citstr=" D07-1038 ">
syntax-based statistical machine translation (ssmt) has achieved significant progress during recent years, with two threads developing simul taneously: the synchronous parsing-based ssmt (galley et al, 2006; <papid> P06-1121 </papid>may and knight, 2007) <papid> D07-1038 </papid>and the tree-to-string (tts) transducer (liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006).<papid> W06-3601 </papid></citsent>
<aftsection>
<nextsent>synchronous ssmt here denotes the systems which accept source sentence as the input and generate the translation and the syntactic structure for both the source and the translation simultaneously.
</nextsent>
<nextsent>such systems are sometimes also called tts transducers, but in this paper, tts transducer refers to the system which starts with the syntax tree of source sentence and recursively transforms the tree to the target language based on tts templates.
</nextsent>
<nextsent>in synchronous ssmt, tts templates are used similar to the context free grammar used in the standard cyk parser, thus the syntax is part of the output and can be thought of as constraint on the translation process.
</nextsent>
<nextsent>in the tts transducer, since the parse tree is given, syntax can be thought of as an additional feature of the input to be used in the translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1678">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>empirical results show that these methods improve the performance of atts transducer based on the standard bleu 4 metric.
</prevsent>
<prevsent>we also experiment with semantic labels in tts transducer, and achieve improvement over our baseline system.
</prevsent>
</prevsection>
<citsent citstr=" P06-1077 ">
syntax-based statistical machine translation (ssmt) has achieved significant progress during recent years, with two threads developing simul taneously: the synchronous parsing-based ssmt (galley et al, 2006; <papid> P06-1121 </papid>may and knight, 2007) <papid> D07-1038 </papid>and the tree-to-string (tts) transducer (liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006).<papid> W06-3601 </papid></citsent>
<aftsection>
<nextsent>synchronous ssmt here denotes the systems which accept source sentence as the input and generate the translation and the syntactic structure for both the source and the translation simultaneously.
</nextsent>
<nextsent>such systems are sometimes also called tts transducers, but in this paper, tts transducer refers to the system which starts with the syntax tree of source sentence and recursively transforms the tree to the target language based on tts templates.
</nextsent>
<nextsent>in synchronous ssmt, tts templates are used similar to the context free grammar used in the standard cyk parser, thus the syntax is part of the output and can be thought of as constraint on the translation process.
</nextsent>
<nextsent>in the tts transducer, since the parse tree is given, syntax can be thought of as an additional feature of the input to be used in the translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1682">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>empirical results show that these methods improve the performance of atts transducer based on the standard bleu 4 metric.
</prevsent>
<prevsent>we also experiment with semantic labels in tts transducer, and achieve improvement over our baseline system.
</prevsent>
</prevsection>
<citsent citstr=" W06-3601 ">
syntax-based statistical machine translation (ssmt) has achieved significant progress during recent years, with two threads developing simul taneously: the synchronous parsing-based ssmt (galley et al, 2006; <papid> P06-1121 </papid>may and knight, 2007) <papid> D07-1038 </papid>and the tree-to-string (tts) transducer (liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006).<papid> W06-3601 </papid></citsent>
<aftsection>
<nextsent>synchronous ssmt here denotes the systems which accept source sentence as the input and generate the translation and the syntactic structure for both the source and the translation simultaneously.
</nextsent>
<nextsent>such systems are sometimes also called tts transducers, but in this paper, tts transducer refers to the system which starts with the syntax tree of source sentence and recursively transforms the tree to the target language based on tts templates.
</nextsent>
<nextsent>in synchronous ssmt, tts templates are used similar to the context free grammar used in the standard cyk parser, thus the syntax is part of the output and can be thought of as constraint on the translation process.
</nextsent>
<nextsent>in the tts transducer, since the parse tree is given, syntax can be thought of as an additional feature of the input to be used in the translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1685">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in synchronous ssmt, tts templates are used similar to the context free grammar used in the standard cyk parser, thus the syntax is part of the output and can be thought of as constraint on the translation process.
</prevsent>
<prevsent>in the tts transducer, since the parse tree is given, syntax can be thought of as an additional feature of the input to be used in the translation.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
the idea of synchronous ssmt can be traced back to wu (1997)<papid> J97-3002 </papid>s stochastic inversion transduction grammars.</citsent>
<aftsection>
<nextsent>a systematic method for extracting tts templates from parallel corpora was proposed by galley et al (2004), and later binarizedby zhang et al (2006) <papid> N06-1033 </papid>for high efficiency and accuracy.</nextsent>
<nextsent>in the other track, the tts transducer originated from the tree transducer proposed by rounds (1970) and thatcher (1970) independently.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1686">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the tts transducer, since the parse tree is given, syntax can be thought of as an additional feature of the input to be used in the translation.
</prevsent>
<prevsent>the idea of synchronous ssmt can be traced back to wu (1997)<papid> J97-3002 </papid>s stochastic inversion transduction grammars.</prevsent>
</prevsection>
<citsent citstr=" N06-1033 ">
a systematic method for extracting tts templates from parallel corpora was proposed by galley et al (2004), and later binarizedby zhang et al (2006) <papid> N06-1033 </papid>for high efficiency and accuracy.</citsent>
<aftsection>
<nextsent>in the other track, the tts transducer originated from the tree transducer proposed by rounds (1970) and thatcher (1970) independently.
</nextsent>
<nextsent>graehl and knight (2004) generalized the tree transducer to the tts transducer and introduced an em algorithm to estimate the probability of tts templates based on bilingual corpus with one side parsed.
</nextsent>
<nextsent>liu et al (2006) <papid> P06-1077 </papid>and huang et al (2006)<papid> W06-3601 </papid>then used the tts transducer on the task of chineseto-english and english-to-chinese translation, respectively, and achieved decent performance.</nextsent>
<nextsent>despite the progress ssmt has achieved, it isstill developing field with many problems unsolved.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1689">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>liu et al (2006) <papid> P06-1077 </papid>and huang et al (2006)<papid> W06-3601 </papid>then used the tts transducer on the task of chineseto-english and english-to-chinese translation, respectively, and achieved decent performance.</prevsent>
<prevsent>despite the progress ssmt has achieved, it isstill developing field with many problems unsolved.</prevsent>
</prevsection>
<citsent citstr=" P07-1003 ">
for example, the word alignment computed by giza++ and used as basis to extract the tts templates in most ssmt systems has been observed to be problem for ssmt (denero and klein, 2007; <papid> P07-1003 </papid>may and knight, 2007), <papid> D07-1038 </papid>due to the fact that the word-based alignment models are not aware of the syntactic structure of the sentences and could produce many syntax-violating word alignments.</citsent>
<aftsection>
<nextsent>approaches have been proposed recently towards getting better word alignment and thus better tts templates, such as encoding syntactic structure information into the hmm-based word alignment model denero and klein (2007), <papid> P07-1003 </papid>and build 62 ing syntax-based word alignment model mayand knight (2007) <papid> D07-1038 </papid>with tts templates.</nextsent>
<nextsent>unfortunately, neither approach reports end-to-end mt performance based on the syntactic alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1705">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> decomposition model of tts transducer.  </section>
<citcontext>
<prevsection>
<prevsent>there is no explicit modeling for the decomposition of syntax tree in the tts transducer (or the probability of the syntactic tree in synchronous ssmt).
</prevsent>
<prevsent>most systems simply use uniform model (liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006) <papid> W06-3601 </papid>or implicitly consider it with joint model producing both syntax trees and the translations (galley et al, 2006).<papid> P06-1121 </papid>a ssmt is natural step along the way towards generating more refined models across languages.</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
the statistical approach to semantic role labeling has been well studied (xue and palmer, 2004; <papid> W04-3212 </papid>ward et al, 2004; toutanova et al., 2005), but there is no work attempting to use such information in ssmt, to our limited knowledge.this paper proposes novel methods towards solving these problems.</citsent>
<aftsection>
<nextsent>specifically, we compare three ways of normalizing the tts templates based on thetree pattern, the root of the tree pattern, and the first level expansion of the tree pattern respectively, in the context of hard counting and em estimation; we present syntactic alignment framework integrating both the template re-estimation and insertion of unaligned target words; we use subtree-based n-gram model to address the decomposition of the syntax trees in tts transducer (or the syntactic language model for synchronous ssmt); we use statistical classifier to label the semantic roles defined by propbank (palmer et al, 2005) <papid> J05-1004 </papid>and try different ways of using the semantic features in tts transducer.we chose the tts transducer instead of synchronous ssmt for two reasons.</nextsent>
<nextsent>first, the decoding algorithm for the tts transducer has lower computational complexity, which makes it easier to integrate complex decomposition model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1706">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> decomposition model of tts transducer.  </section>
<citcontext>
<prevsection>
<prevsent>most systems simply use uniform model (liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006) <papid> W06-3601 </papid>or implicitly consider it with joint model producing both syntax trees and the translations (galley et al, 2006).<papid> P06-1121 </papid>a ssmt is natural step along the way towards generating more refined models across languages.</prevsent>
<prevsent>the statistical approach to semantic role labeling has been well studied (xue and palmer, 2004; <papid> W04-3212 </papid>ward et al, 2004; toutanova et al., 2005), but there is no work attempting to use such information in ssmt, to our limited knowledge.this paper proposes novel methods towards solving these problems.</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
specifically, we compare three ways of normalizing the tts templates based on thetree pattern, the root of the tree pattern, and the first level expansion of the tree pattern respectively, in the context of hard counting and em estimation; we present syntactic alignment framework integrating both the template re-estimation and insertion of unaligned target words; we use subtree-based n-gram model to address the decomposition of the syntax trees in tts transducer (or the syntactic language model for synchronous ssmt); we use statistical classifier to label the semantic roles defined by propbank (palmer et al, 2005) <papid> J05-1004 </papid>and try different ways of using the semantic features in tts transducer.we chose the tts transducer instead of synchronous ssmt for two reasons.</citsent>
<aftsection>
<nextsent>first, the decoding algorithm for the tts transducer has lower computational complexity, which makes it easier to integrate complex decomposition model.
</nextsent>
<nextsent>second, thetts transducer can be easily integrated with semantic role features since the syntax tree is present, and its not clear how to do this in synchronous ssmt system.
</nextsent>
<nextsent>the remainder of the paper will focus on introducing the improved tts transducer and is organized as follows: section 2 describes the implementation of basic tts transducer; section 3 describes the components of the improved tts transducer; section 4 presents the empirical results and section 5 gives the conclusion.
</nextsent>
<nextsent>2 basic tree-to-string transducer for machine translation the tts transducer, as generalization to the finite state transducer, receives tree structure as its input and recursively applies tts templates to generate the target string.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1718">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> decomposition model of tts transducer.  </section>
<citcontext>
<prevsection>
<prevsent>this paper uses the latter approach, and the algorithm is sketched in figure 3.
</prevsent>
<prevsent>for the baseline approach, only the translation model and n-gram model for the target language are used: s?
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
= argmax pr(t |s) = argmax pr(s)pr(s|t )since the n-gram model tends to favor short translations, penalty is added to the translation templates with fewer rhs symbols than lhs leaf symbols: penalty(t) = exp(|t.rhs| ? |t.lhsleaf |) where |t.rhs| denotes the number of symbols inthe rhs of t, and |t.lhsleaf | denotes the number of leaves in the lhs of t. the length penalty is analogous to the length feature widely used in loglinear models for mt (huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2006; <papid> P06-1077 </papid>och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>here we distribute the penalty into tts templates for the convenience of dp, so that we dont have to generate the -best listand do re-ranking.
</nextsent>
<nextsent>to speed up the decoding, standard beam search is used.in figure 3, binary combine denotes the target size binarization (huang et al, 2006) <papid> W06-3601 </papid>combination.the translation candidates of the templates variables, as well as its terminals, are combined pairwise in the order they appear in the rhs of the template.</nextsent>
<nextsent>fi denotes combined translation, whose probability is equal to the product of the probabilities of the component translations, the probability of the rule, the n-gram probability of connecting the component translations, and the length penalty of 64 match(v, t): the descendant tree nodes of v, which match the variables in template v.sk: the stack associated with tree node in(cj , fi): the translation candidate of cj which is chosen to combine fi ???????????????????????????????????</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1721">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> improved tree-to-string transducer for.  </section>
<citcontext>
<prevsection>
<prevsent>without the beam pruning, the decoding algorithm runs in o(n4(n1)rpq), where is the vocabulary size of the target language, is the length of the n-gram model, is the maximum number of templates applicable to one tree node, is the maximum number of variables in template, and is the number of tree nodes in the syntax tree.the dp algorithm works for most systems in the paper, and only needs to be slightly modified to encode the subtree-based n-gram model described in section 3.3.
</prevsent>
<prevsent>machine translation 3.1 normalization of tts templates.
</prevsent>
</prevsection>
<citsent citstr=" P07-1089 ">
given the story that translations are generated based on the source syntax trees, the weight of the template is computed as the probability of the target strings given the source subtree: weight(t) = #(t) #(t? : lhs(t?) = lhs(t)) such normalization, denoted here as tree, is used in most tree-to-string template-based mt systems (liu et al, 2007; <papid> P07-1089 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006).<papid> W06-3601 </papid></citsent>
<aftsection>
<nextsent>galley et al (2006) <papid> P06-1121 </papid>proposed an alteration in synchronous ssmt which addresses the probability of both the source subtree and the target string given the root of the source subtree: weight(t) = #(t) #(t? : root(t?) = root(t)) this method is denoted as root.</nextsent>
<nextsent>here, we propose another modification: weight(t) = #(t) #(t? : cfg(t?) = cfg(t)) (1) cfg in equation 1 denotes the first level expansion of the source subtree and the method is denoted as cfg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1739">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>we used 74,597 pairs of english and chinese sentences in the fbis dataset as our experimental data, which are further divided into 500 test sentence pairs, 500 development sentence pairs and73597 training sentence pairs.
</prevsent>
<prevsent>the test set and development set are selected as those sentences having fewer than 25 words on the chinese side.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the translation is from english to chinese, and charniak (2000)<papid> A00-2018 </papid>s parser, trained on the penn treebank, is used to generate the syntax trees for the englishside.</citsent>
<aftsection>
<nextsent>the weights of the mt components are optimized based on the development set using grid based line search.
</nextsent>
<nextsent>the chinese sentence from these lected pair is used as the single reference to tune and evaluate the mt system with word-based bleu-4 (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
<nextsent>huang et al (2006)<papid> W06-3601 </papid> usedcharacter-based bleu as way of normalizing inconsistent chinese word segmentation, but we avoid this problem as the training, development, and test data are from the same source.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1740">
<title id=" W08-0308.xml">improved treetostring transducer for machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>the translation is from english to chinese, and charniak (2000)<papid> A00-2018 </papid>s parser, trained on the penn treebank, is used to generate the syntax trees for the englishside.</prevsent>
<prevsent>the weights of the mt components are optimized based on the development set using grid based line search.</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the chinese sentence from these lected pair is used as the single reference to tune and evaluate the mt system with word-based bleu-4 (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>huang et al (2006)<papid> W06-3601 </papid> usedcharacter-based bleu as way of normalizing inconsistent chinese word segmentation, but we avoid this problem as the training, development, and test data are from the same source.</nextsent>
<nextsent>4.1 syntax-based system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1742">
<title id=" W08-0406.xml">syntactic reordering integrated with phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on an english danish task, we achieve an absolute improvement in translation quality of 1.1 % bleu.
</prevsent>
<prevsent>manual evaluation supports the claim that the present approach is significantly superior to previous approaches.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the emergence of phrase-based statistical machine translation (psmt) (koehn et al, 2003) <papid> N03-1017 </papid>has beenone of the major developments in statistical approaches to translation.</citsent>
<aftsection>
<nextsent>allowing translation of word sequences (phrases) instead of single words provides smt with robustness in word selection and local word reordering.psmt has two means of reordering the words.
</nextsent>
<nextsent>either phrase pair has been learned where the target word order differs from the source (phrase internal reordering), or distance penalized orderings of target phrases are attempted in decoding (phrase external reordering).
</nextsent>
<nextsent>the first solution is strong, the second is weak.
</nextsent>
<nextsent>the second solution is necessary for reorderings within previously unseen sequence or over distances greater than the maximal phrase length.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1743">
<title id=" W08-0406.xml">syntactic reordering integrated with phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it seems clear that reordering often depends on higher level linguistic information, which is absent from psmt.
</prevsent>
<prevsent>in recent work, there has been some progress towards integrating syntactic information with the statistical approach to reordering.
</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
in works such as (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005;<papid> P05-1066 </papid>wang et al, 2007; <papid> D07-1077 </papid>habash, 2007), reordering decisions are done deterministically?, thus placing these decisions outside the actual psmt system by learning to translate from reordered source lan guage.</citsent>
<aftsection>
<nextsent>(crego and marino, 2007; zhang et al, 2007; li et al, 2007) <papid> P07-1091 </papid>are more in the spirit of psmt, in that multiple reorderings are presented to the psmt system as (possibly weighted) options.</nextsent>
<nextsent>still, there remains basic conflict between the syntactic reordering rules and the psmt system:one that is most likely due to the discrepancy between the translation units (phrases) and units of the linguistic rules, as (zhang et al, 2007) point out.in this paper, we proceed in the spirit of the non deterministic approaches by providing the decoder with multiple source reorderings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1744">
<title id=" W08-0406.xml">syntactic reordering integrated with phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it seems clear that reordering often depends on higher level linguistic information, which is absent from psmt.
</prevsent>
<prevsent>in recent work, there has been some progress towards integrating syntactic information with the statistical approach to reordering.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
in works such as (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005;<papid> P05-1066 </papid>wang et al, 2007; <papid> D07-1077 </papid>habash, 2007), reordering decisions are done deterministically?, thus placing these decisions outside the actual psmt system by learning to translate from reordered source lan guage.</citsent>
<aftsection>
<nextsent>(crego and marino, 2007; zhang et al, 2007; li et al, 2007) <papid> P07-1091 </papid>are more in the spirit of psmt, in that multiple reorderings are presented to the psmt system as (possibly weighted) options.</nextsent>
<nextsent>still, there remains basic conflict between the syntactic reordering rules and the psmt system:one that is most likely due to the discrepancy between the translation units (phrases) and units of the linguistic rules, as (zhang et al, 2007) point out.in this paper, we proceed in the spirit of the non deterministic approaches by providing the decoder with multiple source reorderings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1745">
<title id=" W08-0406.xml">syntactic reordering integrated with phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it seems clear that reordering often depends on higher level linguistic information, which is absent from psmt.
</prevsent>
<prevsent>in recent work, there has been some progress towards integrating syntactic information with the statistical approach to reordering.
</prevsent>
</prevsection>
<citsent citstr=" D07-1077 ">
in works such as (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005;<papid> P05-1066 </papid>wang et al, 2007; <papid> D07-1077 </papid>habash, 2007), reordering decisions are done deterministically?, thus placing these decisions outside the actual psmt system by learning to translate from reordered source lan guage.</citsent>
<aftsection>
<nextsent>(crego and marino, 2007; zhang et al, 2007; li et al, 2007) <papid> P07-1091 </papid>are more in the spirit of psmt, in that multiple reorderings are presented to the psmt system as (possibly weighted) options.</nextsent>
<nextsent>still, there remains basic conflict between the syntactic reordering rules and the psmt system:one that is most likely due to the discrepancy between the translation units (phrases) and units of the linguistic rules, as (zhang et al, 2007) point out.in this paper, we proceed in the spirit of the non deterministic approaches by providing the decoder with multiple source reorderings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1746">
<title id=" W08-0406.xml">syntactic reordering integrated with phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent work, there has been some progress towards integrating syntactic information with the statistical approach to reordering.
</prevsent>
<prevsent>in works such as (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005;<papid> P05-1066 </papid>wang et al, 2007; <papid> D07-1077 </papid>habash, 2007), reordering decisions are done deterministically?, thus placing these decisions outside the actual psmt system by learning to translate from reordered source lan guage.</prevsent>
</prevsection>
<citsent citstr=" P07-1091 ">
(crego and marino, 2007; zhang et al, 2007; li et al, 2007) <papid> P07-1091 </papid>are more in the spirit of psmt, in that multiple reorderings are presented to the psmt system as (possibly weighted) options.</citsent>
<aftsection>
<nextsent>still, there remains basic conflict between the syntactic reordering rules and the psmt system:one that is most likely due to the discrepancy between the translation units (phrases) and units of the linguistic rules, as (zhang et al, 2007) point out.in this paper, we proceed in the spirit of the non deterministic approaches by providing the decoder with multiple source reorderings.
</nextsent>
<nextsent>but instead of scoring the input word order, we score the order of the output.
</nextsent>
<nextsent>by doing this, we avoid the integration problems of previous approaches.it should be noted that even though the experiments are conducted within source reordering approach, this scoring is also compatible with other ap 46 proach.
</nextsent>
<nextsent>we will, however, not look further into this possiblity in the present paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1758">
<title id=" W08-0406.xml">syntactic reordering integrated with phrase based smt </title>
<section> reordering rules.  </section>
<citcontext>
<prevsection>
<prevsent>the rules are extracted from the hand-aligned, copenhagen danish-english dependency treebank (buch-kromann et al, 2007).
</prevsent>
<prevsent>5478 sentences from the news paper domain containing 111,805 english words and 100,185 danish words.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the english side is parsed using state-of-the-art statistical english parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>4.3 integrating rule-based reordering in psmt.
</nextsent>
<nextsent>the integration of the rule-based reordering in our psmt system is carried out in two separate stages: 1.
</nextsent>
<nextsent>reorder the source sentence to assimilate the.
</nextsent>
<nextsent>word order of the target language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1759">
<title id=" W08-0406.xml">syntactic reordering integrated with phrase based smt </title>
<section> the psmt system.  </section>
<citcontext>
<prevsection>
<prevsent>separating the scoring from the source language reordering also has the advantage that the sptoscoring in essence is compatible with other approaches such as traditional psmt system.
</prevsent>
<prevsent>we will, however, not examine this possibility further in the present paper.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
the baseline is the psmt system used for the 2006 naacl smt workshop (koehn and monz, 2006) <papid> W06-3114 </papid>with phrase length 3 and trigram language model(stolcke, 2002).</citsent>
<aftsection>
<nextsent>the system was trained on the english and danish part of the europarl corpus version3 (koehn, 2005).
</nextsent>
<nextsent>fourth quarter of 2000 was removed in order to use the common test set of 11369sentences (330,082 english words and 309,942 danish words with one reference) for testing.
</nextsent>
<nextsent>in addition, fourth quarter of 2001 was removed for development purposes.
</nextsent>
<nextsent>of these, 10194 were used for various analysis purposes, thereby keeping the test data perfectly unseen.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1761">
<title id=" W07-2018.xml">semeval2007 task 19 frame semantic structure extraction </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>in principle, the decision as to what frame to add new lu to should be helped by the same criteria that are used to assign polysemous lemmas to existing frames.
</prevsent>
<prevsent>however,in practice this assignment is difficult, precisely be cause, unlike wsd, there is no assumption that all the senses of each lemma are defined in advance; if 102 the system cant be sure that new use of lemma is in one of the frames listed for that lemma, thenit must consider all the 800+ frames as possibilities.
</prevsent>
</prevsection>
<citsent citstr=" W03-0410 ">
this amounts to the automatic induction of fine-grained semantic similarity from corpus data, notoriously difficult problem (stevenson and joanis, 2003; <papid> W03-0410 </papid>schulte im walde, 2003).for lus which clearly do not fit into any existing frames, the problem is still more difficult.</citsent>
<aftsection>
<nextsent>in the course of creating the gold standard annotation of the three testing texts, the fn team created almost 40 new frames.
</nextsent>
<nextsent>we cannot ask that participants hit uponthe new frame name, but the new frames are not created in vacuum; as mentioned above, they are almost always added to the existing structure of frame to-frame relations; this allows us to give credit for assignment to frames which are not the precise onein the gold standard, but are close in terms of frame to-frame relations.
</nextsent>
<nextsent>whenever participants?
</nextsent>
<nextsent>proposed frames were wrong but connected to the right frameby frame relations, partial credit was given, decreasing by 20% for each link in the frame-frame relation graph between the proposed frame and the gold standard.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1762">
<title id=" W07-2018.xml">semeval2007 task 19 frame semantic structure extraction </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>one result of this was that the test passages had more unseen frames than random unseen passage, which probably lowered the recall on frames.
</prevsent>
<prevsent>it appears that this was not entirely compensated by giving partial credit for related frames.
</prevsent>
</prevsection>
<citsent citstr=" W04-0803 ">
this task is more advanced and realistic version of the automatic semantic role labeling task of senseval-3 (litkowski, 2004).<papid> W04-0803 </papid></citsent>
<aftsection>
<nextsent>unlike that task, the testing data was previously unseen, participants had to determine the correct frames as first step, and participants also had to determine fe boundaries, which were given in the senseval-3.
</nextsent>
<nextsent>a crucial difference from similar approaches, such as srl with propbank roles (pradhan et al, 2004) <papid> N04-1030 </papid>is that by identifying relations as part of frame, you have identified gestalt of relations that enables far more inference, and sentences from the same passage that use other words from the same frame will be easier to link together.</nextsent>
<nextsent>thus, the fn srl results are translatable fairly directly into formal representations which can be used for reasoning, question answering, etc.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1763">
<title id=" W07-2018.xml">semeval2007 task 19 frame semantic structure extraction </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>this task is more advanced and realistic version of the automatic semantic role labeling task of senseval-3 (litkowski, 2004).<papid> W04-0803 </papid></prevsent>
<prevsent>unlike that task, the testing data was previously unseen, participants had to determine the correct frames as first step, and participants also had to determine fe boundaries, which were given in the senseval-3.</prevsent>
</prevsection>
<citsent citstr=" N04-1030 ">
a crucial difference from similar approaches, such as srl with propbank roles (pradhan et al, 2004) <papid> N04-1030 </papid>is that by identifying relations as part of frame, you have identified gestalt of relations that enables far more inference, and sentences from the same passage that use other words from the same frame will be easier to link together.</citsent>
<aftsection>
<nextsent>thus, the fn srl results are translatable fairly directly into formal representations which can be used for reasoning, question answering, etc.
</nextsent>
<nextsent>(scheffczyk et al., 2006; frank and semecky, 2004; <papid> W04-1906 </papid>sinha and narayanan, 2005).</nextsent>
<nextsent>despite the problems with recall, the participants have expressed determination to work to improve these results, and the fn staff are eager to collaborate in this effort.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1764">
<title id=" W07-2018.xml">semeval2007 task 19 frame semantic structure extraction </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>a crucial difference from similar approaches, such as srl with propbank roles (pradhan et al, 2004) <papid> N04-1030 </papid>is that by identifying relations as part of frame, you have identified gestalt of relations that enables far more inference, and sentences from the same passage that use other words from the same frame will be easier to link together.</prevsent>
<prevsent>thus, the fn srl results are translatable fairly directly into formal representations which can be used for reasoning, question answering, etc.</prevsent>
</prevsection>
<citsent citstr=" W04-1906 ">
(scheffczyk et al., 2006; frank and semecky, 2004; <papid> W04-1906 </papid>sinha and narayanan, 2005).</citsent>
<aftsection>
<nextsent>despite the problems with recall, the participants have expressed determination to work to improve these results, and the fn staff are eager to collaborate in this effort.
</nextsent>
<nextsent>a project is now underway at icsi to speed up frame and lu definition, and another tospeed up the training of srl systems is just beginning, so the prospects for improvement seem good.this material is based in part upon work supported by the national science foundation under grant no.
</nextsent>
<nextsent>iis-0535297.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1765">
<title id=" W08-0507.xml">building a bio wordnet using wordnet data structures and wordnets software infrastructurea failure story </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>besides this perspective on rich lexico logical data, over the years software infrastructure has emerged around wordnet that was equally approved by the nlp community.
</prevsent>
<prevsent>this included, e.g., lexicographic file generator, various editor sand visualization tools but also meta tools relying on properly for mated wordnet data such as library of similarity measures (pedersen et al, 2004).
</prevsent>
</prevsection>
<citsent citstr=" P07-1086 ">
in numerous articles the usefulness of this data and software ensemble has been demonstrated (e.g., for word sense disambiguation (patwardhan et al, 2003), the analysis of noun phrase conjuncts (hogan, 2007), <papid> P07-1086 </papid>or the resolution of co references (harabagiu et al, 2001)).<papid> N01-1008 </papid></citsent>
<aftsection>
<nextsent>in our research on information extraction and text mining within the field of biomedical nlp, we similarly recognized an urgent need for lexical resource comparable to wordnet, both in scope and size.
</nextsent>
<nextsent>however, the direct usability of the original wordnet for biomedical nlp is severely hampered by (not so surprising) lack of coverage of the life sciences domain in the general-language english wordnet as was clearly demonstrated by burgun and bodenreider (2001).
</nextsent>
<nextsent>rather than building bio wordnet by hand, as was done for the general-language english wordnet, our idea to set up wordnet-style lexical resource for the life sciences was different.
</nextsent>
<nextsent>we wanted to link the original wordnet with various biomedical terminological resources vastly available in the life sciences domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1766">
<title id=" W08-0507.xml">building a bio wordnet using wordnet data structures and wordnets software infrastructurea failure story </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>besides this perspective on rich lexico logical data, over the years software infrastructure has emerged around wordnet that was equally approved by the nlp community.
</prevsent>
<prevsent>this included, e.g., lexicographic file generator, various editor sand visualization tools but also meta tools relying on properly for mated wordnet data such as library of similarity measures (pedersen et al, 2004).
</prevsent>
</prevsection>
<citsent citstr=" N01-1008 ">
in numerous articles the usefulness of this data and software ensemble has been demonstrated (e.g., for word sense disambiguation (patwardhan et al, 2003), the analysis of noun phrase conjuncts (hogan, 2007), <papid> P07-1086 </papid>or the resolution of co references (harabagiu et al, 2001)).<papid> N01-1008 </papid></citsent>
<aftsection>
<nextsent>in our research on information extraction and text mining within the field of biomedical nlp, we similarly recognized an urgent need for lexical resource comparable to wordnet, both in scope and size.
</nextsent>
<nextsent>however, the direct usability of the original wordnet for biomedical nlp is severely hampered by (not so surprising) lack of coverage of the life sciences domain in the general-language english wordnet as was clearly demonstrated by burgun and bodenreider (2001).
</nextsent>
<nextsent>rather than building bio wordnet by hand, as was done for the general-language english wordnet, our idea to set up wordnet-style lexical resource for the life sciences was different.
</nextsent>
<nextsent>we wanted to link the original wordnet with various biomedical terminological resources vastly available in the life sciences domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1767">
<title id=" W08-0507.xml">building a bio wordnet using wordnet data structures and wordnets software infrastructurea failure story </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we wanted to link the original wordnet with various biomedical terminological resources vastly available in the life sciences domain.
</prevsent>
<prevsent>as an obvious candidate for this merger, we chose one of thema jor high-coverage umbrella systems for biomedical ontologies, the open biomedical ontologies (obo).1 these (currently) over 60 obo ontologies provide domain-specific knowledge in terms of hierarchies of classes that often come with synonym sand textual definitions for lots of biomedical sub domains (such as genes, proteins, cells, sequences, 1http://www.bioontology.org/ repositories.html#obo 31etc.).2 given these resources and their software infrastructure, our plan was to create bio medically focused lexico logical resource, the biowordnet,whose coverage would exceed that of any of its component resources in so far unprecedented manner.
</prevsent>
</prevsection>
<citsent citstr=" W07-1028 ">
only then, given such huge combined resource advanced nlp tasks such as anaphora resolution seem likely to be tackled infeasible way (hahn et al, 1999; castano et al, 2002; poprat andhahn, 2007).<papid> W07-1028 </papid></citsent>
<aftsection>
<nextsent>in particular, we wanted to make direct use of available software infrastructure such as the library of similarity metrics without the need forre-programming and hence foster the reuse of existing software as is. we began our efforts on the assumption that the wordnet software resources were stable and reliable.
</nextsent>
<nextsent>in the course of our work, it turned out that this belief was far too optimistic.
</nextsent>
<nextsent>we discuss the stumbling blocks that we encountered, point out an error in the wordnet software with implications for research based on it, and conclude that building onthe legacy of wordnet data structures and its associated software might preclude sustainable extensions that go beyond the domain of general english.hence, our report contains one of the rare failure stories (not only) in our field.
</nextsent>
<nextsent>while the stock of lexical data assembled in the wordnet lexicon was continuously growing overtime,3 its data format and storage structures, the socalled lexicographic file, by and large, remained unaltered (see section 2.1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1768">
<title id=" W07-1505.xml">an annotation type system for a data driven nlp pipeline </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>second, how can we build nlp systems by composing them, at the abstract levelof functional specification, from these already existing component building blocks disregarding concrete implementation matters?
</prevsent>
<prevsent>yet another burning issue relates to the increasing availability of multiple meta data annotations both in corpora and languageprocessors.
</prevsent>
</prevsection>
<citsent citstr=" W03-0804 ">
if alternative annotation tag sets are chosen for the same functional task data conversion problem is created which should be solved at the abstract specification level as well (ide et al, 2003).<papid> W03-0804 </papid></citsent>
<aftsection>
<nextsent>software engineering methodology points out that these requirements are best met by properly identifying input/output capabilities of constituent components and by specifying general data model (e.g.,based on uml (rumbaugh et al, 1999)) in order to get rid of the low-level implementation (i.e., coding) layer.
</nextsent>
<nextsent>a particularly promising proposal along this line of thought is the unstructured information management architecture (uima) (ferrucciand lally, 2004) originating from ibm research ac tivities.1 uima is but the latest attempt in series of proposals concerned with more generic nlp engines such as atlas (laprun et al, 2002) or gate (cunningham, 2002).
</nextsent>
<nextsent>these frameworks have in common data-driven architecture and data model based on annotation graphs as an adaptation of the tipster architecture (grishman, 1997).
</nextsent>
<nextsent>they suffer, however, from lack of standards for data exchange and abstraction mechanisms at the level of specification languages.this can be achieved by the definition of common annotation scheme.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1769">
<title id=" W07-1505.xml">an annotation type system for a data driven nlp pipeline </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the very beginning, this work often focused exclusively on sub domains of text analysis such as document structure meta-information, syntactic or semantic analysis.
</prevsent>
<prevsent>the text encoding initiative (tei)2 provided schemata for the exchange of documents of various genres.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the dublin core meta data initiative3 established de facto standard for the semantic web.4 for (computational) linguistics proper, syntactic annotation schemes, such as the one from the penn treebank (marcus et al,1993), <papid> J93-2004 </papid>or semantic annotations, such as the one underlying ace (doddington et al, 2004), are increasingly being used in quasi standard way.</citsent>
<aftsection>
<nextsent>in recent years, however, the nlp community is trying to combine and merge different kinds of annotations for single linguistic layers.
</nextsent>
<nextsent>xml format splay central role here.
</nextsent>
<nextsent>an xml-based encoding standard for linguistic corpora xces (ide et al, 2000) is based on ces (corpus encoding standard) as part of the eagles guidelines.5 work on tiger(brants and hansen, 2002) is an example for the liaison of dependency- and constituent-based syntactic annotations.
</nextsent>
<nextsent>new standardization efforts such asthe syntactic annotation framework (synaf) (de clerck, 2006) aim to combine different proposals and create standards for syntactic annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1770">
<title id=" W07-1505.xml">an annotation type system for a data driven nlp pipeline </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we also encounter tendency towards multiple annotations for single corpus.
</prevsent>
<prevsent>major bio-medical corpora, such as genia (ohta et al, 2002) or pennbioie,6 combine several layers of linguistic information in terms of morpho-syntactic, syntactic and semantic annotations (named entities andevents).
</prevsent>
</prevsection>
<citsent citstr=" W06-0606 ">
in the meantime, the annotation compatibility working group (meyers, 2006) <papid> W06-0606 </papid>began to concentrate its activities on the mutual compatibility of annotation schemata for, e.g., pos tagging, tree banking, role labeling, time annotation, etc. the goal of these initiatives, however, has never been to design an annotation scheme for complete 2http://www.tei-c.org 3http://dublincore.org 4http://www.w3.org/2001/sw 5http://www.ilc.cnr.it/eagles96/ 6http://bioie.ldc.upenn.edunlp pipeline as needed, e.g., for information extraction or text mining tasks (hahn and wermter, 2006).</citsent>
<aftsection>
<nextsent>this lack is mainly due to missing standards for specifying comprehensive nlp software architectures.
</nextsent>
<nextsent>the meaning format (pianta et al, 2006)<papid> W06-2713 </papid>is designed to integrate different levels of morphosyntactic annotations.</nextsent>
<nextsent>the heart of gold mid dleware (schafer, 2006) <papid> W06-2714 </papid>combines multidimensional mark-up produced by several nlp components.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1771">
<title id=" W07-1505.xml">an annotation type system for a data driven nlp pipeline </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the meantime, the annotation compatibility working group (meyers, 2006) <papid> W06-0606 </papid>began to concentrate its activities on the mutual compatibility of annotation schemata for, e.g., pos tagging, tree banking, role labeling, time annotation, etc. the goal of these initiatives, however, has never been to design an annotation scheme for complete 2http://www.tei-c.org 3http://dublincore.org 4http://www.w3.org/2001/sw 5http://www.ilc.cnr.it/eagles96/ 6http://bioie.ldc.upenn.edunlp pipeline as needed, e.g., for information extraction or text mining tasks (hahn and wermter, 2006).</prevsent>
<prevsent>this lack is mainly due to missing standards for specifying comprehensive nlp software archi tectures.</prevsent>
</prevsection>
<citsent citstr=" W06-2713 ">
the meaning format (pianta et al, 2006)<papid> W06-2713 </papid>is designed to integrate different levels of morphosyntactic annotations.</citsent>
<aftsection>
<nextsent>the heart of gold mid dleware (schafer, 2006) <papid> W06-2714 </papid>combines multidimensional mark-up produced by several nlp components.</nextsent>
<nextsent>anxml-based nlp tool suite for analyzing and annotating medical language in an nlp pipeline was also proposed by (grover et al, 2002).<papid> W02-1706 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1772">
<title id=" W07-1505.xml">an annotation type system for a data driven nlp pipeline </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this lack is mainly due to missing standards for specifying comprehensive nlp software architectures.
</prevsent>
<prevsent>the meaning format (pianta et al, 2006)<papid> W06-2713 </papid>is designed to integrate different levels of morphosyntactic annotations.</prevsent>
</prevsection>
<citsent citstr=" W06-2714 ">
the heart of gold mid dleware (schafer, 2006) <papid> W06-2714 </papid>combines multidimensional mark-up produced by several nlp components.</citsent>
<aftsection>
<nextsent>anxml-based nlp tool suite for analyzing and annotating medical language in an nlp pipeline was also proposed by (grover et al, 2002).<papid> W02-1706 </papid></nextsent>
<nextsent>all these proposals share their explicit linkage to specific nlp tool suite or nlp system and thus lack generic annotation framework that can be re-used in other develop mental environments.buitelaar et al developed in the context of an information extraction project an xml-based multilayered annotation scheme that covers morphosyntactic, shallow parsing and semantic annotation(buitelaar et al, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1773">
<title id=" W07-1505.xml">an annotation type system for a data driven nlp pipeline </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the meaning format (pianta et al, 2006)<papid> W06-2713 </papid>is designed to integrate different levels of morphosyntactic annotations.</prevsent>
<prevsent>the heart of gold mid dleware (schafer, 2006) <papid> W06-2714 </papid>combines multidimensional mark-up produced by several nlp components.</prevsent>
</prevsection>
<citsent citstr=" W02-1706 ">
anxml-based nlp tool suite for analyzing and annotating medical language in an nlp pipeline was also proposed by (grover et al, 2002).<papid> W02-1706 </papid></citsent>
<aftsection>
<nextsent>all these proposals share their explicit linkage to specific nlp tool suite or nlp system and thus lack generic annotation framework that can be re-used in other develop mental environments.buitelaar et al developed in the context of an information extraction project an xml-based multilayered annotation scheme that covers morphosyntactic, shallow parsing and semantic annotation(buitelaar et al, 2003).
</nextsent>
<nextsent>their scheme borrows concepts from object-oriented programming (e.g., abstract types, polymorphism).
</nextsent>
<nextsent>the object-oriented perspective already allows the development of domain-independent schema and extensions of core types without affecting the base schema.
</nextsent>
<nextsent>this schema is comprehensive indeed and covers significant part of advanced nlp pipelines but it is also not connected to generic framework.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1776">
<title id=" W07-1505.xml">an annotation type system for a data driven nlp pipeline </title>
<section> annotation type system.  </section>
<citcontext>
<prevsection>
<prevsent>in order to account for multiple annotations in the constituent-based approach, we introduced corresponding constituent types which specialize constituent.
</prevsent>
<prevsent>this parallels our approach which we advocate for alternatives in pos tagging and the management of alternative chunking results.currently, the scheme supports three different constituent types, viz.
</prevsent>
</prevsection>
<citsent citstr=" P05-1011 ">
ptb constituent, 38 genia constituent (miyao and tsujii, 2005) <papid> P05-1011 </papid>and pennbioieconstituent.</citsent>
<aftsection>
<nextsent>the attributes of the type ptb constituent cover the complete repertoire of annotation items contained in the penn treebank, such as functional tags forform/function dicrepancies (formfuncdisc), grammatical role (gramrole), adverbials (adv) and miscellaneous tags (misc).
</nextsent>
<nextsent>the representation of null elements, topical ized elements and gaps with corresponding references to the lexicalized elements in tree is reflected in attributes null element, tpc, map and ref, respectively.
</nextsent>
<nextsent>genia constituent andpennbioieconstituent inherit from ptb constituent all listed attributes and provide, in the case of genia constituent , an additional attribute syn to specify the syntactic idiosyncrasy (coordination) of constituents.
</nextsent>
<nextsent>dependency parsing results are directly linked to the token level and are thus referenced in the token type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1777">
<title id=" W07-1505.xml">an annotation type system for a data driven nlp pipeline </title>
<section> annotation type system.  </section>
<citcontext>
<prevsection>
<prevsent>the attribute specific type specifies the analyzed entity in more detailed way (e.g., organism can be specified through the species values human?, mouse?, rat?, etc.) the sub types are currently being developed in thebio-medical domain and cover, e.g., genes, proteins, organisms, diseases, variations.
</prevsent>
<prevsent>this hierarchy can easily be extended or supplemented with entities from other domains.
</prevsent>
</prevsection>
<citsent citstr=" C96-1079 ">
for illustration purposes, we extended it here by muc (grishman and sundheim, 1996) <papid> C96-1079 </papid>entity types such as person, organization, etc. this scheme is still under construction and will soon also incorporate the representation of relationships between entities and domain-specific events.</citsent>
<aftsection>
<nextsent>the general type relation will then be extended with specific conceptual relations such as location, part-of, etc. the representation of events will be covered by type which aggregates pre-defined relations between entities and the event mention.
</nextsent>
<nextsent>an event type such as inhibitioneventwould link the text spans in the sentence protein inhibits protein b?
</nextsent>
<nextsent>in attributes agent (protein a?), patient (protein b?), mention (inhibits?).
</nextsent>
<nextsent>in this paper, we introduced an uima annotation type system which covers the core functionality of morphological, syntactic and semantic analysis components of generic nlp system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1778">
<title id=" W08-0322.xml">kernel regression framework for machine translation ucl system description for wmt 2008 shared translation task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is the first time results based on the real-world data from the shared translation task will be reported at acl 2008 workshop on statistical machine translation.
</prevsent>
<prevsent>this paper presents the key modules of our system, including the kernel ridge regression model, retrieval-based sparse approximation, the decoding algorithm, as well as language modeling issues under this framework.
</prevsent>
</prevsection>
<citsent citstr=" N07-2047 ">
this paper follows the work in (wang et al, 2007; <papid> N07-2047 </papid>wang and shawe-taylor, 2008) which applied the kernel regression method with high-dimensional outputs proposed originally in (cortes et al, 2005) to statistical machine translation (smt) tasks.</citsent>
<aftsection>
<nextsent>in our approach, the machine translation problem is viewed as string-to-string mapping, where both the source and the target strings are embedded into their respective kernel induced feature spaces.
</nextsent>
<nextsent>then kernel ridge regression is employed to learn the mapping from the input feature space to the output one.
</nextsent>
<nextsent>as kernel method, this model offers the potential advantages of capturing very high-dimensional correspondences among the features of the source and target languages as well as easy integration of additional linguistic knowledge via selecting particular kernels.
</nextsent>
<nextsent>however, unlike the sequence labeling tasks such as optical character recognition in (corteset al, 2005), the complexity of the smt problem it self together with the computational complexities of kernel methods significantly complicate the implementation of the regression technique in this field.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1780">
<title id=" W08-0322.xml">kernel regression framework for machine translation ucl system description for wmt 2008 shared translation task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as kernel method, this model offers the potential advantages of capturing very high-dimensional correspondences among the features of the source and target languages as well as easy integration of additional linguistic knowledge via selecting particular kernels.
</prevsent>
<prevsent>however, unlike the sequence labeling tasks such as optical character recognition in (corteset al, 2005), the complexity of the smt problem it self together with the computational complexities of kernel methods significantly complicate the implementation of the regression technique in this field.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
our system is actually designed as hybrid of the classic phrase-based smt model (koehn et al, 2003) <papid> N03-1017 </papid>and the kernel regression model as follows: first, for each source sentence small relevant set of sentence pairs are retrieved from the large-scale parallel corpus.</citsent>
<aftsection>
<nextsent>then, the regression model is trained on this small relevant set only as sparse approximation of the regression hyper plane trained on the entire training set, as proposed in (wang and shawe taylor, 2008).
</nextsent>
<nextsent>finally, beam search algorithm is utilized to decode the target sentence from the very noisy output feature vector we predicted, with the support of pre-trained phrase table to generate possible hypotheses (candidate translations).
</nextsent>
<nextsent>in addition, language model trained on monolingual corpus can be integrated either directly into the regression model or during the decoding procedure as an extra scoring function.before describing each key component of our system in detail, we give block diagram overview in figure 1.
</nextsent>
<nextsent>concretely, the machine translation problem in our method is formulated as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1784">
<title id=" W08-0322.xml">kernel regression framework for machine translation ucl system description for wmt 2008 shared translation task </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>we 157 system bleu (%) nist meteor (%) ter (%) wer (%) per (%) kernel regression 26.59 7.00 52.63 55.98 60.52 43.20 moses 31.15 7.48 56.80 55.14 59.85 42.79 table 3: evaluations based on different metrics with comparison to moses.
</prevsent>
<prevsent>train our regression model on the training set, and test the effects of different language models on the development set (test2007).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the results evaluated by bleu score (papineni et al, 2002) <papid> P02-1040 </papid>is shown in table 2.</citsent>
<aftsection>
<nextsent>it can be found that integrating the language model into the regression framework works slightly better than just using it as an additional score component during decoding.
</nextsent>
<nextsent>but language models ofhigher-order than the n-gram kernel cannot be formulated to the regression problem, which would be drawback of our system.
</nextsent>
<nextsent>furthermore, the bleu score performance suggests that our model is not very powerful, but some interesting hints can be found in table 3 when we compare our method with 5-gram language model to state-of-the-art system moses (koehn and hoang, 2007) <papid> D07-1091 </papid>based on various evaluation metrics, including bleu score, nist score (doddington, 2002), meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>ter (snover et al, 2006), wer and per.</nextsent>
<nextsent>it is shown that our systems ter, wer and per scores are very close to moses, though the gaps in bleu, nist and meteor are significant,which suggests that we would be able to produce accurate translations but might not be good at making fluent sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1785">
<title id=" W08-0322.xml">kernel regression framework for machine translation ucl system description for wmt 2008 shared translation task </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>it can be found that integrating the language model into the regression framework works slightly better than just using it as an additional score component during decoding.
</prevsent>
<prevsent>but language models ofhigher-order than the n-gram kernel cannot be formulated to the regression problem, which would be drawback of our system.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
furthermore, the bleu score performance suggests that our model is not very powerful, but some interesting hints can be found in table 3 when we compare our method with 5-gram language model to state-of-the-art system moses (koehn and hoang, 2007) <papid> D07-1091 </papid>based on various evaluation metrics, including bleu score, nist score (doddington, 2002), meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>ter (snover et al, 2006), wer and per.</citsent>
<aftsection>
<nextsent>it is shown that our systems ter, wer and per scores are very close to moses, though the gaps in bleu, nist and meteor are significant,which suggests that we would be able to produce accurate translations but might not be good at making fluent sentences.
</nextsent>
<nextsent>this work is novel attempt to apply the advanced kernel method to smt tasks.
</nextsent>
<nextsent>the contribution at this stage is still preliminary.
</nextsent>
<nextsent>when applied to real-worlddata, this approach is not as powerful as the state-ofthe-art phrase-based log-linear model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1786">
<title id=" W08-0322.xml">kernel regression framework for machine translation ucl system description for wmt 2008 shared translation task </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>it can be found that integrating the language model into the regression framework works slightly better than just using it as an additional score component during decoding.
</prevsent>
<prevsent>but language models ofhigher-order than the n-gram kernel cannot be formulated to the regression problem, which would be drawback of our system.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
furthermore, the bleu score performance suggests that our model is not very powerful, but some interesting hints can be found in table 3 when we compare our method with 5-gram language model to state-of-the-art system moses (koehn and hoang, 2007) <papid> D07-1091 </papid>based on various evaluation metrics, including bleu score, nist score (doddington, 2002), meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>ter (snover et al, 2006), wer and per.</citsent>
<aftsection>
<nextsent>it is shown that our systems ter, wer and per scores are very close to moses, though the gaps in bleu, nist and meteor are significant,which suggests that we would be able to produce accurate translations but might not be good at making fluent sentences.
</nextsent>
<nextsent>this work is novel attempt to apply the advanced kernel method to smt tasks.
</nextsent>
<nextsent>the contribution at this stage is still preliminary.
</nextsent>
<nextsent>when applied to real-worlddata, this approach is not as powerful as the state-ofthe-art phrase-based log-linear model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1787">
<title id=" W07-1407.xml">learning textual entailment using svms and string similarity measures </title>
<section> official results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>systems used, but qa systems typically return s that contain the expected answer type of the input question; for instance, if the question is when did charles de gaulle die??, will typically contain atemporal expression.
</prevsent>
<prevsent>furthermore, qa systems typically prefer s that contain many words of the question, preferably in the same order, etc.
</prevsent>
</prevsection>
<citsent citstr=" A00-1021 ">
(radev et al., 2000; <papid> A00-1021 </papid>ng et al, 2001; <papid> W01-0509 </papid>harabagiu et al, 2003).hence, if the answers are sought in document collection with high redundancy (e.g., the web), i.e., collection where each answer can be found with many different phrasings, the s (or parts of them) that most qa systems return are often very similar, in terms of phrasings, to the questions, provided that the required answers exist in the collection.</citsent>
<aftsection>
<nextsent>in the qa datasets of the challenge, for each , which was snippet returned by qa system for question (e.g., when did charle de gaulle die??), an was formed by plugging into?
</nextsent>
<nextsent>the question an expression of the expected answer type from . in effect, this converted all questions to propositions (e.g., charle de gaulle died in 1970.?)
</nextsent>
<nextsent>that require yes?
</nextsent>
<nextsent>or no? answer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1788">
<title id=" W07-1407.xml">learning textual entailment using svms and string similarity measures </title>
<section> official results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>systems used, but qa systems typically return s that contain the expected answer type of the input question; for instance, if the question is when did charles de gaulle die??, will typically contain atemporal expression.
</prevsent>
<prevsent>furthermore, qa systems typically prefer s that contain many words of the question, preferably in the same order, etc.
</prevsent>
</prevsection>
<citsent citstr=" W01-0509 ">
(radev et al., 2000; <papid> A00-1021 </papid>ng et al, 2001; <papid> W01-0509 </papid>harabagiu et al, 2003).hence, if the answers are sought in document collection with high redundancy (e.g., the web), i.e., collection where each answer can be found with many different phrasings, the s (or parts of them) that most qa systems return are often very similar, in terms of phrasings, to the questions, provided that the required answers exist in the collection.</citsent>
<aftsection>
<nextsent>in the qa datasets of the challenge, for each , which was snippet returned by qa system for question (e.g., when did charle de gaulle die??), an was formed by plugging into?
</nextsent>
<nextsent>the question an expression of the expected answer type from . in effect, this converted all questions to propositions (e.g., charle de gaulle died in 1970.?)
</nextsent>
<nextsent>that require yes?
</nextsent>
<nextsent>or no? answer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1789">
<title id=" W07-2061.xml">racai meaning affinity models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such methods call upon further processing of the text to be dis ambiguated such as parsing and/or use handcrafted,semantically rich sense inventories such as wordnet (fellbaum, 1998).
</prevsent>
<prevsent>wsd methods in this category range from the very simple ranking based on counting the number of words occurring in both the target words context and its sense definitions in areference dictionary (lesk, 1986) to the more elaborated approaches using the semantic lexicons tax onomies, (shallow) parsing, collocation discovery etc.
</prevsent>
</prevsection>
<citsent citstr=" J01-3001 ">
(stevenson and wilks, 2001).<papid> J01-3001 </papid>one of the central issues of any wsd implementation is given by the context representation.</citsent>
<aftsection>
<nextsent>the standard principle that is applied when trying to disambiguate the meaning of word is that the same word in similar contexts should have the same meaning.
</nextsent>
<nextsent>by and large, the context of target word is materialized by collection of features among whichare: the collocates of the target word, the part-ofspeech (pos) of the target word, words surrounding the target word and/or their poses and soon.
</nextsent>
<nextsent>more often than not, the contexts similarity is estimated by the distance in the feature vector space.
</nextsent>
<nextsent>lin (1997) <papid> P97-1009 </papid>defines the local context of target word by the collection of syntactic dependencies in which the word takes part.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1790">
<title id=" W07-2061.xml">racai meaning affinity models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by and large, the context of target word is materialized by collection of features among whichare: the collocates of the target word, the part-ofspeech (pos) of the target word, words surrounding the target word and/or their poses and soon.
</prevsent>
<prevsent>more often than not, the contexts similarity is estimated by the distance in the feature vector space.
</prevsent>
</prevsection>
<citsent citstr=" P97-1009 ">
lin (1997) <papid> P97-1009 </papid>defines the local context of target word by the collection of syntactic dependencies in which the word takes part.</citsent>
<aftsection>
<nextsent>according to this notion of con 282 text, lin assumes that two different words are likely to have similar meanings if they occur in identical local contexts.
</nextsent>
<nextsent>what we will attempt here is to combine the two views of context similarity/identity versus meaningsimilarity/identity by using dependency-like representation of the context as lexical attraction model.
</nextsent>
<nextsent>more specifically, we will not consider any feature of the context and will try to maximize meaning attraction function over all linked words of sentence.in section 2 we will describe synwsd, an unsupervised, knowledge-based wsd algorithm and in sections 3 and 4 we will present the application of syn wsd to two of semeval-2007 all words?
</nextsent>
<nextsent>tasks: english coarse-grained and english fine-grained.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1794">
<title id=" W07-2061.xml">racai meaning affinity models </title>
<section> synwsd.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 meaning affinity models.
</prevsent>
<prevsent>if the lexical attraction models are geared towards the discovery of the most probable syntactic relations of sentence, we can naturally generalize this idea to construct class of models that will find combination of meanings that maximizes certain meaning attraction function over linkage of sentence.
</prevsent>
</prevsection>
<citsent citstr=" W98-0701 ">
we call this class of models the meaning affinity models.optimizing meaning affinity over syntactic representation of sentence has been tried in (stetina et al., 1998; <papid> W98-0701 </papid>horbovanu, 2002).</citsent>
<aftsection>
<nextsent>synwsd (ion, 2007)is an implementation with two phases of the meaning affinity concept: training which takes as input corpus with lexpar linked sentences (of the type shown in figure 1) and outputs table of meaning co-occurrence frequencies and disambiguation of lexpar linked sentence s, based on the counts in table from the previous phase.
</nextsent>
<nextsent>before continuing with the descriptions of these phases, we will introduce the notations that we will use throughout this section:?
</nextsent>
<nextsent>a n-word sentence is represented by vector of elements, each of them containing triple word form, lemma,pos?.
</nextsent>
<nextsent>for instance, the first element from in figure 1 is s[0] = we,we, pp1pn?;?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1795">
<title id=" W07-2061.xml">racai meaning affinity models </title>
<section> log-likelihood, ll(m1,m2) which is com-.  </section>
<citcontext>
<prevsection>
<prevsent>pointwise mutual information:.
</prevsent>
<prevsent>mi(m1,m2) = log kf(m1,m2)+kf(m2,m1)(f(m1,?)+f(?,m1))(f(m2,?)+f(?,m2))
</prevsent>
</prevsection>
<citsent citstr=" W04-3243 ">
puted as in (moore, 2004).<papid> W04-3243 </papid>after the viterbi path (best path) has been calculated, every state (meaning) from [i] (0 ?   |v |) along this path is added to finald vector.</citsent>
<aftsection>
<nextsent>when the pwn20 sense inventory is used, the reverse of the generalization procedure is applied to each meaning recorded in d, thus coming back to the meanings of the words of s. please note that an entry in may contain more than one meaning especially in the case of pwn20 meanings for which there was not enough training data.
</nextsent>
<nextsent>3 semeval-2007 task #7:.
</nextsent>
<nextsent>coarse-grained english all-words lexpar and synwsd were trained on an 1 million words corpus comprising the george orwells 1984 novel and the semcor corpus (miller et al, 1993).<papid> H93-1061 </papid>both texts have been pos-tagged (with multext east compliant pos tags) and lemmatized and the result was carefully checked by human judges to ensure correct annotation.</nextsent>
<nextsent>synwsd was run with all the meaning attraction functions (dice, mi and ll) for all the sense inventories (pwn20, sumo categories and irst do mains) and combined result was submitted to the task organizers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1796">
<title id=" W07-2061.xml">racai meaning affinity models </title>
<section> log-likelihood, ll(m1,m2) which is com-.  </section>
<citcontext>
<prevsection>
<prevsent>when the pwn20 sense inventory is used, the reverse of the generalization procedure is applied to each meaning recorded in d, thus coming back to the meanings of the words of s. please note that an entry in may contain more than one meaning especially in the case of pwn20 meanings for which there was not enough training data.
</prevsent>
<prevsent>3 semeval-2007 task #7:.
</prevsent>
</prevsection>
<citsent citstr=" H93-1061 ">
coarse-grained english all-words lexpar and synwsd were trained on an 1 million words corpus comprising the george orwells 1984 novel and the semcor corpus (miller et al, 1993).<papid> H93-1061 </papid>both texts have been pos-tagged (with multext east compliant pos tags) and lemmatized and the result was carefully checked by human judges to ensure correct annotation.</citsent>
<aftsection>
<nextsent>synwsd was run with all the meaning attraction functions (dice, mi and ll) for all the sense inventories (pwn20, sumo categories and irst do mains) and combined result was submitted to the task organizers.
</nextsent>
<nextsent>the combined result was prepared in the following way: 1.
</nextsent>
<nextsent>for each sense inventory and for each token identifier, get the union of the meanings for each run (dice, mi and ll); 2.
</nextsent>
<nextsent>for each token identifier with its three union sets of pwn20 meanings, sumo categories and irst domains: (a) for each pwn20 meaningmi in the union, if there is sumo category that maps onto it, increase mis weight by 1; (b) for each pwn20 meaningmi in the union, if there is irst domain that maps onto it, increase mis weight by 1;(c) from the set of weighted pwn20 meanings, select the subset that best overlaps with cluster.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1797">
<title id=" W07-0731.xml">the syntax augmented mt samt system at the shared task for the 2007 acl workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>at the acl 2007 workshop on statistical machine translation.
</prevsent>
<prevsent>following an overview of syntax augmented machine translation, we describe parameters for components in our open-source samt toolkit that were used to generate translation results for the spanish to english in-domain track of the shared task and discuss relative performance against our phrase-based submission.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
as chiang (2005) <papid> P05-1033 </papid>and koehn et al (2003) <papid> N03-1017 </papid>note, purely lexical phrase-based?</citsent>
<aftsection>
<nextsent>translation models suffer from sparse data effects when translating conceptual elements that span or skip across several source language words.
</nextsent>
<nextsent>phrase-based models also rely on distance and lexical distortion models to represent the reordering effects across language pairs.
</nextsent>
<nextsent>however, such models are typically applied over limited source sentence ranges to prevent errors introduced by these models and to maintain efficient decoding (och and ney, 2004).<papid> J04-4002 </papid>to address these concerns, hierarchically structured models as in chiang (2005) <papid> P05-1033 </papid>define weighted transduction rules, interpret able as components ofa probabilistic synchronous grammar (aho and ullman, 1969) that represent translation and reordering operations.</nextsent>
<nextsent>in this work, we describe results fromthe open-source syntax augmented machine translation (samt) toolkit (zollmann and venugopal, 2006) <papid> W06-3119 </papid>applied to the spanish-to-english in-domaintranslation task of the acl07 workshop on statistical machine translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1800">
<title id=" W07-0731.xml">the syntax augmented mt samt system at the shared task for the 2007 acl workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>at the acl 2007 workshop on statistical machine translation.
</prevsent>
<prevsent>following an overview of syntax augmented machine translation, we describe parameters for components in our open-source samt toolkit that were used to generate translation results for the spanish to english in-domain track of the shared task and discuss relative performance against our phrase-based submission.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
as chiang (2005) <papid> P05-1033 </papid>and koehn et al (2003) <papid> N03-1017 </papid>note, purely lexical phrase-based?</citsent>
<aftsection>
<nextsent>translation models suffer from sparse data effects when translating conceptual elements that span or skip across several source language words.
</nextsent>
<nextsent>phrase-based models also rely on distance and lexical distortion models to represent the reordering effects across language pairs.
</nextsent>
<nextsent>however, such models are typically applied over limited source sentence ranges to prevent errors introduced by these models and to maintain efficient decoding (och and ney, 2004).<papid> J04-4002 </papid>to address these concerns, hierarchically structured models as in chiang (2005) <papid> P05-1033 </papid>define weighted transduction rules, interpret able as components ofa probabilistic synchronous grammar (aho and ullman, 1969) that represent translation and reordering operations.</nextsent>
<nextsent>in this work, we describe results fromthe open-source syntax augmented machine translation (samt) toolkit (zollmann and venugopal, 2006) <papid> W06-3119 </papid>applied to the spanish-to-english in-domaintranslation task of the acl07 workshop on statistical machine translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1801">
<title id=" W07-0731.xml">the syntax augmented mt samt system at the shared task for the 2007 acl workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>translation models suffer from sparse data effects when translating conceptual elements that span or skip across several source language words.
</prevsent>
<prevsent>phrase-based models also rely on distance and lexical distortion models to represent the reordering effects across language pairs.
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
however, such models are typically applied over limited source sentence ranges to prevent errors introduced by these models and to maintain efficient decoding (och and ney, 2004).<papid> J04-4002 </papid>to address these concerns, hierarchically structured models as in chiang (2005) <papid> P05-1033 </papid>define weighted transduction rules, interpret able as components ofa probabilistic synchronous grammar (aho and ullman, 1969) that represent translation and reordering operations.</citsent>
<aftsection>
<nextsent>in this work, we describe results fromthe open-source syntax augmented machine translation (samt) toolkit (zollmann and venugopal, 2006) <papid> W06-3119 </papid>applied to the spanish-to-english in-domaintranslation task of the acl07 workshop on statistical machine translation.</nextsent>
<nextsent>we begin by describing the probabilistic model of translation applied by the samt toolkit.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1806">
<title id=" W07-0731.xml">the syntax augmented mt samt system at the shared task for the 2007 acl workshop on statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>phrase-based models also rely on distance and lexical distortion models to represent the reordering effects across language pairs.
</prevsent>
<prevsent>however, such models are typically applied over limited source sentence ranges to prevent errors introduced by these models and to maintain efficient decoding (och and ney, 2004).<papid> J04-4002 </papid>to address these concerns, hierarchically structured models as in chiang (2005) <papid> P05-1033 </papid>define weighted transduction rules, interpret able as components ofa probabilistic synchronous grammar (aho and ullman, 1969) that represent translation and reordering operations.</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
in this work, we describe results fromthe open-source syntax augmented machine translation (samt) toolkit (zollmann and venugopal, 2006) <papid> W06-3119 </papid>applied to the spanish-to-english in-domaintranslation task of the acl07 workshop on statistical machine translation.</citsent>
<aftsection>
<nextsent>we begin by describing the probabilistic model of translation applied by the samt toolkit.
</nextsent>
<nextsent>we then present settings for the pipeline of samt tools that we used in our shared task submission.
</nextsent>
<nextsent>finally, we compare our translation results to the cmu-ukaphrase-based smt system and discuss relative performance.
</nextsent>
<nextsent>probabilistic synchronous context-free grammars (pscfgs) are defined by source terminal set (source vocabulary) ts , target terminal set (targetvocabulary) tt , shared nonterminal setn and production rules of the form ? ??, ?,?, w?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1812">
<title id=" W07-0731.xml">the syntax augmented mt samt system at the shared task for the 2007 acl workshop on statistical machine translation </title>
<section> synchronous grammars for smt.  </section>
<citcontext>
<prevsection>
<prevsent>,#nt(?)} one to-one mapping from nonterminal tokens in ? to nonterminal tokens in ? ?
</prevsent>
<prevsent>w ? [0,?)
</prevsent>
</prevsection>
<citsent citstr=" P99-1039 ">
: nonnegative real-valued weight chiang (2005) <papid> P05-1033 </papid>uses single nonterminal category, galley et al (2004) use syntactic constituents for the pscfg nonterminal set, and zollmann and venugopal (2006) <papid> W06-3119 </papid>take advantage of ccg (combinatorial categorical grammar) (steedman, 1999) <papid> P99-1039 </papid>inspired slash?</citsent>
<aftsection>
<nextsent>and plus?
</nextsent>
<nextsent>categories, focusing on target (rather than source side) categories to generate well formed translations.we now describe the identification and estimation of pscfg rules from parallel sentence aligned corpora under the framework proposed by zollmann and venugopal (2006).<papid> W06-3119 </papid></nextsent>
<nextsent>216 2.1 grammar induction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1818">
<title id=" W07-0731.xml">the syntax augmented mt samt system at the shared task for the 2007 acl workshop on statistical machine translation </title>
<section> synchronous grammars for smt.  </section>
<citcontext>
<prevsection>
<prevsent>(2) where refers to features defined on each rule, plm is language model (lm) probability applied tothe target terminal symbols generated by the derivation d, and z(?)
</prevsent>
<prevsent>is normalization constant chosen such that the probabilities sum up to one.
</prevsent>
</prevsection>
<citsent citstr=" N07-1063 ">
the computational challenges of this search task (com pounded by the integration of the lm) are addressed in (chiang, 2007; venugopal et al, 2007).<papid> N07-1063 </papid></citsent>
<aftsection>
<nextsent>the feature weights are trained in concert with the lm weight via minimum error rate (mer) training (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>we now describe the parameters for the samt implementation of the model described above.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1819">
<title id=" W07-0731.xml">the syntax augmented mt samt system at the shared task for the 2007 acl workshop on statistical machine translation </title>
<section> synchronous grammars for smt.  </section>
<citcontext>
<prevsection>
<prevsent>is normalization constant chosen such that the probabilities sum up to one.
</prevsent>
<prevsent>the computational challenges of this search task (com pounded by the integration of the lm) are addressed in (chiang, 2007; venugopal et al, 2007).<papid> N07-1063 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the feature weights are trained in concert with the lm weight via minimum error rate (mer) training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we now describe the parameters for the samt implementation of the model described above.
</nextsent>
<nextsent>samt provides tools to perform grammar induction ( extractrules?, filterrules?), from bilingual phrase pairs and target language parse trees, as wellas translation (fasttranslatechart?)
</nextsent>
<nextsent>of source sentences given an induced grammar.
</nextsent>
<nextsent>3.1 extractrulesextractrules is the first step of the grammar induction pipeline, where rules are identified based on the process described in section 2.1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1822">
<title id=" W07-0731.xml">the syntax augmented mt samt system at the shared task for the 2007 acl workshop on statistical machine translation </title>
<section> empirical results.  </section>
<citcontext>
<prevsection>
<prevsent>andtest test06?
</prevsent>
<prevsent>corpora as per the workshop guidelines (case sensitive, de-tokenized).
</prevsent>
</prevsection>
<citsent citstr=" W07-0727 ">
we compare our scores against the cmu-uka isl phrase-based submission, state-of-the art phrase-based smt system with part-of-speech (pos) based word reordering (paulik et al, 2007).<papid> W07-0727 </papid></citsent>
<aftsection>
<nextsent>4.1 translation results.
</nextsent>
<nextsent>the samt system achieves bleu score of 32.48% on the dev06?
</nextsent>
<nextsent>development corpus and 32.15% on the unseen test06?
</nextsent>
<nextsent>corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1824">
<title id=" W07-1108.xml">cooccurrence contexts for noun compound interpretation </title>
<section> defining contexts for compound.  </section>
<citcontext>
<prevsection>
<prevsent>token was found (token similarity).
</prevsent>
<prevsent>1such as girju et al (2005), girju (2006), turney (2006).
</prevsent>
</prevsection>
<citsent citstr=" N04-1016 ">
lapata and kellers (2004) <papid> N04-1016 </papid>unsupervised approach is notable exception.</citsent>
<aftsection>
<nextsent>57 simple but effective method for exploiting these contexts is to count features that co-occur with the target items in those contexts.
</nextsent>
<nextsent>co-occurrence maybe defined in terms of proximity in the text, lexical patterns, or syntactic patterns in parse graph.
</nextsent>
<nextsent>we can parameter ise our notion of context further,for example by enforcing constraint that the cooccurrence correspond to particular type of grammatical relation or that co-occurrence features be long to particular word class.2 research in nlp frequently makes use of one or more of these similarity types.
</nextsent>
<nextsent>for example, culotta and sorensen (2004) <papid> P04-1054 </papid>combine word similarity and relation similarity for relation extraction; gliozzo etal.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1825">
<title id=" W07-1108.xml">cooccurrence contexts for noun compound interpretation </title>
<section> defining contexts for compound.  </section>
<citcontext>
<prevsection>
<prevsent>co-occurrence maybe defined in terms of proximity in the text, lexical patterns, or syntactic patterns in parse graph.
</prevsent>
<prevsent>we can parameter ise our notion of context further,for example by enforcing constraint that the cooccurrence correspond to particular type of grammatical relation or that co-occurrence features be long to particular word class.2 research in nlp frequently makes use of one or more of these similarity types.
</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
for example, culotta and sorensen (2004) <papid> P04-1054 </papid>combine word similarity and relation similarity for relation extraction; gliozzo etal.</citsent>
<aftsection>
<nextsent>(2005) combine word similarity and token similarity for word sense disambiguation.
</nextsent>
<nextsent>turney (2006)discusses word similarity (which he calls attributional similarity?)
</nextsent>
<nextsent>and relation similarity, but focusses on the latter and does not perform comparative study of the kind presented here.
</nextsent>
<nextsent>the experiments described here investigate type,word and relation similarity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1826">
<title id=" W07-1108.xml">cooccurrence contexts for noun compound interpretation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>this subset consists of every paragraph in the gigaword corpus belonging to articles tagged as story?
</prevsent>
<prevsent>and containing both constituents of compound in the dataset, whether or not they are compounded there.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
both corpora were lemmatised, tagged and parsed with rasp (briscoe et al, 2006).<papid> P06-4020 </papid></citsent>
<aftsection>
<nextsent>3.3 learning algorithm.
</nextsent>
<nextsent>in all our experiments we use one-against-all implementation of the support vector machine.4 except for the work described in section 6.2 we usedthe linear kernel k(x, y) = y to compute similarity between vector representations of the data items.the linear kernel consistently achieved superior performance to the more flexible gaussian kernel in range tests, presumably due to the sensitivity of 3http://www.natcorp.ox.ac.uk/ 4the software used was libsvm (chang and lin, 2001).
</nextsent>
<nextsent>58the gaussian kernel to its parameter settings.5 one against-all classification (training one classifier perclass) performed better than one-against-one (training one classifier for each pair of classes).
</nextsent>
<nextsent>we estimate test accuracy by 5-fold cross-validation and within each fold we perform further 5-fold cross validation on the training set to optimise the single svm parameter c. an advantage of the linear kernel is that learning is very efficient.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1827">
<title id=" W07-1108.xml">cooccurrence contexts for noun compound interpretation </title>
<section> word similarity.  </section>
<citcontext>
<prevsection>
<prevsent>the feature vector for each target constituent counts its co-occurrences with the 10,000 words that most frequently appear in the co-occurrence relations of interest over the entire corpus.
</prevsent>
<prevsent>a feature vector foreach compound was created by appending the vectors for its modifier and head, and these compound vectors were used for svm learning.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
to model aspects of co-occurrence association that might be obscured by raw frequency, the log-likelihood ratio g2(dunning, 1993) <papid> J93-1003 </papid>was also used to transform the feature space.</citsent>
<aftsection>
<nextsent>5keerthi and lin (2003) prove that the gaussian kernel will always do as well as or better than the linear kernel for binaryclassification.
</nextsent>
<nextsent>for multiclass classification we use multiple bi raw g2 accuracy macro accuracy macro w5 52.60% 51.07% 51.35% 49.93% w10 51.84% 50.32% 50.10% 48.60% rbasic 51.28% 49.92% 51.83% 50.26% rmod 51.35% 50.06% 48.51% 47.03% rverb 48.79% 47.13% 48.58% 47.07% rconj 54.12% 52.44% 54.95% 53.42% table 2: classification results for word similarity micro- and macro-averaged performance figures are given in table 2.
</nextsent>
<nextsent>the micro-averaged figure is calculated as the overall proportion of items that were classified correctly, whereas the macro-average is calculated as the average of the accuracy on each class and thus balances out any skew in the class distribution.
</nextsent>
<nextsent>in all cases macro-accuracy is lower than micro-accuracy; this is due to much better performance on the relations in, inst, actor and about than on be and have.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1829">
<title id=" W07-1108.xml">cooccurrence contexts for noun compound interpretation </title>
<section> comparison with prior work.  </section>
<citcontext>
<prevsection>
<prevsent>the latter paper reports accuracy of 58.0% (55.9% macro-average), which remains the highest reported figure for corpus-based approaches and demonstrates that relational similarity can perform well given sufficient resources.
</prevsent>
<prevsent>we are not aware of previous work that compares the effectiveness of different classes of context for compound interpretation, nor of work that investigates the utility of different corpora.
</prevsent>
</prevsection>
<citsent citstr=" P05-1050 ">
we have also described the first application of string kernels to the compound task, though gap-weighted kernels have been used successfully for related tasks such as word sense disambiguation (gliozzo et al, 2005) <papid> P05-1050 </papid>andre lation extraction (bunescu and mooney, 2005).</citsent>
<aftsection>
<nextsent>we have defined four kinds of co-occurrence contexts for compound interpretation and demonstrated that word similarity outperforms range of relation contexts using information derived from the british national corpus.
</nextsent>
<nextsent>our experiments with the english gigaword corpus indicate that more data is not always better, and that large newswire corpora may not be ideally suited to general relation-based tasks.
</nextsent>
<nextsent>63 on the other hand it might be expected to be very useful for disambiguating relations more typical of news stories (such as tax cut, rail strike).
</nextsent>
<nextsent>future research directions include developing more sophisticated context kernels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1830">
<title id=" W07-0734.xml">meteor an automatic metric for mt evaluation with high levels of correlation with human judgments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluating an mt system using such automatic metrics is much faster, easier and cheaper compared to human evaluations, which require trained bilingual evaluators.
</prevsent>
<prevsent>automatic metrics are useful for comparing the performance of different systems on common translation task, and can be applied on frequent and ongoing basis during mt system development.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the most commonly used mt evaluation metric in recent years has been ibms bleu metric (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>bleu is fast and easy to run, and itcan be used as target function in parameter optimization training procedures that are commonly used in state-of-the-art statistical mt systems (och,2003).<papid> P03-1021 </papid></nextsent>
<nextsent>various researchers have noted, however, various weaknesses in the metric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1831">
<title id=" W07-0734.xml">meteor an automatic metric for mt evaluation with high levels of correlation with human judgments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic metrics are useful for comparing the performance of different systems on common translation task, and can be applied on frequent and ongoing basis during mt system development.
</prevsent>
<prevsent>the most commonly used mt evaluation metric in recent years has been ibms bleu metric (papineni et al, 2002).<papid> P02-1040 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
bleu is fast and easy to run, and itcan be used as target function in parameter optimization training procedures that are commonly used in state-of-the-art statistical mt systems (och,2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>various researchers have noted, however, various weaknesses in the metric.
</nextsent>
<nextsent>most notably, bleu does not produce very reliable sentence-level scores.
</nextsent>
<nextsent>meteor , as well as several other proposed metrics such as gtm (melamed et al, 2003), <papid> N03-2021 </papid>ter (snover et al, 2006) and cder (leusch et al, 2006) <papid> E06-1031 </papid>aim to address some of these weaknesses.</nextsent>
<nextsent>meteor , initially proposed and released in 2004(lavie et al, 2004) was explicitly designed to improve correlation with human judgments of mt quality at the segment level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1832">
<title id=" W07-0734.xml">meteor an automatic metric for mt evaluation with high levels of correlation with human judgments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>various researchers have noted, however, various weaknesses in the metric.
</prevsent>
<prevsent>most notably, bleu does not produce very reliable sentence-level scores.
</prevsent>
</prevsection>
<citsent citstr=" N03-2021 ">
meteor , as well as several other proposed metrics such as gtm (melamed et al, 2003), <papid> N03-2021 </papid>ter (snover et al, 2006) and cder (leusch et al, 2006) <papid> E06-1031 </papid>aim to address some of these weaknesses.</citsent>
<aftsection>
<nextsent>meteor , initially proposed and released in 2004(lavie et al, 2004) was explicitly designed to improve correlation with human judgments of mt quality at the segment level.
</nextsent>
<nextsent>previous publications on meteor (lavie et al, 2004; banerjee and lavie,2005) <papid> W05-0909 </papid>have described the details underlying the metric and have extensively compared its performance with bleu and several other mt evaluation metrics.</nextsent>
<nextsent>this paper recaps the technical details underlying meteor and describes recent improvements in the metric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1833">
<title id=" W07-0734.xml">meteor an automatic metric for mt evaluation with high levels of correlation with human judgments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>various researchers have noted, however, various weaknesses in the metric.
</prevsent>
<prevsent>most notably, bleu does not produce very reliable sentence-level scores.
</prevsent>
</prevsection>
<citsent citstr=" E06-1031 ">
meteor , as well as several other proposed metrics such as gtm (melamed et al, 2003), <papid> N03-2021 </papid>ter (snover et al, 2006) and cder (leusch et al, 2006) <papid> E06-1031 </papid>aim to address some of these weaknesses.</citsent>
<aftsection>
<nextsent>meteor , initially proposed and released in 2004(lavie et al, 2004) was explicitly designed to improve correlation with human judgments of mt quality at the segment level.
</nextsent>
<nextsent>previous publications on meteor (lavie et al, 2004; banerjee and lavie,2005) <papid> W05-0909 </papid>have described the details underlying the metric and have extensively compared its performance with bleu and several other mt evaluation metrics.</nextsent>
<nextsent>this paper recaps the technical details underlying meteor and describes recent improvements in the metric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1834">
<title id=" W07-0734.xml">meteor an automatic metric for mt evaluation with high levels of correlation with human judgments </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>meteor , as well as several other proposed metrics such as gtm (melamed et al, 2003), <papid> N03-2021 </papid>ter (snover et al, 2006) and cder (leusch et al, 2006) <papid> E06-1031 </papid>aim to address some of these weaknesses.</prevsent>
<prevsent>meteor , initially proposed and released in 2004(lavie et al, 2004) was explicitly designed to improve correlation with human judgments of mt quality at the segment level.</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
previous publications on meteor (lavie et al, 2004; banerjee and lavie,2005) <papid> W05-0909 </papid>have described the details underlying the metric and have extensively compared its performance with bleu and several other mt evaluation metrics.</citsent>
<aftsection>
<nextsent>this paper recaps the technical details underlying meteor and describes recent improvements in the metric.
</nextsent>
<nextsent>the latest release extends meteor to support evaluation of mt output in spanish, french and german, in addition to english.
</nextsent>
<nextsent>furthermore,several parameters within the metric have been optimized on language-specific training data.
</nextsent>
<nextsent>we present experimental results that demonstrate the improvements in correlations with human judgments that result from these parameter tunings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1836">
<title id=" W08-0801.xml">a multimodal home entertainment interface via a mobile device </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>users may search an electronic program guide using constraints such as date, time, and genre; however, they cant search by title.
</prevsent>
<prevsent>users can also perform typical remote-control tasks like turning the television on and off, and changing the channel.
</prevsent>
</prevsection>
<citsent citstr=" P07-1048 ">
(johnston etal., 2007) <papid> P07-1048 </papid>also use tablet pc to provide an interface to television content in this case database of movies.</citsent>
<aftsection>
<nextsent>the search can be constrained by attributes such as title, director, or starring actors.
</nextsent>
<nextsent>the tablet pc pen can be used to hand write queries and to point at items (such as actor names) while the user speaks.
</nextsent>
<nextsent>we were also inspired by previous prototypes inwhich mobile devices have been used in conjunction with larger, shared displays.
</nextsent>
<nextsent>for instance, (paek et al, 2004) demonstrate framework for building such applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1837">
<title id=" W08-0801.xml">a multimodal home entertainment interface via a mobile device </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>in the prototype system, flexible and reusable speech recognition and natural language processing capabilities are provided via generic components developed and deployed in numerous spoken dialogue systems by our group, with the exception of an off the-shelf speech synthesizer.
</prevsent>
<prevsent>speech input from the mobile device is recognized using the landmark based summit system (glass, 2003).
</prevsent>
</prevsection>
<citsent citstr=" J92-1004 ">
the resulting n-best hypotheses are processed by the tina language understanding component (seneff, 1992).<papid> J92-1004 </papid></citsent>
<aftsection>
<nextsent>4 galaxy spee chr ecog nize language und ersta ndin dialo gue?
</nextsent>
<nextsent>manager language gen eration text tos peec web ? server tele visio web browse med iapl ayer tvg uide ? media mob iled evic web browse hom em edia server weather mob ile?
</nextsent>
<nextsent>manager aud ioin put?
</nextsent>
<nextsent>/ou tput galaxy dialo gue?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1838">
<title id=" W08-0801.xml">a multimodal home entertainment interface via a mobile device </title>
<section> rapid dialogue system development.  </section>
<citcontext>
<prevsection>
<prevsent>the corpus is used to train probabilities for the natural language parsing grammar (described immediatelybelow), which in turn is used to derive class gram language model (seneff et al, 2003).classes in the language model which correspond to contents of the database are marked as dynamic, and are populated at runtime from the database (chung et al, 2004; hetherington, 2005).
</prevsent>
<prevsent>database entries are heuristic ally normalized into spoken forms.
</prevsent>
</prevsection>
<citsent citstr=" N07-2039 ">
pronunciations not in our 150,000 word lexicon are automatically generated (seneff, 2007).<papid> N07-2039 </papid>parser grammar the tina parser uses probabilistic context-free grammar enhanced with support for wh-movement and grammatical agreementconstraints.</citsent>
<aftsection>
<nextsent>we have developed generic syntactic grammar by examining hundreds of thousands of utterances collected from real user interactions with various existing dialogue systems.
</nextsent>
<nextsent>in addition,we have developed libraries which parse and interpret common semantic classes like dates, times, andnumbers.
</nextsent>
<nextsent>the grammar and semantic libraries provide good coverage for spoken dialogue systems in database-query domains.
</nextsent>
<nextsent>6to build grammar for new domain, developer extends the generic syntactic grammar by augmenting it with domain-specific semantic categories and their lexical entries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1842">
<title id=" W07-2004.xml">semeval2007 task 05 multilingual chinese english lexical sample </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the multilingual chinese-english lexical sample task at semeval-2007 provides framework to evaluate chinese word sense disambiguation and to promote research.
</prevsent>
<prevsent>this paper reports on the task preparation and the results of six participants.
</prevsent>
</prevsection>
<citsent citstr=" W04-0802 ">
the multilingual chinese-english lexical sample task is designed following the leading ideas of the senseval-3 multilingual english-hindi lexical sample task (chklovski et al, 2004).<papid> W04-0802 </papid></citsent>
<aftsection>
<nextsent>the sense tags?
</nextsent>
<nextsent>for the ambiguous chinese target words are given in the form of their english translations.
</nextsent>
<nextsent>the data preparation is introduced in the second section.
</nextsent>
<nextsent>and then the participating systems are briefly described and their scores are listed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1843">
<title id=" W07-2004.xml">semeval2007 task 05 multilingual chinese english lexical sample </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>these phrases are considered as constituents of context, as well as words and punctuations which do not belong to any phrase.
</prevsent>
<prevsent>the type of these phrases which are around the target phrases 2 http:// maxent.sourceforge.net/ 20?
</prevsent>
</prevsection>
<citsent citstr=" P05-1049 ">
word category information comes from chinese thesaurus i2r system used semi-supervised classification algorithm (label propagation algorithm) (niu, et al, 2005).<papid> P05-1049 </papid></citsent>
<aftsection>
<nextsent>they used three types of features: pos of neighboring words with position information, unordered single words in topical context, and local collocations.
</nextsent>
<nextsent>in the label propagation algorithm (lp) (zhu and ghahramani, 2002), label information of any vertex in graph is propagated to nearby vertices through weighted edges until global stable stage is achieved.
</nextsent>
<nextsent>larger edge weights allow labels to travel through easier.
</nextsent>
<nextsent>thus the closer the examples, the more likely they have similar labels (the global consistency assumption).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1844">
<title id=" W08-0614.xml">a pilot annotation to investigate discourse connectivity in biomedical text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we found that the two annotators were able to reach an agreement after discussion.
</prevsent>
<prevsent>thus our experiments suggest that the pdtb annotation can be adapted to new domains by minimally adjusting the guidelines and by adding some further domain-specific linguistic cues.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
large scale annotated corpora, e.g., the penn treebank (ptb) project (marcus et al 1993), <papid> J93-2004 </papid>have played an important role in text-mining.</citsent>
<aftsection>
<nextsent>the penn discourse treebank (pdtb) (http://www.seas.upenn.edu/~pdtb) (prasad et al 2008a) annotates the argument structure, semantics, and attribution of discourse connectives and their arguments.
</nextsent>
<nextsent>the current release of pdtb 2.0 contains the annotations of 1,808 wall street journal articles (~1 million words) from the penn treebank (marcus et al 1993) <papid> J93-2004 </papid>ii distribution and total of 40,600 discourse connective tokens (prasad et al 2008b).</nextsent>
<nextsent>this work examines whether the pdtb annotation guidelines can be adapted to different genre, the biomedical literature.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1846">
<title id=" W08-0614.xml">a pilot annotation to investigate discourse connectivity in biomedical text </title>
<section> a pilot annotation  </section>
<citcontext>
<prevsection>
<prevsent>two linguist annotators independently annotated one full-text biomedical article (verpy et al 1999) that we randomly selected.
</prevsent>
<prevsent>the article is 4,937 tokens long.
</prevsent>
</prevsection>
<citsent citstr=" W04-2703 ">
when the annotation work was completed, we measured the inter-annotator agreement, following the pdtb exact match criterion (miltsakaki et al 2004).<papid> W04-2703 </papid></citsent>
<aftsection>
<nextsent>according to this criterion, discourse relation is in disagreement if there is disagreement on any text span (i.e., the discourse connective or any of its two arguments).
</nextsent>
<nextsent>in addition, we also measured the agreement in the components (i.e., discourse connectives and the arguments).
</nextsent>
<nextsent>we discussed the annotation results and made suggestions to adapt the pdtb guidelines to biomedical text.
</nextsent>
<nextsent>the first annotator identified 74 discourse connectives, and the second annotator identified 75, 68 of which were the same as those identified by the first annotator.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1850">
<title id=" W07-2103.xml">uth svm based semantic relation classification using physical sizes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>classification of semantic relations is important to nlp as it would benefit many nlp applications,such as machine translation and information retrieval.
</prevsent>
<prevsent>researchers have already proposed variousschemes.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
for example, hearst (1992) <papid> C92-2082 </papid>manually designed lexico-syntactic patterns for extracting is-a relations.</citsent>
<aftsection>
<nextsent>berland and charniak (1999) <papid> P99-1008 </papid>proposed similar method for part-whole relations.</nextsent>
<nextsent>brin (1998)employed bootstrapping algorithm for more specific relations (author-book relations).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1851">
<title id=" W07-2103.xml">uth svm based semantic relation classification using physical sizes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers have already proposed variousschemes.
</prevsent>
<prevsent>for example, hearst (1992) <papid> C92-2082 </papid>manually designed lexico-syntactic patterns for extracting is-a relations.</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
berland and charniak (1999) <papid> P99-1008 </papid>proposed similar method for part-whole relations.</citsent>
<aftsection>
<nextsent>brin (1998)employed bootstrapping algorithm for more specific relations (author-book relations).
</nextsent>
<nextsent>kim and baldwin (2006) <papid> P06-2064 </papid>and moldovan et al(2004) <papid> W04-2609 </papid>focused on nominal relations in compound nouns.</nextsent>
<nextsent>turney (2005) measured relation similarity between two words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1852">
<title id=" W07-2103.xml">uth svm based semantic relation classification using physical sizes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>berland and charniak (1999) <papid> P99-1008 </papid>proposed similar method for part-whole relations.</prevsent>
<prevsent>brin (1998)employed bootstrapping algorithm for more specific relations (author-book relations).</prevsent>
</prevsection>
<citsent citstr=" P06-2064 ">
kim and baldwin (2006) <papid> P06-2064 </papid>and moldovan et al(2004) <papid> W04-2609 </papid>focused on nominal relations in compound nouns.</citsent>
<aftsection>
<nextsent>turney (2005) measured relation similarity between two words.
</nextsent>
<nextsent>while these methods differ, they all utilize lexical patterns between two entities.within this context, our goal was to utilize information specific to an entity.
</nextsent>
<nextsent>although entities contain many types of information, we focused on the physical size of an entity.
</nextsent>
<nextsent>here, physical size refers to the typical width/height of an entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1853">
<title id=" W07-2103.xml">uth svm based semantic relation classification using physical sizes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>berland and charniak (1999) <papid> P99-1008 </papid>proposed similar method for part-whole relations.</prevsent>
<prevsent>brin (1998)employed bootstrapping algorithm for more specific relations (author-book relations).</prevsent>
</prevsection>
<citsent citstr=" W04-2609 ">
kim and baldwin (2006) <papid> P06-2064 </papid>and moldovan et al(2004) <papid> W04-2609 </papid>focused on nominal relations in compound nouns.</citsent>
<aftsection>
<nextsent>turney (2005) measured relation similarity between two words.
</nextsent>
<nextsent>while these methods differ, they all utilize lexical patterns between two entities.within this context, our goal was to utilize information specific to an entity.
</nextsent>
<nextsent>although entities contain many types of information, we focused on the physical size of an entity.
</nextsent>
<nextsent>here, physical size refers to the typical width/height of an entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1854">
<title id=" W07-0807.xml">finding variants of outofvocabulary words in arabic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>across british and american usage, and ambience?
</prevsent>
<prevsent>and ambiance?
</prevsent>
</prevsection>
<citsent citstr=" W06-1631 ">
across french and english.a change in character sets compounds the prob lem: for instance, there are at least 32 english forms for the arabic name of the libyan leaderkaddafi?,1 and nwesri et al  (2006) <papid> W06-1631 </papid>have identified 28 different spellings for the name of the former serbian president milosevic in the eleventh text retrieval conference (trec) arabic newswire col lection.</citsent>
<aftsection>
<nextsent>users typically submit only one spelling variant in their query, and current arabic text retrieval systems return only documents that contain that variant (abdelali et al , 2004).
</nextsent>
<nextsent>we apply tech 1http://www.geocities.com/athens/8744/ spelling.htmniques used to identify similar strings in other languages such as english, and present novel approach to identify and retrieve different variants of foreign words in arabic.
</nextsent>
<nextsent>arabic is semitic language written from right to left, with most words derived from three-character root words.
</nextsent>
<nextsent>the arabic alphabet has 28 characters, each with distinct sound.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1856">
<title id=" W07-0807.xml">finding variants of outofvocabulary words in arabic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>with the dice (1945) measure, the similarity of strings and is computed as twice the number of common n-grams between and t, divided by the total number of n-grams in the two strings: dice(s, t) = 2?
</prevsent>
<prevsent>| gs ? gt || gs | + | gt | where gs denotes the set of n-grams in s, and gt denotes the set of n-grams in t.the longest common sub sequence (lcs) algorithm measures the similarity between two strings based on the common characters in the two strings (wagner and fischer, 1974; stephen, 1992).
</prevsent>
</prevsection>
<citsent citstr=" W95-0115 ">
similarity is normalised by dividing the length of the common sub sequence by the length of the longer string (melamed, 1995).<papid> W95-0115 </papid></citsent>
<aftsection>
<nextsent>the similarity between between ahmed?
</nextsent>
<nextsent>and ahmmed?
</nextsent>
<nextsent>is (5/6=0.833).phonetic approaches to determine similarity between two words include the well-known soundex algorithm developed by odell and russell, patented in 1918 and 1922 (hall and dowling, 1980).
</nextsent>
<nextsent>this has predefined codes for the sounds in language, with similar-sounding letters grouped under one code.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1858">
<title id=" W07-2066.xml">swag local context matching for english lexical substitution </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 compiling substitution lexicon.
</prevsent>
<prevsent>we begin by compiling list of candidate synonyms for each target word.
</prevsent>
</prevsection>
<citsent citstr=" P06-1057 ">
following dagan et al (2006),<papid> P06-1057 </papid>we will refer to this list of synonyms as our substitution lexicon.</citsent>
<aftsection>
<nextsent>the performance of our system is limited by the substitution lexicon because it can only pick the correct replacements if they are in the lexicon.
</nextsent>
<nextsent>the substitution lexicon available to our scoring system therefore determines both the maximum attainable recall and the baseline probability of randomly guessing correct replacement.
</nextsent>
<nextsent>one approach to generating substitution lexicon is to query wordnet for lists of synonyms grouped by the senses of each word.
</nextsent>
<nextsent>while wordnet has its advantages, we aimed to create knowledge-light 304 system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1859">
<title id=" W07-2066.xml">swag local context matching for english lexical substitution </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>one approach to generating substitution lexicon is to query wordnet for lists of synonyms grouped by the senses of each word.
</prevsent>
<prevsent>while wordnet has its advantages, we aimed to create knowledge-light 304 system.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
a more knowledge-free system would have used machine readable dictionary or large natural language sample to retrieve its synonyms (see, for example, lin (1998)), <papid> P98-2127 </papid>but our system falls shortof this, relying on rogets new millennium the saurus1 (henceforth rt) as source of synonyms.</citsent>
<aftsection>
<nextsent>though this thesaurus is similar to wordnet in some ways, it does not contain semantic relationships beyond synonyms and antonyms.
</nextsent>
<nextsent>one important advantage of thesaurus over wordnet is that it is easier to obtain for languages other than english.
</nextsent>
<nextsent>we used the trial data to ensure that the quality of the list compiled from rt would be satisfactory for this task.
</nextsent>
<nextsent>we found that by using the synonyms in wordnet synsets2 as our substitution lexicon, we could achieve maximum recall of 53% when using an oracle to select the correct synonyms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1860">
<title id=" W07-2066.xml">swag local context matching for english lexical substitution </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>is the set {was bright?, bright boy?, bright boy only?}.
</prevsent>
<prevsent>once we identified the set of context trigrams, we filtered this set by removing all trigrams which did not include content words.
</prevsent>
</prevsection>
<citsent citstr=" W02-0109 ">
to identify content words, we used the nltk-lite tagger to assign part of speech to each word (loper and bird, 2002).<papid> W02-0109 </papid></citsent>
<aftsection>
<nextsent>we considered open class words (with the exception of the verb to be) and pronouns to be content words.
</nextsent>
<nextsent>we call the filtered set of trigrams the test trigrams.from the above example, we would remove the trigram was bright?
</nextsent>
<nextsent>since it does not contain content word other than the target word.
</nextsent>
<nextsent>we match the test trigrams against trigrams in the web 1t corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1861">
<title id=" W07-2066.xml">swag local context matching for english lexical substitution </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>though limited time prohibited us from doing more thorough evaluation, we decided to use this unorthodox combination as the basis for our second system.
</prevsent>
<prevsent>we submitted two sets of results to this task: the first was our local context matching system (swag1) and the second was the combined flcm and fnn hybrid system (swag2).
</prevsent>
</prevsection>
<citsent citstr=" W07-2009 ">
our systems consistently perform better when mode exists, which makes sense because those are instances in which the annotators are in agreement (mccarthy and navigli, 2007).<papid> W07-2009 </papid></citsent>
<aftsection>
<nextsent>in these cases it is more likely that the most appropriate synonym is clear from the context and therefore easier to pick.
</nextsent>
<nextsent>it is hard to say exactly why swag2 outperforms swag1 because we havent had enough time tofully analyze our results.
</nextsent>
<nextsent>our decision to choose different systems for each part of speech may have been 8filtering was done only on nouns as described above.
</nextsent>
<nextsent>partially responsible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1862">
<title id=" W07-1409.xml">on the role of lexical and world knowledge in rte3 </title>
<section> sources of world knowledge.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 framenet.
</prevsent>
<prevsent>in our earlier analysis, we identified knowledge about stereotypical situations and their events as important for rte.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
framenet (baker et al  1998) <papid> P98-1013 </papid>attempts to encode this knowledge.</citsent>
<aftsection>
<nextsent>framenet was used with some success in rte2 by burchardt and frank (2005).
</nextsent>
<nextsent>framenet basic unit - frame - is script-like conceptual schema that refers to situation, object, or event along with its participants (frame elements), identified independent of their syntactic configuration.
</nextsent>
<nextsent>we earlier discussed how 538.t  ...the o. j. simpson murder trial...  might entail 538.h  o. j. simpson was accused of murder.
</nextsent>
<nextsent>this case applies to frame nets trial frame, which includes the frame elements defendant and charges, with charges being defined as  the legal label for the crime that the defendant is accused of. , thus stating the relationship between the defendant and the charges, unstated in but made explicit in h, validating the entailment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1863">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>is specially relevant when handling language pairs with very different word order, such as arabic-english or chinese-english.
</prevsent>
<prevsent>many alternatives have been proposed on using syntactic information in smt systems.
</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
they range from those aiming at harmonizing (monotonizing) the word order of the considered language pairs bymeans of set of linguistically-motivated reordering patterns (xia and mccord, 2004; <papid> C04-1073 </papid>collins etal., 2005) <papid> P05-1066 </papid>to others considering translation synchronous parsing process where reorderings introduced in the overall search are syntactically motivated (galley et al, 2004; quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>thework presented here follows the word order harmonization strategy.
</nextsent>
<nextsent>53collins et al (2005) <papid> P05-1066 </papid>describe technique for preprocessing german to look more like english syn tactically.</nextsent>
<nextsent>they used six transformations that are applied on german parsed text to reorder it before passing it on to phrase-based system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1864">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>is specially relevant when handling language pairs with very different word order, such as arabic-english or chinese-english.
</prevsent>
<prevsent>many alternatives have been proposed on using syntactic information in smt systems.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
they range from those aiming at harmonizing (monotonizing) the word order of the considered language pairs bymeans of set of linguistically-motivated reordering patterns (xia and mccord, 2004; <papid> C04-1073 </papid>collins etal., 2005) <papid> P05-1066 </papid>to others considering translation synchronous parsing process where reorderings introduced in the overall search are syntactically motivated (galley et al, 2004; quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>thework presented here follows the word order harmonization strategy.
</nextsent>
<nextsent>53collins et al (2005) <papid> P05-1066 </papid>describe technique for preprocessing german to look more like english syn tactically.</nextsent>
<nextsent>they used six transformations that are applied on german parsed text to reorder it before passing it on to phrase-based system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1865">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>is specially relevant when handling language pairs with very different word order, such as arabic-english or chinese-english.
</prevsent>
<prevsent>many alternatives have been proposed on using syntactic information in smt systems.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
they range from those aiming at harmonizing (monotonizing) the word order of the considered language pairs bymeans of set of linguistically-motivated reordering patterns (xia and mccord, 2004; <papid> C04-1073 </papid>collins etal., 2005) <papid> P05-1066 </papid>to others considering translation synchronous parsing process where reorderings introduced in the overall search are syntactically motivated (galley et al, 2004; quirk et al, 2005).<papid> P05-1034 </papid></citsent>
<aftsection>
<nextsent>thework presented here follows the word order harmonization strategy.
</nextsent>
<nextsent>53collins et al (2005) <papid> P05-1066 </papid>describe technique for preprocessing german to look more like english syn tactically.</nextsent>
<nextsent>they used six transformations that are applied on german parsed text to reorder it before passing it on to phrase-based system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1869">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they allow all possible learned reorderings to be used to create lattice that is input to the decoder, which further improves translation accuracy.
</prevsent>
<prevsent>similarly, costa-jussa` and fonollosa (2006)use statistical word classes to generalize reorderings, which are learned/introduced in translation process that transforms the source language into the target language word order.
</prevsent>
</prevsection>
<citsent citstr=" W07-0401 ">
zhang et al(2007) <papid> W07-0401 </papid>describe similar approach using un lexicalized context-free chunk tags (xps) to learn reordering rules for chinese-english smt.</citsent>
<aftsection>
<nextsent>crego and marino (2007c) extend their previous work using syntax trees (dependency parsing) to learn reorderings on chinese-english task.
</nextsent>
<nextsent>habash (2007) applies automatically-learned syntactic reordering rules (for arabic-english smt) to pre process the in put before passing it to phrase-based smt decoder.
</nextsent>
<nextsent>as in (zhang et al, 2007), (<papid> W07-0401 </papid>costa-jussa` and fonollosa, 2006) and (crego and marino, 2007b),we employ word graph for tight coupling between reordering and decoding.</nextsent>
<nextsent>however, we differ on the language pair (arabic-english) and the rules employed to learn reorderings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1871">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> arabic linguistic issues.  </section>
<citcontext>
<prevsection>
<prevsent>and the prepositionl+ of/for?, among others.
</prevsent>
<prevsent>we use the penn arabic treebank tokenization scheme which splits three classes of clitics only.
</prevsent>
</prevsection>
<citsent citstr=" N04-4038 ">
this scheme is compatible with the chunker we use (diab et al, 2004).<papid> N04-4038 </papid>secondly, arabic verb subjects may be: pro dropped (verb conjugated), pre-verbal (svo), orpost-verbal (vso).</citsent>
<aftsection>
<nextsent>the vso order is quite challenging in the context of translation to english.
</nextsent>
<nextsent>for small noun phrases (np), small phrase pairs in phrase table and some degree of distortion can easily move the verb to follow the np.
</nextsent>
<nextsent>but this becomes much less likely with very long nps that exceed the size of phrases in phrase table.finally, arabic adjectival modifiers typically follow their nouns (with small exception of some superlative adjectives).
</nextsent>
<nextsent>for example, rajul tawiyl (lit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1873">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> refinement of word alignments.  </section>
<citcontext>
<prevsection>
<prevsent>we propose an alignment refinement method to reduce the number of wrong alignments.
</prevsent>
<prevsent>the method employs two initial alignment sets: one with high precision, the other with high recall.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we use the intersection and union (och and ney, 2000) <papid> P00-1056 </papid>of both alignment directions2 as the high precision and high recall alignment sets, respectively.</citsent>
<aftsection>
<nextsent>we will study the effect of various initial alignment sets (such as grow-diag-final instead of union) in thefuture.
</nextsent>
<nextsent>the method is based on the fact that linguistic phrases (chunks), like raw words, have translation correspondences and can therefore be aligned.
</nextsent>
<nextsent>we use chunk information to reduce the number of allowed alignments forgiven word.
</nextsent>
<nextsent>the simple idea that words in source chunk are typically aligned to words in single possible target chunk is used to discard alignments which link words from2we use ibm-1 to ibm-5 models (brown et al, 1993) <papid> J93-2003 </papid>implemented with giza++ (och and ney, 2003).<papid> J03-1002 </papid>distant chunks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1874">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> refinement of word alignments.  </section>
<citcontext>
<prevsection>
<prevsent>the method is based on the fact that linguistic phrases (chunks), like raw words, have translation correspondences and can therefore be aligned.
</prevsent>
<prevsent>we use chunk information to reduce the number of allowed alignments forgiven word.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the simple idea that words in source chunk are typically aligned to words in single possible target chunk is used to discard alignments which link words from2we use ibm-1 to ibm-5 models (brown et al, 1993) <papid> J93-2003 </papid>implemented with giza++ (och and ney, 2003).<papid> J03-1002 </papid>distant chunks.</citsent>
<aftsection>
<nextsent>since limiting alignments to one-to one chunk links is perhaps too strict, we extend the number of allowed alignments by permitting words in chunk to be aligned to words in target range of words.
</nextsent>
<nextsent>this target range is computed as projection of the source chunk under consideration.
</nextsent>
<nextsent>the resulting refined set contains all the intersection alignments and some of the union.
</nextsent>
<nextsent>t1 t2 t3 t4 t5 t6 t7 t8 s3 s4 s5 s6 s7 s8 s9s1 s2 c2?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1875">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> refinement of word alignments.  </section>
<citcontext>
<prevsection>
<prevsent>the method is based on the fact that linguistic phrases (chunks), like raw words, have translation correspondences and can therefore be aligned.
</prevsent>
<prevsent>we use chunk information to reduce the number of allowed alignments forgiven word.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the simple idea that words in source chunk are typically aligned to words in single possible target chunk is used to discard alignments which link words from2we use ibm-1 to ibm-5 models (brown et al, 1993) <papid> J93-2003 </papid>implemented with giza++ (och and ney, 2003).<papid> J03-1002 </papid>distant chunks.</citsent>
<aftsection>
<nextsent>since limiting alignments to one-to one chunk links is perhaps too strict, we extend the number of allowed alignments by permitting words in chunk to be aligned to words in target range of words.
</nextsent>
<nextsent>this target range is computed as projection of the source chunk under consideration.
</nextsent>
<nextsent>the resulting refined set contains all the intersection alignments and some of the union.
</nextsent>
<nextsent>t1 t2 t3 t4 t5 t6 t7 t8 s3 s4 s5 s6 s7 s8 s9s1 s2 c2?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1879">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>language models are implemented using the srilm toolkit (stolcke, 2002).for arabic tokenization, we use the arabic treebank tokenization scheme: 4-way normalized segments into conjunction, particle, word and pronominal clitic.
</prevsent>
<prevsent>for pos tagging, we use the collapsed tagset for patb (24 tags).
</prevsent>
</prevsection>
<citsent citstr=" P05-1071 ">
tokenization and pos tagging are done using the publicly available morphological analysis and disambiguation of arabic (mada) tool (habash and rambow, 2005).<papid> P05-1071 </papid></citsent>
<aftsection>
<nextsent>for chunking arabic, we use the amira (asvmt) toolkit (diab et al, 2004).<papid> N04-4038 </papid></nextsent>
<nextsent>english preprocessing simply included down-casing, separating punctuation from words and splitting off s?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1882">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>for chunking arabic, we use the amira (asvmt) toolkit (diab et al, 2004).<papid> N04-4038 </papid></prevsent>
<prevsent>english preprocessing simply included down-casing, separating punctuation from words and splitting off s?.</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
the english side is pos-tagged with tnt(brants, 2000) <papid> A00-1031 </papid>and chunked with the freely available opennlp5 tools.</citsent>
<aftsection>
<nextsent>3http://www.ldc.upenn.edu 4the parallel text includes arabic news (ldc2004t17), etirr (ldc2004e72), english translation of arabic treebank (ldc2005e46), and ummah (ldc2004t18).
</nextsent>
<nextsent>5http://opennlp.sourceforge.net/we use the standard four-reference nist mte val datasets for the years 2003, 2004 and 2005 (henceforth mt03, mt04 and mt05, respectively)for testing and the 2002 dataset for tuning.6 bleu 4 (papineni et al, 2002), <papid> P02-1040 </papid>meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and multiple-reference word error rate scores are reported.</nextsent>
<nextsent>smt decoding is done using marie,7 freely available -gram-based decoder implementing beam search strategy with dis tortion/reordering capabilities (crego and marino,2007a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1883">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the english side is pos-tagged with tnt(brants, 2000) <papid> A00-1031 </papid>and chunked with the freely available opennlp5 tools.</prevsent>
<prevsent>3http://www.ldc.upenn.edu 4the parallel text includes arabic news (ldc2004t17), etirr (ldc2004e72), english translation of arabic treebank (ldc2005e46), and ummah (ldc2004t18).</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
5http://opennlp.sourceforge.net/we use the standard four-reference nist mte val datasets for the years 2003, 2004 and 2005 (henceforth mt03, mt04 and mt05, respectively)for testing and the 2002 dataset for tuning.6 bleu 4 (papineni et al, 2002), <papid> P02-1040 </papid>meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and multiple-reference word error rate scores are reported.</citsent>
<aftsection>
<nextsent>smt decoding is done using marie,7 freely available -gram-based decoder implementing beam search strategy with dis tortion/reordering capabilities (crego and marino,2007a).
</nextsent>
<nextsent>optimization is done with an in-house implementation of the simplex (nelder and mead, 1965) algorithm.
</nextsent>
<nextsent>7.2 results.
</nextsent>
<nextsent>in this section we assess the accuracy results of the techniques introduced in this paper for alignment refinement and word reordering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1884">
<title id=" W08-0307.xml">using shallow syntax information to improve word alignment and reordering for smt </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the english side is pos-tagged with tnt(brants, 2000) <papid> A00-1031 </papid>and chunked with the freely available opennlp5 tools.</prevsent>
<prevsent>3http://www.ldc.upenn.edu 4the parallel text includes arabic news (ldc2004t17), etirr (ldc2004e72), english translation of arabic treebank (ldc2005e46), and ummah (ldc2004t18).</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
5http://opennlp.sourceforge.net/we use the standard four-reference nist mte val datasets for the years 2003, 2004 and 2005 (henceforth mt03, mt04 and mt05, respectively)for testing and the 2002 dataset for tuning.6 bleu 4 (papineni et al, 2002), <papid> P02-1040 </papid>meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and multiple-reference word error rate scores are reported.</citsent>
<aftsection>
<nextsent>smt decoding is done using marie,7 freely available -gram-based decoder implementing beam search strategy with dis tortion/reordering capabilities (crego and marino,2007a).
</nextsent>
<nextsent>optimization is done with an in-house implementation of the simplex (nelder and mead, 1965) algorithm.
</nextsent>
<nextsent>7.2 results.
</nextsent>
<nextsent>in this section we assess the accuracy results of the techniques introduced in this paper for alignment refinement and word reordering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1885">
<title id=" W08-0704.xml">unsupervised word segmentation for sesotho using adaptor grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one can think of the prior as providing an infinite set of possible parameters, from which learner selects subset with which to model their language.if one pairs each of these infinitely-many parameters with possible structures (or equivalently,rules that generate such structures) then these non parametric bayesian learning methods can learn the structures relevant to language.
</prevsent>
<prevsent>determining whether methods such as these can in fact learn linguistic structure bears on the nature vs. nurture debates in language acquisition, since one of the arguments for the nativist position is that there doesnt seem to be way to learn structure from the input that children receive.
</prevsent>
</prevsection>
<citsent citstr=" P06-1085 ">
while theres no reason why these methods cant be used to learn the syntax and semantics of human languages, much of the work to date has focused onlower-level learning problems such as morphological structure learning (goldwater et al, 2006<papid> P06-1085 </papid>b) andword segmentation, where the learner is given unsegmented broad-phonemic utterance transcriptions 20 and has to identify the word boundaries (goldwater et al, 2006<papid> P06-1085 </papid>a; goldwater et al, 2007).</citsent>
<aftsection>
<nextsent>one reason forthis is that these problems seem simpler than learning syntax, where the non-linguistic context plausibly supplies important information to human learners.
</nextsent>
<nextsent>virtually everyone agrees that the set of possible morphemes and words, if not infinite, is astronomically large, so it seems plausible that humans use some kind of non parametric procedure to learn the lexicon.johnson et al (2007) introduced adaptor grammars as framework in which wide variety of linguistically-interesting non parametric inference problems can be formulated and evaluated, including number of variants of the models described by goldwater (2007).
</nextsent>
<nextsent>johnson (2008) presented variety of different adaptor grammar word segmentation models and applied them to the problem of segmenting brents phonemic ized version of the bernstein ratner corpus of child-directed english (bernstein ratner, 1987; brent, 1999).
</nextsent>
<nextsent>the main results of that paper were the following:1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1894">
<title id=" W08-0704.xml">unsupervised word segmentation for sesotho using adaptor grammars </title>
<section> adaptor grammars.  </section>
<citcontext>
<prevsection>
<prevsent>they are parametric models because each pcfg has fixed number of rules, each of which has numerical parameter associated with it.
</prevsent>
<prevsent>one way to construct non parametric bayesian models is to take parametric model class and let one or more of their components grow unboundedly.there are two obvious ways to construct nonpara metric models from pcfgs.
</prevsent>
</prevsection>
<citsent citstr=" D07-1072 ">
first, we can let the number of nonterminals grow unboundedly, as in the infinite pcfg, where the nonterminals of the grammar can be indefinitely refined versions of base pcfg (liang et al, 2007).<papid> D07-1072 </papid></citsent>
<aftsection>
<nextsent>second, we can fix the set of nonterminals but permit the number of rules or productions to grow unboundedly, which leads to adaptor grammars (johnson et al, 2007).
</nextsent>
<nextsent>at any point in learning, an adaptor grammar hasa finite set of rules, but these can grow unbound edly (typically logarithmically) with the size of the training data.
</nextsent>
<nextsent>in word-segmentation application these rules typically generate words or morphemes, so the learner is effectively learning the morphemes and words of its language.
</nextsent>
<nextsent>the new rules learnt by an adaptor grammar are 21 compositions of old ones (that can themselves be compositions of other rules), so its natural to think of these new rules as tree fragments, where each entire fragment is associated with its own probability.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1899">
<title id=" W07-2214.xml">pomset mcfgs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>researchers in parallel computing have explored the addition of con currency and free word order to context free languages, i.e. con currency context sensitivity (gis cher, 1981; warmuth and haussler, 1984; pratt,1985; pratt, 1986; lodaya and weil, 2000).
</prevsent>
<prevsent>computational linguist is have explored adding crossing dependency and discontinuous constituency, i.e. structural context sensitivity (seki et al, 1991; vijay-shanker et al, 1987; stabler, 1996).research considering the combination of two dimensions of expressing context sensitivity have been sparse, e.g.
</prevsent>
</prevsection>
<citsent citstr=" E91-1005 ">
(becker et al, 1991), <papid> E91-1005 </papid>with research dedicated to this topic virtually nonexistent.</citsent>
<aftsection>
<nextsent>natural languages are not well expressed by either form of context sensitivity alone.
</nextsent>
<nextsent>for example, in table 1,sentences 1-8 are valid, but 9, 10 are invalid constructions of norwegian.
</nextsent>
<nextsent>in addition to the crossing dependency between the determiner and adverb phrase, this example can be described by either derfor ga jens kari kyllingen tydeligvis ikke lenger kald therefore gave jens kari the chicken evidently not longer cold derfor ga jens kari tydeligvis kyllingen ikke lenger kald derfor ga jens tydeligvis kari kyllingen ikke lenger kald derfor ga jens tydeligvis kari ikke kyllingen lenger kald derfor ga jens tydeligvis kari ikke lenger kyllingen kald derfor ga jens tydeligvis ikke lenger kari kyllingen kald derfor ga tydeligvis jens ikke lenger kari kyllingen kald derfor ga tydeligvis ikke jens lenger kari kyllingen kald * derfor ga jens ikke tydeligvis kari lenger kyllingen kald * derfor ga jens ikke tydeligvis kyllingen lenger kari kald table 1: bobaljiks paradox/shape conservation example bobaljiks paradox (bobaljik, 1999), which asserts that relative ordering of clausal constituents are not unambiguously determined by the phrase structure,or shape conservation (muller, 2000), i.e. that linear precedence is preserved despite movement operations.
</nextsent>
<nextsent>in other words, the two structurally context sensitive components (due to the crossing dependency between them) can be shuffled arbitrarily, leading to concurrent context sensitivity.this paper proposes pomset mcfgs as formalism for perspicuously expressing both types of context sensitivity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1901">
<title id=" W08-0312.xml">meteor mbleu and mter evaluation metrics for high correlation with human rankings of machine translation output </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic metrics for mt evaluation have been receiving significant attention in recent years.
</prevsent>
<prevsent>evaluating an mt system using such automatic metrics is much faster, easier and cheaper compared to human evaluations, which require trained bilingual evaluators.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the most commonly used mt evaluation metric in recent years has been ibms bleu metric (pa pineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>bleu is fast and easy to run, and it can be used as target function in parameter optimization training procedures that are commonly used in state-of-the-art statistical mt systems (och,2003).<papid> P03-1021 </papid></nextsent>
<nextsent>various researchers have noted, however, various weaknesses in the metric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1902">
<title id=" W08-0312.xml">meteor mbleu and mter evaluation metrics for high correlation with human rankings of machine translation output </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluating an mt system using such automatic metrics is much faster, easier and cheaper compared to human evaluations, which require trained bilingual evaluators.
</prevsent>
<prevsent>the most commonly used mt evaluation metric in recent years has been ibms bleu metric (pa pineni et al, 2002).<papid> P02-1040 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
bleu is fast and easy to run, and it can be used as target function in parameter optimization training procedures that are commonly used in state-of-the-art statistical mt systems (och,2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>various researchers have noted, however, various weaknesses in the metric.
</nextsent>
<nextsent>most notably, bleu does not produce very reliable sentence-level scores.
</nextsent>
<nextsent>meteor , as well as several other proposed metrics such as gtm (melamed et al, 2003), <papid> N03-2021 </papid>ter (snover et al, 2006) and cder (leusch et al, 2006) <papid> E06-1031 </papid>aim to address some of these weaknesses.</nextsent>
<nextsent>meteor , initially proposed and released in 2004(lavie et al, 2004) was explicitly designed to improve correlation with human judgments of mt quality at the segment level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1903">
<title id=" W08-0312.xml">meteor mbleu and mter evaluation metrics for high correlation with human rankings of machine translation output </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>various researchers have noted, however, various weaknesses in the metric.
</prevsent>
<prevsent>most notably, bleu does not produce very reliable sentence-level scores.
</prevsent>
</prevsection>
<citsent citstr=" N03-2021 ">
meteor , as well as several other proposed metrics such as gtm (melamed et al, 2003), <papid> N03-2021 </papid>ter (snover et al, 2006) and cder (leusch et al, 2006) <papid> E06-1031 </papid>aim to address some of these weaknesses.</citsent>
<aftsection>
<nextsent>meteor , initially proposed and released in 2004(lavie et al, 2004) was explicitly designed to improve correlation with human judgments of mt quality at the segment level.
</nextsent>
<nextsent>previous publications on meteor (lavie et al, 2004; banerjee and lavie, 2005; <papid> W05-0909 </papid>lavie and agarwal, 2007) <papid> W07-0734 </papid>have described the details underlying the metric and have extensively compared its performance with bleu and several other mt evaluation metrics.</nextsent>
<nextsent>in (lavie and agarwal, 2007), <papid> W07-0734 </papid>we described the process of tuning free parameters within the metric to optimize the correlation with human judgments and the extension of the metric for evaluating translations in languages other than english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1904">
<title id=" W08-0312.xml">meteor mbleu and mter evaluation metrics for high correlation with human rankings of machine translation output </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>various researchers have noted, however, various weaknesses in the metric.
</prevsent>
<prevsent>most notably, bleu does not produce very reliable sentence-level scores.
</prevsent>
</prevsection>
<citsent citstr=" E06-1031 ">
meteor , as well as several other proposed metrics such as gtm (melamed et al, 2003), <papid> N03-2021 </papid>ter (snover et al, 2006) and cder (leusch et al, 2006) <papid> E06-1031 </papid>aim to address some of these weaknesses.</citsent>
<aftsection>
<nextsent>meteor , initially proposed and released in 2004(lavie et al, 2004) was explicitly designed to improve correlation with human judgments of mt quality at the segment level.
</nextsent>
<nextsent>previous publications on meteor (lavie et al, 2004; banerjee and lavie, 2005; <papid> W05-0909 </papid>lavie and agarwal, 2007) <papid> W07-0734 </papid>have described the details underlying the metric and have extensively compared its performance with bleu and several other mt evaluation metrics.</nextsent>
<nextsent>in (lavie and agarwal, 2007), <papid> W07-0734 </papid>we described the process of tuning free parameters within the metric to optimize the correlation with human judgments and the extension of the metric for evaluating translations in languages other than english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1905">
<title id=" W08-0312.xml">meteor mbleu and mter evaluation metrics for high correlation with human rankings of machine translation output </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>meteor , as well as several other proposed metrics such as gtm (melamed et al, 2003), <papid> N03-2021 </papid>ter (snover et al, 2006) and cder (leusch et al, 2006) <papid> E06-1031 </papid>aim to address some of these weaknesses.</prevsent>
<prevsent>meteor , initially proposed and released in 2004(lavie et al, 2004) was explicitly designed to improve correlation with human judgments of mt quality at the segment level.</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
previous publications on meteor (lavie et al, 2004; banerjee and lavie, 2005; <papid> W05-0909 </papid>lavie and agarwal, 2007) <papid> W07-0734 </papid>have described the details underlying the metric and have extensively compared its performance with bleu and several other mt evaluation metrics.</citsent>
<aftsection>
<nextsent>in (lavie and agarwal, 2007), <papid> W07-0734 </papid>we described the process of tuning free parameters within the metric to optimize the correlation with human judgments and the extension of the metric for evaluating translations in languages other than english.</nextsent>
<nextsent>this paper provides brief technical description of meteor and describes our experiments in re-tuning the metric for improving correlation with the human rankings of translation hypotheses corresponding toa single source sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1907">
<title id=" W08-0312.xml">meteor mbleu and mter evaluation metrics for high correlation with human rankings of machine translation output </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>meteor , as well as several other proposed metrics such as gtm (melamed et al, 2003), <papid> N03-2021 </papid>ter (snover et al, 2006) and cder (leusch et al, 2006) <papid> E06-1031 </papid>aim to address some of these weaknesses.</prevsent>
<prevsent>meteor , initially proposed and released in 2004(lavie et al, 2004) was explicitly designed to improve correlation with human judgments of mt quality at the segment level.</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
previous publications on meteor (lavie et al, 2004; banerjee and lavie, 2005; <papid> W05-0909 </papid>lavie and agarwal, 2007) <papid> W07-0734 </papid>have described the details underlying the metric and have extensively compared its performance with bleu and several other mt evaluation metrics.</citsent>
<aftsection>
<nextsent>in (lavie and agarwal, 2007), <papid> W07-0734 </papid>we described the process of tuning free parameters within the metric to optimize the correlation with human judgments and the extension of the metric for evaluating translations in languages other than english.</nextsent>
<nextsent>this paper provides brief technical description of meteor and describes our experiments in re-tuning the metric for improving correlation with the human rankings of translation hypotheses corresponding toa single source sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1913">
<title id=" W08-0312.xml">meteor mbleu and mter evaluation metrics for high correlation with human rankings of machine translation output </title>
<section> extending bleu and ter with.  </section>
<citcontext>
<prevsection>
<prevsent>finally, the meteor score for the alignment between the two strings is calculated as: score = (1 ? pen) ? fmean the free parameters in the metric, ?, ? and ? are tuned to achieve maximum correlation with the human judgments as described in (lavie and agarwal, 2007).<papid> W07-0734 </papid></prevsent>
<prevsent>flexible matching many widely used metrics like bleu (papineni et al, 2002) <papid> P02-1040 </papid>and ter (snover et al, 2006) are based on measuring string level similarity between the reference translation and translation hypothesis, just like meteor . most of them, however, depend on finding exact matches between the words in two strings.</prevsent>
</prevsection>
<citsent citstr=" P06-2070 ">
many researchers (banerjee and lavie, 2005; <papid> W05-0909 </papid>liu andgildea, 2006), <papid> P06-2070 </papid>have observed consistent gains by using more flexible matching criteria.</citsent>
<aftsection>
<nextsent>in the following experiments, we extend the bleu and ter metric sto use the stemming and wordnet based word mapping modules from meteor . given translation hypothesis and reference pair, we first align them using the word mapping modules from meteor . we then rewrite the reference translation by replacing the matched words with the corresponding words in the translation hypothesis.
</nextsent>
<nextsent>wenow compute bleu and ter with these new references without changing anything inside the metrics.
</nextsent>
<nextsent>to get meaningful bleu scores at segment level, we compute smoothed bleu as described in (lin and och, 2004).<papid> C04-1072 </papid></nextsent>
<nextsent>(callison-burch et al, 2007) reported that the inter coder agreement on the task of assigning ranks to given set of candidate hypotheses is much better than the interco der agreement on the task of assigning score to hypothesis in isolation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1914">
<title id=" W08-0312.xml">meteor mbleu and mter evaluation metrics for high correlation with human rankings of machine translation output </title>
<section> extending bleu and ter with.  </section>
<citcontext>
<prevsection>
<prevsent>in the following experiments, we extend the bleu and ter metric sto use the stemming and wordnet based word mapping modules from meteor . given translation hypothesis and reference pair, we first align them using the word mapping modules from meteor . we then rewrite the reference translation by replacing the matched words with the corresponding words in the translation hypothesis.
</prevsent>
<prevsent>wenow compute bleu and ter with these new references without changing anything inside the metrics.
</prevsent>
</prevsection>
<citsent citstr=" C04-1072 ">
to get meaningful bleu scores at segment level, we compute smoothed bleu as described in (lin and och, 2004).<papid> C04-1072 </papid></citsent>
<aftsection>
<nextsent>(callison-burch et al, 2007) reported that the inter coder agreement on the task of assigning ranks to given set of candidate hypotheses is much better than the interco der agreement on the task of assigning score to hypothesis in isolation.
</nextsent>
<nextsent>based on that finding, in wmt-08, only ranking judgments are being collected from the human judges.
</nextsent>
<nextsent>the current version of meteor uses parameters optimized towards maximizing the pearsons correlation with human judgments of adequacy scores.
</nextsent>
<nextsent>itis not clear that the same parameters would be optimal for correlation with human rankings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1915">
<title id=" W08-0312.xml">meteor mbleu and mter evaluation metrics for high correlation with human rankings of machine translation output </title>
<section> re-tuning meteor for rankings.  </section>
<citcontext>
<prevsection>
<prevsent>the cycles in the graph are broken by assigning same rank to all the nodes in the cycle.
</prevsent>
<prevsent>4.2 measuring correlation.
</prevsent>
</prevsection>
<citsent citstr=" W07-0736 ">
following (ye et al, 2007), <papid> W07-0736 </papid>we first compute the spearman correlation between the human rankings and meteor rankings of the translation hypotheses corresponding to single source sentence.</citsent>
<aftsection>
<nextsent>let be the number of translation hypotheses and be the difference in ranks assigned to hypothesis by two rankings, then spearman correlation is given by: = 1?
</nextsent>
<nextsent>6 ? d2 n(n2 ? 1) the final score for the metric is the average of the spearman correlations for individual sentences.
</nextsent>
<nextsent>5.1 data.
</nextsent>
<nextsent>we use the human judgment data from wmt-07which was released as development data for the evaluation shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1916">
<title id=" W07-2047.xml">lccwsd system description for english coarse grained all words task at semeval 2007 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word sense disambiguation is not useful if it is not performed with high accuracy (sanderson, 1994).
</prevsent>
<prevsent>a coarse grained set of sense gives the opportunity to make more precise sense distinction and to make word sense disambiguation system more useful to other tasks.our goal at semeval 2007 was to measure the performance of known supervised machine learning algorithm using coarse grained senses.
</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
the idea of using supervised machine learning for wsd is not new and was used for example in (ng and lee, 1996).<papid> P96-1006 </papid></citsent>
<aftsection>
<nextsent>we made experiments with two supervised methods:maximum entropy (me) and support vector machines (svm).
</nextsent>
<nextsent>these supervised algorithms were used with topical, syntactic and semantic features.we trained classifier for each word using both supervised algorithms.
</nextsent>
<nextsent>new features were added in3 incremental steps.
</nextsent>
<nextsent>after an initial set of experiments the algorithm performance was enhanced using greedy feature selection algorithm similar to one in (mihalcea, 2002).<papid> C02-1039 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1917">
<title id=" W07-2047.xml">lccwsd system description for english coarse grained all words task at semeval 2007 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these supervised algorithms were used with topical, syntactic and semantic features.we trained classifier for each word using both supervised algorithms.
</prevsent>
<prevsent>new features were added in3 incremental steps.
</prevsent>
</prevsection>
<citsent citstr=" C02-1039 ">
after an initial set of experiments the algorithm performance was enhanced using greedy feature selection algorithm similar to one in (mihalcea, 2002).<papid> C02-1039 </papid></citsent>
<aftsection>
<nextsent>in order to increase the number of training instances, we tried to use the disambiguated wordnet glosses from xwn project(xwn, 2003).
</nextsent>
<nextsent>combining other corpora with dis ambiguated glosses from xwn did not provide any improvement so we used xwn as fall back strategy for 70 words that did not have any training examples in other corpora but xwn.
</nextsent>
<nextsent>section 2 describes the supervised methods used by our wsd system, the pre-processing module andthe set of features.
</nextsent>
<nextsent>section 3 presents the experiments we performed and their results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1919">
<title id=" W07-2047.xml">lccwsd system description for english coarse grained all words task at semeval 2007 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the preprocessing module perform the following steps:   tokenization: using an in house text tokenizer   named entity recognition: using an in house system   part of speech tagging: normally we use the brill tagger, but we took advantage of the part of speech tags given in the test file   wordnet look-up to check if the word exists in wordnet and to get its lemma, possible part of speech for that lemma and if the word has single sense or not.
</prevsent>
<prevsent>for semeval english coarse all words task we took advantage by the lemma provided in the test file.
</prevsent>
</prevsection>
<citsent citstr=" P06-2038 ">
compound concept detection: using classifier based on wordnet  syntactic parsing: using an in-house implementation of collins parser (glaysher and moldovan, 2006)<papid> P06-2038 </papid>the maximum entropy classifier is c++ implementation found on web (le, 2006).</citsent>
<aftsection>
<nextsent>the classifier was adapted to accept symbolic features for classification tasks in natural language processing.
</nextsent>
<nextsent>for training svm classifiers we used libsvmpackage (chang and lin, 2001).
</nextsent>
<nextsent>each symbolic feature can have single value from finite set of values or can be assigned subset of values from the set of all possible values.
</nextsent>
<nextsent>for each value we created mapping between the feature value and dimension in the n-dimensional classification space and we assigned the number 1.0 to that dimension if the feature had the corresponding value or 0.0 otherwise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1923">
<title id=" W07-2045.xml">lccsrn lccs srn system for semeval 2007 task 4 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the system consists of two types of classifiers: classifiers that do not use the syntactic parsed tree and that were built specifically for the semeval 2007 task 4(srn) and classifiers that use specific.
</prevsent>
<prevsent>syntactic pattern to determine the semantic relations and there were previously developed at lcc and then adapted to the srn task (srnpat).
</prevsent>
</prevsection>
<citsent citstr=" H05-1112 ">
the classifiers for each type were built from annotated examples using supervised machine learning algorithms like decision trees (dt)1, support vector machines (svm) 2 , semantic scattering (ss) (moldovan and badulescu, 2005) , <papid> H05-1112 </papid>iterative semantic specialization (iss) (girju, badulescu, and moldovan, 2006), nave bayes (nb) 3 and maximum entropy (me)4.</citsent>
<aftsection>
<nextsent>the outputs of different classifiers (built using different types of machine learning algorithms were combined and ranked using predefined rules.
</nextsent>
<nextsent>figure 1 shows the architecture of our srn system.
</nextsent>
<nextsent>1 c5.0., http://www.rulequest.com/see5-info.html 2 libsvm, www.csie.ntu.edu.tw/~cjlin/libsvm/ 3 jbnc, http://jbnc.sourceforge.net 4 http://homepages.inf.ed.ac.uk/s0450736/maxent_tool kit.html 215 pr pr c es annotated tree text processing tools cl s si fic tio [arg1, arg2, relation, score,classifier] [nparg1, nparg2, relation, score, classifier] srn rel=1, ..7, all rel1, ?, rel7, or nul dt sv me srnpat pat=1-m rel=1, ..,7, all rel1, ?, rel7, or nul dt svss iss fe tu re feature extraction featuresetssrn [arg1arg2pattern, arg1, arg2] featuresetssrnpat [pattern, nparg1, nparg2] se le tio relation selection [arg1, arg2, relation, score] sentences annotations pa tte rn [pattern, nparg1, nparg2] pattern matching [arg1arg2pattern, arg1, arg2] argument detection u tp t generate output rel1: sentid value rel7: sentid value?
</nextsent>
<nextsent>pr pr c es pr pr c es cl s si fic tio cl s si fic tio fe tu re fe tu re se le tio se le tio pa tte rn pa tte rn o tp t figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1924">
<title id=" W08-0303.xml">discriminative word alignment via alignment matrix modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these corpora are of ten aligned at the sentence level, but to use them in the systems in most cases word alignment is needed.
</prevsent>
<prevsent>therefore, forgiven source sentence fj1 and given target sentence ei1 set of links (j, i) has to be found, which describes which source word fj is translated into which target word ei.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
most smt systems use the freely available giza++-toolkit to generate the word alignment.this toolkit implements the ibm- and hmm models introduced in (brown et al, 1993; vogel et al., 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>they have the advantage that they are trained unsupervised and are well suited for noisy channel approach.
</nextsent>
<nextsent>but it is difficult to include additional features into these models.
</nextsent>
<nextsent>in recent years several authors (moore et al, 2006; <papid> P06-1065 </papid>lacoste-julien et al, 2006; blunsom andcohn, 2006) <papid> P06-1009 </papid>proposed discriminative word alignment frameworks and showed that this leads to improved alignment quality.</nextsent>
<nextsent>in contrast to generative models, these models need small amount of hand aligned data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1925">
<title id=" W08-0303.xml">discriminative word alignment via alignment matrix modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they have the advantage that they are trained unsupervised and are well suited for noisy channel approach.
</prevsent>
<prevsent>but it is difficult to include additional features into these models.
</prevsent>
</prevsection>
<citsent citstr=" P06-1065 ">
in recent years several authors (moore et al, 2006; <papid> P06-1065 </papid>lacoste-julien et al, 2006; blunsom andcohn, 2006) <papid> P06-1009 </papid>proposed discriminative word alignment frameworks and showed that this leads to improved alignment quality.</citsent>
<aftsection>
<nextsent>in contrast to generative models, these models need small amount of hand aligned data.
</nextsent>
<nextsent>but it is easy to add features to these models, so all available knowledge sources can be used to find the best alignment.the discriminative model presented in this paper uses conditional random field (crf) to model the alignment matrix.
</nextsent>
<nextsent>by modeling the matrix no restrictions to the alignment are required and even n:m alignments can be generated.
</nextsent>
<nextsent>furthermore, this makes the model symmetric, so the model will produce the same alignment no matter which language is selected as source and which as target language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1926">
<title id=" W08-0303.xml">discriminative word alignment via alignment matrix modeling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they have the advantage that they are trained unsupervised and are well suited for noisy channel approach.
</prevsent>
<prevsent>but it is difficult to include additional features into these models.
</prevsent>
</prevsection>
<citsent citstr=" P06-1009 ">
in recent years several authors (moore et al, 2006; <papid> P06-1065 </papid>lacoste-julien et al, 2006; blunsom andcohn, 2006) <papid> P06-1009 </papid>proposed discriminative word alignment frameworks and showed that this leads to improved alignment quality.</citsent>
<aftsection>
<nextsent>in contrast to generative models, these models need small amount of hand aligned data.
</nextsent>
<nextsent>but it is easy to add features to these models, so all available knowledge sources can be used to find the best alignment.the discriminative model presented in this paper uses conditional random field (crf) to model the alignment matrix.
</nextsent>
<nextsent>by modeling the matrix no restrictions to the alignment are required and even n:m alignments can be generated.
</nextsent>
<nextsent>furthermore, this makes the model symmetric, so the model will produce the same alignment no matter which language is selected as source and which as target language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1927">
<title id=" W08-0303.xml">discriminative word alignment via alignment matrix modeling </title>
<section> the model.  </section>
<citcontext>
<prevsection>
<prevsent>a crf is an unidirectional graphical model.
</prevsent>
<prevsent>it models the conditional distribution over random variables.
</prevsent>
</prevsection>
<citsent citstr=" I05-3027 ">
in most applications like (tseng et al, 2005; <papid> I05-3027 </papid>sha and pereira, 2003), <papid> N03-1028 </papid>sequential model isused.</citsent>
<aftsection>
<nextsent>but to model the alignment matrix the graphical structure of the model is more complex.
</nextsent>
<nextsent>the alignment matrix is described by random variable yji for every source and target word pair (fj , ei).
</nextsent>
<nextsent>these variables can have two values, 0and 1, indicating whether these words are translations of each other or not.
</nextsent>
<nextsent>an example is shown in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1928">
<title id=" W08-0303.xml">discriminative word alignment via alignment matrix modeling </title>
<section> the model.  </section>
<citcontext>
<prevsection>
<prevsent>a crf is an unidirectional graphical model.
</prevsent>
<prevsent>it models the conditional distribution over random variables.
</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
in most applications like (tseng et al, 2005; <papid> I05-3027 </papid>sha and pereira, 2003), <papid> N03-1028 </papid>sequential model isused.</citsent>
<aftsection>
<nextsent>but to model the alignment matrix the graphical structure of the model is more complex.
</nextsent>
<nextsent>the alignment matrix is described by random variable yji for every source and target word pair (fj , ei).
</nextsent>
<nextsent>these variables can have two values, 0and 1, indicating whether these words are translations of each other or not.
</nextsent>
<nextsent>an example is shown in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1929">
<title id=" W08-0303.xml">discriminative word alignment via alignment matrix modeling </title>
<section> training.  </section>
<citcontext>
<prevsection>
<prevsent>to be able to use gradient descent method to optimize the weights,the derivation of the word alignment metric with respect to these weights must be computed.
</prevsent>
<prevsent>this can not be done for the mentioned metrics since they are not smooth functions.
</prevsent>
</prevsection>
<citsent citstr=" P06-1028 ">
we follow (gao et al, 2006;suzuki et al, 2006) <papid> P06-1028 </papid>and approximate the metrics using the sigmoid function.</citsent>
<aftsection>
<nextsent>the sigmoid function usesthe probabilities for every link calculated by the belief propagation algorithm.
</nextsent>
<nextsent>in our experiments we compared the maximum likelihood method and the optimization towards the aer.
</nextsent>
<nextsent>we also tested combinations of both.
</nextsent>
<nextsent>the best results were obtained when the weights were first trained using the ml method and the resulting factors were used as initial values for the aer optimization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1930">
<title id=" W08-0303.xml">discriminative word alignment via alignment matrix modeling </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the so called final text edition of the european parliament pro ceedings?
</prevsent>
<prevsent>consisting of 1.4 million sentences and this hand-aligned data was used as training corpus.
</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
the pos-tags were generated by the brill-tagger (brill, 1995) <papid> J95-4004 </papid>and the freeling-tagger (asterias etal., 2006) for the english and the spanish text re spectively.</citsent>
<aftsection>
<nextsent>to limit the number of different tags for spanish we grouped them according to the first 2 characters in the tag names.
</nextsent>
<nextsent>a second group of experiments was done on an english-french text.
</nextsent>
<nextsent>the data from the 2003 naacl shared task (mihalcea and pedersen, 2003)<papid> W03-0301 </papid>was used.</nextsent>
<nextsent>this data consists of 1.1 million sentences, validation set of 37 sentences and test set of 447 sentences, which have been hand-aligned (och and ney, 2003).<papid> J03-1002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1931">
<title id=" W08-0303.xml">discriminative word alignment via alignment matrix modeling </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to limit the number of different tags for spanish we grouped them according to the first 2 characters in the tag names.
</prevsent>
<prevsent>a second group of experiments was done on an english-french text.
</prevsent>
</prevsection>
<citsent citstr=" W03-0301 ">
the data from the 2003 naacl shared task (mihalcea and pedersen, 2003)<papid> W03-0301 </papid>was used.</citsent>
<aftsection>
<nextsent>this data consists of 1.1 million sentences, validation set of 37 sentences and test set of 447 sentences, which have been hand-aligned (och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>for the english pos-tags again the brill tagger was used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1932">
<title id=" W08-0303.xml">discriminative word alignment via alignment matrix modeling </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>a second group of experiments was done on an english-french text.
</prevsent>
<prevsent>the data from the 2003 naacl shared task (mihalcea and pedersen, 2003)<papid> W03-0301 </papid>was used.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
this data consists of 1.1 million sentences, validation set of 37 sentences and test set of 447 sentences, which have been hand-aligned (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>for the english pos-tags again the brill tagger was used.
</nextsent>
<nextsent>for the french side, the tree tagger (schmid, 1994) was used.finally, to test our alignment approach with languages that differ more in structure chinese english task was selected.
</nextsent>
<nextsent>as hand-aligned data 3160 sentences aligned only with sure links were used (ldc2006e93).
</nextsent>
<nextsent>this was split up into 2000sentences of test data and 1160 sentences of development data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1934">
<title id=" W08-0303.xml">discriminative word alignment via alignment matrix modeling </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the giza++-toolkit was used to train baseline system.
</prevsent>
<prevsent>the models and alignment information were then used as additional knowledge source for the discriminative word alignment.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
for the first two tasks, all heuristics of the pharaoh-toolkit (koehn et al, 2003) <papid> N03-1017 </papid>as well as the refined heuristic (och and ney, 2003) <papid> J03-1002 </papid>to combine both ibm4-alignments were tested and the best ones are shown in the tables.</citsent>
<aftsection>
<nextsent>for the chinese task only the grow-diag-final heuristic was used.
</nextsent>
<nextsent>22 table 1: aer-results on en-es task name dev test ibm4 source-target 21.49 ibm4 target-source 19.23 ibm4 grow-diag 16.48 dwa ibm1 15.26 20.82 + ibm4 14.23 18.67 + giza-fert.
</nextsent>
<nextsent>13.28 18.02 + link feature 12.26 15.97 + pos 9.21 15.36 + phrase feature 8.84 14.77 table 2: aer-results on en-fr task name dev test ibm4 source-target 8.6 ibm4 target-source 9.86 ibm4 intersection 5.38 dwa ibm1 5.54 6.37 + hfrq/pos 3.67 5.57 + link feature 3.13 4.80 + ibm4 3.60 4.60 + phrase feature 3.32 4.30the results measured in aer of the discriminative word alignment for the english-spanish task are shown in table 1.
</nextsent>
<nextsent>in the experiments systems using different knowledge sources were evaluated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1937">
<title id=" W08-0303.xml">discriminative word alignment via alignment matrix modeling </title>
<section> comparison to other work.  </section>
<citcontext>
<prevsection>
<prevsent>they reached an aer of 5.29 using the ibm4-alignment on the english-french task (compared to 4.30 of our approach).
</prevsent>
<prevsent>lacoste-julien et al (2006) enriched the bipartite matching problem to model also larger fertilities and first-or der dependencies.
</prevsent>
</prevsection>
<citsent citstr=" N06-1014 ">
they could reach an aer of 3.8 on the same task, but only if they also included the posteriors of the model of liang et al (2006).<papid> N06-1014 </papid></citsent>
<aftsection>
<nextsent>using only the ibm4-alignment they generated an alignment with an aer of 4.5.
</nextsent>
<nextsent>but they did not use any pos-based features in their experiments.
</nextsent>
<nextsent>finally, moore et al (2006) <papid> P06-1065 </papid>used log-linear model for the features and performed beam search.</nextsent>
<nextsent>they could reach an aer as low as 3.7 with both types of alignment information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1939">
<title id=" W07-0729.xml">the noisier channel translation from morphologically complex languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while the variously inflected forms of one lemma may express differences in meaning that are crucial to correct translation, the strict independence assumptions normally made exacerbate data sparseness and lead to poorly estimated models and sub optimal translations.
</prevsent>
<prevsent>a variety of solutions have been proposed: niessen andney (2001) use of morphological information to improve word reordering before training and after decoding.
</prevsent>
</prevsection>
<citsent citstr=" H05-1085 ">
goldwater and mcclosky (2005) <papid> H05-1085 </papid>show improvements in czech to english word-based translation system when inflectional endings are simplified or removed entirely.</citsent>
<aftsection>
<nextsent>their method can, how ever, actually harm performance since the discarded morphemes carry some information that may have bearing on the translation (cf.
</nextsent>
<nextsent>section 3.3).
</nextsent>
<nextsent>to avoid this pitfall, talbot and osborne (2006) <papid> P06-1122 </papid>use data driven approach to cluster source-language morphological variants that are meaningless in the target language, and yang and kirchhoff (2006) <papid> E06-1006 </papid>propose the use of backoff model that uses morphologically reduced forms only when the translation of the surface form is unavailable.</nextsent>
<nextsent>all of these approaches have in common that the decisions about whether to use morphological information are made in either pre- or post-processing step.recent work in spoken language translation suggests that allowing decisions about the use of morphological information to be made along side other translation decisions (i.e., inside the decoder), will yield better results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1942">
<title id=" W07-0729.xml">the noisier channel translation from morphologically complex languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their method can, how ever, actually harm performance since the discarded morphemes carry some information that may have bearing on the translation (cf.
</prevsent>
<prevsent>section 3.3).
</prevsent>
</prevsection>
<citsent citstr=" P06-1122 ">
to avoid this pitfall, talbot and osborne (2006) <papid> P06-1122 </papid>use data driven approach to cluster source-language morphological variants that are meaningless in the target language, and yang and kirchhoff (2006) <papid> E06-1006 </papid>propose the use of backoff model that uses morphologically reduced forms only when the translation of the surface form is unavailable.</citsent>
<aftsection>
<nextsent>all of these approaches have in common that the decisions about whether to use morphological information are made in either pre- or post-processing step.recent work in spoken language translation suggests that allowing decisions about the use of morphological information to be made along side other translation decisions (i.e., inside the decoder), will yield better results.
</nextsent>
<nextsent>at least as early as ney (1999),it has been shown that when translating the output from automatic speech regonition (asr) systems, the quality can be improved by considering multiple (rather than only single best) transcription hypothesis.
</nextsent>
<nextsent>although state-of-the-art statistical machine translation systems have conventionally assumed unambiguous input; recent work has demonstrated the possibility of efficient decoding of am 207 biguous input (represented as confusion networks or word lattices) within standard phrase-based models(bertoldi et al, to appear 2007) as well as hierarchical phrase-based models (dyer and resnik, 2007).
</nextsent>
<nextsent>these hybrid decoders search for the target language sentence e?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1943">
<title id=" W07-0729.xml">the noisier channel translation from morphologically complex languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their method can, how ever, actually harm performance since the discarded morphemes carry some information that may have bearing on the translation (cf.
</prevsent>
<prevsent>section 3.3).
</prevsent>
</prevsection>
<citsent citstr=" E06-1006 ">
to avoid this pitfall, talbot and osborne (2006) <papid> P06-1122 </papid>use data driven approach to cluster source-language morphological variants that are meaningless in the target language, and yang and kirchhoff (2006) <papid> E06-1006 </papid>propose the use of backoff model that uses morphologically reduced forms only when the translation of the surface form is unavailable.</citsent>
<aftsection>
<nextsent>all of these approaches have in common that the decisions about whether to use morphological information are made in either pre- or post-processing step.recent work in spoken language translation suggests that allowing decisions about the use of morphological information to be made along side other translation decisions (i.e., inside the decoder), will yield better results.
</nextsent>
<nextsent>at least as early as ney (1999),it has been shown that when translating the output from automatic speech regonition (asr) systems, the quality can be improved by considering multiple (rather than only single best) transcription hypothesis.
</nextsent>
<nextsent>although state-of-the-art statistical machine translation systems have conventionally assumed unambiguous input; recent work has demonstrated the possibility of efficient decoding of am 207 biguous input (represented as confusion networks or word lattices) within standard phrase-based models(bertoldi et al, to appear 2007) as well as hierarchical phrase-based models (dyer and resnik, 2007).
</nextsent>
<nextsent>these hybrid decoders search for the target language sentence e?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1944">
<title id=" W07-0729.xml">the noisier channel translation from morphologically complex languages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these hybrid decoders search for the target language sentence e?
</prevsent>
<prevsent>that maximizes the following probability,where g(o) represents the set of weighted transcription hypotheses produced by an asr decoder: e?
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
= argmax max g(o) (e, ?|o) (1)the conditional probability p(e, |o) that is maximized is modeled directly using log-linear model (och and ney, 2002), <papid> P02-1038 </papid>whose parameters can betuned to optimize either the probability of development set or some other objective (such as maximizing bleu).</citsent>
<aftsection>
<nextsent>in addition to the standard translation model features, the asr systems posterior probability is another feature.
</nextsent>
<nextsent>the decoder thus finds translation hypothesis e?
</nextsent>
<nextsent>that maximizes the joint translation/transcription probability, which is not necessarily the one that corresponds to the best single transcription hypothesis.
</nextsent>
<nextsent>we extend the concept of translating from an ambiguous set of source hypotheses to the domain of text translation by redefining g(?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1945">
<title id=" W07-0729.xml">the noisier channel translation from morphologically complex languages </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>re casing was carried out using sris disambig tool using trigram language model.
</prevsent>
<prevsent>the feature set used included bidirectional translation probabilities for rules, lexical translation probabilities, target language model probability, and count features for target words, number of non-terminal symbols used, and finally the number of morphologically simplified forms selected in the cn.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
feature weight tuning was carried out using minimum error rate training, maximizing bleu scores on held-out development set (och,2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>translation scores are reported using case insensitive bleu (papineni et al, 2002) <papid> P02-1040 </papid>with single reference translation.</nextsent>
<nextsent>significance testing was done using bootstrap re sampling (koehn, 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1946">
<title id=" W07-0729.xml">the noisier channel translation from morphologically complex languages </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the feature set used included bidirectional translation probabilities for rules, lexical translation probabilities, target language model probability, and count features for target words, number of non-terminal symbols used, and finally the number of morphologically simplified forms selected in the cn.
</prevsent>
<prevsent>feature weight tuning was carried out using minimum error rate training, maximizing bleu scores on held-out development set (och,2003).<papid> P03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
translation scores are reported using case insensitive bleu (papineni et al, 2002) <papid> P02-1040 </papid>with single reference translation.</citsent>
<aftsection>
<nextsent>significance testing was done using bootstrap re sampling (koehn, 2004).
</nextsent>
<nextsent>4.2 data preparation and training.
</nextsent>
<nextsent>we used czech morphological analyzer by hajic?
</nextsent>
<nextsent>and hladka?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1955">
<title id=" W07-2070.xml">tkbuo using sense clustering for wsd </title>
<section> the disambiguation algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>next subsections describe in detail each component of the whole process.
</prevsent>
<prevsent>2.1 sense representation.
</prevsent>
</prevsection>
<citsent citstr=" C00-1072 ">
for clustering purposes, word senses are represented as topic signatures (lin and hovy, 2000).<papid> C00-1072 </papid></citsent>
<aftsection>
<nextsent>thus, for each word sense we define vector 322algorithm 1 clustering-based approach for the disambiguation of the set of words in the textual context input: the finite set of words and the textual context . output: the disambiguated word senses.
</nextsent>
<nextsent>let be the set of all senses of words in , and = 0; repeat = + 1 = clustering(s, 0(i)) g?
</nextsent>
<nextsent>= filter(g,w, ) = ? gg? {s|s ? g} until |s| = |w | or 0(i + 1) = 1 return st1 : 1, . . .
</nextsent>
<nextsent>, tm : m?, where each ti is wordnet term highly correlated to with an association weight i. the set of signature terms for word sense includes all its wordnet hyponyms, its directly related terms (including coordinated terms) and their filtered and lemmatized glosses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1956">
<title id=" W07-1431.xml">natural logic for textual inference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the last five years have seen surge of interest inthe problem of textual inference, that is, automatically determining whether natural-language hypothesis can be inferred from given premise.
</prevsent>
<prevsent>a broad spectrum of approaches have been explored, ranging from shallow-but-robust to deep-but-brittle.
</prevsent>
</prevsection>
<citsent citstr=" E06-1052 ">
up to now, the most successful approaches have used fairly impoverished semantic representations, relying on measures of lexical or semantic overlap (jijkoun and de rijke, 2005), pattern-based relation extraction (romano et al, 2006), <papid> E06-1052 </papid>or approximate matching of predicate-argument structure (hickl et al., 2006).</citsent>
<aftsection>
<nextsent>such methods, while robust and broadly effective, are imprecise, and are easily confounded by ubiquituous inferences involving monotonicity, particularly in negative polarity contexts, as in: p: no case of indigenously acquired rabies infection has been confirmed in the past 2 years.
</nextsent>
<nextsent>h: no rabies cases have been confirmed.
</nextsent>
<nextsent>because it drops important qualifiers in negative context, the hypothesis does not follow; yet both the lexical content and the predicate-argument structure of the hypothesis closely match the premise.at the other extreme, textual inference can be approached as deduction, building on work informal computational semantics to translate sentences intofirst-order logic (fol), and then applying theorem prover or model builder (akhmatova, 2005; fowler et al, 2005).
</nextsent>
<nextsent>however, such approaches tend to founder on the difficulty of accurately translating natural language in foltricky issues include idioms, intensionality and propositional attitudes, modalities, temporal and causal relations, certain quantifiers, and so on.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1957">
<title id=" W07-1431.xml">natural logic for textual inference </title>
<section> the natlog system.  </section>
<citcontext>
<prevsection>
<prevsent>suppose = ? g. if either or is non-monotone, then so is h. otherwise, if the monotonic ities of and are the same, then is upward-monotone; if they are different,then is downward-monotone.
</prevsent>
<prevsent>(thus, wine has positive polarity in no meal without wine because it falls under two downward-monotone operators.)
</prevsent>
</prevsection>
<citsent citstr=" W05-1201 ">
our natural logic system, dubbed the natlog system, has three-stage architecture similar to those in (marsi and krahmer, 2005; <papid> W05-1201 </papid>maccartney et al, 2006), <papid> N06-1006 </papid>comprising (1) linguistic pre-preprocessing, (2) alignment, and (3) entailment classification.</citsent>
<aftsection>
<nextsent>3.1 linguistic pre-processing.
</nextsent>
<nextsent>relative to other textual inference systems, the natlog system does comparatively little linguistic preprocessing.
</nextsent>
<nextsent>we relyon the stanford parser (klein and manning, 2003), <papid> P03-1054 </papid>treebank-trained statistical parser, for tokenization, part-of-speech tagging, andphrase-structure parsing.</nextsent>
<nextsent>by far the most important analysis performed at this stage is monotonicitymarking, in which we compute the effective mono unary operator: without pattern: in   /?[ww]ithout\$/ argument 1: monotonicity ? on dominating pp pattern: __   pp=proj binary operator: most pattern: jjs   /?[mm]ost\$/ !  qp argument 1: monotonicity 6??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1958">
<title id=" W07-1431.xml">natural logic for textual inference </title>
<section> the natlog system.  </section>
<citcontext>
<prevsection>
<prevsent>suppose = ? g. if either or is non-monotone, then so is h. otherwise, if the monotonic ities of and are the same, then is upward-monotone; if they are different,then is downward-monotone.
</prevsent>
<prevsent>(thus, wine has positive polarity in no meal without wine because it falls under two downward-monotone operators.)
</prevsent>
</prevsection>
<citsent citstr=" N06-1006 ">
our natural logic system, dubbed the natlog system, has three-stage architecture similar to those in (marsi and krahmer, 2005; <papid> W05-1201 </papid>maccartney et al, 2006), <papid> N06-1006 </papid>comprising (1) linguistic pre-preprocessing, (2) alignment, and (3) entailment classification.</citsent>
<aftsection>
<nextsent>3.1 linguistic pre-processing.
</nextsent>
<nextsent>relative to other textual inference systems, the natlog system does comparatively little linguistic preprocessing.
</nextsent>
<nextsent>we relyon the stanford parser (klein and manning, 2003), <papid> P03-1054 </papid>treebank-trained statistical parser, for tokenization, part-of-speech tagging, andphrase-structure parsing.</nextsent>
<nextsent>by far the most important analysis performed at this stage is monotonicitymarking, in which we compute the effective mono unary operator: without pattern: in   /?[ww]ithout\$/ argument 1: monotonicity ? on dominating pp pattern: __   pp=proj binary operator: most pattern: jjs   /?[mm]ost\$/ !  qp argument 1: monotonicity 6??</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1959">
<title id=" W07-1431.xml">natural logic for textual inference </title>
<section> the natlog system.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 linguistic pre-processing.
</prevsent>
<prevsent>relative to other textual inference systems, the natlog system does comparatively little linguistic preprocessing.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we relyon the stanford parser (klein and manning, 2003), <papid> P03-1054 </papid>treebank-trained statistical parser, for tokenization, part-of-speech tagging, andphrase-structure parsing.</citsent>
<aftsection>
<nextsent>by far the most important analysis performed at this stage is monotonicitymarking, in which we compute the effective mono unary operator: without pattern: in   /?[ww]ithout\$/ argument 1: monotonicity ? on dominating pp pattern: __   pp=proj binary operator: most pattern: jjs   /?[mm]ost\$/ !  qp argument 1: monotonicity 6??
</nextsent>
<nextsent>on dominating np pattern: __  +(np) (np=proj !  np) argument 2: monotonicity ? on dominating pattern: __  +(/.*/) (s=proj !  s) figure 1: two examples of monotonicity operator definitions.
</nextsent>
<nextsent>the patterns employ tregex syntax.
</nextsent>
<nextsent>toni city for each token span in each input sentence.for this, we use an adaptation of the marking algorithm of sanchez valencia (section 2); however, our choice of treebank-trained parser (driven by the goal of broad coverage) requires us to modify the algorithm substantially.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1960">
<title id=" W07-1431.xml">natural logic for textual inference </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the study of natural logic was formalized by johan vanbenthem, who crucially connected it with categorial grammar (van benthem, 1986), and later was brought to fruition by victor sanchez valencia, who first gave precise definition of calculus of mono 199 toni city (sanchez valencia, 1991).
</prevsent>
<prevsent>a small current of theoretical work has continued up to the present, for example (zamansky et al, 2006).there has been surprisingly little work on building computational models of natural logic.
</prevsent>
</prevsection>
<citsent citstr=" P85-1008 ">
(fyodorov et al, 2003) describes prolog implementation for small fragment of english, based on categorial grammar parser.6 in an unpublished draft,(van eijck, 2005) describes preliminary implementation in haskell.doing inference with representations close to natural language has also been advocated by jerry hobbs, as in (hobbs, 1985).<papid> P85-1008 </papid></citsent>
<aftsection>
<nextsent>to our knowledge, the fracas results reported here represent the first such evaluation.
</nextsent>
<nextsent>(sukkarieh, 2003) describes applying deductive system to some fracas inferences, but does not perform complete evaluation or report quantitative results.
</nextsent>
<nextsent>our natlog implementation of natural logic successfully handles broad range of inferences involving monotonicity, as demonstrated on the fracas test suite.
</nextsent>
<nextsent>while post-hoc analysis of performance on the rte3 challenge suggests that monotonicity related inferences have limited applicability in rtedata, the greater precision of the natlog system nevertheless significantly improved the performance of hybrid rte system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1961">
<title id=" W07-1706.xml">towards the automatic extraction of definitions in slavic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, section 6 concludes the paper.
</prevsent>
<prevsent>43
</prevsent>
</prevsection>
<citsent citstr=" C04-1199 ">
definition extraction is an important nlp task, most frequently subtask of terminology extraction (pearson, 1996), the automatic creation of glossaries (klavans and muresan, 2000; klavans and muresan,2001), question answering (miliaraki and androutsopoulos, 2004; <papid> C04-1199 </papid>fahmi and bouma, 2006), <papid> W06-2609 </papid>learning lexical semantic relations (malaise?</citsent>
<aftsection>
<nextsent>et al, 2004; storrer and welling hoff, 2006) and automatic construction of ontologies (walter and pinkal, 2006).<papid> W06-0203 </papid></nextsent>
<nextsent>tools for definition extraction are invariably language specific and involve shallow or deep processing, with most work done for english (pearson, 1996; klavans and muresan, 2000; klavans and muresan, 2001) and other germanic languages (fahmi andbouma, 2006; <papid> W06-2609 </papid>storrer and welling hoff, 2006; walter and pinkal, 2006), <papid> W06-0203 </papid>as well as french (malaise?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1962">
<title id=" W07-1706.xml">towards the automatic extraction of definitions in slavic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, section 6 concludes the paper.
</prevsent>
<prevsent>43
</prevsent>
</prevsection>
<citsent citstr=" W06-2609 ">
definition extraction is an important nlp task, most frequently subtask of terminology extraction (pearson, 1996), the automatic creation of glossaries (klavans and muresan, 2000; klavans and muresan,2001), question answering (miliaraki and androutsopoulos, 2004; <papid> C04-1199 </papid>fahmi and bouma, 2006), <papid> W06-2609 </papid>learning lexical semantic relations (malaise?</citsent>
<aftsection>
<nextsent>et al, 2004; storrer and welling hoff, 2006) and automatic construction of ontologies (walter and pinkal, 2006).<papid> W06-0203 </papid></nextsent>
<nextsent>tools for definition extraction are invariably language specific and involve shallow or deep processing, with most work done for english (pearson, 1996; klavans and muresan, 2000; klavans and muresan, 2001) and other germanic languages (fahmi andbouma, 2006; <papid> W06-2609 </papid>storrer and welling hoff, 2006; walter and pinkal, 2006), <papid> W06-0203 </papid>as well as french (malaise?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1963">
<title id=" W07-1706.xml">towards the automatic extraction of definitions in slavic </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>43
</prevsent>
<prevsent>definition extraction is an important nlp task, most frequently subtask of terminology extraction (pearson, 1996), the automatic creation of glossaries (klavans and muresan, 2000; klavans and muresan,2001), question answering (miliaraki and androutsopoulos, 2004; <papid> C04-1199 </papid>fahmi and bouma, 2006), <papid> W06-2609 </papid>learning lexical semantic relations (malaise?</prevsent>
</prevsection>
<citsent citstr=" W06-0203 ">
et al, 2004; storrer and welling hoff, 2006) and automatic construction of ontologies (walter and pinkal, 2006).<papid> W06-0203 </papid></citsent>
<aftsection>
<nextsent>tools for definition extraction are invariably language specific and involve shallow or deep processing, with most work done for english (pearson, 1996; klavans and muresan, 2000; klavans and muresan, 2001) and other germanic languages (fahmi andbouma, 2006; <papid> W06-2609 </papid>storrer and welling hoff, 2006; walter and pinkal, 2006), <papid> W06-0203 </papid>as well as french (malaise?</nextsent>
<nextsent>etal., 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1967">
<title id=" W07-1706.xml">towards the automatic extraction of definitions in slavic </title>
<section> shallow grammars for definition.  </section>
<citcontext>
<prevsection>
<prevsent>all grammars are regular grammars implemented with the use of the lxtransduce tool (tobin, 2005), component of the ltxml2 toolsetdeveloped at the university of edinburgh.3 an example of simple rule for prepositional phrases is given below:  rule name= pp    seq   query match= tok[@ctag = prep?] /   ref name= np1    with-param name= case  value= ?? /   /ref   /seq   /rule  this rule identifies sequence whose first element is token tagged as preposition and whose subsequent elements are identified by rule called np1.this latter rule (not shown here for brevity) is pa rameterised rule which finds nominal phrase of given case, but the way it is called above ensures that it will find an np of any case.
</prevsent>
<prevsent>2part of the representation has been replaced by ?[...]?.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
3among the tools considered here were also clark (simov et al, 2001), ultimately rejected because it currently does not work in batch mode, and gate / jape (cunningham et al, 2002), <papid> P02-1022 </papid>not used here because we found gates handling of previously xml-annotated texts rather cumbersome and ill documented.</citsent>
<aftsection>
<nextsent>cf.
</nextsent>
<nextsent>also fn.
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>44 currently the grammars show varying degrees of sophistication, with small bulgarian grammar (8 rules in 2.5-kilobyte file), larger polish grammar (34 rules in 11kib file) and sophisticated czech grammar most developed (147 rules in 28kib file).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1979">
<title id=" W07-1023.xml">challenges for extracting biomedical knowledge from full text </title>
<section> biomedical nlp.  </section>
<citcontext>
<prevsection>
<prevsent>yu et al (2002) showed that the introduction defines the majority of synonyms, while schuemie et al (2004) and shah et al.
</prevsent>
<prevsent>(2003) showed that the results and methods arethe most and least informative, respectively.
</prevsent>
</prevsection>
<citsent citstr=" W04-1212 ">
in contrast, sinclair and webber (2004) <papid> W04-1212 </papid>found the methods useful in assigning gene ontology codes to articles.these section specific results highlight the information loss resulting from restricting searches to individual sections, as sections often provide uniqueinformation.</citsent>
<aftsection>
<nextsent>furthermore, facts appearing in different contexts across various sections, will be lost.this redundancy has been used for passage validation and ranking (clarke et al, 2001).there are limited training resources for biomedical full-text systems.
</nextsent>
<nextsent>the majority of corpora consist of abstracts annotated for bio-entity recognition and relationship extraction, such as the genia (kim et al, 2003) and the bio creative corpora.
</nextsent>
<nextsent>however, due to the lack of full-text corpora, many current systems only process abstracts (ohta et al, 2006).<papid> P06-4005 </papid></nextsent>
<nextsent>few biomedical corpora exist for other tasks, such as coreference resolution (castano et al, 2004; vlachos et al, 2006), and these are very small.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1980">
<title id=" W07-1023.xml">challenges for extracting biomedical knowledge from full text </title>
<section> biomedical nlp.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, facts appearing in different contexts across various sections, will be lost.this redundancy has been used for passage validation and ranking (clarke et al, 2001).there are limited training resources for biomedical full-text systems.
</prevsent>
<prevsent>the majority of corpora consist of abstracts annotated for bio-entity recognition and relationship extraction, such as the genia (kim et al, 2003) and the bio creative corpora.
</prevsent>
</prevsection>
<citsent citstr=" P06-4005 ">
however, due to the lack of full-text corpora, many current systems only process abstracts (ohta et al, 2006).<papid> P06-4005 </papid></citsent>
<aftsection>
<nextsent>few biomedical corpora exist for other tasks, such as coreference resolution (castano et al, 2004; vlachos et al, 2006), and these are very small.
</nextsent>
<nextsent>in this paper, we estimate the importance of these tasks in bionlp systems, which will help determine which tasks system developers should focus effort on first.despite limited full-text training corpora, competitions such as the genomics track of trec, require systems to retrieve and rank passages from full text that are relevant to question style queries.
</nextsent>
<nextsent>kohn (1999) constructed molecular interaction map (mim) based on literature describing 203 different interactions between bio-entities, such as proteins and genes, in mammalian cells (figure 1).
</nextsent>
<nextsent>interactions in the mim are represented as links between nodes labelled with the bio-entities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1981">
<title id=" W07-1023.xml">challenges for extracting biomedical knowledge from full text </title>
<section> dependencies.  </section>
<citcontext>
<prevsection>
<prevsent>the frequent use of synonyms, abbreviations and acronyms in biomedical text is common source of ambiguity that is often hard to resolve (sehgalet al, 2004).
</prevsent>
<prevsent>furthermore, synonym lists are difficult to maintain in rapidly moving fields like biology (lussier et al, 2006).
</prevsent>
</prevsection>
<citsent citstr=" P06-2083 ">
there has been recent interest in developing systems to identify and extract these (ao and takagi, 2005; okazaki and ananiadou, 2006).<papid> P06-2083 </papid>in our corpus we group all of these synonyms, abbreviations, acronyms and other orthographic variations as synonym facts.</citsent>
<aftsection>
<nextsent>for example, the synonyms(1) e2f4, (2) e2f-4 and (3) e2f1-4 in our corpus refer to the same entity e2f4, however term (3) also includes the entities e2f1, e2f2 and e2f3.
</nextsent>
<nextsent>in table 2, an instance supporting subfact 1.
</nextsent>
<nextsent>is shown in 1.a).
</nextsent>
<nextsent>the bio-entity prb mentioned in the subfact does not appear in this instance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1982">
<title id=" W07-1023.xml">challenges for extracting biomedical knowledge from full text </title>
<section> coreference expressions.  </section>
<citcontext>
<prevsection>
<prevsent>instance 5 also involves cataphoric expression, where suppressor proteins refers to p16ink4a and p19arf event anaphora refer to processes and are quite common in biomedical text.
</prevsent>
<prevsent>we have annotated these separately to pronominal and sortal anaphora.
</prevsent>
</prevsection>
<citsent citstr=" W97-1311 ">
our event anaphora annotations are different to humphreys et al (1997).<papid> W97-1311 </papid></citsent>
<aftsection>
<nextsent>they associate sequential events, while we only refer to the same event.
</nextsent>
<nextsent>an example is shown in instance 6 (table 5)where the additional sortal anaphor complicates resolving the event anaphor.
</nextsent>
<nextsent>the third this refers to the phosphorylation event, phosphorylated, and not the protein cdc25-c like the second this.
</nextsent>
<nextsent>the key facts and results are generally repeated and reworded in various contexts within an article.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1983">
<title id=" W07-1419.xml">svo triple based latent semantic analysis for recognising textual entailment </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>then,we calculate how many times stems co-occur as subject, verb or object with another stem within the same svo instance.
</prevsent>
<prevsent>1minipar can be downloaded from http://www.cs.ualberta.ca/lindek/minipar.htm.
</prevsent>
</prevsection>
<citsent citstr=" C94-1079 ">
it is based on principar, which is described in lin (1994).<papid> C94-1079 </papid></citsent>
<aftsection>
<nextsent>2snowball is freely available from http://snowball.tartarus.org/.
</nextsent>
<nextsent>the english version is based on the original porter stem mer (porter, 1980).
</nextsent>
<nextsent>114 to keep track of the grammatical role (i.e. subject, verb, object) of the words we stem them and label the stems with the corresponding role.
</nextsent>
<nextsent>3.3 building vector spaces to represent stem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1984">
<title id=" W07-2077.xml">ubcupc sequential srl using selectional preferences an approach with maximum entropy markov models </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system presented achieves competitive performance in the conll-2005 shared task dataset and it ranks first in the srl subtask of the semeval-2007 task 17.
</prevsent>
<prevsent>in semantic role labeling (srl) the goal is to identify word sequences or arguments accompanying the predicate and assign them labels depending on their semantic relation.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
in this task we disambiguate argument structures in two ways: predicting verbnet (kipper et al, 2000) thematic roles and propbank (palmer et al, 2005) <papid> J05-1004 </papid>numbered arguments, as well as adjunct arguments.</citsent>
<aftsection>
<nextsent>in this paper we describe our system for the srl subtask of the semeval2007 task 17.
</nextsent>
<nextsent>it is based on the architecture and features of the system named model 2?
</nextsent>
<nextsent>of (surdeanu et al, forthcoming), but it introduces two changes: we use maximum entropy for learning instead of ada boost and we enlarge the feature set with combined features and other semantic features.
</nextsent>
<nextsent>traditionally, most of the features used in srlare extracted from automatically generated syntactic and lexical annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1985">
<title id=" W07-2077.xml">ubcupc sequential srl using selectional preferences an approach with maximum entropy markov models </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 feature representation.
</prevsent>
<prevsent>apart from selectional preferences (cf.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
section 3)and those extracted from provided semantic information, most of the features we used are borrowed from the existing literature (gildea and jurafsky,2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>surdeanu et al, forth coming).</citsent>
<aftsection>
<nextsent>354 on the verb predicate: ? form; lemma; pos tag; chunk type and typeof verb phrase; verb voice; binary flag indicating if the verb is start/end of clause.
</nextsent>
<nextsent>subcategorization, i.e., the phrase structure rule expanding the verb parent node.
</nextsent>
<nextsent>verbnet class of the verb (in the close?
</nextsent>
<nextsent>track only).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1986">
<title id=" W07-2077.xml">ubcupc sequential srl using selectional preferences an approach with maximum entropy markov models </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 feature representation.
</prevsent>
<prevsent>apart from selectional preferences (cf.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
section 3)and those extracted from provided semantic information, most of the features we used are borrowed from the existing literature (gildea and jurafsky,2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>surdeanu et al, forth coming).</citsent>
<aftsection>
<nextsent>354 on the verb predicate: ? form; lemma; pos tag; chunk type and typeof verb phrase; verb voice; binary flag indicating if the verb is start/end of clause.
</nextsent>
<nextsent>subcategorization, i.e., the phrase structure rule expanding the verb parent node.
</nextsent>
<nextsent>verbnet class of the verb (in the close?
</nextsent>
<nextsent>track only).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1989">
<title id=" W07-2077.xml">ubcupc sequential srl using selectional preferences an approach with maximum entropy markov models </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>binary position; if the argument is after or before the predicate.
</prevsent>
<prevsent>constituent path as described in (gildea and jurafsky, 2002); <papid> J02-3001 </papid>all 3/4/5-grams of path constituents beginning at the verb predicate or ending at the constituent.</prevsent>
</prevsection>
<citsent citstr=" W04-2415 ">
partial parsing path as described in (carreras et al, 2004)); <papid> W04-2415 </papid>all 3/4/5-grams of path elements beginning at the verb predicate or ending at the constituent.</citsent>
<aftsection>
<nextsent>syntactic frame as described by xue and palmer (2004) <papid> W04-3212 </papid>combination features ? predicate and phrase type ? predicate and binary position ? head word and predicate ? predicate and propbank frame sense ? predicate, propbank frame sense, verbnet class (in the close?</nextsent>
<nextsent>track only) 2.3 maximum entropy markov models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1991">
<title id=" W07-2077.xml">ubcupc sequential srl using selectional preferences an approach with maximum entropy markov models </title>
<section> including selectional preferences.  </section>
<citcontext>
<prevsection>
<prevsent>they can be learned from corpora, generalizing from the observed argument heads (e.g. apple?, biscuit?, etc.) into abstract classes (e.g. edible things).
</prevsent>
<prevsent>in our case we 1http://mallet.cs.umass.edu2restriction 5 applies to propbank output.
</prevsent>
</prevsection>
<citsent citstr=" W01-0703 ">
restriction 6 applies to verbnet output 355follow (agirre and martinez, 2001) <papid> W01-0703 </papid>and use wordnet (fellbaum, 1998) as the generalization classes (the concept  food,nutrient ).</citsent>
<aftsection>
<nextsent>the aim of using selectional preferences (sp) in srl is to generalize from the argument heads in the training instances into general word classes.
</nextsent>
<nextsent>in theory, using word classes might overcome the data sparseness problem for the head-based features, but at the cost of introducing some noise.more specifically, given verb, we study the occurrences of the target verb in training corpus (e.g. the propbank corpus), and learn set of sps foreach argument and adjunct of that verb.
</nextsent>
<nextsent>for instance, given the verb kill?
</nextsent>
<nextsent>we would have 2 sps for each argument type, and 4 sps for some of the observed adjuncts: kill a0, kill a1, kill amloc, kill am-mnr, kill am-pnc and kill am tmp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1992">
<title id=" W07-2009.xml">semeval2007 task 10 english lexical substitution task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one problem is that wsd systems have been tested on fine-grained inventories, rendering the task harder than it need be for many applications (ide and wilks, 2006).
</prevsent>
<prevsent>another significant problem is that there is no clear choice of inventory for any given task (other than the use of parallel corpus for specific language pair for machine translation application).
</prevsent>
</prevsection>
<citsent citstr=" W02-0816 ">
the lexical substitution task follows on from some previous ideas (mccarthy, 2002) <papid> W02-0816 </papid>to examine the capabilities of wsd systems built by researchers on task which has potential for nlp applications.</citsent>
<aftsection>
<nextsent>finding alternative words that can occur in given contexts would potentially be useful to many applications such as question answering, summarisation, paraphrase acquisition (daganet al, 2006), <papid> P06-1057 </papid>text simplification and lexical acquisition (mccarthy, 2002).<papid> W02-0816 </papid></nextsent>
<nextsent>crucially this task does not specify the inventory for use beforehand to avoid bias to one predefined inventory and makes it easier for those using automatically acquired resources to enter the arena.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1993">
<title id=" W07-2009.xml">semeval2007 task 10 english lexical substitution task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>another significant problem is that there is no clear choice of inventory for any given task (other than the use of parallel corpus for specific language pair for machine translation application).
</prevsent>
<prevsent>the lexical substitution task follows on from some previous ideas (mccarthy, 2002) <papid> W02-0816 </papid>to examine the capabilities of wsd systems built by researchers on task which has potential for nlp applications.</prevsent>
</prevsection>
<citsent citstr=" P06-1057 ">
finding alternative words that can occur in given contexts would potentially be useful to many applications such as question answering, summarisation, paraphrase acquisition (daganet al, 2006), <papid> P06-1057 </papid>text simplification and lexical acquisition (mccarthy, 2002).<papid> W02-0816 </papid></citsent>
<aftsection>
<nextsent>crucially this task does not specify the inventory for use beforehand to avoid bias to one predefined inventory and makes it easier for those using automatically acquired resources to enter the arena.
</nextsent>
<nextsent>indeed, since the systems in semeval did not know the candidate substitutes for word before hand, the lexical resource is evaluate das much as the context based disambiguation component.
</nextsent>
<nextsent>the task involves lexical sample of nouns, verbs,adjectives and adverbs.
</nextsent>
<nextsent>both annotators and systems select one or more substitutes for the target word in the context of sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1995">
<title id=" W07-2009.xml">semeval2007 task 10 english lexical substitution task </title>
<section> scoring.  </section>
<citcontext>
<prevsection>
<prevsent>let mw be the subset of for which there is such multiword response from majority of at least 2 annotators.
</prevsent>
<prevsent>let mwi ? mw be the multiword identified by majority vote for item i. let mwsys be the subset of for which there is multiword response from the system and mwsysi be multiword specified by the system for item i. detection = ? mwsysimwsys 1 if mwi exists at |mwsys| (9) detection = ? mwsysimw 1 if mwi exists at |mw | (10) identification = ? mwsysimwsys 1 if mwsysi = mwi |mwsys| (11) 50 identification = ? mwsysimw 1 if mwsysi = mwi |mw | (12) 3.1 baselines.
</prevsent>
</prevsection>
<citsent citstr=" H93-1061 ">
we produced baselines using wordnet 2.1 (miller et al., 1993<papid> H93-1061 </papid>a) and number of distributional similarity measures.</citsent>
<aftsection>
<nextsent>for the wordnet best baseline we found the best ranked synonym using the criteria 1 to 4 below in order.
</nextsent>
<nextsent>for wordnet oot we found up to 10 synonyms using criteria 1 to 4 in order until 10 were found: 1.
</nextsent>
<nextsent>synonyms from the first synset of the target.
</nextsent>
<nextsent>word, and ranked with frequency data obtained from the bnc (leech, 1992).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1996">
<title id=" W07-2009.xml">semeval2007 task 10 english lexical substitution task </title>
<section> scoring.  </section>
<citcontext>
<prevsection>
<prevsent>4.
</prevsent>
<prevsent>synonyms from the hypernyms (verbs and nouns) or closely related classes (adjectives) of all synsets of the target, ranked with the bnc frequency data.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
we also produced best and oot baselines using the distributional similarity measures l1, jaccard, co sine, lin (lin, 1998) and sd (lee, 1999) <papid> P99-1004 </papid>4.</citsent>
<aftsection>
<nextsent>we tookthe word with the largest similarity (or smallest distance for sd and l1) for best and the top 10 for oot.
</nextsent>
<nextsent>for mw detection and identification we used wordnet to detect if multiword in wordnet which includes the target word occurs within window of 2 words before and 2 words after the target word.
</nextsent>
<nextsent>9 teams registered and 8 participated, and two ofthese teams (swag and irst) each entered two systems, we distinguish the first and second systems with 1 and 2 suffix respectively.the systems all used 1 or more predefined inventories.
</nextsent>
<nextsent>most used web queries (hit, melb, unt) or web data (brants and franz, 2006) (irst2, ku, 4we used 0.99 as the parameter for ? for this measure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1998">
<title id=" W08-0310.xml">limsis statistical translation systems for wmt08 </title>
<section> base system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>they are fairly standard phrase-based univ. montral, felipe@iro.umontreal.ca other target text target text mosestextsource or translation model 4g language model 4g language model and extraction rescoring $n$besttranslations lm interpolation phrase pair extraction neural network or or + news co.europarleuroparl europarlnews co.sources figure 1: generic architecture of limsis smt systems.depending on the condition, the decoder generates either the final output or n-best lists.
</prevsent>
<prevsent>in the latter case, the rescoring incorporates the same translation features, except for better target language model (see text).
</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
translation systems (och and ney, 2004; <papid> J04-4002 </papid>koehn et al., 2003) <papid> N03-1017 </papid>and use moses (koehn et al, 2007) <papid> P07-2045 </papid>to search for the best target sentence.</citsent>
<aftsection>
<nextsent>the search uses the following models: phrase table, providing 4 scores and phrase penalty, lexicalized reordering model (7 scores), language model score and wordpenalty.
</nextsent>
<nextsent>these fourteen scores are weighted and linearly combined (och and ney, 2002; <papid> P02-1038 </papid>och, 2003); <papid> P03-1021 </papid>their respective weights are learned on development data so as to maximize the bleu score.</nextsent>
<nextsent>in the following, we detail several aspects of our systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD1999">
<title id=" W08-0310.xml">limsis statistical translation systems for wmt08 </title>
<section> base system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>they are fairly standard phrase-based univ. montral, felipe@iro.umontreal.ca other target text target text mosestextsource or translation model 4g language model 4g language model and extraction rescoring $n$besttranslations lm interpolation phrase pair extraction neural network or or + news co.europarleuroparl europarlnews co.sources figure 1: generic architecture of limsis smt systems.depending on the condition, the decoder generates either the final output or n-best lists.
</prevsent>
<prevsent>in the latter case, the rescoring incorporates the same translation features, except for better target language model (see text).
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
translation systems (och and ney, 2004; <papid> J04-4002 </papid>koehn et al., 2003) <papid> N03-1017 </papid>and use moses (koehn et al, 2007) <papid> P07-2045 </papid>to search for the best target sentence.</citsent>
<aftsection>
<nextsent>the search uses the following models: phrase table, providing 4 scores and phrase penalty, lexicalized reordering model (7 scores), language model score and wordpenalty.
</nextsent>
<nextsent>these fourteen scores are weighted and linearly combined (och and ney, 2002; <papid> P02-1038 </papid>och, 2003); <papid> P03-1021 </papid>their respective weights are learned on development data so as to maximize the bleu score.</nextsent>
<nextsent>in the following, we detail several aspects of our systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2000">
<title id=" W08-0310.xml">limsis statistical translation systems for wmt08 </title>
<section> base system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>they are fairly standard phrase-based univ. montral, felipe@iro.umontreal.ca other target text target text mosestextsource or translation model 4g language model 4g language model and extraction rescoring $n$besttranslations lm interpolation phrase pair extraction neural network or or + news co.europarleuroparl europarlnews co.sources figure 1: generic architecture of limsis smt systems.depending on the condition, the decoder generates either the final output or n-best lists.
</prevsent>
<prevsent>in the latter case, the rescoring incorporates the same translation features, except for better target language model (see text).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
translation systems (och and ney, 2004; <papid> J04-4002 </papid>koehn et al., 2003) <papid> N03-1017 </papid>and use moses (koehn et al, 2007) <papid> P07-2045 </papid>to search for the best target sentence.</citsent>
<aftsection>
<nextsent>the search uses the following models: phrase table, providing 4 scores and phrase penalty, lexicalized reordering model (7 scores), language model score and wordpenalty.
</nextsent>
<nextsent>these fourteen scores are weighted and linearly combined (och and ney, 2002; <papid> P02-1038 </papid>och, 2003); <papid> P03-1021 </papid>their respective weights are learned on development data so as to maximize the bleu score.</nextsent>
<nextsent>in the following, we detail several aspects of our systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2001">
<title id=" W08-0310.xml">limsis statistical translation systems for wmt08 </title>
<section> base system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>translation systems (och and ney, 2004; <papid> J04-4002 </papid>koehn et al., 2003) <papid> N03-1017 </papid>and use moses (koehn et al, 2007) <papid> P07-2045 </papid>to search for the best target sentence.</prevsent>
<prevsent>the search uses the following models: phrase table, providing 4 scores and phrase penalty, lexicalized reordering model (7 scores), language model score and wordpenalty.</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
these fourteen scores are weighted and linearly combined (och and ney, 2002; <papid> P02-1038 </papid>och, 2003); <papid> P03-1021 </papid>their respective weights are learned on development data so as to maximize the bleu score.</citsent>
<aftsection>
<nextsent>in the following, we detail several aspects of our systems.
</nextsent>
<nextsent>2.1 translation models.
</nextsent>
<nextsent>the translation models deployed in our systems for the europarl condition were trained on the provided europarl parallel data only.
</nextsent>
<nextsent>for the news condition, they were trained on the europarl data merged with 107 the news-commentary parallel data, as depicted on figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2002">
<title id=" W08-0310.xml">limsis statistical translation systems for wmt08 </title>
<section> base system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>translation systems (och and ney, 2004; <papid> J04-4002 </papid>koehn et al., 2003) <papid> N03-1017 </papid>and use moses (koehn et al, 2007) <papid> P07-2045 </papid>to search for the best target sentence.</prevsent>
<prevsent>the search uses the following models: phrase table, providing 4 scores and phrase penalty, lexicalized reordering model (7 scores), language model score and wordpenalty.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
these fourteen scores are weighted and linearly combined (och and ney, 2002; <papid> P02-1038 </papid>och, 2003); <papid> P03-1021 </papid>their respective weights are learned on development data so as to maximize the bleu score.</citsent>
<aftsection>
<nextsent>in the following, we detail several aspects of our systems.
</nextsent>
<nextsent>2.1 translation models.
</nextsent>
<nextsent>the translation models deployed in our systems for the europarl condition were trained on the provided europarl parallel data only.
</nextsent>
<nextsent>for the news condition, they were trained on the europarl data merged with 107 the news-commentary parallel data, as depicted on figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2003">
<title id=" W08-0310.xml">limsis statistical translation systems for wmt08 </title>
<section> base system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>this setup was found to be more favor able than training on europarl data only (for obvious mis matching domain reasons) and than training on news-commentary data only, most probably because of lack of coverage.
</prevsent>
<prevsent>another, alternative way of benefitting from the coverage of the europarl corpus and the relevance of the news-commentary corp usis to use two phrase-tables in parallel, an interesting feature of moses.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
(koehn and schroeder, 2007)<papid> W07-0733 </papid>found that this was the best way to adapt?</citsent>
<aftsection>
<nextsent>a translation system to the news-commentary task.
</nextsent>
<nextsent>these results are corroborated in (dchelotte, 2007)1 , which adapts european parliament?
</nextsent>
<nextsent>system using european and spanish parliaments?
</nextsent>
<nextsent>development set.however, we were not able to reproduce those findings for this evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2004">
<title id=" W08-0310.xml">limsis statistical translation systems for wmt08 </title>
<section> experiments with factored models.  </section>
<citcontext>
<prevsection>
<prevsent>even though these models were not used in our submissions, we feel it useful to comment here our (neg ative) experiments with factored models.
</prevsent>
<prevsent>4.1 overview.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
in this work, factored models (koehn and hoang,2007) <papid> D07-1091 </papid>are experimented with three factors : the surface form, the lemma and the part of speech (pos).</citsent>
<aftsection>
<nextsent>the translation process is composed of different mapping steps, which either translate input factors into output factors, or generate additional output factors from existing output factors.
</nextsent>
<nextsent>in this work, four mapping steps are used with two decoding paths.the first path corresponds to the standard and direct mapping of surface forms.
</nextsent>
<nextsent>the second decoding path consists in two translation steps for respectively pos tag and the lemmas, followed by generation step which produces the surface form given the pos-lemma couple.
</nextsent>
<nextsent>the system also includes three reordering models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2006">
<title id=" W08-0321.xml">improving word alignment with language model based confidence scores </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word alignment models are crucial component in statistical machine translation systems.
</prevsent>
<prevsent>when estimating the parameters of the word alignment models, the sentence pair probability is an important factor in the objective function and is approximated by the empirical probability.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the empirical probability for each sentence pair is estimated by maximum likelihood estimation over the training data (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>due to the limitation of training data, most sentence pairs occur only once, which makes the empirical probability almost uniform.
</nextsent>
<nextsent>this is rather weak approximation of the true distribution.
</nextsent>
<nextsent>in this paper, we investigate the methods of weighting sentence pairs using language models, and extended the general weighting method to genre-dependent weight.
</nextsent>
<nextsent>a method of integrating the weight directly into the phrase table is also explored.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2007">
<title id=" W08-0321.xml">improving word alignment with language model based confidence scores </title>
<section> the baseline phrase-based mt system.  </section>
<citcontext>
<prevsection>
<prevsent>the acl-wmt08 organizers provided europarl andnews-commentary parallel corpora for english ? spanish.
</prevsent>
<prevsent>detailed corpus statistics is given in table 1.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
following the guidelines of the workshop we built baseline systems, using the lower-cased europarl parallel corpus (re stricting sentence length to 40 words), giza++ (och and ney, 2003), <papid> J03-1002 </papid>moses (koehn et al, 2007), <papid> P07-2045 </papid>and the sri lm toolkit (stolcke, 2002) to build 5-gram lms.</citsent>
<aftsection>
<nextsent>since nonews development sets were available we chose news commentary sets as replacements.
</nextsent>
<nextsent>we used test-2006 (e06) and nc-devtest2007 (ncd) as development sets for europarl and news-commentary; test-2007 (e07) and nc-test2007 (nct) as held-out evaluation sets.
</nextsent>
<nextsent>english spanish europarl (e) sentence pairs 1,258,778 unique sent.
</nextsent>
<nextsent>pairs 1,235,134 avg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2008">
<title id=" W08-0321.xml">improving word alignment with language model based confidence scores </title>
<section> the baseline phrase-based mt system.  </section>
<citcontext>
<prevsection>
<prevsent>the acl-wmt08 organizers provided europarl andnews-commentary parallel corpora for english ? spanish.
</prevsent>
<prevsent>detailed corpus statistics is given in table 1.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
following the guidelines of the workshop we built baseline systems, using the lower-cased europarl parallel corpus (re stricting sentence length to 40 words), giza++ (och and ney, 2003), <papid> J03-1002 </papid>moses (koehn et al, 2007), <papid> P07-2045 </papid>and the sri lm toolkit (stolcke, 2002) to build 5-gram lms.</citsent>
<aftsection>
<nextsent>since nonews development sets were available we chose news commentary sets as replacements.
</nextsent>
<nextsent>we used test-2006 (e06) and nc-devtest2007 (ncd) as development sets for europarl and news-commentary; test-2007 (e07) and nc-test2007 (nct) as held-out evaluation sets.
</nextsent>
<nextsent>english spanish europarl (e) sentence pairs 1,258,778 unique sent.
</nextsent>
<nextsent>pairs 1,235,134 avg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2009">
<title id=" W08-0321.xml">improving word alignment with language model based confidence scores </title>
<section> the baseline phrase-based mt system.  </section>
<citcontext>
<prevsection>
<prevsent>sentence length 24.0 27.4 # words 1.54 1.76 vocabulary 44.2 56.9 ktable 1: statistics of english spanish europarl and news commentary corpor ato improve the baseline performance we trained systems on all true-cased training data with sentence length up to 100.
</prevsent>
<prevsent>we used two language models, 5-gram lm build from the europarl corpus and 3-gram lm build from the news-commentary data.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
instead of interpol at ing the two language models, we explicitly used them inthe decoder and optimized their weights via minimum error-rate (mer) training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>to shorten the training time, multi-threaded giza++ version was used to utilize multi-processor servers (gao and vogel, 2008).other parameters were the same as the baseline system.
</nextsent>
<nextsent>table 2 shows results in lowercase bleu (papineni et al, 2002) <papid> P02-1040 </papid>for both the baseline (b) and the improved baseline systems (b5) on development and held 151 out evaluation sets.</nextsent>
<nextsent>we observed significant gains for thenews-commentary test sets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2010">
<title id=" W08-0321.xml">improving word alignment with language model based confidence scores </title>
<section> the baseline phrase-based mt system.  </section>
<citcontext>
<prevsection>
<prevsent>instead of interpol at ing the two language models, we explicitly used them inthe decoder and optimized their weights via minimum error-rate (mer) training (och, 2003).<papid> P03-1021 </papid></prevsent>
<prevsent>to shorten the training time, multi-threaded giza++ version was used to utilize multi-processor servers (gao and vogel, 2008).other parameters were the same as the baseline system.</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
table 2 shows results in lowercase bleu (papineni et al, 2002) <papid> P02-1040 </papid>for both the baseline (b) and the improved baseline systems (b5) on development and held 151 out evaluation sets.</citsent>
<aftsection>
<nextsent>we observed significant gains for thenews-commentary test sets.
</nextsent>
<nextsent>our improved baseline systems obtained comparable performance with the best english spanish systems in 2007 (callison-burch et al, 2007).
</nextsent>
<nextsent>pairs europarl nc e06 e07 ncd nct enes 33.00 32.21 31.84 30.56b5 33.33 32.25 35.10 34.08 esen 33.08 33.23 31.18 31.34b5 33.26 33.23 36.06 35.56 table 2: nist-bleu scores of baseline and improved baseline systems experiments on englishspanish
</nextsent>
<nextsent>3.1 problem definition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2013">
<title id=" W08-0321.xml">improving word alignment with language model based confidence scores </title>
<section> weighting sentence pairs.  </section>
<citcontext>
<prevsection>
<prevsent>the sentence pair confidence score is then given by: sc(ek, fk) = exp(l(ek, fk)).
</prevsent>
<prevsent>(4) 3.3 genre-dependent sentence pair confidence.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
genre adaptation is one of the major challenges in statistical machine translation since translation models suffer from data sparseness (koehn and schroeder, 2007).<papid> W07-0733 </papid></citsent>
<aftsection>
<nextsent>to overcome these problems previous works have focused on explicitly modeling topics and on using multiple language and translation models.
</nextsent>
<nextsent>using mixture of topic dependent viterbi alignments was proposed in (civeraand juan, 2007).<papid> W07-0722 </papid></nextsent>
<nextsent>language and translation model adaptation to europarl and news-commentary have been explored in (paulik et al, 2007).<papid> W07-0727 </papid>given the sentence pair weighting method, it is possible to adopt genre-specific language models into the 152 weighting process.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2014">
<title id=" W08-0321.xml">improving word alignment with language model based confidence scores </title>
<section> weighting sentence pairs.  </section>
<citcontext>
<prevsection>
<prevsent>genre adaptation is one of the major challenges in statistical machine translation since translation models suffer from data sparseness (koehn and schroeder, 2007).<papid> W07-0733 </papid></prevsent>
<prevsent>to overcome these problems previous works have focused on explicitly modeling topics and on using multiple language and translation models.</prevsent>
</prevsection>
<citsent citstr=" W07-0722 ">
using mixture of topic dependent viterbi alignments was proposed in (civeraand juan, 2007).<papid> W07-0722 </papid></citsent>
<aftsection>
<nextsent>language and translation model adaptation to europarl and news-commentary have been explored in (paulik et al, 2007).<papid> W07-0727 </papid>given the sentence pair weighting method, it is possible to adopt genre-specific language models into the 152 weighting process.</nextsent>
<nextsent>the genre-dependent sentence pair confidence gdsc simulates weighting the training sentences again from different data sources, thus, given genre g, it can be formulated as: gdsc(ek, fk) = sc(ek, fk|g) (5)where (eki |h) and (fkj |h) are estimated by genre specific language models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2015">
<title id=" W08-0321.xml">improving word alignment with language model based confidence scores </title>
<section> weighting sentence pairs.  </section>
<citcontext>
<prevsection>
<prevsent>to overcome these problems previous works have focused on explicitly modeling topics and on using multiple language and translation models.
</prevsent>
<prevsent>using mixture of topic dependent viterbi alignments was proposed in (civeraand juan, 2007).<papid> W07-0722 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-0727 ">
language and translation model adaptation to europarl and news-commentary have been explored in (paulik et al, 2007).<papid> W07-0727 </papid>given the sentence pair weighting method, it is possible to adopt genre-specific language models into the 152 weighting process.</citsent>
<aftsection>
<nextsent>the genre-dependent sentence pair confidence gdsc simulates weighting the training sentences again from different data sources, thus, given genre g, it can be formulated as: gdsc(ek, fk) = sc(ek, fk|g) (5)where (eki |h) and (fkj |h) are estimated by genre specific language models.
</nextsent>
<nextsent>the score generally represents the likelihood of the sentence pair to be in specific genre.
</nextsent>
<nextsent>thus, if both sides of the sentence pair show high probability according to the genre-specific language models, alignments in the pair should be more possible to occur in that particular domain, and put more weight may contribute to better alignment for that genre.
</nextsent>
<nextsent>3.4 phrase alignment confidence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2016">
<title id=" W08-0317.xml">effects of morphological analysis in translation between german and english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>research in statistical machine translation (smt) increasingly makes use of linguistic analysis in orderto improve performance.
</prevsent>
<prevsent>by including abstract categories, such as lemmas and parts-of-speech (pos), in the models, it is argued that systems can become better at handling sentences for which training data at the word level is sparse.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
such categories can be integrated in the statistical framework using factored models (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>furthermore, by parsing input sentences and restructuring based on the result to narrow the structural difference between source and target language, the current phrase-based models can be used more effectively (collins et al, 2005).<papid> P05-1066 </papid>german differs structurally from english in several respects (see e.g. collins et al, 2005).<papid> P05-1066 </papid></nextsent>
<nextsent>in this work we wanted to look at one particular aspect of restructuring, namely splitting of german compounds, and evaluate its effect in both translation directions, thus extending the initial experiments reported in holmqvist et al (2007).<papid> W07-0723 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2017">
<title id=" W08-0317.xml">effects of morphological analysis in translation between german and english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by including abstract categories, such as lemmas and parts-of-speech (pos), in the models, it is argued that systems can become better at handling sentences for which training data at the word level is sparse.
</prevsent>
<prevsent>such categories can be integrated in the statistical framework using factored models (koehn et al, 2007).<papid> P07-2045 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
furthermore, by parsing input sentences and restructuring based on the result to narrow the structural difference between source and target language, the current phrase-based models can be used more effectively (collins et al, 2005).<papid> P05-1066 </papid>german differs structurally from english in several respects (see e.g. collins et al, 2005).<papid> P05-1066 </papid></citsent>
<aftsection>
<nextsent>in this work we wanted to look at one particular aspect of restructuring, namely splitting of german compounds, and evaluate its effect in both translation directions, thus extending the initial experiments reported in holmqvist et al (2007).<papid> W07-0723 </papid></nextsent>
<nextsent>in addition, since german is much richer in morphology than english, we wanted to test the effects of using sequence model for german based on morphologically subcategorized parts-of-speech.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2021">
<title id=" W08-0317.xml">effects of morphological analysis in translation between german and english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such categories can be integrated in the statistical framework using factored models (koehn et al, 2007).<papid> P07-2045 </papid></prevsent>
<prevsent>furthermore, by parsing input sentences and restructuring based on the result to narrow the structural difference between source and target language, the current phrase-based models can be used more effectively (collins et al, 2005).<papid> P05-1066 </papid>german differs structurally from english in several respects (see e.g. collins et al, 2005).<papid> P05-1066 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-0723 ">
in this work we wanted to look at one particular aspect of restructuring, namely splitting of german compounds, and evaluate its effect in both translation directions, thus extending the initial experiments reported in holmqvist et al (2007).<papid> W07-0723 </papid></citsent>
<aftsection>
<nextsent>in addition, since german is much richer in morphology than english, we wanted to test the effects of using sequence model for german based on morphologically subcategorized parts-of-speech.
</nextsent>
<nextsent>all systems have been specified as extensions of the moses system provided for the shared task.
</nextsent>
<nextsent>for both english and german we used the part-of speech tagger tree tagger (schmid, 1994) to obtain pos-tags.the german pos-tags from tree tagger were refined by adding morphological information from commercial dependency parser, including case, number, gender, definite ness, and person for nouns, pronouns, verbs, adjectives and determiners in the cases where both tools agreed on the pos-tag.
</nextsent>
<nextsent>if they did not agree, the pos-tag from tree tagger was chosen.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2022">
<title id=" W08-0317.xml">effects of morphological analysis in translation between german and english </title>
<section> compound analysis.  </section>
<citcontext>
<prevsection>
<prevsent>example of compounds with additions and truncations can be seen in (1).
</prevsent>
<prevsent>(1) a. staatsfeind (staat + feind) public enemy b. kirch hof (kirche + hof) graveyard 3.1 splitting compounds.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
noun and adjective compounds are split by modified version of the corpus-based method presented by koehn and knight (2003).<papid> E03-1076 </papid></citsent>
<aftsection>
<nextsent>first the german language model data is pos-tagged and used to calculate frequencies of all nouns, verbs, adjectives, ad verbs and the negative particle.
</nextsent>
<nextsent>then, for each noun and adjective all splits into these known words from the corpus, allowing filler additions and truncations, are considered, choosing the splitting option with the highest arithmetic mean1 of the frequencies of its parts.a length limit of each part was set to 4 characters.
</nextsent>
<nextsent>for adjectives we restrict the number of parts to maximum two, since they do not tend to have multiple parts as often as nouns.
</nextsent>
<nextsent>in addition we added stop list with 14 parts, often mis tagged, that gave rise to wrong adjective splits, such as arische (aryan?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2028">
<title id=" W08-0317.xml">effects of morphological analysis in translation between german and english </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>here we only used the original pos-tags from tree tagger, no additional morphology was added for german.
</prevsent>
<prevsent>de-en en-de baseline 26.95 20.16 factored baseline 27.43 20.27 submitted system 27.63 20.46 table 1: bleu scores for europarl (test2007) de-en en-de baseline 19.54 14.31 factored baseline 20.16 14.37 submitted system 20.61 14.77 table 2: bleu scores for news commentary (nc-test2007)
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
case-sensitive bleu scores4 (papineni et al, 2002) <papid> P02-1040 </papid>for the europarl devtest set (test2007) are shown intable 1.</citsent>
<aftsection>
<nextsent>we can see that the submitted system performs best, and that the factored baseline is better than the pure baseline, especially for translation into english.
</nextsent>
<nextsent>bleu scores for news commentary5 (nc-test2007) are shown in table 2.
</nextsent>
<nextsent>here we can also see that the submitted system is the best.
</nextsent>
<nextsent>as expected, bleu is much lower on out-of-domain news text than on the europarl development test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2029">
<title id=" W07-0803.xml">person name entity recognition for arabic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many researchers have attacked this problem in variety of languages but only few limited researches have focused on ner for arabic text.
</prevsent>
<prevsent>this is due to the lack of resources for arabic ne and the limited amount of progress made in arabic nlp in general.
</prevsent>
</prevsection>
<citsent citstr=" W98-1002 ">
maloney and niv (1998) <papid> W98-1002 </papid>developed tagarab an arabic name recognizer that uses pattern recognition engine integrated with morphological analysis.</citsent>
<aftsection>
<nextsent>the role of the morphological analyzer is to decide where name ends and the non-name context begins.
</nextsent>
<nextsent>the decision depends on the part of-speech of the arabic word and/or its inflections.
</nextsent>
<nextsent>abuleil (2004) presented technique to extract proper names from text to build database of names along with their classification that can be used in question-answering systems.
</nextsent>
<nextsent>this work was done in three main stages: 1) marking the phrases that might include names, 2) building up graphs to represent the words in these phrases and the relationships between them, and 3) applying rules to generate the names, classify each of them, and saves them in database.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2030">
<title id=" W07-0803.xml">person name entity recognition for arabic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for each sentence pair aligned together, they use simple mapping scheme to trans literate all the words in the arabic sentence and return those matching with nes in the spanish sentence as the nes in arabic.
</prevsent>
<prevsent>while they report high precision and recall, it should be noted that their approach is applicable only when parallel corpus is available.
</prevsent>
</prevsection>
<citsent citstr=" W05-0709 ">
zitouni et al (2005) <papid> W05-0709 </papid>has adopted statistical approach for the entity detection and recognition (edr).</citsent>
<aftsection>
<nextsent>in this work, mention can be either named (e.g. john mayor), nominal (the president) or pronominal (she, it).
</nextsent>
<nextsent>an entity is the aggregate of all the mentions (of any level) which refer to one conceptual entity.
</nextsent>
<nextsent>this extended definition of the entity has proved the suitability of the approach.
</nextsent>
<nextsent>3 components of an arabic full name.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2031">
<title id=" W07-1217.xml">partial parse selection for robust deep processing </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this paper presents an approach to partial parse selection for robust deep processing.
</prevsent>
<prevsent>the work is based on bottom-up chart parser for hpsg parsing.
</prevsent>
</prevsection>
<citsent citstr=" P99-1052 ">
following the definition of partial parses in (kasper et al,1999), <papid> P99-1052 </papid>different partial parse selection methods are presented and evaluated on the basis of multiple metrics, from both the syntactic and semantic viewpoints.</citsent>
<aftsection>
<nextsent>the application of the partial parsing in spontaneous speech texts processing shows promising competence of the method.
</nextsent>
<nextsent>linguistically deep processing is of high theoretical and application interest because of its ability to deliver fine-grained accurate analyses of natural language sentences.
</nextsent>
<nextsent>unlike shallow methods which usually return analyses for any input, deep processing methods with precision grammars normally make clear grammaticality judgment on inputs, therefore avoiding the generation of erroneous analyses for less well-formed inputs.
</nextsent>
<nextsent>this is desirable feature, for it allows for more accurate modeling of language itself.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2038">
<title id=" W07-1217.xml">partial parse selection for robust deep processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, unless there are partial treebanks built specifically for the deep grammars, there is simply no gold?
</prevsent>
<prevsent>standard for non-golden partial analyses.instead, in this paper, we evaluate the partial analyses results on the basis of multiple metrics, from both the syntactic and semantic point of views.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
empirical evaluation has been done with the erg on asmall set of texts from the wall street journal section 22 of the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid>a pilot study of applying partial parsing in spontaneous speech text processing is also carried out.the remainder of the paper is organized as fol low.</citsent>
<aftsection>
<nextsent>section 2 provides background knowledge about partial analysis.
</nextsent>
<nextsent>section 3 presents various partial parse selection models.
</nextsent>
<nextsent>section 4 describes the evaluation setup and results.
</nextsent>
<nextsent>section 5 concludes the paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2055">
<title id=" W07-1217.xml">partial parse selection for robust deep processing </title>
<section> partial parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>although different requirements for the scoring function are discussed, no further details have been defined.
</prevsent>
<prevsent>it should be noted that different variations of the shortest path approach are widely in use in many robust deep parsing systems.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
for instance, (riezler et al., 2002) <papid> P02-1035 </papid>uses the fewest chunk method to choose the best fragment analyses for sentences without full analysis.</citsent>
<aftsection>
<nextsent>the well-formed chunks are preferred over token chunks.
</nextsent>
<nextsent>with this partial parse selection method, the grammar achieves 100% coverage on unseen data.
</nextsent>
<nextsent>a similar approach is also used in (van noord et al, 1999).
</nextsent>
<nextsent>3.3 alternative estimation functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2056">
<title id=" W07-1217.xml">partial parse selection for robust deep processing </title>
<section> partial parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>generally speaking, the weights of the edges in the shortest path approach represent the quality of the local analyses and their likelihood of appearing in the analysis of the entire input.this is an interesting parallel to the parse selection models for the full analyses, where goodness score is usually assigned to the full analysis.
</prevsent>
<prevsent>for example, the parse disambiguation model described in (toutanova et al, 2002) uses maximum entropy approach to model the conditional probability of parse forgiven input sequence (t|w).
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
a similar approach has also been reported in (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2002; <papid> P02-1035 </papid>malouf and van noord, 2004).</citsent>
<aftsection>
<nextsent>forgiven partial parse ? = {t1, . . .
</nextsent>
<nextsent>, tk}, ? ={w1, . . .
</nextsent>
<nextsent>, wk} is segmentation of the input sequence so that each local analysis ti ? ?
</nextsent>
<nextsent>corresponds to substring wi ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2058">
<title id=" W07-1217.xml">partial parse selection for robust deep processing </title>
<section> partial parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>fn are the features and 1 . . .
</prevsent>
<prevsent>n are the parameters.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
the parameters can be efficiently estimated from treebank, as shown by (malouf, 2002).<papid> W02-2018 </papid></citsent>
<aftsection>
<nextsent>the only difference from the full parse selection model is that here intermediate results are used to generate events for training the model (i.e. the intermediate nodes are used as positive events if it occurs on one of the active tree, or as negative events if not).
</nextsent>
<nextsent>since there is huge number of intermediate results availalbe, we only randomly select part of them as training data.
</nextsent>
<nextsent>this is essentially similar to the approach in (osborne, 2000), <papid> C00-1085 </papid>where there is an in feasibly large number of training events, only part of which is used in the estimation step.</nextsent>
<nextsent>the exact features used in the log-linear model can significantly influence the disambiguation accu racy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2059">
<title id=" W07-1217.xml">partial parse selection for robust deep processing </title>
<section> partial parse selection.  </section>
<citcontext>
<prevsection>
<prevsent>the only difference from the full parse selection model is that here intermediate results are used to generate events for training the model (i.e. the intermediate nodes are used as positive events if it occurs on one of the active tree, or as negative events if not).
</prevsent>
<prevsent>since there is huge number of intermediate results availalbe, we only randomly select part of them as training data.
</prevsent>
</prevsection>
<citsent citstr=" C00-1085 ">
this is essentially similar to the approach in (osborne, 2000), <papid> C00-1085 </papid>where there is an in feasibly large number of training events, only part of which is used in the estimation step.</citsent>
<aftsection>
<nextsent>the exact features used in the log-linear model can significantly influence the disambiguation accuracy.
</nextsent>
<nextsent>in this experiment we used the same features 131 as those used in the pcfg-s model in (toutanova et al., 2002) (i.e., depth-1 derivation trees).
</nextsent>
<nextsent>the estimation of (?|w) is more difficult.
</nextsent>
<nextsent>in sense it is similar to segmentation or chunking model, where the task is to segment the input intofragments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2060">
<title id=" W07-1217.xml">partial parse selection for robust deep processing </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the parser out put on the test set is compared to the gold standard annotation, either with the widely used parseval measurement, or with more annotation-neutral dependency relations.
</prevsent>
<prevsent>for parsers based on manually compiled grammars, more human judgment is involved in the evaluation.
</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
with the evolution of the grammar, the treebank as the output from the grammar changes over time (oepen et al, 2002).<papid> C02-2025 </papid></citsent>
<aftsection>
<nextsent>the grammar writer inspects the parses generated by the grammar and either accepts?
</nextsent>
<nextsent>or rejects?
</nextsent>
<nextsent>the anal ysis.in partial parsing for manually compiled grammars, the criterion for acceptable analyses is lessevident.
</nextsent>
<nextsent>most current tree banking tools are not designed for annotating partial analyses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2061">
<title id=" W07-1217.xml">partial parse selection for robust deep processing </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the same set of 143 sentences from the wall street journal section 22 of the penn treebank isused.
</prevsent>
<prevsent>the rmrs semantic representations are generated from the partial parses with different selection models.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
to compare with, we used rasp 2 (briscoe et al, 2006), <papid> P06-4020 </papid>domain-independent robust parsing system for english.</citsent>
<aftsection>
<nextsent>according to (briscoe and car roll, 2006), <papid> P06-2006 </papid>the parser achieves fairly good accuracy around 80%.</nextsent>
<nextsent>the reasons why we choose raspfor the evaluation are: i) rasp has reasonable coverage and accuracy; ii) its output can be converted into rmrs representation with the lkb system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2062">
<title id=" W07-1217.xml">partial parse selection for robust deep processing </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the rmrs semantic representations are generated from the partial parses with different selection models.
</prevsent>
<prevsent>to compare with, we used rasp 2 (briscoe et al, 2006), <papid> P06-4020 </papid>domain-independent robust parsing system for english.</prevsent>
</prevsection>
<citsent citstr=" P06-2006 ">
according to (briscoe and car roll, 2006), <papid> P06-2006 </papid>the parser achieves fairly good accuracy around 80%.</citsent>
<aftsection>
<nextsent>the reasons why we choose raspfor the evaluation are: i) rasp has reasonable coverage and accuracy; ii) its output can be converted into rmrs representation with the lkb system.
</nextsent>
<nextsent>since there is no large scale (r)mrs treebank with sentences not covered by the delph-in precision grammars, we hope to use the rasps rmrs out put as standalone annotation to help the evaluation of the different partial parse selection models.
</nextsent>
<nextsent>to compare the rmrs from the rasp and the partial parse selection models, we used the similarity measurement proposed in (dridan and bond,2006).<papid> W06-1106 </papid></nextsent>
<nextsent>the comparison outputs distance value between two different rmrses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2063">
<title id=" W07-1217.xml">partial parse selection for robust deep processing </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the reasons why we choose raspfor the evaluation are: i) rasp has reasonable coverage and accuracy; ii) its output can be converted into rmrs representation with the lkb system.
</prevsent>
<prevsent>since there is no large scale (r)mrs treebank with sentences not covered by the delph-in precision grammars, we hope to use the rasps rmrs out put as standalone annotation to help the evaluation of the different partial parse selection models.
</prevsent>
</prevsection>
<citsent citstr=" W06-1106 ">
to compare the rmrs from the rasp and the partial parse selection models, we used the similarity measurement proposed in (dridan and bond,2006).<papid> W06-1106 </papid></citsent>
<aftsection>
<nextsent>the comparison outputs distance value between two different rmrses.
</nextsent>
<nextsent>we normalized the distance value to be between 0 and 1.
</nextsent>
<nextsent>for each selection model, the average rmrs distance from the rasp output is listed in table 2.
</nextsent>
<nextsent>rmrs dist.(?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2064">
<title id=" W07-1217.xml">partial parse selection for robust deep processing </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>4the repetition error of it?
</prevsent>
<prevsent>is interpreted as topicalization.
</prevsent>
</prevsection>
<citsent citstr=" P04-1005 ">
gions and potentially capturing meaningful text is shallow parsing method described in (johnson and charniak, 2004), <papid> P04-1005 </papid>which searches the text string for approximately repeated constituents.</citsent>
<aftsection>
<nextsent>we ran their system on our random sample of the fisher data, and compared its results to the partial parse output of the nine well-segmented partial parses analyses (every utterance of which contained some speaker-induceddisfluency) to see how well partial parsing could potentially fare as an approach for identifying dis fluent regions of speech text.
</nextsent>
<nextsent>often the (johnson and charniak, 2004) <papid> P04-1005 </papid>method identified dis fluent regions overlapped with identified fragments found in the partial parse, the removal of which would yield fluent sentence.</nextsent>
<nextsent>as we hope to learn confidence measures to determine which fragments are content less or repetitive in the future, we identified those partial parses where whole fragments could be deleted to obtain fluent and meaning-preserving sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2070">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, compound family estate should be interpreted as the estate owned by thefamily; an np such as dress of silk should be interpreted as denoting dress made from silk.
</prevsent>
<prevsent>the problem, while simple to state is hard to solve.
</prevsent>
</prevsection>
<citsent citstr=" W01-0511 ">
the reason is that the meaning of these constructions is most of the time ambiguous or implicit.currently, the best-performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (rosario and hearst, 2001), (<papid> W01-0511 </papid>rosario et al, 2002), (<papid> P02-1032 </papid>moldovan et al, 2004), (<papid> W04-2609 </papid>pantel and pennacchiotti, 2006), (<papid> P06-1015 </papid>pennacchiotti and pantel, 2006), (<papid> P06-1100 </papid>kim and baldwin, 2006), (snow et al., 2006), (<papid> P06-1101 </papid>girju et al, 2005; girju et al, 2006),or use statistical models on large collections of unlabeled data (berland and charniak, 1999), (<papid> P99-1008 </papid>lap ata and keller, 2004), (<papid> N04-1016 </papid>nakov and hearst, 2005),(<papid> W05-0603 </papid>turney, 2006).<papid> P06-1040 </papid></citsent>
<aftsection>
<nextsent>unlike unsupervised models, supervised knowledge-rich approaches rely heavily on large sets of annotated training data.
</nextsent>
<nextsent>for example, we previously showed (girju et al, 2006) that, forest from the computational linguistics community: workshop on multiword expressions at coling/acl 2006, 2004, 2003;computational lexical semantics workshop at acl 2004; tutorial on knowledge discovery from text at acl 2003; shared task on semantic role labeling at conll 2005, 2004 and at senseval 2005.
</nextsent>
<nextsent>168the task of automatic detection of part-whole relations, our systems learning curve reached plateau at 74% f-measure when trained on approximatively 10,000 positive and negative examples.
</nextsent>
<nextsent>interpreting nps correctly requires various types of information from world knowledge to complex context features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2071">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, compound family estate should be interpreted as the estate owned by thefamily; an np such as dress of silk should be interpreted as denoting dress made from silk.
</prevsent>
<prevsent>the problem, while simple to state is hard to solve.
</prevsent>
</prevsection>
<citsent citstr=" P02-1032 ">
the reason is that the meaning of these constructions is most of the time ambiguous or implicit.currently, the best-performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (rosario and hearst, 2001), (<papid> W01-0511 </papid>rosario et al, 2002), (<papid> P02-1032 </papid>moldovan et al, 2004), (<papid> W04-2609 </papid>pantel and pennacchiotti, 2006), (<papid> P06-1015 </papid>pennacchiotti and pantel, 2006), (<papid> P06-1100 </papid>kim and baldwin, 2006), (snow et al., 2006), (<papid> P06-1101 </papid>girju et al, 2005; girju et al, 2006),or use statistical models on large collections of unlabeled data (berland and charniak, 1999), (<papid> P99-1008 </papid>lap ata and keller, 2004), (<papid> N04-1016 </papid>nakov and hearst, 2005),(<papid> W05-0603 </papid>turney, 2006).<papid> P06-1040 </papid></citsent>
<aftsection>
<nextsent>unlike unsupervised models, supervised knowledge-rich approaches rely heavily on large sets of annotated training data.
</nextsent>
<nextsent>for example, we previously showed (girju et al, 2006) that, forest from the computational linguistics community: workshop on multiword expressions at coling/acl 2006, 2004, 2003;computational lexical semantics workshop at acl 2004; tutorial on knowledge discovery from text at acl 2003; shared task on semantic role labeling at conll 2005, 2004 and at senseval 2005.
</nextsent>
<nextsent>168the task of automatic detection of part-whole relations, our systems learning curve reached plateau at 74% f-measure when trained on approximatively 10,000 positive and negative examples.
</nextsent>
<nextsent>interpreting nps correctly requires various types of information from world knowledge to complex context features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2072">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, compound family estate should be interpreted as the estate owned by thefamily; an np such as dress of silk should be interpreted as denoting dress made from silk.
</prevsent>
<prevsent>the problem, while simple to state is hard to solve.
</prevsent>
</prevsection>
<citsent citstr=" W04-2609 ">
the reason is that the meaning of these constructions is most of the time ambiguous or implicit.currently, the best-performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (rosario and hearst, 2001), (<papid> W01-0511 </papid>rosario et al, 2002), (<papid> P02-1032 </papid>moldovan et al, 2004), (<papid> W04-2609 </papid>pantel and pennacchiotti, 2006), (<papid> P06-1015 </papid>pennacchiotti and pantel, 2006), (<papid> P06-1100 </papid>kim and baldwin, 2006), (snow et al., 2006), (<papid> P06-1101 </papid>girju et al, 2005; girju et al, 2006),or use statistical models on large collections of unlabeled data (berland and charniak, 1999), (<papid> P99-1008 </papid>lap ata and keller, 2004), (<papid> N04-1016 </papid>nakov and hearst, 2005),(<papid> W05-0603 </papid>turney, 2006).<papid> P06-1040 </papid></citsent>
<aftsection>
<nextsent>unlike unsupervised models, supervised knowledge-rich approaches rely heavily on large sets of annotated training data.
</nextsent>
<nextsent>for example, we previously showed (girju et al, 2006) that, forest from the computational linguistics community: workshop on multiword expressions at coling/acl 2006, 2004, 2003;computational lexical semantics workshop at acl 2004; tutorial on knowledge discovery from text at acl 2003; shared task on semantic role labeling at conll 2005, 2004 and at senseval 2005.
</nextsent>
<nextsent>168the task of automatic detection of part-whole relations, our systems learning curve reached plateau at 74% f-measure when trained on approximatively 10,000 positive and negative examples.
</nextsent>
<nextsent>interpreting nps correctly requires various types of information from world knowledge to complex context features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2073">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, compound family estate should be interpreted as the estate owned by thefamily; an np such as dress of silk should be interpreted as denoting dress made from silk.
</prevsent>
<prevsent>the problem, while simple to state is hard to solve.
</prevsent>
</prevsection>
<citsent citstr=" P06-1015 ">
the reason is that the meaning of these constructions is most of the time ambiguous or implicit.currently, the best-performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (rosario and hearst, 2001), (<papid> W01-0511 </papid>rosario et al, 2002), (<papid> P02-1032 </papid>moldovan et al, 2004), (<papid> W04-2609 </papid>pantel and pennacchiotti, 2006), (<papid> P06-1015 </papid>pennacchiotti and pantel, 2006), (<papid> P06-1100 </papid>kim and baldwin, 2006), (snow et al., 2006), (<papid> P06-1101 </papid>girju et al, 2005; girju et al, 2006),or use statistical models on large collections of unlabeled data (berland and charniak, 1999), (<papid> P99-1008 </papid>lap ata and keller, 2004), (<papid> N04-1016 </papid>nakov and hearst, 2005),(<papid> W05-0603 </papid>turney, 2006).<papid> P06-1040 </papid></citsent>
<aftsection>
<nextsent>unlike unsupervised models, supervised knowledge-rich approaches rely heavily on large sets of annotated training data.
</nextsent>
<nextsent>for example, we previously showed (girju et al, 2006) that, forest from the computational linguistics community: workshop on multiword expressions at coling/acl 2006, 2004, 2003;computational lexical semantics workshop at acl 2004; tutorial on knowledge discovery from text at acl 2003; shared task on semantic role labeling at conll 2005, 2004 and at senseval 2005.
</nextsent>
<nextsent>168the task of automatic detection of part-whole relations, our systems learning curve reached plateau at 74% f-measure when trained on approximatively 10,000 positive and negative examples.
</nextsent>
<nextsent>interpreting nps correctly requires various types of information from world knowledge to complex context features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2074">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, compound family estate should be interpreted as the estate owned by thefamily; an np such as dress of silk should be interpreted as denoting dress made from silk.
</prevsent>
<prevsent>the problem, while simple to state is hard to solve.
</prevsent>
</prevsection>
<citsent citstr=" P06-1100 ">
the reason is that the meaning of these constructions is most of the time ambiguous or implicit.currently, the best-performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (rosario and hearst, 2001), (<papid> W01-0511 </papid>rosario et al, 2002), (<papid> P02-1032 </papid>moldovan et al, 2004), (<papid> W04-2609 </papid>pantel and pennacchiotti, 2006), (<papid> P06-1015 </papid>pennacchiotti and pantel, 2006), (<papid> P06-1100 </papid>kim and baldwin, 2006), (snow et al., 2006), (<papid> P06-1101 </papid>girju et al, 2005; girju et al, 2006),or use statistical models on large collections of unlabeled data (berland and charniak, 1999), (<papid> P99-1008 </papid>lap ata and keller, 2004), (<papid> N04-1016 </papid>nakov and hearst, 2005),(<papid> W05-0603 </papid>turney, 2006).<papid> P06-1040 </papid></citsent>
<aftsection>
<nextsent>unlike unsupervised models, supervised knowledge-rich approaches rely heavily on large sets of annotated training data.
</nextsent>
<nextsent>for example, we previously showed (girju et al, 2006) that, forest from the computational linguistics community: workshop on multiword expressions at coling/acl 2006, 2004, 2003;computational lexical semantics workshop at acl 2004; tutorial on knowledge discovery from text at acl 2003; shared task on semantic role labeling at conll 2005, 2004 and at senseval 2005.
</nextsent>
<nextsent>168the task of automatic detection of part-whole relations, our systems learning curve reached plateau at 74% f-measure when trained on approximatively 10,000 positive and negative examples.
</nextsent>
<nextsent>interpreting nps correctly requires various types of information from world knowledge to complex context features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2075">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, compound family estate should be interpreted as the estate owned by thefamily; an np such as dress of silk should be interpreted as denoting dress made from silk.
</prevsent>
<prevsent>the problem, while simple to state is hard to solve.
</prevsent>
</prevsection>
<citsent citstr=" P06-1101 ">
the reason is that the meaning of these constructions is most of the time ambiguous or implicit.currently, the best-performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (rosario and hearst, 2001), (<papid> W01-0511 </papid>rosario et al, 2002), (<papid> P02-1032 </papid>moldovan et al, 2004), (<papid> W04-2609 </papid>pantel and pennacchiotti, 2006), (<papid> P06-1015 </papid>pennacchiotti and pantel, 2006), (<papid> P06-1100 </papid>kim and baldwin, 2006), (snow et al., 2006), (<papid> P06-1101 </papid>girju et al, 2005; girju et al, 2006),or use statistical models on large collections of unlabeled data (berland and charniak, 1999), (<papid> P99-1008 </papid>lap ata and keller, 2004), (<papid> N04-1016 </papid>nakov and hearst, 2005),(<papid> W05-0603 </papid>turney, 2006).<papid> P06-1040 </papid></citsent>
<aftsection>
<nextsent>unlike unsupervised models, supervised knowledge-rich approaches rely heavily on large sets of annotated training data.
</nextsent>
<nextsent>for example, we previously showed (girju et al, 2006) that, forest from the computational linguistics community: workshop on multiword expressions at coling/acl 2006, 2004, 2003;computational lexical semantics workshop at acl 2004; tutorial on knowledge discovery from text at acl 2003; shared task on semantic role labeling at conll 2005, 2004 and at senseval 2005.
</nextsent>
<nextsent>168the task of automatic detection of part-whole relations, our systems learning curve reached plateau at 74% f-measure when trained on approximatively 10,000 positive and negative examples.
</nextsent>
<nextsent>interpreting nps correctly requires various types of information from world knowledge to complex context features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2076">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, compound family estate should be interpreted as the estate owned by thefamily; an np such as dress of silk should be interpreted as denoting dress made from silk.
</prevsent>
<prevsent>the problem, while simple to state is hard to solve.
</prevsent>
</prevsection>
<citsent citstr=" P99-1008 ">
the reason is that the meaning of these constructions is most of the time ambiguous or implicit.currently, the best-performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (rosario and hearst, 2001), (<papid> W01-0511 </papid>rosario et al, 2002), (<papid> P02-1032 </papid>moldovan et al, 2004), (<papid> W04-2609 </papid>pantel and pennacchiotti, 2006), (<papid> P06-1015 </papid>pennacchiotti and pantel, 2006), (<papid> P06-1100 </papid>kim and baldwin, 2006), (snow et al., 2006), (<papid> P06-1101 </papid>girju et al, 2005; girju et al, 2006),or use statistical models on large collections of unlabeled data (berland and charniak, 1999), (<papid> P99-1008 </papid>lap ata and keller, 2004), (<papid> N04-1016 </papid>nakov and hearst, 2005),(<papid> W05-0603 </papid>turney, 2006).<papid> P06-1040 </papid></citsent>
<aftsection>
<nextsent>unlike unsupervised models, supervised knowledge-rich approaches rely heavily on large sets of annotated training data.
</nextsent>
<nextsent>for example, we previously showed (girju et al, 2006) that, forest from the computational linguistics community: workshop on multiword expressions at coling/acl 2006, 2004, 2003;computational lexical semantics workshop at acl 2004; tutorial on knowledge discovery from text at acl 2003; shared task on semantic role labeling at conll 2005, 2004 and at senseval 2005.
</nextsent>
<nextsent>168the task of automatic detection of part-whole relations, our systems learning curve reached plateau at 74% f-measure when trained on approximatively 10,000 positive and negative examples.
</nextsent>
<nextsent>interpreting nps correctly requires various types of information from world knowledge to complex context features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2077">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, compound family estate should be interpreted as the estate owned by thefamily; an np such as dress of silk should be interpreted as denoting dress made from silk.
</prevsent>
<prevsent>the problem, while simple to state is hard to solve.
</prevsent>
</prevsection>
<citsent citstr=" N04-1016 ">
the reason is that the meaning of these constructions is most of the time ambiguous or implicit.currently, the best-performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (rosario and hearst, 2001), (<papid> W01-0511 </papid>rosario et al, 2002), (<papid> P02-1032 </papid>moldovan et al, 2004), (<papid> W04-2609 </papid>pantel and pennacchiotti, 2006), (<papid> P06-1015 </papid>pennacchiotti and pantel, 2006), (<papid> P06-1100 </papid>kim and baldwin, 2006), (snow et al., 2006), (<papid> P06-1101 </papid>girju et al, 2005; girju et al, 2006),or use statistical models on large collections of unlabeled data (berland and charniak, 1999), (<papid> P99-1008 </papid>lap ata and keller, 2004), (<papid> N04-1016 </papid>nakov and hearst, 2005),(<papid> W05-0603 </papid>turney, 2006).<papid> P06-1040 </papid></citsent>
<aftsection>
<nextsent>unlike unsupervised models, supervised knowledge-rich approaches rely heavily on large sets of annotated training data.
</nextsent>
<nextsent>for example, we previously showed (girju et al, 2006) that, forest from the computational linguistics community: workshop on multiword expressions at coling/acl 2006, 2004, 2003;computational lexical semantics workshop at acl 2004; tutorial on knowledge discovery from text at acl 2003; shared task on semantic role labeling at conll 2005, 2004 and at senseval 2005.
</nextsent>
<nextsent>168the task of automatic detection of part-whole relations, our systems learning curve reached plateau at 74% f-measure when trained on approximatively 10,000 positive and negative examples.
</nextsent>
<nextsent>interpreting nps correctly requires various types of information from world knowledge to complex context features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2078">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, compound family estate should be interpreted as the estate owned by thefamily; an np such as dress of silk should be interpreted as denoting dress made from silk.
</prevsent>
<prevsent>the problem, while simple to state is hard to solve.
</prevsent>
</prevsection>
<citsent citstr=" W05-0603 ">
the reason is that the meaning of these constructions is most of the time ambiguous or implicit.currently, the best-performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (rosario and hearst, 2001), (<papid> W01-0511 </papid>rosario et al, 2002), (<papid> P02-1032 </papid>moldovan et al, 2004), (<papid> W04-2609 </papid>pantel and pennacchiotti, 2006), (<papid> P06-1015 </papid>pennacchiotti and pantel, 2006), (<papid> P06-1100 </papid>kim and baldwin, 2006), (snow et al., 2006), (<papid> P06-1101 </papid>girju et al, 2005; girju et al, 2006),or use statistical models on large collections of unlabeled data (berland and charniak, 1999), (<papid> P99-1008 </papid>lap ata and keller, 2004), (<papid> N04-1016 </papid>nakov and hearst, 2005),(<papid> W05-0603 </papid>turney, 2006).<papid> P06-1040 </papid></citsent>
<aftsection>
<nextsent>unlike unsupervised models, supervised knowledge-rich approaches rely heavily on large sets of annotated training data.
</nextsent>
<nextsent>for example, we previously showed (girju et al, 2006) that, forest from the computational linguistics community: workshop on multiword expressions at coling/acl 2006, 2004, 2003;computational lexical semantics workshop at acl 2004; tutorial on knowledge discovery from text at acl 2003; shared task on semantic role labeling at conll 2005, 2004 and at senseval 2005.
</nextsent>
<nextsent>168the task of automatic detection of part-whole relations, our systems learning curve reached plateau at 74% f-measure when trained on approximatively 10,000 positive and negative examples.
</nextsent>
<nextsent>interpreting nps correctly requires various types of information from world knowledge to complex context features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2079">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, compound family estate should be interpreted as the estate owned by thefamily; an np such as dress of silk should be interpreted as denoting dress made from silk.
</prevsent>
<prevsent>the problem, while simple to state is hard to solve.
</prevsent>
</prevsection>
<citsent citstr=" P06-1040 ">
the reason is that the meaning of these constructions is most of the time ambiguous or implicit.currently, the best-performing english np interpretation methods in computational linguistics focus mostly on two consecutive noun instances (noun compounds) and are either (weakly) supervised, knowledge-intensive (rosario and hearst, 2001), (<papid> W01-0511 </papid>rosario et al, 2002), (<papid> P02-1032 </papid>moldovan et al, 2004), (<papid> W04-2609 </papid>pantel and pennacchiotti, 2006), (<papid> P06-1015 </papid>pennacchiotti and pantel, 2006), (<papid> P06-1100 </papid>kim and baldwin, 2006), (snow et al., 2006), (<papid> P06-1101 </papid>girju et al, 2005; girju et al, 2006),or use statistical models on large collections of unlabeled data (berland and charniak, 1999), (<papid> P99-1008 </papid>lap ata and keller, 2004), (<papid> N04-1016 </papid>nakov and hearst, 2005),(<papid> W05-0603 </papid>turney, 2006).<papid> P06-1040 </papid></citsent>
<aftsection>
<nextsent>unlike unsupervised models, supervised knowledge-rich approaches rely heavily on large sets of annotated training data.
</nextsent>
<nextsent>for example, we previously showed (girju et al, 2006) that, forest from the computational linguistics community: workshop on multiword expressions at coling/acl 2006, 2004, 2003;computational lexical semantics workshop at acl 2004; tutorial on knowledge discovery from text at acl 2003; shared task on semantic role labeling at conll 2005, 2004 and at senseval 2005.
</nextsent>
<nextsent>168the task of automatic detection of part-whole relations, our systems learning curve reached plateau at 74% f-measure when trained on approximatively 10,000 positive and negative examples.
</nextsent>
<nextsent>interpreting nps correctly requires various types of information from world knowledge to complex context features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2080">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given training set of english noun phrases in context along with their translations in the five romance languages, our algorithm automatically learns classification function that is later on applied to unseen test instances for semantic interpretation.
</prevsent>
<prevsent>as training and test datawe used two text collections of different genre: europarl2 and cluvi3.
</prevsent>
</prevsection>
<citsent citstr=" P95-1007 ">
the training data was annotated with contextual features based on two state-ofthe-art classification tag sets: lauers set of 8 prepositions (lauer, 1995) <papid> P95-1007 </papid>and our list of 22 semantic re lations.</citsent>
<aftsection>
<nextsent>the system achieved an accuracy of 77.9% (europarl) and 74.31% (cluvi).
</nextsent>
<nextsent>the paper is organized as follows.
</nextsent>
<nextsent>section 2 presents summary of linguistic considerations ofnoun phrases.
</nextsent>
<nextsent>in section 3 we describe the list of semantic interpretation categories used along with observations regarding their distribution on the two dif 2http://www.isi.edu/koehn/europarl/ this corpus contains over 20 million words in eleven official languages of the european union covering the proceedings of the european parliament from 1996 to 2001.3cluvi - linguistic corpus of the university of vigo parallel corpus 2.1 - http://sli.uvigo.es/cluvi/.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2085">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> lists of semantic classification relations.  </section>
<citcontext>
<prevsection>
<prevsent>in this research we experiment with two sets of semantic classification categories defined at different abstraction levels.
</prevsent>
<prevsent>the first is core set of 22 semantic relations (22 srs), set which was identified by us from the linguistics literature and from various experiments after many iterations over period of time (moldovan and girju, 2003)4.
</prevsent>
</prevsection>
<citsent citstr=" P98-1015 ">
we proved 4there are also other lists of semantic relations used by the research community (e.g., (barker and szpakowicz, 1998)), <papid> P98-1015 </papid>but empirically that this set is encoded by noun ? noun pairs in noun phrases and is subset of our larger list of 35 semantic relations.</citsent>
<aftsection>
<nextsent>this list, presentedin table 1 along with examples and semantic argument frames, is general enough to cover large majority of text semantics while keeping the semantic relations to manageable number.
</nextsent>
<nextsent>a semantic argument frame is defined for each semantic relation and indicates the position of each semantic argument in the underlying relation.
</nextsent>
<nextsent>for example, arg1 is part of (whole) arg2?
</nextsent>
<nextsent>identifies the part(arg1) and the whole (arg2) entities of this relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2086">
<title id=" W07-1527.xml">experiments with an annotation scheme for a knowledge rich noun phrase interpretation system </title>
<section> the data.  </section>
<citcontext>
<prevsection>
<prevsent>specifically, the spanish-english, italian-english, french english and portuguese-english corpora were automatically aligned based on exact matches of english translations.
</prevsent>
<prevsent>then, only those english sentences which appeared verbatim in all four language pairs were considered.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the resulting english corpus contained 10,000 sentences which were syntactically parsed (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>from these we extracted the first 3,000 np instances (n n: 48.82% and p n: 51.18%).
</nextsent>
<nextsent>the cluvi text collection cluvi (linguistic corpus of the university ofvigo) is an open text repository of parallel corpora of contemporary oral and written languages, resource that besides galician also contains literary text collections in other romance languages.
</nextsent>
<nextsent>we focused only on the english-portuguese and english spanish literary parallel texts from the works of john steinbeck, h. g. wells, j. salinger, amongothers.
</nextsent>
<nextsent>using the cluvi search interface we created sentence-aligned parallel corpus of 2,800 english-spanish and english-portuguese sentences.the english versions were automatically parsed after which each n and p instance thus identified was manually mapped to the corresponding translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2087">
<title id=" W07-2087.xml">umnd2  sense clusters applied to the sense induction task of senseval4 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these instances are then clustered using kmeans where the number of clusters is discovered automatically using the adapted gap statistic.
</prevsent>
<prevsent>in these experiments sense clusters did not use any information outside of the raw untagged text thatwas to be clustered, and no tuning of the system was performed using external corpora.
</prevsent>
</prevsection>
<citsent citstr=" W07-2002 ">
the object of the sense induction task of senseval-4 (agirre and soroa, 2007) <papid> W07-2002 </papid>was to cluster 27,132 instances of 100 different words (35 nouns and 65 verbs) into senses or classes.</citsent>
<aftsection>
<nextsent>the task data consisted of the combination of the test and training data (minus the sense tags) from the english lexical sample task.
</nextsent>
<nextsent>each instance is context of several sentences which contains an occurrence of given word that serves as the target of sense induction.
</nextsent>
<nextsent>sense clusters is based on the presumption that words that occur in similar contexts will have similar meanings.
</nextsent>
<nextsent>this intuition has been presented as both the distributional hypothesis (harris, 1968) and the strong contextual hypothesis (miller and charles, 1991).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2088">
<title id=" W07-2087.xml">umnd2  sense clusters applied to the sense induction task of senseval4 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this intuition has been presented as both the distributional hypothesis (harris, 1968) and the strong contextual hypothesis (miller and charles, 1991).
</prevsent>
<prevsent>sense clusters has been inactive development at the university of minnesota, duluth since 2002.
</prevsent>
</prevsection>
<citsent citstr=" W04-2406 ">
it is an open source project that is freely available from source forge, and has been been described in detail in numerous publications (e.g., (purandare and pedersen, 2004), (<papid> W04-2406 </papid>pedersen et al, 2005), (pedersen and kulkarni, 2007)).</citsent>
<aftsection>
<nextsent>sense clusters supports variety of techniques for selecting lexical features, representing contexts to be clustered, determining the appropriate number of cluster automatically, clustering, labeling of clusters, and evaluating cluster quality.
</nextsent>
<nextsent>the configuration used in senseval-4 was just one possible combination of these techniques.
</nextsent>
<nextsent>for this task, sense clusters represents the instances to be clustered using second order cooccurrence vectors.
</nextsent>
<nextsent>these are constructed by first identifying word cooccurrences, and then replacing each word in an instance to be clustered with its co-occurrence vector.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2089">
<title id=" W07-2087.xml">umnd2  sense clusters applied to the sense induction task of senseval4 </title>
<section> methodology in sense induction task.  </section>
<citcontext>
<prevsection>
<prevsent>it consists of 295 words; in addition, all punctuation, single letter words, and numbers (with the exception of years) were eliminated.each of the contexts that contain particular target word is represented by single vector that is the average (or the centroid) of all the co-occurrencevectors found for the words that make up the context.
</prevsent>
<prevsent>this results in context by feature matrix, where the features are the words that occur with the words in the contexts (i.e., second order co? occurrences).
</prevsent>
</prevsection>
<citsent citstr=" N06-4007 ">
the kmeans algorithm is used for clustering the contexts, where the number of clusters is automatically discovered using the adapted gap statistic (pedersen and kulkarni, 2006).<papid> N06-4007 </papid></citsent>
<aftsection>
<nextsent>the premise of this method is to create randomized sample of data with the same characteristics of the observed data (i.e., the contexts to be clustered).this is done by fixing the marginal totals of the context by feature matrix and then generating randomized values that are consistent with those marginal totals.
</nextsent>
<nextsent>this creates matrix that is can be viewed as being from the same population as the observed data, except that the data is essentially noise (be cause it is randomly generated).
</nextsent>
<nextsent>the randomized data is clustered for successive values of from 1 to some upper limit (the number of contexts or the point at which the criterion functions have plateaued).
</nextsent>
<nextsent>for each value of the criterion function measures the quality of the clustering solution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2090">
<title id=" W07-2087.xml">umnd2  sense clusters applied to the sense induction task of senseval4 </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>this shows that while sense clusters was able to find relatively pure clusters, it errored in finding too few clusters, and was therefore penalized to some degree by the f-score.
</prevsent>
<prevsent>3.2 supervised evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W06-1669 ">
a supervised evaluation was also carried out on the same clustering of the 27,132 instances as was used in the unsupervised evaluation, following the method defined in (agirre et al, 2006).<papid> W06-1669 </papid></citsent>
<aftsection>
<nextsent>here the train portion (22,281 instances) is used to learn table of probabilities that is used to map discovered clusters in the test data to gold standard classes.
</nextsent>
<nextsent>the cluster assigned to each instance in the test portion (4,851 instances) is mapped (assigned) to the most probable class associated with that cluster as defined by this table.
</nextsent>
<nextsent>after this transformation is performed, the newly mapped test results are scored using the scorer2 program, which is the official evaluation program ofthe english lexical sample task and reports the fmeasure, which in these experiments is simply accuracy since precision and recall are the same.in table 2 we show the results of the supervised evaluation, which includes the highest and lowest score from participating systems, as well as table 2: supervised accuracy (test) all nouns verbs rank high 81.6 86.8 75.7 1 umnd2 80.6 84.5 76.2 2 random2 78.9 81.6 75.8 mfs 78.7 80.9 76.2 4 low 78.5 81.4 75.2 7 random4 78.4 81.1 75.5 random3 78.3 80.5 75.9 random10 77.9 79.8 75.8 random50 75.6 78.5 72.4 umnd2, mfs, and the same randomx baselines as included in the unsupervised evaluation.
</nextsent>
<nextsent>we observed that the difference between the scoreof the best performing system (high) and the ran dom50 baseline is six points (81.6 - 75.6).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2091">
<title id=" W07-2087.xml">umnd2  sense clusters applied to the sense induction task of senseval4 </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>this lack of penalty is due to the fact that the mapping operation takes potentially large number of clusters and maps them to relatively few classes (e.g., random50) and then performs the evaluation.
</prevsent>
<prevsent>396 3.3 sense clusters evaluation (f-measure).
</prevsent>
</prevsection>
<citsent citstr=" W97-0322 ">
an evaluation was carried out on the full 27,132 instance train+test dataset using the sense clusters evaluation methodology, which was first defined in (pedersen and bruce, 1997).<papid> W97-0322 </papid></citsent>
<aftsection>
<nextsent>this corresponds to an unsupervised version of the f-measure, which in these experiments can be viewed as an accuracy measure since precision and recall are the same (as is the case for the supervised measure).
</nextsent>
<nextsent>it aligns discovered clusters with classes such that their agreement is maximized.
</nextsent>
<nextsent>the clusters and classes must be aligned one to one, so large penalty can result if the number of discovered clusters differs from the number of gold standard classes.1 for umnd2, there were 145 discovered clusters and 368 gold standard classes.
</nextsent>
<nextsent>due to the one to one alignment that is required, the 145 discovered clusters were aligned with 145 gold standard classes such that there was agreement for 15,291 of 27,132 instances, leading to an f-measure (accuracy) of 56.36 percent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2092">
<title id=" W07-2016.xml">semeval2007 task17 english lexical sample srl and all words </title>
<section> word sense disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 ontonotes english lexical sample wsd.
</prevsent>
<prevsent>it is quite well accepted at this point that it is difficult to achieve high inter-annotator agreement onthe fine-grained wordnet style senses, and without corpus with high annotator agreement, automatic learning methods cannot perform at level that would be acceptable for downstream application.
</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
ontonotes (hovy et al, 2006) <papid> N06-2015 </papid>is project that has annotated several layers of semantic information ? including word senses, at high inter-annotator agreement of over 90%.</citsent>
<aftsection>
<nextsent>therefore we decided to use this data for the lexical sample task.
</nextsent>
<nextsent>2.2.1 data all the data for this task comes from the 1m wordwsj treebank.
</nextsent>
<nextsent>for the convenience of the participants who wanted to use syntactic parse information as features using an off-the-shelf syntactic parser, we decided to compose the training data of sections 02-21.
</nextsent>
<nextsent>for the test sets, we use data from sections 1http://www.cse.unt.edu/rada/senseval/senseval3/scoring/ 2scorer2 reports precision and recall scores for each system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2093">
<title id=" W07-2016.xml">semeval2007 task17 english lexical sample srl and all words </title>
<section> word sense disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>since the coarse and fine-grained disambiguation tasks have been part ofthe two previous senseval competitions, and we happen to have access to that data, we can take this opportunity to look at the disambiguation performancetrend.
</prevsent>
<prevsent>although different test sets were used for every evaluation, we can get rough indication of the trend.
</prevsent>
</prevsection>
<citsent citstr=" W04-0827 ">
for the fine-grained all words sense tagging task, which has always used wordnet, the system performance has ranged from our 59% to 65.2 (sen seval3, (decadt et al, 2004)) <papid> W04-0827 </papid>to 69% (seneval2, (chklovski and mihalcea, 2002)).<papid> W02-0817 </papid></citsent>
<aftsection>
<nextsent>because of time constraints on the data preparation, this years task has proportionally more verbs and fewer nouns than previous all-words english tasks, which may account for the lower scores.
</nextsent>
<nextsent>as expected, the lexical sample task using coarse 88 rank participant system id classifier 1 stephen tratz  stephen.tratz@pnl.gov  pnnl maxent 59.14.5.
</nextsent>
<nextsent>2 hwee tou ng  nght@comp.nus.edu.sg  nus-pt svm 58.74.5.
</nextsent>
<nextsent>3 rada mihalcea  rada@cs.unt.edu  unt-yahoo memory-based 58.34.5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2094">
<title id=" W07-2016.xml">semeval2007 task17 english lexical sample srl and all words </title>
<section> word sense disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>since the coarse and fine-grained disambiguation tasks have been part ofthe two previous senseval competitions, and we happen to have access to that data, we can take this opportunity to look at the disambiguation performancetrend.
</prevsent>
<prevsent>although different test sets were used for every evaluation, we can get rough indication of the trend.
</prevsent>
</prevsection>
<citsent citstr=" W02-0817 ">
for the fine-grained all words sense tagging task, which has always used wordnet, the system performance has ranged from our 59% to 65.2 (sen seval3, (decadt et al, 2004)) <papid> W04-0827 </papid>to 69% (seneval2, (chklovski and mihalcea, 2002)).<papid> W02-0817 </papid></citsent>
<aftsection>
<nextsent>because of time constraints on the data preparation, this years task has proportionally more verbs and fewer nouns than previous all-words english tasks, which may account for the lower scores.
</nextsent>
<nextsent>as expected, the lexical sample task using coarse 88 rank participant system id classifier 1 stephen tratz  stephen.tratz@pnl.gov  pnnl maxent 59.14.5.
</nextsent>
<nextsent>2 hwee tou ng  nght@comp.nus.edu.sg  nus-pt svm 58.74.5.
</nextsent>
<nextsent>3 rada mihalcea  rada@cs.unt.edu  unt-yahoo memory-based 58.34.5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2095">
<title id=" W07-2016.xml">semeval2007 task17 english lexical sample srl and all words </title>
<section> zheng-yu niu  niu zy@hotmail.com  i2r supervised 86.41.2.  </section>
<citcontext>
<prevsection>
<prevsent>svm 89.11.2 table 3: system performance for the ontonotes lexical sample task.
</prevsent>
<prevsent>systems marked with an * were post-competition bug-fix submissions.grained senses provides consistently higher performance than previous more fine-grained lexical sample tasks.
</prevsent>
</prevsection>
<citsent citstr=" N06-1016 ">
the high scores here were foreshadowed in an evaluation involving subset of the data last summer (chen et al, 2006).<papid> N06-1016 </papid></citsent>
<aftsection>
<nextsent>note that the best system performance is now closely approaching the ita for this data of over 90%.
</nextsent>
<nextsent>table 4 shows the performance of the top 8 systems on all the individual verbs and nouns in the test set.
</nextsent>
<nextsent>owing to space constraints we have removed some lemmas that have perfect or almost perfect accuracies.
</nextsent>
<nextsent>at the right are mentioned the average, minimum and maximum performances of the teams per lemma, and atthe bottom are the average scores per lemma (with out considering the lemma frequencies) and broken down by verbs and nouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2097">
<title id=" W07-2016.xml">semeval2007 task17 english lexical sample srl and all words </title>
<section> zheng-yu niu  niu zy@hotmail.com  i2r supervised 86.41.2.  </section>
<citcontext>
<prevsection>
<prevsent>(1) a. what do lobsters like to eatb. recent studies have shown that lobsters primarily feed on live fish, dig for clams, sea urchins, and feed on algae and eel-grass.
</prevsent>
<prevsent>c. in the early 20th century, mainers would only eat lobsters because the fish they caught was too valuable to eat themselves.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
traditionally, srl systems have been trained on either the propbank corpus (palmer et al, 2005) ? <papid> J05-1004 </papid>for two years, the conll workshop (carreras and ma`rquez, 2004; carreras and ma`rquez, 2005) has made this their shared task, or the framenet corpus ? senseval-3 used this for their shared task(litkowski, 2004).<papid> W04-0803 </papid></citsent>
<aftsection>
<nextsent>however, there is still little consensus in the linguistics and nlp communities about what set of role labels are most appropriate.
</nextsent>
<nextsent>the propbank corpus avoids this issue by using theory agnostic labels (arg0, arg1, . . .
</nextsent>
<nextsent>, arg5), and by defining those labels to have only verb-specific meanings.
</nextsent>
<nextsent>under this scheme, propbank can avoid making any claims about how any one verbs arguments relate to other verbs?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2098">
<title id=" W07-2016.xml">semeval2007 task17 english lexical sample srl and all words </title>
<section> zheng-yu niu  niu zy@hotmail.com  i2r supervised 86.41.2.  </section>
<citcontext>
<prevsection>
<prevsent>(1) a. what do lobsters like to eatb. recent studies have shown that lobsters primarily feed on live fish, dig for clams, sea urchins, and feed on algae and eel-grass.
</prevsent>
<prevsent>c. in the early 20th century, mainers would only eat lobsters because the fish they caught was too valuable to eat themselves.
</prevsent>
</prevsection>
<citsent citstr=" W04-0803 ">
traditionally, srl systems have been trained on either the propbank corpus (palmer et al, 2005) ? <papid> J05-1004 </papid>for two years, the conll workshop (carreras and ma`rquez, 2004; carreras and ma`rquez, 2005) has made this their shared task, or the framenet corpus ? senseval-3 used this for their shared task(litkowski, 2004).<papid> W04-0803 </papid></citsent>
<aftsection>
<nextsent>however, there is still little consensus in the linguistics and nlp communities about what set of role labels are most appropriate.
</nextsent>
<nextsent>the propbank corpus avoids this issue by using theory agnostic labels (arg0, arg1, . . .
</nextsent>
<nextsent>, arg5), and by defining those labels to have only verb-specific meanings.
</nextsent>
<nextsent>under this scheme, propbank can avoid making any claims about how any one verbs arguments relate to other verbs?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2099">
<title id=" W08-0803.xml">information extraction using finite state automata and syllable ngrams in a mobile environment </title>
<section> lightweight information extraction sys-.  </section>
<citcontext>
<prevsection>
<prevsent>automata although short messages in an appointment do main often include many incorrect words, temporal instances like dates and times are expressed as correct as possible because they are very important to appointment management.
</prevsent>
<prevsent>in addition, temporal instances are expressed intractable numbers of surface forms in order to make message receivers easily be understood.
</prevsent>
</prevsection>
<citsent citstr=" M98-1028 ">
in muc-7, these kinds of temporal instances are called timex (chinchor, 1998), <papid> M98-1028 </papid>and it has known that timex can be easily extracted by using fsa (srihari, 2001).</citsent>
<aftsection>
<nextsent>based on these previous works, the proposed system extracts temporal instances from short messages by using fsa, as shown in figure 2.
</nextsent>
<nextsent>figure 2.
</nextsent>
<nextsent>an example of fsa for date extraction 2.2 information extraction using statistical.
</nextsent>
<nextsent>syllable n-grams unlike dates and times, locations and topics not only have various surface forms, but also their constituent words are not included in closed set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2103">
<title id=" W07-1205.xml">deep grammars in a tree labeling approach to syntax based statistical machine translation </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we propose new syntax based machine translation (mt) approach based on reducing the mt task to tree labeling task, which is further decomposed into sequence of simple decisions for which discriminative classifiers can be trained.
</prevsent>
<prevsent>the approach is very flexible and we believe that it is particularly well-suitedfor exploiting the linguistic knowledge encoded in deep grammars whenever possible, while at the same time taking advantage of data-based techniques that have proven powerful basis for mt, as recent advances in statistical mt show.
</prevsent>
</prevsection>
<citsent citstr=" W02-1503 ">
a full system using the lexical-functional grammar (lfg) parsing system xle and the grammars from the parallel grammar development project (pargram; (butt et al., 2002)) <papid> W02-1503 </papid>has been implemented, and we present preliminary results on english-togerman translation with tree-labeling system trained on small subsection of the eu roparl corpus.</citsent>
<aftsection>
<nextsent>machine translation (mt) is probably the oldest application of what we call deep linguistic processing techniques today.
</nextsent>
<nextsent>but from its inception, there have been alternative considerations of approaching thetask with data-based statistical techniques (cf.
</nextsent>
<nextsent>warren weavers well-known memo from 1949).
</nextsent>
<nextsent>only with fairly recent advances in computer technology have researchers been able to build effective statistical mt prototypes, but in the last few years, the statistical approach has received enormous research interest and made significant progress.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2104">
<title id=" W07-1205.xml">deep grammars in a tree labeling approach to syntax based statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>warren weavers well-known memo from 1949).
</prevsent>
<prevsent>only with fairly recent advances in computer technology have researchers been able to build effective statistical mt prototypes, but in the last few years, the statistical approach has received enormous research interest and made significant progress.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the most successful statistical mt paradigm has been, for while now, the so-call phrase-based mt approach (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>in this paradigm, sentences are translated from source language to target language through the repeated substitution of contiguous word sequences (phrases?)
</nextsent>
<nextsent>from the source language for word sequences in the target language.
</nextsent>
<nextsent>training of the phrase translation model builds on top of standard statistical word alignment over the training corpus of parallel text (brown et al, 1993) <papid> J93-2003 </papid>for identifying corresponding word blocks, assuming no further linguistic analysis of the source or target language.</nextsent>
<nextsent>in decoding, i.e. the application of the acquired translation model to unseen source sentences, these systems then typically relyon ngram language models and simple statistical reordering models to shuffle the phrases into an order that is coherent in the target language.an obvious advantage of statistical mt approaches is that they can adopt (often very idiomatic) translations of mid- to high-frequency constructions without requiring any language-pair specific engineering work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2105">
<title id=" W07-1205.xml">deep grammars in a tree labeling approach to syntax based statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>in this paradigm, sentences are translated from source language to target language through the repeated substitution of contiguous word sequences (phrases?)
</prevsent>
<prevsent>from the source language for word sequences in the target language.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
training of the phrase translation model builds on top of standard statistical word alignment over the training corpus of parallel text (brown et al, 1993) <papid> J93-2003 </papid>for identifying corresponding word blocks, assuming no further linguistic analysis of the source or target language.</citsent>
<aftsection>
<nextsent>in decoding, i.e. the application of the acquired translation model to unseen source sentences, these systems then typically relyon ngram language models and simple statistical reordering models to shuffle the phrases into an order that is coherent in the target language.an obvious advantage of statistical mt approaches is that they can adopt (often very idiomatic) translations of mid- to high-frequency constructions without requiring any language-pair specific engineering work.
</nextsent>
<nextsent>at the same time it is clear that linguistics-free approach is limited in whatit can ultimately achieve: only linguistically informed systems can detect certain generalizations from lower-frequency constructions in the data and successfully apply them in similar but different linguistic context.
</nextsent>
<nextsent>hence, the idea of hybrid?
</nextsent>
<nextsent>mt, exploiting both linguistic and statistical information is fairly old.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2106">
<title id=" W07-1205.xml">deep grammars in a tree labeling approach to syntax based statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>mt, exploiting both linguistic and statistical information is fairly old.
</prevsent>
<prevsent>here we will not consider classical, rule based systems with some added data-based resource acquisition (although they may be among the best candidates for high-quality special-purpose translation ? but adaption to new language pairs and sublanguages is very costly for these systems).
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
the other form of hybridization ? statistical mt model that is based on deeper analysis of the syntactic 33structure of sentence ? has also long been identified as desirable objective in principle (consider (wu, 1997; <papid> J97-3002 </papid>yamada and knight, 2001)).<papid> P01-1067 </papid></citsent>
<aftsection>
<nextsent>however, attempts to retrofit syntactic information into the phrase-based paradigm have not met with enormous success (koehn et al, 2003; och et al, 2003)1, and purely phrase-based mt systems continue to outperform these syntax/phrase-based hybrids.
</nextsent>
<nextsent>in this work, we try to make fresh start withsyntax-based statistical mt, discarding the phrase based paradigm and designing mt system fromthe ground up, using syntax as our central guiding star ? besides the word alignment over parallel corpus.
</nextsent>
<nextsent>our approach is compatible with andcan benefit substantially from rich linguistic representations obtained from deep grammars like thepargram lfgs.
</nextsent>
<nextsent>nevertheless, contrary to classical inter lingual or deep transfer-based systems, the generative stochastic model that drives our syst emis grounded only in the cross-language word alignment and surface-based phrase structure tree forthe source language and will thus degrade gracefully on input with parsing issues ? which we suspect is an important feature for making the overall system competitive with the highly general phrase based mt approach.preliminary evaluation of our nascent system indicates that this new approach might well have the potential to finally realize some of the promises of syntax in statistical mt.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2107">
<title id=" W07-1205.xml">deep grammars in a tree labeling approach to syntax based statistical machine translation </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>mt, exploiting both linguistic and statistical information is fairly old.
</prevsent>
<prevsent>here we will not consider classical, rule based systems with some added data-based resource acquisition (although they may be among the best candidates for high-quality special-purpose translation ? but adaption to new language pairs and sublanguages is very costly for these systems).
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
the other form of hybridization ? statistical mt model that is based on deeper analysis of the syntactic 33structure of sentence ? has also long been identified as desirable objective in principle (consider (wu, 1997; <papid> J97-3002 </papid>yamada and knight, 2001)).<papid> P01-1067 </papid></citsent>
<aftsection>
<nextsent>however, attempts to retrofit syntactic information into the phrase-based paradigm have not met with enormous success (koehn et al, 2003; och et al, 2003)1, and purely phrase-based mt systems continue to outperform these syntax/phrase-based hybrids.
</nextsent>
<nextsent>in this work, we try to make fresh start withsyntax-based statistical mt, discarding the phrase based paradigm and designing mt system fromthe ground up, using syntax as our central guiding star ? besides the word alignment over parallel corpus.
</nextsent>
<nextsent>our approach is compatible with andcan benefit substantially from rich linguistic representations obtained from deep grammars like thepargram lfgs.
</nextsent>
<nextsent>nevertheless, contrary to classical inter lingual or deep transfer-based systems, the generative stochastic model that drives our syst emis grounded only in the cross-language word alignment and surface-based phrase structure tree forthe source language and will thus degrade gracefully on input with parsing issues ? which we suspect is an important feature for making the overall system competitive with the highly general phrase based mt approach.preliminary evaluation of our nascent system indicates that this new approach might well have the potential to finally realize some of the promises of syntax in statistical mt.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2108">
<title id=" W07-1205.xml">deep grammars in a tree labeling approach to syntax based statistical machine translation </title>
<section> general task.  </section>
<citcontext>
<prevsection>
<prevsent>we refer to these annotated sentence pairs as complete translation objects.
</prevsent>
<prevsent>secondly, we have an evaluation corpus of sourcesentences.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
these sentences are annotated with subset of the auxiliary information used to annotate the1(chiang, 2005) <papid> P05-1033 </papid>also reports that with his hierarchical generalization of the phrase-based approach, the addition of parser information doesnt lead to any improvements.</citsent>
<aftsection>
<nextsent>figure 1: example translation object.
</nextsent>
<nextsent>training corpus.
</nextsent>
<nextsent>we refer to these partially annotated source sentences as partial translation objects.
</nextsent>
<nextsent>the task at hand: use the training corpus to learna procedure, through which we can successfully induce complete translation object from partial translation object.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2109">
<title id=" W07-1205.xml">deep grammars in a tree labeling approach to syntax based statistical machine translation </title>
<section> the generative process.  </section>
<citcontext>
<prevsection>
<prevsent>the use of discriminative classifiers makes our approach very flexible in terms of the information thatcan be exploited in the labeling (or translation) process.
</prevsent>
<prevsent>any information that can be encoded as features relative to ghkm tree nodes can be used.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
for the experiments reported in this paper, we parsed the source language side of parallel corpus (a small subsection of the english-german europarl corpus; (koehn, 2002)) with the xle system, using 36the pargram lfg grammar and applying probabilistic disambiguation (riezler et al, 2002) <papid> P02-1035 </papid>to obtaina single analysis (i.e., c-structure [phrase structure tree] and an f-structure [an associated attribute value matrix with morphosyntactic feature information and shallow semantic interpretation]) for each sentence.</citsent>
<aftsection>
<nextsent>a fall-back mechanism integrated in the parser/grammar ensures that even for sentences that do not receive full parse, sub strings are deeply parsed and can often be treated successfully.we convert the c-structure/f-structure representation that is based on xles sophisticated word internal analysis into plain phrase structure tree representation based on the original tokens in the source language string.
</nextsent>
<nextsent>the morphosyntactic feature information from f-structure is copied as additional labeling information to the relevant ghkm tree nodes, and the f-structural dependency relation among linguistic units is translated into relation among corresponding ghkm tree nodes.
</nextsent>
<nextsent>the relational information is then used to systematically extend the learning feature set for the tree-node based classifiers.in future experiments, we also plan to exploit linguistic knowledge about the target language by fac tori zing the generation of target language words into separate generation of lemmas and the various morphosyntactic features.
</nextsent>
<nextsent>in decoding, morphological generator will be used to generate string of surface words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2110">
<title id=" W08-0111.xml">learning contrastive connectives in sentence realization ranking </title>
<section> corpus study.  </section>
<citcontext>
<prevsection>
<prevsent>based on these findings and previous work on contrastive connectives, we present suggestions for modifying both the generator and the ranker in order to improve the generation of realizations containing contrastive connectives.1we thank marilyn walker and her research team for making all of the match system data available for our study, especially including the sparky restaurant corpus.
</prevsent>
<prevsent>2.1 sparky restaurant corpus.
</prevsent>
</prevsection>
<citsent citstr=" A97-1039 ">
the sparky restaurant corpus was generated by the match spoken language generator (walker et al., 2007) which consists of dialog manager, spur text planner (walker et al, 2004), sparky sentence planner (walker et al, 2007), and realpro surface realizer (lavoie and rambow, 1997).<papid> A97-1039 </papid></citsent>
<aftsection>
<nextsent>the corpus contains realizations for 3 dialogue strategies: ? recommend (rec): recommend an entity from set of entities ? compare-2 (c2): compare 2 entities ? compare-3 (c3): compare 3 or more entities each strategy contains 30 content plans from which either 16 or 20 sentence plans were generated by the sparky sentence plan generator.
</nextsent>
<nextsent>4 sentence plans were discarded due to duplication upon realization, totaling 1756 realizations in the corpus.2 content plan consists of several assertions andthe relations which hold between them.
</nextsent>
<nextsent>content plans from the recommend strategy exclusively employ the rhetorical structure theory(rst) (mann and thompson, 1987) relation justify while those from compare-2 use contrast and elaboration.
</nextsent>
<nextsent>compare-3 content plans consists mostly of contrast and elaboration relations, though some use only justify.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2111">
<title id=" W08-0122.xml">discourse level opinion relations an annotation study </title>
<section> opinion frames.  </section>
<citcontext>
<prevsection>
<prevsent>the components of opinion frames are individual opinions and the relationships between their targets.
</prevsent>
<prevsent>we address two types of opinions, sentiment andarguing.
</prevsent>
</prevsection>
<citsent citstr=" W05-0308 ">
following (wilson and wiebe, 2005; <papid> W05-0308 </papid>somasundaran et al, 2007), sentiment includes positive and negative evaluations, emotions, and judgments, while arguing includes arguing for or against something, and arguing that something should or should not be done.</citsent>
<aftsection>
<nextsent>in our examples, the lexical anchors revealing the opinion type (as the words are interpreted in context) are indicated in boldface.
</nextsent>
<nextsent>in addition, the text span capturing the target of the opinion (again, as interpreted in context) is indicated in italics.
</nextsent>
<nextsent>(2) d:: . . .
</nextsent>
<nextsent>this kind of rubbery material, its bit more bouncy, like you said they get chucked around lot.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2115">
<title id=" W08-0122.xml">discourse level opinion relations an annotation study </title>
<section> annotation studies.  </section>
<citcontext>
<prevsection>
<prevsent>the results, in table 5, show that ? both fortype and polarity tagging is very high.
</prevsent>
<prevsent>this confirms our hypothesis that sentiment and arguing can be reliably distinguished once the opinion spans areknown.
</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
our polarity detection task shows an improvement in ? over similar polarity assignment task by wilson et al (2005) <papid> H05-1044 </papid>for the news corpus (?</citsent>
<aftsection>
<nextsent>of 0.72).
</nextsent>
<nextsent>we believe this improvement can partly be attributed to the target information available to our annotators.
</nextsent>
<nextsent>4.4 target linking.
</nextsent>
<nextsent>as an intuitive first step in evaluating target linking, we treat target links in the discourse similarly to anaphoric chains and apply methods developed for co-reference resolution (passonneau, 2004) for ourevaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2116">
<title id=" W08-0122.xml">discourse level opinion relations an annotation study </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>i think that would not work so well.
</prevsent>
<prevsent>you wanna have both options.
</prevsent>
</prevsection>
<citsent citstr=" W03-0404 ">
evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (riloff et al, 2003;<papid> W03-0404 </papid>pang and lee, 2004)) <papid> P04-1035 </papid>and adjacency pair information has been used to predict congressional votes (thomas et al, 2006).<papid> W06-1639 </papid></citsent>
<aftsection>
<nextsent>however, these methods do not explicitly model the relations between opinions.
</nextsent>
<nextsent>additionally, in our scheme opinions that are notin the immediate context may be allowed to influence the interpretation of given opinion via target chains.
</nextsent>
<nextsent>polanyi and zaenen (2006), in their discussion on contextual valence shift ers, have also observed the phenomena described in this work - namely that central topic may be divided into sub topics in order to perform evaluations, and that discourse structure can influence the overall interpretation of valence.snyder and barzilay (2007) <papid> N07-1038 </papid>combine an agreement model based on contrastive rst relations witha local aspect (or target) model to make more informed overall decision for sentiment classification.the contrastive cue indicates change in the sentiment polarity.</nextsent>
<nextsent>in our scheme, their aspects would be related as same and their high contrast relations would result in frames such as spsnsame, snsp same.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2117">
<title id=" W08-0122.xml">discourse level opinion relations an annotation study </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>i think that would not work so well.
</prevsent>
<prevsent>you wanna have both options.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (riloff et al, 2003;<papid> W03-0404 </papid>pang and lee, 2004)) <papid> P04-1035 </papid>and adjacency pair information has been used to predict congressional votes (thomas et al, 2006).<papid> W06-1639 </papid></citsent>
<aftsection>
<nextsent>however, these methods do not explicitly model the relations between opinions.
</nextsent>
<nextsent>additionally, in our scheme opinions that are notin the immediate context may be allowed to influence the interpretation of given opinion via target chains.
</nextsent>
<nextsent>polanyi and zaenen (2006), in their discussion on contextual valence shift ers, have also observed the phenomena described in this work - namely that central topic may be divided into sub topics in order to perform evaluations, and that discourse structure can influence the overall interpretation of valence.snyder and barzilay (2007) <papid> N07-1038 </papid>combine an agreement model based on contrastive rst relations witha local aspect (or target) model to make more informed overall decision for sentiment classification.the contrastive cue indicates change in the sentiment polarity.</nextsent>
<nextsent>in our scheme, their aspects would be related as same and their high contrast relations would result in frames such as spsnsame, snsp same.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2118">
<title id=" W08-0122.xml">discourse level opinion relations an annotation study </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>i think that would not work so well.
</prevsent>
<prevsent>you wanna have both options.
</prevsent>
</prevsection>
<citsent citstr=" W06-1639 ">
evidence from the surrounding context has been used previously to determine if the current sentence should be subjective/objective (riloff et al, 2003;<papid> W03-0404 </papid>pang and lee, 2004)) <papid> P04-1035 </papid>and adjacency pair information has been used to predict congressional votes (thomas et al, 2006).<papid> W06-1639 </papid></citsent>
<aftsection>
<nextsent>however, these methods do not explicitly model the relations between opinions.
</nextsent>
<nextsent>additionally, in our scheme opinions that are notin the immediate context may be allowed to influence the interpretation of given opinion via target chains.
</nextsent>
<nextsent>polanyi and zaenen (2006), in their discussion on contextual valence shift ers, have also observed the phenomena described in this work - namely that central topic may be divided into sub topics in order to perform evaluations, and that discourse structure can influence the overall interpretation of valence.snyder and barzilay (2007) <papid> N07-1038 </papid>combine an agreement model based on contrastive rst relations witha local aspect (or target) model to make more informed overall decision for sentiment classification.the contrastive cue indicates change in the sentiment polarity.</nextsent>
<nextsent>in our scheme, their aspects would be related as same and their high contrast relations would result in frames such as spsnsame, snsp same.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2119">
<title id=" W08-0122.xml">discourse level opinion relations an annotation study </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, these methods do not explicitly model the relations between opinions.
</prevsent>
<prevsent>additionally, in our scheme opinions that are notin the immediate context may be allowed to influence the interpretation of given opinion via target chains.
</prevsent>
</prevsection>
<citsent citstr=" N07-1038 ">
polanyi and zaenen (2006), in their discussion on contextual valence shift ers, have also observed the phenomena described in this work - namely that central topic may be divided into sub topics in order to perform evaluations, and that discourse structure can influence the overall interpretation of valence.snyder and barzilay (2007) <papid> N07-1038 </papid>combine an agreement model based on contrastive rst relations witha local aspect (or target) model to make more informed overall decision for sentiment classification.the contrastive cue indicates change in the sentiment polarity.</citsent>
<aftsection>
<nextsent>in our scheme, their aspects would be related as same and their high contrast relations would result in frames such as spsnsame, snsp same.
</nextsent>
<nextsent>additionally, our frame relations would link sentiments across non-adjacent clauses, and make connections via alt target relations.
</nextsent>
<nextsent>135 considering the discourse relation annotations inthe pdtb (prasad et al, 2006), <papid> W06-0305 </papid>there can be alignment between discourse relations (like contrast) andour opinion frames when the frames represent dominant relations between two clauses.</nextsent>
<nextsent>however, whenthe relation between opinions is not the most prominent one between two clauses, the discourse relation may not align with the opinion frames.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2120">
<title id=" W08-0122.xml">discourse level opinion relations an annotation study </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in our scheme, their aspects would be related as same and their high contrast relations would result in frames such as spsnsame, snsp same.
</prevsent>
<prevsent>additionally, our frame relations would link sentiments across non-adjacent clauses, and make connections via alt target relations.
</prevsent>
</prevsection>
<citsent citstr=" W06-0305 ">
135 considering the discourse relation annotations inthe pdtb (prasad et al, 2006), <papid> W06-0305 </papid>there can be alignment between discourse relations (like contrast) andour opinion frames when the frames represent dominant relations between two clauses.</citsent>
<aftsection>
<nextsent>however, whenthe relation between opinions is not the most prominent one between two clauses, the discourse relation may not align with the opinion frames.
</nextsent>
<nextsent>and when an opinion frame is between two opinions in the same clause, there would be no discourse relation counterpart at all.
</nextsent>
<nextsent>further, opinion frames assume particular intentions that are not necessary for the establishment of ostensibly similar discourse relations.
</nextsent>
<nextsent>for example, we may not impose an opinion frame evenif there are contrastive cues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2121">
<title id=" W07-2063.xml">shef semantic tagging and summarization techniques applied to cross document coreference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>deciding if two documents refer to the same individual is difficult problem because names are highly ambiguous.
</prevsent>
<prevsent>automatic techniques for solving this problem are required not only for better access to information but also in natural language processing applications such as multi document summarization and information extraction.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
here, we concentrate on the following semeval 2007 web people search task (artiles et al, 2007): <papid> W07-2012 </papid>search engine user types in person name as query.</citsent>
<aftsection>
<nextsent>instead of ranking web pages, an ideal system should organize search results in as many clusters as there are different people sharing the same name in the documents returned by the search engine.
</nextsent>
<nextsent>the input is, therefore, the results given by web search engine using person name as query.
</nextsent>
<nextsent>the output is number of sets, each containing documents referring to the same individual.
</nextsent>
<nextsent>as past and recent research (bagga and baldwin, 1998; <papid> P98-1012 </papid>phan et al, 2006), we have addressed the problem as document clustering problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2122">
<title id=" W07-2063.xml">shef semantic tagging and summarization techniques applied to cross document coreference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the input is, therefore, the results given by web search engine using person name as query.
</prevsent>
<prevsent>the output is number of sets, each containing documents referring to the same individual.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
as past and recent research (bagga and baldwin, 1998; <papid> P98-1012 </papid>phan et al, 2006), we have addressed the problem as document clustering problem.</citsent>
<aftsection>
<nextsent>for our first participation in semeval 2007, we use two ap proaches: lexical or bag-of-words approach and semantic based approach.
</nextsent>
<nextsent>we have implemented ourown clustering algorithms but relyon available extraction and summarization technology developed in our laboratory to produce document representations used as input for the clustering procedure.
</nextsent>
<nextsent>we have implemented an agglomerative clustering algorithm.
</nextsent>
<nextsent>the input to the algorithm is set of document representations implemented as vectors ofterms and weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2123">
<title id=" W07-2063.xml">shef semantic tagging and summarization techniques applied to cross document coreference </title>
<section> extraction and summarization.  </section>
<citcontext>
<prevsection>
<prevsent>if this similarity is less than certain threshold the algorithm stops.
</prevsent>
<prevsent>the input for analysis is set of documents and person name (first name and last name).
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
the documents are analysed by the default gate1 annie system (cunningham et al, 2002) <papid> P02-1022 </papid>and single document summarization modules (saggion and gaizauskas, 2004b) from our summarizationtoolkit2 . no attempt is made to analyse or use contextual information given with the input document.</citsent>
<aftsection>
<nextsent>the processing elements include:  document token isation  sentence splitting  parts-of-speech tagging  named entity recognition using gazetteer lookup module and regular expressions named entity coreference using an orthographic name matchernamed entities of type person, organization, address, date, and location are considered relevant document terms and stored in special named entity called mention.
</nextsent>
<nextsent>coreference chains are created and analysed and if they contain an entity matching the target persons surname, all elements of the chain are marked.
</nextsent>
<nextsent>extractive summaries are created for each document, sentence belongs to the summary if it contains mention which is co referent with the target entity.
</nextsent>
<nextsent>using language resources creation modules from the summarization tool, two frequency tables are 1http://gate.ac.uk 2http://www.dcs.shef.ac.uk/saggioncreated for each document set (or person): (i) an inverted document frequency table for words (no normalisation is applied); and (ii) an inverted frequency table for mentions (the full entity string is used, no normalisation is applied).statistics (term frequencies and tf*idf) are computed over tokens and mentions using the appropriate tables (these tools are part of the summarization toolkit) and vector representations created for each document (same as in (bagga and baldwin, 1998)).<papid> P98-1012 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2125">
<title id=" W07-0802.xml">implementation of the arabic numerals and their syntax in gf </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(nouncase det.n det.d); = agrp3 cn.h cn.g number }; oper agrp3 : species -  gender -  number -  pergennum= \h,g,n -  case  h,n  of {  nohum,pl  =  per3 fem sg; _ =  per3 n }; the agrp3 helping function tests for the case when the species and number are nonhuman andplural.
</prevsent>
<prevsent>this case is treated in agreement as the feminine singular.
</prevsent>
</prevsection>
<citsent citstr=" P00-1025 ">
a large-scale implementation of the arabic morphological system is the xerox arabic morphological analyzer and generator (beesley and karttunen,2000; <papid> P00-1025 </papid>beesley, 2001).</citsent>
<aftsection>
<nextsent>this system is developed using only the xerox finite state technology tools(beesley and karttunen, 2003) from which an arabic finite state lexical transducer is written.
</nextsent>
<nextsent>a research version is available for online testing, and an expanded and updated version can be obtained witha commercial license.
</nextsent>
<nextsent>another notable computational model of the arabic morphology is tim buck walters arabic morphological analyzer (buckwal ter, 2004<papid> W04-1606 </papid>b,a).</nextsent>
<nextsent>buck walters analyzer parses arabic words and gives all their possible morphological interpretations, each solution having unique lemma id, different word constituents, the part-of-speech, and english glosses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2126">
<title id=" W07-0802.xml">implementation of the arabic numerals and their syntax in gf </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this system is developed using only the xerox finite state technology tools(beesley and karttunen, 2003) from which an arabic finite state lexical transducer is written.
</prevsent>
<prevsent>a research version is available for online testing, and an expanded and updated version can be obtained witha commercial license.
</prevsent>
</prevsection>
<citsent citstr=" W04-1606 ">
another notable computational model of the arabic morphology is tim buck walters arabic morphological analyzer (buckwal ter, 2004<papid> W04-1606 </papid>b,a).</citsent>
<aftsection>
<nextsent>buck walters analyzer parses arabic words and gives all their possible morphological interpretations, each solution having unique lemma id, different word constituents, the part-of-speech, and english glosses.
</nextsent>
<nextsent>other works that also use functional languages forthe treatment of arabic include morphology system by smrz?
</nextsent>
<nextsent>(in prep.).
</nextsent>
<nextsent>this work is based on functional morphology (forsberg and ranta, 2004), methodology for building morphological systems in the haskell programming language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2127">
<title id=" W07-1206.xml">question answering based on semantic roles </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a large part of the work done in nlp deals with exploring how different tools and resources can be used to improve performance on task.
</prevsent>
<prevsent>the quality and usefulness of the resource certainly is major factor for the success of the research, but equally so is the creativity with which these tools or resources are used.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
there usually is more than one way to employ these, and the approach chosen largely determines the outcome of the work.this paper illustrates the above claims with respect to three lexical resources ? framenet (baker et al, 1998), <papid> P98-1013 </papid>propbank (palmer et al, 2005) <papid> J05-1004 </papid>and verbnet (schuler, 2005) ? that convey information about lexical predicates and their arguments.</citsent>
<aftsection>
<nextsent>we describe two new and complementary techniques for using these resources and show the improvements to be gained when they are used individually and then together.
</nextsent>
<nextsent>we also point out problems that must be overcome to achieve these results.
</nextsent>
<nextsent>compared with wordnet (miller et al, 1993)which has been used widely in qaframenet, propbank and verbnet are still relatively new, and therefore their usefulness for qa has still to be proven.
</nextsent>
<nextsent>they offer the following features which can be usedto gain better understanding of questions, sentences containing answer candidates, and the relations between them: ? they all provide verb-argument structures for large number of lexical entries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2128">
<title id=" W07-1206.xml">question answering based on semantic roles </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a large part of the work done in nlp deals with exploring how different tools and resources can be used to improve performance on task.
</prevsent>
<prevsent>the quality and usefulness of the resource certainly is major factor for the success of the research, but equally so is the creativity with which these tools or resources are used.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
there usually is more than one way to employ these, and the approach chosen largely determines the outcome of the work.this paper illustrates the above claims with respect to three lexical resources ? framenet (baker et al, 1998), <papid> P98-1013 </papid>propbank (palmer et al, 2005) <papid> J05-1004 </papid>and verbnet (schuler, 2005) ? that convey information about lexical predicates and their arguments.</citsent>
<aftsection>
<nextsent>we describe two new and complementary techniques for using these resources and show the improvements to be gained when they are used individually and then together.
</nextsent>
<nextsent>we also point out problems that must be overcome to achieve these results.
</nextsent>
<nextsent>compared with wordnet (miller et al, 1993)which has been used widely in qaframenet, propbank and verbnet are still relatively new, and therefore their usefulness for qa has still to be proven.
</nextsent>
<nextsent>they offer the following features which can be usedto gain better understanding of questions, sentences containing answer candidates, and the relations between them: ? they all provide verb-argument structures for large number of lexical entries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2129">
<title id=" W07-1206.xml">question answering based on semantic roles </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>so far, there has been little work at the intersection of qa and semantic roles.
</prevsent>
<prevsent>fliedner (2004) describes the functionality of planned system based on the german version of framenet, salsa, but no so far no paper describing the completed system has been published.
</prevsent>
</prevsection>
<citsent citstr=" P06-1113 ">
novischi and moldovan (2006) <papid> P06-1113 </papid>use technique that builds on combination of lexical chains and verb argument structures extracted from verbnet to re-rank answer candidates.</citsent>
<aftsection>
<nextsent>the authors?
</nextsent>
<nextsent>aim is to recognize changing syntactic roles in cases where an answer sentence shows head verb different fromthe question (similar to work described here in section 2).
</nextsent>
<nextsent>however, since verbnet is based on thematic rather than semantic roles, there are problem sin using it for this purpose, illustrated by the following verbnet pattern for buy and sell: [agent] buy [theme] from [source] [agent] sell [recipient] [theme] starting with the sentence peter bought guitar from johnny?, and mapping the above roles for buy to those for sell, the resulting paraphrase in terms of sell would be peter sold unknown guitar?.
</nextsent>
<nextsent>that is, there is nothing blocking the agent role ofbuy being mapped to the agent role of sell, nor any thing linking the source role of buy to any role in sell.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2130">
<title id=" W07-1206.xml">question answering based on semantic roles </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>when their system is asked question, they match the dependency structure of the question against the dependency structures of potential answer candidates.
</prevsent>
<prevsent>additionally, set of 13 equivalence rules allows transformations of the kind the coach of norway, egil olsen?
</prevsent>
</prevsection>
<citsent citstr=" P06-1112 ">
egil olsen, the coach of norway?.secondly, shen and klakow (2006) <papid> P06-1112 </papid>use dependency relation paths to rank answer candidates.</citsent>
<aftsection>
<nextsent>in their work, candidate sentence supports an answer if relations between certain phrases in the candidate sentence are similar to the corresponding ones in the question.
</nextsent>
<nextsent>our work complements that described in both these papers, based as it is on large collection of semantically annotated example sentences: we only require candidate sentence to match one of the annotated example sentences.
</nextsent>
<nextsent>this allows us to deal with much wider range of syntactic possibilities, asthe resources we use do not only document verb argument structures, but also the many ways they can be syntactically realized.
</nextsent>
<nextsent>both methods presented in this paper employ semantic roles but with different aims in mind: the first method focuses on creating obvious answer containing sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2131">
<title id=" W07-2038.xml">ilk2 semantic role labeling of catalan and spanish using timbl </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the timbl parameters used in the systems are the ib1 algorithm, the jeffrey divergence as feature metric, mvdm threshold at level 1, weighting using gain ratio, k=11, and weighting neighbors as function of their inverse linear distance (for details we refer the reader to the timbl reference guide (daelemans et al, 2004)).
</prevsent>
<prevsent>as for the features, we started by using the same feature set for both classifiers and then, after some experimentation, we decided to use slightly different feature sets for the two sub-tasks.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
most of the features we designed are features that have become standard for the srl task (gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>carreras and ma`rquez, 2004; carreras and ma`rquez, 2005).</citsent>
<aftsection>
<nextsent>in our system, the features relate to the verb, the verb siblings, what we take to be the content word of the siblings, the clause, and the relation verbarguments.
</nextsent>
<nextsent>additionally, we added lexical features extracted from theverb lexicon provided for the task, and from word net.after experimenting with 323 features, we selected 98 for the sr task and 77 for the sc subclass.
</nextsent>
<nextsent>in order to select the features, we started with basic system, the results of which were used as baseline.
</nextsent>
<nextsent>every new feature that was added to the basic system was evaluated in terms of average accuracy in 10 fold cross-validation experiments; if it improved the performance on held-out data, it was added to these lection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2132">
<title id=" W07-2038.xml">ilk2 semantic role labeling of catalan and spanish using timbl </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the timbl parameters used in the systems are the ib1 algorithm, the jeffrey divergence as feature metric, mvdm threshold at level 1, weighting using gain ratio, k=11, and weighting neighbors as function of their inverse linear distance (for details we refer the reader to the timbl reference guide (daelemans et al, 2004)).
</prevsent>
<prevsent>as for the features, we started by using the same feature set for both classifiers and then, after some experimentation, we decided to use slightly different feature sets for the two sub-tasks.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
most of the features we designed are features that have become standard for the srl task (gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>carreras and ma`rquez, 2004; carreras and ma`rquez, 2005).</citsent>
<aftsection>
<nextsent>in our system, the features relate to the verb, the verb siblings, what we take to be the content word of the siblings, the clause, and the relation verbarguments.
</nextsent>
<nextsent>additionally, we added lexical features extracted from theverb lexicon provided for the task, and from word net.after experimenting with 323 features, we selected 98 for the sr task and 77 for the sc subclass.
</nextsent>
<nextsent>in order to select the features, we started with basic system, the results of which were used as baseline.
</nextsent>
<nextsent>every new feature that was added to the basic system was evaluated in terms of average accuracy in 10 fold cross-validation experiments; if it improved the performance on held-out data, it was added to these lection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2133">
<title id=" W07-2058.xml">psnus web people name disambiguation by simple clustering with rich features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system is basedon the clustering of the web pages by using variety of features extracted and generated from the data provided.
</prevsent>
<prevsent>this system achieves f?=0.5 = 0.75 and f?=0.2 = 0.78 for the final test dataset of the task.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
we consider the problem of disambiguating person names in web searching scenario as described bythe web people search task in semeval 2007 (artiles et al, 2007).<papid> W07-2012 </papid></citsent>
<aftsection>
<nextsent>here, the system receives as input set of web pages retrieved from search engine using given person name as query.
</nextsent>
<nextsent>the goalis to determine how many different people are represented for that name in the input web pages, and correctly assign each namesake to its corresponding subset of web pages.
</nextsent>
<nextsent>there are many challenges towards an effective solution.
</nextsent>
<nextsent>we are to correctly estimate the number of namesakes forgiven person name and group documents referring to the same individual.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2135">
<title id=" W07-2058.xml">psnus web people name disambiguation by simple clustering with rich features </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>identical to the task baseline by (ar tiles et al, 2005), we stemmed the words in the web pages using the porter stemmer (porter, 1980), to conflate semantically similar english words with thestem.
</prevsent>
<prevsent>each stemmed word is considered to be feature and weighted by its term frequency ? inverse document frequency (tfidf).named entities (ne).
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
we extract the named entities from the web pages using the stanford named entity recognizer (finkel et al, 2005).<papid> P05-1045 </papid></citsent>
<aftsection>
<nextsent>this tagger identifies and labels names of places, organizations and people in the input.
</nextsent>
<nextsent>each named entity token is treated as separate feature, again weighted bytfidf.
</nextsent>
<nextsent>we do not perform stemming for ne features.
</nextsent>
<nextsent>we also consider more target-centric form of the ne feature, motivated by the observation that person names can be differentiated using their middle names or titles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2138">
<title id=" W07-1514.xml">a search tool for parallel treebanks </title>
<section> the stockholm treealigner.  </section>
<citcontext>
<prevsection>
<prevsent>when our monolingual treebanks were finished, the trees were exported from the editor system and converted into tiger-xml.
</prevsent>
<prevsent>tiger-xml is line based (i.e. not nested and thus database-friendly) representation for graph structures which supports crossing edges and secondary edges.2 tiger-xml has been defined as input format for tiger-search, query tool for monolingual treebanks (see section 3).
</prevsent>
</prevsection>
<citsent citstr=" W06-2717 ">
we use this format also as input format for our alignment tool, the stockholm treealigner (volk et al., 2006).<papid> W06-2717 </papid>the treealigner program is graphical user interface to specify (or correct) word and phrase alignments between pairs of syntax trees.3 the treealigner is roughly similar to alignment tools such as i*link (ahrenberg et al, 2002) or cairo (smith and jahr, 2000) but it is especially tailored to visualize and align full syntax trees (including trees with crossing edges).2for information about tiger-xml see www.ims.uni stuttgart.de/projekte/tiger 3the treealigner is freely available at www.ling.su.se/ dali/downloads/treealigner/index.htm figure 1: tree pair german-english in the treealigner.</citsent>
<aftsection>
<nextsent>the treealigner operates on an alignment file in an xml format developed by us.
</nextsent>
<nextsent>this file describes the alignments between two tiger-xml treebanks (specified in the alignment file) holding the trees from language one and language two respectively.
</nextsent>
<nextsent>for example the alignment between two nodes is represented as:  align type= exact    node id= s13_505  tb_id= de /   node id= s14_506  tb_id= en /   /align this says that node 505 in sentence 13 of the german treebank is aligned with node 506 in sentence14 of the english treebank.
</nextsent>
<nextsent>the node identifiers refer to the ids in the tiger-xml treebanks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2139">
<title id=" W07-2085.xml">uiuc a knowledge rich approach to identifying semantic relations between nominals </title>
<section> classification of semantic relations.  </section>
<citcontext>
<prevsection>
<prevsent>the rationale is to identify negative instances where the pp attaches to any other word before np in the sentence.
</prevsent>
<prevsent>for example, eat  e1 pizza /e1  with  e2 fork /e2 , where with fork attaches to the verb to eat (cf.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
(charniak, 2000)).<papid> A00-2018 </papid>furthermore, we implemented and used two semantic role features which identify the semantic role of the phrase in verb argument structure, phrase containing either e1 (f10) or e2 (f11).</citsent>
<aftsection>
<nextsent>in particular, we focus on three semantic roles: time, location, manner.
</nextsent>
<nextsent>the feature is set to 1 if the target noun is part of semantic role phrase and to 0 otherwise.the idea is to filter out near-miss examples, expe cially for the instrument-agency relation.
</nextsent>
<nextsent>for this, we used assert, semantic role labeler developed at the university of colorado at boulder2 which was queried through web interface.
</nextsent>
<nextsent>inter-noun context sequence features (f12, f13) encode the sequence of lexical and part of speech information between the two target nouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2140">
<title id=" W07-2085.xml">uiuc a knowledge rich approach to identifying semantic relations between nominals </title>
<section> learning model and experimental.  </section>
<citcontext>
<prevsection>
<prevsent>precision, recall, f-measure, accuracy, and total (number of examples) are macro averaged for systems performance on all 7 relations.
</prevsent>
<prevsent>base-f shows the baseline measure (all true), while base-acc shows the baseline accuracy score (majority).
</prevsent>
</prevsection>
<citsent citstr=" W04-2609 ">
lection of 3,129 sentences from wall street journal(moldovan et al, 2004; <papid> W04-2609 </papid>girju et al, 2004) was considered for part-whole (1), whole (003), origin-entity (167), product-producer (112), and theme-tool (91).</citsent>
<aftsection>
<nextsent>we also extracted 552 product-producer instances from extended wordnet4 (noun entries and their glossdefinition).
</nextsent>
<nextsent>moreover, for theme-tool and content container we used special lists of constraints5.
</nextsent>
<nextsent>besides the selectional restrictions imposed on the nouns by special features such as f15 and f16 (psy cho logical feature), we created lists of containers from various thesauri6 and identified selectional restrictions that differentiate between containers and locations relying on taxonomies of spatial entities discussed in detail in (herskovits, 1987) and (tyler and evans, 2003).each instance in this text collection had the target nouns identified and annotated with wordnetsenses.
</nextsent>
<nextsent>since the annotations used different wordnet versions, senses were mapped to sense keys.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2141">
<title id=" W07-2051.xml">melbyb preposition sense disambiguation using rich semantic features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this system uses awide variety of semantic and syntactic features to perform the disambiguation task and achieves precision of 69.3% over the test data.
</prevsent>
<prevsent>prepositional phrases (pps) are both common and semantically varied in open english text.
</prevsent>
</prevsection>
<citsent citstr=" W03-0411 ">
while the conventional view on prepositions from the computational linguistics community has been that theyare semantically transient at best, and semantically vacuous at worst, robust account of the semantics of prepositions and disambiguation method can be helpful in range of nlp tasks including machine translation, parsing (prepositional phrase attach ment) and semantic role labelling (durand, 1993; ohara and wiebe, 2003; <papid> W03-0411 </papid>ye and baldwin, 2006a).the semeval 2007 preposition sense disambiguation task provides common test bed for the evaluation of preposition sense disambiguation systems.</citsent>
<aftsection>
<nextsent>our proposed method is maximum entropy based, and combines features developed in the context of preposition sense disambiguation for semantic role labelling (ye and baldwin, 2006a), and verb sense disambiguation (ye and baldwin, 2006b).the remainder of this paper is structured as follows.
</nextsent>
<nextsent>we first discuss the pre-processing steps used in our system (section 2), and outline the features our preposition disambiguation method uses(section 3) and our parameter tuning method (sec tion 4).
</nextsent>
<nextsent>we then discuss and analyse the results ofour method (section 5) and conclude the paper (sec tion 6).
</nextsent>
<nextsent>the following list shows the pre-processing steps that our system goes through and the tools used: part of speech tagging svmtool version 1.2 (gimenez and ma`rquez, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2142">
<title id=" W07-2051.xml">melbyb preposition sense disambiguation using rich semantic features </title>
<section> pre-processing.  </section>
<citcontext>
<prevsection>
<prevsent>we then discuss and analyse the results ofour method (section 5) and conclude the paper (sec tion 6).
</prevsent>
<prevsent>the following list shows the pre-processing steps that our system goes through and the tools used: part of speech tagging svmtool version 1.2 (gimenez and ma`rquez, 2004).
</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
chunking an in-house chunker implemented with fntbl, transformation based learner (ngaiand florian, 2001), <papid> N01-1006 </papid>and trained on the british national corpus (bnc).1parsing charniaks re-ranking parser, version august, 2006 (charniak and johnson, 2005).<papid> P05-1022 </papid>named entity extraction statistical ner system described in cohn et al (2005).<papid> P05-1002 </papid>super sense tagging wordnet-based super sense tagger (ciaramita and altun, 2006).<papid> W06-1670 </papid></citsent>
<aftsection>
<nextsent>semantic role labeling assert version 1.4 (pradhan et al, 2004).
</nextsent>
<nextsent>the disambiguation features used by our system canbe divided into three categories: collocation features, syntactic features and semantic-role based features.
</nextsent>
<nextsent>we discuss each in turn below.
</nextsent>
<nextsent>3.1 collocation features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2143">
<title id=" W07-2051.xml">melbyb preposition sense disambiguation using rich semantic features </title>
<section> pre-processing.  </section>
<citcontext>
<prevsection>
<prevsent>we then discuss and analyse the results ofour method (section 5) and conclude the paper (sec tion 6).
</prevsent>
<prevsent>the following list shows the pre-processing steps that our system goes through and the tools used: part of speech tagging svmtool version 1.2 (gimenez and ma`rquez, 2004).
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
chunking an in-house chunker implemented with fntbl, transformation based learner (ngaiand florian, 2001), <papid> N01-1006 </papid>and trained on the british national corpus (bnc).1parsing charniaks re-ranking parser, version august, 2006 (charniak and johnson, 2005).<papid> P05-1022 </papid>named entity extraction statistical ner system described in cohn et al (2005).<papid> P05-1002 </papid>super sense tagging wordnet-based super sense tagger (ciaramita and altun, 2006).<papid> W06-1670 </papid></citsent>
<aftsection>
<nextsent>semantic role labeling assert version 1.4 (pradhan et al, 2004).
</nextsent>
<nextsent>the disambiguation features used by our system canbe divided into three categories: collocation features, syntactic features and semantic-role based features.
</nextsent>
<nextsent>we discuss each in turn below.
</nextsent>
<nextsent>3.1 collocation features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2144">
<title id=" W07-2051.xml">melbyb preposition sense disambiguation using rich semantic features </title>
<section> pre-processing.  </section>
<citcontext>
<prevsection>
<prevsent>we then discuss and analyse the results ofour method (section 5) and conclude the paper (sec tion 6).
</prevsent>
<prevsent>the following list shows the pre-processing steps that our system goes through and the tools used: part of speech tagging svmtool version 1.2 (gimenez and ma`rquez, 2004).
</prevsent>
</prevsection>
<citsent citstr=" P05-1002 ">
chunking an in-house chunker implemented with fntbl, transformation based learner (ngaiand florian, 2001), <papid> N01-1006 </papid>and trained on the british national corpus (bnc).1parsing charniaks re-ranking parser, version august, 2006 (charniak and johnson, 2005).<papid> P05-1022 </papid>named entity extraction statistical ner system described in cohn et al (2005).<papid> P05-1002 </papid>super sense tagging wordnet-based super sense tagger (ciaramita and altun, 2006).<papid> W06-1670 </papid></citsent>
<aftsection>
<nextsent>semantic role labeling assert version 1.4 (pradhan et al, 2004).
</nextsent>
<nextsent>the disambiguation features used by our system canbe divided into three categories: collocation features, syntactic features and semantic-role based features.
</nextsent>
<nextsent>we discuss each in turn below.
</nextsent>
<nextsent>3.1 collocation features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2145">
<title id=" W07-2051.xml">melbyb preposition sense disambiguation using rich semantic features </title>
<section> pre-processing.  </section>
<citcontext>
<prevsection>
<prevsent>we then discuss and analyse the results ofour method (section 5) and conclude the paper (sec tion 6).
</prevsent>
<prevsent>the following list shows the pre-processing steps that our system goes through and the tools used: part of speech tagging svmtool version 1.2 (gimenez and ma`rquez, 2004).
</prevsent>
</prevsection>
<citsent citstr=" W06-1670 ">
chunking an in-house chunker implemented with fntbl, transformation based learner (ngaiand florian, 2001), <papid> N01-1006 </papid>and trained on the british national corpus (bnc).1parsing charniaks re-ranking parser, version august, 2006 (charniak and johnson, 2005).<papid> P05-1022 </papid>named entity extraction statistical ner system described in cohn et al (2005).<papid> P05-1002 </papid>super sense tagging wordnet-based super sense tagger (ciaramita and altun, 2006).<papid> W06-1670 </papid></citsent>
<aftsection>
<nextsent>semantic role labeling assert version 1.4 (pradhan et al, 2004).
</nextsent>
<nextsent>the disambiguation features used by our system canbe divided into three categories: collocation features, syntactic features and semantic-role based features.
</nextsent>
<nextsent>we discuss each in turn below.
</nextsent>
<nextsent>3.1 collocation features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2146">
<title id=" W07-2051.xml">melbyb preposition sense disambiguation using rich semantic features </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>we discuss each in turn below.
</prevsent>
<prevsent>3.1 collocation features.
</prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
the collocation features were inspired by the one-sense-per-collocation heuristic proposed by yarowsky (1995).<papid> P95-1026 </papid></citsent>
<aftsection>
<nextsent>these features were designed to capture open class words that exhibit strong collocation properties with respect to the different senses of the target preposition.
</nextsent>
<nextsent>details of the features in this category are listed below.
</nextsent>
<nextsent>1this chunker is not exactly the same as ngai and florianssystem, however it does use the default transformation templates supplied by fntbl.
</nextsent>
<nextsent>241 bag of open class words the part-of-speech (pos) tags and lemmas of all the open class words that occur in the same sentence as the target preposition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2147">
<title id=" W07-2051.xml">melbyb preposition sense disambiguation using rich semantic features </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>1this chunker is not exactly the same as ngai and florianssystem, however it does use the default transformation templates supplied by fntbl.
</prevsent>
<prevsent>241 bag of open class words the part-of-speech (pos) tags and lemmas of all the open class words that occur in the same sentence as the target preposition.
</prevsent>
</prevsection>
<citsent citstr=" H93-1103 ">
bag of wordnet synsets the wordnet (miller, 1993) <papid> H93-1103 </papid>synonym sets and their hypernyms of all the open class words that occur in the same sentence as the target preposition.</citsent>
<aftsection>
<nextsent>bag of named entities each named entity in the same sentence as the target preposition is treated as separate feature.surrounding words these features are the combinations of the lemma, pos tag and relative position of the words surrounding the target preposition within window of 7 words.
</nextsent>
<nextsent>surrounding super senses these features are the combinations of super-sense tag, pos tag and relative position of the words surrounding the target preposition within window of 7 words.
</nextsent>
<nextsent>3.2 syntactic features.
</nextsent>
<nextsent>the syntactic features were designed to capture boththe flat and recursive syntactic properties of the target preposition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2148">
<title id=" W07-1503.xml">mining syntactically annotated corpora with xquery </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>now that such parsers are available for various languages, there is growing interest in research that uses automatically annotated corpora.
</prevsent>
<prevsent>while such corpora are not error free, the fact that they can be constructed relatively easily, and the fact that they can be an orderof magnitude larger than manually corrected treebanks, makes them attractive for several types of research.
</prevsent>
</prevsection>
<citsent citstr=" H05-1091 ">
syntactically annotated corpora have succes fully been used to acquire lexico-semantic information (lin and pantel, 2001; snow et al, 2005), for relation extraction (bunescu and mooney, 2005), <papid> H05-1091 </papid>in ir (cui et al, 2005), and in qa (katz and lin, 2003; molla?</citsent>
<aftsection>
<nextsent>and gardiner, 2005).
</nextsent>
<nextsent>what these tasks have in common is the fact that they all operate on large amounts of data extracted from syntactically annotated text.
</nextsent>
<nextsent>tools to perform this task are often developed with only single application in mind (mostly corpus linguistics) or are developed in an ad-hoc fashion, as part of specific application.
</nextsent>
<nextsent>we propose more principled approach, based on two observations:?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2149">
<title id=" W07-1503.xml">mining syntactically annotated corpora with xquery </title>
<section> xquery and xpath.  </section>
<citcontext>
<prevsection>
<prevsent>xquery is in many respects similar to sql and is rapidly becoming the standard for xml database systems.12 distinctive difference between the xslt and xquery is the fact that xslt documents are themselves xml documents,whereas this is not the case for xquery.
</prevsent>
<prevsent>this typically makes xquery more concise and easier to read than xslt.13 these considerations made us experiment withxquery as language for data extraction from syntactically annotated corpora.
</prevsent>
</prevsection>
<citsent citstr=" W06-2704 ">
similar studies were carried out by cassidy (2002) (for an early version of xquery) and mayo et al (2006), <papid> W06-2704 </papid>who compare the nite query language and xquery.</citsent>
<aftsection>
<nextsent>below, we first illustrate task that requires use of xpath only, and then move on to tasks that require the additional functionality of xquery.
</nextsent>
<nextsent>8www.ims.uni-stuttgart.de/projekte/ tiger/ 9www.w3.org/tr/xslt20 10www.w3.org/tr/xquery 11www.w3.org/tr/xpath20 12e.g. exist.sourceforge.net, monetdb.cwi.nl, www.oracle.com/database/berkeley-db/xml 13see kay (2005) for thorough comparison.
</nextsent>
<nextsent>4.1 corpus exploration with xpath.
</nextsent>
<nextsent>as argued in bouma and kloosterman (2002),xpath provides powerful query language for formulating linguistically relevant queries, provided that the xml encoding of the treebank reflects the syntactic structure of the trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2150">
<title id=" W08-0114.xml">a framework for building conversational agents based on a multi expert model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although number of models for conversational agents have been proposed, no model has all of the above properties.
</prevsent>
<prevsent>several multi-domain dialogue system models have been proposed and they are extensible, but it is not clear how they handle interruptions to system utterances and actions (e.g., oneill et al (2004), lin et al (1999), and hartikainen et al (2004)).
</prevsent>
</prevsection>
<citsent citstr=" W02-0201 ">
there are several spoken dialogue agents and robots that can handle interruptions thanks to their asynchronous control (asoh et al, 1999; boye et al, 2000; blaylock et al, 2002; <papid> W02-0201 </papid>lemon et al, 2002), <papid> W02-0216 </papid>they do not focus on making it easy to add new dialogue domains with variety of dialogue strategies.</citsent>
<aftsection>
<nextsent>this paper presents framework called rime (robot intelligence based on multiple experts),which employs modules called experts.1 each expert is specialized for achieving certain kinds of tasks by performing physical actions and engaging in dialogues.
</nextsent>
<nextsent>it corresponds to the symbol-level control module of system that can engage in tasks ina single small domain, and it employs fixed control strategies.
</nextsent>
<nextsent>only some of the experts take charge in understanding user utterances and decide actions.the basic idea behind rime is to specify common interface of experts for coordinating them andto achieve flexible control.
</nextsent>
<nextsent>in rime, several mod 1rime is an improved version of our previous model(nakano et al, 2005), whose interruption handling was too simple and which could not achieve parallel task execution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2151">
<title id=" W08-0114.xml">a framework for building conversational agents based on a multi expert model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although number of models for conversational agents have been proposed, no model has all of the above properties.
</prevsent>
<prevsent>several multi-domain dialogue system models have been proposed and they are extensible, but it is not clear how they handle interruptions to system utterances and actions (e.g., oneill et al (2004), lin et al (1999), and hartikainen et al (2004)).
</prevsent>
</prevsection>
<citsent citstr=" W02-0216 ">
there are several spoken dialogue agents and robots that can handle interruptions thanks to their asynchronous control (asoh et al, 1999; boye et al, 2000; blaylock et al, 2002; <papid> W02-0201 </papid>lemon et al, 2002), <papid> W02-0216 </papid>they do not focus on making it easy to add new dialogue domains with variety of dialogue strategies.</citsent>
<aftsection>
<nextsent>this paper presents framework called rime (robot intelligence based on multiple experts),which employs modules called experts.1 each expert is specialized for achieving certain kinds of tasks by performing physical actions and engaging in dialogues.
</nextsent>
<nextsent>it corresponds to the symbol-level control module of system that can engage in tasks ina single small domain, and it employs fixed control strategies.
</nextsent>
<nextsent>only some of the experts take charge in understanding user utterances and decide actions.the basic idea behind rime is to specify common interface of experts for coordinating them andto achieve flexible control.
</nextsent>
<nextsent>in rime, several mod 1rime is an improved version of our previous model(nakano et al, 2005), whose interruption handling was too simple and which could not achieve parallel task execution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2152">
<title id=" W08-0114.xml">a framework for building conversational agents based on a multi expert model </title>
<section> multi-expert model.  </section>
<citcontext>
<prevsection>
<prevsent>the understand method updates the internal state based on the user speech recognition results, using domain-dependent sentence patterns for utterance understanding.
</prevsent>
<prevsent>this method returns score which indicates the plausibility the user utterance should be dealt with by the expert.
</prevsent>
</prevsection>
<citsent citstr=" W06-1302 ">
domain selection techniques in multi-domain spoken dialogue systems (komatani et al, 2006) <papid> W06-1302 </papid>can be applied to obtain the score.</citsent>
<aftsection>
<nextsent>the select-action method outputs one action based on the content of the internal state.
</nextsent>
<nextsent>here, an action is multimodal command which includes text to speak and/or physical action command.
</nextsent>
<nextsent>89the action can be an empty action, which means doing nothing.
</nextsent>
<nextsent>the detect-interruption method returns boolean value that indicates whether the previous user utterance is an interruption to the action being performed when this expert is being in charge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2154">
<title id=" W07-1403.xml">precision focused textual inference </title>
<section> process pipeline.  </section>
<citcontext>
<prevsection>
<prevsent>this allows each component to accept ambiguous input in packed?
</prevsent>
<prevsent>format, process it without unpacking the ambiguities, and then pass packed input to the next stage.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
the syntactic component, lfg parsing, alsohas stochastic disambiguation system which allows us to pass the n-best on to the semantics (rie zler et al, 2002); <papid> P02-1035 </papid>for the rte3 challenge, we used 16 n=50.</citsent>
<aftsection>
<nextsent>the parser takes the output of the morphology(i.e. series of lemmata with their tags) and produces tree (constituent-structure) and dependency structure (functional-structure) represented as an attribute-value matrix.
</nextsent>
<nextsent>the functional-structure is of primary importance for the semantics and akr.
</nextsent>
<nextsent>in particular, it encodes predicate-argument relations, including long-distance dependencies, and provides other syntactic features (e.g. number, tense, noun type).the output of the syntax is input for the semantics that is produced by an ambiguity enabled packed rewriting system.
</nextsent>
<nextsent>the semantics is described in detail in (crouch and king, 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2155">
<title id=" W07-0722.xml">domain adaptation in statistical machine translation with mixture modelling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this semantic dependency problem could be overcome by learning topic-dependent translation models that capture together the semantic context and the translation process.
</prevsent>
<prevsent>however, there have not been until very recently that the application of mixture modelling in smt has received increasing attention.
</prevsent>
</prevsection>
<citsent citstr=" P06-2124 ">
in (zhao andxing, 2006), <papid> P06-2124 </papid>three fairly sophisticated bayesian topical translation models, taking ibm model 1 as baseline model, were presented under the bilingual topic admixture model formalism.</citsent>
<aftsection>
<nextsent>these models capture latent topics at the document level in order to reduce semantic ambiguity and improve translation coherence.
</nextsent>
<nextsent>the models proposed provide in some cases better word alignment and translation quality than hmm and ibm models on an english-chinesetask.
</nextsent>
<nextsent>in (civera and juan, 2006), mixture extension of ibm model 2 along with specific dynamic programming decoding algorithm were proposed.
</nextsent>
<nextsent>this ibm-2 mixture model offers significant gain in translation quality over the conventional ibm model 2 on semi-synthetic task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2156">
<title id=" W07-0722.xml">domain adaptation in statistical machine translation with mixture modelling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in (civera and juan, 2006), mixture extension of ibm model 2 along with specific dynamic programming decoding algorithm were proposed.
</prevsent>
<prevsent>this ibm-2 mixture model offers significant gain in translation quality over the conventional ibm model 2 on semi-synthetic task.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
in this work, we present mixture extension of the well-known hmm alignment model first proposed in (vogel and others, 1996) and refined in (och andney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>this model possesses appealing properties among which are worth mentioning, the simplicity of the first-order word alignment distribution that can be made independent of absolute positions while 177 taking advantage of the localization phenomenon of word alignment in european languages, and the efficient and exact computation of the e-step and viterbi alignment by using dynamic-programming approach.
</nextsent>
<nextsent>these properties have made this model suitable for extensions (toutanova et al, 2002) <papid> W02-1012 </papid>and integration in phrase-based model (deng and byrne, 2005) <papid> H05-1022 </papid>in the past.</nextsent>
<nextsent>given bilingual pair (x, y), where and are mutual translation, we incorporate the hidden variablea = a1a2 ? ?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2157">
<title id=" W07-0722.xml">domain adaptation in statistical machine translation with mixture modelling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this work, we present mixture extension of the well-known hmm alignment model first proposed in (vogel and others, 1996) and refined in (och andney, 2003).<papid> J03-1002 </papid></prevsent>
<prevsent>this model possesses appealing properties among which are worth mentioning, the simplicity of the first-order word alignment distribution that can be made independent of absolute positions while 177 taking advantage of the localization phenomenon of word alignment in european languages, and the efficient and exact computation of the e-step and viterbi alignment by using dynamic-programming approach.</prevsent>
</prevsection>
<citsent citstr=" W02-1012 ">
these properties have made this model suitable for extensions (toutanova et al, 2002) <papid> W02-1012 </papid>and integration in phrase-based model (deng and byrne, 2005) <papid> H05-1022 </papid>in the past.</citsent>
<aftsection>
<nextsent>given bilingual pair (x, y), where and are mutual translation, we incorporate the hidden variablea = a1a2 ? ?
</nextsent>
<nextsent>a|x| to reveal, for each source word position j, the target word position aj ? {0, 1, . . .
</nextsent>
<nextsent>, |y|} to which it is connected.
</nextsent>
<nextsent>thus, p(x | y) = ? aa(x,y) p(x, | y) (1)where a(x, y) denotes the set of all possible alignments between and y. the alignment-completed probability (x, | y) can be decomposed in terms of source position-dependent probabilities as: p(x, | y)= |x|?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2158">
<title id=" W07-0722.xml">domain adaptation in statistical machine translation with mixture modelling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this work, we present mixture extension of the well-known hmm alignment model first proposed in (vogel and others, 1996) and refined in (och andney, 2003).<papid> J03-1002 </papid></prevsent>
<prevsent>this model possesses appealing properties among which are worth mentioning, the simplicity of the first-order word alignment distribution that can be made independent of absolute positions while 177 taking advantage of the localization phenomenon of word alignment in european languages, and the efficient and exact computation of the e-step and viterbi alignment by using dynamic-programming approach.</prevsent>
</prevsection>
<citsent citstr=" H05-1022 ">
these properties have made this model suitable for extensions (toutanova et al, 2002) <papid> W02-1012 </papid>and integration in phrase-based model (deng and byrne, 2005) <papid> H05-1022 </papid>in the past.</citsent>
<aftsection>
<nextsent>given bilingual pair (x, y), where and are mutual translation, we incorporate the hidden variablea = a1a2 ? ?
</nextsent>
<nextsent>a|x| to reveal, for each source word position j, the target word position aj ? {0, 1, . . .
</nextsent>
<nextsent>, |y|} to which it is connected.
</nextsent>
<nextsent>thus, p(x | y) = ? aa(x,y) p(x, | y) (1)where a(x, y) denotes the set of all possible alignments between and y. the alignment-completed probability (x, | y) can be decomposed in terms of source position-dependent probabilities as: p(x, | y)= |x|?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2161">
<title id=" W07-0722.xml">domain adaptation in statistical machine translation with mixture modelling </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>this model was employed to generate topic-dependent viterbi alignments that were input into state-of-the-art phrase based system.
</prevsent>
<prevsent>the preliminary results reported on the english-spanish partitions of the europarl and news-commentary corpora may raise some doubts about the applicability of mixture modelling to smt,nonetheless in the advent of larger open-domain corpora, the idea behind topic-specific translation models seem to be more than appropriate, necessary.
</prevsent>
</prevsection>
<citsent citstr=" P06-1002 ">
on the other hand, we are fully aware that indirectly assessing the quality of model through phrase based system is difficult task because of the different factors involved (ayan and dorr, 2006).<papid> P06-1002 </papid></citsent>
<aftsection>
<nextsent>finally, the main problem in mixture modelling isthe linear growth of the set of parameters as the number of components increases.
</nextsent>
<nextsent>in the hmm, and also in ibm models, this problem is aggravated because of the use of statistical dictionary entailing large number of parameters.
</nextsent>
<nextsent>a possible solution is the implementation of interpolation techniques to smooth sharp distributions estimated on few events (och and ney, 2003; <papid> J03-1002 </papid>zhao and xing, 2006).<papid> P06-2124 </papid></nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2164">
<title id=" W07-1504.xml">assoc ating facial displays with syntactic constituents for generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an increasing number of systems designed to automatically generate linguistic and multimodal output now make use of corpora to help in decisionmaking (cf.
</prevsent>
<prevsent>belz and varges, 2005).
</prevsent>
</prevsection>
<citsent citstr=" W98-1426 ">
some implementations use corpora to help select output that is grammatical or fluent; for example, langkilde and knight (1998) <papid> W98-1426 </papid>and white (2006) both used n-gramlanguage models to guide stochastic surface realis ers.</citsent>
<aftsection>
<nextsent>in other systems, corpora are used to make decisions based on pragmatic factors such as the reading level of the target user (williams and reiter, 2005) or the visual features of an object being described (cassell et al, 2007).
</nextsent>
<nextsent>the latter typeof domain-specific contextual information is not of ten included in generally-available corpora.
</nextsent>
<nextsent>for this reason, developers of generation systems that need this type of information often create and make use of application-specific corpora.
</nextsent>
<nextsent>the easiest method of including the necessary pragmatic information in corpus is to base the corpus on output generated in situations where the contextual factors are known; this eliminates the need to annotate these factors explicitly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2165">
<title id=" W07-1504.xml">assoc ating facial displays with syntactic constituents for generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the contextual information in the corpus scripts included the move that the player attempted in the game and the result of thatattempt.
</prevsent>
<prevsent>similarly, van deemter et al (2006) created corpus of multimodal referring expressions produced in specific pragmatic contexts and used it to compare several referring-expression generation algorithms to human performance.
</prevsent>
</prevsection>
<citsent citstr=" P05-3012 ">
in this work, the task is to select facial displays for an animated talking head to use while presenting output in the comic multimodal dialogue system (foster et al, 2005), <papid> P05-3012 </papid>which generates spoken descriptions and comparisons of bathroom-tile options.</citsent>
<aftsection>
<nextsent>the output of the comic text planner includes range of information in addition to the text: the syntactic derivation tree, the users evaluation of the object being described, the information status (new or old, contrastive) of each fact described, and the predicted speech-synthesiser prosody.
</nextsent>
<nextsent>all of this contextual information can be used to help select 25appropriate facial displays to accompany the spoken presentation; howe veras in the other systems mentioned above this requires corpus where thefull context for every facial display is known.
</nextsent>
<nextsent>to create such corpus, we recorded speaker performing scripted output in the domain of comic.
</nextsent>
<nextsent>this paper is arranged as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2166">
<title id=" W07-1504.xml">assoc ating facial displays with syntactic constituents for generation </title>
<section> patterns in the corpus.  </section>
<citcontext>
<prevsection>
<prevsent>the annotation scheme described here allowed display to be associated with any contiguous span of words in the sentence.
</prevsent>
<prevsent>annotators were encouraged to use syntactic constituents wherever possible, but also had the option to select multiple nodes where display did not correspond with single constituent in the derivation tree.
</prevsent>
</prevsection>
<citsent citstr=" E06-1045 ">
earlier versions of the annotation scheme did not support this degree of flexibility, so we used the patterns in the corpus to test whether the modifications to the scheme were useful.in previous study using the same video recordings but different, simpler scheme (foster and oberlander, 2006), <papid> E06-1045 </papid>facial displays could only be associated with single leaf nodes (i.e., words); that is, in the terminology of ekman (1979), all motions were considered to be batons rather than under lin ers.</citsent>
<aftsection>
<nextsent>based on the data in the current corpus, that restriction was clearly unrealistic: the mean number of nodes spanned by display in the full corpus was1.95, with maximum of 15 and standard deviation of 2.
</nextsent>
<nextsent>the results were similar in the sub-corpusproduced by the final coder, in which the mean number of nodes spanned by display was 2.25.the annotation rules for this study did not initially permit displays to be associated with more than nodes in the derivation tree.
</nextsent>
<nextsent>this capability was added following inter-coder discussions after the initial test annotation to deal with cases where the speakers displays did not correspond to syntactic constituents for example, if the speaker raised his eyebrows on the tiles are or some other such non-standard constituent.
</nextsent>
<nextsent>the data in the annotated corpus supports this modification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2167">
<title id=" W07-1504.xml">assoc ating facial displays with syntactic constituents for generation </title>
<section> generation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the primary reason for creating this corpus of facial displays was to use the resulting data to select facial displays for the artificial talking head in the comic multimodal dialogue system.
</prevsent>
<prevsent>several different strategies have been implemented to use the corpus data for this task, and number of automated and human evaluations have been carried out comparing the different implementations.as described in the preceding section, the factor with the largest influence on the displays of the recorded speaker was the user-model evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W07-1901 ">
two studies (foster, 2007<papid> W07-1901 </papid>b) were carried out to testthe generality of the characteristic positive and negative displays (figure 4).</citsent>
<aftsection>
<nextsent>in the first study, users were asked to identify the intended user-model polarity of description presented by the talking head based only on the facial displays.
</nextsent>
<nextsent>the participants were generally able to recognise the characteristic positive and negative facial displays; they also identified the displays intended to be neutral (nodding alone) as positive, and tended to judge videos with no facial displays to be negative.
</nextsent>
<nextsent>in the second study, users?
</nextsent>
<nextsent>subjective preferences were gathered between videos in which the user-model evaluation expressed in speech was either consistent or inconsistent with the facial displays.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2171">
<title id=" W07-0738.xml">linguistic features for automatic evaluation of heterogenous mt systems </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W06-3114 ">
evaluation results recently reported by callison-burch et al (2006) and koehn and monz (2006), <papid> W06-3114 </papid>revealed that, in certain cases, the bleu metric may not be reliable mtquality indicator.</citsent>
<aftsection>
<nextsent>this happens, for instance, when the systems under evaluation are based on different paradigms, and therefore, do not share the same lexicon.
</nextsent>
<nextsent>the reason is that, while mt quality aspects are diverse, bleu limits its scope to the lexical dimension.
</nextsent>
<nextsent>in this work, we suggest using metrics which take into account linguistic features at more abstract levels.
</nextsent>
<nextsent>we provide experimental results showing that metrics based on deeper linguistic information (syntactic/shallow-semantic) are able to produce more reliable system rankings than metrics based on lexical matching alone, specially when the systems under evaluation are of different nature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2176">
<title id=" W07-0738.xml">linguistic features for automatic evaluation of heterogenous mt systems </title>
<section> a heterogeneous metric set </section>
<citcontext>
<prevsection>
<prevsent>most of the current metrics operate at the lexicallevel.
</prevsent>
<prevsent>we have selected 7 representatives from different families which have been shown to obtain high levels of correlation with human assessments: bleu we use the default accumulated score up to the level of 4-grams (papineni et al, 2001).
</prevsent>
</prevsection>
<citsent citstr=" N03-2021 ">
nist we use the default accumulated score up to the level of 5-grams (doddington, 2002).gtm we set to 1 the value of the parameter (melamed et al, 2003).<papid> N03-2021 </papid>meteor we run all modules: exact?, porter stem?, wn stem?</citsent>
<aftsection>
<nextsent>and wn synonymy?, in that order (banerjee and lavie, 2005).<papid> W05-0909 </papid>rouge we used the rouge-s* variant (skip bi grams with no max-gap-length).</nextsent>
<nextsent>stemming is enabled (lin and och, 2004<papid> P04-1077 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2177">
<title id=" W07-0738.xml">linguistic features for automatic evaluation of heterogenous mt systems </title>
<section> a heterogeneous metric set </section>
<citcontext>
<prevsection>
<prevsent>we have selected 7 representatives from different families which have been shown to obtain high levels of correlation with human assessments: bleu we use the default accumulated score up to the level of 4-grams (papineni et al, 2001).
</prevsent>
<prevsent>nist we use the default accumulated score up to the level of 5-grams (doddington, 2002).gtm we set to 1 the value of the parameter (melamed et al, 2003).<papid> N03-2021 </papid>meteor we run all modules: exact?, porter stem?, wn stem?</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
and wn synonymy?, in that order (banerjee and lavie, 2005).<papid> W05-0909 </papid>rouge we used the rouge-s* variant (skip bi grams with no max-gap-length).</citsent>
<aftsection>
<nextsent>stemming is enabled (lin and och, 2004<papid> P04-1077 </papid>a).</nextsent>
<nextsent>mwer we use 1 ? mwer (nieen et al, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2178">
<title id=" W07-0738.xml">linguistic features for automatic evaluation of heterogenous mt systems </title>
<section> a heterogeneous metric set </section>
<citcontext>
<prevsection>
<prevsent>nist we use the default accumulated score up to the level of 5-grams (doddington, 2002).gtm we set to 1 the value of the parameter (melamed et al, 2003).<papid> N03-2021 </papid>meteor we run all modules: exact?, porter stem?, wn stem?</prevsent>
<prevsent>and wn synonymy?, in that order (banerjee and lavie, 2005).<papid> W05-0909 </papid>rouge we used the rouge-s* variant (skip bi grams with no max-gap-length).</prevsent>
</prevsection>
<citsent citstr=" P04-1077 ">
stemming is enabled (lin and och, 2004<papid> P04-1077 </papid>a).</citsent>
<aftsection>
<nextsent>mwer we use 1 ? mwer (nieen et al, 2000).
</nextsent>
<nextsent>mper we use 1 ? mper (tillmann et al, 1997).let us note that rouge and meteor may consider stemming (i.e., morphological variations).
</nextsent>
<nextsent>additionally, meteor may perform lookup for synonyms in wordnet (fellbaum, 1998).
</nextsent>
<nextsent>2.2 beyond lexical similarity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2182">
<title id=" W07-0738.xml">linguistic features for automatic evaluation of heterogenous mt systems </title>
<section> a heterogeneous metric set </section>
<citcontext>
<prevsection>
<prevsent>analyze similarities at the level of pos-tagging, lemmati zation, and base phrase chunking.
</prevsent>
<prevsent>outputs and references are automatically annotated using state of-the-art tools.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
pos-tagging and lemmatization are provided by the svmtool package (gimenez andma`rquez, 2004), and base phrase chunking is provided by the phreco software (carreras et al, 2005).tag sets for english are derived from the penn tree bank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>we instantiate overlapping?
</nextsent>
<nextsent>over parts-of-speechand chunk types.
</nextsent>
<nextsent>the goal is to capture the proportion of lexical items correctly translated, according to their shallow syntactic realization:sp-op-t lexical overlapping according to the part of-speech t?.
</nextsent>
<nextsent>for instance, sp-op-nn?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2183">
<title id=" W07-0738.xml">linguistic features for automatic evaluation of heterogenous mt systems </title>
<section> a heterogeneous metric set </section>
<citcontext>
<prevsection>
<prevsent>corresponds to the individual nist score for pos 5-grams.
</prevsent>
<prevsent>2.4 syntactic similarity.
</prevsent>
</prevsection>
<citsent citstr=" W05-0904 ">
we have incorporated, with minor modifications, some of the syntactic metrics described by liu andgildea (2005) <papid> W05-0904 </papid>and amigo?</citsent>
<aftsection>
<nextsent>et al (2006) based on dependency and constituency parsing.
</nextsent>
<nextsent>2.4.1 on dependency parsing (dp)dp?
</nextsent>
<nextsent>metrics capture similarities between dependency trees associated to automatic and reference translations.
</nextsent>
<nextsent>dependency trees are provided by theminipar dependency parser (lin, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2186">
<title id=" W07-0738.xml">linguistic features for automatic evaluation of heterogenous mt systems </title>
<section> a heterogeneous metric set </section>
<citcontext>
<prevsection>
<prevsent>2.4.2 on constituency parsing (cp)cp?
</prevsent>
<prevsent>metrics capture similarities between constituency parse trees associated to automatic and reference translations.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
constituency trees are provided by the charniak-johnsons max-ent reranking parser (charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>cp-stm(i)-l this metric corresponds to the stm metric presented by liu and gildea (2005).<papid> W05-0904 </papid></nextsent>
<nextsent>all syntactic sub paths in the candidate and the reference trees are retrieved.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2195">
<title id=" W07-2075.xml">ubcas a graph based unsupervised system for induction and classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the paper is organized as follows.
</prevsent>
<prevsent>section 2 gives an description of the general framework of our system.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
sections 3 and 4 presents in more detail the implementation of the framework for the semeval 2007 weps task (artiles et al, 2007) <papid> W07-2012 </papid>and semeval-.</citsent>
<aftsection>
<nextsent>2007 sense induction task (agirre and soroa, 2007), <papid> W07-2002 </papid>respectively.</nextsent>
<nextsent>section 5 presents the results obtained in both tasks, and section 6 draws some conclusions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2196">
<title id=" W07-2075.xml">ubcas a graph based unsupervised system for induction and classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>section 2 gives an description of the general framework of our system.
</prevsent>
<prevsent>sections 3 and 4 presents in more detail the implementation of the framework for the semeval 2007 weps task (artiles et al, 2007) <papid> W07-2012 </papid>and semeval-.</prevsent>
</prevsection>
<citsent citstr=" W07-2002 ">
2007 sense induction task (agirre and soroa, 2007), <papid> W07-2002 </papid>respectively.</citsent>
<aftsection>
<nextsent>section 5 presents the results obtained in both tasks, and section 6 draws some conclusions.
</nextsent>
<nextsent>classification the system performs two stage graph based clustering where co-occurrence graph is first clustered to compute similarities against contexts.
</nextsent>
<nextsent>the context similarity matrix is pruned and the resulting associated graph is clustered again by means of random walk type algorithm.
</nextsent>
<nextsent>we will see both steps in turn.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2197">
<title id=" W07-2075.xml">ubcas a graph based unsupervised system for induction and classification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as consequence, each context receives hub score vector, which is just the sum of the score vectors of all the words in the context.
</prevsent>
<prevsent>at this point we can use the hub score vectors to create clusters of contexts, just assigning to each context the hub with maximum score.
</prevsent>
</prevsection>
<citsent citstr=" W06-3814 ">
this process is thoroughly explained in (agirre et al, 2006<papid> W06-3814 </papid>b).</citsent>
<aftsection>
<nextsent>one of the problems of such an approach comes from the tendency of the system to produce high number of hubs, somehow favouring small micro clusters over coarse ones.
</nextsent>
<nextsent>knowing in advance thatthe number of clusters in the tasks we will participate in would not be very high, we decided to perform second stage and re-cluster again the results obtained in the first step, using different graph based technique.
</nextsent>
<nextsent>re-clustering also gives us the opportunity to feed the system with additional data, as will be explained below.
</nextsent>
<nextsent>second step: clustering via mclin this second stage, we compute square matrix with as many rows/columns as contexts, and where each element represents the relatedness between two contexts, just computing the cosine distance of its (normalized) hub score vectors obtained in the first step.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2201">
<title id=" W07-1031.xml">evaluating and combining and biomedical named entity recognition systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in parallel, there have been successful efforts in bootstrapping ner systems using automatically generated training material using domain resources (morgan et al, 2004; vlachos et al, 2006).
</prevsent>
<prevsent>these approaches have significant appeal, since they dont require manual annotation of training material which is an expensive and lengthy process.named entity recognition is an important task be cause it is prerequisite to other more complex ones.
</prevsent>
</prevsection>
<citsent citstr=" W06-3316 ">
examples include anaphora resolution (gasperin, 2006) <papid> W06-3316 </papid>and gene normalization (hirschman et al, 2005).</citsent>
<aftsection>
<nextsent>an important point is that until now ner systems have been evaluated on abstracts, or on sentences selected from abstracts.
</nextsent>
<nextsent>however, ner systems will be applied to full papers, either on their own or in order to support more complex tasks.
</nextsent>
<nextsent>full papers though are expected to present additional challenges to the systems than the abstracts, so it is important to evaluate on the former as well in order to obtain clearer picture of the systems and the task (ananiadou and mcnaught, 2006).
</nextsent>
<nextsent>in this paper, we compare two ner systems ina variety of settings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2202">
<title id=" W07-1031.xml">evaluating and combining and biomedical named entity recognition systems </title>
<section> named entity recognition systems.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 conditional random fields with syntactic.
</prevsent>
<prevsent>parsing the second ner system we used in our experiments was the system of vlachos (2007) that participated in the biocreative2 gene mention task (krallinger and hirschman, 2007).
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
its main components are the conditional random fields toolkit mallet2 (mc callum, 2002) and the rasp syntactic parsingtoolkit3 (briscoe et al, 2006), <papid> P06-4020 </papid>which are both publicly available.</citsent>
<aftsection>
<nextsent>conditional random fields (crfs) (lafferty et al., 2001) are undirected graphical models trained to maximize the conditional probability of the output sequence given the inputs, or, in the case of token based natural language processing tasks, the conditional probability of the sequence of labels given sequence of tokens x. like hmms, the number of previous labels taken into account defines the order of the crf model.
</nextsent>
<nextsent>more formally: (y|x) = 1z(x)exp{ ? t=1 ? k=1 kfk(y, xt)} (2) in the equation above, z(x) is normalization factor computed over all possible label sequences, fk is feature function and its respective weight.
</nextsent>
<nextsent>y represents the labels taken into account as context and it is defined by the order of the crf.
</nextsent>
<nextsent>for n-th order model, becomes yt, yt1..., ytn. it is also worth noting that xt is the feature representation of the token in position t, which can include features extracted by taking the whole input sequence into account, not just the token in question.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2203">
<title id=" W07-1031.xml">evaluating and combining and biomedical named entity recognition systems </title>
<section> named entity recognition systems.  </section>
<citcontext>
<prevsection>
<prevsent>nevertheless, the results of the system in the biocreative2 gene mention task suggest that the use of syntactic parsing features improve performance.
</prevsent>
<prevsent>also, despite thelack of domain-specific features, the system is competitive with other systems, having performance in the second quartile of the task.
</prevsent>
</prevsection>
<citsent citstr=" N06-2038 ">
finally, the bioewscheme (siefkes, 2006) <papid> N06-2038 </papid>was used to tag the tokenized corpora, under which the first token of mul titoken mention is tagged as b, the last token as e, the inner ones as i, single token mentions as and tokens outside an entity as o.</citsent>
<aftsection>
<nextsent>in our experiments we used two corpora consisting of abstracts and one consisting of full papers.
</nextsent>
<nextsent>one of the abstracts corpora was automatically generated while the other two were manually annotated.
</nextsent>
<nextsent>all three were created using resources from flybase4 and they are publicly available5 . the automatically generated corpus was created in order to bootstrap gene name recognizer in vlachos &amp; gasperin (2006).<papid> W06-3328 </papid></nextsent>
<nextsent>the approach used was introduced by morgan et al(2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2204">
<title id=" W07-1031.xml">evaluating and combining and biomedical named entity recognition systems </title>
<section> corpora.  </section>
<citcontext>
<prevsection>
<prevsent>in our experiments we used two corpora consisting of abstracts and one consisting of full papers.
</prevsent>
<prevsent>one of the abstracts corpora was automatically generated while the other two were manually annotated.
</prevsent>
</prevsection>
<citsent citstr=" W06-3328 ">
all three were created using resources from flybase4 and they are publicly available5 . the automatically generated corpus was created in order to bootstrap gene name recognizer in vlachos &amp; gasperin (2006).<papid> W06-3328 </papid></citsent>
<aftsection>
<nextsent>the approach used was introduced by morgan et al(2004).
</nextsent>
<nextsent>in brief, the abstracts of 16,609 articles curated by flybase were retrieved and tokenized by rasp (briscoe et al, 2006).<papid> P06-4020 </papid></nextsent>
<nextsent>for each article, the gene names and their synonyms that were recorded by the curators were annotated automatically in its abstract using longest extent pattern matching.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2233">
<title id=" W07-1031.xml">evaluating and combining and biomedical named entity recognition systems </title>
<section> discussion - related work.  </section>
<citcontext>
<prevsection>
<prevsent>from the analysis presented earlier, the crf+raspsystem behaves differently and therefore its not certain that those strategies would be equally beneficial to it.
</prevsent>
<prevsent>as mentioned in the introduction, there has been lot of work on biomedical ner, either through shared tasks or independent efforts.
</prevsent>
</prevsection>
<citsent citstr=" W04-1221 ">
of particular interest is the work of morgan et al(2004) who boot strapped an hmm-based gene name recognizer using flybase resources and evaluate on abstracts.also of interest is the system presented by settles (2004) <papid> W04-1221 </papid>which used crfs with rich feature setsand suggested that one could use features from syntactic parsing with this model given their flexibility.direct comparisons with these works are not possible since different datasets were used.</citsent>
<aftsection>
<nextsent>finaly, combining models has been successful way of achieving good results, such as those of florian et al (2003) <papid> W03-0425 </papid>who had the top performance in the named entity recognition shared task of conll 2003 (tjong kim sang and de meulder, 2003).</nextsent>
<nextsent>in this paper we compared two different named entity recognition systems on abstracts and full paper corpora using automatically generated training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2234">
<title id=" W07-1031.xml">evaluating and combining and biomedical named entity recognition systems </title>
<section> discussion - related work.  </section>
<citcontext>
<prevsection>
<prevsent>as mentioned in the introduction, there has been lot of work on biomedical ner, either through shared tasks or independent efforts.
</prevsent>
<prevsent>of particular interest is the work of morgan et al(2004) who boot strapped an hmm-based gene name recognizer using flybase resources and evaluate on abstracts.also of interest is the system presented by settles (2004) <papid> W04-1221 </papid>which used crfs with rich feature setsand suggested that one could use features from syntactic parsing with this model given their flexibility.direct comparisons with these works are not possible since different datasets were used.</prevsent>
</prevsection>
<citsent citstr=" W03-0425 ">
finaly, combining models has been successful way of achieving good results, such as those of florian et al (2003) <papid> W03-0425 </papid>who had the top performance in the named entity recognition shared task of conll 2003 (tjong kim sang and de meulder, 2003).</citsent>
<aftsection>
<nextsent>in this paper we compared two different named entity recognition systems on abstracts and full paper corpora using automatically generated training data.
</nextsent>
<nextsent>we demonstrated how the datasets affect the evaluation and how the two systems can be combined.
</nextsent>
<nextsent>also, our experiments showed that bootstrapping using automatically annotated abstracts can be efficient even when evaluating on full papers.as future work, it would be of interest to develop an efficient way to generate data automatically from full papers which could improve there sults further.
</nextsent>
<nextsent>an interesting approach would be to combine dictionary-based matching with an existing ner system in order to reduce the noise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2235">
<title id=" W07-1031.xml">evaluating and combining and biomedical named entity recognition systems </title>
<section> conclusions- future work.  </section>
<citcontext>
<prevsection>
<prevsent>the good performance of bootstrapping gene name recognizers using automatically created training data suggests that it is realistic alternative to fully supervised systems.
</prevsent>
<prevsent>the latter have benefited from series of shared tasks that, by providing atestbed for evaluation, helped assessing and improving their performance.
</prevsent>
</prevsection>
<citsent citstr=" P04-1075 ">
given the variety of methods that are available for generating training data efficiently automatically using extant domain resources (morgan et al, 2004) or semi-automatically (active learning approaches like shen et al (2004) <papid> P04-1075 </papid>or systems using seed rules such as mikheev et al.</citsent>
<aftsection>
<nextsent>(1999)), it would be of interest to have shared task in which the participants would have access to evaluation data only and they would be invited to use such methods to develop their systems.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2236">
<title id=" W07-1212.xml">creating a systemic functional grammar corpus from the penn treebank </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this has been the method used to create ltag (frank, 2001), lfg (frank et al, 2003) and ccg (hockenmaier and steedman, 2005) corpora, among others.
</prevsent>
<prevsent>we employ similar methodology, converting the corpus using manually specified rules.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
since the sfg annotation is semantically oriented,the work also bears some resemblance to propbank (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>however, propbank is concerned with manually adding information to thepenn treebank, rather than automatically reinterpreting the same information through the lens of different linguistic theory.we chose not to base our conversion on the propbank annotation, as it does not currently cover the brown or switchboard sections of the treebank.the wider variety of genres provided by these sections makes the corpus much more useful for sfg,since the theory devotes significant attention to pragmatic phenomena and stylistic variation.
</nextsent>
<nextsent>generating constituent using systemic functional grammar involves traversing decision-tree like structure referred to as system network.
</nextsent>
<nextsent>the nodes of this tree are referred to as systems, and the options from the systems are referred to as features.at each system, the feature selected may add constraints on the type, number or order of the internal structure of the constituent.
</nextsent>
<nextsent>when the entire network has been traversed, the constraints are unified, and the required constituents generated.in order to annotate sentence according to systemic functional grammar, we must specify the setof features encountered as the system network is traversed, and apply function labels to each constituent.the function labeling is required because the constraints are always specified according to the child constituents?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2237">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.1 motivation.
</prevsent>
<prevsent>word alignment typically constitutes the first stage of the statistical machine translation pipeline.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
giza++ (och and ney, 2003)<papid> J03-1002 </papid>an implementation of the ibm (brown et al, 1993) <papid> J93-2003 </papid>and hmm (?)alignment models, is the most widely-used alignment system.</citsent>
<aftsection>
<nextsent>giza++ union alignments have been used in the state-of-the-art syntax-based statistical mt system described in (galley et al, 2006) <papid> P06-1121 </papid>and in the hierarchical phrase-based system hiero (chiang, 2007).</nextsent>
<nextsent>giza++ refined alignments have been usedin state-of-the-art phrase-based statistical mt systems such as (och, 2004); variations on the refined heuristic have been used by (koehn et al, 2003) (<papid> N03-1017 </papid>diag and diag-and) and by the phrase-based system moses (grow-diag-final) (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2239">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.1 motivation.
</prevsent>
<prevsent>word alignment typically constitutes the first stage of the statistical machine translation pipeline.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
giza++ (och and ney, 2003)<papid> J03-1002 </papid>an implementation of the ibm (brown et al, 1993) <papid> J93-2003 </papid>and hmm (?)alignment models, is the most widely-used alignment system.</citsent>
<aftsection>
<nextsent>giza++ union alignments have been used in the state-of-the-art syntax-based statistical mt system described in (galley et al, 2006) <papid> P06-1121 </papid>and in the hierarchical phrase-based system hiero (chiang, 2007).</nextsent>
<nextsent>giza++ refined alignments have been usedin state-of-the-art phrase-based statistical mt systems such as (och, 2004); variations on the refined heuristic have been used by (koehn et al, 2003) (<papid> N03-1017 </papid>diag and diag-and) and by the phrase-based system moses (grow-diag-final) (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2240">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word alignment typically constitutes the first stage of the statistical machine translation pipeline.
</prevsent>
<prevsent>giza++ (och and ney, 2003)<papid> J03-1002 </papid>an implementation of the ibm (brown et al, 1993) <papid> J93-2003 </papid>and hmm (?)alignment models, is the most widely-used alignment system.</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
giza++ union alignments have been used in the state-of-the-art syntax-based statistical mt system described in (galley et al, 2006) <papid> P06-1121 </papid>and in the hierarchical phrase-based system hiero (chiang, 2007).</citsent>
<aftsection>
<nextsent>giza++ refined alignments have been usedin state-of-the-art phrase-based statistical mt systems such as (och, 2004); variations on the refined heuristic have been used by (koehn et al, 2003) (<papid> N03-1017 </papid>diag and diag-and) and by the phrase-based system moses (grow-diag-final) (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>giza++ union alignments have high recall butlow precision, while intersection or refined alignments have high precision but low recall.1 there are two natural approaches to improving upon giza++alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2241">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>giza++ (och and ney, 2003)<papid> J03-1002 </papid>an implementation of the ibm (brown et al, 1993) <papid> J93-2003 </papid>and hmm (?)alignment models, is the most widely-used alignment system.</prevsent>
<prevsent>giza++ union alignments have been used in the state-of-the-art syntax-based statistical mt system described in (galley et al, 2006) <papid> P06-1121 </papid>and in the hierarchical phrase-based system hiero (chiang, 2007).</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
giza++ refined alignments have been usedin state-of-the-art phrase-based statistical mt systems such as (och, 2004); variations on the refined heuristic have been used by (koehn et al, 2003) (<papid> N03-1017 </papid>diag and diag-and) and by the phrase-based system moses (grow-diag-final) (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>giza++ union alignments have high recall butlow precision, while intersection or refined alignments have high precision but low recall.1 there are two natural approaches to improving upon giza++alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments.
</nextsent>
<nextsent>in this work, we delete links from giza++ union alignments to improve precision.
</nextsent>
<nextsent>the low precision of giza++ union alignments poses particular problem for syntax-based rule extraction algorithms such as (quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al,2006): <papid> P06-1077 </papid>if the incorrect links violate syntactic correspondences, they force the rule extraction algorithm to extract rules that are large in size, few in number, and poor in generalization ability.</nextsent>
<nextsent>figure 1 illustrates this problem: the dotted line represents an incorrect link in the giza++ unionalignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2242">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>giza++ (och and ney, 2003)<papid> J03-1002 </papid>an implementation of the ibm (brown et al, 1993) <papid> J93-2003 </papid>and hmm (?)alignment models, is the most widely-used alignment system.</prevsent>
<prevsent>giza++ union alignments have been used in the state-of-the-art syntax-based statistical mt system described in (galley et al, 2006) <papid> P06-1121 </papid>and in the hierarchical phrase-based system hiero (chiang, 2007).</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
giza++ refined alignments have been usedin state-of-the-art phrase-based statistical mt systems such as (och, 2004); variations on the refined heuristic have been used by (koehn et al, 2003) (<papid> N03-1017 </papid>diag and diag-and) and by the phrase-based system moses (grow-diag-final) (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>giza++ union alignments have high recall butlow precision, while intersection or refined alignments have high precision but low recall.1 there are two natural approaches to improving upon giza++alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments.
</nextsent>
<nextsent>in this work, we delete links from giza++ union alignments to improve precision.
</nextsent>
<nextsent>the low precision of giza++ union alignments poses particular problem for syntax-based rule extraction algorithms such as (quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al,2006): <papid> P06-1077 </papid>if the incorrect links violate syntactic correspondences, they force the rule extraction algorithm to extract rules that are large in size, few in number, and poor in generalization ability.</nextsent>
<nextsent>figure 1 illustrates this problem: the dotted line represents an incorrect link in the giza++ unionalignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2243">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>giza++ union alignments have high recall butlow precision, while intersection or refined alignments have high precision but low recall.1 there are two natural approaches to improving upon giza++alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments.
</prevsent>
<prevsent>in this work, we delete links from giza++ union alignments to improve precision.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
the low precision of giza++ union alignments poses particular problem for syntax-based rule extraction algorithms such as (quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al,2006): <papid> P06-1077 </papid>if the incorrect links violate syntactic correspondences, they force the rule extraction algorithm to extract rules that are large in size, few in number, and poor in generalization ability.</citsent>
<aftsection>
<nextsent>figure 1 illustrates this problem: the dotted line represents an incorrect link in the giza++ unionalignment.
</nextsent>
<nextsent>using the rule extraction algorithm described in (galley et al, 2004), we extract the rules shown in the left most column (r1r4).
</nextsent>
<nextsent>rule r1 is large and unlikely to generalize well.
</nextsent>
<nextsent>if we delete the incorrect link in figure 1, we can extract the rules shown in the rightmost column (r2r9): rule r1, the largest rule from the initial set, disappears,and several smaller, more modular rules (r5r9) replace it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2245">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>giza++ union alignments have high recall butlow precision, while intersection or refined alignments have high precision but low recall.1 there are two natural approaches to improving upon giza++alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments.
</prevsent>
<prevsent>in this work, we delete links from giza++ union alignments to improve precision.
</prevsent>
</prevsection>
<citsent citstr=" W06-3601 ">
the low precision of giza++ union alignments poses particular problem for syntax-based rule extraction algorithms such as (quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al,2006): <papid> P06-1077 </papid>if the incorrect links violate syntactic correspondences, they force the rule extraction algorithm to extract rules that are large in size, few in number, and poor in generalization ability.</citsent>
<aftsection>
<nextsent>figure 1 illustrates this problem: the dotted line represents an incorrect link in the giza++ unionalignment.
</nextsent>
<nextsent>using the rule extraction algorithm described in (galley et al, 2004), we extract the rules shown in the left most column (r1r4).
</nextsent>
<nextsent>rule r1 is large and unlikely to generalize well.
</nextsent>
<nextsent>if we delete the incorrect link in figure 1, we can extract the rules shown in the rightmost column (r2r9): rule r1, the largest rule from the initial set, disappears,and several smaller, more modular rules (r5r9) replace it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2246">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>giza++ union alignments have high recall butlow precision, while intersection or refined alignments have high precision but low recall.1 there are two natural approaches to improving upon giza++alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments.
</prevsent>
<prevsent>in this work, we delete links from giza++ union alignments to improve precision.
</prevsent>
</prevsection>
<citsent citstr=" P06-1077 ">
the low precision of giza++ union alignments poses particular problem for syntax-based rule extraction algorithms such as (quirk et al, 2005; <papid> P05-1034 </papid>galley et al, 2006; <papid> P06-1121 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al,2006): <papid> P06-1077 </papid>if the incorrect links violate syntactic correspondences, they force the rule extraction algorithm to extract rules that are large in size, few in number, and poor in generalization ability.</citsent>
<aftsection>
<nextsent>figure 1 illustrates this problem: the dotted line represents an incorrect link in the giza++ unionalignment.
</nextsent>
<nextsent>using the rule extraction algorithm described in (galley et al, 2004), we extract the rules shown in the left most column (r1r4).
</nextsent>
<nextsent>rule r1 is large and unlikely to generalize well.
</nextsent>
<nextsent>if we delete the incorrect link in figure 1, we can extract the rules shown in the rightmost column (r2r9): rule r1, the largest rule from the initial set, disappears,and several smaller, more modular rules (r5r9) replace it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2249">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our link deletion algorithm is easy to implement, runs quickly, and hasbeen used by top-scoring mt system in the chinese newswire track of the 2008 nist evaluation.
</prevsent>
<prevsent>1.2 related work.
</prevsent>
</prevsection>
<citsent citstr=" P05-1057 ">
recently, discriminative methods for alignment have rivaled the quality of ibm model 4 alignments (liu et al, 2005; <papid> P05-1057 </papid>ittycheriah and roukos, 2005; <papid> H05-1012 </papid>taskar et al, 2005; <papid> H05-1010 </papid>moore et al, 2006; <papid> P06-1065 </papid>fraser and marcu, 2007<papid> D07-1006 </papid>b).</citsent>
<aftsection>
<nextsent>however, except for (fraser andmarcu, 2007<papid> D07-1006 </papid>b), none of these advances in alignment quality has improved translation quality of state-of-the-art system.</nextsent>
<nextsent>we use discriminatively trained model to identify and delete incorrect links,and demonstrate that these gains in alignment quality lead to gains in translation quality in state of-the-art syntax-based mt system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2250">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our link deletion algorithm is easy to implement, runs quickly, and hasbeen used by top-scoring mt system in the chinese newswire track of the 2008 nist evaluation.
</prevsent>
<prevsent>1.2 related work.
</prevsent>
</prevsection>
<citsent citstr=" H05-1012 ">
recently, discriminative methods for alignment have rivaled the quality of ibm model 4 alignments (liu et al, 2005; <papid> P05-1057 </papid>ittycheriah and roukos, 2005; <papid> H05-1012 </papid>taskar et al, 2005; <papid> H05-1010 </papid>moore et al, 2006; <papid> P06-1065 </papid>fraser and marcu, 2007<papid> D07-1006 </papid>b).</citsent>
<aftsection>
<nextsent>however, except for (fraser andmarcu, 2007<papid> D07-1006 </papid>b), none of these advances in alignment quality has improved translation quality of state-of-the-art system.</nextsent>
<nextsent>we use discriminatively trained model to identify and delete incorrect links,and demonstrate that these gains in alignment quality lead to gains in translation quality in state of-the-art syntax-based mt system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2251">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our link deletion algorithm is easy to implement, runs quickly, and hasbeen used by top-scoring mt system in the chinese newswire track of the 2008 nist evaluation.
</prevsent>
<prevsent>1.2 related work.
</prevsent>
</prevsection>
<citsent citstr=" H05-1010 ">
recently, discriminative methods for alignment have rivaled the quality of ibm model 4 alignments (liu et al, 2005; <papid> P05-1057 </papid>ittycheriah and roukos, 2005; <papid> H05-1012 </papid>taskar et al, 2005; <papid> H05-1010 </papid>moore et al, 2006; <papid> P06-1065 </papid>fraser and marcu, 2007<papid> D07-1006 </papid>b).</citsent>
<aftsection>
<nextsent>however, except for (fraser andmarcu, 2007<papid> D07-1006 </papid>b), none of these advances in alignment quality has improved translation quality of state-of-the-art system.</nextsent>
<nextsent>we use discriminatively trained model to identify and delete incorrect links,and demonstrate that these gains in alignment quality lead to gains in translation quality in state of-the-art syntax-based mt system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2252">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our link deletion algorithm is easy to implement, runs quickly, and hasbeen used by top-scoring mt system in the chinese newswire track of the 2008 nist evaluation.
</prevsent>
<prevsent>1.2 related work.
</prevsent>
</prevsection>
<citsent citstr=" P06-1065 ">
recently, discriminative methods for alignment have rivaled the quality of ibm model 4 alignments (liu et al, 2005; <papid> P05-1057 </papid>ittycheriah and roukos, 2005; <papid> H05-1012 </papid>taskar et al, 2005; <papid> H05-1010 </papid>moore et al, 2006; <papid> P06-1065 </papid>fraser and marcu, 2007<papid> D07-1006 </papid>b).</citsent>
<aftsection>
<nextsent>however, except for (fraser andmarcu, 2007<papid> D07-1006 </papid>b), none of these advances in alignment quality has improved translation quality of state-of-the-art system.</nextsent>
<nextsent>we use discriminatively trained model to identify and delete incorrect links,and demonstrate that these gains in alignment quality lead to gains in translation quality in state of-the-art syntax-based mt system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2253">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our link deletion algorithm is easy to implement, runs quickly, and hasbeen used by top-scoring mt system in the chinese newswire track of the 2008 nist evaluation.
</prevsent>
<prevsent>1.2 related work.
</prevsent>
</prevsection>
<citsent citstr=" D07-1006 ">
recently, discriminative methods for alignment have rivaled the quality of ibm model 4 alignments (liu et al, 2005; <papid> P05-1057 </papid>ittycheriah and roukos, 2005; <papid> H05-1012 </papid>taskar et al, 2005; <papid> H05-1010 </papid>moore et al, 2006; <papid> P06-1065 </papid>fraser and marcu, 2007<papid> D07-1006 </papid>b).</citsent>
<aftsection>
<nextsent>however, except for (fraser andmarcu, 2007<papid> D07-1006 </papid>b), none of these advances in alignment quality has improved translation quality of state-of-the-art system.</nextsent>
<nextsent>we use discriminatively trained model to identify and delete incorrect links,and demonstrate that these gains in alignment quality lead to gains in translation quality in state of-the-art syntax-based mt system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2262">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we use discriminatively trained model to identify and delete incorrect links,and demonstrate that these gains in alignment quality lead to gains in translation quality in state of-the-art syntax-based mt system.
</prevsent>
<prevsent>in contrast to the semi-supervised leaf alignment algorithm of(fraser and marcu, 2007<papid> D07-1006 </papid>b), which requires 1,5002,000 cpu days per iteration to align 8.4m chinese english sentences (anonymous, p.c.), link deletion requires only 450 cpu hours to re-align such corpus (after initial alignment by giza++, which requires 20-24 cpu days).several recent works incorporate syntactic features into alignment.</prevsent>
</prevsection>
<citsent citstr=" D07-1038 ">
(may and knight, 2007) <papid> D07-1038 </papid>use syntactic constraints to re-align parallel corpus that has been aligned by giza++ as follows: they extract string-to-tree transducer rules from the corpus, the target parse trees, and the alignment; discard the initial alignment; use the extracted rules to construct forest of possible string-to-tree derivations for each string/tree pair in the corpus; use em to select theviterbi derivation tree for each pair; and finally, induce new alignment from the viterbi derivations, using the re-aligned corpus to train syntax-based mt system.</citsent>
<aftsection>
<nextsent>(may and knight, 2007) <papid> D07-1038 </papid>differs from our approach in two ways: first, the set of possible re-alignments they consider for each sentence pair is limited by the initial giza++ alignments seen over the training corpus, while we consider all alignments that can be reached by deleting links from the initial giza++ alignment for that sentence pair.</nextsent>
<nextsent>second, (may and knight, 2007) <papid> D07-1038 </papid>use time-intensive training algorithm to select the best re-alignment for each sentence pair, while we use fast greedy search to determine which links to delete; in contrast to (may and knight, 2007), <papid> D07-1038 </papid>who require 400cpu hours to re-align 330k chinese-english sentence pairs (anonymous, p.c), link deletion requires only 18 cpu hours to re-align such corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2272">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(may and knight, 2007) <papid> D07-1038 </papid>differs from our approach in two ways: first, the set of possible re-alignments they consider for each sentence pair is limited by the initial giza++ alignments seen over the training corpus, while we consider all alignments that can be reached by deleting links from the initial giza++ alignment for that sentence pair.</prevsent>
<prevsent>second, (may and knight, 2007) <papid> D07-1038 </papid>use time-intensive training algorithm to select the best re-alignment for each sentence pair, while we use fast greedy search to determine which links to delete; in contrast to (may and knight, 2007), <papid> D07-1038 </papid>who require 400cpu hours to re-align 330k chinese-english sentence pairs (anonymous, p.c), link deletion requires only 18 cpu hours to re-align such corpus.</prevsent>
</prevsection>
<citsent citstr=" W05-0812 ">
(lopez and resnik, 2005) <papid> W05-0812 </papid>and (denero and klein, 2007) <papid> P07-1003 </papid>modify the distortion model of the hmm alignment model (vogel et al, 1996) <papid> C96-2141 </papid>to reflect tree distance rather than string distance; (cherry and lin, 2006) <papid> P06-2014 </papid>modify an itg aligner by introducinga penalty for induced parses that violate syntactic bracketing constraints.</citsent>
<aftsection>
<nextsent>similarly to these approaches, we use syntactic bracketing to constrain alignment, but our work extends beyond improving alignment quality to improve translation quality as well.
</nextsent>
<nextsent>we propose an algorithm to re-align parallel bitext that has been aligned by giza++ (ibm model 4), then symmetrized using the union heuristic.
</nextsent>
<nextsent>we then train syntax-based translation system on there aligned bitext, and evaluate whether the re-alignedbitext yields better translation model than base line system trained on the giza++ union aligned bitext.
</nextsent>
<nextsent>2.1 link deletion algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2273">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(may and knight, 2007) <papid> D07-1038 </papid>differs from our approach in two ways: first, the set of possible re-alignments they consider for each sentence pair is limited by the initial giza++ alignments seen over the training corpus, while we consider all alignments that can be reached by deleting links from the initial giza++ alignment for that sentence pair.</prevsent>
<prevsent>second, (may and knight, 2007) <papid> D07-1038 </papid>use time-intensive training algorithm to select the best re-alignment for each sentence pair, while we use fast greedy search to determine which links to delete; in contrast to (may and knight, 2007), <papid> D07-1038 </papid>who require 400cpu hours to re-align 330k chinese-english sentence pairs (anonymous, p.c), link deletion requires only 18 cpu hours to re-align such corpus.</prevsent>
</prevsection>
<citsent citstr=" P07-1003 ">
(lopez and resnik, 2005) <papid> W05-0812 </papid>and (denero and klein, 2007) <papid> P07-1003 </papid>modify the distortion model of the hmm alignment model (vogel et al, 1996) <papid> C96-2141 </papid>to reflect tree distance rather than string distance; (cherry and lin, 2006) <papid> P06-2014 </papid>modify an itg aligner by introducinga penalty for induced parses that violate syntactic bracketing constraints.</citsent>
<aftsection>
<nextsent>similarly to these approaches, we use syntactic bracketing to constrain alignment, but our work extends beyond improving alignment quality to improve translation quality as well.
</nextsent>
<nextsent>we propose an algorithm to re-align parallel bitext that has been aligned by giza++ (ibm model 4), then symmetrized using the union heuristic.
</nextsent>
<nextsent>we then train syntax-based translation system on there aligned bitext, and evaluate whether the re-alignedbitext yields better translation model than base line system trained on the giza++ union aligned bitext.
</nextsent>
<nextsent>2.1 link deletion algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2274">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(may and knight, 2007) <papid> D07-1038 </papid>differs from our approach in two ways: first, the set of possible re-alignments they consider for each sentence pair is limited by the initial giza++ alignments seen over the training corpus, while we consider all alignments that can be reached by deleting links from the initial giza++ alignment for that sentence pair.</prevsent>
<prevsent>second, (may and knight, 2007) <papid> D07-1038 </papid>use time-intensive training algorithm to select the best re-alignment for each sentence pair, while we use fast greedy search to determine which links to delete; in contrast to (may and knight, 2007), <papid> D07-1038 </papid>who require 400cpu hours to re-align 330k chinese-english sentence pairs (anonymous, p.c), link deletion requires only 18 cpu hours to re-align such corpus.</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
(lopez and resnik, 2005) <papid> W05-0812 </papid>and (denero and klein, 2007) <papid> P07-1003 </papid>modify the distortion model of the hmm alignment model (vogel et al, 1996) <papid> C96-2141 </papid>to reflect tree distance rather than string distance; (cherry and lin, 2006) <papid> P06-2014 </papid>modify an itg aligner by introducinga penalty for induced parses that violate syntactic bracketing constraints.</citsent>
<aftsection>
<nextsent>similarly to these approaches, we use syntactic bracketing to constrain alignment, but our work extends beyond improving alignment quality to improve translation quality as well.
</nextsent>
<nextsent>we propose an algorithm to re-align parallel bitext that has been aligned by giza++ (ibm model 4), then symmetrized using the union heuristic.
</nextsent>
<nextsent>we then train syntax-based translation system on there aligned bitext, and evaluate whether the re-alignedbitext yields better translation model than base line system trained on the giza++ union aligned bitext.
</nextsent>
<nextsent>2.1 link deletion algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2275">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(may and knight, 2007) <papid> D07-1038 </papid>differs from our approach in two ways: first, the set of possible re-alignments they consider for each sentence pair is limited by the initial giza++ alignments seen over the training corpus, while we consider all alignments that can be reached by deleting links from the initial giza++ alignment for that sentence pair.</prevsent>
<prevsent>second, (may and knight, 2007) <papid> D07-1038 </papid>use time-intensive training algorithm to select the best re-alignment for each sentence pair, while we use fast greedy search to determine which links to delete; in contrast to (may and knight, 2007), <papid> D07-1038 </papid>who require 400cpu hours to re-align 330k chinese-english sentence pairs (anonymous, p.c), link deletion requires only 18 cpu hours to re-align such corpus.</prevsent>
</prevsection>
<citsent citstr=" P06-2014 ">
(lopez and resnik, 2005) <papid> W05-0812 </papid>and (denero and klein, 2007) <papid> P07-1003 </papid>modify the distortion model of the hmm alignment model (vogel et al, 1996) <papid> C96-2141 </papid>to reflect tree distance rather than string distance; (cherry and lin, 2006) <papid> P06-2014 </papid>modify an itg aligner by introducinga penalty for induced parses that violate syntactic bracketing constraints.</citsent>
<aftsection>
<nextsent>similarly to these approaches, we use syntactic bracketing to constrain alignment, but our work extends beyond improving alignment quality to improve translation quality as well.
</nextsent>
<nextsent>we propose an algorithm to re-align parallel bitext that has been aligned by giza++ (ibm model 4), then symmetrized using the union heuristic.
</nextsent>
<nextsent>we then train syntax-based translation system on there aligned bitext, and evaluate whether the re-alignedbitext yields better translation model than base line system trained on the giza++ union aligned bitext.
</nextsent>
<nextsent>2.1 link deletion algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2276">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> link deletion.  </section>
<citcontext>
<prevsection>
<prevsent>1-to-many links appear more frequently in giza++ union alignments than in gold alignments, and are therefore good candidates for deletion.
</prevsent>
<prevsent>the category of 1-to-many links is further subdivided, depending on the degree of contiguity that the link exhibits with its neighbors.4 each link in 1-to-many 3while using dynamic programming algorithm would likely improve search efficiency and allow link deletion to find an optimal solution, in practice, the greedy search runs quickly and improves alignment quality.
</prevsent>
</prevsection>
<citsent citstr=" H05-1022 ">
4(deng and byrne, 2005) <papid> H05-1022 </papid>observe that, in manually aligned chinese-english corpus, 82% of the chinese words that are alignment can have 0, 1, or 2 neighbors, according to how many links are adjacent to it in the 1-to-many alignment: zeroneighbors: in figure 1, the link ? -needs has 0 neighbors.</citsent>
<aftsection>
<nextsent>oneneighbor: in figure 1, the links ? -starts and ? -out each have 1 neighbor namely, each other.
</nextsent>
<nextsent>twoneighbors: in figure 1, in the 1-to-manyalignment formed by {?
</nextsent>
<nextsent>)-its,?
</nextsent>
<nextsent>)-own,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2277">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> link deletion.  </section>
<citcontext>
<prevsection>
<prevsent>these words are aligned with each other frequently (and erroneously) by giza++ union, but rarely in the gold standard.
</prevsent>
<prevsent>we delete all links in the set {a, an, the} ? {{, ?} from ainitial as preprocessing step.7 2.4 perceptron training.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
we set the feature weights ? using modified version of averaged perceptron learning with structured outputs (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>following (moore, 2005),<papid> H05-1011 </papid>we initialize the value of our expected most informative feature (rulecount) to 1.0, and initialize all other feature weights to 0.</nextsent>
<nextsent>during each pass over the discriminative training set, we decode?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2279">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> link deletion.  </section>
<citcontext>
<prevsection>
<prevsent>we delete all links in the set {a, an, the} ? {{, ?} from ainitial as preprocessing step.7 2.4 perceptron training.
</prevsent>
<prevsent>we set the feature weights ? using modified version of averaged perceptron learning with structured outputs (collins, 2002).<papid> W02-1001 </papid></prevsent>
</prevsection>
<citsent citstr=" H05-1011 ">
following (moore, 2005),<papid> H05-1011 </papid>we initialize the value of our expected most informative feature (rulecount) to 1.0, and initialize all other feature weights to 0.</citsent>
<aftsection>
<nextsent>during each pass over the discriminative training set, we decode?
</nextsent>
<nextsent>each sentence pair by greedily deleting links from ainitial inorder to maximize the score of the resulting alignment using the current settings of ?
</nextsent>
<nextsent>(for details, refer to section 2.1).
</nextsent>
<nextsent>5on 400-sentence-pair chinese-english dataset, giza++union alignments have precision of 77.32 while giza++ refined alignments have precision of 85.26.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2280">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> link deletion.  </section>
<citcontext>
<prevsection>
<prevsent>when it is no longer possible to increase score(a) by deleting any links, link deletion concludes and returns the highest-scoring alignment, a1-best.
</prevsent>
<prevsent>in general, agold /?
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
acandidates; following (collins, 2000) and (charniak and johnson, 2005)<papid> P05-1022 </papid>for parse reranking and (liang et al, 2006) <papid> P06-1096 </papid>for translation reranking, we define aoracle as alignment ina candidates that is most similar to agold.8 we up date each feature weight as follows: = + haoraclei ? a1-best . 9 following (moore, 2005),<papid> H05-1011 </papid> after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights.when alignment quality stops increasing on the discriminative training set, perceptron training ends.10 the weight vector returned by perceptron training is the average over the training set of all weight vectors seen during all iterations; averaging reduces overfit ting on the training set (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>3.1 datasets.
</nextsent>
<nextsent>we evaluate the effect of link deletion upon alignment quality and translation quality for two chinese english datasets, and one arabic-english dataset.
</nextsent>
<nextsent>each dataset consists of newswire, and contains small subset of manually aligned sentence pairs.
</nextsent>
<nextsent>we divide the manually aligned subset into training set (used to discriminatively set the feature weights forlink deletion) and test set (used to evaluate the impact of link deletion upon alignment quality).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2281">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> link deletion.  </section>
<citcontext>
<prevsection>
<prevsent>when it is no longer possible to increase score(a) by deleting any links, link deletion concludes and returns the highest-scoring alignment, a1-best.
</prevsent>
<prevsent>in general, agold /?
</prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
acandidates; following (collins, 2000) and (charniak and johnson, 2005)<papid> P05-1022 </papid>for parse reranking and (liang et al, 2006) <papid> P06-1096 </papid>for translation reranking, we define aoracle as alignment ina candidates that is most similar to agold.8 we up date each feature weight as follows: = + haoraclei ? a1-best . 9 following (moore, 2005),<papid> H05-1011 </papid> after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights.when alignment quality stops increasing on the discriminative training set, perceptron training ends.10 the weight vector returned by perceptron training is the average over the training set of all weight vectors seen during all iterations; averaging reduces overfit ting on the training set (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>3.1 datasets.
</nextsent>
<nextsent>we evaluate the effect of link deletion upon alignment quality and translation quality for two chinese english datasets, and one arabic-english dataset.
</nextsent>
<nextsent>each dataset consists of newswire, and contains small subset of manually aligned sentence pairs.
</nextsent>
<nextsent>we divide the manually aligned subset into training set (used to discriminatively set the feature weights forlink deletion) and test set (used to evaluate the impact of link deletion upon alignment quality).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2288">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>10we discuss alignment quality metrics in detail in section 3.2.
</prevsent>
<prevsent>48 using the feature weights learned on the manually aligned training set, we then apply link deletion tothe remainder (non-manually aligned) of each bilingual dataset, and train full syntax-based statistical mt system on these sentence pairs.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
after maximum bleu tuning (och, 2003<papid> P03-1021 </papid>a) on held-out tuning set, we evaluate translation quality on held-out test set.</citsent>
<aftsection>
<nextsent>table 2 lists the source and the size of the training, tuning, and test sets used for each translation task.
</nextsent>
<nextsent>3.2 evaluation metrics.
</nextsent>
<nextsent>aer (alignment error rate) (och and ney, 2003)<papid> J03-1002 </papid>is the most widely used metric of alignment quality, but requires gold-standard alignments labelled with sure/possible?</nextsent>
<nextsent>annotations to compute; lacking such annotations, we can compute alignment measure instead.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2298">
<title id=" W08-0306.xml">using syntax to improve word alignment precision for syntax based machine translation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>we use weighted fully-connected alignment f-measureas the training criterion for link deletion, and to evaluate alignment quality on training and test sets.
</prevsent>
<prevsent>rule f-measure to evaluate the impact of link deletion upon rule quality, we compare the rule precision, recall, and f-measure of the rule set extracted 11in figure 1, the fully-connected version of the alignments shown would include the links ? -starts and ? - out.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
language train test chinese-english 400 400 chinese-english 1500 1500 arabic-english 1500 1500table 1: size (sentence pairs) of datasets used in alignment link deletion tasks from our hypothesized alignments and collins style parser against the rule set extracted from gold alignments and gold parses.bleu for all translation tasks, we report case insensitive nist bleu scores (papineni et al, 2002) <papid> P02-1040 </papid>using 4 references per sentence.</citsent>
<aftsection>
<nextsent>3.3 experiments.
</nextsent>
<nextsent>starting with giza++ union (ibm model 4) alignments, we use perceptron training to set the weights of each feature used in link deletion in order to optimize weighted fully-connected alignment f-measure(?=0.5 for chinese-english and ?=0.1 for arabicenglish) on manually aligned discriminative training set.
</nextsent>
<nextsent>we report the (fully-connected) precision,recall, and weighted alignment f-measure on held out test set after running perceptron training, relative to the baseline giza++ union alignments.
</nextsent>
<nextsent>using the learned feature weights, we then perform link deletion over the giza++ union alignments for the entire training corpus for each translation task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2301">
<title id=" W08-0102.xml">response based confidence annotation for spoken dialogue systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the baseline utterance-level confidence module we make use of in this paper was introduced in (hazen et al,2002); we use subset of the recognizer-derived features used by this module.
</prevsent>
<prevsent>in it, confidence scores are derived by training linear projection model to differentiate utterances with high word error rates.the utterance-level confidence scores are used to decide whether or not the entire utterance should be accepted or rejected, while the decision as to how to respond is left out of the classification process.of course, most other recognizers make use of utterance or hypothesis level confidence scores as well; see, for example (san-segundo et al, 2000; chase, 1997).
</prevsent>
</prevsection>
<citsent citstr=" A00-2029 ">
(litman et al, 2000) <papid> A00-2029 </papid>demonstrate the additional use of prosodic features in deriving confidence scores, and transition the problem from one of word error rate to one involving concept error rate, whichis more appropriate in the context of spoken dialogue systems.</citsent>
<aftsection>
<nextsent>however, they consider only the top recognition hypothesis.our work has been heavily influenced by (gabs dil and lemon, 2004), (<papid> P04-1044 </papid>bohus and rudnicky, 2002),(walker et al, 2000), and (chotimongkol and rud 12 nicky, 2001) all of which demonstrate the utility of training classifier with features derived from the natural language and dialogue management components of spoken dialogue system to better predict the quality of speech recognition results.</nextsent>
<nextsent>the work described in (gabsdil and lemon, 2004) <papid> P04-1044 </papid>is especially relevant, because, as in our experiments, the dialogue system of interest provides for map-basedmultimodal dialogue.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2302">
<title id=" W08-0102.xml">response based confidence annotation for spoken dialogue systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in it, confidence scores are derived by training linear projection model to differentiate utterances with high word error rates.the utterance-level confidence scores are used to decide whether or not the entire utterance should be accepted or rejected, while the decision as to how to respond is left out of the classification process.of course, most other recognizers make use of utterance or hypothesis level confidence scores as well; see, for example (san-segundo et al, 2000; chase, 1997).
</prevsent>
<prevsent>(litman et al, 2000) <papid> A00-2029 </papid>demonstrate the additional use of prosodic features in deriving confidence scores, and transition the problem from one of word error rate to one involving concept error rate, whichis more appropriate in the context of spoken dialogue systems.</prevsent>
</prevsection>
<citsent citstr=" P04-1044 ">
however, they consider only the top recognition hypothesis.our work has been heavily influenced by (gabs dil and lemon, 2004), (<papid> P04-1044 </papid>bohus and rudnicky, 2002),(walker et al, 2000), and (chotimongkol and rud 12 nicky, 2001) all of which demonstrate the utility of training classifier with features derived from the natural language and dialogue management components of spoken dialogue system to better predict the quality of speech recognition results.</citsent>
<aftsection>
<nextsent>the work described in (gabsdil and lemon, 2004) <papid> P04-1044 </papid>is especially relevant, because, as in our experiments, the dialogue system of interest provides for map-basedmultimodal dialogue.</nextsent>
<nextsent>indeed, we view the experiments presented here as extending and validating the techniques developed by gabsdil and lemon.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2305">
<title id=" W08-0102.xml">response based confidence annotation for spoken dialogue systems </title>
<section> experimental data.  </section>
<citcontext>
<prevsection>
<prevsent>users can interact with city browsers map-based graphical user interface by clicking and drawing; and they can speak with it by talking into their computer microphone and listening to response from their speakers.
</prevsent>
<prevsent>speech recognition is performed via the summit recognizer, using trigram language model with dynamically updatable classes for proper nouns such as city, street, and restaurant names see (chung et al, 2004) for description of this capability.
</prevsent>
</prevsection>
<citsent citstr=" J92-1004 ">
speech recognition results were parsed by the tina parser (seneff, 1992)<papid> J92-1004 </papid>using hand-crafted grammar.</citsent>
<aftsection>
<nextsent>a discourse module (filisko and seneff, 2003) then integrates contextual knowledge.
</nextsent>
<nextsent>the fully formed request is sent to the dialogue manager, which attempts to craft an appropriate system response both in terms of verbal and graphical response.
</nextsent>
<nextsent>the genesis system (seneff, 2002) uses hand-crafted generation rules to produce natural language string, which is sent to an off-the-shelf text-to-speech synthesizer.finally, the user hears the response, and the graphical user interface is updated to show, for example, set of search results on the map.
</nextsent>
<nextsent>3.1 data collection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2306">
<title id=" W07-0737.xml">localization of difficulttotranslate phrases </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>conversely, would knowing the correct translation for the dtps improve the systems translation for the rest of the sentence?
</prevsent>
<prevsent>in this work, we model difficulty as measurement with respect to particular mt system.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we further assume that the degree of difficulty of phrase is directly correlated with the quality of the translation produced by the mt system, which can be approximated using an automatic evaluation metric, such as bleu (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>using this formulation of difficulty, we build framework that augments an off-the-shelf phrase based mt system with dtp classifier that we developed.
</nextsent>
<nextsent>we explore the three questions in set of experiments, using the framework as testbed.
</nextsent>
<nextsent>in the first experiment, we verify that our proposed difficulty measurement is sensible.
</nextsent>
<nextsent>the second experiment evaluates the classifier accuracy in predicting whether source phrase is dtp.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2307">
<title id=" W07-0737.xml">localization of difficulttotranslate phrases </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>phrase translations are extracted from the par-.
</prevsent>
<prevsent>allel corpus.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
specifically, we generate word alignments using giza++ (och 2001) in both directions and combine them using the refined methodology (och and ney 2003), <papid> J03-1002 </papid>and then we applied koehns toolkit (2004) to extract parallel phrases.</citsent>
<aftsection>
<nextsent>we have relaxed the length constraints of the toolkit to ensure the extraction of long phrases (as long as 16 words).
</nextsent>
<nextsent>3.
</nextsent>
<nextsent>parallel phrases whose source parts are not.
</nextsent>
<nextsent>well-formed constituents are filtered out.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2308">
<title id=" W07-0737.xml">localization of difficulttotranslate phrases </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>additionally by the usage of our framework, the mt system performs the decoding task only once.
</prevsent>
<prevsent>the idea of isolated phrase translation has been explored successfully in mt community.
</prevsent>
</prevsection>
<citsent citstr=" P03-1040 ">
koehn and knight (2003) <papid> P03-1040 </papid>used isolated translation of np and pp phrases and merge them with the phrase based mt system to translate the complete sen tence.</citsent>
<aftsection>
<nextsent>in our work, instead of focusing on specific type of phrases (np or pp), we focus on isolated translation of difficult phrases with an aim to improve the translation quality of non-difficult segments too.
</nextsent>
<nextsent>we have presented an mt framework that makes use of additional information about difficult-to translate source phrases.
</nextsent>
<nextsent>our framework includes an svm-based phrase classifier that finds the segment of sentence that is most difficult to translate.
</nextsent>
<nextsent>our classifier achieves promising 71.5% accuracy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2309">
<title id=" W07-0737.xml">localization of difficulttotranslate phrases </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we expect different systems will have difficulties with different constructs, and thus they may support each other, and thus reducing the need to ask human translators for help with the difficult phrases.
</prevsent>
<prevsent>second, our current metric for phrasal difficulty depends on bleu.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
considering the recent debates about the shortcomings of the bleu score (callison-burch et. al. 2006), we are interested in applying alternative metrics such meteor (banerjee and lavie 2005).<papid> W05-0909 </papid></citsent>
<aftsection>
<nextsent>third, we believe that there is more room for improvement and extension of our classification features.
</nextsent>
<nextsent>specifically, we believe that our syntactic analysis of source sentences can be improved by including richer parsing features.
</nextsent>
<nextsent>finally, the framework can also be used to diagnose recurring problems in the mt system.
</nextsent>
<nextsent>we are currently developing methods for improving the translation of the difficult phrases for the phrase-based mt system used in our experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2310">
<title id=" W08-0207.xml">exploring large data issues in the curriculum a case study with map reduce </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>over the past couple of decades, the field of computational linguistics, and more broadly, human language technologies, has seen the emergence and later dominance of empirical techniques and data driven research.
</prevsent>
<prevsent>concomitant with this trend is the requirement of systems and algorithms to handle large quantities of data.
</prevsent>
</prevsection>
<citsent citstr=" P01-1005 ">
banko and brill (2001) <papid> P01-1005 </papid>were among the first to demonstrate the importance of dataset size as significant factor governing prediction accuracy in supervised machine learning task.</citsent>
<aftsection>
<nextsent>in fact, they argue that size of training setis perhaps more important than the choice of machine learning algorithm itself.
</nextsent>
<nextsent>similarly, experiments in question answering have shown the effectiveness of simple pattern-matching techniques when applied to large quantities of data (brill etal., 2001).
</nextsent>
<nextsent>more recently, this line of argumentation has been echoed in experiments with large-scale language models.
</nextsent>
<nextsent>brants et al (2007) <papid> D07-1090 </papid>show thatfor statistical machine translation, simple smoothing method (dubbed stupid backoff) approaches the quality of kneser-ney smoothing as the amount of training data increases, and with the simple method one can process significantly more data.given these observations, it is important to integrate discussions of large-data issues into any course on human language technology.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2311">
<title id=" W08-0207.xml">exploring large data issues in the curriculum a case study with map reduce </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>similarly, experiments in question answering have shown the effectiveness of simple pattern-matching techniques when applied to large quantities of data (brill etal., 2001).
</prevsent>
<prevsent>more recently, this line of argumentation has been echoed in experiments with large-scale language models.
</prevsent>
</prevsection>
<citsent citstr=" D07-1090 ">
brants et al (2007) <papid> D07-1090 </papid>show thatfor statistical machine translation, simple smoothing method (dubbed stupid backoff) approaches the quality of kneser-ney smoothing as the amount of training data increases, and with the simple method one can process significantly more data.given these observations, it is important to integrate discussions of large-data issues into any course on human language technology.</citsent>
<aftsection>
<nextsent>most existing courses focus on smaller-sized problems and datasets that can be processed on students?
</nextsent>
<nextsent>personal computers, making them ill-prepared to cope withthe vast quantities of data in operational environments.
</nextsent>
<nextsent>even when larger datasets are leveraged inthe classroom, they are mostly used as static resources.
</nextsent>
<nextsent>thus, students experience disconnect as they transition from learning environment to one where they work on real-world problems.nevertheless, there are at least two major challenges associated with explicit treatment of large data issues in an hlt curriculum: ? the first concerns resources: it is unclear where one might acquire the hardware to supported ucational activities, especially if such activities are in direct competition with research.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2312">
<title id=" W07-2071.xml">tor tormd distributional profiles of concepts for unsupervised word sense disambiguation </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>words in the context of target word have long been used as features by supervised word-sense classifiers.
</prevsent>
</prevsection>
<citsent citstr=" W06-1605 ">
mohammad and hirst (2006<papid> W06-1605 </papid>a) proposed way to determine the strength of association between sense or concept and co-occurringwordsthe distributional profile of concept (dpc)without the use of manually annotated data.</citsent>
<aftsection>
<nextsent>we implemented an unsupervised nave bayes word sense classifier using these dpcs that was best or within one percentage point of the best unsupervised systems in the multilingual chinese?
</nextsent>
<nextsent>english lexical sample task (task #5) and the english lexical sample task (task #17).we also created simple pmi-based classifier to attempt the english lexical substitution task (task #10); however, its performance was poor.
</nextsent>
<nextsent>determining the intended sense of word is potentially useful in many natural language tasks including machine translation and information retrieval.
</nextsent>
<nextsent>the best approaches for word sense disambiguation are supervised and they use words that co-occur withthe target as features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2316">
<title id=" W07-2071.xml">tor tormd distributional profiles of concepts for unsupervised word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these systems relyon sense annotated data to identify words that are indicative of the use of the target in each of its senses.however, only limited amounts of sense annotated data exist and it is expensive to create.
</prevsent>
<prevsent>in our previous work (mohammad and hirst, 2006<papid> W06-1605 </papid>a), we proposed an unsupervised approach to determine the strength of association between sense or concept and its co-occurring words the distributional profile of concept (dpc)relying simply on raw text and published thesaurus.</prevsent>
</prevsection>
<citsent citstr=" C92-2070 ">
the categories in published thesaurus were used as coarse senses or concepts (yarowsky, 1992).<papid> C92-2070 </papid></citsent>
<aftsection>
<nextsent>we now show how distributional profiles of concepts can be used to create an unsupervised nave bayes word-sense classifier.
</nextsent>
<nextsent>we also implemented simple classifier that relies on the pointwise mutual information (pmi) between the senses of the target and co-occurring words.
</nextsent>
<nextsent>these dpc-based classifiers participated inthree semeval 2007 tasks: the english lexical sample task (task #17), the english lexical substitution task (task #10), and the multilingual chinese?
</nextsent>
<nextsent>english lexical sample task (task #5).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2317">
<title id=" W07-2071.xml">tor tormd distributional profiles of concepts for unsupervised word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>english lexical sample task (task #5).
</prevsent>
<prevsent>the english lexical sample task (pradhan et al, 2007) is traditional word sense disambiguation task wherein the intended (wordnet) sense of target word is to be determined from its context.
</prevsent>
</prevsection>
<citsent citstr=" W07-2009 ">
we manually mapped the wordnet senses to the categories in thesaurus and the dpc-based nave bayes classifier was used to identify the intended sense (category) of the target words.the object of the lexical substitution task (mc carthy and navigli, 2007) <papid> W07-2009 </papid>is to replace target word in sentence with suitable substitute that preserves the meaning of the utterance.</citsent>
<aftsection>
<nextsent>the list of possible substitutes forgiven target word is usually contingent on its intended sense.
</nextsent>
<nextsent>therefore, word sense disambiguation is expected to be useful in lexicalsubstitution.
</nextsent>
<nextsent>we used the pmi-based classier to determine the intended sense.
</nextsent>
<nextsent>326 the objective of the multilingual chinese?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2318">
<title id=" W07-2071.xml">tor tormd distributional profiles of concepts for unsupervised word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we used the pmi-based classier to determine the intended sense.
</prevsent>
<prevsent>326 the objective of the multilingual chinese?
</prevsent>
</prevsection>
<citsent citstr=" W07-2004 ">
english lexical sample task (jin et al, 2007) <papid> W07-2004 </papid>is to select from given list suitable english translation of chinese target word in context.</citsent>
<aftsection>
<nextsent>mohammad et al.
</nextsent>
<nextsent>(2007) proposed way to create cross-lingual distributional profiles of concepts (cl-dpcs)?
</nextsent>
<nextsent>the strengths of association between the concepts of one language and words of another.
</nextsent>
<nextsent>for this task, we mapped the list of english translations to appropriate thesaurus categories and used an implementation of cl-dpcbased unsupervised nave bayes classifier to identify the intended senses (and thereby the english translations) of target chinese words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2324">
<title id=" W07-2071.xml">tor tormd distributional profiles of concepts for unsupervised word sense disambiguation </title>
<section> distributional profiles of concepts.  </section>
<citcontext>
<prevsection>
<prevsent>for this task, we mapped the list of english translations to appropriate thesaurus categories and used an implementation of cl-dpcbased unsupervised nave bayes classifier to identify the intended senses (and thereby the english translations) of target chinese words.
</prevsent>
<prevsent>in order to determine the strength of association between sense of the target word and its co-occurring words, we need to determine their individual and joint occurrence counts in corpus.
</prevsent>
</prevsection>
<citsent citstr=" D07-1060 ">
mohammad and hirst (2006<papid> W06-1605 </papid>a) and mohammad et al (2007) <papid> D07-1060 </papid>proposed ways to determine these counts in monolingual andcross-lingual framework without the use of sense annotated data.</citsent>
<aftsection>
<nextsent>we summarize the ideas in this sec tion; the original papers give more details.
</nextsent>
<nextsent>2.1 word category co-occurrence matrix.
</nextsent>
<nextsent>we create word category co-occurrence matrix(wccm) having english word types wen as one dimension and english thesaurus categories cen as an other.
</nextsent>
<nextsent>we used the macquarie thesaurus (bernard, 1986) both as very coarse-grained sense inventory and source of words that together represent each category (concept).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2331">
<title id=" W07-2071.xml">tor tormd distributional profiles of concepts for unsupervised word sense disambiguation </title>
<section> distributional profiles of concepts.  </section>
<citcontext>
<prevsection>
<prevsent>the sense that has the highest cumulative association is chosen as the intended sense.
</prevsent>
<prevsent>a new boot strapped wccm is created such tha teach cell mi j, corresponding to word weni and concept cenj , is populated with the number of times weni co-occurs with any word used in sense cenj . mohammad and hirst (2006<papid> W06-1605 </papid>a) used the dpcs created from the boot strapped wccm to attainnear-upper-bound results in the task of determining word sense dominance.</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
unlike the mccarthy et al (2004) <papid> P04-1036 </papid>dominance system, this approach can be applied to much smaller target texts (a few hundred sentences) without the need for large similarly-sense-distributed text1.</citsent>
<aftsection>
<nextsent>mohammad and hirst (2006<papid> W06-1605 </papid>b) used the dpc-based monolingual distributional measures of concept-distance to rank word pairs by their semantic similarity and to correct real-word spelling errors, attaining markedly better results than monolingual distributional measures of word-distance.</nextsent>
<nextsent>in the spelling correction task, the1the mccarthy et al (2004) <papid> P04-1036 </papid>system needs to first generate distributional thesaurus from the target text (if it is large enougha few million words) or from another large text with distribution of senses similar to the target text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2340">
<title id=" W07-2071.xml">tor tormd distributional profiles of concepts for unsupervised word sense disambiguation </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 english lexical sample task.
</prevsent>
<prevsent>the english lexical sample task training and test data (pradhan et al, 2007) have 22281 and 4851 instances respectively for 100 target words (50 nouns and 50 verbs).
</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
wordnet 2.1 is used as the sense inventory for most of the target words, but certain words have one or more senses from ontonotes (hovy et al, 2006).<papid> N06-2015 </papid></citsent>
<aftsection>
<nextsent>many of the fine grained senses are grouped into coarser senses.
</nextsent>
<nextsent>our approach relies on representing sense with number of near-synonymous words, for which athesaurus is natural source.
</nextsent>
<nextsent>even though the approach can be ported to wordnet4, there was no easy 4the synonyms within synset, along with its one-hop neighbors and all its hyponyms, can represent that sense.
</nextsent>
<nextsent>329 training data test data words baseline pmi-based naive bayes prior likelihood naive bayes all 27.8 41.4 50.8 37.4 49.4 52.1 nouns only 25.6 43.4 53.6 18.1 49.6 49.7 verbs only 29.2 38.4 44.5 58.9 49.1 54.7 table 1: english lexical sample task: results obtained using the pmi-based classifier on the training data and the nave bayes classifier on both training and test dataway of representing ontonotes senses with near synonymous words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2345">
<title id=" W07-1428.xml">a discourse commitment based framework for recognizing textual entailment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>once set of commitments have been extracted from t-h pair, the task of recognizing textual entailment is reduced to the identification of the commitments from t which support the inference of the h. promising results were achieved: our system correctly identified more than 80% of examples from the rte-3 test set correctly, without the need for additional sources of training data or other web-based resources.
</prevsent>
<prevsent>systems participating in the previous two pascal recognizing textual entailment (rte) challenges (bar-haim et al, 2006) have successfully employed variety of shallow?
</prevsent>
</prevsection>
<citsent citstr=" H05-1049 ">
techniques in order to recognize instances of textual entailment, including methods based on: (1) sets of heuristics (vander wende et al, 2006), (2) measures of term overlap (jijkoun and de rijke, 2005), (3) the alignment of graphs created from syntactic or semantic dependencies (haghighi et al, 2005), <papid> H05-1049 </papid>or (4) statistical classifiers which leverage wide range of features, including the output of paraphrase generation (hickl et al, 2006) or model building systems (bos and markert, 2006).</citsent>
<aftsection>
<nextsent>while relatively shallow?
</nextsent>
<nextsent>approaches have shown much promise in rte for entailment pairs where the text and hypothesis remain short, we expect that performance of these types of systems will ultimately degrade as longer and more syntactically complex entailment pairs are considered.
</nextsent>
<nextsent>in order to remain effective as texts get longer, we believe that rte systems will need to employ techniques that will enable them to enumerate the set of propositions which are infer able ? whether asserted, presupposed, or conventionally or conversation ally implicated ? from text-hypothesis pair.
</nextsent>
<nextsent>in this paper, we introduce new framework for recognizing textual entailment which depends on extraction of the set of publicly-held beliefs ? or discourse commitments ? that can be ascribed to the author of text or hypothesis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2346">
<title id=" W07-1428.xml">a discourse commitment based framework for recognizing textual entailment </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>lection, and entailment classification, respectively.
</prevsent>
<prevsent>finally, section 6 discusses results from this years evaluation, and section 7 provides our conclusions.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
the architecture of our system for recognizing textual entailment (rte) is presented in figure 1.in our system, text-hypothesis (t-h) pairs are initially submitted to preprocessing module which(1) syntactic parses each passage (using an implementation of the (collins, 1999) parser), (2) identifies semantic dependencies (using semantic dependency parser trained on propbank (palmer et al., 2005) <papid> J05-1004 </papid>and nombank (meyers et al, 2004)),(3) annotates named entities (using lccs cicero lite named entity recognition system), (4) resolves instances of pronominal and nominal coreference (using system based on (luo et al, 2004)), <papid> P04-1018 </papid>and (5) normalizes temporal and spatial expressions tofully-resolved instances (using technique first introduced in (aarseth et al, 2006)).annotated passages are then sent to commitment extraction module, which uses series of extraction heuristics in order to enumerate subset of the discourse commitments that are infer able from either the text or hypothesis.</citsent>
<aftsection>
<nextsent>following (gunlogson, 2001; stalnaker, 1979), we assume that discourse commitment (c) represents the any of the set of propositions that can necessarily be inferred to be true, given conventional reading of text passage.
</nextsent>
<nextsent>the complete list of commitments that our system is able to extract from from the used in examples 34 and 36 from the rte-3 test set is presented in figure 2.
</nextsent>
<nextsent>(details of our commitment extraction approach are presented in section 3.)commitments are then sent to commitment selection module, which uses weighted bipartite matching algorithm first described in (taskar et al, 2005<papid> H05-1010 </papid>b) in order to identify the commitment from thetwhich features the best alignment for each commitment extracted from the h. the commitment pairs identified for the hypotheses from 34 and 36 are highlighted in figure 2.</nextsent>
<nextsent>(details of our method for selecting and aligning commitments are provided in section 4.)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2347">
<title id=" W07-1428.xml">a discourse commitment based framework for recognizing textual entailment </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>lection, and entailment classification, respectively.
</prevsent>
<prevsent>finally, section 6 discusses results from this years evaluation, and section 7 provides our conclusions.
</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
the architecture of our system for recognizing textual entailment (rte) is presented in figure 1.in our system, text-hypothesis (t-h) pairs are initially submitted to preprocessing module which(1) syntactic parses each passage (using an implementation of the (collins, 1999) parser), (2) identifies semantic dependencies (using semantic dependency parser trained on propbank (palmer et al., 2005) <papid> J05-1004 </papid>and nombank (meyers et al, 2004)),(3) annotates named entities (using lccs cicero lite named entity recognition system), (4) resolves instances of pronominal and nominal coreference (using system based on (luo et al, 2004)), <papid> P04-1018 </papid>and (5) normalizes temporal and spatial expressions tofully-resolved instances (using technique first introduced in (aarseth et al, 2006)).annotated passages are then sent to commitment extraction module, which uses series of extraction heuristics in order to enumerate subset of the discourse commitments that are infer able from either the text or hypothesis.</citsent>
<aftsection>
<nextsent>following (gunlogson, 2001; stalnaker, 1979), we assume that discourse commitment (c) represents the any of the set of propositions that can necessarily be inferred to be true, given conventional reading of text passage.
</nextsent>
<nextsent>the complete list of commitments that our system is able to extract from from the used in examples 34 and 36 from the rte-3 test set is presented in figure 2.
</nextsent>
<nextsent>(details of our commitment extraction approach are presented in section 3.)commitments are then sent to commitment selection module, which uses weighted bipartite matching algorithm first described in (taskar et al, 2005<papid> H05-1010 </papid>b) in order to identify the commitment from thetwhich features the best alignment for each commitment extracted from the h. the commitment pairs identified for the hypotheses from 34 and 36 are highlighted in figure 2.</nextsent>
<nextsent>(details of our method for selecting and aligning commitments are provided in section 4.)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2348">
<title id=" W07-1428.xml">a discourse commitment based framework for recognizing textual entailment </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>following (gunlogson, 2001; stalnaker, 1979), we assume that discourse commitment (c) represents the any of the set of propositions that can necessarily be inferred to be true, given conventional reading of text passage.
</prevsent>
<prevsent>the complete list of commitments that our system is able to extract from from the used in examples 34 and 36 from the rte-3 test set is presented in figure 2.
</prevsent>
</prevsection>
<citsent citstr=" H05-1010 ">
(details of our commitment extraction approach are presented in section 3.)commitments are then sent to commitment selection module, which uses weighted bipartite matching algorithm first described in (taskar et al, 2005<papid> H05-1010 </papid>b) in order to identify the commitment from thetwhich features the best alignment for each commitment extracted from the h. the commitment pairs identified for the hypotheses from 34 and 36 are highlighted in figure 2.</citsent>
<aftsection>
<nextsent>(details of our method for selecting and aligning commitments are provided in section 4.)
</nextsent>
<nextsent>each pair of commitments are then considered in turn by an entailment classification module, which follows (bos and markert, 2006; hickl et al, 2006) in using decision tree classifier in order to compute the likelihood that commitment extracted from t textually entails commitment extracted from an h.if commitment pair is judged to be positive instance of te, it is sent to an entailment validation module, which uses system for recognizing instances of textual contradiction (rtc)based on (harabagiu et al, 2006) in order to determine whether the (presumably) entailed hypothesis is contradicted by any of other commitments extracted from the during commitment extraction.
</nextsent>
<nextsent>ifno text commitment can be identified which contradicts the hypothesis, it is presumed to be textually entailed, and judgment of yes is returned.
</nextsent>
<nextsent>alternatively, if the entailed is textually contradicted by one (or more) of the commitments extracted from the t, the is considered to be contradicted by thet, the entailment pair is classified as negative instance of te, and judgment of no is returned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2364">
<title id=" W07-1428.xml">a discourse commitment based framework for recognizing textual entailment </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>2?
</prevsent>
<prevsent>unaligned chunk: this feature represents the number of chunks in one text that are not aligned with chunk from the other 3?
</prevsent>
</prevsection>
<citsent citstr=" W05-1208 ">
lexical entailment probability: defined as in (glickman and dagan, 2005).<papid> W05-1208 </papid>dependency features: computed from the semantic dependencies identified by the propbank- and nombank-based semantic parsers.</citsent>
<aftsection>
<nextsent>1?
</nextsent>
<nextsent>entity-arg match: this is boolean feature which fires when aligned entities were assigned the same argument role label.2?
</nextsent>
<nextsent>entity-near-arg match: this feature is collapsing the arguments arg1 and arg2 (as well as the argm subtypes) into single categories for the purpose of counting matches.
</nextsent>
<nextsent>3?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2365">
<title id=" W07-2110.xml">xrcet xip temporal module for tempe val campaign </title>
<section> general presentation and system over-.  </section>
<citcontext>
<prevsection>
<prevsent>analyzer our temporal processor, called xtm, is an extension of xip (xerox incremental parser (at mokhtar et al, 2002).
</prevsent>
<prevsent>xip extracts basic grammatical relations and also thematic roles in the form of dependency links.
</prevsent>
</prevsection>
<citsent citstr=" W03-1606 ">
see (brun and hagge 2003) <papid> W03-1606 </papid>for details on deep linguistic processing using xip.</citsent>
<aftsection>
<nextsent>xip is rule-based and its architecture can roughly be divided into the three following parts: ? pre-processing stage handling tokenization, morphological analysis and pos tagging.
</nextsent>
<nextsent>a surface syntactic analysis stage consisting in chunking the input and dealing with named entity recognition (ner).
</nextsent>
<nextsent>a deep syntactic analysis 1.2 intertwining temporal processing and.
</nextsent>
<nextsent>linguistic processing the underlying idea is that temporal processing is one of the necessary steps in more general task of text understanding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2366">
<title id=" W07-2110.xml">xrcet xip temporal module for tempe val campaign </title>
<section> three levels of temporal processing.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1 illustrates this stage for simple anchor date.
</prevsent>
<prevsent>an adv (adverbial) node with associated boolean features is built from linguistic expressions such as 4 years ago?.
</prevsent>
</prevsection>
<citsent citstr=" W06-0405 ">
note that there is call to python function (roux, 2006) <papid> W06-0405 </papid>merge_anchor_and_dur?</citsent>
<aftsection>
<nextsent>whose parameters are three linguistic nodes (#0 represents the resulting left-hand expression).
</nextsent>
<nextsent>the representation of the values is close to timeml format (saur?
</nextsent>
<nextsent>et al 2006).
</nextsent>
<nextsent>2.2 sentence level.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2367">
<title id=" W07-2110.xml">xrcet xip temporal module for tempe val campaign </title>
<section> three levels of temporal processing.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 document level.
</prevsent>
<prevsent>beyond sentence-level, the system is at the first stage of development.
</prevsent>
</prevsection>
<citsent citstr=" C04-1008 ">
we are only able to complete relative dates when it refers to the document creation time, and to infer new relations with the help of composition rules, by saturating the graph of temporal relations (muller and tannier, 2004).<papid> C04-1008 </papid></citsent>
<aftsection>
<nextsent>tions the tempe val track consists of three different tasks described in (verhagen et al 2007).<papid> W07-2014 </papid></nextsent>
<nextsent>tem peval guidelines present several differences with respect to our own methodology.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2369">
<title id=" W07-2110.xml">xrcet xip temporal module for tempe val campaign </title>
<section> adapting xtm to tempe val specifica-.  </section>
<citcontext>
<prevsection>
<prevsent>beyond sentence-level, the system is at the first stage of development.
</prevsent>
<prevsent>we are only able to complete relative dates when it refers to the document creation time, and to infer new relations with the help of composition rules, by saturating the graph of temporal relations (muller and tannier, 2004).<papid> C04-1008 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-2014 ">
tions the tempe val track consists of three different tasks described in (verhagen et al 2007).<papid> W07-2014 </papid></citsent>
<aftsection>
<nextsent>tem peval guidelines present several differences with respect to our own methodology.
</nextsent>
<nextsent>these differences concern definitions of relations and events, as well as choices about linking.
</nextsent>
<nextsent>3.1 timex3 definition.
</nextsent>
<nextsent>timeml definition of temporal expression (timex3) is slightly different from what we consider to be temporal expression in xtm: ? first, we incorporate signals (in, at?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2373">
<title id=" W07-2050.xml">melbmkb lexical substitution system based on relatives in context </title>
<section> development on trial data.  </section>
<citcontext>
<prevsection>
<prevsent>basic 344/1152 (30%) 197 / 300 (66%) hype 404/1152 (35%) 229/300 (76%) hype2 419/1152 (36%) 229/300 (76%) table 1: wordnet coverage for different candidate sets, based on substitute (subs.)
</prevsent>
<prevsent>and instance (inst.)
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
coverage.in lin (1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>a different approach that we are testing for future work is to adapt the algorithm to work with wild cards instead of explicit candidates.
</nextsent>
<nextsent>due to time constraints, we only relied on wordnet for our submission.
</nextsent>
<nextsent>3.2 parameter tuning.
</nextsent>
<nextsent>in this experiment we tuned different parameters of the basic algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2374">
<title id=" W07-2014.xml">semeval2007 task 15 tempe val temporal relation identification </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>timeml (puste jovsky et al, 2003a) is an emerging iso standard for annotation of events, temporal expressions and the anchoring and ordering relations between them.
</prevsent>
<prevsent>time bank (pustejovsky et al, 2003b; boguraev et al., forthcoming) was originally conceived of as aproof of concept that illustrates the timeml language, but has since gone through several rounds of revisions and can now be considered gold standard for temporal information.
</prevsent>
</prevsection>
<citsent citstr=" P06-1095 ">
timeml and time bank have already been used as the basis for automatic time, event and temporal relation annotation tasks in number of research projects in recent years (mani et al, 2006; <papid> P06-1095 </papid>boguraev et al, forthcoming).an open evaluation challenge in the area of temporal annotation should serve to drive research forward, as it has in other areas of nlp.</citsent>
<aftsection>
<nextsent>the automatic identification of all temporal referring expressions, events and temporal relations within text is the ultimate aim of research in this area.
</nextsent>
<nextsent>however, addressing this aim in first evaluation challenge was judged to be too difficult, both for organizers and participants, and staged approach was deemed more effective.
</nextsent>
<nextsent>thus we here present an initial evaluation exercise based on three limited tasks that we believe are realistic both from the perspective of assembling resources for development and testing and from the perspective of developing systems capable of addressing the tasks.
</nextsent>
<nextsent>they are also tasks, which should they be perform able automatically, have application potential.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2375">
<title id=" W07-2201.xml">using self trained bilexical preferences to improve disambiguation accuracy </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>in contrast, the disambiguation model of the dutch parser we are reporting on in this paper is trained on manually labeled corpus of slightly over 7,000 sentences (145,000 words).
</prevsent>
<prevsent>it appears that semi-supervised or un-supervised methods are required here.note that the problem not only occurs for artificial examples such as (1); here are few mis-parsedexamples actually encountered in large parsed cor pus: (2) a. campari moet gedronken hebben campari must have drunk you you must have drunk campari b. de wijn die elvis zou hebben gedronken als hij wijn zou hebben gedronken the wine elvis would have drunk if he had drunk wine the wine that would have drunk elvis if he had drunk wine c. de paus heeft tweehonderd daklozen te eten gehad the pope had twohunderd homeless people for dinner in this paper, we describe an alternative approach in which we employ pointwise mutual information association score in the maximum entropy disambiguation model.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
pointwise mutual information(fano, 1961) was used to measure strength of selection restrictions for instance by church and hanks(1990).<papid> J90-1003 </papid></citsent>
<aftsection>
<nextsent>the association scores used here are estimated using very large parsed corpus of 500 million words (27 million sentences).
</nextsent>
<nextsent>we show that the incorporation of this additional knowledge source improves parsing accuracy.
</nextsent>
<nextsent>because the association scores are estimated on the basis of large corpus that is parsed by the parser that we aim to improve upon, this technique can be described as somewhat particular instance of self-training.
</nextsent>
<nextsent>self-training hasbeen investigated for statistical parsing before.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2376">
<title id=" W07-2201.xml">using self trained bilexical preferences to improve disambiguation accuracy </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>self-training hasbeen investigated for statistical parsing before.
</prevsent>
<prevsent>although naively adding self-labeled material to extend training data is normally not succes full, there have been successful variants of self-learning for parsing as well.
</prevsent>
</prevsection>
<citsent citstr=" N06-1020 ">
for instance, in mcclosky et al (2006) <papid> N06-1020 </papid>self-learning is used to improve two-phaseparser reranker, with very good results for the classical wall street journal parsing task.</citsent>
<aftsection>
<nextsent>clearly, the idea that selection restrictions oughtto be useful for parsing accuracy is not new.
</nextsent>
<nextsent>however, as far as we know this is the first time that automatically acquired selection restrictions have been shown to improve parsing accuracy results.
</nextsent>
<nextsent>related research includes abekawa and okumura (2006)<papid> P06-1105 </papid>and kawahara and kurohashi (2006) <papid> N06-1023 </papid>where statistical information between verbs and case element sis collected on the basis of large automatically analysed corpora.</nextsent>
<nextsent>the experiments are performed using the alpino parser for dutch.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2377">
<title id=" W07-2201.xml">using self trained bilexical preferences to improve disambiguation accuracy </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>clearly, the idea that selection restrictions oughtto be useful for parsing accuracy is not new.
</prevsent>
<prevsent>however, as far as we know this is the first time that automatically acquired selection restrictions have been shown to improve parsing accuracy results.
</prevsent>
</prevsection>
<citsent citstr=" P06-1105 ">
related research includes abekawa and okumura (2006)<papid> P06-1105 </papid>and kawahara and kurohashi (2006) <papid> N06-1023 </papid>where statistical information between verbs and case element sis collected on the basis of large automatically analysed corpora.</citsent>
<aftsection>
<nextsent>the experiments are performed using the alpino parser for dutch.
</nextsent>
<nextsent>in this section we briefly describe the parser, as well as the corpora that we have used in the experiments described later.
</nextsent>
<nextsent>2.1 grammar and lexicon.
</nextsent>
<nextsent>the alpino system is linguistically motivated, wide-coverage grammar and parser for dutch in the tradition of hpsg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2378">
<title id=" W07-2201.xml">using self trained bilexical preferences to improve disambiguation accuracy </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>clearly, the idea that selection restrictions oughtto be useful for parsing accuracy is not new.
</prevsent>
<prevsent>however, as far as we know this is the first time that automatically acquired selection restrictions have been shown to improve parsing accuracy results.
</prevsent>
</prevsection>
<citsent citstr=" N06-1023 ">
related research includes abekawa and okumura (2006)<papid> P06-1105 </papid>and kawahara and kurohashi (2006) <papid> N06-1023 </papid>where statistical information between verbs and case element sis collected on the basis of large automatically analysed corpora.</citsent>
<aftsection>
<nextsent>the experiments are performed using the alpino parser for dutch.
</nextsent>
<nextsent>in this section we briefly describe the parser, as well as the corpora that we have used in the experiments described later.
</nextsent>
<nextsent>2.1 grammar and lexicon.
</nextsent>
<nextsent>the alpino system is linguistically motivated, wide-coverage grammar and parser for dutch in the tradition of hpsg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2380">
<title id=" W07-2201.xml">using self trained bilexical preferences to improve disambiguation accuracy </title>
<section> bilexical preferences.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 using association scores as features.
</prevsent>
<prevsent>the association scores for all dependencies are used in our maximum entropy disambiguation model asfollows.
</prevsent>
</prevsection>
<citsent citstr=" A00-2021 ">
the technique is reminiscent of the inclusion of auxiliary distributions in stochastic attribute value grammar (johnson and riezler, 2000).<papid> A00-2021 </papid></citsent>
<aftsection>
<nextsent>recall that maximum entropy disambiguation model exploits features.
</nextsent>
<nextsent>features are properties of parses, and we can use such features to describe any property of parses that we believe is of importance for disambiguation.
</nextsent>
<nextsent>for the disambiguation model, parse is fully characterized by vector of feature counts.we introduce features z(t, r) for each of thema jor pos labels (verb, noun, adjective, adverb, . . .
</nextsent>
<nextsent>) and each of the dependency relations r. the count?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2381">
<title id=" W07-2205.xml">the impact of deep linguistic processing on parsing technology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these deep linguisticprocessing?
</prevsent>
<prevsent>approaches differ from shallower methods in that they yield richer, more expressive, structural representations which capture long-distance dependencies or the underlying predicate-argument structure directly.
</prevsent>
</prevsection>
<citsent citstr=" W02-1503 ">
aspects of this research have often had their own separate fora, such as the acl 2005 workshop on deep lexical acquisition (baldwin et al, 2005), as well as the tag+ (kallmeyer and becker, 2006), alpino (van der beek et al, 2005), pargram (butt et al, 2002) <papid> W02-1503 </papid>and delph-in (oepen et al, 2002) projects and meetings.</citsent>
<aftsection>
<nextsent>however, the fundamental approaches to building linguistically-founded system and many of the techniques used to engineer efficient systems are common across these project sand independent of the specific grammar formalism chosen.
</nextsent>
<nextsent>as such, we felt the need for common meeting in which experiences could be shared among wider community, similar to the role played by recent meetings on grammar engineering (wint ner, 2006; bender and king, 2007).
</nextsent>
<nextsent>deep linguistic processing has traditionally been concerned with grammar development (for use inboth parsing and generation).
</nextsent>
<nextsent>however, the linguistic precision and complexity of the grammars meant that they had to be manually developed and maintained, and were computationally expensive to run.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2382">
<title id=" W08-0405.xml">a rule driven dynamic programming decoder for statistical mt </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J04-4002 ">
the paper presents an extension of dynamic programming (dp) decoder for phrase-based smt (koehn, 2004; och and ney, 2004) <papid> J04-4002 </papid>that tightly integrates pos-based re-order rules (crego and marino, 2006) into left-to-right beam-search algorithm, rather than handling them in pre-processing or re-order graph generation step.</citsent>
<aftsection>
<nextsent>the novel decoding algorithm can handle tens of thousands of rules efficiently.
</nextsent>
<nextsent>an improvement over standardphrase-based decoder is shown on an arabic english translation task with respect to translation accuracy and speed for large re-order window sizes.
</nextsent>
<nextsent>the paper presents an extension of dynamic programming (dp) decoder for phrase-based smt(koehn, 2004; och and ney, 2004) <papid> J04-4002 </papid>where pos based re-order rules (crego and marino, 2006) are tightly integrated into left-to-right run over the input sentence.</nextsent>
<nextsent>in the literature, re-order rules are applied to the source and/or target sentence as pre-processing step (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007) where the rules can be applied on both training and test data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2386">
<title id=" W08-0405.xml">a rule driven dynamic programming decoder for statistical mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an improvement over standardphrase-based decoder is shown on an arabic english translation task with respect to translation accuracy and speed for large re-order window sizes.
</prevsent>
<prevsent>the paper presents an extension of dynamic programming (dp) decoder for phrase-based smt(koehn, 2004; och and ney, 2004) <papid> J04-4002 </papid>where pos based re-order rules (crego and marino, 2006) are tightly integrated into left-to-right run over the input sentence.</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
in the literature, re-order rules are applied to the source and/or target sentence as pre-processing step (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007) where the rules can be applied on both training and test data.</citsent>
<aftsection>
<nextsent>another way of incorporating re-order rules is via extended monotone search graphs (crego and marino, 2006) or lattices (zhang et al, 2007; <papid> W07-0401 </papid>paulik et al, 2007).<papid> W07-0727 </papid></nextsent>
<nextsent>this paper presents way of handling pos-based re-order rules as an edge generation process: the pos-based re-order rules are tightly integrated into left to right beam search decoder in way that 29 000 rules which may overlap in an arbitrary way (but not recursively) are handled efficiently.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2387">
<title id=" W08-0405.xml">a rule driven dynamic programming decoder for statistical mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an improvement over standardphrase-based decoder is shown on an arabic english translation task with respect to translation accuracy and speed for large re-order window sizes.
</prevsent>
<prevsent>the paper presents an extension of dynamic programming (dp) decoder for phrase-based smt(koehn, 2004; och and ney, 2004) <papid> J04-4002 </papid>where pos based re-order rules (crego and marino, 2006) are tightly integrated into left-to-right run over the input sentence.</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
in the literature, re-order rules are applied to the source and/or target sentence as pre-processing step (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007) where the rules can be applied on both training and test data.</citsent>
<aftsection>
<nextsent>another way of incorporating re-order rules is via extended monotone search graphs (crego and marino, 2006) or lattices (zhang et al, 2007; <papid> W07-0401 </papid>paulik et al, 2007).<papid> W07-0727 </papid></nextsent>
<nextsent>this paper presents way of handling pos-based re-order rules as an edge generation process: the pos-based re-order rules are tightly integrated into left to right beam search decoder in way that 29 000 rules which may overlap in an arbitrary way (but not recursively) are handled efficiently.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2388">
<title id=" W08-0405.xml">a rule driven dynamic programming decoder for statistical mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the paper presents an extension of dynamic programming (dp) decoder for phrase-based smt(koehn, 2004; och and ney, 2004) <papid> J04-4002 </papid>where pos based re-order rules (crego and marino, 2006) are tightly integrated into left-to-right run over the input sentence.</prevsent>
<prevsent>in the literature, re-order rules are applied to the source and/or target sentence as pre-processing step (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007) where the rules can be applied on both training and test data.</prevsent>
</prevsection>
<citsent citstr=" W07-0401 ">
another way of incorporating re-order rules is via extended monotone search graphs (crego and marino, 2006) or lattices (zhang et al, 2007; <papid> W07-0401 </papid>paulik et al, 2007).<papid> W07-0727 </papid></citsent>
<aftsection>
<nextsent>this paper presents way of handling pos-based re-order rules as an edge generation process: the pos-based re-order rules are tightly integrated into left to right beam search decoder in way that 29 000 rules which may overlap in an arbitrary way (but not recursively) are handled efficiently.
</nextsent>
<nextsent>example rules which are used to control the novel dp-based decoder are shown in table 1, where each pos sequence is associated with possibly several permutations pi.
</nextsent>
<nextsent>in order to apply the rules, the input sentences are pos-tagged.
</nextsent>
<nextsent>if pos sequence of arule matches some identical pos sequence in the in put sentence the corresponding words are re-ordered according to pi.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2389">
<title id=" W08-0405.xml">a rule driven dynamic programming decoder for statistical mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the paper presents an extension of dynamic programming (dp) decoder for phrase-based smt(koehn, 2004; och and ney, 2004) <papid> J04-4002 </papid>where pos based re-order rules (crego and marino, 2006) are tightly integrated into left-to-right run over the input sentence.</prevsent>
<prevsent>in the literature, re-order rules are applied to the source and/or target sentence as pre-processing step (xia and mccord, 2004; <papid> C04-1073 </papid>collins et al, 2005; <papid> P05-1066 </papid>wang et al, 2007) where the rules can be applied on both training and test data.</prevsent>
</prevsection>
<citsent citstr=" W07-0727 ">
another way of incorporating re-order rules is via extended monotone search graphs (crego and marino, 2006) or lattices (zhang et al, 2007; <papid> W07-0401 </papid>paulik et al, 2007).<papid> W07-0727 </papid></citsent>
<aftsection>
<nextsent>this paper presents way of handling pos-based re-order rules as an edge generation process: the pos-based re-order rules are tightly integrated into left to right beam search decoder in way that 29 000 rules which may overlap in an arbitrary way (but not recursively) are handled efficiently.
</nextsent>
<nextsent>example rules which are used to control the novel dp-based decoder are shown in table 1, where each pos sequence is associated with possibly several permutations pi.
</nextsent>
<nextsent>in order to apply the rules, the input sentences are pos-tagged.
</nextsent>
<nextsent>if pos sequence of arule matches some identical pos sequence in the in put sentence the corresponding words are re-ordered according to pi.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2391">
<title id=" W08-0405.xml">a rule driven dynamic programming decoder for statistical mt </title>
<section> baseline dp decoder.  </section>
<citcontext>
<prevsection>
<prevsent>3 000 noun case-indef-acc adj nsuff-fem-sg conj adj nsuff-fem-sg ? 2 3 4 5 6 0 1 6 . . .
</prevsent>
<prevsent>28 878 prep det noun det adj prep noun-prop adj ? 0 1 2 7 8 3 4 nsuff-masc-sg-acc-indef conj iv3ms iv ivsuff-do:3fs 9 10 11 12 5 6 2 section 5 shows experimental results.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the translation model used in this paper is phrase based model (koehn et al, 2003), <papid> N03-1017 </papid>where the translation units are so-called blocks: block is pair consisting of source phrase and target phraset which are translations of each other.</citsent>
<aftsection>
<nextsent>the expression block is used here to emphasize that pairs of phrases (especially longer phrases) tend to form closely linked units in such way that the translation process can be formalized as block segmentation process (nagata et al, 2006; <papid> P06-1090 </papid>tillmann and zhang, 2007).</nextsent>
<nextsent>here, the input sentence is segmented from left to right while simultaneously generating the target sentence, one block at time.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2392">
<title id=" W08-0405.xml">a rule driven dynamic programming decoder for statistical mt </title>
<section> baseline dp decoder.  </section>
<citcontext>
<prevsection>
<prevsent>28 878 prep det noun det adj prep noun-prop adj ? 0 1 2 7 8 3 4 nsuff-masc-sg-acc-indef conj iv3ms iv ivsuff-do:3fs 9 10 11 12 5 6 2 section 5 shows experimental results.
</prevsent>
<prevsent>the translation model used in this paper is phrase based model (koehn et al, 2003), <papid> N03-1017 </papid>where the translation units are so-called blocks: block is pair consisting of source phrase and target phraset which are translations of each other.</prevsent>
</prevsection>
<citsent citstr=" P06-1090 ">
the expression block is used here to emphasize that pairs of phrases (especially longer phrases) tend to form closely linked units in such way that the translation process can be formalized as block segmentation process (nagata et al, 2006; <papid> P06-1090 </papid>tillmann and zhang, 2007).</citsent>
<aftsection>
<nextsent>here, the input sentence is segmented from left to right while simultaneously generating the target sentence, one block at time.
</nextsent>
<nextsent>in practice, phrase-based or block-based translation models which largely monotone decoding algorithms obtain close to state-of-the-art performance by using skip and window-based restrictions to reduce the search space (berger et al, 1996).
</nextsent>
<nextsent>during decoding, we maximize the score sw(bn1 ) of phrase-pair sequence bn1 = (si, ti)n1 : sw(bn1 ) = ? i=1 wt ? f(bi, bi1), (1) where bi is block, bi1 is its predecessor block, and f(bi, bi1) is 8-dimensional feature vector where the features are derived from some probabilistic models: language model, translation model, and distortion model probabilities.
</nextsent>
<nextsent>n is the number of blocks in the translation and the weight vector is trained in way as to maximize the decoder bleu score on some training data using an on-line algorithm (tillmann and zhang, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2395">
<title id=" W08-0405.xml">a rule driven dynamic programming decoder for statistical mt </title>
<section> dp search.  </section>
<citcontext>
<prevsection>
<prevsent>viewed in this way, the handling of copies is technique of incorporating higher-level knowledge sources into simple one-step search process: either by processing acoustic models in the context of language model or by processing simple edges in the context of bigger re-ordering units, which exploit richer linguistic context.
</prevsent>
<prevsent>the earley parser in the presentation (jurafsky and martin, 2000) also uses the notion of edges which represent partial constituents derived in the parsing process.
</prevsent>
</prevsection>
<citsent citstr=" W06-3602 ">
these constituents are interpreted as edges in directed acyclic graph (dag) which represents the set of all sub parse trees considered.this paper uses the notion of edges as well following (tillmann, 2006) <papid> W06-3602 </papid>where phrase-based decoding is also linked to dag path finding problem.</citsent>
<aftsection>
<nextsent>since the re-order rules are not applied recursively, the rule-driven algorithm can be linked to an earley parser where parsing is done with linear grammar (for definition of linear grammar see (harrison, 1978)).
</nextsent>
<nextsent>a formal analysis of the rule-driven decoder might be important because of the following consideration: in phrase-based machine translation the target sentence is generated from left-to-right by con catenating target phrases linked to source phrases that cover some source positions.
</nextsent>
<nextsent>here, coverage vector is typically used to ensure that each source position is covered limited number of times (typi cally once).
</nextsent>
<nextsent>including coverage vector into the search state definition results in an inherently exponential complexity: for an input sentence of length there are 2j coverage vectors (koehn, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2396">
<title id=" W08-0405.xml">a rule driven dynamic programming decoder for statistical mt </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>an on-line algorithm similar to (tillmann and zhang, 2008) is used totrain the weight vector w. the decoder uses 5 gram language model , and the phrase table consists of about 3.2 million phrase pairs.
</prevsent>
<prevsent>the phrase table as well as the probabilistic features are trained on much larger training data consisting of 3.8 million sentences.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
translation results are given in terms of the automatic bleu evaluation metric (papineni et al., 2002) <papid> P02-1040 </papid>as well as the ter metric (snover et al, 2006).</citsent>
<aftsection>
<nextsent>our baseline decoder is similar to (koehn, 2004; moore and quirk, 2007).
</nextsent>
<nextsent>the goal of the current paper is not to demonstrate an improvement in decoding speed but show the validity of the rule edge generation algorithm.
</nextsent>
<nextsent>while the baseline and the rule-driven decoder are compared with respect to speed, they are both run with conservatively large beam thresholds, e.g. beam limit of 500 hypotheses and beam threshold of 7.5 (logarithmic scale) per source position j. the baseline decoder and the rule decoder use only 2 stacks to carry out the search(rather than stack for each source position) (till mann, 2006).<papid> W06-3602 </papid></nextsent>
<nextsent>no rest-cost estimation is employed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2399">
<title id=" W08-0402.xml">a scalable decoder for parsing based machine translation with equivalent language model state maintenance </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>large-scale parsing-based statistical machine translation (mt) has made remarkable progress in the last few years.
</prevsent>
<prevsent>the systems being developed diff erin whether they use source- or target-language syntax.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
for instance, the hierarchical translation system of chiang (2007) extracts synchronous grammar from pairs of strings, quirk et al (2005), <papid> P05-1034 </papid>liu etal.</citsent>
<aftsection>
<nextsent>(2006) and huang et al (2006) perform syntactic analyses in the source-language, and galley et al (2006) <papid> P06-1121 </papid>use target-language syntax.a critical component in parsing-based mt systems is the decoder, which is complex to implement and scale up.</nextsent>
<nextsent>most of the systems described above employ tailor-made, dedicated decoders that are not open-source, which results in high barrier to entry for other researchers in the field.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2400">
<title id=" W08-0402.xml">a scalable decoder for parsing based machine translation with equivalent language model state maintenance </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the systems being developed diff erin whether they use source- or target-language syntax.
</prevsent>
<prevsent>for instance, the hierarchical translation system of chiang (2007) extracts synchronous grammar from pairs of strings, quirk et al (2005), <papid> P05-1034 </papid>liu etal.</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
(2006) and huang et al (2006) perform syntactic analyses in the source-language, and galley et al (2006) <papid> P06-1121 </papid>use target-language syntax.a critical component in parsing-based mt systems is the decoder, which is complex to implement and scale up.</citsent>
<aftsection>
<nextsent>most of the systems described above employ tailor-made, dedicated decoders that are not open-source, which results in high barrier to entry for other researchers in the field.
</nextsent>
<nextsent>how ever, with the algorithms proposed in (huang and chiang, 2005; <papid> W05-1506 </papid>chiang, 2007; huang and chiang,2007), <papid> P07-1019 </papid>it is possible to develop general-purpose decoder that can be used by all the parsing-based systems.</nextsent>
<nextsent>in this paper, we describe an important first step towards an extensible, general-purpose, scalable, and open-source parsing-based mt decoder.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2401">
<title id=" W08-0402.xml">a scalable decoder for parsing based machine translation with equivalent language model state maintenance </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2006) and huang et al (2006) perform syntactic analyses in the source-language, and galley et al (2006) <papid> P06-1121 </papid>use target-language syntax.a critical component in parsing-based mt systems is the decoder, which is complex to implement and scale up.</prevsent>
<prevsent>most of the systems described above employ tailor-made, dedicated decoders that are not open-source, which results in high barrier to entry for other researchers in the field.</prevsent>
</prevsection>
<citsent citstr=" W05-1506 ">
how ever, with the algorithms proposed in (huang and chiang, 2005; <papid> W05-1506 </papid>chiang, 2007; huang and chiang,2007), <papid> P07-1019 </papid>it is possible to develop general-purpose decoder that can be used by all the parsing-based systems.</citsent>
<aftsection>
<nextsent>in this paper, we describe an important first step towards an extensible, general-purpose, scalable, and open-source parsing-based mt decoder.
</nextsent>
<nextsent>our decoder is written in java and implements all the essential algorithms described in chiang (2007): chart-parsing, m-gram language model integration,beam- and cube-pruning, and unique k-best extraction.
</nextsent>
<nextsent>additionally, parallel and distributed computing techniques are exploited to make it scalable.straightforward integration of an m-gram language model (lm) into parsing-based decoder substantially increases its computational complexity.
</nextsent>
<nextsent>therefore, it is important to develop efficient methods for lm integration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2402">
<title id=" W08-0402.xml">a scalable decoder for parsing based machine translation with equivalent language model state maintenance </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2006) and huang et al (2006) perform syntactic analyses in the source-language, and galley et al (2006) <papid> P06-1121 </papid>use target-language syntax.a critical component in parsing-based mt systems is the decoder, which is complex to implement and scale up.</prevsent>
<prevsent>most of the systems described above employ tailor-made, dedicated decoders that are not open-source, which results in high barrier to entry for other researchers in the field.</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
how ever, with the algorithms proposed in (huang and chiang, 2005; <papid> W05-1506 </papid>chiang, 2007; huang and chiang,2007), <papid> P07-1019 </papid>it is possible to develop general-purpose decoder that can be used by all the parsing-based systems.</citsent>
<aftsection>
<nextsent>in this paper, we describe an important first step towards an extensible, general-purpose, scalable, and open-source parsing-based mt decoder.
</nextsent>
<nextsent>our decoder is written in java and implements all the essential algorithms described in chiang (2007): chart-parsing, m-gram language model integration,beam- and cube-pruning, and unique k-best extraction.
</nextsent>
<nextsent>additionally, parallel and distributed computing techniques are exploited to make it scalable.straightforward integration of an m-gram language model (lm) into parsing-based decoder substantially increases its computational complexity.
</nextsent>
<nextsent>therefore, it is important to develop efficient methods for lm integration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2403">
<title id=" W08-0402.xml">a scalable decoder for parsing based machine translation with equivalent language model state maintenance </title>
<section> parsing-based mt decoder.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 grammar formalism.
</prevsent>
<prevsent>our decoder assumes probabilistic synchronouscontext-free grammar (scfg).
</prevsent>
</prevsection>
<citsent citstr=" N07-1063 ">
following the notation in venugopal et al (2007), <papid> N07-1063 </papid>probabilistic scfgcomprises set of source-language terminal symbols ts , set of target-language terminal symbols tt , shared set of nonterminal symbols , and set of rules of the form ? ??, ?,?, w?</citsent>
<aftsection>
<nextsent>, (1) where ? , ? ?
</nextsent>
<nextsent>[nts ]?
</nextsent>
<nextsent>is (mixed) sequence of nonterminals and source terminals, ? ?
</nextsent>
<nextsent>[ntt ]?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2404">
<title id=" W08-0402.xml">a scalable decoder for parsing based machine translation with equivalent language model state maintenance </title>
<section> parsing-based mt decoder.  </section>
<citcontext>
<prevsection>
<prevsent>at each step, an aligned pair of nonterminals is rewritten as the two corresponding components of single rule.
</prevsent>
<prevsent>in this sense, the derivations are generated synchronously.
</prevsent>
</prevsection>
<citsent citstr=" P03-2041 ">
our decoder presently handles scfgs of the kind extracted by heiro (chiang, 2007), but is easily ex ten sible to more general scfgs and closely related formalisms such as synchronous tree substitution grammars (eisner, 2003; <papid> P03-2041 </papid>chiang, 2006).</citsent>
<aftsection>
<nextsent>2.2 mt decoding as chart parsing.
</nextsent>
<nextsent>given source-language sentence f?, the decoder must find the target-language yield e(d) of the best derivation among all derivations with source language yield f(d) = f?, i.e. e?
</nextsent>
<nextsent>= ( arg max : f(d)=f? w(d) ) , (2) where w(d) is the composite weight of d. the parser may be treated as deductive proof system (shieber et al, 1995).
</nextsent>
<nextsent>formally (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2409">
<title id=" W08-0402.xml">a scalable decoder for parsing based machine translation with equivalent language model state maintenance </title>
<section> parallel and distributed computing.  </section>
<citcontext>
<prevsection>
<prevsent>it is not possible in some cases to load very large lm into memory on single machine, particularly if the scfg is also very large.
</prevsent>
<prevsent>in other cases, loading the lm each time the decoder runs may be tootime-consuming relative to the time required for decoding itself, such as in iterative decoding with updated combination weights during minimum error rate training.
</prevsent>
</prevsection>
<citsent citstr=" W06-1626 ">
it is therefore desirable to have dedicated servers to load parts of the lm3 ? an idea that has been exploited by (zhang et al, 2006; <papid> W06-1626 </papid>emami et al., 2007; brants et al, 2007).<papid> D07-1090 </papid></citsent>
<aftsection>
<nextsent>our implementation can load (partitioned) lm on different servers before initiating decoding.
</nextsent>
<nextsent>the decoder remotely calls the servers to obtain individual lm probabilities, and linearly interpol ates them on the fly using given set of interpolation weights.
</nextsent>
<nextsent>with this architecture, one can deal with very large target-language text corpus by splitting it into many parts and training separate lms from each.
</nextsent>
<nextsent>the run time interpolation capability may also be used for lm adaptation, e.g. for building document-specific language models.to mitigate potential network communication delays inherent to distributed lm, we implement simple cache mechanism in the decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2410">
<title id=" W08-0402.xml">a scalable decoder for parsing based machine translation with equivalent language model state maintenance </title>
<section> parallel and distributed computing.  </section>
<citcontext>
<prevsection>
<prevsent>it is not possible in some cases to load very large lm into memory on single machine, particularly if the scfg is also very large.
</prevsent>
<prevsent>in other cases, loading the lm each time the decoder runs may be tootime-consuming relative to the time required for decoding itself, such as in iterative decoding with updated combination weights during minimum error rate training.
</prevsent>
</prevsection>
<citsent citstr=" D07-1090 ">
it is therefore desirable to have dedicated servers to load parts of the lm3 ? an idea that has been exploited by (zhang et al, 2006; <papid> W06-1626 </papid>emami et al., 2007; brants et al, 2007).<papid> D07-1090 </papid></citsent>
<aftsection>
<nextsent>our implementation can load (partitioned) lm on different servers before initiating decoding.
</nextsent>
<nextsent>the decoder remotely calls the servers to obtain individual lm probabilities, and linearly interpol ates them on the fly using given set of interpolation weights.
</nextsent>
<nextsent>with this architecture, one can deal with very large target-language text corpus by splitting it into many parts and training separate lms from each.
</nextsent>
<nextsent>the run time interpolation capability may also be used for lm adaptation, e.g. for building document-specific language models.to mitigate potential network communication delays inherent to distributed lm, we implement simple cache mechanism in the decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2411">
<title id=" W08-0402.xml">a scalable decoder for parsing based machine translation with equivalent language model state maintenance </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the parallel data we select contains about 570k chinese-english sentence pairs, adding 15 up to about 19m words on each side.
</prevsent>
<prevsent>to train the english language models, we use the english sideof the parallel text and subset of the english gigaword corpus, for total of about 130m words.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we use the giza toolkit (och and ney, 2000), <papid> P00-1056 </papid>suffix-array architecture (lopez, 2007), <papid> D07-1104 </papid>thesrilm toolkit (stolcke, 2002), and minimum error rate training (och et al, 2003) to obtain word alignments, translation model, language models,and the optimal weights for combining these models, respectively.</citsent>
<aftsection>
<nextsent>5.2 improvements in decoding speed.
</nextsent>
<nextsent>we use python implementation of state-ofthe-art decoder as our baseline4 for decoder comparisons.
</nextsent>
<nextsent>for direct comparison, we use exactly the same models and pruning parameters.
</nextsent>
<nextsent>the scfg contains about 3m rules, the 5-gram lm explicitly lists about 49m k-grams, = 1, 2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2412">
<title id=" W08-0402.xml">a scalable decoder for parsing based machine translation with equivalent language model state maintenance </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the parallel data we select contains about 570k chinese-english sentence pairs, adding 15 up to about 19m words on each side.
</prevsent>
<prevsent>to train the english language models, we use the english sideof the parallel text and subset of the english gigaword corpus, for total of about 130m words.
</prevsent>
</prevsection>
<citsent citstr=" D07-1104 ">
we use the giza toolkit (och and ney, 2000), <papid> P00-1056 </papid>suffix-array architecture (lopez, 2007), <papid> D07-1104 </papid>thesrilm toolkit (stolcke, 2002), and minimum error rate training (och et al, 2003) to obtain word alignments, translation model, language models,and the optimal weights for combining these models, respectively.</citsent>
<aftsection>
<nextsent>5.2 improvements in decoding speed.
</nextsent>
<nextsent>we use python implementation of state-ofthe-art decoder as our baseline4 for decoder comparisons.
</nextsent>
<nextsent>for direct comparison, we use exactly the same models and pruning parameters.
</nextsent>
<nextsent>the scfg contains about 3m rules, the 5-gram lm explicitly lists about 49m k-grams, = 1, 2, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2413">
<title id=" W08-0402.xml">a scalable decoder for parsing based machine translation with equivalent language model state maintenance </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>, 5, and the pruning uses ? = 10, = 30 and ? = 0.1.
</prevsent>
<prevsent>decoder speed bleu-4(sec/sent) mt 03 mt 05 python 26.5 34.4% 32.7% java 1.2 34.5% 32.9%java (parallel) 0.7 table 1: decoder comparison: translation speed and quality on the 2003 and 2005 nist mt benchmark tests.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
as shown in table 1, the java decoder (without explicit parallelization) is 22 times faster than the python decoder, while achieving slightly better translation quality as measured by bleu-4 (pap ineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>the parallel ization further speed sit up by factor of 1.7, making the parallel java decoder is 38 times faster than the python decoder.
</nextsent>
<nextsent>we have used the decoder to successfully decode about one million sentences for large-scale discriminative training experiment.
</nextsent>
<nextsent>5.3 impact of distributed language model.
</nextsent>
<nextsent>we use the srilm toolkit to build eight 7-gram language models, and load and call the lms using 4we are extremely thankful to philip resnik at university of maryland for allowing us the use of their python decoder as the baseline.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2414">
<title id=" W07-0801.xml">elixirfm  implementation of functional arabic morphology </title>
<section> overview </section>
<citcontext>
<prevsection>
<prevsent>one can observe several different streams both in the computational and the purely linguistic modeling ofmorphology.
</prevsent>
<prevsent>some are motivated by the need to analyze word forms as to their compositional structure, others consider word inflection as being driven bythe underlying system of the language and the formal requirements of its grammar.
</prevsent>
</prevsection>
<citsent citstr=" W05-0703 ">
in section 2, before we focus on the principles of elixirfm, we briefly follow the characterization of morphological theories presented by stump (2001)and extend the classification to the most prominent computational models of arabic morphology (beesley, 2001; buckwalter, 2002; habash et al, 2005; <papid> W05-0703 </papid>el dada and ranta, 2006).</citsent>
<aftsection>
<nextsent>in section 3, we survey some of the categories of the syntax morphology interface in modern written arabic, as described by the functional arabic morphology.
</nextsent>
<nextsent>in passing, we will introduce the basic concepts of programming in haskell, modern purely functional language that is an excellent choice for declarative generative modeling of morphologies, as forsberg and ranta (2004) have shown.
</nextsent>
<nextsent>section 4 will be devoted to describing the lexicon of elixirfm.
</nextsent>
<nextsent>we will develop so-called domain specific language embedded in haskell with whichwe will achieve lexical definitions that are simultaneously source code that can be checked for consistency, data structure ready for rather independent processing, and still an easy-to-read-and-edit document resembling the printed dictionaries.in section 5, we will illustrate how rules of inflection and derivation interact with the parameters of the grammar and the lexical information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2417">
<title id=" W07-2053.xml">nusmlimproving word sense disambiguation using topic features </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>note that we do not distinguish the two all-words tasks as the same parameters will be applied.for lexical sample task, we use 5-fold cross validation on the training data provided to determine our parameters.
</prevsent>
<prevsent>for all-words task, we use semcor as our training data and validate on senseval-2 and senseval-3 all-words test data.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
we use mxpost tagger (adwait, 1996) for pos tagging, charniak parser (charniak, 2000) <papid> A00-2018 </papid>forex tracting syntactic relations, and david bleis version of lda1 for lda training and inference.</citsent>
<aftsection>
<nextsent>all default parameters are used unless mentioned otherwise.
</nextsent>
<nextsent>for the all-word tasks, we use sense 1 as back-off for words that have not appeared in semcor.
</nextsent>
<nextsent>we use the same fine-grained system for both the coarse and fine-grained all-words tasks.
</nextsent>
<nextsent>we make predictions 1http://www.cs.princeton.edu/blei/lda-c/ 251 for all words for all the systems - precision, recall and accuracy scores are all the same.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2418">
<title id=" W07-1804.xml">grammar based context specific statistical language modelling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with dialogue move specific slms we would be able toget further improvement if we had an optimal way of predicting the correct language model.
</prevsent>
<prevsent>speech recognition (asr) for dialogue systems is often caught in the trap of the sparse data problem which excludes the possibility of using statistical language models (slms).
</prevsent>
</prevsection>
<citsent citstr=" C00-2097 ">
a common approach is to write grammar for the domain either as speech recognition grammar (srg) or as an interpretation grammar which can be compiled into speech recognition grammar (srg) using some grammar development platform such as gemini, regulus or gf (rayner et al, 2000; <papid> C00-2097 </papid>rayner et al, 2006; ranta,2004).</citsent>
<aftsection>
<nextsent>the last option will assure that the linguistic coverage of the asr and interpretation are kept in sync.
</nextsent>
<nextsent>asr for commercial dialogue systems has mainly focused on grammar-based approaches despite the fact that slms seem to have better over all performance (knight et al, 2001; bangalore and johnston, 2003).
</nextsent>
<nextsent>this probably depends on the time consuming work of collecting corpora for trainings lms compared with the more rapid and straight forward development of srgs.
</nextsent>
<nextsent>however, slms aremore robust for out-of-coverage input, perform better in difficult conditions and seem to work better for naive users as shown in (knight et al, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2419">
<title id=" W07-1804.xml">grammar based context specific statistical language modelling </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, slms aremore robust for out-of-coverage input, perform better in difficult conditions and seem to work better for naive users as shown in (knight et al, 2001).
</prevsent>
<prevsent>srgs on the other hand are limited in their coverage depending on how well grammar writers succeed in predicting what users may say.
</prevsent>
</prevsection>
<citsent citstr=" E06-1008 ">
an approach taken in both dialogue systems and dictation applications is to write grammar for the particular domain and generate an artificial corpus from the grammar to be used as training corpus forslms (galescu et al, 1998; bangalore and johnston, 2003; jonson, 2006).<papid> E06-1008 </papid></citsent>
<aftsection>
<nextsent>these grammar-based models are not as accurate as the ones built from real data as the estimates are artificial, lacking realistic distribution.
</nextsent>
<nextsent>however, as has been shown in (bangalore and johnston, 2003; jonson, 2006) <papid> E06-1008 </papid>these grammar-based statistical models seem to have amuch more robust behaviour than their corresponding grammars which leaves us with much better starting point in the first development stage in dialogue system.</nextsent>
<nextsent>it is way of compromising between the ease of grammar writing and the robust 25 ness of slms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2448">
<title id=" W07-2079.xml">uc3m13 disambiguation of person names based on the composition of simple bags of typed terms </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in our approach web documents are represented as different sets of features or terms of different types (bag of words, urls, names and numbers).
</prevsent>
<prevsent>we apply ag glomerative vector space clustering that uses the similarity between pairs of analogous feature sets.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
this system achieved value of 66% for f?=0.2 and value of 48% for f?=0.5 in the web people search task at semeval-2007 (artiles et al, 2007).<papid> W07-2012 </papid></citsent>
<aftsection>
<nextsent>name queries account for substantial part of web queries in commercial search engines.
</nextsent>
<nextsent>name queries often aim at retrieving information about particular persons.
</nextsent>
<nextsent>nevertheless, the same query or mention name usually recalls several people and the user is unaware of the potential ambiguity and expects to find the related person after skimming some results.
</nextsent>
<nextsent>similar problems are also common for products, organizations and almost any other named object in real world.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2449">
<title id=" W07-2079.xml">uc3m13 disambiguation of person names based on the composition of simple bags of typed terms </title>
<section> background and related research.  </section>
<citcontext>
<prevsection>
<prevsent>in this work we focus on the task of disambiguating web pages retrieved for person name query as proposed in the web people search task at seme val-2007.
</prevsent>
<prevsent>in recent work in named entity disambiguation, malin (2005) identifies two different dimensions to classify approaches to the task depending on the information type that is used and whether the method to train the system is supervised or unsupervised.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
regarding the information type, malin (2006) identifies personal information like biographical facts (bagga and baldwin, 1998; <papid> P98-1012 </papid>mann and yarowsky, 2003) <papid> W03-0405 </papid>or relational information (bekkerman and mccallum, 05), collocations with other entities.</citsent>
<aftsection>
<nextsent>personal name disambiguation has been studied in relation with citation analysis and record linkage and their use to improve web search results have attracted more interest recently (guha and garg 2004; bollegala, 2006), but it is evaluated only at small scale.
</nextsent>
<nextsent>in contrast bekkerman and mccallum (2005) have focused on disambiguating complete social networks and not only results for one name.
</nextsent>
<nextsent>web people search proposes task to find different people sharing the same name referred in set of web pages and associate each of these pages to these people.
</nextsent>
<nextsent>to solve the task we added two simplifying assumptions; each document refers only to one person, and every listed document refers to person.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2450">
<title id=" W07-2079.xml">uc3m13 disambiguation of person names based on the composition of simple bags of typed terms </title>
<section> background and related research.  </section>
<citcontext>
<prevsection>
<prevsent>in this work we focus on the task of disambiguating web pages retrieved for person name query as proposed in the web people search task at seme val-2007.
</prevsent>
<prevsent>in recent work in named entity disambiguation, malin (2005) identifies two different dimensions to classify approaches to the task depending on the information type that is used and whether the method to train the system is supervised or unsupervised.
</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
regarding the information type, malin (2006) identifies personal information like biographical facts (bagga and baldwin, 1998; <papid> P98-1012 </papid>mann and yarowsky, 2003) <papid> W03-0405 </papid>or relational information (bekkerman and mccallum, 05), collocations with other entities.</citsent>
<aftsection>
<nextsent>personal name disambiguation has been studied in relation with citation analysis and record linkage and their use to improve web search results have attracted more interest recently (guha and garg 2004; bollegala, 2006), but it is evaluated only at small scale.
</nextsent>
<nextsent>in contrast bekkerman and mccallum (2005) have focused on disambiguating complete social networks and not only results for one name.
</nextsent>
<nextsent>web people search proposes task to find different people sharing the same name referred in set of web pages and associate each of these pages to these people.
</nextsent>
<nextsent>to solve the task we added two simplifying assumptions; each document refers only to one person, and every listed document refers to person.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2451">
<title id=" W08-0128.xml">a framework for model based evaluation of spoken dialog systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with the help of such models predicting the outcome of user tests, the need for subjective testing can be reduced, restricting it to that subset of the possible systems which have already been vetted in an automatic or semi-automatic way.
</prevsent>
<prevsent>several approaches have already been presented for semi-automatic evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P97-1035 ">
for example, the paradise framework (walker et al, 1997) <papid> P97-1035 </papid>predicts the effects of system changes, quantified in terms of interaction parameters, on an average user judgment.</citsent>
<aftsection>
<nextsent>others (araki and doshita, 1997; lopez-cozar et al., 2003; moller et al, 2006) have developed dialog simulations to aid system optimization.
</nextsent>
<nextsent>however the big picture has been missing: there has been no clear view of how these methods relate to each other, and how they might be improved and joined to support efficient early evaluation.the remainder of this paper is organized as follows.
</nextsent>
<nextsent>section 2 gives brief review of different evaluation purposes and terminology, and outlines anew tripartite decomposition of the evaluation problem.
</nextsent>
<nextsent>one part of our framework models the behavior of user and system during the interaction, and describes the impact of system changes on the interaction flow.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2452">
<title id=" W08-0128.xml">a framework for model based evaluation of spoken dialog systems </title>
<section> performance, quality, usability and.  </section>
<citcontext>
<prevsection>
<prevsent>this may have consequences for the acceptability or the system or service, that is, how readily customer will use the system or service.
</prevsent>
<prevsent>this can be quantified, for example as the ratio of the potential user population to the size of the target group.it is the task of any evaluation to quantify aspects of system performance, quality, usability oracceptability.
</prevsent>
</prevsection>
<citsent citstr=" W07-0306 ">
the exact target depends on the purpose of the evaluation (paek, 2007).<papid> W07-0306 </papid></citsent>
<aftsection>
<nextsent>for example, the system developer might be most interested in quantifying the performance of the system and its components; s/he might further need to know how the performance affects the quality perceived by the user.
</nextsent>
<nextsent>in contrast, the service operator might instead be most interested in the acceptability of the service.
</nextsent>
<nextsent>s/he might further want to know about the satisfaction of the user, influenced by the usability of the system, and also by other (e.g. hedonic) aspects like comfort, joy-of-use, fashion, etc. different evaluation approaches may be complementary, in the sense that metrics determined for one purpose may be helpful for other purposes as well.
</nextsent>
<nextsent>thus, it is useful to describe the components of different evaluation approaches in single framework.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2454">
<title id=" W07-1315.xml">paramor minimally supervised induction of paradigm structure and morphological analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this section we highlight previously proposed minimally supervised approaches to the induction of morphology that, like paramor, draw on the unique structure of natural language morphology.
</prevsent>
<prevsent>one facet of nl morphological structure commonly leveraged by morphology induction algorithms is that morphemes are recurrent building blocks of words.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
brent et al (1995), goldsmith (2001), <papid> J01-2001 </papid>and creutz (2006) emphasize the building block nature of morphemes when they each use recurring word segments to efficiently encode corpus.</citsent>
<aftsection>
<nextsent>these approaches then hypothesize that those recurring segments which most efficiently encode corpus are likely morphemes.
</nextsent>
<nextsent>another technique that exploits morphemes as repeating sub-word segments encodes the lexemes of corpus as character tree, i.e. trie, (harris, 1955; hafer and weis, 1974), or as finite state automaton (fsa) over characters (johnson, h. and martin, 2003; altun and m. johnson, 2001).
</nextsent>
<nextsent>a trie or fsa conflates multiple instances of morpheme into single sequence of states.
</nextsent>
<nextsent>because the choice of possible succeeding characters is highly constrained within morpheme, branch points in the trie or fsa are likely morpheme boundaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2455">
<title id=" W07-1315.xml">paramor minimally supervised induction of paradigm structure and morphological analysis </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a trie or fsa conflates multiple instances of morpheme into single sequence of states.
</prevsent>
<prevsent>because the choice of possible succeeding characters is highly constrained within morpheme, branch points in the trie or fsa are likely morpheme boundaries.
</prevsent>
</prevsection>
<citsent citstr=" N01-1024 ">
often trie similarities are used as first step followed by further processing to identify morphemes (schone and jurafsky, 2001).<papid> N01-1024 </papid></citsent>
<aftsection>
<nextsent>the paradigm structure of nl morphology has also been previously leveraged.
</nextsent>
<nextsent>goldsmith (2001) <papid> J01-2001 </papid>uses morphemes to efficiently encode corpus, but he first groups morphemes into paradigm like structures he calls signatures.</nextsent>
<nextsent>to date, the work that draws the most on paradigm structure is snover (2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2457">
<title id=" W07-2015.xml">semeval2007 task 16 evaluation of wide coverage knowledge resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>itseems that applications will not scale up to working in open domains without more detailed and richgeneral-purpose (and also domain-specific) semantic knowledge built by automatic means.
</prevsent>
<prevsent>fortunately, during the last years, the research community has devised large set of innovative methods and tools for large-scale automatic acquisition of lexical knowledge from structured and unstructured corpora.
</prevsent>
</prevsection>
<citsent citstr=" W01-0703 ">
among others we can mention extended wordnet (mihalcea and moldovan,2001), large collections of semantic preferences acquired from semcor (agirre and martinez, 2001; <papid> W01-0703 </papid>agirre and martinez, 2002) or acquired from british national corpus (bnc) (mccarthy, 2001), large scale topic signatures for each synset acquired from the web (agirre and de lacalle, 2004) or acquired from the bnc (cuadros et al, 2005).</citsent>
<aftsection>
<nextsent>obviously, these semantic resources have been acquired using avery different set of methods, tools and corpora, resulting on different set of new semantic relations between synsets (or between synsets and words).
</nextsent>
<nextsent>many international research groups are working on knowledge-based wsd using wide range of approaches (mihalcea, 2006).
</nextsent>
<nextsent>however, less attention has been devoted on analysing the quality of each semantic resource.
</nextsent>
<nextsent>in fact, each resource presents different volume and accuracy figures (cuadros et al., 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2459">
<title id=" W07-2015.xml">semeval2007 task 16 evaluation of wide coverage knowledge resources </title>
<section> large scale knowledge resources.  </section>
<citcontext>
<prevsection>
<prevsent>table 4 shows the number of semantic relations between synset pairs in the mcr.
</prevsent>
<prevsent>3.1 topic signatures.
</prevsent>
</prevsection>
<citsent citstr=" C00-1072 ">
topic signatures (ts) are word vectors related to aparticular topic (lin and hovy, 2000).<papid> C00-1072 </papid></citsent>
<aftsection>
<nextsent>topic signatures are built by retrieving context words of target topic from large corpora.
</nextsent>
<nextsent>in our case, we consider word senses as topics.
</nextsent>
<nextsent>for this study, we use two different large-scale topic signatures.
</nextsent>
<nextsent>the first constitutes one of the largest available semantic resource with around 100million relations (between synsets and words) acquired from the web (agirre and de lacalle, 2004).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2460">
<title id=" W07-2015.xml">semeval2007 task 16 evaluation of wide coverage knowledge resources </title>
<section> large scale knowledge resources.  </section>
<citcontext>
<prevsection>
<prevsent>the first constitutes one of the largest available semantic resource with around 100million relations (between synsets and words) acquired from the web (agirre and de lacalle, 2004).
</prevsent>
<prevsent>the second has been derived directly from semcor.
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
tsweb2: inspired by the work of (leacock et al., 1998), <papid> J98-1006 </papid>these topic signatures were constructed using monosemous relatives from wordnet (syn onyms, hypernyms, direct and indirect hyponyms, and siblings), querying google and retrieving up to one thousand snippets per query (that is, wordsense), extracting the words with distinctive frequency using tfidf.</citsent>
<aftsection>
<nextsent>for these experiments, we used at maximum the first 700 words of each ts.tssem: these topic signatures have been constructed using the part of semcor having all words tagged by pos, lemmatized and sense tagged according to wn1.6 totalizing 192,639 words.
</nextsent>
<nextsent>for each word-sense appearing in semcor, we gather all sentences for that word sense, building ts using tfidf for all word-senses co-occurring in those sentences.
</nextsent>
<nextsent>2http://ixa.si.ehu.es/ixa/resources/ sense corpus political party#n#1 2.3219 party#n#1 2.3219 election#n#1 1.0926 nominee#n#1 0.4780 candidate#n#1 0.4780 campaigner#n#1 0.4780 regime#n#1 0.3414 identification#n#1 0.3414 government#n#1 0.3414 designation#n#3 0.3414 authorities#n#1 0.3414 table 5: topic signatures for party#n#1 obtained from semcor (11 out of 719 total word senses) .in table 5, there is an example of the first word senses we calculate from party#n#1.
</nextsent>
<nextsent>the total number of relations between wn synsets acquired from semcor is 932,008.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2461">
<title id=" W07-2015.xml">semeval2007 task 16 evaluation of wide coverage knowledge resources </title>
<section> combination of knowledge resources.  </section>
<citcontext>
<prevsection>
<prevsent>in order to evaluate deeply the contribution of each knowledge resource, we also provide some results of the combined outcomes of several resources.
</prevsent>
<prevsent>the3the average size is different with respect senseval-3 be cause the words selected for this task are different kb r f1 av.
</prevsent>
</prevsection>
<citsent citstr=" P06-1013 ">
size (wn+xwn)2 54.9 51.1 52.9 5,153 tsweb 54.8 47.8 51.0 700 xwn 50.1 39.8 44.4 96 wn+xwn 45.4 36.8 40.7 101 mcr 40.2 35.5 37.7 149 tssem 35.1 32.7 33.9 428 mcr2 32.4 29.5 30.9 24,896 wn3 29.3 26.3 27.7 584 wn2 25.9 27.4 26.6 72 spsemcor 31.4 23.0 26.5 51.0 wn4 26.1 23.9 24.9 2,710 wn 36.8 16.1 22.4 13 spbnc 24.4 18.1 20.8 290 table 7: p, and f1 fine-grained results for the resources evaluated individually at semeval-2007, english lexical sample task . kb rank mcr+(wn+xwn)2+tsweb+tssem 55.5table 8: f1 fine-grained results for the 4 system combinations on senseval-3 combinations are performed following very basic strategy (brody et al, 2006).<papid> P06-1013 </papid>rank-based combination (rank): each semantic resource provides ranking of senses of theword to be disambiguated.</citsent>
<aftsection>
<nextsent>for each sense, its placements according to each of the methods are summed and the sense with the lowest total placement (clos est to first place) is selected.table 8 presents the f1 measure result with respect this method when combining four different semantic resources on the senseval-3 test set.
</nextsent>
<nextsent>regarding the basic baselines, this combination outperforms the most frequent sense of semcor (semcor-mfs with f1 of 49.1), wn (wn-mfs with f1 of 53.0) and, the training data (train-mfs with f1 of 54.5).table 9 presents the f1 measure result with respect the rank mthod when combining the same four different semantic resources on the semeval-2007 test set.
</nextsent>
<nextsent>kb rank mcr+(wn+xwn)2+tsweb+tssem 38.9table 9: f1 fine-grained results for the 4 system combinations on semeval-2007 85 in this case, the combination of the four resources obtains much lower result.
</nextsent>
<nextsent>regarding the baselines,this combination performs lower than the most frequent senses from semcor, wn or the trainingdata.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2462">
<title id=" W07-2041.xml">irstbp web people search using name entities </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the common nouns not referring to entities are considered further as coreference clues only if they are found within already co referred documents.
</prevsent>
<prevsent>names are ambiguous items (artiles, gonzalo and sekine 2007).
</prevsent>
</prevsection>
<citsent citstr=" W06-0504 ">
as reported on an experiment carried out on an italian news corpus (magnini et al 2006) <papid> W06-0504 </papid>within 4 consecutive days from local newspaper the perplexity is 56% and 14% for first and last name respectively.</citsent>
<aftsection>
<nextsent>deciding which particular person name refers to within text document depends mainly on the capacity to extract the relevant information out of texts when it is present1.
</nextsent>
<nextsent>we consider relevant?
</nextsent>
<nextsent>here to stand primarily for two properties: (1) uniqueness and (2) appropriateness.
</nextsent>
<nextsent>a feature is unique as long as it appears only with one person.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2463">
<title id=" W07-2041.xml">irstbp web people search using name entities </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>195 alogy pages are very useful, to the extent that the information could be accurately extracted and that the same information occurs in some other pages as well.
</prevsent>
<prevsent>however, in general, for plain web pages, we relyon paragraphs in which single person is mentioned and consequently, the search space for similarity is also within this type of paragraphs.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
our proposal is to relyon special n-grams for coreference and it is variant of agglomerative clustering based on social net works(bagga&baldwin; 1998, <papid> P98-1012 </papid>malin 2005) . the terms the n-grams contain are crucial.</citsent>
<aftsection>
<nextsent>suppose we have the same name shared by two different persons who happen to also have the same profession, lets say, lawyer?, and who also practice in the same state.
</nextsent>
<nextsent>while all three words ?
</nextsent>
<nextsent>(name, profession, state) - might be rare words for the whole corpus, their probability computed as chance to be seen in the same document is low, their three-gram fails to cluster correctly the documents referring to the two persons2.
</nextsent>
<nextsent>knowing that the lawyer?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2464">
<title id=" W07-2021.xml">clr integration of framenet in a text representation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as such, the framenet dictionary was available as the basis for sense disambiguation.
</prevsent>
<prevsent>in the cl research text parser, this integration was seamless, in which disambiguation can be performed against several lexical resources.
</prevsent>
</prevsection>
<citsent citstr=" W04-0835 ">
this work attempts to expand on semantic role labeling experiments in senseval-3 (litkowski, 2004<papid> W04-0835 </papid>a, and litkowski, 2004<papid> W04-0835 </papid>b).</citsent>
<aftsection>
<nextsent>in the following sections, we first describe the overall structure of the cl research knowledge management system and text parser, describing their general parsing and text analysis routines.
</nextsent>
<nextsent>next, we describe the creation of the framenet dictionary, particularly identifying design considerations to exploit the richness of the framenet data.
</nextsent>
<nextsent>in section 4, we describe our submission for the semeval task.
</nextsent>
<nextsent>in section 5, we describe our results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2472">
<title id=" W07-1404.xml">cogex at rte 3 </title>
<section> cogexs innovations for rte 3.  </section>
<citcontext>
<prevsection>
<prevsent>our system used this representation for qa dev pair 579 and qa test pair 582 2.
</prevsent>
<prevsent>2.2 tarsqi toolkit.
</prevsent>
</prevsection>
<citsent citstr=" P05-3021 ">
the tarsqi project (temporal awareness and reasoning systems for question interpretation)3 (ver hagen et al, 2005) <papid> P05-3021 </papid>builds modular system which detects, resolves and normalizes time expressions(both absolute and relative times) - gutime tagger; marks events and their grammatical features 2table 6 lists the pairs referenced throughout the paper.</citsent>
<aftsection>
<nextsent>3http://www.timeml.org/site/tarsqi 22 nlp axioms knowledge world semantic calculus temporal axioms xwn lexical chains axioms on demand named entity recognition partofspeech tagging syntactic parsing coreference resolution semantic parsing time and event representation text hypothesis usable set of support abduction backoff proof, proof score hlf tlf knowledge representation cogex figure 1: cogexs architecture the pet passport alone can be [used]e1:occurrence to [enter]e2:occurrence the uk, but it will not [suffice]e3:occurrence to[enter]e4:occurrence many countries.
</nextsent>
<nextsent>for instance guatemala, like almost every country, [demands]e5:occurrence that all imported pets have rabies vaccination, but will not [accept]e6:i action the pet passport as proof of [said]e7:reporting vacci-nation.
</nextsent>
<nextsent>modality: (e1:can); tense: (e2:infinitive), (e3:future), (e4:infinitive), (e5:present), (e6:future), (e7:past); polarity: (e3:negative), (e6:negative); slink: modal(e1, e2), modal(e5, e6), factive(e6, e7); tlink: before(e1, e2), before(e5, e6), before(e4, e5), before(e6, e7), before(e2, e3), before(e2, e4) table 1: tarsqis treatment of ie dev pair 63s isa(nobel_laureate,winner) theme(nobel_prize,winner) nobel ist, nobel_laureate; synsetid: 06822770 gloss: winner of nobel_prize figure 2: xwn-kb treatment of nobel laureateevita; identifies subordination constructions introducing modality information - slinket; adds temporal relations between events and temporal expressions - gutenlink; and computes temporal closures - sputlink.
</nextsent>
<nextsent>we used the information provided by the tarsqi toolkit (run #1) as an alternative toour event detection and temporal expression identification and normalization modules (run #2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2473">
<title id=" W07-1404.xml">cogex at rte 3 </title>
<section> cogexs innovations for rte 3.  </section>
<citcontext>
<prevsection>
<prevsent>2.5 coreference resolution.
</prevsent>
<prevsent>in order to cope with the long text pairs, we addedin our processing pipeline dedicated pronominal coreference resolution module which replaced the inter-sentential resolution processing we used until now.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
the new tool combines hobbs algorithm (hobbs, 1978) and the resolution of anaphora procedure (rap) algorithm (lappin and leass, 1994).<papid> J94-4002 </papid></citsent>
<aftsection>
<nextsent>for the rte task, it is very important to have tight connections between the predicates of 23 semantic relation axiom templates isa n1(x1) -  n2(x1); v1(e1,x1,x2) -  v2(e1,x1,x2) derivation n(x1) -  v(e1,x1,x2) &amp; agent sr(x1,e1); n(e1) -  v(e1,x1,x2) v(e1,x1,x2) -  n(x1); v(e1,x1,x2) -  n(e1) cause v1(e1,x1,x2) -  v2(e2,x2,x3) &amp; cause sr(e1,e2) agent n1(x1) -  n2(x2) &amp; agent sr(x1,x2) pertain a(x1,x2) -  n(x1) table 2: semantic relation - axiom template mapping long texts.
</nextsent>
<nextsent>for example, for qa dev pair 409, resolving the pronoun he to george h.w. bush is step needed to correctly label the pair.
</nextsent>
<nextsent>but ie dev pair 92 requires more advanced anaphora resolution which co refers the team and the kinston indians.
</nextsent>
<nextsent>3.1 xwn lexical chains.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2474">
<title id=" W07-1404.xml">cogex at rte 3 </title>
<section> natural language axiom improvements.  </section>
<citcontext>
<prevsection>
<prevsent>for this years challenge, we changed the sense selection mechanism and we used the cluster of wordnet senses to which the fine-grained sense assigned by the word sense disambiguation system corresponds.
</prevsent>
<prevsent>we used the coarse-grained sense inventory for wordnet 2.1 released for task #7 insemeval-20074.
</prevsent>
</prevsection>
<citsent citstr=" P06-1014 ">
this clustering was created automatically with the aid of methodology described in (navigli, 2006).<papid> P06-1014 </papid></citsent>
<aftsection>
<nextsent>for example, the 10 wordnet senses for the noun bank are mapped into 3 clusters.
</nextsent>
<nextsent>3.2 nlp axioms.
</nextsent>
<nextsent>in addition to the syntactic re-writing rules which break down complex syntactic structures, including complex nominals and coordinating conjunctions, we added new type of nlp axioms which links named entity to its set of aliases.
</nextsent>
<nextsent>for ie dev pair 35, the link between the central intelligence agency mentioned in and hs cia is very important.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2475">
<title id=" W08-0618.xml">a preliminary approach to extract drugs by combining umls resources and usan naming conventions </title>
<section> introduction </section>
<citcontext>
<prevsection>

<prevsent>this paper presents system1 for drug name identification and classification in biomedical texts.
</prevsent>
</prevsection>
<citsent citstr=" W02-0302 ">
numerous studies have tackled gene and protein names recognition (collier et al 2002), (tanabe and wilbur, 2002).<papid> W02-0302 </papid></citsent>
<aftsection>
<nextsent>nevertheless, drug names have not been widely addressed (rindflesch et al, 2000).
</nextsent>
<nextsent>automating the process of new drugs recognition and classification is challenging task.
</nextsent>
<nextsent>with the rapidly changing vocabulary, new drugs are introduced while old ones are made obsolete.
</nextsent>
<nextsent>though the terminological resources are frequently updated, they can not follow the accelerated pace of the changing terminology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2476">
<title id=" W08-0104.xml">agreement and disputes in dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>intuitively, and agree that the room went dark, that max turned out the light, and that the latter is at least part of the reason why the former occurred.
</prevsent>
<prevsent>thus, implicatures can be agreed upon (that (1b)is part of the cause of (1a) goes beyond compositional semantics), and agreement can be implicated(b does not repeat (1a) and (1b) nor utter ok to indicate his agreement with a).
</prevsent>
</prevsection>
<citsent citstr=" P94-1001 ">
in principle, the grounding acts model (gam, traum (1994), traum and allen (1994)) <papid> P94-1001 </papid>supports implicit agreement.</citsent>
<aftsection>
<nextsent>but it demands an acceptance act for agreement to occur, and its current rules dont predict such an act from (1c).
</nextsent>
<nextsent>segmented discourse representation theory (sdrt, asher and lascarides (2003)) errs in the opposite direction.
</nextsent>
<nextsent>it stipulates that lack of disagreement implicates agreement, and so in (1) too much is agreed upon; e.g., (1c).
</nextsent>
<nextsent>thus, sdrt needs modification to deal with (1), just as gam needs supplementation.agreement can occur even in the context of corrections or disputes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2477">
<title id=" W08-0104.xml">agreement and disputes in dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is for two reasons.
</prevsent>
<prevsent>firstly, revision means that there is in principle no general way of stating what information is preserved from the previous discourse state to the current one.
</prevsent>
</prevsection>
<citsent citstr=" P92-1005 ">
but if we construct logical form in monotonic wayin our case, this means that the discourse structure for conversation at turn is an elementary substructure of the discourse structure at turn + 1then standard preservation results from model theory apply.secondly, monotonicity guarantees that interpretation algorithms can proceed incrementally, combining information from various sources in nondestructive way (alshawi and crouch, 1992).<papid> P92-1005 </papid></citsent>
<aftsection>
<nextsent>to our knowledge, there is currently no dynamic semantics for dialogue that yields adequate interpretations of corrections and implicit agreement.
</nextsent>
<nextsent>wewill address this gap here.
</nextsent>
<nextsent>in section 2, we re 29view two existing approaches to motivate our basic strategy, which we then describe in section 3.
</nextsent>
<nextsent>we will refine sdrt so that it tracks each dialogue participants public commitments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2479">
<title id=" W07-0736.xml">sentence level machine translation evaluation as a ranking </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>( 6 ? d2 n(n2 ? 1) ) (1) where is the difference between each pair of ranks and is the number of candidates for ranking.
</prevsent>
<prevsent>papineni et al(2001) pioneered the automatic mt evaluation study, which scores translation quality vian-gram matching between the candidate and reference translations.
</prevsent>
</prevsection>
<citsent citstr=" W06-1610 ">
following the growing awareness of the deficiency of n-gram based automatic mt evaluation, many studies attempted to improve upon n-gram based metrics (zhou et al, 2006; <papid> W06-1610 </papid>liu, et al., 2005,2006) as well as propose ways to evaluate mt evaluation metrics (lin, et al 2004).</citsent>
<aftsection>
<nextsent>previous studies, however, have focused on mt evaluation atthe document level in order to fight n-gram sparseness problem.
</nextsent>
<nextsent>while document level correlation provides us with general impression of the quality of an mt system, researchers desire to get more informative diagnostic evaluation at sentence levelto improve the mt system instead of just an over all score that does not provide details.
</nextsent>
<nextsent>recent year shave seen several studies investigating mt evaluation at the sentence level (liu et al, 2005,2006; quirk, 2004).
</nextsent>
<nextsent>the state-of-the-art sentence level correlations reported in previous work between human assessments and automatic scoring are around0.20.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2480">
<title id=" W07-0736.xml">sentence level machine translation evaluation as a ranking </title>
<section> experiments and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the bleu score is, how ever, still informative in judging the average mt systems translation.
</prevsent>
<prevsent>4.2.2 dependency structure matching dependency relation information has been widely used in machine translation in recent years.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
fox (2002) <papid> W02-1039 </papid>reported that dependency trees correspond better across translation pairs than constituent trees.</citsent>
<aftsection>
<nextsent>the information summarization community has also seen successful implementation of ideas similar to the depedency structure.
</nextsent>
<nextsent>zhou et al(2005) and hovy et al(2005) reported using basic elements (be) in text summarization and its evaluation.
</nextsent>
<nextsent>in the current3we added an extremely small number to both matched grams and total number of n-grams.
</nextsent>
<nextsent>243paper, we match candidate translation with reference translation on the following five dependency structure (ds) types: ? agent - verb ? verb - patient ? modified noun - modifier ? modified verb - modifier ? preposition - object besides the consideration of the presence of certain lexical items, ds captures information as tohow the lexical items are assembled into good sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2481">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goals of this paper are twofold: first, we evaluate the shared task entries in order to determine which systems produce translations with the highest quality.
</prevsent>
<prevsent>second, we analyze the evaluation measures themselves in order to try to determine best practices?
</prevsent>
</prevsection>
<citsent citstr=" W05-0820 ">
when evaluating machine translation research.previous acl workshops on machine translation were more limited in scope (koehn and monz, 2005; <papid> W05-0820 </papid>koehn and monz, 2006).<papid> W06-3114 </papid></citsent>
<aftsection>
<nextsent>the 2005 workshop evaluated translation quality only in terms of bleu score.
</nextsent>
<nextsent>the 2006 workshop additionally included alimited manual evaluation in the style of nist machine translation evaluation workshop.
</nextsent>
<nextsent>here we apply eleven different automatic evaluation metrics,and conduct three different types of manual evalu ation.beyond examining the quality of translations produced by various systems, we were interested in examining the following questions about evaluation methodologies: how consistent are people when they judge translation quality?
</nextsent>
<nextsent>to what extent dothey agree with other annotators?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2482">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goals of this paper are twofold: first, we evaluate the shared task entries in order to determine which systems produce translations with the highest quality.
</prevsent>
<prevsent>second, we analyze the evaluation measures themselves in order to try to determine best practices?
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
when evaluating machine translation research.previous acl workshops on machine translation were more limited in scope (koehn and monz, 2005; <papid> W05-0820 </papid>koehn and monz, 2006).<papid> W06-3114 </papid></citsent>
<aftsection>
<nextsent>the 2005 workshop evaluated translation quality only in terms of bleu score.
</nextsent>
<nextsent>the 2006 workshop additionally included alimited manual evaluation in the style of nist machine translation evaluation workshop.
</nextsent>
<nextsent>here we apply eleven different automatic evaluation metrics,and conduct three different types of manual evalu ation.beyond examining the quality of translations produced by various systems, we were interested in examining the following questions about evaluation methodologies: how consistent are people when they judge translation quality?
</nextsent>
<nextsent>to what extent dothey agree with other annotators?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2484">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0727 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2485">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0731 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2486">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0725 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2487">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0723 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2488">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0724 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2489">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0726 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2490">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0732 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2491">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0728 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2492">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0730 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2493">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2494">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0729 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2495">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> shared task overview.  </section>
<citcontext>
<prevsection>
<prevsent>english sentences 51,613 43,194 59,975 57797 foreign words 1,263,067 1,028,672 1,297,673 1,083,122 english words 1,076,273 906,593 1,238,274 1,188,006 distinct foreign words 84,303 68,214 115,589 142,146 distinct english words 70,755 63,568 76,419 74,042 language model data english spanish french german sentence 1,407,285 1,431,614 1,435,027 1,478,428 words 34,539,822 36,426,542 35,595,199 32,356,475 distinct words 280,546 385,796 361,205 558,377 europarl test set english spanish french german sentences 2,000 words 53,531 55,380 53,981 49,259 distinct words 8,558 10,451 10,186 11,106 news commentary test set english spanish french german czech sentences 2,007 words 43,767 50,771 49,820 45,075 39,002 distinct words 10,002 10,948 11,244 12,322 15,245 figure 1: properties of the training and test sets used in the shared task.
</prevsent>
<prevsent>the training data is drawn from the europarl corpus and from the project syndicate, web site which collects political commentary in multiple languages.
</prevsent>
</prevsection>
<citsent citstr=" W07-0722 ">
138 id participant cmu-uka carnegie mellon university, usa (paulik et al, 2007) <papid> W07-0727 </papid>cmu-syntax carnegie mellon university, usa (zollmann et al, 2007) <papid> W07-0731 </papid>cu charles university, czech republic (bojar, 2007) limsi limsi-cnrs, france (schwenk, 2007) <papid> W07-0725 </papid>liu university of linkoping, sweden(holmqvist et al, 2007) <papid> W07-0723 </papid>nrc national research council, canada (ueffing et al, 2007) <papid> W07-0724 </papid>pct commercial mt provider from the czech republic saar saarland university &amp; dfki, germany (chen et al, 2007) <papid> W07-0726 </papid>systran systran, france &amp; u. edinburgh, uk (dugast et al, 2007) <papid> W07-0732 </papid>systran-nrc national research council, canada (simard et al, 2007) <papid> W07-0728 </papid>ucb university of california at berkeley, usa (nakov and hearst, 2007) <papid> W07-0730 </papid>uedin university of edinburgh, uk (koehn and schroeder, 2007) <papid> W07-0733 </papid>umd university of maryland, usa (dyer, 2007) <papid> W07-0729 </papid>upc university of catalonia, spain (costa-jussa` and fonollosa, 2007) upv university of valencia, spain (civera and juan, 2007) <papid> W07-0722 </papid>table 1: participants in the shared task.</citsent>
<aftsection>
<nextsent>not all groups participated in all translation directions.increase over last years shared task where submissions were received from 14 groups from 11 institutions.
</nextsent>
<nextsent>of the 11 groups that participated in last years shared task, 6 groups returned this year.this year, most of these groups follow phrase based statistical approach to machine translation.however, several groups submitted results from systems that followed hybrid approach.
</nextsent>
<nextsent>while building machine translation system is aserious undertaking we hope to attract more newcomers to the field by keeping the barrier of entry as low as possible.
</nextsent>
<nextsent>the creation of parallel corpora such as the europarl, the czeng, and the news commentary corpora should help in this direction by providing freely available language resources for building systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2496">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> human evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>word alignments are created between the source sentence and the reference translation (shown), and the source sentence and each of the system translations (not shown).
</prevsent>
<prevsent>we parsed the test sentences for each of the languages aside from czech.
</prevsent>
</prevsection>
<citsent citstr=" P05-1038 ">
we used cowan and collins (2005)s parser for spanish, arun and keller (2005)<papid> P05-1038 </papid>s for french, dubey (2005)<papid> P05-1039 </papid>s forger man, and bikel (2002)s for english.</citsent>
<aftsection>
<nextsent>the word alignments were created with giza++ (och and ney, 2003) <papid> J03-1002 </papid>applied to parallel corpus containing 200,000 sentence pairs of the training data, plus sets of 4,007 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations.</nextsent>
<nextsent>the phrases in the translations were located using techniques from phrase-based statistical machine translation which extract phrase pairs from word alignments (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2004).<papid> J04-4002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2497">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> human evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>word alignments are created between the source sentence and the reference translation (shown), and the source sentence and each of the system translations (not shown).
</prevsent>
<prevsent>we parsed the test sentences for each of the languages aside from czech.
</prevsent>
</prevsection>
<citsent citstr=" P05-1039 ">
we used cowan and collins (2005)s parser for spanish, arun and keller (2005)<papid> P05-1038 </papid>s for french, dubey (2005)<papid> P05-1039 </papid>s forger man, and bikel (2002)s for english.</citsent>
<aftsection>
<nextsent>the word alignments were created with giza++ (och and ney, 2003) <papid> J03-1002 </papid>applied to parallel corpus containing 200,000 sentence pairs of the training data, plus sets of 4,007 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations.</nextsent>
<nextsent>the phrases in the translations were located using techniques from phrase-based statistical machine translation which extract phrase pairs from word alignments (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2004).<papid> J04-4002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2498">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> human evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we parsed the test sentences for each of the languages aside from czech.
</prevsent>
<prevsent>we used cowan and collins (2005)s parser for spanish, arun and keller (2005)<papid> P05-1038 </papid>s for french, dubey (2005)<papid> P05-1039 </papid>s forger man, and bikel (2002)s for english.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the word alignments were created with giza++ (och and ney, 2003) <papid> J03-1002 </papid>applied to parallel corpus containing 200,000 sentence pairs of the training data, plus sets of 4,007 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations.</citsent>
<aftsection>
<nextsent>the phrases in the translations were located using techniques from phrase-based statistical machine translation which extract phrase pairs from word alignments (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2004).<papid> J04-4002 </papid></nextsent>
<nextsent>because the word-alignments we recreated automatically, and because the phrase extraction is heuristic, the phrases that were selected may not exactly correspond to the translations of the selected source phrase.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2499">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> human evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we used cowan and collins (2005)s parser for spanish, arun and keller (2005)<papid> P05-1038 </papid>s for french, dubey (2005)<papid> P05-1039 </papid>s forger man, and bikel (2002)s for english.</prevsent>
<prevsent>the word alignments were created with giza++ (och and ney, 2003) <papid> J03-1002 </papid>applied to parallel corpus containing 200,000 sentence pairs of the training data, plus sets of 4,007 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the phrases in the translations were located using techniques from phrase-based statistical machine translation which extract phrase pairs from word alignments (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>because the word-alignments we recreated automatically, and because the phrase extraction is heuristic, the phrases that were selected may not exactly correspond to the translations of the selected source phrase.
</nextsent>
<nextsent>we noted this in the instructions to judges: rank each constituent translation from best to worst relative to the other choices(ties are allowed).
</nextsent>
<nextsent>grade only the highlighted part of each translation.please note that segments are selected automatically, and they should be taken asan approximate guide.
</nextsent>
<nextsent>they might include extra words that are not in the actual alignment, or miss words on either end.the criteria that we used to select which constituents were to be evaluated were: ? the constituent could not be the whole source sentence ? the constituent had to be longer three words, and be no longer than 15 words ? the constituent had to have corresponding phrase with consistent word alignment in each of the translations the final criterion helped reduce the number of alignment errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2500">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> human evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we used cowan and collins (2005)s parser for spanish, arun and keller (2005)<papid> P05-1038 </papid>s for french, dubey (2005)<papid> P05-1039 </papid>s forger man, and bikel (2002)s for english.</prevsent>
<prevsent>the word alignments were created with giza++ (och and ney, 2003) <papid> J03-1002 </papid>applied to parallel corpus containing 200,000 sentence pairs of the training data, plus sets of 4,007 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations.</prevsent>
</prevsection>
<citsent citstr=" J04-4002 ">
the phrases in the translations were located using techniques from phrase-based statistical machine translation which extract phrase pairs from word alignments (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2004).<papid> J04-4002 </papid></citsent>
<aftsection>
<nextsent>because the word-alignments we recreated automatically, and because the phrase extraction is heuristic, the phrases that were selected may not exactly correspond to the translations of the selected source phrase.
</nextsent>
<nextsent>we noted this in the instructions to judges: rank each constituent translation from best to worst relative to the other choices(ties are allowed).
</nextsent>
<nextsent>grade only the highlighted part of each translation.please note that segments are selected automatically, and they should be taken asan approximate guide.
</nextsent>
<nextsent>they might include extra words that are not in the actual alignment, or miss words on either end.the criteria that we used to select which constituents were to be evaluated were: ? the constituent could not be the whole source sentence ? the constituent had to be longer three words, and be no longer than 15 words ? the constituent had to have corresponding phrase with consistent word alignment in each of the translations the final criterion helped reduce the number of alignment errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2503">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> automatic evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we used the manual evaluation data as means of testing the correlation of range of automatic metrics in addition to bleu.
</prevsent>
<prevsent>in total we used eleven different automatic evaluation measures to rank the shared task submissions.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
they are: ? meteor (banerjee and lavie, 2005)<papid> W05-0909 </papid>meteor measures precision and recall of unigrams when comparing hypothesis translation 142 language pair test set adequacy fluency rank constituent english-german europarl 1,416 1,418 1,419 2,626 news commentary 1,412 1,413 1,412 2,755 german-english europarl 1,525 1,521 1,514 2,999 news commentary 1,626 1,620 1,601 3,084 english-spanish europarl 1,000 1,003 1,064 1,001 news commentary 1,272 1,272 1,238 1,595 spanish-english europarl 1,174 1,175 1,224 1,898 news commentary 947 949 922 1,339 english-french europarl 773 772 769 1,456 news commentary 729 735 728 1,313 french-english europarl 834 833 830 1,641 news commentary 1,041 1,045 1,035 2,036 english-czech news commentary 2,303 2,304 2,331 3,968 czech-english news commentary 1,711 1,711 1,733 0 totals 17,763 17,771 17,820 27,711 table 2: the number of items that were judged for each task during the manual evaluation against reference.</citsent>
<aftsection>
<nextsent>it flexibly matches words using stemming and wordnet synonyms.
</nextsent>
<nextsent>its flexible matching was extended to french, spanish, german and czech for this workshop (lavie and agarwal, 2007).<papid> W07-0734 </papid></nextsent>
<nextsent>bleu (papineni et al, 2002)bleu is currently the de facto standard in machine translation evaluation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2504">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> automatic evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>they are: ? meteor (banerjee and lavie, 2005)<papid> W05-0909 </papid>meteor measures precision and recall of unigrams when comparing hypothesis translation 142 language pair test set adequacy fluency rank constituent english-german europarl 1,416 1,418 1,419 2,626 news commentary 1,412 1,413 1,412 2,755 german-english europarl 1,525 1,521 1,514 2,999 news commentary 1,626 1,620 1,601 3,084 english-spanish europarl 1,000 1,003 1,064 1,001 news commentary 1,272 1,272 1,238 1,595 spanish-english europarl 1,174 1,175 1,224 1,898 news commentary 947 949 922 1,339 english-french europarl 773 772 769 1,456 news commentary 729 735 728 1,313 french-english europarl 834 833 830 1,641 news commentary 1,041 1,045 1,035 2,036 english-czech news commentary 2,303 2,304 2,331 3,968 czech-english news commentary 1,711 1,711 1,733 0 totals 17,763 17,771 17,820 27,711 table 2: the number of items that were judged for each task during the manual evaluation against reference.</prevsent>
<prevsent>it flexibly matches words using stemming and wordnet synonyms.</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
its flexible matching was extended to french, spanish, german and czech for this workshop (lavie and agarwal, 2007).<papid> W07-0734 </papid></citsent>
<aftsection>
<nextsent>bleu (papineni et al, 2002)bleu is currently the de facto standard in machine translation evaluation.
</nextsent>
<nextsent>it calculates n-gram precision anda brevity penalty, and can make use of multiple reference translations as way of capturing some of the allowable variation in translation.we use single reference translation in our ex periments.?
</nextsent>
<nextsent>gtm (melamed et al, 2003)<papid> N03-2021 </papid>gtm generalizes precision, recall, and f-measure to measure overlap between strings, rather than overlap between bags of items.</nextsent>
<nextsent>an exponent?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2505">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> automatic evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>bleu (papineni et al, 2002)bleu is currently the de facto standard in machine translation evaluation.
</prevsent>
<prevsent>it calculates n-gram precision anda brevity penalty, and can make use of multiple reference translations as way of capturing some of the allowable variation in translation.we use single reference translation in our ex periments.?
</prevsent>
</prevsection>
<citsent citstr=" N03-2021 ">
gtm (melamed et al, 2003)<papid> N03-2021 </papid>gtm generalizes precision, recall, and f-measure to measure overlap between strings, rather than overlap between bags of items.</citsent>
<aftsection>
<nextsent>an exponent?
</nextsent>
<nextsent>parameter which controls the relative importance of word order.
</nextsent>
<nextsent>a value of 1.0 reduces gtm to ordinary unigram overlap, with higher values emphasizing order.4 ? translation error rate (snover et al, 2006)?
</nextsent>
<nextsent>4the gtm scores presented here are an f-measure with weight of 0.1, which counts recall at 10x the level of precision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2506">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> automatic evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>ter calculates the number of edits required to change hypothesis translation into reference translation.
</prevsent>
<prevsent>the possible edits inter include insertion, deletion, and substitution of single words, and an edit which moves sequences of contiguous words.
</prevsent>
</prevsection>
<citsent citstr=" W06-1610 ">
paraeval precision and paraeval recall (zhou et al, 2006)<papid> W06-1610 </papid>paraeval matches hypothesis and reference translations using paraphrases thatare extracted from parallel corpora in an unsupervised fashion (bannard and callison-burch, 2005).</citsent>
<aftsection>
<nextsent>it calculates precision and recall using unigram counting strategy.
</nextsent>
<nextsent>dependency overlap (amigo?
</nextsent>
<nextsent>et al, 2006)this metric uses dependency trees for the hypothesis and reference translations, by computing the average overlap between words in the two trees which are dominated by grammatical relationships of the same type.
</nextsent>
<nextsent>semantic role overlap (gimenez and ma`rquez,2007)this metric calculates the lexical overlap between semantic roles (i.e., semantic arguments or adjuncts) of the same type in the the hypothesis and reference translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2507">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> automatic evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>143 ? word error rate over verbs (popovic and ney, 2007)wer?
</prevsent>
<prevsent>creates new reference and anew hypothesis for each pos class by extracting all words belonging to this class, and then to calculate the standardwer.we show results for this metric over verbs.
</prevsent>
</prevsection>
<citsent citstr=" N07-1006 ">
maximum correlation training on adequacy andon fluency (liu and gildea, 2007)<papid> N07-1006 </papid>a linear combination of different evaluation metrics(bleu, meteor, rouge, wer, and stochastic iterative alignment) with weights set to maximize pearsons correlation with adequacy and fluency judgments.</citsent>
<aftsection>
<nextsent>weights were trained on wmt-06 data.the scores produced by these are given in the tables at the end of the paper, and described in section 5.
</nextsent>
<nextsent>we measured the correlation of the automatic evaluation metrics with the different types of human judgments on 12 data conditions, and report these in section 6.
</nextsent>
<nextsent>the results of the human evaluation are given in tables 9, 10, 11 and 12.
</nextsent>
<nextsent>each of those tables present four scores:?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2508">
<title id=" W07-0718.xml">meta evaluation of machine translation </title>
<section> meta-evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>of our evaluation methodologies.
</prevsent>
<prevsent>6.1 inter- and intra-annotator agreement.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
we measured pairwise agreement among annotators using the kappa coefficient (k) which is widely usedin computational linguistics for measuring agreement in category judgments (carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>it is defined as = (a)?
</nextsent>
<nextsent>p (e) 1?
</nextsent>
<nextsent>p (e)where (a) is the proportion of times that the annotators agree, and (e) is the proportion of time that they would agree by chance.
</nextsent>
<nextsent>we define chance agreement for fluency and adequacy as 15 , since they are based on five point scales, and for ranking as 13 evaluation type (a) (e) fluency (absolute) .630 .2 .537 adequacy (absolute) .574 .2 .468 fluency (relative) .690 .333 .535 adequacy (relative) .696 .333 .544 sentence ranking .749 .333 .623 constituent ranking .825 .333 .738 constituent ranking .842 .333 .762 (w/identical constituents) table 6: kappa coefficient values for intra-annotatoragreement for the different types of manual evalua tion since there are three possible outcomes when ranking the output of pair of systems:   b, = b,   b. for inter-annotator agreement we calculated (a) for fluency and adequacy by examining all items that were annotated by two or more annotators, and calculating the proportion of time they assigned identical scores to the same items.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2511">
<title id=" W08-0703.xml">a bayesian model of natural language phonology generating alternations from underlying forms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the effects ofautosegmental phonology and other long-range dependencies (like vowel harmony) cannot be easily bayesianized.
</prevsent>
<prevsent>1.1 related work.
</prevsent>
</prevsection>
<citsent citstr=" P00-1025 ">
in the last decade, finite-state approaches to phonology (gildea and jurafsky, 1996; beesley and karttunen, 2000) <papid> P00-1025 </papid>have effectively brought theoretical linguistic work on rewrite rules into the computational realm.</citsent>
<aftsection>
<nextsent>a finite-state approximation of optimality theory (karttunen, 1998) <papid> W98-1301 </papid>was later refined into acompact treatment of gradient constraints (gerde mann and van noord, 2000).recent work on bayesian models of morphological segmentation (johnson et al, 2007) could be combined with phonological rule induction (gold water and johnson, 2004) <papid> W04-0105 </papid>in variety of ways, some of which will be explored in our discussion of future work.</nextsent>
<nextsent>also, the hierarchical bayes compiler (daume iii, 2007) could be used to generate amodel similar to the one presented here, but less constrained1 which makes correspondingly more random, less accurate predictions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2512">
<title id=" W08-0703.xml">a bayesian model of natural language phonology generating alternations from underlying forms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.1 related work.
</prevsent>
<prevsent>in the last decade, finite-state approaches to phonology (gildea and jurafsky, 1996; beesley and karttunen, 2000) <papid> P00-1025 </papid>have effectively brought theoretical linguistic work on rewrite rules into the computational realm.</prevsent>
</prevsection>
<citsent citstr=" W98-1301 ">
a finite-state approximation of optimality theory (karttunen, 1998) <papid> W98-1301 </papid>was later refined into acompact treatment of gradient constraints (gerde mann and van noord, 2000).recent work on bayesian models of morphological segmentation (johnson et al, 2007) could be combined with phonological rule induction (gold water and johnson, 2004) <papid> W04-0105 </papid>in variety of ways, some of which will be explored in our discussion of future work.</citsent>
<aftsection>
<nextsent>also, the hierarchical bayes compiler (daume iii, 2007) could be used to generate amodel similar to the one presented here, but less constrained1 which makes correspondingly more random, less accurate predictions.
</nextsent>
<nextsent>1.2 dataset.
</nextsent>
<nextsent>as we describe the model and its implementation inthis and subsequent sections, we will refer to sam 1recent updates to hbc, inspired by discussions with the author, have addressed some of these limitations.
</nextsent>
<nextsent>12 ple dataset (in figure 1), consisting of paradigm2 of verb stems and person/number suffixes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2513">
<title id=" W08-0703.xml">a bayesian model of natural language phonology generating alternations from underlying forms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.1 related work.
</prevsent>
<prevsent>in the last decade, finite-state approaches to phonology (gildea and jurafsky, 1996; beesley and karttunen, 2000) <papid> P00-1025 </papid>have effectively brought theoretical linguistic work on rewrite rules into the computational realm.</prevsent>
</prevsection>
<citsent citstr=" W04-0105 ">
a finite-state approximation of optimality theory (karttunen, 1998) <papid> W98-1301 </papid>was later refined into acompact treatment of gradient constraints (gerde mann and van noord, 2000).recent work on bayesian models of morphological segmentation (johnson et al, 2007) could be combined with phonological rule induction (gold water and johnson, 2004) <papid> W04-0105 </papid>in variety of ways, some of which will be explored in our discussion of future work.</citsent>
<aftsection>
<nextsent>also, the hierarchical bayes compiler (daume iii, 2007) could be used to generate amodel similar to the one presented here, but less constrained1 which makes correspondingly more random, less accurate predictions.
</nextsent>
<nextsent>1.2 dataset.
</nextsent>
<nextsent>as we describe the model and its implementation inthis and subsequent sections, we will refer to sam 1recent updates to hbc, inspired by discussions with the author, have addressed some of these limitations.
</nextsent>
<nextsent>12 ple dataset (in figure 1), consisting of paradigm2 of verb stems and person/number suffixes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2514">
<title id=" W07-1904.xml">which way to turn guide orientation in virtual way finding </title>
<section> the virtual guide.  </section>
<citcontext>
<prevsection>
<prevsent>first, the shortest path between starting point and destination is computed based on predefined paths in the virtual environment.
</prevsent>
<prevsent>turn directions are derived from the relative angles of subsequent path segments, and landmarks are selected based on their relative salience (e.g., in terms of sizeor colour) and proximity to turning point.
</prevsent>
</prevsection>
<citsent citstr=" W98-1428 ">
these quence of turn directions and associated landmark sis then given as input to the natural language generation component, which is based on exemplars (white and caldwell, 1998).<papid> W98-1428 </papid></citsent>
<aftsection>
<nextsent>after first version of the route description has been generated using acollection of standard sentence structures, this initial description is revised by randomly aggregating some sentences and adding cue phrases such as and then, after that etc. to achieve some variation in the generated text.
</nextsent>
<nextsent>to generate appropriate gestures to accompany the verbal route description, the generated text is figure 1: the virtual guide.
</nextsent>
<nextsent>extended with tags associating the words in the route description with different types of gestures.currently this is done using simple keyword approach.
</nextsent>
<nextsent>direction words (left, right) are associated with pointing gestures in the corresponding directions, and references to landmarks are associated with deictic gestures pointing to either the absolute or the relative location of these objects (see section 3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2515">
<title id=" W07-1801.xml">speech recognition grammar compilation in grammatical framework </title>
<section> generating context-free grammars.  </section>
<citcontext>
<prevsection>
<prevsent>one example where this is useful is when speech recognition grammar is generated from multimodal grammar (bringert et al, 2005).
</prevsent>
<prevsent>in this case, the start category is different from the start category used by the parser, in that its linearization only contains the speech component of the in 3 gf grammar cfg conversion cycle elimination bottom-up filtering top-down filtering left-recursion elimination identical category elimination ebnf compaction srgs/jsgf/gsl regular approximation fsa compilation minimization slf figure 3: grammar compilation pipeline.put.
</prevsent>
</prevsection>
<citsent citstr=" A00-2033 ">
top-down filtering then has the effect of excluding the non-speech modalities from the speech recognition grammar.the bottom-up and top-down filtering steps are iterated until fixed point is reached, since both these steps may produce new filtering opportunities.left-recursion elimination all direct and indirect left-recursion is removed using the lclr transform described by moore (2000).<papid> A00-2033 </papid></citsent>
<aftsection>
<nextsent>we have modified the lclr transform to avoid adding productions which use category ax when there are no productions for ax . identical category elimination in this step, the categories are grouped into equivalence classes by their right-hand sides and semantic annotations.
</nextsent>
<nextsent>the categories a1 . . .an in each class are replaced by single category a1+.
</nextsent>
<nextsent>.+an throughout the grammar, discarding any duplicate productions.
</nextsent>
<nextsent>this has the effect of replacing all categories which have identical sets of productions with single category.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2516">
<title id=" W07-1801.xml">speech recognition grammar compilation in grammatical framework </title>
<section> semantic interpretation.  </section>
<citcontext>
<prevsection>
<prevsent>as discussed in section 4.2, the semantic interpretation code could be used to implement the non context-free features of gf, but this is not yet done.
</prevsent>
<prevsent>the slot-filling mechanism in the gsl format could also be used to build semantic representations,by returning program code which can then be executed.
</prevsent>
</prevsection>
<citsent citstr=" C02-1095 ">
the uniance grammar compiler (bos, 2002) <papid> C02-1095 </papid>uses that approach.</citsent>
<aftsection>
<nextsent>7.1 unification grammar compilation.
</nextsent>
<nextsent>compilation of unification grammars to speech recognition grammars is well described in the literature (moore, 1999; dowding et al, 2001).<papid> P01-1022 </papid></nextsent>
<nextsent>regulus (rayner et al, 2006) is perhaps the most ambitious such system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2517">
<title id=" W07-1801.xml">speech recognition grammar compilation in grammatical framework </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the uniance grammar compiler (bos, 2002) <papid> C02-1095 </papid>uses that approach.</prevsent>
<prevsent>7.1 unification grammar compilation.</prevsent>
</prevsection>
<citsent citstr=" P01-1022 ">
compilation of unification grammars to speech recognition grammars is well described in the literature (moore, 1999; dowding et al, 2001).<papid> P01-1022 </papid></citsent>
<aftsection>
<nextsent>regulus (rayner et al, 2006) is perhaps the most ambitious such system.
</nextsent>
<nextsent>like gf, regulus uses general grammar for each language, which is specialized to adomain-specific one.
</nextsent>
<nextsent>ljunglof (ljunglof, 2007b) relates gf and regulus by showing how to convert gfgrammars to regulus grammars.
</nextsent>
<nextsent>we carry compositional semantic interpretation through left-recursion elimination using the same idea as the uniance grammar compiler (bos, 2002), <papid> C02-1095 </papid>though our version handles both direct and indirect left-recursion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2519">
<title id=" W07-1801.xml">speech recognition grammar compilation in grammatical framework </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one shortcoming of our system is that it does not yet have support for weighted grammars.
</prevsent>
<prevsent>7.2 generating slms from gf grammars.
</prevsent>
</prevsection>
<citsent citstr=" E06-1008 ">
jonson (2006) <papid> E06-1008 </papid>has shown that in addition to generating grammar-based language models, gf can be used to build statistical language models (slms).</citsent>
<aftsection>
<nextsent>itwas found that compared to our grammar-based approach, use of generated slms improved the recognition performance for out-of-grammar utterances significantly.
</nextsent>
<nextsent>speech recognition grammars generated from gf grammars have already been used in number of research dialogue systems.
</nextsent>
<nextsent>6 gottis (bringert et al, 2005; ericsson et al, 2006), an experimental multimodal and multilingual dialogue system for public transportation queries, uses gf grammars for parsing multimodal input.for speech recognition, it uses gsl grammars generated from the speech modality part of the gf grammars.dj-godis, godis-delux, and gotgodis (er icsson et al, 2006) are three applications which use gf grammars for speech recognition and parsing together with the godis implementation of issue based dialogue management (larsson, 2002).
</nextsent>
<nextsent>got godis has been translated to 7 languages using thegf resource grammar library, with each new translation taking less than one day (ericsson et al, 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2520">
<title id=" W07-1801.xml">speech recognition grammar compilation in grammatical framework </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>got godis has been translated to 7 languages using thegf resource grammar library, with each new translation taking less than one day (ericsson et al, 2006).
</prevsent>
<prevsent>the dico (villing and larsson, 2006) dialogue system for trucks has recently been modified touse gf grammars for speech recognition and parsing (ljunglof, 2007a).
</prevsent>
</prevsection>
<citsent citstr=" E06-2004 ">
dude (lemon and liu, 2006) <papid> E06-2004 </papid>and its extensionreall-dude (lemon et al, 2006b) are environments where non-experts can develop dialogue systems based on business process models describing the applications.</citsent>
<aftsection>
<nextsent>from keywords, prompts and answer sets defined by the developer, the system generates gf grammar.
</nextsent>
<nextsent>this grammar is used for parsing input, and for generating language model in slf or gsl format.
</nextsent>
<nextsent>the voice programming system by georgila and lemon (georgila and lemon, 2006; lemon et al, 2006a) uses an slf language model generated from gf grammar.
</nextsent>
<nextsent>perera and ranta (2007) have studied how gf grammars can be used for localization of dialoguesystems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2524">
<title id=" W07-1901.xml">comparing rule based and data driven selection of facial displays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in some systems, recorded behaviours are analysed and rules are created by hand based on theanalysis; in others, recorded human data is used directly in the decision process.
</prevsent>
<prevsent>the former technique is similar to the classic role of corpora in natural language generation described by reiter and dale (2000), while the latter is more similar to the more recent data-driven techniques that have been adopted (belz and varges, 2005).
</prevsent>
</prevsection>
<citsent citstr=" P01-1016 ">
researchers that have used rule-based techniques to create embodied-agent systems include: poggiand pelachaud (2000), who concentrated on generating appropriate affective facial displays based on descriptions of typical facial expressions of emotion; cassell et al (2001<papid> P01-1016 </papid>a), who selected gestures and facial expressions to accompany text using heuristics derived from studies of typical north american non-verbal-displays; and marsi and van rooden (2007), who generated typical certain and uncertain facial displays for talking head in an information retrieval system.</citsent>
<aftsection>
<nextsent>researchers that used data-driventechniques include: stone et al (2004), who captured the motions of an actor performing scripted output and then used that data to create performance 1 specifications on the fly; cassell et al (2001<papid> P01-1016 </papid>b), who selected posture shifts for an embodied agent based on recorded human behaviour; and kipp (2004), who annotated the gesturing behaviour of skilled public speakers and derived gesture profiles?</nextsent>
<nextsent>to use in the generation process.using rules derived from the data can produce displays that are easily identifiable and is straightforward to implement.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2528">
<title id=" W07-1901.xml">comparing rule based and data driven selection of facial displays </title>
<section> corpus collection and annotation1.  </section>
<citcontext>
<prevsection>
<prevsent>subjective preferences, while in section 5 we measure the impact ofeach strategy on users ability to select spoken descriptions correctly tailored to given set of user preferences.
</prevsent>
<prevsent>finally, in section 6, we discuss the results of these two studies, draw some conclusions, and outline potential future work.
</prevsent>
</prevsection>
<citsent citstr=" P05-3012 ">
the recording scripts for the corpus were created by the output planner of the comic multimodal dialogue system (foster et al, 2005) <papid> P05-3012 </papid>and consisted of total of 444 sentences describing and comparing various tile-design options.</citsent>
<aftsection>
<nextsent>the surface form of each sentence was created by the openccg surfacerealiser (white, 2006), using grammar that spec 1foster (2007) <papid> W07-1504 </papid>gives more details of the face-display corpus.</nextsent>
<nextsent>ified both the words and the intended prosody forthe speech synthesiser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2529">
<title id=" W07-1901.xml">comparing rule based and data driven selection of facial displays </title>
<section> corpus collection and annotation1.  </section>
<citcontext>
<prevsection>
<prevsent>finally, in section 6, we discuss the results of these two studies, draw some conclusions, and outline potential future work.
</prevsent>
<prevsent>the recording scripts for the corpus were created by the output planner of the comic multimodal dialogue system (foster et al, 2005) <papid> P05-3012 </papid>and consisted of total of 444 sentences describing and comparing various tile-design options.</prevsent>
</prevsection>
<citsent citstr=" W07-1504 ">
the surface form of each sentence was created by the openccg surfacerealiser (white, 2006), using grammar that spec 1foster (2007) <papid> W07-1504 </papid>gives more details of the face-display corpus.</citsent>
<aftsection>
<nextsent>ified both the words and the intended prosody forthe speech synthesiser.
</nextsent>
<nextsent>we attached all of the relevant contextual, syntactic, and prosodic information to each node in the openccg derivation tree, including the user-model evaluation of the object being described (positive, negative, or neutral), the predicted pitch accent, the clause of the sentence (first, second, or only), and whether the information being presented was new to the discourse.
</nextsent>
<nextsent>the sentences in the script were presented one at time to speaker who was instructed to read each out loud as expressively as possible into camera directed at his face.
</nextsent>
<nextsent>the following facial displays were then annotated on the recordings: eyebrow motions (up or down), eye squinting, and rigid head motion on all three axes (nodding, leaning, and turning).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2530">
<title id=" W07-2059.xml">pubcd exponential family models for the coarse and fine grained all words tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this statistical framework lends itself to thetask of word sense disambiguation.
</prevsent>
<prevsent>we evaluate the performance of the model in its participation on the semeval-2007 coarse- and fine-grained all-words tasks under variety of parameters.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
this paper describes an exponential family model suited to performing word sense disambiguation.exponential family models are mainstay of modern statistical modeling (brown, 1986) and they are widely and successfully used for example in text classification (berger et al, 1996).<papid> J96-1002 </papid></citsent>
<aftsection>
<nextsent>in statistical machine learning research, general methodology and many algorithms were developed for undirected graphical model representation of exponential families (jordan, 2004), providing solid basis for efficient inference.our model differs from other probabilistic models used for word sense disambiguation in that it captures not only word-sense co-occurrences but also contextual sense-sense co-occurrences, thereby breaking the nave bayes assumption.
</nextsent>
<nextsent>although spare in the types of features, the model is extremely expressive.
</nextsent>
<nextsent>our model has parameters that control for word-sense interaction and sense-sense similarity, allowing us to capture many of the salient features of word and sense use.
</nextsent>
<nextsent>after fitting the parameters of our model from labeled corpus, the task of word sense disambiguation immediately follows by considering the posterior distribution of senses given words.we used this model to participate in semeval 2007 on the coarse- and fine-grained all-words tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2531">
<title id=" W07-2059.xml">pubcd exponential family models for the coarse and fine grained all words tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in both tasks, performance was gauged by comparing the output of each system to human-tagged senses.
</prevsent>
<prevsent>in the fine-grained task,precision and recall were simply and directly computed against the golden annotations.
</prevsent>
</prevsection>
<citsent citstr=" P06-1014 ">
however, in the coarse-grained task, the sense inventory was first clustered semi-automatically with each cluster representing an equivalence class over senses (navigli, 2006).<papid> P06-1014 </papid></citsent>
<aftsection>
<nextsent>precision and recall were computed against equivalence classes.
</nextsent>
<nextsent>this paper briefly derives the model and then explores its properties for wsd.
</nextsent>
<nextsent>we show how common algorithms, such as dominant sense?
</nextsent>
<nextsent>andmost frequent sense,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2532">
<title id=" W07-2059.xml">pubcd exponential family models for the coarse and fine grained all words tasks </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>larger values favor, whereas smaller values disfavor each pair of synsets.
</prevsent>
<prevsent>with the model in hand, we need to address two problems in order to use it for problems such as wsd.
</prevsent>
</prevsection>
<citsent citstr=" H93-1061 ">
first, in parameter estimation, we find values of the parameters that explain labeled corpus, suchas semcor (miller et al, 1993).<papid> H93-1061 </papid></citsent>
<aftsection>
<nextsent>once the parameters are fit, we use posterior inference to compute the posterior probability distribution of set of senses given set of unlabeled words in context, p(s |w).
</nextsent>
<nextsent>this distribution is used to predict the senses of the words.
</nextsent>
<nextsent>in this section, it will be useful to introduce the notation p?(s, w) to denote the empirical probabilities of observing the word-sense pair s, in the entire corpus: p?(s, w) = ? d,i ?(sd,i, s)?(wd,i, w)/ ? nd , where ?(x, y) = 1 if = and 0 otherwise.similarly, we will define p?(s) to denote the empirical probability of observing sense over the entire corpus: p?(s) = ? d,i ?(sd,i, s)/ ? nd . 3.1 word-sense parameters ?.
</nextsent>
<nextsent>fallback let wnw,s = 0 if ? and ? wn w,s = ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2533">
<title id=" W07-2059.xml">pubcd exponential family models for the coarse and fine grained all words tasks </title>
<section> parameter estimation.  </section>
<citcontext>
<prevsection>
<prevsent>using eq.
</prevsent>
<prevsent>(1), with ? = 0, we obtain p?(sd,wd) = exp {?
</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
d,iwd,i,sd,i } ? z?,nd . 273thus, p?(sd,wd) can be viewed as multino mial model with ? nd trials and |s| outcomes,parametrized by w,s. the maximum likelihood estimates in this model are w,s ? ln p?(s, w).this setting of the parameters corresponds precisely to the dominant-sensemodel (mccarthy et al, 2004).<papid> P04-1036 </papid></citsent>
<aftsection>
<nextsent>the resulting model is thus p?,n(s,w) = ? p?(si, wi) .
</nextsent>
<nextsent>(3) 3.2 sense co-occurrence parameters ?.
</nextsent>
<nextsent>unlike ?, it is impossible to find closed-form solution for the maximum-likelihood settings of ?.
</nextsent>
<nextsent>therefore, we turn to intuitive methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2534">
<title id=" W08-0209.xml">combining open source with research to re engineer a handson introductory nlp course </title>
<section> goals.  </section>
<citcontext>
<prevsection>
<prevsent>for example, we used an in-house hmm library written in for any hmm-based assignments and perl for some other assignments.
</prevsent>
<prevsent>as expected, such an approach requires students to familiarize themselves with different programming interface for each assignment and discourages student sto explore on their own.
</prevsent>
</prevsection>
<citsent citstr=" W02-0109 ">
to address this concern, we chose the python (python, 2007) programming language and the natural language toolkit (loper and bird, 2002), <papid> W02-0109 </papid>written entirely in python, for all our assignments and programming tasks.</citsent>
<aftsection>
<nextsent>we discuss our use of nltk in more detail in the next section.?
</nextsent>
<nextsent>real-world data &amp; corpora.
</nextsent>
<nextsent>in our previous course, students did not have access to anyof the corpora that are used in actual nlp research.
</nextsent>
<nextsent>we found this to be serious shortcoming and wanted to ensure that our new curriculum allowed students to use real corpora for evaluating their programming assignments.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2535">
<title id=" W08-0209.xml">combining open source with research to re engineer a handson introductory nlp course </title>
<section> future plans.  </section>
<citcontext>
<prevsection>
<prevsent>we believe that this is an important topic that should be included in the curriculum.
</prevsent>
<prevsent>we plan to do so in the context of lexical paraphrase acquisition or synonyms automatically from corpora, task that relies heavily on this notion of distributional similarity.
</prevsent>
</prevsection>
<citsent citstr=" P93-1024 ">
there has been lot of work in this area in the past years (pereira et al, 1993; <papid> P93-1024 </papid>gasperin etal., 2001; glickman and dagan, 2003; shimohata and sumita, 2005), much of which can be easily replicated using the python-nltk com bination.</citsent>
<aftsection>
<nextsent>this would allow for very hands-on treatment and would allow the students to gain insight into this important, but often omitted, idea from computational linguistics.
</nextsent>
<nextsent>our primacy goal was to design an introductory level natural language processing course for class of first year computer science and linguistics graduate students.
</nextsent>
<nextsent>we wanted the curriculum to encourage the students to approach solutions to problems with themind-set of researcher.
</nextsent>
<nextsent>to accomplish this, we relied on two basic ideas.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2536">
<title id=" W07-1520.xml">two tools for creating and visualizing sub sentential alignments of parallel text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in reality, of course, things are more complicated.
</prevsent>
<prevsent>one word in one language may have to be translated into several in the other or not at all, or several words may form conceptual unit that cannot be translated word for word.
</prevsent>
</prevsection>
<citsent citstr=" P06-1065 ">
because of its central role in building machine translation systems and because of the complexity of the task, sub-sentential alignment of parallel corpora continues to be an active area of research (e.g., moore et al, 2006; <papid> P06-1065 </papid>fraser and marcu, 2006), <papid> P06-1097 </papid>andthis implies continuing demand for manually created or human-verified gold standard alignments for development and evaluation purposes.we present here two tools that are designed to facilitate the process and allow human inspection of automatically aligned parallel corpora for the study of translation.</citsent>
<aftsection>
<nextsent>the first is web-based interface for manual sub-sentential alignment of parallel sentences.
</nextsent>
<nextsent>the second is an extension of the traditional keywords-in-context tools to the bilingual case.
</nextsent>
<nextsent>a distinctive feature of both tools is that they are based on an interactive process.
</nextsent>
<nextsent>rather than showing all alignment information at once, they hide most information most of the time and visualize alignment information only selectively and only on demand.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2537">
<title id=" W07-1520.xml">two tools for creating and visualizing sub sentential alignments of parallel text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in reality, of course, things are more complicated.
</prevsent>
<prevsent>one word in one language may have to be translated into several in the other or not at all, or several words may form conceptual unit that cannot be translated word for word.
</prevsent>
</prevsection>
<citsent citstr=" P06-1097 ">
because of its central role in building machine translation systems and because of the complexity of the task, sub-sentential alignment of parallel corpora continues to be an active area of research (e.g., moore et al, 2006; <papid> P06-1065 </papid>fraser and marcu, 2006), <papid> P06-1097 </papid>andthis implies continuing demand for manually created or human-verified gold standard alignments for development and evaluation purposes.we present here two tools that are designed to facilitate the process and allow human inspection of automatically aligned parallel corpora for the study of translation.</citsent>
<aftsection>
<nextsent>the first is web-based interface for manual sub-sentential alignment of parallel sentences.
</nextsent>
<nextsent>the second is an extension of the traditional keywords-in-context tools to the bilingual case.
</nextsent>
<nextsent>a distinctive feature of both tools is that they are based on an interactive process.
</nextsent>
<nextsent>rather than showing all alignment information at once, they hide most information most of the time and visualize alignment information only selectively and only on demand.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2538">
<title id=" W07-1513.xml">adding semantic role annotation to a corpus of written dutch </title>
<section> existing projects.  </section>
<citcontext>
<prevsection>
<prevsent>framenet reaches level of granularity in the specification of the semantic roles which mightbe desirable for certain applications (i.e. question answering).
</prevsent>
<prevsent>moreover, the predicates are linked to an underlying frame ontology that classifies the verbs within semantic hierarchy.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
on the other hand, despite the relevant work of gildea and jurafsky (2002), <papid> J02-3001 </papid>it is still an open issue whether framenet classes and frame elements can be obtained and used automatically because of the richness of the semantic structures employed (dzikovska et al, 2004).</citsent>
<aftsection>
<nextsent>furthermore, the framenet approach might raise problems with respect to uniformity of role labeling even if human annotators are involved.
</nextsent>
<nextsent>incompleteness, however, constitutes the biggest problem, i.e. several frame sand relations among frames are missing mainly because framenet is still underdevelopment.
</nextsent>
<nextsent>adopting the framenet lexicon for semantic annotation means contributing to its development with the addition of (language specific) and missing frames.
</nextsent>
<nextsent>in our study, we have assumed that the framenet classification even though it is based on english could be applicable to dutch as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2542">
<title id=" W07-1513.xml">adding semantic role annotation to a corpus of written dutch </title>
<section> the timbl classification system.  </section>
<citcontext>
<prevsection>
<prevsent>in choosing the feature set for our system, we mainly looked at previous research, especially systems that participated in the 2004 and 2005 conll shared tasks on semantic role labeling (carreras and ma`rquez, 2005).
</prevsent>
<prevsent>it is worth noting that none of the systems in the conll shared tasks used features extracted from dependency structures.
</prevsent>
</prevsection>
<citsent citstr=" C04-1186 ">
however, we encountered one system (hacioglu, 2004) <papid> C04-1186 </papid>that did not participate in the conll-shared task but did use the same data and was based on dependency structures.</citsent>
<aftsection>
<nextsent>the main difference with our system is that hacioglu did not use dependency parser to create the dependency trees, instead existing constituent trees were converted to dependency structures.
</nextsent>
<nextsent>furthermore, the system was trained and tested on english sentences.
</nextsent>
<nextsent>from features used in previous systems and some experimentation with timbl, we derived the following feature set.
</nextsent>
<nextsent>the first group of features describes the predicate (verb): (1) predicate stem - the verb stem, provided by alpino.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2544">
<title id=" W07-1008.xml">annotation of chemical named entities </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>small-molecule chemistry also plays role in biomedical natural language processing.
</prevsent>
<prevsent>pubmed has included abstracts from medicinal chemistry journals for long time, and is increasingly carrying other chemistry journals too.
</prevsent>
</prevsection>
<citsent citstr=" W04-3111 ">
both the genia corpus (kim et al, 2003) and the bioie cytochrome p450 corpus (kulick et al, 2004) <papid> W04-3111 </papid>come with named entity annotations that include proportion of chemicals, and at least few abstracts that are recognisable as chemistry abstracts.</citsent>
<aftsection>
<nextsent>chemical named entity recognition enables number of applications.
</nextsent>
<nextsent>linking chemical names to chemical structures, by mixture of database lookup and the parsing of systematic nomenclature, allows the creation of semantically enhanced articles, with benefits for readers.
</nextsent>
<nextsent>an example of this is shown inthe project prospect2 annotations by the royal society of chemistry (rsc).
</nextsent>
<nextsent>linking chemical ner to chemical information retrieval techniques allows corpora to be searched for chemicals with similar structures to query molecule, or chemicals that contain particular structural motif (corbett and murray-rust, 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2545">
<title id=" W07-1008.xml">annotation of chemical named entities </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an example of this is shown inthe project prospect2 annotations by the royal society of chemistry (rsc).
</prevsent>
<prevsent>linking chemical ner to chemical information retrieval techniques allows corpora to be searched for chemicals with similar structures to query molecule, or chemicals that contain particular structural motif (corbett and murray-rust, 2006).
</prevsent>
</prevsection>
<citsent citstr=" N04-2002 ">
with information extraction techniques, chemicals could be linked to their properties, applications and reactions, and with traditional gene/protein nlp techniques, it could be pos 1http://pubchem.ncbi.nlm.nih.gov/ 2http://www.projectprospect.org/ 57 sible to discover new links between chemical data and bio informatics data.a few chemical named entity recognition (cor bett and murray-rust, 2006; townsend et al, 2005; vasserman, 2004; <papid> N04-2002 </papid>kemp and lynch, 1998; sun etal., 2007) or classification (wilbur et al, 1999) systems have been published.</citsent>
<aftsection>
<nextsent>a plugin for the gatesystem3 will also recognise limited range of chemical entities.
</nextsent>
<nextsent>other named entity recognition or classification systems (narayanaswamy et al, 2003; torii et al, 2004; torii and vijay-shanker, 2002; spasic and ananiadou, 2004) sometimes include chemicals as well as genes, proteins and other biological entities.
</nextsent>
<nextsent>however, due to differences in corpora and the scope of the task, it is difficult to compare them.
</nextsent>
<nextsent>there has been no chemical equivalent of the jnlpba (kim et al, 2004) or bio creative (yeh et al, 2005) evaluations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2548">
<title id=" W07-1008.xml">annotation of chemical named entities </title>
<section> inter-annotator agreement.  </section>
<citcontext>
<prevsection>
<prevsent>demetriou and gaizauskas (2003) report an  score of 89% between two domain experts for task involving various aspects of protein science.
</prevsent>
<prevsent>morgan et al (2004) report an   score of87% between domain expert and systems developer for d. melanogaster gene names.
</prevsent>
</prevsection>
<citsent citstr=" W06-3328 ">
vlachos and gasperin (2006) <papid> W06-3328 </papid>produced revised version of the 59 guidelines for the task, and were able to achieve an   score of 91%, and kappa of 0.905, between computational linguist and domain expert.</citsent>
<aftsection>
<nextsent>3.2 subjects.
</nextsent>
<nextsent>three subjects took part in the study.
</nextsent>
<nextsent>subject was chemist and the main author of the guidelines.
</nextsent>
<nextsent>subject was another chemist, highly involved in the development of the guidelines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2553">
<title id=" W07-0724.xml">nrcs portage system for wmt 2007 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these include new scoring methods for phrase pairs, pruning of phrase tables based on significance, higher-order language model,adapted language models, and several new decoder and rescoring models.
</prevsent>
<prevsent>portage wasalso used in joint system developed in cooperation with systran.
</prevsent>
</prevsection>
<citsent citstr=" W07-0728 ">
the interested reader is referred to (simard et al, 2007).<papid> W07-0728 </papid>throughout this paper, let sj1 := s1 . . .</citsent>
<aftsection>
<nextsent>sj denote source sentence of length , ti1 := t1 . . .
</nextsent>
<nextsent>ti target sentence of length i, and s?
</nextsent>
<nextsent>and t?
</nextsent>
<nextsent>phrases in source and target language, respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2554">
<title id=" W07-0724.xml">nrcs portage system for wmt 2007 </title>
<section> baseline.  </section>
<citcontext>
<prevsection>
<prevsent>phrases in source and target language, respectively.
</prevsent>
<prevsent>as baseline for our experiments, we used version of portage corresponding to its state atthe time of the wmt 2006 shared task.
</prevsent>
</prevsection>
<citsent citstr=" W06-3118 ">
we provide basic description of this system here; for more details see (johnson et al, 2006).<papid> W06-3118 </papid>portage implements two-stage translation process: first, the decoder generates best lists, using basic set of models which arethen rescored with additional models in second step.</citsent>
<aftsection>
<nextsent>in the baseline system, the decoder uses the following models (or feature functions): ? one or several phrase table(s), which model the translation direction p(s? | t?).
</nextsent>
<nextsent>they are generated from the training corpus via the diag-and?
</nextsent>
<nextsent>method (koehn et al, 2003)<papid> N03-1017 </papid>and smoothed using kneser-ney smoothing (foster et al, 2006), ? <papid> W06-1607 </papid>one or several n-gram language model(s) trained with the srilm toolkit (stolcke, 2002); in the baseline experiments reported here, we used trigram model, ? distortion model which assigns penalty based on the number of source words which are skipped when generating new target phrase, ? word penalty.these different models are combined log linearly.</nextsent>
<nextsent>their weights are optimizedw.r.t. bleu score using the algorithm described in (och, 2003).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2555">
<title id=" W07-0724.xml">nrcs portage system for wmt 2007 </title>
<section> baseline.  </section>
<citcontext>
<prevsection>
<prevsent>in the baseline system, the decoder uses the following models (or feature functions): ? one or several phrase table(s), which model the translation direction p(s? | t?).
</prevsent>
<prevsent>they are generated from the training corpus via the diag-and?
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
method (koehn et al, 2003)<papid> N03-1017 </papid>and smoothed using kneser-ney smoothing (foster et al, 2006), ? <papid> W06-1607 </papid>one or several n-gram language model(s) trained with the srilm toolkit (stolcke, 2002); in the baseline experiments reported here, we used trigram model, ? distortion model which assigns penalty based on the number of source words which are skipped when generating new target phrase, ? word penalty.these different models are combined log linearly.</citsent>
<aftsection>
<nextsent>their weights are optimizedw.r.t. bleu score using the algorithm described in (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>this is done on the provided development corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2556">
<title id=" W07-0724.xml">nrcs portage system for wmt 2007 </title>
<section> baseline.  </section>
<citcontext>
<prevsection>
<prevsent>in the baseline system, the decoder uses the following models (or feature functions): ? one or several phrase table(s), which model the translation direction p(s? | t?).
</prevsent>
<prevsent>they are generated from the training corpus via the diag-and?
</prevsent>
</prevsection>
<citsent citstr=" W06-1607 ">
method (koehn et al, 2003)<papid> N03-1017 </papid>and smoothed using kneser-ney smoothing (foster et al, 2006), ? <papid> W06-1607 </papid>one or several n-gram language model(s) trained with the srilm toolkit (stolcke, 2002); in the baseline experiments reported here, we used trigram model, ? distortion model which assigns penalty based on the number of source words which are skipped when generating new target phrase, ? word penalty.these different models are combined log linearly.</citsent>
<aftsection>
<nextsent>their weights are optimizedw.r.t. bleu score using the algorithm described in (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>this is done on the provided development corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2557">
<title id=" W07-0724.xml">nrcs portage system for wmt 2007 </title>
<section> baseline.  </section>
<citcontext>
<prevsection>
<prevsent>they are generated from the training corpus via the diag-and?
</prevsent>
<prevsent>method (koehn et al, 2003)<papid> N03-1017 </papid>and smoothed using kneser-ney smoothing (foster et al, 2006), ? <papid> W06-1607 </papid>one or several n-gram language model(s) trained with the srilm toolkit (stolcke, 2002); in the baseline experiments reported here, we used trigram model, ? distortion model which assigns penalty based on the number of source words which are skipped when generating new target phrase, ? word penalty.these different models are combined log linearly.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
their weights are optimizedw.r.t. bleu score using the algorithm described in (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>this is done on the provided development corpus.
</nextsent>
<nextsent>the search algorithm implemented in the decoder is dynamic-programming beam-search algorithm.
</nextsent>
<nextsent>185after the decoding step, rescoring with additional models is performed.
</nextsent>
<nextsent>the baseline system generates 1,000-best list of alternative translations for each source sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2558">
<title id=" W07-0724.xml">nrcs portage system for wmt 2007 </title>
<section> baseline.  </section>
<citcontext>
<prevsection>
<prevsent>185after the decoding step, rescoring with additional models is performed.
</prevsent>
<prevsent>the baseline system generates 1,000-best list of alternative translations for each source sentence.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
these lists are rescored with the different models described above, character penalty, and three different features based on ibm models 1 and 2 (brownet al, 1993) <papid> J93-2003 </papid>calculated in both translation di rections.</citsent>
<aftsection>
<nextsent>the weights of these additional models and of the decoder models are again optimized to maximize bleu score.note that we did not use the decision-tree based distortion models described in (johnson et al, 2006) <papid> W06-3118 </papid>here because they did not improve translation quality.</nextsent>
<nextsent>in the following subsections, we will describe the new models added to the system for our wmt 2007 submissions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2561">
<title id=" W07-0724.xml">nrcs portage system for wmt 2007 </title>
<section> improvements in portage.  </section>
<citcontext>
<prevsection>
<prevsent>first, we used several types of phrase table smoothing in the wmt 2007 system because this proved helpful on other translation tasks: relative frequency estimates, kneser-ney- and zens-ney-smoothed probabilities (foster et al, 2006).<papid> W06-1607 </papid></prevsent>
<prevsent>furthermore, we added normalized joint probability estimates to the phrase translation model.</prevsent>
</prevsection>
<citsent citstr=" D07-1103 ">
the other three scores will be explained at the end of this subsection.we pruned the generated phrase tables following the method introduced in (johnson et al., 2007).<papid> D07-1103 </papid></citsent>
<aftsection>
<nextsent>this approach considers all phrase pairs (s?, t?)
</nextsent>
<nextsent>in the phrase table.
</nextsent>
<nextsent>the count c(s?, t?)of all sentence pairs containing (s?, t?)
</nextsent>
<nextsent>is determined, as well as the count of all source/target sentences containing s?/t?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2563">
<title id=" W07-0724.xml">nrcs portage system for wmt 2007 </title>
<section> improvements in portage.  </section>
<citcontext>
<prevsection>
<prevsent>the others are determined on the levelof words, phrases, and n-grams, and then combined into value for the whole sentence.
</prevsent>
<prevsent>all posterior probabilities are calculated over then best list, using the sentence probabilities which the baseline system assigns to the translationhypotheses.
</prevsent>
</prevsection>
<citsent citstr=" W06-3110 ">
for details on the posterior probabilities, see (ueffing and ney, 2007; zens and ney, 2006).<papid> W06-3110 </papid></citsent>
<aftsection>
<nextsent>this year, we increased the length of the -best lists from 1,000 to 5,000.
</nextsent>
<nextsent>3.4 post-processing.
</nextsent>
<nextsent>for true casing the translation output, we used the model described in (agbago et al, 2005).this model uses combination of statistical components, including an n-gram language model, case mapping model, and specialized language model for unknown words.
</nextsent>
<nextsent>the language model is 5-gram model trained on the wmt 2007 data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2564">
<title id=" W07-1712.xml">named entity recognition for ukrainian a resource light approach </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we conclude with the outlook for the future work.
</prevsent>
<prevsent>the existing ner systems use many sources in order to be able to extract nes from the text data.some of them relyon hand-written rules and pre compiled lists of city names, person names and other nes in given language, while others explore methods to automatically extract nes without prior knowledge.
</prevsent>
</prevsection>
<citsent citstr=" W02-2004 ">
in the first case, the gazette ers will in most cases improve ner results (carreras et al, 2002) <papid> W02-2004 </papid>but, unfortunately, they may not exist for language one is working on.</citsent>
<aftsection>
<nextsent>hand-written rules can also cover more nes but building such patterns will be very time-consuming process.
</nextsent>
<nextsent>there have been many methods applied to ner,varying from the statistical to the memory-based approaches.
</nextsent>
<nextsent>most work on ner has been focused on english but there are also approaches to other languages such as spanish (kozareva et al, 2005), german, or dutch.
</nextsent>
<nextsent>in addition, several competitions have been organized, with focus on multilingual ner (tjong kim sang, 2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2565">
<title id=" W07-1712.xml">named entity recognition for ukrainian a resource light approach </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>nevertheless, orthographic features can already be language-specific.
</prevsent>
<prevsent>for instance, capitalization is certainly very important for such languages as english or dutch but it might be less useful for german.
</prevsent>
</prevsection>
<citsent citstr=" W03-0428 ">
2sometimes, these types of features are referred to as word-external and word-internal (klein et al, 2003) <papid> W03-0428 </papid>the feature set of some ner methods (wu, 2002) also includes part-of-speech information and/orword prefixes and suffixes.</citsent>
<aftsection>
<nextsent>although this information (and especially lemmas) is very useful for the languages with rich morphology, it presupposes the existence of pos taggers forgiven language.
</nextsent>
<nextsent>another conclusion which can be drawn relates to the machine learning approaches.
</nextsent>
<nextsent>the best results have been received by applying ensemble methods (wu, 2002; florian, 2002; <papid> W02-2010 </papid>carreras et al, 2002).<papid> W02-2004 </papid>a very interesting work on named entity recognition task was reported by collins et al (1999) who used only few named entities to bootstrap more.</nextsent>
<nextsent>the other approach proposed recently makes use of the data extracted from the web (talukdar et al, 2006).<papid> W06-2919 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2566">
<title id=" W07-1712.xml">named entity recognition for ukrainian a resource light approach </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>although this information (and especially lemmas) is very useful for the languages with rich morphology, it presupposes the existence of pos taggers forgiven language.
</prevsent>
<prevsent>another conclusion which can be drawn relates to the machine learning approaches.
</prevsent>
</prevsection>
<citsent citstr=" W02-2010 ">
the best results have been received by applying ensemble methods (wu, 2002; florian, 2002; <papid> W02-2010 </papid>carreras et al, 2002).<papid> W02-2004 </papid>a very interesting work on named entity recognition task was reported by collins et al (1999) who used only few named entities to bootstrap more.</citsent>
<aftsection>
<nextsent>the other approach proposed recently makes use of the data extracted from the web (talukdar et al, 2006).<papid> W06-2919 </papid></nextsent>
<nextsent>by restricting themselves to the fixed context of the extracted named entities and by employing grammar inference techniques, the authors filter out the most useful patterns.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2568">
<title id=" W07-1712.xml">named entity recognition for ukrainian a resource light approach </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>another conclusion which can be drawn relates to the machine learning approaches.
</prevsent>
<prevsent>the best results have been received by applying ensemble methods (wu, 2002; florian, 2002; <papid> W02-2010 </papid>carreras et al, 2002).<papid> W02-2004 </papid>a very interesting work on named entity recognition task was reported by collins et al (1999) who used only few named entities to bootstrap more.</prevsent>
</prevsection>
<citsent citstr=" W06-2919 ">
the other approach proposed recently makes use of the data extracted from the web (talukdar et al, 2006).<papid> W06-2919 </papid></citsent>
<aftsection>
<nextsent>by restricting themselves to the fixed context of the extracted named entities and by employing grammar inference techniques, the authors filter out the most useful patterns.
</nextsent>
<nextsent>as they show, by applying such approach precision can already be largely boosted.
</nextsent>
<nextsent>pastra et al (2002) focused on the applicability of already existing resources in one language to an other.
</nextsent>
<nextsent>their case study was based on english and romanian, where system, originally developed for ner in english was adapted to romanian.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2570">
<title id=" W07-1712.xml">named entity recognition for ukrainian a resource light approach </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>for example, word ukraine?
</prevsent>
<prevsent>can belong to the category loc as well as to the category org (as it is part of complex named entity).
</prevsent>
</prevsection>
<citsent citstr=" W99-0613 ">
in addition, we would also like to explore the semi-supervised techniques such as co-training and self-training (collins and singer, 1999).<papid> W99-0613 </papid></citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2571">
<title id=" W07-2107.xml">wit web people search disambiguation using random walks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in fact, person names are highly ambiguous: (guha andgarg, 2004) reports that only 90.000 thousand different names are shared by 100 million people according to the u.s. census bureau.
</prevsent>
<prevsent>this creates the need to disambiguate the several referents typically found in the web pages returned by query forgiven person name.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
the semeval07 web people search challenge (artiles et al, 2007) <papid> W07-2012 </papid>formally evaluated systems on this task.</citsent>
<aftsection>
<nextsent>in this paper, we describe our work on random walks-based approach to disambiguating people in web search results, heavily influenced by (minkov et al, 2006).
</nextsent>
<nextsent>this particular model was chosen due to its elegance in seamlessly combining lexico-syntactic features local to given webpage with topological features derived from its place in the network formed by the hyper linked web pages returned by the query, to arrive at one single measure of similarity between any two pages.
</nextsent>
<nextsent>in nutshell, our approach 1) uses graph to model the web pages returned by the search engine query,2) discards irrelevant web pages using few simple hand-crafted heuristics, 3) computes similarity matrix for web pages using random walks over the graph, and 4) finally clusters the web pages given the similarity matrix.
</nextsent>
<nextsent>the next subsections detail these steps.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2572">
<title id=" W07-2107.xml">wit web people search disambiguation using random walks </title>
<section> proposed method.  </section>
<citcontext>
<prevsection>
<prevsent>let ltd = {l(x, y) : (x, y) ? ? (x) = td} be the set of possible labels for edges leaving nodes of type td.
</prevsent>
<prevsent>we require that the weights form probability distribution over ltd , i.e. ? lltd w(l) = 1 (1) we build an adjacency matrix of locally appropriate similarity between nodes as wij = { ? lkl w(lk) |(i,?)e:l(i,?)=lk| , (i, j) ? 0, otherwise (2) where wij is the ith-line and jth-column entry of , indexed by . equation 2 distributes uniformly the weight of edges of the same type leaving given node.
</prevsent>
</prevsection>
<citsent citstr=" N06-1061 ">
we could choose to distribute them otherwise, e.g. we could distribute the weights according to some string similarity function or language model (erkan, 2006), <papid> N06-1061 </papid>depending on the label.we associate the state of markov chain to every node of the graph, that is, to each node we associate the one-step probability (0)(j|i) of random walker traversing to an adjacent node j. these 481probabilities are expressed by the row stochastic matrix d1w , where is the diagonal degree matrix given by dii = ? wik.</citsent>
<aftsection>
<nextsent>the reinforced?
</nextsent>
<nextsent>similarity between two nodes in the graph is given by the t-step transition probability (t)(j|i), which can be simply computed by matrix power, i.e., (t)(j|i) = [(d1w )t]ij . note that should not be very large in our case.
</nextsent>
<nextsent>the probability distribution of an infinite random walk over the nodes, called the stationary distribution of the graph, is uninteresting to us for clustering purposes since it gives an information related to the global structure of the graph.
</nextsent>
<nextsent>it is often used as measure to rank the structural importance of the nodes in graph (page et al, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2574">
<title id=" W07-0726.xml">multiengine machine translation with an open source smt decoder </title>
<section> architectures for multi-engine mt.  </section>
<citcontext>
<prevsection>
<prevsent>as smt systems are trained on massive amounts of data, they are typically quite good at capturing implicit knowledge contained inco-occurrence statistics, which can serve as shallow replacement for the world knowledge that would be required for the resolution of ambiguities and the insertion of information that happens to be mis singin the source text but is required to generate well formed text in the target language.already before, decades of work went into the implementation of mt systems (typically rule-based)for frequently used language pairs1, and these systems quite often contain wealth of linguistic knowledge about the languages involved, such as fairly complete mechanisms for morphological and syntactic analysis and generation, as well as large number of bilingual lexical entries spanning many application domains.it is an interesting challenge to combine the different types of knowledge into integrated systems that could then exploit both explicit linguistic knowledge contained in the rules of one or several conventional mt system(s) and implicit knowledge that can be extracted from large amounts of text.the recently started euromatrix2 project will explore this integration of rule-based and statistical knowledge sources, and one of the approaches tobe investigated is the combination of existing rule based mt systems into multi-engine architecture.
</prevsent>
<prevsent>the work described in this paper is one of the first incarnations of such multi-engine architecture within the project, and careful analysis of the results will guide us in the choice of further steps within the project.
</prevsent>
</prevsection>
<citsent citstr=" A94-1016 ">
combinations of mt systems into multi-engine architectures have long tradition, starting perhaps with (frederking and nirenburg, 1994).<papid> A94-1016 </papid></citsent>
<aftsection>
<nextsent>multiengine systems can be roughly divided into simple 1see (hutchins et al, 2006) for list of commercial mt systems 2see http://www.euromatrix.net 193 figure 1: architecture for multi-engine mt driven by smt decoder architectures that try to select the best output from anumber of systems, but leave the individual hypotheses as is (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba et al, 2001; callison-burch and flournoy, 2001; akiba etal., 2002; <papid> C02-1076 </papid>nomoto, 2004; <papid> P04-1063 </papid>eisele, 2005) <papid> W05-0828 </papid>and more sophisticated setups that try to re combine the best parts from multiple hypotheses into new utterance that can be better than the best of the given candidates, as described in (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006; <papid> E06-1005 </papid>rosti et al, 2007).<papid> N07-1029 </papid>re combining multiple mt results requires finding the correspondences between alternative renderings of source-language expression proposed by different mt systems.</nextsent>
<nextsent>this is generally not straight forward, as different word order and errors in the output can make it hard to identify the alignment.still, we assume that good way to combine the various mt outcomes will need to involve word alignment between the mt output and the given source text, and hence specialized module for word alignment is central component of our setup.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2575">
<title id=" W07-0726.xml">multiengine machine translation with an open source smt decoder </title>
<section> architectures for multi-engine mt.  </section>
<citcontext>
<prevsection>
<prevsent>the work described in this paper is one of the first incarnations of such multi-engine architecture within the project, and careful analysis of the results will guide us in the choice of further steps within the project.
</prevsent>
<prevsent>combinations of mt systems into multi-engine architectures have long tradition, starting perhaps with (frederking and nirenburg, 1994).<papid> A94-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" C00-2122 ">
multiengine systems can be roughly divided into simple 1see (hutchins et al, 2006) for list of commercial mt systems 2see http://www.euromatrix.net 193 figure 1: architecture for multi-engine mt driven by smt decoder architectures that try to select the best output from anumber of systems, but leave the individual hypotheses as is (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba et al, 2001; callison-burch and flournoy, 2001; akiba etal., 2002; <papid> C02-1076 </papid>nomoto, 2004; <papid> P04-1063 </papid>eisele, 2005) <papid> W05-0828 </papid>and more sophisticated setups that try to re combine the best parts from multiple hypotheses into new utterance that can be better than the best of the given candidates, as described in (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006; <papid> E06-1005 </papid>rosti et al, 2007).<papid> N07-1029 </papid>re combining multiple mt results requires finding the correspondences between alternative renderings of source-language expression proposed by different mt systems.</citsent>
<aftsection>
<nextsent>this is generally not straight forward, as different word order and errors in the output can make it hard to identify the alignment.still, we assume that good way to combine the various mt outcomes will need to involve word alignment between the mt output and the given source text, and hence specialized module for word alignment is central component of our setup.
</nextsent>
<nextsent>additionally, recombination system needs way to pick the best combination of alternative buildingblocks; and when judging the quality of particular configuration, both the plausibility of the building blocks as such and their relation to the context need to be taken into account.
</nextsent>
<nextsent>the required optimization process is very similar to the search in asmt decoder that looks for naturally sounding combinations of highly probable partial translations.
</nextsent>
<nextsent>instead of implementing special-purpose search procedure from scratch, we transform the information contained in the mt output into form that is suit able as input for an existing smt decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2576">
<title id=" W07-0726.xml">multiengine machine translation with an open source smt decoder </title>
<section> architectures for multi-engine mt.  </section>
<citcontext>
<prevsection>
<prevsent>the work described in this paper is one of the first incarnations of such multi-engine architecture within the project, and careful analysis of the results will guide us in the choice of further steps within the project.
</prevsent>
<prevsent>combinations of mt systems into multi-engine architectures have long tradition, starting perhaps with (frederking and nirenburg, 1994).<papid> A94-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" C02-1076 ">
multiengine systems can be roughly divided into simple 1see (hutchins et al, 2006) for list of commercial mt systems 2see http://www.euromatrix.net 193 figure 1: architecture for multi-engine mt driven by smt decoder architectures that try to select the best output from anumber of systems, but leave the individual hypotheses as is (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba et al, 2001; callison-burch and flournoy, 2001; akiba etal., 2002; <papid> C02-1076 </papid>nomoto, 2004; <papid> P04-1063 </papid>eisele, 2005) <papid> W05-0828 </papid>and more sophisticated setups that try to re combine the best parts from multiple hypotheses into new utterance that can be better than the best of the given candidates, as described in (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006; <papid> E06-1005 </papid>rosti et al, 2007).<papid> N07-1029 </papid>re combining multiple mt results requires finding the correspondences between alternative renderings of source-language expression proposed by different mt systems.</citsent>
<aftsection>
<nextsent>this is generally not straight forward, as different word order and errors in the output can make it hard to identify the alignment.still, we assume that good way to combine the various mt outcomes will need to involve word alignment between the mt output and the given source text, and hence specialized module for word alignment is central component of our setup.
</nextsent>
<nextsent>additionally, recombination system needs way to pick the best combination of alternative buildingblocks; and when judging the quality of particular configuration, both the plausibility of the building blocks as such and their relation to the context need to be taken into account.
</nextsent>
<nextsent>the required optimization process is very similar to the search in asmt decoder that looks for naturally sounding combinations of highly probable partial translations.
</nextsent>
<nextsent>instead of implementing special-purpose search procedure from scratch, we transform the information contained in the mt output into form that is suit able as input for an existing smt decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2577">
<title id=" W07-0726.xml">multiengine machine translation with an open source smt decoder </title>
<section> architectures for multi-engine mt.  </section>
<citcontext>
<prevsection>
<prevsent>the work described in this paper is one of the first incarnations of such multi-engine architecture within the project, and careful analysis of the results will guide us in the choice of further steps within the project.
</prevsent>
<prevsent>combinations of mt systems into multi-engine architectures have long tradition, starting perhaps with (frederking and nirenburg, 1994).<papid> A94-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1063 ">
multiengine systems can be roughly divided into simple 1see (hutchins et al, 2006) for list of commercial mt systems 2see http://www.euromatrix.net 193 figure 1: architecture for multi-engine mt driven by smt decoder architectures that try to select the best output from anumber of systems, but leave the individual hypotheses as is (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba et al, 2001; callison-burch and flournoy, 2001; akiba etal., 2002; <papid> C02-1076 </papid>nomoto, 2004; <papid> P04-1063 </papid>eisele, 2005) <papid> W05-0828 </papid>and more sophisticated setups that try to re combine the best parts from multiple hypotheses into new utterance that can be better than the best of the given candidates, as described in (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006; <papid> E06-1005 </papid>rosti et al, 2007).<papid> N07-1029 </papid>re combining multiple mt results requires finding the correspondences between alternative renderings of source-language expression proposed by different mt systems.</citsent>
<aftsection>
<nextsent>this is generally not straight forward, as different word order and errors in the output can make it hard to identify the alignment.still, we assume that good way to combine the various mt outcomes will need to involve word alignment between the mt output and the given source text, and hence specialized module for word alignment is central component of our setup.
</nextsent>
<nextsent>additionally, recombination system needs way to pick the best combination of alternative buildingblocks; and when judging the quality of particular configuration, both the plausibility of the building blocks as such and their relation to the context need to be taken into account.
</nextsent>
<nextsent>the required optimization process is very similar to the search in asmt decoder that looks for naturally sounding combinations of highly probable partial translations.
</nextsent>
<nextsent>instead of implementing special-purpose search procedure from scratch, we transform the information contained in the mt output into form that is suit able as input for an existing smt decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2578">
<title id=" W07-0726.xml">multiengine machine translation with an open source smt decoder </title>
<section> architectures for multi-engine mt.  </section>
<citcontext>
<prevsection>
<prevsent>the work described in this paper is one of the first incarnations of such multi-engine architecture within the project, and careful analysis of the results will guide us in the choice of further steps within the project.
</prevsent>
<prevsent>combinations of mt systems into multi-engine architectures have long tradition, starting perhaps with (frederking and nirenburg, 1994).<papid> A94-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-0828 ">
multiengine systems can be roughly divided into simple 1see (hutchins et al, 2006) for list of commercial mt systems 2see http://www.euromatrix.net 193 figure 1: architecture for multi-engine mt driven by smt decoder architectures that try to select the best output from anumber of systems, but leave the individual hypotheses as is (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba et al, 2001; callison-burch and flournoy, 2001; akiba etal., 2002; <papid> C02-1076 </papid>nomoto, 2004; <papid> P04-1063 </papid>eisele, 2005) <papid> W05-0828 </papid>and more sophisticated setups that try to re combine the best parts from multiple hypotheses into new utterance that can be better than the best of the given candidates, as described in (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006; <papid> E06-1005 </papid>rosti et al, 2007).<papid> N07-1029 </papid>re combining multiple mt results requires finding the correspondences between alternative renderings of source-language expression proposed by different mt systems.</citsent>
<aftsection>
<nextsent>this is generally not straight forward, as different word order and errors in the output can make it hard to identify the alignment.still, we assume that good way to combine the various mt outcomes will need to involve word alignment between the mt output and the given source text, and hence specialized module for word alignment is central component of our setup.
</nextsent>
<nextsent>additionally, recombination system needs way to pick the best combination of alternative buildingblocks; and when judging the quality of particular configuration, both the plausibility of the building blocks as such and their relation to the context need to be taken into account.
</nextsent>
<nextsent>the required optimization process is very similar to the search in asmt decoder that looks for naturally sounding combinations of highly probable partial translations.
</nextsent>
<nextsent>instead of implementing special-purpose search procedure from scratch, we transform the information contained in the mt output into form that is suit able as input for an existing smt decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2579">
<title id=" W07-0726.xml">multiengine machine translation with an open source smt decoder </title>
<section> architectures for multi-engine mt.  </section>
<citcontext>
<prevsection>
<prevsent>the work described in this paper is one of the first incarnations of such multi-engine architecture within the project, and careful analysis of the results will guide us in the choice of further steps within the project.
</prevsent>
<prevsent>combinations of mt systems into multi-engine architectures have long tradition, starting perhaps with (frederking and nirenburg, 1994).<papid> A94-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-3026 ">
multiengine systems can be roughly divided into simple 1see (hutchins et al, 2006) for list of commercial mt systems 2see http://www.euromatrix.net 193 figure 1: architecture for multi-engine mt driven by smt decoder architectures that try to select the best output from anumber of systems, but leave the individual hypotheses as is (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba et al, 2001; callison-burch and flournoy, 2001; akiba etal., 2002; <papid> C02-1076 </papid>nomoto, 2004; <papid> P04-1063 </papid>eisele, 2005) <papid> W05-0828 </papid>and more sophisticated setups that try to re combine the best parts from multiple hypotheses into new utterance that can be better than the best of the given candidates, as described in (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006; <papid> E06-1005 </papid>rosti et al, 2007).<papid> N07-1029 </papid>re combining multiple mt results requires finding the correspondences between alternative renderings of source-language expression proposed by different mt systems.</citsent>
<aftsection>
<nextsent>this is generally not straight forward, as different word order and errors in the output can make it hard to identify the alignment.still, we assume that good way to combine the various mt outcomes will need to involve word alignment between the mt output and the given source text, and hence specialized module for word alignment is central component of our setup.
</nextsent>
<nextsent>additionally, recombination system needs way to pick the best combination of alternative buildingblocks; and when judging the quality of particular configuration, both the plausibility of the building blocks as such and their relation to the context need to be taken into account.
</nextsent>
<nextsent>the required optimization process is very similar to the search in asmt decoder that looks for naturally sounding combinations of highly probable partial translations.
</nextsent>
<nextsent>instead of implementing special-purpose search procedure from scratch, we transform the information contained in the mt output into form that is suit able as input for an existing smt decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2580">
<title id=" W07-0726.xml">multiengine machine translation with an open source smt decoder </title>
<section> architectures for multi-engine mt.  </section>
<citcontext>
<prevsection>
<prevsent>the work described in this paper is one of the first incarnations of such multi-engine architecture within the project, and careful analysis of the results will guide us in the choice of further steps within the project.
</prevsent>
<prevsent>combinations of mt systems into multi-engine architectures have long tradition, starting perhaps with (frederking and nirenburg, 1994).<papid> A94-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
multiengine systems can be roughly divided into simple 1see (hutchins et al, 2006) for list of commercial mt systems 2see http://www.euromatrix.net 193 figure 1: architecture for multi-engine mt driven by smt decoder architectures that try to select the best output from anumber of systems, but leave the individual hypotheses as is (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba et al, 2001; callison-burch and flournoy, 2001; akiba etal., 2002; <papid> C02-1076 </papid>nomoto, 2004; <papid> P04-1063 </papid>eisele, 2005) <papid> W05-0828 </papid>and more sophisticated setups that try to re combine the best parts from multiple hypotheses into new utterance that can be better than the best of the given candidates, as described in (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006; <papid> E06-1005 </papid>rosti et al, 2007).<papid> N07-1029 </papid>re combining multiple mt results requires finding the correspondences between alternative renderings of source-language expression proposed by different mt systems.</citsent>
<aftsection>
<nextsent>this is generally not straight forward, as different word order and errors in the output can make it hard to identify the alignment.still, we assume that good way to combine the various mt outcomes will need to involve word alignment between the mt output and the given source text, and hence specialized module for word alignment is central component of our setup.
</nextsent>
<nextsent>additionally, recombination system needs way to pick the best combination of alternative buildingblocks; and when judging the quality of particular configuration, both the plausibility of the building blocks as such and their relation to the context need to be taken into account.
</nextsent>
<nextsent>the required optimization process is very similar to the search in asmt decoder that looks for naturally sounding combinations of highly probable partial translations.
</nextsent>
<nextsent>instead of implementing special-purpose search procedure from scratch, we transform the information contained in the mt output into form that is suit able as input for an existing smt decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2581">
<title id=" W07-0726.xml">multiengine machine translation with an open source smt decoder </title>
<section> architectures for multi-engine mt.  </section>
<citcontext>
<prevsection>
<prevsent>the work described in this paper is one of the first incarnations of such multi-engine architecture within the project, and careful analysis of the results will guide us in the choice of further steps within the project.
</prevsent>
<prevsent>combinations of mt systems into multi-engine architectures have long tradition, starting perhaps with (frederking and nirenburg, 1994).<papid> A94-1016 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1029 ">
multiengine systems can be roughly divided into simple 1see (hutchins et al, 2006) for list of commercial mt systems 2see http://www.euromatrix.net 193 figure 1: architecture for multi-engine mt driven by smt decoder architectures that try to select the best output from anumber of systems, but leave the individual hypotheses as is (tidhar and kussner, 2000; <papid> C00-2122 </papid>akiba et al, 2001; callison-burch and flournoy, 2001; akiba etal., 2002; <papid> C02-1076 </papid>nomoto, 2004; <papid> P04-1063 </papid>eisele, 2005) <papid> W05-0828 </papid>and more sophisticated setups that try to re combine the best parts from multiple hypotheses into new utterance that can be better than the best of the given candidates, as described in (rayner and carter, 1997; hogan and frederking, 1998; bangalore et al, 2001; jayaraman and lavie, 2005; <papid> P05-3026 </papid>matusov et al, 2006; <papid> E06-1005 </papid>rosti et al, 2007).<papid> N07-1029 </papid>re combining multiple mt results requires finding the correspondences between alternative renderings of source-language expression proposed by different mt systems.</citsent>
<aftsection>
<nextsent>this is generally not straight forward, as different word order and errors in the output can make it hard to identify the alignment.still, we assume that good way to combine the various mt outcomes will need to involve word alignment between the mt output and the given source text, and hence specialized module for word alignment is central component of our setup.
</nextsent>
<nextsent>additionally, recombination system needs way to pick the best combination of alternative buildingblocks; and when judging the quality of particular configuration, both the plausibility of the building blocks as such and their relation to the context need to be taken into account.
</nextsent>
<nextsent>the required optimization process is very similar to the search in asmt decoder that looks for naturally sounding combinations of highly probable partial translations.
</nextsent>
<nextsent>instead of implementing special-purpose search procedure from scratch, we transform the information contained in the mt output into form that is suit able as input for an existing smt decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2582">
<title id=" W07-0726.xml">multiengine machine translation with an open source smt decoder </title>
<section> implementation details.  </section>
<citcontext>
<prevsection>
<prevsent>3see http://www.statmt.org/moses/ 194
</prevsent>
<prevsent>4.1 alignment of mt output.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the input text and the output text of the mt systems was aligned by means of giza++ (och and ney,2003), <papid> J03-1002 </papid>tool with which statistical models for alignment of parallel texts can be trained.</citsent>
<aftsection>
<nextsent>since training new models on merely short texts does not yield very accurate results, we applied method where text can be aligned based on existing models that have be entrained on the europarl corpus (koehn, 2005) beforehand.
</nextsent>
<nextsent>this was achieved by using modified version of giza++ that is able to load given models.
</nextsent>
<nextsent>the modified version of giza++ is embedded into client-server setup.
</nextsent>
<nextsent>the user can send two corresponding files to the server, and specify two models for both translation directions from which alignments should be generated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2583">
<title id=" W07-0726.xml">multiengine machine translation with an open source smt decoder </title>
<section> implementation details.  </section>
<citcontext>
<prevsection>
<prevsent>we then concatenated the phrase tables from the smt baseline system and the phrase tables obtained from the rule-based mt systems and augmented them by additional columns, one for each system used.
</prevsent>
<prevsent>with this additional information it is clear which of the mt systems phrase pair stems from,enabling us to assign relative weights to the contributions of the different systems.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the optimal weights for the different columns can then be assigned with the help of minimum error rate training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we compared the hybrid system to purely statistical baseline system as well as two rule-based systems.
</nextsent>
<nextsent>the only differences between the baseline system and our hybrid system are the phrase table ? the hybrid system includes more lexical entries than the baseline ? and the weights obtained from minimum error rate training.
</nextsent>
<nextsent>for statistical system, lexical coverage becomes an obstacle ? especially when the bilingual lexical entries are trained on documents from different domains.
</nextsent>
<nextsent>however, due to the distinct mechanisms used to generate these entries, rule-based systems and statistical systems usually differ in coverage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2584">
<title id=" W07-2203.xml">semi supervised training of a statistical parser from unlabeled partially bracketed data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, hockenmeier (2003) trains statistical parser based on combinatory categorial grammar (ccg) on the wsj ptb, but first maps the treebank to ccg derivationssemi-automatically.
</prevsent>
<prevsent>thirdly, many (lexical) parameter estimates do not generalize well between domains.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
for instance, gildea (2001) <papid> W01-0521 </papid>reports that wsj-derived bilexical parameters in collins?</citsent>
<aftsection>
<nextsent>(1999) model 1 parser contribute about 1% to parse selection accuracy when test datais in the same domain, but yield no improvement for test data selected from the brown corpus.
</nextsent>
<nextsent>tadayoshi et al (2005) adapt statistical parser trained on the wsj ptb to the biomedical domain by retraining on the genia corpus, augmented with manually corrected derivations in the same format.
</nextsent>
<nextsent>to make statistical parsing more viable for range of applications, we need to make more effective and flexible use of extant training data and minimize the cost of annotation for new data created to tune system to new domain.
</nextsent>
<nextsent>unsupervised methods for training parser shave been relatively unsuccessful to date, including expectation maximization (em) such as the inside-outside algorithm (ioa) over pcfgs (baker, 1979; prescher, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2586">
<title id=" W07-2203.xml">semi supervised training of a statistical parser from unlabeled partially bracketed data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to make statistical parsing more viable for range of applications, we need to make more effective and flexible use of extant training data and minimize the cost of annotation for new data created to tune system to new domain.
</prevsent>
<prevsent>unsupervised methods for training parser shave been relatively unsuccessful to date, including expectation maximization (em) such as the inside-outside algorithm (ioa) over pcfgs (baker, 1979; prescher, 2001).
</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
however, pereira and schabes (1992) <papid> P92-1017 </papid>adapted the ioa to apply over semi-supervised data (unlabeled bracket ings) extracted from the ptb.</citsent>
<aftsection>
<nextsent>they constrain the training data (parses) considered within the ioa to those consistent with the constituent boundaries defined by the bracketing.
</nextsent>
<nextsent>one advantage of this approach is that, although less information is derived from the treebank, it gen 23 eralizes better to parsers which make different representational assumptions, and it is easier, as pereira and schabes did, to map unlabeled bracketings to format more consistent with the target grammar.
</nextsent>
<nextsent>another is that the cost of annotation with unlabeled brackets should belower than that of developing representation ally richer treebank.
</nextsent>
<nextsent>more recently, both riezler et al (2002) <papid> P02-1035 </papid>and clark and curran (2004) <papid> P04-1014 </papid>have successfully trained maximum entropy parsing models utilizing all derivations in the model consistent with the annotation of the wsj ptb, weighting counts by the normalized probability of the associated derivation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2588">
<title id=" W07-2203.xml">semi supervised training of a statistical parser from unlabeled partially bracketed data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one advantage of this approach is that, although less information is derived from the treebank, it gen 23 eralizes better to parsers which make different representational assumptions, and it is easier, as pereira and schabes did, to map unlabeled bracketings to format more consistent with the target grammar.
</prevsent>
<prevsent>another is that the cost of annotation with unlabeled brackets should belower than that of developing representation ally richer treebank.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
more recently, both riezler et al (2002) <papid> P02-1035 </papid>and clark and curran (2004) <papid> P04-1014 </papid>have successfully trained maximum entropy parsing models utilizing all derivations in the model consistent with the annotation of the wsj ptb, weighting counts by the normalized probability of the associated derivation.</citsent>
<aftsection>
<nextsent>in this paper, we extend this line of investigation by utilizing only unlabeled and partial bracketing.we compare the performance of statistical parsing model trained from detailed tree bank with that of the same model trained withsemi-supervised techniques that require only unlabeled partially-bracketed data.
</nextsent>
<nextsent>we contrast an ioa-based em method for training pglr parser (inui et al, 1997), similar to the method applied by pereira and schabes to pcfgs, to arange of confidence-based semi-supervised methods described below.
</nextsent>
<nextsent>the ioa is generalization of the baum-welch or forward-backward algorithm, another instance of em, which can be used to train hidden markov models (hmms).elworthy (1994)<papid> A94-1009 </papid>and merialdo (1994) <papid> J94-2001 </papid>demonstrated that baum-welch does not necessarily improve the performance of an hmm part-ofspeech tagger when deployed in an unsupervised or semi-supervised setting.</nextsent>
<nextsent>these some what negative results, in contrast to those of pereira and schabes (1992), <papid> P92-1017 </papid>suggest that em techniques require fairly determinate training data to yield useful models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2589">
<title id=" W07-2203.xml">semi supervised training of a statistical parser from unlabeled partially bracketed data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one advantage of this approach is that, although less information is derived from the treebank, it gen 23 eralizes better to parsers which make different representational assumptions, and it is easier, as pereira and schabes did, to map unlabeled bracketings to format more consistent with the target grammar.
</prevsent>
<prevsent>another is that the cost of annotation with unlabeled brackets should belower than that of developing representation ally richer treebank.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
more recently, both riezler et al (2002) <papid> P02-1035 </papid>and clark and curran (2004) <papid> P04-1014 </papid>have successfully trained maximum entropy parsing models utilizing all derivations in the model consistent with the annotation of the wsj ptb, weighting counts by the normalized probability of the associated derivation.</citsent>
<aftsection>
<nextsent>in this paper, we extend this line of investigation by utilizing only unlabeled and partial bracketing.we compare the performance of statistical parsing model trained from detailed tree bank with that of the same model trained withsemi-supervised techniques that require only unlabeled partially-bracketed data.
</nextsent>
<nextsent>we contrast an ioa-based em method for training pglr parser (inui et al, 1997), similar to the method applied by pereira and schabes to pcfgs, to arange of confidence-based semi-supervised methods described below.
</nextsent>
<nextsent>the ioa is generalization of the baum-welch or forward-backward algorithm, another instance of em, which can be used to train hidden markov models (hmms).elworthy (1994)<papid> A94-1009 </papid>and merialdo (1994) <papid> J94-2001 </papid>demonstrated that baum-welch does not necessarily improve the performance of an hmm part-ofspeech tagger when deployed in an unsupervised or semi-supervised setting.</nextsent>
<nextsent>these some what negative results, in contrast to those of pereira and schabes (1992), <papid> P92-1017 </papid>suggest that em techniques require fairly determinate training data to yield useful models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2590">
<title id=" W07-2203.xml">semi supervised training of a statistical parser from unlabeled partially bracketed data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we extend this line of investigation by utilizing only unlabeled and partial bracketing.we compare the performance of statistical parsing model trained from detailed tree bank with that of the same model trained withsemi-supervised techniques that require only unlabeled partially-bracketed data.
</prevsent>
<prevsent>we contrast an ioa-based em method for training pglr parser (inui et al, 1997), similar to the method applied by pereira and schabes to pcfgs, to arange of confidence-based semi-supervised methods described below.
</prevsent>
</prevsection>
<citsent citstr=" A94-1009 ">
the ioa is generalization of the baum-welch or forward-backward algorithm, another instance of em, which can be used to train hidden markov models (hmms).elworthy (1994)<papid> A94-1009 </papid>and merialdo (1994) <papid> J94-2001 </papid>demonstrated that baum-welch does not necessarily improve the performance of an hmm part-ofspeech tagger when deployed in an unsupervised or semi-supervised setting.</citsent>
<aftsection>
<nextsent>these some what negative results, in contrast to those of pereira and schabes (1992), <papid> P92-1017 </papid>suggest that em techniques require fairly determinate training data to yield useful models.</nextsent>
<nextsent>another motivation to explore alternative non-iterative methods is that the derivation space over partially bracketed data can remain large ( 1k) while the confidence-based methods we explore have atotal processing overhead equivalent to one iteration of an ioa-based em algorithm.as we utilize an initial model to annotate additional training data, our methods are closely related to self-training methods described in the literature (e.g. mcclosky et al 2006, bacchiani et al 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2592">
<title id=" W07-2203.xml">semi supervised training of a statistical parser from unlabeled partially bracketed data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we extend this line of investigation by utilizing only unlabeled and partial bracketing.we compare the performance of statistical parsing model trained from detailed tree bank with that of the same model trained withsemi-supervised techniques that require only unlabeled partially-bracketed data.
</prevsent>
<prevsent>we contrast an ioa-based em method for training pglr parser (inui et al, 1997), similar to the method applied by pereira and schabes to pcfgs, to arange of confidence-based semi-supervised methods described below.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
the ioa is generalization of the baum-welch or forward-backward algorithm, another instance of em, which can be used to train hidden markov models (hmms).elworthy (1994)<papid> A94-1009 </papid>and merialdo (1994) <papid> J94-2001 </papid>demonstrated that baum-welch does not necessarily improve the performance of an hmm part-ofspeech tagger when deployed in an unsupervised or semi-supervised setting.</citsent>
<aftsection>
<nextsent>these some what negative results, in contrast to those of pereira and schabes (1992), <papid> P92-1017 </papid>suggest that em techniques require fairly determinate training data to yield useful models.</nextsent>
<nextsent>another motivation to explore alternative non-iterative methods is that the derivation space over partially bracketed data can remain large ( 1k) while the confidence-based methods we explore have atotal processing overhead equivalent to one iteration of an ioa-based em algorithm.as we utilize an initial model to annotate additional training data, our methods are closely related to self-training methods described in the literature (e.g. mcclosky et al 2006, bacchiani et al 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2595">
<title id=" W07-2203.xml">semi supervised training of a statistical parser from unlabeled partially bracketed data </title>
<section> the parsing system.  </section>
<citcontext>
<prevsection>
<prevsent>for example, if we compile out the attribute plural which has 2 possible values (plural or not) we will create 2 cfg rules for each rule with categories that contain plural.
</prevsent>
<prevsent>therefore, no information is lost during this process.
</prevsent>
</prevsection>
<citsent citstr=" J87-1004 ">
24 constructed from this backbone (tomita, 1987).<papid> J87-1004 </papid></citsent>
<aftsection>
<nextsent>the residue of features not incorporated into the backbone are unified on each reduce action and if unification fails the associated derivation paths also fail.
</nextsent>
<nextsent>the parser creates packed parse forest represented as graph-structuredstack.2 the parse selection model ranks complete derivations in the parse forest by computing the product of the probabilities of the (shift/reduce) parse actions (given lr state and look ahead item) which created each derivation (inui et al, 1997).
</nextsent>
<nextsent>estimating action probabilities, consists of a) recording an action history for the correct derivation in the parse forest (for each sentence in treebank), b) computing the frequency of each action over all action histories and c) normalizing these frequencies to determine probability distributions over conflicting (i.e. shift/reduce or reduce/reduce) actions.
</nextsent>
<nextsent>inui et al (1997) describe the probability model utilized in the system where transition is represented by the probability of moving from one stack state, i1, (an instance of the graph structured stack) to another, i. they estimate this probability using the stack-top state si1, next input symbol li and next action ai.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2600">
<title id=" W07-2203.xml">semi supervised training of a statistical parser from unlabeled partially bracketed data </title>
<section> the evaluation scheme.  </section>
<citcontext>
<prevsection>
<prevsent>relations are organized into hierarchy with the root node specifying an unlabeled dependency.
</prevsent>
<prevsent>the micro averaged precision, recall and f1 scores are calculated from the counts for all relations in the hierarchy which subsume the parser output.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
the microaveragedf1 score for the baseline system using this evaluation scheme is 75.61%, which ? over similar sets of relational dependencies ? is broadly comparable to recent evaluation results published byking and collaborators with their state-of-the art parsing system (briscoe et al, 2006).<papid> P06-4020 </papid></citsent>
<aftsection>
<nextsent>3the pipeline is the same as that used for creating though we do not automatically map the bracketing to be more consistent with the system grammar, instead, we simply removed unary brackets.
</nextsent>
<nextsent>26 4.1 wilcox on signed ranks test.
</nextsent>
<nextsent>the wilcox on signed ranks (wilcoxon, hence forth) test is non-parametric test for statistical significance that is appropriate when there is one data sample and several measures.
</nextsent>
<nextsent>for example, to compare the accuracy of two parsers over thesame dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2601">
<title id=" W07-2203.xml">semi supervised training of a statistical parser from unlabeled partially bracketed data </title>
<section> training from unlabeled.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, the summation and normalization performed for cfg rule within ioa is instead applied within such contexts.
</prevsent>
<prevsent>we can apply (our pglr normalization function with out laplace smoothing) to perform the required steps if we output the action history with the model prec rec f1 (z)baseline 77.05 74.22 75.61 il(?(s)) 76.02 73.40 74.69 0.0294 c1(il(?(s)), ?(s)) 77.05 74.22 75.61 0.4960 cn(il(?(s)), ?(s)) 77.51 74.80 76.13 0.0655 cr(il(?(s)), ?(s)) 77.73 74.98 76.33 0.0154 cp(il(?(s)), ?(s)) 76.45 73.91 75.16 0.2090 il(?(w )) 77.01 74.31 75.64 0.1038 c1(il(?(w )), ?(w )) 76.90 74.23 75.55 0.2546 cn(il(?(w )), ?(w )) 77.85 75.07 76.43 0.0017 cr(il(?(w )), ?(w )) 77.88 75.04 76.43 0.0011 cp(il(?(w )), ?(w )) 77.40 74.75 76.05 0.1335 il(?(sw )) 77.09 74.35 75.70 0.1003 c1(il(?(sw )), ?(sw )) 76.86 74.21 75.51 0.2483 cn(il(?(sw )), ?(sw )) 77.88 75.05 76.44 0.0048 cr(il(?(sw )), ?(sw )) 78.01 75.13 76.54 0.0007 cp(il(?(sw )), ?(sw )) 77.54 74.95 76.23 0.0618 table 2: performance of all models on depbank.represents the statistical significance of the system against the baseline model.
</prevsent>
</prevsection>
<citsent citstr=" W05-1517 ">
corresponding normalized inside-outside weight for each node (watson et al, 2005).<papid> W05-1517 </papid>we perform em starting from two initial mod els; either uniform probability model, il(), orfrom models derived from unambiguous training data, ?.</citsent>
<aftsection>
<nextsent>figure 1 shows the cross entropy decreasing monotonic ally from iteration 2 (asguaranteed by the em method) for different corpora and initial models.
</nextsent>
<nextsent>some models show an initial increase in cross-entropy from iteration 1to iteration 2, because the models are initial ized from subset of the data which is used to perform maximisation.
</nextsent>
<nextsent>cross-entropy increases, by definition, as we incorporate ambiguous data with more than one consistent derivation.
</nextsent>
<nextsent>performance over depbank can be seen in figures 2, 3, and 4 for each dataset s, and sw, respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2604">
<title id=" W07-2203.xml">semi supervised training of a statistical parser from unlabeled partially bracketed data </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>indeed, bracketed corpus provides flexibility as existing treebanks can be utilized despite the incompatibility between the system grammar and the underlying grammar of the treebank.
</prevsent>
<prevsent>mapping an incompatible annotated treebank to compatible partially-bracketed corpus is relatively easy compared to mapping to compatible fully-annotated corpus.
</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
an immediate benefit of this work is that (re)training parsers with incrementally-modifiedgrammars based on different linguistic frameworks should be much more straightforward ? see, for example oepen et al (2002) <papid> C02-2025 </papid>for good discussion of the problem.</citsent>
<aftsection>
<nextsent>furthermore, it suggests that it may be possible to usefully tune 30 parser to new domain with less annotation effort.
</nextsent>
<nextsent>our findings support those of elworthy (1994)<papid> A94-1009 </papid>and merialdo (1994) <papid> J94-2001 </papid>for pos tagging and suggest that em is not always the most suitable semi-supervised training method (espe cially when some in-domain training data is available).</nextsent>
<nextsent>the confidence-based methods were successful because the level of noise introduced did not outweigh the benefit of incorporating all derivations compatible with the bracketing in which the derivations contained high proportion of correct constituents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2608">
<title id=" W07-2203.xml">semi supervised training of a statistical parser from unlabeled partially bracketed data </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>our findings support those of elworthy (1994)<papid> A94-1009 </papid>and merialdo (1994) <papid> J94-2001 </papid>for pos tagging and suggest that em is not always the most suitable semi-supervised training method (espe cially when some in-domain training data is available).</prevsent>
<prevsent>the confidence-based methods were successful because the level of noise introduced did not outweigh the benefit of incorporating all derivations compatible with the bracketing in which the derivations contained high proportion of correct constituents.</prevsent>
</prevsection>
<citsent citstr=" P99-1010 ">
these findings may not hold if the level of bracketing available does not adequately constrain the parses considered ? see hwa (1999) <papid> P99-1010 </papid>for related investigation with em.</citsent>
<aftsection>
<nextsent>in future work we intend to further investigate the problem of tuning to new domain, given that minimal manual effort is major priority.
</nextsent>
<nextsent>we hope to develop methods which require dno manual annotation, for example, high precision automatic partial bracketing using phrase chunking and/or named entity recognition techniques might yield enough information to support the training methods developed here.
</nextsent>
<nextsent>finally, further experiments on weighting the contribution of each dataset might be beneficial.for instance, bacchiani et al (2006) demonstrate imrpovements in parsing accuracy with unsupervised adaptation from unannotated data and explore the effect of different weighting of counts derived from the supervised and unsupervised data.
</nextsent>
<nextsent>acknowledgements the first author is funded by the overseas research students awards scheme, and the poynton scholarship awarded by the cambridge australia trust in collaboration with the cambridge commonwealth trust.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2609">
<title id=" W08-0125.xml">modelling and detecting decisions in multiparty dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in collaborative and organized work environments,people share information and make decisions extensively through multi-party conversations, usually inthe form of meetings.
</prevsent>
<prevsent>when audio or video recordings are made of these meetings, it would be valuable to extract important information, such as the decisions that were made and the trains of reasoning that led to those decisions.
</prevsent>
</prevsection>
<citsent citstr=" N07-1004 ">
such capability would allow workgroups to keep track of courses of action that were shelved or rejected, and could allow new team members to get quickly up to speed.thanks to the recent availability of substantial meeting corpora such as the isl (burger et al, 2002), icsi (janin et al, 2004), and ami (mccowan et al., 2005) meeting corpora current research on the structure of decision-making dialogue and its use for automatic decision detection has helped to bring this vision closer to reality (verbree et al, 2006; hsueh and moore, 2007<papid> N07-1004 </papid>b).our aim here is to further that research by applying simple notion of dialogue structure to thetask of automatically detecting decisions in multiparty dialogue.</citsent>
<aftsection>
<nextsent>a central hypothesis underlying our approach is that this task is best addressed by taking into account the roles that different utterances play in the decision-making process.
</nextsent>
<nextsent>our claim is that this approach facilitates both the detection of regions of discourse where decisions are discussed and adopted, and also the identification of important aspects of the decision discussions themselves, thus opening the way to better and more concise report ing.in the next section, we describe prior work on related efforts, including our own work on action item detection (purver et al, 2007).
</nextsent>
<nextsent>sections 3 and 4 then present our decision annotation scheme, which distinguishes several types of decision-related dialogue acts (das), and the corpus used as data (in this studya section of the ami meeting corpus).
</nextsent>
<nextsent>next, in section 5, we describe our experimental methodology, including the basic conception of our classification approach, the features we used in classification, and our evaluation metrics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2613">
<title id=" W08-0125.xml">modelling and detecting decisions in multiparty dialogue </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to great extent, this is due to the fact that decisions have 156 been shown to be key aspect of meeting speech.
</prevsent>
<prevsent>user studies (lisowska et al, 2004; banerjee et al, 2005) have shown that participants regard decisions as one of the most important outputs of meeting,while whittaker et al (2006) found that the development of an automatic decision detection component is critical to the re-use of meeting archives.
</prevsent>
</prevsection>
<citsent citstr=" N03-2012 ">
identifying decision-making regions in meeting transcripts can thus be expected to support development of awide range of applications, such as automatic meeting assistants that process, understand, summarize and report the output of meetings; meeting tracking systems that assist in implementing decisions; and group decision support systems that, for instance, help in constructing group memory (romano and nunamaker, 2001; post et al, 2004; voss et al, 2007).previously researchers have focused on the interactive aspects of argumentative and decisionmaking dialogue, tackling issues such as the detection of agreement and disagreement and the levelof emotional involvement of conversational participants (hillard et al, 2003; <papid> N03-2012 </papid>wrede and shriberg, 2003; galley et al, 2004; <papid> P04-1085 </papid>gatica-perez et al, 2005).</citsent>
<aftsection>
<nextsent>from perhaps more formal perspective, verbree etal.
</nextsent>
<nextsent>(2006) have created an argumentation scheme intended to support automatic production of argument structure diagrams from decision-oriented meeting transcripts.
</nextsent>
<nextsent>only hsueh and moore (2007<papid> N07-1004 </papid>a), hsueh and moore (2007<papid> N07-1004 </papid>b),however, have specifically investigated the automatic detection of decisions.</nextsent>
<nextsent>using the ami meeting corpus, hsueh and moore (2007<papid> N07-1004 </papid>b) attempt to identify the dialogue acts(das) in meeting transcript that are decisionrelated?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2614">
<title id=" W08-0125.xml">modelling and detecting decisions in multiparty dialogue </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to great extent, this is due to the fact that decisions have 156 been shown to be key aspect of meeting speech.
</prevsent>
<prevsent>user studies (lisowska et al, 2004; banerjee et al, 2005) have shown that participants regard decisions as one of the most important outputs of meeting,while whittaker et al (2006) found that the development of an automatic decision detection component is critical to the re-use of meeting archives.
</prevsent>
</prevsection>
<citsent citstr=" P04-1085 ">
identifying decision-making regions in meeting transcripts can thus be expected to support development of awide range of applications, such as automatic meeting assistants that process, understand, summarize and report the output of meetings; meeting tracking systems that assist in implementing decisions; and group decision support systems that, for instance, help in constructing group memory (romano and nunamaker, 2001; post et al, 2004; voss et al, 2007).previously researchers have focused on the interactive aspects of argumentative and decisionmaking dialogue, tackling issues such as the detection of agreement and disagreement and the levelof emotional involvement of conversational participants (hillard et al, 2003; <papid> N03-2012 </papid>wrede and shriberg, 2003; galley et al, 2004; <papid> P04-1085 </papid>gatica-perez et al, 2005).</citsent>
<aftsection>
<nextsent>from perhaps more formal perspective, verbree etal.
</nextsent>
<nextsent>(2006) have created an argumentation scheme intended to support automatic production of argument structure diagrams from decision-oriented meeting transcripts.
</nextsent>
<nextsent>only hsueh and moore (2007<papid> N07-1004 </papid>a), hsueh and moore (2007<papid> N07-1004 </papid>b),however, have specifically investigated the automatic detection of decisions.</nextsent>
<nextsent>using the ami meeting corpus, hsueh and moore (2007<papid> N07-1004 </papid>b) attempt to identify the dialogue acts(das) in meeting transcript that are decisionrelated?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2692">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>these lection criteria for the best path are determined by the crf tagging model trained on the genia corpus.
</prevsent>
<prevsent>in this example, il-2/nn-protein-/- mediated/vvn activation/nn is selected as the best path.
</prevsent>
</prevsection>
<citsent citstr=" W04-3230 ">
following kudo et al (kudo et al, 2004), <papid> W04-3230 </papid>we adapted the core engine of the crf-based morphological analyzer, mecab1, to our pos/protein tagging task.</citsent>
<aftsection>
<nextsent>mecabs dictionary databases employ double arrays (aoe, 1989) which enable efficient lexical look-ups.
</nextsent>
<nextsent>the features used were: ? pos ? protein 1http://sourceforge.net/project/showfiles.phpgroup id=177856/ ? pos-protein ? bigram of adjacent pos ? bigram of adjacent protein ? bigram of adjacent pos-protein during the construction of the trellis, white space is considered as the delimiter unless otherwise stated within dictionary entries.
</nextsent>
<nextsent>this means that unknown tokens are character sequences without spaces.
</nextsent>
<nextsent>2.2.2 dictionary construct iona dictionary-based approach requires the dictionary to cover not only wide variety of biomedical terms but also entries with: ? all possible capitalization ? all possible linguistic inflections we constructed freely available, wide-coverageenglish word dictionary that satisfies these conditions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2693">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>it is not possible in reality to train the recognize ron target data, i.e., the test set, but it would be possible for users to add discovered protein names to the dictionary so that they could improve the overall performance of the recognizer without retraining.
</prevsent>
<prevsent>rule-based and procedural approaches are takenin (fukuda et al, 1998; franzen et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" C00-1030 ">
machine learning-based approaches are taken in (col lier et al, 2000; <papid> C00-1030 </papid>lee et al, 2003; <papid> W03-1305 </papid>kazama et al, 2002; <papid> W02-0301 </papid>tanabe and wilbur, 2002; yamamoto et al, 2003; <papid> W03-1309 </papid>tsuruoka, 2006; okanohara et al, 2006).<papid> P06-1059 </papid></citsent>
<aftsection>
<nextsent>machine learning algorithms used in these studies are naive bayes, c4.5, maximum entropy models, support vector machines, and conditional randomfields.
</nextsent>
<nextsent>most of these studies applied machine learning techniques to tokenized sentences.table 3 shows the scores reported by other systems.
</nextsent>
<nextsent>tsai et al (tsai et al, 2006) and zhou and su (zhou and su, 2004) <papid> W04-1219 </papid>combined machine learning techniques and hand-crafted rules.</nextsent>
<nextsent>tsai et al (tsai et al, 2006) applied crfs to the jnlpba-2004 data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2694">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>it is not possible in reality to train the recognize ron target data, i.e., the test set, but it would be possible for users to add discovered protein names to the dictionary so that they could improve the overall performance of the recognizer without retraining.
</prevsent>
<prevsent>rule-based and procedural approaches are takenin (fukuda et al, 1998; franzen et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" W03-1305 ">
machine learning-based approaches are taken in (col lier et al, 2000; <papid> C00-1030 </papid>lee et al, 2003; <papid> W03-1305 </papid>kazama et al, 2002; <papid> W02-0301 </papid>tanabe and wilbur, 2002; yamamoto et al, 2003; <papid> W03-1309 </papid>tsuruoka, 2006; okanohara et al, 2006).<papid> P06-1059 </papid></citsent>
<aftsection>
<nextsent>machine learning algorithms used in these studies are naive bayes, c4.5, maximum entropy models, support vector machines, and conditional randomfields.
</nextsent>
<nextsent>most of these studies applied machine learning techniques to tokenized sentences.table 3 shows the scores reported by other systems.
</nextsent>
<nextsent>tsai et al (tsai et al, 2006) and zhou and su (zhou and su, 2004) <papid> W04-1219 </papid>combined machine learning techniques and hand-crafted rules.</nextsent>
<nextsent>tsai et al (tsai et al, 2006) applied crfs to the jnlpba-2004 data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2695">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>it is not possible in reality to train the recognize ron target data, i.e., the test set, but it would be possible for users to add discovered protein names to the dictionary so that they could improve the overall performance of the recognizer without retraining.
</prevsent>
<prevsent>rule-based and procedural approaches are takenin (fukuda et al, 1998; franzen et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" W02-0301 ">
machine learning-based approaches are taken in (col lier et al, 2000; <papid> C00-1030 </papid>lee et al, 2003; <papid> W03-1305 </papid>kazama et al, 2002; <papid> W02-0301 </papid>tanabe and wilbur, 2002; yamamoto et al, 2003; <papid> W03-1309 </papid>tsuruoka, 2006; okanohara et al, 2006).<papid> P06-1059 </papid></citsent>
<aftsection>
<nextsent>machine learning algorithms used in these studies are naive bayes, c4.5, maximum entropy models, support vector machines, and conditional randomfields.
</nextsent>
<nextsent>most of these studies applied machine learning techniques to tokenized sentences.table 3 shows the scores reported by other systems.
</nextsent>
<nextsent>tsai et al (tsai et al, 2006) and zhou and su (zhou and su, 2004) <papid> W04-1219 </papid>combined machine learning techniques and hand-crafted rules.</nextsent>
<nextsent>tsai et al (tsai et al, 2006) applied crfs to the jnlpba-2004 data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2696">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>it is not possible in reality to train the recognize ron target data, i.e., the test set, but it would be possible for users to add discovered protein names to the dictionary so that they could improve the overall performance of the recognizer without retraining.
</prevsent>
<prevsent>rule-based and procedural approaches are takenin (fukuda et al, 1998; franzen et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" W03-1309 ">
machine learning-based approaches are taken in (col lier et al, 2000; <papid> C00-1030 </papid>lee et al, 2003; <papid> W03-1305 </papid>kazama et al, 2002; <papid> W02-0301 </papid>tanabe and wilbur, 2002; yamamoto et al, 2003; <papid> W03-1309 </papid>tsuruoka, 2006; okanohara et al, 2006).<papid> P06-1059 </papid></citsent>
<aftsection>
<nextsent>machine learning algorithms used in these studies are naive bayes, c4.5, maximum entropy models, support vector machines, and conditional randomfields.
</nextsent>
<nextsent>most of these studies applied machine learning techniques to tokenized sentences.table 3 shows the scores reported by other systems.
</nextsent>
<nextsent>tsai et al (tsai et al, 2006) and zhou and su (zhou and su, 2004) <papid> W04-1219 </papid>combined machine learning techniques and hand-crafted rules.</nextsent>
<nextsent>tsai et al (tsai et al, 2006) applied crfs to the jnlpba-2004 data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2697">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>it is not possible in reality to train the recognize ron target data, i.e., the test set, but it would be possible for users to add discovered protein names to the dictionary so that they could improve the overall performance of the recognizer without retraining.
</prevsent>
<prevsent>rule-based and procedural approaches are takenin (fukuda et al, 1998; franzen et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P06-1059 ">
machine learning-based approaches are taken in (col lier et al, 2000; <papid> C00-1030 </papid>lee et al, 2003; <papid> W03-1305 </papid>kazama et al, 2002; <papid> W02-0301 </papid>tanabe and wilbur, 2002; yamamoto et al, 2003; <papid> W03-1309 </papid>tsuruoka, 2006; okanohara et al, 2006).<papid> P06-1059 </papid></citsent>
<aftsection>
<nextsent>machine learning algorithms used in these studies are naive bayes, c4.5, maximum entropy models, support vector machines, and conditional randomfields.
</nextsent>
<nextsent>most of these studies applied machine learning techniques to tokenized sentences.table 3 shows the scores reported by other systems.
</nextsent>
<nextsent>tsai et al (tsai et al, 2006) and zhou and su (zhou and su, 2004) <papid> W04-1219 </papid>combined machine learning techniques and hand-crafted rules.</nextsent>
<nextsent>tsai et al (tsai et al, 2006) applied crfs to the jnlpba-2004 data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2698">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>machine learning algorithms used in these studies are naive bayes, c4.5, maximum entropy models, support vector machines, and conditional randomfields.
</prevsent>
<prevsent>most of these studies applied machine learning techniques to tokenized sentences.table 3 shows the scores reported by other systems.
</prevsent>
</prevsection>
<citsent citstr=" W04-1219 ">
tsai et al (tsai et al, 2006) and zhou and su (zhou and su, 2004) <papid> W04-1219 </papid>combined machine learning techniques and hand-crafted rules.</citsent>
<aftsection>
<nextsent>tsai et al (tsai et al, 2006) applied crfs to the jnlpba-2004 data.
</nextsent>
<nextsent>after applying pattern-based post-processing, they achieved the best f-score (75.12) among those reported so far.
</nextsent>
<nextsent>kim and yoon(kim and yoon, 2007) also applied heuristic post-processing.
</nextsent>
<nextsent>zhou and su (zhou and su, 2004) <papid> W04-1219 </papid>achieved an f-score of 73.77.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2712">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> acknowledgments.  </section>
<citcontext>
<prevsection>
<prevsent>further more, thanks to the dictionary-based ner approach, the upper bound performance using ideal dictionary enrichment, without any retraining of the models, yielded f-score 78.72.
</prevsent>
<prevsent>this research is partly supported by ec ist project fp6-028099 (bootstrep), whose manchester team is hosted by the jisc/bbsrc/epsrc sponsored national centre for text mining.
</prevsent>
</prevsection>
<citsent citstr=" W04-1217 ">
68 table 3: conventional results for protein name recognition authors p tsai et al(tsai et al, 2006) 71.31 79.36 75.12 our system 79.85 68.58 73.78 zhou and su(zhou and su, 2004) <papid> W04-1219 </papid>69.01 79.24 73.77 kim and yoon(kim and yoon, 2007) 75.82 71.02 73.34 okanohara et al(okanohara et al, 2006) <papid> P06-1059 </papid>77.74 68.92 73.07 tsuruoka(tsuruoka, 2006) 81.41 65.82 72.79 finkel et al(finkel et al, 2004) <papid> W04-1217 </papid>77.40 68.48 72.67 settles(settles, 2004) <papid> W04-1221 </papid>76.1 68.2 72.0 song et al(song et al, 2004) <papid> W04-1220 </papid>65.50 73.04 69.07 rossler(rossler, 2004) <papid> W04-1218 </papid>72.9 62.0 67.0 park et al(park et al, 2004) <papid> W04-1214 </papid>69.71 59.37 64.12</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2713">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> acknowledgments.  </section>
<citcontext>
<prevsection>
<prevsent>further more, thanks to the dictionary-based ner approach, the upper bound performance using ideal dictionary enrichment, without any retraining of the models, yielded f-score 78.72.
</prevsent>
<prevsent>this research is partly supported by ec ist project fp6-028099 (bootstrep), whose manchester team is hosted by the jisc/bbsrc/epsrc sponsored national centre for text mining.
</prevsent>
</prevsection>
<citsent citstr=" W04-1221 ">
68 table 3: conventional results for protein name recognition authors p tsai et al(tsai et al, 2006) 71.31 79.36 75.12 our system 79.85 68.58 73.78 zhou and su(zhou and su, 2004) <papid> W04-1219 </papid>69.01 79.24 73.77 kim and yoon(kim and yoon, 2007) 75.82 71.02 73.34 okanohara et al(okanohara et al, 2006) <papid> P06-1059 </papid>77.74 68.92 73.07 tsuruoka(tsuruoka, 2006) 81.41 65.82 72.79 finkel et al(finkel et al, 2004) <papid> W04-1217 </papid>77.40 68.48 72.67 settles(settles, 2004) <papid> W04-1221 </papid>76.1 68.2 72.0 song et al(song et al, 2004) <papid> W04-1220 </papid>65.50 73.04 69.07 rossler(rossler, 2004) <papid> W04-1218 </papid>72.9 62.0 67.0 park et al(park et al, 2004) <papid> W04-1214 </papid>69.71 59.37 64.12</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2714">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> acknowledgments.  </section>
<citcontext>
<prevsection>
<prevsent>further more, thanks to the dictionary-based ner approach, the upper bound performance using ideal dictionary enrichment, without any retraining of the models, yielded f-score 78.72.
</prevsent>
<prevsent>this research is partly supported by ec ist project fp6-028099 (bootstrep), whose manchester team is hosted by the jisc/bbsrc/epsrc sponsored national centre for text mining.
</prevsent>
</prevsection>
<citsent citstr=" W04-1220 ">
68 table 3: conventional results for protein name recognition authors p tsai et al(tsai et al, 2006) 71.31 79.36 75.12 our system 79.85 68.58 73.78 zhou and su(zhou and su, 2004) <papid> W04-1219 </papid>69.01 79.24 73.77 kim and yoon(kim and yoon, 2007) 75.82 71.02 73.34 okanohara et al(okanohara et al, 2006) <papid> P06-1059 </papid>77.74 68.92 73.07 tsuruoka(tsuruoka, 2006) 81.41 65.82 72.79 finkel et al(finkel et al, 2004) <papid> W04-1217 </papid>77.40 68.48 72.67 settles(settles, 2004) <papid> W04-1221 </papid>76.1 68.2 72.0 song et al(song et al, 2004) <papid> W04-1220 </papid>65.50 73.04 69.07 rossler(rossler, 2004) <papid> W04-1218 </papid>72.9 62.0 67.0 park et al(park et al, 2004) <papid> W04-1214 </papid>69.71 59.37 64.12</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2715">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> acknowledgments.  </section>
<citcontext>
<prevsection>
<prevsent>further more, thanks to the dictionary-based ner approach, the upper bound performance using ideal dictionary enrichment, without any retraining of the models, yielded f-score 78.72.
</prevsent>
<prevsent>this research is partly supported by ec ist project fp6-028099 (bootstrep), whose manchester team is hosted by the jisc/bbsrc/epsrc sponsored national centre for text mining.
</prevsent>
</prevsection>
<citsent citstr=" W04-1218 ">
68 table 3: conventional results for protein name recognition authors p tsai et al(tsai et al, 2006) 71.31 79.36 75.12 our system 79.85 68.58 73.78 zhou and su(zhou and su, 2004) <papid> W04-1219 </papid>69.01 79.24 73.77 kim and yoon(kim and yoon, 2007) 75.82 71.02 73.34 okanohara et al(okanohara et al, 2006) <papid> P06-1059 </papid>77.74 68.92 73.07 tsuruoka(tsuruoka, 2006) 81.41 65.82 72.79 finkel et al(finkel et al, 2004) <papid> W04-1217 </papid>77.40 68.48 72.67 settles(settles, 2004) <papid> W04-1221 </papid>76.1 68.2 72.0 song et al(song et al, 2004) <papid> W04-1220 </papid>65.50 73.04 69.07 rossler(rossler, 2004) <papid> W04-1218 </papid>72.9 62.0 67.0 park et al(park et al, 2004) <papid> W04-1214 </papid>69.71 59.37 64.12</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2716">
<title id=" W08-0609.xml">how to make the most of ne dictionaries in statistical ner </title>
<section> acknowledgments.  </section>
<citcontext>
<prevsection>
<prevsent>further more, thanks to the dictionary-based ner approach, the upper bound performance using ideal dictionary enrichment, without any retraining of the models, yielded f-score 78.72.
</prevsent>
<prevsent>this research is partly supported by ec ist project fp6-028099 (bootstrep), whose manchester team is hosted by the jisc/bbsrc/epsrc sponsored national centre for text mining.
</prevsent>
</prevsection>
<citsent citstr=" W04-1214 ">
68 table 3: conventional results for protein name recognition authors p tsai et al(tsai et al, 2006) 71.31 79.36 75.12 our system 79.85 68.58 73.78 zhou and su(zhou and su, 2004) <papid> W04-1219 </papid>69.01 79.24 73.77 kim and yoon(kim and yoon, 2007) 75.82 71.02 73.34 okanohara et al(okanohara et al, 2006) <papid> P06-1059 </papid>77.74 68.92 73.07 tsuruoka(tsuruoka, 2006) 81.41 65.82 72.79 finkel et al(finkel et al, 2004) <papid> W04-1217 </papid>77.40 68.48 72.67 settles(settles, 2004) <papid> W04-1221 </papid>76.1 68.2 72.0 song et al(song et al, 2004) <papid> W04-1220 </papid>65.50 73.04 69.07 rossler(rossler, 2004) <papid> W04-1218 </papid>72.9 62.0 67.0 park et al(park et al, 2004) <papid> W04-1214 </papid>69.71 59.37 64.12</citsent>
<aftsection>




</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2717">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also evaluated our method in the brown corpus to show the portability of our approach in another domain.
</prevsent>
<prevsent>domain portability is an important aspect of the applicability of nlp tools to practical tasks.
</prevsent>
</prevsection>
<citsent citstr=" P06-1043 ">
therefore, domain adaptation methods have recently been proposed in several nlp areas, e.g., word sense disambiguation (chan and ng, 2006), statistical parsing (lease and charniak, 2005; mcclosky et al , 2006), <papid> P06-1043 </papid>and lexicalized-grammar parsing (johnson and riezler, 2000; <papid> A00-2021 </papid>hara et al , 2005).</citsent>
<aftsection>
<nextsent>their aim was to re-train probabilistic model for new domain at low cost, and more or less successfully improved the accuracy for the domain.
</nextsent>
<nextsent>in this paper, we propose method for adapting an hpsg parser (miyao and tsujii, 2002; ninomiya et al , 2006) <papid> W06-1619 </papid>trained on the wsj section of the penn treebank (marcus et al , 1994) <papid> H94-1020 </papid>to biomedical do main.</nextsent>
<nextsent>our method re-trains probabilistic model of lexical entry assignments to words in target do main, and incorporates it into the original parser.the model of lexical entry assignments is loglinear model re-trained with machine learning features only of word n-grams.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2718">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also evaluated our method in the brown corpus to show the portability of our approach in another domain.
</prevsent>
<prevsent>domain portability is an important aspect of the applicability of nlp tools to practical tasks.
</prevsent>
</prevsection>
<citsent citstr=" A00-2021 ">
therefore, domain adaptation methods have recently been proposed in several nlp areas, e.g., word sense disambiguation (chan and ng, 2006), statistical parsing (lease and charniak, 2005; mcclosky et al , 2006), <papid> P06-1043 </papid>and lexicalized-grammar parsing (johnson and riezler, 2000; <papid> A00-2021 </papid>hara et al , 2005).</citsent>
<aftsection>
<nextsent>their aim was to re-train probabilistic model for new domain at low cost, and more or less successfully improved the accuracy for the domain.
</nextsent>
<nextsent>in this paper, we propose method for adapting an hpsg parser (miyao and tsujii, 2002; ninomiya et al , 2006) <papid> W06-1619 </papid>trained on the wsj section of the penn treebank (marcus et al , 1994) <papid> H94-1020 </papid>to biomedical do main.</nextsent>
<nextsent>our method re-trains probabilistic model of lexical entry assignments to words in target do main, and incorporates it into the original parser.the model of lexical entry assignments is loglinear model re-trained with machine learning features only of word n-grams.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2719">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, domain adaptation methods have recently been proposed in several nlp areas, e.g., word sense disambiguation (chan and ng, 2006), statistical parsing (lease and charniak, 2005; mcclosky et al , 2006), <papid> P06-1043 </papid>and lexicalized-grammar parsing (johnson and riezler, 2000; <papid> A00-2021 </papid>hara et al , 2005).</prevsent>
<prevsent>their aim was to re-train probabilistic model for new domain at low cost, and more or less successfully improved the accuracy for the domain.</prevsent>
</prevsection>
<citsent citstr=" W06-1619 ">
in this paper, we propose method for adapting an hpsg parser (miyao and tsujii, 2002; ninomiya et al , 2006) <papid> W06-1619 </papid>trained on the wsj section of the penn treebank (marcus et al , 1994) <papid> H94-1020 </papid>to biomedical do main.</citsent>
<aftsection>
<nextsent>our method re-trains probabilistic model of lexical entry assignments to words in target do main, and incorporates it into the original parser.the model of lexical entry assignments is loglinear model re-trained with machine learning features only of word n-grams.
</nextsent>
<nextsent>hence, the cost for the re-training is much lower than the cost of training the entire disambiguation model from scratch.in the experiments, we used an hpsg parser originally trained with the penn treebank, and evaluated disambiguation model re-trained with the genia treebank (kim et al , 2003), which consists of abstracts of biomedical papers.
</nextsent>
<nextsent>we varied the size of training corpus, and measured the transition of the parsing accuracy and the cost required for parameter estimation.
</nextsent>
<nextsent>for comparison, we also examined other possible approaches to adapting the same parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2720">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, domain adaptation methods have recently been proposed in several nlp areas, e.g., word sense disambiguation (chan and ng, 2006), statistical parsing (lease and charniak, 2005; mcclosky et al , 2006), <papid> P06-1043 </papid>and lexicalized-grammar parsing (johnson and riezler, 2000; <papid> A00-2021 </papid>hara et al , 2005).</prevsent>
<prevsent>their aim was to re-train probabilistic model for new domain at low cost, and more or less successfully improved the accuracy for the domain.</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
in this paper, we propose method for adapting an hpsg parser (miyao and tsujii, 2002; ninomiya et al , 2006) <papid> W06-1619 </papid>trained on the wsj section of the penn treebank (marcus et al , 1994) <papid> H94-1020 </papid>to biomedical do main.</citsent>
<aftsection>
<nextsent>our method re-trains probabilistic model of lexical entry assignments to words in target do main, and incorporates it into the original parser.the model of lexical entry assignments is loglinear model re-trained with machine learning features only of word n-grams.
</nextsent>
<nextsent>hence, the cost for the re-training is much lower than the cost of training the entire disambiguation model from scratch.in the experiments, we used an hpsg parser originally trained with the penn treebank, and evaluated disambiguation model re-trained with the genia treebank (kim et al , 2003), which consists of abstracts of biomedical papers.
</nextsent>
<nextsent>we varied the size of training corpus, and measured the transition of the parsing accuracy and the cost required for parameter estimation.
</nextsent>
<nextsent>for comparison, we also examined other possible approaches to adapting the same parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2721">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, combined with the existing adaptation method, our approach achieves accuracy as high as that obtained by re-training the original parser from scratch, but with much lower training cost.
</prevsent>
<prevsent>in this paper, we report these experimental results in detail, and discuss how disambiguation models of lexical entry assignments contribute to domain adaptation.in recent years, it has been shown that lexical in 11formation plays very important role for high accuracy of lexicalized grammar parsing.
</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
bangalore and joshi (1999) <papid> J99-2004 </papid>indicated that, correct disambiguation with super tagging, i.e., assignment of lexical entries before parsing, enabled effective ltag (lexical ized tree-adjoining grammar) parsing.</citsent>
<aftsection>
<nextsent>clark and curran (2004<papid> P04-1014 </papid>a) showed that super tagging reduced cost for training and execution of ccg (combinatory categorial grammar) parser while keeping ac curacy.</nextsent>
<nextsent>clark and curran (2006) <papid> N06-1019 </papid>showed that ccg parser trained on data derived from lexical category sequences alone was only slightly less accurate thanone trained on complete dependency structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2722">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we report these experimental results in detail, and discuss how disambiguation models of lexical entry assignments contribute to domain adaptation.in recent years, it has been shown that lexical in 11formation plays very important role for high accuracy of lexicalized grammar parsing.
</prevsent>
<prevsent>bangalore and joshi (1999) <papid> J99-2004 </papid>indicated that, correct disambiguation with super tagging, i.e., assignment of lexical entries before parsing, enabled effective ltag (lexical ized tree-adjoining grammar) parsing.</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
clark and curran (2004<papid> P04-1014 </papid>a) showed that super tagging reduced cost for training and execution of ccg (combinatory categorial grammar) parser while keeping ac curacy.</citsent>
<aftsection>
<nextsent>clark and curran (2006) <papid> N06-1019 </papid>showed that ccg parser trained on data derived from lexical category sequences alone was only slightly less accurate thanone trained on complete dependency structures.</nextsent>
<nextsent>ninomiya et al  (2006) <papid> W06-1619 </papid>also succeeded insignificantly improving speed and accuracy of hpsg parsing byusing super tagging probabilities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2724">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>bangalore and joshi (1999) <papid> J99-2004 </papid>indicated that, correct disambiguation with super tagging, i.e., assignment of lexical entries before parsing, enabled effective ltag (lexical ized tree-adjoining grammar) parsing.</prevsent>
<prevsent>clark and curran (2004<papid> P04-1014 </papid>a) showed that super tagging reduced cost for training and execution of ccg (combinatory categorial grammar) parser while keeping ac curacy.</prevsent>
</prevsection>
<citsent citstr=" N06-1019 ">
clark and curran (2006) <papid> N06-1019 </papid>showed that ccg parser trained on data derived from lexical category sequences alone was only slightly less accurate thanone trained on complete dependency structures.</citsent>
<aftsection>
<nextsent>ninomiya et al  (2006) <papid> W06-1619 </papid>also succeeded insignificantly improving speed and accuracy of hpsg parsing byusing super tagging probabilities.</nextsent>
<nextsent>these results indicate that the probability of lexical entry assignments is essential for parse disambiguation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2727">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> an hpsg parser.  </section>
<citcontext>
<prevsection>
<prevsent>after that, the application of grammar rules is done iteratively, and then we can finally obtain the parse tree as is shown in figure 2.
</prevsent>
<prevsent>in practice, since two or more parse candidates can be given for one sentence, disambiguation model gives probabilities to these candidates, and candidate given the highest probability is then chosen as correct parse.
</prevsent>
</prevsection>
<citsent citstr=" P05-1011 ">
12 the hpsg parser used in this study is ninomiya et al  (2006), <papid> W06-1619 </papid>which is based on enju (miyao and tsujii, 2005).<papid> P05-1011 </papid></citsent>
<aftsection>
<nextsent>lexical entries of enju were extracted from the penn treebank (marcus et al , 1994), <papid> H94-1020 </papid>which consists of sentences collected from the wall street journal (miyao et al , 2004).</nextsent>
<nextsent>the disambiguation model of enju was trained on the same treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2729">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> an hpsg parser.  </section>
<citcontext>
<prevsection>
<prevsent>lexical entries of enju were extracted from the penn treebank (marcus et al , 1994), <papid> H94-1020 </papid>which consists of sentences collected from the wall street journal (miyao et al , 2004).</prevsent>
<prevsent>the disambiguation model of enju was trained on the same treebank.</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the disambiguation model of enju is based on feature forest model (miyao and tsujii, 2002), which is log-linear model (berger et al , 1996) <papid> J96-1002 </papid>on packed forest structure.</citsent>
<aftsection>
<nextsent>the probability, e (tjw), of producing the parse result forgiven sentence = hw 1 ; :::; u is defined as e (tjw) = 1 s i lex (l jw; i)
</nextsent>
<nextsent>q syn (tjl); s = t2t (w) i lex (l jw; i)
</nextsent>
<nextsent>q syn (tjl) where = hl 1 ; :::; ui is list of lexical entries assigned to w, lex (l jw; i) is probabilistic model giving the probability that lexical entry i is assigned to word i , syn (tjl) is an un normalized log-linearmodel of tree construction and gives the possibility that parse candidate is produced from lexical entries l, and (w) is set of parse candidates assigned to w. with treebank of target domain as training data, model parameters of lex and syn are estimated so as to maximize the log-likelihood of the training data.
</nextsent>
<nextsent>probabilistic model lexis defined as log-linear model as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2741">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this section explores how our research is relevant to the previous works.
</prevsent>
<prevsent>our previous work (hara et al , 2005) and this research mainly focused on how to draw as much benefit from smaller amount of in-domain annotated data as possible.
</prevsent>
</prevsection>
<citsent citstr=" W06-2902 ">
titov and henderson (2006) <papid> W06-2902 </papid>also took this type of approach.</citsent>
<aftsection>
<nextsent>they first trained probabilistic model on original and target treebanks and used it to define kernel over parse trees.
</nextsent>
<nextsent>this kernel was used in large margin classifier trained on small set of data only from the target domain, and the classifier was then used for reranking the top 20 table 10: coverage of each training set for the brown corpus % of covered sentences for the target corpus training set al cf cg ck cl cm cn cp cr target treebank 74.99 % 49.13 % 50.00 % 47.97 % 49.08 % 29.66 % 53.51 % 64.01 % 8.57% ptb treebank 70.02 % 72.09 % 68.93 % 66.42 % 68.87 % 78.62 % 70.00 % 77.59 % 47.14 % target + ptb 79.77 % 74.71 % 71.47 % 71.59 % 70.45 % 80.00 % 72.70 % 80.39 % 52.86 % parses on the target domain.
</nextsent>
<nextsent>on the other hand, several studies have explore dhow to draw useful information from un labelled in domain data.
</nextsent>
<nextsent>roark and bacchiani (2003) <papid> N03-1027 </papid>adapted lexicalized pcfg by using maximum posteriori(map) estimation for handling un labelled adaptation data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2742">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this kernel was used in large margin classifier trained on small set of data only from the target domain, and the classifier was then used for reranking the top 20 table 10: coverage of each training set for the brown corpus % of covered sentences for the target corpus training set al cf cg ck cl cm cn cp cr target treebank 74.99 % 49.13 % 50.00 % 47.97 % 49.08 % 29.66 % 53.51 % 64.01 % 8.57% ptb treebank 70.02 % 72.09 % 68.93 % 66.42 % 68.87 % 78.62 % 70.00 % 77.59 % 47.14 % target + ptb 79.77 % 74.71 % 71.47 % 71.59 % 70.45 % 80.00 % 72.70 % 80.39 % 52.86 % parses on the target domain.
</prevsent>
<prevsent>on the other hand, several studies have explore dhow to draw useful information from un labelled in domain data.
</prevsent>
</prevsection>
<citsent citstr=" N03-1027 ">
roark and bacchiani (2003) <papid> N03-1027 </papid>adapted lexicalized pcfg by using maximum posteriori(map) estimation for handling un labelled adaptation data.</citsent>
<aftsection>
<nextsent>in the field of classifications, blitzer et al  (2006) <papid> W06-1615 </papid>utilized un labelled corpora to extract features of structural correspondences, and then adapted pos-tagger to biomedical domain.</nextsent>
<nextsent>steedman etal.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2743">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, several studies have explore dhow to draw useful information from un labelled in domain data.
</prevsent>
<prevsent>roark and bacchiani (2003) <papid> N03-1027 </papid>adapted lexicalized pcfg by using maximum posteriori(map) estimation for handling un labelled adaptation data.</prevsent>
</prevsection>
<citsent citstr=" W06-1615 ">
in the field of classifications, blitzer et al  (2006) <papid> W06-1615 </papid>utilized un labelled corpora to extract features of structural correspondences, and then adapted pos-tagger to biomedical domain.</citsent>
<aftsection>
<nextsent>steedman etal.
</nextsent>
<nextsent>(2003) utilized co-training parser for adaptation and showed that co-training is effective even across domains.
</nextsent>
<nextsent>mcclosky et al  (2006) <papid> P06-1043 </papid>adapted re-ranking parser to target domain by self-training the parser with un labelled data in the target domain.clegg and shepherd (2005) combined several existing parsers with voting schemes or parse selection, and then succeeded to gain the improvement of performance for biomedical domain.</nextsent>
<nextsent>although unsupervised methods can exploit large in-domaindata, the above studies could not obtain the accuracy as high as that for an original domain, even with the sufficient size of the un labelled corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2745">
<title id=" W07-2202.xml">evaluating impact of retraining a lexical disambiguation model on domain adaptation of an hpsg parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>szolovits (2003) extended lexical dictionary for target domain by predicting lexical information for words.
</prevsent>
<prevsent>they transplanted lexical in discernibility of words in an original domain into atarget domain.
</prevsent>
</prevsection>
<citsent citstr=" W04-1203 ">
pyysalo et al  (2004) <papid> W04-1203 </papid>showed the experimental results that this approach improved the performance of parser for link grammar.</citsent>
<aftsection>
<nextsent>since our re-trained model of lexical entry assignments was shown to be unable to cope with this problem properly (shown in section 4), the combination of the above approaches with our approach would be expected to bring further improvement.
</nextsent>
<nextsent>this paper presented an effective approach to adapting an hpsg parser trained on the penn treebank to biomedical domain.
</nextsent>
<nextsent>we trained probabilistic model of lexical entry assignments in target domain and then incorporated it into the original parser.
</nextsent>
<nextsent>the experimental results showed that this approach obtains higher parsing accuracy than the existing approach of adapting the structural modelalone.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2746">
<title id=" W07-1708.xml">multiword term extraction for bulgarian </title>
<section> filtering of term candidates.  </section>
<citcontext>
<prevsection>
<prevsent>of the word pair (a,b) containing the observed frequencies of (a,b), as fol lows: nii = the joint frequency of word and word b; nij = the frequency word occurs and word does not; nji = the frequency word occurs and word does not;njj = the frequency word and word do not oc cur; npp = the total number of ngrams; np1, np2, n1p, n2p are the marginal counts.
</prevsent>
<prevsent>the lexical association measures are formulas that relate the observed frequencies to the expected frequency (mij = (np1 * n1p) / npp) under the assumption that and are independent.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
for the current work, the log-likelihood coefficient has been employed (dunning, 1993), <papid> J93-1003 </papid>as it is reported to perform well among other scoring methods (daille, 1995).</citsent>
<aftsection>
<nextsent>log-likelihood = 2 * ?
</nextsent>
<nextsent>( nij * log( nij / mij) )this calculation over the text serves as an important technique in identifying term candidates.
</nextsent>
<nextsent>the larger the value of log-likelihood is, the stronger is the association between the two pairs of the string; consequently the string is the most probable candidate.
</nextsent>
<nextsent>statistic filtering is applied only to those term candidates extracted by the linguistic component.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2747">
<title id=" W07-1412.xml">shallow semantic in fast textual entailment rule learners </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in (tatu et al, 2005), deep semantic representation is paired with large amount of general and task specific semantic rules (explicit knowl edge).
</prevsent>
<prevsent>in (hickl et al, 2005), the machine learning model is trained over large amounts of examples (implicit knowledge).
</prevsent>
</prevsection>
<citsent citstr=" P06-1051 ">
in contrast, zanzotto&moschitti; (2006) <papid> P06-1051 </papid>proposed machine-learning based approach which reaches high accuracy by only using the available rte data.the key idea is the cross-pair similarity, i.e. similarity applied to two text and hypothesis pairs which considers the relations between the words in the two texts and between the words in the two hypotheses.this is obtained by using place holders to link there lated words.</citsent>
<aftsection>
<nextsent>results in (bar haim et al, 2006) are comparable with the best machine learning system when this latter is trained only on the rte exam ples.given the high potential of the cross-pair similarity model, for the rte3 challenge, we built on it by including some features of the two best systems: 1) we go towards deeper semantic representation of learning pairs including shallow semantic information in the syntactic trees using typed placeholders; 2) we reduce the computational cost of the cross-pairsimilarity computation algorithm to allow the learning over larger training sets.
</nextsent>
<nextsent>the paper is organized as follows: in sec.
</nextsent>
<nextsent>2 we review the cross-pair similarity model and its limits; in sec.
</nextsent>
<nextsent>3, we introduce our model for typed anchors;in sec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2752">
<title id=" W07-1412.xml">shallow semantic in fast textual entailment rule learners </title>
<section> cross-pair similarity and its limits.  </section>
<citcontext>
<prevsection>
<prevsent>there lated co-indexed representation is: t2 (s (pp (in in) (np (nn: automn))) (, ,) (np: (dt all) (nns: leaves)) (vp: (vbp: fall))) h2 (s (pp (in in) (np: (nn: automn))) (, ,) (np: (dt all) (nn maple) (nns: leaves)) (vp: (vbp: fall))) (e2) e1 and e2 share the following subtrees: t3 (s (np: (dt all) (nns: )) (vp: (vbp: ))) h3 (s (np: (dt all) (nn) (nns: )) (vp: (vbp: ))) (r3) this is the rewrite rule they have in common.
</prevsent>
<prevsent>then, e2 can be likely classified as valid entailment, as it shares the rule with the valid entailment e1.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
the cross-pair similarity model uses: (1) tree similarity measure kt (1), similarity measure kt (2) (collins and duffy, 2002) <papid> P02-1034 </papid>that counts the subtrees that 1 and 2 have in common; (2) substitution function t(?, c) that changes names of the place holders in tree according to set of correspondences between place holders c. given as the collection of all correspondences between the place holders of (t ?,h ?) and (t ??,h ??), the cross-pair similarity is computed as: ks((t ?, ?), (t ??, ??)) = maxcc(kt (t(t ?, c), t(t ??, c)) + kt (t(h ?, c), t(h ??, c))) (1) the cross-pair similarity ks , used in kernel-basedlearning model as the support vector machines, allows the exploitation of implicit true and false entailment rewrite rules described in the examples.</citsent>
<aftsection>
<nextsent>2.2 limits of the syntactic cross-pair similarity.
</nextsent>
<nextsent>learning from examples using cross-pair similarity is an attractive and effective approach.
</nextsent>
<nextsent>however,the cross-pair strategy, as any machine learning approach, is highly sensitive on how the examples are represented in the feature space, as this can strongly bias the performance of the classifier.consider for example the following text hypothesis pair, which can lead to an incorrect rule, if misused.
</nextsent>
<nextsent>t4 for my younger readers, chapman killed john lennon more than twenty years ago.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2754">
<title id=" W07-1412.xml">shallow semantic in fast textual entailment rule learners </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>more details on the algorithm and the decrease in computational cost may be found in (moschitti and zanzotto, 2007).
</prevsent>
<prevsent>5.1 experimental setup.
</prevsent>
</prevsection>
<citsent citstr=" E06-1015 ">
we implemented the novel cross-similarity kern elin the svm-light-tk (moschitti, 2006) <papid> E06-1015 </papid>that encodes the basic syntactic kernel kt in svm-light (joachims, 1999).</citsent>
<aftsection>
<nextsent>to assess the validity of the typed anchor model (tap), we evaluated two sets of systems: the plain and lexical-boosted systems.
</nextsent>
<nextsent>the plain systems are:-tap: our tree-kernel approach using typed place holders with climbing in the syntactic tree; -tree: the cross-similarity model described in sec.2.
</nextsent>
<nextsent>its comparison with tap indicates the effectiveness of our approaches; the lexical-boosted systems are:-lex: standard approach based on lexical overlap.
</nextsent>
<nextsent>the classifier uses as the only feature the lexical overlap similarity score described in (corley and mihalcea, 2005); -<papid> W05-1203 </papid>lex+tap: these configurations mix lexical overlap and our typed anchor approaches; -lex+tree: the comparison of this configuration withlex+tap should further support the validity of our intuition on typed anchors;preliminary experiments have been performed using two datasets: rte2 (the 1600 entailment pairs from the rte-2 challenge) and rte3d (the development dataset of this challenge).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2756">
<title id=" W07-1412.xml">shallow semantic in fast textual entailment rule learners </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the plain systems are:-tap: our tree-kernel approach using typed place holders with climbing in the syntactic tree; -tree: the cross-similarity model described in sec.2.
</prevsent>
<prevsent>its comparison with tap indicates the effectiveness of our approaches; the lexical-boosted systems are:-lex: standard approach based on lexical overlap.
</prevsent>
</prevsection>
<citsent citstr=" W05-1203 ">
the classifier uses as the only feature the lexical overlap similarity score described in (corley and mihalcea, 2005); -<papid> W05-1203 </papid>lex+tap: these configurations mix lexical overlap and our typed anchor approaches; -lex+tree: the comparison of this configuration withlex+tap should further support the validity of our intuition on typed anchors;preliminary experiments have been performed using two datasets: rte2 (the 1600 entailment pairs from the rte-2 challenge) and rte3d (the development dataset of this challenge).</citsent>
<aftsection>
<nextsent>we randomly divided this latter in two halves: rte3d0 and rte3d1.
</nextsent>
<nextsent>5.2 investigatory results analysis and.
</nextsent>
<nextsent>submission results table 2 reports the results of the experiments.
</nextsent>
<nextsent>the first column indicates the training set whereas the second one specifies the used test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2757">
<title id=" W07-1003.xml">the role of roles in classifying annotated biomedical text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>information about role concepts is integrated into the schema as attributes on nes.
</prevsent>
<prevsent>this work takes the investigation one step forward by showing empirical evidence for the usefulness of role concepts in practical application.in this paper, we focus on the task of text classification, proceeding under the simplifying assumption that given enough annotated training data fornes and their roles both can be automatically tagged with high accuracy.
</prevsent>
</prevsection>
<citsent citstr=" W04-3239 ">
in recent years there have been many studies on text classification using general methods (sebastiani, 2002; yang and liu, 1999) semi-structured texts (kudo and matsumoto, 2004), <papid> W04-3239 </papid>and xml classification (zaki and aggarwal, 2003).</citsent>
<aftsection>
<nextsent>other research has investigated the contribution of semantic information in the form of synonyms, syntax, etc. in text representation (bloehdorn and hotho, 2004; hotho et al, 2003; frurnkranz et al, 1998).
</nextsent>
<nextsent>feature selection (scott and matwin, 1999) has also been studied.
</nextsent>
<nextsent>the contribution of this paper is to provide an analysis and evaluation on the roles of nes in annotated text classification.
</nextsent>
<nextsent>the rest of this paper is organized as follows: in section 2, we outline the bio caster schema for the annotation of terms in biomedical text; section 3 presents description of the bio caster gold standard corpus; section 4 provides details of the method and experimental results of classification on the gold standard corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2758">
<title id=" W07-1402.xml">a semantic approach to textual entailment system evaluation and task analysis </title>
<section> the salsa rte system.  </section>
<citcontext>
<prevsection>
<prevsent>more details can be found in (burchardt and frank, 2006).
</prevsent>
<prevsent>2.1 architecture.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the salsa rte system is based on three maincomponents: (i) linguistic analysis of text and hypothesis based primarily on lfg and frame semantics (baker et al, 1998), (<papid> P98-1013 </papid>ii) the computation of amatch graph that encodes the semantic overlap?</citsent>
<aftsection>
<nextsent>between text and hypothesis, and (iii) statistical entailment decision.
</nextsent>
<nextsent>10 figure 1: linguistic analysis of leloir discovered the metabolism of carbon hydrates.
</nextsent>
<nextsent>(rte3-test).linguistic analysis.
</nextsent>
<nextsent>the primary linguistic analysis components are the probabilistic lfg grammar for english developed at parc (riezler et al., 2002), <papid> P02-1035 </papid>and combination of systems for frame semantic annotation: the probabilistic shalmaneser system for frame and role annotation (erk and pado, 2006), and the rule-based detour system for frame assignment (burchardt et al, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2759">
<title id=" W07-1402.xml">a semantic approach to textual entailment system evaluation and task analysis </title>
<section> the salsa rte system.  </section>
<citcontext>
<prevsection>
<prevsent>10 figure 1: linguistic analysis of leloir discovered the metabolism of carbon hydrates.
</prevsent>
<prevsent>(rte3-test).linguistic analysis.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
the primary linguistic analysis components are the probabilistic lfg grammar for english developed at parc (riezler et al., 2002), <papid> P02-1035 </papid>and combination of systems for frame semantic annotation: the probabilistic shalmaneser system for frame and role annotation (erk and pado, 2006), and the rule-based detour system for frame assignment (burchardt et al, 2005).</citsent>
<aftsection>
<nextsent>frame semantic analysis is especially interesting for the task of recognising textual entailment as it offers robust yet relatively precise measure for semantic overlap.
</nextsent>
<nextsent>the lexical meaning of predicates and their arguments are modelled in terms of frames and roles.
</nextsent>
<nextsent>a frame describes prototypical situation and roles identify participants involved in the situation.
</nextsent>
<nextsent>frames provide normalisations over divers surface realisations, including variations in argument structure realisations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2760">
<title id=" W07-1402.xml">a semantic approach to textual entailment system evaluation and task analysis </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>implies possibly kill?
</prevsent>
<prevsent>pragmatic principles seem to block entailment here.
</prevsent>
</prevsection>
<citsent citstr=" W05-1206 ">
the observation that standard logical entailment and textual entailment deviate in certain respects isnot surprising and has also been addressed in discussion initiated by (zaenen et al, 2005).<papid> W05-1206 </papid></citsent>
<aftsection>
<nextsent>still, there is no consensus regarding the precise mechanisms involved in the latter such as general principles of plausibility?
</nextsent>
<nextsent>or pragmatic principles.we conducted short annotation experiment during reading circle at our department on randomly chosen subset of 10 pairs from the rte 1 (includ ing (1) and (2) from above).
</nextsent>
<nextsent>a central result wasthat it is relatively easy to decide whether textual entailment holds while it often remained controversial 14 why this is the case.
</nextsent>
<nextsent>in particular, it seems difficult to tell whether an inference is strict or just plausible, and whether it relies on lexical knowledge only or whether world knowledge?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2761">
<title id=" W07-2013.xml">semeval2007 task 14 affective text </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>to perform the annotations, we developed web based annotation interface that displayed one headline at time, together with six slide bars for emotions and one slide bar for valence.
</prevsent>
<prevsent>the interval for the emotion annotations was set to [0, 100], where 0means the emotion is missing from the given head line, and 100 represents maximum emotional load.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
the interval for the valence annotations was set to [100, 100], where 0 represents neutral headline, 100 represents highly negative headline, and 100 corresponds to highly positive headline.unlike previous annotations of sentiment or subjectivity (wiebe et al, 2005; pang and lee, 2004), <papid> P04-1035 </papid>which typically relied on binary 0/1 annotations, we decided to use finer-grained scale, hence allowing the annotators to select different degrees of emotional load.</citsent>
<aftsection>
<nextsent>the test dataset was independently labeled by six annotators.
</nextsent>
<nextsent>the annotators were instructed to select the appropriate emotions for each headline based on the presence of words or phrases with emotional content, as well as the overall feeling invoked bythe headline.
</nextsent>
<nextsent>annotation examples were also provided, including examples of headlines bearing twoor more emotions to illustrate the case where several emotions were jointly applicable.
</nextsent>
<nextsent>finally, the annotators were encouraged to follow their first in tuition,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2762">
<title id=" W07-2013.xml">semeval2007 task 14 affective text </title>
<section> participating systems.  </section>
<citcontext>
<prevsection>
<prevsent>the system uses three main kinds of knowledge: list of sentiment-bearing words, list of valence shift ers and set of rules that define the scope and the result of the combination of sentiment-bearing words and valence shifters.
</prevsent>
<prevsent>the unigrams used for sentence/headline classification were learned from wordnet dictionary entries.
</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
in order to take advantage of the special properties of wordnet glosses and relations, we developed system that used thelist of human-annotated adjectives from (hatzivas siloglou and mckeown, 1997) <papid> P97-1023 </papid>as seed list and learned additional unigrams from wordnet synsets and glosses.</citsent>
<aftsection>
<nextsent>the list was then expanded by adding to it all the words annotated with positive or negative tags in the general inquirer.
</nextsent>
<nextsent>each unigram in the resulting list had the degree of membership in the category of positive or negative sentiment assigned to it using the fuzzy net overlap score method described in the teams earlier work (andreevskaia and bergler, 2006).
</nextsent>
<nextsent>only words with fuzzy member ship score not equal to zero were retained in thelist.
</nextsent>
<nextsent>the resulting list contained 10,809 sentiment bearing words of different parts of speech.the fuzzy net overlap score counts were complemented with the capability to discern and take into account some relevant elements of syntactic structure of the sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2763">
<title id=" W08-0309.xml">further meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we validate our manual evaluation methodology by measuring intra- and inter-annotatoragreement, and collecting timing information.
</prevsent>
<prevsent>this paper presents the results the shared tasks of the 2008 acl workshop on statistical machine trans-.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
lation, which builds on two past workshops (koehn andmonz, 2006; <papid> W06-3114 </papid>callison-burch et al , 2007).</citsent>
<aftsection>
<nextsent>there were two shared tasks this year: translation task which evaluated translation between 10 pairs of european languages, and an evaluation task which examines automatic evaluation metrics.
</nextsent>
<nextsent>there were number of differences between this years workshop and last years workshop: ? test set selection ? instead of creating our test set by reserving portion of the training data, we instead hired translators to translate set of newspaper articles from number of different sources.
</nextsent>
<nextsent>this out-of-domain test set contrasts with the in-domain europarl test set.?
</nextsent>
<nextsent>new language pairs ? we evaluated the quality of hungarian-english machine translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2764">
<title id=" W08-0309.xml">further meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our rationale behind investing considerable sum to create the news test setwas that we believe that it more accurately represents the quality of systems?
</prevsent>
<prevsent>translations than when we simply hold out portion of the training dataas the test set, as with the europarl set.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
for instance, statistical systems are heavily optimized to their training data, and do not perform as well on out-of-domain data (koehn and schroeder, 2007).<papid> W07-0733 </papid></citsent>
<aftsection>
<nextsent>having both the news test set and the europarl test set al ows us to contrast the performance of systems on in-domain and out-of-domain data, and provides fairer comparison between systems trained on the europarl corpus and systems that were developed without it.
</nextsent>
<nextsent>to lower the barrier of entry for newcomers to the field, we provided complete baseline mt system, along with data resources.
</nextsent>
<nextsent>we provided: ? sentence-aligned training corpora ? language model data ? development and dev-test sets?
</nextsent>
<nextsent>moses open source toolkit for phrase-based statistical translation (koehn et al , 2007) the performance of this baseline system is similar to the best submissions in last years shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2765">
<title id=" W08-0309.xml">further meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for czech and hungarian we use other available parallel corpora.
</prevsent>
<prevsent>note that the number of words is computed based on the provided tokenizer and that the number of distinct words is the based on lower cased tokens.
</prevsent>
</prevsection>
<citsent citstr=" P05-3026 ">
73 id participant bbn-combo bbn system combination (rosti et al , 2008) cmu-combo carnegie mellon university system combination (jayaraman and lavie, 2005) <papid> P05-3026 </papid>cmu-gimpel carnegie mellon university gimpel (gimpel and smith, 2008) cmu-smt carnegie mellon university smt (bach et al , 2008) cmu-statxfer carnegie mellon university stat-xfer (hanneman et al , 2008) cu-tectomt charles university tectomt (zabokrtsky et al , 2008) cu-bojar charles university bojar (bojar and hajic?, 2008) cued cambridge university (blackwood et al , 2008) dcu dublin city university (tinsley et al , 2008) limsi limsi (dechelotte et al , 2008) liu linkoping university (stymne et al , 2008) lium-systran lium / systran (schwenk et al , 2008) mlogic morphologic (novak et al , 2008) pct commercial mt provider from the czech republic rbmt16 babel fish, lingenio, lucy, open logos, promt, sdl (ordering anonymized) saar university of saarbruecken (eisele et al , 2008) systran systran (dugast et al , 2008) ucb university of california at berkeley (nakov, 2008) ucl university college london (wang and shawe-taylor, 2008) uedin university of edinburgh (koehn et al , 2008) uedin-combo university of edinburgh system combination (josh schroeder) umd university of maryland (dyer, 2007) upc universitat politecnica de catalunya, barcelona (khalilov et al , 2008) uw university of washington (axelrod et al , 2008) xerox xerox research centre europe (nikoulina and dymetman, 2008) table 2: participants in the shared translation task.</citsent>
<aftsection>
<nextsent>not all groups participated in all language pairs.
</nextsent>
<nextsent>74 the human judgments to validate automatic metrics.manual evaluation is time consuming, and it requires monumental effort to conduct it on the scale of our workshop.
</nextsent>
<nextsent>we distributed the workload across number of people, including shared task participants, interested volunteers, and small number of paid annotators.
</nextsent>
<nextsent>more than 100 people participated in the manual evaluation, with 75 people putting in more than an hours worth of effort, and 25 putting in more than four hours.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2766">
<title id=" W08-0309.xml">further meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 2 illustrates how the source and reference phrases are highlighted via automatic word alignments.
</prevsent>
<prevsent>the same is done for sentence and each of the system translations.
</prevsent>
</prevsection>
<citsent citstr=" P05-1038 ">
the english, french, german and spanish test sets were automatically parsed using high quality parsers for those languages (bikel, 2002; arun and keller, 2005; <papid> P05-1038 </papid>dubey, 2005; <papid> P05-1039 </papid>bick, 2006).</citsent>
<aftsection>
<nextsent>the word alignments were created with giza++ (och and ney, 2003) <papid> J03-1002 </papid>applied to parallel corpus containing the complete europarl training data, plus sets of 4,051 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations.</nextsent>
<nextsent>the phrases in the translations were located using standard phrase extraction techniques (koehn et al , 2003).<papid> N03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2767">
<title id=" W08-0309.xml">further meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 2 illustrates how the source and reference phrases are highlighted via automatic word alignments.
</prevsent>
<prevsent>the same is done for sentence and each of the system translations.
</prevsent>
</prevsection>
<citsent citstr=" P05-1039 ">
the english, french, german and spanish test sets were automatically parsed using high quality parsers for those languages (bikel, 2002; arun and keller, 2005; <papid> P05-1038 </papid>dubey, 2005; <papid> P05-1039 </papid>bick, 2006).</citsent>
<aftsection>
<nextsent>the word alignments were created with giza++ (och and ney, 2003) <papid> J03-1002 </papid>applied to parallel corpus containing the complete europarl training data, plus sets of 4,051 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations.</nextsent>
<nextsent>the phrases in the translations were located using standard phrase extraction techniques (koehn et al , 2003).<papid> N03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2768">
<title id=" W08-0309.xml">further meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the same is done for sentence and each of the system translations.
</prevsent>
<prevsent>the english, french, german and spanish test sets were automatically parsed using high quality parsers for those languages (bikel, 2002; arun and keller, 2005; <papid> P05-1038 </papid>dubey, 2005; <papid> P05-1039 </papid>bick, 2006).</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the word alignments were created with giza++ (och and ney, 2003) <papid> J03-1002 </papid>applied to parallel corpus containing the complete europarl training data, plus sets of 4,051 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations.</citsent>
<aftsection>
<nextsent>the phrases in the translations were located using standard phrase extraction techniques (koehn et al , 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>because the word-alignments were created automatically, and because the phrase extraction is heuristic, the phrases that were selected may not exactly correspond to the translations of the selected source phrase.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2769">
<title id=" W08-0309.xml">further meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the english, french, german and spanish test sets were automatically parsed using high quality parsers for those languages (bikel, 2002; arun and keller, 2005; <papid> P05-1038 </papid>dubey, 2005; <papid> P05-1039 </papid>bick, 2006).</prevsent>
<prevsent>the word alignments were created with giza++ (och and ney, 2003) <papid> J03-1002 </papid>applied to parallel corpus containing the complete europarl training data, plus sets of 4,051 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the phrases in the translations were located using standard phrase extraction techniques (koehn et al , 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>because the word-alignments were created automatically, and because the phrase extraction is heuristic, the phrases that were selected may not exactly correspond to the translations of the selected source phrase.
</nextsent>
<nextsent>we noted this in the instructions to judges: rank each constituent translation from best to worst relative to the other choices(ties are allowed).
</nextsent>
<nextsent>grade only the highlighted part of each translation.please note that segments are selected automatically, and they should be taken asan approximate guide.
</nextsent>
<nextsent>they might include extra words that are not in the actual alignment, or miss words on either end.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2770">
<title id=" W08-0309.xml">further meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we continued the shared task which we debuted last year, by examining how well various automatic metrics correlate with human judgments.
</prevsent>
<prevsent>in addition to examining how well the automatic evaluation metrics predict human judgments at thesystem-level, this year we have also started to measure their ability to predict sentence-level judgments.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the automatic metrics that were evaluated in this years shared task were the following: ? bleu (papineni et al , 2002)<papid> P02-1040 </papid>bleu remains thede facto standard in machine translation eval uation.</citsent>
<aftsection>
<nextsent>it calculates n-gram precision and abrevity penalty, and can make use of multiple reference translations as way of capturing some of the allowable variation in translation.we use single reference translation in our experiments.
</nextsent>
<nextsent>meteor (agarwal and lavie, 2008)meteor measures precision and recall for unigrams and applies fragmentation penalty.
</nextsent>
<nextsent>it uses flexible word matching based on stemming and wordnet-synonymy.
</nextsent>
<nextsent>a number of variants are investigated here: meteor-baseline and meteor ranking are optimized for correlation with adequacy and ranking judgments respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2771">
<title id=" W08-0309.xml">further meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>r n c n t e /n o e a l meteor-ranking .81 .72 .77 .76 ulch .68 .79 .82 .76 meteor-baseline .77 .75 .74 .75 posbleu .77 .8 .66 .74 pos4gramfmeasure .75 .62 .82 .73 ulc .66 .67 .84 .72 dr .79 .55 .76 .70 sr .79 .53 .76 .69 dp .57 .79 .65 .67 mbleu .61 .77 .56 .65 mter .47 .72 .68 .62 bleu .61 .59 .44 .54 svm-rank .21 .24 .35 .27 table 8: average system-level correlations for the automatic evaluation metrics on translations into english 5.2 measuring consistency at the sentence-level.
</prevsent>
<prevsent>measuring sentence-level correlation under our human evaluation framework was made complicated by the fact that we abandoned the fluency and adequacy judgments which are intended to be absolute scales.
</prevsent>
</prevsection>
<citsent citstr=" P07-1111 ">
some previous work has focused on developing automatic metrics which predict human ranking at the sentence-level (kulesza and shieber, 2004; albrecht and hwa, 2007<papid> P07-1111 </papid>a; albrecht and hwa,2007<papid> P07-1111 </papid>b).</citsent>
<aftsection>
<nextsent>such work generally used the 5-point fluency and adequacy scales to combine the translations of all sentences into single ranked list.
</nextsent>
<nextsent>this list could be compared against the scores assigned by automatic metrics and used to calculate correlation coefficients.
</nextsent>
<nextsent>we did not gather any absolute scores and thus cannot compare translations across different sentences.
</nextsent>
<nextsent>given the seemingly unreliable fluency and adequacy assignments that people make even for translations of the same sentences, it maybe dubious to assume that their scoring will be reliable across sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2773">
<title id=" W08-0309.xml">further meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation in addition to scoring the shared task entries, we also continued on our campaign for improving the process of manual evaluation.
</prevsent>
<prevsent>7.1 inter- and intra-annotator agreement.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
we measured pairwise agreement among annotators using the kappa coefficient (k) which is widely usedin computational linguistics for measuring agreement in category judgments (carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>it is defined as = (a) ? (e) 1 ? (e) evaluation type (a) (e) sentence ranking .578 .333 .367 constituent ranking .671 .333 .506 constituent (w/identicals) .678 .333 .517 yes/no judgments .821 .5 .642 yes/no (w/identicals) .825 .5 .649 table 12: kappa coefficient values representing the inter-annotator agreement for the different types of manual evaluation evaluation type (a) (e) sentence ranking .691 .333 .537 constituent ranking .825 .333 .737 constituent (w/identicals) .832 .333 .748 yes/no judgments .928 .5 .855 yes/no (w/identicals) .930 .5 .861table 13: kappa coefficient values for intra annotator agreement for the different types of manual evaluation where (a) is the proportion of times that the annotators agree, and (e) is the proportion of time that they would agree by chance.
</nextsent>
<nextsent>we define chance agreement for ranking tasks as 13 since there are three possible outcomes when ranking the output of pair of systems:   b, = b,   b, and for the yes/no judgments as 12 since we ignored those items marked not sure?.
</nextsent>
<nextsent>for inter-annotator agreement we calculated (a) for the yes/no judgments by examining all items that were annotated by two or more annotators, and calculating the proportion of time they assigned identical scores to the same items.
</nextsent>
<nextsent>for the ranking tasks we calculated (a) by examining all pairs of systems which had been judged by two or more judges, and calculated the proportion of time that they agreed that   b, = b, or   b. for intra-annotator agreement we did similarly, but gathered items that were annotated on multiple occasions by single annotator.table 12 givesk values for inter-annotator agreement, and table 13 gives values for intra annotator agreement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2774">
<title id=" W08-0309.xml">further meta evaluation of machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>accumulating these judgments over time would give very reliable idea of what alternative translations were allowable.
</prevsent>
<prevsent>this would be useful because it could alleviate the problems associated with bleu failing to recognize allowable variation in translation when multiple reference translations are not available (callison-burch et al , 2006).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
a large database of human judgments might also be useful as an objective function for minimum error rate training (och, 2003) <papid> P03-1021 </papid>or in other system development tasks.</citsent>
<aftsection>
<nextsent>8 conclusions.
</nextsent>
<nextsent>similar to previous editions of this workshop we carried out an extensive manual and automatic evaluation of machine translation performance for translating from european languages into english, and vice versa.
</nextsent>
<nextsent>one important aspect in which this years shared task differed from previous years was the introduction of an additional newswire test set that was different in nature to the training data.
</nextsent>
<nextsent>we also added new language pairs to our evaluation: hungarian-english and german-spanish.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2775">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a central tenet of statistical natural language processing (nlp) is theres no data like more data?.
</prevsent>
<prevsent>one method for generating more data is to restate each phrase in corpus, keeping similar semantics while changing both the words and the word sequence.
</prevsent>
</prevsection>
<citsent citstr=" N06-1058 ">
the efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (kauchak and barzilay, 2006), <papid> N06-1058 </papid>text summarization (kittredge, 2002), question answering (rinaldi et al , 2003), <papid> W03-1604 </papid>document retrieval (zukerman and raskutti, 2002), <papid> C02-1161 </papid>and many others.most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (bannard and callison-burch, 2005; barzilay and lee, 2003; <papid> N03-1003 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>callison-burch et al , 2006; dolan et al , 2004; <papid> C04-1051 </papid>ibrahim et al , 2003; <papid> W03-1608 </papid>lin and pantel, 2001; pang et al ., 2003; <papid> N03-1024 </papid>quirk et al , 2004; <papid> W04-3219 </papid>shinyama et al , 2002).mutaphrase instead generates paraphrases algorith mically using an input sentence and framenet, afreely available lexico-semantic resource (information regarding framenet, including relevant terminology, is presented in section 2).</citsent>
<aftsection>
<nextsent>3yntax3imilar $ifferent 3em antic ) like eating cheese%ating cheese is liked by me ) like to snack on bread ) fear sipping juice4o sip on juice disturbs me figure 1: syntactic and semantic similarity to like eating cheese.
</nextsent>
<nextsent>conceptually, the mutaphrase algorithm takes semantic specification of sentence, provided by an automatic semantic parser such as shalmaneser (erk 143and pado?, 2006), and recursively replaces each semantically parsed phrase with semantically similarphrase.
</nextsent>
<nextsent>to generate each new phrase, each of these mantic parts of the original phrase is mapped, using framenet data, onto new word or phrase whose position and syntactic marking may be quite different.
</nextsent>
<nextsent>the mutaphrase algorithm outputs large set of paraphrases with variety of distances from the input in terms of both syntax and semantics; see figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2776">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a central tenet of statistical natural language processing (nlp) is theres no data like more data?.
</prevsent>
<prevsent>one method for generating more data is to restate each phrase in corpus, keeping similar semantics while changing both the words and the word sequence.
</prevsent>
</prevsection>
<citsent citstr=" W03-1604 ">
the efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (kauchak and barzilay, 2006), <papid> N06-1058 </papid>text summarization (kittredge, 2002), question answering (rinaldi et al , 2003), <papid> W03-1604 </papid>document retrieval (zukerman and raskutti, 2002), <papid> C02-1161 </papid>and many others.most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (bannard and callison-burch, 2005; barzilay and lee, 2003; <papid> N03-1003 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>callison-burch et al , 2006; dolan et al , 2004; <papid> C04-1051 </papid>ibrahim et al , 2003; <papid> W03-1608 </papid>lin and pantel, 2001; pang et al ., 2003; <papid> N03-1024 </papid>quirk et al , 2004; <papid> W04-3219 </papid>shinyama et al , 2002).mutaphrase instead generates paraphrases algorith mically using an input sentence and framenet, afreely available lexico-semantic resource (information regarding framenet, including relevant terminology, is presented in section 2).</citsent>
<aftsection>
<nextsent>3yntax3imilar $ifferent 3em antic ) like eating cheese%ating cheese is liked by me ) like to snack on bread ) fear sipping juice4o sip on juice disturbs me figure 1: syntactic and semantic similarity to like eating cheese.
</nextsent>
<nextsent>conceptually, the mutaphrase algorithm takes semantic specification of sentence, provided by an automatic semantic parser such as shalmaneser (erk 143and pado?, 2006), and recursively replaces each semantically parsed phrase with semantically similarphrase.
</nextsent>
<nextsent>to generate each new phrase, each of these mantic parts of the original phrase is mapped, using framenet data, onto new word or phrase whose position and syntactic marking may be quite different.
</nextsent>
<nextsent>the mutaphrase algorithm outputs large set of paraphrases with variety of distances from the input in terms of both syntax and semantics; see figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2777">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a central tenet of statistical natural language processing (nlp) is theres no data like more data?.
</prevsent>
<prevsent>one method for generating more data is to restate each phrase in corpus, keeping similar semantics while changing both the words and the word sequence.
</prevsent>
</prevsection>
<citsent citstr=" C02-1161 ">
the efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (kauchak and barzilay, 2006), <papid> N06-1058 </papid>text summarization (kittredge, 2002), question answering (rinaldi et al , 2003), <papid> W03-1604 </papid>document retrieval (zukerman and raskutti, 2002), <papid> C02-1161 </papid>and many others.most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (bannard and callison-burch, 2005; barzilay and lee, 2003; <papid> N03-1003 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>callison-burch et al , 2006; dolan et al , 2004; <papid> C04-1051 </papid>ibrahim et al , 2003; <papid> W03-1608 </papid>lin and pantel, 2001; pang et al ., 2003; <papid> N03-1024 </papid>quirk et al , 2004; <papid> W04-3219 </papid>shinyama et al , 2002).mutaphrase instead generates paraphrases algorith mically using an input sentence and framenet, afreely available lexico-semantic resource (information regarding framenet, including relevant terminology, is presented in section 2).</citsent>
<aftsection>
<nextsent>3yntax3imilar $ifferent 3em antic ) like eating cheese%ating cheese is liked by me ) like to snack on bread ) fear sipping juice4o sip on juice disturbs me figure 1: syntactic and semantic similarity to like eating cheese.
</nextsent>
<nextsent>conceptually, the mutaphrase algorithm takes semantic specification of sentence, provided by an automatic semantic parser such as shalmaneser (erk 143and pado?, 2006), and recursively replaces each semantically parsed phrase with semantically similarphrase.
</nextsent>
<nextsent>to generate each new phrase, each of these mantic parts of the original phrase is mapped, using framenet data, onto new word or phrase whose position and syntactic marking may be quite different.
</nextsent>
<nextsent>the mutaphrase algorithm outputs large set of paraphrases with variety of distances from the input in terms of both syntax and semantics; see figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2778">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a central tenet of statistical natural language processing (nlp) is theres no data like more data?.
</prevsent>
<prevsent>one method for generating more data is to restate each phrase in corpus, keeping similar semantics while changing both the words and the word sequence.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
the efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (kauchak and barzilay, 2006), <papid> N06-1058 </papid>text summarization (kittredge, 2002), question answering (rinaldi et al , 2003), <papid> W03-1604 </papid>document retrieval (zukerman and raskutti, 2002), <papid> C02-1161 </papid>and many others.most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (bannard and callison-burch, 2005; barzilay and lee, 2003; <papid> N03-1003 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>callison-burch et al , 2006; dolan et al , 2004; <papid> C04-1051 </papid>ibrahim et al , 2003; <papid> W03-1608 </papid>lin and pantel, 2001; pang et al ., 2003; <papid> N03-1024 </papid>quirk et al , 2004; <papid> W04-3219 </papid>shinyama et al , 2002).mutaphrase instead generates paraphrases algorith mically using an input sentence and framenet, afreely available lexico-semantic resource (information regarding framenet, including relevant terminology, is presented in section 2).</citsent>
<aftsection>
<nextsent>3yntax3imilar $ifferent 3em antic ) like eating cheese%ating cheese is liked by me ) like to snack on bread ) fear sipping juice4o sip on juice disturbs me figure 1: syntactic and semantic similarity to like eating cheese.
</nextsent>
<nextsent>conceptually, the mutaphrase algorithm takes semantic specification of sentence, provided by an automatic semantic parser such as shalmaneser (erk 143and pado?, 2006), and recursively replaces each semantically parsed phrase with semantically similarphrase.
</nextsent>
<nextsent>to generate each new phrase, each of these mantic parts of the original phrase is mapped, using framenet data, onto new word or phrase whose position and syntactic marking may be quite different.
</nextsent>
<nextsent>the mutaphrase algorithm outputs large set of paraphrases with variety of distances from the input in terms of both syntax and semantics; see figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2779">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a central tenet of statistical natural language processing (nlp) is theres no data like more data?.
</prevsent>
<prevsent>one method for generating more data is to restate each phrase in corpus, keeping similar semantics while changing both the words and the word sequence.
</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
the efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (kauchak and barzilay, 2006), <papid> N06-1058 </papid>text summarization (kittredge, 2002), question answering (rinaldi et al , 2003), <papid> W03-1604 </papid>document retrieval (zukerman and raskutti, 2002), <papid> C02-1161 </papid>and many others.most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (bannard and callison-burch, 2005; barzilay and lee, 2003; <papid> N03-1003 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>callison-burch et al , 2006; dolan et al , 2004; <papid> C04-1051 </papid>ibrahim et al , 2003; <papid> W03-1608 </papid>lin and pantel, 2001; pang et al ., 2003; <papid> N03-1024 </papid>quirk et al , 2004; <papid> W04-3219 </papid>shinyama et al , 2002).mutaphrase instead generates paraphrases algorith mically using an input sentence and framenet, afreely available lexico-semantic resource (information regarding framenet, including relevant terminology, is presented in section 2).</citsent>
<aftsection>
<nextsent>3yntax3imilar $ifferent 3em antic ) like eating cheese%ating cheese is liked by me ) like to snack on bread ) fear sipping juice4o sip on juice disturbs me figure 1: syntactic and semantic similarity to like eating cheese.
</nextsent>
<nextsent>conceptually, the mutaphrase algorithm takes semantic specification of sentence, provided by an automatic semantic parser such as shalmaneser (erk 143and pado?, 2006), and recursively replaces each semantically parsed phrase with semantically similarphrase.
</nextsent>
<nextsent>to generate each new phrase, each of these mantic parts of the original phrase is mapped, using framenet data, onto new word or phrase whose position and syntactic marking may be quite different.
</nextsent>
<nextsent>the mutaphrase algorithm outputs large set of paraphrases with variety of distances from the input in terms of both syntax and semantics; see figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2780">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a central tenet of statistical natural language processing (nlp) is theres no data like more data?.
</prevsent>
<prevsent>one method for generating more data is to restate each phrase in corpus, keeping similar semantics while changing both the words and the word sequence.
</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
the efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (kauchak and barzilay, 2006), <papid> N06-1058 </papid>text summarization (kittredge, 2002), question answering (rinaldi et al , 2003), <papid> W03-1604 </papid>document retrieval (zukerman and raskutti, 2002), <papid> C02-1161 </papid>and many others.most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (bannard and callison-burch, 2005; barzilay and lee, 2003; <papid> N03-1003 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>callison-burch et al , 2006; dolan et al , 2004; <papid> C04-1051 </papid>ibrahim et al , 2003; <papid> W03-1608 </papid>lin and pantel, 2001; pang et al ., 2003; <papid> N03-1024 </papid>quirk et al , 2004; <papid> W04-3219 </papid>shinyama et al , 2002).mutaphrase instead generates paraphrases algorith mically using an input sentence and framenet, afreely available lexico-semantic resource (information regarding framenet, including relevant terminology, is presented in section 2).</citsent>
<aftsection>
<nextsent>3yntax3imilar $ifferent 3em antic ) like eating cheese%ating cheese is liked by me ) like to snack on bread ) fear sipping juice4o sip on juice disturbs me figure 1: syntactic and semantic similarity to like eating cheese.
</nextsent>
<nextsent>conceptually, the mutaphrase algorithm takes semantic specification of sentence, provided by an automatic semantic parser such as shalmaneser (erk 143and pado?, 2006), and recursively replaces each semantically parsed phrase with semantically similarphrase.
</nextsent>
<nextsent>to generate each new phrase, each of these mantic parts of the original phrase is mapped, using framenet data, onto new word or phrase whose position and syntactic marking may be quite different.
</nextsent>
<nextsent>the mutaphrase algorithm outputs large set of paraphrases with variety of distances from the input in terms of both syntax and semantics; see figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2781">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a central tenet of statistical natural language processing (nlp) is theres no data like more data?.
</prevsent>
<prevsent>one method for generating more data is to restate each phrase in corpus, keeping similar semantics while changing both the words and the word sequence.
</prevsent>
</prevsection>
<citsent citstr=" W03-1608 ">
the efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (kauchak and barzilay, 2006), <papid> N06-1058 </papid>text summarization (kittredge, 2002), question answering (rinaldi et al , 2003), <papid> W03-1604 </papid>document retrieval (zukerman and raskutti, 2002), <papid> C02-1161 </papid>and many others.most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (bannard and callison-burch, 2005; barzilay and lee, 2003; <papid> N03-1003 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>callison-burch et al , 2006; dolan et al , 2004; <papid> C04-1051 </papid>ibrahim et al , 2003; <papid> W03-1608 </papid>lin and pantel, 2001; pang et al ., 2003; <papid> N03-1024 </papid>quirk et al , 2004; <papid> W04-3219 </papid>shinyama et al , 2002).mutaphrase instead generates paraphrases algorith mically using an input sentence and framenet, afreely available lexico-semantic resource (information regarding framenet, including relevant terminology, is presented in section 2).</citsent>
<aftsection>
<nextsent>3yntax3imilar $ifferent 3em antic ) like eating cheese%ating cheese is liked by me ) like to snack on bread ) fear sipping juice4o sip on juice disturbs me figure 1: syntactic and semantic similarity to like eating cheese.
</nextsent>
<nextsent>conceptually, the mutaphrase algorithm takes semantic specification of sentence, provided by an automatic semantic parser such as shalmaneser (erk 143and pado?, 2006), and recursively replaces each semantically parsed phrase with semantically similarphrase.
</nextsent>
<nextsent>to generate each new phrase, each of these mantic parts of the original phrase is mapped, using framenet data, onto new word or phrase whose position and syntactic marking may be quite different.
</nextsent>
<nextsent>the mutaphrase algorithm outputs large set of paraphrases with variety of distances from the input in terms of both syntax and semantics; see figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2782">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a central tenet of statistical natural language processing (nlp) is theres no data like more data?.
</prevsent>
<prevsent>one method for generating more data is to restate each phrase in corpus, keeping similar semantics while changing both the words and the word sequence.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
the efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (kauchak and barzilay, 2006), <papid> N06-1058 </papid>text summarization (kittredge, 2002), question answering (rinaldi et al , 2003), <papid> W03-1604 </papid>document retrieval (zukerman and raskutti, 2002), <papid> C02-1161 </papid>and many others.most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (bannard and callison-burch, 2005; barzilay and lee, 2003; <papid> N03-1003 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>callison-burch et al , 2006; dolan et al , 2004; <papid> C04-1051 </papid>ibrahim et al , 2003; <papid> W03-1608 </papid>lin and pantel, 2001; pang et al ., 2003; <papid> N03-1024 </papid>quirk et al , 2004; <papid> W04-3219 </papid>shinyama et al , 2002).mutaphrase instead generates paraphrases algorith mically using an input sentence and framenet, afreely available lexico-semantic resource (information regarding framenet, including relevant terminology, is presented in section 2).</citsent>
<aftsection>
<nextsent>3yntax3imilar $ifferent 3em antic ) like eating cheese%ating cheese is liked by me ) like to snack on bread ) fear sipping juice4o sip on juice disturbs me figure 1: syntactic and semantic similarity to like eating cheese.
</nextsent>
<nextsent>conceptually, the mutaphrase algorithm takes semantic specification of sentence, provided by an automatic semantic parser such as shalmaneser (erk 143and pado?, 2006), and recursively replaces each semantically parsed phrase with semantically similarphrase.
</nextsent>
<nextsent>to generate each new phrase, each of these mantic parts of the original phrase is mapped, using framenet data, onto new word or phrase whose position and syntactic marking may be quite different.
</nextsent>
<nextsent>the mutaphrase algorithm outputs large set of paraphrases with variety of distances from the input in terms of both syntax and semantics; see figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2783">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a central tenet of statistical natural language processing (nlp) is theres no data like more data?.
</prevsent>
<prevsent>one method for generating more data is to restate each phrase in corpus, keeping similar semantics while changing both the words and the word sequence.
</prevsent>
</prevsection>
<citsent citstr=" W04-3219 ">
the efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (kauchak and barzilay, 2006), <papid> N06-1058 </papid>text summarization (kittredge, 2002), question answering (rinaldi et al , 2003), <papid> W03-1604 </papid>document retrieval (zukerman and raskutti, 2002), <papid> C02-1161 </papid>and many others.most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (bannard and callison-burch, 2005; barzilay and lee, 2003; <papid> N03-1003 </papid>barzilay and mckeown, 2001; <papid> P01-1008 </papid>callison-burch et al , 2006; dolan et al , 2004; <papid> C04-1051 </papid>ibrahim et al , 2003; <papid> W03-1608 </papid>lin and pantel, 2001; pang et al ., 2003; <papid> N03-1024 </papid>quirk et al , 2004; <papid> W04-3219 </papid>shinyama et al , 2002).mutaphrase instead generates paraphrases algorith mically using an input sentence and framenet, afreely available lexico-semantic resource (information regarding framenet, including relevant terminology, is presented in section 2).</citsent>
<aftsection>
<nextsent>3yntax3imilar $ifferent 3em antic ) like eating cheese%ating cheese is liked by me ) like to snack on bread ) fear sipping juice4o sip on juice disturbs me figure 1: syntactic and semantic similarity to like eating cheese.
</nextsent>
<nextsent>conceptually, the mutaphrase algorithm takes semantic specification of sentence, provided by an automatic semantic parser such as shalmaneser (erk 143and pado?, 2006), and recursively replaces each semantically parsed phrase with semantically similarphrase.
</nextsent>
<nextsent>to generate each new phrase, each of these mantic parts of the original phrase is mapped, using framenet data, onto new word or phrase whose position and syntactic marking may be quite different.
</nextsent>
<nextsent>the mutaphrase algorithm outputs large set of paraphrases with variety of distances from the input in terms of both syntax and semantics; see figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2784">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>pruning earlier during paraphrase generation should help address this issue.
</prevsent>
<prevsent>currently, mutaphrase requires the input sentences to have been marked with framenet annotations prior to processing.
</prevsent>
</prevsection>
<citsent citstr=" W04-0841 ">
although automatic semantic parsing is large and growing field (moldovan et al ., 2004; <papid> W04-0841 </papid>litkowski, 2004; <papid> W04-0803 </papid>baldewein et al , 2004), <papid> W04-0817 </papid>two problems present themselves.</citsent>
<aftsection>
<nextsent>first, output from 148 an automated parser is not typically compatible with framenet markup.
</nextsent>
<nextsent>although this is mostly simple matter of programming?, some linguistic tools must be developed to convert between formats (e.g. to infer framenet phrase types from part-of-speech tags).5 second, it is not yet clear how the inevitable errors introduced by the parser will affect the mutaphrase algorithm6.
</nextsent>
<nextsent>we plan to use application dependent measures to judge the effects of parsing errors.
</nextsent>
<nextsent>certain types of semantic ill-formedness cannot be detected by the current version of mutaphrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2785">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>pruning earlier during paraphrase generation should help address this issue.
</prevsent>
<prevsent>currently, mutaphrase requires the input sentences to have been marked with framenet annotations prior to processing.
</prevsent>
</prevsection>
<citsent citstr=" W04-0803 ">
although automatic semantic parsing is large and growing field (moldovan et al ., 2004; <papid> W04-0841 </papid>litkowski, 2004; <papid> W04-0803 </papid>baldewein et al , 2004), <papid> W04-0817 </papid>two problems present themselves.</citsent>
<aftsection>
<nextsent>first, output from 148 an automated parser is not typically compatible with framenet markup.
</nextsent>
<nextsent>although this is mostly simple matter of programming?, some linguistic tools must be developed to convert between formats (e.g. to infer framenet phrase types from part-of-speech tags).5 second, it is not yet clear how the inevitable errors introduced by the parser will affect the mutaphrase algorithm6.
</nextsent>
<nextsent>we plan to use application dependent measures to judge the effects of parsing errors.
</nextsent>
<nextsent>certain types of semantic ill-formedness cannot be detected by the current version of mutaphrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2786">
<title id=" W07-1424.xml">mutaphrase paraphrasing with framenet </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>pruning earlier during paraphrase generation should help address this issue.
</prevsent>
<prevsent>currently, mutaphrase requires the input sentences to have been marked with framenet annotations prior to processing.
</prevsent>
</prevsection>
<citsent citstr=" W04-0817 ">
although automatic semantic parsing is large and growing field (moldovan et al ., 2004; <papid> W04-0841 </papid>litkowski, 2004; <papid> W04-0803 </papid>baldewein et al , 2004), <papid> W04-0817 </papid>two problems present themselves.</citsent>
<aftsection>
<nextsent>first, output from 148 an automated parser is not typically compatible with framenet markup.
</nextsent>
<nextsent>although this is mostly simple matter of programming?, some linguistic tools must be developed to convert between formats (e.g. to infer framenet phrase types from part-of-speech tags).5 second, it is not yet clear how the inevitable errors introduced by the parser will affect the mutaphrase algorithm6.
</nextsent>
<nextsent>we plan to use application dependent measures to judge the effects of parsing errors.
</nextsent>
<nextsent>certain types of semantic ill-formedness cannot be detected by the current version of mutaphrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2787">
<title id=" W08-0603.xml">using automated feature optimisation to create an adaptable relation extraction system </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the extraction of protein-protein interactions hasalso been helped by the availability of annotated corpora, such as aimed (bunescu et al, 2005), which consists of around 1000 medline abstracts annotated with proteins and their interactions.
</prevsent>
<prevsent>in common with the lll corpus, the aimed corpus only contains intra-sentential relations, and is somewhat smaller than the corpus used in the current work.
</prevsent>
</prevsection>
<citsent citstr=" D07-1024 ">
in addition to the work by the corpus creators (bunescu and mooney, 2007), other authors have achieved good results on aimed by making use of dependency parses in different ways (erkan et al, 2007; <papid> D07-1024 </papid>katrenko and adriaans, 2006).</citsent>
<aftsection>
<nextsent>it is not clear, however, how well these techniques would transfer to other, similar, re problems, and how much work would be involved in tuning the systems for new problem.supervised learning based on shallow syntactic features has also been applied to the biomedical do main, again focusing on protein-protein interactions(nielsen, 2006; <papid> W06-3322 </papid>giuliano et al, 2006).<papid> E06-1051 </papid></nextsent>
<nextsent>a systematic exploration of set of such features for protein protein interaction extraction was recently provided by jiang and zhai (2007), <papid> N07-1015 </papid>who also used features derived from the collins parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2788">
<title id=" W08-0603.xml">using automated feature optimisation to create an adaptable relation extraction system </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in common with the lll corpus, the aimed corpus only contains intra-sentential relations, and is somewhat smaller than the corpus used in the current work.
</prevsent>
<prevsent>in addition to the work by the corpus creators (bunescu and mooney, 2007), other authors have achieved good results on aimed by making use of dependency parses in different ways (erkan et al, 2007; <papid> D07-1024 </papid>katrenko and adriaans, 2006).</prevsent>
</prevsection>
<citsent citstr=" W06-3322 ">
it is not clear, however, how well these techniques would transfer to other, similar, re problems, and how much work would be involved in tuning the systems for new problem.supervised learning based on shallow syntactic features has also been applied to the biomedical do main, again focusing on protein-protein interactions(nielsen, 2006; <papid> W06-3322 </papid>giuliano et al, 2006).<papid> E06-1051 </papid></citsent>
<aftsection>
<nextsent>a systematic exploration of set of such features for protein protein interaction extraction was recently provided by jiang and zhai (2007), <papid> N07-1015 </papid>who also used features derived from the collins parser.</nextsent>
<nextsent>they did not, however, experiment with the automated optimisation of the feature sets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2789">
<title id=" W08-0603.xml">using automated feature optimisation to create an adaptable relation extraction system </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in common with the lll corpus, the aimed corpus only contains intra-sentential relations, and is somewhat smaller than the corpus used in the current work.
</prevsent>
<prevsent>in addition to the work by the corpus creators (bunescu and mooney, 2007), other authors have achieved good results on aimed by making use of dependency parses in different ways (erkan et al, 2007; <papid> D07-1024 </papid>katrenko and adriaans, 2006).</prevsent>
</prevsection>
<citsent citstr=" E06-1051 ">
it is not clear, however, how well these techniques would transfer to other, similar, re problems, and how much work would be involved in tuning the systems for new problem.supervised learning based on shallow syntactic features has also been applied to the biomedical do main, again focusing on protein-protein interactions(nielsen, 2006; <papid> W06-3322 </papid>giuliano et al, 2006).<papid> E06-1051 </papid></citsent>
<aftsection>
<nextsent>a systematic exploration of set of such features for protein protein interaction extraction was recently provided by jiang and zhai (2007), <papid> N07-1015 </papid>who also used features derived from the collins parser.</nextsent>
<nextsent>they did not, however, experiment with the automated optimisation of the feature sets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2790">
<title id=" W08-0603.xml">using automated feature optimisation to create an adaptable relation extraction system </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to the work by the corpus creators (bunescu and mooney, 2007), other authors have achieved good results on aimed by making use of dependency parses in different ways (erkan et al, 2007; <papid> D07-1024 </papid>katrenko and adriaans, 2006).</prevsent>
<prevsent>it is not clear, however, how well these techniques would transfer to other, similar, re problems, and how much work would be involved in tuning the systems for new problem.supervised learning based on shallow syntactic features has also been applied to the biomedical do main, again focusing on protein-protein interactions(nielsen, 2006; <papid> W06-3322 </papid>giuliano et al, 2006).<papid> E06-1051 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1015 ">
a systematic exploration of set of such features for protein protein interaction extraction was recently provided by jiang and zhai (2007), <papid> N07-1015 </papid>who also used features derived from the collins parser.</citsent>
<aftsection>
<nextsent>they did not, however, experiment with the automated optimisation of the feature sets.
</nextsent>
<nextsent>in the news domain, the best reported results on the ace dataset1 have been achieved by composite kernel which depends partially on full parse, and partially on collection of shallow syntactic features (zhou et al, 2007).<papid> D07-1076 </papid></nextsent>
<nextsent>aside from protein-protein interactions, there has been little work directed at other types of relation sin the biomedical domain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2791">
<title id=" W08-0603.xml">using automated feature optimisation to create an adaptable relation extraction system </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a systematic exploration of set of such features for protein protein interaction extraction was recently provided by jiang and zhai (2007), <papid> N07-1015 </papid>who also used features derived from the collins parser.</prevsent>
<prevsent>they did not, however, experiment with the automated optimisation of the feature sets.</prevsent>
</prevsection>
<citsent citstr=" D07-1076 ">
in the news domain, the best reported results on the ace dataset1 have been achieved by composite kernel which depends partially on full parse, and partially on collection of shallow syntactic features (zhou et al, 2007).<papid> D07-1076 </papid></citsent>
<aftsection>
<nextsent>aside from protein-protein interactions, there has been little work directed at other types of relation sin the biomedical domain.
</nextsent>
<nextsent>recent corpus annotation projects such as genia (kim et al, 2008) and bio infer (pyysalo et al, 2007) include multiple types of relations, however many of the relation types are represented in fairly small quantities.
</nextsent>
<nextsent>in earlier work(skounakis et al, 2003), the extraction of cell localisation relations was studied using an automatically created corpus.
</nextsent>
<nextsent>1http://www.nist.gov/speech/tests/ace/
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2792">
<title id=" W08-0603.xml">using automated feature optimisation to create an adaptable relation extraction system </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>the pre-processing involved tokenisation,sentence boundary detection, lemmatising.
</prevsent>
<prevsent>part-of speech tagging, head word detection and chunking.
</prevsent>
</prevsection>
<citsent citstr=" W03-0424 ">
the part-of-speech tagging uses the curran &amp; clark maximum entropymarkovmodel tagger (curran and clark, 2003) <papid> W03-0424 </papid>trained on medpost data (smith et al., 2004), whilst the other preprocessing stages areall rule-based.</citsent>
<aftsection>
<nextsent>the token isation, sentence boundary detection, head word identification and chunking components were implemented with the lt-xml2tools (grover and tobin, 2006), and the lemma tisa tion used morpha (minnen et al, 2000).<papid> W00-1427 </papid></nextsent>
<nextsent>3.2 the relation extraction system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2793">
<title id=" W08-0603.xml">using automated feature optimisation to create an adaptable relation extraction system </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>part-of speech tagging, head word detection and chunking.
</prevsent>
<prevsent>the part-of-speech tagging uses the curran &amp; clark maximum entropymarkovmodel tagger (curran and clark, 2003) <papid> W03-0424 </papid>trained on medpost data (smith et al., 2004), whilst the other preprocessing stages areall rule-based.</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
the token isation, sentence boundary detection, head word identification and chunking components were implemented with the lt-xml2tools (grover and tobin, 2006), and the lemma tisa tion used morpha (minnen et al, 2000).<papid> W00-1427 </papid></citsent>
<aftsection>
<nextsent>3.2 the relation extraction system.
</nextsent>
<nextsent>relation extraction is treated classification problem, by generating candidate relations, and classifying them as either true or false.
</nextsent>
<nextsent>in the optimisation experiments described in this paper, zhang les maximum entropy (maxent) classifier2 was used, since its performance was very competitive and itsfast training time permitted extensive feature experimentation.
</nextsent>
<nextsent>the gaussian prior was set to 0.1, and the maximum training iterations to 100.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2794">
<title id=" W08-0603.xml">using automated feature optimisation to create an adaptable relation extraction system </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, the hyperparameter optimisation of the classifiers (for example the gaussian prior in maxent) could be incorporated into the search.
</prevsent>
<prevsent>whilst the relation extractor was successful onintra-sentential relations, it is less successful on inter sentential relations, perhaps becuase of the lingusiticcomplexity of these, and the sparsity of positive examples.
</prevsent>
</prevsection>
<citsent citstr=" P07-1075 ">
the split into inter- and inter-sentential examples in the current system seems justified as they have quite different characteristic, but there may also be case for splitting the intra-sententials further, into intra- and inter-clausals, as suggested by maslennikov and chua (2007), <papid> P07-1075 </papid>and then treating inter-clausals and inter-sententials together.</citsent>
<aftsection>
<nextsent>whilstintra-clausals are more likely to use simple constructions and be amenable to modelling with shallow linguistic features, inter-sententials and inter-clausals are more likely to use complex linguistic phenomena such as corefereces.
</nextsent>
<nextsent>acknowledgements this work was supported by the text mining programme of iti life sciences scotland (http://www.
</nextsent>
<nextsent>itilifesciences.com).
</nextsent>
<nextsent>26
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2795">
<title id=" W07-2027.xml">dfki2 an information extraction based approach to people disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentence patterns related to name, i.e. patterns that contain the name as subject or object like be(person x, lawyer)?
</prevsent>
<prevsent>often convey uniquely identifying information about person.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
our system was not built specifically for the web people search task weps (artiles et al, 2007), <papid> W07-2012 </papid>but is an early version of an ie system that has the more general goal to discover relations between nes.</citsent>
<aftsection>
<nextsent>we see the weps task as specific instance of the set oftasks our system should be able to handle.
</nextsent>
<nextsent>therefore, we only adapted it slightly to work with theweps data, but did not make any further customization w.r.t. the special requirements of people disambiguation.
</nextsent>
<nextsent>as our system was built to handle pure texts rather than structured web pages, we relied completely on linguistic information and did not exploit the html structure of the documents provided.
</nextsent>
<nextsent>our system was inspired by the preemptive and on demand ie approaches by sekine and shinyama(sekine, 2006; <papid> P06-2094 </papid>shinyama, 2006) that cluster news paper articles into classes of articles that talk about the same type of event.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2796">
<title id=" W07-2027.xml">dfki2 an information extraction based approach to people disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, we only adapted it slightly to work with theweps data, but did not make any further customization w.r.t. the special requirements of people disambiguation.
</prevsent>
<prevsent>as our system was built to handle pure texts rather than structured web pages, we relied completely on linguistic information and did not exploit the html structure of the documents provided.
</prevsent>
</prevsection>
<citsent citstr=" P06-2094 ">
our system was inspired by the preemptive and on demand ie approaches by sekine and shinyama(sekine, 2006; <papid> P06-2094 </papid>shinyama, 2006) that cluster news paper articles into classes of articles that talk about the same type of event.</citsent>
<aftsection>
<nextsent>they proposed system to discover in advance all possible relations and to return them in form of tables.
</nextsent>
<nextsent>we took the idea of distinctive personal attributes as criterion for disambiguation from the work of bollegala et al (2006).<papid> W06-0803 </papid></nextsent>
<nextsent>they propose an unsupervised learning approach to extract phrases that uniquely identify person from the web and use these discriminative features for clustering.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2797">
<title id=" W07-2027.xml">dfki2 an information extraction based approach to people disambiguation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our system was inspired by the preemptive and on demand ie approaches by sekine and shinyama(sekine, 2006; <papid> P06-2094 </papid>shinyama, 2006) that cluster news paper articles into classes of articles that talk about the same type of event.</prevsent>
<prevsent>they proposed system to discover in advance all possible relations and to return them in form of tables.</prevsent>
</prevsection>
<citsent citstr=" W06-0803 ">
we took the idea of distinctive personal attributes as criterion for disambiguation from the work of bollegala et al (2006).<papid> W06-0803 </papid></citsent>
<aftsection>
<nextsent>they propose an unsupervised learning approach to extract phrases that uniquely identify person from the web and use these discriminative features for clustering.
</nextsent>
<nextsent>the goal of the weps task is to cluster the top 100 web pages returned by web search engine for certain name as search query and classify them w.r.t. the underlying different people they refer to.the problem of clustering documents about people into different entities can be seen as two subproblems: the determination of the correct number of clusters and the clustering of the given documents into this number of entities.
</nextsent>
<nextsent>these problems could either be solved consecutively by first estimating the number of classes and then produce this pre 137 html ? text  coreference resolution    pp ne-tagging  // semantic parsing vvmmm feature vectors // clustering figure 1: system overview set number of clusters or by determining the number of classes dynamically during the clustering process.
</nextsent>
<nextsent>figure 1 gives an overview of our system, that clusters web documents into pre-defined number of classes, thereby being only concerned with the second problem and neglecting the estimation of different namesakes for now.every web page in the weps training data is represented by the set of its files.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2798">
<title id=" W07-1301.xml">computing and historical phonology </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>there is substantial and growing body of work applying computational techniques of various sorts to problems in historical phonology.
</prevsent>
<prevsent>we mention few here to give the flavor of the sort of work wehoped to attract for presentation incoherent sig morphon workshop.
</prevsent>
</prevsection>
<citsent citstr=" P06-1035 ">
kessler (2001) estimates the likelihood of chance phonemic correspondences using permutation statistics; kondrak (2002) develops algorithms to detect cognates and sound corre spondences; mcmahon and mcmahon (2005) andalso nakhleh, ringe and warnow (2005) apply phy logenetic techniques to comparative reconstruction;and ellison and kirby (2006) <papid> P06-1035 </papid>suggest means of detecting relationships which do not depend on word by word comparisons.</citsent>
<aftsection>
<nextsent>but we likewise wished todraw on the creativity of the computational linguistics (cl) community to see which other important problems in historical phonology might also be addressed computationally (see below).there has recently been good deal of computational work in historical linguistics involving phylogenetic inference, i.e., the inference to the genealogical tree which best explains the historical developments (gray and atkinson, 2003; dunn et al, 2005).
</nextsent>
<nextsent>while the application of phylogenetic analysis hasnot universally been welcomed with open philological arms (holm, 2007), it has attracted good deal of attention, some of which we hoped to engage.
</nextsent>
<nextsent>we take no stand on these controversies here, but note that computing may be employed in historical linguistics, and in particular in historical phonology in more versatile way, its uses extending well beyond phylogenetic inference.
</nextsent>
<nextsent>the workshop thus brings together researchers interested in applying computational techniques to problems in historical phonology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2799">
<title id=" W07-1301.xml">computing and historical phonology </title>
<section> papers.  </section>
<citcontext>
<prevsection>
<prevsent>list.
</prevsent>
<prevsent>but such data is not always available, nor is it straightforward to construct.
</prevsent>
</prevsection>
<citsent citstr=" W05-0606 ">
singh and surana construct n-gram models of order five (5), and compare indo-iranian and dravidian languages based on symmetric cross-entropy.martijn wieling, therese leinonen and john nerbonne apply pair hidden markov models(phmm), introduced to cl by mackay and kondrak (2005), <papid> W05-0606 </papid>to large collection of dutch dialect pronunciations in an effort to learn the degree of segment differentiation.</citsent>
<aftsection>
<nextsent>essentially the phmm regards frequently aligned segments as more similar,and wieling et al show that the induced similarity indeed corresponds to phonetic similarity in the case of vowels, whose acoustic properties facilitate the assessment of similarity.
</nextsent>
<nextsent>3.3 views from other perspectives.
</nextsent>
<nextsent>several papers examined dia chronic change from well-developed perspectives outside of historical linguistics, including evolution and genetic algorithms, language learning, biological cladistics, and the structure of vowel systems.
</nextsent>
<nextsent>monojit choudhury, vaibhav jalan, sudeshnasarkar and anupam basu distinguish two components in language developments, on the one hand functional forces or constraints including ease of articulation, perceptual contrast, and learnability,which are modeled by the fitness function of genetic algorithm (ga).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2800">
<title id=" W07-2078.xml">ubczas a knn based multi classifier system to perform wsd in a reduced dimensional vector space </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the selection of those dimensions is based on the number of training cases available for each word, and limited to 500; the used dimensions vary from 19 (for the word grant) to 481 (for the word part).
</prevsent>
<prevsent>3.3 the number of classifiers (tdi).
</prevsent>
</prevsection>
<citsent citstr=" W06-2604 ">
based on previous experiments carried out for document categorization (zelaia et al, 2006), <papid> W06-2604 </papid>we decided to create 30 classifiers for some words and 50 for others, i.e. 30 or 50 individual k-nn algorithms will be used by the multi classifier in order to combine opinions by bayesian voting.</citsent>
<aftsection>
<nextsent>3.4 number of neigbors for k-nn.
</nextsent>
<nextsent>based on our previous experiments, we decided to use = 1 and = 5, and to select the best for each of the words.
</nextsent>
<nextsent>the cosine similarity measure is used in order to find the nearest or the 5 nearests.
</nextsent>
<nextsent>the experiment was conducted by considering the optimal values for parameters tuned by using the training case set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2801">
<title id=" W07-2056.xml">pku combining supervised classifiers with features selection </title>
<section> classifiers.  </section>
<citcontext>
<prevsection>
<prevsent>the same classifier was tried on different feature sets to get different outputs and then were combined.
</prevsent>
<prevsent>the support vector machines (svm) are group of supervised learning methods that can be applied to classification or regression.
</prevsent>
</prevsection>
<citsent citstr=" W04-0834 ">
it is developed by vapnik and has been applied into wsd (lee et al, 2004).<papid> W04-0834 </papid></citsent>
<aftsection>
<nextsent>since most of the target words have more than two senses, we used the implementation of svm that includes lib-svm (chang and lin, 2001) and svm-multiclass (joachims, 2004).
</nextsent>
<nextsent>to lib-svm, the parameter of b? which is used to obtain probability information after training is set 0 or 1 individually to form different classifiers.
</nextsent>
<nextsent>the default linear kernel is used.
</nextsent>
<nextsent>each vector dimension represents feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2802">
<title id=" W07-2056.xml">pku combining supervised classifiers with features selection </title>
<section> classifiers.  </section>
<citcontext>
<prevsection>
<prevsent>me modeling provides framework for integrating information for classification from many heterogeneous information sources.
</prevsent>
<prevsent>the intuition behind the maximum entropy principle is: given set of training data, model what is known and assume no further knowledge about the unknown by assigning them equal probability (entropy is maximum).
</prevsent>
</prevsection>
<citsent citstr=" C02-1168 ">
there are also some researchers using me to wsd (chao and dyer, 2002).<papid> C02-1168 </papid></citsent>
<aftsection>
<nextsent>dekang lins implementation of me was used.
</nextsent>
<nextsent>he used generalized iterative scaling (gis) algorithm.
</nextsent>
<nextsent>because of time constraints, we could not experiment all the training data by cross-validation.
</nextsent>
<nextsent>to each target word, we extract first 50 training instances as the test.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2803">
<title id=" W08-0101.xml">optimizing end pointing thresholds using dialogue features in a spoken dialogue system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, regarding this last aspect, ore strom notes about his corpus that there is no simple way to formalizing semantic analysis of this conversational mate rial?.
</prevsent>
<prevsent>this difficulty in formalizing higher levels of conversation might explain the relatively low interest that conversational analysts have had in semantics and discourse.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
yet, as conversational analysts focused on micro-levels of dialogue such as turn taking, computational linguists uncovered and formalized macro-level dialogue structure and devised well-defined representations of semantics for at least some forms of dialogues (allen and perrault, 1980; grosz and sidner, 1986; <papid> J86-3001 </papid>clark, 1996), which have in turn been implemented in spoken dialogue systems (rich and sidner, 1998; allen et al , 2005).<papid> P05-3022 </papid></citsent>
<aftsection>
<nextsent>1 1.2 current approaches to turn-taking in.
</nextsent>
<nextsent>spoken dialogue systems unfortunately, while socio- and psycho-linguists revealed the complexity of conversational turn-takingbehavior, designers of practical spoken dialogue systems have stuck to simplistic approach to end-ofturn detection (hereafter endpointing).
</nextsent>
<nextsent>typically, silences in user speech are detected using low-levelvoice activity detector (vad) and turn is considered finished once silence lasts longer than fixed threshold.
</nextsent>
<nextsent>this approach has the advantage of being simple, only relying on easily computable low-level features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2804">
<title id=" W08-0101.xml">optimizing end pointing thresholds using dialogue features in a spoken dialogue system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, regarding this last aspect, ore strom notes about his corpus that there is no simple way to formalizing semantic analysis of this conversational mate rial?.
</prevsent>
<prevsent>this difficulty in formalizing higher levels of conversation might explain the relatively low interest that conversational analysts have had in semantics and discourse.
</prevsent>
</prevsection>
<citsent citstr=" P05-3022 ">
yet, as conversational analysts focused on micro-levels of dialogue such as turn taking, computational linguists uncovered and formalized macro-level dialogue structure and devised well-defined representations of semantics for at least some forms of dialogues (allen and perrault, 1980; grosz and sidner, 1986; <papid> J86-3001 </papid>clark, 1996), which have in turn been implemented in spoken dialogue systems (rich and sidner, 1998; allen et al , 2005).<papid> P05-3022 </papid></citsent>
<aftsection>
<nextsent>1 1.2 current approaches to turn-taking in.
</nextsent>
<nextsent>spoken dialogue systems unfortunately, while socio- and psycho-linguists revealed the complexity of conversational turn-takingbehavior, designers of practical spoken dialogue systems have stuck to simplistic approach to end-ofturn detection (hereafter endpointing).
</nextsent>
<nextsent>typically, silences in user speech are detected using low-levelvoice activity detector (vad) and turn is considered finished once silence lasts longer than fixed threshold.
</nextsent>
<nextsent>this approach has the advantage of being simple, only relying on easily computable low-level features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2805">
<title id=" W08-0101.xml">optimizing end pointing thresholds using dialogue features in a spoken dialogue system </title>
<section> silences and dialogue features.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 overview of the data.
</prevsent>
<prevsent>3.1.1 the lets go corpus lets go is telephone-based spoken dialogue system that provides bus schedule information for the pittsburgh metropolitan area.
</prevsent>
</prevsection>
<citsent citstr=" W07-0305 ">
it is built on the olympus architecture (bohus et al , 2007), <papid> W07-0305 </papid>using the raven claw dialogue management framework, and the apollo interaction manager (raux et al , 2007) as core components.</citsent>
<aftsection>
<nextsent>outside of business hours callers to the bus companys customer service are offered the option to use lets go.
</nextsent>
<nextsent>all calls are recorded and extensively logged for further analysis.
</nextsent>
<nextsent>the corpus used for this study was collected between december 26, 2007 and january 25, 2008, with total of 1326 dialogues, and 18013 user turns.
</nextsent>
<nextsent>of the calls that had at least 4 user turns, 73% were complete, meaning that the system provided some schedule information to the user.while working on real user data has its advantages (large amounts of data, increased validity of the results), it also has its challenges.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2806">
<title id=" W08-0702.xml">bayesian learning over conflicting data predictions for language change </title>
<section> the bayesian learner.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 mixed-grammar hypotheses.
</prevsent>
<prevsent>before we can assess the performance of the bayesian learner with respect to the ug-delimited hprinciple we must make sure we consider all potential competitor hypotheses that might be better predictors of the data than those examined so far.in particular, it is instructive to introduce something like class of null hypotheses: hybrid grammars which explicitly encode equality between any pair of competing alternatives?
</prevsent>
</prevsection>
<citsent citstr=" P99-1055 ">
ability to explain the data 5 . 5 the effect of mixed-grammar hypotheses can also be realized by allowing selection procedure over set of simple grammars, as described in section 3.2, but, crucially, with the weights calculated under the assumption that data are generated by combination of grammars (see, for example, the variational model proposed by yang (1999), <papid> P99-1055 </papid>or the 6 define this class as follows: the posterior probability that the hypothesis null(i/j) ? assigns to stress class is calculated by allotting equal probability to selecting the i ? or the j ? rule to produce an output of that class: ? p(c | null(i / j) ? , y) = i p(c |h ? , y) + j p(c |h ? , y) (6) where i = j = .5.</citsent>
<aftsection>
<nextsent>from equation (6) and the definition in [3], we can compute the probability distribution of stress assignment given the application of null(i/j) ? to particular word, [4] null(i/j) ? : null hypothesis?
</nextsent>
<nextsent>p(c | null(i / j) ? , y) = 1?
</nextsent>
<nextsent>2?
</nextsent>
<nextsent>c = i (y) = j (y) 1??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2807">
<title id=" W08-0702.xml">bayesian learning over conflicting data predictions for language change </title>
<section> the bayesian learner.  </section>
<citcontext>
<prevsection>
<prevsent>c ? i (y) &c; ? j (y) ? ?
</prevsent>
<prevsent>when i = gujarati* and j = gujarati, max(g*/g) ? assigns the highest posterior of any we have seen so far (approximately 56 orders of magnitude larger than g*).
</prevsent>
</prevsection>
<citsent citstr=" W06-3207 ">
this is because, with inthe space of candidates, it gives the highest likelihood to the observed data, and the prior probability probabilistic version of optimality theory over rankings utilized by jarosz (2006)).<papid> W06-3207 </papid></citsent>
<aftsection>
<nextsent>(assumed so far to be uniform) plays no role in this calculation.
</nextsent>
<nextsent>as the hypotheses we are considering become more complicated, however, we are led to consider an alternative to this assumption, one in which hypotheses with longer description lengths, or greater complexity, are penalized (rissanen 1989).
</nextsent>
<nextsent>3.4 non-uniform prior: hypothesis description.
</nextsent>
<nextsent>length under the uniform prior assumption, only with lexicon in which gujarati* accounts for at least 44 times as much data as does gujarati will max(g*/g) ? be defeated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2808">
<title id=" W08-0335.xml">improved statistical machine translation by multiple chinese word segmentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>chinese word segmentation (cws) is necessary step in chinese-english statistical machine translation (smt).
</prevsent>
<prevsent>the research on cws independently from smt has been conducted for decades.
</prevsent>
</prevsection>
<citsent citstr=" I05-3017 ">
as an evidence, the cws evaluation campaign, the sighan bakeoff (emerson, 2005),<papid> I05-3017 </papid>1, has been held four times since 2004.</citsent>
<aftsection>
<nextsent>however, works on relations between cws and smt are scarce.
</nextsent>
<nextsent>generally, two factors need to be considered in constructing cws system.
</nextsent>
<nextsent>the first one is the specifications for cws, i.e., the rules or guidelines for word segmentation, and the second one is the cws methods.
</nextsent>
<nextsent>there are many cws specifications used by different organizations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2810">
<title id=" W08-0335.xml">improved statistical machine translation by multiple chinese word segmentation </title>
<section> cws specifications and corpora from.  </section>
<citcontext>
<prevsection>
<prevsent>this enabled us to examine the effect of cws specifications on smt.
</prevsent>
<prevsent>we used chinese word segmentation tool, achilles, to implement word segmentation.
</prevsent>
</prevsection>
<citsent citstr=" N06-2049 ">
part of the work using this tool was described by (zhang et al, 2006).<papid> N06-2049 </papid></citsent>
<aftsection>
<nextsent>the approach was reported to achieve the highest word segmentation accuracy using the data from the second sighan bakeoff.
</nextsent>
<nextsent>moreover, this tool meets our need to test the effect of the two kinds of cws approaches for smt.
</nextsent>
<nextsent>we can easily train dictionary-based and crf-based cws by using this tool.
</nextsent>
<nextsent>by turning the programs option for the crf model on and off, we can use the achilles as dictionary-based approach and as crf-based cws.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2811">
<title id=" W08-0335.xml">improved statistical machine translation by multiple chinese word segmentation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we used the corpus, ldc2006e43, as the development data for loglinear model optimization.
</prevsent>
<prevsent>we used phrase-based smt system that is basedon log-linear model incorporating multiple features.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the training and decoding system of our smt used the publicly available pharaoh (koehn et al, 2003)<papid> N03-1017 </papid>2.</citsent>
<aftsection>
<nextsent>giza++ was used for word alignment.
</nextsent>
<nextsent>the pharaoh decoder was used exclusively in all the experiments.
</nextsent>
<nextsent>no additional features but the defaults defined by pharaoh were used.
</nextsent>
<nextsent>the feature weights were optimized against the bleu scores (och, 2003).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2812">
<title id=" W08-0335.xml">improved statistical machine translation by multiple chinese word segmentation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the pharaoh decoder was used exclusively in all the experiments.
</prevsent>
<prevsent>no additional features but the defaults defined by pharaoh were used.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the feature weights were optimized against the bleu scores (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>we chose automatic metrics to evaluate cws and smt.
</nextsent>
<nextsent>we used the f-score for cws and bleu for smt.
</nextsent>
<nextsent>the bleu is bleu4, computed using the nist-provided mt-eval?
</nextsent>
<nextsent>script.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2813">
<title id=" W08-0335.xml">improved statistical machine translation by multiple chinese word segmentation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the second group contains two schemes 13 and 14.
</prevsent>
<prevsent>the ictclas is hhmm-based hierarchical.
</prevsent>
</prevsection>
<citsent citstr=" W03-1730 ">
hmm segmenter (zhang et al, 2003) <papid> W03-1730 </papid>that uses the specifications of pku.</citsent>
<aftsection>
<nextsent>this segmenter incorporatesparts-of-speech information in the probability models and generates multiple hmm models for solving segmentation ambiguities.
</nextsent>
<nextsent>the msrseg was developed by gao et al (gao et al, 2004).<papid> P04-1059 </papid></nextsent>
<nextsent>this seg menter is based on the msr specifications.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2814">
<title id=" W08-0335.xml">improved statistical machine translation by multiple chinese word segmentation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>hmm segmenter (zhang et al, 2003) <papid> W03-1730 </papid>that uses the specifications of pku.</prevsent>
<prevsent>this segmenter incorporatesparts-of-speech information in the probability models and generates multiple hmm models for solving segmentation ambiguities.</prevsent>
</prevsection>
<citsent citstr=" P04-1059 ">
the msrseg was developed by gao et al (gao et al, 2004).<papid> P04-1059 </papid></citsent>
<aftsection>
<nextsent>this seg menter is based on the msr specifications.
</nextsent>
<nextsent>it uses log-linear model that integrates multiple features.
</nextsent>
<nextsent>the segment ers of the first group, dict-as and dict-ldc-as, are two dictionary-based cws schemes.
</nextsent>
<nextsent>they differ in lexicon size and lexicon extracting source.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2816">
<title id=" W08-0335.xml">improved statistical machine translation by multiple chinese word segmentation </title>
<section> effect of combining multiple cws.  </section>
<citcontext>
<prevsection>
<prevsent>si=1 = 1.
</prevsent>
<prevsent>s can be obtained by maximizing the likelihood or bleu scores of the development data.
</prevsent>
</prevsection>
<citsent citstr=" W07-0717 ">
optimizing the ? has been described elsewhere (foster and kuhn, 2007).<papid> W07-0717 </papid></citsent>
<aftsection>
<nextsent>p(e| ) is the phrase translation model generated.
</nextsent>
<nextsent>in addition to the phrase translation model, we used the same approach to integrate three other features: phrase inverse probability p( |e), lexical probability lex(e| , a), and lexical inverse probability lex( |e, a).
</nextsent>
<nextsent>we integrated the cws schemes ranked in thetop five in table 4: ictclas, dict-hybrid, dict ldc-pku, dict-cityu, and crf-as.
</nextsent>
<nextsent>we labeled the five schemes a, b, c, d, and e, respectively,as shown in table 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2818">
<title id=" W07-2023.xml">cmuat semantic distance and background knowledge for identifying semantic relations </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>we compute semantic distances to negative training examples as well, comparing the total positive and negative scores in order to decide whether relation is true or false in the test sentence.
</prevsent>
<prevsent>many systems which perform well on related tasks use syntactic features of the input sentence, coupled with classification by machine learning.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
this approach has been applied to problems like compound noun interpretation (rosario and hearst 2001) and semantic role labeling (gildea and jurafsky 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>in preparing our system for task 4, we started by applying similar syntax-based feature analysis to the trial data: 140 labeled examples of the relation content-container?.
</nextsent>
<nextsent>in 10-fold cross validation with this data we achieved an average fscore of 70.6, based on features similar to the subset trees used for semantic role labeling in (moschitti 2004).<papid> P04-1043 </papid></nextsent>
<nextsent>for classification we applied the updated tree-kernel package (moschitti 2006), <papid> E06-1015 </papid>distributed with the svm-light tool (joachims 1999) for learning support vector machines (svms).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2819">
<title id=" W07-2023.xml">cmuat semantic distance and background knowledge for identifying semantic relations </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>this approach has been applied to problems like compound noun interpretation (rosario and hearst 2001) and semantic role labeling (gildea and jurafsky 2002).<papid> J02-3001 </papid></prevsent>
<prevsent>in preparing our system for task 4, we started by applying similar syntax-based feature analysis to the trial data: 140 labeled examples of the relation content-container?.</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
in 10-fold cross validation with this data we achieved an average fscore of 70.6, based on features similar to the subset trees used for semantic role labeling in (moschitti 2004).<papid> P04-1043 </papid></citsent>
<aftsection>
<nextsent>for classification we applied the updated tree-kernel package (moschitti 2006), <papid> E06-1015 </papid>distributed with the svm-light tool (joachims 1999) for learning support vector machines (svms).</nextsent>
<nextsent>training data for task 4 is small, compared to other tasks where machine learning is commonly applied.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2820">
<title id=" W07-2023.xml">cmuat semantic distance and background knowledge for identifying semantic relations </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>in preparing our system for task 4, we started by applying similar syntax-based feature analysis to the trial data: 140 labeled examples of the relation content-container?.
</prevsent>
<prevsent>in 10-fold cross validation with this data we achieved an average fscore of 70.6, based on features similar to the subset trees used for semantic role labeling in (moschitti 2004).<papid> P04-1043 </papid></prevsent>
</prevsection>
<citsent citstr=" E06-1015 ">
for classification we applied the updated tree-kernel package (moschitti 2006), <papid> E06-1015 </papid>distributed with the svm-light tool (joachims 1999) for learning support vector machines (svms).</citsent>
<aftsection>
<nextsent>training data for task 4 is small, compared to other tasks where machine learning is commonly applied.
</nextsent>
<nextsent>we had difficulty finding combination of features which gave good performance in cross validation, but which did not result in separate support vector being stored for every training sentence ? possible indicator of overfitting.
</nextsent>
<nextsent>as an example, the ratio of support vectors to training 121 examples for the experiment described above was .97, nearly 1-to-1.
</nextsent>
<nextsent>as result of this analysis we started work on our knowledge-based system, with the goal of using the two approaches together.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2821">
<title id=" W07-2023.xml">cmuat semantic distance and background knowledge for identifying semantic relations </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>as result of this analysis we started work on our knowledge-based system, with the goal of using the two approaches together.
</prevsent>
<prevsent>we were also motivated by an interest in using relation definitions and background knowledge from wordnet to greater advantage.
</prevsent>
</prevsection>
<citsent citstr=" P06-1051 ">
the algorithm we used in our final submission is similar to recent systems which discover textual entailment relationships (haghig hi, ng et al 2005; zanzotto and moschitti 2006).<papid> P06-1051 </papid></citsent>
<aftsection>
<nextsent>it gives us way to encode information from the relation definitions directly, in the form of statements in knowledge representation language.
</nextsent>
<nextsent>the inference rules that are learned by this system from training examples are also easier to interpret than the models generated by an svm.
</nextsent>
<nextsent>in small data applications this can be an advantage.
</nextsent>
<nextsent>the example sentence below is taken (in abbreviated form) from the training data for task 4, relation 7 content-container?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2823">
<title id=" W07-1604.xml">detection of grammatical errors involving prepositions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>eeg-olofsson et al (2003) used 31 handcrafted matching rules to detect extraneous, omitted, and incorrect prepositions in swedish text written by native speakers of english, arabic, and japanese.
</prevsent>
<prevsent>the rules, which were based on the kinds of errors that were found in training set of text produced by non-native swedish writers, targeted spelling errors involving prepositions and some particularly problematic swedish verbs.
</prevsent>
</prevsection>
<citsent citstr=" P03-2026 ">
in test of the system, 11 of 40 preposition errors were correctly detected.izumi et al (2003) <papid> P03-2026 </papid>and (2004) used error annotated transcripts of japanese speakers in an interview-based test of spoken english to train maximum entropy classifier (ratnaparkhi, 1998) to recognize 13 different types of grammatical and lexical errors, including errors involving prepositions.</citsent>
<aftsection>
<nextsent>the classifier relied on lexical and syntactic features.
</nextsent>
<nextsent>overall performance for the 13 error types reached 25.1% precision with 7.1% recall on an independent test set of sentences from the same source, but the researchers do not separately report the results for preposition error detection.
</nextsent>
<nextsent>the approach taken by izumi and colleagues is most similar to the one we have used, which is described in the next section.
</nextsent>
<nextsent>more recently, (lee and seneff, 2006) used language model and stochastic grammar to replace prepositions removed from dialogue corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2824">
<title id=" W08-0327.xml">can we relearn an rbmt system </title>
<section> training without any human reference.  </section>
<citcontext>
<prevsection>
<prevsent>though human evaluation of these systems will provide additional insight, we try here to start analyzing the specificities of those systems.
</prevsent>
<prevsent>translation if the need in terms of monolingual corpus to build language models can most of the time be fulfilled without much problem, the reliance of statistical models on parallel corpora is much more problematic.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
work on domain adaptation for statistical machine translation (koehn and schroeder, 2007) <papid> W07-0733 </papid>tries to bring solutions to this issue.</citsent>
<aftsection>
<nextsent>statistical post-editing may well be another way to perform efficient domain-adaptation, but still requires parallel corpora.
</nextsent>
<nextsent>we try here to open new path.
</nextsent>
<nextsent>our submitted system for french-english on the europarl task is phrase based system, whose phrase table was trained on the rule based translation of the french europarl corpus.
</nextsent>
<nextsent>the french side of the europarl parallel corpus was translated with the baseline rule-based translation engine to produce the target side of the training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2825">
<title id=" W08-0123.xml">argumentative human computer dialogue for automated persuasion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the paper introduces layered management architecture that mixestask-oriented dialogue techniques with chatbot techniques to achieve better persuasiveness in the dialogue.
</prevsent>
<prevsent>human computer dialogue is wide research area in artificial intelligence.
</prevsent>
</prevsection>
<citsent citstr=" A00-1008 ">
computer dialogue is now used at production stage for applications such as tutorial dialogue ? that helps teaching students (freedman, 2000) ? <papid> A00-1008 </papid>task-oriented dialogue ? that achieves particular, limited task, such as booking trip (allen et al, 2000) ? and chatbot dialogue(levy et al, 1997) ? that is used within entertainment and help systems.</citsent>
<aftsection>
<nextsent>none of these approaches use persuasion as mechanism to achieve dialogue goals.
</nextsent>
<nextsent>however,research towards the use of persuasion in human computer interactions has spawned around the field of natural argumentation (norman and reed,2003).
</nextsent>
<nextsent>similarly research on embodied conversational agents (eca) (bickmore and picard,2005) is also attempting to improve the persuasiveness of agents with persuasion techniques; how ever, it concentrates on the visual representation of the interlocutor rather than the dialogue management.
</nextsent>
<nextsent>previous research on human computer dialogue has rarely focused on persuasive techniques (guerini, stock, and zancanaro, 2004, initiated some research in that field).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2826">
<title id=" W08-0123.xml">argumentative human computer dialogue for automated persuasion </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>eventually, this translates into more persuasive dialogue (see section 6).
</prevsent>
<prevsent>persuasion through dialogue is novel field of human computer interaction.
</prevsent>
</prevsection>
<citsent citstr=" W00-1407 ">
reiter, robertson, and osman (2003),reed (1998) and carenini and moore (2000) <papid> W00-1407 </papid>apply persuasive communication principles to natural language generation, but only focus on monologue.</citsent>
<aftsection>
<nextsent>the 3-tier planner for tutoring dialogue byzinn, moore, and core (2002) provides dialogue management technique close to our approach: top-tier generates dialogue plan, the middle-tier generates refinements to the plan and the bottom-tier generates utterances.
</nextsent>
<nextsent>mazzotta, de rosis, and carofiglio (2007) also propose planning framework for user-adapted persuasion where the plan operators are mapped to natural language (or eca) generation.
</nextsent>
<nextsent>how ever, these planning approaches do not include mechanism to react to users counterarguments that are difficult to plan beforehand.
</nextsent>
<nextsent>this paper propose novel approach that could improve the users comfort in the dialogue as well as its persuasiveness.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2827">
<title id=" W07-1905.xml">a person in the interface effects on user perceptions of multi biometrics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experience and enrich the interaction.
</prevsent>
<prevsent>some applications of ecas promise to bring us closer to achieving universal usability.
</prevsent>
</prevsection>
<citsent citstr=" P05-2007 ">
for instance, they can be used to communicate with hearing impaired people through sign language (huenerfauth, 2005) <papid> P05-2007 </papid>or lip-reading (beskow et al, 2004).</citsent>
<aftsection>
<nextsent>furthermore, language and the appearance, style, gesture repertoire and attitude of the character can be tuned to each applications context, to user preferences, and more importantly to take into account cultural particularities.
</nextsent>
<nextsent>the effects of animated characters on users and on the dynamics of user-system interaction are still unclear, as is the question of how to use them in order to maximize the benefits desired.
</nextsent>
<nextsent>however, the literature does report significant improvements in users?
</nextsent>
<nextsent>perception of the system and their interaction with it when the interface includes anani mated character (moundridou and virvou, 2001; mori et al, 2003; van mulken et al, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2828">
<title id=" W07-1425.xml">a compositional approach toward dynamic phrasal thesaurus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the second uses the family of tree kernels (collins and duffy, 2001; takahashi, 2005).
</prevsent>
<prevsent>the degree of equivalence of two trees (sentences) is defined as the number of common subtrees included in both trees.
</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
the third estimates the equivalence based onword alignment composed using templates or translation probabilities derived from set of parallel text (barzilay and lee, 2003; <papid> N03-1003 </papid>brockett and dolan,2005).<papid> I05-5001 </papid></citsent>
<aftsection>
<nextsent>the fourth espouses the distributional hypothesis (harris, 1968): given two words are likely to be equivalent if distributions of their surrounding words are similar (lin and pantel, 2001; weeds etal., 2005).<papid> W05-1202 </papid></nextsent>
<nextsent>the final regards two expressions equivalent if they can be associated by using set of lexico syntactic paraphrase patterns (melcuk, 1996; dras, 1999; yoshi kane et al, 1999; takahashi, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2829">
<title id=" W07-1425.xml">a compositional approach toward dynamic phrasal thesaurus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the second uses the family of tree kernels (collins and duffy, 2001; takahashi, 2005).
</prevsent>
<prevsent>the degree of equivalence of two trees (sentences) is defined as the number of common subtrees included in both trees.
</prevsent>
</prevsection>
<citsent citstr=" I05-5001 ">
the third estimates the equivalence based onword alignment composed using templates or translation probabilities derived from set of parallel text (barzilay and lee, 2003; <papid> N03-1003 </papid>brockett and dolan,2005).<papid> I05-5001 </papid></citsent>
<aftsection>
<nextsent>the fourth espouses the distributional hypothesis (harris, 1968): given two words are likely to be equivalent if distributions of their surrounding words are similar (lin and pantel, 2001; weeds etal., 2005).<papid> W05-1202 </papid></nextsent>
<nextsent>the final regards two expressions equivalent if they can be associated by using set of lexico syntactic paraphrase patterns (melcuk, 1996; dras, 1999; yoshi kane et al, 1999; takahashi, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2830">
<title id=" W07-1425.xml">a compositional approach toward dynamic phrasal thesaurus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the degree of equivalence of two trees (sentences) is defined as the number of common subtrees included in both trees.
</prevsent>
<prevsent>the third estimates the equivalence based onword alignment composed using templates or translation probabilities derived from set of parallel text (barzilay and lee, 2003; <papid> N03-1003 </papid>brockett and dolan,2005).<papid> I05-5001 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-1202 ">
the fourth espouses the distributional hypothesis (harris, 1968): given two words are likely to be equivalent if distributions of their surrounding words are similar (lin and pantel, 2001; weeds etal., 2005).<papid> W05-1202 </papid></citsent>
<aftsection>
<nextsent>the final regards two expressions equivalent if they can be associated by using set of lexico syntactic paraphrase patterns (melcuk, 1996; dras, 1999; yoshi kane et al, 1999; takahashi, 2005).
</nextsent>
<nextsent>despite the results previous work has achieved, no system that robustly recognizes and generates paraphrases is established.
</nextsent>
<nextsent>we are not convinced of hypothesis underlying the word-based approaches because the structure of words also conveys some meaning.
</nextsent>
<nextsent>even tree kernels, which take structures into account, do not have mechanism for identifying typical equivalents: e.g., dative alternation and passivization, and abilities to generate paraphrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2831">
<title id=" W07-1425.xml">a compositional approach toward dynamic phrasal thesaurus </title>
<section> dynamic phrasal thesaurus.  </section>
<citcontext>
<prevsection>
<prevsent>what sorts of phrases should be treated ? how to cope with variety of expressions although technologies of shallow parsing have been dramatically improved in the last decade, it is still difficult to represent arbitrary expression in logical form.
</prevsent>
<prevsent>we therefore think it is reasonable to define the range relying on lexico-syntactic structure instead of using particular semantic representation.
</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
according to the work of (chklovski and pantel, 2004; <papid> W04-3205 </papid>torisawa, 2006), <papid> N06-1008 </papid>predicate phrase (simple sentence) is reasonable unit because it approximately corresponds to the meaning of single event.combination of words and variety of construction coerce us into handling an enormous number of expressions than word-based approaches.</citsent>
<aftsection>
<nextsent>one may think taking phrase is like treading thorny path because one of the arguments in section 1 is about coverage.
</nextsent>
<nextsent>on this issue, we speculate thatone of the feasible approach to realize robust system is to divide phenomena into compositional andnon-compositional (idiosyncratic) ones1, and separately develop resources to handle them as described in (fujita and inui, 2005).<papid> I05-5004 </papid></nextsent>
<nextsent>to compute semantic equivalence of idiosyncratic paraphrases, pairs or groups of paraphrases have tobe static ally compiled into dictionary as word based thesaurus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2832">
<title id=" W07-1425.xml">a compositional approach toward dynamic phrasal thesaurus </title>
<section> dynamic phrasal thesaurus.  </section>
<citcontext>
<prevsection>
<prevsent>what sorts of phrases should be treated ? how to cope with variety of expressions although technologies of shallow parsing have been dramatically improved in the last decade, it is still difficult to represent arbitrary expression in logical form.
</prevsent>
<prevsent>we therefore think it is reasonable to define the range relying on lexico-syntactic structure instead of using particular semantic representation.
</prevsent>
</prevsection>
<citsent citstr=" N06-1008 ">
according to the work of (chklovski and pantel, 2004; <papid> W04-3205 </papid>torisawa, 2006), <papid> N06-1008 </papid>predicate phrase (simple sentence) is reasonable unit because it approximately corresponds to the meaning of single event.combination of words and variety of construction coerce us into handling an enormous number of expressions than word-based approaches.</citsent>
<aftsection>
<nextsent>one may think taking phrase is like treading thorny path because one of the arguments in section 1 is about coverage.
</nextsent>
<nextsent>on this issue, we speculate thatone of the feasible approach to realize robust system is to divide phenomena into compositional andnon-compositional (idiosyncratic) ones1, and separately develop resources to handle them as described in (fujita and inui, 2005).<papid> I05-5004 </papid></nextsent>
<nextsent>to compute semantic equivalence of idiosyncratic paraphrases, pairs or groups of paraphrases have tobe static ally compiled into dictionary as word based thesaurus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2833">
<title id=" W07-1425.xml">a compositional approach toward dynamic phrasal thesaurus </title>
<section> dynamic phrasal thesaurus.  </section>
<citcontext>
<prevsection>
<prevsent>according to the work of (chklovski and pantel, 2004; <papid> W04-3205 </papid>torisawa, 2006), <papid> N06-1008 </papid>predicate phrase (simple sentence) is reasonable unit because it approximately corresponds to the meaning of single event.combination of words and variety of construction coerce us into handling an enormous number of expressions than word-based approaches.</prevsent>
<prevsent>one may think taking phrase is like treading thorny path because one of the arguments in section 1 is about coverage.</prevsent>
</prevsection>
<citsent citstr=" I05-5004 ">
on this issue, we speculate thatone of the feasible approach to realize robust system is to divide phenomena into compositional andnon-compositional (idiosyncratic) ones1, and separately develop resources to handle them as described in (fujita and inui, 2005).<papid> I05-5004 </papid></citsent>
<aftsection>
<nextsent>to compute semantic equivalence of idiosyncratic paraphrases, pairs or groups of paraphrases have tobe static ally compiled into dictionary as word based thesaurus.
</nextsent>
<nextsent>the corpus-based approach is valuable for that purpose, although they are not guaranteed to collect all idiosyncratic paraphrases.
</nextsent>
<nextsent>on the other hand, compositional paraphrases can be captured by relatively small number of rules.
</nextsent>
<nextsent>thus itseems tolerable approach to generate them dynamically by applying such rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2834">
<title id=" W07-1425.xml">a compositional approach toward dynamic phrasal thesaurus </title>
<section> dynamic phrasal thesaurus.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 target language: japanese.
</prevsent>
<prevsent>while the discussion above does not depend on particular language, our implementation of dynamicphrasal thesaurus is targeted at japanese.
</prevsent>
</prevsection>
<citsent citstr=" P02-1028 ">
several methods for paraphrasing japanese predicate phrases have been proposed (kondo et al, 1999; kondo et al, 2001; kaji et al, 2002; <papid> P02-1028 </papid>fujita et al, 2005).</citsent>
<aftsection>
<nextsent>the range they treat is, however, relatively narrow because they tend to focus on particular paraphrase phenomena or to relyon existing resources.on the other hand, we define the range of phenomena from top-down viewpoint.
</nextsent>
<nextsent>as concrete definition of predicate phrase in japanese, noun phrase + case marker + predicate is employed which is hereafter referred to phrase.noun phrase and predicate in japanese themselves sub categorize various syntactic variants as shown in figure 1 and paraphrase phenomena for above phrase also involve those focused on their interaction.
</nextsent>
<nextsent>thus the range of phenomena is not so narrow, and intriguing ones, such as shown in exam ples2 (2) and (3), are included.
</nextsent>
<nextsent>1we regard lexical paraphrases (e.g., scope?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2835">
<title id=" W07-1425.xml">a compositional approach toward dynamic phrasal thesaurus </title>
<section> slm-based filtering.  </section>
<citcontext>
<prevsection>
<prevsent>from dictionary: retrieve all word pairs from the given set of words those satisfying the following four conditions: (i) beginning with kanji character, (ii) having different poss, (iii) sharing at least the first character and the first sound, and (iv) having suffix pattern which corresponds to at least two pairs.?
</prevsent>
<prevsent>using dictionary and corpus: generate candidates from set of words by applying set of typical suffix patterns, and then check if each candidate is an actual word using corpus.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
this is based on (langkilde and knight, 1998).<papid> P98-1116 </papid></citsent>
<aftsection>
<nextsent>step 2.
</nextsent>
<nextsent>manual selection: the set of word pairs collected in the previous step includes those do not have particular semantic relationship.
</nextsent>
<nextsent>this step involves human to discard noises.
</nextsent>
<nextsent>156 table 4 shows the size of 10 dictionaries, where each column denotes the number of word pairs retrieved from ipadic5 (|d|), those using ipadic, seven patterns and the same corpus as in section 3.4(|c|), their union (|d ? c|), and those manually judged correct (|j |), respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2836">
<title id=" W07-1425.xml">a compositional approach toward dynamic phrasal thesaurus </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>however,we have no sufficient condition to control the application of such knowledge.
</prevsent>
<prevsent>it has not been thoroughly clarified what clue canbe sufficient condition to ensure semantic equivalence, even in number of previous work.
</prevsent>
</prevsection>
<citsent citstr=" N07-1071 ">
though, at least, roles of participants in the event have to be preserved by some means, such as the way presented in (pantel et al, 2007).<papid> N07-1071 </papid></citsent>
<aftsection>
<nextsent>kaji et al (2002) <papid> P02-1028 </papid>introduceda method of case frame alignment in paraphrase gen eration.</nextsent>
<nextsent>in the model, arguments of main verb in the source are taken over by that of the target according to the similarities between arguments of the source and target.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2838">
<title id=" W07-1509.xml">semi automated named entity annotation </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>this class of models includes popular tagging models for named entities such as conditional random fields, maximum entropy markov models and max-margin markov networks.
</prevsent>
<prevsent>linear sequence models score possible tag sequences forgiven input as the dot product between learned weight vector and feature vector derived from the input and proposed tas sequence.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
linear sequence models differ principally on how the weight vector is learned.our experiments use the mira algorithm (cram mer et al, 2006; mcdonald et al, 2005) <papid> P05-1012 </papid>to learn the weight vector.</citsent>
<aftsection>
<nextsent>2.1 notation.
</nextsent>
<nextsent>in what follows, denotes the generic input sentence, (x) the set of possible labelings of x, and +(x) the set of correct labelings of x. there is also distinguished gold?
</nextsent>
<nextsent>labeling y(x) ? +(x).
</nextsent>
<nextsent>for each pair of sentence and labeling y (x), we compute vector-valued feature representation f(x, y).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2839">
<title id=" W07-1509.xml">semi automated named entity annotation </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>labeling y(x) ? +(x).
</prevsent>
<prevsent>for each pair of sentence and labeling y (x), we compute vector-valued feature representation f(x, y).
</prevsent>
</prevsection>
<citsent citstr=" W95-0107 ">
given weight vector w, the scorew ? f(x, y) ranks possible labelings of x, and we denote by yk,w(x) the set of top scoring labelings for x. we use the standard b,i,o encoding for named entities (ramshaw and marcus, 1995).<papid> W95-0107 </papid></citsent>
<aftsection>
<nextsent>thus (x) for of length is the set of all sequences of length matching the regular expression (o|(bi?))?.
</nextsent>
<nextsent>in linear sequence model, for suitable feature functions , yk,w(x) can be computed efficiently with viterbi decoding.
</nextsent>
<nextsent>2.2 k-best mira and loss functions the learning portion of our method finds weight vector that scores the correct labelings of the test data higher than incorrect labelings.
</nextsent>
<nextsent>we used k 53 best version of the mira algorithm (crammer et al., 2006; mcdonald et al, 2005).<papid> P05-1012 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2841">
<title id=" W07-1509.xml">semi automated named entity annotation </title>
<section> relation to previous work.  </section>
<citcontext>
<prevsection>
<prevsent>annotation the most common approach to semi-automatic annotation is to automatically tag an instance and then ask an annotator to correct the results.
</prevsent>
<prevsent>we restrict our discussion to this paradigm due to space constraints.
</prevsent>
</prevsection>
<citsent citstr=" H01-1026 ">
marcus et al (1994), chiou et al (2001) <papid> H01-1026 </papid>and xue et al (2002) apply this approach with some minor modifications to part of speech tagging and phrase structure parsing.</citsent>
<aftsection>
<nextsent>the automatic system of marcus et al only produces partial parses that are then assembled by the annotators, while chiou et al modified their automatic parser specifically for use in annotation.
</nextsent>
<nextsent>chou et al (2006) <papid> W06-0602 </papid>use this tag and correct approach to create corpus of predicate argument structures in the biomedical domain.</nextsent>
<nextsent>culota et al (2006) use refinement of the tag and correct approach to extract address book information from mail messages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2842">
<title id=" W07-1509.xml">semi automated named entity annotation </title>
<section> relation to previous work.  </section>
<citcontext>
<prevsection>
<prevsent>marcus et al (1994), chiou et al (2001) <papid> H01-1026 </papid>and xue et al (2002) apply this approach with some minor modifications to part of speech tagging and phrase structure parsing.</prevsent>
<prevsent>the automatic system of marcus et al only produces partial parses that are then assembled by the annotators, while chiou et al modified their automatic parser specifically for use in annotation.</prevsent>
</prevsection>
<citsent citstr=" W06-0602 ">
chou et al (2006) <papid> W06-0602 </papid>use this tag and correct approach to create corpus of predicate argument structures in the biomedical domain.</citsent>
<aftsection>
<nextsent>culota et al (2006) use refinement of the tag and correct approach to extract address book information from mail messages.
</nextsent>
<nextsent>they modify the systems best guessas the user makes corrections, resulting in less annotation actions.
</nextsent>
<nextsent>we now evaluate to what extent our semi-automated annotation framework can be useful, and how much effort it requires.
</nextsent>
<nextsent>for both questions we compare semi-automatic to fully manual annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2843">
<title id=" W08-0411.xml">syntax driven learning of sub sentential translation equivalents and translation rules from parsed parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these are then converted into synchronous context-free rules.
</prevsent>
<prevsent>we describe the approach and analyze its application to chinese-english parallel data.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
phrase-based statistical mt (pb-smt) (koehn et al., 2003) <papid> N03-1017 </papid>has become the predominant approach to machine translation in recent years.</citsent>
<aftsection>
<nextsent>pb-smt requires broad-coverage databases of phrase-to-phrasetranslation equivalents.
</nextsent>
<nextsent>these are commonly acquired from large volumes of automatically word aligned sentence-parallel text corpora.
</nextsent>
<nextsent>accurate identification of sub-sentential translation equivalents, however, is critical process in all data-driven mt approaches, including variety of data-driven syntax-based approaches that have been developed in recent years.
</nextsent>
<nextsent>(chiang, 2005) (<papid> P05-1033 </papid>imamura et al, 2004) (<papid> C04-1015 </papid>galley et al, 2004).<papid> N04-1035 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2844">
<title id=" W08-0411.xml">syntax driven learning of sub sentential translation equivalents and translation rules from parsed parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these are commonly acquired from large volumes of automatically word aligned sentence-parallel text corpora.
</prevsent>
<prevsent>accurate identification of sub-sentential translation equivalents, however, is critical process in all data-driven mt approaches, including variety of data-driven syntax-based approaches that have been developed in recent years.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
(chiang, 2005) (<papid> P05-1033 </papid>imamura et al, 2004) (<papid> C04-1015 </papid>galley et al, 2004).<papid> N04-1035 </papid></citsent>
<aftsection>
<nextsent>in this paper, we describe multi-step process for automatically learning reliable sub-sentential syntactic phrases that are translation equivalents of each other and syntactic translation rules between two languages.
</nextsent>
<nextsent>the input to the process is corpus of parallel sentences, word-aligned and annotated with phrase-structure parse trees for both languages.
</nextsent>
<nextsent>our method consists of three steps.
</nextsent>
<nextsent>in the first step, we apply newly developed algorithm for aligning parse-tree nodes between the two parallel trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2845">
<title id=" W08-0411.xml">syntax driven learning of sub sentential translation equivalents and translation rules from parsed parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these are commonly acquired from large volumes of automatically word aligned sentence-parallel text corpora.
</prevsent>
<prevsent>accurate identification of sub-sentential translation equivalents, however, is critical process in all data-driven mt approaches, including variety of data-driven syntax-based approaches that have been developed in recent years.
</prevsent>
</prevsection>
<citsent citstr=" C04-1015 ">
(chiang, 2005) (<papid> P05-1033 </papid>imamura et al, 2004) (<papid> C04-1015 </papid>galley et al, 2004).<papid> N04-1035 </papid></citsent>
<aftsection>
<nextsent>in this paper, we describe multi-step process for automatically learning reliable sub-sentential syntactic phrases that are translation equivalents of each other and syntactic translation rules between two languages.
</nextsent>
<nextsent>the input to the process is corpus of parallel sentences, word-aligned and annotated with phrase-structure parse trees for both languages.
</nextsent>
<nextsent>our method consists of three steps.
</nextsent>
<nextsent>in the first step, we apply newly developed algorithm for aligning parse-tree nodes between the two parallel trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2846">
<title id=" W08-0411.xml">syntax driven learning of sub sentential translation equivalents and translation rules from parsed parallel corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these are commonly acquired from large volumes of automatically word aligned sentence-parallel text corpora.
</prevsent>
<prevsent>accurate identification of sub-sentential translation equivalents, however, is critical process in all data-driven mt approaches, including variety of data-driven syntax-based approaches that have been developed in recent years.
</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
(chiang, 2005) (<papid> P05-1033 </papid>imamura et al, 2004) (<papid> C04-1015 </papid>galley et al, 2004).<papid> N04-1035 </papid></citsent>
<aftsection>
<nextsent>in this paper, we describe multi-step process for automatically learning reliable sub-sentential syntactic phrases that are translation equivalents of each other and syntactic translation rules between two languages.
</nextsent>
<nextsent>the input to the process is corpus of parallel sentences, word-aligned and annotated with phrase-structure parse trees for both languages.
</nextsent>
<nextsent>our method consists of three steps.
</nextsent>
<nextsent>in the first step, we apply newly developed algorithm for aligning parse-tree nodes between the two parallel trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2848">
<title id=" W08-0411.xml">syntax driven learning of sub sentential translation equivalents and translation rules from parsed parallel corpora </title>
<section> pfa algorithm for node aligment.  </section>
<citcontext>
<prevsection>
<prevsent>(tinsley et al, 2007) use statistical lexicons derived from automatic statistical word alignment for aligning nodes in parallel trees.
</prevsent>
<prevsent>in our approach, we use the word alignment information directly, which we believe may be more reliable than the statistical lexicon.
</prevsent>
</prevsection>
<citsent citstr=" C04-1154 ">
(groves etal., 2004) <papid> C04-1154 </papid>propose method of aligning nodes between parallel trees automatically, based on wordalignments.</citsent>
<aftsection>
<nextsent>in addition to the word alignment information, their approach uses the constituent labels of nodes in the trees, and the general structure of the tree.
</nextsent>
<nextsent>our approach is more general in the sense thatwe only consider the word alignments, thereby making the approach applicable to any parser or phrase structure representation, even ones that are quite different for the two languages involved.
</nextsent>
<nextsent>88 2.3 unaligned words and contiguity.
</nextsent>
<nextsent>word-level alignment of phrase-level translation equivalents often leaves some words unaligned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2849">
<title id=" W08-0411.xml">syntax driven learning of sub sentential translation equivalents and translation rules from parsed parallel corpora </title>
<section> synchronous tree fragment and cfg.  </section>
<citcontext>
<prevsection>
<prevsent>combination gave the best results, with precision of 0.6251, recall of 0.3566, thus an f-0.5 measure of 0.4996.
</prevsent>
<prevsent>rule extraction 5.1 related work.
</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
syntax-based reordering rules can be used as preprocessing step for pb-smt (and other approaches),to decrease the word-order and syntactic distortion between the source and target languages (xia and mccord, 2004).<papid> C04-1073 </papid></citsent>
<aftsection>
<nextsent>a variety of hierarchical andsyntax-based models, which are applied during decoding, have also been developed.
</nextsent>
<nextsent>many of these approaches involve automatic learning and extraction of the underlying syntax-based rules from data.
</nextsent>
<nextsent>the underlying formalisms used has been quite broad and include simple formalisms such as itgs (wu, 1997), <papid> J97-3002 </papid>hierarchical synchronous rules (chiang, 2005), <papid> P05-1033 </papid>string to tree models by (galley et al, 2004) <papid> N04-1035 </papid>and (galley et al, 2006), <papid> P06-1121 </papid>synchronous cfg models such (xia and mccord, 2004) (<papid> C04-1073 </papid>yamada and knight, 2001), <papid> P01-1067 </papid>synchronous lexical functional grammar inspired approaches (probst et al, 2002) and others.</nextsent>
<nextsent>most of the previous approaches for acquiring syntactic transferor reordering rules from parallel corpora use syntactic information from only one side of the parallel corpus, typically the target side.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2850">
<title id=" W08-0411.xml">syntax driven learning of sub sentential translation equivalents and translation rules from parsed parallel corpora </title>
<section> synchronous tree fragment and cfg.  </section>
<citcontext>
<prevsection>
<prevsent>a variety of hierarchical andsyntax-based models, which are applied during decoding, have also been developed.
</prevsent>
<prevsent>many of these approaches involve automatic learning and extraction of the underlying syntax-based rules from data.
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
the underlying formalisms used has been quite broad and include simple formalisms such as itgs (wu, 1997), <papid> J97-3002 </papid>hierarchical synchronous rules (chiang, 2005), <papid> P05-1033 </papid>string to tree models by (galley et al, 2004) <papid> N04-1035 </papid>and (galley et al, 2006), <papid> P06-1121 </papid>synchronous cfg models such (xia and mccord, 2004) (<papid> C04-1073 </papid>yamada and knight, 2001), <papid> P01-1067 </papid>synchronous lexical functional grammar inspired approaches (probst et al, 2002) and others.</citsent>
<aftsection>
<nextsent>most of the previous approaches for acquiring syntactic transferor reordering rules from parallel corpora use syntactic information from only one side of the parallel corpus, typically the target side.
</nextsent>
<nextsent>(hearne and way, 2003) describes an approach that uses syntactic information from the source side to derive reordering subtrees, which can then be used within data-oriented translation?
</nextsent>
<nextsent>(dot) mt system, similar in framework to (poutsma, 2000).<papid> C00-2092 </papid></nextsent>
<nextsent>ourwork is different from the above in that we use syntactic trees for both source and target sides to infer constituent node alignments, from which we then learn synchronous trees and rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2853">
<title id=" W08-0411.xml">syntax driven learning of sub sentential translation equivalents and translation rules from parsed parallel corpora </title>
<section> synchronous tree fragment and cfg.  </section>
<citcontext>
<prevsection>
<prevsent>a variety of hierarchical andsyntax-based models, which are applied during decoding, have also been developed.
</prevsent>
<prevsent>many of these approaches involve automatic learning and extraction of the underlying syntax-based rules from data.
</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
the underlying formalisms used has been quite broad and include simple formalisms such as itgs (wu, 1997), <papid> J97-3002 </papid>hierarchical synchronous rules (chiang, 2005), <papid> P05-1033 </papid>string to tree models by (galley et al, 2004) <papid> N04-1035 </papid>and (galley et al, 2006), <papid> P06-1121 </papid>synchronous cfg models such (xia and mccord, 2004) (<papid> C04-1073 </papid>yamada and knight, 2001), <papid> P01-1067 </papid>synchronous lexical functional grammar inspired approaches (probst et al, 2002) and others.</citsent>
<aftsection>
<nextsent>most of the previous approaches for acquiring syntactic transferor reordering rules from parallel corpora use syntactic information from only one side of the parallel corpus, typically the target side.
</nextsent>
<nextsent>(hearne and way, 2003) describes an approach that uses syntactic information from the source side to derive reordering subtrees, which can then be used within data-oriented translation?
</nextsent>
<nextsent>(dot) mt system, similar in framework to (poutsma, 2000).<papid> C00-2092 </papid></nextsent>
<nextsent>ourwork is different from the above in that we use syntactic trees for both source and target sides to infer constituent node alignments, from which we then learn synchronous trees and rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2855">
<title id=" W08-0411.xml">syntax driven learning of sub sentential translation equivalents and translation rules from parsed parallel corpora </title>
<section> synchronous tree fragment and cfg.  </section>
<citcontext>
<prevsection>
<prevsent>a variety of hierarchical andsyntax-based models, which are applied during decoding, have also been developed.
</prevsent>
<prevsent>many of these approaches involve automatic learning and extraction of the underlying syntax-based rules from data.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
the underlying formalisms used has been quite broad and include simple formalisms such as itgs (wu, 1997), <papid> J97-3002 </papid>hierarchical synchronous rules (chiang, 2005), <papid> P05-1033 </papid>string to tree models by (galley et al, 2004) <papid> N04-1035 </papid>and (galley et al, 2006), <papid> P06-1121 </papid>synchronous cfg models such (xia and mccord, 2004) (<papid> C04-1073 </papid>yamada and knight, 2001), <papid> P01-1067 </papid>synchronous lexical functional grammar inspired approaches (probst et al, 2002) and others.</citsent>
<aftsection>
<nextsent>most of the previous approaches for acquiring syntactic transferor reordering rules from parallel corpora use syntactic information from only one side of the parallel corpus, typically the target side.
</nextsent>
<nextsent>(hearne and way, 2003) describes an approach that uses syntactic information from the source side to derive reordering subtrees, which can then be used within data-oriented translation?
</nextsent>
<nextsent>(dot) mt system, similar in framework to (poutsma, 2000).<papid> C00-2092 </papid></nextsent>
<nextsent>ourwork is different from the above in that we use syntactic trees for both source and target sides to infer constituent node alignments, from which we then learn synchronous trees and rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2856">
<title id=" W08-0411.xml">syntax driven learning of sub sentential translation equivalents and translation rules from parsed parallel corpora </title>
<section> synchronous tree fragment and cfg.  </section>
<citcontext>
<prevsection>
<prevsent>most of the previous approaches for acquiring syntactic transferor reordering rules from parallel corpora use syntactic information from only one side of the parallel corpus, typically the target side.
</prevsent>
<prevsent>(hearne and way, 2003) describes an approach that uses syntactic information from the source side to derive reordering subtrees, which can then be used within data-oriented translation?
</prevsent>
</prevsection>
<citsent citstr=" C00-2092 ">
(dot) mt system, similar in framework to (poutsma, 2000).<papid> C00-2092 </papid></citsent>
<aftsection>
<nextsent>ourwork is different from the above in that we use syntactic trees for both source and target sides to infer constituent node alignments, from which we then learn synchronous trees and rules.
</nextsent>
<nextsent>our process of extraction of rules as synchronous trees and then converting them to synchronous cfg rules is most similar to that of (galley et al, 2004).<papid> N04-1035 </papid></nextsent>
<nextsent>5.2 synchronous tree fragment pair.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2859">
<title id=" W08-0411.xml">syntax driven learning of sub sentential translation equivalents and translation rules from parsed parallel corpora </title>
<section> synchronous tree fragment and cfg.  </section>
<citcontext>
<prevsection>
<prevsent>the other synchronous tree fragment pair consists of the remaining portions of the trees.
</prevsent>
<prevsent>the translation equivalence of the complete tree (or subtree) prior to decomposition implies that these tree fragments (which exclude the detached subtrees) also correspond to translation equivalents.
</prevsent>
</prevsection>
<citsent citstr=" C90-3045 ">
the tree fragments that are obtained by decomposing the synchronous trees in this fashion are similar to the synchronous tree insertion grammar of (shieber and schabes, 1990).<papid> C90-3045 </papid>we developed tree traversal algorithm that decomposes parallel trees into all minimal tree frag ments.</citsent>
<aftsection>
<nextsent>given two synchronous trees and their node alignment decomposition information, our tree fragment extraction algorithm operates by an in-order?
</nextsent>
<nextsent>traversal of the trees top down, starting from the root nodes.
</nextsent>
<nextsent>the traversal can be guided by either the source or target parse tree.
</nextsent>
<nextsent>each node in the tree that is marked as an aligned node triggers decomposition.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2860">
<title id=" W07-2097.xml">upvwsd  combining different wsd methods by means of fuzzy borda voting </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>then the preferences are evaluated using the fuzzy borda scheme in order to select the best sense.
</prevsent>
<prevsent>the methods we considered are the sense frequency probability calculated over semcor, the conceptual density calculated over both hyperonyms and meronyms hyerarchies in wordnet, the extended lesk by banerjee and pedersen, and finally method based on wordnet domains.
</prevsent>
</prevsection>
<citsent citstr=" W04-0820 ">
one of the lessons learned from our previous experience at senseval-31 (buscaldi et al, 2004; <papid> W04-0820 </papid>vazquez et al, 2004) is that the integration of different systems usually works better than standalone system.</citsent>
<aftsection>
<nextsent>in our opinion this reflects the reality where humans do not apply always the same rule in order to disambiguate the same ambigue word; for instance, if we consider the sentences he hit home run?
</nextsent>
<nextsent>and the thermometer hit 100 degrees?, in the first case the sport domain helps in determining the right sense for 1http://www.senseval.orghit, whereas in the latter the disambiguation is carried out mostly depending on the fact that the subject of the sentence is an object.
</nextsent>
<nextsent>the combination of distinct methods represents itself major problem.
</nextsent>
<nextsent>if the methods return different answers, how can we select the best one?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2861">
<title id=" W07-2097.xml">upvwsd  combining different wsd methods by means of fuzzy borda voting </title>
<section> wsd experts.  </section>
<citcontext>
<prevsection>
<prevsent>zero frequency are normalized to 1.
</prevsent>
<prevsent>3.2 conceptual density.
</prevsent>
</prevsection>
<citsent citstr=" C96-1005 ">
conceptual density (cd) was originally introduced by (agirre and rigau, 1996).<papid> C96-1005 </papid></citsent>
<aftsection>
<nextsent>it is computed on wordnet sub hierarchies, determined by the hyper nymy (or is-a) relationship.
</nextsent>
<nextsent>our formulation (rosso et al, 2003) of the conceptual density of wordnet sub hierarchy is: cd(m, f, n) = m?
</nextsent>
<nextsent>(m ) (4) 435where are the relevant synsets in the sub hierarchy, is the total number of synsets in the subhierar chy.the relevant synsets are both the synsets of the word to be disambiguated and those of the context words.the wsd system based on this formula participated at the senseval-3 competition as theciaosenso system (buscaldi et al, 2004), <papid> W04-0820 </papid>obtaining 75.3% in precision over nouns in the all words task (baseline: 70.1%).</nextsent>
<nextsent>these results were obtained with context window of two nouns, the one preceding and the one following the word.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2863">
<title id=" W07-2064.xml">sics valence annotation based on seeds in word space </title>
<section> seeds.  </section>
<citcontext>
<prevsection>
<prevsent>these words were chosen (subjectively) to represent typical expression of positive or negative attitude in news texts.
</prevsent>
<prevsent>the size of the seed set was determined by number of initial experiments on the development data, where we varied the size of the seed sets from these 8 words to some 700 words in each set (us ing the wordnet affect hierarchy (strapparava and valitutti, 2004)).
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
as comparison, turney and littman (2003) used seed sets consisting of 7 words in their word valence annotation experiments, while turney (2002) <papid> P02-1053 </papid>used minimal seed sets consisting of only one positive and one negative word (excellent?</citsent>
<aftsection>
<nextsent>and poor?)
</nextsent>
<nextsent>inhis experiments on review classification.
</nextsent>
<nextsent>such minimal seed sets of antonym pairs are not possible to use in the present experiment because they are often nearest neighbors to each other in the word space.
</nextsent>
<nextsent>also, it is difficult to find such clear paradigm words for the newswire domain.the seed words were used to postulate one positive and one negative point (i.e. vector) in the word space by simply taking the centro id of the seed word points:
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2864">
<title id=" W07-2040.xml">irstbp preposition disambiguation based on chain clarifying relationships contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a topical context is formed by the list of those words that are likely to co-occur with particular sense of word.
</prevsent>
<prevsent>generally, the wsd methods have marked predilection for topical context, with the consequence that structural clues are rarely, if ever, taken into account.
</prevsent>
</prevsection>
<citsent citstr=" W97-0109 ">
however, it has been suggested (stetina&nagao; 1997, <papid> W97-0109 </papid>dekang 1997) that structural words, especially prepositions and particles, play an important role in computing the lexical preferences considered to be the most important clues for disambiguation.</citsent>
<aftsection>
<nextsent>closed class words, prepositions in particular, are ambiguous (litkowski&hargraves2006;).<papid> W06-2106 </papid></nextsent>
<nextsent>their disambiguation is essential for the correct processing of the meaning of whole phrase.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2865">
<title id=" W07-2040.xml">irstbp preposition disambiguation based on chain clarifying relationships contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>generally, the wsd methods have marked predilection for topical context, with the consequence that structural clues are rarely, if ever, taken into account.
</prevsent>
<prevsent>however, it has been suggested (stetina&nagao; 1997, <papid> W97-0109 </papid>dekang 1997) that structural words, especially prepositions and particles, play an important role in computing the lexical preferences considered to be the most important clues for disambiguation.</prevsent>
</prevsection>
<citsent citstr=" W06-2106 ">
closed class words, prepositions in particular, are ambiguous (litkowski&hargraves2006;).<papid> W06-2106 </papid></citsent>
<aftsection>
<nextsent>their disambiguation is essential for the correct processing of the meaning of whole phrase.
</nextsent>
<nextsent>a wrong pp-attachment may render the sense of the whole sentence unintelligible.
</nextsent>
<nextsent>consider for example: (1) joe heard the gossip about you and me.
</nextsent>
<nextsent>(2) bob rowed about his old car and his mother.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2866">
<title id=" W08-0408.xml">multiple reorderings in phrase based machine translation </title>
<section> introduction and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>n is bounded by the computational requirements.
</prevsent>
<prevsent>recent work on reordering has been on trying to find smart?
</prevsent>
</prevsection>
<citsent citstr=" D07-1056 ">
ways to decide word order, using syntactic features such as pos tags (lee and ge 2005) , parse trees (zhang et.al, 2007, <papid> D07-1056 </papid>wang et.al. 2007, <papid> D07-1077 </papid>collins et.al. 2005, yamada and knight 2001) <papid> P01-1067 </papid>to name just few, and synchronized cfg (wu 1997, <papid> J97-3002 </papid>chiang 2005), <papid> P05-1033 </papid>again to name just few.</citsent>
<aftsection>
<nextsent>these efforts have shown promising improvements in translation quality.
</nextsent>
<nextsent>however, to use these features during decoding requires either separate decoder to be written or some ad-hoc mechanisms to be invented to incorporate them into an existing decoder, or in some cases (wang et. al. 2007) <papid> D07-1077 </papid>the input source is pre-ordered to be decoded monotonically.</nextsent>
<nextsent>(kanthak et. al. 2005) <papid> W05-0831 </papid>described framework in which different reordering methods are represented as search constraints to finite state automata.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2867">
<title id=" W08-0408.xml">multiple reorderings in phrase based machine translation </title>
<section> introduction and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>n is bounded by the computational requirements.
</prevsent>
<prevsent>recent work on reordering has been on trying to find smart?
</prevsent>
</prevsection>
<citsent citstr=" D07-1077 ">
ways to decide word order, using syntactic features such as pos tags (lee and ge 2005) , parse trees (zhang et.al, 2007, <papid> D07-1056 </papid>wang et.al. 2007, <papid> D07-1077 </papid>collins et.al. 2005, yamada and knight 2001) <papid> P01-1067 </papid>to name just few, and synchronized cfg (wu 1997, <papid> J97-3002 </papid>chiang 2005), <papid> P05-1033 </papid>again to name just few.</citsent>
<aftsection>
<nextsent>these efforts have shown promising improvements in translation quality.
</nextsent>
<nextsent>however, to use these features during decoding requires either separate decoder to be written or some ad-hoc mechanisms to be invented to incorporate them into an existing decoder, or in some cases (wang et. al. 2007) <papid> D07-1077 </papid>the input source is pre-ordered to be decoded monotonically.</nextsent>
<nextsent>(kanthak et. al. 2005) <papid> W05-0831 </papid>described framework in which different reordering methods are represented as search constraints to finite state automata.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2868">
<title id=" W08-0408.xml">multiple reorderings in phrase based machine translation </title>
<section> introduction and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>n is bounded by the computational requirements.
</prevsent>
<prevsent>recent work on reordering has been on trying to find smart?
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
ways to decide word order, using syntactic features such as pos tags (lee and ge 2005) , parse trees (zhang et.al, 2007, <papid> D07-1056 </papid>wang et.al. 2007, <papid> D07-1077 </papid>collins et.al. 2005, yamada and knight 2001) <papid> P01-1067 </papid>to name just few, and synchronized cfg (wu 1997, <papid> J97-3002 </papid>chiang 2005), <papid> P05-1033 </papid>again to name just few.</citsent>
<aftsection>
<nextsent>these efforts have shown promising improvements in translation quality.
</nextsent>
<nextsent>however, to use these features during decoding requires either separate decoder to be written or some ad-hoc mechanisms to be invented to incorporate them into an existing decoder, or in some cases (wang et. al. 2007) <papid> D07-1077 </papid>the input source is pre-ordered to be decoded monotonically.</nextsent>
<nextsent>(kanthak et. al. 2005) <papid> W05-0831 </papid>described framework in which different reordering methods are represented as search constraints to finite state automata.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2869">
<title id=" W08-0408.xml">multiple reorderings in phrase based machine translation </title>
<section> introduction and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>n is bounded by the computational requirements.
</prevsent>
<prevsent>recent work on reordering has been on trying to find smart?
</prevsent>
</prevsection>
<citsent citstr=" J97-3002 ">
ways to decide word order, using syntactic features such as pos tags (lee and ge 2005) , parse trees (zhang et.al, 2007, <papid> D07-1056 </papid>wang et.al. 2007, <papid> D07-1077 </papid>collins et.al. 2005, yamada and knight 2001) <papid> P01-1067 </papid>to name just few, and synchronized cfg (wu 1997, <papid> J97-3002 </papid>chiang 2005), <papid> P05-1033 </papid>again to name just few.</citsent>
<aftsection>
<nextsent>these efforts have shown promising improvements in translation quality.
</nextsent>
<nextsent>however, to use these features during decoding requires either separate decoder to be written or some ad-hoc mechanisms to be invented to incorporate them into an existing decoder, or in some cases (wang et. al. 2007) <papid> D07-1077 </papid>the input source is pre-ordered to be decoded monotonically.</nextsent>
<nextsent>(kanthak et. al. 2005) <papid> W05-0831 </papid>described framework in which different reordering methods are represented as search constraints to finite state automata.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2870">
<title id=" W08-0408.xml">multiple reorderings in phrase based machine translation </title>
<section> introduction and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>n is bounded by the computational requirements.
</prevsent>
<prevsent>recent work on reordering has been on trying to find smart?
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
ways to decide word order, using syntactic features such as pos tags (lee and ge 2005) , parse trees (zhang et.al, 2007, <papid> D07-1056 </papid>wang et.al. 2007, <papid> D07-1077 </papid>collins et.al. 2005, yamada and knight 2001) <papid> P01-1067 </papid>to name just few, and synchronized cfg (wu 1997, <papid> J97-3002 </papid>chiang 2005), <papid> P05-1033 </papid>again to name just few.</citsent>
<aftsection>
<nextsent>these efforts have shown promising improvements in translation quality.
</nextsent>
<nextsent>however, to use these features during decoding requires either separate decoder to be written or some ad-hoc mechanisms to be invented to incorporate them into an existing decoder, or in some cases (wang et. al. 2007) <papid> D07-1077 </papid>the input source is pre-ordered to be decoded monotonically.</nextsent>
<nextsent>(kanthak et. al. 2005) <papid> W05-0831 </papid>described framework in which different reordering methods are represented as search constraints to finite state automata.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2872">
<title id=" W08-0408.xml">multiple reorderings in phrase based machine translation </title>
<section> introduction and previous work.  </section>
<citcontext>
<prevsection>
<prevsent>these efforts have shown promising improvements in translation quality.
</prevsent>
<prevsent>however, to use these features during decoding requires either separate decoder to be written or some ad-hoc mechanisms to be invented to incorporate them into an existing decoder, or in some cases (wang et. al. 2007) <papid> D07-1077 </papid>the input source is pre-ordered to be decoded monotonically.</prevsent>
</prevsection>
<citsent citstr=" W05-0831 ">
(kanthak et. al. 2005) <papid> W05-0831 </papid>described framework in which different reordering methods are represented as search constraints to finite state automata.</citsent>
<aftsection>
<nextsent>it is able to compute distance-based and itg-style reordering automata.
</nextsent>
<nextsent>we differ from that approach in couple of ways.
</nextsent>
<nextsent>one is that in (kanthak et. al. 2005), <papid> W05-0831 </papid>an on-demand 61 reordering graph is pre-computed which is then taken as input for monotonic decoding.</nextsent>
<nextsent>we compute the reordering as the sentence is being decoded.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2874">
<title id=" W08-0408.xml">multiple reorderings in phrase based machine translation </title>
<section> reordering modules.  </section>
<citcontext>
<prevsection>
<prevsent>we present these four to demonstrate the ability of the framework to incorporate wide variety of reordering methods.
</prevsent>
<prevsent>3.1 distance-based skip reordering.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
this is the type of reordering first presented by (brown et.al. 1993) <papid> J93-2003 </papid>and was briefly alluded to in the above introduction section.</citsent>
<aftsection>
<nextsent>this method is controlled by 2 parameters: skip = number of words whose translations are to be delayed.
</nextsent>
<nextsent>let us call these words skipped words.
</nextsent>
<nextsent>window width (ww) = maximum number of words allowed to be translated before translating the skipped words.
</nextsent>
<nextsent>this reordering module outputs all the possible next source words to be translated according to these two parameters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2882">
<title id=" W08-0408.xml">multiple reorderings in phrase based machine translation </title>
<section> x deg nn nn deg 10 0.002  </section>
<citcontext>
<prevsection>
<prevsent>the reordering module not only proposes the next source segment according to the reordering patterns but also proposes monotone choices.
</prevsent>
<prevsent>this is because first, the parser is errorful.
</prevsent>
</prevsection>
<citsent citstr=" P03-1056 ">
in this work, we use the stanford parser (levy and manning 2003).<papid> P03-1056 </papid></citsent>
<aftsection>
<nextsent>on the last 929 sentences of chtb5, the parser achieves 81% label f-measure on true chtb5 word segmentation and drops to 65% on system segmentation using the stanford crf segmenter (tseng et.al. 2005).<papid> I05-3027 </papid></nextsent>
<nextsent>the second reason to let the decoder choose between reordering and monotone is other modules such as phrase tables and target lm can have an influence on the order choice too, especially when both reorder and monotone are acceptable as in the following example: ch: (my/mine/i/me) (deg/null) (book) english1: my book (monotone) english2: the book of mine (reorder) since the chinese has deg, our reordering rule will prefer to swap but monotone is often correct . in cases like these we let the other models, such as tm and lm, to also have say in deciding the outcome.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2883">
<title id=" W08-0408.xml">multiple reorderings in phrase based machine translation </title>
<section> x deg nn nn deg 10 0.002  </section>
<citcontext>
<prevsection>
<prevsent>this is because first, the parser is errorful.
</prevsent>
<prevsent>in this work, we use the stanford parser (levy and manning 2003).<papid> P03-1056 </papid></prevsent>
</prevsection>
<citsent citstr=" I05-3027 ">
on the last 929 sentences of chtb5, the parser achieves 81% label f-measure on true chtb5 word segmentation and drops to 65% on system segmentation using the stanford crf segmenter (tseng et.al. 2005).<papid> I05-3027 </papid></citsent>
<aftsection>
<nextsent>the second reason to let the decoder choose between reordering and monotone is other modules such as phrase tables and target lm can have an influence on the order choice too, especially when both reorder and monotone are acceptable as in the following example: ch: (my/mine/i/me) (deg/null) (book) english1: my book (monotone) english2: the book of mine (reorder) since the chinese has deg, our reordering rule will prefer to swap but monotone is often correct . in cases like these we let the other models, such as tm and lm, to also have say in deciding the outcome.
</nextsent>
<nextsent>the reordering module will present both choices to be produced.
</nextsent>
<nextsent>4 experiment results.
</nextsent>
<nextsent>we run our experiments on nist chinese-english mt03 and mt04 and also on weblog (wl) and broadcast news (bn) data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2884">
<title id=" W07-1028.xml">quantitative data on referring expressions in biomedical abstracts </title>
<section> problem statement.  </section>
<citcontext>
<prevsection>
<prevsent>the resolution of bridging anaphora, however, proves to be awkward because encyclopedic knowledge is necessary.1 but in practice, are all of these phenomena equally importanta look at the publications reveals that comprehensive overview of the quantity and distribution of referring expressions in biomedical abstracts is still missing.
</prevsent>
<prevsent>nevertheless, some scattered data can be found: castano et al (2002) state that 60 of 100 anaphora are nominal anaphora.
</prevsent>
</prevsection>
<citsent citstr=" W04-0711 ">
sanchez et al (2006) confirm this proportion (24 pronominal and 50 nominal anaphora in 74 anaphoric expressions).kim and park (2004), <papid> W04-0711 </papid>however, detect 53 pronominal and 26 nominal anaphora in 87 anaphoric expres sions.</citsent>
<aftsection>
<nextsent>but gawronska and erlendsson (2005), on the other hand, claim that pronominal anaphora are rare and nominal anaphora are predominant.
</nextsent>
<nextsent>studies on bridging anaphora in the biomedical domain are re 1however, even the resolution of pronouns can benefit from extra-textual information (castano et al, 2002).
</nextsent>
<nextsent>ally still missing.
</nextsent>
<nextsent>only cimiano (2003) states that 10% of definite descriptions are bridging anaphora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2885">
<title id=" W07-2019.xml">aug a combined classification and clustering approach for web people disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given the high ambiguity of person names and the increasing amount of information on the web, it becomes very important to organize this large amount of information into meaningful clusters referring each to one single individual.
</prevsent>
<prevsent>the problem of resolving name ambiguity onthe internet has been approached from different angles.
</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
mann and yarowsky (2003) <papid> W03-0405 </papid>have proposed aweb based clustering technique relying on feature space combining biographic facts and associated names, whereas bagga and baldwin (1998)<papid> P98-1012 </papid>have looked for coreference chains within each document, take the context of these chains for creating summaries about each entity and convert these summaries into bag of words.</citsent>
<aftsection>
<nextsent>documents get clustered using the standard vector space model.
</nextsent>
<nextsent>other researchers have taken this search for distinctive keywords one step further and tried to come up with concepts?
</nextsent>
<nextsent>describing the documents.
</nextsent>
<nextsent>fleischman and hovy (2004) <papid> W04-0701 </papid>introduce the maximum entropy model?: binary classifier determines whether twoconcept-instance pairs refer to the same individual.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2886">
<title id=" W07-2019.xml">aug a combined classification and clustering approach for web people disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given the high ambiguity of person names and the increasing amount of information on the web, it becomes very important to organize this large amount of information into meaningful clusters referring each to one single individual.
</prevsent>
<prevsent>the problem of resolving name ambiguity onthe internet has been approached from different angles.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
mann and yarowsky (2003) <papid> W03-0405 </papid>have proposed aweb based clustering technique relying on feature space combining biographic facts and associated names, whereas bagga and baldwin (1998)<papid> P98-1012 </papid>have looked for coreference chains within each document, take the context of these chains for creating summaries about each entity and convert these summaries into bag of words.</citsent>
<aftsection>
<nextsent>documents get clustered using the standard vector space model.
</nextsent>
<nextsent>other researchers have taken this search for distinctive keywords one step further and tried to come up with concepts?
</nextsent>
<nextsent>describing the documents.
</nextsent>
<nextsent>fleischman and hovy (2004) <papid> W04-0701 </papid>introduce the maximum entropy model?: binary classifier determines whether twoconcept-instance pairs refer to the same individual.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2887">
<title id=" W07-2019.xml">aug a combined classification and clustering approach for web people disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other researchers have taken this search for distinctive keywords one step further and tried to come up with concepts?
</prevsent>
<prevsent>describing the documents.
</prevsent>
</prevsection>
<citsent citstr=" W04-0701 ">
fleischman and hovy (2004) <papid> W04-0701 </papid>introduce the maximum entropy model?: binary classifier determines whether twoconcept-instance pairs refer to the same individual.</citsent>
<aftsection>
<nextsent>pedersen (2006) presented an unsupervised approach using bigrams in the contexts to be clustered, thus aiming at concept level semantic space instead of word level feature space.
</nextsent>
<nextsent>for the semeval contest, we approached the task from double supervised and unsupervised perspective.
</nextsent>
<nextsent>for the supervised classification, the task was redefined in the form of feature vectors containing disambiguating information on pairs of documents.
</nextsent>
<nextsent>in addition to this, different clustering approaches were applied on matrices of keywords.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2888">
<title id=" W07-2019.xml">aug a combined classification and clustering approach for web people disambiguation </title>
<section> datasets and feature construction.  </section>
<citcontext>
<prevsection>
<prevsent>section 4 gives an overview of the results on the test data and section 5 summarizes the main findings of the paper.
</prevsent>
<prevsent>105
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
the data we have used for training our system were made available in the framework of the semeval (task 13: web people search) competition (artileset al, 2007).<papid> W07-2012 </papid></citsent>
<aftsection>
<nextsent>as preliminary training corpus (re ferred to as trial data?
</nextsent>
<nextsent>in our article), we used the weps corpus (web people search corpus), available at http://nlp.uned.es/weps.
</nextsent>
<nextsent>for the real training set,this trial set was expanded in order to cover different degrees of ambiguity (very common names, uncommon names and celebrity names which tend to monopolize search results).
</nextsent>
<nextsent>the training corpus is composed of 40 sets of 100 web pages, each set corresponding to the first 100 results for person name query.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2890">
<title id=" W07-1806.xml">a bidirectional grammar based medical speech translator </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>medslt (bouillon et al, 2005) is an open source system of this type, which has been under construction at geneva university since 2003.
</prevsent>
<prevsent>the system is built on top of regulus (rayner et al, 2006), an open source platform which supports development ofgrammar-based speech-enabled applications.
</prevsent>
</prevsection>
<citsent citstr=" P05-3008 ">
regu lus has also been used to build several other systems, including nasas clarissa (rayner et al, 2005<papid> P05-3008 </papid>b).the most common architecture for speech translation today uses statistical methods to perform both speech recognition and translation, so it is worth clarifying why we have chosen to use grammar based methods.</citsent>
<aftsection>
<nextsent>even though statistical architectures exhibit many desirable properties (purely data driven, domain independent), this is not necessarily the best alternative in safety-critical medical applications.
</nextsent>
<nextsent>anecdotally, many physicians express reluctance to trust translation device whose out put is not readily predictable, and most of the speech translation systems which have reached the stage of field testing relyon various types ofgrammar-based recognition and rule-based translation (phraselator, 2007; fluent ial, 2007).statistical speech recognisers can achieve impressive levels of accuracy when trained on enough data,but it is daunting task to collect training material in the requisite quantities (usually, tens of thousands of high-quality utterances) when trying tobuild practical systems.
</nextsent>
<nextsent>considering that the medical speech translation applications we are interested in constructing here need to work for multiple languages and sub domains, the problem becomes even more challenging.
</nextsent>
<nextsent>our experience is that grammar based systems which also incorporate probabilistic context-free grammar tuning deliver better results than purely statistical ones when training data are sparse (rayner et al, 2005<papid> P05-3008 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2900">
<title id=" W07-1806.xml">a bidirectional grammar based medical speech translator </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>it is by no means obvious, however,that restricted coverage is such serious problem.
</prevsent>
<prevsent>in text processing, work on several generations of controlled language systems has developed range of techniques for keeping users within the bounds of system coverage (kittredge, 2003; mitamura, 1999), and variants of these methods can also be adapted for spoken language applications.
</prevsent>
</prevsection>
<citsent citstr=" W06-3702 ">
our experiments with medslt show that even quite simple help system is enough to guide users quickly towards the intended coverage of medium vocabulary grammar-based speech translation application, with most users appearing confident after just an hour or two of exposure (starlander et al, 2005; chatzichrisafis et al, 2006).<papid> W06-3702 </papid>until recently, the medslt system only supported unidirectional processing in the physician to patient direction.</citsent>
<aftsection>
<nextsent>the assumption was that the physician would mostly ask yes/no questions, to which the patient would respond non-verbally, for example by nodding or shaking their head.
</nextsent>
<nextsent>a unidirectional architecture is easier to make habitable than bidirectional one.
</nextsent>
<nextsent>it is reasonable to assume that the physician will use the system regularly enough to learn the coverage, but most patients will not have used the system before, and it is less clear that they will be able to acclimatize within the narrow window at their disposal.
</nextsent>
<nextsent>these considerations must however be balanced against the fact that unidirectional system does not allow for apatient-centered interaction characterized by meaningful patient-clinician communication or shared decisionmaking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2902">
<title id=" W07-1806.xml">a bidirectional grammar based medical speech translator </title>
<section> grammar-based processing.  </section>
<citcontext>
<prevsection>
<prevsent>for recognition, the grammar is then processed further into cfg language model, using an algorithm which alternates expansion of feature values and filtering of the partially expanded grammar to remove irrelevant rules.
</prevsent>
<prevsent>detailed descriptions of the ebl learning and feature grammar cfg compilation algorithms can be found in chapters 8 and 10 of (rayner et al, 2006).
</prevsent>
</prevsection>
<citsent citstr=" J90-1004 ">
regulus feature grammars can also be compiled into generators using version of the semantic head driven algorithm (shieber et al, 1990).<papid> J90-1004 </papid>the english (physician) side recogniser is compiled from the large english resource grammar described in chapter 9 of (rayner et al, 2006), andwas constructed in the same way as the one described in (rayner et al, 2005<papid> P05-3008 </papid>a), which was used fora headache examination task.</citsent>
<aftsection>
<nextsent>the ope rationality criteria are the same, and the only changes are different training corpus and the addition of new entries to the lexicon.
</nextsent>
<nextsent>the same resources, with different training corpus, were used to build the english language generator.
</nextsent>
<nextsent>it is worth pointing out that, although uniform method was used to build these various grammars, the results were all very different.
</nextsent>
<nextsent>for example, the recognition grammar from (rayner et al, 2005<papid> P05-3008 </papid>a) is specialised to cover only second-person questions (do you get headaches in the mornings??), while the generator grammar used in the present application covers only first person declarative statements (i visited the doctor last monday.?).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2920">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the labels on the arcs can represent basic grammatical relations such as subject?
</prevsent>
<prevsent>and object?.
</prevsent>
</prevsection>
<citsent citstr=" P04-1054 ">
dependency trees capture grammatical structures that can be useful in several language processing tasks such as information extraction (culotta &amp; sorensen, 2004) <papid> P04-1054 </papid>and machine translation (ding &amp; palmer, 2005).<papid> P05-1067 </papid></citsent>
<aftsection>
<nextsent>dependency treebanks are becoming available in many languages, and several approaches to dependency parsing on multiple languages have been evaluated in the conll 2006 and 2007 shared tasks (buchholz &amp; marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007).<papid> D07-1096 </papid></nextsent>
<nextsent>dependency parsing is simpler than constituency parsing, since dependency trees do not have extranon-terminal nodes and there is no need for grammar to generate them.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2921">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the labels on the arcs can represent basic grammatical relations such as subject?
</prevsent>
<prevsent>and object?.
</prevsent>
</prevsection>
<citsent citstr=" P05-1067 ">
dependency trees capture grammatical structures that can be useful in several language processing tasks such as information extraction (culotta &amp; sorensen, 2004) <papid> P04-1054 </papid>and machine translation (ding &amp; palmer, 2005).<papid> P05-1067 </papid></citsent>
<aftsection>
<nextsent>dependency treebanks are becoming available in many languages, and several approaches to dependency parsing on multiple languages have been evaluated in the conll 2006 and 2007 shared tasks (buchholz &amp; marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007).<papid> D07-1096 </papid></nextsent>
<nextsent>dependency parsing is simpler than constituency parsing, since dependency trees do not have extranon-terminal nodes and there is no need for grammar to generate them.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2922">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and object?.
</prevsent>
<prevsent>dependency trees capture grammatical structures that can be useful in several language processing tasks such as information extraction (culotta &amp; sorensen, 2004) <papid> P04-1054 </papid>and machine translation (ding &amp; palmer, 2005).<papid> P05-1067 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
dependency treebanks are becoming available in many languages, and several approaches to dependency parsing on multiple languages have been evaluated in the conll 2006 and 2007 shared tasks (buchholz &amp; marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007).<papid> D07-1096 </papid></citsent>
<aftsection>
<nextsent>dependency parsing is simpler than constituency parsing, since dependency trees do not have extranon-terminal nodes and there is no need for grammar to generate them.
</nextsent>
<nextsent>approaches to dependency parsing either generate such trees by considering all possible spanning trees (mcdonald et al, 2005), <papid> H05-1066 </papid>or build single tree by means of shift-reduce parsing actions (yamada &amp; matsumoto, 2003).</nextsent>
<nextsent>deterministic dependency parsers which run in linear time have also been developed (nivre &amp; scholz, 2004; <papid> C04-1010 </papid>attardi,2006).<papid> W06-2922 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2923">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and object?.
</prevsent>
<prevsent>dependency trees capture grammatical structures that can be useful in several language processing tasks such as information extraction (culotta &amp; sorensen, 2004) <papid> P04-1054 </papid>and machine translation (ding &amp; palmer, 2005).<papid> P05-1067 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
dependency treebanks are becoming available in many languages, and several approaches to dependency parsing on multiple languages have been evaluated in the conll 2006 and 2007 shared tasks (buchholz &amp; marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007).<papid> D07-1096 </papid></citsent>
<aftsection>
<nextsent>dependency parsing is simpler than constituency parsing, since dependency trees do not have extranon-terminal nodes and there is no need for grammar to generate them.
</nextsent>
<nextsent>approaches to dependency parsing either generate such trees by considering all possible spanning trees (mcdonald et al, 2005), <papid> H05-1066 </papid>or build single tree by means of shift-reduce parsing actions (yamada &amp; matsumoto, 2003).</nextsent>
<nextsent>deterministic dependency parsers which run in linear time have also been developed (nivre &amp; scholz, 2004; <papid> C04-1010 </papid>attardi,2006).<papid> W06-2922 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2924">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency treebanks are becoming available in many languages, and several approaches to dependency parsing on multiple languages have been evaluated in the conll 2006 and 2007 shared tasks (buchholz &amp; marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007).<papid> D07-1096 </papid></prevsent>
<prevsent>dependency parsing is simpler than constituency parsing, since dependency trees do not have extranon-terminal nodes and there is no need for grammar to generate them.</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
approaches to dependency parsing either generate such trees by considering all possible spanning trees (mcdonald et al, 2005), <papid> H05-1066 </papid>or build single tree by means of shift-reduce parsing actions (yamada &amp; matsumoto, 2003).</citsent>
<aftsection>
<nextsent>deterministic dependency parsers which run in linear time have also been developed (nivre &amp; scholz, 2004; <papid> C04-1010 </papid>attardi,2006).<papid> W06-2922 </papid></nextsent>
<nextsent>these parsers process the sentence sequentially, hence their efficiency makes them suitable for processing large amounts of text, as required, forex ample, in information retrieval applications.recent work on dependency parsing has highlighted the benefits of using rich feature setsand high-order modeling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2925">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency parsing is simpler than constituency parsing, since dependency trees do not have extranon-terminal nodes and there is no need for grammar to generate them.
</prevsent>
<prevsent>approaches to dependency parsing either generate such trees by considering all possible spanning trees (mcdonald et al, 2005), <papid> H05-1066 </papid>or build single tree by means of shift-reduce parsing actions (yamada &amp; matsumoto, 2003).</prevsent>
</prevsection>
<citsent citstr=" C04-1010 ">
deterministic dependency parsers which run in linear time have also been developed (nivre &amp; scholz, 2004; <papid> C04-1010 </papid>attardi,2006).<papid> W06-2922 </papid></citsent>
<aftsection>
<nextsent>these parsers process the sentence sequentially, hence their efficiency makes them suitable for processing large amounts of text, as required, forex ample, in information retrieval applications.recent work on dependency parsing has highlighted the benefits of using rich feature setsand high-order modeling.
</nextsent>
<nextsent>yamada and matsumoto (2003) showed that learning an svm modelin the dual space with higher-degree polynomial kernel functions improves significantly the parsers accuracy.
</nextsent>
<nextsent>mcdonald and pereira (2006) <papid> E06-1011 </papid>have shown that incorporating second order features relating to adjacent edge pairs improves the accuracy of maximum spanning tree parsers (mst).</nextsent>
<nextsent>in the svm based approach, if the training data is large, it is not feasible to train single model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2926">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency parsing is simpler than constituency parsing, since dependency trees do not have extranon-terminal nodes and there is no need for grammar to generate them.
</prevsent>
<prevsent>approaches to dependency parsing either generate such trees by considering all possible spanning trees (mcdonald et al, 2005), <papid> H05-1066 </papid>or build single tree by means of shift-reduce parsing actions (yamada &amp; matsumoto, 2003).</prevsent>
</prevsection>
<citsent citstr=" W06-2922 ">
deterministic dependency parsers which run in linear time have also been developed (nivre &amp; scholz, 2004; <papid> C04-1010 </papid>attardi,2006).<papid> W06-2922 </papid></citsent>
<aftsection>
<nextsent>these parsers process the sentence sequentially, hence their efficiency makes them suitable for processing large amounts of text, as required, forex ample, in information retrieval applications.recent work on dependency parsing has highlighted the benefits of using rich feature setsand high-order modeling.
</nextsent>
<nextsent>yamada and matsumoto (2003) showed that learning an svm modelin the dual space with higher-degree polynomial kernel functions improves significantly the parsers accuracy.
</nextsent>
<nextsent>mcdonald and pereira (2006) <papid> E06-1011 </papid>have shown that incorporating second order features relating to adjacent edge pairs improves the accuracy of maximum spanning tree parsers (mst).</nextsent>
<nextsent>in the svm based approach, if the training data is large, it is not feasible to train single model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2927">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these parsers process the sentence sequentially, hence their efficiency makes them suitable for processing large amounts of text, as required, forex ample, in information retrieval applications.recent work on dependency parsing has highlighted the benefits of using rich feature setsand high-order modeling.
</prevsent>
<prevsent>yamada and matsumoto (2003) showed that learning an svm modelin the dual space with higher-degree polynomial kernel functions improves significantly the parsers accuracy.
</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
mcdonald and pereira (2006) <papid> E06-1011 </papid>have shown that incorporating second order features relating to adjacent edge pairs improves the accuracy of maximum spanning tree parsers (mst).</citsent>
<aftsection>
<nextsent>in the svm based approach, if the training data is large, it is not feasible to train single model.
</nextsent>
<nextsent>rather, yamada and matsumoto (see also (hall et al, 2006)) <papid> P06-2041 </papid>partition the training data in different sets, on the basis of part of-speech, then train one dual svm model per set.</nextsent>
<nextsent>while this approach simplifies the learning task it makes the parser more sensitive to the error rate of the pos tagger.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2929">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mcdonald and pereira (2006) <papid> E06-1011 </papid>have shown that incorporating second order features relating to adjacent edge pairs improves the accuracy of maximum spanning tree parsers (mst).</prevsent>
<prevsent>in the svm based approach, if the training data is large, it is not feasible to train single model.</prevsent>
</prevsection>
<citsent citstr=" P06-2041 ">
rather, yamada and matsumoto (see also (hall et al, 2006)) <papid> P06-2041 </papid>partition the training data in different sets, on the basis of part of-speech, then train one dual svm model per set.</citsent>
<aftsection>
<nextsent>while this approach simplifies the learning task it makes the parser more sensitive to the error rate of the pos tagger.
</nextsent>
<nextsent>the second-order mst algorithm has cubic time complexity.
</nextsent>
<nextsent>for non-projective languages the algorithm is np-hard and mcdonald and pereira (2006) <papid> E06-1011 </papid>introduce an approximate algorithm to handle such cases.</nextsent>
<nextsent>in this paper we extend shift reduce parsing withsecond-order feature maps which explicitly repre 133sent all feature pairs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2932">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, excellent efficiency/accuracy trade-off is achieved by using the perceptron algorithm, with out the need to resort to approximations, producing high-accuracy classifiers based on single model.we also evaluate novel set of features for parsing.
</prevsent>
<prevsent>recently various forms of shallow semantic processing have been investigated such as named entity recognition (ner), semantic role labeling (srl) and relation extraction.
</prevsent>
</prevsection>
<citsent citstr=" W05-0620 ">
syntactic parsing can provide useful features for these tasks; e.g., punyakanok et al (2005) show that full parsing is effective for semantic role labeling (see also related approaches evaluated within the connl 2005 shared task (carreras et al, 2005)).<papid> W05-0620 </papid></citsent>
<aftsection>
<nextsent>however, no evidence has been provided so far that annotated semantic information can be leveraged for improving parser performance.
</nextsent>
<nextsent>we report experiments showing that adding features extracted by an entity tagger improves the accuracy of dependency parser.
</nextsent>
<nextsent>a dependency parser takes as input sentence and returns dependency graph d. figure 1 shows dependency tree for the sentence last week cbs inc. canceled the people next door?.1.
</nextsent>
<nextsent>dependencies are represented as labeled arrows from the head ofthe relation to the modifier word; thus, in the example, inc.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2939">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> a shift-reduce parser </section>
<citcontext>
<prevsection>
<prevsent>the parsing algorithm is fully deterministic and has linear complexity.
</prevsent>
<prevsent>the parsers behavior can be described as repeatedly selecting and applying parsing rule to transform its state,while advancing through the sentence.
</prevsent>
</prevsection>
<citsent citstr=" W04-0308 ">
each token is analyzed once and decision is made locally concerning the action to take, that is, without considering global properties of the tree being built.nivre (2004) <papid> W04-0308 </papid>investigated the issue of (strict) incre mentality for this type of parsers; i.e., if at any pointof the analysis the processed input forms one connected structure.</citsent>
<aftsection>
<nextsent>nivre found that strict incrementality is not guaranteed within this parsing framework, although for correctly parsed trees the property holds in almost 90% of the cases.
</nextsent>
<nextsent>3.1 parsing algorithm.
</nextsent>
<nextsent>the state of the parser is represented by triple s, i,a?, where is the stack, is the list of input tokens that remain to be processed and is the arc 134 figure 1.
</nextsent>
<nextsent>a dependency tree from the penn treebank, with additional entity annotation from the bbn corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2941">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> a shift-reduce parser </section>
<citcontext>
<prevsection>
<prevsent>perceptron the problem of learning parsing model can be framed as classification task where each class yi ? represents one of possible parsing actions.each of such actions is associated with weight vector ? ird.
</prevsent>
<prevsent>given data point ? , d dimensional vector of binary features in the input space , parsing action is chosen with winner take-all discriminant function: estimateaction(x, ?) = argmax f(x, k) (4) when using linear classifier, such as the perceptron or svm, f(u,v) = u,v? is the inner product between vectors and v. we learn the parameters ? from the training data with the perceptron (rosemblatt, 1958), in the online multiclass formulation of the algorithm (cram mer &amp; singer, 2003) with uniform negative updates.
</prevsent>
</prevsection>
<citsent citstr=" W06-2925 ">
the perceptron has been used in previous work on dependency parsing by carreras et al (2006), <papid> W06-2925 </papid>with parser based on eisners algorithm (eisner, 2000), and also on incremental constituent parsing (collins &amp; roark, 2006).</citsent>
<aftsection>
<nextsent>also the mst parser of mcdonald uses variant of the perceptron algorithm (mcdon ald, 2006).
</nextsent>
<nextsent>the choice is motivated by the simplicity and performance of perceptrons, which have proved competitive on number of tasks; e.g., in shallow parsing, where perceptrons performance is comparable to that of conditional random field models (sha &amp; pereira, 2003).<papid> N03-1028 </papid></nextsent>
<nextsent>the only adjustable parameter of the model is the number of instances to use for training.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2942">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> a shift-reduce parser </section>
<citcontext>
<prevsection>
<prevsent>the perceptron has been used in previous work on dependency parsing by carreras et al (2006), <papid> W06-2925 </papid>with parser based on eisners algorithm (eisner, 2000), and also on incremental constituent parsing (collins &amp; roark, 2006).</prevsent>
<prevsent>also the mst parser of mcdonald uses variant of the perceptron algorithm (mcdon ald, 2006).</prevsent>
</prevsection>
<citsent citstr=" N03-1028 ">
the choice is motivated by the simplicity and performance of perceptrons, which have proved competitive on number of tasks; e.g., in shallow parsing, where perceptrons performance is comparable to that of conditional random field models (sha &amp; pereira, 2003).<papid> N03-1028 </papid></citsent>
<aftsection>
<nextsent>the only adjustable parameter of the model is the number of instances to use for training.
</nextsent>
<nextsent>we fixed using the development portion of the data.
</nextsent>
<nextsent>in our experiments, the best value is between 20 and 30 times the size of the training data.
</nextsent>
<nextsent>to regularize the model we take as the final model the average of all weight vectors posited during training (collins,2002).<papid> W02-1001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2943">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> a shift-reduce parser </section>
<citcontext>
<prevsection>
<prevsent>we fixed using the development portion of the data.
</prevsent>
<prevsent>in our experiments, the best value is between 20 and 30 times the size of the training data.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
to regularize the model we take as the final model the average of all weight vectors posited during training (collins,2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>algorithm 2 illustrates the perceptron learning procedure.
</nextsent>
<nextsent>the final average model can be computed efficiently during training without storing the individual ? vectors (e.g., see (ciaramita &amp; johnson, 2003)).<papid> W03-1022 </papid></nextsent>
<nextsent>algorithm 2: average multiclass perceptron input : = (xi, yi)n ;0k = ~0, ? for = 1 to do choose et = {r ? : xj , tr?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2944">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> a shift-reduce parser </section>
<citcontext>
<prevsection>
<prevsent>to regularize the model we take as the final model the average of all weight vectors posited during training (collins,2002).<papid> W02-1001 </papid></prevsent>
<prevsent>algorithm 2 illustrates the perceptron learning procedure.</prevsent>
</prevsection>
<citsent citstr=" W03-1022 ">
the final average model can be computed efficiently during training without storing the individual ? vectors (e.g., see (ciaramita &amp; johnson, 2003)).<papid> W03-1022 </papid></citsent>
<aftsection>
<nextsent>algorithm 2: average multiclass perceptron input : = (xi, yi)n ;0k = ~0, ? for = 1 to do choose et = {r ? : xj , tr?
</nextsent>
<nextsent>xj , ? yj ?} if |et|   0 then t+1r = ? r ? xj |et| , ? t t+1yj = ? yj + xj output: = 1t ? ? k, ? 3.4 higher-order feature spaces.
</nextsent>
<nextsent>yamada and matsumoto (2003) and mcdonald and pereira (2006) <papid> E06-1011 </papid>have shown that higher-order feature representations and modeling can improve parsing accuracy, although at significant computational costs.</nextsent>
<nextsent>to make svm training feasible in the dual model with polynomial kernels, yamada and matsumoto split the training data into several sets, based on pos tags, and train parsing model for each set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2946">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> semantic features.  </section>
<citcontext>
<prevsection>
<prevsent>charniaks 1997 parser (1997), defined probability estimates backed off to word clusters.
</prevsent>
<prevsent>collins and koo (collins &amp; koo, 2005) introduced an improved reranking model for parsing which includes hidden layer of semantic features.
</prevsent>
</prevsection>
<citsent citstr=" W05-0639 ">
yi and palmer (2005) <papid> W05-0639 </papid>retrained constituent pars erin which phrases were annotated with argument information to improve srl, however this didnt im prove over the output of the basic parser.</citsent>
<aftsection>
<nextsent>in recent years there has been significant amount of work on semantic annotation tasks such as named-entity recognition, semantic role labeling and relation extraction.
</nextsent>
<nextsent>there is evidence that dependency and constituent parsing can be helpful inthese and other tasks; e.g., by means of tree kernels in question classification and semantic role labeling (zhang &amp; lee, 2003; moschitti, 2006).
</nextsent>
<nextsent>it is natural to ask if also the opposite holds:whether semantic annotations can be used to im prove parsing.
</nextsent>
<nextsent>in particular, it would be interesting to know if entity-like tags can be used for this purpose.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2947">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> semantic features.  </section>
<citcontext>
<prevsection>
<prevsent>we treated semantic tags as pos tags.
</prevsent>
<prevsent>a tagger was trained on the bbn gold standard annotation and used it to annotate development and evaluation data.
</prevsent>
</prevsection>
<citsent citstr=" W06-1670 ">
we briefly describe the tagger (see (ciaramita &amp; altun, 2006) <papid> W06-1670 </papid>for more details), hidden markov model trained with the perceptron algorithm introduced in (collins, 2002).<papid> W02-1001 </papid></citsent>
<aftsection>
<nextsent>the tagger uses viterbi decoding.
</nextsent>
<nextsent>label to label dependencies are limited tothe previous tag (first order hmm).
</nextsent>
<nextsent>a generic feature set for ner based on words, lemmas, pos tags, and word shape features was used.
</nextsent>
<nextsent>the tagger is trained on sections 2-21 of the bbn corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2949">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> parsing experiments.  </section>
<citcontext>
<prevsection>
<prevsent>as final remark we notice that the taggers complexity, linear in the length of the sentence, preserves the parsers complexity.
</prevsent>
<prevsent>5.1 data and setup.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we used the standard partitions of the wall street journal penn treebank (marcus et al, 1993); <papid> J93-2004 </papid>i.e.,sections 2-21 for training, section 22 for development and section 23 for evaluation.</citsent>
<aftsection>
<nextsent>the constituent trees were transformed into dependency trees by means of program created by joakim nivre that implements the rules proposed by yamada and matsumoto, which in turn are based on the head rules of collins?
</nextsent>
<nextsent>parser (collins, 1999)5.
</nextsent>
<nextsent>the lemma foreach token was produced using the morph?
</nextsent>
<nextsent>function of the wordnet (fellbaum, 1998) library6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2954">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> parsing experiments.  </section>
<citcontext>
<prevsection>
<prevsent>a possible simple exaplanation is that some information captured by the semantic features is correlated with other higher-order features which do not occur in the 1st-order encoding.
</prevsent>
<prevsent>overall the accuracy of the desr parser with semantic information is slightly inferior to that of the second-order mst parser (mcdonald &amp; pereira, 2006) (<papid> E06-1011 </papid>91.5% uas).</prevsent>
</prevsection>
<citsent citstr=" N06-2033 ">
the best result on this dataset to date (92.7% uas) is that of sagae and lavie (sagae &amp; lavie,2006) <papid> N06-2033 </papid>who use parser which combines the predictions of several pre-existing parsers, including mcdonalds and nivres parsers.</citsent>
<aftsection>
<nextsent>table 5 lists the main results to date on the version of the penn treebank for dependency parsing task used in this paper.
</nextsent>
<nextsent>in table 4 we also evaluate the gain obtained by adding one semantic feature type at time (cf.
</nextsent>
<nextsent>rowseos/bio/tag).
</nextsent>
<nextsent>these results show that all semantic features provide some improvement (with the dubious case of eos in the 2nd-order model).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2958">
<title id=" W07-2217.xml">dependency parsing with second order feature maps and annotated semantic information </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>although the magnitude of the improvement is not striking, to the best of our knowledge this is the first encouraging evidence that annotated semantic information can improve parsing and suggests several options for further research.
</prevsent>
<prevsent>for example, this finding might indicate that this type of approach, which combines semantic tagging and parsing, is viable for the adaptation of parsing to new domains for which semantic taggers exist.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
semantic features could be also easily included in other types of dependency parsing algorithms, e.g., mst,and in current methods for constituent parse reranking (collins, 2000; charniak &amp; johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>for future research several issues concerning the semantic features could be tackled.
</nextsent>
<nextsent>we notice that more complex semantic features can be designed and evaluated.
</nextsent>
<nextsent>for example, it might be useful toguess the head?
</nextsent>
<nextsent>of segments with simple heuristics, i.e., the guess the node which is more likely to connect the segment with the rest of the tree, which all internal components of the entity depend upon.it would be also interesting to extract semantic features from taggers trained on different datasets and based on different tagsets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2959">
<title id=" W07-1219.xml">local ambiguity packing and discontinuity in german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>incontext-free grammars augmented with unification formalism, packing based on the cf symbol equality has been complemented by subsumption- or disjunction-based packing of the associated feature structures (moore and alshawi, 1992; maxwell and kaplan, 1995).
</prevsent>
<prevsent>for parsing with constraint-based grammars, such as hpsg, which do not possess an explicit context-free backbone, (oepen and carroll, 2000) have proposed an efficient packing algorithm based on feature structure subsumption only.in contrast to the symbols in context-free grammars, feature structures in unification-based grammars often include information encoding (part of)the derivation history, most notably semantics.
</prevsent>
</prevsection>
<citsent citstr=" P85-1018 ">
in order to achieve successful packing rates, feature restriction (shieber, 1985) <papid> P85-1018 </papid>is used to remove this information during creation of the packed parse forest.</citsent>
<aftsection>
<nextsent>during the unpacking phase, which operates only on successful parse trees, these features are unified back in again.for their experiments with efficient subsumptionbased packing, (oepen and carroll, 2000) experimented with different settings of the packing restrictor for the english resource grammar erg (copes take and flickinger, 2000): they found that good packing rates, and overall good performance during forest creation and unpacking were achieved, for the erg, with partial restriction of the semantics, e.g. keeping index features unrestricted, since they have an impact on external combinatorial potential,but restricting most of the internal mrs representation, including the list of elementary predications and scope constraints.
</nextsent>
<nextsent>restriction of syntactically potent features, has thus been found both unnecessary and less efficient.
</nextsent>
<nextsent>first experiments in ambiguity packing with agerman hpsg grammar (gg; http://gg.dfki.de) revealed that restriction of semantics only does not give rise to any acceptible results in terms of runtime performance.
</nextsent>
<nextsent>it became clear quite quickly that the 144 bulk of failing subsumptions impeding creation of asufficiently compact forest were related to two syntactic features, slash and dsl.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2960">
<title id=" W07-2093.xml">up13 knowledge poor methods sometimes perform poorly </title>
<section> a (too) lazy approach  </section>
<citcontext>
<prevsection>
<prevsent>we chose not to use any part-of-speech tagger or syntactic or semantic analyzer; we did not use any external knowledge or any other annotated corpus than the one provided for the training phase.
</prevsent>
<prevsent>since no nlp tool was used, we had to duplicate most of the words in order to get the singular and the plural form.
</prevsent>
</prevsection>
<citsent citstr=" P03-1008 ">
our system is thus very simple compared to 418 the state-of-art in this domain (e.g. nissim and markert, 2003).<papid> P03-1008 </papid></citsent>
<aftsection>
<nextsent>we used discriminative plain words only.
</nextsent>
<nextsent>these are gathered as follows: all the words in given window (here we use 7 word window, before and after the target entity since it gave the best results on the training data) are extracted and associated with two classes (literal vs. non literal).
</nextsent>
<nextsent>we thus consider the most discriminative words, i.e. words that appear frequently in some contexts but not in others (literal vs. non-literal readings).
</nextsent>
<nextsent>discriminative words are elements that are abnormally frequent or rare in one corpus compared to another one.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2964">
<title id=" W07-2002.xml">semeval2007 task 02 evaluating word sense induction and discrimination systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word sense disambiguation (wsd) is key enabling-technology.
</prevsent>
<prevsent>supervised wsd techniques are the best performing in public evaluations, butneed large amounts of hand-tagging data.
</prevsent>
</prevsection>
<citsent citstr=" H93-1061 ">
existing hand-annotated corpora like semcor (miller et al, 1993), <papid> H93-1061 </papid>which is annotated with wordnet senses (fellbaum, 1998) allow for small improvement over the simple most frequent sense heuristic,as attested in the all-words track of the last senseval competition (snyder and palmer, 2004).<papid> W04-0811 </papid></citsent>
<aftsection>
<nextsent>in theory, larger amounts of training data (semcor hasapprox.
</nextsent>
<nextsent>500m words) would improve the performance of supervised wsd, but no current project exists to provide such an expensive resource.
</nextsent>
<nextsent>an other problem of the supervised approach is that the inventory and distribution of senses changes dramatically from one domain to the other, requiring additional hand-tagging of corpora (martnez and agirre, 2000; koeling et al, 2005).<papid> H05-1053 </papid></nextsent>
<nextsent>supervised wsd is based on the fixed-list of senses?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2965">
<title id=" W07-2002.xml">semeval2007 task 02 evaluating word sense induction and discrimination systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>word sense disambiguation (wsd) is key enabling-technology.
</prevsent>
<prevsent>supervised wsd techniques are the best performing in public evaluations, butneed large amounts of hand-tagging data.
</prevsent>
</prevsection>
<citsent citstr=" W04-0811 ">
existing hand-annotated corpora like semcor (miller et al, 1993), <papid> H93-1061 </papid>which is annotated with wordnet senses (fellbaum, 1998) allow for small improvement over the simple most frequent sense heuristic,as attested in the all-words track of the last senseval competition (snyder and palmer, 2004).<papid> W04-0811 </papid></citsent>
<aftsection>
<nextsent>in theory, larger amounts of training data (semcor hasapprox.
</nextsent>
<nextsent>500m words) would improve the performance of supervised wsd, but no current project exists to provide such an expensive resource.
</nextsent>
<nextsent>an other problem of the supervised approach is that the inventory and distribution of senses changes dramatically from one domain to the other, requiring additional hand-tagging of corpora (martnez and agirre, 2000; koeling et al, 2005).<papid> H05-1053 </papid></nextsent>
<nextsent>supervised wsd is based on the fixed-list of senses?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2966">
<title id=" W07-2002.xml">semeval2007 task 02 evaluating word sense induction and discrimination systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in theory, larger amounts of training data (semcor hasapprox.
</prevsent>
<prevsent>500m words) would improve the performance of supervised wsd, but no current project exists to provide such an expensive resource.
</prevsent>
</prevsection>
<citsent citstr=" H05-1053 ">
an other problem of the supervised approach is that the inventory and distribution of senses changes dramatically from one domain to the other, requiring additional hand-tagging of corpora (martnez and agirre, 2000; koeling et al, 2005).<papid> H05-1053 </papid></citsent>
<aftsection>
<nextsent>supervised wsd is based on the fixed-list of senses?
</nextsent>
<nextsent>paradigm, where the senses for target wordare closed list coming from dictionary or lexicon.
</nextsent>
<nextsent>lexicographers and semantic ists have long warned about the problems of such an approach,where senses are listed separately as discrete entities, and have argued in favor of more complex representations, where, for instance, senses are dense regions in continuum (cruse, 2000).unsupervised word sense induction and discrimination (wsid, also known as corpus-based unsupervised systems) has followed this line of thinking, and tries to induce word senses directly fromthe corpus.
</nextsent>
<nextsent>typical wsid systems involve clustering techniques, which group together similar examples.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2967">
<title id=" W07-2002.xml">semeval2007 task 02 evaluating word sense induction and discrimination systems </title>
<section> evaluating wsid systems.  </section>
<citcontext>
<prevsection>
<prevsent>a second alternative would be to devise method to map the clusters returned by the systems to the senses in lexicon.
</prevsent>
<prevsent>pantel and lin (2002) automatically map the senses to wordnet, and then measure the quality of the mapping.
</prevsent>
</prevsection>
<citsent citstr=" W04-2406 ">
more recently, the mapping has been used to test the system on publicly available benchmarks (purandare and pedersen, 2004; <papid> W04-2406 </papid>niu et al, 2005).<papid> W05-0605 </papid>a third alternative is to evaluate the systems according to some performance in an application, e.g. information retrieval (schutze, 1998).</citsent>
<aftsection>
<nextsent>this is very attractive idea, but requires expensive system development and it is sometimes difficult to separate the reasons for the good (or bad) performance.in this task we decided to adopt the first two alternatives, since they allow for comparison over publicly available systems of any kind.
</nextsent>
<nextsent>with this goal onmind we gave all the participants an unlabeled corpus, and asked them to induce the senses and create clustering solution on it.
</nextsent>
<nextsent>we evaluate the results according to the following types of evaluation: 1.
</nextsent>
<nextsent>evaluate the induced senses as clusters of ex-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2968">
<title id=" W07-2002.xml">semeval2007 task 02 evaluating word sense induction and discrimination systems </title>
<section> evaluating wsid systems.  </section>
<citcontext>
<prevsection>
<prevsent>a second alternative would be to devise method to map the clusters returned by the systems to the senses in lexicon.
</prevsent>
<prevsent>pantel and lin (2002) automatically map the senses to wordnet, and then measure the quality of the mapping.
</prevsent>
</prevsection>
<citsent citstr=" W05-0605 ">
more recently, the mapping has been used to test the system on publicly available benchmarks (purandare and pedersen, 2004; <papid> W04-2406 </papid>niu et al, 2005).<papid> W05-0605 </papid>a third alternative is to evaluate the systems according to some performance in an application, e.g. information retrieval (schutze, 1998).</citsent>
<aftsection>
<nextsent>this is very attractive idea, but requires expensive system development and it is sometimes difficult to separate the reasons for the good (or bad) performance.in this task we decided to adopt the first two alternatives, since they allow for comparison over publicly available systems of any kind.
</nextsent>
<nextsent>with this goal onmind we gave all the participants an unlabeled corpus, and asked them to induce the senses and create clustering solution on it.
</nextsent>
<nextsent>we evaluate the results according to the following types of evaluation: 1.
</nextsent>
<nextsent>evaluate the induced senses as clusters of ex-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2969">
<title id=" W07-2002.xml">semeval2007 task 02 evaluating word sense induction and discrimination systems </title>
<section> evaluating wsid systems.  </section>
<citcontext>
<prevsection>
<prevsent>for formal definition refer to (zhao and karypis, 2005).
</prevsent>
<prevsent>2.2 supervised evaluation.
</prevsent>
</prevsection>
<citsent citstr=" W06-3814 ">
we have followed the supervised evaluation framework for evaluating wsid systems as described in (agirre et al, 2006).<papid> W06-3814 </papid></citsent>
<aftsection>
<nextsent>first, we split the corpus intoa train/test part.
</nextsent>
<nextsent>using the hand-annotated sense information in the train part, we compute mapping matrix that relates clusters and senses in the following way.
</nextsent>
<nextsent>suppose there are clusters and senses for the target word.
</nextsent>
<nextsent>then, = {mij} 1 ? ? m, 1 ? ? n, and each mij = (sj |hi), that is, mij is the probability of word having sense jgiven that it has been assigned cluster i. this probability can be computed counting the times an occurrence with sense sj has been assigned cluster hi in the train corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2970">
<title id=" W07-2025.xml">cutmp temporal relation classification using syntactic and semantic features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>consider sentence like: (1) the top commander of cambodian resistance force said thursday he has sent team to recover the remains of british mine removal expert kidnapped and presumed killed by khmer rouge guerrillas almost two years ago.english speakers immediately recognize that kidnapping came first, then sending, and finally saying, even though before and after never appeared in the text.
</prevsent>
<prevsent>how can machines learn to do the same?
</prevsent>
</prevsection>
<citsent citstr=" W07-2014 ">
the 2007 tempe val competition tries to address this question by establishing common corpus onwhich research systems can compete to find temporal relations (verhagen et al, 2007).<papid> W07-2014 </papid></citsent>
<aftsection>
<nextsent>tempe val considers the following types of event-time temporal re lations: task events1and times within the same sentence task events1 and document times task matrix verb events in adjacent sentences in each of these tasks, systems attempt to annotate pairs with one of the following relations: before,before-or-overlap, overlap, overlap-of after, after or vague.
</nextsent>
<nextsent>competing systems are instructed to find all temporal relations of these types in corpus of newswire documents.we approach these tasks as pair-wise classification problems, where each event/time pair is assigned one of the tempe val relation classes(before, after, etc.).
</nextsent>
<nextsent>event/time pairs are encoded using syntactically and semantically motivated features, and then used to train support vector machine (svm) classifiers.the remainder of this paper is structured as follows.
</nextsent>
<nextsent>section 2 describes the features used to characterize event/time relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2971">
<title id=" W07-2025.xml">cutmp temporal relation classification using syntactic and semantic features </title>
<section> models.  </section>
<citcontext>
<prevsection>
<prevsent>using the features described in the previous section, each temporal relation ? an event paired with timeor another event ? was translated into set of feature values.
</prevsent>
<prevsent>pairing those feature values with the tempe val labels (before, after, etc.) we train eda statistical classifier for each task.
</prevsent>
</prevsection>
<citsent citstr=" N01-1025 ">
we chose support vector machines3(svms) for our classifiers as they have shown good performance on variety of natural language processing tasks (kudo and matsumoto, 2001; <papid> N01-1025 </papid>pradhan et al, 2005).</citsent>
<aftsection>
<nextsent>using cross-validations on the training data, we performed simple feature selection where any feature whose removal improved the cross-validation f-score was discarded.
</nextsent>
<nextsent>the resulting features foreach task are listed in table 1.
</nextsent>
<nextsent>after feature selection, we set the svm free parameters, e.g. the kernel degree and cost of misclassification, by performing additional cross-validations on the training data, and selecting the model parameters which yielded the highest f-score for each task4.
</nextsent>
<nextsent>3we used the tinysvm implementation from http://chasen.org/%7etaku/software/tinysvm/ and trained one-vs-rest classifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2972">
<title id=" W07-1410.xml">machine learning with semantic based distances between sentences for textual entailment </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we performed an experiment using rte-1 and rte-2data sets as training set and the rte-3 development set filtered (541 te pairs) as test set.
</prevsent>
<prevsent>in this experiment ada boost and svm obtained accuracies of 0.6672 and 0.6396 respectively (see results in table 3.
</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
we performed the same experiment joining the answer validation exercise4 (ave) 2006 english dataset (penas et al, 2006) and the microsoft research paraphrase corpus5 (msrpc) (dolan etal., 2004) <papid> C04-1051 </papid>to the previous corpora (rte-1 and rte 2) resulting total of 8585 entailment pairs filtering pairs with text or hypothesis with more than 1sentence.</citsent>
<aftsection>
<nextsent>in our approach we considered that paraphrases were bidirectional entailments.
</nextsent>
<nextsent>the paraphrases of the msrpc have been used as textual en tail ments in only one direction: the first sentence in the paraphrase has been considered the hypothesis and the second one has been considered the text.using the second corpus for training and the rte 3 development set as test set resulted in notable degradation of accuracy (see table 3).
</nextsent>
<nextsent>accuracy algorithm corpus corpus ada boost 66.72% 53.78% svm 63.95% 59.88% table 3: results over the rte-3 development set filtered (541 te pairs) using as training set corpus (rte-1 and rte-2) and corpus (rte-1, rte-2, msrpc, and ave2006 english)finally, we performed set of experiments to detect the contribution of the different features used for machine learning.
</nextsent>
<nextsent>these experiments revealed that 4ave.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2973">
<title id=" W08-0126.xml">user simulation as testing for spoken dialog systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these simulated users can interact with the dialog systems to generate large amounts of training data in low-cost and time-efficient manner.
</prevsent>
<prevsent>many previous studies (scheffler, 2002; pietquin, 2004) have shown that the dialog strategies learned from the simulated training data out perform the hand-crafted strategies.
</prevsent>
</prevsection>
<citsent citstr=" P04-1009 ">
there are also studies that use user simulation to train speech recognition and understanding components (chung, 2004).<papid> P04-1009 </papid></citsent>
<aftsection>
<nextsent>while user simulation is largely used in dialog system training, it has only been used in limited scope for testing specific dialog system components in the system evaluation phase (lpez-czar et al, 2003; filisko and seneff, 2006).
</nextsent>
<nextsent>this is partly because the state-of-the-art simulated users have quite limited abilities in mimicking human users  behaviors and typically over-generate possible dialog behaviors.
</nextsent>
<nextsent>this is not major problem when using simulated dialog corpus as the training corpus for dialog strategy learning because the over-generated simulation behaviors would only provide the machine learners with broader dialog state space to explore (ai et al, 2007).<papid> N07-2001 </papid></nextsent>
<nextsent>however, realistic user behaviors are highly desired in the testing phase because the systems are evaluated and adjusted based on the analysis of the dialogs generated in this phase.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2974">
<title id=" W08-0126.xml">user simulation as testing for spoken dialog systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while user simulation is largely used in dialog system training, it has only been used in limited scope for testing specific dialog system components in the system evaluation phase (lpez-czar et al, 2003; filisko and seneff, 2006).
</prevsent>
<prevsent>this is partly because the state-of-the-art simulated users have quite limited abilities in mimicking human users  behaviors and typically over-generate possible dialog behaviors.
</prevsent>
</prevsection>
<citsent citstr=" N07-2001 ">
this is not major problem when using simulated dialog corpus as the training corpus for dialog strategy learning because the over-generated simulation behaviors would only provide the machine learners with broader dialog state space to explore (ai et al, 2007).<papid> N07-2001 </papid></citsent>
<aftsection>
<nextsent>however, realistic user behaviors are highly desired in the testing phase because the systems are evaluated and adjusted based on the analysis of the dialogs generated in this phase.
</nextsent>
<nextsent>therefore, we would ex user simulation as testing for spoken dialog systems hua ai* fuliang weng intelligent systems program research and technology center university of pittsburgh robert bosch llc 210 s. bouquet st., pittsburg, pa 15260 4009 miranda ave., palo alto, ca 94304 hua@cs.pitt.edu fuliang.weng@us.bosch.com 164 pect that these user behaviors are what we will see in the final evaluation with human users.
</nextsent>
<nextsent>in this case, any over-generated dialog behaviors may cause the system to be blamed for untargeted functions.
</nextsent>
<nextsent>what is more, the simulated users cannot provide subjective user satisfaction feedback which is also important for improving the systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2975">
<title id=" W08-0126.xml">user simulation as testing for spoken dialog systems </title>
<section> user simulation techniques.  </section>
<citcontext>
<prevsection>
<prevsent>later, many studies model more comprehensive user behaviors by adding user goals to constrain the user actions (scheffler, 2002; pietquin, 2004).
</prevsent>
<prevsent>these simulated users mimic real user behaviors in statistical way, conditioning the user actions on the user goals and the dialog contexts.
</prevsent>
</prevsection>
<citsent citstr=" N07-2038 ">
more recent research defines agenda for simulated users to complete set of settled goals (schatzmann et al, 2007).<papid> N07-2038 </papid></citsent>
<aftsection>
<nextsent>this type of simulated user updates the agenda and the current goal based on the changes of the dialog states.
</nextsent>
<nextsent>in this study, we build simulated user similar to (schatzmann et al, 2007) <papid> N07-2038 </papid>in which the simulated user keeps list of its goals and another agenda of actions to complete the goals.</nextsent>
<nextsent>in our restaurant selection domain, the users?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2977">
<title id=" W08-0126.xml">user simulation as testing for spoken dialog systems </title>
<section> evaluation measures.  </section>
<citcontext>
<prevsection>
<prevsent>the matches of understandings can be calculated automatically from the user simulation and the system logs.
</prevsent>
<prevsent>however, since we work with human users  dialogs in the first part of this study, we manually annotated the semantic contents (e.g., cuisine name) in the real user corpus.
</prevsent>
</prevsection>
<citsent citstr=" P97-1035 ">
previous studies (e.g., walker et al, 1997) <papid> P97-1035 </papid>use corpus level semantic accuracy measure (semanti caccuracy) to capture the systems understanding ability.</citsent>
<aftsection>
<nextsent>semantic accuracy is defined in the standard way as the total number of correctly under stood constraints divided by the total number of constraints mentioned in the entire dialog.
</nextsent>
<nextsent>theun derstandingagreement measure we introduce here is essentially the averaged per-sentence semantic accuracy, which emphasizes the utterance level perception rather than single corpus level average.
</nextsent>
<nextsent>the intuition behind this new measure is that it is better for the system to always understand something to keep conversation going than for the system to understand really well sometimes but really bad at other times.
</nextsent>
<nextsent>we compute both measures in our experiments for comparison.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2978">
<title id=" W07-1506.xml">discontinuity revisited an improved conversion to context free representations </title>
<section> conversion to context-free syntax.  </section>
<citcontext>
<prevsection>
<prevsent>the converted sentence from figure 1 is shown in figure 2.
</prevsent>
<prevsent>in any sentence, multiple nodes could each be raised one or more times, so it is difficult to automatically reconstruct the original sentence.
</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
previous work on pcfg parsing using negra ortiger has either used the provided penn treebank style versions of the corpora included with negra and tiger version 1 (dubey and keller, 2003; <papid> P03-1013 </papid>dubey, 2004) or used program provided with the negra/tiger annotate software (plaehn and brants, 2000) which performs the raising algorithm (kubler, 2005; kubler et al, 2006).</citsent>
<aftsection>
<nextsent>this conversion will be referred to as the raising method?.
</nextsent>
<nextsent>3.2 new approach to eliminating discontinuities the raising method has the advantages of preserving the number of nodes in the tree, but it is not easily reversible and disrupts local trees.
</nextsent>
<nextsent>raising non-headnodes is not an ideal way of eliminating discontinuities because it does not preserve the relationship between head and dependent that is represented in local tree in the tiger annotation.
</nextsent>
<nextsent>after raising one or more nodes in 30% of the sentences in the corpus, local trees are no longer consistent across the treebank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2979">
<title id=" W07-2048.xml">lth semantic structure extraction using non projective dependency trees </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it has also been claimed that dependency syntax is easier to understand and to teach to people without linguistic background.
</prevsent>
<prevsent>despite these advantages, dependency syntax has relatively rarely been used in semantic structure extraction, with few exceptions.
</prevsent>
</prevsection>
<citsent citstr=" W04-0814 ">
ahn et al (2004) <papid> W04-0814 </papid>used post-processing step to convert constituent trees into labeled dependency trees that were then used as input to semantic role labeler.</citsent>
<aftsection>
<nextsent>pradhan et al.
</nextsent>
<nextsent>(2005) used rule-based dependency parser, but the results were significantly worse than when using constituent parser.
</nextsent>
<nextsent>this paper describes system for frame-semantic structure extraction that is based on dependency parser.
</nextsent>
<nextsent>the next section presents the dependency grammar that we relyon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2980">
<title id=" W07-2048.xml">lth semantic structure extraction using non projective dependency trees </title>
<section> dependency parsing with the penn.  </section>
<citcontext>
<prevsection>
<prevsent>the next section presents the dependency grammar that we relyon.
</prevsent>
<prevsent>we then give the details on the frame detection and disambiguation, the frame element (fe) identification and classification, and dictionary extension, after which the results and conclusions are given.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
treebank the last few years have seen an increasing interest in dependency parsing (buchholz and marsi, 2006) <papid> W06-2920 </papid>with significant improvements of the state of the art, and dependency treebanks are now available for wide range of languages.</citsent>
<aftsection>
<nextsent>the parsing algorithms are comparatively easy to implement and efficient: some of the algorithms parse sentences in linear time (yamada and matsumoto, 2003; nivre et al, 2006).
</nextsent>
<nextsent>in the semantic structure extraction system, we used the stanford part-of-speech tagger (toutanova et al, 2003) <papid> N03-1033 </papid>to tag the training and test sentences and malt parser, statistical dependency parser (nivre et al., 2006), to parse them.we trained the parser on the penn treebank (mar cus et al, 1993).<papid> J93-2004 </papid></nextsent>
<nextsent>the dependency trees used to train the parser were created from the constituent trees using conversion program (johansson and nugues, 2007)1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2981">
<title id=" W07-2048.xml">lth semantic structure extraction using non projective dependency trees </title>
<section> dependency parsing with the penn.  </section>
<citcontext>
<prevsection>
<prevsent>treebank the last few years have seen an increasing interest in dependency parsing (buchholz and marsi, 2006) <papid> W06-2920 </papid>with significant improvements of the state of the art, and dependency treebanks are now available for wide range of languages.</prevsent>
<prevsent>the parsing algorithms are comparatively easy to implement and efficient: some of the algorithms parse sentences in linear time (yamada and matsumoto, 2003; nivre et al, 2006).</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
in the semantic structure extraction system, we used the stanford part-of-speech tagger (toutanova et al, 2003) <papid> N03-1033 </papid>to tag the training and test sentences and malt parser, statistical dependency parser (nivre et al., 2006), to parse them.we trained the parser on the penn treebank (mar cus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>the dependency trees used to train the parser were created from the constituent trees using conversion program (johansson and nugues, 2007)1.
</nextsent>
<nextsent>the converter handles most of the secondary edges in the treebank and encodes those edges as (generally) non projective dependencyarcs.
</nextsent>
<nextsent>such information is available in the penn tree bank in the form of empty categories and secondary edges, it is however not available in the output of traditional constituent parsers, although there have been some attempts to apply post-processing step to predict it, see ahn et al (2004), <papid> W04-0814 </papid>inter alia.</nextsent>
<nextsent>figures 1 and 2 show constituent tree from the treebank and its corresponding dependency tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2982">
<title id=" W07-2048.xml">lth semantic structure extraction using non projective dependency trees </title>
<section> dependency parsing with the penn.  </section>
<citcontext>
<prevsection>
<prevsent>treebank the last few years have seen an increasing interest in dependency parsing (buchholz and marsi, 2006) <papid> W06-2920 </papid>with significant improvements of the state of the art, and dependency treebanks are now available for wide range of languages.</prevsent>
<prevsent>the parsing algorithms are comparatively easy to implement and efficient: some of the algorithms parse sentences in linear time (yamada and matsumoto, 2003; nivre et al, 2006).</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
in the semantic structure extraction system, we used the stanford part-of-speech tagger (toutanova et al, 2003) <papid> N03-1033 </papid>to tag the training and test sentences and malt parser, statistical dependency parser (nivre et al., 2006), to parse them.we trained the parser on the penn treebank (mar cus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>the dependency trees used to train the parser were created from the constituent trees using conversion program (johansson and nugues, 2007)1.
</nextsent>
<nextsent>the converter handles most of the secondary edges in the treebank and encodes those edges as (generally) non projective dependencyarcs.
</nextsent>
<nextsent>such information is available in the penn tree bank in the form of empty categories and secondary edges, it is however not available in the output of traditional constituent parsers, although there have been some attempts to apply post-processing step to predict it, see ahn et al (2004), <papid> W04-0814 </papid>inter alia.</nextsent>
<nextsent>figures 1 and 2 show constituent tree from the treebank and its corresponding dependency tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2984">
<title id=" W07-2048.xml">lth semantic structure extraction using non projective dependency trees </title>
<section> semantic structure extraction.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to detecing the fes, the argument identification classifier detects the dependency nodes that should be tagged on the layers other than the frame element layer: supp, cop, null, exist, and asp.
</prevsent>
<prevsent>the ant and rel labels could be inserted using simple rules.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
similarly to xue and palmer (2004), <papid> W04-3212 </papid>argument identification fe supp cop asp exist null argument none self_mover path etc classification figure 3: fe extraction steps.we could filter away many nodes before the argument identification step by assuming that the arguments forgiven predicate correspond to subset of the dependents of the target or of its transitive heads.</citsent>
<aftsection>
<nextsent>both classifiers were implemented using svms and use the following features: target lemma, voice (for verb targets only), subcategorization frame (forverb targets only), the set of dependencies of the target, part of speech of the target node, path through the dependency tree from the target to the node, position (before, after, or on), word and part of speech for the head, word and part of speech for left most and rightmost descendent.
</nextsent>
<nextsent>in the path feature, we removed steps through verb chains and coordination.
</nextsent>
<nextsent>for instance, in the sentece have seen and heard it, the path from heard to is only sbj?
</nextsent>
<nextsent>and to it obj?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2985">
<title id=" W07-2048.xml">lth semantic structure extraction using non projective dependency trees </title>
<section> semantic structure extraction.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 named entity recognition.
</prevsent>
<prevsent>in addition to the frame-semantic information, the semeval task also scores named entities.
</prevsent>
</prevsection>
<citsent citstr=" P03-1004 ">
we used yamcha (kudo and matsumoto, 2003) <papid> P03-1004 </papid>to detect named entities, and we trained it on the semeval full-text training sets.</citsent>
<aftsection>
<nextsent>apart from the word and partof speech, we used suffixes up to length 5 as features.
</nextsent>
<nextsent>we think that results could be improved further by using an external ne tagger.
</nextsent>
<nextsent>the system was evaluated on three texts.
</nextsent>
<nextsent>table 1 shows the results for frame detection averaged over the test texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2986">
<title id=" W07-2048.xml">lth semantic structure extraction using non projective dependency trees </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>while most previous systems have been based on constituents, our system relies on dependency parser.
</prevsent>
<prevsent>we also described an automatic method to add new units to the framenet lexical database.to improve labeling quality, we would like to apply constraints to the semantic output so that semantic type and core ness rules are obeyed.
</prevsent>
</prevsection>
<citsent citstr=" P05-1073 ">
in addition, while the system described here is based onpipelined classification, recent research on semantic role labeling has shown that significant performance improvements can be gained by exploiting interdependencies between arguments (toutanova et al., 2005).<papid> P05-1073 </papid></citsent>
<aftsection>
<nextsent>with an increasing amount of running text annotated with frame semantics, we believe that this insight can be extended to model interdependencies between frames as well.
</nextsent>
<nextsent>our motivation for using dependency grammar is that we hope that it will eventually make semantic structure extraction easier to implement and more theoretically well-founded.
</nextsent>
<nextsent>how to best design the dependency syntax is also still an open question.
</nextsent>
<nextsent>ideally, all arguments would be direct dependents of the predicate node and we could get rid of the sparse and brittle path feature in the classifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2987">
<title id=" W07-0733.xml">experiments in domain adaptation for statistical machine translation </title>
<section> our framework: the moses mt system.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P07-2045 ">
the open source moses (koehn et al, 2007) <papid> P07-2045 </papid>mt system was originally developed at the university of edinburgh and received major boost through 2007 johns hopkins workshop.</citsent>
<aftsection>
<nextsent>it is now used at.
</nextsent>
<nextsent>several academic institutions as the basic infrastructure for statistical machine translation research.
</nextsent>
<nextsent>the moses system is an implementation of the phrase-based machine translation approach (koehn et al, 2003).
</nextsent>
<nextsent>in this approach, an input sentence is first split into text chunks (so-called phrases), which are then mapped one-to-one to target phrases usinga large phrase translation table.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2988">
<title id=" W07-0733.xml">experiments in domain adaptation for statistical machine translation </title>
<section> our framework: the moses mt system.  </section>
<citcontext>
<prevsection>
<prevsent>the different system components hi (phrase translation probabilities, language figure 1: phrase-based statistical machine translation model: input is split into text chunks (phrases) which are mapped using large phrase translation table.
</prevsent>
<prevsent>phrases are mapped one-to-one, and may be reordered.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
model, etc.) are combined in log-linear model to obtain the score for the translation for an input sentence f: score(e, f) = exp ? i hi(e, f) (1) the weights of the components are set by adiscriminative training method on held-out development data (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>the basic components used in our experiments are: (a) two phrase translation probabilities (both p(e|f) and p(f |e)), (b) two word translation probabilities (both p(e|f) and p(f |e)), (c) phrase count, (d) output word count, (e) language model, (f) distance-based reordering model, and (g) lexicalized reordering model.
</nextsent>
<nextsent>for more detailed description of this model, please refer to (koehn et al, 2005).
</nextsent>
<nextsent>since training data for statistical machine translation is typically collected opportunistically from wherever it is available, the application domain forma chine translation system may be very different from the domain of the systems training data.
</nextsent>
<nextsent>for the wmt 2007 shared task, the challenge was to use large amount of out-of-domain training data 224 (about 40 million words) combined with much smaller amount of in-domain training data (about 1 million words) to optimize translation performance on that particular domain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2989">
<title id=" W07-0733.xml">experiments in domain adaptation for statistical machine translation </title>
<section> domain adaption.  </section>
<citcontext>
<prevsection>
<prevsent>such decomposition is called decoding path.
</prevsent>
<prevsent>a more recent feature of the factored translation model framework is the possible use of multiple alternative decoding paths.
</prevsent>
</prevsection>
<citsent citstr=" W07-0702 ">
this alternate decoding path model was developed by birch et al (2007).<papid> W07-0702 </papid></citsent>
<aftsection>
<nextsent>for our purposes, we use two decoding paths, each consisting of only one translation step.
</nextsent>
<nextsent>one decoding path is the in-domain translation table, and the other decoding path is the out-of-domain translationtable.
</nextsent>
<nextsent>again, respective weights are set with minimum error rate training.
</nextsent>
<nextsent>table 1 shows results of our domain adaptation experiments on the development test set (nc-devtest 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2990">
<title id=" W07-0733.xml">experiments in domain adaptation for statistical machine translation </title>
<section> wmt 2007 shared task submissions.  </section>
<citcontext>
<prevsection>
<prevsent>4.4 german english system.
</prevsent>
<prevsent>the german english language pair is especially challenging due to the large differences in word order.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
collins et al (2005) <papid> P05-1066 </papid>suggest method to reorder the german input before translating using set of manually crafted rules.</citsent>
<aftsection>
<nextsent>in our german english submissions, this is done both to the training data and the input to the machine translation system.
</nextsent>
<nextsent>our submission to the wmt 2007 shared task is fairly straight-forward use of the moses mt system using default parameters.
</nextsent>
<nextsent>in sense, we submitted baseline performance of this system.
</nextsent>
<nextsent>bleu and nist scores for all our systems on the test sets are displayed in table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2991">
<title id=" W07-2033.xml">gyder maxent metonymy resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the basic ner categories person, place, organisation state-of-the-art systems generally perform in the mid to the high nineties.
</prevsent>
<prevsent>these systems typically do not distinguish between literal or metonymic usage of entity names, even though this would be helpful for most applications.
</prevsent>
</prevsection>
<citsent citstr=" W02-1027 ">
resolving metonymic usage of proper names would therefore directly benefit ner and indirectly all nlp tasks (such as anaphor resolution) that require ner.markert and nissim (2002) <papid> W02-1027 </papid>outlined corpus based approach to proper name metonymy as semantic classification problem that forms the basis of the 2007 semeval metonymy resolution task.</citsent>
<aftsection>
<nextsent>instances like he was shocked by vietnam?
</nextsent>
<nextsent>or schengen boosted tourism?
</nextsent>
<nextsent>were assigned to broad categories like place-for-event, sometimes ignoring narrower distinctions, such as the fact that it wasnt the signing of the treaty at schengen but rather its actual implementation (which didnt take place at schengen) that boosted tourism.
</nextsent>
<nextsent>but the corpus makes clear that even with these (sometimes coarse) class distinctions, several metonymy types seem to appear extremely rarely in actual texts.the shared task focused on two broad named entity classes as metonymic sources, location and org, each having several target classes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2992">
<title id=" W07-2033.xml">gyder maxent metonymy resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>were assigned to broad categories like place-for-event, sometimes ignoring narrower distinctions, such as the fact that it wasnt the signing of the treaty at schengen but rather its actual implementation (which didnt take place at schengen) that boosted tourism.
</prevsent>
<prevsent>but the corpus makes clear that even with these (sometimes coarse) class distinctions, several metonymy types seem to appear extremely rarely in actual texts.the shared task focused on two broad named entity classes as metonymic sources, location and org, each having several target classes.
</prevsent>
</prevsection>
<citsent citstr=" W07-2007 ">
for more details on the datasets, see the task description paper markert and nissim (2007).<papid> W07-2007 </papid></citsent>
<aftsection>
<nextsent>several categories (e.g. place-for-event, organisation-for-index) did not contain asufficient number of examples for machine learning, and we decided early on to accept the fact that these categories will not be learned and to concentrate on those classes where learning seemed feasible.
</nextsent>
<nextsent>the shared task itself consisted of 3 subtasks of different granularity for both organisation and location names.
</nextsent>
<nextsent>the fine-grained evaluation aimed at distinguishing between all categories, while the medium-grained evaluation grouped different types of metonymic usage together and addressed literal /mixed / metonymic usage.
</nextsent>
<nextsent>the coarse-grained subtask was in fact literal / non literal two-class classification task.though gyder has obtained the highest accuracy for the metonymy shared task at semeval-2007 in all six subtasks, we dont consider the results 161(72.80% accuracy for org, 84.36% for loc) particularly impressive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2993">
<title id=" W07-1414.xml">dependency based paraphrasing for recognizing textual entailment </title>
<section> dependency-based paraphrasing.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 preprocessing rte data.
</prevsent>
<prevsent>starting from the text-hypothesis pairs in the rte xml format, we first pre process the data.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
as the text part may consist of more than one sentence,we first perform sentence splitting using mxtermi nator (reynar and ratnaparkhi, 1997), <papid> A97-1004 </papid>maximum 83 entropy-based end of sentence classifier trained onthe penn treebank data.</citsent>
<aftsection>
<nextsent>next, each sentence is tokenized and syntactically parsed using the minipar parser (lin, 1998).
</nextsent>
<nextsent>from the parsers tabular output we extract the word forms, lemmas, part-of-speech tags and dependency relations.
</nextsent>
<nextsent>this information isthen stored in an ad-hoc xml format which represents the trees as an hierarchy of node elements in order to facilitate tree matching.
</nextsent>
<nextsent>2.2 dirt data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2994">
<title id=" W07-1414.xml">dependency based paraphrasing for recognizing textual entailment </title>
<section> results on rte3 data.  </section>
<citcontext>
<prevsection>
<prevsent>and with paraphrasing (+) task dev?
</prevsent>
<prevsent>dev+ test?
</prevsent>
</prevsection>
<citsent citstr=" C96-1078 ">
test+ ie 59.5 61.0 53.0 53.5 ir 67.0 68.0 58.5 61.5 qa 76.0 76.5 69.0 68.0 sum 66.0 67.5 53.0 53.5 overall 66.9 68.2 58.6 59.1 of our rte2 system as described in (ref supressed for blind reviewing) the core of the system is still the tree alignment algorithm from (meyers et al, 1996), <papid> C96-1078 </papid>but without normalization of node weight sand applied to minipar instead of malt parser output.</citsent>
<aftsection>
<nextsent>to keep things simple, we do not apply syntactic normalization, nor do we use wordnet or other resources to improve node matching.
</nextsent>
<nextsent>instead, we simply align each text tree to the corresponding hypothesis tree and calculate the coverage, which is defined as the proportion of aligned content wordsin the hypothesis.
</nextsent>
<nextsent>if the coverage is above task specific threshold, we say entailment is true, otherwise it is false.
</nextsent>
<nextsent>the results are summarized in table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2995">
<title id=" W08-0602.xml">extracting clinical relationships from patient narratives </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such approaches have typically been applied to journal texts.
</prevsent>
<prevsent>they have been used both for entity recognition and extraction of various relations, such as protein-protein interactions (see, for example, grover et al(2007)).
</prevsent>
</prevsection>
<citsent citstr=" P05-1053 ">
this follows on from the success of these methods in general nlp (see for example zhou et al(2005)).<papid> P05-1053 </papid></citsent>
<aftsection>
<nextsent>statistical machine learning has also been applied to clinical text, but its use has generally been limited to entity recognition.
</nextsent>
<nextsent>the mayo clinic text analysis system (pakhomov et al, 2005), <papid> P05-3007 </papid>for example, uses combination of dictionary lookup and nave bayes classifier to identify entities for information retrievalapplications.</nextsent>
<nextsent>to the best of our knowledge, statistical methods have not been previously applied to extraction of clinical relationships from text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2996">
<title id=" W08-0602.xml">extracting clinical relationships from patient narratives </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this follows on from the success of these methods in general nlp (see for example zhou et al(2005)).<papid> P05-1053 </papid></prevsent>
<prevsent>statistical machine learning has also been applied to clinical text, but its use has generally been limited to entity recognition.</prevsent>
</prevsection>
<citsent citstr=" P05-3007 ">
the mayo clinic text analysis system (pakhomov et al, 2005), <papid> P05-3007 </papid>for example, uses combination of dictionary lookup and nave bayes classifier to identify entities for information retrievalapplications.</citsent>
<aftsection>
<nextsent>to the best of our knowledge, statistical methods have not been previously applied to extraction of clinical relationships from text.
</nextsent>
<nextsent>this paper describes experiments in the statistical machine learning of relationships from novel text type: oncology narratives.
</nextsent>
<nextsent>the set of relationships extracted are considered to be of interest for clinical and research applications down line of ie, such as querying to support clinical research.
</nextsent>
<nextsent>we apply support vector machine (svm) classifiers to learn theserelationships.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD2997">
<title id=" W08-0602.xml">extracting clinical relationships from patient narratives </title>
<section> relationship extraction.  </section>
<citcontext>
<prevsection>
<prevsent>annotators were further told that relationships could span multiple sentences, and that it was acceptable to use clinical domain knowledge to infer that relationship existed between two mentions.
</prevsent>
<prevsent>counts of all relationships annotated in c77 are shown in table 2, sub-divided by the number of sentence boundaries spanned by relationship.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
the system we have built uses the gate nlp toolkit (cunningham et al, 2002) <papid> P02-1022 </papid>1.</citsent>
<aftsection>
<nextsent>the system is shown in figure 1, and is described below.
</nextsent>
<nextsent>narratives are first pre-processed using standard gate modules.
</nextsent>
<nextsent>narratives were token ised, sentences found with regular expression-based sentence splitter, part-of-speech (pos) tagged, and morphological roots found for tokens.
</nextsent>
<nextsent>each token was also labelled with generalised pos tag, the first two characters of the full pos tag.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3000">
<title id=" W08-0601.xml">a graph kernel for protein protein interaction extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(bunescu et al, 2005)).
</prevsent>
<prevsent>a wide range of results have been reported for the systems, but as we will show, differences in evaluation resources, metrics and strategies make direct comparison of these numbers problematic.
</prevsent>
</prevsection>
<citsent citstr=" W07-1004 ">
further, the results gained from the bio creative ii evaluation, where the best performing system achieved 29% f-score (hunter et al, 2008), suggest that the problem of extracting binary protein protein interactions is far from solved.the public availability of large annotated ppi corpora such as aimed (bunescu et al, 2005), bio infer (pyysalo et al, 2007<papid> W07-1004 </papid>a) and genia (kim et al, 2008), provides an opportunity for building ppi extraction systems automatically using machine learning.</citsent>
<aftsection>
<nextsent>a major challenge is how to supply the learner with the contextual and syntactic information needed to distinguish between interactions andnon-interactions.
</nextsent>
<nextsent>to address the ambiguity and variability of the natural language expressions used to state ppi, several recent studies have focused on the development, adaptation and application of nlp tools for the biomedical domain.
</nextsent>
<nextsent>many high-qualitydomain-specific tools are now freely available, including full parsers such as that introduced by charniak and lease (2005).
</nextsent>
<nextsent>additionally, number of conversions from phrase structure parses to dependency structures that make the relationships between words more directly accessible have been introduced.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3001">
<title id=" W08-0601.xml">a graph kernel for protein protein interaction extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>approaches such as sub sequence kernels (bunescu and mooney, 2006), tree kernels (zelenko 1 interaction of p1 and p2 prep_of  conj_and prep_of  p1 is p2 binding protein  nn nn  det cop  nsubj p1 fails to bind p2  nsubj  aux dobj xcomp   xsubjfigure 1: stanford dependency parses (collapsed?
</prevsent>
<prevsent>representation) where the shortest path, shown in bold, excludes important words.
</prevsent>
</prevsection>
<citsent citstr=" H05-1091 ">
et al, 2003) and shortest path kernels (bunescuand mooney, 2005) <papid> H05-1091 </papid>have been proposed and successfully used for relation extraction.</citsent>
<aftsection>
<nextsent>however, these methods lack the expressive power to consider representations derived from general, possibly cyclic, dependency graph structures, such as those generated by the stanford tools.
</nextsent>
<nextsent>the sub sequence kernel approach does not consider parses at all, and the shortest path approach is limited to representing only single path in the full dependency graph, which excludes relevant words even in many simple cases (figure 1).
</nextsent>
<nextsent>tree kernels can represent more complex structures, but are still restricted to tree representations.
</nextsent>
<nextsent>lately, in the framework of kernel-based machine learning methods there has been an increased interest in designing kernel functions for graph data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3009">
<title id=" W08-0601.xml">a graph kernel for protein protein interaction extraction </title>
<section> experimental evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we form the graph representation described earlier for each candidate interaction.we evaluate the method with 10-fold document level cross-validation on all of the corpora.
</prevsent>
<prevsent>this guarantees the maximal use of the available data, and also allows comparison to relevant earlier work.in particular, on the aimed corpus we apply the exact same 10-fold split that was used by bunescu et al.
</prevsent>
</prevsection>
<citsent citstr=" E06-1051 ">
(2006) and giuliano et al (2006).<papid> E06-1051 </papid></citsent>
<aftsection>
<nextsent>performance is measured according to the following criteria: interactions are considered untyped, undirected pairwise relations between specific protein mentions, that is, if the same protein name occurs multiple 1available at http://mars.cs.utu.fi/ppicorpora.
</nextsent>
<nextsent>times in sentence, the correct interactions must be extracted for each occurrence.
</nextsent>
<nextsent>further, we do not consider self-interactions as candidates and remove them from the corpora prior to evaluation.
</nextsent>
<nextsent>the majority of ppi extraction system evaluations use the balanced f-score measure for quantifying the performance of the systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3020">
<title id=" W07-0732.xml">statistical post editing on sys trans rule based translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these tools have been presented in senellart (2006) and most of them will be integrated in systran version 7 systems.
</prevsent>
<prevsent>independently, two experiments were carried out for the shared task of the acl 2007 workshop on statistical machine translation to combine raw systran system with statistical post editing (spe) system.
</prevsent>
</prevsection>
<citsent citstr=" W07-0728 ">
one experiment was run by nrc using the language pair english  french in the context of ? automatic post-edition ? systems using the portage system as described in si mard et al (2007).<papid> W07-0728 </papid></citsent>
<aftsection>
<nextsent>the second experiment based on the same principle was run on the german english and spanish english1 language pairs using the moses system (koehn et al 2007).
</nextsent>
<nextsent>the objective was to train smt system on parallel corpus composed of systran translations with the referenced source aligned with its referenced translation.
</nextsent>
<nextsent>beyond both (a) the huge (and expected) improvement of the bleu score for the combined system compared to raw translation output (for german-english, around 10 bleu points for the europarl test set of wmt2007) and (b) the (expected) corresponding improvement of the translation fluency, we provide qualitative analysis on the contributions (positive and negative) of the spe layer imposed on the systran translation output in this paper.
</nextsent>
<nextsent>for this analysis we classifiy the different types of post-editing?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3022">
<title id=" W08-0407.xml">experiments in discriminating phrase based translations on the basis of syntactic coupling features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although the improvements in terms of automatic measures such as bleu and nist are inconclusive, an initial human assessment of the results appears to show certain qualitative improvements.
</prevsent>
<prevsent>1.1 motivation.
</prevsent>
</prevsection>
<citsent citstr=" H05-1095 ">
when we use the phrase-based smt system matrax (simard et al, 2005) <papid> H05-1095 </papid>to translate the sentence our declaration of rights is the first of this millenium from english to french, the result returned by the system is the erroneous translation notre declaration des droits de la premie`re est de ce millen aire, while somewhere down the n-best listof lesser-scored candidates we find correct transla tion: notre declaration des droits est la premie`re de ce millenaire.on closer inspection, the difference of scores between the two candidates is the following.</citsent>
<aftsection>
<nextsent>in the second (correct) case, the phrase of rights was translated into the phrase des droits, while in the first (in correct) case, the phrase of was translated into the phrase de and the phrase rights into the phrase des droits.
</nextsent>
<nextsent>however, while the two bi-phrases of/de and rights/des droits independently make perfect sense,the sequence de des droits in french is not possible, situation which is easily detected by standard ngram language model; the language model hasthen tendency to try to place the (in fact super flu ous) de at further place in the target (just before la premie`re), where it is more acceptable to it.
</nextsent>
<nextsent>the overall consequence is translation that while formally possible from the viewpoint of simple language model, is not an adequate representation of the meaning of the source.
</nextsent>
<nextsent>now suppose that we parse both the source and the two candidates with dependency parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3023">
<title id=" W08-0407.xml">experiments in discriminating phrase based translations on the basis of syntactic coupling features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features).
</prevsent>
<prevsent>1.2 related work.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
there is growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (chiang, 2007) that use formal syntax?, that is syntactic structures for the source and target that are discovered on the basis of bilingual corpus, but without resort to an externally motivated parser, to approaches such as (yamada and knight, 2001) <papid> P01-1067 </papid>and (marcu et al, 2006) <papid> W06-1606 </papid>that use an external parser on the target only, or such as (quirk et al, 2005) <papid> P05-1034 </papid>on the source only, or such as (cowan et al., 2006) <papid> W06-1628 </papid>that use external parsers both on the source and on the target.our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build target structure (or string) directly, but rather by using baseline phrase-basedsystem as generator of candidates, and then selecting between these candidates through discriminative procedure.</citsent>
<aftsection>
<nextsent>some other researchers have taken similar line, for example (hasan et al, 2006), <papid> W06-2606 </papid>which only uses parser on the target, and attempts to improve the fluency of the translation produced, andes pecially (och et al, 2003) that reports experiments using large number of syntactic features.</nextsent>
<nextsent>in one of the experiments briefly reported, dependency parser is used both for the source and for the target and few features are introduced for counting the number of edges that project from the source to the target.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3024">
<title id=" W08-0407.xml">experiments in discriminating phrase based translations on the basis of syntactic coupling features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features).
</prevsent>
<prevsent>1.2 related work.
</prevsent>
</prevsection>
<citsent citstr=" W06-1606 ">
there is growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (chiang, 2007) that use formal syntax?, that is syntactic structures for the source and target that are discovered on the basis of bilingual corpus, but without resort to an externally motivated parser, to approaches such as (yamada and knight, 2001) <papid> P01-1067 </papid>and (marcu et al, 2006) <papid> W06-1606 </papid>that use an external parser on the target only, or such as (quirk et al, 2005) <papid> P05-1034 </papid>on the source only, or such as (cowan et al., 2006) <papid> W06-1628 </papid>that use external parsers both on the source and on the target.our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build target structure (or string) directly, but rather by using baseline phrase-basedsystem as generator of candidates, and then selecting between these candidates through discriminative procedure.</citsent>
<aftsection>
<nextsent>some other researchers have taken similar line, for example (hasan et al, 2006), <papid> W06-2606 </papid>which only uses parser on the target, and attempts to improve the fluency of the translation produced, andes pecially (och et al, 2003) that reports experiments using large number of syntactic features.</nextsent>
<nextsent>in one of the experiments briefly reported, dependency parser is used both for the source and for the target and few features are introduced for counting the number of edges that project from the source to the target.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3025">
<title id=" W08-0407.xml">experiments in discriminating phrase based translations on the basis of syntactic coupling features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features).
</prevsent>
<prevsent>1.2 related work.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
there is growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (chiang, 2007) that use formal syntax?, that is syntactic structures for the source and target that are discovered on the basis of bilingual corpus, but without resort to an externally motivated parser, to approaches such as (yamada and knight, 2001) <papid> P01-1067 </papid>and (marcu et al, 2006) <papid> W06-1606 </papid>that use an external parser on the target only, or such as (quirk et al, 2005) <papid> P05-1034 </papid>on the source only, or such as (cowan et al., 2006) <papid> W06-1628 </papid>that use external parsers both on the source and on the target.our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build target structure (or string) directly, but rather by using baseline phrase-basedsystem as generator of candidates, and then selecting between these candidates through discriminative procedure.</citsent>
<aftsection>
<nextsent>some other researchers have taken similar line, for example (hasan et al, 2006), <papid> W06-2606 </papid>which only uses parser on the target, and attempts to improve the fluency of the translation produced, andes pecially (och et al, 2003) that reports experiments using large number of syntactic features.</nextsent>
<nextsent>in one of the experiments briefly reported, dependency parser is used both for the source and for the target and few features are introduced for counting the number of edges that project from the source to the target.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3026">
<title id=" W08-0407.xml">experiments in discriminating phrase based translations on the basis of syntactic coupling features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>fluency, which would be better addressed by target-specific syntactic features than by coupling syntactic features).
</prevsent>
<prevsent>1.2 related work.
</prevsent>
</prevsection>
<citsent citstr=" W06-1628 ">
there is growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (chiang, 2007) that use formal syntax?, that is syntactic structures for the source and target that are discovered on the basis of bilingual corpus, but without resort to an externally motivated parser, to approaches such as (yamada and knight, 2001) <papid> P01-1067 </papid>and (marcu et al, 2006) <papid> W06-1606 </papid>that use an external parser on the target only, or such as (quirk et al, 2005) <papid> P05-1034 </papid>on the source only, or such as (cowan et al., 2006) <papid> W06-1628 </papid>that use external parsers both on the source and on the target.our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build target structure (or string) directly, but rather by using baseline phrase-basedsystem as generator of candidates, and then selecting between these candidates through discriminative procedure.</citsent>
<aftsection>
<nextsent>some other researchers have taken similar line, for example (hasan et al, 2006), <papid> W06-2606 </papid>which only uses parser on the target, and attempts to improve the fluency of the translation produced, andes pecially (och et al, 2003) that reports experiments using large number of syntactic features.</nextsent>
<nextsent>in one of the experiments briefly reported, dependency parser is used both for the source and for the target and few features are introduced for counting the number of edges that project from the source to the target.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3027">
<title id=" W08-0407.xml">experiments in discriminating phrase based translations on the basis of syntactic coupling features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.2 related work.
</prevsent>
<prevsent>there is growing body of work on the use of syntax for improving statistical machine translation, from approaches such as (chiang, 2007) that use formal syntax?, that is syntactic structures for the source and target that are discovered on the basis of bilingual corpus, but without resort to an externally motivated parser, to approaches such as (yamada and knight, 2001) <papid> P01-1067 </papid>and (marcu et al, 2006) <papid> W06-1606 </papid>that use an external parser on the target only, or such as (quirk et al, 2005) <papid> P05-1034 </papid>on the source only, or such as (cowan et al., 2006) <papid> W06-1628 </papid>that use external parsers both on the source and on the target.our approach is in this last category, but is distinguished from all the cited approaches by the fact that it does not try to build target structure (or string) directly, but rather by using baseline phrase-basedsystem as generator of candidates, and then selecting between these candidates through discriminative procedure.</prevsent>
</prevsection>
<citsent citstr=" W06-2606 ">
some other researchers have taken similar line, for example (hasan et al, 2006), <papid> W06-2606 </papid>which only uses parser on the target, and attempts to improve the fluency of the translation produced, andes pecially (och et al, 2003) that reports experiments using large number of syntactic features.</citsent>
<aftsection>
<nextsent>in one of the experiments briefly reported, dependency parser is used both for the source and for the target and few features are introduced for counting the number of edges that project from the source to the target.
</nextsent>
<nextsent>this experiment, which as far as we know was not followed up by deeper investigations,is very similar to what we do.
</nextsent>
<nextsent>however we introduce and compare results for wider variety of coupling features, taking into account different combinations involving normalization of the counts, symmetrized features between the source and target, labelled dependencies, and also consider several ways for computing the word alignment on the basis of which edge couplings are determined.
</nextsent>
<nextsent>2.1 background.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3030">
<title id=" W07-2037.xml">i2r three systems for word sense discrimination chinese word sense disambiguation and english word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for the lexical sample subtask for task17, our system achieved 86.4% coarse grained precision and recall.
</prevsent>
<prevsent>semeval-2007 launches totally 18 tasks for evaluation exercise, covering word sense disambiguation, word sense discrimination, semantic role labeling, and sense disambiguation for information retrieval, and other topics in nlp.
</prevsent>
</prevsection>
<citsent citstr=" W07-2002 ">
we participated three tasks in semeval-2007, which are task 2 (evaluating word sense induction and discrimination systems),task 5 (multilingual chinese-english lexical sample task) and the first subtask at task 17 (english lexical sample, english semantic role labeling and english all-words tasks).the goal for semeval-2007 task 2 (evaluating word sense induction and discrimination sys tems)(agirre and soroa, 2007) <papid> W07-2002 </papid>is to automatically discriminate the senses of english target words by the use of only untagged data.</citsent>
<aftsection>
<nextsent>here we address thi sword sense discrimination problem by (1) estimating the number of word senses of target word in untagged data using stability criterion, and then (2) grouping the instances of this target word into the estimated number of clusters according to the similarity of contexts of the instances.
</nextsent>
<nextsent>no sense-tagged data is used to help the clustering process.the goal of task 5 (chinese word sense disam biguation) is to create framework for the evaluation of word sense disambiguation in chinese-english machine translation systems.
</nextsent>
<nextsent>each participates ofthis task will be provided with sense tagged training data and untagged test data for 40 chinese polysemous words.
</nextsent>
<nextsent>the sense tags?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3031">
<title id=" W07-2037.xml">i2r three systems for word sense discrimination chinese word sense disambiguation and english word sense disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the sense tags?
</prevsent>
<prevsent>for the ambiguous chinese target words are given in the form oftheir english translations.
</prevsent>
</prevsection>
<citsent citstr=" P05-1049 ">
here we used semi supervised classification algorithm (label propagation algorithm) (niu, et al, 2005) <papid> P05-1049 </papid>to address this chinese word sense disambiguation problem.</citsent>
<aftsection>
<nextsent>the lexical sample subtask of task 17 (english word sense disambiguation) provides sense-tagged training data and untagged test data for 35 nouns and 65 verbs.
</nextsent>
<nextsent>this data includes, for each target word:ontonotes sense tags (these are groupings of wordnet senses that are more coarse-grained than tradi 177 tional wn entries), as well as the sense inventory for these lemmas.
</nextsent>
<nextsent>here we used only the training data supplied in this subtask for sense disambiguation in test set.
</nextsent>
<nextsent>the label propagation algorithm (niu, et al, 2005) <papid> P05-1049 </papid>was used to perform sense disambiguation by the use of both training data and test data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3035">
<title id=" W07-2037.xml">i2r three systems for word sense discrimination chinese word sense disambiguation and english word sense disambiguation </title>
<section> feature set.  </section>
<citcontext>
<prevsection>
<prevsent>finally we will give conclusion of our work in section 7.
</prevsent>
<prevsent>in task 2, task 5 and task 17, we used three types of features to capture contextual information: part-ofspeech of neighboring words (no more than three word distance) with position information, unordered single words in topical context (all the contextualsentences), and local collocations (including 11 col locations).
</prevsent>
</prevsection>
<citsent citstr=" W02-1006 ">
the feature set used here is as same as the feature set used in (lee and ng, 2002) <papid> W02-1006 </papid>except that we did not use syntactic relations.</citsent>
<aftsection>
<nextsent>for task 2word sense discrimination is to automatically discriminate the senses of target words by the use of only untagged data.
</nextsent>
<nextsent>so we can employ clustering algorithms to address this problem.
</nextsent>
<nextsent>another problem is that there is no sense inventories for target words.
</nextsent>
<nextsent>so the clustering algorithms should have the ability to automatically estimate the sense number of target word.here we used the sequential information bottleneck algorithm (sib) (slonim, et al, 2002) to estimate cluster structure, which measures the similarity of contexts of instances of target words according to the similarity of their contextual feature conditionaldistribution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3036">
<title id=" W07-1807.xml">a development environment for building grammar based speech enabled applications </title>
<section> the regulus platform.  </section>
<citcontext>
<prevsection>
<prevsent>the regulus platform is comprehensive toolkit for developing grammar-based speech-enabled systems that can be run on the commercially available nuance recognition environment.
</prevsent>
<prevsent>the platform has been developed by an open source consortium, the main partners of which have been nasa ames research center and geneva university, and is freely available for download from the source forge website1.
</prevsent>
</prevsection>
<citsent citstr=" P05-3008 ">
regulus has been used to build several large systems, including geneva universitys medslt medical speech translator(bouillon et al, 2005) and nasas clarissa procedure browser (rayner et al, 2005<papid> P05-3008 </papid>b)2.</citsent>
<aftsection>
<nextsent>regulus is described at length in (rayner et al, 2006), the first half of which consists of an extended tutorial introduction.
</nextsent>
<nextsent>the release 1http://sourceforge.net/projects/regulus/ 2http://ic.arc.nasa.gov/projects/clarissa/ also includes extensive online documentation, including several example applications.the core functionality offered by regulus is compilation of typed unification grammars into parsers, generators, and nuance-formatted cfg language models, and hence also into nuance recognitionpackages.
</nextsent>
<nextsent>small unification grammars can be compiled directly into executable forms.
</nextsent>
<nextsent>the central idea of regulus, however, is to base as much ofthe development work as possible on large, domain independent resource grammars.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3040">
<title id=" W08-0333.xml">fast easy and cheap construction of statistical machine translation models with map reduce </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the map reduce abstraction shields the programmer from having to explicitly worry about system-level issues such as synchronization, data exchange, and fault tolerance (see section 2 for details).
</prevsent>
<prevsent>the run time is able to transparently distribute computations across large clusters of commodity hardware with good scaling characteristics.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
this frees the programmer to focus on actual mt issues.in this paper we present map reduce implementations of training algorithms for two kinds of models commonly used in statistical mt today: phrase based translation model (koehn et al, 2003) <papid> N03-1017 </papid>andword alignment models based on pairwise lexical translation trained using expectation maximization (dempster et al, 1977).</citsent>
<aftsection>
<nextsent>currently, such model stake days to construct using standard tools with publicly available training corpora; our map reduce implementation cuts this time to hours.
</nextsent>
<nextsent>as an benefit to the community, it is our intention to release this code under an open source license.
</nextsent>
<nextsent>it is worthwhile to emphasize that we present these results as sweet spot?
</nextsent>
<nextsent>in the complex design space of engineering decisions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3041">
<title id=" W08-0333.xml">fast easy and cheap construction of statistical machine translation models with map reduce </title>
<section> phrase-based translation.  </section>
<citcontext>
<prevsection>
<prevsent>models in question: representing (b|a = a) in the phrase model required at most 90k parameters, and in the lexical model, 128k parameters (i.e., the size of the vocabulary for language b).
</prevsent>
<prevsent>for the remainder of the experiments reported, we confine ourselves to the use of method 3.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
in phrase-based translation, the translation process is modeled by splitting the source sentence into phrases (a contiguous string of words) and translating the phrases as unit (och et al, 1999; <papid> W99-0604 </papid>koehnet al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>phrases are extracted from word aligned parallel sentence according to the strategy proposed by och et al (1999), <papid> W99-0604 </papid>where every word in phrase is aligned only to other words in the phrase,and not to any words outside the phrase bounds.</nextsent>
<nextsent>figure 4 shows an example aligned sentence and some of the consistent subphrases that may be extracted.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3044">
<title id=" W08-0333.xml">fast easy and cheap construction of statistical machine translation models with map reduce </title>
<section> phrase-based translation.  </section>
<citcontext>
<prevsection>
<prevsent>the framework provides conceptually simple solution to the problem, while providing an implementation that is both scalable and fault tolerant in fact, transparently so since the runtime hides all these complexities from there searcher.
</prevsent>
<prevsent>from the graph it is clear that the overhead associated with the framework itself is quite low, especially for large quantities of data.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
we concede that it may be possible for custom solution (e.g., with mpi) to achieve even faster running times, but we argue that devoting resources to developing such solution would not be cost-effective.next, we explore class of models where the stan 5following och and ney (2002), <papid> P02-1038 </papid>it is customary to combine both these probabilities as feature values in log-linear model.</citsent>
<aftsection>
<nextsent>6in our cluster, only 19 machines actually compute, and each has two single-core processors.
</nextsent>
<nextsent>dard tools work primarily in memory, but where the computational complexity of the models is greater.
</nextsent>
<nextsent>although word-based translation models have been largely supplanted by models that make use of larger translation units, the task of generating word alignment, the mapping between the words in the source and target sentences that are translation ally equivalent, remains crucial to nearly all approaches to statistical machine translation.
</nextsent>
<nextsent>the ibm models, together with hidden markov model (hmm), form class of generative models that are based on lexical translation model (fj |ei) where each word fj in the foreign sentencefm1 is generated by precisely one word ei in the sentence el1, independently of the other translation decisions (brown et al, 1993; <papid> J93-2003 </papid>vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2000).<papid> C00-2163 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3045">
<title id=" W08-0333.xml">fast easy and cheap construction of statistical machine translation models with map reduce </title>
<section> word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>dard tools work primarily in memory, but where the computational complexity of the models is greater.
</prevsent>
<prevsent>although word-based translation models have been largely supplanted by models that make use of larger translation units, the task of generating word alignment, the mapping between the words in the source and target sentences that are translation ally equivalent, remains crucial to nearly all approaches to statistical machine translation.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the ibm models, together with hidden markov model (hmm), form class of generative models that are based on lexical translation model (fj |ei) where each word fj in the foreign sentencefm1 is generated by precisely one word ei in the sentence el1, independently of the other translation decisions (brown et al, 1993; <papid> J93-2003 </papid>vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2000).<papid> C00-2163 </papid></citsent>
<aftsection>
<nextsent>given these assumptions, we let the sentence translation probability be mediated bya latent alignment variable (am1 in the equations be low) that specifies the pairwise mapping between words in the source and target languages.
</nextsent>
<nextsent>assuming given sentence length for fm1 , the translation probability is defined as follows: (fm1 |e 1) = ? am1 (fm1 , m 1 |e 1) = ? am1 (am1 |e 1, m 1 ) m?
</nextsent>
<nextsent>j=1 (fj |eaj ) once the model parameters have been estimated, the single-best word alignment is computed according to the following decision rule: am1 = argmax am1 (am1 |e 1, m 1 ) m?
</nextsent>
<nextsent>j=1 (fj |eaj )in this section, we consider the map reduce implementation of two specific alignment models: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3047">
<title id=" W08-0333.xml">fast easy and cheap construction of statistical machine translation models with map reduce </title>
<section> word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>dard tools work primarily in memory, but where the computational complexity of the models is greater.
</prevsent>
<prevsent>although word-based translation models have been largely supplanted by models that make use of larger translation units, the task of generating word alignment, the mapping between the words in the source and target sentences that are translation ally equivalent, remains crucial to nearly all approaches to statistical machine translation.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
the ibm models, together with hidden markov model (hmm), form class of generative models that are based on lexical translation model (fj |ei) where each word fj in the foreign sentencefm1 is generated by precisely one word ei in the sentence el1, independently of the other translation decisions (brown et al, 1993; <papid> J93-2003 </papid>vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2000).<papid> C00-2163 </papid></citsent>
<aftsection>
<nextsent>given these assumptions, we let the sentence translation probability be mediated bya latent alignment variable (am1 in the equations be low) that specifies the pairwise mapping between words in the source and target languages.
</nextsent>
<nextsent>assuming given sentence length for fm1 , the translation probability is defined as follows: (fm1 |e 1) = ? am1 (fm1 , m 1 |e 1) = ? am1 (am1 |e 1, m 1 ) m?
</nextsent>
<nextsent>j=1 (fj |eaj ) once the model parameters have been estimated, the single-best word alignment is computed according to the following decision rule: am1 = argmax am1 (am1 |e 1, m 1 ) m?
</nextsent>
<nextsent>j=1 (fj |eaj )in this section, we consider the map reduce implementation of two specific alignment models: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3048">
<title id=" W08-0333.xml">fast easy and cheap construction of statistical machine translation models with map reduce </title>
<section> word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>dard tools work primarily in memory, but where the computational complexity of the models is greater.
</prevsent>
<prevsent>although word-based translation models have been largely supplanted by models that make use of larger translation units, the task of generating word alignment, the mapping between the words in the source and target sentences that are translation ally equivalent, remains crucial to nearly all approaches to statistical machine translation.
</prevsent>
</prevsection>
<citsent citstr=" C00-2163 ">
the ibm models, together with hidden markov model (hmm), form class of generative models that are based on lexical translation model (fj |ei) where each word fj in the foreign sentencefm1 is generated by precisely one word ei in the sentence el1, independently of the other translation decisions (brown et al, 1993; <papid> J93-2003 </papid>vogel et al, 1996; <papid> C96-2141 </papid>och and ney, 2000).<papid> C00-2163 </papid></citsent>
<aftsection>
<nextsent>given these assumptions, we let the sentence translation probability be mediated bya latent alignment variable (am1 in the equations be low) that specifies the pairwise mapping between words in the source and target languages.
</nextsent>
<nextsent>assuming given sentence length for fm1 , the translation probability is defined as follows: (fm1 |e 1) = ? am1 (fm1 , m 1 |e 1) = ? am1 (am1 |e 1, m 1 ) m?
</nextsent>
<nextsent>j=1 (fj |eaj ) once the model parameters have been estimated, the single-best word alignment is computed according to the following decision rule: am1 = argmax am1 (am1 |e 1, m 1 ) m?
</nextsent>
<nextsent>j=1 (fj |eaj )in this section, we consider the map reduce implementation of two specific alignment models: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3051">
<title id=" W08-0333.xml">fast easy and cheap construction of statistical machine translation models with map reduce </title>
<section> word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>although it is necessary to compute sum over all possible alignments, the independence assumptions made in these models allow the total probability of generating particular observation to be efficiently computed using dynamic programming.8 the hmm alignment model uses the forward-backward algorithm (baum et al, 1970), which is also an instance of em.
</prevsent>
<prevsent>even with dynamic programming, this requires o(slm) operations for model 1, and o(slm2) for the hmm model, where and arethe average lengths of the foreign and english sentences in the training corpus, and is the number ofsentences.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
figure 6 shows measurements of the average iteration run-time for model 1 and the hmm alignment model as implemented in giza++ (ochand ney, 2003), <papid> J03-1002 </papid>state-of-the-art c++ implementation of the ibm and hmm alignment models thatis widely used.</citsent>
<aftsection>
<nextsent>five iterations are generally necessary to train the models, so the time to carry out full training of the models is approximately five times the per-iteration run-time.
</nextsent>
<nextsent>5.1 em with mapreduce.
</nextsent>
<nextsent>expectation-maximization algorithms can be expressed quite naturally in the map reduce framework (chu et al, 2006).
</nextsent>
<nextsent>in general, for discrete generative models, mappers iterate over the training instances and compute the partial expected counts for all the un observable events in the model that should 7for the first iteration, when there is no prior model, heuristic, random, or uniform distribution may be chosen.8for ibm models 3-5, which are not our primary focus, dynamic programming is not possible, but the general strategy for computing expected counts from previous model and updating remains identical and therefore the techniques we suggest in this section are applicable to those models as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3052">
<title id=" W08-0333.xml">fast easy and cheap construction of statistical machine translation models with map reduce </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, since the database is distributed across the same nodes as the map reduce jobs, many of the same data locality benefits that wolfe et al (2007) sought to capitalize on will be available without abandoning the guarantees of the map reduce paradigm.
</prevsent>
<prevsent>although it does not use map reduce, the mttk tool suite implements distributed model 1, 2 andhmm training using home-grown?
</prevsent>
</prevsection>
<citsent citstr=" N06-4004 ">
paralleliza tion scheme (deng and byrne, 2006).<papid> N06-4004 </papid></citsent>
<aftsection>
<nextsent>however, the tool relies on cluster where all nodes have access to the same shared networked file storage, restriction that map reduce does not impose.
</nextsent>
<nextsent>205 there has been fair amount of work inspired by the problems of long latencies and excessive space requirements in the construction of phrase-based and hierarchical phrase-based translation models.several authors have advocated indexing the training data with suffix array and computing the necessary statistics during or immediately prior to decoding (callison-burch et al, 2005; lopez, 2007).<papid> D07-1104 </papid>although this technique works quite well, the standard channel probability (f |e) cannot be computed, which is not limitation of mapreduce.10</nextsent>
<nextsent>we have shown that an important class of model building algorithms in statistical machine translation can be straightforwardly recast into the mapre duce framework, yielding distributed solution that is cost-effective, scalable, robust, and exact(i.e., doesnt resort to approximations).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3053">
<title id=" W08-0333.xml">fast easy and cheap construction of statistical machine translation models with map reduce </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>paralleliza tion scheme (deng and byrne, 2006).<papid> N06-4004 </papid></prevsent>
<prevsent>however, the tool relies on cluster where all nodes have access to the same shared networked file storage, restriction that map reduce does not impose.</prevsent>
</prevsection>
<citsent citstr=" D07-1104 ">
205 there has been fair amount of work inspired by the problems of long latencies and excessive space requirements in the construction of phrase-based and hierarchical phrase-based translation models.several authors have advocated indexing the training data with suffix array and computing the necessary statistics during or immediately prior to decoding (callison-burch et al, 2005; lopez, 2007).<papid> D07-1104 </papid>although this technique works quite well, the standard channel probability (f |e) cannot be computed, which is not limitation of mapreduce.10</citsent>
<aftsection>
<nextsent>we have shown that an important class of model building algorithms in statistical machine translation can be straightforwardly recast into the mapre duce framework, yielding distributed solution that is cost-effective, scalable, robust, and exact(i.e., doesnt resort to approximations).
</nextsent>
<nextsent>alternative strategies for parallelizing these algorithms either impose significant demands on the developer,the hardware infrastructure, or both; or, they require making unwarranted independence assumptions, such as dividing the training data into chunks and building separate models.
</nextsent>
<nextsent>we have further shown that on 20-machine cluster of commodity hardware, the map reduce implementations have excellent performance and scaling characteristics.why does this matter?
</nextsent>
<nextsent>given the difficulty of implementing model training algorithms (phrase-based model estimation is difficult because of the size of data involved, and word-based alignment models area challenge because of the computational complexity associated with computing expected counts), handful of single-core tools have come to be widely used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3054">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> dimensions of un lexicalized parsing.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J98-4004 ">
probabilistic context free grammars (pcfgs) arethe formal backbone of most high-accuracy statistical parsers for english, and variety of techniques was developed to enhance their performance relative to the nave treebank implementation ? from un lexicalized extensions exploiting simple category splits (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003)<papid> P03-1054 </papid>to fully lexicalized parsers that condition events below constituent upon the head and additional lexical content (collins, 2003; <papid> J03-4003 </papid>charniak, 1997).</citsent>
<aftsection>
<nextsent>whileit is clear that conditioning on lexical content improves the grammars disambiguation capabilities,klein and manning (2003) <papid> P03-1054 </papid>demonstrate that well crafted un lexicalized pcfg can close the gap, to large extent, with current state-of-the-art lexicalized parsers for english.the factor that sets apart vanilla pcfgs (charniak, 1996) from their un lexicalized extensions proposed by, e.g., (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003)<papid> P03-1054 </papid>, is the choice for statistical parametrization that weakens the independence assumptions implicit in the treebank grammar.</nextsent>
<nextsent>studies on accurate unlex icalized parsing models outline two dimensions of parametrization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3056">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> dimensions of un lexicalized parsing.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P03-1054 ">
probabilistic context free grammars (pcfgs) arethe formal backbone of most high-accuracy statistical parsers for english, and variety of techniques was developed to enhance their performance relative to the nave treebank implementation ? from un lexicalized extensions exploiting simple category splits (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003)<papid> P03-1054 </papid>to fully lexicalized parsers that condition events below constituent upon the head and additional lexical content (collins, 2003; <papid> J03-4003 </papid>charniak, 1997).</citsent>
<aftsection>
<nextsent>whileit is clear that conditioning on lexical content improves the grammars disambiguation capabilities,klein and manning (2003) <papid> P03-1054 </papid>demonstrate that well crafted un lexicalized pcfg can close the gap, to large extent, with current state-of-the-art lexicalized parsers for english.the factor that sets apart vanilla pcfgs (charniak, 1996) from their un lexicalized extensions proposed by, e.g., (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003)<papid> P03-1054 </papid>, is the choice for statistical parametrization that weakens the independence assumptions implicit in the treebank grammar.</nextsent>
<nextsent>studies on accurate unlex icalized parsing models outline two dimensions of parametrization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3057">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> dimensions of un lexicalized parsing.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J03-4003 ">
probabilistic context free grammars (pcfgs) arethe formal backbone of most high-accuracy statistical parsers for english, and variety of techniques was developed to enhance their performance relative to the nave treebank implementation ? from un lexicalized extensions exploiting simple category splits (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003)<papid> P03-1054 </papid>to fully lexicalized parsers that condition events below constituent upon the head and additional lexical content (collins, 2003; <papid> J03-4003 </papid>charniak, 1997).</citsent>
<aftsection>
<nextsent>whileit is clear that conditioning on lexical content improves the grammars disambiguation capabilities,klein and manning (2003) <papid> P03-1054 </papid>demonstrate that well crafted un lexicalized pcfg can close the gap, to large extent, with current state-of-the-art lexicalized parsers for english.the factor that sets apart vanilla pcfgs (charniak, 1996) from their un lexicalized extensions proposed by, e.g., (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003)<papid> P03-1054 </papid>, is the choice for statistical parametrization that weakens the independence assumptions implicit in the treebank grammar.</nextsent>
<nextsent>studies on accurate unlex icalized parsing models outline two dimensions of parametrization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3080">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> dimensions of un lexicalized parsing.  </section>
<citcontext>
<prevsection>
<prevsent>156klein and manning (2003) <papid> P03-1054 </papid>systematize the distinction between these two forms of parametrizationby drawing them on horizontal-vertical grid: parent encoding is vertical (external to the rule) whereas head-outward generation is horizontal (internal tothe rule).</prevsent>
<prevsent>by varying the value of the parameters along the grid, klein and manning (2003) <papid> P03-1054 </papid>tune their treebank grammar to achieve improved perfor mance.</prevsent>
</prevsection>
<citsent citstr=" P03-1013 ">
this two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for english as well as other languages, such as german (dubey and keller, 2003) <papid> P03-1013 </papid>czech (collins et al, 1999) <papid> P99-1065 </papid>and chinese (bikel and chiang, 2000).<papid> W00-1201 </papid></citsent>
<aftsection>
<nextsent>however, accuracy results for parsing languages other than english still lag behind.1we propose that for various languages including the semitic family, e.g. modern hebrew (mh)and modern standard arabic (msa), third dimension of parametrization is necessary for encoding linguistic information relevant for breaking false independence assumptions.
</nextsent>
<nextsent>in semitic languages, arguments may move around rather freely and the phrase-structure of clause-level categories is often shallow.
</nextsent>
<nextsent>for such languages agreement features play role in disambiguation at least as important as the vertical and horizontal conditioning.
</nextsent>
<nextsent>we propose third dimension of parameterizations that encodes morphological features such as those realizing syntactic agreement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3081">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> dimensions of un lexicalized parsing.  </section>
<citcontext>
<prevsection>
<prevsent>156klein and manning (2003) <papid> P03-1054 </papid>systematize the distinction between these two forms of parametrizationby drawing them on horizontal-vertical grid: parent encoding is vertical (external to the rule) whereas head-outward generation is horizontal (internal tothe rule).</prevsent>
<prevsent>by varying the value of the parameters along the grid, klein and manning (2003) <papid> P03-1054 </papid>tune their treebank grammar to achieve improved perfor mance.</prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
this two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for english as well as other languages, such as german (dubey and keller, 2003) <papid> P03-1013 </papid>czech (collins et al, 1999) <papid> P99-1065 </papid>and chinese (bikel and chiang, 2000).<papid> W00-1201 </papid></citsent>
<aftsection>
<nextsent>however, accuracy results for parsing languages other than english still lag behind.1we propose that for various languages including the semitic family, e.g. modern hebrew (mh)and modern standard arabic (msa), third dimension of parametrization is necessary for encoding linguistic information relevant for breaking false independence assumptions.
</nextsent>
<nextsent>in semitic languages, arguments may move around rather freely and the phrase-structure of clause-level categories is often shallow.
</nextsent>
<nextsent>for such languages agreement features play role in disambiguation at least as important as the vertical and horizontal conditioning.
</nextsent>
<nextsent>we propose third dimension of parameterizations that encodes morphological features such as those realizing syntactic agreement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3082">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> dimensions of un lexicalized parsing.  </section>
<citcontext>
<prevsection>
<prevsent>156klein and manning (2003) <papid> P03-1054 </papid>systematize the distinction between these two forms of parametrizationby drawing them on horizontal-vertical grid: parent encoding is vertical (external to the rule) whereas head-outward generation is horizontal (internal tothe rule).</prevsent>
<prevsent>by varying the value of the parameters along the grid, klein and manning (2003) <papid> P03-1054 </papid>tune their treebank grammar to achieve improved perfor mance.</prevsent>
</prevsection>
<citsent citstr=" W00-1201 ">
this two-dimensional parametrization has been instrumental in devising parsing models that improve disambiguation capabilities for english as well as other languages, such as german (dubey and keller, 2003) <papid> P03-1013 </papid>czech (collins et al, 1999) <papid> P99-1065 </papid>and chinese (bikel and chiang, 2000).<papid> W00-1201 </papid></citsent>
<aftsection>
<nextsent>however, accuracy results for parsing languages other than english still lag behind.1we propose that for various languages including the semitic family, e.g. modern hebrew (mh)and modern standard arabic (msa), third dimension of parametrization is necessary for encoding linguistic information relevant for breaking false independence assumptions.
</nextsent>
<nextsent>in semitic languages, arguments may move around rather freely and the phrase-structure of clause-level categories is often shallow.
</nextsent>
<nextsent>for such languages agreement features play role in disambiguation at least as important as the vertical and horizontal conditioning.
</nextsent>
<nextsent>we propose third dimension of parameterizations that encodes morphological features such as those realizing syntactic agreement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3084">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> dimensions of modern hebrew syntax.  </section>
<citcontext>
<prevsection>
<prevsent>determining the child constituents that contribute each of the features is not trivial matter either.
</prevsent>
<prevsent>to illustrate the extent and the complexity of that matter let us consider definite ness in mh, which is morphologically marked (as an prefix to the stem, glossed here explicitly as the-?)
</prevsent>
</prevsection>
<citsent citstr=" P06-1087 ">
and behaves as syntactic 3see (wintner, 2000) and (goldberg et al, 2006) <papid> P06-1087 </papid>for formal and statistical accounts (respectively) of noun phrases in mh.</citsent>
<aftsection>
<nextsent>(a) np.fs.d np.fs.d sganit hmnhl deputy.fs the-manager.ms.d adjp.fs.d hmswrh the-dedicated.fs.d (a) np.fs.d sganit hmnhl deputy.fs the-manager.ms.d predp.fs mswrh dedicated.fs figure 2: definite ness in mh as phrase-level agreementfeature: agreement on definite ness helps to determine the internal structure of higher level np (a), and the absence thereof helps to determine the attachment to predicate in verb-less sentence (b) (marking d(efiniteness)) (a) np.fs.d nnt.fs sganit deputy.fs n.ms.d hmnhl the-manager.ms.d vp.fs v.fs htpjrh resigned.fs (b) sv? npnnt?.fs.d nnt.fs sganit deputy.fs n.ms.d hmnhl the-manager.ms.d vpv?).fs v.fs htpjrh resigned.fsfigure 3: phrase-level agreement features and head dependencies in mh: the direction of percolating definite ness in mh is distinct of that of the head (marking head-tag?)property (danon, 2001).
</nextsent>
<nextsent>definite noun-phrases exhibit agreement with other modifying phrases, andsuch agreement helps to determine the internal structure, labels, and the correct level of attachment as illustrated in figure 2.
</nextsent>
<nextsent>the agreement on definite ness helps to determine the internal structure of noun phrases 2(a), and the absence thereof helps in determining the attachment to predicates in verb-less sentences, as in 2(b).
</nextsent>
<nextsent>finally, definite ness may be percolated from different form than the one determining the gender and number of phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3085">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> dimensions of modern hebrew syntax.  </section>
<citcontext>
<prevsection>
<prevsent>158 2.2 the modern hebrew treebank scheme.
</prevsent>
<prevsent>the annotation scheme of version 2.0 of the mh treebank (simaan et al, 2001)4 aims to capture the morphological and syntactic properties of mh justdescribed.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
this results in several aspects that distinguish the mh treebank from, e.g., the wsj penn treebank annotation scheme (marcus et al, 1994).<papid> H94-1020 </papid></citsent>
<aftsection>
<nextsent>the mh treebank is built over word segments.
</nextsent>
<nextsent>this means that the yields of the syntactic trees do not correspond to space delimited words but rather to morphological segments that carry distinct syntactic roles, i.e., each segment corresponds to single pos tag.
</nextsent>
<nextsent>(this in turn means that prefixes marking determiners, relativizers, prepositions and definite articles are segmented away and appear as leaves in syntactic parse tree.)
</nextsent>
<nextsent>the pos categories assigned to segmented words are decorated with features such as gender, number, person and tense, and these features are percolated higher up the tree according to pre-defined syntactic dependencies (kry molowski et al, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3095">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> refining the parameter space.  </section>
<citcontext>
<prevsection>
<prevsent>in bottom up process this annotation strategy imposes soft constraints on the top-down head-outward generation process.figure 6(a) focuses on selected np node highlighted in figure 4 and shows its expansion possibilities in three dimensions.
</prevsent>
<prevsent>figure 6(b) illustrates howthe depth expansion interacts with both parent anno 160 (a) the horizontal/vertical grid (b) the vertical dimension (c) the horizontal dimension figure 5: the two-dimensional space: the horizontal and vertical dimensions outlined by (klein and manning, 2003)<papid> P03-1054 </papid> tation and neighbor dependencies thereby affecting both distributions.</prevsent>
</prevsection>
<citsent citstr=" P05-1010 ">
3.1 note on state-splitsrecent studies (klein and manning, 2003; <papid> P03-1054 </papid>matsuzaki et al, 2005; <papid> P05-1010 </papid>prescher, 2005; <papid> W05-1512 </papid>petrov et al,2006) <papid> P06-1055 </papid>suggest that category-splits help in enhancing the performance of treebank grammars, and aprevious study on mh (tsarfaty, 2006) <papid> P06-3009 </papid>outlines specific pos-tags splits that improve mh parsing ac curacy.</citsent>
<aftsection>
<nextsent>yet, there is major difference between category-splits, whether manually or automatically acquired, and the kind of state-splits that arise from agreement features that refine phrasal categories.while category-splits aim at each category in isolation, agreement features apply to whole setof categories all at once, thereby capturing refinement of the categories as well as linguistically motivated co-occurrences between them.
</nextsent>
<nextsent>individualcategory-splits are viewed as taking place in two dimensional space and it is hard to analyze and empirically evaluate their interaction with other annotation strategies.
</nextsent>
<nextsent>here we propose principled way to statistically model the interaction between different linguistic processes that license grammatical structures and empirically contrast their contribution.
</nextsent>
<nextsent>3.2 note on stochastic av grammars the practice of having morphological features orthogonal to constituency structure is not new one and is familiar from formal theories of syntax such as hpsg (sag et al, 2003) and lfg (kaplan and bresnan, 1982).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3096">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> refining the parameter space.  </section>
<citcontext>
<prevsection>
<prevsent>in bottom up process this annotation strategy imposes soft constraints on the top-down head-outward generation process.figure 6(a) focuses on selected np node highlighted in figure 4 and shows its expansion possibilities in three dimensions.
</prevsent>
<prevsent>figure 6(b) illustrates howthe depth expansion interacts with both parent anno 160 (a) the horizontal/vertical grid (b) the vertical dimension (c) the horizontal dimension figure 5: the two-dimensional space: the horizontal and vertical dimensions outlined by (klein and manning, 2003)<papid> P03-1054 </papid> tation and neighbor dependencies thereby affecting both distributions.</prevsent>
</prevsection>
<citsent citstr=" W05-1512 ">
3.1 note on state-splitsrecent studies (klein and manning, 2003; <papid> P03-1054 </papid>matsuzaki et al, 2005; <papid> P05-1010 </papid>prescher, 2005; <papid> W05-1512 </papid>petrov et al,2006) <papid> P06-1055 </papid>suggest that category-splits help in enhancing the performance of treebank grammars, and aprevious study on mh (tsarfaty, 2006) <papid> P06-3009 </papid>outlines specific pos-tags splits that improve mh parsing ac curacy.</citsent>
<aftsection>
<nextsent>yet, there is major difference between category-splits, whether manually or automatically acquired, and the kind of state-splits that arise from agreement features that refine phrasal categories.while category-splits aim at each category in isolation, agreement features apply to whole setof categories all at once, thereby capturing refinement of the categories as well as linguistically motivated co-occurrences between them.
</nextsent>
<nextsent>individualcategory-splits are viewed as taking place in two dimensional space and it is hard to analyze and empirically evaluate their interaction with other annotation strategies.
</nextsent>
<nextsent>here we propose principled way to statistically model the interaction between different linguistic processes that license grammatical structures and empirically contrast their contribution.
</nextsent>
<nextsent>3.2 note on stochastic av grammars the practice of having morphological features orthogonal to constituency structure is not new one and is familiar from formal theories of syntax such as hpsg (sag et al, 2003) and lfg (kaplan and bresnan, 1982).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3097">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> refining the parameter space.  </section>
<citcontext>
<prevsection>
<prevsent>in bottom up process this annotation strategy imposes soft constraints on the top-down head-outward generation process.figure 6(a) focuses on selected np node highlighted in figure 4 and shows its expansion possibilities in three dimensions.
</prevsent>
<prevsent>figure 6(b) illustrates howthe depth expansion interacts with both parent anno 160 (a) the horizontal/vertical grid (b) the vertical dimension (c) the horizontal dimension figure 5: the two-dimensional space: the horizontal and vertical dimensions outlined by (klein and manning, 2003)<papid> P03-1054 </papid> tation and neighbor dependencies thereby affecting both distributions.</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
3.1 note on state-splitsrecent studies (klein and manning, 2003; <papid> P03-1054 </papid>matsuzaki et al, 2005; <papid> P05-1010 </papid>prescher, 2005; <papid> W05-1512 </papid>petrov et al,2006) <papid> P06-1055 </papid>suggest that category-splits help in enhancing the performance of treebank grammars, and aprevious study on mh (tsarfaty, 2006) <papid> P06-3009 </papid>outlines specific pos-tags splits that improve mh parsing ac curacy.</citsent>
<aftsection>
<nextsent>yet, there is major difference between category-splits, whether manually or automatically acquired, and the kind of state-splits that arise from agreement features that refine phrasal categories.while category-splits aim at each category in isolation, agreement features apply to whole setof categories all at once, thereby capturing refinement of the categories as well as linguistically motivated co-occurrences between them.
</nextsent>
<nextsent>individualcategory-splits are viewed as taking place in two dimensional space and it is hard to analyze and empirically evaluate their interaction with other annotation strategies.
</nextsent>
<nextsent>here we propose principled way to statistically model the interaction between different linguistic processes that license grammatical structures and empirically contrast their contribution.
</nextsent>
<nextsent>3.2 note on stochastic av grammars the practice of having morphological features orthogonal to constituency structure is not new one and is familiar from formal theories of syntax such as hpsg (sag et al, 2003) and lfg (kaplan and bresnan, 1982).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3098">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> refining the parameter space.  </section>
<citcontext>
<prevsection>
<prevsent>in bottom up process this annotation strategy imposes soft constraints on the top-down head-outward generation process.figure 6(a) focuses on selected np node highlighted in figure 4 and shows its expansion possibilities in three dimensions.
</prevsent>
<prevsent>figure 6(b) illustrates howthe depth expansion interacts with both parent anno 160 (a) the horizontal/vertical grid (b) the vertical dimension (c) the horizontal dimension figure 5: the two-dimensional space: the horizontal and vertical dimensions outlined by (klein and manning, 2003)<papid> P03-1054 </papid> tation and neighbor dependencies thereby affecting both distributions.</prevsent>
</prevsection>
<citsent citstr=" P06-3009 ">
3.1 note on state-splitsrecent studies (klein and manning, 2003; <papid> P03-1054 </papid>matsuzaki et al, 2005; <papid> P05-1010 </papid>prescher, 2005; <papid> W05-1512 </papid>petrov et al,2006) <papid> P06-1055 </papid>suggest that category-splits help in enhancing the performance of treebank grammars, and aprevious study on mh (tsarfaty, 2006) <papid> P06-3009 </papid>outlines specific pos-tags splits that improve mh parsing ac curacy.</citsent>
<aftsection>
<nextsent>yet, there is major difference between category-splits, whether manually or automatically acquired, and the kind of state-splits that arise from agreement features that refine phrasal categories.while category-splits aim at each category in isolation, agreement features apply to whole setof categories all at once, thereby capturing refinement of the categories as well as linguistically motivated co-occurrences between them.
</nextsent>
<nextsent>individualcategory-splits are viewed as taking place in two dimensional space and it is hard to analyze and empirically evaluate their interaction with other annotation strategies.
</nextsent>
<nextsent>here we propose principled way to statistically model the interaction between different linguistic processes that license grammatical structures and empirically contrast their contribution.
</nextsent>
<nextsent>3.2 note on stochastic av grammars the practice of having morphological features orthogonal to constituency structure is not new one and is familiar from formal theories of syntax such as hpsg (sag et al, 2003) and lfg (kaplan and bresnan, 1982).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3099">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> refining the parameter space.  </section>
<citcontext>
<prevsection>
<prevsent>here we propose to reframe systematic morphological decoration of syntactic categories at all levels of the hierarchy as (a) (b) figure 6: the expansion possibilities of non-terminal node: expanding the np from figure 4 in three-dimensional parameterization space an additional dimension of statistical estimation for learning un lexicalized treebank pcfgs.
</prevsent>
<prevsent>our proposal deviates from various stochastic extensions of such constraints-based grammatical formalisms (cf.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
(abney, 1997)) <papid> J97-4005 </papid>and has the advantage of elegantly bypassing the issue of loosing probability mass to failed derivations due to unification failures.</citsent>
<aftsection>
<nextsent>to the best of our knowledge, this proposal has not been empirically explored before.
</nextsent>
<nextsent>our goal is to determine the optimal strategy for learning treebank grammars for mh and to contras tit with bi-dimensional strategies explored for english.
</nextsent>
<nextsent>the methodology we use is adopted from (klein and manning, 2003)<papid> P03-1054 </papid> and our procedure is identical to the one described in (johnson, 1998).<papid> J98-4004 </papid>we define transformations over the treebank that accept as input specific points in the (h, v, d) space depicted in figure 7.</nextsent>
<nextsent>we use the transformed training sets for learning different treebank pcfgs which wethen used to parse unseen sentences, and detrans form the parses for the purpose of evaluation.55previous studied on mh used different portions of the tree bank and its annotation scheme due to its gradual development 161 data we use version 2.0 of the mh treebank which consists of 6501 sentences from the daily newspaper haaretz?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3118">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however its use for statistical parsing hasbeen more scarce and less successful.
</prevsent>
<prevsent>the only previous studies attempting to parse mh we know of are (simaan et al, 2001), applying variation of thedop tree-gram model to 500 sentences, and (tsar faty, 2006), <papid> P06-3009 </papid>using treebank pcfg in an integrated system for morphological and syntactic disambigua tion.9 the adaptation of state-of-the-art parsing models to mh is not immediate as the flat variable structures of phrases are hard to parse and plentiful of morphological features that would facilitate disambiguation are not exploited by currently available parsers.</prevsent>
</prevsection>
<citsent citstr=" W04-1602 ">
also, the mh treebank is much smaller than the ones for, e.g., english (marcus et al, 1994) <papid> H94-1020 </papid>and arabic (maamouri and bies, 2004), <papid> W04-1602 </papid>making ithard to apply data-intensive methods such as the all subtrees approach (bod, 1992) or full lexicalization(collins, 2003)<papid> J03-4003 </papid></citsent>
<aftsection>
<nextsent>our best performing model incorporates three dimensions of parametrization and our best result (75.25%) is similar to the one obtained by the parser of (bikel, 2004) <papid> J04-4004 </papid>for modern standard arabic (75%) using fully lexicalized model and training corpus about three times as large as our newest mh treebank.</nextsent>
<nextsent>this work has shown that devising an adequate baseline for parsing mh requires more than simple category-splits and sophisticated head-driven extensions, and our results provide preliminary evidence for the variation in performance of different parametrization strategies relative to the properties and structure of given language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3123">
<title id=" W07-2219.xml">three dimensional parametrization for parsing morphologically rich languages </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the only previous studies attempting to parse mh we know of are (simaan et al, 2001), applying variation of thedop tree-gram model to 500 sentences, and (tsar faty, 2006), <papid> P06-3009 </papid>using treebank pcfg in an integrated system for morphological and syntactic disambigua tion.9 the adaptation of state-of-the-art parsing models to mh is not immediate as the flat variable structures of phrases are hard to parse and plentiful of morphological features that would facilitate disambiguation are not exploited by currently available parsers.</prevsent>
<prevsent>also, the mh treebank is much smaller than the ones for, e.g., english (marcus et al, 1994) <papid> H94-1020 </papid>and arabic (maamouri and bies, 2004), <papid> W04-1602 </papid>making ithard to apply data-intensive methods such as the all subtrees approach (bod, 1992) or full lexicalization(collins, 2003)<papid> J03-4003 </papid></prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
our best performing model incorporates three dimensions of parametrization and our best result (75.25%) is similar to the one obtained by the parser of (bikel, 2004) <papid> J04-4004 </papid>for modern standard arabic (75%) using fully lexicalized model and training corpus about three times as large as our newest mh treebank.</citsent>
<aftsection>
<nextsent>this work has shown that devising an adequate baseline for parsing mh requires more than simple category-splits and sophisticated head-driven extensions, and our results provide preliminary evidence for the variation in performance of different parametrization strategies relative to the properties and structure of given language.
</nextsent>
<nextsent>the comparison with parsing accuracy for msa suggests that parametrizing an orthogonal depth dimension may be able to compensate, to some extent, on the lackof sister-dependencies, lexical information, and perhaps even the lack of annotated data, but establishing empirically its contribution to parsing msa is matter for further research.
</nextsent>
<nextsent>in the future we intend to further investigate the significance of the depth dimension by extending our models to include more morphological features, more variation in the pa9both studies acheived between 60%70% accuracy, how ever the results are not comparable to our study because of the use of different training sets, different annotation conventions, and different evaluation schemes.
</nextsent>
<nextsent>165 figure 7: all models: locating un lexicalized parsing models in three-dimensional parametrization space figure 8: all results: parsing results for un lexicalized models in three-dimensional parametrization space rameter space, and applications to more languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3131">
<title id=" W07-2028.xml">fbkirst kernel methods for semantic relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiments were carried out using support vector machines as classifier.
</prevsent>
<prevsent>the system achieves an overall f1 of 71.8% on the classification of semantic relations between nominals task at semeval-2007.
</prevsent>
</prevsection>
<citsent citstr=" E06-1051 ">
the starting point of our research is an approach for identifying relations between named entities exploiting only shallow linguistic information, such as tokenization, sentence splitting, part-of-speech tagging and lemmatization (giuliano et al, 2006).<papid> E06-1051 </papid></citsent>
<aftsection>
<nextsent>a combination of kernel functions is used to represent two distinct information sources: (i) the global context where entities appear and (ii) their local contexts.
</nextsent>
<nextsent>the whole sentence where the entities appear (global context) is used to discover the presence of relation between two entities.
</nextsent>
<nextsent>windows of limited size around the entities (local contexts) provide useful clues to identify the roles played by the entities within relation (e.g., agent and target of gene in teraction).
</nextsent>
<nextsent>in the task of detecting protein-protein interactions, we obtained state-of-the-art results ontwo biomedical datasets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3132">
<title id=" W07-2028.xml">fbkirst kernel methods for semantic relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition to the original feature representation, we have integrated deep syntactic processing of the global context and semantic information for each candidate nominals using wordnet as external knowledge source.
</prevsent>
<prevsent>each source of information is represented by kernel functions.
</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
a tree kernel(moschitti, 2004) <papid> P04-1043 </papid>is used to exploit the deep syntactic processing obtained using the charniak parser(charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>on the other hand, bag of synonyms and hypernyms is used to enhance the representation of the candidate nominals.
</nextsent>
<nextsent>the final system is based on five basic kernel functions (bag-ofwords kernel, global context kernel, tree kernel, su per sense kernel, bag of synonyms and hypernymskernel) linearly combined and weighted under different conditions.
</nextsent>
<nextsent>the experiments were carried out using support vector machines (vapnik, 1998) as classifier.we present results on the classification of semantic relations between nominals task at semeval 2007, in which sentences containing ordered pairs of marked nominals, possibly semantically related, have to be classified.
</nextsent>
<nextsent>on this task, we achieve an overall f1 of 71.8% (b category evaluation), largely outperforming all the baselines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3133">
<title id=" W07-2028.xml">fbkirst kernel methods for semantic relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition to the original feature representation, we have integrated deep syntactic processing of the global context and semantic information for each candidate nominals using wordnet as external knowledge source.
</prevsent>
<prevsent>each source of information is represented by kernel functions.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
a tree kernel(moschitti, 2004) <papid> P04-1043 </papid>is used to exploit the deep syntactic processing obtained using the charniak parser(charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>on the other hand, bag of synonyms and hypernyms is used to enhance the representation of the candidate nominals.
</nextsent>
<nextsent>the final system is based on five basic kernel functions (bag-ofwords kernel, global context kernel, tree kernel, su per sense kernel, bag of synonyms and hypernymskernel) linearly combined and weighted under different conditions.
</nextsent>
<nextsent>the experiments were carried out using support vector machines (vapnik, 1998) as classifier.we present results on the classification of semantic relations between nominals task at semeval 2007, in which sentences containing ordered pairs of marked nominals, possibly semantically related, have to be classified.
</nextsent>
<nextsent>on this task, we achieve an overall f1 of 71.8% (b category evaluation), largely outperforming all the baselines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3136">
<title id=" W07-2028.xml">fbkirst kernel methods for semantic relation extraction </title>
<section> kernel methods for relation extraction.  </section>
<citcontext>
<prevsection>
<prevsent>let nt be the set of nodes of tree and = {f1, f2, . . .
</prevsent>
<prevsent>, f|f|} be the fragment space of t1 and t2.
</prevsent>
</prevsection>
<citsent citstr=" W06-2909 ">
then kt (t1, t2) = nint1 njnt2 ?(ni, nj) , (5) where ?(ni, nj) = ?|f| k=1 ik(ni) ? ik(nj) and ik(n) = 1 if is rooted in n, 0 otherwise.for this task, we defined an ad-hoc class of structured features (moschitti et al, 2006), <papid> W06-2909 </papid>the reduced tree (rt), which can be derived from sentence parse tree by the following steps: (1) remove all the terminal nodes but those labeled as relation entities and those pos tagged as verbs, auxiliaries, prepositions, modals or adverbs; (2) remove all the internal nodes not covering any remaining terminal; (3) replace the entity words with place holders that indicate the direction in which the relation should hold.</citsent>
<aftsection>
<nextsent>figure 1 shows parse tree and the resulting rt structure.
</nextsent>
<nextsent>2.2 semantic kernels.
</nextsent>
<nextsent>in (giuliano et al, 2006), <papid> E06-1051 </papid>we used the local context kernel to infer semantic information on the candidate entities (i.e., roles played by the entities).</nextsent>
<nextsent>as the task organizers provide the wordnet sense androle for each nominal, we directly use this information to enrich the feature space and do not include the local context kernel in the combination.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3138">
<title id=" W07-2028.xml">fbkirst kernel methods for semantic relation extraction </title>
<section> discussion and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>relation r f1 acc cause-effect 67.3 90.2 77.1 72.5 instrument-agency 76.9 78.9 77.9 78.2 product-producer 76.2 77.4 76.8 68.8 origin-entity 62.2 63.9 63.0 66.7 theme-tool 69.2 62.1 65.5 73.2 part-whole 65.5 73.1 69.1 76.4 content-container 78.8 68.4 73.2 74.3 avg 70.9 73.4 71.8 72.9 table 1: results on the test set.for content-container we obtain the best performance combining the tree kernel and the bag of synonyms and hypernyms kernel; on the other hand, for instrument-agency the best performance is obtained by combining the global kernel and the super sense kernel.
</prevsent>
<prevsent>surprisingly, the super sense kernel alone works quite well and obtains results comparable to the bag of synonyms and hypernyms kernel.
</prevsent>
</prevsection>
<citsent citstr=" W06-1670 ">
this result is particularly interesting as super sense tagger can easily provide satisfactory accuracy (ciaramita and altun, 2006).<papid> W06-1670 </papid></citsent>
<aftsection>
<nextsent>on the other hand, obtaining an acceptable accuracy in word sense disambiguation (required for realistic application of thebag of synonyms and hypernyms kernel) is impractical as sufficient amount of training for at least all nouns is currently not available.
</nextsent>
<nextsent>hence, the super sense could play crucial role to improve the performance when approaching this task without the nominals disambiguated.
</nextsent>
<nextsent>to model the global context using the fore-between, between and between-after contexts did not produce significant improvement with respect to the bag-of-words model.
</nextsent>
<nextsent>this is mainly due to the fact that examples have been collected from the web using heuristic patterns/queries, most of which implying between patterns/contexts (e.g., for the cause-effect relation ?* comes from *?, ?* out of *?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3139">
<title id=" W08-0305.xml">learning performance of a machine translation system a statistical and computational analysis </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P07-2045 ">
we present an extensive experimental study of statistical machine translation system, moses (koehn et al, 2007), <papid> P07-2045 </papid>from the pointof view of its learning capabilities.</citsent>
<aftsection>
<nextsent>very accurate learning curves are obtained, by using high-performance computing, and extrapolations are provided of the projected performance of the system under different conditions.
</nextsent>
<nextsent>we provide discussion of learning curves, and we suggest that: 1) the representation power of the system is not currently limitation to its performance, 2) the inference of its models from finite sets of i.i.d. datais responsible for current performance limitations, 3) it is unlikely that increasing dataset sizes will result insignificant improvements(at least in traditional i.i.d. setting), 4) it is unlikely that novel statistical estimation methods will result insignificant improvements.
</nextsent>
<nextsent>the current performance wall is mostly consequence of zipfs law, and this should be taken into account when designing statistical machine translation system.
</nextsent>
<nextsent>a few possible research directions are discussed as result ofthis investigation, most notably the integration of linguistic rules into the model inference phase, and the development of active learning procedures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3140">
<title id=" W08-0305.xml">learning performance of a machine translation system a statistical and computational analysis </title>
<section> statistical machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>what is the best function class to map spanish documents into english documents?
</prevsent>
<prevsent>this is question of linguistic nature, and has been the subject of long debate.
</prevsent>
</prevsection>
<citsent citstr=" P98-2162 ">
the de-facto answer came during the 1990s from the research community on statistical machine translation, who made use of statistical tools based on noisy channel model originally developed for speech recognition (brown et al, 1994; och and weber, 1998; <papid> P98-2162 </papid>r.zens et al, 2002; och andney, 2001; koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>a markov ian language model, based on phrases rather than words, coupled with phrase-to-phrase translation table are at the heart of most modern systems.
</nextsent>
<nextsent>translating atext amounts to computing the most likely translation based on the available model parameters.
</nextsent>
<nextsent>inferring the parameters of these models from bilingual corpora is matter of statistics.
</nextsent>
<nextsent>by model inference we mean the task of extracting all tables, parameters and functions, from the corpus, that will be used to translate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3141">
<title id=" W08-0305.xml">learning performance of a machine translation system a statistical and computational analysis </title>
<section> statistical machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>what is the best function class to map spanish documents into english documents?
</prevsent>
<prevsent>this is question of linguistic nature, and has been the subject of long debate.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the de-facto answer came during the 1990s from the research community on statistical machine translation, who made use of statistical tools based on noisy channel model originally developed for speech recognition (brown et al, 1994; och and weber, 1998; <papid> P98-2162 </papid>r.zens et al, 2002; och andney, 2001; koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>a markov ian language model, based on phrases rather than words, coupled with phrase-to-phrase translation table are at the heart of most modern systems.
</nextsent>
<nextsent>translating atext amounts to computing the most likely translation based on the available model parameters.
</nextsent>
<nextsent>inferring the parameters of these models from bilingual corpora is matter of statistics.
</nextsent>
<nextsent>by model inference we mean the task of extracting all tables, parameters and functions, from the corpus, that will be used to translate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3143">
<title id=" W08-0305.xml">learning performance of a machine translation system a statistical and computational analysis </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>it provides all the components needed to create machine translation system from one language to another.
</prevsent>
<prevsent>it contains different modules to pre process data, train the language models and the translation models.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
these models can be tuned using minimum error rate training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>moses uses standard external tools for some of these tasks, such as giza++ (och and ney, 2003) <papid> J03-1002 </papid>for word alignments and srilm (stolcke, 2002) for language modeling.</nextsent>
<nextsent>notice that moses is avery sophisticated system, capable of learning translation tables, language models and decoding parameters from data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3144">
<title id=" W08-0305.xml">learning performance of a machine translation system a statistical and computational analysis </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>it contains different modules to pre process data, train the language models and the translation models.
</prevsent>
<prevsent>these models can be tuned using minimum error rate training (och, 2003).<papid> P03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
moses uses standard external tools for some of these tasks, such as giza++ (och and ney, 2003) <papid> J03-1002 </papid>for word alignments and srilm (stolcke, 2002) for language modeling.</citsent>
<aftsection>
<nextsent>notice that moses is avery sophisticated system, capable of learning translation tables, language models and decoding parameters from data.
</nextsent>
<nextsent>we analyse the contribution of each component to the overall score.given parallel training corpus, moses prepro cesses it removing long sentences, lower casing and tokenizing sentences.
</nextsent>
<nextsent>these sentences are used to train the language and translation models.
</nextsent>
<nextsent>this phase requires several steps as aligning words, computing the lexical translation, extracting phrases, scoring the phrases and creating the reorderingmodel.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3145">
<title id=" W08-0305.xml">learning performance of a machine translation system a statistical and computational analysis </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>test set is used to evaluate the quality of models on the data.
</prevsent>
<prevsent>the translated sentences are embedded in sgm format, such that the quality of the translation can be evaluated using the most common machine translation scores.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
moses provides bleu (k.papineni et al, 2001) and nist (doddington, 2002), but meteor (banerjee and lavie, 2005; <papid> W05-0909 </papid>lavie and agarwal, 2007) <papid> W07-0734 </papid>and ter (snover et al, 2006) can easily be used instead.</citsent>
<aftsection>
<nextsent>nist is used in this paperas evaluation score after we observed its high correlation to the other scores on the corpus (turchi et al, in preparation).
</nextsent>
<nextsent>all experiments have been run using the default parameter configuration of moses.
</nextsent>
<nextsent>it means that giza++ has used ibm model 1, 2, 3, and 4 with number of iterations for model 1 equal to 5, model 2 equal to 0, model 3 and 4 equal to 3; srilmhas used n-gram order equal to 3 and the kneserney smoothing algorithm; mert has been run fixing to 100 the number of nbest target sentence for 37 each develop sentence, and it stops when none of the weights changed more than 1e-05 or the nbest list does not change.
</nextsent>
<nextsent>the training, development and test set sentences are tokenized and lowercased.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3146">
<title id=" W08-0305.xml">learning performance of a machine translation system a statistical and computational analysis </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>test set is used to evaluate the quality of models on the data.
</prevsent>
<prevsent>the translated sentences are embedded in sgm format, such that the quality of the translation can be evaluated using the most common machine translation scores.
</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
moses provides bleu (k.papineni et al, 2001) and nist (doddington, 2002), but meteor (banerjee and lavie, 2005; <papid> W05-0909 </papid>lavie and agarwal, 2007) <papid> W07-0734 </papid>and ter (snover et al, 2006) can easily be used instead.</citsent>
<aftsection>
<nextsent>nist is used in this paperas evaluation score after we observed its high correlation to the other scores on the corpus (turchi et al, in preparation).
</nextsent>
<nextsent>all experiments have been run using the default parameter configuration of moses.
</nextsent>
<nextsent>it means that giza++ has used ibm model 1, 2, 3, and 4 with number of iterations for model 1 equal to 5, model 2 equal to 0, model 3 and 4 equal to 3; srilmhas used n-gram order equal to 3 and the kneserney smoothing algorithm; mert has been run fixing to 100 the number of nbest target sentence for 37 each develop sentence, and it stops when none of the weights changed more than 1e-05 or the nbest list does not change.
</nextsent>
<nextsent>the training, development and test set sentences are tokenized and lowercased.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3147">
<title id=" W08-0305.xml">learning performance of a machine translation system a statistical and computational analysis </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the first obvious approach is an effort to identify or produce datasets on demand (ac tive learning, where the learning system can request translations of specific sentences, to satisfy its information needs).
</prevsent>
<prevsent>this is classical machine learning question, that however comes with the need for further theoretical work, since it breaks the traditionali.i.d. assumptions on the origin of data.
</prevsent>
</prevsection>
<citsent citstr=" C04-1046 ">
further more, it would also require an effective way to do confidence estimation on translations, as traditional active learning approaches are effectively based on the identification (or generation) of instances where there is low confidence in the output (blatz et al, 2004; <papid> C04-1046 </papid>ueffing and ney, 2004; ueffing and ney, 2005<papid> H05-1096 </papid>b; ueffing and ney, 2005<papid> H05-1096 </papid>a).the second natural direction involves the introduction of significant domain knowledge in the form of linguistic rules, so to dramatically reduce the amount of data needed to essentially reconstruct them by using statistics.</citsent>
<aftsection>
<nextsent>these rules could take the form of generation of artificial training data, based on existing training data, or posteriori expansion of translation and language tables.
</nextsent>
<nextsent>any way to enforce linguistic constraints will result in reduced need for data, and ultimately in more complete models, given the same amount of data (koehn and hoang, 2007).<papid> D07-1091 </papid>obviously, it is always possible that the identification of radically different representations of language might introduce totally different constraints on both approximation and estimation error, and this might be worth considering.</nextsent>
<nextsent>what is not likely to work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3148">
<title id=" W08-0305.xml">learning performance of a machine translation system a statistical and computational analysis </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the first obvious approach is an effort to identify or produce datasets on demand (ac tive learning, where the learning system can request translations of specific sentences, to satisfy its information needs).
</prevsent>
<prevsent>this is classical machine learning question, that however comes with the need for further theoretical work, since it breaks the traditionali.i.d. assumptions on the origin of data.
</prevsent>
</prevsection>
<citsent citstr=" H05-1096 ">
further more, it would also require an effective way to do confidence estimation on translations, as traditional active learning approaches are effectively based on the identification (or generation) of instances where there is low confidence in the output (blatz et al, 2004; <papid> C04-1046 </papid>ueffing and ney, 2004; ueffing and ney, 2005<papid> H05-1096 </papid>b; ueffing and ney, 2005<papid> H05-1096 </papid>a).the second natural direction involves the introduction of significant domain knowledge in the form of linguistic rules, so to dramatically reduce the amount of data needed to essentially reconstruct them by using statistics.</citsent>
<aftsection>
<nextsent>these rules could take the form of generation of artificial training data, based on existing training data, or posteriori expansion of translation and language tables.
</nextsent>
<nextsent>any way to enforce linguistic constraints will result in reduced need for data, and ultimately in more complete models, given the same amount of data (koehn and hoang, 2007).<papid> D07-1091 </papid>obviously, it is always possible that the identification of radically different representations of language might introduce totally different constraints on both approximation and estimation error, and this might be worth considering.</nextsent>
<nextsent>what is not likely to work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3152">
<title id=" W08-0305.xml">learning performance of a machine translation system a statistical and computational analysis </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>further more, it would also require an effective way to do confidence estimation on translations, as traditional active learning approaches are effectively based on the identification (or generation) of instances where there is low confidence in the output (blatz et al, 2004; <papid> C04-1046 </papid>ueffing and ney, 2004; ueffing and ney, 2005<papid> H05-1096 </papid>b; ueffing and ney, 2005<papid> H05-1096 </papid>a).the second natural direction involves the introduction of significant domain knowledge in the form of linguistic rules, so to dramatically reduce the amount of data needed to essentially reconstruct them by using statistics.</prevsent>
<prevsent>these rules could take the form of generation of artificial training data, based on existing training data, or posteriori expansion of translation and language tables.</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
any way to enforce linguistic constraints will result in reduced need for data, and ultimately in more complete models, given the same amount of data (koehn and hoang, 2007).<papid> D07-1091 </papid>obviously, it is always possible that the identification of radically different representations of language might introduce totally different constraints on both approximation and estimation error, and this might be worth considering.</citsent>
<aftsection>
<nextsent>what is not likely to work.
</nextsent>
<nextsent>it does not seem thatthe introduction of more data will change the situation significantly, as long as the data is sampled i.i.d. from the same distribution.
</nextsent>
<nextsent>it also does notseem that more flexible versions of markov models would be likely to change the situation.
</nextsent>
<nextsent>finally, it does not seem that new and different methods to estimate probabilities would make much of difference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3153">
<title id=" W07-1602.xml">landmark classification for route directions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the only research we are aware of which has addressed this same topic of landmark interpretation is that of tezuka and tanaka (2005).
</prevsent>
<prevsent>in an investigation of the spatial use of landmarks in sentences, tezuka and tanaka (2005) modified existing web mining methods to include spatial context in order to obtain landmark information.
</prevsent>
</prevsection>
<citsent citstr=" J03-3001 ">
it is natural to question the appropriateness of webdata for research purposes, because web data is inevitably noisy and search engines themselves can introduce certain idiosyncracies which can distort results (kilgarriff and grefenstette, 2003).<papid> J03-3001 </papid></citsent>
<aftsection>
<nextsent>however, the vast amount of data available can nevertheless give better results than more theoretically motivated techniques (lapata and keller, 2004).<papid> N04-1016 </papid></nextsent>
<nextsent>and importantly, the data that can be gleaned from the webdoes not mirror the view of single person or select group, but of the entire global community (or at least the best available representation of it).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3154">
<title id=" W07-1602.xml">landmark classification for route directions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>in an investigation of the spatial use of landmarks in sentences, tezuka and tanaka (2005) modified existing web mining methods to include spatial context in order to obtain landmark information.
</prevsent>
<prevsent>it is natural to question the appropriateness of webdata for research purposes, because web data is inevitably noisy and search engines themselves can introduce certain idiosyncracies which can distort results (kilgarriff and grefenstette, 2003).<papid> J03-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1016 ">
however, the vast amount of data available can nevertheless give better results than more theoretically motivated techniques (lapata and keller, 2004).<papid> N04-1016 </papid></citsent>
<aftsection>
<nextsent>and importantly, the data that can be gleaned from the webdoes not mirror the view of single person or select group, but of the entire global community (or at least the best available representation of it).
</nextsent>
<nextsent>10
</nextsent>
<nextsent>the prepositions and verbs which accompany aland mark in spatial sentences capture that landmarks implicit conceptualisation.
</nextsent>
<nextsent>we use this implicit conceptual isation, as represented on the web, to develop two automated classification schemes: asimple voting classifier and neural network classifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3155">
<title id=" W07-1602.xml">landmark classification for route directions </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>it is difficult to determine the context of sentences using search engine.
</prevsent>
<prevsent>it is uncertain whether the documents found by google use the searched-for linguistic chunks in spatial context or in some other context.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for this reason, each preposition and verb was assigned weight based on the proportion of occurrences of that word in the penn treebank(marcus et al, 1993) <papid> J93-2004 </papid>which are labelled with spatial meaning.</citsent>
<aftsection>
<nextsent>this weighting should give an approximation to the proportion of spatial usages of that word on the web.
</nextsent>
<nextsent>automated classification as naive automated classification of the landmarks, the document counts were used to place each landmark in one of the three conceptual classes.
</nextsent>
<nextsent>each landmark was placed in the class in which it was found to appear most frequently, based on the classes of the prepositions and verbs with which it appeared on the web.
</nextsent>
<nextsent>hence landmarks which appeared more often with point-like preposition orverb, such as at or pass, were placed in the point cat egory; landmarks which appeared more often with line-like preposition or verb, such as follow, we replaced in the line category; and landmarks which appeared more often with an area-like preposition orverb, such as around, were placed in the area category.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3156">
<title id=" W07-1602.xml">landmark classification for route directions </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the neural network classifier outperformed the voting classifier in all experiments but the final one.of the 58 melbourne landmarks, 27 were classified as points by the majority of annotators, 2 as lines, and 29 as areas.
</prevsent>
<prevsent>these majority classifications were used as the gold standard.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
for these classifications, we calculated kappa statistic of 0.528 (carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>this suggests that the annotation classification task itself was only moderately well-formed, and that the assumption that multiple annotators will classify landmarks in similar manner does not necessarily hold true.to determine whether the classifiers were performing at an acceptable level, we established majority-class baseline: 29 of the 58 landmarks were areas, and hence the majority class classifier has an accuracy of 50%.
</nextsent>
<nextsent>the maximum meaningful accuracy that can be achieved by classifier is limited by the accuracy of the annotations themselves, creating an upper bound for classifier performance.
</nextsent>
<nextsent>the upper bound was calculated as the mean pairwise inter-annotator agreement, which was determined to be 74.4%.
</nextsent>
<nextsent>accuracy (%) e.r.r.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3157">
<title id=" W07-1703.xml">a language independent approach for name categorization and discrimination </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they construct second order co-occurrence features according to which the entities are clustered and associated to different underlying names.
</prevsent>
<prevsent>the performance of this method ranges from 51% to 73% depending on the pair ofnamed entities that have to be disambiguated.
</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
similar approach was developed by (bagga and baldwin, 1998), <papid> P98-1012 </papid>who created first order context vectors that represent the instance in which the ambiguous name occurs.</citsent>
<aftsection>
<nextsent>their approach is evaluated on 35 different mentions of john smith, and the f-score is 84%.for fine-grained person ne categorization, (fleis chman and hovy, 2002) <papid> C02-1130 </papid>carried out supervised learning for which they deduced features from the local context in which the entity resides, as well as semantic information derived from the topic signatures and wordnet.</nextsent>
<nextsent>according to their results, to improve the 70% coverage for person name categorization, more sophisticated features are needed, together with more solid data generation procedure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3159">
<title id=" W07-1703.xml">a language independent approach for name categorization and discrimination </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the performance of this method ranges from 51% to 73% depending on the pair ofnamed entities that have to be disambiguated.
</prevsent>
<prevsent>similar approach was developed by (bagga and baldwin, 1998), <papid> P98-1012 </papid>who created first order context vectors that represent the instance in which the ambiguous name occurs.</prevsent>
</prevsection>
<citsent citstr=" C02-1130 ">
their approach is evaluated on 35 different mentions of john smith, and the f-score is 84%.for fine-grained person ne categorization, (fleis chman and hovy, 2002) <papid> C02-1130 </papid>carried out supervised learning for which they deduced features from the local context in which the entity resides, as well as semantic information derived from the topic signatures and wordnet.</citsent>
<aftsection>
<nextsent>according to their results, to improve the 70% coverage for person name categorization, more sophisticated features are needed, together with more solid data generation procedure.
</nextsent>
<nextsent>(tanev and magnini, 2006) <papid> E06-1003 </papid>classified geographic location and person names into several subclasses.</nextsent>
<nextsent>they use syntactic information and observed how often syntactic pattern co-occurs with certain member of given class.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3160">
<title id=" W07-1703.xml">a language independent approach for name categorization and discrimination </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their approach is evaluated on 35 different mentions of john smith, and the f-score is 84%.for fine-grained person ne categorization, (fleis chman and hovy, 2002) <papid> C02-1130 </papid>carried out supervised learning for which they deduced features from the local context in which the entity resides, as well as semantic information derived from the topic signatures and wordnet.</prevsent>
<prevsent>according to their results, to improve the 70% coverage for person name categorization, more sophisticated features are needed, together with more solid data generation procedure.</prevsent>
</prevsection>
<citsent citstr=" E06-1003 ">
(tanev and magnini, 2006) <papid> E06-1003 </papid>classified geographic location and person names into several subclasses.</citsent>
<aftsection>
<nextsent>they use syntactic information and observed how often syntactic pattern co-occurs with certain member of given class.
</nextsent>
<nextsent>their method reaches 65%accuracy.
</nextsent>
<nextsent>(pasca, 2004) presented lightly supervised lexico-syntactic method for named entity categorization which reaches 76% when evaluated with unstructured text of web documents.
</nextsent>
<nextsent>(mann, 2002) <papid> W02-1111 </papid>populated fine-grained proper noun ontology using common noun patterns and following the hierarchy of wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3161">
<title id=" W07-1703.xml">a language independent approach for name categorization and discrimination </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their method reaches 65%accuracy.
</prevsent>
<prevsent>(pasca, 2004) presented lightly supervised lexico-syntactic method for named entity categorization which reaches 76% when evaluated with unstructured text of web documents.
</prevsent>
</prevsection>
<citsent citstr=" W02-1111 ">
(mann, 2002) <papid> W02-1111 </papid>populated fine-grained proper noun ontology using common noun patterns and following the hierarchy of wordnet.</citsent>
<aftsection>
<nextsent>they studied the influence of the newly generated person ontology ina question answering system.
</nextsent>
<nextsent>according to the obtained results, the precision of the ontology is high, but still suffers in coverage.
</nextsent>
<nextsent>a similar approach for the population of the cyc knowledge base (kb) was presented in (shah et al, 2006).
</nextsent>
<nextsent>they used information from the web and other electronically available text corpora to gather facts about particular named entities, to validate and finally to add them to the cyc kb.in this paper, we present new text semantic similarity approach for fine-grained person name categorization and discrimination which is similar to those of (pedersen et al, 2005) and (bagga and baldwin, 1998), <papid> P98-1012 </papid>but instead of simple word co-occurrences, we consider the whole text segment and relate the deduced semantic information of latent semantic analysis (lsa) to trace the text cohesion between thousands of sentences containing named entities which belong to different fine-grained categories or individuals.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3164">
<title id=" W08-0202.xml">building a flexible collaborative intensive masters program in computational linguistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this program can be completed in one-year of full-time study, or two-three years of part-timestudy.
</prevsent>
<prevsent>originally designed for cs professionals looking for additional training, the program has evolved inflexibility to accommodate students from more diverse backgrounds and with more diverse goals.
</prevsent>
</prevsection>
<citsent citstr=" W02-0112 ">
in the past two decades, there has been tremendous progress in natural language processing and variousundergraduate/graduate programs in language technology have been established around the world (koit et al, 2002; <papid> W02-0112 </papid>frederking et al, 2002; <papid> W02-0106 </papid>dale et al, 2002; <papid> W02-0104 </papid>uszkoreit et al, 2005; <papid> W05-0108 </papid>pilon et al, 2005).<papid> W05-0110 </papid>this paper introduces the university of washingtons professional masters program in computational linguistics (clma)one of the largest programs of its kind in the united state sand highlights unique features that are key to its success.</citsent>
<aftsection>
<nextsent>the clma program is currently operating in its third year as fee-based degree program managed jointly by the department of linguistics and the educational outreach arm of the university.
</nextsent>
<nextsent>the program is distinguished by its programmatic focus, its flexibility, its format and delivery as well as in the partnerships that are an integral part of this degree.
</nextsent>
<nextsent>this paper highlights how these features of our program contribute to effective teaching in our interdisciplinary field as well as making the program relevant to both working professionals and students on the research track.
</nextsent>
<nextsent>we provide brief program overview highlighting the people and partnerships involved, course design, practicum and research options, and dealing with student diversity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3165">
<title id=" W08-0202.xml">building a flexible collaborative intensive masters program in computational linguistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this program can be completed in one-year of full-time study, or two-three years of part-timestudy.
</prevsent>
<prevsent>originally designed for cs professionals looking for additional training, the program has evolved inflexibility to accommodate students from more diverse backgrounds and with more diverse goals.
</prevsent>
</prevsection>
<citsent citstr=" W02-0106 ">
in the past two decades, there has been tremendous progress in natural language processing and variousundergraduate/graduate programs in language technology have been established around the world (koit et al, 2002; <papid> W02-0112 </papid>frederking et al, 2002; <papid> W02-0106 </papid>dale et al, 2002; <papid> W02-0104 </papid>uszkoreit et al, 2005; <papid> W05-0108 </papid>pilon et al, 2005).<papid> W05-0110 </papid>this paper introduces the university of washingtons professional masters program in computational linguistics (clma)one of the largest programs of its kind in the united state sand highlights unique features that are key to its success.</citsent>
<aftsection>
<nextsent>the clma program is currently operating in its third year as fee-based degree program managed jointly by the department of linguistics and the educational outreach arm of the university.
</nextsent>
<nextsent>the program is distinguished by its programmatic focus, its flexibility, its format and delivery as well as in the partnerships that are an integral part of this degree.
</nextsent>
<nextsent>this paper highlights how these features of our program contribute to effective teaching in our interdisciplinary field as well as making the program relevant to both working professionals and students on the research track.
</nextsent>
<nextsent>we provide brief program overview highlighting the people and partnerships involved, course design, practicum and research options, and dealing with student diversity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3166">
<title id=" W08-0202.xml">building a flexible collaborative intensive masters program in computational linguistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this program can be completed in one-year of full-time study, or two-three years of part-timestudy.
</prevsent>
<prevsent>originally designed for cs professionals looking for additional training, the program has evolved inflexibility to accommodate students from more diverse backgrounds and with more diverse goals.
</prevsent>
</prevsection>
<citsent citstr=" W02-0104 ">
in the past two decades, there has been tremendous progress in natural language processing and variousundergraduate/graduate programs in language technology have been established around the world (koit et al, 2002; <papid> W02-0112 </papid>frederking et al, 2002; <papid> W02-0106 </papid>dale et al, 2002; <papid> W02-0104 </papid>uszkoreit et al, 2005; <papid> W05-0108 </papid>pilon et al, 2005).<papid> W05-0110 </papid>this paper introduces the university of washingtons professional masters program in computational linguistics (clma)one of the largest programs of its kind in the united state sand highlights unique features that are key to its success.</citsent>
<aftsection>
<nextsent>the clma program is currently operating in its third year as fee-based degree program managed jointly by the department of linguistics and the educational outreach arm of the university.
</nextsent>
<nextsent>the program is distinguished by its programmatic focus, its flexibility, its format and delivery as well as in the partnerships that are an integral part of this degree.
</nextsent>
<nextsent>this paper highlights how these features of our program contribute to effective teaching in our interdisciplinary field as well as making the program relevant to both working professionals and students on the research track.
</nextsent>
<nextsent>we provide brief program overview highlighting the people and partnerships involved, course design, practicum and research options, and dealing with student diversity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3167">
<title id=" W08-0202.xml">building a flexible collaborative intensive masters program in computational linguistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this program can be completed in one-year of full-time study, or two-three years of part-timestudy.
</prevsent>
<prevsent>originally designed for cs professionals looking for additional training, the program has evolved inflexibility to accommodate students from more diverse backgrounds and with more diverse goals.
</prevsent>
</prevsection>
<citsent citstr=" W05-0108 ">
in the past two decades, there has been tremendous progress in natural language processing and variousundergraduate/graduate programs in language technology have been established around the world (koit et al, 2002; <papid> W02-0112 </papid>frederking et al, 2002; <papid> W02-0106 </papid>dale et al, 2002; <papid> W02-0104 </papid>uszkoreit et al, 2005; <papid> W05-0108 </papid>pilon et al, 2005).<papid> W05-0110 </papid>this paper introduces the university of washingtons professional masters program in computational linguistics (clma)one of the largest programs of its kind in the united state sand highlights unique features that are key to its success.</citsent>
<aftsection>
<nextsent>the clma program is currently operating in its third year as fee-based degree program managed jointly by the department of linguistics and the educational outreach arm of the university.
</nextsent>
<nextsent>the program is distinguished by its programmatic focus, its flexibility, its format and delivery as well as in the partnerships that are an integral part of this degree.
</nextsent>
<nextsent>this paper highlights how these features of our program contribute to effective teaching in our interdisciplinary field as well as making the program relevant to both working professionals and students on the research track.
</nextsent>
<nextsent>we provide brief program overview highlighting the people and partnerships involved, course design, practicum and research options, and dealing with student diversity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3168">
<title id=" W08-0202.xml">building a flexible collaborative intensive masters program in computational linguistics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this program can be completed in one-year of full-time study, or two-three years of part-timestudy.
</prevsent>
<prevsent>originally designed for cs professionals looking for additional training, the program has evolved inflexibility to accommodate students from more diverse backgrounds and with more diverse goals.
</prevsent>
</prevsection>
<citsent citstr=" W05-0110 ">
in the past two decades, there has been tremendous progress in natural language processing and variousundergraduate/graduate programs in language technology have been established around the world (koit et al, 2002; <papid> W02-0112 </papid>frederking et al, 2002; <papid> W02-0106 </papid>dale et al, 2002; <papid> W02-0104 </papid>uszkoreit et al, 2005; <papid> W05-0108 </papid>pilon et al, 2005).<papid> W05-0110 </papid>this paper introduces the university of washingtons professional masters program in computational linguistics (clma)one of the largest programs of its kind in the united state sand highlights unique features that are key to its success.</citsent>
<aftsection>
<nextsent>the clma program is currently operating in its third year as fee-based degree program managed jointly by the department of linguistics and the educational outreach arm of the university.
</nextsent>
<nextsent>the program is distinguished by its programmatic focus, its flexibility, its format and delivery as well as in the partnerships that are an integral part of this degree.
</nextsent>
<nextsent>this paper highlights how these features of our program contribute to effective teaching in our interdisciplinary field as well as making the program relevant to both working professionals and students on the research track.
</nextsent>
<nextsent>we provide brief program overview highlighting the people and partnerships involved, course design, practicum and research options, and dealing with student diversity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3169">
<title id=" W07-2026.xml">cunit a semantic role labeling system for modern standard arabic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, effective ways for seeing this belief come to fruition require lot more research investment.
</prevsent>
<prevsent>since most of the available data resources are forthe english language, most of the reported srl systems to date only deal with english.
</prevsent>
</prevsection>
<citsent citstr=" N04-1032 ">
nevertheless, we do see some headway for other languages, such as german and chinese (erk and pado, 2006; sun and jurafsky, 2004; <papid> N04-1032 </papid>xue and palmer, 2005).</citsent>
<aftsection>
<nextsent>the systems for non-english languages follow the successful models devised for english, e.g.
</nextsent>
<nextsent>(gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>pradhan etal., 2003).</nextsent>
<nextsent>however, no srl system exists for ara bic.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3170">
<title id=" W07-2026.xml">cunit a semantic role labeling system for modern standard arabic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nevertheless, we do see some headway for other languages, such as german and chinese (erk and pado, 2006; sun and jurafsky, 2004; <papid> N04-1032 </papid>xue and palmer, 2005).</prevsent>
<prevsent>the systems for non-english languages follow the successful models devised for english, e.g.</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
(gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>pradhan etal., 2003).</citsent>
<aftsection>
<nextsent>however, no srl system exists for arabic.
</nextsent>
<nextsent>in this paper, we present system for semantic role labeling for modern standard arabic.
</nextsent>
<nextsent>to our knowledge, it is the first srl system for semitic language in the literature.
</nextsent>
<nextsent>it is based on supervised model that uses support vector machines (svm)technology for argument boundary detection and argument classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3171">
<title id=" W07-2026.xml">cunit a semantic role labeling system for modern standard arabic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>nevertheless, we do see some headway for other languages, such as german and chinese (erk and pado, 2006; sun and jurafsky, 2004; <papid> N04-1032 </papid>xue and palmer, 2005).</prevsent>
<prevsent>the systems for non-english languages follow the successful models devised for english, e.g.</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
(gildea and jurafsky, 2002; <papid> J02-3001 </papid>xue and palmer, 2004; <papid> W04-3212 </papid>pradhan etal., 2003).</citsent>
<aftsection>
<nextsent>however, no srl system exists for arabic.
</nextsent>
<nextsent>in this paper, we present system for semantic role labeling for modern standard arabic.
</nextsent>
<nextsent>to our knowledge, it is the first srl system for semitic language in the literature.
</nextsent>
<nextsent>it is based on supervised model that uses support vector machines (svm)technology for argument boundary detection and argument classification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3172">
<title id=" W07-2026.xml">cunit a semantic role labeling system for modern standard arabic </title>
<section> srl system for arabic.  </section>
<citcontext>
<prevsection>
<prevsent>however, remarkable amount of research has already been done in srl and we can capitalize from it to design basic and effective srl system.
</prevsent>
<prevsent>the idea is to use the technology developed for english and verify if it is suitable for arabic.our adopted srl models use support vector machines (svm) to implement two steps classification approach, i.e. boundary detection and argumentclassification.
</prevsent>
</prevsection>
<citsent citstr=" W05-0630 ">
such models have already been investigated in (pradhan et al, 2003; moschitti et al, 2005) <papid> W05-0630 </papid>and their description is hereafter reported.</citsent>
<aftsection>
<nextsent>2.1 predicate argument extraction.
</nextsent>
<nextsent>the extraction of predicative structures is carried out at the sentence level.
</nextsent>
<nextsent>given predicate within natural language sentence, its arguments have to be properly labeled.
</nextsent>
<nextsent>this problem is usually divided in two subtasks: (a) the detection of the boundaries, i.e. the word spans of the arguments, and (b) the classification of their type, e.g. arg0 and argm in 133 snp nn
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3178">
<title id=" W07-2026.xml">cunit a semantic role labeling system for modern standard arabic </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>the results presented here are based on gold parses.
</prevsent>
<prevsent>we would like to experiment with automatic parses and shallower representations such as chunked data.
</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
finally,we would like to experiment with more sophisticated kernels, the tree kernels described in (mos chitti, 2004), <papid> P04-1043 </papid>i.e. models that have shown lot of promise for the english srl process.</citsent>
<aftsection>
<nextsent>acknowledgements the first author is funded by darpa contract no.
</nextsent>
<nextsent>hr0011 06-c-0023.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3179">
<title id=" W07-1517.xml">combining independent syntactic and semantic annotation schemes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>simple tree-based and one-directional merg-.
</prevsent>
<prevsent>ing of annotations is useful for visualization of overlap between schemes.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
the annotation schemes currently embedded in mais are the proposition bank (palmer et al,2005), <papid> J05-1004 </papid>nombank (meyers et al, 2004) <papid> W04-2705 </papid>and time bank (pustejovsky et al, 2003).</citsent>
<aftsection>
<nextsent>other linguistics annotation schemes like the opinion annotation (wiebe et al, 2005), named entity annotation, and discourse annotation (miltsakaki et al, 2004) will be added in the future.
</nextsent>
<nextsent>in the next section, we elaborate on the first two requirements mentioned above and present the mais methodology to achieve interoperability of annotations.
</nextsent>
<nextsent>in section 3, we present the xbank browser, unified browser that allows researchers to inspect overlap between annotation schemes.
</nextsent>
<nextsent>our goal is not to define static merger of all annotation schemes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3180">
<title id=" W07-1517.xml">combining independent syntactic and semantic annotation schemes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>simple tree-based and one-directional merg-.
</prevsent>
<prevsent>ing of annotations is useful for visualization of overlap between schemes.
</prevsent>
</prevsection>
<citsent citstr=" W04-2705 ">
the annotation schemes currently embedded in mais are the proposition bank (palmer et al,2005), <papid> J05-1004 </papid>nombank (meyers et al, 2004) <papid> W04-2705 </papid>and time bank (pustejovsky et al, 2003).</citsent>
<aftsection>
<nextsent>other linguistics annotation schemes like the opinion annotation (wiebe et al, 2005), named entity annotation, and discourse annotation (miltsakaki et al, 2004) will be added in the future.
</nextsent>
<nextsent>in the next section, we elaborate on the first two requirements mentioned above and present the mais methodology to achieve interoperability of annotations.
</nextsent>
<nextsent>in section 3, we present the xbank browser, unified browser that allows researchers to inspect overlap between annotation schemes.
</nextsent>
<nextsent>our goal is not to define static merger of all annotation schemes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3181">
<title id=" W07-1517.xml">combining independent syntactic and semantic annotation schemes </title>
<section> the xbank browser.  </section>
<citcontext>
<prevsection>
<prevsent>the xbank browser does not adhere to the mais philosophy that all resources are independent.
</prevsent>
<prevsent>instead, it designates one syntactic annotation to provide the basic shape of the xml tree and requires tags from other annotations to find landing spots in the basic tree.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the penn treebank annotation (marcus et al, 1993) <papid> J93-2004 </papid>was chosen to be the first among equals: it is the starting point for the merger and data fro mother annotations are attached at tree nodes.</citsent>
<aftsection>
<nextsent>currently, only one heuristic is used to merge in data from other sources: go up the tree to find treebank constituent that contains the entire extent of the tagthat is merged in, then select the head of this constituent.
</nextsent>
<nextsent>a more sophisticated approach would consist of two steps: ? first try to find an exact match of the imported tag with treebank constituent, ? if that fails, find the constituent that contains the entire tag that is merged in, and select this constituent in the latter case, there can be an option to select the head rather than the whole constituent.
</nextsent>
<nextsent>in any case, the attached node will be marked if its original extent does not line up with the extent at the tree node.it should be noted that this merging is one directional since no attempt is made to change the shape of the tree defined by the treebank annotation.
</nextsent>
<nextsent>the unified browser currently displays markups from the proposition bank, nombank, time bank and the discourse treebank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3182">
<title id=" W07-2092.xml">uoy a hypergraph model for word sense induction  disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our system participates in semeval-2007 word sense induction and discrimination task.
</prevsent>
<prevsent>the majority of both supervised and unsupervised approaches to wsd is based on the fixed-list?
</prevsent>
</prevsection>
<citsent citstr=" W06-1669 ">
of senses paradigm where the senses of target wordis closed list of definitions coming from standard dictionary (agirre et al, 2006).<papid> W06-1669 </papid></citsent>
<aftsection>
<nextsent>lexicographershave long warned about the problems of such an approach, since dictionaries are not suited to this task; they often contain general definitions, they suffer from the lack of explicit semantic and topical relations or interconnections, and they often do notre flect the exact content of the context, in which the target word appears (veronis, 2004).
</nextsent>
<nextsent>to overcome this limitation, unsupervised wsd has moved towards inducing the senses of target word directly from corpus, and then disambiguat ing each instance of it.
</nextsent>
<nextsent>most of the work in wsiis based on the vector space model, where the context of each instance of target word is represent edas vector of features (e.g second-order word cooccurrences) (schutze, 1998; purandare and pedersen, 2004).<papid> W04-2406 </papid></nextsent>
<nextsent>these vectors are clustered and the resulting clusters represent the induced senses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3184">
<title id=" W07-2092.xml">uoy a hypergraph model for word sense induction  disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexicographershave long warned about the problems of such an approach, since dictionaries are not suited to this task; they often contain general definitions, they suffer from the lack of explicit semantic and topical relations or interconnections, and they often do notre flect the exact content of the context, in which the target word appears (veronis, 2004).
</prevsent>
<prevsent>to overcome this limitation, unsupervised wsd has moved towards inducing the senses of target word directly from corpus, and then disambiguat ing each instance of it.
</prevsent>
</prevsection>
<citsent citstr=" W04-2406 ">
most of the work in wsiis based on the vector space model, where the context of each instance of target word is represent edas vector of features (e.g second-order word cooccurrences) (schutze, 1998; purandare and pedersen, 2004).<papid> W04-2406 </papid></citsent>
<aftsection>
<nextsent>these vectors are clustered and the resulting clusters represent the induced senses.
</nextsent>
<nextsent>how ever, as shown experimentally in (veronis, 2004),vector-based techniques are unable to detect low frequency senses of target word.
</nextsent>
<nextsent>recently, graph-based methods were employed in wsi to isolate highly infrequent senses of target word.
</nextsent>
<nextsent>hyper lex (veronis, 2004) and the adaptation of page rank (brin and page, 1998) in (agirre et al,2006) <papid> W06-1669 </papid>have been shown to outperform the most frequent sense (mfs) baseline in terms of supervised recall, but they still fall short of supervised wsd systems.graph-based approaches operate on 2dimensional space, assuming one-to-one relationship between co-occurring words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3186">
<title id=" W07-2092.xml">uoy a hypergraph model for word sense induction  disambiguation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in such model, cooccurrences of two or more words are represented using weighted hyperedges.
</prevsent>
<prevsent>a hyperedge is more expressive representation than simple edge, be cause it is able to capture the information shared by two or more words.
</prevsent>
</prevsection>
<citsent citstr=" W07-2002 ">
our system participates in 414semeval-2007 word sense induction and discrimination task (swsid) (agirre and soroa, 2007).<papid> W07-2002 </papid></citsent>
<aftsection>
<nextsent>this section presents the induction and disambiguation algorithms.
</nextsent>
<nextsent>2.1 sense induction.
</nextsent>
<nextsent>2.1.1 the hypergraph model hypergraph = (v, ) is generalization of graph, which consists of set of vertices and set of hyperedges ; each hyperedge is subset ofvertices.
</nextsent>
<nextsent>while an edge relates 2 vertices, hyperedge relates vertices (where ? 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3188">
<title id=" W07-2092.xml">uoy a hypergraph model for word sense induction  disambiguation </title>
<section> sense induction &amp; disambiguation.  </section>
<citcontext>
<prevsection>
<prevsent>we apply filtering heuristic (parameter p4) to remove hyperedges with low weights from the hypergraph.
</prevsent>
<prevsent>at the end of this stage, the constructed hypergraph is reduced, so that our hypergraph model agrees with the one described in subsection 2.1.1.
</prevsent>
</prevsection>
<citsent citstr=" W04-0807 ">
2.1.3 extracting senses preliminary experiments on 10 nouns of senseval-3 english lexical-sample task (mihalcea et al, 2004) (<papid> W04-0807 </papid>s3ls), suggested that our hypergraphs 415 are small-world networks, since they exhibited high clustering coefficient and small average path length.</citsent>
<aftsection>
<nextsent>furthermore, the frequency of vertices with given degree plotted against the degree showed that our hypergraphs satisfy power-law distribution (d) = ? d??, where is the vertex degree, (d) is the frequency of vertices with degree d. figure 2 shows the log-log plot for the noun difference of s3ls.
</nextsent>
<nextsent>figure 2: log-log plot for the noun difference.
</nextsent>
<nextsent>in order to extract the senses of the target word, we modify the hyper lex algorithm (veronis, 2004)for selecting the root hubs of the hypergraph as follows.
</nextsent>
<nextsent>at each step, the algorithm finds the vertex vi with the highest degree, which is selected as root hub, according to two criteria.the first one is the minimum number of hyperedges it belongs to (parameter p5), and the second isthe average weight of the first p5 hyperedges (parameter p6) 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3191">
<title id=" W07-1411.xml">a perspective based approach for solving textual entailment recognition </title>
<section> system specification.  </section>
<citcontext>
<prevsection>
<prevsent>the weight is normalized by the size of the hypothesis?
</prevsent>
<prevsent>tri-grams set.rouge measures: considering the impact of ngram overlap metrics in textual entailment, we believe that the idea of integrating these measures1 into our system is very appealing.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
we have implemented them as defined in (lin, 2004).<papid> W04-1013 </papid></citsent>
<aftsection>
<nextsent>each measure is applied to the words, lemmas and stems belonging to the text-hypothesis pair.
</nextsent>
<nextsent>with inthe entire set of measures, each one of them is considered as feature for the training and test stages of machine learning algorithm.
</nextsent>
<nextsent>the selected one was support vector machine due to the fact that its properties are suitable for recognizing entailment.
</nextsent>
<nextsent>2.3 syntactic module.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3192">
<title id=" W07-1411.xml">a perspective based approach for solving textual entailment recognition </title>
<section> system specification.  </section>
<citcontext>
<prevsection>
<prevsent>in order to reduce our systems noise and increase its accuracy rate, we only keep the relevant words and discard the ones that we believe do not provide useful information, such as determinants and auxiliary verbs.
</prevsent>
<prevsent>after this step hasbeen performed we can proceed to compare the generated syntactic dependency trees of the text and the hypothesis.the graph node matching, termed alignment, between both the text and the hypothesis consists in finding pairs of words in both trees whose lemmas are identical, no matter whether they are in the same position within the tree.
</prevsent>
</prevsection>
<citsent citstr=" N06-1005 ">
some authors have already designed similar matching techniques, such as the one described in (snow et al, 2006).<papid> N06-1005 </papid></citsent>
<aftsection>
<nextsent>however, these include semantic constraints that we have decided not to consider.
</nextsent>
<nextsent>the reason of this decision is that we desired to overcome the textual entailment recognition from an exclusively syntactic perspective.
</nextsent>
<nextsent>the formula that provides the similarity rate between the dependency trees of the text and the hypothesis in our system, denoted by the symbol ?, is shown in equation 3: ?(?, ?) = ? ???
</nextsent>
<nextsent>(3) where ? and ? represent the texts and hypothesis?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3193">
<title id=" W07-0725.xml">building a statistical machine translation system for french using the europarl corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by these means we expect to take better advantage of the limited amount of training data.
</prevsent>
<prevsent>finally, we have investigated the usefulness of second reference translation of the development data.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
this paper describes the development of statistical machine translation system based on the moses decoder (koehn et al, 2007) <papid> P07-2045 </papid>for the 2007 wmt shared tasks.</citsent>
<aftsection>
<nextsent>due to time constraints, we only considered the translation between french and english.
</nextsent>
<nextsent>a system with similar architecture was successfully applied to the translation between spanish and english in the framework of the 2007 tc-star eval uation.1 for the 2007 wmt shared task recipe is provided to build baseline translation system using the moses decoder.
</nextsent>
<nextsent>our system differs in several aspects from this base-line: 1) the training data is not lower-cased; 2) giza alignments are calculated on sentences of up to 90 words; 3) two pass-decodingwas used; and 4) so called continuous space language model is used in order to take better advantage of the limited amount of training data.
</nextsent>
<nextsent>1a paper on this work is submitted to mt sumit 2007.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3194">
<title id=" W07-0725.xml">building a statistical machine translation system for french using the europarl corpus </title>
<section> architecture of the system.  </section>
<citcontext>
<prevsection>
<prevsent>1a paper on this work is submitted to mt sumit 2007.
</prevsent>
<prevsent>this architecture is motivated and detailed in the following sections.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the goal of statistical machine translation (smt) isto produce target sentence from source sentence . it is today common practice to use phrases as translation units (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2003) <papid> J03-1002 </papid>and loglinear framework in order to introduce several models explaining the translation process: e?</citsent>
<aftsection>
<nextsent>= arg max p(e|f) = arg max {exp( ? ihi(e, f))} (1) the feature functions hi are the system models and the weights are typically optimized to maximize scoring function on development set (och andney, 2002).<papid> P02-1038 </papid></nextsent>
<nextsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3195">
<title id=" W07-0725.xml">building a statistical machine translation system for french using the europarl corpus </title>
<section> architecture of the system.  </section>
<citcontext>
<prevsection>
<prevsent>1a paper on this work is submitted to mt sumit 2007.
</prevsent>
<prevsent>this architecture is motivated and detailed in the following sections.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the goal of statistical machine translation (smt) isto produce target sentence from source sentence . it is today common practice to use phrases as translation units (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2003) <papid> J03-1002 </papid>and loglinear framework in order to introduce several models explaining the translation process: e?</citsent>
<aftsection>
<nextsent>= arg max p(e|f) = arg max {exp( ? ihi(e, f))} (1) the feature functions hi are the system models and the weights are typically optimized to maximize scoring function on development set (och andney, 2002).<papid> P02-1038 </papid></nextsent>
<nextsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3196">
<title id=" W07-0725.xml">building a statistical machine translation system for french using the europarl corpus </title>
<section> architecture of the system.  </section>
<citcontext>
<prevsection>
<prevsent>this architecture is motivated and detailed in the following sections.
</prevsent>
<prevsent>the goal of statistical machine translation (smt) isto produce target sentence from source sentence . it is today common practice to use phrases as translation units (koehn et al, 2003; <papid> N03-1017 </papid>och and ney, 2003) <papid> J03-1002 </papid>and loglinear framework in order to introduce several models explaining the translation process: e?</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
= arg max p(e|f) = arg max {exp( ? ihi(e, f))} (1) the feature functions hi are the system models and the weights are typically optimized to maximize scoring function on development set (och andney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>in our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).
</nextsent>
<nextsent>the system is constructed as follows.
</nextsent>
<nextsent>first, giza++ is used to perform word alignments in both directions.
</nextsent>
<nextsent>second, phrases and lexical reorderings are extracted using the default settings of the moses smt toolkit.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3197">
<title id=" W07-0720.xml">ngrambased statistical machine translation enhanced with multiple weighted reordering hypotheses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, this system introduces target language model based on statistical classes, feature for out-of-domain units and an improved optimization procedure.the paper provides details of this system participation in the acl 2007 second workshop on statistical machine translation.
</prevsent>
<prevsent>results on three pairs of languages are reported, namely from spanish, french and german into english (and the other way round) for both the in-domain and out-of-domain tasks.
</prevsent>
</prevsection>
<citsent citstr=" W05-0820 ">
based on estimating joint-probability model between the source and the target languages, ngram-based smt has proved to be very competitive alternatively tophrase-based and other state-of-the-art systems in previous evaluation campaigns, as shown in (koehn and monz, 2005; <papid> W05-0820 </papid>koehn and monz, 2006).<papid> W06-3114 </papid></citsent>
<aftsection>
<nextsent>given the challenge of domain adaptation, efforts have been focused on improving strategies for ngram-based smt which could generalize better.
</nextsent>
<nextsent>specifically, novel reordering strategy is explored.
</nextsent>
<nextsent>it is based on extending the search by using pre computed statistical information.results are promising while keeping computational expenses at similar level as monotonic search.
</nextsent>
<nextsent>additionally, bonus for tuples from the out-of-domain corpus is introduced, as well as target language model based on statistical classes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3198">
<title id=" W07-0720.xml">ngrambased statistical machine translation enhanced with multiple weighted reordering hypotheses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, this system introduces target language model based on statistical classes, feature for out-of-domain units and an improved optimization procedure.the paper provides details of this system participation in the acl 2007 second workshop on statistical machine translation.
</prevsent>
<prevsent>results on three pairs of languages are reported, namely from spanish, french and german into english (and the other way round) for both the in-domain and out-of-domain tasks.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
based on estimating joint-probability model between the source and the target languages, ngram-based smt has proved to be very competitive alternatively tophrase-based and other state-of-the-art systems in previous evaluation campaigns, as shown in (koehn and monz, 2005; <papid> W05-0820 </papid>koehn and monz, 2006).<papid> W06-3114 </papid></citsent>
<aftsection>
<nextsent>given the challenge of domain adaptation, efforts have been focused on improving strategies for ngram-based smt which could generalize better.
</nextsent>
<nextsent>specifically, novel reordering strategy is explored.
</nextsent>
<nextsent>it is based on extending the search by using pre computed statistical information.results are promising while keeping computational expenses at similar level as monotonic search.
</nextsent>
<nextsent>additionally, bonus for tuples from the out-of-domain corpus is introduced, as well as target language model based on statistical classes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3199">
<title id=" W07-0720.xml">ngrambased statistical machine translation enhanced with multiple weighted reordering hypotheses </title>
<section> baseline system enhanced with a.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 concept.
</prevsent>
<prevsent>the smr system can be seen as smt system which translates from an original source language (s) to reordered source language (s?), given target language (t).
</prevsent>
</prevsection>
<citsent citstr=" E99-1010 ">
the smr technique works with statistical word classes (och, 1999) <papid> E99-1010 </papid>instead of words themselves (partic ularly, we have used 200 classes in all experiments).</citsent>
<aftsection>
<nextsent>figure 1: smr approach in the (a) training step (b) in the test step (the weight of each arch is in brackets).
</nextsent>
<nextsent>3.2 using smr technique to improve smt training.
</nextsent>
<nextsent>the original source corpus is translated into the reordered source corpus s?
</nextsent>
<nextsent>with the smr system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3200">
<title id=" W07-0720.xml">ngrambased statistical machine translation enhanced with multiple weighted reordering hypotheses </title>
<section> baseline system enhanced with a.  </section>
<citcontext>
<prevsection>
<prevsent>this weight is added as feature function in the log-linear framework.
</prevsent>
<prevsent>figure 3 shows the weighted reordering graph.
</prevsent>
</prevsection>
<citsent citstr=" W06-3125 ">
the main difference with the reordering technique forwmt06 (crego et al, 2006) <papid> W06-3125 </papid>lies in (1) the tuples are extracted from the word alignment between the reordered source training corpus and the given target training corpus and (2) the graph structure: the smr graph provides weights for each reordering path.</citsent>
<aftsection>
<nextsent>in addition to the novel reordering strategy, we consider two new features functions.
</nextsent>
<nextsent>4.1 target language model based on statistical.
</nextsent>
<nextsent>classes this feature implements 5-gram language model of target statistical classes (och, 1999).<papid> E99-1010 </papid></nextsent>
<nextsent>this model is trained by considering statistical classes, instead of words, for 168figure 3: weighted reordering input graph for smt sys tem.the target side of the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3202">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the perceptron performs as well as the log-linear model; it trains in few hours on single machine; and it requires only few hundred mb of ram for practical training compared to 20gb for the log-linear model.
</prevsent>
<prevsent>we also investigate the order in which the training examples are presented to the online perceptron learner, and find that order does not significantly affect the results.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
a recent development in data-driven parsing is the use of discriminative training methods (riezler et al., 2002; <papid> P02-1035 </papid>taskar et al, 2004; <papid> W04-3201 </papid>collins and roark,2004; <papid> P04-1015 </papid>turian and melamed, 2006).<papid> P06-1110 </papid></citsent>
<aftsection>
<nextsent>one popular approach is to use log-linear parsing model and maximise the conditional likelihood function (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2002; <papid> P02-1035 </papid>clark and curran, 2004<papid> P04-1014 </papid>b; malouf and van noord, 2004; miyao and tsujii, 2005).<papid> P05-1011 </papid></nextsent>
<nextsent>maximising the likelihood involves calculating feature expectations, which is computationally expensive.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3203">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the perceptron performs as well as the log-linear model; it trains in few hours on single machine; and it requires only few hundred mb of ram for practical training compared to 20gb for the log-linear model.
</prevsent>
<prevsent>we also investigate the order in which the training examples are presented to the online perceptron learner, and find that order does not significantly affect the results.
</prevsent>
</prevsection>
<citsent citstr=" W04-3201 ">
a recent development in data-driven parsing is the use of discriminative training methods (riezler et al., 2002; <papid> P02-1035 </papid>taskar et al, 2004; <papid> W04-3201 </papid>collins and roark,2004; <papid> P04-1015 </papid>turian and melamed, 2006).<papid> P06-1110 </papid></citsent>
<aftsection>
<nextsent>one popular approach is to use log-linear parsing model and maximise the conditional likelihood function (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2002; <papid> P02-1035 </papid>clark and curran, 2004<papid> P04-1014 </papid>b; malouf and van noord, 2004; miyao and tsujii, 2005).<papid> P05-1011 </papid></nextsent>
<nextsent>maximising the likelihood involves calculating feature expectations, which is computationally expensive.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3205">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the perceptron performs as well as the log-linear model; it trains in few hours on single machine; and it requires only few hundred mb of ram for practical training compared to 20gb for the log-linear model.
</prevsent>
<prevsent>we also investigate the order in which the training examples are presented to the online perceptron learner, and find that order does not significantly affect the results.
</prevsent>
</prevsection>
<citsent citstr=" P04-1015 ">
a recent development in data-driven parsing is the use of discriminative training methods (riezler et al., 2002; <papid> P02-1035 </papid>taskar et al, 2004; <papid> W04-3201 </papid>collins and roark,2004; <papid> P04-1015 </papid>turian and melamed, 2006).<papid> P06-1110 </papid></citsent>
<aftsection>
<nextsent>one popular approach is to use log-linear parsing model and maximise the conditional likelihood function (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2002; <papid> P02-1035 </papid>clark and curran, 2004<papid> P04-1014 </papid>b; malouf and van noord, 2004; miyao and tsujii, 2005).<papid> P05-1011 </papid></nextsent>
<nextsent>maximising the likelihood involves calculating feature expectations, which is computationally expensive.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3206">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the perceptron performs as well as the log-linear model; it trains in few hours on single machine; and it requires only few hundred mb of ram for practical training compared to 20gb for the log-linear model.
</prevsent>
<prevsent>we also investigate the order in which the training examples are presented to the online perceptron learner, and find that order does not significantly affect the results.
</prevsent>
</prevsection>
<citsent citstr=" P06-1110 ">
a recent development in data-driven parsing is the use of discriminative training methods (riezler et al., 2002; <papid> P02-1035 </papid>taskar et al, 2004; <papid> W04-3201 </papid>collins and roark,2004; <papid> P04-1015 </papid>turian and melamed, 2006).<papid> P06-1110 </papid></citsent>
<aftsection>
<nextsent>one popular approach is to use log-linear parsing model and maximise the conditional likelihood function (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2002; <papid> P02-1035 </papid>clark and curran, 2004<papid> P04-1014 </papid>b; malouf and van noord, 2004; miyao and tsujii, 2005).<papid> P05-1011 </papid></nextsent>
<nextsent>maximising the likelihood involves calculating feature expectations, which is computationally expensive.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3207">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also investigate the order in which the training examples are presented to the online perceptron learner, and find that order does not significantly affect the results.
</prevsent>
<prevsent>a recent development in data-driven parsing is the use of discriminative training methods (riezler et al., 2002; <papid> P02-1035 </papid>taskar et al, 2004; <papid> W04-3201 </papid>collins and roark,2004; <papid> P04-1015 </papid>turian and melamed, 2006).<papid> P06-1110 </papid></prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
one popular approach is to use log-linear parsing model and maximise the conditional likelihood function (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2002; <papid> P02-1035 </papid>clark and curran, 2004<papid> P04-1014 </papid>b; malouf and van noord, 2004; miyao and tsujii, 2005).<papid> P05-1011 </papid></citsent>
<aftsection>
<nextsent>maximising the likelihood involves calculating feature expectations, which is computationally expensive.
</nextsent>
<nextsent>dynamic programming (dp) in the form of the inside-outside algorithm can be usedto calculate the expectations, if the features are sufficiently local (miyao and tsujii, 2002); however,the memory requirements can be prohibitive, especially for automatically extracted, wide-coveragegrammars.
</nextsent>
<nextsent>in clark and curran (2004<papid> P04-1014 </papid>b) we use cluster computing resources to solve this problem.parsing research has also begun to adopt discriminative methods from the machine learning literature, such as the perceptron (freund and schapire,1999; collins and roark, 2004) <papid> P04-1015 </papid>and the large margin methods underlying support vector machines (taskar et al, 2004; <papid> W04-3201 </papid>mcdonald, 2006).parser training involves decoding in an iterative process, updating the model parameters so that the decoder performs better on the training data, according to some training criterion.</nextsent>
<nextsent>hence, for efficient training, these methods require an efficient decoder; in fact, for methods like the perceptron, the update procedure is so trivial that the training algorithm essentially is decoding.this paper describes decoder for lexicalized grammar parser which is efficient enough for practical discriminative training.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3209">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also investigate the order in which the training examples are presented to the online perceptron learner, and find that order does not significantly affect the results.
</prevsent>
<prevsent>a recent development in data-driven parsing is the use of discriminative training methods (riezler et al., 2002; <papid> P02-1035 </papid>taskar et al, 2004; <papid> W04-3201 </papid>collins and roark,2004; <papid> P04-1015 </papid>turian and melamed, 2006).<papid> P06-1110 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
one popular approach is to use log-linear parsing model and maximise the conditional likelihood function (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2002; <papid> P02-1035 </papid>clark and curran, 2004<papid> P04-1014 </papid>b; malouf and van noord, 2004; miyao and tsujii, 2005).<papid> P05-1011 </papid></citsent>
<aftsection>
<nextsent>maximising the likelihood involves calculating feature expectations, which is computationally expensive.
</nextsent>
<nextsent>dynamic programming (dp) in the form of the inside-outside algorithm can be usedto calculate the expectations, if the features are sufficiently local (miyao and tsujii, 2002); however,the memory requirements can be prohibitive, especially for automatically extracted, wide-coveragegrammars.
</nextsent>
<nextsent>in clark and curran (2004<papid> P04-1014 </papid>b) we use cluster computing resources to solve this problem.parsing research has also begun to adopt discriminative methods from the machine learning literature, such as the perceptron (freund and schapire,1999; collins and roark, 2004) <papid> P04-1015 </papid>and the large margin methods underlying support vector machines (taskar et al, 2004; <papid> W04-3201 </papid>mcdonald, 2006).parser training involves decoding in an iterative process, updating the model parameters so that the decoder performs better on the training data, according to some training criterion.</nextsent>
<nextsent>hence, for efficient training, these methods require an efficient decoder; in fact, for methods like the perceptron, the update procedure is so trivial that the training algorithm essentially is decoding.this paper describes decoder for lexicalized grammar parser which is efficient enough for practical discriminative training.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3215">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also investigate the order in which the training examples are presented to the online perceptron learner, and find that order does not significantly affect the results.
</prevsent>
<prevsent>a recent development in data-driven parsing is the use of discriminative training methods (riezler et al., 2002; <papid> P02-1035 </papid>taskar et al, 2004; <papid> W04-3201 </papid>collins and roark,2004; <papid> P04-1015 </papid>turian and melamed, 2006).<papid> P06-1110 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1011 ">
one popular approach is to use log-linear parsing model and maximise the conditional likelihood function (johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2002; <papid> P02-1035 </papid>clark and curran, 2004<papid> P04-1014 </papid>b; malouf and van noord, 2004; miyao and tsujii, 2005).<papid> P05-1011 </papid></citsent>
<aftsection>
<nextsent>maximising the likelihood involves calculating feature expectations, which is computationally expensive.
</nextsent>
<nextsent>dynamic programming (dp) in the form of the inside-outside algorithm can be usedto calculate the expectations, if the features are sufficiently local (miyao and tsujii, 2002); however,the memory requirements can be prohibitive, especially for automatically extracted, wide-coveragegrammars.
</nextsent>
<nextsent>in clark and curran (2004<papid> P04-1014 </papid>b) we use cluster computing resources to solve this problem.parsing research has also begun to adopt discriminative methods from the machine learning literature, such as the perceptron (freund and schapire,1999; collins and roark, 2004) <papid> P04-1015 </papid>and the large margin methods underlying support vector machines (taskar et al, 2004; <papid> W04-3201 </papid>mcdonald, 2006).parser training involves decoding in an iterative process, updating the model parameters so that the decoder performs better on the training data, according to some training criterion.</nextsent>
<nextsent>hence, for efficient training, these methods require an efficient decoder; in fact, for methods like the perceptron, the update procedure is so trivial that the training algorithm essentially is decoding.this paper describes decoder for lexicalized grammar parser which is efficient enough for practical discriminative training.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3263">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in clark and curran (2004<papid> P04-1014 </papid>b) we use cluster computing resources to solve this problem.parsing research has also begun to adopt discriminative methods from the machine learning literature, such as the perceptron (freund and schapire,1999; collins and roark, 2004) <papid> P04-1015 </papid>and the large margin methods underlying support vector machines (taskar et al, 2004; <papid> W04-3201 </papid>mcdonald, 2006).parser training involves decoding in an iterative process, updating the model parameters so that the decoder performs better on the training data, according to some training criterion.</prevsent>
<prevsent>hence, for efficient training, these methods require an efficient decoder; in fact, for methods like the perceptron, the update procedure is so trivial that the training algorithm essentially is decoding.this paper describes decoder for lexicalized grammar parser which is efficient enough for practical discriminative training.</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
we use lexicalized phrase-structure parser, the ccg parser of clark and curran (2004<papid> P04-1014 </papid>b), together with dp-based decoder.the key idea is to exploit the properties of lexicalized grammars by using finite-state super tag ger prior to parsing (bangalore and joshi, 1999; <papid> J99-2004 </papid>clark and curran, 2004<papid> P04-1014 </papid>a).</citsent>
<aftsection>
<nextsent>the decoder still uses the cky algorithm, so the worst case complexity of 9 the parsing is unchanged; however, by allowing thesupertagger to do much of the parsing work, the efficiency of the decoder is greatly increased in practice.we chose the perceptron for the training algorithm because it has shown good performance onother nlp tasks; in particular, collins (2002)<papid> W02-1001 </papid>reported good performance for perceptron tagger compared to maximum entropy tagger.</nextsent>
<nextsent>like collins (2002)<papid> W02-1001 </papid>the decoder is the same for both the perceptron and the log-linear parsing models; the only change is the method for setting the weights.the perceptron model performs as well as the loglinear model, but is considerably easier to train.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3270">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hence, for efficient training, these methods require an efficient decoder; in fact, for methods like the perceptron, the update procedure is so trivial that the training algorithm essentially is decoding.this paper describes decoder for lexicalized grammar parser which is efficient enough for practical discriminative training.
</prevsent>
<prevsent>we use lexicalized phrase-structure parser, the ccg parser of clark and curran (2004<papid> P04-1014 </papid>b), together with dp-based decoder.the key idea is to exploit the properties of lexicalized grammars by using finite-state super tag ger prior to parsing (bangalore and joshi, 1999; <papid> J99-2004 </papid>clark and curran, 2004<papid> P04-1014 </papid>a).</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
the decoder still uses the cky algorithm, so the worst case complexity of 9 the parsing is unchanged; however, by allowing thesupertagger to do much of the parsing work, the efficiency of the decoder is greatly increased in practice.we chose the perceptron for the training algorithm because it has shown good performance onother nlp tasks; in particular, collins (2002)<papid> W02-1001 </papid>reported good performance for perceptron tagger compared to maximum entropy tagger.</citsent>
<aftsection>
<nextsent>like collins (2002)<papid> W02-1001 </papid>the decoder is the same for both the perceptron and the log-linear parsing models; the only change is the method for setting the weights.the perceptron model performs as well as the loglinear model, but is considerably easier to train.</nextsent>
<nextsent>another contribution of this paper is to advancewide-coverage ccg parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3303">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> the ccg parser.  </section>
<citcontext>
<prevsection>
<prevsent>a packed chart representation allows efficient decoding, with the viterbi algorithm finding the most probable derivation.
</prevsent>
<prevsent>the super tagger is key part of the system.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
it uses log-linear model to define distribution overthe lexical category set for each word and the previous two categories (ratnaparkhi, 1996) <papid> W96-0213 </papid>and the forward backward algorithm efficiently sums over all histories to give distibution for each word.</citsent>
<aftsection>
<nextsent>these distributions are then used to assign set of lexical categories to each word (curran et al, 2006).<papid> P06-1088 </papid>super tagging was first defined for ltag (banga lore and joshi, 1999), <papid> J99-2004 </papid>and was designed to increase parsing speed for lexicalized grammars by allowing finite-state tagger to do some of the parsingwork.</nextsent>
<nextsent>since the elementary syntactic units in lexicalized grammar ? in ltags case elementary tree sand in ccgs case lexical categories ? contain significant amount of grammatical information, combining them together is easier than the parsing typically performed by phrase-structure parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3304">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> the ccg parser.  </section>
<citcontext>
<prevsection>
<prevsent>the super tagger is key part of the system.
</prevsent>
<prevsent>it uses log-linear model to define distribution overthe lexical category set for each word and the previous two categories (ratnaparkhi, 1996) <papid> W96-0213 </papid>and the forward backward algorithm efficiently sums over all histories to give distibution for each word.</prevsent>
</prevsection>
<citsent citstr=" P06-1088 ">
these distributions are then used to assign set of lexical categories to each word (curran et al, 2006).<papid> P06-1088 </papid>super tagging was first defined for ltag (banga lore and joshi, 1999), <papid> J99-2004 </papid>and was designed to increase parsing speed for lexicalized grammars by allowing finite-state tagger to do some of the parsingwork.</citsent>
<aftsection>
<nextsent>since the elementary syntactic units in lexicalized grammar ? in ltags case elementary tree sand in ccgs case lexical categories ? contain significant amount of grammatical information, combining them together is easier than the parsing typically performed by phrase-structure parsers.
</nextsent>
<nextsent>hence 10 bangalore and joshi (1999) <papid> J99-2004 </papid>refer to super tagging as almost parsing.</nextsent>
<nextsent>super tagging has been especially successful for ccg: clark and curran (2004<papid> P04-1014 </papid>a) demonstrates the considerable increases in speed that can be obtained through use of supertagger.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3356">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> the ccg parser.  </section>
<citcontext>
<prevsection>
<prevsent>in clark and curran (2004<papid> P04-1014 </papid>b) we use cluster of 45 machines, together with parallel implementation of the bfgs training algorithm, to solve this problem.</prevsent>
<prevsent>the need for cluster computing resources presentsa barrier to the development of further ccg parsing models.</prevsent>
</prevsection>
<citsent citstr=" P02-1043 ">
hockenmaier and steedman (2002) <papid> P02-1043 </papid>describe generative model for ccg, which only requires non-iterative counting process for training,but it is generally acknowledged that discriminative models provide greater flexibility and typically higher performance.</citsent>
<aftsection>
<nextsent>in this paper we propose the perceptron algorithm as solution.
</nextsent>
<nextsent>the perceptron is an online learning algorithm, and so the parameters are updated one training instance at time.however, the key difference compared with the loglinear training is that the perceptron converges in many fewer iterations, and so it is practical to read the training instances into memory one at time.
</nextsent>
<nextsent>the difficulty in using the perceptron for training phrase-structure parsing models is the need for an efficient decoder (since perceptron training essentially is decoding).
</nextsent>
<nextsent>here we exploit the lexicalized nature of ccg by using the super tagger to restrict thesize of the charts over which viterbi decoding is performed, resulting in an extremely effcient decoder.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3449">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we made sure that every word was assigned the correct lexical category among its set (we did not do this for testing).
</prevsent>
<prevsent>thenthe parser was run on the super tagged sentences, using the cky algorithm and the ccg combinatory rules.
</prevsent>
</prevsection>
<citsent citstr=" P96-1011 ">
we applied the same normal-form restrictions used in clark and curran (2004<papid> P04-1014 </papid>b): categories can 12 only combine if they have been seen to combine in sections 2-21 of ccgbank, and only if they do not violate the eisner (1996<papid> P96-1011 </papid>a) normal-form constraints.</citsent>
<aftsection>
<nextsent>this part of the process requires few hundred mb of ram to run the parser, and takes few hours for sections 2-21 of ccgbank.
</nextsent>
<nextsent>any further training times or memory requirements reported do not include the resources needed to create the forests.
</nextsent>
<nextsent>the feature forests are extracted from the packed chart representation used in the parser.
</nextsent>
<nextsent>we only use feature forest for training if it contains the correct derivation (according to ccgbank).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3498">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> comparison with other work.  </section>
<citcontext>
<prevsection>
<prevsent>taskar et al (2004) <papid> W04-3201 </papid>investigate discriminative training methods for phrase-structure parser, and also use dynamic programming for the decoder.</prevsent>
<prevsent>the key difference between our work and theirs is that they are only able to train on sentences of 15 words or less, because of the expense of the decoding.there is work on discriminative models forde pendency parsing (mcdonald, 2006); since there are efficient decoding algorithms available (eisner,1996<papid> P96-1011 </papid>b), complete resources such as the penn tree bank can used for estimation, leading to accurateparsers.</prevsent>
</prevsection>
<citsent citstr=" J05-1003 ">
there is also work on discriminative models for parse reranking (collins and koo, 2005).<papid> J05-1003 </papid></citsent>
<aftsection>
<nextsent>the main drawback with this approach is that the correct parse may get lost in the first phase.
</nextsent>
<nextsent>the existing work most similar to ours is collins and roark (2004).<papid> P04-1015 </papid></nextsent>
<nextsent>they use beam-search decoder as part of phrase-structure parser to allow practical estimation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3502">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>an advantage of the perceptron over the log-linear model is that it is considerably easier to train, requiring 1/1000th of the memory requirements and converging in only 4 iterations.
</prevsent>
<prevsent>given that the global log-linear model used here(crf) is thought to provide state-of-the-art performance for many nlp tasks, it is perhaps surprising 15that the perceptron performs as well.
</prevsent>
</prevsection>
<citsent citstr=" P07-1032 ">
the evaluation in this paper was based solely on ccgbank, but we have shown in clark and curran (2007) <papid> P07-1032 </papid>that theccg parser gives state-of-the-art performance, outperforming the rasp parser (briscoe et al, 2006) <papid> P06-4020 </papid>by over 5% on depbank.</citsent>
<aftsection>
<nextsent>this suggests the need formore comparisons of crfs and discriminative methods such as the perceptron for other nlp tasks.
</nextsent>
<nextsent>acknowledgements james curran was funded under arc discovery grants dp0453131 and dp0665973.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3503">
<title id=" W07-1202.xml">perceptron training for a wide coverage lexicalized grammar parser </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>an advantage of the perceptron over the log-linear model is that it is considerably easier to train, requiring 1/1000th of the memory requirements and converging in only 4 iterations.
</prevsent>
<prevsent>given that the global log-linear model used here(crf) is thought to provide state-of-the-art performance for many nlp tasks, it is perhaps surprising 15that the perceptron performs as well.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
the evaluation in this paper was based solely on ccgbank, but we have shown in clark and curran (2007) <papid> P07-1032 </papid>that theccg parser gives state-of-the-art performance, outperforming the rasp parser (briscoe et al, 2006) <papid> P06-4020 </papid>by over 5% on depbank.</citsent>
<aftsection>
<nextsent>this suggests the need formore comparisons of crfs and discriminative methods such as the perceptron for other nlp tasks.
</nextsent>
<nextsent>acknowledgements james curran was funded under arc discovery grants dp0453131 and dp0665973.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3504">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one widely used standard is the penn chinese treebank (ctb) segmentation standard (xue et al, 2005).it has been recognized that different nlp applications have different needs for segmentation.
</prevsent>
<prevsent>chinese information retrieval (ir) systems benefit from segmentation that breaks compound words into shorter words?
</prevsent>
</prevsection>
<citsent citstr=" C02-1148 ">
(peng et al, 2002), <papid> C02-1148 </papid>paralleling their gains from compound splitting in languages like german (hollink et al, 2004), whereas automatic speech recognition (asr) systems prefer having longer words in the speech lexicon (gao etal., 2005).<papid> J05-4005 </papid></citsent>
<aftsection>
<nextsent>however, despite decade of very intense work on chinese to english machine translation (mt), the way in which chinese word segmentation affects mt performance is very poorly understood.
</nextsent>
<nextsent>with current statistical phrase-based mt systems, one might hypothesize that segmenting into small chunks, including perhaps even working with individual characters would be optimal.
</nextsent>
<nextsent>this is be cause the role of phrase table is to build domain and application appropriate larger chunks that are semantically coherent in the translation process.
</nextsent>
<nextsent>for example, even if the word for smallpox is treated as two one-character words, they can still appear in phrase like ssmallpox?, so that smallpox will still be candidate translation when the system translates u? s?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3505">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one widely used standard is the penn chinese treebank (ctb) segmentation standard (xue et al, 2005).it has been recognized that different nlp applications have different needs for segmentation.
</prevsent>
<prevsent>chinese information retrieval (ir) systems benefit from segmentation that breaks compound words into shorter words?
</prevsent>
</prevsection>
<citsent citstr=" J05-4005 ">
(peng et al, 2002), <papid> C02-1148 </papid>paralleling their gains from compound splitting in languages like german (hollink et al, 2004), whereas automatic speech recognition (asr) systems prefer having longer words in the speech lexicon (gao etal., 2005).<papid> J05-4005 </papid></citsent>
<aftsection>
<nextsent>however, despite decade of very intense work on chinese to english machine translation (mt), the way in which chinese word segmentation affects mt performance is very poorly understood.
</nextsent>
<nextsent>with current statistical phrase-based mt systems, one might hypothesize that segmenting into small chunks, including perhaps even working with individual characters would be optimal.
</nextsent>
<nextsent>this is be cause the role of phrase table is to build domain and application appropriate larger chunks that are semantically coherent in the translation process.
</nextsent>
<nextsent>for example, even if the word for smallpox is treated as two one-character words, they can still appear in phrase like ssmallpox?, so that smallpox will still be candidate translation when the system translates u? s?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3506">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, even if the word for smallpox is treated as two one-character words, they can still appear in phrase like ssmallpox?, so that smallpox will still be candidate translation when the system translates u? s?.
</prevsent>
<prevsent>nevertheless, xu et al (2004)show that an mt system with word segmenter outperforms system working with individual characters in an alignment template approach.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
on different language pairs, (koehn and knight, 2003) <papid> E03-1076 </papid>and (habash and sadat, 2006) <papid> N06-2013 </papid>showed that data-driven methods for splitting and preprocessing can improve arabic-english and german-english mt.beyond this, there has been no finer-grained analysis of what style and size of word segmentation is optimal for mt. moreover, most discussion of segmentation for other tasks relates to the size units to identify in the segmentation standard: whether to join or split noun compounds, for instance.</citsent>
<aftsection>
<nextsent>people 224 generally assume that improvements in systems word segmentation accuracy will be monotonic ally reflected in overall system performance.
</nextsent>
<nextsent>this is the assumption that justifies the concerted recent workon the independent task of chinese word segmentation evaluation at sighan and other venues.
</nextsent>
<nextsent>how ever, we show that this assumption is false: aspects of segment ers other than error rate are more critical to their performance when embedded in an mtsystem.
</nextsent>
<nextsent>unless these issues are attended to, simple baseline segment ers can be more effective inside an mt system than more complex machine learning based models, with much lower word segmentation error rate.in this paper, we show that even having basic word segmenter helps mt performance, and we analyze why building an mt system over individual characters doesnt function as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3507">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, even if the word for smallpox is treated as two one-character words, they can still appear in phrase like ssmallpox?, so that smallpox will still be candidate translation when the system translates u? s?.
</prevsent>
<prevsent>nevertheless, xu et al (2004)show that an mt system with word segmenter outperforms system working with individual characters in an alignment template approach.
</prevsent>
</prevsection>
<citsent citstr=" N06-2013 ">
on different language pairs, (koehn and knight, 2003) <papid> E03-1076 </papid>and (habash and sadat, 2006) <papid> N06-2013 </papid>showed that data-driven methods for splitting and preprocessing can improve arabic-english and german-english mt.beyond this, there has been no finer-grained analysis of what style and size of word segmentation is optimal for mt. moreover, most discussion of segmentation for other tasks relates to the size units to identify in the segmentation standard: whether to join or split noun compounds, for instance.</citsent>
<aftsection>
<nextsent>people 224 generally assume that improvements in systems word segmentation accuracy will be monotonic ally reflected in overall system performance.
</nextsent>
<nextsent>this is the assumption that justifies the concerted recent workon the independent task of chinese word segmentation evaluation at sighan and other venues.
</nextsent>
<nextsent>how ever, we show that this assumption is false: aspects of segment ers other than error rate are more critical to their performance when embedded in an mtsystem.
</nextsent>
<nextsent>unless these issues are attended to, simple baseline segment ers can be more effective inside an mt system than more complex machine learning based models, with much lower word segmentation error rate.in this paper, we show that even having basic word segmenter helps mt performance, and we analyze why building an mt system over individual characters doesnt function as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3508">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>the training data contains 509k words, and the test data has 155k words.
</prevsent>
<prevsent>the percentage of words in the test data that are unseen in the training data is 8.8%.
</prevsent>
</prevsection>
<citsent citstr=" W06-0115 ">
detail of the bakeoff datasets is in (levow, 2006).<papid> W06-0115 </papid></citsent>
<aftsection>
<nextsent>to understand how each segmenter learns about oov words, we will report the measure, the in-vocabulary (iv) recall rate as well as oov recall rate of each segmenter.
</nextsent>
<nextsent>2.2 phrase-based chinese-to-english mt. the mt system used in this paper is moses, state of-the-art phrase-based system (koehn et al, 2003).<papid> N03-1017 </papid>we build phrase translations by first acquiring bidirectional giza++ (och and ney, 2003) <papid> J03-1002 </papid>alignments,and using moses?</nextsent>
<nextsent>grow-diag alignment symmetriza tion heuristic.1 we set the maximum phrase length to large value (10), because some segment ers described later in this paper will result in shorter 1in our experiments, this heuristic consistently performed better than the default, grow-diag-final.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3509">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>detail of the bakeoff datasets is in (levow, 2006).<papid> W06-0115 </papid></prevsent>
<prevsent>to understand how each segmenter learns about oov words, we will report the measure, the in-vocabulary (iv) recall rate as well as oov recall rate of each segmenter.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
2.2 phrase-based chinese-to-english mt. the mt system used in this paper is moses, state of-the-art phrase-based system (koehn et al, 2003).<papid> N03-1017 </papid>we build phrase translations by first acquiring bidirectional giza++ (och and ney, 2003) <papid> J03-1002 </papid>alignments,and using moses?</citsent>
<aftsection>
<nextsent>grow-diag alignment symmetriza tion heuristic.1 we set the maximum phrase length to large value (10), because some segment ers described later in this paper will result in shorter 1in our experiments, this heuristic consistently performed better than the default, grow-diag-final.
</nextsent>
<nextsent>225words, therefore it is more comparable if we increase the maximum phrase length.
</nextsent>
<nextsent>during decoding, we incorporate the standard eight feature functions of moses as well as the lexicalized reordering model.
</nextsent>
<nextsent>we tuned the parameters of these features with minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the nist mt03 evaluation dataset (919 sentences), and then test the mt performance on nist mt03 and mt05 evaluation data (878 and 1082 sentences, respectively).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3510">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>detail of the bakeoff datasets is in (levow, 2006).<papid> W06-0115 </papid></prevsent>
<prevsent>to understand how each segmenter learns about oov words, we will report the measure, the in-vocabulary (iv) recall rate as well as oov recall rate of each segmenter.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
2.2 phrase-based chinese-to-english mt. the mt system used in this paper is moses, state of-the-art phrase-based system (koehn et al, 2003).<papid> N03-1017 </papid>we build phrase translations by first acquiring bidirectional giza++ (och and ney, 2003) <papid> J03-1002 </papid>alignments,and using moses?</citsent>
<aftsection>
<nextsent>grow-diag alignment symmetriza tion heuristic.1 we set the maximum phrase length to large value (10), because some segment ers described later in this paper will result in shorter 1in our experiments, this heuristic consistently performed better than the default, grow-diag-final.
</nextsent>
<nextsent>225words, therefore it is more comparable if we increase the maximum phrase length.
</nextsent>
<nextsent>during decoding, we incorporate the standard eight feature functions of moses as well as the lexicalized reordering model.
</nextsent>
<nextsent>we tuned the parameters of these features with minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the nist mt03 evaluation dataset (919 sentences), and then test the mt performance on nist mt03 and mt05 evaluation data (878 and 1082 sentences, respectively).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3511">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>225words, therefore it is more comparable if we increase the maximum phrase length.
</prevsent>
<prevsent>during decoding, we incorporate the standard eight feature functions of moses as well as the lexicalized reordering model.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we tuned the parameters of these features with minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the nist mt03 evaluation dataset (919 sentences), and then test the mt performance on nist mt03 and mt05 evaluation data (878 and 1082 sentences, respectively).</citsent>
<aftsection>
<nextsent>we report the mtperformance using the original bleu metric (pap ineni et al, 2001).
</nextsent>
<nextsent>all bleu scores in this paper are uncased.
</nextsent>
<nextsent>the mt training data was sub sampled from gale year 2 training data using collection of character 5-grams and smaller n-grams drawn from all segment ations of the test data.
</nextsent>
<nextsent>since the mt training data is sub sampled with character n-grams, it is not biased towards any particular word segmentation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3512">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> understanding chinese word.  </section>
<citcontext>
<prevsection>
<prevsent>our experiments show that higher measure does not necessarily 227 lead to higher bleu score.
</prevsent>
<prevsent>in order to contrast with the simple maximum matching lexicon-based model (maxmatch), we built another segmenter witha crf model.
</prevsent>
</prevsection>
<citsent citstr=" C04-1081 ">
crf is statistical sequence modeling framework introduced by lafferty et al (2001),and was first used for the chinese word segmentation task by peng et al (2004), <papid> C04-1081 </papid>who treated word segmentation as binary decision task.</citsent>
<aftsection>
<nextsent>we optimized the parameters with quasi-newton method, and used gaussian priors to prevent overfitting.
</nextsent>
<nextsent>the probability assigned to label sequence for particular sequence of characters by crf is given by the equation: p?
</nextsent>
<nextsent>(y|x) = 1 z(x) exp ? t=1 ? k=1 fk(x,yt1,yt , t) (1) is sequence of unsegmented characters, z(x) is the partition function that ensures that equation 1 is probability distribution, { fk}kk=1 is set of feature functions, and is the sequence of binary predictions for the sentence, where the prediction yt = +1indicates the t-th character of the sequence is preceded by space, and where yt =1 indicates thereis none.
</nextsent>
<nextsent>we trained crf model with set of basic features: character identity features of the current character, previous character and next character, and the conjunction of previous and current characters inthe zero-order templates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3513">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> optimal average token length for mt.  </section>
<citcontext>
<prevsection>
<prevsent>in conclusion, for mt performance, it is helpful to have consistent segmentation, while still having word segmentation matching the granularity of the segmented chinese lexicon and the english lexicon.
</prevsent>
<prevsent>we have shown earlier that word-level segmentation vastly outperforms character based segmentation inmt evaluations.
</prevsent>
</prevsection>
<citsent citstr=" N06-2024 ">
since the word segmentation standard under consideration (chinese treebank (xue et al, 2005)) was neither specifically designed nor optimized for mt, it seems reasonable to investigate whether any segmentation granularity in continuum between character-level and ctb-style segmentation is more effective for mt. in this section,we present technique for directly optimizing segmentation property characters per token average for translation quality, which yields significant improvements in mt performance.in order to calibrate the average word length produced by our crf segmenteri.e., to adjust the rate of word boundary predictions (yt = +1), we apply relatively simple technique (minkov et al, 2006) <papid> N06-2024 </papid>originally devised for adjusting the precision/recall tradeoff of any sequential classifier.</citsent>
<aftsection>
<nextsent>specifically, the weight vector and feature vector of trained linear sequence classifier are augmented at test time to include new class-conditional feature functions tobias the classifier towards particular class labels.
</nextsent>
<nextsent>in our case, since we wish to increase the frequency of word boundaries, we add feature function: f0(x,yt1,yt , t) = { 1 if yt = +1 0 otherwise its weight 0 controls the extent of which the classifier will make positive predictions, with very large positive 0 values causing only positive predictions (i.e., character-based segmentation) and large negative values effectively disabling segmentation boundaries.
</nextsent>
<nextsent>table 5 displays how changes of the 229 0 1 0 1 2 4 8 32 len 1.64 1.62 1.61 1.59 1.55 1.37 1 table 5: effect of the bias parameter 0 on the average number of character per token on mt data.
</nextsent>
<nextsent>bias parameter 0 affect segmentation granularity.4 since we are interested in analyzing the different regimes of mt performance between ctb segmentation and character-based, we performed grid search in the range between 0 = 0 (maximum likelihood estimate) and 0 = 32 (a value that is large enough to produce only positive predictions).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3514">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> improving segmentation consistency of.  </section>
<citcontext>
<prevsection>
<prevsent>one way to improve the consistency of the crf model is to make use of external lexicons (which are not part of the segmentation training data) to add lexicon-based features.
</prevsent>
<prevsent>all the features we use are listed in table 6.
</prevsent>
</prevsection>
<citsent citstr=" W04-3236 ">
our linguistic features are adopted from (ng and low, 2004) <papid> W04-3236 </papid>and (tseng et al., 2005).<papid> I05-3027 </papid></citsent>
<aftsection>
<nextsent>there are three categories of features: 230 lexicon-based features linguistic features (1.1) lbegin(cn),n ? [2,1] (2.1) cn,n ? [2,1] (1.2) lmid(cn),n ? [2,1] (2.2) cn1cn,n ? [1,1] (1.3) lend(cn),n ? [2,1] (2.3) cn2cn,n ? [1,2] (1.4) lend(c1)+lend(c0) (2.4) single(cn),n ? [2,1] +lend(c1) (2.5) unknownbigram(c1c0) (1.5) lend(c2)+lend(c1) (2.6) productivea f ixes(c1,c0) +lbegin(c0)+lmid(c0) (2.7) reduplication(c1,cn),n ? [0,1] (1.6) lend(c2)+lend(c1) +lbegin(c1) +lbegin(c0)+lmid(c0) table 6: features for crf-lexcharacter identity n-grams, morphological and character reduplication features.
</nextsent>
<nextsent>our lexicon-based features are adopted from (shi and wang, 2007), where lbegin(c0), lmid(c0) and lend(c0) represent the maximum length of words found in lexicon that contain the current character as either the first, middle or last character, and we group any length equal or longer than 6 together.
</nextsent>
<nextsent>the linguistic features help capturing words that were unseen to the seg menter; while the lexicon-based features constrain the segmenter with external knowledge of what sequences are likely to be words.
</nextsent>
<nextsent>we built crf segmenter with all the features listed in table 6 (crf-lex).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3515">
<title id=" W08-0336.xml">optimizing chinese word segmentation for machine translation performance </title>
<section> improving segmentation consistency of.  </section>
<citcontext>
<prevsection>
<prevsent>one way to improve the consistency of the crf model is to make use of external lexicons (which are not part of the segmentation training data) to add lexicon-based features.
</prevsent>
<prevsent>all the features we use are listed in table 6.
</prevsent>
</prevsection>
<citsent citstr=" I05-3027 ">
our linguistic features are adopted from (ng and low, 2004) <papid> W04-3236 </papid>and (tseng et al., 2005).<papid> I05-3027 </papid></citsent>
<aftsection>
<nextsent>there are three categories of features: 230 lexicon-based features linguistic features (1.1) lbegin(cn),n ? [2,1] (2.1) cn,n ? [2,1] (1.2) lmid(cn),n ? [2,1] (2.2) cn1cn,n ? [1,1] (1.3) lend(cn),n ? [2,1] (2.3) cn2cn,n ? [1,2] (1.4) lend(c1)+lend(c0) (2.4) single(cn),n ? [2,1] +lend(c1) (2.5) unknownbigram(c1c0) (1.5) lend(c2)+lend(c1) (2.6) productivea f ixes(c1,c0) +lbegin(c0)+lmid(c0) (2.7) reduplication(c1,cn),n ? [0,1] (1.6) lend(c2)+lend(c1) +lbegin(c1) +lbegin(c0)+lmid(c0) table 6: features for crf-lexcharacter identity n-grams, morphological and character reduplication features.
</nextsent>
<nextsent>our lexicon-based features are adopted from (shi and wang, 2007), where lbegin(c0), lmid(c0) and lend(c0) represent the maximum length of words found in lexicon that contain the current character as either the first, middle or last character, and we group any length equal or longer than 6 together.
</nextsent>
<nextsent>the linguistic features help capturing words that were unseen to the seg menter; while the lexicon-based features constrain the segmenter with external knowledge of what sequences are likely to be words.
</nextsent>
<nextsent>we built crf segmenter with all the features listed in table 6 (crf-lex).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3520">
<title id=" W07-2035.xml">hitwsd using search engine for multilingual chinese english lexical sample task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the majority of methods using the web often try to automatically generate sense tagged corpora (agirre and martinez 2000;agirre and martinez 2004;gonzalo et al 2003; mihalcea and moldovan 1999;santamaria et al 2003).
</prevsent>
<prevsent>in this paper, we experiment with our initial attempt on another research trend that uses the web not for extracting training samples but helping disambiguate directly during the translation selection process.
</prevsent>
</prevsection>
<citsent citstr=" P06-1057 ">
the approach we present here is inspired by (mihalcea and moldovan 1999;brill 2003; rosso et al 2005; dagan et al 2006; <papid> P06-1057 </papid>mccarthy 2002).<papid> W02-0816 </papid></citsent>
<aftsection>
<nextsent>suppose that source ambiguous words are apt to appear with its target translation on bilingual web pages either parallel or non-parallel.
</nextsent>
<nextsent>instead of searching the source language or target language respectively on web, we try to let the search engine think in bilingual style.
</nextsent>
<nextsent>first, our system gets the co-occurrence information of chinese context and its corresponding english context.
</nextsent>
<nextsent>then it computes association measurements of chinese context and english context in 4 kinds of way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3521">
<title id=" W07-2035.xml">hitwsd using search engine for multilingual chinese english lexical sample task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the majority of methods using the web often try to automatically generate sense tagged corpora (agirre and martinez 2000;agirre and martinez 2004;gonzalo et al 2003; mihalcea and moldovan 1999;santamaria et al 2003).
</prevsent>
<prevsent>in this paper, we experiment with our initial attempt on another research trend that uses the web not for extracting training samples but helping disambiguate directly during the translation selection process.
</prevsent>
</prevsection>
<citsent citstr=" W02-0816 ">
the approach we present here is inspired by (mihalcea and moldovan 1999;brill 2003; rosso et al 2005; dagan et al 2006; <papid> P06-1057 </papid>mccarthy 2002).<papid> W02-0816 </papid></citsent>
<aftsection>
<nextsent>suppose that source ambiguous words are apt to appear with its target translation on bilingual web pages either parallel or non-parallel.
</nextsent>
<nextsent>instead of searching the source language or target language respectively on web, we try to let the search engine think in bilingual style.
</nextsent>
<nextsent>first, our system gets the co-occurrence information of chinese context and its corresponding english context.
</nextsent>
<nextsent>then it computes association measurements of chinese context and english context in 4 kinds of way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3522">
<title id=" W07-1709.xml">the best of two worlds cooperation of statistical and rule based taggers for czech </title>
<section> subpos detailed pos.  </section>
<citcontext>
<prevsection>
<prevsent>the approach to tagging (understood as stand alone task) using hand-written disambiguation rules has been proposed and implemented for the first time in the form of constraint-based grammars (karlsson, 1995).
</prevsent>
<prevsent>on larger scale, this aproach was applied to english, (karlsson, 1995) and (samuels son, 1997), and french (chanod, 1995).
</prevsent>
</prevsection>
<citsent citstr=" C90-2040 ">
also (bick, 2000) uses manually written disambiguation rules for tagging brazilian portuguese, (karlsson, 1985) and (koskenniemi, 1990) <papid> C90-2040 </papid>for finish and (oflazer, 1997) reports the same for turkish.</citsent>
<aftsection>
<nextsent>2.4.1 overview in the hybrid tagging system presented in this paper, the rule-based component is used to further reduce the ambiguity (the number of tags) of tokens in an input sentence, as output by the morphological processor (see sect.
</nextsent>
<nextsent>1).
</nextsent>
<nextsent>the core of the component is hand-written grammar (set of rules).
</nextsent>
<nextsent>each rule represents portion of knowledge of the language system (in particular, of czech).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3523">
<title id=" W07-2005.xml">semeval2007 task 06 word sense disambiguation of prepositions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the semeval-2007 task to disambiguate prepositions was designed as lexical sample task to investigate the extent to which an important closed class of words could be disambiguated.
</prevsent>
<prevsent>in addition, because they are closed class, with stable senses, the requisite datasets for this task are enduring and can be used as long as the problem of preposition disambiguation remains.
</prevsent>
</prevsection>
<citsent citstr=" W06-2106 ">
the data used in this task was developed in the preposition project (tpp, litkowski &amp; hargraves (2005) and litkowski &amp; hargraves (2006)), <papid> W06-2106 </papid>1 with further refinements to fit the requirements of semeval task.</citsent>
<aftsection>
<nextsent>in the following sections, we first describe the motivations for preposition disambiguation task.
</nextsent>
<nextsent>next, we describe the development of the datasets used for the task, i.e., the instance sets and the sense inventories.
</nextsent>
<nextsent>we describe how the task was performed and how it was evaluated (essentially using the same scoring methods as previous senseval lexical sample tasks).
</nextsent>
<nextsent>we present the results obtained from the participating teams and provide an initial analysis of these results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3524">
<title id=" W07-2005.xml">semeval2007 task 06 word sense disambiguation of prepositions </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>their analysis relied on penn treebank data.
</prevsent>
<prevsent>further insights may be available from the finer-grained data available in the preposition disambiguation task.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
another important thread of investigation concerning preposition behavior is the task of semantic role (and perhaps semantic relation) labeling (gildea &amp; jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>this task has been the subject of previous senseval task (automatic semantic role labeling, litkowski (2004)) <papid> W04-0803 </papid>and two shared tasks on semantic role labeling in the conference on natural language learning (carreras &amp; marquez (2004) and carreras &amp; marquez (2005)).</nextsent>
<nextsent>in addition, three other tasks in semeval-2007 (semantic relations between nominals, task 4; temporal relation labeling, task 15; and frame semantic structure extraction, task 19) address issues of semantic role labeling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3525">
<title id=" W07-2005.xml">semeval2007 task 06 word sense disambiguation of prepositions </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>further insights may be available from the finer-grained data available in the preposition disambiguation task.
</prevsent>
<prevsent>another important thread of investigation concerning preposition behavior is the task of semantic role (and perhaps semantic relation) labeling (gildea &amp; jurafsky, 2002).<papid> J02-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-0803 ">
this task has been the subject of previous senseval task (automatic semantic role labeling, litkowski (2004)) <papid> W04-0803 </papid>and two shared tasks on semantic role labeling in the conference on natural language learning (carreras &amp; marquez (2004) and carreras &amp; marquez (2005)).</citsent>
<aftsection>
<nextsent>in addition, three other tasks in semeval-2007 (semantic relations between nominals, task 4; temporal relation labeling, task 15; and frame semantic structure extraction, task 19) address issues of semantic role labeling.
</nextsent>
<nextsent>since great proportion of these semantic roles are realized in prepositional phrases, this gives greater urgency to understanding preposition behavior.
</nextsent>
<nextsent>despite the predominant view of prepositions as function words carrying little meaning, this view is not borne out in dictionary treatment of their definitions.
</nextsent>
<nextsent>to all appearances, prepositions exhibit definitional behavior similar to that of open class words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3526">
<title id=" W08-0605.xml">accelerating the annotation of sparse named entities by dynamic sentence selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluated our framework by simulating the annotation process using two named entity corpora and show that our approach could drastically reduce the number of sentences to be annotated when applied to sparse named entities.
</prevsent>
<prevsent>named entities play central role in conveying important domain specific information in text, and good named entity recognizers are often required in building practical information extraction systems.
</prevsent>
</prevsection>
<citsent citstr=" W04-1221 ">
previous studies have shown that automatic named entity recognition can be performed with reason able level of accuracy by using various machine learning models such as support vector machines (svms) or conditional random fields (crfs) (tjong kim sang and de meulder, 2003; settles, 2004; <papid> W04-1221 </papid>okanohara et al, 2006).<papid> P06-1059 </papid></citsent>
<aftsection>
<nextsent>however, the lack of annotated corpora, which are indispensable for training machine learning models, makes it difficult to broaden the scope of text miningapplications.
</nextsent>
<nextsent>in the biomedical domain, for example, several annotated corpora such as genia (kim et al, 2003), pennbioie (kulick et al, 2004), <papid> W04-3111 </papid>and genetag (tanabe et al, 2005) have been created and made publicly available, but the named entity categories annotated in these corpora are tailored totheir specific needs and not always sufficient or suit able for text mining tasks that other researchers need to address.</nextsent>
<nextsent>active learning is framework which can be used for reducing the amount of human effort required to create training corpus (dagan and engelson, 1995; engelson and dagan, 1996; <papid> P96-1042 </papid>thompson et al, 1999; shen et al, 2004).<papid> P04-1075 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3527">
<title id=" W08-0605.xml">accelerating the annotation of sparse named entities by dynamic sentence selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluated our framework by simulating the annotation process using two named entity corpora and show that our approach could drastically reduce the number of sentences to be annotated when applied to sparse named entities.
</prevsent>
<prevsent>named entities play central role in conveying important domain specific information in text, and good named entity recognizers are often required in building practical information extraction systems.
</prevsent>
</prevsection>
<citsent citstr=" P06-1059 ">
previous studies have shown that automatic named entity recognition can be performed with reason able level of accuracy by using various machine learning models such as support vector machines (svms) or conditional random fields (crfs) (tjong kim sang and de meulder, 2003; settles, 2004; <papid> W04-1221 </papid>okanohara et al, 2006).<papid> P06-1059 </papid></citsent>
<aftsection>
<nextsent>however, the lack of annotated corpora, which are indispensable for training machine learning models, makes it difficult to broaden the scope of text miningapplications.
</nextsent>
<nextsent>in the biomedical domain, for example, several annotated corpora such as genia (kim et al, 2003), pennbioie (kulick et al, 2004), <papid> W04-3111 </papid>and genetag (tanabe et al, 2005) have been created and made publicly available, but the named entity categories annotated in these corpora are tailored totheir specific needs and not always sufficient or suit able for text mining tasks that other researchers need to address.</nextsent>
<nextsent>active learning is framework which can be used for reducing the amount of human effort required to create training corpus (dagan and engelson, 1995; engelson and dagan, 1996; <papid> P96-1042 </papid>thompson et al, 1999; shen et al, 2004).<papid> P04-1075 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3528">
<title id=" W08-0605.xml">accelerating the annotation of sparse named entities by dynamic sentence selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous studies have shown that automatic named entity recognition can be performed with reason able level of accuracy by using various machine learning models such as support vector machines (svms) or conditional random fields (crfs) (tjong kim sang and de meulder, 2003; settles, 2004; <papid> W04-1221 </papid>okanohara et al, 2006).<papid> P06-1059 </papid></prevsent>
<prevsent>however, the lack of annotated corpora, which are indispensable for training machine learning models, makes it difficult to broaden the scope of text miningapplications.</prevsent>
</prevsection>
<citsent citstr=" W04-3111 ">
in the biomedical domain, for example, several annotated corpora such as genia (kim et al, 2003), pennbioie (kulick et al, 2004), <papid> W04-3111 </papid>and genetag (tanabe et al, 2005) have been created and made publicly available, but the named entity categories annotated in these corpora are tailored totheir specific needs and not always sufficient or suit able for text mining tasks that other researchers need to address.</citsent>
<aftsection>
<nextsent>active learning is framework which can be used for reducing the amount of human effort required to create training corpus (dagan and engelson, 1995; engelson and dagan, 1996; <papid> P96-1042 </papid>thompson et al, 1999; shen et al, 2004).<papid> P04-1075 </papid></nextsent>
<nextsent>inactive learning, samples that need to be annotated by the human annotator are picked up by machine learning model in an iterative and interactive manner, considering the infor mativeness of the samples.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3529">
<title id=" W08-0605.xml">accelerating the annotation of sparse named entities by dynamic sentence selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the lack of annotated corpora, which are indispensable for training machine learning models, makes it difficult to broaden the scope of text miningapplications.
</prevsent>
<prevsent>in the biomedical domain, for example, several annotated corpora such as genia (kim et al, 2003), pennbioie (kulick et al, 2004), <papid> W04-3111 </papid>and genetag (tanabe et al, 2005) have been created and made publicly available, but the named entity categories annotated in these corpora are tailored totheir specific needs and not always sufficient or suit able for text mining tasks that other researchers need to address.</prevsent>
</prevsection>
<citsent citstr=" P96-1042 ">
active learning is framework which can be used for reducing the amount of human effort required to create training corpus (dagan and engelson, 1995; engelson and dagan, 1996; <papid> P96-1042 </papid>thompson et al, 1999; shen et al, 2004).<papid> P04-1075 </papid></citsent>
<aftsection>
<nextsent>inactive learning, samples that need to be annotated by the human annotator are picked up by machine learning model in an iterative and interactive manner, considering the infor mativeness of the samples.
</nextsent>
<nextsent>active learning has been shown to be effective in several natural language processing tasks including named entity recognition.
</nextsent>
<nextsent>the problem with active learning is, however, that the resulting annotated data is highly dependent on the machine learning algorithm and the sampling strategy employed, because active learning annotates only subset of the given corpus.
</nextsent>
<nextsent>this sampling bias is not serious problem if one is to use the annotated corpus only for their own machine learning purpose and with the same machine learning algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3530">
<title id=" W08-0605.xml">accelerating the annotation of sparse named entities by dynamic sentence selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the lack of annotated corpora, which are indispensable for training machine learning models, makes it difficult to broaden the scope of text miningapplications.
</prevsent>
<prevsent>in the biomedical domain, for example, several annotated corpora such as genia (kim et al, 2003), pennbioie (kulick et al, 2004), <papid> W04-3111 </papid>and genetag (tanabe et al, 2005) have been created and made publicly available, but the named entity categories annotated in these corpora are tailored totheir specific needs and not always sufficient or suit able for text mining tasks that other researchers need to address.</prevsent>
</prevsection>
<citsent citstr=" P04-1075 ">
active learning is framework which can be used for reducing the amount of human effort required to create training corpus (dagan and engelson, 1995; engelson and dagan, 1996; <papid> P96-1042 </papid>thompson et al, 1999; shen et al, 2004).<papid> P04-1075 </papid></citsent>
<aftsection>
<nextsent>inactive learning, samples that need to be annotated by the human annotator are picked up by machine learning model in an iterative and interactive manner, considering the infor mativeness of the samples.
</nextsent>
<nextsent>active learning has been shown to be effective in several natural language processing tasks including named entity recognition.
</nextsent>
<nextsent>the problem with active learning is, however, that the resulting annotated data is highly dependent on the machine learning algorithm and the sampling strategy employed, because active learning annotates only subset of the given corpus.
</nextsent>
<nextsent>this sampling bias is not serious problem if one is to use the annotated corpus only for their own machine learning purpose and with the same machine learning algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3531">
<title id=" W08-0605.xml">accelerating the annotation of sparse named entities by dynamic sentence selection </title>
<section> discussion and related work.  </section>
<citcontext>
<prevsection>
<prevsent>the seriousness of missing rate of, for example, 1% is not entirely clearit depends on the application and the purpose of annotation.
</prevsent>
<prevsent>in general, however, itis hard to achieve coverage of 100% in real annotation work even if the human annotator scans through all sentences, because there is often ambiguity in deciding whether particular named entity should be annotated or not.
</prevsent>
</prevsection>
<citsent citstr=" W06-3328 ">
previous studies report that inter-annotator agreement rates with regards to gene/protein name annotation are f-scores around 90% (morgan et al, 2004; vlachos and gasperin, 2006).<papid> W06-3328 </papid></citsent>
<aftsection>
<nextsent>we believe that the missing rate of 1% can bean acceptable level of sacrifice, given the cost reduction achieved and the unavoidable discrepancy made by the human annotator.
</nextsent>
<nextsent>at the same time, we should also note that our framework could be used in conjunction with existing methods for semi-supervised learning to im prove the performance of the crf tagger, whichin turn will improve the coverage.
</nextsent>
<nextsent>it is also possible to improve the performance of the tagger byusing external dictionaries or using more sophisticated probabilistic models such as semi-markovcrfs (sarawagi and cohen, 2004).
</nextsent>
<nextsent>these enhancements should further improve the coverage, keeping the same degree of cost reduction.the idea of improving the efficiency of annotation work by using automatic taggers is certainly not new.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3532">
<title id=" W07-1012.xml">bionoculars extracting protein protein interactions from biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 bne tagging.
</prevsent>
<prevsent>concerning bne tagging, the most common approaches are based on hand-crafted rules, statistical classifiers, or hybrid of both (usually in conjunction with dictionaries of bne).
</prevsent>
</prevsection>
<citsent citstr=" W03-1309 ">
rule-based systems (fukuda et al, 1998; hanisch et al, 2003; yamamoto et al, 2003) <papid> W03-1309 </papid>that use dictionaries tend to exhibit high precision in tagging named entities but generally with lower tagging recall.</citsent>
<aftsection>
<nextsent>they tend to lag the latest published research and are sensitive to the expression of the named entities.
</nextsent>
<nextsent>dictionaries of bne are typically laborious and expensive to build, and they are dependant on nomenclatures and specific species.
</nextsent>
<nextsent>statistical approaches (collier etal., 2000; <papid> C00-1030 </papid>kazama et al, 2002; <papid> W02-0301 </papid>settles, 2004) <papid> W04-1221 </papid>typically improve recall at the expense of precision,but are more readily retarget able for new nomen clatures and organisms.</nextsent>
<nextsent>hybrid systems (tanabe and wilbur, 2002; mika and rost, 2004) attempt to take advantage of both approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3533">
<title id=" W07-1012.xml">bionoculars extracting protein protein interactions from biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>they tend to lag the latest published research and are sensitive to the expression of the named entities.
</prevsent>
<prevsent>dictionaries of bne are typically laborious and expensive to build, and they are dependant on nomenclatures and specific species.
</prevsent>
</prevsection>
<citsent citstr=" C00-1030 ">
statistical approaches (collier etal., 2000; <papid> C00-1030 </papid>kazama et al, 2002; <papid> W02-0301 </papid>settles, 2004) <papid> W04-1221 </papid>typically improve recall at the expense of precision,but are more readily retarget able for new nomen clatures and organisms.</citsent>
<aftsection>
<nextsent>hybrid systems (tanabe and wilbur, 2002; mika and rost, 2004) attempt to take advantage of both approaches.
</nextsent>
<nextsent>although these approaches tend to generate acceptable recognition, they are heavily dependent on the type of data on which they are trained.(fukuda et al, 1998) proposed rule-based protein name extraction system called proper (pro tein proper-noun phrase extracting rules) system, which utilizes set of rules based on the surface form of text in conjunction with part-of-speech (pos) tagging to identify what looks like protein without referring to any specific bne dictionary.they reported 94.7% precision and 98.84% recall for the identification of bnes.
</nextsent>
<nextsent>the results that they achieved seem to be too specific to their training and test sets.
</nextsent>
<nextsent>(hanisch et al, 2003) proposed rule-based protein and gene name extraction system called pro miner, which is based on the construction of ageneral-purpose dictionary along with different dictionaries of synonyms and an automatic cur ation procedure based on simple token model of protein names.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3534">
<title id=" W07-1012.xml">bionoculars extracting protein protein interactions from biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>they tend to lag the latest published research and are sensitive to the expression of the named entities.
</prevsent>
<prevsent>dictionaries of bne are typically laborious and expensive to build, and they are dependant on nomenclatures and specific species.
</prevsent>
</prevsection>
<citsent citstr=" W02-0301 ">
statistical approaches (collier etal., 2000; <papid> C00-1030 </papid>kazama et al, 2002; <papid> W02-0301 </papid>settles, 2004) <papid> W04-1221 </papid>typically improve recall at the expense of precision,but are more readily retarget able for new nomen clatures and organisms.</citsent>
<aftsection>
<nextsent>hybrid systems (tanabe and wilbur, 2002; mika and rost, 2004) attempt to take advantage of both approaches.
</nextsent>
<nextsent>although these approaches tend to generate acceptable recognition, they are heavily dependent on the type of data on which they are trained.(fukuda et al, 1998) proposed rule-based protein name extraction system called proper (pro tein proper-noun phrase extracting rules) system, which utilizes set of rules based on the surface form of text in conjunction with part-of-speech (pos) tagging to identify what looks like protein without referring to any specific bne dictionary.they reported 94.7% precision and 98.84% recall for the identification of bnes.
</nextsent>
<nextsent>the results that they achieved seem to be too specific to their training and test sets.
</nextsent>
<nextsent>(hanisch et al, 2003) proposed rule-based protein and gene name extraction system called pro miner, which is based on the construction of ageneral-purpose dictionary along with different dictionaries of synonyms and an automatic cur ation procedure based on simple token model of protein names.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3535">
<title id=" W07-1012.xml">bionoculars extracting protein protein interactions from biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>they tend to lag the latest published research and are sensitive to the expression of the named entities.
</prevsent>
<prevsent>dictionaries of bne are typically laborious and expensive to build, and they are dependant on nomenclatures and specific species.
</prevsent>
</prevsection>
<citsent citstr=" W04-1221 ">
statistical approaches (collier etal., 2000; <papid> C00-1030 </papid>kazama et al, 2002; <papid> W02-0301 </papid>settles, 2004) <papid> W04-1221 </papid>typically improve recall at the expense of precision,but are more readily retarget able for new nomen clatures and organisms.</citsent>
<aftsection>
<nextsent>hybrid systems (tanabe and wilbur, 2002; mika and rost, 2004) attempt to take advantage of both approaches.
</nextsent>
<nextsent>although these approaches tend to generate acceptable recognition, they are heavily dependent on the type of data on which they are trained.(fukuda et al, 1998) proposed rule-based protein name extraction system called proper (pro tein proper-noun phrase extracting rules) system, which utilizes set of rules based on the surface form of text in conjunction with part-of-speech (pos) tagging to identify what looks like protein without referring to any specific bne dictionary.they reported 94.7% precision and 98.84% recall for the identification of bnes.
</nextsent>
<nextsent>the results that they achieved seem to be too specific to their training and test sets.
</nextsent>
<nextsent>(hanisch et al, 2003) proposed rule-based protein and gene name extraction system called pro miner, which is based on the construction of ageneral-purpose dictionary along with different dictionaries of synonyms and an automatic cur ation procedure based on simple token model of protein names.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3539">
<title id=" W07-1012.xml">bionoculars extracting protein protein interactions from biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the identification of bnes was done by consulting the gena gene name dictionary and family name dictionary.
</prevsent>
<prevsent>in extracting the biological functions of genes and proteins, their system reported recall of 64% and precision of 94%.
</prevsent>
</prevsection>
<citsent citstr=" P04-1025 ">
saric et al developed system to extract gene expression regulatory information in yeast as wellas other regulatory mechanisms such phosphoryla tion (saric et al, 2004; <papid> P04-1025 </papid>saric et al, 2006).</citsent>
<aftsection>
<nextsent>they used rule based named entity recognition module, which recognizes named entities via cascading finite state automata.
</nextsent>
<nextsent>they reported precision of 83-90% and 86-95% for the extraction of gene expression and phosphorylation regulatory information respectively.
</nextsent>
<nextsent>(leroy and chen, 2005) used linguistic parser sand concept spaces, which use generic cooccurrence based technique that extracts relevant medical phrases using noun chunker.
</nextsent>
<nextsent>their system employed umls (humphreys and lindberg, 1993), go (ashburner et al, 2000), and gena (koike and takagi, 2004) <papid> W04-3102 </papid>to further improve extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3540">
<title id=" W07-1012.xml">bionoculars extracting protein protein interactions from biomedical text </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>they reported precision of 83-90% and 86-95% for the extraction of gene expression and phosphorylation regulatory information respectively.
</prevsent>
<prevsent>(leroy and chen, 2005) used linguistic parser sand concept spaces, which use generic cooccurrence based technique that extracts relevant medical phrases using noun chunker.
</prevsent>
</prevsection>
<citsent citstr=" W04-3102 ">
their system employed umls (humphreys and lindberg, 1993), go (ashburner et al, 2000), and gena (koike and takagi, 2004) <papid> W04-3102 </papid>to further improve extraction.</citsent>
<aftsection>
<nextsent>their main purpose was entity identification and cross reference to other databases to obtain more knowledge about entities involved in the system.other extraction approaches such as the one reported on by (cooper and kershenbaum, 2005) utilized large manually curated dictionary of many possible combinations of gene/protein names and aliases from different databases and ontologies.they annotated their corpus using dictionary based longest matching technique.
</nextsent>
<nextsent>in addition, they used filtering with maximum entropy based named entity recognizer in order to remove the false positives that were generated from merging databases.the problem with this approach is the resulting inconsistencies from merging databases, which could hurt the effectiveness of the system.
</nextsent>
<nextsent>they reported recall of 87.1 % and precision of 78.5% in the relationship extraction task.work by (mack et al, 2004) used the munich information center for protein sequences (mips) for entity identification.
</nextsent>
<nextsent>their system was integrated inthe ibm unstructured information management architecture (uima) framework (ferrucci and lally, 2004) for tokenization, identification of entities, and extraction of relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3541">
<title id=" W07-1012.xml">bionoculars extracting protein protein interactions from biomedical text </title>
<section> bionoculars.  </section>
<citcontext>
<prevsection>
<prevsent>it then matches the generated patterns against arbitrary text to extract interactions and their respective partners.
</prevsent>
<prevsent>the system scored an f1-measure of 51.8% on the lll05 evaluation set.the aforementioned systems used either rule based approaches, which require manual intervention from domain experts, or statistical approaches,either supervised or semi-supervised, which also require manually curated training data.
</prevsent>
</prevsection>
<citsent citstr=" W06-1659 ">
bionoculars is relationship extraction system that based on fully unsupervised technique suggested by (hassan et al, 2006) <papid> W06-1659 </papid>to automatically extract protein-protein interaction from medical articles.</citsent>
<aftsection>
<nextsent>itcan be retargeted to different domains such as protein interactions in diseases.
</nextsent>
<nextsent>the only requirement is to compile domain specific taggers and dictionaries, which would aid the system in performing the required task.
</nextsent>
<nextsent>the approach uses an unsupervised graph-basedmutual reinforcement, which depends on the construction of generalized extraction patterns that could match instances of relationships (hassan et al., 2006).<papid> W06-1659 </papid></nextsent>
<nextsent>graph-based mutual reinforcement is similar to the idea of hubs and authorities in web pages depicted by the hits algorithm (kleinberg, 1998).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3544">
<title id=" W08-0330.xml">the role of pseudo references in mt evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one way to supplement the single human reference is to use pseudo references, or sentences produced by off-the-shelf mt systems, as stand-ins for human references.
</prevsent>
<prevsent>however, since pseudo references may be imperfect translations themselves, the comparisons cannot befully trusted.
</prevsent>
</prevsection>
<citsent citstr=" P07-1038 ">
previously, we have taken learning based approach to develop composite metric that combines measurements taken from multiple pseudo references (albrecht and hwa, 2007).<papid> P07-1038 </papid></citsent>
<aftsection>
<nextsent>experimental results suggested the approach to be promising; but those studies did not consider how well the metric might generalize across multiple years and differentlanguages.
</nextsent>
<nextsent>in this paper, we investigate the applicability of the pseudo-reference metrics under these more general conditions.using the wmt06 workshop shared-task results (koehn and monz, 2006) as training examples, we train metric that evaluates new sentences by comparing them against pseudo references produced by three off-the-shelf mt systems.
</nextsent>
<nextsent>we apply the learned metric to sentences from the wmt07shared-task (callison-burch et al, 2007b) and compare the metrics predictions against human judgments.
</nextsent>
<nextsent>we find that additional pseudo references improve correlations for automatic metrics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3545">
<title id=" W08-0330.xml">the role of pseudo references in mt evaluation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the metrics are trained using support vector regression with gaussian kernel as implemented in the svm-light package (joachims, 1999).
</prevsent>
<prevsent>the svm parameters are tuned via grid-search on development data, 20% of the full training set that has been reserved for this purpose.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
188we used three mt systems to generate pseudo ref erences: systran1, googlemt 2, and moses (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we chose these three systems because they are widely accessible and because they take relatively different approaches.
</nextsent>
<nextsent>moreover, although they have not all been human-evaluated in the pastwmt shared tasks, they are well-known for producing good translations.
</nextsent>
<nextsent>a metric is evaluated based on its spearman rank correlation coefficient between the scores it gave to the evaluative dataset and human assessments for the same data.
</nextsent>
<nextsent>the correlation coefficient is real number between -1, indicating perfect negative correlations, and +1, indicating perfect positive correlations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3546">
<title id=" W08-0330.xml">the role of pseudo references in mt evaluation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>a metric is evaluated based on its spearman rank correlation coefficient between the scores it gave to the evaluative dataset and human assessments for the same data.
</prevsent>
<prevsent>the correlation coefficient is real number between -1, indicating perfect negative correlations, and +1, indicating perfect positive correlations.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
two standard reference-based metrics, bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>are used for comparisons.</citsent>
<aftsection>
<nextsent>bleu is smoothed (lin and och, 2004), <papid> C04-1072 </papid>and it considers only matching up to bigrams because this has higher correlations with human judgments than when higher ordered n-grams are included.</nextsent>
<nextsent>the full experimental comparisons are summarized in table 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3547">
<title id=" W08-0330.xml">the role of pseudo references in mt evaluation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>a metric is evaluated based on its spearman rank correlation coefficient between the scores it gave to the evaluative dataset and human assessments for the same data.
</prevsent>
<prevsent>the correlation coefficient is real number between -1, indicating perfect negative correlations, and +1, indicating perfect positive correlations.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
two standard reference-based metrics, bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>are used for comparisons.</citsent>
<aftsection>
<nextsent>bleu is smoothed (lin and och, 2004), <papid> C04-1072 </papid>and it considers only matching up to bigrams because this has higher correlations with human judgments than when higher ordered n-grams are included.</nextsent>
<nextsent>the full experimental comparisons are summarized in table 1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3548">
<title id=" W08-0330.xml">the role of pseudo references in mt evaluation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the correlation coefficient is real number between -1, indicating perfect negative correlations, and +1, indicating perfect positive correlations.
</prevsent>
<prevsent>two standard reference-based metrics, bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>are used for comparisons.</prevsent>
</prevsection>
<citsent citstr=" C04-1072 ">
bleu is smoothed (lin and och, 2004), <papid> C04-1072 </papid>and it considers only matching up to bigrams because this has higher correlations with human judgments than when higher ordered n-grams are included.</citsent>
<aftsection>
<nextsent>the full experimental comparisons are summarized in table 1.
</nextsent>
<nextsent>each cell shows the correlation coefficient between the human judgments and metric (column) that uses particular kind of references (row) for some evaluation dataset (block row).
</nextsent>
<nextsent>the role of learning with the exception of the german-english data, the learned metrics had higher correlations with human judges than the baselines, which used standard metrics with single human reference.
</nextsent>
<nextsent>on the other hand, results suggest that pseudo references often also improve correlations for standard metrics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3549">
<title id=" W07-2076.xml">ubcumb combining unsupervised and supervised systems for all words wsd </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>thus, this paper describes both the unsupervised system (ubc-umb-1), and the combined supervised system (ubc-umb-2) submitted to the all-words task.
</prevsent>
<prevsent>our motivation in building unsupervised systems comes from the difficulty of creating hand-taggeddata for all words and all languages, which is colloquially known as the knowledge acquisition bottleneck.
</prevsent>
</prevsection>
<citsent citstr=" P06-1013 ">
there have also been promising results in recent work on the combination of unsupervised approaches that suggest the gap with respect to supervised systems is narrowing (brody et al, 2006).<papid> P06-1013 </papid>the remainder of the paper is organized as follows.</citsent>
<aftsection>
<nextsent>first we describe the disambiguation algorithms in section 2.
</nextsent>
<nextsent>next, the development experiments are presented in section 3, and our final submissions and results in section 4.
</nextsent>
<nextsent>finally, we summarize our conclusions in section 5.
</nextsent>
<nextsent>in this section, we will describe the standalone algorithms (three unsupervised and one supervised) andthe combination schemes we explored.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3550">
<title id=" W07-2076.xml">ubcumb combining unsupervised and supervised systems for all words wsd </title>
<section> algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>topic signatures (agirre and de lacalle, 2004) are lists of words related to particular sense.
</prevsent>
<prevsent>they canbe built from variety of sources, and be used directly to perform wsd.
</prevsent>
</prevsection>
<citsent citstr=" W06-1663 ">
cuadros and rigau (2006) <papid> W06-1663 </papid>present detailed evaluation of topic signatures built from variety of knowledge sources.</citsent>
<aftsection>
<nextsent>in this work we built those coming from the following:?
</nextsent>
<nextsent>the relations in the multilingual central repository (ts-mcr)?
</nextsent>
<nextsent>the relations in the extended wordnet (ts xwn)in order to apply this resource for wsd, we simply measured the word-overlap between the target context and each of the senses of the target word.the sense with highest overlap is chosen as the correct sense.
</nextsent>
<nextsent>350 2.2 relatives in context (ric).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3551">
<title id=" W07-2076.xml">ubcumb combining unsupervised and supervised systems for all words wsd </title>
<section> algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>we tested this voting approach both for the unsupervised and supervised settings.the second method could only be applied in combination with the supervised knn system.
</prevsent>
<prevsent>the idea was to include the unsupervised predictions as weighted features for the supervised system.
</prevsent>
</prevsection>
<citsent citstr=" J01-3001 ">
we refer to this method as stacking?, and it has been previously used to integrate heterogeneous knowledge sources for wsd (stevenson and wilks, 2001).<papid> J01-3001 </papid></citsent>
<aftsection>
<nextsent>we tested the single algorithms and their combination over both semcor and the training distribution of the semeval-2007 lexical-sample subtask of task 17 (s07ls for short).
</nextsent>
<nextsent>the goal of these experiments was to obtain an estimate of the expected performance, and submit the most promising configuration.
</nextsent>
<nextsent>we present first the tests on the unsupervised setting, and then the supervised setting.
</nextsent>
<nextsent>it is important to note that the hand-tagged corpora was not used to fine-tune the parameters of the unsupervised algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3552">
<title id=" W07-1805.xml">handling outofgrammar commands in mobile speech interaction using backoff filler models </title>
<section> backoff approach.  </section>
<citcontext>
<prevsection>
<prevsent>using partial backoff rules prevents degradation of confidence scores for ing constituents and improves partial recognitions, as we show in section 4.
</prevsent>
<prevsent>partial backoff rules not only handle oog slot commands where, for example, the name slot is not recognized, but also many types of segmentation, deletion and substitution commands as well.
</prevsent>
</prevsection>
<citsent citstr=" E03-1075 ">
following prior research (gorrell et al, 2002; hockey et al, 2003), <papid> E03-1075 </papid>we sought to improve partial recognitions so that the system could provide feedback to users on what was recognized, and to encourage them to stay within the c&c; syntax.</citsent>
<aftsection>
<nextsent>clarification dialogue with implicit instruction of the syntax might proceed as follows: if partial recognition only corresponded to one cfg rule, then the system could assume the semantics of that rule and remind the user of the proper syntax.
</nextsent>
<nextsent>on the other hand, if partial recognition corresponded to more than one rule, then disambiguation dialogue could relate the proper syntax for the choices.
</nextsent>
<nextsent>for example, suppose user says telephone bob?, using the oog word telephone?.
</nextsent>
<nextsent>although the original cfg would most likely mis recognize or even drop this command, our approach would obtain partial recognition with higher confidence score for the contact slot.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3554">
<title id=" W07-1521.xml">building chinese sense annotated corpus with the help of software tools </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it was argued that no fundamental progress in wsd could be made until large scale lexical resources were built (veronis, 2003).
</prevsent>
<prevsent>in english word sense annotated corpus sem cor (semantic concordances) (landes et al, 1999) has been built, which was later trained and tested by many wsd systems and stimulated large amounts of wsd work.
</prevsent>
</prevsection>
<citsent citstr=" W06-0608 ">
in japanese the hinoki sense bank is constructed (tanaka et al, 2006).<papid> W06-0608 </papid></citsent>
<aftsection>
<nextsent>in the field of chinese corpus construction, plenty of attention has been paid to pos tagging and syntactic structures bracketing, for instance the penn chinese treebank (xue et al, 2002) <papid> C02-1145 </papid>and sinica corpus (huang et al, 1992), but very limited work has been done with semantic knowledge annotation.</nextsent>
<nextsent>huang et al (2004) introduced the sinica sense-based lexical knowledge base, but as is well known, chinese pervasive in taiwan is not the same as mandarin chinese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3555">
<title id=" W07-1521.xml">building chinese sense annotated corpus with the help of software tools </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in english word sense annotated corpus sem cor (semantic concordances) (landes et al, 1999) has been built, which was later trained and tested by many wsd systems and stimulated large amounts of wsd work.
</prevsent>
<prevsent>in japanese the hinoki sense bank is constructed (tanaka et al, 2006).<papid> W06-0608 </papid></prevsent>
</prevsection>
<citsent citstr=" C02-1145 ">
in the field of chinese corpus construction, plenty of attention has been paid to pos tagging and syntactic structures bracketing, for instance the penn chinese treebank (xue et al, 2002) <papid> C02-1145 </papid>and sinica corpus (huang et al, 1992), but very limited work has been done with semantic knowledge annotation.</citsent>
<aftsection>
<nextsent>huang et al (2004) introduced the sinica sense-based lexical knowledge base, but as is well known, chinese pervasive in taiwan is not the same as mandarin chinese.
</nextsent>
<nextsent>senseval-3 provides chinese word sense annotated corpus, which contains 20 words and 15 sentences per meaning for most words, but obviously the data is too limited to achieve wide coverage, high accuracy wsd systems.
</nextsent>
<nextsent>this paper is devoted to building large-scale chinese corpus annotated with word senses.
</nextsent>
<nextsent>a small part of the chinese sense annotated corpus has been adopted as one of the semeval-2007 tasks namely multilingual chinese-english lexical sample task?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3556">
<title id=" W07-1521.xml">building chinese sense annotated corpus with the help of software tools </title>
<section> word sense annotating.  </section>
<citcontext>
<prevsection>
<prevsent>this will in turn save 16% of the annotation effort compared with the sense annotating before the preprocessing of pos tagging.
</prevsent>
<prevsent>fig.1.the overall procedure along with the software tools
</prevsent>
</prevsection>
<citsent citstr=" C02-2007 ">
the resulting lexical knowledge base in this project will contain three major components: 1) corpus annotated with chinese word senses namely chinese senses pool (csp); 2) lexicon containing sense distinction and description namely chinese semantic dictionary (csd); 3) the linking between the csd and the chinese concept dictionary (ccd) (liu et al, 2002).<papid> C02-2007 </papid></citsent>
<aftsection>
<nextsent>the corpus csp, the lexicon csd and ccd constitute highly relational and tightly integrated system: 1) in csd the sense distinctions are described relying on the corpus; 2) in csp the word occurrences are assigned sense tags according to the sense en 126 try specified in csd; 3) the linking between the sense entry in csd and ccd synsets are established.
</nextsent>
<nextsent>the dynamic model is shown in figure 2.
</nextsent>
<nextsent>a software tool is developed in java to be used as the word sense annotating interface (figure 3), which embodies the spirit of the dynamic model properly.
</nextsent>
<nextsent>3.1 sense describing in the lexicon and sense.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3558">
<title id=" W08-0503.xml">zymake a computational workflow system for machine learning and natural language processing </title>
<section> other approaches.  </section>
<citcontext>
<prevsection>
<prevsent>this is passed to pegasus, which instantiates the dag with instances of the described resources and passes it to condor for actual execution.
</prevsent>
<prevsent>the system has been used for large-scale scientific experiments, such as earthquake simulation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
however, we believe that the added complexity of the input that user has to provide over zymakes simple shell-like syntax will mean typical machine learning or natural language processing researcher will find zymake easier to use.the gate and uima architectures focus specifically on the management of components for language processing (cunningham et al, 2002; <papid> P02-1022 </papid>ferrucci and lally, 2004).</citsent>
<aftsection>
<nextsent>while zymake knows nothing about the structure of the files it manages, these systems provide common format for textual annotations which all components must use.
</nextsent>
<nextsent>gate provides graphical user interface for running components and for viewing and producing annotations.uima provides framework not just for running experiments but for data analysis and application deployment.
</nextsent>
<nextsent>compared to writing zymake script, however, the requirements for using these systems to manage an experiment are greater.
</nextsent>
<nextsent>in addition,both these architectures most naturally support com 11 ponents written in java (and in the case of uima, c++).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3559">
<title id=" W07-1102.xml">distinguishing sub types of multiword expressions using linguistically motivated statistical measures </title>
<section> statistical measures of semantic.  </section>
<citcontext>
<prevsection>
<prevsent>we refer to this group of measures as inst.
</prevsent>
<prevsent>3.2 measuring fixedness.
</prevsent>
</prevsection>
<citsent citstr=" E06-1043 ">
to measure fixed ness, we use statistical measures of lexical, syntactic, and overall fixed ness that we have developed in previous study (fazly and stevenson, 2006), <papid> E06-1043 </papid>as well as some new measures we introducehere.</citsent>
<aftsection>
<nextsent>the following paragraphs give brief description of each.fixednesslex quantifies the degree of lexical fixed ness of the target combination, ,n?, by comparing its strength of association (measured by pmi) with those of its lexical variants.
</nextsent>
<nextsent>like lin (1999),<papid> P99-1041 </papid>we generate lexical variants of the target automatically by replacing either the verb or the noun constituent by semantically similar word from the automatically-built thesaurus of lin (1998).<papid> P98-2127 </papid></nextsent>
<nextsent>we then use standard statistic, the -score, to calculate fixednesslex: fixednesslex(v , n) .= pmi(v , n) ? pmi std (2)where pmi is the mean and std the standard deviation over the pmi of the target and all its variants.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3560">
<title id=" W07-1102.xml">distinguishing sub types of multiword expressions using linguistically motivated statistical measures </title>
<section> statistical measures of semantic.  </section>
<citcontext>
<prevsection>
<prevsent>to measure fixed ness, we use statistical measures of lexical, syntactic, and overall fixed ness that we have developed in previous study (fazly and stevenson, 2006), <papid> E06-1043 </papid>as well as some new measures we introducehere.</prevsent>
<prevsent>the following paragraphs give brief description of each.fixednesslex quantifies the degree of lexical fixed ness of the target combination, ,n?, by comparing its strength of association (measured by pmi) with those of its lexical variants.</prevsent>
</prevsection>
<citsent citstr=" P99-1041 ">
like lin (1999),<papid> P99-1041 </papid>we generate lexical variants of the target automatically by replacing either the verb or the noun constituent by semantically similar word from the automatically-built thesaurus of lin (1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>we then use standard statistic, the -score, to calculate fixednesslex: fixednesslex(v , n) .= pmi(v , n) ? pmi std (2)where pmi is the mean and std the standard deviation over the pmi of the target and all its variants.
</nextsent>
<nextsent>fixednesssyn quantifies the degree of syntactic fixed ness of the target combination, by comparing its behaviour in text with the behaviour of typical verb object, both defined as probability distributions over predefined set of patterns.
</nextsent>
<nextsent>we use standard information-theoretic measure, relative entropy, 11 det:null nsg det:null npl det:a/an nsg det:the nsg det:the npl det:dem nsg det:dem npl det:poss nsg det:poss npl det:other nsg,pl det:any nsg,pl be vpassive table 2: patterns for syntactic fixed ness measure.to calculate the divergence between the two distributions as follows: fixednesssyn (v , n) .= d(p(pt |v ,n) ||p(pt)) = ? ptkp p(ptk | , n) log p(ptk | , n) p(ptk ) (3) where is the set of patterns (shown in table 2) known to be relevant to syntactic fixed ness in lvcsand idms.
</nextsent>
<nextsent>p(pt | , n) represents the syntactic behaviour of the target, and p(pt) represents the typical syntactic behaviour over all verb object pairs.fixednesssyn does not show which syntactic pattern the target prefers the most.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3561">
<title id=" W07-1102.xml">distinguishing sub types of multiword expressions using linguistically motivated statistical measures </title>
<section> statistical measures of semantic.  </section>
<citcontext>
<prevsection>
<prevsent>to measure fixed ness, we use statistical measures of lexical, syntactic, and overall fixed ness that we have developed in previous study (fazly and stevenson, 2006), <papid> E06-1043 </papid>as well as some new measures we introducehere.</prevsent>
<prevsent>the following paragraphs give brief description of each.fixednesslex quantifies the degree of lexical fixed ness of the target combination, ,n?, by comparing its strength of association (measured by pmi) with those of its lexical variants.</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
like lin (1999),<papid> P99-1041 </papid>we generate lexical variants of the target automatically by replacing either the verb or the noun constituent by semantically similar word from the automatically-built thesaurus of lin (1998).<papid> P98-2127 </papid></citsent>
<aftsection>
<nextsent>we then use standard statistic, the -score, to calculate fixednesslex: fixednesslex(v , n) .= pmi(v , n) ? pmi std (2)where pmi is the mean and std the standard deviation over the pmi of the target and all its variants.
</nextsent>
<nextsent>fixednesssyn quantifies the degree of syntactic fixed ness of the target combination, by comparing its behaviour in text with the behaviour of typical verb object, both defined as probability distributions over predefined set of patterns.
</nextsent>
<nextsent>we use standard information-theoretic measure, relative entropy, 11 det:null nsg det:null npl det:a/an nsg det:the nsg det:the npl det:dem nsg det:dem npl det:poss nsg det:poss npl det:other nsg,pl det:any nsg,pl be vpassive table 2: patterns for syntactic fixed ness measure.to calculate the divergence between the two distributions as follows: fixednesssyn (v , n) .= d(p(pt |v ,n) ||p(pt)) = ? ptkp p(ptk | , n) log p(ptk | , n) p(ptk ) (3) where is the set of patterns (shown in table 2) known to be relevant to syntactic fixed ness in lvcsand idms.
</nextsent>
<nextsent>p(pt | , n) represents the syntactic behaviour of the target, and p(pt) represents the typical syntactic behaviour over all verb object pairs.fixednesssyn does not show which syntactic pattern the target prefers the most.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3563">
<title id=" W07-1102.xml">distinguishing sub types of multiword expressions using linguistically motivated statistical measures </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>interestingly, fixd features achieve the highest accuracy, 50%, with relative error reduction of33%, showing that fixed ness is salient aspect of semantic idiosyncrasy.
</prevsent>
<prevsent>comp features achieve reasonably good accuracy, around 40%, though still notably lower than the accuracy of fixd features.
</prevsent>
</prevsection>
<citsent citstr=" W03-1810 ">
this is especially interesting since much previous research has focused solely on the non-compositionality of mwes to identify them (mccarthy et al, 2003; <papid> W03-1810 </papid>baldwin et al., 2003; <papid> W03-1812 </papid>bannard et al, 2003).<papid> W03-1809 </papid></citsent>
<aftsection>
<nextsent>our results confirm the relevance of this property, while at the same time revealing its insufficiency.
</nextsent>
<nextsent>interestingly, features related to the semantic properties of the constituents, verb and nsem, overall perform comparably to the compositionality features.
</nextsent>
<nextsent>however, closer look attheir performance on the individual classes (see section 5.2) reveals that, unlike comp, they are mainly good at identifying items from certain classes.
</nextsent>
<nextsent>as hypothesized, we achieve the highest performance, an accuracy of 58% and relative error reduction of 44%, when we combine all features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3565">
<title id=" W07-1102.xml">distinguishing sub types of multiword expressions using linguistically motivated statistical measures </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>interestingly, fixd features achieve the highest accuracy, 50%, with relative error reduction of33%, showing that fixed ness is salient aspect of semantic idiosyncrasy.
</prevsent>
<prevsent>comp features achieve reasonably good accuracy, around 40%, though still notably lower than the accuracy of fixd features.
</prevsent>
</prevsection>
<citsent citstr=" W03-1812 ">
this is especially interesting since much previous research has focused solely on the non-compositionality of mwes to identify them (mccarthy et al, 2003; <papid> W03-1810 </papid>baldwin et al., 2003; <papid> W03-1812 </papid>bannard et al, 2003).<papid> W03-1809 </papid></citsent>
<aftsection>
<nextsent>our results confirm the relevance of this property, while at the same time revealing its insufficiency.
</nextsent>
<nextsent>interestingly, features related to the semantic properties of the constituents, verb and nsem, overall perform comparably to the compositionality features.
</nextsent>
<nextsent>however, closer look attheir performance on the individual classes (see section 5.2) reveals that, unlike comp, they are mainly good at identifying items from certain classes.
</nextsent>
<nextsent>as hypothesized, we achieve the highest performance, an accuracy of 58% and relative error reduction of 44%, when we combine all features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3566">
<title id=" W07-1102.xml">distinguishing sub types of multiword expressions using linguistically motivated statistical measures </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>interestingly, fixd features achieve the highest accuracy, 50%, with relative error reduction of33%, showing that fixed ness is salient aspect of semantic idiosyncrasy.
</prevsent>
<prevsent>comp features achieve reasonably good accuracy, around 40%, though still notably lower than the accuracy of fixd features.
</prevsent>
</prevsection>
<citsent citstr=" W03-1809 ">
this is especially interesting since much previous research has focused solely on the non-compositionality of mwes to identify them (mccarthy et al, 2003; <papid> W03-1810 </papid>baldwin et al., 2003; <papid> W03-1812 </papid>bannard et al, 2003).<papid> W03-1809 </papid></citsent>
<aftsection>
<nextsent>our results confirm the relevance of this property, while at the same time revealing its insufficiency.
</nextsent>
<nextsent>interestingly, features related to the semantic properties of the constituents, verb and nsem, overall perform comparably to the compositionality features.
</nextsent>
<nextsent>however, closer look attheir performance on the individual classes (see section 5.2) reveals that, unlike comp, they are mainly good at identifying items from certain classes.
</nextsent>
<nextsent>as hypothesized, we achieve the highest performance, an accuracy of 58% and relative error reduction of 44%, when we combine all features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3573">
<title id=" W07-1102.xml">distinguishing sub types of multiword expressions using linguistically motivated statistical measures </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>particularly important for the identification of highly idiosyncratic mwes, such as lvcs and idms.
</prevsent>
<prevsent>much recent work on classifying mwes focuses on determining different levels of compositionality inverb+particle combinations using measure of distributional similarity (mccarthy et al, 2003; <papid> W03-1810 </papid>baldwin et al, 2003; <papid> W03-1812 </papid>bannard et al, 2003).<papid> W03-1809 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-1207 ">
another group of research attempts to classify particular mwe subtype, such as verb-particle constructions (vpcs) orlvcs, according to some fine-grained semantic criteria (wanner, 2004; uchiyama et al, 2005; cook and stevenson, 2006).<papid> W06-1207 </papid></citsent>
<aftsection>
<nextsent>here, we distinguish sub types of mwes that are defined according to coarse-grained distinctions in their degree of semantic idiosyncrasy.wermter and hahn (2004) <papid> C04-1141 </papid>recognize the importance of distinguishing mwe sub types that are similar to our four classes, but only focus on separating mwes as one single class from literal combina tions.</nextsent>
<nextsent>for this, they use measure that draws on the limited modifiability of mwes, in addition to their expected high frequency.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3574">
<title id=" W07-1102.xml">distinguishing sub types of multiword expressions using linguistically motivated statistical measures </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>much recent work on classifying mwes focuses on determining different levels of compositionality inverb+particle combinations using measure of distributional similarity (mccarthy et al, 2003; <papid> W03-1810 </papid>baldwin et al, 2003; <papid> W03-1812 </papid>bannard et al, 2003).<papid> W03-1809 </papid></prevsent>
<prevsent>another group of research attempts to classify particular mwe subtype, such as verb-particle constructions (vpcs) orlvcs, according to some fine-grained semantic criteria (wanner, 2004; uchiyama et al, 2005; cook and stevenson, 2006).<papid> W06-1207 </papid></prevsent>
</prevsection>
<citsent citstr=" C04-1141 ">
here, we distinguish sub types of mwes that are defined according to coarse-grained distinctions in their degree of semantic idiosyncrasy.wermter and hahn (2004) <papid> C04-1141 </papid>recognize the importance of distinguishing mwe sub types that are similar to our four classes, but only focus on separating mwes as one single class from literal combina tions.</citsent>
<aftsection>
<nextsent>for this, they use measure that draws on the limited modifiability of mwes, in addition to their expected high frequency.
</nextsent>
<nextsent>krenn and evert (2001)attempt to separate german idioms, lvcs, and literal phrases (of the form verb+prepositional phrase).they treat lvcs and idioms as institutionalized expressions, and use frequency and several association measures, such as pmi, for the task.
</nextsent>
<nextsent>the main goal of their work is to find which association measures are particularly suited for identifying which of these classes.
</nextsent>
<nextsent>here, we look at properties of mwes other than their institutionalization (the latter we quantify using an association measure).the work most similar to ours is that of venkatapathy and joshi (2005).<papid> H05-1113 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3575">
<title id=" W07-1102.xml">distinguishing sub types of multiword expressions using linguistically motivated statistical measures </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>krenn and evert (2001)attempt to separate german idioms, lvcs, and literal phrases (of the form verb+prepositional phrase).they treat lvcs and idioms as institutionalized expressions, and use frequency and several association measures, such as pmi, for the task.
</prevsent>
<prevsent>the main goal of their work is to find which association measures are particularly suited for identifying which of these classes.
</prevsent>
</prevsection>
<citsent citstr=" H05-1113 ">
here, we look at properties of mwes other than their institutionalization (the latter we quantify using an association measure).the work most similar to ours is that of venkatapathy and joshi (2005).<papid> H05-1113 </papid></citsent>
<aftsection>
<nextsent>they propose minimally supervised classification schema that incorporates variety of features to group verb+noun combinations according to their level of compositionality.
</nextsent>
<nextsent>their work has the advantage of requiring only small amount of manually-labeled training data.
</nextsent>
<nextsent>however,their classes are defined on the basis of compositionality only.
</nextsent>
<nextsent>here, we consider classes that are linguistically salient, and moreover need special treatment within computational system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3576">
<title id=" W07-1210.xml">semantic composition with robust minimal recur sion semantics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>no such cases have been found.
</prevsent>
<prevsent>79
</prevsent>
</prevsection>
<citsent citstr=" C04-1180 ">
bos et al (2004) <papid> C04-1180 </papid>and bos (2005) derive semantic interpretations from wide-coverage categorial grammar. there are several differences between this and rasp-rmrs, but the most important arise from the differences between ccg and rasp.</citsent>
<aftsection>
<nextsent>the ccg parser relies on having detailed subcategorization information (automatically derived from the ccg bank which was semi-automatically constructed from the penn treebank), and thus semantic construction can assume that the arity of the predicate is lexicallyavailable.
</nextsent>
<nextsent>however, because ccg is purely lexical ist, phenomena that we expect to have construction semantics (e.g., compound nouns, larger numbers) have to be dealt with in post-parsing phase rather than compositionally.spreyer and frank (2005) demonstrate rmrs construction from tiger dependencies, but do not attempt to match deep parser output.
</nextsent>
<nextsent>we have demonstrated that the mrs algebra, originally intended as formalisation of some aspects of semantic composition in constraint-based grammars, can be extended to rmrs and other types of grammar framework and can be used as the basis of full implementation of composition.
</nextsent>
<nextsent>the algebra can thus be used much more widely than originally envisaged and could be exploited by wide range of parsers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3577">
<title id=" W07-1210.xml">semantic composition with robust minimal recur sion semantics </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>we have demonstrated that the mrs algebra, originally intended as formalisation of some aspects of semantic composition in constraint-based grammars, can be extended to rmrs and other types of grammar framework and can be used as the basis of full implementation of composition.
</prevsent>
<prevsent>the algebra can thus be used much more widely than originally envisaged and could be exploited by wide range of parsers.
</prevsent>
</prevsection>
<citsent citstr=" P04-1032 ">
useful properties concerning monotonicityand scope (see fuchss et al (2004)) <papid> P04-1032 </papid>are thus guaranteed for range of grammars.</citsent>
<aftsection>
<nextsent>phrasal-level compatibility of rmrs (to the extent that this is syntactically possible) is also an important result.
</nextsent>
<nextsent>the main practical outcome of this work so far has been semantic component for the rasp system which produces representations compatible with that of theerg without compromising rasp speed or robustness.
</nextsent>
<nextsent>rasp-rmrss have already been used in systems for question answering, information extraction,email response, creative authoring and ontology extraction (e.g., uszkoreit et al (2004), watson et al (2003), herbelot and copestake (2006)).
</nextsent>
<nextsent>acknowledgements this work was funded by epsrc (ep/c010035/1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3578">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are preferred because they give precise and in-depth analyses for explaining linguistic phenomena, such as pas siv ization, control verbs and relative clauses.
</prevsent>
<prevsent>themain difficulty of developing parsers in these formalisms was how to model well-defined probabilistic model for graph structures such as feature structures.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></citsent>
<aftsection>
<nextsent>following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></nextsent>
<nextsent>an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3579">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are preferred because they give precise and in-depth analyses for explaining linguistic phenomena, such as pas siv ization, control verbs and relative clauses.
</prevsent>
<prevsent>themain difficulty of developing parsers in these formalisms was how to model well-defined probabilistic model for graph structures such as feature structures.
</prevsent>
</prevsection>
<citsent citstr=" J97-4005 ">
this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></citsent>
<aftsection>
<nextsent>following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></nextsent>
<nextsent>an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3581">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are preferred because they give precise and in-depth analyses for explaining linguistic phenomena, such as pas siv ization, control verbs and relative clauses.
</prevsent>
<prevsent>themain difficulty of developing parsers in these formalisms was how to model well-defined probabilistic model for graph structures such as feature structures.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></citsent>
<aftsection>
<nextsent>following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></nextsent>
<nextsent>an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3583">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are preferred because they give precise and in-depth analyses for explaining linguistic phenomena, such as pas siv ization, control verbs and relative clauses.
</prevsent>
<prevsent>themain difficulty of developing parsers in these formalisms was how to model well-defined probabilistic model for graph structures such as feature structures.
</prevsent>
</prevsection>
<citsent citstr=" P00-1061 ">
this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></citsent>
<aftsection>
<nextsent>following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></nextsent>
<nextsent>an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3585">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are preferred because they give precise and in-depth analyses for explaining linguistic phenomena, such as pas siv ization, control verbs and relative clauses.
</prevsent>
<prevsent>themain difficulty of developing parsers in these formalisms was how to model well-defined probabilistic model for graph structures such as feature structures.
</prevsent>
</prevsection>
<citsent citstr=" N04-1013 ">
this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></citsent>
<aftsection>
<nextsent>following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></nextsent>
<nextsent>an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3587">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are preferred because they give precise and in-depth analyses for explaining linguistic phenomena, such as pas siv ization, control verbs and relative clauses.
</prevsent>
<prevsent>themain difficulty of developing parsers in these formalisms was how to model well-defined probabilistic model for graph structures such as feature structures.
</prevsent>
</prevsection>
<citsent citstr=" P05-1011 ">
this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></citsent>
<aftsection>
<nextsent>following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></nextsent>
<nextsent>an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3590">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>themain difficulty of developing parsers in these formalisms was how to model well-defined probabilistic model for graph structures such as feature structures.
</prevsent>
<prevsent>this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1036 ">
following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></citsent>
<aftsection>
<nextsent>an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></nextsent>
<nextsent>super tagging is process where words in an input sentence are tagged with supertags,?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3591">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>themain difficulty of developing parsers in these formalisms was how to model well-defined probabilistic model for graph structures such as feature structures.
</prevsent>
<prevsent>this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></citsent>
<aftsection>
<nextsent>an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></nextsent>
<nextsent>super tagging is process where words in an input sentence are tagged with supertags,?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3611">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>themain difficulty of developing parsers in these formalisms was how to model well-defined probabilistic model for graph structures such as feature structures.
</prevsent>
<prevsent>this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-1511 ">
following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></citsent>
<aftsection>
<nextsent>an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></nextsent>
<nextsent>super tagging is process where words in an input sentence are tagged with supertags,?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3623">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></prevsent>
<prevsent>following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-0307 ">
an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>super tagging is process where words in an input sentence are tagged with supertags,?
</nextsent>
<nextsent>which are lexical entries in lexicalized grammars, e.g., elementary trees in ltag, lexical categories in ccg, and lexical entries in hpsg.
</nextsent>
<nextsent>the concept of super tagging is simple and interesting, and the effects of this were recently demonstrated in the case of ccg parser (clark and curran, 2004<papid> P04-1014 </papid>a)with the result of drastic improvement in the parsing speed.</nextsent>
<nextsent>wang and harper (2004) <papid> W04-0307 </papid>also demonstrated the effects of super tagging with statistical constraint dependency grammar (cdg) parser by showing accuracy as high as the state-of-the-art parsers, and foth et al (2006) <papid> P06-1037 </papid>and foth and menzel(2006) <papid> P06-1041 </papid>reported that accuracy was significantly improved by incorporating the super tagging probabilities into manually tuned weighted cdg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3625">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></prevsent>
<prevsent>following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-1619 ">
an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>super tagging is process where words in an input sentence are tagged with supertags,?
</nextsent>
<nextsent>which are lexical entries in lexicalized grammars, e.g., elementary trees in ltag, lexical categories in ccg, and lexical entries in hpsg.
</nextsent>
<nextsent>the concept of super tagging is simple and interesting, and the effects of this were recently demonstrated in the case of ccg parser (clark and curran, 2004<papid> P04-1014 </papid>a)with the result of drastic improvement in the parsing speed.</nextsent>
<nextsent>wang and harper (2004) <papid> W04-0307 </papid>also demonstrated the effects of super tagging with statistical constraint dependency grammar (cdg) parser by showing accuracy as high as the state-of-the-art parsers, and foth et al (2006) <papid> P06-1037 </papid>and foth and menzel(2006) <papid> P06-1041 </papid>reported that accuracy was significantly improved by incorporating the super tagging probabilities into manually tuned weighted cdg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3626">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></prevsent>
<prevsent>following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-1037 ">
an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>super tagging is process where words in an input sentence are tagged with supertags,?
</nextsent>
<nextsent>which are lexical entries in lexicalized grammars, e.g., elementary trees in ltag, lexical categories in ccg, and lexical entries in hpsg.
</nextsent>
<nextsent>the concept of super tagging is simple and interesting, and the effects of this were recently demonstrated in the case of ccg parser (clark and curran, 2004<papid> P04-1014 </papid>a)with the result of drastic improvement in the parsing speed.</nextsent>
<nextsent>wang and harper (2004) <papid> W04-0307 </papid>also demonstrated the effects of super tagging with statistical constraint dependency grammar (cdg) parser by showing accuracy as high as the state-of-the-art parsers, and foth et al (2006) <papid> P06-1037 </papid>and foth and menzel(2006) <papid> P06-1041 </papid>reported that accuracy was significantly improved by incorporating the super tagging probabilities into manually tuned weighted cdg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3627">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></prevsent>
<prevsent>following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-1041 ">
an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>super tagging is process where words in an input sentence are tagged with supertags,?
</nextsent>
<nextsent>which are lexical entries in lexicalized grammars, e.g., elementary trees in ltag, lexical categories in ccg, and lexical entries in hpsg.
</nextsent>
<nextsent>the concept of super tagging is simple and interesting, and the effects of this were recently demonstrated in the case of ccg parser (clark and curran, 2004<papid> P04-1014 </papid>a)with the result of drastic improvement in the parsing speed.</nextsent>
<nextsent>wang and harper (2004) <papid> W04-0307 </papid>also demonstrated the effects of super tagging with statistical constraint dependency grammar (cdg) parser by showing accuracy as high as the state-of-the-art parsers, and foth et al (2006) <papid> P06-1037 </papid>and foth and menzel(2006) <papid> P06-1041 </papid>reported that accuracy was significantly improved by incorporating the super tagging probabilities into manually tuned weighted cdg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3628">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this was overcome by probabilistic model which provides probabilities of discriminating correct parse tree among candidates of parse trees in log-linear model or maximum entropy model (berger et al, 1996) <papid> J96-1002 </papid>with many features for parse trees (abney, 1997; <papid> J97-4005 </papid>johnson et al, 1999; <papid> P99-1069 </papid>riezler et al, 2000; <papid> P00-1061 </papid>malouf and van noord, 2004; kaplan et al, 2004; <papid> N04-1013 </papid>miyao and tsujii, 2005).<papid> P05-1011 </papid></prevsent>
<prevsent>following this discriminative approach, techniques for efficiency were investigated for estimation (geman and johnson, 2002; <papid> P02-1036 </papid>miyao and tsujii, 2002; malouf and van noord, 2004) and parsing (clark and curran, 2004<papid> P04-1014 </papid>b; clark and curran, 2004<papid> P04-1014 </papid>a; ninomiya et al, 2005).<papid> W05-1511 </papid></prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
an interesting approach to the problem of parsing efficiency was using super tagging (clark and cur 60 ran, 2004b; clark and curran, 2004<papid> P04-1014 </papid>a; wang, 2003; wang and harper, 2004; <papid> W04-0307 </papid>nasr and rambow, 2004; ninomiya et al, 2006; <papid> W06-1619 </papid>foth et al, 2006; <papid> P06-1037 </papid>foth and menzel, 2006), <papid> P06-1041 </papid>which was originally developed for lexicalized tree adjoining grammars (ltag) (ban galore and joshi, 1999).<papid> J99-2004 </papid></citsent>
<aftsection>
<nextsent>super tagging is process where words in an input sentence are tagged with supertags,?
</nextsent>
<nextsent>which are lexical entries in lexicalized grammars, e.g., elementary trees in ltag, lexical categories in ccg, and lexical entries in hpsg.
</nextsent>
<nextsent>the concept of super tagging is simple and interesting, and the effects of this were recently demonstrated in the case of ccg parser (clark and curran, 2004<papid> P04-1014 </papid>a)with the result of drastic improvement in the parsing speed.</nextsent>
<nextsent>wang and harper (2004) <papid> W04-0307 </papid>also demonstrated the effects of super tagging with statistical constraint dependency grammar (cdg) parser by showing accuracy as high as the state-of-the-art parsers, and foth et al (2006) <papid> P06-1037 </papid>and foth and menzel(2006) <papid> P06-1041 </papid>reported that accuracy was significantly improved by incorporating the super tagging probabilities into manually tuned weighted cdg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3691">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> hpsg and probabilistic models.  </section>
<citcontext>
<prevsection>
<prevsent>u ufu(t ) ) zw = ? ? exp (?
</prevsent>
<prevsent>u ufu(t ?) ) ,where is model parameter, fu is feature function that represents characteristic of parse tree , and zw is the sum over the set of all possible parse trees for the sentence.
</prevsent>
</prevsection>
<citsent citstr=" W02-2018 ">
intuitively, the probability is defined as the normalized product of the weights exp(u) when characteristic corresponding to fu appears in parse result . the model parameters, u, are estimated using numerical optimization methods (malouf, 2002) <papid> W02-2018 </papid>to maximize the log-likelihood of the training data.however, the above model cannot be easily estimated because the estimation requires the computation of p(t |w) for all parse candidates assigned to sentence w. because the number of parse candidates is exponentially related to the length of the sentence, the estimation is intractable for long sentences.</citsent>
<aftsection>
<nextsent>to make the model estimation tractable, ge man and johnson (geman and johnson, 2002) <papid> P02-1036 </papid>and miyao and tsujii (miyao and tsujii, 2002) proposed dynamic programming algorithm for estimating p(t |w).</nextsent>
<nextsent>miyao and tsujii (2005)<papid> P05-1011 </papid>also introduced apreliminary probabilistic model p0(t |w) whose estimation does not require the parsing of treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3706">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> hpsg and probabilistic models.  </section>
<citcontext>
<prevsection>
<prevsent>to make the model estimation tractable, ge man and johnson (geman and johnson, 2002) <papid> P02-1036 </papid>and miyao and tsujii (miyao and tsujii, 2002) proposed dynamic programming algorithm for estimating p(t |w).</prevsent>
<prevsent>miyao and tsujii (2005)<papid> P05-1011 </papid>also introduced apreliminary probabilistic model p0(t |w) whose estimation does not require the parsing of treebank.</prevsent>
</prevsection>
<citsent citstr=" A00-2021 ">
this model is introduced as reference distribution (jelinek, 1998; johnson and riezler, 2000) <papid> A00-2021 </papid>of the probabilistic hpsg model; i.e., the computation of parse trees given low probabilities by the model is omitted in the estimation stage (miyao and tsujii, 2005), <papid> P05-1011 </papid>or probabilistic model can be augmented by several distributions estimated from the larger and simpler corpus (johnson and riezler, 2000).<papid> A00-2021 </papid></citsent>
<aftsection>
<nextsent>in (miyao and tsujii, 2005), <papid> P05-1011 </papid>p0(t |w) is defined as the product of probabilities of selecting lexical entries with word and pos unigram features: (miyao and tsujii (2005)<papid> P05-1011 </papid>s model) puniref (t |w) = p0(t |w) 1zw exp (?</nextsent>
<nextsent>u ufu(t ) ) zw = ? ? p0(t ?|w) exp (?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3947">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>time (%) (%) (%) (%) (%) (%) (ms) miyao and tsujii (2005)<papid> P05-1011 </papid>s model 84.96 84.25 84.60 89.55 88.80 89.17 674 ninomiya et al (2006)<papid> W06-1619 </papid>s model 1 85.00 84.01 84.50 88.85 87.82 88.33 154 ninomiya et al (2006)<papid> W06-1619 </papid>s model 3 87.35 86.29 86.82 91.24 90.13 90.68 183 matsuzaki et al (2007)s model 86.93 86.47 86.70 - - - 30 our model 1 87.28 87.05 87.17 91.62 91.38 91.50 260 our model 2 87.56 87.46 87.51 91.88 91.77 91.82 1821 table 4: experimental results for section 23.</prevsent>
<prevsent>abilistic models were trained using the same portion of the treebank.</prevsent>
</prevsection>
<citsent citstr=" W97-0302 ">
we used beam thresholding, global thresholding (goodman, 1997), <papid> W97-0302 </papid>preserved iterative parsing (ninomiya et al, 2005) <papid> W05-1511 </papid>and quick check (malouf et al, 2000).we measured the accuracy of the predicate argument relations output of the parser.</citsent>
<aftsection>
<nextsent>a predicate-argument relation is defined as tuple ??,wh, a, wa?, where ? is the predicate type (e.g., adjective, in transitive verb), wh is the head word of the predicate, is the argument label (modarg, arg1, ..., arg4), and wa is the head word ofthe argument.
</nextsent>
<nextsent>labeled precision (lp)/labeled recall (lr) is the ratio of tuples correctly identified by the parser2.
</nextsent>
<nextsent>unlabeled precision (up)/unlabeledrecall (ur) is the ratio of tuples without the predicate type and the argument label.
</nextsent>
<nextsent>this evaluation scheme was the same as used in previous evaluations of lexicalized grammars (hockenmaier, 2003; <papid> P03-1046 </papid>clark the hpsg treebank is used for training the probabilistic model for lexical entry selection, and hence, those lexical entries thatdo not appear in the treebank are rarely selected by the probabilistic model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3949">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>labeled precision (lp)/labeled recall (lr) is the ratio of tuples correctly identified by the parser2.
</prevsent>
<prevsent>unlabeled precision (up)/unlabeledrecall (ur) is the ratio of tuples without the predicate type and the argument label.
</prevsent>
</prevsection>
<citsent citstr=" P03-1046 ">
this evaluation scheme was the same as used in previous evaluations of lexicalized grammars (hockenmaier, 2003; <papid> P03-1046 </papid>clark the hpsg treebank is used for training the probabilistic model for lexical entry selection, and hence, those lexical entries thatdo not appear in the treebank are rarely selected by the probabilistic model.</citsent>
<aftsection>
<nextsent>the effective?
</nextsent>
<nextsent>tag set size, therefore, is around 1,361, the number of lexical entries without those never-seen lexical entries.2when parsing fails, precision and recall are evaluated, although nothing is output by the parser; i.e., recall decreases greatly.
</nextsent>
<nextsent>and curran, 2004b; miyao and tsujii, 2005).<papid> P05-1011 </papid></nextsent>
<nextsent>the experiments were conducted on an amd opteronserver with 2.4-ghz cpu.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD3953">
<title id=" W07-2208.xml">a loglinear model with an ngram reference distribution for accurate hpsg parsing </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>table 3 details the numbers and average lengths of the tested sentences of ? 100 words in sections 23 and 24, and the total numbers of sentences in sections 23 and 24.
</prevsent>
<prevsent>the parsing performance for section 23 is shownin table 4.
</prevsent>
</prevsection>
<citsent citstr=" H05-1059 ">
the upper half of the table shows the performance using the correct poss in the penn treebank, and the lower half shows the performance using the poss given by pos tagger (tsuruoka and tsujii, 2005).<papid> H05-1059 </papid></citsent>
<aftsection>
<nextsent>lf and uf in the figure are labeledf-score and unlabeled f-score.
</nextsent>
<nextsent>f-score is the harmonic mean of precision and recall.
</nextsent>
<nextsent>we evaluated our model in two settings.
</nextsent>
<nextsent>one is implemented with narrow beam width (our model 1?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4094">
<title id=" W08-0106.xml">semantic negotiation in dialogue the mechanisms of alignment </title>
<section> exploitation  of  alignment:  patterns  of.  </section>
<citcontext>
<prevsection>
<prevsent>or reformulations?
</prevsent>
<prevsent>(cf.
</prevsent>
</prevsection>
<citsent citstr=" W04-2325 ">
purver et al ., 2004, schlangen 2004).<papid> W04-2325 </papid></citsent>
<aftsection>
<nextsent>during the course of maze task dialogues, participants shift seamlessly and tacitly from one description type to another.
</nextsent>
<nextsent>this occurs both within problematic and un problematic dialogue.
</nextsent>
<nextsent>from an informational perspective, miscommunication is readily describable as form of mismatch, yet from semantic perspective, participants match each other more when encountering difficulties.
</nextsent>
<nextsent>50thus alignment cannot be taken as straightforward index of successful interaction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4095">
<title id=" W07-2029.xml">fbkirst lexical substitution task exploiting domain and syntagmatic coherence </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for each word to be substituted, the systems rank the associated synonym list according to similarity metric based on latent semantic analysis and to the occurrences in the web 1t 5-gram corpus, respectively.
</prevsent>
<prevsent>in particular, the latter system achieves the state-of-the-art performance, largely surpassing the baseline proposed by the organizers.
</prevsent>
</prevsection>
<citsent citstr=" W06-2907 ">
the lexical substitution (glickman et al, 2006<papid> W06-2907 </papid>a) can be regarded as subtask of the lexical entailment, in which forgiven word in context the system isasked to select an alternative word that can be replaced in that context preserving the meaning.</citsent>
<aftsection>
<nextsent>lexical entailment, and in particular lexical reference(glickman et al, 2006<papid> W06-2907 </papid>b)1 , is in turn subtask of textual entailment, which is formally defined as relationship between coherent text and language expression, the hypothesis . is said to entail ,denoted by ? , if the meaning of can be inferred from the meaning of (dagan et al, 2005;dagan and glickman., 2004).</nextsent>
<nextsent>even though this notion has been only recently proposed in the computational linguistics literature, it attracts more and more attention due to the high generality of its settings and to the usefulness of its (potential) applications.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4103">
<title id=" W07-2029.xml">fbkirst lexical substitution task exploiting domain and syntagmatic coherence </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical entailment, and in particular lexical reference(glickman et al, 2006<papid> W06-2907 </papid>b)1 , is in turn subtask of textual entailment, which is formally defined as relationship between coherent text and language expression, the hypothesis . is said to entail ,denoted by ? , if the meaning of can be inferred from the meaning of (dagan et al, 2005;dagan and glickman., 2004).</prevsent>
<prevsent>even though this notion has been only recently proposed in the computational linguistics literature, it attracts more and more attention due to the high generality of its settings and to the usefulness of its (potential) applications.</prevsent>
</prevsection>
<citsent citstr=" P06-1057 ">
1in the literature, slight variations of this problem have been also referred to as sense matching (dagan et al, 2006).<papid> P06-1057 </papid>with respect to lexical entailment, the lexical substitution task has more restrictive criterion.</citsent>
<aftsection>
<nextsent>in fact, two words can be substituted when meaning is preserved, while the criterion for lexical entailment is that the meaning of the thesis is implied by the meaning of the hypothesis.
</nextsent>
<nextsent>the latter condition is in general ensured by substituting either hyperonyms or synonyms, while the former is more rigid because only synonyms are in principle accepted.
</nextsent>
<nextsent>formally, in lexical entailment task system isasked to decide whether the substitution of particular term with the term incoherent text hw = lwhr generates sentence he = lehr such that hw ? he, where l and hr denote the left and the right context of w, respectively.
</nextsent>
<nextsent>for example, given the source word weapon?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4104">
<title id=" W08-0316.xml">european language translation with weighted finite state transducers the cued mt system for the 2008 acl workshop on smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the cued system follows generative model of translation and is implemented by composition of component models realised as weighted finite state transducers, without the use of special-purpose decoder.
</prevsent>
<prevsent>details of system tuning for both europarl and news translation tasks are provided.
</prevsent>
</prevsection>
<citsent citstr=" H05-1021 ">
the cambridge university engineering department statistical machine translation system follows the transducer translation model (kumar and byrne, 2005; <papid> H05-1021 </papid>kumar et al, 2006), phrase-based generative model of translation that applies series of transformations specified by conditional probability distributions and encoded as weighted finite state transducers (mohri et al, 2002).the main advantages of this approach are its modularity, which facilitates the development and evaluation of each component individually, and its implementation simplicity which allows us to focus on modeling issues rather than complex decoding and search algorithms.</citsent>
<aftsection>
<nextsent>in addition, no special-purpose decoder is required since standard wfst operation scan be used to obtain the 1-best translation or lattice of alternative hypotheses.
</nextsent>
<nextsent>finally, the system architecture readily extends to speech translation, in which input asr lattices can be translated in the same way as for text (mathias and byrne, 2006).
</nextsent>
<nextsent>this paper reviews the first participation of cuedin the acl workshop on statistical machine translation in 2008.
</nextsent>
<nextsent>it is organised as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4106">
<title id=" W08-0316.xml">european language translation with weighted finite state transducers the cued mt system for the 2008 acl workshop on smt </title>
<section> system development.  </section>
<citcontext>
<prevsection>
<prevsent>however, the 2008 evaluation included new news task, for which no corresponding development set was available.
</prevsent>
<prevsent>sentences words vocab fr 39.9m 124k en 1.33m 36.4m 106k es 38.2m 140k en 1.30m 35.7m 106k table 1: parallel corpora statistics.all of the training and system tuning was performed using lower-cased data.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
word alignments were generated using giza++ (och and ney, 2003) <papid> J03-1002 </papid>over stemmed version of the parallel text.</citsent>
<aftsection>
<nextsent>stems for each language were obtained using the snowball stemmer1.
</nextsent>
<nextsent>after unio ning the viterbi alignments, the stems were replaced with their original words, and phrase-pairs of up to five foreign words in length were extracted in the usual fashion (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>3.1 system tuning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4107">
<title id=" W08-0316.xml">european language translation with weighted finite state transducers the cued mt system for the 2008 acl workshop on smt </title>
<section> system development.  </section>
<citcontext>
<prevsection>
<prevsent>word alignments were generated using giza++ (och and ney, 2003) <papid> J03-1002 </papid>over stemmed version of the parallel text.</prevsent>
<prevsent>stems for each language were obtained using the snowball stemmer1.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
after unio ning the viterbi alignments, the stems were replaced with their original words, and phrase-pairs of up to five foreign words in length were extracted in the usual fashion (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>3.1 system tuning.
</nextsent>
<nextsent>minimum error training (och, 2003) <papid> P03-1021 </papid>under bleu (papineni et al, 2001) was used to optimise the feature weights of the decoder with respect to the dev2006 development set.</nextsent>
<nextsent>the following features are optimized: ? language model scale factor ? word and phrase insertion penalties ? reordering scale factor ? insertion scale factor ? translation model scale factor: u-to-v ? translation model scale factor: v-to-u ? three phrase pair count features the phrase-pair count features track whether each phrase-pair occurred once, twice, or more than twice 1available at http://snowball.tartarus.org 132in the parallel text (bender et al, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4108">
<title id=" W08-0316.xml">european language translation with weighted finite state transducers the cued mt system for the 2008 acl workshop on smt </title>
<section> system development.  </section>
<citcontext>
<prevsection>
<prevsent>after unio ning the viterbi alignments, the stems were replaced with their original words, and phrase-pairs of up to five foreign words in length were extracted in the usual fashion (koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
<prevsent>3.1 system tuning.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
minimum error training (och, 2003) <papid> P03-1021 </papid>under bleu (papineni et al, 2001) was used to optimise the feature weights of the decoder with respect to the dev2006 development set.</citsent>
<aftsection>
<nextsent>the following features are optimized: ? language model scale factor ? word and phrase insertion penalties ? reordering scale factor ? insertion scale factor ? translation model scale factor: u-to-v ? translation model scale factor: v-to-u ? three phrase pair count features the phrase-pair count features track whether each phrase-pair occurred once, twice, or more than twice 1available at http://snowball.tartarus.org 132in the parallel text (bender et al, 2007).
</nextsent>
<nextsent>all decoding and minimum error training operations are performed with wfsts and implemented using the openfst libraries (allauzen et al, 2007).
</nextsent>
<nextsent>3.2 english language models.
</nextsent>
<nextsent>separate language models are used when translating the europarl and news sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4109">
<title id=" W08-0316.xml">european language translation with weighted finite state transducers the cued mt system for the 2008 acl workshop on smt </title>
<section> system development.  </section>
<citcontext>
<prevsection>
<prevsent>separate language models are used when translating the europarl and news sets.
</prevsent>
<prevsent>the models are estimated using srilm (stolcke, 2002) and converted to wfsts for use in ttm translation.
</prevsent>
</prevsection>
<citsent citstr=" P03-1006 ">
we use the of fline approximation in which failure transitions are replaced with epsilons (allauzen et al, 2003).<papid> P03-1006 </papid>the europarl language model is kneserney (kneser and ney, 1995) smoothed default cutoff 5-gram back-off language model estimated over the concatenation of the europarl and news language model training data.</citsent>
<aftsection>
<nextsent>the news language model is created by optimising the interpolation weights of two component models with respect to the news commentary development sets since we believe these more closely match the newstest2008 domain.
</nextsent>
<nextsent>the optimised interpolation weights were 0.44 for the europarl corpus and 0.56 for the much smaller news commentary corpus.
</nextsent>
<nextsent>for our contrast submission, we rescore the first-pass translation lattices with large zero-cutoff stupid-backoff (brantset al, 2007) <papid> D07-1090 </papid>language model estimated over approximately five billion words of newswire text.</nextsent>
<nextsent>table 2 reports lower-cased bleu scores for the french english and spanish english europarl and news translation tasks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4110">
<title id=" W08-0316.xml">european language translation with weighted finite state transducers the cued mt system for the 2008 acl workshop on smt </title>
<section> system development.  </section>
<citcontext>
<prevsection>
<prevsent>the news language model is created by optimising the interpolation weights of two component models with respect to the news commentary development sets since we believe these more closely match the newstest2008 domain.
</prevsent>
<prevsent>the optimised interpolation weights were 0.44 for the europarl corpus and 0.56 for the much smaller news commentary corpus.
</prevsent>
</prevsection>
<citsent citstr=" D07-1090 ">
for our contrast submission, we rescore the first-pass translation lattices with large zero-cutoff stupid-backoff (brantset al, 2007) <papid> D07-1090 </papid>language model estimated over approximately five billion words of newswire text.</citsent>
<aftsection>
<nextsent>table 2 reports lower-cased bleu scores for the french english and spanish english europarl and news translation tasks.
</nextsent>
<nextsent>the nist scores are also provided in parentheses.
</nextsent>
<nextsent>the row labelled ttm+met?
</nextsent>
<nextsent>shows results obtained after ttmtranslation and minimum error training, i.e. our primary submission constrained to use only the data distributed for the task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4111">
<title id=" W07-1516.xml">active learning for partofspeech tagging accelerating corpus annotation </title>
<section> part of speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 draws conclusions and identifies opportunities for follow-up research.
</prevsent>
<prevsent>labeling natural language data with part-of-speech tags can be complicated task, requiring much effort and expense, even for trained annotators.
</prevsent>
</prevsection>
<citsent citstr=" A97-1051 ">
several efforts, notably the alembic workbench (day et al, 1997) <papid> A97-1051 </papid>and similar tools, have provided interfaces to aid annotators in the process.</citsent>
<aftsection>
<nextsent>automatic pos tagging of text using probabilistic models is mostly solved problem but requires supervised learning from substantial amounts of training data.
</nextsent>
<nextsent>previous work demonstrates the suitability of hidden markov models for pos tagging (kupiec, 1992; brants, 2000).<papid> A00-1031 </papid></nextsent>
<nextsent>more recent work has achieved state-of-the-art results with maxi 101 mum entropy conditional markov models (maxent cmms, or memms for short) (ratnaparkhi, 1996; <papid> W96-0213 </papid>toutanova &amp; manning, 2000; <papid> W00-1308 </papid>toutanova et al, 2003).<papid> N03-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4112">
<title id=" W07-1516.xml">active learning for partofspeech tagging accelerating corpus annotation </title>
<section> part of speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>several efforts, notably the alembic workbench (day et al, 1997) <papid> A97-1051 </papid>and similar tools, have provided interfaces to aid annotators in the process.</prevsent>
<prevsent>automatic pos tagging of text using probabilistic models is mostly solved problem but requires supervised learning from substantial amounts of training data.</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
previous work demonstrates the suitability of hidden markov models for pos tagging (kupiec, 1992; brants, 2000).<papid> A00-1031 </papid></citsent>
<aftsection>
<nextsent>more recent work has achieved state-of-the-art results with maxi 101 mum entropy conditional markov models (maxent cmms, or memms for short) (ratnaparkhi, 1996; <papid> W96-0213 </papid>toutanova &amp; manning, 2000; <papid> W00-1308 </papid>toutanova et al, 2003).<papid> N03-1033 </papid></nextsent>
<nextsent>part of the success of memms can be attributed to the absence of independence assumptions among predictive features and the resulting ease of feature engineering.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4113">
<title id=" W07-1516.xml">active learning for partofspeech tagging accelerating corpus annotation </title>
<section> part of speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>automatic pos tagging of text using probabilistic models is mostly solved problem but requires supervised learning from substantial amounts of training data.
</prevsent>
<prevsent>previous work demonstrates the suitability of hidden markov models for pos tagging (kupiec, 1992; brants, 2000).<papid> A00-1031 </papid></prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
more recent work has achieved state-of-the-art results with maxi 101 mum entropy conditional markov models (maxent cmms, or memms for short) (ratnaparkhi, 1996; <papid> W96-0213 </papid>toutanova &amp; manning, 2000; <papid> W00-1308 </papid>toutanova et al, 2003).<papid> N03-1033 </papid></citsent>
<aftsection>
<nextsent>part of the success of memms can be attributed to the absence of independence assumptions among predictive features and the resulting ease of feature engineering.
</nextsent>
<nextsent>to the best of our knowledge, the present work is the first to present results using memms in an active learning framework.
</nextsent>
<nextsent>an memm is probabilistic model for sequence labeling.
</nextsent>
<nextsent>it is conditional markov model (cmm as illustrated in figure 1) in which maximum entropy (maxent) classifier is employed to estimate the probability distribution 1..
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4114">
<title id=" W07-1516.xml">active learning for partofspeech tagging accelerating corpus annotation </title>
<section> part of speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>automatic pos tagging of text using probabilistic models is mostly solved problem but requires supervised learning from substantial amounts of training data.
</prevsent>
<prevsent>previous work demonstrates the suitability of hidden markov models for pos tagging (kupiec, 1992; brants, 2000).<papid> A00-1031 </papid></prevsent>
</prevsection>
<citsent citstr=" W00-1308 ">
more recent work has achieved state-of-the-art results with maxi 101 mum entropy conditional markov models (maxent cmms, or memms for short) (ratnaparkhi, 1996; <papid> W96-0213 </papid>toutanova &amp; manning, 2000; <papid> W00-1308 </papid>toutanova et al, 2003).<papid> N03-1033 </papid></citsent>
<aftsection>
<nextsent>part of the success of memms can be attributed to the absence of independence assumptions among predictive features and the resulting ease of feature engineering.
</nextsent>
<nextsent>to the best of our knowledge, the present work is the first to present results using memms in an active learning framework.
</nextsent>
<nextsent>an memm is probabilistic model for sequence labeling.
</nextsent>
<nextsent>it is conditional markov model (cmm as illustrated in figure 1) in which maximum entropy (maxent) classifier is employed to estimate the probability distribution 1..
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4115">
<title id=" W07-1516.xml">active learning for partofspeech tagging accelerating corpus annotation </title>
<section> part of speech tagging.  </section>
<citcontext>
<prevsection>
<prevsent>automatic pos tagging of text using probabilistic models is mostly solved problem but requires supervised learning from substantial amounts of training data.
</prevsent>
<prevsent>previous work demonstrates the suitability of hidden markov models for pos tagging (kupiec, 1992; brants, 2000).<papid> A00-1031 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
more recent work has achieved state-of-the-art results with maxi 101 mum entropy conditional markov models (maxent cmms, or memms for short) (ratnaparkhi, 1996; <papid> W96-0213 </papid>toutanova &amp; manning, 2000; <papid> W00-1308 </papid>toutanova et al, 2003).<papid> N03-1033 </papid></citsent>
<aftsection>
<nextsent>part of the success of memms can be attributed to the absence of independence assumptions among predictive features and the resulting ease of feature engineering.
</nextsent>
<nextsent>to the best of our knowledge, the present work is the first to present results using memms in an active learning framework.
</nextsent>
<nextsent>an memm is probabilistic model for sequence labeling.
</nextsent>
<nextsent>it is conditional markov model (cmm as illustrated in figure 1) in which maximum entropy (maxent) classifier is employed to estimate the probability distribution 1..
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4123">
<title id=" W07-1516.xml">active learning for partofspeech tagging accelerating corpus annotation </title>
<section> active learning.  </section>
<citcontext>
<prevsection>
<prevsent>query by committee (qbc) was introduced by seung, opper, and sompolinsky (1992).
</prevsent>
<prevsent>freund, seung, shamir, and tishby (1997) provided careful analysis of the approach.
</prevsent>
</prevsection>
<citsent citstr=" P96-1042 ">
engelson and dagan (1996) <papid> P96-1042 </papid>experimented with qbc using hmms for pos tagging and found that selective sampling of sentences can significantly reduce the number of samples required to achieve desirable tag accura cies.</citsent>
<aftsection>
<nextsent>unlike the present work, engelson &amp; dagan were restricted by computational resources to selection from small windows of the unannotated set, not from the entire unannotated set.
</nextsent>
<nextsent>related work includes learning ensembles of pos taggers, as in the work of brill and wu (1998), <papid> P98-1029 </papid>where an ensemble consisting of unigram model, an n-gram model, transformation-based model, and an memm for pos tagging achieves substantial results beyond the individual taggers.</nextsent>
<nextsent>their conclusion relevant to this paper is that different taggers commit complementary errors, useful fact to exploit inactive learning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4124">
<title id=" W07-1516.xml">active learning for partofspeech tagging accelerating corpus annotation </title>
<section> active learning.  </section>
<citcontext>
<prevsection>
<prevsent>engelson and dagan (1996) <papid> P96-1042 </papid>experimented with qbc using hmms for pos tagging and found that selective sampling of sentences can significantly reduce the number of samples required to achieve desirable tag accura cies.</prevsent>
<prevsent>unlike the present work, engelson &amp; dagan were restricted by computational resources to selection from small windows of the unannotated set, not from the entire unannotated set.</prevsent>
</prevsection>
<citsent citstr=" P98-1029 ">
related work includes learning ensembles of pos taggers, as in the work of brill and wu (1998), <papid> P98-1029 </papid>where an ensemble consisting of unigram model, an n-gram model, transformation-based model, and an memm for pos tagging achieves substantial results beyond the individual taggers.</citsent>
<aftsection>
<nextsent>their conclusion relevant to this paper is that different taggers commit complementary errors, useful fact to exploit inactive learning.
</nextsent>
<nextsent>qbc employs committee of models, in which each model votes on the correct tagging of sentence.
</nextsent>
<nextsent>the potential infor mativeness of sentence is measured by the total number of tag sequence disagreements (compared pair-wise) among the committee members.
</nextsent>
<nextsent>possible variants of qbc involve the number of committee members, how the training data is split among the committee members, and whether the training data is sampled with or without replacement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4125">
<title id=" W07-1516.xml">active learning for partofspeech tagging accelerating corpus annotation </title>
<section> active learning.  </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, current active learning results involving this mc pos tagging decoder are negative on small training set sizes, so we do not present them here.
</prevsent>
<prevsent>another alternative approximation worth pursuing is computing the per-sentence entropy using the n-best pos tag sequences.
</prevsent>
</prevsection>
<citsent citstr=" N07-2028 ">
very recent work by mann and mccallum (2007) <papid> N07-2028 </papid>proposes an approach in which exact sequence entropy can be calculated efficient ly.</citsent>
<aftsection>
<nextsent>further experimentation is required to compare our approximation to these alternatives.
</nextsent>
<nextsent>an alternative approach that eliminates the overhead of entropy computations entirely is to estimate per-sentence uncertainty with 1 ( )p t?
</nextsent>
<nextsent>, where t?
</nextsent>
<nextsent>is the viterbi (best) tag sequence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4126">
<title id=" W07-2007.xml">semeval2007 task 08 metonymy resolution at semeval2007 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, the meaning of stopover in the sentence he saw teaching as stopover on his way to bigger things is metaphorical sense of the sense stopping place in physical journey?, with the literal sense listed in wordnet 2.0 but the metaphorical one not being listed.1 the same holds for the metonymic reading of rattlesnake (for the animals meat) in roast rattlesnake tastes like chicken.2 again, the meat read 1this example was taken from the berkely master metaphor list (lakoff and johnson, 1980) . 2from now on, all examples in this paper are taken from the british national corpus (bnc) (burnard, 1995), but ex.
</prevsent>
<prevsent>23.
</prevsent>
</prevsection>
<citsent citstr=" E03-1067 ">
ing of rattlesnake is not listed in wordnet whereas the meat reading for chicken is. as there is no common framework or corpus for figurative language resolution, previous computational works (fass, 1997; hobbs et al, 1993; barnden et al, 2003, <papid> E03-1067 </papid>among others) carry out only small scale evaluations.</citsent>
<aftsection>
<nextsent>in recent years, there has been growing interest in metaphor and metonymy resolution that is either corpus-based or evaluated on larger datasets (martin, 1994; nissim and markert, 2003; <papid> P03-1008 </papid>mason, 2004; <papid> J04-1002 </papid>peirsman, 2006; <papid> E06-3009 </papid>birke and sarkaar, 2006; krishnakamuran and zhu, 2007).</nextsent>
<nextsent>still, apart from (nissim and markert, 2003; <papid> P03-1008 </papid>peirsman, 2006) <papid> E06-3009 </papid>who evaluate their work on the same dataset, results are hardly comparable as they all operate within different frameworks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4127">
<title id=" W07-2007.xml">semeval2007 task 08 metonymy resolution at semeval2007 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>23.
</prevsent>
<prevsent>ing of rattlesnake is not listed in wordnet whereas the meat reading for chicken is. as there is no common framework or corpus for figurative language resolution, previous computational works (fass, 1997; hobbs et al, 1993; barnden et al, 2003, <papid> E03-1067 </papid>among others) carry out only small scale evaluations.</prevsent>
</prevsection>
<citsent citstr=" P03-1008 ">
in recent years, there has been growing interest in metaphor and metonymy resolution that is either corpus-based or evaluated on larger datasets (martin, 1994; nissim and markert, 2003; <papid> P03-1008 </papid>mason, 2004; <papid> J04-1002 </papid>peirsman, 2006; <papid> E06-3009 </papid>birke and sarkaar, 2006; krishnakamuran and zhu, 2007).</citsent>
<aftsection>
<nextsent>still, apart from (nissim and markert, 2003; <papid> P03-1008 </papid>peirsman, 2006) <papid> E06-3009 </papid>who evaluate their work on the same dataset, results are hardly comparable as they all operate within different frameworks.</nextsent>
<nextsent>this situation motivated us to organise the first shared task for figurative language, concentrating on metonymy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4129">
<title id=" W07-2007.xml">semeval2007 task 08 metonymy resolution at semeval2007 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>23.
</prevsent>
<prevsent>ing of rattlesnake is not listed in wordnet whereas the meat reading for chicken is. as there is no common framework or corpus for figurative language resolution, previous computational works (fass, 1997; hobbs et al, 1993; barnden et al, 2003, <papid> E03-1067 </papid>among others) carry out only small scale evaluations.</prevsent>
</prevsection>
<citsent citstr=" J04-1002 ">
in recent years, there has been growing interest in metaphor and metonymy resolution that is either corpus-based or evaluated on larger datasets (martin, 1994; nissim and markert, 2003; <papid> P03-1008 </papid>mason, 2004; <papid> J04-1002 </papid>peirsman, 2006; <papid> E06-3009 </papid>birke and sarkaar, 2006; krishnakamuran and zhu, 2007).</citsent>
<aftsection>
<nextsent>still, apart from (nissim and markert, 2003; <papid> P03-1008 </papid>peirsman, 2006) <papid> E06-3009 </papid>who evaluate their work on the same dataset, results are hardly comparable as they all operate within different frameworks.</nextsent>
<nextsent>this situation motivated us to organise the first shared task for figurative language, concentrating on metonymy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4130">
<title id=" W07-2007.xml">semeval2007 task 08 metonymy resolution at semeval2007 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>23.
</prevsent>
<prevsent>ing of rattlesnake is not listed in wordnet whereas the meat reading for chicken is. as there is no common framework or corpus for figurative language resolution, previous computational works (fass, 1997; hobbs et al, 1993; barnden et al, 2003, <papid> E03-1067 </papid>among others) carry out only small scale evaluations.</prevsent>
</prevsection>
<citsent citstr=" E06-3009 ">
in recent years, there has been growing interest in metaphor and metonymy resolution that is either corpus-based or evaluated on larger datasets (martin, 1994; nissim and markert, 2003; <papid> P03-1008 </papid>mason, 2004; <papid> J04-1002 </papid>peirsman, 2006; <papid> E06-3009 </papid>birke and sarkaar, 2006; krishnakamuran and zhu, 2007).</citsent>
<aftsection>
<nextsent>still, apart from (nissim and markert, 2003; <papid> P03-1008 </papid>peirsman, 2006) <papid> E06-3009 </papid>who evaluate their work on the same dataset, results are hardly comparable as they all operate within different frameworks.</nextsent>
<nextsent>this situation motivated us to organise the first shared task for figurative language, concentrating on metonymy.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4134">
<title id=" W07-2007.xml">semeval2007 task 08 metonymy resolution at semeval2007 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in ex.
</prevsent>
<prevsent>2 and 3, bmw, the name of company, stands for its index on the stockmarket, or vehicle manufactured by bmw, respectively.
</prevsent>
</prevsection>
<citsent citstr=" P93-1012 ">
(2) bmw slipped 4p to 31p (3) his bmw went on to race at lemans the importance of resolving metonymies has been shown for variety of nlp tasks, such as ma 36chine translation (kamei and wakao, 1992), question answering (stallard, 1993), <papid> P93-1012 </papid>anaphora resolution (harabagiu, 1998; <papid> W98-0720 </papid>markert and hahn, 2002) and geographical information retrieval (leveling and hartrumpf, 2006).although metonymic readings are, like all figurative readings, potentially open ended and can be innovative, the regularity of usage for word groups helps in establishing common evaluation frame work.</citsent>
<aftsection>
<nextsent>many other location names, for instance, can be used in the same fashion as vietnam in ex.
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>thus, given semantic class (e.g. location), one can specify several regular metonymic patterns (e.g. place-for-event) that instances of the class are likely to undergo.
</nextsent>
<nextsent>in addition to literal readings, regular metonymic patterns and innovative metonymicreadings, there can also be so-called mixed readings, similar to zeugma, where both literal and metonymic reading are evoked (nunberg, 1995).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4135">
<title id=" W07-2007.xml">semeval2007 task 08 metonymy resolution at semeval2007 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in ex.
</prevsent>
<prevsent>2 and 3, bmw, the name of company, stands for its index on the stockmarket, or vehicle manufactured by bmw, respectively.
</prevsent>
</prevsection>
<citsent citstr=" W98-0720 ">
(2) bmw slipped 4p to 31p (3) his bmw went on to race at lemans the importance of resolving metonymies has been shown for variety of nlp tasks, such as ma 36chine translation (kamei and wakao, 1992), question answering (stallard, 1993), <papid> P93-1012 </papid>anaphora resolution (harabagiu, 1998; <papid> W98-0720 </papid>markert and hahn, 2002) and geographical information retrieval (leveling and hartrumpf, 2006).although metonymic readings are, like all figurative readings, potentially open ended and can be innovative, the regularity of usage for word groups helps in establishing common evaluation frame work.</citsent>
<aftsection>
<nextsent>many other location names, for instance, can be used in the same fashion as vietnam in ex.
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>thus, given semantic class (e.g. location), one can specify several regular metonymic patterns (e.g. place-for-event) that instances of the class are likely to undergo.
</nextsent>
<nextsent>in addition to literal readings, regular metonymic patterns and innovative metonymicreadings, there can also be so-called mixed readings, similar to zeugma, where both literal and metonymic reading are evoked (nunberg, 1995).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4136">
<title id=" W07-2007.xml">semeval2007 task 08 metonymy resolution at semeval2007 </title>
<section> data collection and annotation.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, sample was also removed if the name extracted wasa homonym not in the desired semantic class (for example mr. greenland when annotating locations).4 for those names that do have the semantic class location or organisation, metonymy annotation was performed, using the categories described in section 2.
</prevsent>
<prevsent>all training set annotation was carried out independently by both organisers.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
annotation was highly reliable with kappa (carletta, 1996) <papid> J96-2004 </papid>of 3https://www.cia.gov/cia/publications/ factbook/index.html 4given that the task is not about standard named entity recognition, we assume that the general semantic class of the name is already known.</citsent>
<aftsection>
<nextsent>38 table 1: reading distribution for locations reading train test literal 737 721 mixed 15 20 other met 9 11 obj-for-name 0 4 obj-for-representation 0 0 place-for-people 161 141 place-for-event 3 10 place-for-product 0 1 total 925 908 table 2: reading distribution for organisations reading train test literal 690 520 mixed 59 60 other met 14 8 obj-for-name 8 6 obj-for-representation 1 0 org-for-members 220 161 org-for-event 2 1 org-for-product 74 67 org-for-facility 15 16 org-for-index 7 3 total 1090 842 .88/.89 for locations/organisations.5 as agreement was established, annotation of the test set was carried out by the first organiser.
</nextsent>
<nextsent>all cases which were not entirely straightforward were then independently checked by the second organiser.
</nextsent>
<nextsent>samples whose readings could not be agreed on (after reconciliation phase) were excluded from both training and test set.
</nextsent>
<nextsent>the reading distributions of training and test sets for both subtasks are shown in tables 1 and 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4137">
<title id=" W07-2007.xml">semeval2007 task 08 metonymy resolution at semeval2007 </title>
<section> systems and results.  </section>
<citcontext>
<prevsection>
<prevsent>tables 3 and 4 report accuracy for all systems.6 table 5 provides summary of the results with lowest, highest, and average accuracy and f-scores for each subtask and granularity level.7 the task seemed extremely difficult, with 2 of the 5 systems (up13,fuh) participating in the location task not beating the baseline.
</prevsent>
<prevsent>these two systems relied mainly on shallow features with limited or no use of external resources, thus suggesting that these features might only be of limited use for identifying metonymic shifts.
</prevsent>
</prevsection>
<citsent citstr=" W02-1027 ">
the organisers themselves have come to similar conclusions in their own experiments (markert and nissim, 2002).<papid> W02-1027 </papid></citsent>
<aftsection>
<nextsent>the systems using syntactic/grammatical features (gyder, utd-hlt-cg, xrce-m) could improve over the baseline whether using manual annotation or parsing.
</nextsent>
<nextsent>these systems also made heavy use of feature generalisation.
</nextsent>
<nextsent>classification granularity had only small effect on system performance.
</nextsent>
<nextsent>only few of the fine-grained categories could be distinguished with reasonable success (see the scores in table 5).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4138">
<title id=" W08-0107.xml">degrees of grounding based on evidence of understanding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this model has been developed and evaluated by corpus analysis, and includes set of types of evidence of understanding, setof degrees of grounded ness, set of grounding criteria, and methods for identifying each of these.
</prevsent>
<prevsent>we describe how this model can be used for dialogue management.
</prevsent>
</prevsection>
<citsent citstr=" H05-1029 ">
dialogue system researchers are active in investigating ways of detecting and recovering from error, including determining when to provide confirmations or rejections, or how to handle cases of complete non-understanding (bohus and rudnicky, 2005<papid> H05-1029 </papid>a; bohus and rudnicky, 2005<papid> H05-1029 </papid>b; skantze, 2005).</citsent>
<aftsection>
<nextsent>studying the strategies that humans use when speaking amongst themselves can be helpful (swerts et al, 2000; paek, 2003; litman et al, 2006).
</nextsent>
<nextsent>one approach to studying how humans manage errors of understanding is to view conversation as joint activity, in which grounding, or the process of adding material to the common ground between speakers, plays central role (clark and schaefer, 1989).from this perspective, conversations are highly coordinated efforts in which participants work together to ensure that knowledge is properly understood by all participants.
</nextsent>
<nextsent>there is wide variety of grounding behavior that is determined by the communication medium, among other things (clark and brennan, 1991).
</nextsent>
<nextsent>this approach is developed computationally by traum, who presents model of grounding which adapts clark and schaefers contributions model to make it usable in an online dialogue system (traum,1994).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4142">
<title id=" W07-2102.xml">utdsrl a pipeline architecture for extracting frame semantic structures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>designed as pipeline of classifiers, the semantic parsing system obtained competitive precision scores on the test data.
</prevsent>
<prevsent>the semeval2007 task for extracting frame semantic structures relies on the human annotated data available in the framenet (fn) database.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
the berkeley framenet project (baker et al, 1998) <papid> P98-1013 </papid>is an ongoing effort of building semantic lexicon for english based on the theory of frame semantics.</citsent>
<aftsection>
<nextsent>inframe semantics, the meaning of words or word expressions, also called target words (tw), comprises aspects of conceptual structures, or frames, that describe specific situations.
</nextsent>
<nextsent>the semantic roles, or frame elements (fe), associated with target wordare locally defined in the frame evoked by the target word.
</nextsent>
<nextsent>currently, the fn lexicon includes more than 135,000 sentences extracted from the british national corpus containing more than 6,100 target words that evoke more than 825 semantic frames.
</nextsent>
<nextsent>for this task, we extended our previous work atsenseval-3 (bejan et al, 2004) <papid> W04-0819 </papid>by (1) experimenting with additional features, (2) adding new classification sub-tasks to accomplish all the requirements,and (3) integrating these sub-tasks into pipeline ar chitecture.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4143">
<title id=" W07-2102.xml">utdsrl a pipeline architecture for extracting frame semantic structures </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the semantic roles, or frame elements (fe), associated with target wordare locally defined in the frame evoked by the target word.
</prevsent>
<prevsent>currently, the fn lexicon includes more than 135,000 sentences extracted from the british national corpus containing more than 6,100 target words that evoke more than 825 semantic frames.
</prevsent>
</prevsection>
<citsent citstr=" W04-0819 ">
for this task, we extended our previous work atsenseval-3 (bejan et al, 2004) <papid> W04-0819 </papid>by (1) experimenting with additional features, (2) adding new classification sub-tasks to accomplish all the requirements,and (3) integrating these sub-tasks into pipeline ar chitecture.</citsent>
<aftsection>
<nextsent>given sentence, the frame semantic structure extraction task consists of recognizing the word expressions that evoke semantic frames, assigning the correct frame to them and, for each target word,detecting and labeling the corresponding frame elements properly.
</nextsent>
<nextsent>the task also requires the determination of syntactic realizations associated to frame element, such as grammatical function (gf) and phrase type (pt).
</nextsent>
<nextsent>the following illustrates asentence example annotated with frame elements together with their corresponding grammatical functions and phrase types for the target word tie?: fe = content2 gf = dep pt = pp fe = content1 gf = ext pt = np aeois activities and facilities have been tied to several universities . frame = make_cognitive_connection evoke sto extract semantic structures similar to those illustrated in the example we divide the semeval?
</nextsent>
<nextsent>2007 task into four sub-tasks: (1) target word frame disambiguation (twfd); (2) fe boundary detection (febd); (3) gf label classification (gflc) and (4) fe label classification (felc).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4147">
<title id=" W07-2102.xml">utdsrl a pipeline architecture for extracting frame semantic structures </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>figure 2: classification examples for each sub-task.ambiguation sub-task extracts features corresponding to the constituent tied in order to predict the right frame between the semantic frames that can be evoked by this target word.
</prevsent>
<prevsent>in this figure, the correct categories for each sub-task are shown in boldface.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
the complete set of features extracted for all the classification sub-tasks is illustrated in figure 3.these represent subset of features used in previous works (gildea and jurafsky, 2002; <papid> J02-3001 </papid>florian et al, 2002; surdeanu et al, 2003; <papid> P03-1002 </papid>xue and palmer, 2004;<papid> W04-3212 </papid>bejan et al, 2004; <papid> W04-0819 </papid>pradhan et al, 2005) for automatic semantic role labeling and word sense disam biguation.</citsent>
<aftsection>
<nextsent>figure 3 also indicates whether or not feature is selected for specific classification task.
</nextsent>
<nextsent>in the remaining part of this section we describe in detail each classification sub-task and the features that have the most salient effect on improving the corresponding classifiers.
</nextsent>
<nextsent>2.1 frame disambiguation.
</nextsent>
<nextsent>in framenet, some target words can evoke multiple semantic frames.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4148">
<title id=" W07-2102.xml">utdsrl a pipeline architecture for extracting frame semantic structures </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>figure 2: classification examples for each sub-task.ambiguation sub-task extracts features corresponding to the constituent tied in order to predict the right frame between the semantic frames that can be evoked by this target word.
</prevsent>
<prevsent>in this figure, the correct categories for each sub-task are shown in boldface.
</prevsent>
</prevsection>
<citsent citstr=" P03-1002 ">
the complete set of features extracted for all the classification sub-tasks is illustrated in figure 3.these represent subset of features used in previous works (gildea and jurafsky, 2002; <papid> J02-3001 </papid>florian et al, 2002; surdeanu et al, 2003; <papid> P03-1002 </papid>xue and palmer, 2004;<papid> W04-3212 </papid>bejan et al, 2004; <papid> W04-0819 </papid>pradhan et al, 2005) for automatic semantic role labeling and word sense disam biguation.</citsent>
<aftsection>
<nextsent>figure 3 also indicates whether or not feature is selected for specific classification task.
</nextsent>
<nextsent>in the remaining part of this section we describe in detail each classification sub-task and the features that have the most salient effect on improving the corresponding classifiers.
</nextsent>
<nextsent>2.1 frame disambiguation.
</nextsent>
<nextsent>in framenet, some target words can evoke multiple semantic frames.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4149">
<title id=" W07-2102.xml">utdsrl a pipeline architecture for extracting frame semantic structures </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>figure 2: classification examples for each sub-task.ambiguation sub-task extracts features corresponding to the constituent tied in order to predict the right frame between the semantic frames that can be evoked by this target word.
</prevsent>
<prevsent>in this figure, the correct categories for each sub-task are shown in boldface.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
the complete set of features extracted for all the classification sub-tasks is illustrated in figure 3.these represent subset of features used in previous works (gildea and jurafsky, 2002; <papid> J02-3001 </papid>florian et al, 2002; surdeanu et al, 2003; <papid> P03-1002 </papid>xue and palmer, 2004;<papid> W04-3212 </papid>bejan et al, 2004; <papid> W04-0819 </papid>pradhan et al, 2005) for automatic semantic role labeling and word sense disam biguation.</citsent>
<aftsection>
<nextsent>figure 3 also indicates whether or not feature is selected for specific classification task.
</nextsent>
<nextsent>in the remaining part of this section we describe in detail each classification sub-task and the features that have the most salient effect on improving the corresponding classifiers.
</nextsent>
<nextsent>2.1 frame disambiguation.
</nextsent>
<nextsent>in framenet, some target words can evoke multiple semantic frames.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4155">
<title id=" W07-2215.xml">modular and efficient topdown parsing for ambiguous left recursive grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>application of parser for such grammar results in infinite descent.)
</prevsent>
<prevsent>these shortcomings limit the use of parser combinators and dcgs especially in natural-language processing.
</prevsent>
</prevsection>
<citsent citstr=" J91-1004 ">
the problem of exponential time complexity intop-down parsers constructed assets of mutually recursive functions has been solved by norvig (1991) <papid> J91-1004 </papid>who uses memo tables to achieve polynomial complexity.</citsent>
<aftsection>
<nextsent>norvigs technique is similar to the use of dynamic programming and state sets in earleys algorithm (1970), and tables in the cyk algorithm of cocke, younger and kasami.
</nextsent>
<nextsent>the basic idea in norvigs approach is that when parser is applied to the input, the result is stored in memo table for subsequent reuse if the same parser is ever reapplied to the same input.
</nextsent>
<nextsent>in the context of parser combina tors, norvigs approach can be implemented using function memoize to selectively memoize?
</nextsent>
<nextsent>parsers.in some applications, the problem of left recur sion can be overcome by transforming the grammar to weakly equivalent non-left-recursive form.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4157">
<title id=" W07-2215.xml">modular and efficient topdown parsing for ambiguous left recursive grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(i.e. to grammar which derives the same set of sentences).
</prevsent>
<prevsent>early methods of doing this resulted in grammars that are significantly larger than the original grammars.
</prevsent>
</prevsection>
<citsent citstr=" A00-2033 ">
this problem of grammar size has been solved by moore (2000) <papid> A00-2033 </papid>who developed amethod, based on left-corner grammar transformation, which produces non-left recursive grammars that are not much larger than the originals.</citsent>
<aftsection>
<nextsent>however, although converting grammar to weakly equivalent form is appropriate in some applications (such as speech recognition) it is not appropriate in other applications.
</nextsent>
<nextsent>according to aho, sethi, and ullman (1986) converting grammar to non-left recursive form makes it harder to translate expressions containing left-associative operators.
</nextsent>
<nextsent>also, in nlp it is easier to integrate semantic actions with parsing when both left most and rightmost parses of ambiguous input are being generated.
</nextsent>
<nextsent>for example, consider the first of the following grammar rules: np ::= noun | np conj np conj ::=  and  |  or  noun ::=  jim  |  su  |  ali  and its non-left-recursive weakly equivalent form: np ::= noun np?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4158">
<title id=" W07-2215.xml">modular and efficient topdown parsing for ambiguous left recursive grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>that work is described in detail in section 3.
</prevsent>
<prevsent>in this paper, we integrate norvigs technique with aspects of existing techniques for dealing with left recursion.
</prevsent>
</prevsection>
<citsent citstr=" J95-3005 ">
in particular: a) we make use of the length of the remaining input as does kuno (1965), b) we keep record of how many times each parser is applied to each input position in way that is similar to the use of cancellation sets by nederhof and koster (1993), c) we integrate memo ization with technique for dealing with left recur sion as does johnson (1995), <papid> J95-3005 </papid>and d) we store left-recursioncounts?</citsent>
<aftsection>
<nextsent>in the memo table, and encapsulate the mem oization process in programming construct called monad, as suggested by frost and hafiz (2006).our method includes new technique for accommodating indirect left recur sion which ensures correct reuse of stored results created through curtailment of left-recursive parsers.
</nextsent>
<nextsent>we also modify thememoization process so that the memo table represents the potentially exponential number of parse trees in compact polynomial sized form using 110 technique derived from the chart parsing methods of kay (1980) and tomita (1986).
</nextsent>
<nextsent>as an example use of our method, consider the following ambiguous left-recursive grammar from tomita (1985) in which pp stands for prepositional phrase, and prep for preposition.
</nextsent>
<nextsent>this grammar is left recursive in the rules for and np.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4165">
<title id=" W07-2054.xml">nuspt exploiting parallel texts for word sense disambiguation in the english all words tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the coarse-grained english all-words task, systems have to perform word sense disambiguation (wsd) of all content words (noun, adjective, verb, and adverb) occurring in five documents, using acoarse-grained version of the wordnet sense inventory.
</prevsent>
<prevsent>in the fine-grained english all-words task, systems have to predict the correct sense of verbs and head nouns of the verb arguments occurring in three documents, according to the fine-grained sense inventory of wordnet.results from previous senseval english all words task have shown that supervised learning gives the best performance.
</prevsent>
</prevsection>
<citsent citstr=" W04-0827 ">
further, the best performing system in senseval-3 english all-words task (decadt et al, 2004) <papid> W04-0827 </papid>used training data gathered from multiple sources, highlighting the importance of having large amount of training data.</citsent>
<aftsection>
<nextsent>hence, besides gathering examples from the widely usedsemcor corpus, we also gathered training examples from 6 english-chinese parallel corpora and the dso corpus (ng and lee, 1996).<papid> P96-1006 </papid></nextsent>
<nextsent>we developed 2 separate systems; one for each task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4167">
<title id=" W07-2054.xml">nuspt exploiting parallel texts for word sense disambiguation in the english all words tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the fine-grained english all-words task, systems have to predict the correct sense of verbs and head nouns of the verb arguments occurring in three documents, according to the fine-grained sense inventory of wordnet.results from previous senseval english all words task have shown that supervised learning gives the best performance.
</prevsent>
<prevsent>further, the best performing system in senseval-3 english all-words task (decadt et al, 2004) <papid> W04-0827 </papid>used training data gathered from multiple sources, highlighting the importance of having large amount of training data.</prevsent>
</prevsection>
<citsent citstr=" P96-1006 ">
hence, besides gathering examples from the widely usedsemcor corpus, we also gathered training examples from 6 english-chinese parallel corpora and the dso corpus (ng and lee, 1996).<papid> P96-1006 </papid></citsent>
<aftsection>
<nextsent>we developed 2 separate systems; one for each task.
</nextsent>
<nextsent>for both systems, we performed supervised word sense disambiguation based on the approach of (lee and ng, 2002) <papid> W02-1006 </papid>and using support vector machines (svm) as our learning algorithm.</nextsent>
<nextsent>the knowledge sources used include local collocations, parts-of-speech (pos), and surrounding words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4168">
<title id=" W07-2054.xml">nuspt exploiting parallel texts for word sense disambiguation in the english all words tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hence, besides gathering examples from the widely usedsemcor corpus, we also gathered training examples from 6 english-chinese parallel corpora and the dso corpus (ng and lee, 1996).<papid> P96-1006 </papid></prevsent>
<prevsent>we developed 2 separate systems; one for each task.</prevsent>
</prevsection>
<citsent citstr=" W02-1006 ">
for both systems, we performed supervised word sense disambiguation based on the approach of (lee and ng, 2002) <papid> W02-1006 </papid>and using support vector machines (svm) as our learning algorithm.</citsent>
<aftsection>
<nextsent>the knowledge sources used include local collocations, parts-of-speech (pos), and surrounding words.
</nextsent>
<nextsent>our system employed for the coarse-grained english all words task was trained with the coarse-grained sense inventory released by the task organizers, while our system employed for the fine-grained english all words task was trained with the fine-grained sense 253 inventory of wordnet.
</nextsent>
<nextsent>in the next section, we describe the different sources of training data used.
</nextsent>
<nextsent>in section 3, we describe the knowledge sources used by the learningalgorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4169">
<title id=" W07-2054.xml">nuspt exploiting parallel texts for word sense disambiguation in the english all words tasks </title>
<section> training corpora.  </section>
<citcontext>
<prevsection>
<prevsent>in section 3, we describe the knowledge sources used by the learningalgorithm.
</prevsent>
<prevsent>in section 4, we present our official evaluation results, before concluding in section 5.
</prevsent>
</prevsection>
<citsent citstr=" H94-1046 ">
we gathered training examples from parallel corpora, semcor (miller et al, 1994), <papid> H94-1046 </papid>and the dso corpus.</citsent>
<aftsection>
<nextsent>in this section, we describe these corpora and how examples gathered from them are combined to form the training data used by our systems.
</nextsent>
<nextsent>asthese data sources use an earlier version of the wordnet sense inventory as compared to the test data of the two tasks we participated in, we also discuss the need to map between different versions of wordnet.
</nextsent>
<nextsent>2.1 parallel text.
</nextsent>
<nextsent>research in (ng et al, 2003; <papid> P03-1058 </papid>chan and ng, 2005) has shown that examples gathered from parallel texts are useful for wsd.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4170">
<title id=" W07-2054.xml">nuspt exploiting parallel texts for word sense disambiguation in the english all words tasks </title>
<section> training corpora.  </section>
<citcontext>
<prevsection>
<prevsent>asthese data sources use an earlier version of the wordnet sense inventory as compared to the test data of the two tasks we participated in, we also discuss the need to map between different versions of wordnet.
</prevsent>
<prevsent>2.1 parallel text.
</prevsent>
</prevsection>
<citsent citstr=" P03-1058 ">
research in (ng et al, 2003; <papid> P03-1058 </papid>chan and ng, 2005) has shown that examples gathered from parallel texts are useful for wsd.</citsent>
<aftsection>
<nextsent>in this evaluation, we gathered training data from 6 english-chinese parallel corpora (hong kong hansa rds, hongkong news, hongkong laws, sino rama, xinhua news, and english translation of chinese treebank), available from the linguistic data consortium (ldc).
</nextsent>
<nextsent>to gather examples from these parallel corpora, we followed the approach in (ng et al, 2003).<papid> P03-1058 </papid></nextsent>
<nextsent>briefly, after ensuring the corpora were sentence-aligned, we tokenized the english texts and performed word segmentation on the chinese texts (low et al, 2005).<papid> I05-3025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4172">
<title id=" W07-2054.xml">nuspt exploiting parallel texts for word sense disambiguation in the english all words tasks </title>
<section> training corpora.  </section>
<citcontext>
<prevsection>
<prevsent>in this evaluation, we gathered training data from 6 english-chinese parallel corpora (hong kong hansa rds, hongkong news, hongkong laws, sino rama, xinhua news, and english translation of chinese treebank), available from the linguistic data consortium (ldc).
</prevsent>
<prevsent>to gather examples from these parallel corpora, we followed the approach in (ng et al, 2003).<papid> P03-1058 </papid></prevsent>
</prevsection>
<citsent citstr=" I05-3025 ">
briefly, after ensuring the corpora were sentence-aligned, we tokenized the english texts and performed word segmentation on the chinese texts (low et al, 2005).<papid> I05-3025 </papid></citsent>
<aftsection>
<nextsent>we then made use of the giza++ software (och andney, 2000) <papid> P00-1056 </papid>to perform word alignment on the parallel corpora.</nextsent>
<nextsent>then, we assigned some possible chinese translations to each sense of an english word w. from the word alignment output of giza++, we selected those occurrences of which were aligned to one of the chinese translations chosen.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4173">
<title id=" W07-2054.xml">nuspt exploiting parallel texts for word sense disambiguation in the english all words tasks </title>
<section> training corpora.  </section>
<citcontext>
<prevsection>
<prevsent>to gather examples from these parallel corpora, we followed the approach in (ng et al, 2003).<papid> P03-1058 </papid></prevsent>
<prevsent>briefly, after ensuring the corpora were sentence-aligned, we tokenized the english texts and performed word segmentation on the chinese texts (low et al, 2005).<papid> I05-3025 </papid></prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we then made use of the giza++ software (och andney, 2000) <papid> P00-1056 </papid>to perform word alignment on the parallel corpora.</citsent>
<aftsection>
<nextsent>then, we assigned some possible chinese translations to each sense of an english word w. from the word alignment output of giza++, we selected those occurrences of which were aligned to one of the chinese translations chosen.
</nextsent>
<nextsent>the english side of these occurrences served as training data for w, as they were considered to have been dis ambiguated and sense-tagged?
</nextsent>
<nextsent>by the appropriate chinese translations.we note that frequently occurring words are usually highly polysemous and hard to disambiguate.
</nextsent>
<nextsent>to maximize the benefits of using parallel texts, we gathered training data from parallel texts for the set of most frequently occurring noun, adjective, and verb types in the brown corpus (bc).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4178">
<title id=" W07-2054.xml">nuspt exploiting parallel texts for word sense disambiguation in the english all words tasks </title>
<section> training corpora.  </section>
<citcontext>
<prevsection>
<prevsent>however, the examples we gathered from the parallel texts and the semcor corpus are based on the wordnet-1.7.1 sense inventory.
</prevsent>
<prevsent>hence, there 254 is need to map these examples from wordnet-1.7.1 to wordnet-2.1 sense inventory.
</prevsent>
</prevsection>
<citsent citstr=" P00-1064 ">
for this, we rely primarily on the wordnet sense mappings automatically generated by the work of (daude et al, 2000).<papid> P00-1064 </papid>to ensure the accuracy of the mappings, we performed some manual corrections of our own, focusing on the set of most frequently occurring nouns, adjectives, and verbs.</citsent>
<aftsection>
<nextsent>for the verb examples fromthe dso corpus which are based on the wordnet 1.5 sense inventory, we manually mapped them to wordnet-2.1 senses.
</nextsent>
<nextsent>following the approach of (lee and ng, 2002), we train an svm classifier for each word using the knowledge sources of local collocations, parts-of speech (pos), and surrounding words.
</nextsent>
<nextsent>we omit the syntactic relation features for efficiency reasons.
</nextsent>
<nextsent>for local collocations, we use 11 features: c1,1, c1,1, c2,2, c2,2, c2,1, c1,1, c1,2, c3,1, c2,1, c1,2, and c1,3, where ci,j refers to the ordered sequence of tokens in the local context of an ambiguous word w. offsets and denote the starting and ending position (relative to w) of the sequence, where negative (positive) offset refers to tokento its left (right).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4179">
<title id=" W07-2089.xml">unnweps web person search using co present names and lexical chains </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as such, simple methods that improved overall success modestly were preferred to complex ones that did not.
</prevsent>
<prevsent>consequently, to reduce the search space, we used the one sense per discourse?
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
heuristic (gale et al 1992).<papid> H92-1045 </papid></citsent>
<aftsection>
<nextsent>this assumes that one web page would not refer to two different individuals that share name.
</nextsent>
<nextsent>unn-weps was made up of three components, comprising modules to: 1.
</nextsent>
<nextsent>create seed clusters that associated files.
</nextsent>
<nextsent>with person names other than those being searched for.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4180">
<title id=" W07-2089.xml">unnweps web person search using co present names and lexical chains </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>heuristic.
</prevsent>
<prevsent>further details of the unn-weps algorithm are given in figure 2 below.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
unn-weps achieved an average purity of 0.6, and inverse purity of 0.73 in semeval task 13, achieving seventh position out of sixteen competing systems (artiles et al 2007).<papid> W07-2012 </papid></citsent>
<aftsection>
<nextsent>however there was considerable variance in unn-weps results as shown in graph 1 below.
</nextsent>
<nextsent>purity vs name 0 0.2 0.4 0.6 0.8 1 ar th a_ ed ar ds ja es _m or eh ea vi ol et _h ow ar ja es _c ur ra ka re n_ pe te rs on th om as _k irk ar k_ jo hn so st ep he n_ cl ar al vi n_ co op er harry _h ug he ar th ur _m or ga ju de _b ro wn je rr y_ ho bb chris _b ro ck et sh ar on _g ol dw at er p(submitted) p(no-chain) (places-chainer) foreach person_name 1.
</nextsent>
<nextsent>tag raw html files with part of speech..
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4184">
<title id=" W07-1101.xml">a measure of syntactic flexibility for automatically identifying multiword expressions in corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many linguists have offered classification schemes for mwes.
</prevsent>
<prevsent>while these accounts vary intheir terminology, they mostly focus on three different phenomena: collocation, non-compositionalityand syntactic fixedness.
</prevsent>
</prevsection>
<citsent citstr=" P05-2003 ">
in computational linguistics, great deal of work has been done on the extraction of collocations in the last decade and half (see pecina (2005) <papid> P05-2003 </papid>for survey).</citsent>
<aftsection>
<nextsent>there have also been number of papers focusing on the detection of semantic non-compositional items in recent years beginning with the work of schone and jurafsky (2001).<papid> W01-0513 </papid></nextsent>
<nextsent>the task of identifying syntactically-fixed phrases, however, has been much less explored.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4185">
<title id=" W07-1101.xml">a measure of syntactic flexibility for automatically identifying multiword expressions in corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while these accounts vary intheir terminology, they mostly focus on three different phenomena: collocation, non-compositionalityand syntactic fixedness.
</prevsent>
<prevsent>in computational linguistics, great deal of work has been done on the extraction of collocations in the last decade and half (see pecina (2005) <papid> P05-2003 </papid>for survey).</prevsent>
</prevsection>
<citsent citstr=" W01-0513 ">
there have also been number of papers focusing on the detection of semantic non-compositional items in recent years beginning with the work of schone and jurafsky (2001).<papid> W01-0513 </papid></citsent>
<aftsection>
<nextsent>the task of identifying syntactically-fixed phrases, however, has been much less explored.
</nextsent>
<nextsent>this third variety is the focus of the present paper.
</nextsent>
<nextsent>languages contain many word combinations that do not allow the variation we would expect based solely on their grammatical form.
</nextsent>
<nextsent>in the most extreme case there are many phrases which seem to allow no syntactic variation whatsoever.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4186">
<title id=" W07-1101.xml">a measure of syntactic flexibility for automatically identifying multiword expressions in corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the most extreme case there are many phrases which seem to allow no syntactic variation whatsoever.
</prevsent>
<prevsent>these include phrases such as by and large and in short, which do not allow any morphological variation (*in shortest) or internal modification (*by and pretty large).
</prevsent>
</prevsection>
<citsent citstr=" C04-1141 ">
we focus here on phrases that allow some syntactic variation, but do not allow other kinds.the small amount of previous work on the identification of syntactic fixed ness (wermter and hahn(2004), <papid> C04-1141 </papid>fazly and stevenson (2006)) <papid> E06-1043 </papid>has either focused on single variation variety, or has only been evaluated for combinations of small preselectedlist of words, presumably due to noise.</citsent>
<aftsection>
<nextsent>in this paper we employ syntactic parser, thus allowing us to include wider range of syntactic features in ourmodel.
</nextsent>
<nextsent>furthermore we describe statistical measure of variation that is robust enough to be freely evaluated over the full set of possible word combinations found in the corpus.
</nextsent>
<nextsent>the remainder of our paper will be structured as follows.
</nextsent>
<nextsent>section 2 will discuss the kinds of fixednessthat we observe in our target phrase variety.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4187">
<title id=" W07-1101.xml">a measure of syntactic flexibility for automatically identifying multiword expressions in corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the most extreme case there are many phrases which seem to allow no syntactic variation whatsoever.
</prevsent>
<prevsent>these include phrases such as by and large and in short, which do not allow any morphological variation (*in shortest) or internal modification (*by and pretty large).
</prevsent>
</prevsection>
<citsent citstr=" E06-1043 ">
we focus here on phrases that allow some syntactic variation, but do not allow other kinds.the small amount of previous work on the identification of syntactic fixed ness (wermter and hahn(2004), <papid> C04-1141 </papid>fazly and stevenson (2006)) <papid> E06-1043 </papid>has either focused on single variation variety, or has only been evaluated for combinations of small preselectedlist of words, presumably due to noise.</citsent>
<aftsection>
<nextsent>in this paper we employ syntactic parser, thus allowing us to include wider range of syntactic features in ourmodel.
</nextsent>
<nextsent>furthermore we describe statistical measure of variation that is robust enough to be freely evaluated over the full set of possible word combinations found in the corpus.
</nextsent>
<nextsent>the remainder of our paper will be structured as follows.
</nextsent>
<nextsent>section 2 will discuss the kinds of fixednessthat we observe in our target phrase variety.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4188">
<title id=" W07-1101.xml">a measure of syntactic flexibility for automatically identifying multiword expressions in corpora </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>this paper aims to provide method for highlighting those verb plus noun phrases that are syntactically fixed and consequently need to be included inthe lexicon.
</prevsent>
<prevsent>this is intended as tool for lexicog raphers.
</prevsent>
</prevsection>
<citsent citstr=" P01-1025 ">
we hypothesize that in list that has been inversely ranked with the variability measure valid mwes will occur at the top.the evaluation procedure used here (first suggested by evert and krenn (2001) <papid> P01-1025 </papid>for evaluating measures of lexical association) involves producing and evaluating just such ranking.</citsent>
<aftsection>
<nextsent>the rasp parser identifies 979,156 unique verb-noun pairs in the bnc.
</nextsent>
<nextsent>the measure of syntactic flexibility was used to inverse rank these items (the most fixed first).1this ranking was then evaluated using list of idioms taken from published dictionaries, by observing how many of the gold standard items were found in each top n, and calculating the accuracy score.
</nextsent>
<nextsent>2 by reason of the diverse nature of mwes, these.
</nextsent>
<nextsent>lists can be expected to contain manymwes that are not syntactically fixed, giving us very low upper bound.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4190">
<title id=" W07-1101.xml">a measure of syntactic flexibility for automatically identifying multiword expressions in corpora </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>by contrast, none of the collocation scores perform significantly better than frequency.
</prevsent>
<prevsent>3 3as very low frequency items have been observed to cause 6 syntactic variation collocation dictionary freq p,i &d; p,i,d &freq; mi llr 2 top 100 items long mans 14 21 15 16 0 13 0 said 21 17 17 23 0 17 0 both 28 18 25 32 0 25 0 top 1000 items long mans 6.6 10.4 10.2 6.3 0 6.5 0.3 said 9.1 9 9.9 9 0 8.1 0.2 both 12.2 14.2 15.2 12 0 11.4 0.4 top 5000 items long mans 3.24 4.28 4.84 3.12 0.06 3.44 0.58 said 3.86 3.56 4.54 3.68 0.04 3.86 0.54 both 5.56 5.86 7.68 5.34 0.04 5.66 0.88 table 2: accuracy for top 100, 1000 and 5000 items (scores beating frequency at   0.05 are in bold) an important issue for future research is how much the performance of our measure is affected by the technology used.
</prevsent>
</prevsection>
<citsent citstr=" E03-1025 ">
in an evalutaion of rasp, preiss (2003) <papid> E03-1025 </papid>reports an precision of 85.83 and recall of 78.48 for the direct object relation, 69.45/57.72 for the ncmod?</citsent>
<aftsection>
<nextsent>relation, and 91.15/98.77 for the detmod?
</nextsent>
<nextsent>relation.
</nextsent>
<nextsent>there is clearly some variance here, but it is not easy to see any straightforward relationship with our results.
</nextsent>
<nextsent>the highest performance relation (detmod?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4193">
<title id=" W07-2034.xml">hitirwsd a wsd system for english lexical sample task </title>
<section> knowledge sources.  </section>
<citcontext>
<prevsection>
<prevsent>many effective context words are not in short distance to the target word, but we shouldnt enlarge the window size too much in case of including too many noises.
</prevsent>
<prevsent>a solution to this problem is to use the syntactic relations of the target word and its parent head word.
</prevsent>
</prevsection>
<citsent citstr=" W06-2933 ">
we use nivre et al, (2006)<papid> W06-2933 </papid>s dependency parser.</citsent>
<aftsection>
<nextsent>in this part, we get 4 features from every instance: head word of the target word, the headwords pos, the headwords dependency relation with the target word and the relative position of the head word to the target word.
</nextsent>
<nextsent>still take the same instance which has been mentioned in the las subsection as example.
</nextsent>
<nextsent>the features we extracted are syn_head_is, syn_headpos_vbz, syn_relation_prd, syn_headright?, in which syn_head_is stands for is is the head word of age; syn_headpos_vbz stands for the pos of the 5http://www.lsi.upc.es/~nlp/svmtool/penntreebank.html?
</nextsent>
<nextsent>head word is is vbz; syn_relation_prd stands for the relationship between the head word is and target word age is prd; and syn_headright stands for the target word age is in the right side of the head word is.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4194">
<title id=" W07-1203.xml">filling statistics with linguistics  property design for the disambiguation of german lfg parses </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the grammar has coverage in terms of full parses that exceeds 80% on newspaper corpora.
</prevsent>
<prevsent>for sentences out of coverage, it employs the robustness techniques (fragment parsing, skimming?)
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
implemented in xle and described in riezler et al (2002), <papid> P02-1035 </papid>so that 100% of our corpus sentences receive at least some sort of analysis.</citsent>
<aftsection>
<nextsent>a dependency-based evaluation of the analyses produced by the grammar on the tiger dependency bank (forst et al, 2004)<papid> W04-1905 </papid>results in an f-score between 80.42% on all gram 17 matical relations and morphosyntactic features (or 72.59% on grammatical relations only) and 85.50%(or 79.36%).</nextsent>
<nextsent>the lower bound is based on an arbitrary selection among the parses built up by the symbolic grammar; the upper bound is determined by the best possible selection.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4195">
<title id=" W07-1203.xml">filling statistics with linguistics  property design for the disambiguation of german lfg parses </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>for sentences out of coverage, it employs the robustness techniques (fragment parsing, skimming?)
</prevsent>
<prevsent>implemented in xle and described in riezler et al (2002), <papid> P02-1035 </papid>so that 100% of our corpus sentences receive at least some sort of analysis.</prevsent>
</prevsection>
<citsent citstr=" W04-1905 ">
a dependency-based evaluation of the analyses produced by the grammar on the tiger dependency bank (forst et al, 2004)<papid> W04-1905 </papid>results in an f-score between 80.42% on all gram 17 matical relations and morphosyntactic features (or 72.59% on grammatical relations only) and 85.50%(or 79.36%).</citsent>
<aftsection>
<nextsent>the lower bound is based on an arbitrary selection among the parses built up by the symbolic grammar; the upper bound is determined by the best possible selection.
</nextsent>
<nextsent>2.2 log-linear models for disambiguation.
</nextsent>
<nextsent>since johnson et al (1999), <papid> P99-1069 </papid>log-linear models ofthe following form have become standard as disambiguation devices for precision grammars: p?(x|y) = m j=1 fj(x,y) ? xx(y) m j=1 fj(x ?,y)they are used for parse selection in the english resource grammar (toutanova et al, 2002), the english pargram lfg (riezler et al, 2002), <papid> P02-1035 </papid>the english enju hpsg (miyao and tsujii, 2002), the hpsg-inspired alpino parser for dutch (malouf and van noord, 2004; van noord, 2006) and the english ccg from edinburgh (clark and curran, 2004).<papid> P04-1014 </papid></nextsent>
<nextsent>while relatively much work has gone into the question of how to estimate the property weights 1 . . .</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4196">
<title id=" W07-1203.xml">filling statistics with linguistics  property design for the disambiguation of german lfg parses </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the lower bound is based on an arbitrary selection among the parses built up by the symbolic grammar; the upper bound is determined by the best possible selection.
</prevsent>
<prevsent>2.2 log-linear models for disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P99-1069 ">
since johnson et al (1999), <papid> P99-1069 </papid>log-linear models ofthe following form have become standard as disambiguation devices for precision grammars: p?(x|y) = m j=1 fj(x,y) ? xx(y) m j=1 fj(x ?,y)they are used for parse selection in the english resource grammar (toutanova et al, 2002), the english pargram lfg (riezler et al, 2002), <papid> P02-1035 </papid>the english enju hpsg (miyao and tsujii, 2002), the hpsg-inspired alpino parser for dutch (malouf and van noord, 2004; van noord, 2006) and the english ccg from edinburgh (clark and curran, 2004).<papid> P04-1014 </papid></citsent>
<aftsection>
<nextsent>while relatively much work has gone into the question of how to estimate the property weights 1 . . .
</nextsent>
<nextsent>m efficiently and accurately on the basis of (annotated) corpus data, the question of howto define suitable and informative property functions f1 . . .
</nextsent>
<nextsent>fmhas received relatively little attention.
</nextsent>
<nextsent>however, we are convinced that property design is the possibility of improving log-linear models for parse selection now that the machine learning machinery is relatively well established.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4198">
<title id=" W07-1203.xml">filling statistics with linguistics  property design for the disambiguation of german lfg parses </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the lower bound is based on an arbitrary selection among the parses built up by the symbolic grammar; the upper bound is determined by the best possible selection.
</prevsent>
<prevsent>2.2 log-linear models for disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
since johnson et al (1999), <papid> P99-1069 </papid>log-linear models ofthe following form have become standard as disambiguation devices for precision grammars: p?(x|y) = m j=1 fj(x,y) ? xx(y) m j=1 fj(x ?,y)they are used for parse selection in the english resource grammar (toutanova et al, 2002), the english pargram lfg (riezler et al, 2002), <papid> P02-1035 </papid>the english enju hpsg (miyao and tsujii, 2002), the hpsg-inspired alpino parser for dutch (malouf and van noord, 2004; van noord, 2006) and the english ccg from edinburgh (clark and curran, 2004).<papid> P04-1014 </papid></citsent>
<aftsection>
<nextsent>while relatively much work has gone into the question of how to estimate the property weights 1 . . .
</nextsent>
<nextsent>m efficiently and accurately on the basis of (annotated) corpus data, the question of howto define suitable and informative property functions f1 . . .
</nextsent>
<nextsent>fmhas received relatively little attention.
</nextsent>
<nextsent>however, we are convinced that property design is the possibility of improving log-linear models for parse selection now that the machine learning machinery is relatively well established.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4202">
<title id=" W07-1110.xml">semantic labeling of compound nominal ization in chinese </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>the rule-based approaches such as (finin, 1980; mcdonald, 1982; leonard,1984; vanderwende, 1995) think that the interpretation of ncs depends heavily on the constituent concepts and model the semantic interpretation as slot filling process.
</prevsent>
<prevsent>various rules are employed by such approaches to determine, for example, whether the modifier can fill in one slot of the head.the statistic-based approaches view the semantic interpretation as multi-class classification problem.
</prevsent>
</prevsection>
<citsent citstr=" W01-0511 ">
(rosario and hearst, 2001; <papid> W01-0511 </papid>moldovan et al,2004; <papid> W04-2609 </papid>kim and baldwin, 2005) use supervised methods and explore classification features from simple structured type hierarchy.</citsent>
<aftsection>
<nextsent>(kim and baldwin, 2006) <papid> P06-2064 </papid>use set of seed verbs to characterize the semantic relation between the constituent nouns and explores parsed corpus to classify ncs.</nextsent>
<nextsent>(turney, 2005) uses latent relational analysis to classify ncs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4203">
<title id=" W07-1110.xml">semantic labeling of compound nominal ization in chinese </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>the rule-based approaches such as (finin, 1980; mcdonald, 1982; leonard,1984; vanderwende, 1995) think that the interpretation of ncs depends heavily on the constituent concepts and model the semantic interpretation as slot filling process.
</prevsent>
<prevsent>various rules are employed by such approaches to determine, for example, whether the modifier can fill in one slot of the head.the statistic-based approaches view the semantic interpretation as multi-class classification problem.
</prevsent>
</prevsection>
<citsent citstr=" W04-2609 ">
(rosario and hearst, 2001; <papid> W01-0511 </papid>moldovan et al,2004; <papid> W04-2609 </papid>kim and baldwin, 2005) use supervised methods and explore classification features from simple structured type hierarchy.</citsent>
<aftsection>
<nextsent>(kim and baldwin, 2006) <papid> P06-2064 </papid>use set of seed verbs to characterize the semantic relation between the constituent nouns and explores parsed corpus to classify ncs.</nextsent>
<nextsent>(turney, 2005) uses latent relational analysis to classify ncs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4204">
<title id=" W07-1110.xml">semantic labeling of compound nominal ization in chinese </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>various rules are employed by such approaches to determine, for example, whether the modifier can fill in one slot of the head.the statistic-based approaches view the semantic interpretation as multi-class classification problem.
</prevsent>
<prevsent>(rosario and hearst, 2001; <papid> W01-0511 </papid>moldovan et al,2004; <papid> W04-2609 </papid>kim and baldwin, 2005) use supervised methods and explore classification features from simple structured type hierarchy.</prevsent>
</prevsection>
<citsent citstr=" P06-2064 ">
(kim and baldwin, 2006) <papid> P06-2064 </papid>use set of seed verbs to characterize the semantic relation between the constituent nouns and explores parsed corpus to classify ncs.</citsent>
<aftsection>
<nextsent>(turney, 2005) uses latent relational analysis to classify ncs.
</nextsent>
<nextsent>the similarity between two ncs is characterized by the similarity between their related pattern set.
</nextsent>
<nextsent>(lauer, 1995) is the first to use paraphrase based unsupervised statistical models to classify semantic relations of ncs.
</nextsent>
<nextsent>(lapata, 2000; grover et al, 2005; nicholson, 2005) use paraphrase statistics computed from parsed texts to interpret compound nominal ization, but the relations used are purely syntactic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4205">
<title id=" W07-1110.xml">semantic labeling of compound nominal ization in chinese </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 semantic role labeling of nominalization.
</prevsent>
<prevsent>most previous work on semantic role labeling of nominalizations are conducted in the situation where verb nominal ization is the head of general noun phrase.
</prevsent>
</prevsection>
<citsent citstr=" P87-1019 ">
(dahl et al, 1987; <papid> P87-1019 </papid>hull and gomez, 1996)use hand-coded slot-filling rules to determine these mantic roles of the arguments of nominalization.</citsent>
<aftsection>
<nextsent>in such approaches, first, parsers are used to identify syntactic clues such as prepositional types.
</nextsent>
<nextsent>then, rules are applied to label semantic roles according to clues and constraints of different roles.
</nextsent>
<nextsent>supervised machine learning methods become prevalent in recent years in semantic role labeling of verb nominalizations as part of the resurgence of research in shallow semantic analysis.
</nextsent>
<nextsent>(pradhan et al, 2004) <papid> N04-4036 </papid>use svm classifier for the semantic role labeling of nominalizations in english and chinese based on the framenet database and the chinese propbank respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4206">
<title id=" W07-1110.xml">semantic labeling of compound nominal ization in chinese </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>then, rules are applied to label semantic roles according to clues and constraints of different roles.
</prevsent>
<prevsent>supervised machine learning methods become prevalent in recent years in semantic role labeling of verb nominalizations as part of the resurgence of research in shallow semantic analysis.
</prevsent>
</prevsection>
<citsent citstr=" N04-4036 ">
(pradhan et al, 2004) <papid> N04-4036 </papid>use svm classifier for the semantic role labeling of nominalizations in english and chinese based on the framenet database and the chinese propbank respectively.</citsent>
<aftsection>
<nextsent>(xue, 2006) <papid> N06-1055 </papid>uses the chinese nombank to label nominalizations in chi nese.</nextsent>
<nextsent>compared to english, the main difficulty of using supervised method for chinese, as noted by xue (2006), <papid> N06-1055 </papid>is that the precision of current parsers of chinese is very low due to the lack of morphology, difficulty in segmentation and lack of sufficient training materials in chinese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4207">
<title id=" W07-1110.xml">semantic labeling of compound nominal ization in chinese </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>supervised machine learning methods become prevalent in recent years in semantic role labeling of verb nominalizations as part of the resurgence of research in shallow semantic analysis.
</prevsent>
<prevsent>(pradhan et al, 2004) <papid> N04-4036 </papid>use svm classifier for the semantic role labeling of nominalizations in english and chinese based on the framenet database and the chinese propbank respectively.</prevsent>
</prevsection>
<citsent citstr=" N06-1055 ">
(xue, 2006) <papid> N06-1055 </papid>uses the chinese nombank to label nominalizations in chi nese.</citsent>
<aftsection>
<nextsent>compared to english, the main difficulty of using supervised method for chinese, as noted by xue (2006), <papid> N06-1055 </papid>is that the precision of current parsers of chinese is very low due to the lack of morphology, difficulty in segmentation and lack of sufficient training materials in chinese.</nextsent>
<nextsent>2.3 web as large corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4209">
<title id=" W07-1110.xml">semantic labeling of compound nominal ization in chinese </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>(grefenstette and nioche, 2000;jones and ghani, 2000) use the web to generate corpora for languages for which electronic resources are scarce.
</prevsent>
<prevsent>(zhu and rosenfeld, 2001) use web based n-gram counts for language modeling.
</prevsent>
</prevsection>
<citsent citstr=" J03-3005 ">
(keller and lapata, 2003) <papid> J03-3005 </papid>show that web page counts and n-gram frequency counts are highly correlated in log scale.</citsent>
<aftsection>
<nextsent>74
</nextsent>
<nextsent>although verb nominal ization is commonly considered to have arguments as the verb predicate,xue(2006) <papid> N06-1055 </papid>finds that there tend to be fewer arguments and fewer types of adjuncts in verb nomi nalizations compared to verb predicates in chinese.</nextsent>
<nextsent>we argue that this phenomenon is more obvious in compound nominalization.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4211">
<title id=" W07-1110.xml">semantic labeling of compound nominal ization in chinese </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>finally, the 300 data instances were partitioned into training set and testing set containing 225 and 75 instances respectively.
</prevsent>
<prevsent>5.2 maximum entropy model.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
we use the maximum entropy (me) model (berger et al, 1996) <papid> J96-1002 </papid>for our classification task.</citsent>
<aftsection>
<nextsent>given set of training examples of random process, me is method of estimating the conditional probabilityp(y|x) that, given context x, the process will out put y. in our task, the output corresponds to the four relation labels pp, pa, ma andra.
</nextsent>
<nextsent>the modeling of me is based on the maximum entropy principle, that is, modeling all that is known and assuming nothing about what is unknown.
</nextsent>
<nextsent>the computation of p(y|x) is illustrated as the formula (2).
</nextsent>
<nextsent>fi(x, y) are binary valued feature functions with the parameter used to express the statistics of the data sample.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4212">
<title id=" W08-0213.xml">studying discourse and dialogue with sidgrid </title>
<section> sidgrid framework.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 motivation.
</prevsent>
<prevsent>recent research programs in multi-modal environments, including understanding and analysis of multi-party meeting data and oral history recording projects, have created an explosion of multi-modal datasets, including video and audio recordings,transcripts and other annotations, and increased interest in annotation and analysis of such data.
</prevsent>
</prevsection>
<citsent citstr=" W01-1601 ">
anumber of systems have been developed to manage and support annotation of multi-modal data, including annotation graphs (bird and liberman, 2001), exmeralda (schmidt, 2004), nite xml toolkit (carletta et al, 2003), multi tool (allwoodet al, 2001), <papid> W01-1601 </papid>anvil (kipp, 2001), and elan (wit tenburg et al, 2006).</citsent>
<aftsection>
<nextsent>the social informatics data grid (sidgrid), developed under the nsf cyberin fra structure program, aims to extend the capabilities of such systems by focusing on support for largescale, extensible distributed data annotation, sharing, and analysis.
</nextsent>
<nextsent>the system is open-source and multi-platform and based on existing open-source software and standards.
</nextsent>
<nextsent>the system greatly eases the integration of annotation with analysis though user defined functions both on the client-side for data exploration and on the tera grid for large-scale distributed data processing.
</nextsent>
<nextsent>a web-accessible repository supports data search, sharing, and distributedannotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4213">
<title id=" W08-0213.xml">studying discourse and dialogue with sidgrid </title>
<section> course setting and activities.  </section>
<citcontext>
<prevsection>
<prevsent>this collection includes automatic transcriptions of interviews from an oral history project, accompanied by manual segmentation created as part of the malach project (franz et al, 2003).
</prevsent>
<prevsent>the exercise employs the web-based portal to the tera grid to perform segmentation of multiple interviews in parallel on the grid, followed by evaluation in parallel.
</prevsent>
</prevsection>
<citsent citstr=" P03-1071 ">
we perform segmentation using lcseg (galley et al, 2003) <papid> P03-1071 </papid>and evaluate using the pk and window diff metrics.</citsent>
<aftsection>
<nextsent>students identify the best segmentation parameters for these interviews and perform error analysis to assess the effect of asr errors.
</nextsent>
<nextsent>the dialogue act tagging exercise involves both annotation and analysis components.
</nextsent>
<nextsent>the students are asked to download and annotate small portion of conversation from the ami corpus (carletta etal., 2005) with dialogue act tags.
</nextsent>
<nextsent>the ami corpus of multiparty meetings includes recorded video, recorded audio, aligned manual transcriptions, and manually annotated head and hand gesture.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4214">
<title id=" W08-0213.xml">studying discourse and dialogue with sidgrid </title>
<section> course setting and activities.  </section>
<citcontext>
<prevsection>
<prevsent>students are asked to assess the influence of different features on their annotation process and to compare to gold standard annotation which is later provided.
</prevsent>
<prevsent>the automatic analysis phase is performed on the web-based portal to assess the impact of different feature sets on automatic tagging.
</prevsent>
</prevsection>
<citsent citstr=" P04-1088 ">
the tagging isdone in the feature latent semantic analysis framework (serafin and di eugenio, 2004), <papid> P04-1088 </papid>augmented with additional prosodic and multi-modal features drawn from the annotation.</citsent>
<aftsection>
<nextsent>since this analysis requires singular value decomposition of the potentially large feature-by-dialogue-act matrices, it is often impractical to execute on single personal oreven departmental servers.
</nextsent>
<nextsent>furthermore, feature extraction, such as pitch tracking, of the full conversation can itself strain the computational resources available to students.
</nextsent>
<nextsent>grid-based processing overcomes both of these problems.
</nextsent>
<nextsent>exercises on turn-taking follow similar patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4215">
<title id=" W08-0213.xml">studying discourse and dialogue with sidgrid </title>
<section> impact on interdisciplinary instruction.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, the web-based archive provides simple mechanisms to browse and download range of data sources.
</prevsent>
<prevsent>the students all found the archive, download, and transformation mechanisms easy to use, regardless of prior programming experience.
</prevsent>
</prevsection>
<citsent citstr=" P04-3031 ">
itis important to remember that the goal of this environment is not to replace existing software systems for natural language processing, such the natural language toolkit (nltk) (bird and loper, 2004),<papid> P04-3031 </papid>but rather to provide simpler interface to such software tools and to support their application to potentially large datasets, irrespective of the processing power of the individual user?</citsent>
<aftsection>
<nextsent>system.
</nextsent>
<nextsent>4.2 enabling large-scale experimentation.
</nextsent>
<nextsent>a second goal is to enable larger-scale experimentation by both expert and non-expert users.
</nextsent>
<nextsent>the use of the web-based portal to the tera grid provides such opportunities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4216">
<title id=" W07-0723.xml">getting to know moses initial experiments on german english factored translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our experiments we combined syntactic and morphological factors from an off-the-shelf parser with the factored translation framework in moses (moses, 2007).
</prevsent>
<prevsent>we wanted to test the following hypotheses: ? translation models based on lemmas will im prove translation quality (popovi?
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
and ney, 2004) ? decompounding german nominal compounds will improve translation quality (koehn and knight, 2003) ? <papid> E03-1076 </papid>re-ordering models based on word forms and parts-of-speech will improve translation quality (zens and ney, 2006).<papid> W06-3108 </papid></citsent>
<aftsection>
<nextsent>the parser, machin ese syntax, is commercially available dependency parser from conn exor oy 1.
</nextsent>
<nextsent>it provides each word with lemma, part-of-speech, morphological features and dependency relations (see figure 1).
</nextsent>
<nextsent>in addition, the lemmas of compounds are marked by ?#?
</nextsent>
<nextsent>separating the two parts of the compound.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4217">
<title id=" W07-0723.xml">getting to know moses initial experiments on german english factored translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our experiments we combined syntactic and morphological factors from an off-the-shelf parser with the factored translation framework in moses (moses, 2007).
</prevsent>
<prevsent>we wanted to test the following hypotheses: ? translation models based on lemmas will im prove translation quality (popovi?
</prevsent>
</prevsection>
<citsent citstr=" W06-3108 ">
and ney, 2004) ? decompounding german nominal compounds will improve translation quality (koehn and knight, 2003) ? <papid> E03-1076 </papid>re-ordering models based on word forms and parts-of-speech will improve translation quality (zens and ney, 2006).<papid> W06-3108 </papid></citsent>
<aftsection>
<nextsent>the parser, machin ese syntax, is commercially available dependency parser from conn exor oy 1.
</nextsent>
<nextsent>it provides each word with lemma, part-of-speech, morphological features and dependency relations (see figure 1).
</nextsent>
<nextsent>in addition, the lemmas of compounds are marked by ?#?
</nextsent>
<nextsent>separating the two parts of the compound.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4218">
<title id=" W07-0723.xml">getting to know moses initial experiments on german english factored translation </title>
<section> the parser.  </section>
<citcontext>
<prevsection>
<prevsent>some common multiword units, such as at all?
</prevsent>
<prevsent>and von heute?, are treated as single words by the parser (cf.
</prevsent>
</prevsection>
<citsent citstr=" J04-2003 ">
niessen and ney, 2004).<papid> J04-2003 </papid></citsent>
<aftsection>
<nextsent>the german parser also splits contracted prepositions and determiners like zum?
</nextsent>
<nextsent>zu dem?
</nextsent>
<nextsent>(to the?).
</nextsent>
<nextsent>for our experiments with moses we basically followed the shared task baseline system setup to train our factored translation models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4221">
<title id=" W07-0723.xml">getting to know moses initial experiments on german english factored translation </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>among these were cases that can be handled such as separable prefix verbs like aufzeigten?
</prevsent>
<prevsent>(pointed out?)
</prevsent>
</prevsection>
<citsent citstr=" C00-2162 ">
(niessen and ney, 2000) <papid> C00-2162 </papid>or adjective compounds such as multidimensionale?</citsent>
<aftsection>
<nextsent>(multi dimensional?).
</nextsent>
<nextsent>there were also some noun compounds left which indicates that we might need better decompounding strategy than the one used by the parser (see e.g. koehn and knight, 2003).<papid> E03-1076 </papid></nextsent>
<nextsent>4.2 experiences and future plans.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4224">
<title id=" W07-2052.xml">naistjapan temporal relation identification using dependency parsed tree </title>
<section> features from dependency parsed tree.  </section>
<citcontext>
<prevsection>
<prevsent>a dependency relation is head-modifier relation ona syntactic tree.
</prevsent>
<prevsent>figure 4 shows an example dependency parsed tree of the following sentence ? the warrants may be exercised until 90 days after their issue date?.
</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
we parsed the timeeval data using mst parser v0.2 (mcdonald and pereira, 2006), <papid> E06-1011 </papid>which is trained with all penn treebank (marcus et al., 1993) <papid> J93-2004 </papid>without dependency label.we introduce tree position labels between antar get node and another node on the dependency parsedtree: anc (ancestor), des (descendant), sib (sib ling), and target (target word).</citsent>
<aftsection>
<nextsent>figure 5 shows the labels, in which the box with double lines is the target node.
</nextsent>
<nextsent>the tree position between the target event and word in the target timex3 is used as feature for our machine learning-based relation identifier.
</nextsent>
<nextsent>we also use the words in the sentence including the target entities as features.
</nextsent>
<nextsent>each word is anno 246 the warrants may be exercised until 90 days after their issue date figure 4: an example of dependency parsed tree anc anc target des anc sib desdes sib anc figure 5: tree position labels the warrants may be exercised until 90 days after their issue date anc anc anc anc des des des des des des des target the warrants may be exercised until 90 days after their issue date anc anc anc anc anc anc target target sib sib sib anc the warrants may be exercised until 90 days after their issue date anc/anc anc/anc anc/anc anc/anc des/anc des/anc des/target des/target des/sib des/sib des/sib target/anc target node: exercised?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4225">
<title id=" W07-2052.xml">naistjapan temporal relation identification using dependency parsed tree </title>
<section> features from dependency parsed tree.  </section>
<citcontext>
<prevsection>
<prevsent>a dependency relation is head-modifier relation ona syntactic tree.
</prevsent>
<prevsent>figure 4 shows an example dependency parsed tree of the following sentence ? the warrants may be exercised until 90 days after their issue date?.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we parsed the timeeval data using mst parser v0.2 (mcdonald and pereira, 2006), <papid> E06-1011 </papid>which is trained with all penn treebank (marcus et al., 1993) <papid> J93-2004 </papid>without dependency label.we introduce tree position labels between antar get node and another node on the dependency parsedtree: anc (ancestor), des (descendant), sib (sib ling), and target (target word).</citsent>
<aftsection>
<nextsent>figure 5 shows the labels, in which the box with double lines is the target node.
</nextsent>
<nextsent>the tree position between the target event and word in the target timex3 is used as feature for our machine learning-based relation identifier.
</nextsent>
<nextsent>we also use the words in the sentence including the target entities as features.
</nextsent>
<nextsent>each word is anno 246 the warrants may be exercised until 90 days after their issue date figure 4: an example of dependency parsed tree anc anc target des anc sib desdes sib anc figure 5: tree position labels the warrants may be exercised until 90 days after their issue date anc anc anc anc des des des des des des des target the warrants may be exercised until 90 days after their issue date anc anc anc anc anc anc target target sib sib sib anc the warrants may be exercised until 90 days after their issue date anc/anc anc/anc anc/anc anc/anc des/anc des/anc des/target des/target des/sib des/sib des/sib target/anc target node: exercised?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4226">
<title id=" W07-2052.xml">naistjapan temporal relation identification using dependency parsed tree </title>
<section> results and discussions.  </section>
<citcontext>
<prevsection>
<prevsent>(  stands for wild cards) label (1) of tree position from the event to the timex3 all words in the succeeding sentence table 2: features for task all attributes in the target even tall attributes in the target timex3 of in the current sentence with event-based label (1) of tree position all attributes in the target timex3 of in the preceding and succeeding sentence all words in the current sentence with event-based label (1) of tree position all words in the succeeding sentence table 3: features for task all attributes in the target two events (event-1 and event-2) all attributes in the timex3 in the sentence includingevent-1 with the label (1) of tree position to event 1 all attributes in the timex3 in the sentence includingevent-2 with the label (1) of tree position to event 2 all words in the sentence including event-1 with the label (1) of tree position to event-1 all words in the sentence including event-2 with the label (1) of tree position to event-2 machine learners such as maximum entropy andmulti-class support vector machines.
</prevsent>
<prevsent>however, sequence labeling method with hmm svm outperformed other point-wise methods in the trial data.we have dependency parsed trees of the sentences.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
naturally, it would be effective to introduce point-wise tree-based classifiers such as tree kernels in svm (collins and duffy, 2002; <papid> P02-1034 </papid>vishwanathan and smola, 2002) and boosting for classification of trees (kudo and matsumoto, 2004).<papid> W04-3239 </papid></citsent>
<aftsection>
<nextsent>we tried boosting learner 3which enables us to perform subtree feature selection for the tasks.
</nextsent>
<nextsent>however, the boosting learner selected only one-node subtrees as useful features.
</nextsent>
<nextsent>thus, we perform simple vector based feature engineering on hmm svm.
</nextsent>
<nextsent>3http://chasen.org/taku/software/bact/ table 4: results task r rank task (strict) 0.61 0.61 0.61 2/6 task (relaxed) 0.63 0.63 0.63 2/6 task (strict) 0.75 0.75 0.75 2/6 task (relaxed) 0.76 0.76 0.76 2/6 task (strict) 0.49 0.49 0.49 5/6 task (relaxed) 0.56 0.56 0.56 6/6 we believe that it is necessary for solving task to incorporate knowledge of verb-verb relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4227">
<title id=" W07-2052.xml">naistjapan temporal relation identification using dependency parsed tree </title>
<section> results and discussions.  </section>
<citcontext>
<prevsection>
<prevsent>(  stands for wild cards) label (1) of tree position from the event to the timex3 all words in the succeeding sentence table 2: features for task all attributes in the target even tall attributes in the target timex3 of in the current sentence with event-based label (1) of tree position all attributes in the target timex3 of in the preceding and succeeding sentence all words in the current sentence with event-based label (1) of tree position all words in the succeeding sentence table 3: features for task all attributes in the target two events (event-1 and event-2) all attributes in the timex3 in the sentence includingevent-1 with the label (1) of tree position to event 1 all attributes in the timex3 in the sentence includingevent-2 with the label (1) of tree position to event 2 all words in the sentence including event-1 with the label (1) of tree position to event-1 all words in the sentence including event-2 with the label (1) of tree position to event-2 machine learners such as maximum entropy andmulti-class support vector machines.
</prevsent>
<prevsent>however, sequence labeling method with hmm svm outperformed other point-wise methods in the trial data.we have dependency parsed trees of the sentences.
</prevsent>
</prevsection>
<citsent citstr=" W04-3239 ">
naturally, it would be effective to introduce point-wise tree-based classifiers such as tree kernels in svm (collins and duffy, 2002; <papid> P02-1034 </papid>vishwanathan and smola, 2002) and boosting for classification of trees (kudo and matsumoto, 2004).<papid> W04-3239 </papid></citsent>
<aftsection>
<nextsent>we tried boosting learner 3which enables us to perform subtree feature selection for the tasks.
</nextsent>
<nextsent>however, the boosting learner selected only one-node subtrees as useful features.
</nextsent>
<nextsent>thus, we perform simple vector based feature engineering on hmm svm.
</nextsent>
<nextsent>3http://chasen.org/taku/software/bact/ table 4: results task r rank task (strict) 0.61 0.61 0.61 2/6 task (relaxed) 0.63 0.63 0.63 2/6 task (strict) 0.75 0.75 0.75 2/6 task (relaxed) 0.76 0.76 0.76 2/6 task (strict) 0.49 0.49 0.49 5/6 task (relaxed) 0.56 0.56 0.56 6/6 we believe that it is necessary for solving task to incorporate knowledge of verb-verb relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4228">
<title id=" W07-2052.xml">naistjapan temporal relation identification using dependency parsed tree </title>
<section> results and discussions.  </section>
<citcontext>
<prevsection>
<prevsent>thus, we perform simple vector based feature engineering on hmm svm.
</prevsent>
<prevsent>3http://chasen.org/taku/software/bact/ table 4: results task r rank task (strict) 0.61 0.61 0.61 2/6 task (relaxed) 0.63 0.63 0.63 2/6 task (strict) 0.75 0.75 0.75 2/6 task (relaxed) 0.76 0.76 0.76 2/6 task (strict) 0.49 0.49 0.49 5/6 task (relaxed) 0.56 0.56 0.56 6/6 we believe that it is necessary for solving task to incorporate knowledge of verb-verb relation.
</prevsent>
</prevsection>
<citsent citstr=" P06-1095 ">
we also tried to use features in verb ontology such as verb ocean (chklovsky and pantel, 2004) which is used in (mani et al, 2006).<papid> P06-1095 </papid></citsent>
<aftsection>
<nextsent>it did not improved performance in our preliminary experiments with trial data.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4229">
<title id=" W07-1308.xml">phonological reconstruction of a dead language using the gradual learning algorithm </title>
<section> implementation of h-eval.  </section>
<citcontext>
<prevsection>
<prevsent>for an annotation graph to be aligned?, every grapheme must be licensed by some part of the phonology, and every phoneme must be represented in the orthography.
</prevsent>
<prevsent>without such licensing relationship, it is impossible tomake the comparisons needed to count constraint violations.
</prevsent>
</prevsection>
<citsent citstr=" W06-1107 ">
there is considerable previous work in the area of alignment, most recently summarized by kondrak and sherif (2006).<papid> W06-1107 </papid></citsent>
<aftsection>
<nextsent>the algorithm used in this study is similarity-based approach, not unlike aline(kondrak, 2000).<papid> A00-2038 </papid></nextsent>
<nextsent>it differs in some significant respects, notably the use of binary features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4230">
<title id=" W07-1308.xml">phonological reconstruction of a dead language using the gradual learning algorithm </title>
<section> implementation of h-eval.  </section>
<citcontext>
<prevsection>
<prevsent>without such licensing relationship, it is impossible tomake the comparisons needed to count constraint violations.
</prevsent>
<prevsent>there is considerable previous work in the area of alignment, most recently summarized by kondrak and sherif (2006).<papid> W06-1107 </papid></prevsent>
</prevsection>
<citsent citstr=" A00-2038 ">
the algorithm used in this study is similarity-based approach, not unlike aline(kondrak, 2000).<papid> A00-2038 </papid></citsent>
<aftsection>
<nextsent>it differs in some significant respects, notably the use of binary features.
</nextsent>
<nextsent>determining the eligibility of two phonemes for matching requires distance function.
</nextsent>
<nextsent>the approach taken was to assign weight to each phonological feature, and to calculate the distance as the sum of the weights of all features that differ between the two phonemes.
</nextsent>
<nextsent>the full listing of feature weights isshown in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4231">
<title id=" W07-0806.xml">adapting a medical speech to speech translation system medslt to arabic </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this article focuses on the system development for arabic.
</prevsent>
<prevsent>in general, translation in this context raises two specific questions: 1) how to achieve recognition quality that is good enough for translation, and 2) how to get translations to be as idiomatic as possible so they can be understood by the patient.
</prevsent>
</prevsection>
<citsent citstr=" W06-3701 ">
for close languages and domains where accuracy is not very important (e.g. information requests), it may be possible to combine statistical recognizer with commercial translation system as it is often done in commercial tools such as spoken translation (seligman and dillinger, 2006).<papid> W06-3701 </papid></citsent>
<aftsection>
<nextsent>however, for this specific application in multilingual context, this solution is not applicable at all: even if perfect recognition were possible (which is far from being the case), current commercial tools for translating to arabic do not guarantee good quality.
</nextsent>
<nextsent>the domain dealt with here contains, in fact, many structures specific to this type of oral dialogue that can not be handled by these systems.
</nextsent>
<nextsent>for example, all the doctors interactions with the medslt system consist of questions whose structures differ from one language to another, with each language having its own constraints.
</nextsent>
<nextsent>consequently, two types of errors occur in arabic translation systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4232">
<title id=" W07-0806.xml">adapting a medical speech to speech translation system medslt to arabic </title>
<section> the architecture.  </section>
<citcontext>
<prevsection>
<prevsent>first, all the language models (for recognition, analysis, generation) are produced from linguistically motivated, general unification grammars using the regulus platform (rayner, et al, 2006).
</prevsent>
<prevsent>first, domain specific unification grammars are created from the general grammar for the different domains of medical diagnosis through trainable corpus-based automatic grammar specialization process.
</prevsent>
</prevsection>
<citsent citstr=" J90-1004 ">
they are, next, compiled into context free grammars (cfgs) in format suitable for use with the nuance speech 42 recognition platform, and into form needed for variant of semantic head-driven generation (shie beret al, 1990).<papid> J90-1004 </papid></citsent>
<aftsection>
<nextsent>therefore, the different grammars needed by the system under this approach are easy to build and maintain.
</nextsent>
<nextsent>this leads us to the second feature.
</nextsent>
<nextsent>because grammar-based speech recognition only produces competitive results for the sentences covered by the grammar, the user will need to learn the cover age of the system.
</nextsent>
<nextsent>in order to assist in this, help system is included in the system (starlander et al, 2005 and chatzichrisafis et al, 2006).<papid> W06-3702 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4233">
<title id=" W07-0806.xml">adapting a medical speech to speech translation system medslt to arabic </title>
<section> the architecture.  </section>
<citcontext>
<prevsection>
<prevsent>this leads us to the second feature.
</prevsent>
<prevsent>because grammar-based speech recognition only produces competitive results for the sentences covered by the grammar, the user will need to learn the cover age of the system.
</prevsent>
</prevsection>
<citsent citstr=" W06-3702 ">
in order to assist in this, help system is included in the system (starlander et al, 2005 and chatzichrisafis et al, 2006).<papid> W06-3702 </papid></citsent>
<aftsection>
<nextsent>the help system suggests, after each user utterance, similar utterances covered by the grammar which can be taken as model.
</nextsent>
<nextsent>in order to derive the help sentences, the system performs, in parallel, statistical recognition of the input speech.
</nextsent>
<nextsent>it then compares the recognition result using an n-gram based metric, against set of known correct in-coverage questions to extract the most similar ones.
</nextsent>
<nextsent>it is in that way that we introduce some of the robustness of the statistical systems in the controlled application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4235">
<title id=" W07-2003.xml">semeval2007 task 04 classification of semantic relations between nominals </title>
<section> task description and related work.  </section>
<citcontext>
<prevsection>
<prevsent>the classification occurs in the context of sentence in written english text.
</prevsent>
<prevsent>algorithms for classifying semantic relations can be applied in information retrieval, information extraction, text summarization, question answering and so on.
</prevsent>
</prevsection>
<citsent citstr=" H05-1047 ">
the recognition of textual entailment (tatu and moldovan, 2005) <papid> H05-1047 </papid>is an example of successful use ofthis type of deeper analysis in high-end nlp appli cations.</citsent>
<aftsection>
<nextsent>the literature shows wide variety of methods of nominal relation classification.
</nextsent>
<nextsent>they depend asmuch on the training data as on the domain of application and the available resources.
</nextsent>
<nextsent>rosario and hearst (2001) <papid> W01-0511 </papid>classify noun compounds from the domain of medicine, using 13 classes that describe the semantic relation between the head noun and the modifier in given noun compound.</nextsent>
<nextsent>rosario et al (2002) <papid> P02-1032 </papid>classify noun compounds using themesh hierarchy and multi-level hierarchy of semantic relations, with 15 classes at the top level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4236">
<title id=" W07-2003.xml">semeval2007 task 04 classification of semantic relations between nominals </title>
<section> task description and related work.  </section>
<citcontext>
<prevsection>
<prevsent>the literature shows wide variety of methods of nominal relation classification.
</prevsent>
<prevsent>they depend asmuch on the training data as on the domain of application and the available resources.
</prevsent>
</prevsection>
<citsent citstr=" W01-0511 ">
rosario and hearst (2001) <papid> W01-0511 </papid>classify noun compounds from the domain of medicine, using 13 classes that describe the semantic relation between the head noun and the modifier in given noun compound.</citsent>
<aftsection>
<nextsent>rosario et al (2002) <papid> P02-1032 </papid>classify noun compounds using themesh hierarchy and multi-level hierarchy of semantic relations, with 15 classes at the top level.</nextsent>
<nextsent>nastase and szpakowicz (2003) present two-level hierarchy for classifying noun-modifier relations in base noun phrases from general text, with 5 class esat the top and 30 classes at the bottom; other researchers (turney and littman, 2005; turney, 2005; nastase et al, 2006) have used their class scheme and data set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4237">
<title id=" W07-2003.xml">semeval2007 task 04 classification of semantic relations between nominals </title>
<section> task description and related work.  </section>
<citcontext>
<prevsection>
<prevsent>they depend asmuch on the training data as on the domain of application and the available resources.
</prevsent>
<prevsent>rosario and hearst (2001) <papid> W01-0511 </papid>classify noun compounds from the domain of medicine, using 13 classes that describe the semantic relation between the head noun and the modifier in given noun compound.</prevsent>
</prevsection>
<citsent citstr=" P02-1032 ">
rosario et al (2002) <papid> P02-1032 </papid>classify noun compounds using themesh hierarchy and multi-level hierarchy of semantic relations, with 15 classes at the top level.</citsent>
<aftsection>
<nextsent>nastase and szpakowicz (2003) present two-level hierarchy for classifying noun-modifier relations in base noun phrases from general text, with 5 class esat the top and 30 classes at the bottom; other researchers (turney and littman, 2005; turney, 2005; nastase et al, 2006) have used their class scheme and dataset.
</nextsent>
<nextsent>moldovan et al (2004) <papid> W04-2609 </papid>propose 35 class scheme to classify relations in various phrases;the same scheme has been applied to noun compounds and other noun phrases (girju et al, 2005).</nextsent>
<nextsent>chklovski and pantel (2004) <papid> W04-3205 </papid>introduce 5-class set, designed specifically for characterizing verb-verb semantic relations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4238">
<title id=" W07-2003.xml">semeval2007 task 04 classification of semantic relations between nominals </title>
<section> task description and related work.  </section>
<citcontext>
<prevsection>
<prevsent>rosario et al (2002) <papid> P02-1032 </papid>classify noun compounds using themesh hierarchy and multi-level hierarchy of semantic relations, with 15 classes at the top level.</prevsent>
<prevsent>nastase and szpakowicz (2003) present two-level hierarchy for classifying noun-modifier relations in base noun phrases from general text, with 5 class esat the top and 30 classes at the bottom; other researchers (turney and littman, 2005; turney, 2005; nastase et al, 2006) have used their class scheme and data set.</prevsent>
</prevsection>
<citsent citstr=" W04-2609 ">
moldovan et al (2004) <papid> W04-2609 </papid>propose 35 class scheme to classify relations in various phrases;the same scheme has been applied to noun compounds and other noun phrases (girju et al, 2005).</citsent>
<aftsection>
<nextsent>chklovski and pantel (2004) <papid> W04-3205 </papid>introduce 5-class set, designed specifically for characterizing verb-verb semantic relations.</nextsent>
<nextsent>stephens et al (2001) propose17 classes targeted to relations between genes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4239">
<title id=" W07-2003.xml">semeval2007 task 04 classification of semantic relations between nominals </title>
<section> task description and related work.  </section>
<citcontext>
<prevsection>
<prevsent>nastase and szpakowicz (2003) present two-level hierarchy for classifying noun-modifier relations in base noun phrases from general text, with 5 class esat the top and 30 classes at the bottom; other researchers (turney and littman, 2005; turney, 2005; nastase et al, 2006) have used their class scheme and dataset.
</prevsent>
<prevsent>moldovan et al (2004) <papid> W04-2609 </papid>propose 35 class scheme to classify relations in various phrases;the same scheme has been applied to noun compounds and other noun phrases (girju et al, 2005).</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
chklovski and pantel (2004) <papid> W04-3205 </papid>introduce 5-class set, designed specifically for characterizing verb-verb semantic relations.</citsent>
<aftsection>
<nextsent>stephens et al (2001) propose17 classes targeted to relations between genes.
</nextsent>
<nextsent>lapata (2002) <papid> J02-3004 </papid>presents binary classification of relations in nominalizations.</nextsent>
<nextsent>there is little consensus on the relation sets and algorithms for analyzing semantic relations, and it seems unlikely that any single scheme could workfor all applications.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4240">
<title id=" W07-2003.xml">semeval2007 task 04 classification of semantic relations between nominals </title>
<section> task description and related work.  </section>
<citcontext>
<prevsection>
<prevsent>chklovski and pantel (2004) <papid> W04-3205 </papid>introduce 5-class set, designed specifically for characterizing verb-verb semantic relations.</prevsent>
<prevsent>stephens et al (2001) propose17 classes targeted to relations between genes.</prevsent>
</prevsection>
<citsent citstr=" J02-3004 ">
lapata (2002) <papid> J02-3004 </papid>presents binary classification of relations in nominalizations.</citsent>
<aftsection>
<nextsent>there is little consensus on the relation sets and algorithms for analyzing semantic relations, and it seems unlikely that any single scheme could workfor all applications.
</nextsent>
<nextsent>for example, the gene-gene relation scheme of stephens et al (2001), with relations like phosphorylates y, is unlikely to be transferred easily to general text.
</nextsent>
<nextsent>we have created benchmark dataset to allow the evaluation of different semantic relation classification algorithms.
</nextsent>
<nextsent>we do not presume to propose single classification scheme, however alluring it would 13 relation training data test data agreement example positive set size positive set size (independent tagging) cause-effect 52.1% 140 51.3% 80 86.1% laugh (cause) wrinkles (effect) instrument-agency 50.7% 140 48.7% 78 69.6% laser (instrument) printer (agency) product-producer 60.7% 140 66.7% 93 68.5% honey (product) bee (producer) origin-entity 38.6% 140 44.4% 81 77.8% message (entity) from outer-space (origin) theme-tool 41.4% 140 40.8% 71 47.8% news (theme) conference(tool) part-whole 46.4% 140 36.1% 72 73.2% the door (part) of the car (whole) content-container 46.4% 140 51.4% 74 69.1% the apples (content) in the basket (container) table 1: dataset statistics be to try to design unified standard ? it would be likely to have shortcomings just as any of the others we have just reviewed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4242">
<title id=" W07-2003.xml">semeval2007 task 04 classification of semantic relations between nominals </title>
<section> building the annotated datasets.  </section>
<citcontext>
<prevsection>
<prevsent>we wrote seven detailed definitions, including restrictions and conventions, plus prototypical positive and near-miss negative examples.
</prevsent>
<prevsent>for each relation separately, we based data collection on wild-card search patterns that google allows.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
we built the patterns manually, following hearst (1992) <papid> C92-2082 </papid>and nakov and hearst (2006).</citsent>
<aftsection>
<nextsent>instances of the relation content-container, for example, come up in response to queries such as?* contains *?, ?* holds *?, the * in the *?.
</nextsent>
<nextsent>following the model of the senseval-3 english lexical sample task, we set out to collect 140 training and at least 70 test examples per relation, so we had number of different patterns to ensure variety.
</nextsent>
<nextsent>we also aimed to collect balanced number of positive and negative examples.
</nextsent>
<nextsent>the use of heuristic patterns to search for both positive and negative examples should naturally result in negative examples that are near misses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4243">
<title id=" W07-2003.xml">semeval2007 task 04 classification of semantic relations between nominals </title>
<section> the participants.  </section>
<citcontext>
<prevsection>
<prevsent>the systems?
</prevsent>
<prevsent>performance information in terms of precision, recall, -measure and accuracy, macro averaged over all relations, appears in table 3.
</prevsent>
</prevsection>
<citsent citstr=" H91-1061 ">
we computed these measures as described in lewis (1991).<papid> H91-1061 </papid></citsent>
<aftsection>
<nextsent>we distinguish four categories of systems based on the type of information used ? wordnet senses and/or google queries: ? wordnet = no &amp; query = no; ? wordnet = yes &amp; query = no; ? wordnet = no &amp; query = yes; ? wordnet = yes &amp; query = yes.
</nextsent>
<nextsent>wordnet = yes?
</nextsent>
<nextsent>or wordnet = no? tells usonly whether system uses the wordnet sense labels in the datasets.
</nextsent>
<nextsent>a system may use wordnet internally for varied purposes, but ignore our sense labels; such system would be in category or . based on the input variation, each submitted system may have up to 4 variations ? a,b,c,d. table 2 presents three baselines for relation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4244">
<title id=" W08-0708.xml">evaluating an agglutinative segmentation model for paramor </title>
<section> unsupervised morphology induction.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P07-1013 ">
analyzing the morphological structure of words can benefit natural language processing (nlp) applications from grapheme-to-phoneme conversion (demberg et al, 2007) <papid> P07-1013 </papid>to machine translation (goldwater and mcclosky, 2005).<papid> H05-1085 </papid></citsent>
<aftsection>
<nextsent>but many of the worlds languages currently lack morphological analysis systems.
</nextsent>
<nextsent>unsupervised induction could facilitate, for these lesser-resourced languages, the quick development of morphological systems from raw text corpora.
</nextsent>
<nextsent>unsupervised morphology induction has been shown to help nlp tasks including speech recognition (creutz, 2006) and information retrieval (kurimo et al, 2007b).
</nextsent>
<nextsent>in this paper we work with languages like spanish, german, and turkish for which morphological analysis systems already exist.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4245">
<title id=" W08-0708.xml">evaluating an agglutinative segmentation model for paramor </title>
<section> unsupervised morphology induction.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" H05-1085 ">
analyzing the morphological structure of words can benefit natural language processing (nlp) applications from grapheme-to-phoneme conversion (demberg et al, 2007) <papid> P07-1013 </papid>to machine translation (goldwater and mcclosky, 2005).<papid> H05-1085 </papid></citsent>
<aftsection>
<nextsent>but many of the worlds languages currently lack morphological analysis systems.
</nextsent>
<nextsent>unsupervised induction could facilitate, for these lesser-resourced languages, the quick development of morphological systems from raw text corpora.
</nextsent>
<nextsent>unsupervised morphology induction has been shown to help nlp tasks including speech recognition (creutz, 2006) and information retrieval (kurimo et al, 2007b).
</nextsent>
<nextsent>in this paper we work with languages like spanish, german, and turkish for which morphological analysis systems already exist.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4246">
<title id=" W08-0708.xml">evaluating an agglutinative segmentation model for paramor </title>
<section> unsupervised morphology induction.  </section>
<citcontext>
<prevsection>
<prevsent>unsupervised morphology induction has been shown to help nlp tasks including speech recognition (creutz, 2006) and information retrieval (kurimo et al, 2007b).
</prevsent>
<prevsent>in this paper we work with languages like spanish, german, and turkish for which morphological analysis systems already exist.
</prevsent>
</prevsection>
<citsent citstr=" W07-1315 ">
the baseline paramor algorithm which we extend here competed in the english and german tracks of morpho challenge 2007 (monson et al, 2007<papid> W07-1315 </papid>b).</citsent>
<aftsection>
<nextsent>the peer operated competitions of the morpho challenge series standardize the evaluation of unsupervised morphology induction algorithms (kurimo et al, 2007a; 2007b).
</nextsent>
<nextsent>the paramor algorithm showed promise in the 2007 challenge, placing first in the linguistic evaluation of german.
</nextsent>
<nextsent>developed after the close of morpho challenge 2007, our improvements to the paramor algorithm could not officially compete in this challenge.
</nextsent>
<nextsent>however, the morpho challenge 2007 organizing committee (kurimo et al, 2008) graciously over saw the quantitative evaluation of our agglutinative version of paramor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4252">
<title id=" W08-0708.xml">evaluating an agglutinative segmentation model for paramor </title>
<section> unsupervised morphology induction.  </section>
<citcontext>
<prevsection>
<prevsent>since character sequences are less predictable at morpheme boundaries than within any particular morpheme (see discussion in section 2.1), first unsupervised mor 49phology induction technique measures the predictability of word-internal character sequences.
</prevsent>
<prevsent>harris (1955) was the first to propose the branching factor of the character tree of corpus vocabulary as measure of character predictability.
</prevsent>
</prevsection>
<citsent citstr=" N01-1024 ">
character trees have been incorporated into number of more recently proposed unsupervised morphology induction systems (schone and jurafsky, 2001; <papid> N01-1024 </papid>wicentowski, 2002; goldsmith, 2006; bordag, 2007).</citsent>
<aftsection>
<nextsent>johnson and martin (2003) <papid> N03-2015 </papid>generalize from character trees and model morphological character sequences with minimized finite state automata.</nextsent>
<nextsent>bernhard (2007) measures character predictability by directly computing transitional probabilities between sub strings of words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4253">
<title id=" W08-0708.xml">evaluating an agglutinative segmentation model for paramor </title>
<section> unsupervised morphology induction.  </section>
<citcontext>
<prevsection>
<prevsent>harris (1955) was the first to propose the branching factor of the character tree of corpus vocabulary as measure of character predictability.
</prevsent>
<prevsent>character trees have been incorporated into number of more recently proposed unsupervised morphology induction systems (schone and jurafsky, 2001; <papid> N01-1024 </papid>wicentowski, 2002; goldsmith, 2006; bordag, 2007).</prevsent>
</prevsection>
<citsent citstr=" N03-2015 ">
johnson and martin (2003) <papid> N03-2015 </papid>generalize from character trees and model morphological character sequences with minimized finite state automata.</citsent>
<aftsection>
<nextsent>bernhard (2007) measures character predictability by directly computing transitional probabilities between sub strings of words.
</nextsent>
<nextsent>a second successful technique has used the minimum description length principle to capture the morpheme as recurrent structure of morphology.
</nextsent>
<nextsent>the linguist ica system of goldsmith (2006), the morfessor system of creutz (2006), and the system described in brent et al (1995) take this approach.
</nextsent>
<nextsent>a third technique leverages inflectional paradigms as the organizational structure of morphology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4254">
<title id=" W08-0708.xml">evaluating an agglutinative segmentation model for paramor </title>
<section> unsupervised morphology induction.  </section>
<citcontext>
<prevsection>
<prevsent>first, section 2.2 of this paper introduces an agglutinative segmentation model.
</prevsent>
<prevsent>this agglutinative model segments words into as many morphemes as the data justify.
</prevsent>
</prevsection>
<citsent citstr=" J01-2001 ">
although goldsmith (2001) <papid> J01-2001 </papid>and goldsmith and hu (2004) discuss ideas for segmenting individual words into more than two morphemes, the implemented linguist ica algorithm, as presented in goldsmith (2006), permits at most single morpheme boundary in each word.</citsent>
<aftsection>
<nextsent>second, paramor decouples the task of paradigm identification from that of word segmentation (monson et al, 2007<papid> W07-1315 </papid>b).</nextsent>
<nextsent>in contrast, morphology models in linguist ica inherently encode both belief about paradigm structure on individual words as well as segmentation of those words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4286">
<title id=" W08-0108.xml">rapidly deploying grammar based speech applications with active learning and backoff grammars </title>
<section> gather data from users..  </section>
<citcontext>
<prevsection>
<prevsent>two steps are added to the typical iterative process.
</prevsent>
<prevsent>in step 1.1, we generate back-off grammar from the cfg.
</prevsent>
</prevsection>
<citsent citstr=" W07-1805 ">
one way to accomplish this is by constructing back off cfg using filler models (paek et al, 2007), <papid> W07-1805 </papid>which when applied to the same command-andcontrol task in section 4 can result in 35% relative reduction in semantic error rate for oog ut terances.</citsent>
<aftsection>
<nextsent>however, the back-off grammar could also be slm trained on artificial data created from the cfg (galescu et al, 1998).
</nextsent>
<nextsent>whatever back-off mechanism is employed, its coverage should be wider than the original cfg so that utterances that fail to be recognized by the cfg, or fall below an acceptable confidence threshold, can be handled by the back-off in second or simultaneous pass.
</nextsent>
<nextsent>that is the gist of step 2.1, the second additional step.
</nextsent>
<nextsent>it is not only important to generate back-off grammar, but it must be utilized for handling possible oog utterances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4292">
<title id=" W07-1422.xml">semantic inference at the lexical syntactic level for textual entailment recognition </title>
<section> inference framework.  </section>
<citcontext>
<prevsection>
<prevsent>the dotted arc represents alignment.
</prevsent>
<prevsent>figure 1: application of inference rules.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
pos and relation labels are based on minipar (lin, 1998<papid> P98-2127 </papid>b) if complete proof is found (h was generated), the prover concludes that entailment holds.</citsent>
<aftsection>
<nextsent>otherwise, entailment is determined by comparing the minimal cost found during the proof search to some threshold ?.
</nextsent>
<nextsent>like logic-based systems, our proof system consists of propositions (t, h, and intermediate premises), and inference (entailment) rules, which derive new propositions from previously established ones.
</nextsent>
<nextsent>3.1 propositions.
</nextsent>
<nextsent>propositions are represented as dependency trees,where nodes represent words, and hold set of features and their values.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4298">
<title id=" W07-1422.xml">semantic inference at the lexical syntactic level for textual entailment recognition </title>
<section> system implementation.  </section>
<citcontext>
<prevsection>
<prevsent>deriving the initial propositions and from the in put text fragments consists of the following steps: (i) anaphora resolution, using the mars system (mitkov et al, 2002).
</prevsent>
<prevsent>each anaphor was replaced byits antecedent.
</prevsent>
</prevsection>
<citsent citstr=" A97-1004 ">
(ii) sentence splitting, using mxterminator (reynar and ratnaparkhi, 1997).<papid> A97-1004 </papid></citsent>
<aftsection>
<nextsent>(iii) dependency parsing, using minipar (lin, 1998<papid> P98-2127 </papid>b).</nextsent>
<nextsent>the proof search is implemented as depth-first search, with maximal depth (i.e. proof length) of 4.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4302">
<title id=" W08-0118.xml">optimal dialog in consumer rating systems using pomdp framework </title>
<section> pomdp framework in voice-rate.  </section>
<citcontext>
<prevsection>
<prevsent>the two main models that we consider include an observation model that captures speech recognition uncertainty, and user knowledge model that captures the variability of user knowledge required for answering questions on different attributes.observation model: since the speech recognition engine we are using returns only one-best andits confidence value ? [0, 1].
</prevsent>
<prevsent>we define the observation function as follows, (au|au) = { if au = au, 1c |au|1 otherwise.
</prevsent>
</prevsection>
<citsent citstr=" W07-0301 ">
(2) where au is the true user action, au is the speech recognition output (i.e., corrupted user action), andau is the set of user actions related to the last machine action.user knowledge model: in most of the applications (roy et al, 2000; williams, 2007) <papid> W07-0301 </papid>where 107 the pomdp framework got applied, it is normally assumed that the user needs only common sense to answer the questions asked by the dialog system.our application is more complex as the product information is very rich.</citsent>
<aftsection>
<nextsent>a user may have different difficulty in answering different questions.
</nextsent>
<nextsent>forex ample, while user can easily answer question on category, he may not be able to answer question on the part number.
</nextsent>
<nextsent>thus, we define user knowledge model to capture such uncertainty.
</nextsent>
<nextsent>specifically, given question (say am) and an intended product (say gu) in the users mind, we want to know how likely the user has required knowledge to answer the question.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4303">
<title id=" W07-2036.xml">hit web based scoring method for english lexical substitution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 describes our system, especially the web-based scoring method.
</prevsent>
<prevsent>section 4 presents the results and analysis.
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
synonyms defined in wordnet have been widely used in lexical substitution and expansion (smeaton et al , 1994; langkilde and knight, 1998; <papid> P98-1116 </papid>bol 173 shakov and gelbukh, 2004).</citsent>
<aftsection>
<nextsent>in addition, lot of methods have been proposed to automatically construct thesauri of synonyms.
</nextsent>
<nextsent>for example, lin (1998) <papid> P98-2127 </papid>clustered words with similar meanings by calculating the dependency similarity.</nextsent>
<nextsent>barzilay and mckeown (2001) <papid> P01-1008 </papid>extracted paraphrases using multiple translations of literature works.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4304">
<title id=" W07-2036.xml">hit web based scoring method for english lexical substitution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>synonyms defined in wordnet have been widely used in lexical substitution and expansion (smeaton et al , 1994; langkilde and knight, 1998; <papid> P98-1116 </papid>bol 173 shakov and gelbukh, 2004).</prevsent>
<prevsent>in addition, lot of methods have been proposed to automatically construct thesauri of synonyms.</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
for example, lin (1998) <papid> P98-2127 </papid>clustered words with similar meanings by calculating the dependency similarity.</citsent>
<aftsection>
<nextsent>barzilay and mckeown (2001) <papid> P01-1008 </papid>extracted paraphrases using multiple translations of literature works.</nextsent>
<nextsent>wu and zhou (2003) <papid> W03-1610 </papid>extracted synonyms with multiple resources, including monolingual dictionary, bilingual corpus, and monolingual corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4305">
<title id=" W07-2036.xml">hit web based scoring method for english lexical substitution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, lot of methods have been proposed to automatically construct thesauri of synonyms.
</prevsent>
<prevsent>for example, lin (1998) <papid> P98-2127 </papid>clustered words with similar meanings by calculating the dependency similarity.</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
barzilay and mckeown (2001) <papid> P01-1008 </papid>extracted paraphrases using multiple translations of literature works.</citsent>
<aftsection>
<nextsent>wu and zhou (2003) <papid> W03-1610 </papid>extracted synonyms with multiple resources, including monolingual dictionary, bilingual corpus, and monolingual corpus.</nextsent>
<nextsent>besides the handcrafted and automatic synonym resources, the web has been exploited as resource for lexical substitute extraction (zhao et al , 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4306">
<title id=" W07-2036.xml">hit web based scoring method for english lexical substitution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for example, lin (1998) <papid> P98-2127 </papid>clustered words with similar meanings by calculating the dependency similarity.</prevsent>
<prevsent>barzilay and mckeown (2001) <papid> P01-1008 </papid>extracted paraphrases using multiple translations of literature works.</prevsent>
</prevsection>
<citsent citstr=" W03-1610 ">
wu and zhou (2003) <papid> W03-1610 </papid>extracted synonyms with multiple resources, including monolingual dictionary, bilingual corpus, and monolingual corpus.</citsent>
<aftsection>
<nextsent>besides the handcrafted and automatic synonym resources, the web has been exploited as resource for lexical substitute extraction (zhao et al , 2007).
</nextsent>
<nextsent>as for substitute scoring, various methods have been investigated, among which the classification method is the most widely used (dagan et al , 2006; <papid> P06-1057 </papid>kauchak and barzilay, 2006).<papid> N06-1058 </papid></nextsent>
<nextsent>in detail, binary classifier is trained for each candidate substitute, using the contexts of the substitute as features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4307">
<title id=" W07-2036.xml">hit web based scoring method for english lexical substitution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wu and zhou (2003) <papid> W03-1610 </papid>extracted synonyms with multiple resources, including monolingual dictionary, bilingual corpus, and monolingual corpus.</prevsent>
<prevsent>besides the handcrafted and automatic synonym resources, the web has been exploited as resource for lexical substitute extraction (zhao et al , 2007).</prevsent>
</prevsection>
<citsent citstr=" P06-1057 ">
as for substitute scoring, various methods have been investigated, among which the classification method is the most widely used (dagan et al , 2006; <papid> P06-1057 </papid>kauchak and barzilay, 2006).<papid> N06-1058 </papid></citsent>
<aftsection>
<nextsent>in detail, binary classifier is trained for each candidate substitute, using the contexts of the substitute as features.
</nextsent>
<nextsent>then new contextual sentence containing the target word can be classified as 1 (the candidate is correct substitute in the given sentence) or 0 (oth erwise).
</nextsent>
<nextsent>the features used in the classification are usually similar with that in word sense disambiguation (wsd), including bag of word lemmas in the sentence, n-grams and parts of speech (pos) in window, etc. there are other models presented for candidate substitute scoring.
</nextsent>
<nextsent>glickman et al  (2006) <papid> W06-2907 </papid>proposed bayesian model and neural network model, which estimate the probability of word may occur in given context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4308">
<title id=" W07-2036.xml">hit web based scoring method for english lexical substitution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wu and zhou (2003) <papid> W03-1610 </papid>extracted synonyms with multiple resources, including monolingual dictionary, bilingual corpus, and monolingual corpus.</prevsent>
<prevsent>besides the handcrafted and automatic synonym resources, the web has been exploited as resource for lexical substitute extraction (zhao et al , 2007).</prevsent>
</prevsection>
<citsent citstr=" N06-1058 ">
as for substitute scoring, various methods have been investigated, among which the classification method is the most widely used (dagan et al , 2006; <papid> P06-1057 </papid>kauchak and barzilay, 2006).<papid> N06-1058 </papid></citsent>
<aftsection>
<nextsent>in detail, binary classifier is trained for each candidate substitute, using the contexts of the substitute as features.
</nextsent>
<nextsent>then new contextual sentence containing the target word can be classified as 1 (the candidate is correct substitute in the given sentence) or 0 (oth erwise).
</nextsent>
<nextsent>the features used in the classification are usually similar with that in word sense disambiguation (wsd), including bag of word lemmas in the sentence, n-grams and parts of speech (pos) in window, etc. there are other models presented for candidate substitute scoring.
</nextsent>
<nextsent>glickman et al  (2006) <papid> W06-2907 </papid>proposed bayesian model and neural network model, which estimate the probability of word may occur in given context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4309">
<title id=" W07-2036.xml">hit web based scoring method for english lexical substitution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>then new contextual sentence containing the target word can be classified as 1 (the candidate is correct substitute in the given sentence) or 0 (oth erwise).
</prevsent>
<prevsent>the features used in the classification are usually similar with that in word sense disambiguation (wsd), including bag of word lemmas in the sentence, n-grams and parts of speech (pos) in window, etc. there are other models presented for candidate substitute scoring.
</prevsent>
</prevsection>
<citsent citstr=" W06-2907 ">
glickman et al  (2006) <papid> W06-2907 </papid>proposed bayesian model and neural network model, which estimate the probability of word may occur in given context.</citsent>
<aftsection>
<nextsent>3.1 candidate substitute extraction.
</nextsent>
<nextsent>in hit, candidate substitutes are extracted from wordnet.
</nextsent>
<nextsent>both synonyms and hypernyms defined in wordnet are investigated.
</nextsent>
<nextsent>let be target word, pos the specified pos of w. the number of ws synsets defined in wordnet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4310">
<title id=" W07-2036.xml">hit web based scoring method for english lexical substitution </title>
<section> hit system.  </section>
<citcontext>
<prevsection>
<prevsent>obviously, this assumption is not always true.
</prevsent>
<prevsent>however, considering only the neighboring words can reduce the risk of bringing in noise.
</prevsent>
</prevsection>
<citsent citstr=" P97-1067 ">
besides, edmonds (1997) <papid> P97-1067 </papid>has also demonstrated in his paper that short-distance collocations with neighboring words are more useful in lexical choice than long ones.</citsent>
<aftsection>
<nextsent>let be the target word, a candidate substitute, the context sentence.
</nextsent>
<nextsent>our basic idea is that: one can substitute in with t, which generates new sentence s?.
</nextsent>
<nextsent>if s?
</nextsent>
<nextsent>can be found on the web, then the substitute is admissible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4311">
<title id=" W08-0319.xml">phrase based and deep syntactic englishtoczech statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the czech morphological system (hajic?, 2004) defines 4,000 tags in theory and 2,000 were actually seen in big tagged corpus while the english penn treebank tagset contains just about 50 tags.
</prevsent>
<prevsent>in our parallel corpus (see below), the english vocabulary size is 148k distinct word forms but more than twice as big in czech, 343k distinct word forms.when translating to czech from an analytic language such as english, target word forms have tobe chosen correctly to produce grammatical sentence and preserve the expressed relations between elements in the sentence, e.g. verbs and their modifiers.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
this year, we have taken two radically different approaches to english-to-czech mt. section 2 describes our setup of the phrase-based system moses(koehn et al, 2007) <papid> P07-2045 </papid>and section 3 focuses on system with probabilistic tree transfer employed at adeep syntactic layer and the new challenges this approach brings.the work on this project was supported by the grants fp6 ist-5-034291-stp (euromatrix), msm0021620838, msmt cr lc536, and ga405/06/0589.</citsent>
<aftsection>
<nextsent>bojar (2007) describes various experiments with factored translation to czech aimed at improving target-side morphology.
</nextsent>
<nextsent>we use essentially the same setup with some cleanup and significantly larger target-side training data: parallel data from czeng 0.7 (bojar et al, 2008),with original sentence-level alignment and tokenization.
</nextsent>
<nextsent>the parallel corpus was taken as monolithic text source disregarding differences between czeng data sources.
</nextsent>
<nextsent>we use only 1-1 aligned sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4312">
<title id=" W08-0319.xml">phrase based and deep syntactic englishtoczech statistical machine translation </title>
<section> factored phrase-based mt to czech.  </section>
<citcontext>
<prevsection>
<prevsent>the parallel corpus was taken as monolithic text source disregarding differences between czeng data sources.
</prevsent>
<prevsent>we use only 1-1 aligned sentences.
</prevsent>
</prevsection>
<citsent citstr=" C00-2163 ">
word alignment using giza++ toolkit (och and ney, 2000), <papid> C00-2163 </papid>the default configuration as available intraining scripts for moses.</citsent>
<aftsection>
<nextsent>we based the word alignment on czech and english lemmas (base formsof words) as provided by the combination of taggers and lemmatizers by hajic?
</nextsent>
<nextsent>(2004) for czech and brants (2000) followed by minnen et al (2001) forenglish.
</nextsent>
<nextsent>we symmetrized the two giza++ runs using grow-diag-final heuristic.truecasing.
</nextsent>
<nextsent>we attempted to preserve meaning bearing case distinctions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4313">
<title id=" W08-0319.xml">phrase based and deep syntactic englishtoczech statistical machine translation </title>
<section> factored phrase-based mt to czech.  </section>
<citcontext>
<prevsection>
<prevsent>4-grams of word forms based on czech national corpus (kocek et al, 2000), version syn2006, 365m tokens, ? three models of 7-grams of morphological tags from the same sources.lexicalized reordering using the mono tone/swap/discontinuous bidirectional model based on both source and target word forms.
</prevsent>
<prevsent>mert.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we use the minimum-error rate training procedure by och (2003) <papid> P03-1021 </papid>as implemented in the moses toolkit to set the weights of the various translation and language models, optimizing for bleu.final detokenization is simple rule-based procedure based on czech typographical conventions.</citsent>
<aftsection>
<nextsent>finally, we capitalize the beginnings of sentences.
</nextsent>
<nextsent>see bleu scores in table 2 below.
</nextsent>
<nextsent>3.1 theoretical background.
</nextsent>
<nextsent>czech has well-established theory of linguistic analysis called functional generative description (sgall et al, 1986) supported by big tree banking enterprise (hajic?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4314">
<title id=" W08-0319.xml">phrase based and deep syntactic englishtoczech statistical machine translation </title>
<section> mt with deep syntactic transfer.  </section>
<citcontext>
<prevsection>
<prevsent>= log ? et2 p(c(e) | g(e)) (3) the probabilistic dictionary of aligned treelet pairs is extracted from node-aligned (giza++ on linear ized trees) parallel automatic treebank as in moses?
</prevsent>
<prevsent>training: all treelet pairs compatible with the node alignment.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
3.2.1 factored treelet translation labels of nodes at the t-layer are not atomic but consist of more than 20 attributes representing various linguistic features.3 we can consider the attributes as individual factors (koehn and hoang, 2007).<papid> D07-1091 </papid></citsent>
<aftsection>
<nextsent>this allows us to condition the translation choice on subset of source factors only.
</nextsent>
<nextsent>in order to generate value for each target-side factor, we use sequence of mapping steps similar to koehn and hoang (2007).<papid> D07-1091 </papid></nextsent>
<nextsent>for technical reasons, our current implementation allows to generate factored target side only when translating single node to single node, i.e. preserving the tree structure.in our experiments we used 8 source (english) node attributes and 14 target (czech) attributes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4316">
<title id=" W08-0319.xml">phrase based and deep syntactic englishtoczech statistical machine translation </title>
<section> mt with deep syntactic transfer.  </section>
<citcontext>
<prevsection>
<prevsent>3.3.1 discussion our syntax-based approach does not reach scores of phrase-based mt due to the following reasons: cumulation of errors at every step of analysis.
</prevsent>
<prevsent>data loss due to incompatible parses and node alignment.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
unlike e.g. quirk et al (2005) <papid> P05-1034 </papid>or huang et al (2006) who parse only one side and project the structure, we parse both languages independently.</citsent>
<aftsection>
<nextsent>natural divergence and random errors in either ofthe parses and/or the alignment prevent us from extracting many treelet pairs.combinatorial explosion in target node attributes.
</nextsent>
<nextsent>currently, treelet options are fully built in advance.
</nextsent>
<nextsent>uncertainty in the many t-node attributes leads to too many insignificant variations while e.g. different lexical choices are pushed off the stack.while vital for final sentence generation (see table 1), fine-grained t-node attributes should be produced only once all key structural, lexical and form decisions have been made.
</nextsent>
<nextsent>the same sort of explosion makes complicated factored setups not yet feasible in moses, either.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4317">
<title id=" W08-0319.xml">phrase based and deep syntactic englishtoczech statistical machine translation </title>
<section> mt with deep syntactic transfer.  </section>
<citcontext>
<prevsection>
<prevsent>3.3.2 related research our approach should not be confused with the tectomt submission by zdenek zabokrtsky?
</prevsent>
<prevsent>with deterministic transfer: heuristics fully exploiting the similarity of english and czech t-layers.
</prevsent>
</prevsection>
<citsent citstr=" P05-1067 ">
ding and palmer (2005) <papid> P05-1067 </papid>improve over word-based mt baseline with formalism very similar to stsg.though not explicitly stated, they seem not to encode frontiers in the tree lets and allow for adjunction(adding siblings), like quirk et al (2005), <papid> P05-1034 </papid>which significantly reduces data sparseness.</citsent>
<aftsection>
<nextsent>riezler and iii (2006) <papid> N06-1032 </papid>report an improvement in mt grammaticality on very restricted test set:short sentences parsable by an lfg grammar with out back-off rules.</nextsent>
<nextsent>we have presented our best-performing factored phrase-based english-to-czech translation and ahighly experimental complex system with tree based transfer at deep syntactic layer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4319">
<title id=" W08-0319.xml">phrase based and deep syntactic englishtoczech statistical machine translation </title>
<section> mt with deep syntactic transfer.  </section>
<citcontext>
<prevsection>
<prevsent>with deterministic transfer: heuristics fully exploiting the similarity of english and czech t-layers.
</prevsent>
<prevsent>ding and palmer (2005) <papid> P05-1067 </papid>improve over word-based mt baseline with formalism very similar to stsg.though not explicitly stated, they seem not to encode frontiers in the tree lets and allow for adjunction(adding siblings), like quirk et al (2005), <papid> P05-1034 </papid>which significantly reduces data sparseness.</prevsent>
</prevsection>
<citsent citstr=" N06-1032 ">
riezler and iii (2006) <papid> N06-1032 </papid>report an improvement in mt grammaticality on very restricted test set:short sentences parsable by an lfg grammar with out back-off rules.</citsent>
<aftsection>
<nextsent>we have presented our best-performing factored phrase-based english-to-czech translation and ahighly experimental complex system with tree based transfer at deep syntactic layer.
</nextsent>
<nextsent>we have discussed some of the reasons why the phrase-based mt currently performs much better.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4320">
<title id=" W08-0505.xml">adapting naturally occurring test suites for evaluation of clinical question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a fair number of high-quality manually created collections present answers to clinical question sin this form and could be obtained online.
</prevsent>
<prevsent>three partially freely-available sources: family practitioner inquiry network (fpin)2, park hurst exchange forum (pe)3, and bmj clinical evidence (bmj-ce)4 were used to design and develop the presented test suites and evaluation methods.
</prevsent>
</prevsection>
<citsent citstr=" W04-3101 ">
although there seems to be distinction between test collections and test suites (co hen et al, 2004) (<papid> W04-3101 </papid>the former defined as pieces of text?</citsent>
<aftsection>
<nextsent>and associated with corpora, the latter, as lists of specially constructed sentences, or sentence sequences, or sentence fragments (balkan et al, 1994)), evaluation of answers to clinical questions crosses this boundary and requires the availability of carefully generated sentence fragments as well as suitable document collections.
</nextsent>
<nextsent>2http://www.primeanswers.org/primeanswers/ 3http://www.parkhurstexchange.com/qa/index.php 4http://www.clinicalevidence.com/ceweb/conditions/index.jsp 21
</nextsent>
<nextsent>the multi-tiered answer model of the fpin and bmj-ce resources is adapted in this work.
</nextsent>
<nextsent>the toptier contains the bottom-line advice?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4321">
<title id=" W07-1032.xml">unsupervised learning of the morpho semantic relationship in medline </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>jurafsky and martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes.
</prevsent>
<prevsent>robust tools for morphological analysis enable one to predict the root of word and its syntactic class or part of speech in sentence.
</prevsent>
</prevsection>
<citsent citstr=" W05-0617 ">
a good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (freitag, 2005; <papid> W05-0617 </papid>jacquemin, 1997; monson, 2004; <papid> P04-2012 </papid>schone and jurafsky, 2000; <papid> W00-0712 </papid>wicentowski, 2004; <papid> W04-0109 </papid>xu and croft, 1998; yarowsky and wicentowski, 2000).<papid> P00-1027 </papid></citsent>
<aftsection>
<nextsent>while this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in language.
</nextsent>
<nextsent>while our interest is related to this work, we are concerned with the multitude of tokens that appear in english texts on the subject of biology.
</nextsent>
<nextsent>we believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but not in any standard way or by any simple rules that have general applicability even in biology.
</nextsent>
<nextsent>it is our goal here to achieve some understanding of when two tokens can be said to be semantically related based on their similarity as strings of characters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4322">
<title id=" W07-1032.xml">unsupervised learning of the morpho semantic relationship in medline </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>jurafsky and martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes.
</prevsent>
<prevsent>robust tools for morphological analysis enable one to predict the root of word and its syntactic class or part of speech in sentence.
</prevsent>
</prevsection>
<citsent citstr=" P04-2012 ">
a good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (freitag, 2005; <papid> W05-0617 </papid>jacquemin, 1997; monson, 2004; <papid> P04-2012 </papid>schone and jurafsky, 2000; <papid> W00-0712 </papid>wicentowski, 2004; <papid> W04-0109 </papid>xu and croft, 1998; yarowsky and wicentowski, 2000).<papid> P00-1027 </papid></citsent>
<aftsection>
<nextsent>while this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in language.
</nextsent>
<nextsent>while our interest is related to this work, we are concerned with the multitude of tokens that appear in english texts on the subject of biology.
</nextsent>
<nextsent>we believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but not in any standard way or by any simple rules that have general applicability even in biology.
</nextsent>
<nextsent>it is our goal here to achieve some understanding of when two tokens can be said to be semantically related based on their similarity as strings of characters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4323">
<title id=" W07-1032.xml">unsupervised learning of the morpho semantic relationship in medline </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>jurafsky and martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes.
</prevsent>
<prevsent>robust tools for morphological analysis enable one to predict the root of word and its syntactic class or part of speech in sentence.
</prevsent>
</prevsection>
<citsent citstr=" W00-0712 ">
a good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (freitag, 2005; <papid> W05-0617 </papid>jacquemin, 1997; monson, 2004; <papid> P04-2012 </papid>schone and jurafsky, 2000; <papid> W00-0712 </papid>wicentowski, 2004; <papid> W04-0109 </papid>xu and croft, 1998; yarowsky and wicentowski, 2000).<papid> P00-1027 </papid></citsent>
<aftsection>
<nextsent>while this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in language.
</nextsent>
<nextsent>while our interest is related to this work, we are concerned with the multitude of tokens that appear in english texts on the subject of biology.
</nextsent>
<nextsent>we believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but not in any standard way or by any simple rules that have general applicability even in biology.
</nextsent>
<nextsent>it is our goal here to achieve some understanding of when two tokens can be said to be semantically related based on their similarity as strings of characters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4325">
<title id=" W07-1032.xml">unsupervised learning of the morpho semantic relationship in medline </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>jurafsky and martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes.
</prevsent>
<prevsent>robust tools for morphological analysis enable one to predict the root of word and its syntactic class or part of speech in sentence.
</prevsent>
</prevsection>
<citsent citstr=" W04-0109 ">
a good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (freitag, 2005; <papid> W05-0617 </papid>jacquemin, 1997; monson, 2004; <papid> P04-2012 </papid>schone and jurafsky, 2000; <papid> W00-0712 </papid>wicentowski, 2004; <papid> W04-0109 </papid>xu and croft, 1998; yarowsky and wicentowski, 2000).<papid> P00-1027 </papid></citsent>
<aftsection>
<nextsent>while this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in language.
</nextsent>
<nextsent>while our interest is related to this work, we are concerned with the multitude of tokens that appear in english texts on the subject of biology.
</nextsent>
<nextsent>we believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but not in any standard way or by any simple rules that have general applicability even in biology.
</nextsent>
<nextsent>it is our goal here to achieve some understanding of when two tokens can be said to be semantically related based on their similarity as strings of characters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4326">
<title id=" W07-1032.xml">unsupervised learning of the morpho semantic relationship in medline </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>jurafsky and martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes.
</prevsent>
<prevsent>robust tools for morphological analysis enable one to predict the root of word and its syntactic class or part of speech in sentence.
</prevsent>
</prevsection>
<citsent citstr=" P00-1027 ">
a good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (freitag, 2005; <papid> W05-0617 </papid>jacquemin, 1997; monson, 2004; <papid> P04-2012 </papid>schone and jurafsky, 2000; <papid> W00-0712 </papid>wicentowski, 2004; <papid> W04-0109 </papid>xu and croft, 1998; yarowsky and wicentowski, 2000).<papid> P00-1027 </papid></citsent>
<aftsection>
<nextsent>while this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in language.
</nextsent>
<nextsent>while our interest is related to this work, we are concerned with the multitude of tokens that appear in english texts on the subject of biology.
</nextsent>
<nextsent>we believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but not in any standard way or by any simple rules that have general applicability even in biology.
</nextsent>
<nextsent>it is our goal here to achieve some understanding of when two tokens can be said to be semantically related based on their similarity as strings of characters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4330">
<title id=" W07-1207.xml">deep linguistic processing for spoken dialogue systems </title>
<section> parsing for deep linguistic processing.  </section>
<citcontext>
<prevsection>
<prevsent>the lf supports fragment and ellipsis interpretation, discussed in section 5.2 2.1 semantic lexicon.
</prevsent>
<prevsent>the content of our semantic representation comes from domain-independent ontology linked to domain-independent lexicon.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
our syntax relies ona frame-based design in the lf ontology, common representation in semantic lexicons (baker etal., 1998, <papid> P98-1013 </papid>kipper et al, 2000).</citsent>
<aftsection>
<nextsent>the lf type hierarchy is influenced by argument structure, but provides more detailed level of semantic analysis than found in most broad coverage parsers as it distinguishes senses even if the senses take the same argument structure, and may collapse lexical entries with different argument structures to the same sense.
</nextsent>
<nextsent>as very simple example, the generic lexicon includes the senses for the verb take shown 49 in figure 1.
</nextsent>
<nextsent>our generic senses have been inspired by framenet (baker et al, 1998).<papid> P98-1013 </papid></nextsent>
<nextsent>in addition, types are augmented with semantic features derived from euro wordnet (vossen et al,1997) and extended.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4332">
<title id=" W07-1207.xml">deep linguistic processing for spoken dialogue systems </title>
<section> parsing for deep linguistic processing.  </section>
<citcontext>
<prevsection>
<prevsent>the grammar used in all our applications uses these hand-tuned rule weights, which have proven to work relatively well across domains.
</prevsent>
<prevsent>we do not use statistical parser based on trained corpus because in most dialogue-system projects, sufficient amounts of training data are not available and would be too time consuming to collect.
</prevsent>
</prevsection>
<citsent citstr=" W05-1526 ">
in the one domain in which we have reasonable amount of training data (about 9300 utterances), we experimented with pcfg using trained probabilities with the collins algorithm, but were not able to improve on the hand-tuned preferences in overall performance (elsner et al, 2005).<papid> W05-1526 </papid>figure 3 summarizes some of the most important preferences encoded in our rule weights.</citsent>
<aftsection>
<nextsent>be cause we are dealing with speech, which is often ungrammatical and fragmented, the grammar includes robust?
</nextsent>
<nextsent>rules (e.g., allowing dropped de terminers) that would not be found in grammar of written english.
</nextsent>
<nextsent>the logical form language captures domain independent semantic representation of the utterance.
</nextsent>
<nextsent>as shown later in this paper, it can be seen as variant of mrs (copestake et al, 2006) but is expressed in frame-like notation rather than predicate calculus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4333">
<title id=" W07-1207.xml">deep linguistic processing for spoken dialogue systems </title>
<section> the logical form language.  </section>
<citcontext>
<prevsection>
<prevsent>the logical form language captures domain independent semantic representation of the utterance.
</prevsent>
<prevsent>as shown later in this paper, it can be seen as variant of mrs (copestake et al, 2006) but is expressed in frame-like notation rather than predicate calculus.
</prevsent>
</prevsection>
<citsent citstr=" J87-1005 ">
in addition, it has relatively simple method of computing possible quantifier scoping, drawing from the approaches by (hobbs &amp; shieber, 1987) <papid> J87-1005 </papid>and (alshawi, 1990).<papid> J90-3001 </papid></citsent>
<aftsection>
<nextsent>a logical form is set of terms that can be viewed as rooted graph with each term being node identified by unique id (the variable).
</nextsent>
<nextsent>there are three types of terms.
</nextsent>
<nextsent>the first corresponds to generalized quantifiers, and is on the form ( quant   id   type   modifiers *).
</nextsent>
<nextsent>as simple example, the np every dog would be captured by the term (every d1 dog).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4334">
<title id=" W07-1207.xml">deep linguistic processing for spoken dialogue systems </title>
<section> the logical form language.  </section>
<citcontext>
<prevsection>
<prevsent>the logical form language captures domain independent semantic representation of the utterance.
</prevsent>
<prevsent>as shown later in this paper, it can be seen as variant of mrs (copestake et al, 2006) but is expressed in frame-like notation rather than predicate calculus.
</prevsent>
</prevsection>
<citsent citstr=" J90-3001 ">
in addition, it has relatively simple method of computing possible quantifier scoping, drawing from the approaches by (hobbs &amp; shieber, 1987) <papid> J87-1005 </papid>and (alshawi, 1990).<papid> J90-3001 </papid></citsent>
<aftsection>
<nextsent>a logical form is set of terms that can be viewed as rooted graph with each term being node identified by unique id (the variable).
</nextsent>
<nextsent>there are three types of terms.
</nextsent>
<nextsent>the first corresponds to generalized quantifiers, and is on the form ( quant   id   type   modifiers *).
</nextsent>
<nextsent>as simple example, the np every dog would be captured by the term (every d1 dog).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4335">
<title id=" W07-1207.xml">deep linguistic processing for spoken dialogue systems </title>
<section> comparison of lf and mrs.  </section>
<citcontext>
<prevsection>
<prevsent>minimal recur sion semantics (mrs) (copestake et al 2006) is semantic formalism which has been widely adopted in the last several years.
</prevsent>
<prevsent>thishas motivated some research on how this formalism compares to some traditional semantic formalisms.
</prevsent>
</prevsection>
<citsent citstr=" P04-1032 ">
for example, fuchss et al (2004) <papid> P04-1032 </papid>formally show that the translation from mrs to dominance constraints is feasible.</citsent>
<aftsection>
<nextsent>we have also found that mrs is very similar to lf in its descriptive power.
</nextsent>
<nextsent>in fact, we can convert every lfto an equivalent mrs structure with simple algorithm.
</nextsent>
<nextsent>first, consider the sentence every dog hates acat.
</nextsent>
<nextsent>figure 5 shows the lf and mrs representations for this sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4336">
<title id=" W07-1207.xml">deep linguistic processing for spoken dialogue systems </title>
<section> generic discourse interpretation.  </section>
<citcontext>
<prevsection>
<prevsent>our domain-independent representation supports reference resolution in two ways.
</prevsent>
<prevsent>first, the quanti fiers and dependency structure extracted from the sentence allow for implementing reference resolution algorithms based on extracted syntactic features.
</prevsent>
</prevsection>
<citsent citstr=" P02-1011 ">
the system uses different strategies for re figure 8: the lf-mrs conversion algorithm 53 solving each type of referring expression along the lines described in (byron, 2002).<papid> P02-1011 </papid>second, domain-independent semantic information helps greatly in resolving pronouns and definite descriptions.</citsent>
<aftsection>
<nextsent>the general capability provided for resolving referring expressions is to search through the discourse history for the most recent entity that matches the semantic requirements,where recency within an utterance may be reordered to reflect focusing heuristics (tetreault,2001).<papid> J01-4003 </papid></nextsent>
<nextsent>for definite descriptions, the semantic information required is explicit in the lexicon.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4337">
<title id=" W07-1207.xml">deep linguistic processing for spoken dialogue systems </title>
<section> generic discourse interpretation.  </section>
<citcontext>
<prevsection>
<prevsent>first, the quanti fiers and dependency structure extracted from the sentence allow for implementing reference resolution algorithms based on extracted syntactic features.
</prevsent>
<prevsent>the system uses different strategies for re figure 8: the lf-mrs conversion algorithm 53 solving each type of referring expression along the lines described in (byron, 2002).<papid> P02-1011 </papid>second, domain-independent semantic information helps greatly in resolving pronouns and definite descriptions.</prevsent>
</prevsection>
<citsent citstr=" J01-4003 ">
the general capability provided for resolving referring expressions is to search through the discourse history for the most recent entity that matches the semantic requirements,where recency within an utterance may be reordered to reflect focusing heuristics (tetreault,2001).<papid> J01-4003 </papid></citsent>
<aftsection>
<nextsent>for definite descriptions, the semantic information required is explicit in the lexicon.
</nextsent>
<nextsent>for pronouns, the parser can often compute semantic features from verb argument restrictions.
</nextsent>
<nextsent>for instance, the pronoun it carries little semantic information by itself, but in the utterance eat it we know we are looking for an edible object.
</nextsent>
<nextsent>this simple technique performs well in practice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4338">
<title id=" W08-0105.xml">reactive redundancy and listener comprehension in direction giving </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>developing better understanding of the factors that affect how and when speakers respond to signs of listener confusion is important at both theoretical and applied levels: first, it can better explain the variation in discourse strategies used in different communicative situa tions; second, it can help in the design of dialogue systems (kopp et al , 2008; theune et al , 2007).
</prevsent>
<prevsent>in this study, we examine what types of listener behavior increase the likelihood that speaker will produce redundant utterance.
</prevsent>
</prevsection>
<citsent citstr=" C92-1054 ">
we also examine how communicative context affects the amount redundancy speaker produces overall (walker, 1992, <papid> C92-1054 </papid>1996) and speakers use of redundancy in response to listener confusion.</citsent>
<aftsection>
<nextsent>in contrast to previous work, we study reactive redundancy, or redundancy produced in response to signs of listener confusion.
</nextsent>
<nextsent>we investigate two factors that may influence speakers tendency to produce redundant utterances and to respond to listener confusion with redundancy: the relationship between the interlocutors and their visual contact.
</nextsent>
<nextsent>in the following section, we review relevant literature and present our hypotheses; we then describe the direction-giving experiment which we used to examine redundancy in task-oriented dialogue, and present our results; we discuss our results in light of the literature and conclude by noting potential applications and future work.
</nextsent>
<nextsent>37
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4340">
<title id=" W08-0105.xml">reactive redundancy and listener comprehension in direction giving </title>
<section> related work and predictions.  </section>
<citcontext>
<prevsection>
<prevsent>we also examine eye-gaze as non-verbal marker of listener comprehension.
</prevsent>
<prevsent>goodwin (1981) described gaze towards the speaker as sign of listener attention.
</prevsent>
</prevsection>
<citsent citstr=" P03-1070 ">
however, nakano et al  (2003) <papid> P03-1070 </papid>found that speakers seemed to interpret listener gazing at them rather than at map as sign of listener misunderstanding.</citsent>
<aftsection>
<nextsent>therefore, shifting eyegaze away from the speaker can signal that listener is losing attention, perhaps due to confusion, while shifting gaze towards the speaker can signal misunderstanding.
</nextsent>
<nextsent>in this study there is no map, and listeners who can see the speaker spend most of the conversation gazing at the speaker.
</nextsent>
<nextsent>still, due to the opposing findings in the literature, we analyze eye-gaze shifts both towards and away from the speaker as potential signs of listener confusion.
</nextsent>
<nextsent>2.3 relationship and communication.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4342">
<title id=" W08-0105.xml">reactive redundancy and listener comprehension in direction giving </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>half the dyads were pairs of friends and half were strangers.
</prevsent>
<prevsent>3.2 procedure.
</prevsent>
</prevsection>
<citsent citstr=" W07-1906 ">
the task consisted of three consecutive direction giving sessions, as described in cassell et al  (2007).<papid> W07-1906 </papid></citsent>
<aftsection>
<nextsent>at the start of each session, the experimenter led the direction-giver to point in the building, and back to the experiment room.
</nextsent>
<nextsent>half of the dyads sat facing each other during the direction-giving (the vision condition) and half sat back-to-back with screen between them (the no-vision condi tion).
</nextsent>
<nextsent>the direction-giver then explained the route to the direction-receiver.
</nextsent>
<nextsent>there were no time limits or restrictions on what could be said, but the dyads could not use maps or props.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4344">
<title id=" W08-0326.xml">matrex the dcu mt system for wmt 2008 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>it consists of number of extendible and re-implementable modules, the most significant of which are: ? word alignment module: outputs set of word alignments given parallel corpus, ? chunking module: outputs set of chunks given an input corpus, ? chunk alignment module: outputs aligned chunk pairs given source and target chunks extracted from comparable corpora, ? decoder: returns optimal translation given set of aligned sentence, chunk/phrase and word pairs.
</prevsent>
<prevsent>in some cases, these modules may comprise wrappers around pre-existing software.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
for example, our system configuration for the shared task incorporates wrapper around giza++ (och and ney, 2003) <papid> J03-1002 </papid>for word alignment and wrapper around moses (koehn et al, 2007) <papid> P07-2045 </papid>for decoding.</citsent>
<aftsection>
<nextsent>it 171 should be noted, however, that the complete system is not limited to using only these specific module choices.
</nextsent>
<nextsent>the following subsections describe those modules unique to our system.
</nextsent>
<nextsent>2.1 marker-based chunking.
</nextsent>
<nextsent>the chunking module used for the shared task is based on the marker hypothesis, psycho linguistic constraint which posits that all languages are marked for surface syntax by specific closed set of lex emes or morphemes which signify context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4345">
<title id=" W08-0326.xml">matrex the dcu mt system for wmt 2008 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>it consists of number of extendible and re-implementable modules, the most significant of which are: ? word alignment module: outputs set of word alignments given parallel corpus, ? chunking module: outputs set of chunks given an input corpus, ? chunk alignment module: outputs aligned chunk pairs given source and target chunks extracted from comparable corpora, ? decoder: returns optimal translation given set of aligned sentence, chunk/phrase and word pairs.
</prevsent>
<prevsent>in some cases, these modules may comprise wrappers around pre-existing software.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
for example, our system configuration for the shared task incorporates wrapper around giza++ (och and ney, 2003) <papid> J03-1002 </papid>for word alignment and wrapper around moses (koehn et al, 2007) <papid> P07-2045 </papid>for decoding.</citsent>
<aftsection>
<nextsent>it 171 should be noted, however, that the complete system is not limited to using only these specific module choices.
</nextsent>
<nextsent>the following subsections describe those modules unique to our system.
</nextsent>
<nextsent>2.1 marker-based chunking.
</nextsent>
<nextsent>the chunking module used for the shared task is based on the marker hypothesis, psycho linguistic constraint which posits that all languages are marked for surface syntax by specific closed set of lex emes or morphemes which signify context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4346">
<title id=" W08-0326.xml">matrex the dcu mt system for wmt 2008 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>deletion?)
</prevsent>
<prevsent>probability.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
assuming that the parameters p(etk |fsk) are known, the most likely alignment is computed by simple dynamic-programming algorithm.1instead of using an expectation-maximization algorithm to estimate these parameters, as commonly done when performing word alignment (brownet al, 1993; <papid> J93-2003 </papid>och and ney, 2003), <papid> J03-1002 </papid>we directly compute these parameters by relying on the information contained within the chunks.</citsent>
<aftsection>
<nextsent>the conditional probability p(etk |fsk) can be computed in several ways.
</nextsent>
<nextsent>in our experiments, we have considered three main sources of knowledge: (i) word-to-word translation probabilities, (ii) word-to-word cognates, and (iii)chunk labels.
</nextsent>
<nextsent>these sources of knowledge are combined in log-linear framework.
</nextsent>
<nextsent>the weights ofthe log-linear model are not optimised; we experimented with different sets of parameters and did not find any significant difference as long as the weights stay in the interval [0.5 ? 1.5].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4348">
<title id=" W08-0326.xml">matrex the dcu mt system for wmt 2008 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 unused modules.
</prevsent>
<prevsent>there are numerous other features available in our system which, due to time constraints, were not exploited for the purposes of the shared task.
</prevsent>
</prevsection>
<citsent citstr=" P07-1039 ">
they include: ? word packing (ma et al, 2007): <papid> P07-1039 </papid>bilingually motivated packing of words that changes the basic unit of the alignment process in order to simplify word alignment.?</citsent>
<aftsection>
<nextsent>super tagging (hassan et al, 2007<papid> P07-1037 </papid>b): incorporating lexical syntactic descriptions, in the form of supertags, to the language model and target side of the translation model in order to better inform decoding.</nextsent>
<nextsent>source-context features (stroppa et al, 2007): use memory-based classification to incorporate context-informed features on the source side of the translation model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4349">
<title id=" W08-0326.xml">matrex the dcu mt system for wmt 2008 </title>
<section> the matrex system.  </section>
<citcontext>
<prevsection>
<prevsent>there are numerous other features available in our system which, due to time constraints, were not exploited for the purposes of the shared task.
</prevsent>
<prevsent>they include: ? word packing (ma et al, 2007): <papid> P07-1039 </papid>bilingually motivated packing of words that changes the basic unit of the alignment process in order to simplify word alignment.?</prevsent>
</prevsection>
<citsent citstr=" P07-1037 ">
super tagging (hassan et al, 2007<papid> P07-1037 </papid>b): incorporating lexical syntactic descriptions, in the form of supertags, to the language model and target side of the translation model in order to better inform decoding.</citsent>
<aftsection>
<nextsent>source-context features (stroppa et al, 2007): use memory-based classification to incorporate context-informed features on the source side of the translation model.
</nextsent>
<nextsent>treebank-based phrase extraction (tinsleyet al, 2007): extract word and phrase alignments based on linguistically informed sub sentential alignment of the parallel data.1this algorithm is actually classical edit-distance algorithm in which distances are replaced by opposite-log conditional probabilities.
</nextsent>
<nextsent>172 english: [i voted] [in favour] [of the strategy presented] [by the council] [concerning relations] [with mediterranean countries] spanish: [he votado] [a favor] [de la estrategia presentada] [por el consejo] [relativa las relaciones] [con los pases mediterraneos] figure 1: english and spanish marker-based chunking filter criteria esen fren czen initial total 1258778 1288074 1096941 blank lines 5632 4200 2 length 6794 8361 2922 fertility 120 82 1672 final total 1246234 1275432 1092345 table 1: summary of pre-processing on training data.
</nextsent>
<nextsent>the following section describes the system setup using the spanish english and french english eu roparl, and czech english czeng training data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4351">
<title id=" W08-0326.xml">matrex the dcu mt system for wmt 2008 </title>
<section> shared task setup.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 system configuration.
</prevsent>
<prevsent>as mentioned in section 2, our word alignment module employs wrapper around giza++.we built 5-gram language model based the target side of the training data.
</prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
this was done using the sri language modelling toolkit (stolcke, 2002)employing linear interpolation and modified kneser ney discounting (chen and goodman, 1996).<papid> P96-1041 </papid></citsent>
<aftsection>
<nextsent>our phrase-table comprised combination of marker-based chunk pairs2, extracted as described in sections 2.1 and 2.2, and word-alignment-based phrase pairs extracted using the grow-diag-final?
</nextsent>
<nextsent>method of koehn et al (2003), <papid> N03-1017 </papid>with maximum phrase length of 7 words.</nextsent>
<nextsent>phrase translation probabilities were estimated by relative frequency over all phrase pairs and were combined with other features, 2this module was omitted from the czech english syst emas we have yet to verify whether marker-based chunking is appropriate for czech.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4352">
<title id=" W08-0326.xml">matrex the dcu mt system for wmt 2008 </title>
<section> shared task setup.  </section>
<citcontext>
<prevsection>
<prevsent>this was done using the sri language modelling toolkit (stolcke, 2002)employing linear interpolation and modified kneser ney discounting (chen and goodman, 1996).<papid> P96-1041 </papid></prevsent>
<prevsent>our phrase-table comprised combination of marker-based chunk pairs2, extracted as described in sections 2.1 and 2.2, and word-alignment-based phrase pairs extracted using the grow-diag-final?</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
method of koehn et al (2003), <papid> N03-1017 </papid>with maximum phrase length of 7 words.</citsent>
<aftsection>
<nextsent>phrase translation probabilities were estimated by relative frequency over all phrase pairs and were combined with other features, 2this module was omitted from the czech english syst emas we have yet to verify whether marker-based chunking is appropriate for czech.
</nextsent>
<nextsent>system bleu (-ebmt) bleu (+ebmt) esen 0.3283 0.3287 fren 0.2768 0.2770czen 0.2235 table 2: summary of results on developments sets de vtest2006 for europarl tasks and nc-test2007 for czen tasks.
</nextsent>
<nextsent>system bleu (-ebmt) bleu (+ebmt) esen 0.3274 0.3285 fren 0.3163 0.3174czen (news) 0.1458 czen (nc) 0.2217 table 3: summary of results on 2008 test data.such as reordering model, in log-linear combination of functions.we tuned our system on the development set de vtest2006 for the europarl tasks and on nc-test2007for czech english, using minimum error-rate training (och, 2003) <papid> P03-1021 </papid>to optimise bleu score.</nextsent>
<nextsent>finally, we carried out decoding using wrapper around the moses decoder.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4353">
<title id=" W08-0326.xml">matrex the dcu mt system for wmt 2008 </title>
<section> shared task setup.  </section>
<citcontext>
<prevsection>
<prevsent>phrase translation probabilities were estimated by relative frequency over all phrase pairs and were combined with other features, 2this module was omitted from the czech english syst emas we have yet to verify whether marker-based chunking is appropriate for czech.
</prevsent>
<prevsent>system bleu (-ebmt) bleu (+ebmt) esen 0.3283 0.3287 fren 0.2768 0.2770czen 0.2235 table 2: summary of results on developments sets de vtest2006 for europarl tasks and nc-test2007 for czen tasks.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
system bleu (-ebmt) bleu (+ebmt) esen 0.3274 0.3285 fren 0.3163 0.3174czen (news) 0.1458 czen (nc) 0.2217 table 3: summary of results on 2008 test data.such as reordering model, in log-linear combination of functions.we tuned our system on the development set de vtest2006 for the europarl tasks and on nc-test2007for czech english, using minimum error-rate training (och, 2003) <papid> P03-1021 </papid>to optimise bleu score.</citsent>
<aftsection>
<nextsent>finally, we carried out decoding using wrapper around the moses decoder.
</nextsent>
<nextsent>3.3 post-processing.
</nextsent>
<nextsent>case restoration was carried out by training the system outlined above - without the ebmt chunk extraction - to translate from the lower cased version of the applicable target language training data to the true cased version.
</nextsent>
<nextsent>we have previously shown this approach to be very effective for both case and punctuation restoration (hassan et al, 2007<papid> P07-1037 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4356">
<title id=" W08-0506.xml">software testing and the naturally occurring data assumption in natural language processing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>although software testing is first-class research object in computer science, it has received little attention in the natural language processing arena.
</prevsent>
<prevsent>a notable exception to this comes from the grammar engineering community.
</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
this has produced body of publications that includes oepens work on test suite design (oepen et al , 1998), volks work on test suite encoding (volk, 1998), oepen et al work on the redwoods project (oepen et al , 2002), <papid> C02-2025 </papid>butt and kings discussion of the importance of testing (buttand king, 2003), flickinger et al work on semantics debugging?</citsent>
<aftsection>
<nextsent>with redwoods data (flickinger et al ., 2005), and bender et al recent work on test suite generation (bender et al , 2007).<papid> W07-1218 </papid></nextsent>
<nextsent>outside ofthe realm of grammar engineering, work on testing for nlp is quite limited.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4357">
<title id=" W08-0506.xml">software testing and the naturally occurring data assumption in natural language processing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>a notable exception to this comes from the grammar engineering community.
</prevsent>
<prevsent>this has produced body of publications that includes oepens work on test suite design (oepen et al , 1998), volks work on test suite encoding (volk, 1998), oepen et al work on the redwoods project (oepen et al , 2002), <papid> C02-2025 </papid>butt and kings discussion of the importance of testing (buttand king, 2003), flickinger et al work on semantics debugging?</prevsent>
</prevsection>
<citsent citstr=" W07-1218 ">
with redwoods data (flickinger et al ., 2005), and bender et al recent work on test suite generation (bender et al , 2007).<papid> W07-1218 </papid></citsent>
<aftsection>
<nextsent>outside ofthe realm of grammar engineering, work on testing for nlp is quite limited.
</nextsent>
<nextsent>(cohen et al , 2004) <papid> W04-3101 </papid>describes methodology for generating test suites for molecular biology named entity recognition systems, and (johnson et al , 2007) describes the development of fault model for linguistically-based ontology mapping, alignment, and linking systems.however, when most researchers in the nlp community refer in print to testing,?</nextsent>
<nextsent>they do not meanit in the sense in which that term is used in software engineering.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4358">
<title id=" W08-0506.xml">software testing and the naturally occurring data assumption in natural language processing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>with redwoods data (flickinger et al ., 2005), and bender et al recent work on test suite generation (bender et al , 2007).<papid> W07-1218 </papid></prevsent>
<prevsent>outside ofthe realm of grammar engineering, work on testing for nlp is quite limited.</prevsent>
</prevsection>
<citsent citstr=" W04-3101 ">
(cohen et al , 2004) <papid> W04-3101 </papid>describes methodology for generating test suites for molecular biology named entity recognition systems, and (johnson et al , 2007) describes the development of fault model for linguistically-based ontology mapping, alignment, and linking systems.however, when most researchers in the nlp community refer in print to testing,?</citsent>
<aftsection>
<nextsent>they do not meanit in the sense in which that term is used in software engineering.
</nextsent>
<nextsent>some projects have publicized aspects of their testing work, but have not published ontheir approaches: the nltk project posts module level line coverage statistics, having achieved median coverage of 55% on 116 python modules2 and38% coverage for the project as whole; the mallet project indicates on its web site that it encourages the production of unit tests during development, but unfortunately does not go into details of their recommendations for unit-testing machine learning code3.
</nextsent>
<nextsent>4.2 conclusions.
</nextsent>
<nextsent>we note number of shortcomings of code coverage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4359">
<title id=" W07-2204.xml">adapting wsj trained parsers to the british national corpus using in domain self training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we introduce set of 1,000 gold standard parse trees for the british national corpus (bnc) and perform series of self-training experiments with charniak and johnsons reranking parser and bnc sentences.
</prevsent>
<prevsent>weshow that retraining this parser with combination of one million bnc parse trees(produced by the same parser) and the original wsj training data yields improvements of 0.4% on wsj section 23 and 1.7% on the new bnc gold standard set.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
given the success of statistical parsing models on the wall street journal (wsj) section of the penn treebank (ptb) (charniak, 2000; <papid> A00-2018 </papid>collins, 2003, <papid> J03-4003 </papid>for example), there has been change in focus in recent years towards the problem of replicating this succes son genres other than american financial news stories.</citsent>
<aftsection>
<nextsent>the main challenge in solving the parser adaptation problem are the resources required to construct reliable annotated training examples.
</nextsent>
<nextsent>a breakthrough has come in the form of research by mcclosky et al (2006<papid> P06-1043 </papid>a), mcclosky et al (2006<papid> P06-1043 </papid>b) who show thatself-training can be used to improve parser performance when combined with two-stage reranking parser model (charniak and johnson, 2005).<papid> P05-1022 </papid></nextsent>
<nextsent>self training is the process of training parser on its own output, and earlier self-training experiments using generative statistical parsers did not yield encouraging results (steedman et al, 2003).<papid> E03-1008 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4360">
<title id=" W07-2204.xml">adapting wsj trained parsers to the british national corpus using in domain self training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we introduce set of 1,000 gold standard parse trees for the british national corpus (bnc) and perform series of self-training experiments with charniak and johnsons reranking parser and bnc sentences.
</prevsent>
<prevsent>weshow that retraining this parser with combination of one million bnc parse trees(produced by the same parser) and the original wsj training data yields improvements of 0.4% on wsj section 23 and 1.7% on the new bnc gold standard set.
</prevsent>
</prevsection>
<citsent citstr=" J03-4003 ">
given the success of statistical parsing models on the wall street journal (wsj) section of the penn treebank (ptb) (charniak, 2000; <papid> A00-2018 </papid>collins, 2003, <papid> J03-4003 </papid>for example), there has been change in focus in recent years towards the problem of replicating this succes son genres other than american financial news stories.</citsent>
<aftsection>
<nextsent>the main challenge in solving the parser adaptation problem are the resources required to construct reliable annotated training examples.
</nextsent>
<nextsent>a breakthrough has come in the form of research by mcclosky et al (2006<papid> P06-1043 </papid>a), mcclosky et al (2006<papid> P06-1043 </papid>b) who show thatself-training can be used to improve parser performance when combined with two-stage reranking parser model (charniak and johnson, 2005).<papid> P05-1022 </papid></nextsent>
<nextsent>self training is the process of training parser on its own output, and earlier self-training experiments using generative statistical parsers did not yield encouraging results (steedman et al, 2003).<papid> E03-1008 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4361">
<title id=" W07-2204.xml">adapting wsj trained parsers to the british national corpus using in domain self training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given the success of statistical parsing models on the wall street journal (wsj) section of the penn treebank (ptb) (charniak, 2000; <papid> A00-2018 </papid>collins, 2003, <papid> J03-4003 </papid>for example), there has been change in focus in recent years towards the problem of replicating this succes son genres other than american financial news stories.</prevsent>
<prevsent>the main challenge in solving the parser adaptation problem are the resources required to construct reliable annotated training examples.</prevsent>
</prevsection>
<citsent citstr=" P06-1043 ">
a breakthrough has come in the form of research by mcclosky et al (2006<papid> P06-1043 </papid>a), mcclosky et al (2006<papid> P06-1043 </papid>b) who show thatself-training can be used to improve parser performance when combined with two-stage reranking parser model (charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>self training is the process of training parser on its own output, and earlier self-training experiments using generative statistical parsers did not yield encouraging results (steedman et al, 2003).<papid> E03-1008 </papid></nextsent>
<nextsent>mcclosky et al.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4385">
<title id=" W07-2204.xml">adapting wsj trained parsers to the british national corpus using in domain self training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given the success of statistical parsing models on the wall street journal (wsj) section of the penn treebank (ptb) (charniak, 2000; <papid> A00-2018 </papid>collins, 2003, <papid> J03-4003 </papid>for example), there has been change in focus in recent years towards the problem of replicating this succes son genres other than american financial news stories.</prevsent>
<prevsent>the main challenge in solving the parser adaptation problem are the resources required to construct reliable annotated training examples.</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
a breakthrough has come in the form of research by mcclosky et al (2006<papid> P06-1043 </papid>a), mcclosky et al (2006<papid> P06-1043 </papid>b) who show thatself-training can be used to improve parser performance when combined with two-stage reranking parser model (charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>self training is the process of training parser on its own output, and earlier self-training experiments using generative statistical parsers did not yield encouraging results (steedman et al, 2003).<papid> E03-1008 </papid></nextsent>
<nextsent>mcclosky et al.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4386">
<title id=" W07-2204.xml">adapting wsj trained parsers to the british national corpus using in domain self training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main challenge in solving the parser adaptation problem are the resources required to construct reliable annotated training examples.
</prevsent>
<prevsent>a breakthrough has come in the form of research by mcclosky et al (2006<papid> P06-1043 </papid>a), mcclosky et al (2006<papid> P06-1043 </papid>b) who show thatself-training can be used to improve parser performance when combined with two-stage reranking parser model (charniak and johnson, 2005).<papid> P05-1022 </papid></prevsent>
</prevsection>
<citsent citstr=" E03-1008 ">
self training is the process of training parser on its own output, and earlier self-training experiments using generative statistical parsers did not yield encouraging results (steedman et al, 2003).<papid> E03-1008 </papid></citsent>
<aftsection>
<nextsent>mcclosky et al.
</nextsent>
<nextsent>(2006a), (2006b) proceed as follows: sentences now affiliated to lalic, universite?
</nextsent>
<nextsent>paris 4 la sorbonne.from the la times newspaper are parsed by first stage generative statistical parser trained on some seed training data (wsj sections 2-21) and the best parse trees produced by this parser are reranked by discriminative reranker.
</nextsent>
<nextsent>the highest ranked parse trees are added to the training set of the parser and the parser is retrained.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4413">
<title id=" W07-2204.xml">adapting wsj trained parsers to the british national corpus using in domain self training </title>
<section> the bnc data.  </section>
<citcontext>
<prevsection>
<prevsent>99.8% of the 6 million bnc sentences obtained parse, with an average parsing speed of 1.4s per sentence.
</prevsent>
<prevsent>a gold standard set of 1,000 bnc sentences was constructed by one annotator by correcting the out put of the first stage of charniak and johnsons reranking parser.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the sentences included in the gold standard were chosen at random from the bnc, subject to the condition that they contain verb which does not occur in the training sections of the wsj section of the ptb (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>a decision was made to select sentences for the gold standard set which differ from the sentences in the wsj training sections, and one way of finding different sentences is to focus on verbs which are not attested in the wsj sections 2-21.
</nextsent>
<nextsent>it is expected that these gold standard parse trees can be used as training data although they are used only as test and development data in this work.
</nextsent>
<nextsent>because they contain verbs which do not occur in the parsers training set, they are likely to represent hard test for wsj-trained parsers.
</nextsent>
<nextsent>the ptb bracketing guidelines (bies et al, 1995) and the ptb itself were used as references by the bnc annotator.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4438">
<title id=" W07-2204.xml">adapting wsj trained parsers to the british national corpus using in domain self training </title>
<section> self-training experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we retrain the first-stage generative statistical parser of charniak and johnson using combinations of bnc trees (parsed using the reranking parser) and wsj treebank trees.
</prevsent>
<prevsent>we test the combinations on the bnc gold standard development set and onwsj section 00.
</prevsent>
</prevsection>
<citsent citstr=" W01-0521 ">
table 1 shows that parser accuracy increases with the size of the in-domain self training material.3 the figures confirm the claim of mcclosky et al (2006<papid> P06-1043 </papid>a) that self-training with reranking parsing model is effective for improving parser accuracy in general, and the claim of gildea (2001) <papid> W01-0521 </papid>that training on in-domain data is effective for parser adaption.</citsent>
<aftsection>
<nextsent>they confirm that self-training on in-domain data is effective for parser adaptation.
</nextsent>
<nextsent>the wsj section 00 results suggest that, in orderto maintain performance on the seed training do main, it is necessary to combine bnc parse trees 2all scores are for the second stage of the parsing process,i.e. the evaluation takes place after the reranking.
</nextsent>
<nextsent>all evaluation is carried out using the parseval labelled bracketing metrics, with evalb and parameter file new.prm.
</nextsent>
<nextsent>3the notation bnc500k+5wsj refers to set of 500,000 parser output parse trees of sentences taken randomly from the bnc concatenated with five copies of wsj sections 2-21.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4439">
<title id=" W07-1523.xml">web based annotation of anaphoric relations and lexical chains </title>
<section> annotating large text corpora.  </section>
<citcontext>
<prevsection>
<prevsent>(2004) or strube and mller (2003) have shown the feasibility of decision trees for the domain of anaphora resolution; we have chosen this approach as it makes it possible to easily switch the information set for training and evaluation as opposed to e. g. rewriting rule sets.
</prevsent>
<prevsent>both, training and evaluation as well as empirically based analysis of anaphora need an annotated reference corpus (poesio et al, 2002).
</prevsent>
</prevsection>
<citsent citstr=" W04-2327 ">
scheme and annotation process are described in the following section.the annotation scheme for anaphoric relations several annotation schemes for annotating anaphoric relations have been developed inthe last years, e. g. the ucrel anaphora annotation scheme (fligelstone, 1992; garside et al., 1997), the sgml-based muc annotation scheme (hirschmann, 1997), and the mate/g nome scheme (poesio, 2004), <papid> W04-2327 </papid>amongst others.</citsent>
<aftsection>
<nextsent>in order to annotate discourse relations ? either anaphoric relations or lexical chains (cf.
</nextsent>
<nextsent>section 2.2) ? two types of information have to be specified.
</nextsent>
<nextsent>first, the markables, i. e. the elements that can be part of relation, have to be specified (cf.
</nextsent>
<nextsent>mller and strube (2003)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4440">
<title id=" W07-1523.xml">web based annotation of anaphoric relations and lexical chains </title>
<section> annotating large text corpora.  </section>
<citcontext>
<prevsection>
<prevsent>in understanding the text.
</prevsent>
<prevsent>on this basis they were askedto determine the semantic relations of every possible chaining candidate pair, thus chain the noun sand annotate the three texts.
</prevsent>
</prevsection>
<citsent citstr=" W04-2607 ">
just like previously reported case studies (beigman klebanov, 2005; morris and hirst, 2004; <papid> W04-2607 </papid>morris and hirst, 2005) aiming at the annotation of lexical chains, we found that the inter-annotator agreement was in general relatively low.</citsent>
<aftsection>
<nextsent>only the annotation of very prominent items in the three texts, which accounted for approximately one fifth of the chaining candidates,resulted in satisfying agreement (that is: thema jority of the subjects produced an identical or very similar annotation).
</nextsent>
<nextsent>however, all subjects complained about the task.
</nextsent>
<nextsent>they found it rather difficult to construct linear ized or quasi-linearized structures, in short, chains.
</nextsent>
<nextsent>instead, most of the subjects built clusters and drew very complex graphs to illustrate the cohesive relations they found.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4442">
<title id=" W07-2017.xml">semeval2007 task 18 arabic semantic labeling </title>
<section> task: wsd.  </section>
<citcontext>
<prevsection>
<prevsent>the part of speech (pos) tag set used in the released data for both the wsd and the srl sub-tasks is the reduced tag set that is officially released with the atb.
</prevsent>
<prevsent>in the context of this task, word sense disambiguation is the process by which words in context are tagged with their specific meaning definitions from predefined lexical resource such as dictionary or taxonomy.
</prevsent>
</prevsection>
<citsent citstr=" J98-1001 ">
the nlp field has gone through very 94 long tradition of algorithms designed for solving this problem (ide and veronis, 1998).<papid> J98-1001 </papid></citsent>
<aftsection>
<nextsent>most of the systems however target english since it is the language with most resources.
</nextsent>
<nextsent>in fact big push forward dawned on english wsd with the wide release of significant resources such as wordnet.
</nextsent>
<nextsent>arabic poses some interesting challenges forwsd since it has an inherent complexity in its writing system.
</nextsent>
<nextsent>as mentioned earlier, written msa is underspecified for short vowels and diacritics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4443">
<title id=" W07-2017.xml">semeval2007 task 18 arabic semantic labeling </title>
<section> task: semantic role labeling (srl).  </section>
<citcontext>
<prevsection>
<prevsent>specifically,shallow approaches to semantic processing are making large strides in the direction of efficiently and effectively deriving tacit semantic information fromtext.
</prevsent>
<prevsent>semantic role labeling (srl) is one such approach.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
with the advent of faster and powerful computers, more effective machine learning algorithms, and importantly, large data resources annotated with relevant levels of semantic information framenet (baker et al, 1998) <papid> P98-1013 </papid>and prob bank corpora (palmeret al, 2005), <papid> J05-1004 </papid>we are seeing surge inefficient approaches to srl (carreras and ma`rquez, 2005).</citsent>
<aftsection>
<nextsent>srl is the process by which predicates and their arguments are identified and their roles defined in sentence.
</nextsent>
<nextsent>to date, most of the reported srl systems are forenglish.
</nextsent>
<nextsent>we do see some headway for other languages such as german and chinese.
</nextsent>
<nextsent>the systems for the other languages follow the successful models devised for english, (gildea and jurafsky, 2002; <papid> J02-3001 </papid>95xue and palmer, 2004; <papid> W04-3212 </papid>pradhan et al, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4444">
<title id=" W07-2017.xml">semeval2007 task 18 arabic semantic labeling </title>
<section> task: semantic role labeling (srl).  </section>
<citcontext>
<prevsection>
<prevsent>specifically,shallow approaches to semantic processing are making large strides in the direction of efficiently and effectively deriving tacit semantic information fromtext.
</prevsent>
<prevsent>semantic role labeling (srl) is one such approach.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
with the advent of faster and powerful computers, more effective machine learning algorithms, and importantly, large data resources annotated with relevant levels of semantic information framenet (baker et al, 1998) <papid> P98-1013 </papid>and prob bank corpora (palmeret al, 2005), <papid> J05-1004 </papid>we are seeing surge inefficient approaches to srl (carreras and ma`rquez, 2005).</citsent>
<aftsection>
<nextsent>srl is the process by which predicates and their arguments are identified and their roles defined in sentence.
</nextsent>
<nextsent>to date, most of the reported srl systems are forenglish.
</nextsent>
<nextsent>we do see some headway for other languages such as german and chinese.
</nextsent>
<nextsent>the systems for the other languages follow the successful models devised for english, (gildea and jurafsky, 2002; <papid> J02-3001 </papid>95xue and palmer, 2004; <papid> W04-3212 </papid>pradhan et al, 2003).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4445">
<title id=" W07-2017.xml">semeval2007 task 18 arabic semantic labeling </title>
<section> task: semantic role labeling (srl).  </section>
<citcontext>
<prevsection>
<prevsent>to date, most of the reported srl systems are forenglish.
</prevsent>
<prevsent>we do see some headway for other languages such as german and chinese.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
the systems for the other languages follow the successful models devised for english, (gildea and jurafsky, 2002; <papid> J02-3001 </papid>95xue and palmer, 2004; <papid> W04-3212 </papid>pradhan et al, 2003).</citsent>
<aftsection>
<nextsent>how ever, no srl systems exist for arabic.
</nextsent>
<nextsent>challenges of arabic for srl given the deep difference between such languages, this method may not be straightforward.
</nextsent>
<nextsent>to clarify this point, let us consider figure 1.
</nextsent>
<nextsent>it illustrates sample arabic syntactic tree with the relevant part of speech tags and arguments defined.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4446">
<title id=" W07-2017.xml">semeval2007 task 18 arabic semantic labeling </title>
<section> task: semantic role labeling (srl).  </section>
<citcontext>
<prevsection>
<prevsent>to date, most of the reported srl systems are forenglish.
</prevsent>
<prevsent>we do see some headway for other languages such as german and chinese.
</prevsent>
</prevsection>
<citsent citstr=" W04-3212 ">
the systems for the other languages follow the successful models devised for english, (gildea and jurafsky, 2002; <papid> J02-3001 </papid>95xue and palmer, 2004; <papid> W04-3212 </papid>pradhan et al, 2003).</citsent>
<aftsection>
<nextsent>how ever, no srl systems exist for arabic.
</nextsent>
<nextsent>challenges of arabic for srl given the deep difference between such languages, this method may not be straightforward.
</nextsent>
<nextsent>to clarify this point, let us consider figure 1.
</nextsent>
<nextsent>it illustrates sample arabic syntactic tree with the relevant part of speech tags and arguments defined.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4447">
<title id=" W07-1218.xml">validation and regression testing for a cross linguistic grammar resource </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in combination with test suite management software such as [incr tsdb()] (oepen, 2002), they are used for validation and regression testing of precision (deep linguistic) grammars as well as the exploration of potential changes to the grammar.
</prevsent>
<prevsent>in this paper, we consider what happens when the precision grammar resource being developed isnt agr ammar of particular language, but rather cross linguistic grammar resource.
</prevsent>
</prevsection>
<citsent citstr=" W02-1502 ">
in particular, we consider the lingo grammar matrix (bender et al,2002; <papid> W02-1502 </papid>bender and flickinger, 2005).<papid> I05-2035 </papid></citsent>
<aftsection>
<nextsent>there are several (related) obstacles to making effective use of test suites in this scenario: (1) the matrix core grammar isnt itself grammar, and therefore cant parse any strings.
</nextsent>
<nextsent>(2) there is no single language modeled by the cross-linguistic resource from whichto draw test strings.
</nextsent>
<nextsent>(3) the space of possible grammars (alternatively, language types) modeled by the resource is enormous, well beyond the scope of what can be thoroughly explored.
</nextsent>
<nextsent>we present methodology for the validation and regression testing of the grammar matrix that addresses these obstacles, developing the ideas originally proposed in (poulson, 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4448">
<title id=" W07-1218.xml">validation and regression testing for a cross linguistic grammar resource </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in combination with test suite management software such as [incr tsdb()] (oepen, 2002), they are used for validation and regression testing of precision (deep linguistic) grammars as well as the exploration of potential changes to the grammar.
</prevsent>
<prevsent>in this paper, we consider what happens when the precision grammar resource being developed isnt agr ammar of particular language, but rather cross linguistic grammar resource.
</prevsent>
</prevsection>
<citsent citstr=" I05-2035 ">
in particular, we consider the lingo grammar matrix (bender et al,2002; <papid> W02-1502 </papid>bender and flickinger, 2005).<papid> I05-2035 </papid></citsent>
<aftsection>
<nextsent>there are several (related) obstacles to making effective use of test suites in this scenario: (1) the matrix core grammar isnt itself grammar, and therefore cant parse any strings.
</nextsent>
<nextsent>(2) there is no single language modeled by the cross-linguistic resource from whichto draw test strings.
</nextsent>
<nextsent>(3) the space of possible grammars (alternatively, language types) modeled by the resource is enormous, well beyond the scope of what can be thoroughly explored.
</nextsent>
<nextsent>we present methodology for the validation and regression testing of the grammar matrix that addresses these obstacles, developing the ideas originally proposed in (poulson, 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4451">
<title id=" W07-1218.xml">validation and regression testing for a cross linguistic grammar resource </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>an interesting area for future work would be the comparison between the test suites generated by the system described here and the mg test suites.the key to the test-suite development process proposed here is to leverage the work already being done by the matrix developers into largely automated process for creating test-suite items.
</prevsent>
<prevsent>the information required from the developers is essentially structured and systematic version of the knowledge that is required for the creation of libraries in the first place.
</prevsent>
</prevsection>
<citsent citstr=" C00-1018 ">
this basic approach, is also the basis for the approach taken in (broker, 2000); <papid> C00-1018 </papid>the specific formsof knowledge leveraged, and the test-suite development strategies used, however, are quite different.</citsent>
<aftsection>
<nextsent>the addition of the next library to the grammar matrix will provide us with an opportunity to try to quantify the effect of this methodology.
</nextsent>
<nextsent>with the grammar matrix and the filters stabilized, the validation of new library can be carefully tracked.
</nextsent>
<nextsent>we can try to quantify the number of errors obtained and the source of the errors, e.g., library or filters.
</nextsent>
<nextsent>in addition to this kind of quantification and error analysis as means of validating this methodology, we also intend to undertake comparison of the test suites created from our database to hand built created for matrix-derived grammars by students in the multilingual grammar engineering course at the university of washington.4 students in this class each develop grammars for different language, and create test suites of positive and negative examples as part of their development process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4452">
<title id=" W07-1711.xml">multilingual word sense discrimination a comparative cross linguistic study </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>based on this approach, sense is defined as cluster of contexts of an ambiguous word.
</prevsent>
<prevsent>each occurrence of an ambiguous word is represented as vector of features, where features are based on terms occurring in the context of the target word.
</prevsent>
</prevsection>
<citsent citstr=" W97-0322 ">
for example, pedersen and bruce (1997) <papid> W97-0322 </papid>cluster the occurrences of an ambiguous word by constructing avector of terms occurring in the context of the tar get.</citsent>
<aftsection>
<nextsent>schutze (1992) presents method that explores the similarity between the context terms occurring around the target.
</nextsent>
<nextsent>this is accomplished by considering feature vectors of context terms of the ambiguous word.
</nextsent>
<nextsent>the algorithm is evaluated on natural and artificially-constructed ambiguous english words.sproat and van santen (1998) introduce technique for automatic detection of ambiguous words in corpus and measuring their degree of polysemy.this technique employs similarity measure between the context terms similar in spirit to the onein (schutze, 1992) and singular value decomposition in order to detect context terms that are important for disambiguating the target.
</nextsent>
<nextsent>they show thatthe method is capable of identifying polysemous english words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4453">
<title id=" W07-1711.xml">multilingual word sense discrimination a comparative cross linguistic study </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>he finds 50 most similar words to the target and clusters the minto groups, the number of groups being the number of senses.
</prevsent>
<prevsent>he reports comparable results forthe two languages, but he uses both morphologically and lexically ambiguous words.
</prevsent>
</prevsection>
<citsent citstr=" P06-1038 ">
moreover, the evaluation methodology focuses on the success of disambiguation for an ambiguous word, and reports the number of ambiguous words that were disam biguated successfully.davidov and rappoport (2006) <papid> P06-1038 </papid>describe an algorithm for unsupervised discovery of word categories and evaluate it on russian and english corpora.</citsent>
<aftsection>
<nextsent>however, the focus of their work is on the discovery of semantic categories and from the results they report for the two languages it is difficult to infer how the languages compare against each other.
</nextsent>
<nextsent>we conduct more thorough evaluation.
</nextsent>
<nextsent>we also 83 control cross-linguistically for number of training examples and level of ambiguity of selected words, as described in section 4.
</nextsent>
<nextsent>2.3 morphology and wsd.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4454">
<title id=" W07-1711.xml">multilingual word sense discrimination a comparative cross linguistic study </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we also 83 control cross-linguistically for number of training examples and level of ambiguity of selected words, as described in section 4.
</prevsent>
<prevsent>2.3 morphology and wsd.
</prevsent>
</prevsection>
<citsent citstr=" J92-1001 ">
mcroy (1992) <papid> J92-1001 </papid>describes study of different sources useful for word sense disambiguation, including morphological information.</citsent>
<aftsection>
<nextsent>she reports that morphology is useful, but the focus is on derivational morphology of the english language.
</nextsent>
<nextsent>in the present context, we are interested in the effect of inflectional morphology onwsd, especially for languages, such as russian and hebrew.gaustad (2004) <papid> C04-1112 </papid>proposes lemma-based approach to maximum entropy word sense disambiguation system for dutch.</nextsent>
<nextsent>she shows that collapsing word forms of an ambiguous word yields more robust classifier due to the availability of more training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4455">
<title id=" W07-1711.xml">multilingual word sense discrimination a comparative cross linguistic study </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>mcroy (1992) <papid> J92-1001 </papid>describes study of different sources useful for word sense disambiguation, including morphological information.</prevsent>
<prevsent>she reports that morphology is useful, but the focus is on derivational morphology of the english language.</prevsent>
</prevsection>
<citsent citstr=" C04-1112 ">
in the present context, we are interested in the effect of inflectional morphology onwsd, especially for languages, such as russian and hebrew.gaustad (2004) <papid> C04-1112 </papid>proposes lemma-based approach to maximum entropy word sense disambiguation system for dutch.</citsent>
<aftsection>
<nextsent>she shows that collapsing word forms of an ambiguous word yields more robust classifier due to the availability of more training data.
</nextsent>
<nextsent>the results indicate an improvement of this approach over classification based on wordforms.
</nextsent>
<nextsent>our algorithm relies on the method for selection of relevant contextual terms and on distance measure between them introduced in (sproat and van santen, 1998) and on the approach described in (schutze, 1998), though the details of clustering differ slightly.the intuition behind the algorithm can be summarized as follows: (1) words that occur in the context of the ambiguous word are useful for determining its sense; and (2) contextual terms of an ambiguous word belong to topics corresponding to the senses of the ambiguous word.
</nextsent>
<nextsent>before describing the algorithm in detail, we give an overview of the system.the algorithm starts by collecting all the occurrences of an ambiguous word in the corpus together with the surrounding context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4456">
<title id=" W07-1019.xml">the extraction of enriched protein protein interactions from biomedical text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>some conclusions and suggestions for further work are offered in section 6.
</prevsent>
<prevsent>145
</prevsent>
</prevsection>
<citsent citstr=" E06-1051 ">
there has been much recent interest in extracting ppis from abstracts and full text papers (bunescu and mooney, 2006; giuliano et al, 2006; <papid> E06-1051 </papid>plake et al., 2005; blaschke and valencia, 2002; donaldson et al, 2003).</citsent>
<aftsection>
<nextsent>in these systems however, the focus has been on extracting just the ppis without attempts to enrich the ppis with further information.
</nextsent>
<nextsent>enriched ppis can be seen as type of biological event extraction (alphonse et al, 2004; <papid> W04-1207 </papid>wattarujeekrit et al, 2004), technique for mapping entities found in text to roles in predefined templates which was made popular in the muc tasks (marsh and perzanowski, 1998).<papid> M98-1002 </papid></nextsent>
<nextsent>there has also been work to enrich sentences with semantic categories (shah and bork, 2006) and qualitative dimensions such as polarity (wilbur et al., 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4457">
<title id=" W07-1019.xml">the extraction of enriched protein protein interactions from biomedical text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there has been much recent interest in extracting ppis from abstracts and full text papers (bunescu and mooney, 2006; giuliano et al, 2006; <papid> E06-1051 </papid>plake et al., 2005; blaschke and valencia, 2002; donaldson et al, 2003).</prevsent>
<prevsent>in these systems however, the focus has been on extracting just the ppis without attempts to enrich the ppis with further information.</prevsent>
</prevsection>
<citsent citstr=" W04-1207 ">
enriched ppis can be seen as type of biological event extraction (alphonse et al, 2004; <papid> W04-1207 </papid>wattarujeekrit et al, 2004), technique for mapping entities found in text to roles in predefined templates which was made popular in the muc tasks (marsh and perzanowski, 1998).<papid> M98-1002 </papid></citsent>
<aftsection>
<nextsent>there has also been work to enrich sentences with semantic categories (shah and bork, 2006) and qualitative dimensions such as polarity (wilbur et al., 2006).
</nextsent>
<nextsent>using nlp to aid in cur ation was addressed inthe kdd 2002 cup (yeh et al, 2002), where participants attempted to extract records curatable with respect to the flybase database, and has been further studied by many groups (xu et al, 2006; karamanis et al, 2007; ursing et al, 2001).
</nextsent>
<nextsent>the protein-protein interaction task of the recent bio creative challenge (krallinger et al, 2007) was concerned with selecting papers and extracting information suitable for curation.
</nextsent>
<nextsent>the ppi detectionsubtask (ips) required participants not simply to detect ppi mentions, but to detect curatable ppi mentions, in other words to enrich the ppi mentions with extra information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4458">
<title id=" W07-1019.xml">the extraction of enriched protein protein interactions from biomedical text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there has been much recent interest in extracting ppis from abstracts and full text papers (bunescu and mooney, 2006; giuliano et al, 2006; <papid> E06-1051 </papid>plake et al., 2005; blaschke and valencia, 2002; donaldson et al, 2003).</prevsent>
<prevsent>in these systems however, the focus has been on extracting just the ppis without attempts to enrich the ppis with further information.</prevsent>
</prevsection>
<citsent citstr=" M98-1002 ">
enriched ppis can be seen as type of biological event extraction (alphonse et al, 2004; <papid> W04-1207 </papid>wattarujeekrit et al, 2004), technique for mapping entities found in text to roles in predefined templates which was made popular in the muc tasks (marsh and perzanowski, 1998).<papid> M98-1002 </papid></citsent>
<aftsection>
<nextsent>there has also been work to enrich sentences with semantic categories (shah and bork, 2006) and qualitative dimensions such as polarity (wilbur et al., 2006).
</nextsent>
<nextsent>using nlp to aid in cur ation was addressed inthe kdd 2002 cup (yeh et al, 2002), where participants attempted to extract records curatable with respect to the flybase database, and has been further studied by many groups (xu et al, 2006; karamanis et al, 2007; ursing et al, 2001).
</nextsent>
<nextsent>the protein-protein interaction task of the recent bio creative challenge (krallinger et al, 2007) was concerned with selecting papers and extracting information suitable for curation.
</nextsent>
<nextsent>the ppi detectionsubtask (ips) required participants not simply to detect ppi mentions, but to detect curatable ppi mentions, in other words to enrich the ppi mentions with extra information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4459">
<title id=" W07-1019.xml">the extraction of enriched protein protein interactions from biomedical text </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 pipeline processing.
</prevsent>
<prevsent>the property and attribute assignment modules were implemented as part of an nlp pipeline based on the lt-xml2 architecture1 . the pipeline consists of token isation, lemmatisation, part-of-speech tagging, species word identification, abbreviation detection and chunking, named entiry recognition (ner) and relation extraction.
</prevsent>
</prevsection>
<citsent citstr=" W03-0424 ">
the part-of-speech tagging uses the curran and clark pos tagger (curran and clark, 2003) <papid> W03-0424 </papid>trained on medpost data (smith et al, 2004), whilst the other preprocessing stages are all rule based.</citsent>
<aftsection>
<nextsent>token isation, species word identification and chunking were implemented in-house using the ltxml2 tools (grover and tobin, 2006), whilst abbreviation extraction used the schwartz and hearst abbreviation extractor (schwartz and hearst, 2003) and lemmatisation used morpha (minnen et al, 2000).<papid> W00-1427 </papid></nextsent>
<nextsent>the ner module uses the curran and clark ner tagger (curran and clark, 2003), <papid> W03-0424 </papid>augmented with extra features tailored to the biomedical domain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4460">
<title id=" W07-1019.xml">the extraction of enriched protein protein interactions from biomedical text </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>the property and attribute assignment modules were implemented as part of an nlp pipeline based on the lt-xml2 architecture1 . the pipeline consists of token isation, lemmatisation, part-of-speech tagging, species word identification, abbreviation detection and chunking, named entiry recognition (ner) and relation extraction.
</prevsent>
<prevsent>the part-of-speech tagging uses the curran and clark pos tagger (curran and clark, 2003) <papid> W03-0424 </papid>trained on medpost data (smith et al, 2004), whilst the other preprocessing stages are all rule based.</prevsent>
</prevsection>
<citsent citstr=" W00-1427 ">
token isation, species word identification and chunking were implemented in-house using the ltxml2 tools (grover and tobin, 2006), whilst abbreviation extraction used the schwartz and hearst abbreviation extractor (schwartz and hearst, 2003) and lemmatisation used morpha (minnen et al, 2000).<papid> W00-1427 </papid></citsent>
<aftsection>
<nextsent>the ner module uses the curran and clark ner tagger (curran and clark, 2003), <papid> W03-0424 </papid>augmented with extra features tailored to the biomedical domain.</nextsent>
<nextsent>finally, relation extractor based on maximum entropy model and set of shallow linguistic features is employed, as described in (nielsen, 2006).<papid> W06-3322 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4462">
<title id=" W07-1019.xml">the extraction of enriched protein protein interactions from biomedical text </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>token isation, species word identification and chunking were implemented in-house using the ltxml2 tools (grover and tobin, 2006), whilst abbreviation extraction used the schwartz and hearst abbreviation extractor (schwartz and hearst, 2003) and lemmatisation used morpha (minnen et al, 2000).<papid> W00-1427 </papid></prevsent>
<prevsent>the ner module uses the curran and clark ner tagger (curran and clark, 2003), <papid> W03-0424 </papid>augmented with extra features tailored to the biomedical domain.</prevsent>
</prevsection>
<citsent citstr=" W06-3322 ">
finally, relation extractor based on maximum entropy model and set of shallow linguistic features is employed, as described in (nielsen, 2006).<papid> W06-3322 </papid></citsent>
<aftsection>
<nextsent>4.2 properties.
</nextsent>
<nextsent>to assign properties to each ppi extracted by the relation extraction component, machine learning based property tagger was trained on set of features extracted from the context of the ppi.
</nextsent>
<nextsent>the property tagger used separate classifier for each property, but with the same feature set, and both maximum entropy (implemented using zhang les maxent2) and support vector machines (implemented using 1http://www.ltg.ed.ac.uk/software/xml/ 2http://homepages.inf.ed.ac.uk/s0450736/ maxent_toolkit.htmlsvmlight3) were tested.
</nextsent>
<nextsent>to choose an optimal feature set, an iterative greedy optimisation procedure was employed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4463">
<title id=" W07-1019.xml">the extraction of enriched protein protein interactions from biomedical text </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>performance on each attribute value is measured using f1, and then micro averaged to give an overall figure.
</prevsent>
<prevsent>machine learners.
</prevsent>
</prevsection>
<citsent citstr=" P04-1043 ">
however it is also possible thatthe shallow linguistic features used in these experiments are not sufficient to make the sometimes subtle distinction between negative statement about an interaction and positive one, and that models based on deeper linguistic analysis (e.g. parse trees as in (moschitti, 2004)) <papid> P04-1043 </papid>would be more successful.note also that the feature set was optimised for maximum performance across all property values, with all given equal weight, but if some values are more important than others then this could be taken into account in the optimisation, with possibly different feature sets used for different property names.</citsent>
<aftsection>
<nextsent>the results for the attributes using the rule-basedsystem are approximately 75% of human performance and are higher than results for the machine learning system.
</nextsent>
<nextsent>however, for the modification after, cell line, and interactiondetectionmethod attributes, which occur more frequently than the other attributes and have higher iaa, the machine learning system is competitive and even slightly outperforms in the case of the interactiondetectionmethod.
</nextsent>
<nextsent>the scores are directly correlated with the iaa and both the scores and the iaa are higher for the attributes that tend to occur in the same sentence as the ppi.
</nextsent>
<nextsent>on practical level, this suggests that those who hope to create similar systems would be advised to start with local attributes and pay particular attention to iaa on non-local attributes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4464">
<title id=" W07-1309.xml">evolution optimization and language change the case of bengali verb inflections </title>
<section> the problem.  </section>
<citcontext>
<prevsection>
<prevsent>rewrite rules are quite expressive and therefore, it is possible to represent complex phonological changes using single rewrite rule.
</prevsent>
<prevsent>on the other hand, apos are simple phonological changes that can be explained independently in terms of phonetic factors (ohala, 1993).
</prevsent>
</prevsection>
<citsent citstr=" W04-0103 ">
in fact, there are also computational models satisfactorily accounting for cases of vowel deletion (choudhury et al, 2004; <papid> W04-0103 </papid>choudhury et al, 2006b) and assimilation (dras et al., 2003).</citsent>
<aftsection>
<nextsent>table 3 shows the derivation of the scb verb forms from classical bengali in terms of apos.
</nextsent>
<nextsent>the derivations are constructed based on the data provided in (chatterji, 1926).
</nextsent>
<nextsent>2.3 functional explanation for change of bvi.
</nextsent>
<nextsent>let 0 be the lexicon of classical bengali verb forms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4470">
<title id=" W07-1027.xml">developing feature types for classifying clinical notes </title>
<section> the task of assigning icd-9-cm codes.  </section>
<citcontext>
<prevsection>
<prevsent>for each code found in the corpus, we created separate classifier which makes binary yes?
</prevsent>
<prevsent>or no? decisions for the target code of clinical record.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
maximum entropy modeling (maxent) (berger et al, 1996) <papid> J96-1002 </papid>and support vector machine (svm) (vapnik, 1995) were used to build the classifiers in our solution.</citsent>
<aftsection>
<nextsent>a variety of features were developed to represent what we believed were the important determiners of the icd-9-cm codes.bag-of-words (bow) features: include only unigrams and bigrams in the text.
</nextsent>
<nextsent>negation features: were used in the classification system to capture the terms that are negated or uncertain, for example pneumonia?
</nextsent>
<nextsent>vs no evidence of pneumonia?.
</nextsent>
<nextsent>we created negation-finding system which uses an algorithm similar to (chapman et al, 2001) to identify the negation phrase and the scope of negations.gloss matching feature: the icd-9-cm provides detailed text definition for each code.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4471">
<title id=" W07-2082.xml">ucdpn classification of semantic relations between nominals using wordnet and web counts </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>in our system we combine these two knowledge sources and build set of features to use as input to support vector machine learning algorithm.
</prevsent>
<prevsent>the use of hit counts from web search engines to obtain lexical information was introduced by turney (2001).
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
the idea of searching large corpus for specific lexico-syntactic phrases to indicate semantic relation of interest was first described by hearst (1992).<papid> C92-2082 </papid></citsent>
<aftsection>
<nextsent>a lexical pattern specific enough to indicate particular semantic relation is usually not very frequent, and using the web as corpus alleviates the data sparseness problem.
</nextsent>
<nextsent>however, it also introduces some problems.
</nextsent>
<nextsent>the number of results returned is unstable as pages are created and deleted all the time, and the major search engines return only rounded frequency estimates and do not allow very sophisticated query interface.
</nextsent>
<nextsent>nakov and hearst (2005) <papid> H05-1105 </papid>examined the use of web based n-gram frequencies for an nlp task and concluded that these issues do not greatly impact the interpretation of the results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4472">
<title id=" W07-2082.xml">ucdpn classification of semantic relations between nominals using wordnet and web counts </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, it also introduces some problems.
</prevsent>
<prevsent>the number of results returned is unstable as pages are created and deleted all the time, and the major search engines return only rounded frequency estimates and do not allow very sophisticated query interface.
</prevsent>
</prevsection>
<citsent citstr=" H05-1105 ">
nakov and hearst (2005) <papid> H05-1105 </papid>examined the use of web based n-gram frequencies for an nlp task and concluded that these issues do not greatly impact the interpretation of the results.</citsent>
<aftsection>
<nextsent>turney and littman (2005) use web queries to the alta vista search engine as the basis for their system to assign semantic relations to modifier noun phrases.
</nextsent>
<nextsent>they use set of 64 short prepositional and conjunctive phrases (joining terms) to generate exact queries of the form noun joining term modifier?, and modifier joining term noun?.
</nextsent>
<nextsent>using 64 joining terms and trying the noun and modifier in either order resulted in vector of 128 374 hit counts for each noun-modifier pair.
</nextsent>
<nextsent>these hit counts were used with supervised (nearest neighbor) algorithm to label the modifier-noun phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4473">
<title id=" W07-2082.xml">ucdpn classification of semantic relations between nominals using wordnet and web counts </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>by retrieving the words that most commonly occurred in the place of the wild card they were able to identify very specific predicates that are likely to represent the relation between noun and modifier.
</prevsent>
<prevsent>there have also been several approaches which used hand built knowledge sources.
</prevsent>
</prevsection>
<citsent citstr=" W01-0511 ">
rosario and hearst (2001) <papid> W01-0511 </papid>used mesh, lexical hierarchy of medical terms.</citsent>
<aftsection>
<nextsent>they use this hierarchy to assign semantic properties to head and modifier words in the medical domain.
</nextsent>
<nextsent>they use neural network trained on these attributes to assign the noun phrases semantic relation.
</nextsent>
<nextsent>nastase and szpakowicz (2003) use the position of the noun and modifier words within general semantic hierarchies (roget thesaurus and word net) as attributes for their learning algorithms.
</nextsent>
<nextsent>they experiment with decision trees, rule induction system, relational learner and memory based learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4474">
<title id=" W07-2082.xml">ucdpn classification of semantic relations between nominals using wordnet and web counts </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>they experiment with decision trees, rule induction system, relational learner and memory based learning.
</prevsent>
<prevsent>they conclude that the rule induction system is capable of generalizing to characterize the noun phrases.
</prevsent>
</prevsection>
<citsent citstr=" W04-2609 ">
moldovan et al(2004) <papid> W04-2609 </papid>also use wordnet.</citsent>
<aftsection>
<nextsent>they experiment with bayesian algorithm, decision trees, and their own algorithm; semantic scattering.
</nextsent>
<nextsent>as far as we are aware ours is the first system to combine features derived from hand-built lexical database with corpus frequencies of lexical patterns.
</nextsent>
<nextsent>2.1 wordnet features our system uses both features derived from wordnet and features obtained by collecting web frequencies for lexical patterns.
</nextsent>
<nextsent>we did not use any information from the sentence in which the two nominals appeared, nor did we use the query used to retrieve the examples.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4475">
<title id=" W07-1201.xml">multicomponent tree adjoining grammars dependency graph models and linguistic analyses </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P06-2066 ">
recent work identifies two properties that appear particularly relevant to the characterization of graph-based dependency models of syntactic structure1: the absence of inter leaving substructures (well-nestedness) and bound on type of discontinuity (gap-degree ? 1) successfully describe more than 99% of the structures in two dependency treebanks (kuhlmann and nivre 2006).<papid> P06-2066 </papid>2 bodirsky et al (2005) establish that every dependency structure with these two properties can be recast as lexicalized tree adjoining grammar (ltag) derivation and vice versa.</citsent>
<aftsection>
<nextsent>however, multicomponent extensions of tag (mc-tag), argued to be necessary on linguistic grounds, induce dependency structures that do not conform to these two properties (kuhlmann and mhl 2006).<papid> W06-1517 </papid></nextsent>
<nextsent>in this paper, we observe that several types of mc-tag as used for linguistic analysis are more restrictive than the formal system is in prin ciple.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4476">
<title id=" W07-1201.xml">multicomponent tree adjoining grammars dependency graph models and linguistic analyses </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>recent work identifies two properties that appear particularly relevant to the characterization of graph-based dependency models of syntactic structure1: the absence of inter leaving substructures (well-nestedness) and bound on type of discontinuity (gap-degree ? 1) successfully describe more than 99% of the structures in two dependency treebanks (kuhlmann and nivre 2006).<papid> P06-2066 </papid>2 bodirsky et al (2005) establish that every dependency structure with these two properties can be recast as lexicalized tree adjoining grammar (ltag) derivation and vice versa.</prevsent>
</prevsection>
<citsent citstr=" W06-1517 ">
however, multicomponent extensions of tag (mc-tag), argued to be necessary on linguistic grounds, induce dependency structures that do not conform to these two properties (kuhlmann and mhl 2006).<papid> W06-1517 </papid></citsent>
<aftsection>
<nextsent>in this paper, we observe that several types of mc-tag as used for linguistic analysis are more restrictive than the formal system is in principle.
</nextsent>
<nextsent>in particular, tree-local mc-tag, tree-local mc-tag with flexible composi 1 whereas weak equivalence of grammar classes is only concerned with string sets and fails to shed light on equivalence at the structural level, our work involves the equivalence of derivations and graph based models of dependencies.
</nextsent>
<nextsent>thus, our work is relevant to certain aspects of grammar engineering that weak equivalence does not speak to.
</nextsent>
<nextsent>2 these properties hold for many of the so-called non projective dependency structures and the corresponding non context free structures associated with tag, further allowing cky type dynamic programming approaches to parsing to these dependency graphs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4487">
<title id=" W07-1201.xml">multicomponent tree adjoining grammars dependency graph models and linguistic analyses </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>whereas basic tag takes the basic unit to be single elementary tree, mc-tag extends the do main of locality to encompass set of elementary trees.
</prevsent>
<prevsent>that is, these sets are the objects over which the combinatory operations apply.
</prevsent>
</prevsection>
<citsent citstr=" W06-1509 ">
the mcextension allows for linguistically satisfying accounts for number of attested phenomena, such as: english extra position (kroch and joshi 1986), subj-aux inversion in combination with raising verbs (frank 1992), anaphoric binding (ryant and scheffler 2006), <papid> W06-1509 </papid>quantifier scope ambiguity (joshi et al 2003), clitic climbing in romance (bleam 1994), and japanese causatives (heycock 1986).</citsent>
<aftsection>
<nextsent>the primary concern of this paper is the reconciliation of the observation noted above, that mc tag appears to be on the right track for good generative characterization of natural language, with second observation: the graph drawings that correspond to mc-tag derivations, are not guaranteed to retain the properties of basic-tag induced graph drawings.
</nextsent>
<nextsent>kuhlmann and mhl (2006) <papid> W06-1517 </papid>report that if an entire mc set is anchored by single lexical element (the natural extension of lexicalization?</nextsent>
<nextsent>of tags to mc-tags), then the class of dependency structures is expanded with respect to both conditions that characterized the tag-induced graph drawings: mc-tag induced graph drawings include structures that are not well-nested, have gap degree   1, or both.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4502">
<title id=" W07-1201.xml">multicomponent tree adjoining grammars dependency graph models and linguistic analyses </title>
<section> properties of dependency graphs.  </section>
<citcontext>
<prevsection>
<prevsent>7 this result refers to single graph drawings and particular.
</prevsent>
<prevsent>ltag derivation.
</prevsent>
</prevsection>
<citsent citstr=" P07-1021 ">
see kuhlmann and mhl (2007) <papid> P07-1021 </papid>on the relationship between sets of graph drawings and ltags.</citsent>
<aftsection>
<nextsent>y np x* zag (saw) np zwemmen (swim) jan de kind eren (the children) zag jan de kind eren zwemmen jan de kind eren zag zwemmen jan np de kind eren (the children) np np x* zag (saw) x np zwemmen (swim) 3 recall that the nodes of graph drawing are in precedence relation, and that this precedence relation is total.
</nextsent>
<nextsent>definition: gap is discontinuity with respect to precedence in the projection of node in the drawing.
</nextsent>
<nextsent>(e.g. in (4), de kind eren is the gap preventing jan and zag from forming contiguous interval.)
</nextsent>
<nextsent>definition: the gap degree of node is the number of gaps in its projection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4516">
<title id=" W07-1512.xml">computing translation units and quantifying parallelism in parallel dependency treebanks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>but non parallelism can also be the result of differences in the linguistic analyses of the source text and target text, eg, with respect to whether noun phrases are headed by nouns or determiners, whether conjunctions are headed by the first conjunct or the coordinator, whether prepositions are analyzed as heads or adjuncts in prepositional phrases, etc. in this paper, we focus on parallel dependency treebanks that consist of source texts and translations annotated with dependency analyses and word-alignments.
</prevsent>
<prevsent>these requirements are directly satisfied by the analytical layer of the prague czech-english dependency treebank (cmejrek et al., 2004) and by the dependency layer of the copenhagen danish-english dependency treebank (buch-kromann et al, 2007).
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
the requirements are also indirectly satisifed by parallel treebanks with constituent layer and word alignment, eg (han et al., 2002; cyrus, 2006; hansen-schirra et al, 2006; samuelsson and volk, 2006), since it is possible to transform constituent structures into dependency structures ? procedure used in the conll shared tasks in 2006 and 2007 (buchholz and marsi, 2006).<papid> W06-2920 </papid></citsent>
<aftsection>
<nextsent>finally, it is worth pointing out that the requirements are also met by any corpus equipped with two different dependency annotations since text is alwaystrivially word-aligned with itself.
</nextsent>
<nextsent>the methods proposed in the paper therefore apply to wide range of parallel treebanks, as well as to comparing two monolingual treebank annotations with each other.
</nextsent>
<nextsent>the paper is structured as follows.
</nextsent>
<nextsent>in section 2,we define our notions of word alignments and dependencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4517">
<title id=" W07-1512.xml">computing translation units and quantifying parallelism in parallel dependency treebanks </title>
<section> word alignments and dependencies.  </section>
<citcontext>
<prevsection>
<prevsent>y subj dobj vobj pobj nobj figure 3: the six translation units derived from the parallel dependency analysis in figure 2.
</prevsent>
<prevsent>the definition and interpretation of these rules.
</prevsent>
</prevsection>
<citsent citstr=" P05-1034 ">
in particular, unlike the essentially context-free translation rules used in frameworks such as (quirk et al., 2005; <papid> P05-1034 </papid>ding, 2006; chiang, 2007), we will not assume that the words in the translation rules are ordered, and that the translation rules can only be used in way that leads to projective dependency trees.</citsent>
<aftsection>
<nextsent>dependency-based translation model in many parallel treebanks, word alignments and syntactic annotations are created independently of each other, and there is therefore no guarantee that the word or phrase alignments coincide with any meaningful notion of translation units.
</nextsent>
<nextsent>to rectify this problem, we need to define notion of translation units that links the word alignments and the source and target dependency analysis in meaningful way, and we need to specify procedure for constructing meaningful set of word alignments from the actual treebank annotation.statistical machine translation models often embody an explicit notion of translation units.
</nextsent>
<nextsent>how ever, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (galley et al, 2004; <papid> N04-1035 </papid>marcu et al, 2006; <papid> W06-1606 </papid>koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>other smt models assume translation units where the source and target language annotation is based on either context free grammar (yamada and knight, 2001; <papid> P01-1067 </papid>chiang, 2007) or context-free dependency grammar (quirket al, 2005; <papid> P05-1034 </papid>ding, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4518">
<title id=" W07-1512.xml">computing translation units and quantifying parallelism in parallel dependency treebanks </title>
<section> translation units within simple.  </section>
<citcontext>
<prevsection>
<prevsent>dependency-based translation model in many parallel treebanks, word alignments and syntactic annotations are created independently of each other, and there is therefore no guarantee that the word or phrase alignments coincide with any meaningful notion of translation units.
</prevsent>
<prevsent>to rectify this problem, we need to define notion of translation units that links the word alignments and the source and target dependency analysis in meaningful way, and we need to specify procedure for constructing meaningful set of word alignments from the actual treebank annotation.statistical machine translation models often embody an explicit notion of translation units.
</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
how ever, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (galley et al, 2004; <papid> N04-1035 </papid>marcu et al, 2006; <papid> W06-1606 </papid>koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>other smt models assume translation units where the source and target language annotation is based on either context free grammar (yamada and knight, 2001; <papid> P01-1067 </papid>chiang, 2007) or context-free dependency grammar (quirket al, 2005; <papid> P05-1034 </papid>ding, 2006).</nextsent>
<nextsent>however, since non 71projectivity is not directly compatible with context free grammar, and parallel dependency treebanks tend to encode non-projective dependencies directly,the context-free smt models are not directly applicable to parallel dependency treebanks in general.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4519">
<title id=" W07-1512.xml">computing translation units and quantifying parallelism in parallel dependency treebanks </title>
<section> translation units within simple.  </section>
<citcontext>
<prevsection>
<prevsent>dependency-based translation model in many parallel treebanks, word alignments and syntactic annotations are created independently of each other, and there is therefore no guarantee that the word or phrase alignments coincide with any meaningful notion of translation units.
</prevsent>
<prevsent>to rectify this problem, we need to define notion of translation units that links the word alignments and the source and target dependency analysis in meaningful way, and we need to specify procedure for constructing meaningful set of word alignments from the actual treebank annotation.statistical machine translation models often embody an explicit notion of translation units.
</prevsent>
</prevsection>
<citsent citstr=" W06-1606 ">
how ever, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (galley et al, 2004; <papid> N04-1035 </papid>marcu et al, 2006; <papid> W06-1606 </papid>koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>other smt models assume translation units where the source and target language annotation is based on either context free grammar (yamada and knight, 2001; <papid> P01-1067 </papid>chiang, 2007) or context-free dependency grammar (quirket al, 2005; <papid> P05-1034 </papid>ding, 2006).</nextsent>
<nextsent>however, since non 71projectivity is not directly compatible with context free grammar, and parallel dependency treebanks tend to encode non-projective dependencies directly,the context-free smt models are not directly applicable to parallel dependency treebanks in general.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4520">
<title id=" W07-1512.xml">computing translation units and quantifying parallelism in parallel dependency treebanks </title>
<section> translation units within simple.  </section>
<citcontext>
<prevsection>
<prevsent>dependency-based translation model in many parallel treebanks, word alignments and syntactic annotations are created independently of each other, and there is therefore no guarantee that the word or phrase alignments coincide with any meaningful notion of translation units.
</prevsent>
<prevsent>to rectify this problem, we need to define notion of translation units that links the word alignments and the source and target dependency analysis in meaningful way, and we need to specify procedure for constructing meaningful set of word alignments from the actual treebank annotation.statistical machine translation models often embody an explicit notion of translation units.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
how ever, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (galley et al, 2004; <papid> N04-1035 </papid>marcu et al, 2006; <papid> W06-1606 </papid>koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>other smt models assume translation units where the source and target language annotation is based on either context free grammar (yamada and knight, 2001; <papid> P01-1067 </papid>chiang, 2007) or context-free dependency grammar (quirket al, 2005; <papid> P05-1034 </papid>ding, 2006).</nextsent>
<nextsent>however, since non 71projectivity is not directly compatible with context free grammar, and parallel dependency treebanks tend to encode non-projective dependencies directly,the context-free smt models are not directly applicable to parallel dependency treebanks in general.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4521">
<title id=" W07-1512.xml">computing translation units and quantifying parallelism in parallel dependency treebanks </title>
<section> translation units within simple.  </section>
<citcontext>
<prevsection>
<prevsent>to rectify this problem, we need to define notion of translation units that links the word alignments and the source and target dependency analysis in meaningful way, and we need to specify procedure for constructing meaningful set of word alignments from the actual treebank annotation.statistical machine translation models often embody an explicit notion of translation units.
</prevsent>
<prevsent>how ever, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (galley et al, 2004; <papid> N04-1035 </papid>marcu et al, 2006; <papid> W06-1606 </papid>koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
other smt models assume translation units where the source and target language annotation is based on either context free grammar (yamada and knight, 2001; <papid> P01-1067 </papid>chiang, 2007) or context-free dependency grammar (quirket al, 2005; <papid> P05-1034 </papid>ding, 2006).</citsent>
<aftsection>
<nextsent>however, since non 71projectivity is not directly compatible with context free grammar, and parallel dependency treebanks tend to encode non-projective dependencies directly,the context-free smt models are not directly applicable to parallel dependency treebanks in general.
</nextsent>
<nextsent>but the context-free smt models are an important inspiration for the simple dependency-based translation model and notion of translation units that we will present below.in our translation model, we will for simplicity assume that both the source dependency analysis and the target dependency analysis are unordered trees,ie, dependency transfer and word ordering are modelled as two separate processes.
</nextsent>
<nextsent>in this paper, we only look at the dependency transfer and ignore the word ordering, as well as the probabilistic modelling of the rules for transfer and word ordering.
</nextsent>
<nextsent>there are three kinds of translation rules in the model: a. complement rules have the form (x)t ?(x?)where (x) is source dependency tree with variables = (x1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4523">
<title id=" W07-0901.xml">naming the past named entity and animacy recognition in 19th century swedish literature </title>
<section> named entity recognition.  </section>
<citcontext>
<prevsection>
<prevsent>in any case, personal names, location and organization names are considered generic?.
</prevsent>
<prevsent>since semantic annotation is not as well understood as grammatical annotation, there is no consensus on standard tagset and content to be generally applicable.
</prevsent>
</prevsection>
<citsent citstr=" C02-1130 ">
recently, however, there have been attempts to define and apply richer name hierarchies for various tasks, both specific (fleisch man and hovy, 2002) <papid> C02-1130 </papid>and generic (sekine, 2004).</citsent>
<aftsection>
<nextsent>our current system implements rather fine grained named entity taxonomy with 8 main named entitiy types as well as 57 subtypes.
</nextsent>
<nextsent>details can be found in johannessen et al, 2005, and kokkinakis, 2004.
</nextsent>
<nextsent>the eight main categories are: ? person (prs): people names (forenames, surnames), groups of people, animal/pet names, mythological, theonyms; ? location (loc): functional locations, geographical, geo-political, astrological; ? organization (org): political, athletic, media, military, etc.; ? artifact (obj): food/wine products, prizes, communic.
</nextsent>
<nextsent>means (vehicles) etc.; ? work&art; (wrk): printed material, names of films and novels, sculptures etc.; ? event (evn): religious, athletic, scientific, cultural etc.; ? measure/numerical (msr): volume, age, index, dosage, web-related, speed etc.; ? temporal (tme).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4524">
<title id=" W07-0901.xml">naming the past named entity and animacy recognition in 19th century swedish literature </title>
<section> the document centered approach.  </section>
<citcontext>
<prevsection>
<prevsent>this implies form of online learning from the document being processed where unambiguous usages are used for assigning annotations to ambiguous words, and information for disambiguation is derived from the entire document.
</prevsent>
<prevsent>similarly, label consistency, the preference of the same annotation for the same word sequence everywhere in particular discourse, is comparable approach for achieving qualitatively higher recall rates with minimal resource overhead (cf.
</prevsent>
</prevsection>
<citsent citstr=" P06-1141 ">
krishnan and manning, 2006).<papid> P06-1141 </papid></citsent>
<aftsection>
<nextsent>such an approach has been used, e.g., by aramaki et al (2006), for the identification of personal health information (age, id, date, phone, location and doctors and patients names).
</nextsent>
<nextsent>figure 1.
</nextsent>
<nextsent>example of label consistency figure 1 illustrates this approach with an example taken from almqvists collected works, vol.
</nextsent>
<nextsent>30.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4525">
<title id=" W07-2046.xml">lccte a hybrid approach to temporal relation identification in news text </title>
<section> feature engineering.  </section>
<citcontext>
<prevsection>
<prevsent>the way we compute tense and aspect shifts is taking pair of contiguous events and assign true/false value to each relation instance based on whether tense or shift change in this pair.
</prevsent>
<prevsent>our experiments show that these two features didn contribute to the overall score, probably because they are redundant with the tense and aspect features of each event term.
</prevsent>
</prevsection>
<citsent citstr=" N03-2019 ">
temporal signal 1 initially used in (mani, et. al. 2003).<papid> N03-2019 </papid></citsent>
<aftsection>
<nextsent>human rule predictor machine learning ml testing documents with new tlinks word sense disambiguation ne &amp; pos tagging syntactic parsing syntactic pattern matching semantic parsing context detection temporal tagging &amp; normalizing temporal merging feature extraction &amp; composition documents with tempe val markups 220 represents temporal prepositions and they slightly contribute to the overall score of classifiers.
</nextsent>
<nextsent>the last feature in this category is the temporal relation between the document creation time and the temporal expression in the target sentence.
</nextsent>
<nextsent>the value of this feature could be greater than?, less than?, equal?, or none?.
</nextsent>
<nextsent>experiments show that this is an important feature for task and b, because it contributes several points to the overall score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4526">
<title id=" W07-2046.xml">lccte a hybrid approach to temporal relation identification in news text </title>
<section> feature engineering.  </section>
<citcontext>
<prevsection>
<prevsent>the basic idea here is that we want to have the option to call either component on the fly in different situations so that we can take advantage of the two empirical approaches in an integrated way.
</prevsent>
<prevsent>we did some initial experiments on dynamically applying human rule predictor and machine learner on task and we were able to obtain comparable results with or without using hand-crafted rules.
</prevsent>
</prevsection>
<citsent citstr=" W06-0110 ">
as pointed out in (li, et, al. 2006), <papid> W06-0110 </papid>support vector machine, as well as other classifiers, makes most mistakes near the decision plane in feature space.</citsent>
<aftsection>
<nextsent>we will investigate the 221 possibility of applying human rule prediction to those relation instances where machine learning makes most mistakes.
</nextsent>
<nextsent>3.2 experiments and results.
</nextsent>
<nextsent>based on the features discussed in section 3.3, we did series of experiments for each task on four models: naive-bayes, decision tree (c5.0), maximum entropy and support vector machine.
</nextsent>
<nextsent>due to space constraint, we only report results from svm model 3 , which produces best performance in our case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4527">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency representations of natural language are simple yet flexible mechanism for encoding words and their syntactic dependencies through directed graphs.
</prevsent>
<prevsent>these representations have been thoroughly studied in descriptive linguistics (tesnie`re, 1959; hudson, 1984; sgall et al, 1986; melcuk, 1988) andhave been applied in numerous language processing tasks.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
figure 1 gives an example dependency graph for the sentence mr. tomash will remain as director emeritus, which has been extracted from the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>each edge in this graph represents single syntactic dependency directed from word to its modifier.
</nextsent>
<nextsent>in this representation all edges are labeled with the specific syntactic function of the dependency, e.g., sbj for subject and nmod for modifier of noun.
</nextsent>
<nextsent>to simplify computation and some important definitions, an artificial token is inserted into the sentence as the left most word and will always represent the root of the dependency graph.
</nextsent>
<nextsent>we assume all dependency graphs are directed trees originating out of single node, which is common constraint (nivre, 2005).the dependency graph in figure 1 is an example of nested or projective graph.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4528">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one interesting class of data-driven models are 121 figure 1: projective dependency graph.
</prevsent>
<prevsent>figure 2: non-projective dependency graph.those that assume each dependency decision is independent modulo the global structural constraint that dependency graphs must be trees.
</prevsent>
</prevsection>
<citsent citstr=" P05-1012 ">
such models are commonly referred to as edge-factored since their parameters factor relative to individual edges of the graph (paskin, 2001; mcdonald et al,2005<papid> P05-1012 </papid>a).</citsent>
<aftsection>
<nextsent>edge-factored models have many computational benefits, most notably that inference for non projective dependency graphs can be achieved inpolynomial time (mcdonald et al, 2005<papid> P05-1012 </papid>b).</nextsent>
<nextsent>the primary problem in treating each dependency as independent is that it is not realistic assumption.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4544">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>edge-factored models have many computational benefits, most notably that inference for non projective dependency graphs can be achieved inpolynomial time (mcdonald et al, 2005<papid> P05-1012 </papid>b).</prevsent>
<prevsent>the primary problem in treating each dependency as independent is that it is not realistic assumption.</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
non-local information, such as arity (or valency) and neighbouring dependencies, can be crucial to obtaining high parsing accuracies (klein and manning, 2002; mcdonald and pereira, 2006).<papid> E06-1011 </papid></citsent>
<aftsection>
<nextsent>how ever, in the data-driven parsing setting this can be partially adver ted by incorporating rich feature representations over the input (mcdonald et al, 2005<papid> P05-1012 </papid>a).</nextsent>
<nextsent>the goal of this work is to further our current understanding of the computational nature of non projective parsing algorithms for both learning and inference within the data-driven setting.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4576">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a consequence of these results is that it is unlikely that exact non-projective dependency parsing is tractable for any model assumptions weaker than those made by the edge-factored models.
</prevsent>
<prevsent>1.1 related work.
</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
there has been extensive work on data-driven dependency parsing for both projective parsing (eis ner, 1996; <papid> C96-1058 </papid>paskin, 2001; yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>mcdonald et al, 2005<papid> P05-1012 </papid>a) and non-projective parsing systems (nivreand nilsson, 2005; <papid> P05-1013 </papid>hall and novak, 2005; mcdonald et al, 2005<papid> P05-1012 </papid>b).</citsent>
<aftsection>
<nextsent>these approaches can often be classified into two broad categories.
</nextsent>
<nextsent>in the first category are those methods that employ approximate inference, typically through the use of linear timeshift-reduce parsing algorithms (yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>nivre and nilsson, 2005).<papid> P05-1013 </papid></nextsent>
<nextsent>in the second category are those that employ exhaustive inference algorithms, usually by making strong independence assumptions, as is the case for edge-factored models (paskin, 2001; mcdonald et al, 2005<papid> P05-1012 </papid>a; mcdonald et al, 2005<papid> P05-1012 </papid>b).recently there have also been proposals for exhaustive methods that weaken the edge-factored assumption, including both approximate methods (mcdonald and pereira, 2006) <papid> E06-1011 </papid>and exact methods through integer linear programming (riedel and clarke, 2006) <papid> W06-1616 </papid>or branch-and-bound algorithms (hirakawa, 2006).<papid> P06-2047 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4577">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a consequence of these results is that it is unlikely that exact non-projective dependency parsing is tractable for any model assumptions weaker than those made by the edge-factored models.
</prevsent>
<prevsent>1.1 related work.
</prevsent>
</prevsection>
<citsent citstr=" C04-1010 ">
there has been extensive work on data-driven dependency parsing for both projective parsing (eis ner, 1996; <papid> C96-1058 </papid>paskin, 2001; yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>mcdonald et al, 2005<papid> P05-1012 </papid>a) and non-projective parsing systems (nivreand nilsson, 2005; <papid> P05-1013 </papid>hall and novak, 2005; mcdonald et al, 2005<papid> P05-1012 </papid>b).</citsent>
<aftsection>
<nextsent>these approaches can often be classified into two broad categories.
</nextsent>
<nextsent>in the first category are those methods that employ approximate inference, typically through the use of linear timeshift-reduce parsing algorithms (yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>nivre and nilsson, 2005).<papid> P05-1013 </papid></nextsent>
<nextsent>in the second category are those that employ exhaustive inference algorithms, usually by making strong independence assumptions, as is the case for edge-factored models (paskin, 2001; mcdonald et al, 2005<papid> P05-1012 </papid>a; mcdonald et al, 2005<papid> P05-1012 </papid>b).recently there have also been proposals for exhaustive methods that weaken the edge-factored assumption, including both approximate methods (mcdonald and pereira, 2006) <papid> E06-1011 </papid>and exact methods through integer linear programming (riedel and clarke, 2006) <papid> W06-1616 </papid>or branch-and-bound algorithms (hirakawa, 2006).<papid> P06-2047 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4593">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a consequence of these results is that it is unlikely that exact non-projective dependency parsing is tractable for any model assumptions weaker than those made by the edge-factored models.
</prevsent>
<prevsent>1.1 related work.
</prevsent>
</prevsection>
<citsent citstr=" P05-1013 ">
there has been extensive work on data-driven dependency parsing for both projective parsing (eis ner, 1996; <papid> C96-1058 </papid>paskin, 2001; yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>mcdonald et al, 2005<papid> P05-1012 </papid>a) and non-projective parsing systems (nivreand nilsson, 2005; <papid> P05-1013 </papid>hall and novak, 2005; mcdonald et al, 2005<papid> P05-1012 </papid>b).</citsent>
<aftsection>
<nextsent>these approaches can often be classified into two broad categories.
</nextsent>
<nextsent>in the first category are those methods that employ approximate inference, typically through the use of linear timeshift-reduce parsing algorithms (yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>nivre and nilsson, 2005).<papid> P05-1013 </papid></nextsent>
<nextsent>in the second category are those that employ exhaustive inference algorithms, usually by making strong independence assumptions, as is the case for edge-factored models (paskin, 2001; mcdonald et al, 2005<papid> P05-1012 </papid>a; mcdonald et al, 2005<papid> P05-1012 </papid>b).recently there have also been proposals for exhaustive methods that weaken the edge-factored assumption, including both approximate methods (mcdonald and pereira, 2006) <papid> E06-1011 </papid>and exact methods through integer linear programming (riedel and clarke, 2006) <papid> W06-1616 </papid>or branch-and-bound algorithms (hirakawa, 2006).<papid> P06-2047 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4628">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these approaches can often be classified into two broad categories.
</prevsent>
<prevsent>in the first category are those methods that employ approximate inference, typically through the use of linear timeshift-reduce parsing algorithms (yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>nivre and nilsson, 2005).<papid> P05-1013 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-1616 ">
in the second category are those that employ exhaustive inference algorithms, usually by making strong independence assumptions, as is the case for edge-factored models (paskin, 2001; mcdonald et al, 2005<papid> P05-1012 </papid>a; mcdonald et al, 2005<papid> P05-1012 </papid>b).recently there have also been proposals for exhaustive methods that weaken the edge-factored assumption, including both approximate methods (mcdonald and pereira, 2006) <papid> E06-1011 </papid>and exact methods through integer linear programming (riedel and clarke, 2006) <papid> W06-1616 </papid>or branch-and-bound algorithms (hirakawa, 2006).<papid> P06-2047 </papid></citsent>
<aftsection>
<nextsent>for grammar based models there has been limited work on empirical systems for non-projective parsing systems, notable exceptions include the work of wang and harper (2004).<papid> W04-0307 </papid></nextsent>
<nextsent>theoretical studies of note include the work of neuhaus and boker (1997)<papid> P97-1043 </papid>showing that the recognition problem for mini 122 mal dependency grammar is hard.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4629">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these approaches can often be classified into two broad categories.
</prevsent>
<prevsent>in the first category are those methods that employ approximate inference, typically through the use of linear timeshift-reduce parsing algorithms (yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>nivre and nilsson, 2005).<papid> P05-1013 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-2047 ">
in the second category are those that employ exhaustive inference algorithms, usually by making strong independence assumptions, as is the case for edge-factored models (paskin, 2001; mcdonald et al, 2005<papid> P05-1012 </papid>a; mcdonald et al, 2005<papid> P05-1012 </papid>b).recently there have also been proposals for exhaustive methods that weaken the edge-factored assumption, including both approximate methods (mcdonald and pereira, 2006) <papid> E06-1011 </papid>and exact methods through integer linear programming (riedel and clarke, 2006) <papid> W06-1616 </papid>or branch-and-bound algorithms (hirakawa, 2006).<papid> P06-2047 </papid></citsent>
<aftsection>
<nextsent>for grammar based models there has been limited work on empirical systems for non-projective parsing systems, notable exceptions include the work of wang and harper (2004).<papid> W04-0307 </papid></nextsent>
<nextsent>theoretical studies of note include the work of neuhaus and boker (1997)<papid> P97-1043 </papid>showing that the recognition problem for mini 122 mal dependency grammar is hard.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4630">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the first category are those methods that employ approximate inference, typically through the use of linear timeshift-reduce parsing algorithms (yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>nivre and nilsson, 2005).<papid> P05-1013 </papid></prevsent>
<prevsent>in the second category are those that employ exhaustive inference algorithms, usually by making strong independence assumptions, as is the case for edge-factored models (paskin, 2001; mcdonald et al, 2005<papid> P05-1012 </papid>a; mcdonald et al, 2005<papid> P05-1012 </papid>b).recently there have also been proposals for exhaustive methods that weaken the edge-factored assumption, including both approximate methods (mcdonald and pereira, 2006) <papid> E06-1011 </papid>and exact methods through integer linear programming (riedel and clarke, 2006) <papid> W06-1616 </papid>or branch-and-bound algorithms (hirakawa, 2006).<papid> P06-2047 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-0307 ">
for grammar based models there has been limited work on empirical systems for non-projective parsing systems, notable exceptions include the work of wang and harper (2004).<papid> W04-0307 </papid></citsent>
<aftsection>
<nextsent>theoretical studies of note include the work of neuhaus and boker (1997)<papid> P97-1043 </papid>showing that the recognition problem for mini 122 mal dependency grammar is hard.</nextsent>
<nextsent>in addition, the work of kahane et al (1998) <papid> P98-1106 </papid>provides polynomialparsing algorithm for constrained class of non projective structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4631">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the second category are those that employ exhaustive inference algorithms, usually by making strong independence assumptions, as is the case for edge-factored models (paskin, 2001; mcdonald et al, 2005<papid> P05-1012 </papid>a; mcdonald et al, 2005<papid> P05-1012 </papid>b).recently there have also been proposals for exhaustive methods that weaken the edge-factored assumption, including both approximate methods (mcdonald and pereira, 2006) <papid> E06-1011 </papid>and exact methods through integer linear programming (riedel and clarke, 2006) <papid> W06-1616 </papid>or branch-and-bound algorithms (hirakawa, 2006).<papid> P06-2047 </papid></prevsent>
<prevsent>for grammar based models there has been limited work on empirical systems for non-projective parsing systems, notable exceptions include the work of wang and harper (2004).<papid> W04-0307 </papid></prevsent>
</prevsection>
<citsent citstr=" P97-1043 ">
theoretical studies of note include the work of neuhaus and boker (1997)<papid> P97-1043 </papid>showing that the recognition problem for mini 122 mal dependency grammar is hard.</citsent>
<aftsection>
<nextsent>in addition, the work of kahane et al (1998) <papid> P98-1106 </papid>provides polynomialparsing algorithm for constrained class of non projective structures.</nextsent>
<nextsent>non-projective dependency parsing can be related to certain parsing problems defined for phrase structure representations, as for instance immediate dominance cfg parsing (barton et al, 1987) and shake-and-bake translation (brew, 1992).<papid> C92-2092 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4632">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for grammar based models there has been limited work on empirical systems for non-projective parsing systems, notable exceptions include the work of wang and harper (2004).<papid> W04-0307 </papid></prevsent>
<prevsent>theoretical studies of note include the work of neuhaus and boker (1997)<papid> P97-1043 </papid>showing that the recognition problem for mini 122 mal dependency grammar is hard.</prevsent>
</prevsection>
<citsent citstr=" P98-1106 ">
in addition, the work of kahane et al (1998) <papid> P98-1106 </papid>provides polynomialparsing algorithm for constrained class of non projective structures.</citsent>
<aftsection>
<nextsent>non-projective dependency parsing can be related to certain parsing problems defined for phrase structure representations, as for instance immediate dominance cfg parsing (barton et al, 1987) and shake-and-bake translation (brew, 1992).<papid> C92-2092 </papid></nextsent>
<nextsent>independently of this work, koo et al (2007) <papid> D07-1015 </papid>and smith and smith (2007) <papid> D07-1014 </papid>showed that the matrix tree theorem can be used to train edge-factoredlog-linear models of dependency parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4633">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>theoretical studies of note include the work of neuhaus and boker (1997)<papid> P97-1043 </papid>showing that the recognition problem for mini 122 mal dependency grammar is hard.</prevsent>
<prevsent>in addition, the work of kahane et al (1998) <papid> P98-1106 </papid>provides polynomialparsing algorithm for constrained class of non projective structures.</prevsent>
</prevsection>
<citsent citstr=" C92-2092 ">
non-projective dependency parsing can be related to certain parsing problems defined for phrase structure representations, as for instance immediate dominance cfg parsing (barton et al, 1987) and shake-and-bake translation (brew, 1992).<papid> C92-2092 </papid></citsent>
<aftsection>
<nextsent>independently of this work, koo et al (2007) <papid> D07-1015 </papid>and smith and smith (2007) <papid> D07-1014 </papid>showed that the matrix tree theorem can be used to train edge-factoredlog-linear models of dependency parsing.</nextsent>
<nextsent>both studies constructed implementations that compare favorably with the state-of-the-art.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4634">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, the work of kahane et al (1998) <papid> P98-1106 </papid>provides polynomialparsing algorithm for constrained class of non projective structures.</prevsent>
<prevsent>non-projective dependency parsing can be related to certain parsing problems defined for phrase structure representations, as for instance immediate dominance cfg parsing (barton et al, 1987) and shake-and-bake translation (brew, 1992).<papid> C92-2092 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1015 ">
independently of this work, koo et al (2007) <papid> D07-1015 </papid>and smith and smith (2007) <papid> D07-1014 </papid>showed that the matrix tree theorem can be used to train edge-factoredlog-linear models of dependency parsing.</citsent>
<aftsection>
<nextsent>both studies constructed implementations that compare favorably with the state-of-the-art.
</nextsent>
<nextsent>the work of meila?
</nextsent>
<nextsent>and jaakkola (2000) is also of note.
</nextsent>
<nextsent>in that study they use the matrix tree theorem to develop tractable bayesian learning algorithms for tree belief networks, which in many ways are closely related to probabilistic dependency parsing formalisms and the problems we address here.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4636">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in addition, the work of kahane et al (1998) <papid> P98-1106 </papid>provides polynomialparsing algorithm for constrained class of non projective structures.</prevsent>
<prevsent>non-projective dependency parsing can be related to certain parsing problems defined for phrase structure representations, as for instance immediate dominance cfg parsing (barton et al, 1987) and shake-and-bake translation (brew, 1992).<papid> C92-2092 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1014 ">
independently of this work, koo et al (2007) <papid> D07-1015 </papid>and smith and smith (2007) <papid> D07-1014 </papid>showed that the matrix tree theorem can be used to train edge-factoredlog-linear models of dependency parsing.</citsent>
<aftsection>
<nextsent>both studies constructed implementations that compare favorably with the state-of-the-art.
</nextsent>
<nextsent>the work of meila?
</nextsent>
<nextsent>and jaakkola (2000) is also of note.
</nextsent>
<nextsent>in that study they use the matrix tree theorem to develop tractable bayesian learning algorithms for tree belief networks, which in many ways are closely related to probabilistic dependency parsing formalisms and the problems we address here.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4712">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 inference based learning.
</prevsent>
<prevsent>many learning paradigms can be defined asinference-based learning.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
these include the perceptron (collins, 2002) <papid> W02-1001 </papid>and its large-margin variants (crammer and singer, 2003; mcdonald et al, 2005<papid> P05-1012 </papid>a).</citsent>
<aftsection>
<nextsent>in these settings, models parameters are iteratively updated based on the argmax calculation for single or set of training instances under the current parameter settings.
</nextsent>
<nextsent>the work of mcdonald et al (2005<papid> P05-1012 </papid>b) showed that it is possible to learn highly accurate non-projective dependency parser for multiple languages using the chu-liu-edmonds algorithm for unlabeled parsing.</nextsent>
<nextsent>4.2 non-projective min-risk decoding.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4743">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>in the supervised setting this model can be trained with maximum likelihood estimation, which amounts to simple counts over the data.
</prevsent>
<prevsent>learning in the unsupervised setting requires em and is discussed in section 4.4.2.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
another generative dependency model of interest is that given by klein and manning (2004).<papid> P04-1061 </papid></citsent>
<aftsection>
<nextsent>in this model the sentence and tree are generated jointly, which allows one to drop the assumption that p(t |n) is uniform.
</nextsent>
<nextsent>this requires the addition to the modelof parameters px,stop for each ? ?, with the normalization condition px,stop + ? y,k k x,y = 1.
</nextsent>
<nextsent>it is possible to extend the model of klein and manning 127(2004) to the non-projective case.
</nextsent>
<nextsent>however, there sulting distribution will be over multi sets of words from the alphabet instead of strings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4750">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> beyond edge-factored models.  </section>
<citcontext>
<prevsection>
<prevsent>in general, we would like to say that every dependency decision is dependent on every other edge in graph.
</prevsent>
<prevsent>however, modeling dependency parsing in such manner would be computational nightmare.instead, we would like to make markov assumption over the edges of the tree, in similar way that markov assumption can be made for sequential classification problems in order to ensure tractable learning and inference.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
klein and manning (2003) <papid> P03-1054 </papid>distinguish between two kinds of markov ization for un lexicalized cfg parsing.</citsent>
<aftsection>
<nextsent>the first is vertical markov ization, which makes the generation of non-terminal dependent on other non-terminals that have been generated at different levels in the phrase-structure tree.
</nextsent>
<nextsent>the second is horizontal markov ization, which makes the generation of non-terminal dependent on other non-terminals that have been generated at the same level in the tree.for dependency parsing there are analogous notions of vertical and horizontal markov ization forgiven edge (i, j)k. first, let us define the vertical and horizontal neighbourhoods of (i, j)k. the vertical neighbourhood includes all edges in any path fromthe root to leaf that passes through (i, j)k. the horizontal neighbourhood contains all edges (i, j?)k ? .figure 4 graphically displays the vertical and horizontal neighbourhoods for an edge in the dependency graph from figure 1.
</nextsent>
<nextsent>vertical and horizontal markov ization essentially allow the score of the graph to factor over larger scope of edges, provided those edges are in the same vertical or horizontal neighbourhood.
</nextsent>
<nextsent>a dth order factor ization is one in which the score factors only over the nearest edges in the neighbourhoods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4769">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>thus, the existence of bottom-up chart parsing algorithms for projective dependency parsing provides many advantages.
</prevsent>
<prevsent>as mentioned above, it permits simple augmentation techniques to incorporate non-local information such as arity constraints and markovization.
</prevsent>
</prevsection>
<citsent citstr=" A00-2030 ">
it also ensures the compatibility of projective parsing algorithms with many important natural language processing methods that work within bottom-up chart parsing framework, including information extraction (miller et al, 2000) <papid> A00-2030 </papid>and syntax-based machine translation (wu, 1996).<papid> P96-1021 </papid></citsent>
<aftsection>
<nextsent>the complexity results given here suggest that polynomial chart-parsing algorithms do not exist for the non-projective case.
</nextsent>
<nextsent>otherwise we should be able to augment them and move beyond edge factored models without encountering intractability ? just like the projective case.
</nextsent>
<nextsent>an interesting line of research is to investigate classes of non-projectivestructures that can be parsed with chart-parsing algorithms and how these classes relate to the languages parsable by other syntactic formalisms.
</nextsent>
<nextsent>acknowledgments thanks to ben taskar for pointing out the work of meila?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4770">
<title id=" W07-2216.xml">on the complexity of non projective data driven dependency parsing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>thus, the existence of bottom-up chart parsing algorithms for projective dependency parsing provides many advantages.
</prevsent>
<prevsent>as mentioned above, it permits simple augmentation techniques to incorporate non-local information such as arity constraints and markovization.
</prevsent>
</prevsection>
<citsent citstr=" P96-1021 ">
it also ensures the compatibility of projective parsing algorithms with many important natural language processing methods that work within bottom-up chart parsing framework, including information extraction (miller et al, 2000) <papid> A00-2030 </papid>and syntax-based machine translation (wu, 1996).<papid> P96-1021 </papid></citsent>
<aftsection>
<nextsent>the complexity results given here suggest that polynomial chart-parsing algorithms do not exist for the non-projective case.
</nextsent>
<nextsent>otherwise we should be able to augment them and move beyond edge factored models without encountering intractability ? just like the projective case.
</nextsent>
<nextsent>an interesting line of research is to investigate classes of non-projectivestructures that can be parsed with chart-parsing algorithms and how these classes relate to the languages parsable by other syntactic formalisms.
</nextsent>
<nextsent>acknowledgments thanks to ben taskar for pointing out the work of meila?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4771">
<title id=" W08-0201.xml">teaching computational linguistics to a large diverse student body courses tools and interdepartmental interaction </title>
<section> courses.  </section>
<citcontext>
<prevsection>
<prevsent>a useful strategy we have found for scoring these projects is to use standard conference reviews in computational linguistics ii.
</prevsent>
<prevsent>the final projects have led to several workshops and conference publications for the students so far, as wellas honors theses.
</prevsent>
</prevsection>
<citsent citstr=" P07-3002 ">
the topics have been quite varied (in line with our varied student body), including lexicon induction using genetic algorithms (ponvert,2007), <papid> P07-3002 </papid>alignment-and-transfer for bootstrapping taggers (moon and baldridge, 2007), lemmatization using parallel corpora (moon and erk, 2008), graphical visualization of articles using syntactic dependencies (jeff rego, cs honors thesis), and feature extraction for semantic role labeling (trevor fountain, cs honors thesis).working with corpora.</citsent>
<aftsection>
<nextsent>computational linguistics skills and techniques are tremendously valuable for linguists using corpora.
</nextsent>
<nextsent>ideally, linguist should be able to extract the relevant data, count occurrences of phenomena, and do statistical analyses.
</nextsent>
<nextsent>the intersection of these skills and needs is the core of this course, which covers corpus formats (xml, bracket formats for syntax, word/pos?
</nextsent>
<nextsent>formats for part-of-speech information), query languages and tools (regular expressions, cqp, tregex), and some statistical analysis techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4772">
<title id=" W08-0201.xml">teaching computational linguistics to a large diverse student body courses tools and interdepartmental interaction </title>
<section> courses.  </section>
<citcontext>
<prevsection>
<prevsent>but interestingly they had no problems with learning this second programming language (after python).
</prevsent>
<prevsent>this is particularly striking as most of the students had no programming experience prior to the class.
</prevsent>
</prevsection>
<citsent citstr=" W02-0109 ">
we have not yet used the natural language toolkit (loper and bird, 2002) (<papid> W02-0109 </papid>see section 3.1) in this course.</citsent>
<aftsection>
<nextsent>but as it, too, offers visualization and rapid access to meaningful results, we intend to use it in the future.
</nextsent>
<nextsent>in particular, the nltk allows very easy access to toolbox data (robinson et al, 2007), which we feel will greatly improve the utility and appeal of the course for the significant number of documentary linguistics students in the department.
</nextsent>
<nextsent>seminars.
</nextsent>
<nextsent>we also offer several seminars in our areas of interest.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4773">
<title id=" W08-0201.xml">teaching computational linguistics to a large diverse student body courses tools and interdepartmental interaction </title>
<section> courses.  </section>
<citcontext>
<prevsection>
<prevsent>many of them were highly satisfied that they could build interesting programs and experiment with their behavior so easily.
</prevsent>
<prevsent>language and computers.
</prevsent>
</prevsection>
<citsent citstr=" W05-0103 ">
we had fortunately already planned the first replacement course: language and computers, based on the course designed at the department of linguistics at the ohio state university (brew et al, 2005).<papid> W05-0103 </papid></citsent>
<aftsection>
<nextsent>this course intro 3duces computational linguistics to general audience and is ideal for students who want exposure to computational methods without having to learn to program.
</nextsent>
<nextsent>we designed and taught it jointly, and added several new aspects to the course.
</nextsent>
<nextsent>whereas osus course fulfills mathematical and logical analysis requirement, our course fulfills science requirement for liberal arts majors.
</nextsent>
<nextsent>these requirements were met by course content that requires understanding and thinking about formal methods.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4775">
<title id=" W08-0201.xml">teaching computational linguistics to a large diverse student body courses tools and interdepartmental interaction </title>
<section> teaching tools and tutorials.  </section>
<citcontext>
<prevsection>
<prevsent>as with other implementation-oriented activities in our classes, we created wiki page for xfst tutorials.3 these were adapted and expanded fromxe rox parc materials and mark gawrons examples.
</prevsent>
<prevsent>eisners hmm materials.
</prevsent>
</prevsection>
<citsent citstr=" W02-0102 ">
simply put: the spreadsheet designed by jason eisner (eisner, 2002) <papid> W02-0102 </papid>for teaching hidden markov models is fantastic.</citsent>
<aftsection>
<nextsent>we used that plus eisners hmm homework assignment for computational linguistics ii in fall 2007.
</nextsent>
<nextsent>the spreadsheet is great for interactive classroom exploration of hmmsstudents were very engaged.
</nextsent>
<nextsent>the homework allows students to implement an hmm from scratch, giving enough detail to alleviate much of the needless frustration that could occur with this task while ensuring that students need to put in significant effort and understand the concepts in order to make it work.
</nextsent>
<nextsent>it also helps that the new edition of jurafsky and martins textbook discusses eisners ice cream scenario as part of its much improved explanation of hmms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4776">
<title id=" W08-0120.xml">a frame based probabilistic framework for spoken dialog management using dialog examples </title>
<section> example-based system action genera-.  </section>
<citcontext>
<prevsection>
<prevsent>this is great advantage when system developer wants to change or refine dialog control flow.
</prevsent>
<prevsent>4.2 calculating expected utilities.
</prevsent>
</prevsection>
<citsent citstr=" N04-1006 ">
we adopted the principle of maximum expected utility to determine the optimized system actions among the hypotheses (paek and horvitz, 2004).<papid> N04-1006 </papid></citsent>
<aftsection>
<nextsent>124 * argmax ( | ) argmax ( | ) ( , ) argmax ( ) ( , ) a h a eu p h a b u h ? ?
</nextsent>
<nextsent>where ? denotes all information about the environment, u(a,h) means the utility of taking an action when the internal state of the machine is h, which consists of three sub states, (f, au, sd) : is frame state, au is users last action, and sd is dialog history.
</nextsent>
<nextsent>the utility function u(a,h) can be specific to each application.
</nextsent>
<nextsent>we defined handcrafted utility function to calculate the expected utility.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4777">
<title id=" W07-1001.xml">syntactic complexity measures for detecting mild cognitive impairment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>different measures show different patterns for our dataset, indicating that using multiple, complementary measures is important for such an application.
</prevsent>
<prevsent>natural language processing (nlp) techniques are often applied to electronic health records and other clinical datasets.
</prevsent>
</prevsection>
<citsent citstr=" P05-1025 ">
another potential clinical use of nlp is for processing patient language samples, which can be used to assess language development(sagae et al, 2005) <papid> P05-1025 </papid>or the impact of neurodegenerative impairments on speech and language (roark etal., 2007).</citsent>
<aftsection>
<nextsent>in this paper, we present methods for automatically measuring syntactic complexity of spoken language samples elicited during neuro psycho logical exams of elderly subjects, and examine the utility of these measures for discriminating between clinically defined groups.mild cognitive impairment (mci), and in particular amnestic mci, the earliest clinically defined stage of alzheimers-related dementia, often goes undiagnosed due to the inadequacy of common screening tests such as the mini-mental state examination (mmse) for reliably detecting relatively subtle impairments.
</nextsent>
<nextsent>linguistic memory tests,such as word list and narrative recall, are more effective than the mmse in detecting mci, yet are still individually insufficient for adequate discrimination between healthy and impaired subjects.
</nextsent>
<nextsent>be cause of this, battery of examinations is typically used to improve psychometric classification.
</nextsent>
<nextsent>yet the summary recall scores derived from these linguistic memory tests (total correctly recalled) ignore potentially useful information in the characteristics of the spoken language itself.narrative retellings provide natural, conversational speech sample that can be analyzed for many of the characteristics of speech and language that have been shown to discriminate between healthy and impaired subjects, including syntactic complexity (kemper et al, 1993; lyons et al, 1994) and mean pause duration (singh et al, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4778">
<title id=" W07-1001.xml">syntactic complexity measures for detecting mild cognitive impairment </title>
<section> syntactic annotation.  </section>
<citcontext>
<prevsection>
<prevsent>this is followed by section describing range of complexity measures to be derived from these annotations.
</prevsent>
<prevsent>finally, we present empirical results on the samples of spoken narrative retellings.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
for manual syntactic annotation of collected data(see section 4), we followed the syntactic annotation conventions of the well-known penn treebank(marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>this provides several key benefits.
</nextsent>
<nextsent>first, there is an extensive annotation guide that has been developed, not just for written but also for spoken language, so that consistent annotation was facilitated.
</nextsent>
<nextsent>second, the large out-of-domaincorpora, in particular the 1 million words of syntactically annotated switchboard telephone conversations, provide good starting point for training domain adapted parsing models.
</nextsent>
<nextsent>finally, we can use multiple domains for evaluating the correlations between various syntactic complexity measures.there are characteristics of penn treebank annotation that can impact syntactic complexity scoring.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4780">
<title id=" W07-1001.xml">syntactic complexity measures for detecting mild cognitive impairment </title>
<section> syntactic complexity.  </section>
<citcontext>
<prevsection>
<prevsent>thus, the yn gve score for these two words is 1.
</prevsent>
<prevsent>when the next word a? is reached, however, there are two categories on the stack: pp and nn, so this word receives an yngve score of 2.
</prevsent>
</prevsection>
<citsent citstr=" C92-1032 ">
stack size has been related by some (resnik, 1992) <papid> C92-1032 </papid>to working memory demands, although it most directly measures deviation from right-branching trees.</citsent>
<aftsection>
<nextsent>to calculate the size of the stack at each word, we can use the following simple algorithm.
</nextsent>
<nextsent>at each node in the tree, label the branches from that node to each of its children, beginning with zero at the rightmost child and continuing to the left most child, incrementing the score by one for each child.
</nextsent>
<nextsent>hence,each rightmost branch in the tree of figure 1 is labeled with 0, the left most branch in all binary nodes is labeled with 1, and the left most branch in the ternary node is labeled with 2.
</nextsent>
<nextsent>then the score for each word is the sum of the branch scores from the root of the tree to the word.given the score for each word, we can then derive an overall complexity score by summing them or taking the maximum or mean.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4781">
<title id=" W07-1001.xml">syntactic complexity measures for detecting mild cognitive impairment </title>
<section> syntactic complexity.  </section>
<citcontext>
<prevsection>
<prevsent>sequences of sentence nodes, i.e. an sbar appearing directly under an node, were only counted as single sentence node and thus only contributed to the score once.
</prevsent>
<prevsent>3 she was cook in school cafeteria 1 figure 3: dependency graph for the example string.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
tributed to magerman (1995), <papid> P95-1037 </papid>to percolate lexical heads up the tree.</citsent>
<aftsection>
<nextsent>figure 3 shows the dependency graph that results from this head percolation approach, where each link in the graph represents dependency relation from the modifier to the head.
</nextsent>
<nextsent>for example, conventional head percolation rules specify the vp as the head of the s, so was?, as the headof the vp, is thus the lexical head of the entire sentence.
</nextsent>
<nextsent>the lexical heads of the other children of the node are called modifiers of the head of the node; thus, since she?
</nextsent>
<nextsent>is the head of the subject np, there is dependency relation between she?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4782">
<title id=" W07-1001.xml">syntactic complexity measures for detecting mild cognitive impairment </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>algorithms for automatically extracting syntactic complexity markers from parse trees were written to accept either man system lr lp f-measure out-of-domain (wsj) 77.7 80.1 78.9 out-of-domain (swbd) 84.0 86.2 85.1 domain adapted from swbd 87.9 88.3 88.1table 2: parser accuracy on wechsler logical memory responses using just out-of-domain data (either from the wall st. journal (wsj) or switchboard (swbd) treebanks) versus using domain adapted system.ually annotated trees or trees output from an automatic parser, to demonstrate the plausibility of using automatically generated parse trees.
</prevsent>
<prevsent>4.3 parsing.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
for automatic parsing, we made use of the well known charniak parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>following best practices (charniak and johnson, 2001), <papid> N01-1016 </papid>we removed sequences covered by edited nodes in thetree from the strings prior to parsing.</nextsent>
<nextsent>for this paper, edited nodes were identified from the manual parse, not automatically.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4783">
<title id=" W07-1001.xml">syntactic complexity measures for detecting mild cognitive impairment </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>4.3 parsing.
</prevsent>
<prevsent>for automatic parsing, we made use of the well known charniak parser (charniak, 2000).<papid> A00-2018 </papid></prevsent>
</prevsection>
<citsent citstr=" N01-1016 ">
following best practices (charniak and johnson, 2001), <papid> N01-1016 </papid>we removed sequences covered by edited nodes in thetree from the strings prior to parsing.</citsent>
<aftsection>
<nextsent>for this paper, edited nodes were identified from the manual parse, not automatically.
</nextsent>
<nextsent>table 2 shows parsing accuracy of our annotated retellings under three parsing model training conditions: 1) trained on approximately 1 million words of wall st. journal (wsj) text; 2) trained on approximately 1 million wordsof switchboard (swbd) corpus telephone conver sations; and 3) using domain adaptation techniques starting from the swbd treebank.
</nextsent>
<nextsent>the swbd outof-domain system reaches quite respectable accuracies, and domain adaptation achieves 3 percent absolute improvement over that.for domain adaptation, we used map adaptation techniques (bacchiani et al, 2006) via cross validation over the entire set of retellings.
</nextsent>
<nextsent>for each subject, we trained model using the swbd treebank as the out-of-domain treebank, and theretellings of the other 46 subjects as in-domain training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4785">
<title id=" W07-2106.xml">uofl word sense disambiguation using lexical cohesion </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, an understanding of the reference of pronoun (i.e.: he, she, it, etc.) requires to look back to something that has been said before.
</prevsent>
<prevsent>through this cohesion relation, two text clauses are linked together.
</prevsent>
</prevsection>
<citsent citstr=" W97-0703 ">
cohesion is achieved through the use in the text of semantically related terms, reference, ellipse and conjunctions (barzilay and elhadad, 1997).<papid> W97-0703 </papid></citsent>
<aftsection>
<nextsent>among the different cohesion-building devices, the most easily identifiable and the most frequent type is lexical cohesion.
</nextsent>
<nextsent>lexical cohesion is created by using semantically related words (repetitions, synonyms, hypernyms, hyponyms, meronyms and holonyms, glosses, etc.) our technique used wordnet (miller, 1990) as the knowledge source to find the semantic relations among the words in text.
</nextsent>
<nextsent>we assign weights to the semantic relations.
</nextsent>
<nextsent>the technique can be decomposed into two steps: (1) building representation of all possible senses of the words and (2) dis ambiguating the words based on the highest score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4787">
<title id=" W07-2106.xml">uofl word sense disambiguation using lexical cohesion </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>lexical chaining is the process of connecting semantically related words, creating set of chains that represent different threads of cohesion through the text (galley and mckeown, 2003).
</prevsent>
<prevsent>this intermediate representation of text has been used in many natural language processing applications, including automatic summarization (barzilay and elhadad, 1997; <papid> W97-0703 </papid>silber and mccoy, 2003), information retrieval (al-halimi and kazman, 1998), and intelligent spell checking (hirst and st-onge, 1998).</prevsent>
</prevsection>
<citsent citstr=" J91-1002 ">
morris and hirst (1991) <papid> J91-1002 </papid>at first proposed manual method for computing lexical chains and first computational model of lexical chains was introduced by hirst and st-onge (1997).</citsent>
<aftsection>
<nextsent>this linear time algorithm, however, suffers from inaccurate wsd, since their greedy strategy immediately dis ambiguates word as it is first encountered.
</nextsent>
<nextsent>later 476 research (barzilay and elhadad, 1997) <papid> W97-0703 </papid>significantly alleviated this problem at the cost of worse running time (quadratic); computational inefficiency is due to their processing of many possible combinations of word senses in the text in order to decide which assignment is the most likely.</nextsent>
<nextsent>silber and mccoy (2003) presented an efficient linear-time algorithm to compute lexical chains, which models barzilays approach, but nonetheless has inaccuracies in wsd.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4790">
<title id=" W07-2074.xml">ubcalm combining knn with svd for wsd </title>
<section> feature set.  </section>
<citcontext>
<prevsection>
<prevsent>the following relations were used: object, subject, noun-modifier, preposition, and sibling.
</prevsent>
<prevsent>bag-of-words features: we extract the lemmas of the content words in the whole context, and in 4-word window around the target.
</prevsent>
</prevsection>
<citsent citstr=" N01-1011 ">
we also obtain salient bigrams in the context, with the methods and the software described in (pedersen, 2001).<papid> N01-1011 </papid>domain features: the wordnet domains resource was used to identify the most relevant domains in the context.</citsent>
<aftsection>
<nextsent>following the relevance formula presented in (magnini and cavaglia?, 2000), we defined 2 feature types: (1) the most relevant do main, and (2) list of domains above predefined threshold3 . 1the pos tagging was performed with the fntbl toolkit (ngai and florian, 2001).<papid> N01-1006 </papid></nextsent>
<nextsent>2this software was kindly provided by david yarowskys group, from johns hopkins university.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4791">
<title id=" W07-2074.xml">ubcalm combining knn with svd for wsd </title>
<section> feature set.  </section>
<citcontext>
<prevsection>
<prevsent>bag-of-words features: we extract the lemmas of the content words in the whole context, and in 4-word window around the target.
</prevsent>
<prevsent>we also obtain salient bigrams in the context, with the methods and the software described in (pedersen, 2001).<papid> N01-1011 </papid>domain features: the wordnet domains resource was used to identify the most relevant domains in the context.</prevsent>
</prevsection>
<citsent citstr=" N01-1006 ">
following the relevance formula presented in (magnini and cavaglia?, 2000), we defined 2 feature types: (1) the most relevant do main, and (2) list of domains above predefined threshold3 . 1the pos tagging was performed with the fntbl toolkit (ngai and florian, 2001).<papid> N01-1006 </papid></citsent>
<aftsection>
<nextsent>2this software was kindly provided by david yarowskys group, from johns hopkins university.
</nextsent>
<nextsent>3the software to obtain the relevant domains was kindly provided by gerard escuderos group, from universitat politec 342 2.2 svd features.
</nextsent>
<nextsent>singular value decomposition (svd) is an interesting solution to the sparse data problem.
</nextsent>
<nextsent>this technique reduces the dimensions of the vector ial space finding correlations and collapsing features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4792">
<title id=" W07-2074.xml">ubcalm combining knn with svd for wsd </title>
<section> experiments on training data.  </section>
<citcontext>
<prevsection>
<prevsent>the figures show that optimizing each word the performance increases 0.7 percentage points over the best combination.
</prevsent>
<prevsent>4.2 optimization for the all-words task.
</prevsent>
</prevsection>
<citsent citstr=" H93-1061 ">
to train the classifiers for the all-words task we just used semcor (miller et al, 1993).<papid> H93-1061 </papid></citsent>
<aftsection>
<nextsent>in (agirre et al., 2006) we already tested our approach on the senseval-3 all-words task.
</nextsent>
<nextsent>the best performance for the senseval-3 all-words task was obtained with = 5 and = 200, but we decided to to perform further experiments to search for the best combination.
</nextsent>
<nextsent>we tested the performance of the combination of single k-nn training on semcor and testing both on the senseval-3 all-words data (cf.
</nextsent>
<nextsent>table 2) and on the training data from semeval-2007 lexical sample (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4793">
<title id=" W07-0804.xml">arabic cross document person name normalization </title>
<section> introduction:.  </section>
<citcontext>
<prevsection>
<prevsent>(chinchor, 1999; maynard et al, 2001; sekine, 2004; joachims, 2002).
</prevsent>
<prevsent>the ner task is challenging due to the ambiguity of natural language and to the lack of uniformity in writing styles and vocabulary used across documents (solorio, 2004).
</prevsent>
</prevsection>
<citsent citstr=" N04-1001 ">
beyond ner, considerable work has focused on the tracking and normalization of entities that could be mentioned using different names (e.g. george bush, bush) or nominals (e.g. the president, mr., the son) (florian et al, 2004).<papid> N04-1001 </papid></citsent>
<aftsection>
<nextsent>most of the named entity tracking work has focused on intra-document normalization with very limited work on cross-documents normalization.
</nextsent>
<nextsent>recognizing and tracking entities of type person name?
</nextsent>
<nextsent>are particularly important for information extraction.
</nextsent>
<nextsent>yet they pose interesting challenges that require special attention.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4795">
<title id=" W07-0804.xml">arabic cross document person name normalization </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>they used large number of features to accomplish their work, depending mostly on language specific dictionaries and wordnet.
</prevsent>
<prevsent>some these resources are not available for arabic and many other languages.
</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
mann and yarowsky (mann and yarowsky, 2003) <papid> W03-0405 </papid>examined the same problem but they treated it as clustering task.</citsent>
<aftsection>
<nextsent>they focused on information extraction to build biographical profiles (date of birth, place of birth, etc.), and they wanted to disambiguate biographies belonging to different authors with identical names.
</nextsent>
<nextsent>dozier and zielund (dozier and zielund, 2004) reported on cross-document person name normalization in the legal domain.
</nextsent>
<nextsent>they used figure 1 normalization model e1 e3 e7 e5 e2 e4 e6 e8 normalization e1 e4 e8 e2 e3 e7 e5 e6 26 finite state machine that identifies paragraphs in document containing the names of attorneys, judges, or experts and semantic parser that extracts from the paragraphs template information about each named individual.
</nextsent>
<nextsent>they relied on reliable biographies for each individual.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4796">
<title id=" W07-0804.xml">arabic cross document person name normalization </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>however, implicit links can be useful when looking at completely unstructured text.
</prevsent>
<prevsent>other work has extended beyond entities of type person name?
</prevsent>
</prevsection>
<citsent citstr=" C02-1127 ">
to include the normalization of location names (li et al, 2002) <papid> C02-1127 </papid>and organizations (ji and grishman.</citsent>
<aftsection>
<nextsent>2004).
</nextsent>
<nextsent>for this work, set of 7,184 person name entities was constructed.
</nextsent>
<nextsent>building new training and test sets is warranted, because the task at hand is sufficiently different from previously reported tasks in the literature.
</nextsent>
<nextsent>the entities were recognized from 2,931 topically related documents (relating to the situation in the gaza and lebanon during july of 2006) from different arabic news sources (obtained from searching the arabic version of news.google.com).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4798">
<title id=" W07-0804.xml">arabic cross document person name normalization </title>
<section> preprocessing  and the dataset.  </section>
<citcontext>
<prevsection>
<prevsent>such entities are errant because they over normalize name mentions.
</prevsent>
<prevsent>persons are referred to using limited number of name mentions.
</prevsent>
</prevsection>
<citsent citstr=" P03-1051 ">
context sensitive arabic stemmer (lee et al 2003) <papid> P03-1051 </papid>to overcome the morphological complexity of arabic.</citsent>
<aftsection>
<nextsent>for example, jkl??
</nextsent>
<nextsent>= president?, ? ojklq ? = the president?, ? ojklq ? = and the president?, ? skltu ? = its presidents?
</nextsent>
<nextsent>etc are stemmed to jkl??
</nextsent>
<nextsent>= president?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4799">
<title id=" W07-1220.xml">the corpus and the lexicon standardising deep lexical acquisition evaluation </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>this paper is concerned with the standardisation of evaluation metrics for lexical acquisition over precision grammars, which are attuned to actual parser performance.
</prevsent>
<prevsent>specifically, we investigate the impact that lexicons at varying levels of lexical item precision and recall have on the performance of pre-existing broad-coverage precision grammars in parsing, i.e., on their coverage and accuracy.
</prevsent>
</prevsection>
<citsent citstr=" W02-1210 ">
the grammars used for the experiments reported here are the lingo english resource grammar (erg; flickinger (2000)) and jacy (siegel and bender, 2002), <papid> W02-1210 </papid>precision grammars of english and japanese, respectively.</citsent>
<aftsection>
<nextsent>our results show convincingly that traditional score-based evaluation of lexical acquisition does not correlate with actual parsing performance.
</nextsent>
<nextsent>what we argue for, therefore, is arecall-heavy interpretation of f-score in designing and optimising automated lexical acquisition algorithms.
</nextsent>
<nextsent>deep processing is the process of applying rich linguistic resources within nlp tasks, to arrive at detailed (=deep) syntactic and semantic analysis ofthe data.
</nextsent>
<nextsent>it is conventionally driven by deep grammars, which encode linguistically-motivated predictions of language behaviour, are usually capable ofboth parsing and generation, and generate high level semantic abstraction of the input data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4800">
<title id=" W07-1220.xml">the corpus and the lexicon standardising deep lexical acquisition evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as noted in previous work (baldwin et al, 2004), significant causeof diminished coverage is the lack of lexical cover age.
</prevsent>
<prevsent>various attempts have been made to ameliorate the deficiencies of hand-crafted lexicons.
</prevsent>
</prevsection>
<citsent citstr=" W05-1008 ">
more recently, there has been an explosion of interest in deep lexical acquisition (dla; (baldwin, 2005; <papid> W05-1008 </papid>zhang and kordoni, 2006; van de cruys, 2006))for broad-coverage deep grammars, either by exploiting the linguistic information encoded in the grammar itself (in vivo), or by using secondary language resources (in vitro).</citsent>
<aftsection>
<nextsent>such approaches provide (semi-)automatic ways of extending the lexicon with minimal (or no) human interference.
</nextsent>
<nextsent>one stumbling block in dla research has been the lack of standardisation in evaluation, with commonly-used evaluation metrics including:?
</nextsent>
<nextsent>type precision: the proportion of correctly hy pothesised lexical entries ? type recall: the proportion of gold-standard lexical entries that are correctly hypothesised ? type f-measure: the harmonic mean of the type precision and type recall?
</nextsent>
<nextsent>token accuracy: the accuracy of the lexical entries evaluated against their token occurrences in gold-standard corpus data it is often the case that the different measures lead to significantly different assessments of the quality of dla, even forgiven dla approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4802">
<title id=" W07-1220.xml">the corpus and the lexicon standardising deep lexical acquisition evaluation </title>
<section> lexical acquisition in deep parsing.  </section>
<citcontext>
<prevsection>
<prevsent>a static, manually compiled lexicon, therefore, becomes inevitably insufficient when faced with open domain text.in recent years, some approaches have been developed to (semi-)automatically detect and/or repair the lexical errors in linguistic grammars.
</prevsent>
<prevsent>such approaches can be broadly categorised as either symbolic or statistical.
</prevsent>
</prevsection>
<citsent citstr=" P98-1014 ">
erbach (1990), barg and walther (1998) <papid> P98-1014 </papid>andfouvry (2003) <papid> E03-1041 </papid>followed unification-based symbolic approach to unknown wordprocessing for constraint-based grammars.</citsent>
<aftsection>
<nextsent>the basic idea is to use underspecified lexical entries, namely entries with fewer constraints, to parse whole sentences, and generate the real?
</nextsent>
<nextsent>lexical entries afterwards by collecting information from the full parses.
</nextsent>
<nextsent>however, lexical entries generated in this way may be either too general or too specific.
</nextsent>
<nextsent>underspecified lexical entries with fewer constraints allow more grammar rules to be applied while parsing, and fully underspecified lexical entries are computationally intractable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4803">
<title id=" W07-1220.xml">the corpus and the lexicon standardising deep lexical acquisition evaluation </title>
<section> lexical acquisition in deep parsing.  </section>
<citcontext>
<prevsection>
<prevsent>a static, manually compiled lexicon, therefore, becomes inevitably insufficient when faced with open domain text.in recent years, some approaches have been developed to (semi-)automatically detect and/or repair the lexical errors in linguistic grammars.
</prevsent>
<prevsent>such approaches can be broadly categorised as either symbolic or statistical.
</prevsent>
</prevsection>
<citsent citstr=" E03-1041 ">
erbach (1990), barg and walther (1998) <papid> P98-1014 </papid>andfouvry (2003) <papid> E03-1041 </papid>followed unification-based symbolic approach to unknown wordprocessing for constraint-based grammars.</citsent>
<aftsection>
<nextsent>the basic idea is to use underspecified lexical entries, namely entries with fewer constraints, to parse whole sentences, and generate the real?
</nextsent>
<nextsent>lexical entries afterwards by collecting information from the full parses.
</nextsent>
<nextsent>however, lexical entries generated in this way may be either too general or too specific.
</nextsent>
<nextsent>underspecified lexical entries with fewer constraints allow more grammar rules to be applied while parsing, and fully underspecified lexical entries are computationally intractable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4807">
<title id=" W07-1220.xml">the corpus and the lexicon standardising deep lexical acquisition evaluation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>it should be noted in hpsgs, the grammar is made up of two basic components: the grammarrules/type hierarchy, and the lexicon (which interfaces with the type hierarchy via leaf lexical types).
</prevsent>
<prevsent>this is different to strictly lexicalised formalisms like ltag and ccg, where essentially all linguistic description resides in individual lexical entries in the lexicon.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
the manually compiled grammars in our experiment are also intrinsically different to grammars automatically induced from treebanks (e.g. that used in the charniak parser (charniak, 2000) <papid> A00-2018 </papid>or the various ccg parsers (hockenmaier, 2006)).<papid> P06-1064 </papid></citsent>
<aftsection>
<nextsent>these differences sharply differentiate our work from previous research on the interaction between lexical acquisition and parse performance.
</nextsent>
<nextsent>furthermore, to test the grammar precision and accuracy, we use two treebanks: redwoods (oepen et al, 2002) <papid> C02-2025 </papid>for english and hinoki (bond et al, 2004) <papid> W04-1901 </papid>for japanese.</nextsent>
<nextsent>these treebanks are so-calleddynamic treebanks, meaning that they can be (semi)automatically updated when the grammar is up dated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4808">
<title id=" W07-1220.xml">the corpus and the lexicon standardising deep lexical acquisition evaluation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>it should be noted in hpsgs, the grammar is made up of two basic components: the grammarrules/type hierarchy, and the lexicon (which interfaces with the type hierarchy via leaf lexical types).
</prevsent>
<prevsent>this is different to strictly lexicalised formalisms like ltag and ccg, where essentially all linguistic description resides in individual lexical entries in the lexicon.
</prevsent>
</prevsection>
<citsent citstr=" P06-1064 ">
the manually compiled grammars in our experiment are also intrinsically different to grammars automatically induced from treebanks (e.g. that used in the charniak parser (charniak, 2000) <papid> A00-2018 </papid>or the various ccg parsers (hockenmaier, 2006)).<papid> P06-1064 </papid></citsent>
<aftsection>
<nextsent>these differences sharply differentiate our work from previous research on the interaction between lexical acquisition and parse performance.
</nextsent>
<nextsent>furthermore, to test the grammar precision and accuracy, we use two treebanks: redwoods (oepen et al, 2002) <papid> C02-2025 </papid>for english and hinoki (bond et al, 2004) <papid> W04-1901 </papid>for japanese.</nextsent>
<nextsent>these treebanks are so-calleddynamic treebanks, meaning that they can be (semi)automatically updated when the grammar is up dated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4809">
<title id=" W07-1220.xml">the corpus and the lexicon standardising deep lexical acquisition evaluation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the manually compiled grammars in our experiment are also intrinsically different to grammars automatically induced from treebanks (e.g. that used in the charniak parser (charniak, 2000) <papid> A00-2018 </papid>or the various ccg parsers (hockenmaier, 2006)).<papid> P06-1064 </papid></prevsent>
<prevsent>these differences sharply differentiate our work from previous research on the interaction between lexical acquisition and parse performance.</prevsent>
</prevsection>
<citsent citstr=" C02-2025 ">
furthermore, to test the grammar precision and accuracy, we use two treebanks: redwoods (oepen et al, 2002) <papid> C02-2025 </papid>for english and hinoki (bond et al, 2004) <papid> W04-1901 </papid>for japanese.</citsent>
<aftsection>
<nextsent>these treebanks are so-calleddynamic treebanks, meaning that they can be (semi)automatically updated when the grammar is updated.
</nextsent>
<nextsent>this feature is especially useful when wewant to evaluate the grammar performance with different lexicon configurations.
</nextsent>
<nextsent>with conventional treebanks, our experiment is difficult (if not impos sible) to perform as the static trees in the treebank cannot be easily synchronised to the evolution of the grammar, meaning that we cannot regenerate gold standard parse trees relative to given lexicon (es pecially when for reduced recall where there is no guarantee we will be able to produce all of the parses in the 100% recall gold-standard).
</nextsent>
<nextsent>as result, it is extremely difficult to faithfully update the statistical models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4810">
<title id=" W07-1220.xml">the corpus and the lexicon standardising deep lexical acquisition evaluation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the manually compiled grammars in our experiment are also intrinsically different to grammars automatically induced from treebanks (e.g. that used in the charniak parser (charniak, 2000) <papid> A00-2018 </papid>or the various ccg parsers (hockenmaier, 2006)).<papid> P06-1064 </papid></prevsent>
<prevsent>these differences sharply differentiate our work from previous research on the interaction between lexical acquisition and parse performance.</prevsent>
</prevsection>
<citsent citstr=" W04-1901 ">
furthermore, to test the grammar precision and accuracy, we use two treebanks: redwoods (oepen et al, 2002) <papid> C02-2025 </papid>for english and hinoki (bond et al, 2004) <papid> W04-1901 </papid>for japanese.</citsent>
<aftsection>
<nextsent>these treebanks are so-calleddynamic treebanks, meaning that they can be (semi)automatically updated when the grammar is updated.
</nextsent>
<nextsent>this feature is especially useful when wewant to evaluate the grammar performance with different lexicon configurations.
</nextsent>
<nextsent>with conventional treebanks, our experiment is difficult (if not impos sible) to perform as the static trees in the treebank cannot be easily synchronised to the evolution of the grammar, meaning that we cannot regenerate gold standard parse trees relative to given lexicon (es pecially when for reduced recall where there is no guarantee we will be able to produce all of the parses in the 100% recall gold-standard).
</nextsent>
<nextsent>as result, it is extremely difficult to faithfully update the statistical models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4811">
<title id=" W07-2091.xml">unt sub finder combining knowledge sources for automatic lexical substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system isable to provide the most likely set of substitutes for word in given context, by combining several techniques and knowledge sources.
</prevsent>
<prevsent>sub finder has successfully participated in the best and out of ten (oot) tracks in the semeval lexical substitution task, consistently ranking in the first or second place.
</prevsent>
</prevsection>
<citsent citstr=" W02-0816 ">
lexical substitution is defined as the task of identifying the most likely alternatives (substitutes) for target word, given its context (mccarthy, 2002).<papid> W02-0816 </papid></citsent>
<aftsection>
<nextsent>many natural language processing applications can benefit from the availability of such alternative words,including word sense disambiguation, lexical acquisition, machine translation, information retrieval, question answering, text simplification, and others.
</nextsent>
<nextsent>the task is closely related to the problem of word sense disambiguation, with the substitutes acting as synonyms for the input word meaning.
</nextsent>
<nextsent>unlike word sense disambiguation however, lexical substitution is not performed with respect to given sense inventory, but instead candidate synonyms are generate don the fly?
</nextsent>
<nextsent>forgiven word occurrence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4812">
<title id=" W07-2091.xml">unt sub finder combining knowledge sources for automatic lexical substitution </title>
<section> candidate ranking.  </section>
<citcontext>
<prevsection>
<prevsent>similar to the previous models, the target word in the context is replaced by all the generated inflections of the selected candidate and then queried using web search engine.
</prevsent>
<prevsent>the resulting rank represents the sum of the total number of pages in which the candidate or any of its inflections occur together with the context.
</prevsent>
</prevsection>
<citsent citstr=" P06-1057 ">
this also reflects the semantic relatedness or the relevance of the candidate to the context.word sense disambiguation (wsd): since previous work indicated the usefulness of word sense disambiguation systems in lexical substitution (da gan et al, 2006), <papid> P06-1057 </papid>we use the sense learner word sense disambiguation tool (mihalcea and csomai,2005) <papid> P05-3014 </papid>to disambiguate the target word and, accordingly, to propose its synonyms as candidates.</citsent>
<aftsection>
<nextsent>final system: our candidate ranking methods are aimed at different aspects of what constitutes good candidate.
</nextsent>
<nextsent>on one hand, we measure the semantic relatedness of candidate with the original context(the lsa and wsd methods fall under this cate gory).
</nextsent>
<nextsent>on the other hand, we also want to ensure that the candidate fits the context and leads to well formed english sentence (e.g., the language model method).
</nextsent>
<nextsent>given that the methods described earlier aim at orthogonal aspects of the problem, it is expected that combination of these will provide better overall ranking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4813">
<title id=" W07-2091.xml">unt sub finder combining knowledge sources for automatic lexical substitution </title>
<section> candidate ranking.  </section>
<citcontext>
<prevsection>
<prevsent>similar to the previous models, the target word in the context is replaced by all the generated inflections of the selected candidate and then queried using web search engine.
</prevsent>
<prevsent>the resulting rank represents the sum of the total number of pages in which the candidate or any of its inflections occur together with the context.
</prevsent>
</prevsection>
<citsent citstr=" P05-3014 ">
this also reflects the semantic relatedness or the relevance of the candidate to the context.word sense disambiguation (wsd): since previous work indicated the usefulness of word sense disambiguation systems in lexical substitution (da gan et al, 2006), <papid> P06-1057 </papid>we use the sense learner word sense disambiguation tool (mihalcea and csomai,2005) <papid> P05-3014 </papid>to disambiguate the target word and, accordingly, to propose its synonyms as candidates.</citsent>
<aftsection>
<nextsent>final system: our candidate ranking methods are aimed at different aspects of what constitutes good candidate.
</nextsent>
<nextsent>on one hand, we measure the semantic relatedness of candidate with the original context(the lsa and wsd methods fall under this cate gory).
</nextsent>
<nextsent>on the other hand, we also want to ensure that the candidate fits the context and leads to well formed english sentence (e.g., the language model method).
</nextsent>
<nextsent>given that the methods described earlier aim at orthogonal aspects of the problem, it is expected that combination of these will provide better overall ranking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4814">
<title id=" W07-2091.xml">unt sub finder combining knowledge sources for automatic lexical substitution </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>a mode?
</prevsent>
<prevsent>evaluation is also conducted, which measures the ability of the systems to capture the most frequent response (the mode?)
</prevsent>
</prevsection>
<citsent citstr=" W07-2009 ">
from the gold standard annotations.for details, please refer to the official task description document (mccarthy and navigli, 2007).<papid> W07-2009 </papid>tables 2 and 3 show the results obtained by sub finder in the best and oot tracks respectively.</citsent>
<aftsection>
<nextsent>the tables also show breakdown of the results based 412 on: only target words that were not identified as multi words (nmwt); only substitutes that were not identified as multi words (nmws); only items with sentences randomly selected from the internet corpus (rand); only items with sentences manually selected from the internet corpus (man).
</nextsent>
<nextsent>wsd lsa ir lb mcs mta mtg lm best 34 2 64 63 56 69 38 97 oot 6 82 7 28 46 14 32 68 table 1: weights of the individual ranking methods r mode mode overall 12.77 12.77 20.73 20.73 further analysis nmwt 13.46 13.46 21.63 21.63 nmws 13.79 13.79 21.59 21.59 rand 12.85 12.85 20.18 20.18 man 12.69 12.69 21.35 21.35 baselines wordnet 9.95 9.95 15.28 15.28 lin 8.84 8.53 14.69 14.23 table 2: best results r mode mode overall 49.19 49.19 66.26 66.26 further analysis nmwt 51.13 51.13 68.03 68.03 nmws 54.01 54.01 70.15 70.15 rand 51.71 51.71 68.04 68.04 man 46.26 46.26 64.24 64.24 baselines wordnet 29.70 29.35 40.57 40.57 lin 27.70 26.72 40.47 39.19 table 3: oot results compared to other systems participating in this task, our system consistently ranks on the first or second place.
</nextsent>
<nextsent>sub finder clearly outperforms allthe other systems for the mode?
</nextsent>
<nextsent>evaluation, showing the ability of the system to find the substitute most often preferred by the human annotators.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4815">
<title id=" W07-2105.xml">uvavu wordnet similarity and lexical patterns for semantic relation classification </title>
<section> submitted run.  </section>
<citcontext>
<prevsection>
<prevsent>for each relation method performing beston the training set was selected (using 5-fold cross validation).
</prevsent>
<prevsent>2.2 learnt lexical patterns.
</prevsent>
</prevsection>
<citsent citstr=" P06-1040 ">
this classifier models the intuition that when pair of nominals is used in similar phrases as another pair they share at least one relation, and when no such phrases can be found they do not share any relation.applied to the semantic relation classification problem this means that when pair in the test set can be found in the same patterns as pairs from the training set, the classification for the pair will be true.to find the patterns we followed step 1 to 6 described in (turney, 2006), <papid> P06-1040 </papid>with the exception that we used both google and the wmts to compute pattern frequency.</citsent>
<aftsection>
<nextsent>first we extracted the pairs of nominals ,y ? from the training sentences and created one google query and set of wmts queries for each pair.
</nextsent>
<nextsent>the google queries were of the form  * or  * .
</nextsent>
<nextsent>currently, google performs morphological normalization on every query, so we did not make separate queries for various endings of the nominals.
</nextsent>
<nextsent>for the wmts we did make separate queries for various morphological variations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4820">
<title id=" W07-2067.xml">swatmpthe semeval2007 systems for task 5 and task 14 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this system uses synonym expansion and matches lemmatized unigrams inthe test headlines against corpus of hand annotated headlines.
</prevsent>
<prevsent>this paper describes our two entries in semeval 2007.
</prevsent>
</prevsection>
<citsent citstr=" W04-0862 ">
the first entry, supervised system used in the multilingual chinese-english lexical sample task (task 5), is an extension of the system described in(wicentowski et al, 2004).<papid> W04-0862 </papid></citsent>
<aftsection>
<nextsent>we implement five different classifiers: nave bayes classifier, decision list classifier, two different nearest neighbor cosineclassifiers, and classifier based on latent semantic analysis.
</nextsent>
<nextsent>section 2.2 describes each of the individual classifiers, section 2.3 describes our classifier combination system, and section 2.4 presents our results.
</nextsent>
<nextsent>the second entry, supervised system used in the affective text task (task 14), uses corpus of headlines hand-annotated by non-experts.
</nextsent>
<nextsent>it also uses an online thesaurus to match synonyms and antonyms of the sense labels (thesaurus.com, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4824">
<title id=" W07-2067.xml">swatmpthe semeval2007 systems for task 5 and task 14 </title>
<section> task 5: multilingual chinese-english ls.  </section>
<citcontext>
<prevsection>
<prevsent>to implement additive smoothing, we added very small number, ?, to the frequency count of each feature (and divided the final product by this ? value times the size of the feature set to maintain accurateprobabilities).
</prevsent>
<prevsent>this small number has almost no effect on more frequent words, but boosts the score of less common, yet potentially equally informative, words.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
2.2.2 decision list the decision list classifier uses the log-likelihood of correspondence between each context feature and each sense, using additive smoothing (yarowsky, 1994).<papid> P94-1013 </papid></citsent>
<aftsection>
<nextsent>the decision list was created by ordering the correspondences from strongest to weakest.
</nextsent>
<nextsent>instances that did not match any rule in the decision list were assigned the most frequent sense, as calculated from the training data.
</nextsent>
<nextsent>2.2.3 nearest neighbor cosine the nearest neighbor cosine classifier required the creation of term-document matrix, which contains row for each training instance of an ambiguous word, and column for each feature that can occur in the context of an ambiguous word.
</nextsent>
<nextsent>the rows of this matrix are referred to as sense vectors because each row represents combination of the features of all ambiguous words that share the same sense.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4825">
<title id=" W08-0208.xml">multidisciplinary instruction with the natural language toolkit </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>yet these approaches have almost nothing in common, and it is stretch to call either of these nlp: more apt titles for such courses might be linguistic data management?
</prevsent>
<prevsent>and text technologies.?
</prevsent>
</prevsection>
<citsent citstr=" W02-0109 ">
the natural language toolkit, or nltk, was developed to give broad range of students access to the core knowledge and skills of nlp (loper and bird, 2002).<papid> W02-0109 </papid></citsent>
<aftsection>
<nextsent>in particular, nltk makes it feasible to run course that covers substantial amount of theory and practice with an audience consisting of both linguists and computer scientists.
</nextsent>
<nextsent>nltk is suite of python modules distributed under the gpl open source license via nltk.org.
</nextsent>
<nextsent>nltk comes with large collection of corpora, extensive documentation, and hundreds of exercises, making nltk unique in providing comprehensive framework for students to develop computational understanding of language.
</nextsent>
<nextsent>nltks code base of 100,000 lines of python code includes support for corpus access, tokenizing, stemming, tagging, chunking, parsing, clustering, classification, language modeling, semantic interpretation, unification, and much else besides.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4826">
<title id=" W08-0208.xml">multidisciplinary instruction with the natural language toolkit </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(bonwell and eison, 1991).
</prevsent>
<prevsent>this paper describes the main features of nltk, and reports on how it has been used effectively in classes that involve combination of linguists and computer scientists.
</prevsent>
</prevsection>
<citsent citstr=" P04-3031 ">
first we discuss aspects of the design of the toolkit that 1(bird and loper, 2004; <papid> P04-3031 </papid>loper, 2004; bird, 2005; hearst, 2005; <papid> W05-0101 </papid>bird, 2006; <papid> P06-4018 </papid>klein, 2006; liddy and mccracken, 2005; <papid> W05-0111 </papid>madnani, 2007; madnani and dorr, 2008; baldridge and erk, 2008) 62 arose from our need to teach computational linguistics to multidisciplinary audience (2).</citsent>
<aftsection>
<nextsent>the following sections cover three distinct challenges: getting started with course (3); interactive demonstrations (4); and organizing assignments and projects (5).
</nextsent>
<nextsent>2.1 python.
</nextsent>
<nextsent>we chose python2 as the implementation language for nltk because it has shallow learning curve, its syntax and semantics are transparent, and it has good string-handling functionality.
</nextsent>
<nextsent>as an interpreted language, python facilitates interactive exploration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4827">
<title id=" W08-0208.xml">multidisciplinary instruction with the natural language toolkit </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(bonwell and eison, 1991).
</prevsent>
<prevsent>this paper describes the main features of nltk, and reports on how it has been used effectively in classes that involve combination of linguists and computer scientists.
</prevsent>
</prevsection>
<citsent citstr=" W05-0101 ">
first we discuss aspects of the design of the toolkit that 1(bird and loper, 2004; <papid> P04-3031 </papid>loper, 2004; bird, 2005; hearst, 2005; <papid> W05-0101 </papid>bird, 2006; <papid> P06-4018 </papid>klein, 2006; liddy and mccracken, 2005; <papid> W05-0111 </papid>madnani, 2007; madnani and dorr, 2008; baldridge and erk, 2008) 62 arose from our need to teach computational linguistics to multidisciplinary audience (2).</citsent>
<aftsection>
<nextsent>the following sections cover three distinct challenges: getting started with course (3); interactive demonstrations (4); and organizing assignments and projects (5).
</nextsent>
<nextsent>2.1 python.
</nextsent>
<nextsent>we chose python2 as the implementation language for nltk because it has shallow learning curve, its syntax and semantics are transparent, and it has good string-handling functionality.
</nextsent>
<nextsent>as an interpreted language, python facilitates interactive exploration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4828">
<title id=" W08-0208.xml">multidisciplinary instruction with the natural language toolkit </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(bonwell and eison, 1991).
</prevsent>
<prevsent>this paper describes the main features of nltk, and reports on how it has been used effectively in classes that involve combination of linguists and computer scientists.
</prevsent>
</prevsection>
<citsent citstr=" P06-4018 ">
first we discuss aspects of the design of the toolkit that 1(bird and loper, 2004; <papid> P04-3031 </papid>loper, 2004; bird, 2005; hearst, 2005; <papid> W05-0101 </papid>bird, 2006; <papid> P06-4018 </papid>klein, 2006; liddy and mccracken, 2005; <papid> W05-0111 </papid>madnani, 2007; madnani and dorr, 2008; baldridge and erk, 2008) 62 arose from our need to teach computational linguistics to multidisciplinary audience (2).</citsent>
<aftsection>
<nextsent>the following sections cover three distinct challenges: getting started with course (3); interactive demonstrations (4); and organizing assignments and projects (5).
</nextsent>
<nextsent>2.1 python.
</nextsent>
<nextsent>we chose python2 as the implementation language for nltk because it has shallow learning curve, its syntax and semantics are transparent, and it has good string-handling functionality.
</nextsent>
<nextsent>as an interpreted language, python facilitates interactive exploration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4829">
<title id=" W08-0208.xml">multidisciplinary instruction with the natural language toolkit </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(bonwell and eison, 1991).
</prevsent>
<prevsent>this paper describes the main features of nltk, and reports on how it has been used effectively in classes that involve combination of linguists and computer scientists.
</prevsent>
</prevsection>
<citsent citstr=" W05-0111 ">
first we discuss aspects of the design of the toolkit that 1(bird and loper, 2004; <papid> P04-3031 </papid>loper, 2004; bird, 2005; hearst, 2005; <papid> W05-0101 </papid>bird, 2006; <papid> P06-4018 </papid>klein, 2006; liddy and mccracken, 2005; <papid> W05-0111 </papid>madnani, 2007; madnani and dorr, 2008; baldridge and erk, 2008) 62 arose from our need to teach computational linguistics to multidisciplinary audience (2).</citsent>
<aftsection>
<nextsent>the following sections cover three distinct challenges: getting started with course (3); interactive demonstrations (4); and organizing assignments and projects (5).
</nextsent>
<nextsent>2.1 python.
</nextsent>
<nextsent>we chose python2 as the implementation language for nltk because it has shallow learning curve, its syntax and semantics are transparent, and it has good string-handling functionality.
</nextsent>
<nextsent>as an interpreted language, python facilitates interactive exploration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4831">
<title id=" W07-2020.xml">cityuhif wsd with human informed feature preference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in recent years, many research teams all over the world have gained rich experience on word sense disambiguation (wsd) from the shared tasks of the senseval workshops.
</prevsent>
<prevsent>the need for multiple knowledge sources has become golden rule, and the lexical sensitivity?
</prevsent>
</prevsection>
<citsent citstr=" W04-0828 ">
once remarked by resnik and yarowsky (1997) is addressed by various means in statistical classifiers, such as learning an optimal combination of the various knowledge sources for individual target words (e.g. mihalcea, 2002; escudero et al, 2004).<papid> W04-0828 </papid></citsent>
<aftsection>
<nextsent>another common practice is to use an ensemble of classifiers.
</nextsent>
<nextsent>as pointed out by mihalcea et al (2004), <papid> W04-0807 </papid>among the participating systems in the senseval-3 english lexical sample task, several of the top performance systems are based on combination of multiple classifiers, which shows once again that voting scheme that combine several learning algorithms outperform the accuracy of individual classifiers?.</nextsent>
<nextsent>however, the advancement in wsd is rarely accompanied by any extensive account on the cognitive aspects of the task or qualitative analysis of the relation between the disambiguation results and the nature of individual target words underlying the apparent lexical sensitivity of the task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4832">
<title id=" W07-2020.xml">cityuhif wsd with human informed feature preference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>once remarked by resnik and yarowsky (1997) is addressed by various means in statistical classifiers, such as learning an optimal combination of the various knowledge sources for individual target words (e.g. mihalcea, 2002; escudero et al, 2004).<papid> W04-0828 </papid></prevsent>
<prevsent>another common practice is to use an ensemble of classifiers.</prevsent>
</prevsection>
<citsent citstr=" W04-0807 ">
as pointed out by mihalcea et al (2004), <papid> W04-0807 </papid>among the participating systems in the senseval-3 english lexical sample task, several of the top performance systems are based on combination of multiple classifiers, which shows once again that voting scheme that combine several learning algorithms outperform the accuracy of individual classifiers?.</citsent>
<aftsection>
<nextsent>however, the advancement in wsd is rarely accompanied by any extensive account on the cognitive aspects of the task or qualitative analysis of the relation between the disambiguation results and the nature of individual target words underlying the apparent lexical sensitivity of the task.
</nextsent>
<nextsent>given that humans apparently use different strategies in making sense of words, it might be beneficial to have such cognitive aspects, including the type and strength of various kinds of semantic association, realised in nlp systems explicitly.
</nextsent>
<nextsent>thus in addition to an optimal combination of classifiers alone, to better understand the contribution of different information types for different types of target words, it is important to look at wsd in relation to the very intrinsic nature of individual target words, which could comprise many factors such as frequency, abstract ness, sense relatedness and parts-of-speech (pos).
</nextsent>
<nextsent>we thus use the concept information susceptibility (kwong, 2005) to refer to the relationship between the intrinsic features of target word and its senses, and the effectiveness of various lexical information to characterise them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4833">
<title id=" W07-2020.xml">cityuhif wsd with human informed feature preference </title>
<section> intrinsic nature of target words.  </section>
<citcontext>
<prevsection>
<prevsent>one is automatic feature selection (afs), for which we used cfssubseteval (correla tion-based feature selection) as implemented in weka, based on the training samples of each target word.
</prevsent>
<prevsent>the other is human-informed feature preference (hif), for which we ran another nave bayes classifier in parallel with feature subset deemed informative by human judges to fine-tune the disambiguation results obtained from the core system (see sections 3 and 4 below).
</prevsent>
</prevsection>
<citsent citstr=" J98-1006 ">
leacock et al (1998), <papid> J98-1006 </papid>for example, observed that the benefits of adding topical to local context alone depend on syntactic category as well as on the characteristics of the individual word?.</citsent>
<aftsection>
<nextsent>in other words, some target words happen to be more topical?
</nextsent>
<nextsent>than others and might therefore be more susceptible to topical contextual features during disambiguation.
</nextsent>
<nextsent>others, however, might only be optimally disambiguated with other types of information.
</nextsent>
<nextsent>target features w0 word form of the target word p0 pos of the target word local features p-2 p-1 p+1 p+2 pos of words at fixed positions from the target word, including the first and second word on its left and the first and second word on its right w-2 w-1 w+1 w+2 word forms of the words at fixed positions from the target word, including the first and second word on its left and the first and second word on its right topical features w-10w+10 content words appearing within the window of ten words on each side of the target word syntactic features p-2 p0 p-1 p0 p0 p+1 p0 p+2 pos bigrams composed of the target word and its neighbouring words, the non-immediate p-2 p0 and p0 p+2 are included to accommodate for some flexibility p-2 p-1 p0 p0 p+1 p+2 pos trigrams composed of the target word and its neighbouring words table 1 features used in the nave bayes classifer while statistical wsd has more or less reached its ceiling, it is assumed that more thorough understanding of the effectiveness of different types of lexical information for characterising word sense and distinguishing it from others should be able to further inform and enhance the development of wsd systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4834">
<title id=" W07-2090.xml">untyahoo supersenselearner combining sense learner with super sense and other coarse semantic features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the applicability of such supervised algorithms is however limited only to those few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.instead, methods that address all words in unrestricted text have received significantly less attention.
</prevsent>
<prevsent>while the performance of such methods is usually exceeded by their supervised lexical-sample alternatives, they have however the advantage of providing larger coverage.in this paper, we describe supersenselearner ? system for solving the semantic ambiguity of all words in unrestricted text.
</prevsent>
</prevsection>
<citsent citstr=" P05-3014 ">
super sense learner brings together under one system the features previously used in the sense learner (mihalcea and csomai, 2005) <papid> P05-3014 </papid>and the super sense (ciaramita and altun, 2006) <papid> W06-1670 </papid>all-words word sense disambiguation systems.</citsent>
<aftsection>
<nextsent>the system is using relatively small pre-existing sense-annotated dataset for training purposes, and it learns global semantic models for general word categories.
</nextsent>
<nextsent>disambiguation our goal is to use as little annotated data as possible, and at the same time make the algorithm general enough to be able to disambiguate as many content words as possible in text, and efficient enough so that large amounts of text can be annotated in real time.
</nextsent>
<nextsent>supersenselearner is attempting to learn general semantic models for various word categories, starting with relatively small sense-annotated corpus.
</nextsent>
<nextsent>we base our experiment son semcor (miller et al, 1993), <papid> H93-1061 </papid>balanced, semantically annotated dataset, with all content words manually tagged by trained lexicographers.the input to the disambiguation algorithm consists of raw text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4835">
<title id=" W07-2090.xml">untyahoo supersenselearner combining sense learner with super sense and other coarse semantic features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the applicability of such supervised algorithms is however limited only to those few words for which sense tagged data is available, and their accuracy is strongly connected to the amount of labeled data available at hand.instead, methods that address all words in unrestricted text have received significantly less attention.
</prevsent>
<prevsent>while the performance of such methods is usually exceeded by their supervised lexical-sample alternatives, they have however the advantage of providing larger coverage.in this paper, we describe supersenselearner ? system for solving the semantic ambiguity of all words in unrestricted text.
</prevsent>
</prevsection>
<citsent citstr=" W06-1670 ">
super sense learner brings together under one system the features previously used in the sense learner (mihalcea and csomai, 2005) <papid> P05-3014 </papid>and the super sense (ciaramita and altun, 2006) <papid> W06-1670 </papid>all-words word sense disambiguation systems.</citsent>
<aftsection>
<nextsent>the system is using relatively small pre-existing sense-annotated dataset for training purposes, and it learns global semantic models for general word categories.
</nextsent>
<nextsent>disambiguation our goal is to use as little annotated data as possible, and at the same time make the algorithm general enough to be able to disambiguate as many content words as possible in text, and efficient enough so that large amounts of text can be annotated in real time.
</nextsent>
<nextsent>supersenselearner is attempting to learn general semantic models for various word categories, starting with relatively small sense-annotated corpus.
</nextsent>
<nextsent>we base our experiment son semcor (miller et al, 1993), <papid> H93-1061 </papid>balanced, semantically annotated dataset, with all content words manually tagged by trained lexicographers.the input to the disambiguation algorithm consists of raw text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4836">
<title id=" W07-2090.xml">untyahoo supersenselearner combining sense learner with super sense and other coarse semantic features </title>
<section> learning for all-words word sense.  </section>
<citcontext>
<prevsection>
<prevsent>disambiguation our goal is to use as little annotated data as possible, and at the same time make the algorithm general enough to be able to disambiguate as many content words as possible in text, and efficient enough so that large amounts of text can be annotated in real time.
</prevsent>
<prevsent>supersenselearner is attempting to learn general semantic models for various word categories, starting with relatively small sense-annotated corpus.
</prevsent>
</prevsection>
<citsent citstr=" H93-1061 ">
we base our experiment son semcor (miller et al, 1993), <papid> H93-1061 </papid>balanced, semantically annotated dataset, with all content words manually tagged by trained lexicographers.the input to the disambiguation algorithm consists of raw text.</citsent>
<aftsection>
<nextsent>the output is text with word meaning annotations for all open-class words.
</nextsent>
<nextsent>the algorithm starts with preprocessing stage,where the text is tokenized and annotated with part 406 of-speech tags; collocations are identified using asliding window approach, where collocation is defined as sequence of words that forms compound concept defined in wordnet (miller, 1995).next, semantic model is learned for all predefined word categories, where word category is defined as group of words that share some common syntactic or semantic properties.
</nextsent>
<nextsent>word categories can be of various granularities.
</nextsent>
<nextsent>for instance, model can be defined and trained to handle all the nouns in the test corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4837">
<title id=" W07-2090.xml">untyahoo supersenselearner combining sense learner with super sense and other coarse semantic features </title>
<section> sense learner semantic models.  </section>
<citcontext>
<prevsection>
<prevsent>the words thatare not covered by these models (typically about 10 15% of the words in the test corpus) are assigned the most frequent sense in wordnet.
</prevsent>
<prevsent>different semantic models can be defined and trained for the disambiguation of different word categories.
</prevsent>
</prevsection>
<citsent citstr=" W04-0827 ">
although more general than models that are built individually for each word in test corpus(decadt et al, 2004), <papid> W04-0827 </papid>the applicability of the semantic models built as part of sense learner is still limited to those words previously seen in the training corpus, and therefore their overall coverage is not 100%.</citsent>
<aftsection>
<nextsent>starting with an annotated corpus consisting of all the annotated files in semcor, augmented with the senseval-2 and senseval-3 all-words datasets, separate training dataset is built for each model.
</nextsent>
<nextsent>there are seven models provided with the current sense learner distribution, implementing the following features: 3.1 noun models.
</nextsent>
<nextsent>modelnn1: contextual model that relies on the first noun, verb, or adjective before the target noun, and their corresponding part-of-speech tags.modelnncoll: collocation model that implements collocation-like features based on the first word to the left and the first word to the right of the target noun.
</nextsent>
<nextsent>3.2 verb models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4839">
<title id=" W07-2090.xml">untyahoo supersenselearner combining sense learner with super sense and other coarse semantic features </title>
<section> super senses and other coarse-grained.  </section>
<citcontext>
<prevsection>
<prevsent>several of these types are further divided into sub types, for total of 105 classes.1 4.2 taggers.
</prevsent>
<prevsent>we annotate the training and evaluation data using three sequential taggers, one for each tagset.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
the tagger is hidden markov model trained with the perceptron algorithm introduced in (collins, 2002), <papid> W02-1001 </papid>which applies viterbi decoding and is regularized using averaging.</citsent>
<aftsection>
<nextsent>label to label dependencies are limited to the previous tag (first order hmm).
</nextsent>
<nextsent>we use generic feature set for ner based on words,lemmas, pos tags, and word shape features, in addition we use as feature of each token the supersenseof first (super)sense baseline.
</nextsent>
<nextsent>a detailed description of the features used and the tagger can be foundin (ciaramita and altun, 2006).<papid> W06-1670 </papid></nextsent>
<nextsent>the super sense tagger is trained on the brown sections one and two ofsemcor.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4841">
<title id=" W07-2090.xml">untyahoo supersenselearner combining sense learner with super sense and other coarse semantic features </title>
<section> feature combination.  </section>
<citcontext>
<prevsection>
<prevsent>next, word sense predictions are made for all the test examples, with separate learning process run for each semantic model.
</prevsent>
<prevsent>for learning, we are using the timbl memory based learning algorithm (daele 408 training results mode size precision recall noun 89052 0.658 0.228 verb 48936 0.539 0.353 all 137988 0.583 0.583table 1: precision and recall for the super sense learner semantic models.
</prevsent>
</prevsection>
<citsent citstr=" W02-0814 ">
training results mode size precision recall noun 89052 0.666 0.233 verb 48936 0.554 0.360 all 137988 0.593 0.593table 2: precision and recall for the super sense learner semantic models - without labels.mans et al, 2001), which was previously found useful for the task of word sense disambiguation (hoste et al, 2002; <papid> W02-0814 </papid>mihalcea, 2002).<papid> C02-1039 </papid></citsent>
<aftsection>
<nextsent>following the learning stage, each vector in the test dataset is labeled with predicted word andsense.
</nextsent>
<nextsent>if the word predicted by the learning algorithm coincides with the target word in the test feature vector, then the predicted sense is used to annotate the test instance.
</nextsent>
<nextsent>otherwise, if the predicted word is different from the target word, no annotation is produced, and the word is left for annotation in later stage (e.g., using the most frequent sense back-off method).
</nextsent>
<nextsent>the supersenselearner system participated inthe semeval all-words word sense disambiguation task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4842">
<title id=" W07-2090.xml">untyahoo supersenselearner combining sense learner with super sense and other coarse semantic features </title>
<section> feature combination.  </section>
<citcontext>
<prevsection>
<prevsent>next, word sense predictions are made for all the test examples, with separate learning process run for each semantic model.
</prevsent>
<prevsent>for learning, we are using the timbl memory based learning algorithm (daele 408 training results mode size precision recall noun 89052 0.658 0.228 verb 48936 0.539 0.353 all 137988 0.583 0.583table 1: precision and recall for the super sense learner semantic models.
</prevsent>
</prevsection>
<citsent citstr=" C02-1039 ">
training results mode size precision recall noun 89052 0.666 0.233 verb 48936 0.554 0.360 all 137988 0.593 0.593table 2: precision and recall for the super sense learner semantic models - without labels.mans et al, 2001), which was previously found useful for the task of word sense disambiguation (hoste et al, 2002; <papid> W02-0814 </papid>mihalcea, 2002).<papid> C02-1039 </papid></citsent>
<aftsection>
<nextsent>following the learning stage, each vector in the test dataset is labeled with predicted word andsense.
</nextsent>
<nextsent>if the word predicted by the learning algorithm coincides with the target word in the test feature vector, then the predicted sense is used to annotate the test instance.
</nextsent>
<nextsent>otherwise, if the predicted word is different from the target word, no annotation is produced, and the word is left for annotation in later stage (e.g., using the most frequent sense back-off method).
</nextsent>
<nextsent>the supersenselearner system participated inthe semeval all-words word sense disambiguation task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4843">
<title id=" W08-0611.xml">knowledge sources for word sense disambiguation of biomedical text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previous researchers have used variety of approaches for wsd of biomedical text.
</prevsent>
<prevsent>some of them have taken techniques proven to be effective for wsd of general text and applied them to ambiguities in the biomedical domain, while others have created systems using domain-specific biomedical resources.
</prevsent>
</prevsection>
<citsent citstr=" J01-3001 ">
however, there has been no direct comparison of which knowledge sources are the most useful or whether combining variety of knowledge sources, strategy which has been shown to be successful for wsd in the general domain (stevenson and wilks, 2001), <papid> J01-3001 </papid>improves results.this paper compares the effectiveness of variety of knowledge sources for wsd in the biomedical domain.</citsent>
<aftsection>
<nextsent>these include features which have been commonly used for wsd of general text as well as information derived from domain-specific resources.
</nextsent>
<nextsent>one of these features is mesh terms,which we find to be particularly effective when combined with generic features.
</nextsent>
<nextsent>the next section provides an overview of various approaches to wsd in the biomedical domain.
</nextsent>
<nextsent>sec 80tion 3 outlines our approach, paying particular attention to the range of knowledge sources used by our system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4844">
<title id=" W08-0611.xml">knowledge sources for word sense disambiguation of biomedical text </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>which contained 9 terms.
</prevsent>
<prevsent>the terms which form these various subsets are shown in figure 1.
</prevsent>
</prevsection>
<citsent citstr=" P04-1036 ">
the 50 terms which form the nlm-wsd dataset represent range of challenges for wsd systems.the most frequent sense (mfs) heuristic has be come standard baseline in wsd (mccarthy et al, 2004) <papid> P04-1036 </papid>and is simply the accuracy which would be obtained by assigning the most common meaning of term to all of its instances in corpus.</citsent>
<aftsection>
<nextsent>despite its simplicity, the mfs heuristic is hard baseline to beat, particularly for unsupervised systems, because it uses hand-tagged data to determine which sense is the most frequent.
</nextsent>
<nextsent>analysis of the nlm-wsddata set showed that the mfs over all 50 ambiguous terms is 78%.
</nextsent>
<nextsent>the different subsets have lower mfs, indicating that the terms they contain are more difficult to disambiguate.
</nextsent>
<nextsent>the 22 terms used by (liu et al, 2004) have mfs of 69.9% while the set used by (leroy and rindflesch, 2005) has an mfs of 55.3%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4845">
<title id=" W08-0611.xml">knowledge sources for word sense disambiguation of biomedical text </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>they concluded that cuis are more useful for wsd than umls semantic types but that they are not as robustas features which are known to work in general english, such as unigrams and bigrams.
</prevsent>
<prevsent>our approach is to adapt state-of-the-art wsd system to the biomedical domain by augmenting it with additional domain-specific and domain-independent knowledge sources.
</prevsent>
</prevsection>
<citsent citstr=" W04-0813 ">
our basic system (agirre andmartnez, 2004) <papid> W04-0813 </papid>participated in the senseval-3 challenge (mihalcea et al, 2004) with performance close to the best system for the english and basque lexical sample tasks.</citsent>
<aftsection>
<nextsent>the system is based on supervised learning approach.
</nextsent>
<nextsent>the features used by agirre and martnez (2004) <papid> W04-0813 </papid>are derived from text around the ambiguous word and are domain inde pendent.</nextsent>
<nextsent>we refer to these as linguistic features.this feature set has been adapted for the disambiguation of biomedical text by adding further linguistic features and two different types of domain specific features: cuis (as used by (mcinnes et al, 2007)) and medical subject heading (mesh) terms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4847">
<title id=" W08-0611.xml">knowledge sources for word sense disambiguation of biomedical text </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>in the above example, heparin?
</prevsent>
<prevsent>is noun-modifier feature of adjustment?.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
2a maximum-entropy-based part of speech tagger was used (ratnaparkhi, 1996) <papid> W96-0213 </papid>without the adaptation to the biomedical domain.?</citsent>
<aftsection>
<nextsent>salient bigrams: salient bigrams within the abstract with high log-likelihood scores, as described by pedersen (2001).<papid> N01-1011 </papid></nextsent>
<nextsent>unigrams: lemmas of unigrams which appear more frequently than predefined threshold in the entire corpus, excluding those in list of stopwords.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4848">
<title id=" W08-0611.xml">knowledge sources for word sense disambiguation of biomedical text </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>is noun-modifier feature of adjustment?.
</prevsent>
<prevsent>2a maximum-entropy-based part of speech tagger was used (ratnaparkhi, 1996) <papid> W96-0213 </papid>without the adaptation to the biomedical domain.?</prevsent>
</prevsection>
<citsent citstr=" N01-1011 ">
salient bigrams: salient bigrams within the abstract with high log-likelihood scores, as described by pedersen (2001).<papid> N01-1011 </papid></citsent>
<aftsection>
<nextsent>unigrams: lemmas of unigrams which appear more frequently than predefined threshold in the entire corpus, excluding those in list of stopwords.
</nextsent>
<nextsent>we empirically set the threshold to 1.
</nextsent>
<nextsent>this feature was not used by agirre and martnez (2004), <papid> W04-0813 </papid>but joshi et al (2005) found them to be useful for this task.</nextsent>
<nextsent>concept unique identifiers (cuis): we follow the approach presented by mcinnes et al (2007) to generate features based on umls concept unique identifiers (cuis).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4850">
<title id=" W07-1701.xml">slavic information extraction and partial parsing </title>
<section> slavonic is hard.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, discuss linguistic phenomena which make ie in slavonic harder than in germanic or romance, 2, but also those which seem to make it easier, 3.
</prevsent>
<prevsent>we will also look at various general tools which have been usedin ie tasks in the context of slavonic languages, especially at tools for partial (or shallow) parsing, 4.i deal mainly with polish, as good representative of the slavonic family: although polish is relatively large language, with about 44 million native speakers world-wide (over 38 million in poland), the availability of linguistic resources and tools for this language does not reflect this fact: it compares unfavourably with czech, and probably favourably with, say, ukrainian.
</prevsent>
</prevsection>
<citsent citstr=" P99-1065 ">
there are various characteristics of slavonic lan guages1 that make them more difficult for automatic processing, whether shallow or deep, than germanic and romance languages.2 the two of them which are most conspicuous, and identified as most problematic, e.g., in (collins et al, 1999), <papid> P99-1065 </papid>are rich nominal inflection (2.1) and free word order (2.6).</citsent>
<aftsection>
<nextsent>others, causing problems to varying extents, include: idiosyncratic inflection of slavonic proper names (2.2); unstable inflection of some foreign names(2.3); high degree of trans- and, especially, intra paradigmatic syncretisms (2.4); and, on the more syntactic level, the infamous quirkiness of numeral phrases (numps; 2.5).
</nextsent>
<nextsent>2.1 rich nominal inflection.
</nextsent>
<nextsent>the rich nominal inflection of slavonic makes already the most basic ie task, namely named entity recognition (ner), more difficult than in germanic or romance.
</nextsent>
<nextsent>slavonic nouns, apart from in1many of the typo logical features discussed below distinguish between, on the one hand, east slavonic (russian, ukrainian, belorussian, rusyn), west slavonic (czech, slovak, upper and lower sorbian, polish, kashubian) and the western subgroup of south slavonic (croatian, bosnian, serbian, slove nian), and, on the other hand, the eastern subgroup of south slavonic (bulgarian and macedonian).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4851">
<title id=" W07-1701.xml">slavic information extraction and partial parsing </title>
<section> slavonic is hard.  </section>
<citcontext>
<prevsection>
<prevsent>numerals (not ending in 2, 3 or 4), the polish nump in subject position does not agree with the verb; instead, the verb occurs in the default 3rd person singular neuter form,106one of the largest formal grammars of polish, (swidz inski, 1992), implemented as wide coverage deep parser in(wolinski, 2004), does not deal with numps at all.
</prevsent>
<prevsent>later modifications of the parser in (ogrodniczuk, 2006) include some limited treatment of numerals.
</prevsent>
</prevsection>
<citsent citstr=" P06-2062 ">
7this property turned out to be problematic for adapting the gf parallel resource grammar to russian (khegai, 2006).<papid> P06-2062 </papid>8another exception is jeden 1?, which is actually an adjective, rather than numeral (przepirkowski, 2006a).</citsent>
<aftsection>
<nextsent>also, the description above holds for non-virile genders, but is even more complicated for virile.
</nextsent>
<nextsent>9the latter may occur in contexts like: . . .
</nextsent>
<nextsent>wedug paragrafu 155 dolary nie sa?
</nextsent>
<nextsent>srodkiem patniczym polsce ?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4852">
<title id=" W07-1701.xml">slavic information extraction and partial parsing </title>
<section> slavonic is proces sable.  </section>
<citcontext>
<prevsection>
<prevsent>2) grammars to particular practical tasks.
</prevsent>
<prevsent>in some of these attempts no particular dedicated language processing system was used to implement shallow grammars: apparently they were coded directly in the host programming language.
</prevsent>
</prevsection>
<citsent citstr=" W04-0403 ">
one example is (sharoff, 2004), <papid> W04-0403 </papid>where shallow parsing is used for the identification of prepositional multiword expressions in russian, with the following explanation of reasons for performing some language-dependent processing: given thatthe word order in russian (and other slavonic lan guages) is relatively free and typical word (i.e. lemma) has many forms (typically from 9 for nouns to 50 for verbs), the sequences of exact n-grams are much less frequent than in english, thus rendering purely statistical approaches useless.for polish, simple shallow grammars were implemented for the tasks of question answering(piechocinski and mykowiecka, 2005) and automatic valence acquisition (fast and przepirkowski,2005; przepirkowski and fast, 2005); in the latter case grammar was implemented as cascade of perl regular expressions.</citsent>
<aftsection>
<nextsent>similarly, (zeman,2001) describes perl regular expression implementation of shallow pre processor for deep statisticalparser.
</nextsent>
<nextsent>much earlier, (nenadic?
</nextsent>
<nextsent>and vitas, 1998; nenadic?, 2000) developed shallow grammars of serbo croatian for the recognition of noun phrases (nps) and certain kinds of coordinate structures.
</nextsent>
<nextsent>see also (bekavac and tadic?, 2007) on the recognition of croatian nes with regular grammars.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4853">
<title id=" W07-1701.xml">slavic information extraction and partial parsing </title>
<section> slavonic is proces sable.  </section>
<citcontext>
<prevsection>
<prevsent>and vitas, 1998; nenadic?, 2000) developed shallow grammars of serbo croatian for the recognition of noun phrases (nps) and certain kinds of coordinate structures.
</prevsent>
<prevsent>see also (bekavac and tadic?, 2007) on the recognition of croatian nes with regular grammars.
</prevsent>
</prevsection>
<citsent citstr=" C02-1027 ">
moreover, for bulgarian more general integrated system was developed, called lingua (tanev and mitkov, 2002), <papid> C02-1027 </papid>which ? apart from modules for 12again, this test may fail due to case syncretisms; cf.</citsent>
<aftsection>
<nextsent>2.4.tokenisation, morphosyntactic analysis and disambiguation, and anaphora resolution ? includes annp extractor and bottom-up grammar of bulgarian.
</nextsent>
<nextsent>this system, together with set of shallow patterns for identifying definition patterns, has been employed in question answering prototype system (tanev, 2004).
</nextsent>
<nextsent>bulgarian pattern-matching grammars are also employed in (koeva, 2007).apart from these language-specific implementations, there exist tools and tool boxes which facilitate various ie tasks, including shallow parsing.
</nextsent>
<nextsent>probably the best known such general system is gate (cunningham et al, 1995; cunningham et al, 2002), <papid> P02-1022 </papid>which contains some ne resources for bulgarian and russian (humphreys et al, 2002; popov et al,2004) and allows to write shallow (regular) grammars in the jape subsystem (cunningham et al, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4854">
<title id=" W07-1701.xml">slavic information extraction and partial parsing </title>
<section> slavonic is proces sable.  </section>
<citcontext>
<prevsection>
<prevsent>this system, together with set of shallow patterns for identifying definition patterns, has been employed in question answering prototype system (tanev, 2004).
</prevsent>
<prevsent>bulgarian pattern-matching grammars are also employed in (koeva, 2007).apart from these language-specific implementations, there exist tools and tool boxes which facilitate various ie tasks, including shallow parsing.
</prevsent>
</prevsection>
<citsent citstr=" P02-1022 ">
probably the best known such general system is gate (cunningham et al, 1995; cunningham et al, 2002), <papid> P02-1022 </papid>which contains some ne resources for bulgarian and russian (humphreys et al, 2002; popov et al,2004) and allows to write shallow (regular) grammars in the jape subsystem (cunningham et al, 2000).</citsent>
<aftsection>
<nextsent>a system similar in scope is sprout (becker et al., 2002), whose shallow parsing language allow sto write regular grammars over hpsg-style (pol lard and sag, 1994) typed feature structures and which includes the operation of unification.
</nextsent>
<nextsent>preliminary work on adapting sprout to the processing of baltic and slavonic languages is presented in (drozdzynski et al, 2003), with much subsequent work devoted to the processing of polish, especially, in the area of information extraction from medical texts (piskorski et al, 2004; piskorski, 2004a; piskorski, 2004b; marciniak et al, 2005; mykowiecka et al., 2005a; mykowiecka et al, 2005b; marciniak and mykowiecka, 2007).
</nextsent>
<nextsent>although gate and sprout may be adapted to the processing of xml documents, they are perhaps not the most natural choice for the further processing of morpho syntactically annotated documents in, for example, the xces (xml corpus encoding stan dard; (ide et al, 2000)) format, as assumed, e.g., in the ipi pan corpus of polish (przepirkowski, 2004a), in the slovak national corpus (garabk and gianitsov?-olotiakov?, 2005), or in the lt4el project (http://www.lt4el.eu/).
</nextsent>
<nextsent>specialised xml-aware tools exist for such tasks.one of the earliest collections of xml processing tools is the lt xml library (brew et al, 2000), whose second edition, lt-xml2 is currently under preparation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4855">
<title id=" W07-1209.xml">pruning the search space of a handcrafted parsing system with a probabilistic parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this instance, the log-linear disambiguation does not need to choose the most probable result.
</prevsent>
<prevsent>the research question we pose is whether the search space can be pruned earlier before unification takes place.
</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
bangalore and joshi (1999), <papid> J99-2004 </papid>clark and curran (2004) <papid> C04-1041 </papid>and matsuzaki et al (2007) show that by using super tagger before (ccg andhpsg) parsing, the space required for disc rimini tive training is drastically reduced.</citsent>
<aftsection>
<nextsent>supertaggingis not widely used within the lfg framework, although there has been some work on using hyper tags (kinyon, 2000).<papid> C00-1065 </papid></nextsent>
<nextsent>ninomiya et al (2006) <papid> W06-1619 </papid>propose method for faster hpsg parsing while maintaining accuracy by only using the probabilities of lexical entry selections (i.e. the supertags) in their discriminitive model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4856">
<title id=" W07-1209.xml">pruning the search space of a handcrafted parsing system with a probabilistic parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this instance, the log-linear disambiguation does not need to choose the most probable result.
</prevsent>
<prevsent>the research question we pose is whether the search space can be pruned earlier before unification takes place.
</prevsent>
</prevsection>
<citsent citstr=" C04-1041 ">
bangalore and joshi (1999), <papid> J99-2004 </papid>clark and curran (2004) <papid> C04-1041 </papid>and matsuzaki et al (2007) show that by using super tagger before (ccg andhpsg) parsing, the space required for disc rimini tive training is drastically reduced.</citsent>
<aftsection>
<nextsent>supertaggingis not widely used within the lfg framework, although there has been some work on using hyper tags (kinyon, 2000).<papid> C00-1065 </papid></nextsent>
<nextsent>ninomiya et al (2006) <papid> W06-1619 </papid>propose method for faster hpsg parsing while maintaining accuracy by only using the probabilities of lexical entry selections (i.e. the supertags) in their discriminitive model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4857">
<title id=" W07-1209.xml">pruning the search space of a handcrafted parsing system with a probabilistic parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the research question we pose is whether the search space can be pruned earlier before unification takes place.
</prevsent>
<prevsent>bangalore and joshi (1999), <papid> J99-2004 </papid>clark and curran (2004) <papid> C04-1041 </papid>and matsuzaki et al (2007) show that by using super tagger before (ccg andhpsg) parsing, the space required for disc rimini tive training is drastically reduced.</prevsent>
</prevsection>
<citsent citstr=" C00-1065 ">
supertaggingis not widely used within the lfg framework, although there has been some work on using hyper tags (kinyon, 2000).<papid> C00-1065 </papid></citsent>
<aftsection>
<nextsent>ninomiya et al (2006) <papid> W06-1619 </papid>propose method for faster hpsg parsing while maintaining accuracy by only using the probabilities of lexical entry selections (i.e. the supertags) in their discriminitive model.</nextsent>
<nextsent>in the work presented here, we con 1for example, is can be copula, progressive auxiliary or passive auxiliary, while slower can either be an adjective or an adverb.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4858">
<title id=" W07-1209.xml">pruning the search space of a handcrafted parsing system with a probabilistic parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>bangalore and joshi (1999), <papid> J99-2004 </papid>clark and curran (2004) <papid> C04-1041 </papid>and matsuzaki et al (2007) show that by using super tagger before (ccg andhpsg) parsing, the space required for disc rimini tive training is drastically reduced.</prevsent>
<prevsent>supertaggingis not widely used within the lfg framework, although there has been some work on using hyper tags (kinyon, 2000).<papid> C00-1065 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-1619 ">
ninomiya et al (2006) <papid> W06-1619 </papid>propose method for faster hpsg parsing while maintaining accuracy by only using the probabilities of lexical entry selections (i.e. the supertags) in their discriminitive model.</citsent>
<aftsection>
<nextsent>in the work presented here, we con 1for example, is can be copula, progressive auxiliary or passive auxiliary, while slower can either be an adjective or an adverb.
</nextsent>
<nextsent>65 cent rate on reducing the number of c-structure trees that the unifier has to process, ideally to one tree.
</nextsent>
<nextsent>the hope was that this would speed up the parsing process, but how would it affect the quality of the structures?
</nextsent>
<nextsent>this is similar to the approach taken by cahill et al (2005) who do not use hand-crafted complete unification system (rather an automatically acquired probabilistic approximation).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4859">
<title id=" W07-1209.xml">pruning the search space of a handcrafted parsing system with a probabilistic parser </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>alternative to determine the viability of the pruningstrategy; this is the experiment reported in this paper.
</prevsent>
<prevsent>this is implemented by stipulating constituent boundaries in the input string, so that any c-structure that is incompatible with these constraints is invalid and will not be processed by the unifier.
</prevsent>
</prevsection>
<citsent citstr=" P02-1035 ">
this wasdone to some extent in riezler et al (2002) <papid> P02-1035 </papid>to automatically generate training data for the log-linear disambiguation component of xle.</citsent>
<aftsection>
<nextsent>previous work obtained the constituent constraints (i.e. brackets)from the gold-standard trees in the penn-ii tree bank.
</nextsent>
<nextsent>however, to parse novel text, gold-standard trees are unavailable.
</nextsent>
<nextsent>we used state-of-the-art probabilistic parser to provide the bracketing constraints to xle.
</nextsent>
<nextsent>these parsers are accurate (achieving accuracy of over 90% on section 23 wsj text), fast, and robust.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4860">
<title id=" W07-1209.xml">pruning the search space of a handcrafted parsing system with a probabilistic parser </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>.))) labeled: \[s1 \[s growth \[vp is \[adjp slower\] \].\] \] unlabeled:\[ \[ growth \[ is \[ slower\] \].\] \] figure 2: example of retained brackets from parser output to constrain the xle parser 2.2 the xle parsing system.
</prevsent>
<prevsent>the xle parsing system is deep-grammar-based parsing system.
</prevsent>
</prevsection>
<citsent citstr=" W02-1503 ">
the experiments reported in this paper use the english lfg grammar constructed as part of the pargram project (butt et al, 2002).<papid> W02-1503 </papid>this system incorporates sophisticated ambiguity management technology so that all possible syntactic analyses of sentence are computed in an efficient, packed representation (maxwell and kaplan, 1993).<papid> J93-4001 </papid></citsent>
<aftsection>
<nextsent>in accordance with lfg theory, the output includes not only standard context free phrase-structure trees (c-structures) but alsoattribute-value matrices (f-structures) that explicitly encode predicate-argument relations and other meaningful properties.
</nextsent>
<nextsent>the f-structures can be deterministically mapped to dependency triples without any loss of information, using the built-in ordered rewrite system (crouch et al, 2002).
</nextsent>
<nextsent>xle selects the most probable analysis from the potentially large candidate set by means of stochastic disambiguation component based on log-linear probability model (riezler et al, 2002) <papid> P02-1035 </papid>that works on the packed representations.</nextsent>
<nextsent>the underlying parsing system also has built-in robustness mechanisms that allow it to parse strings that are outside the scope ofthe grammar as list of fewest well-formed frag ments?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4861">
<title id=" W07-1209.xml">pruning the search space of a handcrafted parsing system with a probabilistic parser </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>.))) labeled: \[s1 \[s growth \[vp is \[adjp slower\] \].\] \] unlabeled:\[ \[ growth \[ is \[ slower\] \].\] \] figure 2: example of retained brackets from parser output to constrain the xle parser 2.2 the xle parsing system.
</prevsent>
<prevsent>the xle parsing system is deep-grammar-based parsing system.
</prevsent>
</prevsection>
<citsent citstr=" J93-4001 ">
the experiments reported in this paper use the english lfg grammar constructed as part of the pargram project (butt et al, 2002).<papid> W02-1503 </papid>this system incorporates sophisticated ambiguity management technology so that all possible syntactic analyses of sentence are computed in an efficient, packed representation (maxwell and kaplan, 1993).<papid> J93-4001 </papid></citsent>
<aftsection>
<nextsent>in accordance with lfg theory, the output includes not only standard context free phrase-structure trees (c-structures) but alsoattribute-value matrices (f-structures) that explicitly encode predicate-argument relations and other meaningful properties.
</nextsent>
<nextsent>the f-structures can be deterministically mapped to dependency triples without any loss of information, using the built-in ordered rewrite system (crouch et al, 2002).
</nextsent>
<nextsent>xle selects the most probable analysis from the potentially large candidate set by means of stochastic disambiguation component based on log-linear probability model (riezler et al, 2002) <papid> P02-1035 </papid>that works on the packed representations.</nextsent>
<nextsent>the underlying parsing system also has built-in robustness mechanisms that allow it to parse strings that are outside the scope ofthe grammar as list of fewest well-formed frag ments?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4863">
<title id=" W07-1209.xml">pruning the search space of a handcrafted parsing system with a probabilistic parser </title>
<section> baseline experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we carried out baseline experiment with twostate-of-the-art parsers to establish what effect pre bracketing the input to the xle system has on the quality and number of the solutions produced.
</prevsent>
<prevsent>weused the bikel () multi-threaded, head-driven chart parsing engine developed at the university of pennsylvania.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
the second parser is that described in charniak and johnson (2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>this parser uses adiscriminative reranker that selects the most probable parse from the 50-best parses returned by generative parser based on charniak (2000).<papid> A00-2018 </papid></nextsent>
<nextsent>we evaluated against the parc 700 dependency bank (king et al, 2003) which provides gold standard analyses for 700 sentences chosen at random from section 23 of the penn-ii treebank.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4864">
<title id=" W07-1209.xml">pruning the search space of a handcrafted parsing system with a probabilistic parser </title>
<section> baseline experiments.  </section>
<citcontext>
<prevsection>
<prevsent>weused the bikel () multi-threaded, head-driven chart parsing engine developed at the university of pennsylvania.
</prevsent>
<prevsent>the second parser is that described in charniak and johnson (2005).<papid> P05-1022 </papid></prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
this parser uses adiscriminative reranker that selects the most probable parse from the 50-best parses returned by generative parser based on charniak (2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>we evaluated against the parc 700 dependency bank (king et al, 2003) which provides gold standard analyses for 700 sentences chosen at random from section 23 of the penn-ii treebank.
</nextsent>
<nextsent>the dependency bank was boot strapped by parsing the 700 sentences with the xle english grammar, andthen manually correcting the output.
</nextsent>
<nextsent>the data is divided into two sets, 140-sentence development set and test set of 560 sentences (kaplan et al, 2004).<papid> N04-1013 </papid></nextsent>
<nextsent>we took the raw strings from the 140-sentence development set and parsed them with each of the state-of-the-art probabilistic parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4865">
<title id=" W07-1209.xml">pruning the search space of a handcrafted parsing system with a probabilistic parser </title>
<section> baseline experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluated against the parc 700 dependency bank (king et al, 2003) which provides gold standard analyses for 700 sentences chosen at random from section 23 of the penn-ii treebank.
</prevsent>
<prevsent>the dependency bank was boot strapped by parsing the 700 sentences with the xle english grammar, andthen manually correcting the output.
</prevsent>
</prevsection>
<citsent citstr=" N04-1013 ">
the data is divided into two sets, 140-sentence development set and test set of 560 sentences (kaplan et al, 2004).<papid> N04-1013 </papid></citsent>
<aftsection>
<nextsent>we took the raw strings from the 140-sentence development set and parsed them with each of the state-of-the-art probabilistic parsers.
</nextsent>
<nextsent>as an upper bound for the baseline experiment, we use the brackets in the original penn-ii treebank trees for the 140 development set.we then used the brackets from each parser out put (or original treebank trees) to constrain the xle parser.
</nextsent>
<nextsent>if the input to the xle parser is bracketed, the parser will only generate c-structures that respect these brackets (i.e., only c-structures with brackets that are compatible with the input brackets are considered during the unification stage).
</nextsent>
<nextsent>figure 2 givesan example of retained brackets from the parser output.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4867">
<title id=" W07-1209.xml">pruning the search space of a handcrafted parsing system with a probabilistic parser </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 pre-tagging.
</prevsent>
<prevsent>we performed some error analysis on the output ofthe bikel-xle system and noticed that consider able number of errors were due to mis-tagging.
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
so, we pre-tagged the input to the bikel parser using the mxpost tagger (ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>the results for the non-fragment grammars are presented in table 4.
</nextsent>
<nextsent>pre-tagging with mxpost, however, doesnot result in statistically significantly higher result than parsing untagged input, although more sentences can be parsed by both systems.
</nextsent>
<nextsent>pre-tagging also adds an extra time overhead cost.
</nextsent>
<nextsent>no pretags mxpost tags xle bikel-xle bikel-xle unlabeled total parsing time 964 380 493 # xle parses (/140) 119 89 92 f-score of subset 81.57 85.62 84.98 overall f-score 72.01 59.34 *61.11 labeled total parsing time 964 336 407 # xle parses (/140) 119 77 80 f-score of subset 81.57 86.11 85.87 overall f-score 72.01 52.84 *54.91table 4: mxpost pre-tagged, non-fragment grammar 5.3 pruning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4870">
<title id=" W07-1511.xml">annotating chinese collocations with multi information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>consequently, collocation knowledge is widely employed in natural language processing tasks such as word sense disambiguation, machine translation, information retrieval and natural language generation (manning et al 1999).
</prevsent>
<prevsent>although the importance of collocation is well known, it is difficult to compile complete collocation dictionary.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
there are some existing corpus linguistic researches on automatic extraction of collocations from electronic text (smadja 1993; <papid> J93-1007 </papid>lin 1998; xu and lu 2006).</citsent>
<aftsection>
<nextsent>these techniques are mainly based on statistical techniques and syntactic analysis.
</nextsent>
<nextsent>however, the performances of automatic collocation extraction systems are not satisfactory (pecina 2005).<papid> P05-2003 </papid></nextsent>
<nextsent>a problem is that collocations are word combinations that co-occur within short context, but not all such co-occurrences are true collocations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZD4871">
<title id=" W07-1511.xml">annotating chinese collocations with multi information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are some existing corpus linguistic researches on automatic extraction of collocations from electronic text (smadja 1993; <papid> J93-1007 </papid>lin 1998; xu and lu 2006).</prevsent>
<prevsent>these techniques are mainly based on statistical techniques and syntactic analysis.</prevsent>
</prevsection>
<citsent citstr=" P05-2003 ">
however, the performances of automatic collocation extraction systems are not satisfactory (pecina 2005).<papid> P05-2003 </papid></citsent>
<aftsection>
<nextsent>a problem is that collocations are word combinations that co-occur within short context, but not all such co-occurrences are true collocations.
</nextsent>
<nextsent>further examinations is needed to filter out pseudo-collocations once co-occurred word pairs are identified.
</nextsent>
<nextsent>a collocation bank with true collocations annotated is naturally an indispensable resource for collocation research.
</nextsent>
<nextsent>(kosho et al 2000) presented their works of collocation annotation on japanese text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
</paper>