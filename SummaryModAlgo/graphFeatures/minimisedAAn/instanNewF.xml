<paper>
<cited id="F0">
<title id=" C94-1091.xml">classifier assignment by corpus based approach </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>as far as we can do in the rule~based approach is to give default rule to pick up corresponding classifier of each noun.
</prevsent>
<prevsent>registration of classifier for each noun is limited to the type of unit classifier because other types ,are open due to the meaning of representation.
</prevsent>
</prevsection>
<citsent citstr=" J93-3004 ">
we propose corpus-based method (biber,1993; <papid> J93-3004 </papid>nagao,1993; smadja,1993) <papid> J93-1007 </papid>which generates noun classifier associations (nca) to overcome the problems in classifier assignment and semantic construction of noun phrase.</citsent>
<aftsection>
<nextsent>the nca is created statistically from large corpus and re composed under concept hierarchy constraints and frequency of occurrences.
</nextsent>
<nextsent>keywords: thai language, classifier, corpus-based method, noun classifier associations (nca)
</nextsent>
<nextsent>a classifier has significant use in thai language tbr construction of noun or verb to express quantity, determination, pronoun, etc. by far the most common use of classifiers, however, is in enumerations, where the classifiers follow numerals and precede demonstratives (noss,1964).
</nextsent>
<nextsent>not all types of classifier have relationship with noun or verb as unit classifier does.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F1">
<title id=" C94-1091.xml">classifier assignment by corpus based approach </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>as far as we can do in the rule~based approach is to give default rule to pick up corresponding classifier of each noun.
</prevsent>
<prevsent>registration of classifier for each noun is limited to the type of unit classifier because other types ,are open due to the meaning of representation.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
we propose corpus-based method (biber,1993; <papid> J93-3004 </papid>nagao,1993; smadja,1993) <papid> J93-1007 </papid>which generates noun classifier associations (nca) to overcome the problems in classifier assignment and semantic construction of noun phrase.</citsent>
<aftsection>
<nextsent>the nca is created statistically from large corpus and re composed under concept hierarchy constraints and frequency of occurrences.
</nextsent>
<nextsent>keywords: thai language, classifier, corpus-based method, noun classifier associations (nca)
</nextsent>
<nextsent>a classifier has significant use in thai language tbr construction of noun or verb to express quantity, determination, pronoun, etc. by far the most common use of classifiers, however, is in enumerations, where the classifiers follow numerals and precede demonstratives (noss,1964).
</nextsent>
<nextsent>not all types of classifier have relationship with noun or verb as unit classifier does.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F2">
<title id=" C96-1050.xml">language specific mappings from semantics to syntax </title>
<section> from semantics  to syntax.  </section>
<citcontext>
<prevsection>
<prevsent>the overlap in the syntax of generation vs enable ment sentences is confined to expressions of purpose.
</prevsent>
<prevsent>figures 7 and 8 show the relationships between semantic relation and syntax with an overlay of discourse: rhetorical relations and discourse markers.
</prevsent>
</prevsection>
<citsent citstr=" P95-1018 ">
\[ discourse syntax generated generatl ng (80.1%) condition (9.3%) result (1..5%) cne caso ed se el) + aulomat- icamente ed ~-nfinitive infinitive nominal infinitive p;msive u\[ure (agent = artifact) ~imperative,passive, infinitive} basta + infinitive {imperative, infinitive} imperative} infinitive/imperative ~npera6c, figure 7: portuguese: generation the figures show strong and unambiguous re- sthis can be compared with the finding presented by (moser and moore, 1995) <papid> P95-1018 </papid>in their acl-95 presen-.</citsent>
<aftsection>
<nextsent>tation, that discourse cues are significantly more likely to occur when the  contributor  component of there- lation precedes the  core  in english dialogues.
</nextsent>
<nextsent>lationship between rhetorical relation, discourse marker, and syntax.
</nextsent>
<nextsent>there is strong tendency to present generation in terms of the rhetorical relation of urpose, which is marked almost in-variably by para or para que (so that), both of which can only take nominal or infiniti val ex-pression.
</nextsent>
<nextsent>sequence, on the other hand, is sig-nalled by temporal connectives uch as antes de (before), depois de (after) or apes (afte,9, by the connective (and) or implicitly by the use of comma between the elements of string of imper-atives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F3">
<title id=" C96-2109.xml">an evaluation semantics for datr theories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the seman-tics is presented as set of inference rules that axiomatises the evaluation relation-ship for datr expressions.
</prevsent>
<prevsent>the infer-ence rules provide clear picture of the way in which datr works, and should lead to better understanding of the mathematical nd computational prop-erties of the language.
</prevsent>
</prevsection>
<citsent citstr=" E89-1009 ">
datr was originally introduced by evans and gazdar (1989<papid> E89-1009 </papid>a), evans and gazdar (1989<papid> E89-1009 </papid>b) as simple, non- monotonic language for representing lexical inher-itance hierarchies.</citsent>
<aftsection>
<nextsent>a datr hierarchy is defined by means of path-value specifications.
</nextsent>
<nextsent>inheritance of values permits appropriate generalizations to be captured and redundancy in the description of data to be avoided.
</nextsent>
<nextsent>a simple default mechanism provides for concise descriptions while allowing for particular exceptions to inherited information to be stated in natural way.
</nextsent>
<nextsent>currently, datr is the most widely-used lexical knowledge representation language in the natural language processing community.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F7">
<title id=" C96-2109.xml">an evaluation semantics for datr theories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a simple default mechanism provides for concise descriptions while allowing for particular exceptions to inherited information to be stated in natural way.
</prevsent>
<prevsent>currently, datr is the most widely-used lexical knowledge representation language in the natural language processing community.
</prevsent>
</prevsection>
<citsent citstr=" E93-1012 ">
the formalism has been applied to wide variety of problems, including inflectional and derivational morphol-ogy (gazdar, 1992; kilbury, 1992; corbett and fraser, 1993), lexical semantics (kilgariff, 1993), morphonology (cahill, 1993), <papid> E93-1012 </papid>prosody (gibbon and bleiching, 1991) and speech (andry et al, 1992).<papid> J92-3001 </papid></citsent>
<aftsection>
<nextsent>in more recent work, datr has been used to provide concise, inheritance-based ncoding of lexiealized tree adjoining grammar (evans et al, 1995).<papid> P95-1011 </papid></nextsent>
<nextsent>there are around dozen different implementations of datr in existence and large- scale datr lexicons have been designed for use in number of natural anguage processing applica-tions (cahill and evans, 1990; andry et al, 1992; <papid> J92-3001 </papid>cahill, 1994).<papid> A94-1045 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F8">
<title id=" C96-2109.xml">an evaluation semantics for datr theories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a simple default mechanism provides for concise descriptions while allowing for particular exceptions to inherited information to be stated in natural way.
</prevsent>
<prevsent>currently, datr is the most widely-used lexical knowledge representation language in the natural language processing community.
</prevsent>
</prevsection>
<citsent citstr=" J92-3001 ">
the formalism has been applied to wide variety of problems, including inflectional and derivational morphol-ogy (gazdar, 1992; kilbury, 1992; corbett and fraser, 1993), lexical semantics (kilgariff, 1993), morphonology (cahill, 1993), <papid> E93-1012 </papid>prosody (gibbon and bleiching, 1991) and speech (andry et al, 1992).<papid> J92-3001 </papid></citsent>
<aftsection>
<nextsent>in more recent work, datr has been used to provide concise, inheritance-based ncoding of lexiealized tree adjoining grammar (evans et al, 1995).<papid> P95-1011 </papid></nextsent>
<nextsent>there are around dozen different implementations of datr in existence and large- scale datr lexicons have been designed for use in number of natural anguage processing applica-tions (cahill and evans, 1990; andry et al, 1992; <papid> J92-3001 </papid>cahill, 1994).<papid> A94-1045 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F9">
<title id=" C96-2109.xml">an evaluation semantics for datr theories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>currently, datr is the most widely-used lexical knowledge representation language in the natural language processing community.
</prevsent>
<prevsent>the formalism has been applied to wide variety of problems, including inflectional and derivational morphol-ogy (gazdar, 1992; kilbury, 1992; corbett and fraser, 1993), lexical semantics (kilgariff, 1993), morphonology (cahill, 1993), <papid> E93-1012 </papid>prosody (gibbon and bleiching, 1991) and speech (andry et al, 1992).<papid> J92-3001 </papid></prevsent>
</prevsection>
<citsent citstr=" P95-1011 ">
in more recent work, datr has been used to provide concise, inheritance-based ncoding of lexiealized tree adjoining grammar (evans et al, 1995).<papid> P95-1011 </papid></citsent>
<aftsection>
<nextsent>there are around dozen different implementations of datr in existence and large- scale datr lexicons have been designed for use in number of natural anguage processing applica-tions (cahill and evans, 1990; andry et al, 1992; <papid> J92-3001 </papid>cahill, 1994).<papid> A94-1045 </papid></nextsent>
<nextsent>a comprehensive, informal intro-duction to datr and its application to the design of natural language lexicons can tbund in (evans and gazdar, 1996).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F11">
<title id=" C96-2109.xml">an evaluation semantics for datr theories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the formalism has been applied to wide variety of problems, including inflectional and derivational morphol-ogy (gazdar, 1992; kilbury, 1992; corbett and fraser, 1993), lexical semantics (kilgariff, 1993), morphonology (cahill, 1993), <papid> E93-1012 </papid>prosody (gibbon and bleiching, 1991) and speech (andry et al, 1992).<papid> J92-3001 </papid></prevsent>
<prevsent>in more recent work, datr has been used to provide concise, inheritance-based ncoding of lexiealized tree adjoining grammar (evans et al, 1995).<papid> P95-1011 </papid></prevsent>
</prevsection>
<citsent citstr=" A94-1045 ">
there are around dozen different implementations of datr in existence and large- scale datr lexicons have been designed for use in number of natural anguage processing applica-tions (cahill and evans, 1990; andry et al, 1992; <papid> J92-3001 </papid>cahill, 1994).<papid> A94-1045 </papid></citsent>
<aftsection>
<nextsent>a comprehensive, informal intro-duction to datr and its application to the design of natural language lexicons can tbund in (evans and gazdar, 1996).
</nextsent>
<nextsent>the original publications on datr sought to provide the language with (1) formal theory of inference (evans and gazdar, 1989<papid> E89-1009 </papid>a) and (2) model-theoretic semantics (evans and gazdar, 1989<papid> E89-1009 </papid>b).</nextsent>
<nextsent>unfortunately, the definitions et out in these papers are not general enough to cover all of the constructs available in the datr language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F24">
<title id=" C96-2109.xml">an evaluation semantics for datr theories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, the definitions et out in these papers are not general enough to cover all of the constructs available in the datr language.
</prevsent>
<prevsent>in particular, they fail to provide full and cor-rect treatment of datr notion of  global inher-itance , or the widely-used  evaluable path  con-struct.
</prevsent>
</prevsection>
<citsent citstr=" P95-1008 ">
a denotational semantics for datr that covers all of the major constructs has been pre-sented in (keller, 1995).<papid> P95-1008 </papid></citsent>
<aftsection>
<nextsent>however, it still remains to provide suitably general, formal theory of in-ference for datr, and it is this objective that is addressed in the present paper.
</nextsent>
<nextsent>let node and atom be finite sets of symbols.
</nextsent>
<nextsent>e1- einents of node are called nodes and denoted by n. elements of atom are called atoms and de-noted by a. elements of atom* are called values and denoted by a, /3, 7- the set desc of datr value descriptors (or simply descriptors) is built up from the nodes and atoms as shown below.
</nextsent>
<nextsent>\[n the following, sequences of descriptors in desc* are denoted ?, ~/j. 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F49">
<title id=" C92-4177.xml">degrees of stat ivity the lexical representation of verb aspect </title>
<section> les ptopri6t6s lexicales inh6rentes.  </section>
<citcontext>
<prevsection>
<prevsent>once applied, we propose represen-tation for verb aspect hat associates value with weights for event types.
</prevsent>
<prevsent>weights reflect typical verb use, and thus represent measure of the resis-tance or ease of coercion in sentential context.
</prevsent>
</prevsection>
<citsent citstr=" J80-1003 ">
the results we report here have been obtained in two ways: by extracting relevant information from the tagged brown corpus (francis and ka~era 1982), and by running ~ parser (mccord 1980, <papid> J80-1003 </papid>1990) on the reader digest corpus to extract more accu-rate information on verb usage in text.</citsent>
<aftsection>
<nextsent>1 overview.
</nextsent>
<nextsent>our work illustrates two points: 1.
</nextsent>
<nextsent>inherent lexical properties can be deterufined.
</nextsent>
<nextsent>by applying battery of established hnguistic tests to corpora~ this adds to the utility of corpus analysis dimension beyond coocnr- fence phenomena (e.g. mutual information, substitutability).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F50">
<title id=" C94-2106.xml">a system of verbal semantic attributes focused on the syntactic correspondence between japanese and english </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>when giving verbal semantic attributes to pair of individual japanese and english patterns, it is possible to refer to the meaning of verbs not only in japanese but also in english.
</prevsent>
<prevsent>attributes 3.1 classification standards for.
</prevsent>
</prevsection>
<citsent citstr=" C80-1067 ">
verbal semantic attributes regarding the classification of verbs for use in machine translation, nishida et al (1980) <papid> C80-1067 </papid>proposed system of verbal classification.</citsent>
<aftsection>
<nextsent>this system of classification was introduced to resolve syntactic and semantic ambiguities of english in english to japanese machine translation.
</nextsent>
<nextsent>to this system, they added the semantic attributes of verbs to the patterns of english verbs proposed by hornby (1975) and determined the case structures depending on the combination of these two kinds of information.
</nextsent>
<nextsent>this system of verbal semantic attributes was introduced on the condition that the features of syntactic structures are expressed by hornby patterns of english verbs.
</nextsent>
<nextsent>so, this system of classification focused only on word meaning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F51">
<title id=" C92-2105.xml">self monitoring with reversible grammars </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>but this would blur the distinction between the grammat-ical and the conceptual level, because this would imply that both components share the grammar (see also appelt (1989), meteer (1990), neumann (1991)).
</prevsent>
<prevsent>1 in order to maintain modular design addi-tional mechanisms are necessary to perform some monitoring of the generator output.
</prevsent>
</prevsection>
<citsent citstr=" T87-1041 ">
several authors argue for such additional mechanisms (jameson and wahlster, 1982; de smedt and kempen, 1987; joshi, 1987; <papid> T87-1041 </papid>levelt, 1989).</citsent>
<aftsection>
<nextsent>for example, levelt (1989) pointed out tbat  speak-ers monitor what they are saying and how they are saying it .
</nextsent>
<nextsent>in particular he shows that speaker is also able to note that what she is say-ing involves potential ambiguity for the hearer and can handle this problem by means of self- monitoring.
</nextsent>
<nextsent>in this paper we describe an approach for self-monitoring which allows to generate un-ambiguous utterances in such situations where possible misunderstandings by tire user have to be avoided.
</nextsent>
<nextsent>the proposed method is based on very strict integration of parsing and genera-tion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F52">
<title id=" C96-2138.xml">content oriented categorization of document images </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ocr is major bot-tleneck for information retrieval systems in terms of speed.
</prevsent>
<prevsent>for example, myers and mulgaonkar reported in their ocr-based information extraction system that the total processing time was dominated by char-acter and word recognition processes (myers and mulgaonkar, 1995).
</prevsent>
</prevsection>
<citsent citstr=" C94-1085 ">
this suggests an important ques- tion:  how much nlp can be done without character recognition (church, et al, 1994)? <papid> C94-1085 </papid></citsent>
<aftsection>
<nextsent>as an alternative technique to ocr, there is word shape token processing which converts images into shape-based representation.
</nextsent>
<nextsent>it recognizes coarse character shape classes (character shape codes) rather than character codes.
</nextsent>
<nextsent>because the number of charac-ter shape codes is small and they are defined by sim-ple graphical features, their recognition from images is inexpensive.
</nextsent>
<nextsent>word shape token processing has been proven to be of use for european language iden-tification (nakayama and spitz, 1993; sibun and spitz, 1994).<papid> A94-1003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F53">
<title id=" C96-2138.xml">content oriented categorization of document images </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it recognizes coarse character shape classes (character shape codes) rather than character codes.
</prevsent>
<prevsent>because the number of charac-ter shape codes is small and they are defined by sim-ple graphical features, their recognition from images is inexpensive.
</prevsent>
</prevsection>
<citsent citstr=" A94-1003 ">
word shape token processing has been proven to be of use for european language iden-tification (nakayama and spitz, 1993; sibun and spitz, 1994).<papid> A94-1003 </papid></citsent>
<aftsection>
<nextsent>also, its feasibility for content charac-terization has been discussed with the use of con-trolled (noise-free) on-line dataset (nakayama, 1994; <papid> A94-1004 </papid>nakayama 1995; sibun and farrar, 1994).<papid> C94-2108 </papid></nextsent>
<nextsent>however, no analysis has been done with real document images, which are usually degraded in quality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F54">
<title id=" C96-2138.xml">content oriented categorization of document images </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>because the number of charac-ter shape codes is small and they are defined by sim-ple graphical features, their recognition from images is inexpensive.
</prevsent>
<prevsent>word shape token processing has been proven to be of use for european language iden-tification (nakayama and spitz, 1993; sibun and spitz, 1994).<papid> A94-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" A94-1004 ">
also, its feasibility for content charac-terization has been discussed with the use of con-trolled (noise-free) on-line dataset (nakayama, 1994; <papid> A94-1004 </papid>nakayama 1995; sibun and farrar, 1994).<papid> C94-2108 </papid></citsent>
<aftsection>
<nextsent>however, no analysis has been done with real document images, which are usually degraded in quality.
</nextsent>
<nextsent>in addition, comparative valuation between the word shape token-based and the ocr-based approach is needed.
</nextsent>
<nextsent>we have developed technique which automati-cally categorizes document images into pre-defined classes based on their content.
</nextsent>
<nextsent>it employs vector space classifier drawn from many robust statistical techniques in information retrieval (see salton, 1991).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F55">
<title id=" C96-2138.xml">content oriented categorization of document images </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>because the number of charac-ter shape codes is small and they are defined by sim-ple graphical features, their recognition from images is inexpensive.
</prevsent>
<prevsent>word shape token processing has been proven to be of use for european language iden-tification (nakayama and spitz, 1993; sibun and spitz, 1994).<papid> A94-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" C94-2108 ">
also, its feasibility for content charac-terization has been discussed with the use of con-trolled (noise-free) on-line dataset (nakayama, 1994; <papid> A94-1004 </papid>nakayama 1995; sibun and farrar, 1994).<papid> C94-2108 </papid></citsent>
<aftsection>
<nextsent>however, no analysis has been done with real document images, which are usually degraded in quality.
</nextsent>
<nextsent>in addition, comparative valuation between the word shape token-based and the ocr-based approach is needed.
</nextsent>
<nextsent>we have developed technique which automati-cally categorizes document images into pre-defined classes based on their content.
</nextsent>
<nextsent>it employs vector space classifier drawn from many robust statistical techniques in information retrieval (see salton, 1991).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F56">
<title id=" C96-2147.xml">zero pronoun resolution in japanese discourse based on centering theory </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>mtl(me(lelfl;s of zoa pronouns.
</prevsent>
<prevsent>l{,(;ccntly thor( ~.
</prevsent>
</prevsection>
<citsent citstr=" J94-2003 ">
have t)(~cn ~t lllllnl)(;r of works (;ha.t mo(lcl tim (zca o) pronoun rt!solution with chc (;on( x~.t)(, calh:d  (;()itl;( .r (grosz (.q; a,l., 11995; ih cn- nan el; al., 1!)87; -walker et al, 1994; <papid> J94-2003 </papid>kamo.ymna., !)86).</citsent>
<aftsection>
<nextsent>~i ilc co, ill;(willp~ i;h( ,ory lr ios l;() iden(;i(y die ;tai|;(x ,( ,(1oll|, of ;t (zero) i)rollotllt l)y im i(te~ t;llm; |;lw.
</nextsent>
<nextsent>ondl;y |;hal; a, s(~ilto, ll(;e itlos(; centrally con- (:(!rns(ctmi;(:r) (;ends (;o 1)(: (;xl)rcss(:d by (zt:r()) pronoun.
</nextsent>
<nextsent>tim (:entering t;hoory has tit(: follow-ing adwmtagcs.
</nextsent>
<nextsent>because it uses only the mlr- ftu:( , information in sent(races and does not n(:cd huge amount of common sense knowledge to rc- solvo (zero) pronouns, it is easy to implem(:nt i|; on computer syst(:ms. secondly, it; cmt bc appli(:d to many languages(grosz (:1; al., 1995; walk(!r (!t al., \] 994).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F57">
<title id=" C96-2147.xml">zero pronoun resolution in japanese discourse based on centering theory </title>
<section> two versions of the centering.  </section>
<citcontext>
<prevsection>
<prevsent>the set of cfs is ordered by their grammatical properties which are considered to reflect their degrees of salience.
</prevsent>
<prevsent>the centering theory specifies the following (heuristic) rule: if the cb of the current sentence is the same as the cb of the previous sentence, (zero) pronoun should be used.
</prevsent>
</prevsection>
<citsent citstr=" P86-1031 ">
there are two versions of the centering theory that have been applied to japanese zero pronoun resolution: kameyama s(kameyama, 1986) <papid> P86-1031 </papid>and walker s(walker et al, 1994).<papid> J94-2003 </papid></citsent>
<aftsection>
<nextsent>roughly both ver-sions use the following same forward center rank-ing for japanese: topic   empathy   subject   object2   object   others, where empathy is grammatical property that in-dicates the speaker position in describing situ-ation.
</nextsent>
<nextsent>in addition to the above rule, kameyama version uses the property sharing constraint hat two zero pronouns in adjacent sentences, which co-specify the same cb, should share one of the grammatical properties.
</nextsent>
<nextsent>this constraint is used for ranking discourse ntities in the order of pref-erence as the antecedent of zero pronoun.
</nextsent>
<nextsent>walker version, on the other hand, uses the following additional rules and constraint: ? constraint for each sentence ui: the center, cb(ui), is the highest- ranked element of i (\[7/-1) that ap-pears in ui.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F59">
<title id=" C96-2147.xml">zero pronoun resolution in japanese discourse based on centering theory </title>
<section> p rocess ing  complex  sentences   </section>
<citcontext>
<prevsection>
<prevsent>however, it is necessary to handle complex sentences that are prevalent in naturally occurring discourses with the centering algorithms.
</prevsent>
<prevsent>we can think of (at least) two ways to handle complex sentences.
</prevsent>
</prevsection>
<citsent citstr=" J94-2006 ">
for instance, consider process-ing complex sentence of the form  sx conj sy,  where sx and sy each consists of simple sen-tence and conj is conjunctive lement(suri and mccoy, 1994) <papid> J94-2006 </papid>1.</citsent>
<aftsection>
<nextsent>one can imagine processing sx first and then sy as if they are linear sequence of simple sentences and applying the centering the-ory to each sentence successively and updating the data structures for centering.
</nextsent>
<nextsent>on the other hand, the whole sentence can be treated as single unit.
</nextsent>
<nextsent>this approach, how- ever, has two problems.
</nextsent>
<nextsent>first, the intrasenten- tial ellipsis that the antecedent exists in the same sentence 9 cannot be handled with the centering theory, because the centering theory only han-dles the inter sentential lipsis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F60">
<title id=" C96-2147.xml">zero pronoun resolution in japanese discourse based on centering theory </title>
<section> experiment  and  iscuss ion.  </section>
<citcontext>
<prevsection>
<prevsent>and nishizaw~, 1994; onhil\[lol;o, \],(js(i; sill all(l nicc()y, 1994:).
</prevsent>
<prevsent>t/e- c.mme n;,kaiw~ds(nakaiwa.
</prevsent>
</prevsection>
<citsent citstr=" C94-2107 ">
mtd lkehara., 1992)mm na.kagawa s(nakagawa and nishizawa, 1994) <papid> C94-2107 </papid>a.p- t)ro~w.ht .s use /,he in_forma.l;ion in r(~stricl;(~(l it)- main or ~oo fine-grainc(l grmmna.ti(:al information, we think they are dif\[icult {;o be tune(1 to th( .</citsent>
<aftsection>
<nextsent>1)road cov(~rag(  z(;ro l)ronoun r(;solution system.
</nextsent>
<nextsent>furth( ,r-- more, nakagaw~l and y()shimol,o s(yoslfimol;o, 1986) a.t)t)r()a(:h( ,,q are not; fully ( va.lual;(~d with rea.1 (lis(:om s(~s. although nakniwa ~q)proa(:h ym(ts high ,~;u(:(:( ,ss; rat(; (if 93%, he uses rath(,r small t(!s{, sets(102 ,q(mt;enc(~s from 29 a.rt;icl(~s), and the input, is r(~,qtrm,(~(t ix) th(~ first t)nragrat)hs of newsl)a.l)(~r ~u ti(:h;s. ,qm s work(suri a.u(l m(:coy, \]994) mighl; t)e one of tim few works that extend i;h(; (:(ml,(~rh~/, , i\]a.m(;w()~k 1,() hind(lie (:oml)h .x ,q(\]lll;(~.ll(:(. s, although 8  /5 she handles only sentences ofthe form  sx because sy,  and uses sidner focusing framework(sidner, 1983), that is different from the centering theory that our method is based on.
</nextsent>
<nextsent>purthermore, the effectiveness ofher work is not evaluated with real discourses.
</nextsent>
<nextsent>takada work(t&kada; nd doi, 1994) might be the only exception that proposes the zero pronoun resolution method based on the centering theory and evaluates its effectiveness with real discourses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F61">
<title id=" C96-2147.xml">zero pronoun resolution in japanese discourse based on centering theory </title>
<section> experiment  and  iscuss ion.  </section>
<citcontext>
<prevsection>
<prevsent>since he handles not only zero pronouns but also overt pronouns, the exact comparison is difficult, but his approach, that is based on kameyama approach, yields the performance of 74.8% if the results for overt pronouns are excluded.
</prevsent>
<prevsent>in addi-tion, to handle complex sentences, he adopts the other approach where they are treated as single unit, and admits that some problems arise because of this approach.
</prevsent>
</prevsection>
<citsent citstr=" P93-1009 ">
taking into account the information of conjunc- tive elements in the pronoun resolution reminds us of the works that use the establishment of coher-ence relations between clauses for pronoun reso- lution(hobbs, 1979; kehler, 1993).<papid> P93-1009 </papid></citsent>
<aftsection>
<nextsent>they try to establish coherence relations by the costly infer-ence, while we use only the surface information.
</nextsent>
<nextsent>in this paper, we presented simple method to handle complex sentences with the centering the-ory and described our framework that can identify the antecedents of zero pronouns in naturally oc-curring japanese discourses.
</nextsent>
<nextsent>we also presented tile evaluation of our framework with real dis-courses, although the evaluation is not so large- scale to assert he effectiveness of our framework.
</nextsent>
<nextsent>our simple method yielded the accuracy of 78% for the zero pronoun resolution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F62">
<title id=" C96-2101.xml">goal formulation based on communicative principles </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>contributions are planned as reactions to the changing context, and no dialogue grammar is needed.
</prevsent>
<prevsent>also speech act classification is aban-doned, in favour of contextual reasoning and rationality considerations.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
two general approaches can be distinguished in dialogue management: the structural approach, which uses dialogue grammar to capture regu-larities of the dialogue in terms of exchanges and moves (bilange, 1992; cawsey, 1993; grosz and sidner, 1986), <papid> J86-3001 </papid>and the intention-based approach, which classifies the speaker beliefs and intentions into speech acts, and uses planning operators to describe them (appel% 1985; allen and perrault, 1980; bunt et al, 1984).</citsent>
<aftsection>
<nextsent>both regard natural an- guage as purposeful behaviour, but differ in how this behaviour is to be described.
</nextsent>
<nextsent>the former sees dialogues as products and compiles participants  beliefs and intentions into predefined ialogue structure, whereas the latter focusses on the par-ticipants  goals, and hides the structure in there- lations between acts which contain appropriately chosen sets of beliefs and intentions as their pre-conditions and effects.
</nextsent>
<nextsent>we will not go into detailed evaluation of the approaches, ee e.g.
</nextsent>
<nextsent>(jokinen, 1994), but draw at-tention to three aspects of dialogues which have *i am grateful to yuji matsumoto for providing an excellent resem ch environment during my jsps post-doctoral fellowship, and graham wilcock for helpful discussions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F63">
<title id=" C96-2143.xml">a computational model for generating referring expressions in a multilingual application domain </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>
<prevsent>this repre-sents the primary focus of un and links the current sentence with the previous discourse.
</prevsent>
<prevsent>the basic constraint on center ealization is for-mulated in the following rules: rule 1 : if any element of cf(u,~) is realized by pronoun in u,+i then the cb(u,~+i) must be realized by pronoun also.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
(grosz et al, 1995) <papid> J95-2003 </papid>rule 1  : if an element in cf(un+i) is coref- erent with cp(u,~) then it can be pronominalized.</citsent>
<aftsection>
<nextsent>(kehler, 1993) these rules can be used to constrain pronominal- ization in the text generation process.
</nextsent>
<nextsent>the centering model was first conceived for en-glish, language where pronouns are always made explicit.
</nextsent>
<nextsent>but as soon as we consider languages that allow null pronominmization (like italian) new extensions to the original model have to be designed in order to deal with pronouns with no phonetic ontent.
</nextsent>
<nextsent>for italian, we defined the fol-lowing rule (not and zancanaro, 1996) which is compatible with the results of empirical research presented in (di eugenio, 1995): rule 1  : if the cb of the current utter-ance (cb(u,,+i)) is the same as the cp of the previous utterance (cp(u~)) then null pronoun should be used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F64">
<title id=" C96-2119.xml">automatic englishtokorean text translation of telegraphic messages in a limited domain </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the process flow of our text translation system is given in figure 2.
</prevsent>
<prevsent>2.1 language understanding.
</prevsent>
</prevsection>
<citsent citstr=" J92-1004 ">
the language understanding system, tina, described at length in (seneff, 1992), <papid> J92-1004 </papid>integrates key ideas fi onl context free grmmnar, augmented transition etwork and unification concepts.</citsent>
<aftsection>
<nextsent>with the context fi ee granunar rules of fnglish as input, the system produces the parse tree of an inlmt sen-tence.
</nextsent>
<nextsent>the parse tree is then mapped onto semantic frame., which plays the role of an interlingua.
</nextsent>
<nextsent>the parse tree and the semantic frame of the input sentence  0819 uss sterett 3refer to (kim, 1994) for other ongoing efforts in en- glish/korean text translation im;luding (choi, 1994).
</nextsent>
<nextsent>see (lee, 1995) for speech translation work with korean as the source language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F65">
<title id=" C96-1037.xml">aligning more words with high precision for small bilingual corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we found that the algorithm can align over 80% of word pairs while maintaining comparably high precision rate, even when small corpus was used in .training.
</prevsent>
<prevsent>the algorithm also poses the advantage of producing tagged corpus for word sense disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
brown et al (1990) <papid> J90-2002 </papid>initiated much of the recent interest in bilingual corpora.</citsent>
<aftsection>
<nextsent>they advocated applying statistical approach to machine translation (smt).
</nextsent>
<nextsent>the smt approach can be understood as word by word model consisting of two submodels: language model for generating source text segment stand translation model for translating st to target ext segment tt.
</nextsent>
<nextsent>they recommended using an aligned bilingual corpus to estimate the parameters of translation probability, pr(st \[tt) in the translation model.
</nextsent>
<nextsent>the resolution of alignment can vat3, from low to high: section, paragraph, sentence, phrase, and word (gale and church 1993; <papid> J93-1004 </papid>matsumoto et al 1993).<papid> P93-1004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F67">
<title id=" C96-1037.xml">aligning more words with high precision for small bilingual corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the smt approach can be understood as word by word model consisting of two submodels: language model for generating source text segment stand translation model for translating st to target ext segment tt.
</prevsent>
<prevsent>they recommended using an aligned bilingual corpus to estimate the parameters of translation probability, pr(st \[tt) in the translation model.
</prevsent>
</prevsection>
<citsent citstr=" J93-1004 ">
the resolution of alignment can vat3, from low to high: section, paragraph, sentence, phrase, and word (gale and church 1993; <papid> J93-1004 </papid>matsumoto et al 1993).<papid> P93-1004 </papid></citsent>
<aftsection>
<nextsent>in addition to machine translation, many applications tbr aligped corpora have been proposed, including bilingual lexicography (gale and church 199l, smadja 1992, dallie, gaussier and lange 1994), and word-sense disambiguation (gale, church and yarowsky 1992, chen and chang 1994).
</nextsent>
<nextsent>in the context of statistical machine translation, brown et al (1993) <papid> J93-2003 </papid>presented series of five models for pr(st \[tt).</nextsent>
<nextsent>the first two models have been used in research on word alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F68">
<title id=" C96-1037.xml">aligning more words with high precision for small bilingual corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the smt approach can be understood as word by word model consisting of two submodels: language model for generating source text segment stand translation model for translating st to target ext segment tt.
</prevsent>
<prevsent>they recommended using an aligned bilingual corpus to estimate the parameters of translation probability, pr(st \[tt) in the translation model.
</prevsent>
</prevsection>
<citsent citstr=" P93-1004 ">
the resolution of alignment can vat3, from low to high: section, paragraph, sentence, phrase, and word (gale and church 1993; <papid> J93-1004 </papid>matsumoto et al 1993).<papid> P93-1004 </papid></citsent>
<aftsection>
<nextsent>in addition to machine translation, many applications tbr aligped corpora have been proposed, including bilingual lexicography (gale and church 199l, smadja 1992, dallie, gaussier and lange 1994), and word-sense disambiguation (gale, church and yarowsky 1992, chen and chang 1994).
</nextsent>
<nextsent>in the context of statistical machine translation, brown et al (1993) <papid> J93-2003 </papid>presented series of five models for pr(st \[tt).</nextsent>
<nextsent>the first two models have been used in research on word alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F69">
<title id=" C96-1037.xml">aligning more words with high precision for small bilingual corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the resolution of alignment can vat3, from low to high: section, paragraph, sentence, phrase, and word (gale and church 1993; <papid> J93-1004 </papid>matsumoto et al 1993).<papid> P93-1004 </papid></prevsent>
<prevsent>in addition to machine translation, many applications tbr aligped corpora have been proposed, including bilingual lexicography (gale and church 199l, smadja 1992, dallie, gaussier and lange 1994), and word-sense disambiguation (gale, church and yarowsky 1992, chen and chang 1994).</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
in the context of statistical machine translation, brown et al (1993) <papid> J93-2003 </papid>presented series of five models for pr(st \[tt).</citsent>
<aftsection>
<nextsent>the first two models have been used in research on word alignment.
</nextsent>
<nextsent>model 1 assumes that pr(st\[tt) depends only on lexical translation probability t(s t), i.e., the probability of the i-th word in st producing the j-th word in tt as its translation.
</nextsent>
<nextsent>the pair of words (s, t) is called connection.
</nextsent>
<nextsent>model 2 enhances model 1 by considering the dependence of pr(st itt) on the distortion probability, d(i j, 1, m) where and are the numbers of words in stand tt, respectively.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F72">
<title id=" C96-1037.xml">aligning more words with high precision for small bilingual corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the authors claimed that 60.5% of 65,000 words in the document were correctly aligned.
</prevsent>
<prevsent>for 84% of the words, the offset from correct alignment was at most 3.
</prevsent>
</prevsection>
<citsent citstr=" H91-1026 ">
motivated by the need to reduce on the memory requirement and to insure robustness in estimation of probability, gale and church (1991) <papid> H91-1026 </papid>proposed an alternative algorithm in which probabilities are not estimated and stored for all word pairs.</citsent>
<aftsection>
<nextsent>instead, only strongly associated word pairs are ibund and stored.
</nextsent>
<nextsent>this is achieved by applying do 2 test, x~-like statistic.
</nextsent>
<nextsent>the extracted word pairs are used to match words in stand tt.
</nextsent>
<nextsent>the algorithm works from left to right in st, using dynamic programming procedure to maximize pr(st itt).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F74">
<title id=" C96-1037.xml">aligning more words with high precision for small bilingual corpora </title>
<section> discussions.  </section>
<citcontext>
<prevsection>
<prevsent>this generally corresponds to the results from recent work on variety of tasks such as terminology extraction and structural disambiguation.
</prevsent>
<prevsent>dallie, gaussier and lange (1994) demonstrated that simple criteria related to frequency coupled with linguistic filter works better than mutual information tbr terminology extraction.
</prevsent>
</prevsection>
<citsent citstr=" C94-2195 ">
recent work involving structural disambiguation (brill and resnik 1994) <papid> C94-2195 </papid>also indicated that statistics related to frequency outperform utual intbrmation and q~2 statistic.</citsent>
<aftsection>
<nextsent>this paper has presented an algorithm capable of identit~,ing words and their translation in bilingual corpus.
</nextsent>
<nextsent>it is effective for specific linguistic reasons.
</nextsent>
<nextsent>the significant majority of words in bilingual sentences have diverging translation; those translations are not often tbund in bilingual dictionaly.
</nextsent>
<nextsent>however, those deviation are largely limited within the classes defined by thesauri.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F75">
<title id=" C96-1095.xml">towards a more careful evaluation of broad coverage parsing systems </title>
<section> introduction.  </section>
<citcontext>
<prevsection>

<prevsent>during the last few years large treebanks have be- come available to many researchers, which has re-sulted in researches applying range of new tech-niques for parsing systems.
</prevsent>
</prevsection>
<citsent citstr=" P93-1005 ">
most of the meth-ods that are being suggested include some kind of machine learning, such as history based gram-mars and decision tree models (black et al, 1993; <papid> P93-1005 </papid>magerman, 1995), <papid> P95-1037 </papid>training or inducing statisti-cal grammars (black, garside and leech, 1993; pereira and schabes, 1992; <papid> P92-1017 </papid>schabes et al, 1993), <papid> E93-1040 </papid>or other techniques (bod, 1993).<papid> E93-1006 </papid></citsent>
<aftsection>
<nextsent>consequently, syntactical analysis has become an area with wide variety of (a) algorithms and methods for learning and parsing, and (b) type of information used for learning and parsing (some- times referred to as feature set).
</nextsent>
<nextsent>these meth-ods only could become popular through evalua-tion methods for parsing systems, such as bracket accuracy, bracket recall, sentence accuracy and viterbi score.
</nextsent>
<nextsent>some of them were introduced in (black et al, 1991; <papid> H91-1060 </papid>harrison et m., 1991).</nextsent>
<nextsent>these evaluation metrics have number of problems, and in this paper we argue that they need to be reconsidered, and give number of suggestions either to overcome those problems or to gain better understanding of those prob- lems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F76">
<title id=" C96-1095.xml">towards a more careful evaluation of broad coverage parsing systems </title>
<section> introduction.  </section>
<citcontext>
<prevsection>

<prevsent>during the last few years large treebanks have be- come available to many researchers, which has re-sulted in researches applying range of new tech-niques for parsing systems.
</prevsent>
</prevsection>
<citsent citstr=" P95-1037 ">
most of the meth-ods that are being suggested include some kind of machine learning, such as history based gram-mars and decision tree models (black et al, 1993; <papid> P93-1005 </papid>magerman, 1995), <papid> P95-1037 </papid>training or inducing statisti-cal grammars (black, garside and leech, 1993; pereira and schabes, 1992; <papid> P92-1017 </papid>schabes et al, 1993), <papid> E93-1040 </papid>or other techniques (bod, 1993).<papid> E93-1006 </papid></citsent>
<aftsection>
<nextsent>consequently, syntactical analysis has become an area with wide variety of (a) algorithms and methods for learning and parsing, and (b) type of information used for learning and parsing (some- times referred to as feature set).
</nextsent>
<nextsent>these meth-ods only could become popular through evalua-tion methods for parsing systems, such as bracket accuracy, bracket recall, sentence accuracy and viterbi score.
</nextsent>
<nextsent>some of them were introduced in (black et al, 1991; <papid> H91-1060 </papid>harrison et m., 1991).</nextsent>
<nextsent>these evaluation metrics have number of problems, and in this paper we argue that they need to be reconsidered, and give number of suggestions either to overcome those problems or to gain better understanding of those prob- lems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F77">
<title id=" C96-1095.xml">towards a more careful evaluation of broad coverage parsing systems </title>
<section> introduction.  </section>
<citcontext>
<prevsection>

<prevsent>during the last few years large treebanks have be- come available to many researchers, which has re-sulted in researches applying range of new tech-niques for parsing systems.
</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
most of the meth-ods that are being suggested include some kind of machine learning, such as history based gram-mars and decision tree models (black et al, 1993; <papid> P93-1005 </papid>magerman, 1995), <papid> P95-1037 </papid>training or inducing statisti-cal grammars (black, garside and leech, 1993; pereira and schabes, 1992; <papid> P92-1017 </papid>schabes et al, 1993), <papid> E93-1040 </papid>or other techniques (bod, 1993).<papid> E93-1006 </papid></citsent>
<aftsection>
<nextsent>consequently, syntactical analysis has become an area with wide variety of (a) algorithms and methods for learning and parsing, and (b) type of information used for learning and parsing (some- times referred to as feature set).
</nextsent>
<nextsent>these meth-ods only could become popular through evalua-tion methods for parsing systems, such as bracket accuracy, bracket recall, sentence accuracy and viterbi score.
</nextsent>
<nextsent>some of them were introduced in (black et al, 1991; <papid> H91-1060 </papid>harrison et m., 1991).</nextsent>
<nextsent>these evaluation metrics have number of problems, and in this paper we argue that they need to be reconsidered, and give number of suggestions either to overcome those problems or to gain better understanding of those prob- lems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F78">
<title id=" C96-1095.xml">towards a more careful evaluation of broad coverage parsing systems </title>
<section> introduction.  </section>
<citcontext>
<prevsection>

<prevsent>during the last few years large treebanks have be- come available to many researchers, which has re-sulted in researches applying range of new tech-niques for parsing systems.
</prevsent>
</prevsection>
<citsent citstr=" E93-1040 ">
most of the meth-ods that are being suggested include some kind of machine learning, such as history based gram-mars and decision tree models (black et al, 1993; <papid> P93-1005 </papid>magerman, 1995), <papid> P95-1037 </papid>training or inducing statisti-cal grammars (black, garside and leech, 1993; pereira and schabes, 1992; <papid> P92-1017 </papid>schabes et al, 1993), <papid> E93-1040 </papid>or other techniques (bod, 1993).<papid> E93-1006 </papid></citsent>
<aftsection>
<nextsent>consequently, syntactical analysis has become an area with wide variety of (a) algorithms and methods for learning and parsing, and (b) type of information used for learning and parsing (some- times referred to as feature set).
</nextsent>
<nextsent>these meth-ods only could become popular through evalua-tion methods for parsing systems, such as bracket accuracy, bracket recall, sentence accuracy and viterbi score.
</nextsent>
<nextsent>some of them were introduced in (black et al, 1991; <papid> H91-1060 </papid>harrison et m., 1991).</nextsent>
<nextsent>these evaluation metrics have number of problems, and in this paper we argue that they need to be reconsidered, and give number of suggestions either to overcome those problems or to gain better understanding of those prob- lems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F79">
<title id=" C96-1095.xml">towards a more careful evaluation of broad coverage parsing systems </title>
<section> introduction.  </section>
<citcontext>
<prevsection>

<prevsent>during the last few years large treebanks have be- come available to many researchers, which has re-sulted in researches applying range of new tech-niques for parsing systems.
</prevsent>
</prevsection>
<citsent citstr=" E93-1006 ">
most of the meth-ods that are being suggested include some kind of machine learning, such as history based gram-mars and decision tree models (black et al, 1993; <papid> P93-1005 </papid>magerman, 1995), <papid> P95-1037 </papid>training or inducing statisti-cal grammars (black, garside and leech, 1993; pereira and schabes, 1992; <papid> P92-1017 </papid>schabes et al, 1993), <papid> E93-1040 </papid>or other techniques (bod, 1993).<papid> E93-1006 </papid></citsent>
<aftsection>
<nextsent>consequently, syntactical analysis has become an area with wide variety of (a) algorithms and methods for learning and parsing, and (b) type of information used for learning and parsing (some- times referred to as feature set).
</nextsent>
<nextsent>these meth-ods only could become popular through evalua-tion methods for parsing systems, such as bracket accuracy, bracket recall, sentence accuracy and viterbi score.
</nextsent>
<nextsent>some of them were introduced in (black et al, 1991; <papid> H91-1060 </papid>harrison et m., 1991).</nextsent>
<nextsent>these evaluation metrics have number of problems, and in this paper we argue that they need to be reconsidered, and give number of suggestions either to overcome those problems or to gain better understanding of those prob- lems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F80">
<title id=" C96-1095.xml">towards a more careful evaluation of broad coverage parsing systems </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>consequently, syntactical analysis has become an area with wide variety of (a) algorithms and methods for learning and parsing, and (b) type of information used for learning and parsing (some- times referred to as feature set).
</prevsent>
<prevsent>these meth-ods only could become popular through evalua-tion methods for parsing systems, such as bracket accuracy, bracket recall, sentence accuracy and viterbi score.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
some of them were introduced in (black et al, 1991; <papid> H91-1060 </papid>harrison et m., 1991).</citsent>
<aftsection>
<nextsent>these evaluation metrics have number of problems, and in this paper we argue that they need to be reconsidered, and give number of suggestions either to overcome those problems or to gain better understanding of those prob-lems.
</nextsent>
<nextsent>particular problems we look at are arbi-trary choices in the treebank, errors in the tree- bank, types of errors made by parsers, and the statistical significance of differences in test scores by parsers.
</nextsent>
<nextsent>metrics until now number of problems with evaluation have been pointed out.
</nextsent>
<nextsent>one well known prob-lem is that measures based only on the absence of crossing errors on sentence level, such as sen-tence accuracy and viterbi consistency, are not usable for parsing systems that apply partial bracketing, since sparse bracketing improves the score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F81">
<title id=" C94-1017.xml">perspectives of dbmt for monolingual authors on the basis of lidia1 an implemented mockup </title>
<section> towards an operational prototype.  </section>
<citcontext>
<prevsection>
<prevsent>the idea of the interactive clarilication approach in the context of natural language processing seems now to interest real cotmnunity.
</prevsent>
<prevsent>for mt, the current work of \[wehrli 1993\], \[yamaguchi, et al 1993\], atul lhc ongoing work on jets \[tsutsumi, et al 199311 arc some good examples.
</prevsent>
</prevsection>
<citsent citstr=" C92-3165 ">
for speech systems, tile interactive clarification approach is also solution as shown iu \[fraukish, et al 1992\] and proposed in \[ainsworth &amp; pratt 1992\] and \[saito 1992\].<papid> C92-3165 </papid></citsent>
<aftsection>
<nextsent>as far as 1he tlture is concerned, we have begun to study multimodal interactive disambiguation with atr-itl in more general framework than 1,1dia-1.
</nextsent>
<nextsent>we hope to gel adequate support r}r developing more larger-scale prototype in the next few years.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F82">
<title id=" C92-3145.xml">a freely available wide coverage morphological analyzer for english </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>each format contains the morphological information for over 317000 english words.
</prevsent>
<prevsent>the morphological database for english runs under unix; pc-kimmo runs under unix and on pc.
</prevsent>
</prevsection>
<citsent citstr=" A92-1030 ">
this package can be easily embedded into natural language parser; hooks for accessing the morphological database from parser are provided for both lucid common lisp and c. this morphological database is currently being used in graphical workbench (xtag) for the development of tree-adjoining rammars and their parsers (paroubek et al, 1992).<papid> A92-1030 </papid></citsent>
<aftsection>
<nextsent>morphological analysis has experienced great suc-cess since the introduction of two-level morphology (koskenniemi, 1983; karttunen, 1983).
</nextsent>
<nextsent>two-level mor-phology and its implementation are now well under- stood both linguistically and eomputationany (kart- tunen, 1983; karttunen and wittenburg, 1983; kosken-niemi, 1985; barton et al, 1987; koskenniemi and church, 1988).<papid> C88-1069 </papid></nextsent>
<nextsent>this computational model has proved to be well suited for many languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F83">
<title id=" C92-3145.xml">a freely available wide coverage morphological analyzer for english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this package can be easily embedded into natural language parser; hooks for accessing the morphological database from parser are provided for both lucid common lisp and c. this morphological database is currently being used in graphical workbench (xtag) for the development of tree-adjoining rammars and their parsers (paroubek et al, 1992).<papid> A92-1030 </papid></prevsent>
<prevsent>morphological analysis has experienced great suc-cess since the introduction of two-level morphology (koskenniemi, 1983; karttunen, 1983).</prevsent>
</prevsection>
<citsent citstr=" C88-1069 ">
two-level mor-phology and its implementation are now well under- stood both linguistically and eomputationany (kart- tunen, 1983; karttunen and wittenburg, 1983; kosken-niemi, 1985; barton et al, 1987; koskenniemi and church, 1988).<papid> C88-1069 </papid></citsent>
<aftsection>
<nextsent>this computational model has proved to be well suited for many languages.
</nextsent>
<nextsent>although there are some proprietary wide coverage morphological n- alyzers for english, to our knowledge those that are freely available provide only very small coverage.
</nextsent>
<nextsent>working from the 1979 edition of the collins dic-tionary of the english language available through acl-dci (liberman, 1989), <papid> H89-2024 </papid>we constructed lexicons for pc-kimmo (antworth, 1990), public domain implementation of two-level processor.</nextsent>
<nextsent>using the morphological rules for english inflections provided by karttunen and wittenburg (1983) and our lexicons, pc-kimmo outputs all possible analyses of each in- put word, giving its root form and its inflectional *this work was partially supported by darpa grant n0014- 90-31863, aro grant daal03-89-c-0031, and nsf grant ipd90-16592.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F84">
<title id=" C92-3145.xml">a freely available wide coverage morphological analyzer for english </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this computational model has proved to be well suited for many languages.
</prevsent>
<prevsent>although there are some proprietary wide coverage morphological n- alyzers for english, to our knowledge those that are freely available provide only very small coverage.
</prevsent>
</prevsection>
<citsent citstr=" H89-2024 ">
working from the 1979 edition of the collins dic-tionary of the english language available through acl-dci (liberman, 1989), <papid> H89-2024 </papid>we constructed lexicons for pc-kimmo (antworth, 1990), public domain implementation of two-level processor.</citsent>
<aftsection>
<nextsent>using the morphological rules for english inflections provided by karttunen and wittenburg (1983) and our lexicons, pc-kimmo outputs all possible analyses of each in- put word, giving its root form and its inflectional *this work was partially supported by darpa grant n0014- 90-31863, aro grant daal03-89-c-0031, and nsf grant ipd90-16592.
</nextsent>
<nextsent>we thank aravind joshl for his support for this work.
</nextsent>
<nextsent>we also thank evan ant worth, mark fo~ter, laur~ kart-tunen, mark liberman, and annie zaenen for their help and suggestions.
</nextsent>
<nextsent>visiting from stanford university.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F85">
<title id=" C94-1029.xml">multitape two level morphology a case study in semitic nonlinear morphology </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>\[puhnan and hepi)le 1993\] prol)osed formalism for bidirectional segmental phonological processing, and i)roposed using it for arabic.
</prevsent>
<prevsent>the next subsection presents the develoi)ment of this formalism.
</prevsent>
</prevsection>
<citsent citstr=" E87-1003 ">
3.3 rev ious formal sms \[black et al. 1987\] <papid> E87-1003 </papid>pointed out ttmt previous two-level rules (cf.</citsent>
<aftsection>
<nextsent>,~a.1) affect one character at time and pro-posed formalism wtfich maps tletween (equal ram  bered) sequences of surface and lexical characters of the form, surf ~ lex alnidal consonant clusters, cc, take prosthetic /pi/.
</nextsent>
<nextsent>a lexical t ing maps l;o sllrfaee slring iff they can be partitioned into pairs of lexical-sm fi~ce, sub- sequences, wtmre each pair is licenced i)y rule.
</nextsent>
<nextsent>\[l\].uessink 1989\] added explicit contexts and allowed unequal sequences.
</nextsent>
<nextsent>\[puhnan and iiepple 19931 (level- oiled the ormalism further, allowing feature-based rep-resentations interpreted via unification.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F86">
<title id=" C96-1014.xml">integrating syntactic and prosodic information for the efficient detection of empty categories </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the output of the parser is the seman-tic representation for the best string hypothesis in the lattice.
</prevsent>
<prevsent>it is our main result that prosodic informa-tion can be employed in such system to de-termine possible locations for empty elements in tile input.
</prevsent>
</prevsection>
<citsent citstr=" P90-1003 ">
rather than treating prosodic informa-tion as virtual input items which have to match an appropriate category in tile grammar rules (bear&price;, 1990), <papid> P90-1003 </papid>or which by virtue of being  unknown  in the grammar force the parser to close off the current phrase (marcus&hindle;, 1990), our parser employs prosodic information as affecting the postulation of empty elements.</citsent>
<aftsection>
<nextsent>clause structure \[\[psg makes crucial use of  head traces  to ana-lyze the verb-second (v2) phenomenon pertinent in german, i.e. the fact that finite verbs appear in second position in main clauses but in final posi-tion insubordinate clauses, as exemplified in (la) and (lb).
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>(a) gestern reparierte den wagen.
</nextsent>
<nextsent>(yesterday fixed he the car)  yesterday, he fixed the car.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F88">
<title id=" C94-1079.xml">principar  an efficient broad coverage principle based parser </title>
<section> parsing by message passing.  </section>
<citcontext>
<prevsection>
<prevsent>table 1 lists the parsing time and the number of parses for several ex-ample sentences.
</prevsent>
<prevsent>the correct parses for all the sentences in tm)le 1 are returned by the parser.
</prevsent>
</prevsection>
<citsent citstr=" P92-1024 ">
even though the lexicon is derived from ma-chine readable dictionaries and contains \]a.rge number of senses for many words, the ratio be-tween the number of parse trees and the sen-tence length here is well bellow the ratio re-ported in (black et al , 1992).<papid> P92-1024 </papid></citsent>
<aftsection>
<nextsent>acknowledgements the author wishes to thanl?
</nextsent>
<nextsent>bonnie dorr for comments about sections 1, 2, and 3.
</nextsent>
<nextsent>this re - search was supported by naturm sciences and engineering research council of canada grant ogp121338.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F89">
<title id=" C96-2151.xml">handling sparse data by successive abstraction </title>
<section> examples  rom pos  tagging.  </section>
<citcontext>
<prevsection>
<prevsent>,wn) k=l 1:=1 p(tk tk -n+i , . . .
</prevsent>
<prevsent>,tk -1 ; vizk) ? 7   .p(t~ wk) p(tk ~k-n+l , . . .
</prevsent>
</prevsection>
<citsent citstr=" J88-1003 ">
, - ) \[ k=l l p(tk p(t,) tk-n+~,..., ~-~)  p(wk tk) ~:~ p(wk) since the maximum does not depend on the fac-tors p(wk), these can be omitted, yielding the standard statistical pos tagging task: max \]-\[ p(tk iu~-~v+~,...,tk-j.p(wk jt~) ti ,...,t~, t~l= this is well-described in for example (derose 1988).<papid> J88-1003 </papid></citsent>
<aftsection>
<nextsent>we thus have to estimate the two following sets of probabilities: ? lexical probabi i ies : the probability of each tag i conditional on the word that is to be tagged, p(r  i wr!
</nextsent>
<nextsent>i often the converse probabilities p(w are given instead, but we will for reasons oou to become apparent use the former formula-tion.
</nextsent>
<nextsent>tag n-grams: the probability of tag i at position in the input string, denoted t~, given that tags 7~.-n+1 , . . .
</nextsent>
<nextsent>, k-1 have been assigned to the previous n- 1 words?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F90">
<title id=" C96-1076.xml">modularizing contexted constraints </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>4q ht ,se lexical rules air(!
</prevsent>
<prevsent>simplitied versions of those presented in (polb~rd ~md sag, \]994).
</prevsent>
</prevsection>
<citsent citstr=" C94-2154 ">
449 piion ~ lleben, liebt / \[dl vform ~ bse, fill} i, el subj \[\] rvform bse\] \] ) \[lieben -\] \[aag~ 2t!\]\] { rv,, oambsol } s, , , ,s , , d2 another example of where modular ization might prove useful is in the treatment of typed feature structures presented in (gerdemann and king, 1994).<papid> C94-2154 </papid></citsent>
<aftsection>
<nextsent>their approach produces set of feature structures from satisfiability algorithm such that all of the feature structures have the same shape but the nodes may be labeled by dif-ferent types.
</nextsent>
<nextsent>they then collapse this set down to single feature structure where nodes are labeled with dependent dis junctions of types.
</nextsent>
<nextsent>many of the groups of dis junctions in their feature structures can be made more efficient via modularization.
</nextsent>
<nextsent>a final example is in the compaction algo-rithm for feature structures, presented in (grigith, 1995).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F91">
<title id=" C96-2116.xml">a generalized reconstruction algorithm for ellipsis resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the algorithm we propose implements the second view of ellipsis, by characterizing ellipsis resolution as the specification of relation of (possibly partial) correspondence tween the lexically unrealized head of an elided clause and its arguments and adjuncts as one term of the relation, and the realized head of the antecedent clause and its arguments and adjuncts as the second term.
</prevsent>
<prevsent>the algorithm is generalized procedure for syntactic reconstruction which provides unified way of handling significant variety of ellipsis constructions.
</prevsent>
</prevsection>
<citsent citstr=" J90-4001 ">
it modifies and extends the reconstruction strategy for handling vp ellipsis suggested in lappin and mccord (1990).<papid> J90-4001 </papid></citsent>
<aftsection>
<nextsent>the algorithm covers vp ellipsis, illustrated in 1, pseudo-gapping (in 2), bare ellipsis involving sequences of bare arguments, adjuncts or both (in 3), and gapping (in 4).
</nextsent>
<nextsent>1.
</nextsent>
<nextsent>john completed his paper before he.
</nextsent>
<nextsent>expected to.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F92">
<title id=" C96-2116.xml">a generalized reconstruction algorithm for ellipsis resolution </title>
<section> coverage and implementation of the.  </section>
<citcontext>
<prevsection>
<prevsent>interpreted vp ellipsis tree.
</prevsent>
<prevsent>\[ subj(n) top ndet objcn) iobj(to) objprep vsubconj , subjcn) sccomp ndet objcn) iobj(to) objprep john(l) noun(prop) send(2,l,4,6) verb(fin) the(3) det(det) flower(4) noun(cn) to(5),  to(6) prep(to) mary(6) noun(prop) before(7),  before(9) subconj he(8) noun(pron) send(9,8,11,6) verb(fin) the(l o) det(det) chocolate(11) noun(cn) to(5),  to(6) prep(to) mary(6) noun(prop) the algorithm is currently being re-implemented in prolog to apply to the output of modified itpsg (pollard and sag (1994)) grammar designed to handle ellipsis.
</prevsent>
</prevsection>
<citsent citstr=" E95-1025 ">
we are developing the grammar within the framework of erbach (1995) <papid> E95-1025 </papid>profit system for augmenting prolog with typed feature structures.</citsent>
<aftsection>
<nextsent>the feature structures which the grammar currently generates tbr simple bare argument and bare adjunct ellipsis cases are illustrated by the avm in 7 and 8, respectively (cases of bare adverb ellipsis are discussed in chao (1988) and kcmpson and gabbay (1993)).
</nextsent>
<nextsent>7.
</nextsent>
<nextsent>john gives mary flowers, and.
</nextsent>
<nextsent>chocolates too.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F93">
<title id=" C96-2127.xml">an hpsg based generator for german an experiment in the re usability of linguistic resources </title>
<section> available resources.  </section>
<citcontext>
<prevsection>
<prevsent>instead of list-valued subcat feature the feature args is used.
</prevsent>
<prevsent>the correspondence between (syntactic) arguments anti semantic roles is established by placing the constituent under feature corresponding to its semantic role.
</prevsent>
</prevsection>
<citsent citstr=" H89-1022 ">
thus list manipulation is avoided and the structure corresponds more closely to the input specification (given in language based on spl (kasper, 1989)).<papid> H89-1022 </papid></citsent>
<aftsection>
<nextsent>the non local feature is dropped.
</nextsent>
<nextsent>slash ex-traction is handled differently.
</nextsent>
<nextsent>it should be noted that this entry does not col re-spond exactly to the actual representation the generator, it serves simply to illustrate the basic ideas underlying the transformation.
</nextsent>
<nextsent>the actual implementation additionally allows for ? the specification of arguments via externa macros, accounting for more principled treatment of case assignment, argument re-duction and slash extraction; ? ditferentiation between lexemes and stems to account for treatment of inflection by the morphology component.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F94">
<title id=" C96-2127.xml">an hpsg based generator for german an experiment in the re usability of linguistic resources </title>
<section> available resources.  </section>
<citcontext>
<prevsection>
<prevsent>x2morf augmertts standard two-lewj mor-phology in two ways.
</prevsent>
<prevsent>first, it replaces the contimmtion class mechanism with feature- based word grammar and lexicon.
</prevsent>
</prevsection>
<citsent citstr=" C94-1022 ">
this is an important prerequisite for its use in \[hature-based sentence-level processing system (see trost and matiasek (1994)).<papid> C94-1022 </papid></citsent>
<aftsection>
<nextsent>second, it al-lows for interaction between two-level rules and word grammar facilitating the formulation of rules for non-concatenative morphol.actics like umlaut.
</nextsent>
<nextsent>although the main components to be integrated fulfill re usability requirements (fu being fairly general and modular generation engine, the hpsg grammar being declaratively written resource), integration of these resources into unified sys-tem couhl only be achieved after suitable adap-tation.
</nextsent>
<nextsent>the morphological component of fuf is very restricted.
</nextsent>
<nextsent>thus it needed to be replaced by x2morf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F95">
<title id=" C92-3139.xml">a statistical approach to machine aided translation of terminology banks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the set of roots and their  hand-translation are then used iu compositional translation of the terminology bank.
</prevsent>
<prevsent>one can expect he translation of terminology bank using this approach to be more cost-effective, consistent, and with better closure.
</prevsent>
</prevsection>
<citsent citstr=" J85-1001 ">
existing machine translators work well for limited domains (slocum, 1985).<papid> J85-1001 </papid></citsent>
<aftsection>
<nextsent>wlmn an mt system is transported to another domain, among other things, the domain specific terms have to be acquired and translated before the system can do any reasonable work again (knowles, 1982).
</nextsent>
<nextsent>current ways of handling this porting process are largely manual.
</nextsent>
<nextsent>usually one either gleans domain specific tenns from large amount of document at once and translates them one by one by hand, or translated each unkalown term when it appears.
</nextsent>
<nextsent>l iese previous approaches all involve large amount of effort of more than one person.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F96">
<title id=" C92-3139.xml">a statistical approach to machine aided translation of terminology banks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, anslation of terms on one-for-one basis ires no closure.
</prevsent>
<prevsent>when eneounteruig an unknown term, however similar to known one, the system will not be able to fall softly and produce some kind of reasonably acceptable translation like human translator does.
</prevsent>
</prevsection>
<citsent citstr=" E91-1018 ">
similar consideration motives text-to-speech research on producing pronunciation for an mflulown words through morphological decomposition (black et al 1991).<papid> E91-1018 </papid></citsent>
<aftsection>
<nextsent>this paper reports on project experimenting on new approach to this problem.
</nextsent>
<nextsent>the project involves statistical lexical acquisition from large corpus of document build terminology bank, and automatic extraction of roots from tile tenuinology bank.
</nextsent>
<nextsent>the idea is to perform htmlan translation of these roots and to translate term by composing the translation of its constituent roots.
</nextsent>
<nextsent>this idea is similar to the root- oriented dictiotmry proposed ill (tufts and popescu, 1991).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F97">
<title id=" C96-2144.xml">a constraint based case frame lexicon </title>
<section> the lexicon  arch tec ture.  </section>
<citcontext>
<prevsection>
<prevsent>5.
</prevsent>
<prevsent>semantic constraints that indicate seman-.
</prevsent>
</prevsection>
<citsent citstr=" J85-2001 ">
tic selectional restriction constraints that may resolved using companion ontologi- cal database (again implemented in tfs) in which we model the world by defining se-mantic categories, uch as human, thing, non- living object, living object, etc., along the lines described by nagao et al (1985).<papid> J85-2001 </papid></citsent>
<aftsection>
<nextsent>figure 2 illustrates the simplified form of the constraint-sense mapping of the verb yc (eal).
</nextsent>
<nextsent>a.a va leney changing transtbrmat ions as we have already stated, we encode senses of verbs inactive voice unless verb has an idiomatic usage with obligatory passive, causative and/or 856 reflexive voices.
</nextsent>
<nextsent>2 in order to handle these valency changing transfor-mations, we dellne lexical rules as shown in figure 3.
</nextsent>
<nextsent>input ~ case i,rame refl~.xivi/~,ql(-in: \] rellexive: \[- little ~   t, rellexive:~+ \[  ~ c,,.,~,.~.,,,~,,,/ in: ~- ~ , ~a e (~illl sil v13 ,.~ ~ ~ 1 .i~xicon p~ssbi*ali~,rl ( in:  ~ ~ passive - passive: ~1 i, igure 3: valency transforma.tions using lexical rllles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F98">
<title id=" C94-1077.xml">emergent parsing and generation with generalized chart </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a better strategy is to i)ostulate no specific algo-rithms for parsing or generation or any particular t~k, but instead single uniform computational method from which emerge various types of computation in- eluding parsing and generation dei)ending ui)on vari-ous computational contexts.
</prevsent>
<prevsent>for example, earley deduct iml (pereir:t &amp; warren, 1983) is general procedure for dealing with horn clauses which gives rise to earlcy-like parsing when given context-free grammar and word string as the inlmt.
</prevsent>
</prevsection>
<citsent citstr=" C88-2128 ">
shieber (1988) <papid> C88-2128 </papid>has generalized this method so as to adapt to sentence generation as well.</citsent>
<aftsection>
<nextsent>those nmthods fail to give rise to cllicieut conq)utation for wide variety of contexts, however, because they pre-scribe processing directions such ,~ left-to-right f(jr parsing and bottom-up for generation.
</nextsent>
<nextsent>they also hu:k general way of efficient anfl)iguity l)acking unlimited to context-free grammars.
</nextsent>
<nextsent>hasida (1994a) i)rol)oses more general inference method for clausal form logic l)rograms wtfich accounts for efficient parsing and gen-eration ~m emergent l)hmmmena.
</nextsent>
<nextsent>this mctho(l pre-scribes no fixed processing directions, and the way it packs ambiguity is not specific to context-free gnun- mare.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F99">
<title id=" C96-1081.xml">a sign expansion approach to dynamic multipurpose lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in many cases, it also clutters the lexicon structure, so that important lexical relationships and gener-alizations are lost.
</prevsent>
<prevsent>structuring the lexicon in inheritance hierar-chies opens for more compact lexicon represen-tations.
</prevsent>
</prevsection>
<citsent citstr=" J92-3002 ">
so far, lexicons have been structured in syntactic inheritance hierarchies, in which more or less abstract syntactic lasses form the upper nodes and actual words are associated with the leaf nodes (flickinger and nerbonne, 1992; <papid> J92-3002 </papid>rus-sell et al, 1992).<papid> J92-3003 </papid></citsent>
<aftsection>
<nextsent>however, the nature and num-ber of these abstract syntactic lasses are not very clear, and it seems difficult to come up with sound method for how to decide on such classes.
</nextsent>
<nextsent>at the same time, there are also good reasons for assuming similar hierarchy based on seman-tic properties (hellan and dimitrova-vulchanova, 1994).
</nextsent>
<nextsent>representing many competing hierarchies in the lexicon is problem in itself and is here even more problematic as there are many com-plex relationships between semantic and syntac-tic properties (gropen et al, 1992; hellan and dimitrova-vulchanova, 1996).
</nextsent>
<nextsent>another problem is related to the notions and structures adopted in the lexicon systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F101">
<title id=" C96-1081.xml">a sign expansion approach to dynamic multipurpose lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in many cases, it also clutters the lexicon structure, so that important lexical relationships and gener-alizations are lost.
</prevsent>
<prevsent>structuring the lexicon in inheritance hierar-chies opens for more compact lexicon represen-tations.
</prevsent>
</prevsection>
<citsent citstr=" J92-3003 ">
so far, lexicons have been structured in syntactic inheritance hierarchies, in which more or less abstract syntactic lasses form the upper nodes and actual words are associated with the leaf nodes (flickinger and nerbonne, 1992; <papid> J92-3002 </papid>rus-sell et al, 1992).<papid> J92-3003 </papid></citsent>
<aftsection>
<nextsent>however, the nature and num-ber of these abstract syntactic lasses are not very clear, and it seems difficult to come up with sound method for how to decide on such classes.
</nextsent>
<nextsent>at the same time, there are also good reasons for assuming similar hierarchy based on seman-tic properties (hellan and dimitrova-vulchanova, 1994).
</nextsent>
<nextsent>representing many competing hierarchies in the lexicon is problem in itself and is here even more problematic as there are many com-plex relationships between semantic and syntac-tic properties (gropen et al, 1992; hellan and dimitrova-vulchanova, 1996).
</nextsent>
<nextsent>another problem is related to the notions and structures adopted in the lexicon systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F102">
<title id=" C96-1081.xml">a sign expansion approach to dynamic multipurpose lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>another problem is related to the notions and structures adopted in the lexicon systems.
</prevsent>
<prevsent>most lexicons today are constructed within the frame-work of some syntactic theory.
</prevsent>
</prevsection>
<citsent citstr=" J92-3001 ">
this theory guides the structuring of lexical information and also de-cides what information should be available to the user (andry et al, 1992; <papid> J92-3001 </papid>flickinger and nerbonne, 1992; <papid> J92-3002 </papid>mel suk and polgu~re, 1987; russell et ~l., 1992; krieger and nerbonne, 1991).</citsent>
<aftsection>
<nextsent>some lexicon systems try to be reasonably theory-independent, though they still have to adopt some basic syn-tactic notions that locate them into family of theories (gofii and gonzalez, 1995; grimshaw and jackendoff, 1985; grishman et al, 1994).<papid> C94-1042 </papid></nextsent>
<nextsent>the sign expansion approach forms basis for creating non-redundant lexicon systems that are structured along semantic lines.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F105">
<title id=" C96-1081.xml">a sign expansion approach to dynamic multipurpose lexicons </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most lexicons today are constructed within the frame-work of some syntactic theory.
</prevsent>
<prevsent>this theory guides the structuring of lexical information and also de-cides what information should be available to the user (andry et al, 1992; <papid> J92-3001 </papid>flickinger and nerbonne, 1992; <papid> J92-3002 </papid>mel suk and polgu~re, 1987; russell et ~l., 1992; krieger and nerbonne, 1991).</prevsent>
</prevsection>
<citsent citstr=" C94-1042 ">
some lexicon systems try to be reasonably theory-independent, though they still have to adopt some basic syn-tactic notions that locate them into family of theories (gofii and gonzalez, 1995; grimshaw and jackendoff, 1985; grishman et al, 1994).<papid> C94-1042 </papid></citsent>
<aftsection>
<nextsent>the sign expansion approach forms basis for creating non-redundant lexicon systems that are structured along semantic lines.
</nextsent>
<nextsent>the stored lexical entries are sign frames rather than actual words, and whole system of expansion rules and consis-tency rules are used to generate dynamic entries of words that contain all the necessary semantic, syntactic, and morphological information.
</nextsent>
<nextsent>in section 2, we give brief introduction to sign expansion theory called the sign model.
</nextsent>
<nextsent>sec-tion 3 explains the use of lexical expansion rules, whereas ome concluding remarks and directions for further work are found in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F106">
<title id=" C96-2129.xml">automatic detection of omissions in translations </title>
<section> bitext maps.  </section>
<citcontext>
<prevsection>
<prevsent>to un(ler- stand such correspondence, think of the original text and the translation as single i text (hat ris, 1988).
</prevsent>
<prevsent>a description of the correspondence between the two halves of the bitext is called b text map.
</prevsent>
</prevsection>
<citsent citstr=" P93-1001 ">
at least two methods for finding bitext maps have been described in tile literature (church, 1993; <papid> P93-1001 </papid>melamed, 1996).</citsent>
<aftsection>
<nextsent>both methods output sequence of corresponding character po-sitions in the two texts.
</nextsent>
<nextsent>the novelty of  the omis-sion detection method presented in this paper dies in analyzing these correspondence points geomet-rically.
</nextsent>
<nextsent>a text and its translation can form the axes of rectangular i text space, as in figure 1.
</nextsent>
<nextsent>the height and width of the rectangle correspond to the lengths of the two texts, in characters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F108">
<title id=" C96-2129.xml">automatic detection of omissions in translations </title>
<section> bitext maps.  </section>
<citcontext>
<prevsection>
<prevsent>the bitext map between two texts that are translations of each other (mutua translations) will be inject ive (one to one).
</prevsent>
<prevsent>bitext maps have another property that is crucial lbr detecting omissions in translations.
</prevsent>
</prevsection>
<citsent citstr=" P91-1023 ">
there is very high correlation between the lengths of mutual translations ( = .991) (gale &amp; church, 1991).<papid> P91-1023 </papid></citsent>
<aftsection>
<nextsent>this implies that the slope of segments of the bitext map flmction tlne- tuates very little.
</nextsent>
<nextsent>the slope of any segment of the 764 mall will, in probal)ility, be very close to the ratio of the lengths of l, lm two texts.
</nextsent>
<nextsent>\[n  )ther words, the slop\[; of ma.p segments has vel low val ia/lge.
</nextsent>
<nextsent>omissions in translations give rise to distinctive atterns in \[ itext maps, as illustrated in l! igure i.  he nearly horizontal l)art of the 1)itext inal  in ..q 8 d. ~3 =   -- ii ie : , . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F112">
<title id=" C94-2178.xml">kvec a new approach for aligning parallel texts </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>for example, it discovers that the english word fisheries is similar to the french p~ches by noting that the distribution of fisheries in the english text is similar to the distribution of p~ches in the french.
</prevsent>
<prevsent>k-vec does not depend on sentence boundaries.
</prevsent>
</prevsection>
<citsent citstr=" J90-2002 ">
there have been quite number of recent papers on parallel text: brown et al(1990, <papid> J90-2002 </papid>1991, 1993), chen (1993), <papid> P93-1002 </papid>church (1993), <papid> P93-1001 </papid>church et al(1993), dagan et al(1993), <papid> W93-0301 </papid>gale and church (1991), <papid> H91-1026 </papid>gale and church (1993), <papid> P93-1001 </papid>isabelle (1992), kay and rgsenschein (1993), klavans and tzoukermann (1990), kupiec (1993), <papid> P93-1003 </papid>matsumoto (1991), ogden and gonzales (1993), shemtov (1993), <papid> E93-1054 </papid>simard et al(1992), warwick- armstrong and russell (1990), wu (to appear).</citsent>
<aftsection>
<nextsent>most of this work has been focused on european language pairs, especially english-french.
</nextsent>
<nextsent>it remains an open question how well these methods might generalize to other language pairs, especially pairs such as english-japanese and english- chinese.
</nextsent>
<nextsent>in previous work (church et al 1993), we have reported some preliminary success in aligning the english and japanese versions of the awk manual (aho, kernighan, weinberger (1980)), using char align (church, 1993), <papid> P93-1001 </papid>method that looks for character sequences that are the same in both the source and target.</nextsent>
<nextsent>the char align method was designed for european language pairs, where cognates often share character sequences, e.g., government and gouvernement.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F113">
<title id=" C94-2178.xml">kvec a new approach for aligning parallel texts </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>for example, it discovers that the english word fisheries is similar to the french p~ches by noting that the distribution of fisheries in the english text is similar to the distribution of p~ches in the french.
</prevsent>
<prevsent>k-vec does not depend on sentence boundaries.
</prevsent>
</prevsection>
<citsent citstr=" P93-1002 ">
there have been quite number of recent papers on parallel text: brown et al(1990, <papid> J90-2002 </papid>1991, 1993), chen (1993), <papid> P93-1002 </papid>church (1993), <papid> P93-1001 </papid>church et al(1993), dagan et al(1993), <papid> W93-0301 </papid>gale and church (1991), <papid> H91-1026 </papid>gale and church (1993), <papid> P93-1001 </papid>isabelle (1992), kay and rgsenschein (1993), klavans and tzoukermann (1990), kupiec (1993), <papid> P93-1003 </papid>matsumoto (1991), ogden and gonzales (1993), shemtov (1993), <papid> E93-1054 </papid>simard et al(1992), warwick- armstrong and russell (1990), wu (to appear).</citsent>
<aftsection>
<nextsent>most of this work has been focused on european language pairs, especially english-french.
</nextsent>
<nextsent>it remains an open question how well these methods might generalize to other language pairs, especially pairs such as english-japanese and english- chinese.
</nextsent>
<nextsent>in previous work (church et al 1993), we have reported some preliminary success in aligning the english and japanese versions of the awk manual (aho, kernighan, weinberger (1980)), using char align (church, 1993), <papid> P93-1001 </papid>method that looks for character sequences that are the same in both the source and target.</nextsent>
<nextsent>the char align method was designed for european language pairs, where cognates often share character sequences, e.g., government and gouvernement.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F114">
<title id=" C94-2178.xml">kvec a new approach for aligning parallel texts </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>for example, it discovers that the english word fisheries is similar to the french p~ches by noting that the distribution of fisheries in the english text is similar to the distribution of p~ches in the french.
</prevsent>
<prevsent>k-vec does not depend on sentence boundaries.
</prevsent>
</prevsection>
<citsent citstr=" P93-1001 ">
there have been quite number of recent papers on parallel text: brown et al(1990, <papid> J90-2002 </papid>1991, 1993), chen (1993), <papid> P93-1002 </papid>church (1993), <papid> P93-1001 </papid>church et al(1993), dagan et al(1993), <papid> W93-0301 </papid>gale and church (1991), <papid> H91-1026 </papid>gale and church (1993), <papid> P93-1001 </papid>isabelle (1992), kay and rgsenschein (1993), klavans and tzoukermann (1990), kupiec (1993), <papid> P93-1003 </papid>matsumoto (1991), ogden and gonzales (1993), shemtov (1993), <papid> E93-1054 </papid>simard et al(1992), warwick- armstrong and russell (1990), wu (to appear).</citsent>
<aftsection>
<nextsent>most of this work has been focused on european language pairs, especially english-french.
</nextsent>
<nextsent>it remains an open question how well these methods might generalize to other language pairs, especially pairs such as english-japanese and english- chinese.
</nextsent>
<nextsent>in previous work (church et al 1993), we have reported some preliminary success in aligning the english and japanese versions of the awk manual (aho, kernighan, weinberger (1980)), using char align (church, 1993), <papid> P93-1001 </papid>method that looks for character sequences that are the same in both the source and target.</nextsent>
<nextsent>the char align method was designed for european language pairs, where cognates often share character sequences, e.g., government and gouvernement.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F116">
<title id=" C94-2178.xml">kvec a new approach for aligning parallel texts </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>for example, it discovers that the english word fisheries is similar to the french p~ches by noting that the distribution of fisheries in the english text is similar to the distribution of p~ches in the french.
</prevsent>
<prevsent>k-vec does not depend on sentence boundaries.
</prevsent>
</prevsection>
<citsent citstr=" W93-0301 ">
there have been quite number of recent papers on parallel text: brown et al(1990, <papid> J90-2002 </papid>1991, 1993), chen (1993), <papid> P93-1002 </papid>church (1993), <papid> P93-1001 </papid>church et al(1993), dagan et al(1993), <papid> W93-0301 </papid>gale and church (1991), <papid> H91-1026 </papid>gale and church (1993), <papid> P93-1001 </papid>isabelle (1992), kay and rgsenschein (1993), klavans and tzoukermann (1990), kupiec (1993), <papid> P93-1003 </papid>matsumoto (1991), ogden and gonzales (1993), shemtov (1993), <papid> E93-1054 </papid>simard et al(1992), warwick- armstrong and russell (1990), wu (to appear).</citsent>
<aftsection>
<nextsent>most of this work has been focused on european language pairs, especially english-french.
</nextsent>
<nextsent>it remains an open question how well these methods might generalize to other language pairs, especially pairs such as english-japanese and english- chinese.
</nextsent>
<nextsent>in previous work (church et al 1993), we have reported some preliminary success in aligning the english and japanese versions of the awk manual (aho, kernighan, weinberger (1980)), using char align (church, 1993), <papid> P93-1001 </papid>method that looks for character sequences that are the same in both the source and target.</nextsent>
<nextsent>the char align method was designed for european language pairs, where cognates often share character sequences, e.g., government and gouvernement.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F117">
<title id=" C94-2178.xml">kvec a new approach for aligning parallel texts </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>for example, it discovers that the english word fisheries is similar to the french p~ches by noting that the distribution of fisheries in the english text is similar to the distribution of p~ches in the french.
</prevsent>
<prevsent>k-vec does not depend on sentence boundaries.
</prevsent>
</prevsection>
<citsent citstr=" H91-1026 ">
there have been quite number of recent papers on parallel text: brown et al(1990, <papid> J90-2002 </papid>1991, 1993), chen (1993), <papid> P93-1002 </papid>church (1993), <papid> P93-1001 </papid>church et al(1993), dagan et al(1993), <papid> W93-0301 </papid>gale and church (1991), <papid> H91-1026 </papid>gale and church (1993), <papid> P93-1001 </papid>isabelle (1992), kay and rgsenschein (1993), klavans and tzoukermann (1990), kupiec (1993), <papid> P93-1003 </papid>matsumoto (1991), ogden and gonzales (1993), shemtov (1993), <papid> E93-1054 </papid>simard et al(1992), warwick- armstrong and russell (1990), wu (to appear).</citsent>
<aftsection>
<nextsent>most of this work has been focused on european language pairs, especially english-french.
</nextsent>
<nextsent>it remains an open question how well these methods might generalize to other language pairs, especially pairs such as english-japanese and english- chinese.
</nextsent>
<nextsent>in previous work (church et al 1993), we have reported some preliminary success in aligning the english and japanese versions of the awk manual (aho, kernighan, weinberger (1980)), using char align (church, 1993), <papid> P93-1001 </papid>method that looks for character sequences that are the same in both the source and target.</nextsent>
<nextsent>the char align method was designed for european language pairs, where cognates often share character sequences, e.g., government and gouvernement.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F121">
<title id=" C94-2178.xml">kvec a new approach for aligning parallel texts </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>for example, it discovers that the english word fisheries is similar to the french p~ches by noting that the distribution of fisheries in the english text is similar to the distribution of p~ches in the french.
</prevsent>
<prevsent>k-vec does not depend on sentence boundaries.
</prevsent>
</prevsection>
<citsent citstr=" P93-1003 ">
there have been quite number of recent papers on parallel text: brown et al(1990, <papid> J90-2002 </papid>1991, 1993), chen (1993), <papid> P93-1002 </papid>church (1993), <papid> P93-1001 </papid>church et al(1993), dagan et al(1993), <papid> W93-0301 </papid>gale and church (1991), <papid> H91-1026 </papid>gale and church (1993), <papid> P93-1001 </papid>isabelle (1992), kay and rgsenschein (1993), klavans and tzoukermann (1990), kupiec (1993), <papid> P93-1003 </papid>matsumoto (1991), ogden and gonzales (1993), shemtov (1993), <papid> E93-1054 </papid>simard et al(1992), warwick- armstrong and russell (1990), wu (to appear).</citsent>
<aftsection>
<nextsent>most of this work has been focused on european language pairs, especially english-french.
</nextsent>
<nextsent>it remains an open question how well these methods might generalize to other language pairs, especially pairs such as english-japanese and english- chinese.
</nextsent>
<nextsent>in previous work (church et al 1993), we have reported some preliminary success in aligning the english and japanese versions of the awk manual (aho, kernighan, weinberger (1980)), using char align (church, 1993), <papid> P93-1001 </papid>method that looks for character sequences that are the same in both the source and target.</nextsent>
<nextsent>the char align method was designed for european language pairs, where cognates often share character sequences, e.g., government and gouvernement.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F122">
<title id=" C94-2178.xml">kvec a new approach for aligning parallel texts </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>for example, it discovers that the english word fisheries is similar to the french p~ches by noting that the distribution of fisheries in the english text is similar to the distribution of p~ches in the french.
</prevsent>
<prevsent>k-vec does not depend on sentence boundaries.
</prevsent>
</prevsection>
<citsent citstr=" E93-1054 ">
there have been quite number of recent papers on parallel text: brown et al(1990, <papid> J90-2002 </papid>1991, 1993), chen (1993), <papid> P93-1002 </papid>church (1993), <papid> P93-1001 </papid>church et al(1993), dagan et al(1993), <papid> W93-0301 </papid>gale and church (1991), <papid> H91-1026 </papid>gale and church (1993), <papid> P93-1001 </papid>isabelle (1992), kay and rgsenschein (1993), klavans and tzoukermann (1990), kupiec (1993), <papid> P93-1003 </papid>matsumoto (1991), ogden and gonzales (1993), shemtov (1993), <papid> E93-1054 </papid>simard et al(1992), warwick- armstrong and russell (1990), wu (to appear).</citsent>
<aftsection>
<nextsent>most of this work has been focused on european language pairs, especially english-french.
</nextsent>
<nextsent>it remains an open question how well these methods might generalize to other language pairs, especially pairs such as english-japanese and english- chinese.
</nextsent>
<nextsent>in previous work (church et al 1993), we have reported some preliminary success in aligning the english and japanese versions of the awk manual (aho, kernighan, weinberger (1980)), using char align (church, 1993), <papid> P93-1001 </papid>method that looks for character sequences that are the same in both the source and target.</nextsent>
<nextsent>the char align method was designed for european language pairs, where cognates often share character sequences, e.g., government and gouvernement.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F130">
<title id=" C92-2109.xml">a constraint based approach to translating anaphoric dependencies </title>
<section> existing approaches.  </section>
<citcontext>
<prevsection>
<prevsent>2 2.2.
</prevsent>
<prevsent>constraint based approaches.
</prevsent>
</prevsection>
<citsent citstr=" E89-1037 ">
in this section, we will outline the approach to the translation of non-local re- entrances proposed in kaplan et al (1989).<papid> E89-1037 </papid></citsent>
<aftsection>
<nextsent>in lfg projections are linguistically relevant mappings or correspondences between levels, whether these mappings are direct or involve function composition (kaplan (198 0, halvorscn and kaplan (1988), dalrymple (1990) and dalrymple al (1990)).
</nextsent>
<nextsent>by means of these projections, equations can be stated which co- describe elements of the two levels related by the projection.
</nextsent>
<nextsent>the standard projections are (normally expressed in terms of and ~,, from c-structure to f-structure), and (variously from c- and f-structure to semantic structures).
</nextsent>
<nextsent>kaptan et al extend this approach to provide what amounts to transfer lormalism for lfg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F132">
<title id=" C96-2165.xml">on inference based procedures for lexical disambiguation </title>
<section> int roduct ion.  </section>
<citcontext>
<prevsection>
<prevsent>we can distinguish two classes of approaches:  surface- oriented  approaches and  inference-based  ap-proaches.
</prevsent>
<prevsent>surface-oriented approaches relyon selectional restrictions (of.
</prevsent>
</prevsection>
<citsent citstr=" J89-1003 ">
e.g. mccord 1989) (<papid> J89-1003 </papid>sometimes upplied by an external type hierar- chy/ontology (e.g. nirenburg 1989) or are statis-tical (e.g. kameyama, peters, and schiitze 1993).</citsent>
<aftsection>
<nextsent>although quite useful for some purposes, the performance of surface-oriented approaches in-herently limited in that their context sensitivity is always locally bounded (see e.g. kay, gawron, and norvig 1994 for details).
</nextsent>
<nextsent>since we cannot assume fixed finite context, boundaries within each lexical ambiguity can be locally resolved, inference-based approaches seem more promising for handling lex-ical disambiguation, hfference-based approaches assume thai; the language of logic is used to rep-resent the meaning of discourse, that the same language is used to store our conceptual and world knowledge and that resolution is achieved on the basis of the underlying logic by special inferences.
</nextsent>
<nextsent>the most promineut inference pattern (which is also the center of the discussion here) is e.g. the proof of contradiction from given read-ing in given context and our conceptual and world knowledge which allows us to rule out that reading.
</nextsent>
<nextsent>although these approaches can handle the problem of disambiguating information arbi-trarily far away (the whole context is available as premise), without any fllrther restrictions they run into tract ability problems which exclude practical application.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F133">
<title id=" C96-2100.xml">good bigrams </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>co-occurrence is still interesting be- cause bigrams occur non-randomly, someti-mes to such an extent hat we discern some structure beyond co-occurrence.
</prevsent>
<prevsent>the reason why it should be so is probably that part of the use of words is reflected by the company that words keep.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
researchers (church &amp; hanks, 1990; <papid> J90-1003 </papid>kita &amp; al., 1994, inter al.) have noted that mutual information tends to be insensitive to high fi equency patterns, and unstable for low fre-quency patterns.</citsent>
<aftsection>
<nextsent>johansson (1994) <papid> C94-2165 </papid>compared another measure, the difference in mutual in-formation (ag), of collocational strength with mutual information (g).</nextsent>
<nextsent>that measure ranked high frequency bigrams higher than other bi- grams if the order was consistent, whereas mutual information tended to pick out combi-nations of low frequency items.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F135">
<title id=" C96-2100.xml">good bigrams </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the reason why it should be so is probably that part of the use of words is reflected by the company that words keep.
</prevsent>
<prevsent>researchers (church &amp; hanks, 1990; <papid> J90-1003 </papid>kita &amp; al., 1994, inter al.) have noted that mutual information tends to be insensitive to high fi equency patterns, and unstable for low fre-quency patterns.</prevsent>
</prevsection>
<citsent citstr=" C94-2165 ">
johansson (1994) <papid> C94-2165 </papid>compared another measure, the difference in mutual in-formation (ag), of collocational strength with mutual information (g).</citsent>
<aftsection>
<nextsent>that measure ranked high frequency bigrams higher than other bi- grams if the order was consistent, whereas mutual information tended to pick out combi-nations of low frequency items.
</nextsent>
<nextsent>since low frequency items carry more specific informa-tion such bigrams give an illusion of semantic content.
</nextsent>
<nextsent>it is usually this semantic illusion that we are interested in, but what says that  of the  or  in  are worse bigrams than  wood-en spades  or  various pretexts .
</nextsent>
<nextsent>johansson proposed the test of finding some of the characters in the children tory  alice in wonderland , and showed that  new  measure was to some degree  better  than mutual information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F138">
<title id=" C96-2100.xml">good bigrams </title>
<section> definitions.  </section>
<citcontext>
<prevsection>
<prevsent>in the following p(x) will denote the observed probability as defined by p(x)=f(x)/n where f(x) is the frequency of occurrence of x, and is the number of observed cases.
</prevsent>
<prevsent>n is, in the calculations, equal to the corpus size in words.
</prevsent>
</prevsection>
<citsent citstr=" J93-1001 ">
given this, the mutual information ratio (church &amp; hanks, 1990; <papid> J90-1003 </papid>church &amp; mercer, 1993; <papid> J93-1001 </papid>steier &amp; belew, 1991) is expressed by formula 1.</citsent>
<aftsection>
<nextsent>(church &amp; hanks refer to this measure as the association ratio tbr technical reasons).
</nextsent>
<nextsent>592 \]./ - - log2(rwt)) ) (~2 ) = (n *occ(\[wl,w2l)~ formula 1: the mutual information ratio the instability of statistical measures seems to be problem in statistical bigralns.
</nextsent>
<nextsent>especially low frequency counts cause instability.
</nextsent>
<nextsent>to avoid this use the rule of thumb that bigram must occur more than four times (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F144">
<title id=" C96-2100.xml">good bigrams </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>significant fre-quency counts are achieved through the use of very large corpus, and/or corpus speciali-sed for specific task.
</prevsent>
<prevsent>they report hat it was possible for them to divide large corpus into smaller sub-sections with little loss.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
smadja (1993)<papid> J93-1007 </papid>finds significant bigrams using an estimate of z-score (deviation from an expected mean).</citsent>
<aftsection>
<nextsent>smadja method seems to require very large corpora, since the met-hod needs to estimate reliable measure of the variance of the frequencies with which words co-occur.
</nextsent>
<nextsent>this makes the method dependent on the corpus size.
</nextsent>
<nextsent>smadja reports the use of corpus of size 10 million words.
</nextsent>
<nextsent> more precisely, the statistical methods we use do not seem to be effective on low frequency words (fewer than 100 occurrences).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F146">
<title id=" C96-2100.xml">good bigrams </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>steier &amp; belew (1991) discuss the  exporting  of phrases into general vocabulary, where word pair with high mutual information within topic tends to have lower mutual in-formation within the collection, and vice versa.
</prevsent>
<prevsent>they relate higher mutual information within topic than in the collection to lower value of discrimination.
</prevsent>
</prevsection>
<citsent citstr=" W95-0110 ">
church &amp; gale (1995) <papid> W95-0110 </papid>have found it useful to compare the distribution of terms across do- cuments.</citsent>
<aftsection>
<nextsent>they showed that distribution dif-ferent from what could be expected by (random) poisson process indicates interest-ing terms.
</nextsent>
<nextsent>this approach is similar to the use of one genre to find interesting items in 596 another.
</nextsent>
<nextsent>however, removal of the overlap needs some knowledge about the genres - - apart from checking explicitly for genre with least overlap.
</nextsent>
<nextsent>cancelling overlap has the ad-vantage that it can cancel out similar underly-ing causes, while it exaggerates the underly-ing causes that differ between genres.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F147">
<title id=" C94-1084.xml">towards automatic extraction of monolingual and bilingual terminology </title>
<section> linguistic specifications of.  </section>
<citcontext>
<prevsection>
<prevsent>informations provided by shan-non diversity and distance measures are pre-sented in \[daille, 1994\].
</prevsent>
<prevsent>most of the associa-tion criteria can be found in the classic liter-ature, such as \[clifford and stephenson, 1975\], and are based on the so-called  contingency ta-bles .
</prevsent>
</prevsection>
<citsent citstr=" C88-1016 ">
in the field of eomputationa.1 linguis-tics, mutual information \[brown et al, 1988\], <papid> C88-1016 </papid>2 \[church and hanks, 1990\], or likelihood ra-tio test \[dunning, 199a\] are suggested.</citsent>
<aftsection>
<nextsent>our testing method consists in comparing our result list, sorted according to specified score, with reference list containing only valid terms.
</nextsent>
<nextsent>in order to l)uild the reference list, we augmented an existing terminology database (eurodicautom) with hand work: we se-lected those candidates for which at least two judges out of three agreed on their goodness, and included them in the reference llst.
</nextsent>
<nextsent>a candi-date will be considered  good  when it is found in this reference list.
</nextsent>
<nextsent>the program for the extraction of candi-dates was run on 240,000 words french corpus, divided into 9,541 sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F148">
<title id=" C96-1041.xml">markov random field based english partofspeech tagging system </title>
<section> int roduct ion.  </section>
<citcontext>
<prevsection>

<prevsent>part-of-speech tagging is to assign the correct tag to each word in the context of the sentence.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
\[ here are three main approaches in tagging problem: rule-based approach (klein and simmons 1%3; brodda 1982; paulussen and martin 1992; brill et al 1990), statistical approach (church :1988; <papid> A88-1019 </papid>merialdo 1994; <papid> J94-2001 </papid>foster 1991; weischedel et al 1993; <papid> J93-2006 </papid>kupiec 1992) and connection ist approach (benello et al 1989; nakanmra et al 1989).</citsent>
<aftsection>
<nextsent>in these approaches, tatistical approach as the fol-lowing advantages : ? theoretical framework is provided ? automatic learning facility is provided ? the probabilities provide straightforward way to disambiguate many information sources must be combined to solve tagging problem with statistical approach.
</nextsent>
<nextsent>it is significant assumption that tire correct tag can generally be chosen from i.he local context.
</nextsent>
<nextsent>not only local sequences of words and tags are needed to solve tagging problem, but syntax, se-mantic, and morphological level information is also required in general.
</nextsent>
<nextsent>usually information sources such as t)igram, trigram and migra.m are used in the tagging systems which are based on statistical method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F149">
<title id=" C96-1041.xml">markov random field based english partofspeech tagging system </title>
<section> int roduct ion.  </section>
<citcontext>
<prevsection>

<prevsent>part-of-speech tagging is to assign the correct tag to each word in the context of the sentence.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
\[ here are three main approaches in tagging problem: rule-based approach (klein and simmons 1%3; brodda 1982; paulussen and martin 1992; brill et al 1990), statistical approach (church :1988; <papid> A88-1019 </papid>merialdo 1994; <papid> J94-2001 </papid>foster 1991; weischedel et al 1993; <papid> J93-2006 </papid>kupiec 1992) and connection ist approach (benello et al 1989; nakanmra et al 1989).</citsent>
<aftsection>
<nextsent>in these approaches, tatistical approach as the fol-lowing advantages : ? theoretical framework is provided ? automatic learning facility is provided ? the probabilities provide straightforward way to disambiguate many information sources must be combined to solve tagging problem with statistical approach.
</nextsent>
<nextsent>it is significant assumption that tire correct tag can generally be chosen from i.he local context.
</nextsent>
<nextsent>not only local sequences of words and tags are needed to solve tagging problem, but syntax, se-mantic, and morphological level information is also required in general.
</nextsent>
<nextsent>usually information sources such as t)igram, trigram and migra.m are used in the tagging systems which are based on statistical method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F150">
<title id=" C96-1041.xml">markov random field based english partofspeech tagging system </title>
<section> int roduct ion.  </section>
<citcontext>
<prevsection>

<prevsent>part-of-speech tagging is to assign the correct tag to each word in the context of the sentence.
</prevsent>
</prevsection>
<citsent citstr=" J93-2006 ">
\[ here are three main approaches in tagging problem: rule-based approach (klein and simmons 1%3; brodda 1982; paulussen and martin 1992; brill et al 1990), statistical approach (church :1988; <papid> A88-1019 </papid>merialdo 1994; <papid> J94-2001 </papid>foster 1991; weischedel et al 1993; <papid> J93-2006 </papid>kupiec 1992) and connection ist approach (benello et al 1989; nakanmra et al 1989).</citsent>
<aftsection>
<nextsent>in these approaches, tatistical approach as the fol-lowing advantages : ? theoretical framework is provided ? automatic learning facility is provided ? the probabilities provide straightforward way to disambiguate many information sources must be combined to solve tagging problem with statistical approach.
</nextsent>
<nextsent>it is significant assumption that tire correct tag can generally be chosen from i.he local context.
</nextsent>
<nextsent>not only local sequences of words and tags are needed to solve tagging problem, but syntax, se-mantic, and morphological level information is also required in general.
</nextsent>
<nextsent>usually information sources such as t)igram, trigram and migra.m are used in the tagging systems which are based on statistical method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F151">
<title id=" C96-1097.xml">a statistical method for extracting uninterrupted and interrupted collocations from very large corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>phrase translations or pattern translations based on phrase or pattern dictionaries are considered very useful for the translations ofthese expressions.
</prevsent>
<prevsent>in order to realize these translation, it is required to identify phrases of high frequency and patterns of expres-sions from the corpora.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
there are many method proposed to extract rigid expressions from corpora such as method of focusing on the binding strength of two words (church and hanks 1990); <papid> J90-1003 </papid>the distance between words (smadja nd makeown 1990); and the number of combined words and frequency of appearance (kita 1993, 1994).</citsent>
<aftsection>
<nextsent>but it was not easy to identify and extract expressions of arbitrary lengths and high frequency of appearance from very large corpora.
</nextsent>
<nextsent>thus, conventional methods had to introduce some kinds of restrictions such as the limitation of the kind of chains or the length of chains to be extracted (smadja 1993, <papid> J93-1007 </papid>shinnou and isahara 1995).</nextsent>
<nextsent>recently, new method which can calculate arbitrary number of n-gram statistics for very large corpora has been proposed (nagao and mori 1994).<papid> C94-1101 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F152">
<title id=" C96-1097.xml">a statistical method for extracting uninterrupted and interrupted collocations from very large corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are many method proposed to extract rigid expressions from corpora such as method of focusing on the binding strength of two words (church and hanks 1990); <papid> J90-1003 </papid>the distance between words (smadja nd makeown 1990); and the number of combined words and frequency of appearance (kita 1993, 1994).</prevsent>
<prevsent>but it was not easy to identify and extract expressions of arbitrary lengths and high frequency of appearance from very large corpora.</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
thus, conventional methods had to introduce some kinds of restrictions such as the limitation of the kind of chains or the length of chains to be extracted (smadja 1993, <papid> J93-1007 </papid>shinnou and isahara 1995).</citsent>
<aftsection>
<nextsent>recently, new method which can calculate arbitrary number of n-gram statistics for very large corpora has been proposed (nagao and mori 1994).<papid> C94-1101 </papid></nextsent>
<nextsent>this method has made it possible to automatically and quickly extract and tabulate sub strings of any length used in source texts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F153">
<title id=" C96-1097.xml">a statistical method for extracting uninterrupted and interrupted collocations from very large corpora </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>but it was not easy to identify and extract expressions of arbitrary lengths and high frequency of appearance from very large corpora.
</prevsent>
<prevsent>thus, conventional methods had to introduce some kinds of restrictions such as the limitation of the kind of chains or the length of chains to be extracted (smadja 1993, <papid> J93-1007 </papid>shinnou and isahara 1995).</prevsent>
</prevsection>
<citsent citstr=" C94-1101 ">
recently, new method which can calculate arbitrary number of n-gram statistics for very large corpora has been proposed (nagao and mori 1994).<papid> C94-1101 </papid></citsent>
<aftsection>
<nextsent>this method has made it possible to automatically and quickly extract and tabulate sub strings of any length used in source texts.
</nextsent>
<nextsent>unfortu-nately, in this method, so many fractional sub strings that were grammatically and semantically inconsistent were being extracted that it was difficult to extract combinations of expressions collocated at separate locations (i.e. inter-rupted collocation) which requires search of the source text by combining the strings thus extracted.
</nextsent>
<nextsent>thus, the analyses had to be limited into small texts (colier 1994).
</nextsent>
<nextsent>to overcome this problems, this paper first, proposes method that can automatically extract and tabulate un-interrupted collocational sub strings and without omission from the corpora in the order of substring length and fre-quency under the condition that fractional sub strings are excluded.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F157">
<title id=" C96-2152.xml">disambiguation by prioritized circumscription </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>
<prevsent>this kind of revision of reading cmmot be rcl)- res( .nl,ed by infl .ren(:e in (:l;~ssical logic siu(:e in classi(:;d logic, once wc gel; ~ inferred result, we can no hmger rel:ra.(:t the result (monotonic pr op- erty).
</prevsent>
<prevsent>therefore, to ml(lerstand tit(,, phenolnen&amp; we need other reasoning met;hods rout in f~(:t, 901 many researches h;tve been using general reason- inn f~am(:works in artificial intelligence.
</prevsent>
</prevsection>
<citsent citstr=" C88-2163 ">
such a,s abduction (ttobbs et al, 1993), prol)abilistic net-work (chm niak and gohhnan, 1989), truth lnain- t(mance system (zernik and brown, 1988), <papid> C88-2163 </papid>default logic (quantz, 1993) and conditional ogic (las- carides, 1993).</citsent>
<aftsection>
<nextsent>in this paper, wc ttropose another alternative, that is, circ,,.m.~cription (mccarthy, 1986: lifschitz, 1985).
</nextsent>
<nextsent>even though circumscrit)- tion is one of the most pottular fornlmisn,s in the collllllllllit, of llolllllollotollic reasoning rcs(,.ar(:h, it is surprishlg that .ry few h~ts examined feasi-bility of (:ircumscrit)tion for disa, mbiguation.
</nextsent>
<nextsent>our work of disambiguation by intcrt)retation ordering is originated from (satoh, 1991) and in more recent work, kameymna (kameyama, 1994) has indcp(mdently propos( .d usage of circumscription for interpretation of pronominal anaphora.
</nextsent>
<nextsent>in this paper, we explore this direction fur-ther.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F158">
<title id=" C94-1020.xml">an englishtokorean machine translator matesek </title>
<section> overview of the system.  </section>
<citcontext>
<prevsection>
<prevsent>glish syntactic an~dysis : we dew .loped set of augmented context free gr~mmu~r rules \[ or general english synt~mtic analysis a, td the.
</prevsent>
<prevsent>~m- alyzer is implemented using  /bnfita~ li{.
</prevsent>
</prevsection>
<citsent citstr=" J87-1004 ">
pars-ing algorithm (tomita, 1987).<papid> J87-1004 </papid></citsent>
<aftsection>
<nextsent>, i,exical semantic structure (lss) to repre-- sent the intermediate representation : the result of the syntactic structure is trans.- tbrmed into an intermediate representatkm lss, which is dependency structure that is relatively independent to specific lan-guages.
</nextsent>
<nextsent>in i, ss, the constituents in sen-tence are combined only in head-dependent relation based on the lexieal categories, and there art.  no order relatkm between the con-stituents.
</nextsent>
<nextsent>hence lss is desirable for trans- 129 ell- formed~ english \ sentence\ semanticll /  ~isyntac ic ianalysis~ 1 trams feri~\]generat \[or \[grammar ~i grammar ~lgrammar -- / / s~nlenoe / grammar writing language environment / . . .
</nextsent>
<nextsent>h ...........
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F159">
<title id=" C96-1062.xml">interpretation of nominal compounds combining domain independent and domain specific information </title>
<section> mot ivat ion.  </section>
<citcontext>
<prevsection>
<prevsent>in many cases, no surface information is available to deduce the relation, and in particular no morphological evidence of link between the constituents and the underlying predicate.
</prevsent>
<prevsent>this problem has been tackled in several types of nlp systems, mainly: - domain-dependent systems.
</prevsent>
</prevsection>
<citsent citstr=" P84-1108 ">
such systems are very efficient but are limited to the domain they are built for: interpretation rules are inferred from the observation of specific semantic patterns (marsh, 1984) <papid> P84-1108 </papid>or from fine-grained conceptual representation (ter stal, 1996).</citsent>
<aftsection>
<nextsent>domain-independent systems (finin, 1980; macdonald, 1982), built to account for any kind of interpretation patterns, including rules that are not inferred from the properties of the con-stituents (what finin calls productive rulcs, in op-position to structural rules).
</nextsent>
<nextsent>frequency and prob-ability scores are added to the rules.
</nextsent>
<nextsent>such numeric weighting of general semantic rules is hardly de-fensible in the absence of any reference to do- main.
</nextsent>
<nextsent>consequently, the questions that we propose to answer are: how far call we go in design-ing model of interpretation rules which account for productive patterns of interpretation, indepen-dently of any domain?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F160">
<title id=" C96-1062.xml">interpretation of nominal compounds combining domain independent and domain specific information </title>
<section> domain - independent  lnode l.  </section>
<citcontext>
<prevsection>
<prevsent>nominm compounds illustrate the distributional properties of nouns in the absenee of any ex-plicit verbal ln edicate.
</prevsent>
<prevsent>they attest an rattier- lying event structure associated to nominal con-stituents, which makes it possible to derive pred- icative relation from the mere collocation of two simple nouns.
</prevsent>
</prevsection>
<citsent citstr=" J91-4003 ">
the idea that noun meaning in-volves ewmt-based escription has been particu-larly emphasized by j. pustejovsky (1991).<papid> J91-4003 </papid></citsent>
<aftsection>
<nextsent>we propose to apl)ly crucial component of his gener-ative lea:icon, tile qualia st ructurc, to tile semantic interpre~tation conlpoullds.
</nextsent>
<nextsent>the key idea tllnt underlies the qualia sl, uctu,v is that nouns are implicitly related to predicative information, and that noun selects tbr the tyl)e of predicate, that can govern it.
</nextsent>
<nextsent>the four typ-ical nominal relations that constitute the qualia struetmv are tile telic role, that refers to the pur-pose and function of the referent, the agentive role, that concerns the factors involved in its origins, the constitutive role, that captures the relation be-tween an object and its constituent parts, and the jormal role, that distinguishes the ol)ject within larger domain.
</nextsent>
<nextsent>we illustrate the use of this theoretical flame- work r)r the interpretation of nolnitm.l contpounds.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F161">
<title id=" C96-1062.xml">interpretation of nominal compounds combining domain independent and domain specific information </title>
<section> domain - independent  lnode l.  </section>
<citcontext>
<prevsection>
<prevsent>the nouns that denote such information are mostly elements of the attribute class, which is defined in wordnet as  an abstraction belonging to or characteristic of an entity .
</prevsent>
<prevsent>each member of this class may appear at the head position of com-pounds in which the non-head denotes the entity that is characterized: desk height --+ character- ize(attribute: he_ight, entity: desk).
</prevsent>
</prevsection>
<citsent citstr=" P84-1109 ">
these nouns are uni-relationm nouns that can appear as the head of  n1 of n2  groups, where n2 is syn-tactic argument of n1 (e.g. height of the desk) (isabelle, 1984).<papid> P84-1109 </papid></citsent>
<aftsection>
<nextsent>consequently, pustejovsky notion of noun qualia helps to characterize implicit predicative link in compounds.
</nextsent>
<nextsent>this semantic framework demonstrates that the association between nomi-nal constituents and underlying predicative rela-tion in root compounds is not arbitrary: it in-volves conceptual mechanisms that are triggered in other linguistic phenomena such as type coer-cion (pustejovsky, 1991), <papid> J91-4003 </papid>anaphora (fradin, 1984) or adjectival constructions (bouillon and viegas, 1993).</nextsent>
<nextsent>2.3 imp lemen tat ion and resu t s. the implementation of these principles in our model is based on conceptual framework in or-der to associate predicative information with nom-inal constituents.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F164">
<title id=" C96-1062.xml">interpretation of nominal compounds combining domain independent and domain specific information </title>
<section> domain-specif ic semantic.  </section>
<citcontext>
<prevsection>
<prevsent>these are typically the specific patterns that cannot be taken into ac-count in general model.
</prevsent>
<prevsent>exhibiting semantic patterns in the texts is thus way to autolnati- eally learn more specific patterns of associations in sublanguages.
</prevsent>
</prevsection>
<citsent citstr=" J91-2002 ">
we are currently experimenting the way techniques of computer-aided acquisition for learning conceptual relations fi om syntactic ollo- cates (velardi et al 1991) <papid> J91-2002 </papid>can be applied to n associations.</citsent>
<aftsection>
<nextsent>3.2 ident f ca ion of the pred icat ive ink.
</nextsent>
<nextsent>our model associates fixed verbal predicate with nouns or nominal classes to account forgiven semantic facet.
</nextsent>
<nextsent>this predicate corresponds to the typical predicative information that occur ill the wordnet textual gloss, when it is available.
</nextsent>
<nextsent>in fact, this predicate may vary fl om one corpus to another, and we nmst take into account this vari-ation which corresponds to specific conceptual de-scriptions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F165">
<title id=" C96-1062.xml">interpretation of nominal compounds combining domain independent and domain specific information </title>
<section> domain-specif ic semantic.  </section>
<citcontext>
<prevsection>
<prevsent>given compound n1 n2, we may look for strings in which the couple (n1, n2) occurs in different relation.
</prevsent>
<prevsent>in the following ex-amples, the context provides the missing verbal predicate: compiler warnings: (compiler,warning) =  it is reasonable for the compiler to emit warning  in this example, which corresponds to the agen-tive role, we see that the two nouns are argmnents of the predicate that instantiates the underlying relation, which means that corpus-based methods can use rich linguistic structure to identify the predicate.
</prevsent>
</prevsection>
<citsent citstr=" J93-2005 ">
pustejovsky et al (1993) <papid> J93-2005 </papid>show how statistical techniques, such as mutual information measures can contribute to automatically acquire lexical information regarding the link between noun and predicate.</citsent>
<aftsection>
<nextsent>similar techniques are used by (grefenstette and teut~l 1.995) to determiue the support verb associated with deverbal nouns.
</nextsent>
<nextsent>conclusion this paper describes domain-independent model tbr the ,interpretation of nominal compounds; it shows how general knowledge and domain-specific 368 itiforinal;ion inay be combined for the interpreta-tion of nolnitlal colllpoulids.
</nextsent>
<nextsent>otlr goal is to ac-count for l)roductive and actress-domain rules of interpretal,ion, \]xperimentation shows that the delinition of general rules, which inchide concep-tual description of the norninal constituents, im-plies the generation of multiple interpretations, es-pecially since we are dealing with arnbiguous nom-inal constituerits.
</nextsent>
<nextsent>we have \])reposed several ways of incoq)orat- ing specific 8elnantic inforination in our model, and we have suggested how corl)us observations can detect l)referential semantic relations and llll- predicted semantic patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F166">
<title id=" C94-2133.xml">multimodal definite clause grammar </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>
<prevsent>othe.r palmrs explor-ing multimodal interfaces include \[allgayer el.
</prevsent>
<prevsent>al., 1989; cohen el.
</prevsent>
</prevsection>
<citsent citstr=" C86-1085 ">
a . , 1989; cohen, 1991; kobsa et. al., 1986; <papid> C86-1085 </papid>wahlster, 1989\].</citsent>
<aftsection>
<nextsent>most of this work, howew. r, has tb- cused on the application of the ideas, and not on the principles for integrating the different inputs.
</nextsent>
<nextsent>1 7 conclusion.
</nextsent>
<nextsent>in this paper, we haw; proposed the use of grammar for dealing with input ewmt.s in lmdti-modal user in-terface.
</nextsent>
<nextsent>we proposed mm-i)c(~, novel gralnmatical framework for amult imodal inl.erface.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F167">
<title id=" C96-1067.xml">word completion  a first step toward target text mediated imt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of the three, imt is the most ambitious and theoretically the most powerflfl.
</prevsent>
<prevsent>it has potential advantage over post edition in that information imparted to the system may help it to avoid cascading errors that would later require much greater effort to correct; and it has potential advantage over pre edition in that knowledge of the machine current state may be useful in reducing the number of analyses the human is required to provide.
</prevsent>
</prevsection>
<citsent citstr=" C90-2006 ">
existing approaches to imt (blanchon, 1994; boitet, 1990; <papid> C90-2006 </papid>brown and nirenburg, 1990; kay, 1973; maruyama nd watanabe, 1990; whitelock et al , 1986; <papid> C86-1077 </papid>zajac, 1988) <papid> C88-2160 </papid>place the mt system in control of the translation process and for the most part limit the human role to performing various source language disambiguations on de- man&amp; although this arrangement is appropriate for some applications, notably those in which the user knowledge of tile target language may be limited, or where there are multiple target, lan-guages, it is not well suited to tile needs of pro-fessional oi  other highly skilled translators.</citsent>
<aftsection>
<nextsent>the lack of direct human control over the tinal target text (modulo postedition) is serious drawback in this case, and it is not clear that, for com-petent translator, disambiguat, ing source text, is much easier than translating it.
</nextsent>
<nextsent>this conclusion is supported by the fact that true imt is not, to our knowledge, used in most modern transla-tor support environments, eg (eurolang, 1995; i, rederking et al , 1993; ibm, 1995; kugler et al , 1991; nirenburg, 1992; ~li ados, 1995).
</nextsent>
<nextsent>such envi-ronments, when they incorporate mt at all, tend to do so wholesale, giving the user control over whether and when an mt component is invoked, as well as extensive post editing facilities for mod-ifying its outtmt, but not the ability to intervene while it is operating.
</nextsent>
<nextsent>in our view, this state of affairs should not be taken as evidence that imt for skilled translators is an inherently bad idea.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F168">
<title id=" C96-1067.xml">word completion  a first step toward target text mediated imt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of the three, imt is the most ambitious and theoretically the most powerflfl.
</prevsent>
<prevsent>it has potential advantage over post edition in that information imparted to the system may help it to avoid cascading errors that would later require much greater effort to correct; and it has potential advantage over pre edition in that knowledge of the machine current state may be useful in reducing the number of analyses the human is required to provide.
</prevsent>
</prevsection>
<citsent citstr=" C86-1077 ">
existing approaches to imt (blanchon, 1994; boitet, 1990; <papid> C90-2006 </papid>brown and nirenburg, 1990; kay, 1973; maruyama nd watanabe, 1990; whitelock et al , 1986; <papid> C86-1077 </papid>zajac, 1988) <papid> C88-2160 </papid>place the mt system in control of the translation process and for the most part limit the human role to performing various source language disambiguations on de- man&amp; although this arrangement is appropriate for some applications, notably those in which the user knowledge of tile target language may be limited, or where there are multiple target, lan-guages, it is not well suited to tile needs of pro-fessional oi  other highly skilled translators.</citsent>
<aftsection>
<nextsent>the lack of direct human control over the tinal target text (modulo postedition) is serious drawback in this case, and it is not clear that, for com-petent translator, disambiguat, ing source text, is much easier than translating it.
</nextsent>
<nextsent>this conclusion is supported by the fact that true imt is not, to our knowledge, used in most modern transla-tor support environments, eg (eurolang, 1995; i, rederking et al , 1993; ibm, 1995; kugler et al , 1991; nirenburg, 1992; ~li ados, 1995).
</nextsent>
<nextsent>such envi-ronments, when they incorporate mt at all, tend to do so wholesale, giving the user control over whether and when an mt component is invoked, as well as extensive post editing facilities for mod-ifying its outtmt, but not the ability to intervene while it is operating.
</nextsent>
<nextsent>in our view, this state of affairs should not be taken as evidence that imt for skilled translators is an inherently bad idea.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F169">
<title id=" C96-1067.xml">word completion  a first step toward target text mediated imt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of the three, imt is the most ambitious and theoretically the most powerflfl.
</prevsent>
<prevsent>it has potential advantage over post edition in that information imparted to the system may help it to avoid cascading errors that would later require much greater effort to correct; and it has potential advantage over pre edition in that knowledge of the machine current state may be useful in reducing the number of analyses the human is required to provide.
</prevsent>
</prevsection>
<citsent citstr=" C88-2160 ">
existing approaches to imt (blanchon, 1994; boitet, 1990; <papid> C90-2006 </papid>brown and nirenburg, 1990; kay, 1973; maruyama nd watanabe, 1990; whitelock et al , 1986; <papid> C86-1077 </papid>zajac, 1988) <papid> C88-2160 </papid>place the mt system in control of the translation process and for the most part limit the human role to performing various source language disambiguations on de- man&amp; although this arrangement is appropriate for some applications, notably those in which the user knowledge of tile target language may be limited, or where there are multiple target, lan-guages, it is not well suited to tile needs of pro-fessional oi  other highly skilled translators.</citsent>
<aftsection>
<nextsent>the lack of direct human control over the tinal target text (modulo postedition) is serious drawback in this case, and it is not clear that, for com-petent translator, disambiguat, ing source text, is much easier than translating it.
</nextsent>
<nextsent>this conclusion is supported by the fact that true imt is not, to our knowledge, used in most modern transla-tor support environments, eg (eurolang, 1995; i, rederking et al , 1993; ibm, 1995; kugler et al , 1991; nirenburg, 1992; ~li ados, 1995).
</nextsent>
<nextsent>such envi-ronments, when they incorporate mt at all, tend to do so wholesale, giving the user control over whether and when an mt component is invoked, as well as extensive post editing facilities for mod-ifying its outtmt, but not the ability to intervene while it is operating.
</nextsent>
<nextsent>in our view, this state of affairs should not be taken as evidence that imt for skilled translators is an inherently bad idea.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F170">
<title id=" C96-1067.xml">word completion  a first step toward target text mediated imt </title>
<section> hypothesis  eva luat ion.  </section>
<citcontext>
<prevsection>
<prevsent>be- cause of the restricted form of the state transition ualong with source and target text lengths in l/town et al fornmlation, lint these are constant for arty particular hmm.
</prevsent>
<prevsent>the results 1)resented in this pa- lter are optimistic in that the target text lengl;h was assumed to be known in advance, which of course is unrealistic.
</prevsent>
</prevsection>
<citsent citstr=" W93-0301 ">
iiowever, (dagan et al , 1993) <papid> W93-0301 </papid>have shown that knowledge of target-text length is not crucial to the model i)ertbrmanee.</citsent>
<aftsection>
<nextsent>395  ai  autres cxcmplcs  autres pays 3 ~ 1 :4 5 counlrics 8 8 figure 1: plausible state sequence by which the hmm corresponding to the english sentence have other cxamples from many other countries might generate the french sentence shown.
</nextsent>
<nextsent>the state-transition probabilities (horizontal arrows) are all 1/9 for model 1, and depend on the next state for model 2, eg p((froms, 6} ) = a(516).
</nextsent>
<nextsent>the output probabilities (vertical arrows) depend on the words involved, eg p(d  {from~, 6}) = p(d  from ).
</nextsent>
<nextsent>matrices for these models, they have the prop-erty that- unlike hmm in general they gen-erate target-language words independently.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F171">
<title id=" C96-2153.xml">semantic construction from parse forests </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our choice are parse forests since there are well- known methods of construction for t, hem and it is guarant;eed that every syntactic ambiguit;y can be represented in this way.
</prevsent>
<prevsent>isu ther more wide range of existing parsing systems, e.g.
</prevsent>
</prevsection>
<citsent citstr=" C92-1017 ">
(block and schachtl, 1992), <papid> C92-1017 </papid>produce packed representations of this kind.</citsent>
<aftsection>
<nextsent>let us begin wil;h rough sketch of the arctfitec- lure of the systmn.
</nextsent>
<nextsent>the semantic cons|;rllcl;ion module works on parse forests and presut)t)oses 907 semantic grammar of certain kind (see chap-ter 6).
</nextsent>
<nextsent>the semantic grammar must be correlated with the syntactic grammar so that there is one- to-one mapping between lexical entries and rules.
</nextsent>
<nextsent>input string parser using: syntactic grammar 4, parse forest emantic construction module using: semantic grammar $ packed udrs inside the semantic on struction module three processes are distinguished.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F172">
<title id=" C94-1078.xml">syntacticheaddriven generation </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J90-1004 ">
the previously proposed semanl ic -head-dr iw   .n ken eration methods run into problems if none of the daughter eonstituents in the syntact.o-semantic rule schemata of grammar fits the definition of semantic head given in \[shieber et al, 1990\].<papid> J90-1004 </papid></citsent>
<aftsection>
<nextsent>this is the case for the semantic analysis rnles of certain constraint- based semantic representations, e.g. underspecified discourse r,epresentation structures (ui)rss) \[l! rank and r.eyle, 1992\].
</nextsent>
<nextsent>since head-driven generation in general has its me  its, we simply return to syntactic definition of qmad  and demonstrate the feasibility of synlac ic - head-clriveu generation.
</nextsent>
<nextsent>in addition to its generality, syntactic-head-driven algorithm provides basis for logically well-defined treatment of the nmvement of (syntactic) heads, for which only ad-hoc solutions ex-isted, so far.
</nextsent>
<nextsent>iiead-driven generation methods combine both, top- clown search and bottom-np combination, in an ideal way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F173">
<title id=" C94-1078.xml">syntacticheaddriven generation </title>
<section> previous  work.  </section>
<citcontext>
<prevsection>
<prevsent>a clepth-first realization of this abstract op-down algorithm would work line as long ms tl,e semantic rep- 4z5 all leaves of the syntax tree are labeled with terminals (success) xo xo figure 1: top-down generation (g grammar description; xl syntactic ategory; xi semantic representation) resent ations of the leaves are always strictly smaller in size as the semantic form of the root node.
</prevsent>
<prevsent>but, if the actual semantic decomposition takes place in the lexi-con, the semantic representations of ome sub goals will be variables, which stand for semantic representations of any size: np vp , lambda ? \[y\] sere walk(y) walks (2) strict left-to-right, depth-first expansion of sub goals might run into problems with the grammar fragment in (2) if left..reeursive up-rule exists, because these- mantics of the np is only instantiated once the  scman- tic head  of the vp has been looked up in the lexicon.
</prevsent>
</prevsection>
<citsent citstr=" C88-2150 ">
a top-down, semantic-structure-driven generational- gorithm has been defined by \[wedekind, 1988\] <papid> C88-2150 </papid>which gives basis for dynamic subgoal-reordering guided by the semantic input.</citsent>
<aftsection>
<nextsent>some proposals have been made for subgoal reordering at compile-time, .g. \[minnen et al, 1993\] elaborating on the work by \[strzalkowski, 1990\].<papid> C90-2060 </papid></nextsent>
<nextsent>but there will be no helpful st, bgoal reordering for rules with semantic head recnrsion: l ambda :  ~ obviously, bottom-up component is required.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F174">
<title id=" C94-1078.xml">syntacticheaddriven generation </title>
<section> previous  work.  </section>
<citcontext>
<prevsection>
<prevsent>but, if the actual semantic decomposition takes place in the lexi-con, the semantic representations of ome sub goals will be variables, which stand for semantic representations of any size: np vp , lambda ? \[y\] sere walk(y) walks (2) strict left-to-right, depth-first expansion of sub goals might run into problems with the grammar fragment in (2) if left..reeursive up-rule exists, because these- mantics of the np is only instantiated once the  scman- tic head  of the vp has been looked up in the lexicon.
</prevsent>
<prevsent>a top-down, semantic-structure-driven generational- gorithm has been defined by \[wedekind, 1988\] <papid> C88-2150 </papid>which gives basis for dynamic subgoal-reordering guided by the semantic input.</prevsent>
</prevsection>
<citsent citstr=" C90-2060 ">
some proposals have been made for subgoal reordering at compile-time, .g. \[minnen et al, 1993\] elaborating on the work by \[strzalkowski, 1990\].<papid> C90-2060 </papid></citsent>
<aftsection>
<nextsent>but there will be no helpful st, bgoal reordering for rules with semantic head recnrsion: l ambda :  ~ obviously, bottom-up component is required.
</nextsent>
<nextsent>one solution is to keep to top-down strategy hut to do breadth-first search, ef.
</nextsent>
<nextsent>\[kohl, 1992\], <papid> C92-2103 </papid>which will be fair and not delay the access to the lexicon forever, as pure depth-first strategy does.</nextsent>
<nextsent>alternatively, one could adopt pure bottom-up strategy like the one which has been proposed in \[shieber, 1988\] <papid> C88-2128 </papid>and which is presented in fig.2 in lfighly schematic manner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F175">
<title id=" C94-1078.xml">syntacticheaddriven generation </title>
<section> previous  work.  </section>
<citcontext>
<prevsection>
<prevsent>but there will be no helpful st, bgoal reordering for rules with semantic head recnrsion: l ambda :  ~ obviously, bottom-up component is required.
</prevsent>
<prevsent>one solution is to keep to top-down strategy hut to do breadth-first search, ef.
</prevsent>
</prevsection>
<citsent citstr=" C92-2103 ">
\[kohl, 1992\], <papid> C92-2103 </papid>which will be fair and not delay the access to the lexicon forever, as pure depth-first strategy does.</citsent>
<aftsection>
<nextsent>alternatively, one could adopt pure bottom-up strategy like the one which has been proposed in \[shieber, 1988\] <papid> C88-2128 </papid>and which is presented in fig.2 in lfighly schematic manner.</nextsent>
<nextsent>a lexical entry qualifies as potential leaf node if its se-mantic form is non-trivial substructure of the input semantics (rule (lex)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F176">
<title id=" C94-1078.xml">syntacticheaddriven generation </title>
<section> previous  work.  </section>
<citcontext>
<prevsection>
<prevsent>one solution is to keep to top-down strategy hut to do breadth-first search, ef.
</prevsent>
<prevsent>\[kohl, 1992\], <papid> C92-2103 </papid>which will be fair and not delay the access to the lexicon forever, as pure depth-first strategy does.</prevsent>
</prevsection>
<citsent citstr=" C88-2128 ">
alternatively, one could adopt pure bottom-up strategy like the one which has been proposed in \[shieber, 1988\] <papid> C88-2128 </papid>and which is presented in fig.2 in lfighly schematic manner.</citsent>
<aftsection>
<nextsent>a lexical entry qualifies as potential leaf node if its se-mantic form is non-trivial substructure of the input semantics (rule (lex)).
</nextsent>
<nextsent>the derivation trees are built up by the (complete}-rule.
</nextsent>
<nextsent>generation finally succeeds if the root node of i, he current syntax tree is labeled with the start symbol of the grammar and the root of the semantic analysis trec with the input semantics.
</nextsent>
<nextsent>due to tile exclusion of phr~es with  empty  seman-tics (which would be trivial substructures of the input semantics), tile method always terminates, liowever, tile lack of top-down guidance will lead, in general, to lot of non-determinism.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F178">
<title id=" C94-1078.xml">syntacticheaddriven generation </title>
<section> syntactic -head-dr iven gener-.  </section>
<citcontext>
<prevsection>
<prevsent>a grammar is lexiealized if for every local syntax tree there is at least one pre terminal leaf, cf.
</prevsent>
<prevsent>\[sehabes and waters, 1993\].
</prevsent>
</prevsection>
<citsent citstr=" P93-1017 ">
note that lexicalization does not affect the expressibility of the grammar \[bar-llillcl el al., 1960\], \[schabes and waters, 1993\].<papid> P93-1017 </papid></citsent>
<aftsection>
<nextsent>ilowever, the gen-eration algorithm turns much simpler and hence more efficient.
</nextsent>
<nextsent>there is no need for transitive link relation, since goal can match immediately the mother node of preterminal.
</nextsent>
<nextsent>the lexicon access and the head- corner completion step can be merged into one rule schema 2.
</nextsent>
<nextsent>a version of the non-local-feature principle of iipsg has been integrated into the algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F179">
<title id=" C94-1078.xml">syntacticheaddriven generation </title>
<section> syntactic -head-dr iven gener-.  </section>
<citcontext>
<prevsection>
<prevsent>example (9).
</prevsent>
<prevsent>from these static values, the dynamic inher ted :s lash-va lues ithe cuf-system is an implementation of theorem prover for horn clause logic with typed feature terms \[dt;rre and dorna, 1993\].
</prevsent>
</prevsection>
<citsent citstr=" E89-1032 ">
2an instance of our head-corner generator (without an inte-grated treatment ofmovement) is the ucg-generator by calder et al \[calder et al, 1989\] (<papid> E89-1032 </papid>modulo the use of unary category transformation rules) which relies, in addition, on the symme-try of syntactic and semantic head.</citsent>
<aftsection>
<nextsent>a syntactic-head-drlven generator for kind of lexlcallzed grammars has been proposed independently \[kay, 1993\].
</nextsent>
<nextsent>another variant of lexlcmized grammar by \[dymetman ctal., 1990\] does not make use of the head-corner idea but rather corresponds to the top-down gen-eration schema presented in fig.1.
</nextsent>
<nextsent>(feature abbreviated ms //) can be calculated during generation, see rule (lex) in fig.7.
</nextsent>
<nextsent>( la ) choose lexical entry as the head xh of the current goal x0.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F180">
<title id=" C92-2121.xml">semantic network array processor as a massively parallel computing platform for high performance and largescale natural language processing </title>
<section> snap arch tec ture.  </section>
<citcontext>
<prevsection>
<prevsent>ov coling-92.
</prevsent>
<prevsent>nai, rves, aug. 23-28, 1992 tsmlttamtm4 ~et tmmant |nap.1 ~ cam~ oan@~a? . ~t~ ss^p figure i: snap-1 architecture strain ts using some type of networks which can be mapped onto semantic networks.
</prevsent>
</prevsection>
<citsent citstr=" P91-1002 ">
recent studies on the classification-based parsing \[kasper, 1989\] and the systemic choice network \[carpenter and pollard~ 1991\] <papid> P91-1002 </papid>assume hierarchical networks to represent var- ions linguistic constraints, and the search on these networks can be done by marker-passing.</citsent>
<aftsection>
<nextsent>also, there are more radical approaches to implement entire natu-ral language systems using parallel marker-passing as seen in \[norvig, 1986\], \[riesbeck and martin, 1985\], \[tomabechi, 1987\], and \[kitano, 1991\].
</nextsent>
<nextsent>there are, however, differences in types of information carried in each marker-passing model.
</nextsent>
<nextsent>we will describe our design decisions later.
</nextsent>
<nextsent>as reported in \[evett, at.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F181">
<title id=" C92-2121.xml">semantic network array processor as a massively parallel computing platform for high performance and largescale natural language processing </title>
<section> other approaches.  </section>
<citcontext>
<prevsection>
<prevsent>+m . . .
</prevsent>
<prevsent>nap-1 ooo lm 2o+ +~ 4oo +?~ +ix, figure 5: retrieval time vs. kb size framework of the unification-based grammar formal-ism and use vlkbs as major knowledge sources.
</prevsent>
</prevsection>
<citsent citstr=" C90-3052 ">
a more radical approacl however rooted in the tra-ditional model is to fully map the typed unification grammars \[emele and zajac, 1990 <papid> C90-3052 </papid>on the snap.</citsent>
<aftsection>
<nextsent>the typed unification grammar is based on the typed fea-ture structure (tfs) \[zajac, 1989\] <papid> P89-1001 </papid>and hpsg \[pollard and sag, 1987\], and represents all objects in tfs.</nextsent>
<nextsent>objects includes phrasal sign, lexical sign, general principles uch as the  head feature principle , the  subcat feature principle , grammar ules such as the  complement head constituent order feature principle,  the  head complements constituent or-der feature principle,  and lexical entries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F182">
<title id=" C92-2121.xml">semantic network array processor as a massively parallel computing platform for high performance and largescale natural language processing </title>
<section> other approaches.  </section>
<citcontext>
<prevsection>
<prevsent>nap-1 ooo lm 2o+ +~ 4oo +?~ +ix, figure 5: retrieval time vs. kb size framework of the unification-based grammar formal-ism and use vlkbs as major knowledge sources.
</prevsent>
<prevsent>a more radical approacl however rooted in the tra-ditional model is to fully map the typed unification grammars \[emele and zajac, 1990 <papid> C90-3052 </papid>on the snap.</prevsent>
</prevsection>
<citsent citstr=" P89-1001 ">
the typed unification grammar is based on the typed fea-ture structure (tfs) \[zajac, 1989\] <papid> P89-1001 </papid>and hpsg \[pollard and sag, 1987\], and represents all objects in tfs.</citsent>
<aftsection>
<nextsent>objects includes phrasal sign, lexical sign, general principles uch as the  head feature principle , the  subcat feature principle , grammar ules such as the  complement head constituent order feature principle,  the  head complements constituent or-der feature principle,  and lexical entries.
</nextsent>
<nextsent>the lexi-cal entries can be indexed under the lexical hierarchy.
</nextsent>
<nextsent>in this apporach, all linguistic knowledge is precom- piled into huge network.
</nextsent>
<nextsent>parsing and generation will be carried out as search on this network.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F183">
<title id=" C96-2142.xml">adjectival modification in text meaning representation </title>
<section> non-property-based adjectival.  </section>
<citcontext>
<prevsection>
<prevsent>abusivele is then tile even tive sense of the adjective formed from abuse-v1 (9), and abusive is 1a the agentive sense of the adjective in the same sense of abuse.
</prevsent>
<prevsent>the difference between file two is, essentially, in the position of ^ $varl in the lex-mai  and ill the scope of atlribntion of the two attitudes inherited from file ver-bal entry.
</prevsent>
</prevsection>
<citsent citstr=" W96-0310 ">
natla auy, file adjective ntries replace the ver-bal syn- struc below wifll the standard adj one (see 845 (1) above--for more data and discussion see also raskin and nirenburg 1996).<papid> W96-0310 </papid></citsent>
<aftsection>
<nextsent>(9) (abuse (abuse-v 1 (cat v) (syn- struc ((root svar0) (cat v) (subj ((root $varl) (eat n)) (obj ((root svar2) (cat n)))))) (sem-struc (lex-map (communicative- event (agent (value ^ $varl) (sere human)) (benef (value ^ $var2) (sem human)) (theme (value refseml)) (attitudel (type evaluative) (attitude-value (value (  0.25))) (scope refsem 1) (attributed-to (or (^$var 2 speaker)))) (attitude2 (type evaluative) (attitude-value (value (  0.25))) (scope ^$var2) (attributed-to ^$varl)))))) 4.5 relative (denominal) adjectives.
</nextsent>
<nextsent>rel alive adjectives ,are denourinal, object-related, in their meaning.
</nextsent>
<nextsent>the following example illustrates the connection between ominal mid adjectival meanings.
</nextsent>
<nextsent>(10) (i) (medicine (medicine-nl) (cat n) (syn-struc (root svar0) (cat n))) (sem-struc (lex-map medicine)))) (ii) (medical (medicabadj) (ca fad j) (sem-struc (l~x-map (^swirl (pertain-to medicine)))))) as file default property connecting file modifier to the modifiexl, the mikrokosmos analyzer uses file catch- all relation pertain-to.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F184">
<title id=" C96-2130.xml">learning partofspeech guessing rules from lexicon extension to nonconcatenative operations </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>an example of such guesser is the guesser supplied with the xerox tag-ger (kupiec, 1992).
</prevsent>
<prevsent>a similar approach was taken gome of the research reported here was funded as part of epsrc project ied4/1/5808  integrated lan-guage database .
</prevsent>
</prevsection>
<citsent citstr=" J93-2006 ">
in (weischedel et al, 1993) <papid> J93-2006 </papid>where an unknown word was guessed given the probabilities for an unknown word to be of particular pos, its cap-italisation feature and its ending.</citsent>
<aftsection>
<nextsent>in (brill, 1995) <papid> J95-4004 </papid>system of rules which uses both ending-guessing and more morphologically motivated rules is de- scribed.</nextsent>
<nextsent>best of these methods were reported to achieve 82-85% of tagging accuracy on unknown words, e.g.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F185">
<title id=" C96-2130.xml">learning partofspeech guessing rules from lexicon extension to nonconcatenative operations </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>a similar approach was taken gome of the research reported here was funded as part of epsrc project ied4/1/5808  integrated lan-guage database .
</prevsent>
<prevsent>in (weischedel et al, 1993) <papid> J93-2006 </papid>where an unknown word was guessed given the probabilities for an unknown word to be of particular pos, its cap-italisation feature and its ending.</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
in (brill, 1995) <papid> J95-4004 </papid>system of rules which uses both ending-guessing and more morphologically motivated rules is de- scribed.</citsent>
<aftsection>
<nextsent>best of these methods were reported to achieve 82-85% of tagging accuracy on unknown words, e.g.
</nextsent>
<nextsent>(brill, 1995; <papid> J95-4004 </papid>weischedel et al, 1993).<papid> J93-2006 </papid></nextsent>
<nextsent>in (mikheev, 1996) <papid> P96-1043 </papid>cascading word-pos guesser is described.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F189">
<title id=" C96-2130.xml">learning partofspeech guessing rules from lexicon extension to nonconcatenative operations </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>best of these methods were reported to achieve 82-85% of tagging accuracy on unknown words, e.g.
</prevsent>
<prevsent>(brill, 1995; <papid> J95-4004 </papid>weischedel et al, 1993).<papid> J93-2006 </papid></prevsent>
</prevsection>
<citsent citstr=" P96-1043 ">
in (mikheev, 1996) <papid> P96-1043 </papid>cascading word-pos guesser is described.</citsent>
<aftsection>
<nextsent>it applies first morpho-logical prefix and suffix guessing rules and then ending-guessing rules.
</nextsent>
<nextsent>this guesser is reported to achieve higher guessing accuracy than quoted be-fore which in average was about by 8-9% better than that of the xerox guesser and by 6-7% bet-ter than that of brill guesser, reaching 87-92% tagging accuracy on unknown words.
</nextsent>
<nextsent>there are two kinds of word-guessing rules em-ployed by the cascading uesser: morphological rules and ending guessing rules.
</nextsent>
<nextsent>morphological word-guessing rules describe how one word can be guessed given that another word is known.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F197">
<title id=" C96-2130.xml">learning partofspeech guessing rules from lexicon extension to nonconcatenative operations </title>
<section> the learning paradigm.  </section>
<citcontext>
<prevsection>
<prevsent>the major topic in the development of worth pos guess ers is the strategy which is to be used f()r dm acquisition of the guessing rules.
</prevsent>
<prevsent>brill (brill, 1995) <papid> J95-4004 </papid>outlines transformation-based learner which learns guessing rules from pre- tagged training corpus.</prevsent>
</prevsection>
<citsent citstr=" C94-1027 ">
a statistical-based suffix learnex is presented in (schmid, 1994).<papid> C94-1027 </papid></citsent>
<aftsection>
<nextsent>from l)re-tagged training corpus it constructs the suf-fix tree where every sutfix is associated with its information measure.
</nextsent>
<nextsent>the learning technique employed in the in-duction of tile rules of the cascading guesser (mikheev, 1996) <papid> P96-1043 </papid>does not require specially pre-pared training data and employs fully tmsuper- vised statistical learning from the lexicon supplied with the tagger and word-ti equeneies obtained from raw corpus.</nextsent>
<nextsent>the learning is implemented as two-staged process with fe.edback.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F227">
<title id=" C96-1016.xml">measuring semantic coverage </title>
<section> measures of size versus.  </section>
<citcontext>
<prevsection>
<prevsent>these measures are ofl;en mis-leading by themselves since what may be cov-ered are just one or two highly specific phe-nomena such as recognizing place or prod-uct names (i.e., limited breadth).
</prevsent>
<prevsent>nlp is not yet at stage where  covering corpus  can mean  analyzing all elenmnts of meanings of texts in the corpus.
</prevsent>
</prevsection>
<citsent citstr=" X93-1018 ">
it may be noted that  correctly  is problematic term since peo-ple often have difficulty judging what is  cor-rect  (will, 1993).<papid> X93-1018 </papid></citsent>
<aftsection>
<nextsent>moreover, correctness is orthogonal to the entire discussion here since we would like to increase semantic coverage along various dimensions while maintaining an acceptable degree of correctness.
</nextsent>
<nextsent>on the same lines, processing efficiency (often spec-ified in terms such as  sentence of length 9 takes 750 milliseconds to process ) is also more or less orthogonal to the dimensions we propose for measuring semantic overage.
</nextsent>
<nextsent>in-creasing semantic (:overage would be ntile if 34  henome l)t~. ired late   . rent ta te iiiii , , - ~ ~ : : . :   knowled base figure 1: dimensions of semantic coverage: (hlr- rent and desired l)irections processing became xponentially expensive as result.
</nextsent>
<nextsent>figure 1 shows the dimensions of size and breadth (or phenomenon coverage) along tit( , hor-izontal plane.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F228">
<title id=" C96-2102.xml">towards a syntactic account of punctuation </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>
<prevsent>several studies have already shown the potential for using punctuation within nlp.
</prevsent>
<prevsent>dale (1991) has shown the positive benefits of using punctuation ill the fields of discourse structure and semantics, suggesting that it can be used to indicate degrees of rhetorical balance and aggre-gation between juxtaposed elements, and also that in certain cases punctuation mark can determine the rhetorical relations that hold between two elements.
</prevsent>
</prevsection>
<citsent citstr=" C94-1069 ">
in the field of syntax jones (1994) <papid> C94-1069 </papid>has shown, through comparison of the performance of grammar that uses punctuation and one which does not, that for the more complex sentences of real language, parsing with punctuated grammar yields around two orders of magnitude fewer parses than parsing with an nnpunctuated grammar, and that additionally the punctuated parses better reflect the linguistic structure of the sentences.</citsent>
<aftsection>
<nextsent>briscoe and carroll (1995) extend this work to show the real contribution that usage of punctuation can make to the syntactic analysis of text.
</nextsent>
<nextsent>they also point out some funda-mental problems of the approach adopted by jones (1994).<papid> C94-1069 </papid></nextsent>
<nextsent>if, based on the conclusions of these studies, we are to include punctuation in nlp systems it is necessary to have some theory upon which treatment can be based.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F236">
<title id=" C94-2211.xml">a knowledge acquisition and management system for morphological dictionaries </title>
<section> finite-state morphology.  </section>
<citcontext>
<prevsection>
<prevsent>in section 4, an overview of the present state of the wm-project is given.
</prevsent>
<prevsent>systems one of the most widespread approaches to morphological dictionaries is finite- state morphology.
</prevsent>
</prevsection>
<citsent citstr=" C92-1025 ">
currently, the most attractive architecture is as in figure 1 (karttunen et al (1992)): <papid> C92-1025 </papid>1284 string alternation rules formative lexicon\] ~ compilation  1 compilation (lexicon fsa) (rule fsts) lexical ransducel2, figure l: architecture of two-level morphology.</citsent>
<aftsection>
<nextsent>compared to the original systems of koskenniemi (1983) and karttunen (1983), the major improvements made during the past ten years were in the compilation of the finite-state transition tables, and the switching from analyzers to transducers.
</nextsent>
<nextsent>by pushing finite-state technology to its limits, the resulting finite-state machines are extremely t2qst.
</nextsent>
<nextsent>if we consider current finite-state mor-phology systems as potential solution to the problem sketched in section 1, i.e. the acquisition and maintenance of mor-phological and lexical knowledge, they have number of shortcomings.
</nextsent>
<nextsent>first, knowledge acquisition is not supported very well: the editing of the formative lexicon and the string alternation rules must be done with text editors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F237">
<title id=" C94-2211.xml">a knowledge acquisition and management system for morphological dictionaries </title>
<section> word manager.  </section>
<citcontext>
<prevsection>
<prevsent>3.1.
</prevsent>
<prevsent>coverage.
</prevsent>
</prevsection>
<citsent citstr=" E87-1002 ">
a strictly finite-state mechanism has number of problems in covering natural language morphology, as has been recognized earlier (e.g. kay (1987)).<papid> E87-1002 </papid></citsent>
<aftsection>
<nextsent>in order to treat pre fixation and com-pounding in way parallel to suffixa- 1285 tion, the rules for combining format ives in wm are context-free.
</nextsent>
<nextsent>another differ-ence with two-level morphology is the basic distinction between inflection and word formation in wm.
</nextsent>
<nextsent>inflection is treated as the paradigmatic realization of certain features on lexeme, whereas word formation is the application of rule to lexeme, resulting in new lexeme.
</nextsent>
<nextsent>this type of distinction is lin-guistically motivated and pragmatically elaborated by ten hacken (1993).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F238">
<title id=" C94-1073.xml">a corpus based learning technique for building a selfextensible parser </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>

<prevsent>it is commonly believed in many psycho linguistics studies \[pinker, 1984; wexler &amp; culicover, 1980\] that extra input (in addition to raw sentences) is necessary for human language learners.
</prevsent>
</prevsection>
<citsent citstr=" P90-1019 ">
most existing compu-tational natural language acquisition models also as-sumed various kinds of the extra input (e.g. semantic associations \[siskind, 1990; <papid> P90-1019 </papid>webster &amp; marcus, 1989; <papid> P89-1022 </papid>zernik, 1987\] and syntactic structures \[berwick, 1985; liu &amp; soo, 1992a\] of input sentences) and human intervention (e.g. information interactively given by the trainer \[tang &amp; ilirschman, 1988; velardi et al, 1991\]) <papid> J91-2002 </papid>during learning.</citsent>
<aftsection>
<nextsent>the preparation of tile ex-tra input and human intervention may often cause inconsistencies, errors, and inefficiency in learning.
</nextsent>
<nextsent>it is often bottle neck in scaling up natural language processing systems.
</nextsent>
<nextsent>therefore, simple syntactic heuristics had been used to collect the extra input \[brent, 1993; <papid> J93-2002 </papid>sekine, 1992\].</nextsent>
<nextsent>however, the information that may be collect-ed by the simple heuristics is limited.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F239">
<title id=" C94-1073.xml">a corpus based learning technique for building a selfextensible parser </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>

<prevsent>it is commonly believed in many psycho linguistics studies \[pinker, 1984; wexler &amp; culicover, 1980\] that extra input (in addition to raw sentences) is necessary for human language learners.
</prevsent>
</prevsection>
<citsent citstr=" P89-1022 ">
most existing compu-tational natural language acquisition models also as-sumed various kinds of the extra input (e.g. semantic associations \[siskind, 1990; <papid> P90-1019 </papid>webster &amp; marcus, 1989; <papid> P89-1022 </papid>zernik, 1987\] and syntactic structures \[berwick, 1985; liu &amp; soo, 1992a\] of input sentences) and human intervention (e.g. information interactively given by the trainer \[tang &amp; ilirschman, 1988; velardi et al, 1991\]) <papid> J91-2002 </papid>during learning.</citsent>
<aftsection>
<nextsent>the preparation of tile ex-tra input and human intervention may often cause inconsistencies, errors, and inefficiency in learning.
</nextsent>
<nextsent>it is often bottle neck in scaling up natural language processing systems.
</nextsent>
<nextsent>therefore, simple syntactic heuristics had been used to collect the extra input \[brent, 1993; <papid> J93-2002 </papid>sekine, 1992\].</nextsent>
<nextsent>however, the information that may be collect-ed by the simple heuristics is limited.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F241">
<title id=" C94-1073.xml">a corpus based learning technique for building a selfextensible parser </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>

<prevsent>it is commonly believed in many psycho linguistics studies \[pinker, 1984; wexler &amp; culicover, 1980\] that extra input (in addition to raw sentences) is necessary for human language learners.
</prevsent>
</prevsection>
<citsent citstr=" J91-2002 ">
most existing compu-tational natural language acquisition models also as-sumed various kinds of the extra input (e.g. semantic associations \[siskind, 1990; <papid> P90-1019 </papid>webster &amp; marcus, 1989; <papid> P89-1022 </papid>zernik, 1987\] and syntactic structures \[berwick, 1985; liu &amp; soo, 1992a\] of input sentences) and human intervention (e.g. information interactively given by the trainer \[tang &amp; ilirschman, 1988; velardi et al, 1991\]) <papid> J91-2002 </papid>during learning.</citsent>
<aftsection>
<nextsent>the preparation of tile ex-tra input and human intervention may often cause inconsistencies, errors, and inefficiency in learning.
</nextsent>
<nextsent>it is often bottle neck in scaling up natural language processing systems.
</nextsent>
<nextsent>therefore, simple syntactic heuristics had been used to collect the extra input \[brent, 1993; <papid> J93-2002 </papid>sekine, 1992\].</nextsent>
<nextsent>however, the information that may be collect-ed by the simple heuristics is limited.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F242">
<title id=" C94-1073.xml">a corpus based learning technique for building a selfextensible parser </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>
<prevsent>the preparation of tile ex-tra input and human intervention may often cause inconsistencies, errors, and inefficiency in learning.
</prevsent>
<prevsent>it is often bottle neck in scaling up natural language processing systems.
</prevsent>
</prevsection>
<citsent citstr=" J93-2002 ">
therefore, simple syntactic heuristics had been used to collect the extra input \[brent, 1993; <papid> J93-2002 </papid>sekine, 1992\].</citsent>
<aftsection>
<nextsent>however, the information that may be collect-ed by the simple heuristics is limited.
</nextsent>
<nextsent>more sophisti-cated processors uch as taggers and parsers had also been tested in collecting the extra input \[webster &amp; marcus, 1989; <papid> P89-1022 </papid>zernik, 1989\].</nextsent>
<nextsent>ttowever, since learning was based on the input that may be successfully and unambiguously analyzed by the processors, upgrad-ing tile performance of the processors became new bottle neck of upgrading the performance of learning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F245">
<title id=" C96-2131.xml">an agreement corrector for russian </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system, called below  corrector , uses formal description of the russian syntax in terms of dependency structures.
</prevsent>
<prevsent>in our case, these structures are directed trees whose nodes represent the words of sentence, and whose arcs are labelled with names of syntactic relations (see mel ~uk 1974; mel ~uk and pertsov 1987; apres jan et al 1992).
</prevsent>
</prevsection>
<citsent citstr=" J83-3002 ">
the corrector is based on the general idea widely used in this kind of systems: if an input sentence is syntactically ill-formed, i.e. it cannot be assigned syntactic structure (synts), the system considers minimal changes that enable it to construct synts, and presents them as possible corrections (see, for example, carbonell and hayes 1983; jensen et al 1983; <papid> J83-3002 </papid>weiscbedel and sond-heimer 1983; mellish 1989; <papid> P89-1013 </papid>bolioli et al 1992).<papid> C92-3155 </papid></citsent>
<aftsection>
<nextsent>a segment of sentence is called  syntactically connected  if well-formed ependency tree can be constructed on it.
</nextsent>
<nextsent>(in terms of constituents, con-nectedness of segment would mean that it can be parsed as single constituent.)
</nextsent>
<nextsent>the  degree of syn-tactic dis connectedness  of sentence is defined as the least number of connected segments into which the sentence can be partitioned.
</nextsent>
<nextsent>hence, = 1 if and only if the sentence can be assigned synts; for an  absolutely disconnected  sentence would be equal to the number of words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F247">
<title id=" C96-2131.xml">an agreement corrector for russian </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system, called below  corrector , uses formal description of the russian syntax in terms of dependency structures.
</prevsent>
<prevsent>in our case, these structures are directed trees whose nodes represent the words of sentence, and whose arcs are labelled with names of syntactic relations (see mel ~uk 1974; mel ~uk and pertsov 1987; apres jan et al 1992).
</prevsent>
</prevsection>
<citsent citstr=" P89-1013 ">
the corrector is based on the general idea widely used in this kind of systems: if an input sentence is syntactically ill-formed, i.e. it cannot be assigned syntactic structure (synts), the system considers minimal changes that enable it to construct synts, and presents them as possible corrections (see, for example, carbonell and hayes 1983; jensen et al 1983; <papid> J83-3002 </papid>weiscbedel and sond-heimer 1983; mellish 1989; <papid> P89-1013 </papid>bolioli et al 1992).<papid> C92-3155 </papid></citsent>
<aftsection>
<nextsent>a segment of sentence is called  syntactically connected  if well-formed ependency tree can be constructed on it.
</nextsent>
<nextsent>(in terms of constituents, con-nectedness of segment would mean that it can be parsed as single constituent.)
</nextsent>
<nextsent>the  degree of syn-tactic dis connectedness  of sentence is defined as the least number of connected segments into which the sentence can be partitioned.
</nextsent>
<nextsent>hence, = 1 if and only if the sentence can be assigned synts; for an  absolutely disconnected  sentence would be equal to the number of words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F248">
<title id=" C96-2131.xml">an agreement corrector for russian </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system, called below  corrector , uses formal description of the russian syntax in terms of dependency structures.
</prevsent>
<prevsent>in our case, these structures are directed trees whose nodes represent the words of sentence, and whose arcs are labelled with names of syntactic relations (see mel ~uk 1974; mel ~uk and pertsov 1987; apres jan et al 1992).
</prevsent>
</prevsection>
<citsent citstr=" C92-3155 ">
the corrector is based on the general idea widely used in this kind of systems: if an input sentence is syntactically ill-formed, i.e. it cannot be assigned syntactic structure (synts), the system considers minimal changes that enable it to construct synts, and presents them as possible corrections (see, for example, carbonell and hayes 1983; jensen et al 1983; <papid> J83-3002 </papid>weiscbedel and sond-heimer 1983; mellish 1989; <papid> P89-1013 </papid>bolioli et al 1992).<papid> C92-3155 </papid></citsent>
<aftsection>
<nextsent>a segment of sentence is called  syntactically connected  if well-formed ependency tree can be constructed on it.
</nextsent>
<nextsent>(in terms of constituents, con-nectedness of segment would mean that it can be parsed as single constituent.)
</nextsent>
<nextsent>the  degree of syn-tactic dis connectedness  of sentence is defined as the least number of connected segments into which the sentence can be partitioned.
</nextsent>
<nextsent>hence, = 1 if and only if the sentence can be assigned synts; for an  absolutely disconnected  sentence would be equal to the number of words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F251">
<title id=" C96-2131.xml">an agreement corrector for russian </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>the corrector employs the morphological and syntactic dictionaries of russian which are part of the processor.
</prevsent>
<prevsent>as regards its linguistic content, the grammar of the corrector is similar to the russian 778 grammar used in tim processor, as they describe the same corresixmdence tween russian sentences and their syntactic structures, ltowever, the eorrector uses different formalism to represent rules, which partly stems from the difference in parsing methods: in the processor an algorithm of the so-called  filter-ing  type is implemented, while the corrector uses an algorithm of the  bottom-ut? variety.
</prevsent>
</prevsection>
<citsent citstr=" J83-3003 ">
it shouhl be noted dmt, in contrast certain other systems (for example, jensen et al 1983; <papid> J83-3002 </papid>weischedel and sondheimer 1983; <papid> J83-3003 </papid>v&onis; 1988; chanod et at.</citsent>
<aftsection>
<nextsent>1992), the present corrcvtor does not contain any  negative  information intended specifi-cally for correcting errors.
</nextsent>
<nextsent>it contains only  positive  rules that describe correct syntss and their parts and are assumed to be used in ordinary parsing.
</nextsent>
<nextsent>correction of errors is reduced to parsiug on the extended morphs, as described in ~ction 3.
</nextsent>
<nextsent>in comparison with the experimental version of the system (mitjushin 1993), in the present w~ rsion the grammar is augmented, and it is made possible to process words absent from the syntactic diction-ary and to consider quasi-correct sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F252">
<title id=" C96-2131.xml">an agreement corrector for russian </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>due to space limitations, we cannot describe the parsing algorithm in detail and give only sketch.
</prevsent>
<prevsent>the parsing, i.e. constructing fragments by the bottom-up rocedure, is performed in three stages, in the order of decreasing predictability of syntactic links.
</prevsent>
</prevsection>
<citsent citstr=" C88-2141 ">
the parser intensively exploits the idea of syntactic preference used in wide range of systems based on various principles (see, for example, tsejtin 1975; kula gina 1987, 1990; tsujii et al 1988; <papid> C88-2141 </papid>llobbs and bear 1990).</citsent>
<aftsection>
<nextsent>at the first stage the parser constructs fragments containing  high-l)rnbability  links; as result, on average 70 - 80% of all syntactic links of sentence are established (for details see mitjushin 1992).<papid> C92-3141 </papid></nextsent>
<nextsent>at the second stage the fragments are connected with  weaker  and more ainbiguous links, like those be-tween verb or noun and modifying prepositional phrase.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F253">
<title id=" C96-2131.xml">an agreement corrector for russian </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>the parsing, i.e. constructing fragments by the bottom-up rocedure, is performed in three stages, in the order of decreasing predictability of syntactic links.
</prevsent>
<prevsent>the parser intensively exploits the idea of syntactic preference used in wide range of systems based on various principles (see, for example, tsejtin 1975; kula gina 1987, 1990; tsujii et al 1988; <papid> C88-2141 </papid>llobbs and bear 1990).</prevsent>
</prevsection>
<citsent citstr=" C92-3141 ">
at the first stage the parser constructs fragments containing  high-l)rnbability  links; as result, on average 70 - 80% of all syntactic links of sentence are established (for details see mitjushin 1992).<papid> C92-3141 </papid></citsent>
<aftsection>
<nextsent>at the second stage the fragments are connected with  weaker  and more ainbiguous links, like those be-tween verb or noun and modifying prepositional phrase.
</nextsent>
<nextsent>at the third stage  rare  and/or  far  links are established, such as coordination of independent clauses.
</nextsent>
<nextsent>at the second and third stage attempts are also made t() establish links of previous stages, as they could be not established at their  own  stage because of missing intermediate links of tile later stages.
</nextsent>
<nextsent>at each stage the sentence is looked through from left to right, and attempts are made to link each fragment with its left neighbours.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F254">
<title id=" C94-2147.xml">table driven neural syntactic analysis of spoken korean </title>
<section> table driven neural syntactic analysis.  </section>
<citcontext>
<prevsection>
<prevsent>3.1.
</prevsent>
<prevsent>extending the categorial grammar.
</prevsent>
</prevsection>
<citsent citstr=" C86-1045 ">
to model the syntax of korean, we extended the categorial grammar in two ways (zeevat 1988; uszkoreit 1986).<papid> C86-1045 </papid></citsent>
<aftsection>
<nextsent>a (directional) categorial grammar is an ordered quintuple =  v, c, s, r, , where 1) v: the vocabulary set, 2) c: finite set of basic categories which generates full set  of categories via recursive application of the following category furmation rules: if a~ c, then a~  and if a~c  and b~ , then a/b~  and akbc , 3) s: the category for sentences, 4) r: set of functional application rules such as left cancellation ? b\a __  right cancellation  b/a _.  5) f: an assignment flmction from elements of into the subsets of .
</nextsent>
<nextsent>to treat the free word-order in korean, we extended the category formation rules and the application rules: 2 ) extended category formation rules: fa~c, then a~c  and fa~c  and scc   , then a/s~  and a~  and 4 ) extended functional application rules : left cancellation : ai i~{ai,...,an}-  ~{al,...,ai-l,ai+l,...,atl} right cancellation : b/{ai,...,an} ai --  b/{ai,...,ai_ l,ai+l,...,an} 3.2.
</nextsent>
<nextsent>interactive relaxation parsing.
</nextsent>
<nextsent>(howells 1988) developed an interactive relaxation parsing method which used dynamic network building scheme, and decay over time with competition instead of explicit inhibitory links, which is similar to the (reggia 1987) approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F255">
<title id=" C96-1043.xml">evaluating and comparing three text production techniques </title>
<section> three techniques for producing.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 automatic hybrid generation.
</prevsent>
<prevsent>( ianguistic + template approach) lea rcdoutc and gsi-erli have developed real- situation pilot system (for details on this project, see (coch, david, and magnolcr, 1995)) which builds up text (i.e. letter) fronl data entered by tile human operator who processes the request; custonlcf database; and knowledge bases.
</prevsent>
</prevsection>
<citsent citstr=" W96-0507 ">
it uses gsi-erli alcthgen text generation toolbox (see (coch, 1996)).<papid> W96-0507 </papid></citsent>
<aftsection>
<nextsent>the overall system is composed of two inain modules: thc i)ccision module and the generation module.
</nextsent>
<nextsent>the decision module has the following functions: 249 ? it allows the writer (who reads the request letter) to identify the author and subject of the request letter; ? it asks the writer for relevant information; ? it suggests decision (for example, order cancellation, renewal, etc.), after consulting the customer database and the domain knowledge; ? it asks the writer to validate the decision (or make different choice); ? it communicates the relevant information to the generation module.
</nextsent>
<nextsent>the generation module automatically produces the reply letter in standard l~rmat (sgml).
</nextsent>
<nextsent>this module consists of several submodulcs (for more details, see (coch, david and magnoler 1995) and (coch and david, 1994)): <papid> A94-1041 </papid>the direct generator; the text deep-structure planner (or conceptual planner); the text surface-structure planner (or rhetorical planner); and linguistic realisation, inspired by the meaning- text theory.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F256">
<title id=" C96-1043.xml">evaluating and comparing three text production techniques </title>
<section> three techniques for producing.  </section>
<citcontext>
<prevsection>
<prevsent>the decision module has the following functions: 249 ? it allows the writer (who reads the request letter) to identify the author and subject of the request letter; ? it asks the writer for relevant information; ? it suggests decision (for example, order cancellation, renewal, etc.), after consulting the customer database and the domain knowledge; ? it asks the writer to validate the decision (or make different choice); ? it communicates the relevant information to the generation module.
</prevsent>
<prevsent>the generation module automatically produces the reply letter in standard l~rmat (sgml).
</prevsent>
</prevsection>
<citsent citstr=" A94-1041 ">
this module consists of several submodulcs (for more details, see (coch, david and magnoler 1995) and (coch and david, 1994)): <papid> A94-1041 </papid>the direct generator; the text deep-structure planner (or conceptual planner); the text surface-structure planner (or rhetorical planner); and linguistic realisation, inspired by the meaning- text theory.</citsent>
<aftsection>
<nextsent>the direct generator has two functions: 1.
</nextsent>
<nextsent>planning the text in direct mode (top-down), anti 2.
</nextsent>
<nextsent>generating more or less fixed expressions or non- linguistic texts (i.e. tables, addresses, lists, etc.).
</nextsent>
<nextsent>the direct generator could be used without the other sub modules to generate texts in an automatic but non-linguistic way (manipulation of character strings).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F258">
<title id=" C96-2113.xml">an underspecified hpsg representation for information structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>2small caps are used to highlight pitch accents.
</prevsent>
<prevsent>moreover, is can be exploited to choose be-tween certain translation alternatives on sentence level (of.
</prevsent>
</prevsection>
<citsent citstr=" C96-1057 ">
(eberle, 1996)).<papid> C96-1057 </papid></citsent>
<aftsection>
<nextsent>the particle noch has different ranslations depending on accentuation: (3) g. maria sucht noch einen briefkasten.
</nextsent>
<nextsent>maria looks@~r still post-bo~ e. maria is still looking for post box.
</nextsent>
<nextsent>(4) g. maria sucht nocll einen briefkasten.
</nextsent>
<nextsent>e. maria is looking for another post box.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F259">
<title id=" C94-2134.xml">hypothesis selection in grammar acquisition </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>

<prevsent>re usability of existing linguistic knowledge is the most import,~mt requirement for the rapid development of pra.ctical nal, ural \]augtlage l)rocessing systems.
</prevsent>
</prevsection>
<citsent citstr=" E93-1027 ">
in or-der to realize, automatic ustomizatiou of existing lin-guistic knowledge to each applicat;ion domain, we pro-posed new approach of linguistic knowledge acquisi-tion, which is combination of symbolic and statistical approaches \[kiyono and tsujii, 1993\].<papid> E93-1027 </papid></citsent>
<aftsection>
<nextsent>the fi:amework of our al)proach is shown in figure 1.
</nextsent>
<nextsent> 1 111 .
</nextsent>
<nextsent>acquisilion flow starl;s with executing the l)arse of each sentence in corpus.
</nextsent>
<nextsent>if parsing lhiled, |,he  tiy- poi;hesis generator  produces the hyl)otheses of addi-tional gramnu~tical knowh;dge, each of which could re-cover t;lle incompleteness of the existing grammar af-ter ite rating t;his hypothesis generation process for all the senten( es in the corpus, the hypotheses are passed to the statistical analysis procc.ss and finally plausible hypotheses are chosen as new knowh .dge by observing statistical properties of tile hypotheses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F261">
<title id=" C94-2134.xml">hypothesis selection in grammar acquisition </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>acquisilion flow starl;s with executing the l)arse of each sentence in corpus.
</prevsent>
<prevsent>if parsing lhiled, |,he  tiy- poi;hesis generator  produces the hyl)otheses of addi-tional gramnu~tical knowh;dge, each of which could re-cover t;lle incompleteness of the existing grammar af-ter ite rating t;his hypothesis generation process for all the senten( es in the corpus, the hypotheses are passed to the statistical analysis procc.ss and finally plausible hypotheses are chosen as new knowh .dge by observing statistical properties of tile hypotheses.
</prevsent>
</prevsection>
<citsent citstr=" P89-1013 ">
unlike robusl; parsing \[mellish, 1989; <papid> P89-1013 </papid>goeser, 1992; <papid> C92-1022 </papid>l)ouglas and i)ale, 1 !)92\] or nou-statisl.ical ll)roach for grallunar a(:lluisil;ioll , our al/proach does ilol; require mechanism to detect tile cause of the parsing fail-- ure in the sentencial analysis phase and therefore the  ilypothesis (~eneral;or  may output ;111 i,he possible hy-potheses, l\[owever, the greater part 1)t  hypotheses gen-erated by simple deductive mechanism are unnatural revisions of the e.xisting rammar.</citsent>
<aftsection>
<nextsent>for example, even ~ rule which derives tot) node category ,9 direcl,ly from the input string of words might be hypol,hesize(i. *a.lso staff member ol7 mattsus|dt~t electric lndustri~d co.,ltd., shina.gawa, tokyo, .iapan.
</nextsent>
<nextsent>q__._ crlnts ) 17 ilypothesis \[ (lener;ttor nyl,oth~s,: ,~ i~)-- ..... ~ (~ra111111\[tr) st a.tistiea.i analyser - \[iypothesis i)b) indc-bascd processing corpus-betsed lsocessiu figure 1: framework of graulmar acquisition linguistically unnatural hypqtheses have harnfful et: fects on lille lbl lowing corpus-based process, not only making the process inefficient but, also int, erl ering wil, ll statistical dnl, as noise.
</nextsent>
<nextsent>in this paper, some techniques to remove such inadequate hytml, heses are proposed and the results of exl)eriments which show the efl ec- l.iwme.ss of the proposed techniques are also discussed.
</nextsent>
<nextsent>2.1 grammar formal sm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F262">
<title id=" C94-2134.xml">hypothesis selection in grammar acquisition </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>acquisilion flow starl;s with executing the l)arse of each sentence in corpus.
</prevsent>
<prevsent>if parsing lhiled, |,he  tiy- poi;hesis generator  produces the hyl)otheses of addi-tional gramnu~tical knowh;dge, each of which could re-cover t;lle incompleteness of the existing grammar af-ter ite rating t;his hypothesis generation process for all the senten( es in the corpus, the hypotheses are passed to the statistical analysis procc.ss and finally plausible hypotheses are chosen as new knowh .dge by observing statistical properties of tile hypotheses.
</prevsent>
</prevsection>
<citsent citstr=" C92-1022 ">
unlike robusl; parsing \[mellish, 1989; <papid> P89-1013 </papid>goeser, 1992; <papid> C92-1022 </papid>l)ouglas and i)ale, 1 !)92\] or nou-statisl.ical ll)roach for grallunar a(:lluisil;ioll , our al/proach does ilol; require mechanism to detect tile cause of the parsing fail-- ure in the sentencial analysis phase and therefore the  ilypothesis (~eneral;or  may output ;111 i,he possible hy-potheses, l\[owever, the greater part 1)t  hypotheses gen-erated by simple deductive mechanism are unnatural revisions of the e.xisting rammar.</citsent>
<aftsection>
<nextsent>for example, even ~ rule which derives tot) node category ,9 direcl,ly from the input string of words might be hypol,hesize(i. *a.lso staff member ol7 mattsus|dt~t electric lndustri~d co.,ltd., shina.gawa, tokyo, .iapan.
</nextsent>
<nextsent>q__._ crlnts ) 17 ilypothesis \[ (lener;ttor nyl,oth~s,: ,~ i~)-- ..... ~ (~ra111111\[tr) st a.tistiea.i analyser - \[iypothesis i)b) indc-bascd processing corpus-betsed lsocessiu figure 1: framework of graulmar acquisition linguistically unnatural hypqtheses have harnfful et: fects on lille lbl lowing corpus-based process, not only making the process inefficient but, also int, erl ering wil, ll statistical dnl, as noise.
</nextsent>
<nextsent>in this paper, some techniques to remove such inadequate hytml, heses are proposed and the results of exl)eriments which show the efl ec- l.iwme.ss of the proposed techniques are also discussed.
</nextsent>
<nextsent>2.1 grammar formal sm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F263">
<title id=" C94-2134.xml">hypothesis selection in grammar acquisition </title>
<section> grammar hypothes iz ing.  </section>
<citcontext>
<prevsection>
<prevsent>as we adopted unification- based grmnmar fbrmalism, we extended the algorithm so thai, it can hyt)othesize feature structure of lex-ical entry by observing surrounding successful cate-gories.
</prevsent>
<prevsent>as the algorithm works even ibr eoml)lex feature like subcategorization frame, it can be used to acquire subeategorization dictionary.
</prevsent>
</prevsection>
<citsent citstr=" P91-1027 ">
while some previous works on subcategorization fi alne acquisition assumed very little prior knowledge concerning the classification of subcategorization frames \[brent, 1991; <papid> P91-1027 </papid>manning, 1993\], <papid> P93-1032 </papid>our apllroach assumes the existence of grammar rules sllecifying subcategorization fi ame assignment, which enables more accurate learning of subcategorization frames.</citsent>
<aftsection>
<nextsent>multiple defects: in \[step 2\] of the algorithm, it is sul)t)osed that each unsuccessfully parsed sentence has exactly one cause of failure but sentmtee in actual texts often contains two or more causes of failure (for example, two unknown words).
</nextsent>
<nextsent>to solve this problem, we extended the algorithm so that it searches for multiple hypothesis which is set of rewriting rules and lexlcal entries.
</nextsent>
<nextsent>3.1 basic grammat ica const ra in ts.
</nextsent>
<nextsent>from linguistic point of view, hypotheses generated by the algorithnl given above might contain nlany un-natural hypotheses because the algorithm itself does not have any linguistic knowledge to judge the appro-priateness of hypotheses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F264">
<title id=" C94-2134.xml">hypothesis selection in grammar acquisition </title>
<section> grammar hypothes iz ing.  </section>
<citcontext>
<prevsection>
<prevsent>as we adopted unification- based grmnmar fbrmalism, we extended the algorithm so thai, it can hyt)othesize feature structure of lex-ical entry by observing surrounding successful cate-gories.
</prevsent>
<prevsent>as the algorithm works even ibr eoml)lex feature like subcategorization frame, it can be used to acquire subeategorization dictionary.
</prevsent>
</prevsection>
<citsent citstr=" P93-1032 ">
while some previous works on subcategorization fi alne acquisition assumed very little prior knowledge concerning the classification of subcategorization frames \[brent, 1991; <papid> P91-1027 </papid>manning, 1993\], <papid> P93-1032 </papid>our apllroach assumes the existence of grammar rules sllecifying subcategorization fi ame assignment, which enables more accurate learning of subcategorization frames.</citsent>
<aftsection>
<nextsent>multiple defects: in \[step 2\] of the algorithm, it is sul)t)osed that each unsuccessfully parsed sentence has exactly one cause of failure but sentmtee in actual texts often contains two or more causes of failure (for example, two unknown words).
</nextsent>
<nextsent>to solve this problem, we extended the algorithm so that it searches for multiple hypothesis which is set of rewriting rules and lexlcal entries.
</nextsent>
<nextsent>3.1 basic grammat ica const ra in ts.
</nextsent>
<nextsent>from linguistic point of view, hypotheses generated by the algorithnl given above might contain nlany un-natural hypotheses because the algorithm itself does not have any linguistic knowledge to judge the appro-priateness of hypotheses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F267">
<title id=" C94-2110.xml">virtual polysemy </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>one of the central aspects of lexical knowledge, per-haps the most significant in characterizing the creative aspect of language use, is our ability to generate appro~ priate uses of words in coutext.
</prevsent>
<prevsent>this ability is usually exercized by manipulating semantic and/or syntactic properties of words to achieve desirable collocational settings.
</prevsent>
</prevsection>
<citsent citstr=" J91-4003 ">
some illustrative examples are given in (1) where ? move can be interpreted as psychological verb when used transit ively with sentient direct object, * enjoy can take either noun or verb phrase com-plement when used in the expet~ence nse (puste- jovsky, 1991, <papid> J91-4003 </papid>1993; briscoe, copestake &amp; boguraev, 1990), , accord is synonymous with either agree or give/granl depending on its valency (poznafiski &amp; sanfilippo, 1993), and * the occurrence of directional argument with swim triggers shift in aspect ual interpretation.</citsent>
<aftsection>
<nextsent>(1) a. please move your car her sadness moves him b. john enjoys the book john enjoys reading the book e. the two alibis do not accord they accorded him warm welcome d. john swam for hours john swam across the channel although the precise nrechanisms which govern lexi-cal knowledge are still largely unknown, there is strong evidence that word sense extensibi\[ity is not arbitrary (atkins &amp;: levin, 1991; pustejovsky, 1991, <papid> J91-4003 </papid>1994; ostler atkius, 1991).</nextsent>
<nextsent>\[, or example, the amen ability of *this work was carried out as part of the f project at siiarp laboratories of europe.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F269">
<title id=" C94-2110.xml">virtual polysemy </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>this practice has largely charac-terized the compilation of dictionary entries in the tex- ico graphic tradition and has consequently iniluenced the shape of comlmtational lexicons since the large scale construction of such lexicons has typically in-volved semiautomatic knowledge acquisition from ma-chine readable dictionaries (carroll &amp; grover, 1989).
</prevsent>
<prevsent>word sense enumeration provides highly specialized lexical entries, but ? it fails to make explicit regularities about word sense cxtensibility which are necessary in promoting com- pactedness in lexical description, ? it is at odds with our ability to create new word uses in novel contexts, and ? it generates massive lexic~d ambiguity.
</prevsent>
</prevsection>
<citsent citstr=" C94-1043 ">
the use of lexical rules to generate different uses of word fl om kernel entry (copestake gg briscoe, 199l; sanfilippo, 1994) <papid> C94-1043 </papid>provides 1)rincipled alternative to word sense enumeration and can be made to eater for uovel uses of words.</citsent>
<aftsection>
<nextsent>ilowever, it is not clear whether this practice can address the question of lexical ambi-guity suc(:essfully as there is no known general control 696 regime on lexicm rules which would dctcrmiuisti(:ally restrict polysemic explmsion without preenq)ting the generation of l)ossible word uses.
</nextsent>
<nextsent>the gom , this paper is to show how more dy-namic approach to lexical stlecilic;~tion can iic used to tackle the l)roblem of lexical a, nhiguity and at the same time to model creative azl)ccts of word usage.
</nextsent>
<nextsent>in particular, our objective is to present ways iu which word sense enmner~d;ion n be eschewed by contl ating different word senses into single recta-entry which allows sense/usage expansiou without reliance on coercive operations /lel, as lexical rules.
</nextsent>
<nextsent>this approach is implemented within ~l typed feature structure lilt.- realism where word sense coutlatkm c~tn be c.xpressed in terms of lexical type uudersllccificatiou: wnrd en-try is ~lssociated with lcxical tylle havi ,g suhtype extensious which describe llossible uses of the word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F270">
<title id=" C94-1025.xml">probabilistic tagging with feature structures </title>
<section> tagging algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>figure 2: decomposition amt reconstruction of contextual tag probability (state transition probability) using probabilislic feature relations (pfh,) tain the d-pair, the other branch concerns tim tri-grams which do not contain it.
</prevsent>
<prevsent>the recursive xpan- sion of the tree stops if either the information gained by consulting further fv-pairs or the frequencies upon which the calculus is based are smaller than defined thresholds.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
starting point for the implementation of feature structure tagger was second-0rdcr-iimm tagger (tri- grams) based on modified version of the viterbi al-gorithm (viterbi, 1967; church, 1988) <papid> A88-1019 </papid>which we had earlier implemented in (kempe ,1994).</citsent>
<aftsection>
<nextsent>there we replaced the function which estimated the contextual probability of tag (state transition probability) hy dividing trigram frequency by bigram frequency (eq.
</nextsent>
<nextsent>3) with flmction which accomplished this cal-culus either using pf1ls in the above-described way (eq.s 6, 7) or by consulting decision tree (fig.
</nextsent>
<nextsent>3).
</nextsent>
<nextsent>to estimate the contextual probability of tag we have to know the contextual probabilities of its fv- pairs in order to multiply them (eq.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F271">
<title id=" C96-1072.xml">learning to recognize names across languages </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>analysis of the immediate context surrounding company names may lead to the discovery of key phrases like  said it ,  entered venture , and  is located in .
</prevsent>
<prevsent>table 1 shows summary of various types of features used in system development.
</prevsent>
</prevsection>
<citsent citstr=" M93-1011 ">
the longest common substring (lcs) feature (jacobs et al , 1993) <papid> M93-1011 </papid>is useful for finding proper name aliases.</citsent>
<aftsection>
<nextsent>2.2 feature trees.
</nextsent>
<nextsent>the id3 algorithm (quinlan, 1986) selects and orga-nizes features into discrimination tree, one tree for each type of name (person, company, etc.).
</nextsent>
<nextsent>the tree, once built, typically contains 100+ nodes, each one inquiring about one feature in the text, within the locality of the current proper name of interest.
</nextsent>
<nextsent>an example of tree which was generated for companies is shown in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F272">
<title id=" C96-1072.xml">learning to recognize names across languages </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>the tokenizer separates punctuation from words.
</prevsent>
<prevsent>for non-token languages (no spaces between words), it also separates contiguous characters into constituent words.
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
the part of speech (pos) tagger (brill, 1992; <papid> A92-1021 </papid>farwell et. al., 1994; matsumoto et al , 1992) at-taches parts of speech.</citsent>
<aftsection>
<nextsent>thc set of derived features is attached.
</nextsent>
<nextsent>during the delimitation phase, proper names are delimited using set of pos-based hand- coded tcmplates.
</nextsent>
<nextsent>using id3, dccision tree is gen-erated based on the existing feature set and thc speci-fied level of context be considered.
</nextsent>
<nextsent>the generated tree is applied to test data and scored.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F273">
<title id=" C96-1072.xml">learning to recognize names across languages </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>various parameterizations were used for system development, including: (1) context depth, (2) feature set size, (3) training set size, and (4) incorpo-ration of hand-coded phrasal templates.
</prevsent>
<prevsent>figure 3 shows ttle performance sults for eng-lish.
</prevsent>
</prevsection>
<citsent citstr=" W93-0104 ">
the metrics used were recall (r), precision (p), and an averaging measure, p&r;, defined as: p&r; = 2*p*r/(p+r) (2) obtained results for english compare to the english results of rau (1992) and mcdonald (1993).<papid> W93-0104 </papid></citsent>
<aftsection>
<nextsent>the weighted average of the p&r; for companies, per-sons, locations, and dates is 94.0%.
</nextsent>
<nextsent>ii recah ? precision compan los persons locations dates figure 3.
</nextsent>
<nextsent>english performance sults.
</nextsent>
<nextsent>the date grammar is rather small in comparison to other name classes, hence the performance for dates was perfect.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F274">
<title id=" C96-1085.xml">restricted parallelism in object oriented lexical parsing </title>
<section> object-oriented lexical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 the parse talk model.
</prevsent>
<prevsent>the parse talk grammar we use (for survey, cf.
</prevsent>
</prevsection>
<citsent citstr=" C94-1061 ">
broker et al (1994)) <papid> C94-1061 </papid>is based on binary relations be-tween words, e.g., dependency relations between head and its modifier, or textual relations between an anaphor and its antecedent.</citsent>
<aftsection>
<nextsent>restrictions on possible relations are attached to the words, e.g., expressed as valencies in the case of dependency relations, yielding strictly lexicalized grammar in the sense of schabes et al (1988).<papid> C88-2121 </papid></nextsent>
<nextsent>the individual behavior of words is gen-eralized in terms of word classes which are primarily motivated by governability orphrasal distribution; ad-ditional criteria include inflection, anaphoric behavior, and possible modifiers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F275">
<title id=" C96-1085.xml">restricted parallelism in object oriented lexical parsing </title>
<section> object-oriented lexical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>the parse talk grammar we use (for survey, cf.
</prevsent>
<prevsent>broker et al (1994)) <papid> C94-1061 </papid>is based on binary relations be-tween words, e.g., dependency relations between head and its modifier, or textual relations between an anaphor and its antecedent.</prevsent>
</prevsection>
<citsent citstr=" C88-2121 ">
restrictions on possible relations are attached to the words, e.g., expressed as valencies in the case of dependency relations, yielding strictly lexicalized grammar in the sense of schabes et al (1988).<papid> C88-2121 </papid></citsent>
<aftsection>
<nextsent>the individual behavior of words is gen-eralized in terms of word classes which are primarily motivated by governability orphrasal distribution; ad-ditional criteria include inflection, anaphoric behavior, and possible modifiers.
</nextsent>
<nextsent>a word class specifies mor-phosyntactic features, valencies, and allowed order- ings for its instances.
</nextsent>
<nextsent>further abstraction is achieved by organizing word classes at different levels of speci- ticity in terms of inheritance hierarchies.
</nextsent>
<nextsent>the specifi-cation of binary constraints already provides inherent means for robust analysis, as grammatical functions describe relations between words rather than well- tormed constituents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F276">
<title id=" C96-1085.xml">restricted parallelism in object oriented lexical parsing </title>
<section> object-oriented lexical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in order to establish, e.g., dependency re-lation the syntactic and semantic onstraints relating to the head and its prospective modifier are checked in tandem.
</prevsent>
<prevsent>due to this close coupling of grammat-ical and conceptual constraints syntactically possible though otherwise disallowed structures are filtered out as early as possible.
</prevsent>
</prevsection>
<citsent citstr=" E95-1033 ">
also, the provision of con-ceptual entities which are incrementally generated by the semantic interpretation process upplies the neces-sary anchoring points for the continuous resolution of textual anaphora nd ellipses (strube &amp; hahn, 1995; <papid> E95-1033 </papid>hahn et al, 1996).<papid> C96-1084 </papid></citsent>
<aftsection>
<nextsent>the lexical distribution of grammatical knowledge one finds in many lexiealized grammar formalisms (e.g., ltags (schabes et al, 1988) <papid> C88-2121 </papid>or hpsg (pollard &amp; sag, 1994)) is still constrained to declarative no- tions.</nextsent>
<nextsent>given that the control flow of text understand-ing is globally unpredictable and, also, needs to be purposefully adapted to critical states of the analysis (e.g., cases of severe extragrammaticality), we drive lexicalization to its limits in that we also incorporate procedural control knowledge at the lexical gr, unmar level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F277">
<title id=" C96-1085.xml">restricted parallelism in object oriented lexical parsing </title>
<section> object-oriented lexical parsing.  </section>
<citcontext>
<prevsection>
<prevsent>in order to establish, e.g., dependency re-lation the syntactic and semantic onstraints relating to the head and its prospective modifier are checked in tandem.
</prevsent>
<prevsent>due to this close coupling of grammat-ical and conceptual constraints syntactically possible though otherwise disallowed structures are filtered out as early as possible.
</prevsent>
</prevsection>
<citsent citstr=" C96-1084 ">
also, the provision of con-ceptual entities which are incrementally generated by the semantic interpretation process upplies the neces-sary anchoring points for the continuous resolution of textual anaphora nd ellipses (strube &amp; hahn, 1995; <papid> E95-1033 </papid>hahn et al, 1996).<papid> C96-1084 </papid></citsent>
<aftsection>
<nextsent>the lexical distribution of grammatical knowledge one finds in many lexiealized grammar formalisms (e.g., ltags (schabes et al, 1988) <papid> C88-2121 </papid>or hpsg (pollard &amp; sag, 1994)) is still constrained to declarative no- tions.</nextsent>
<nextsent>given that the control flow of text understand-ing is globally unpredictable and, also, needs to be purposefully adapted to critical states of the analysis (e.g., cases of severe extragrammaticality), we drive lexicalization to its limits in that we also incorporate procedural control knowledge at the lexical gr, unmar level.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F279">
<title id=" C96-1085.xml">restricted parallelism in object oriented lexical parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>major drawbacks concerned an overstatement of he role of lexical idiosyncrasies and the lack of grammatical bstraction and formalization.
</prevsent>
<prevsent>preserving the strengths of this approach (lexicalized control), but at the sane time reconciling it with cur-rent standards of lexicalized grammar specification, the parse talk system can be considered unifying approach which combines procedural and declarative specifications atthe grammar level informally disci-plined way.
</prevsent>
</prevsection>
<citsent citstr=" P93-1016 ">
this also distinguishes our approach from another major stream of object-oriented natural an- guage parsing which is almost entirely concerned with implementational aspects of object-oriented program- ruing, e.g., habert (1991), lin (1993) <papid> P93-1016 </papid>or yonezawa &amp; ohsawa (1994).</citsent>
<aftsection>
<nextsent>the reasons why we diverge from conventional parsing methodologies, e.g., chart parsing based on 506 earley- or tomita-style algorithms, are two-fold.
</nextsent>
<nextsent>first, at the syntactic level, any kind of chart parsing algorithm faces combinatorial problems with non-contiguous grammar specifications (accounting for discontinuous language structures) and, in particular, extra- and ungrammatical language input (cf., e.g., magerman &amp; weir (1992) <papid> P92-1006 </papid>for probabilistic and lee et al (1995) <papid> E95-1031 </papid>for symbolic heuristics to cope with that problem).</nextsent>
<nextsent>thus, under ealistic onditions, these tech-niques loose lot of their theoretical ppeal and com-pete with other approaches merely on the basis of per-formance measurements.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F280">
<title id=" C96-1085.xml">restricted parallelism in object oriented lexical parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this also distinguishes our approach from another major stream of object-oriented natural an- guage parsing which is almost entirely concerned with implementational aspects of object-oriented program- ruing, e.g., habert (1991), lin (1993) <papid> P93-1016 </papid>or yonezawa &amp; ohsawa (1994).</prevsent>
<prevsent>the reasons why we diverge from conventional parsing methodologies, e.g., chart parsing based on 506 earley- or tomita-style algorithms, are two-fold.</prevsent>
</prevsection>
<citsent citstr=" P92-1006 ">
first, at the syntactic level, any kind of chart parsing algorithm faces combinatorial problems with non-contiguous grammar specifications (accounting for discontinuous language structures) and, in particular, extra- and ungrammatical language input (cf., e.g., magerman &amp; weir (1992) <papid> P92-1006 </papid>for probabilistic and lee et al (1995) <papid> E95-1031 </papid>for symbolic heuristics to cope with that problem).</citsent>
<aftsection>
<nextsent>thus, under ealistic onditions, these tech-niques loose lot of their theoretical ppeal and com-pete with other approaches merely on the basis of per-formance measurements.
</nextsent>
<nextsent>second, including seman-tic considerations, even if we assume fficient syntac-tic processing for the sake of argument, he question arises how semantic interpretations can be processed in an incremental, comparably efficient way.
</nextsent>
<nextsent>though experiments have been run with packing feature struc-tures and inter leaving syntactic and semantic analyses (dowding et al, 1994), <papid> P94-1016 </papid>or with the intentional under- specification of logical forms (leaving scope ambigui-ties of quantifiers and neg ations underdetermined; cf., e.g., hobbs (1983) <papid> P83-1009 </papid>or reyle (1995)), <papid> E95-1001 </papid>no conclusive v- idences have been generated so far in favor of gen-eral method for efficient, online semantic interpreta- tion.</nextsent>
<nextsent>as we are faced, however, with the problem to work out text interpretations incrementally and within reasonable resource bounds, we opt for methodol-ogy that constrains the amount of ambiguous truc- tures right at the source.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F281">
<title id=" C96-1085.xml">restricted parallelism in object oriented lexical parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this also distinguishes our approach from another major stream of object-oriented natural an- guage parsing which is almost entirely concerned with implementational aspects of object-oriented program- ruing, e.g., habert (1991), lin (1993) <papid> P93-1016 </papid>or yonezawa &amp; ohsawa (1994).</prevsent>
<prevsent>the reasons why we diverge from conventional parsing methodologies, e.g., chart parsing based on 506 earley- or tomita-style algorithms, are two-fold.</prevsent>
</prevsection>
<citsent citstr=" E95-1031 ">
first, at the syntactic level, any kind of chart parsing algorithm faces combinatorial problems with non-contiguous grammar specifications (accounting for discontinuous language structures) and, in particular, extra- and ungrammatical language input (cf., e.g., magerman &amp; weir (1992) <papid> P92-1006 </papid>for probabilistic and lee et al (1995) <papid> E95-1031 </papid>for symbolic heuristics to cope with that problem).</citsent>
<aftsection>
<nextsent>thus, under ealistic onditions, these tech-niques loose lot of their theoretical ppeal and com-pete with other approaches merely on the basis of per-formance measurements.
</nextsent>
<nextsent>second, including seman-tic considerations, even if we assume fficient syntac-tic processing for the sake of argument, he question arises how semantic interpretations can be processed in an incremental, comparably efficient way.
</nextsent>
<nextsent>though experiments have been run with packing feature struc-tures and inter leaving syntactic and semantic analyses (dowding et al, 1994), <papid> P94-1016 </papid>or with the intentional under- specification of logical forms (leaving scope ambigui-ties of quantifiers and neg ations underdetermined; cf., e.g., hobbs (1983) <papid> P83-1009 </papid>or reyle (1995)), <papid> E95-1001 </papid>no conclusive v- idences have been generated so far in favor of gen-eral method for efficient, online semantic interpreta- tion.</nextsent>
<nextsent>as we are faced, however, with the problem to work out text interpretations incrementally and within reasonable resource bounds, we opt for methodol-ogy that constrains the amount of ambiguous truc- tures right at the source.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F282">
<title id=" C96-1085.xml">restricted parallelism in object oriented lexical parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>thus, under ealistic onditions, these tech-niques loose lot of their theoretical ppeal and com-pete with other approaches merely on the basis of per-formance measurements.
</prevsent>
<prevsent>second, including seman-tic considerations, even if we assume fficient syntac-tic processing for the sake of argument, he question arises how semantic interpretations can be processed in an incremental, comparably efficient way.
</prevsent>
</prevsection>
<citsent citstr=" P94-1016 ">
though experiments have been run with packing feature struc-tures and inter leaving syntactic and semantic analyses (dowding et al, 1994), <papid> P94-1016 </papid>or with the intentional under- specification of logical forms (leaving scope ambigui-ties of quantifiers and neg ations underdetermined; cf., e.g., hobbs (1983) <papid> P83-1009 </papid>or reyle (1995)), <papid> E95-1001 </papid>no conclusive v- idences have been generated so far in favor of gen-eral method for efficient, online semantic interpreta- tion.</citsent>
<aftsection>
<nextsent>as we are faced, however, with the problem to work out text interpretations incrementally and within reasonable resource bounds, we opt for methodol-ogy that constrains the amount of ambiguous truc- tures right at the source.
</nextsent>
<nextsent>hence, the incompleteness of the algorithm trades theoretical purism for feasibility of realistic nlp.
</nextsent>
<nextsent>we have presented restricted approach to paral-lelism for object-oriented lexicalized parsing.
</nextsent>
<nextsent>given the complex control structure requirements of real-istic text understanding system (integrated, incremen-tal, robust processing), we argued for unifying ap-proach in which declarative grammar constraints are lexically encoded and procedural knowledge can be specified by distinguished lexicalized communication primitives (viz.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F283">
<title id=" C96-1085.xml">restricted parallelism in object oriented lexical parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>thus, under ealistic onditions, these tech-niques loose lot of their theoretical ppeal and com-pete with other approaches merely on the basis of per-formance measurements.
</prevsent>
<prevsent>second, including seman-tic considerations, even if we assume fficient syntac-tic processing for the sake of argument, he question arises how semantic interpretations can be processed in an incremental, comparably efficient way.
</prevsent>
</prevsection>
<citsent citstr=" P83-1009 ">
though experiments have been run with packing feature struc-tures and inter leaving syntactic and semantic analyses (dowding et al, 1994), <papid> P94-1016 </papid>or with the intentional under- specification of logical forms (leaving scope ambigui-ties of quantifiers and neg ations underdetermined; cf., e.g., hobbs (1983) <papid> P83-1009 </papid>or reyle (1995)), <papid> E95-1001 </papid>no conclusive v- idences have been generated so far in favor of gen-eral method for efficient, online semantic interpreta- tion.</citsent>
<aftsection>
<nextsent>as we are faced, however, with the problem to work out text interpretations incrementally and within reasonable resource bounds, we opt for methodol-ogy that constrains the amount of ambiguous truc- tures right at the source.
</nextsent>
<nextsent>hence, the incompleteness of the algorithm trades theoretical purism for feasibility of realistic nlp.
</nextsent>
<nextsent>we have presented restricted approach to paral-lelism for object-oriented lexicalized parsing.
</nextsent>
<nextsent>given the complex control structure requirements of real-istic text understanding system (integrated, incremen-tal, robust processing), we argued for unifying ap-proach in which declarative grammar constraints are lexically encoded and procedural knowledge can be specified by distinguished lexicalized communication primitives (viz.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F284">
<title id=" C96-1085.xml">restricted parallelism in object oriented lexical parsing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>thus, under ealistic onditions, these tech-niques loose lot of their theoretical ppeal and com-pete with other approaches merely on the basis of per-formance measurements.
</prevsent>
<prevsent>second, including seman-tic considerations, even if we assume fficient syntac-tic processing for the sake of argument, he question arises how semantic interpretations can be processed in an incremental, comparably efficient way.
</prevsent>
</prevsection>
<citsent citstr=" E95-1001 ">
though experiments have been run with packing feature struc-tures and inter leaving syntactic and semantic analyses (dowding et al, 1994), <papid> P94-1016 </papid>or with the intentional under- specification of logical forms (leaving scope ambigui-ties of quantifiers and neg ations underdetermined; cf., e.g., hobbs (1983) <papid> P83-1009 </papid>or reyle (1995)), <papid> E95-1001 </papid>no conclusive v- idences have been generated so far in favor of gen-eral method for efficient, online semantic interpreta- tion.</citsent>
<aftsection>
<nextsent>as we are faced, however, with the problem to work out text interpretations incrementally and within reasonable resource bounds, we opt for methodol-ogy that constrains the amount of ambiguous truc- tures right at the source.
</nextsent>
<nextsent>hence, the incompleteness of the algorithm trades theoretical purism for feasibility of realistic nlp.
</nextsent>
<nextsent>we have presented restricted approach to paral-lelism for object-oriented lexicalized parsing.
</nextsent>
<nextsent>given the complex control structure requirements of real-istic text understanding system (integrated, incremen-tal, robust processing), we argued for unifying ap-proach in which declarative grammar constraints are lexically encoded and procedural knowledge can be specified by distinguished lexicalized communication primitives (viz.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F285">
<title id=" C96-1024.xml">compositional semantics in verb mobil </title>
<section> re la ted  work.  </section>
<citcontext>
<prevsection>
<prevsent>in umrs this is modified by expressing the scoping possibilities directly as disiunctions.
</prevsent>
<prevsent>the main difference between both types of mrss and lui) is that the interpretation of lui) in an object language other than ordinary predicate logic is well delined, as described in section 3.2.
</prevsent>
</prevsection>
<citsent citstr=" P91-1021 ">
the translation task of the sics-sri l:/ilin-- gnal conversation interpreter, bci (alshawi et al., 1991) <papid> P91-1021 </papid>is quite similar to that of verbmobil.</citsent>
<aftsection>
<nextsent>the bci does translation at the level of quasi- 13 3 das : geht : ap.
</nextsent>
<nextsent>  { } ,{ l, : dm(z) } ,{ li main(p ) }  @p(z) ll : pred(gehen, e), ) ay   { h, }, :pre (the..e,e,y), ,{ zk   h, }   lk : li lj jeder : ap.aq.
</nextsent>
<nextsent>  { hi } lk : lj maln(p) , it   top(q),     main(q)   hi 11 : lk -4 hi te rmin : ax.
</nextsent>
<nextsent>  { } ,{ li : termin(x) } ,{ }   15 pred(gehen, e), 17   ho,   das geht : ae.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F286">
<title id=" C96-1024.xml">compositional semantics in verb mobil </title>
<section> re la ted  work.  </section>
<citcontext>
<prevsection>
<prevsent>  { hi } lk : lj maln(p) , it   top(q),     main(q)   hi 11 : lk -4 hi te rmin : ax.
</prevsent>
<prevsent>  { } ,{ li : termin(x) } ,{ }   15 pred(gehen, e), 17   ho,   das geht : ae.
</prevsent>
</prevsection>
<citsent citstr=" P92-1005 ">
{ ho }, 16 pred(theme,e,z) ,   14 ~i 17 lz 15 16   @p(z) @ q(z) figure 1: lexical entries and sample derivation in lud logical form, qlf which also is monotonic representation language for compositional seman-tics as discussed in (alshawi and crouch, 1992).<papid> P92-1005 </papid></citsent>
<aftsection>
<nextsent>the qlf formalism incorporates davidson ian approach to semantics, containing underspecified quantifiers and operators, as well as  anaphoric terms  which stand for entities and relations to be determined by reference resolution.
</nextsent>
<nextsent>in these re-spects, the basic ideas of the qlf formalism are quite similar to lud.
</nextsent>
<nextsent>imp lemen tat ion 5.1 grammar.
</nextsent>
<nextsent>the lud semantic on struction component has been implemented in the grammar formalism tug, trace and unification grammar (block and schachtl, 1992), <papid> C92-1017 </papid>in system called trug (in coop-eration with siemens ag, munich, who provided the german syntax and the trug system).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F287">
<title id=" C96-1024.xml">compositional semantics in verb mobil </title>
<section> syntax -semant ics  inter face  and.  </section>
<citcontext>
<prevsection>
<prevsent>in these re-spects, the basic ideas of the qlf formalism are quite similar to lud.
</prevsent>
<prevsent>imp lemen tat ion 5.1 grammar.
</prevsent>
</prevsection>
<citsent citstr=" C92-1017 ">
the lud semantic on struction component has been implemented in the grammar formalism tug, trace and unification grammar (block and schachtl, 1992), <papid> C92-1017 </papid>in system called trug (in coop-eration with siemens ag, munich, who provided the german syntax and the trug system).</citsent>
<aftsection>
<nextsent>tug is formalism that combines ideas from gov-ernment and binding theory, namely the use of traces, with unification in order to account for, for example, the free word order phenomena found in german.
</nextsent>
<nextsent>5.1.1 syntax and semantics tug grammar basically consists of patr-ii style context free rules with feature annotations.
</nextsent>
<nextsent>each syntactic rule gets annotated with seman-tic counterpart.
</nextsent>
<nextsent>in this way, syntactic derivation and semantic construction are fully interleaved and semantics can further constrain the possible readings of the input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F288">
<title id=" C96-1028.xml">cross serial dependencies are not hard to process </title>
<section> a\[i,...\] ----+ w\[...\]  </section>
<citcontext>
<prevsection>
<prevsent>these classes of languages can be arranged into hierarchy based on proper containment rela-tions among them: 3 2 1.5 1 0 (0 is the least restrictive, the most expres- sive).
</prevsent>
<prevsent>aho (1968) shows the existence of lan-guages that are proper subset of the indexed languages and proper superset of the context free.
</prevsent>
</prevsection>
<citsent citstr=" J89-4003 ">
joshi et al (1989) conjecture that there is actually convergence inexpressive power among the  mildly context sensitive  (mcs) lan-guages, but other work points out exceptions (sav- itch, 1989; <papid> J89-4003 </papid>vogel and erjavec, 1994).</citsent>
<aftsection>
<nextsent>since the reduplication languages (savitch, 1989) <papid> J89-4003 </papid>are cen-tral to the point of this paper we define them-- the languages homomorphic to the set of strings {ww\[w 6 {a,b}*}.</nextsent>
<nextsent>the string duplication lan-guages are not context free, although they are closely related to the string reversal anguages ({wwr\[w 6 {a, b}*}, where the indicates there- versal operator) which are context free.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F290">
<title id=" C96-1028.xml">cross serial dependencies are not hard to process </title>
<section> a\[i,...\] ----+ w\[...\]  </section>
<citcontext>
<prevsection>
<prevsent>meta- grammatical techniques give an alternative that preserve coverage, but use special purpose pro-cessing.
</prevsent>
<prevsent>we suggest parsing method for lan-guages that relyon ww which does not cost greater complexity fec than the worst case for parsing context fi ee grammars.
</prevsent>
</prevsection>
<citsent citstr=" J83-2002 ">
the method is meta grammatical and therefore akin to propos-als put forward previously for handling coordina-tion (dahl and mccord, 1983) <papid> J83-2002 </papid>with logic gram-mars and tags (shieber, 1995) or for extraposi- tion (milward, 1994).</citsent>
<aftsection>
<nextsent>the method is constrained enough not to augment overall processing com-plexity, implying that ww does not require the worst case recognition complexity for its charac-teristic class, the mcs languages.
</nextsent>
<nextsent>3.1 why not?.
</nextsent>
<nextsent>trivially, the string duplication languages can be recognized with time complexity proportional to the length of the string - - if the string is of even length, and its first half is identical to the sec-ond half, then this can be established in just lin-ear time.
</nextsent>
<nextsent>though trivial in the sense of being about mere recognition, this is nonetheless inter-esting.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F295">
<title id=" C96-1028.xml">cross serial dependencies are not hard to process </title>
<section> d iscuss ion   </section>
<citcontext>
<prevsection>
<prevsent>the idea ix that speakers of bmguages with ww homomorphisms have different pattenl of in-voking copy-checking than those who speak lan- 161 guages that do not admit cross serial dependen-cies.
</prevsent>
<prevsent>these differences should be manifest in speech corpora like those that are currently being accumulated (anderson et al, 1992; miller, 1995), but which n~d augmentation by corpus derived from copy-language dialects.
</prevsent>
</prevsection>
<citsent citstr=" C92-4171 ">
verifying this would, for example, establish whether the copied strings need to be constituents, and this has bearing on whether processing models designed for incremen-tal interpretation (milward, 1992) <papid> C92-4171 </papid>are the best de-scriptors of human performance. </citsent>
<aftsection>
<nextsent>we do not offer arguments that our meta grammatical approach is the best description of human processing of cross- serial dependencies, just that it is another theo-retical justification for the difference in process-ing nested dependencies and efficient processing of crossed dependencies.
</nextsent>
<nextsent>acknowledgements vogel is grateful to the sfb 340 for funding his stay stuttgart; hahn acknowledges the sup-port of esrc grant no.
</nextsent>
<nextsent>r004293341442; brani- tan, epsi~c research studentship no. 92315069.
</nextsent>
<nextsent>all would like to thank catherine collin, toma~ erjavec, tsutomu fujinami:, merce prat, fred p0powich, mark steedman, and the anonymous reviewers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F296">
<title id=" C96-2099.xml">segmenting sentences into linky strings using dbigram statistics </title>
<section> l inking score  </section>
<citcontext>
<prevsection>
<prevsent>d.bigrsm 7q \[e3 l__ l___i \ [ __ l__ ? =  i; i, j jr \] . . .~ ....
</prevsent>
<prevsent>figure l: i)-bigram 3.3 ca lcu la ion.
</prevsent>
</prevsection>
<citsent citstr=" C94-1036 ">
mutua in i rmat ion i th is tance expression (1) iv for calculating mutual intbrma- tion between two events(nobesawa et al, 1994): (<papid> C94-1036 </papid>ai, bj, d) bj, d) = log ( .d /   (b , ) (1) ai : letter p(ai) : the possibility the letter ai appears l?(ai, bj, d) : the possibility ai and bj appear together with the distance in sentence the parameter shows the distance between two events.</citsent>
<aftsection>
<nextsent>in figure 2, the distance between   m~d  pen  is 1, and the distm,ce between  is  and  pen  is 2 as well.
</nextsent>
<nextsent>since the event order has meaning, in this case the distance between  pen  and   is defined as -1 . thl~ is pen . dm2 d=3 figure 2: d-bigram example as the vahm of mi gets bigger, the stronger is the association between the two events.
</nextsent>
<nextsent>l inking score expression (2) is tbr calculating the linking score between two letters in sentence ~.
</nextsent>
<nextsent>z (2) d:-:l j= - (d -1) dmax : max distance used wl : the i-th letter in the sentence g(d) : certain weight for iv// concerning distance between letters the information between two remote words has less nmaning in sentence when it comes to the semantic analysis(church and hanks, 1989).<papid> P89-1010 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F297">
<title id=" C96-2099.xml">segmenting sentences into linky strings using dbigram statistics </title>
<section> l inking score  </section>
<citcontext>
<prevsection>
<prevsent>since the event order has meaning, in this case the distance between  pen  and   is defined as -1 . thl~ is pen . dm2 d=3 figure 2: d-bigram example as the vahm of mi gets bigger, the stronger is the association between the two events.
</prevsent>
<prevsent>l inking score expression (2) is tbr calculating the linking score between two letters in sentence ~.
</prevsent>
</prevsection>
<citsent citstr=" P89-1010 ">
z (2) d:-:l j= - (d -1) dmax : max distance used wl : the i-th letter in the sentence g(d) : certain weight for iv// concerning distance between letters the information between two remote words has less nmaning in sentence when it comes to the semantic analysis(church and hanks, 1989).<papid> P89-1010 </papid></citsent>
<aftsection>
<nextsent>according to the idea we put g(d) in the expres-sion so that nearer pair can be more effective in calculating the score of the sentence.
</nextsent>
<nextsent>|   , , i - -  1 c @@ g figure 3: calculation of linking score pair of far-away letters do not have strong relation between each other, neither syntactically nor semantically.
</nextsent>
<nextsent>for this reason we use dma,, and in this paper we set tile dmax value 2 to 5 and 1.
</nextsent>
<nextsent>when the dma, is 1, the mi used in calculation is only bigram data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F298">
<title id=" C96-1052.xml">a computational model of incremental utterance production in task oriented dialogues </title>
<section> re la ted  research.  </section>
<citcontext>
<prevsection>
<prevsent>this model exploits the following pragmatic onstraints.
</prevsent>
<prevsent>(cl) avoid conveying redundant information.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
((:2) pronominalize objects in the focus of atten-tion (grosz and sidner 1986).<papid> J86-3001 </papid></citsent>
<aftsection>
<nextsent>(c3) be relevant according to the attentionm state.
</nextsent>
<nextsent>?\[ he context model records the information that has been conveyed and tracks the attentional state.
</nextsent>
<nextsent>for example, consider the domain action of moving from one location 11 to another 12.
</nextsent>
<nextsent>to describe such domain action with verbs such as  iku(go) , it must be in focus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F299">
<title id=" C96-1052.xml">a computational model of incremental utterance production in task oriented dialogues </title>
<section> re la ted  research.  </section>
<citcontext>
<prevsection>
<prevsent>8 experiments.
</prevsent>
<prevsent>this model has been implemented in com-mon lisp.
</prevsent>
</prevsection>
<citsent citstr=" P91-1040 ">
a logical constraint unification sys- tern (nakano 1991) <papid> P91-1040 </papid>is used in the planners.</citsent>
<aftsection>
<nextsent>the domain planner includes 18 action schemata nd 16 decomposition methods.
</nextsent>
<nextsent>the utterance plan- 308 (el) musas hino sentaa kara-wa desune / pn front-topic, copula (from the musas hino center) (e2) ~to kichijoji made / dete-kudasai / fili,f,i~ pn to go-t)le~se (crm to kichijoji station) (please go) @3) ~to desune sore kara inokashira-sen de filler then pn by (erm then by the inokastfira line) (e4) odakyu-sen hi/ norikaete / pn for change ((:hange train for the odakyu line) basu de / moyori-no-eki made / bus by nearest station to (by ires) (to the nearest station) desune / shimokitazawa made / coi ui,a pn to (to shimokitazawa station) aiko-ishida made / ikimasu / .....
</nextsent>
<nextsent>pn to go (to aiko-ishida station) (go) figure 6: discourse generated by implemented system ner includes 16 action schemata nd 16 decom-position methods.
</nextsent>
<nextsent>we ewduated pragmatic on- strain ts in an utterance simulation experiment, where discourses generate.d with the constraints were cont pared with those generated without them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F300">
<title id=" C96-2111.xml">topdown predictive linking and complexfeaturebased formalisms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>complex-feature-based formalisms are under- stood here as equivalent to unification-based formalisms as exemplified by patr-ii, hpsg, and others (cf shieber 1986, carpenter 1992).
</prevsent>
<prevsent>such formalisms typically include context- free (cf) base, which allows the use of parsing algorithms designed for cf languages despite the fact that complex-feature-based formalisms are essentially more powerful than cf gram-mars.
</prevsent>
</prevsection>
<citsent citstr=" P85-1018 ">
however, such an adaptation of cf algo-rithms involves their extension to possibly infi-nite nonterminal domains, which, as shieber (1985) <papid> P85-1018 </papid>and haas (1989) <papid> J89-4001 </papid>have shown, is nontriv- ial.</citsent>
<aftsection>
<nextsent>various cf algorithms make use of binary relation between goal category and the cate-gory of constituent (phrase or word) which either has just been parsed or is to be parsed next.
</nextsent>
<nextsent>different erms have been used to desig-nate this relation; kay (1980) speaks of reach- ability, while pereira/shieber (1987) and others before them use the term linking for the rela-tion.
</nextsent>
<nextsent>whatever term one takes, an important aspect of the relation is that it can be used to reduce the search space of possible syntactic analyses at an earlier point in parsing and thus serves to improve the efficiency of parser.
</nextsent>
<nextsent>shieber (1985), <papid> P85-1018 </papid>shieber (1992) follows established terminology in speaking of top-down filtering in connection with the prediction step of the earley algo- rithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F302">
<title id=" C96-2111.xml">topdown predictive linking and complexfeaturebased formalisms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>complex-feature-based formalisms are under- stood here as equivalent to unification-based formalisms as exemplified by patr-ii, hpsg, and others (cf shieber 1986, carpenter 1992).
</prevsent>
<prevsent>such formalisms typically include context- free (cf) base, which allows the use of parsing algorithms designed for cf languages despite the fact that complex-feature-based formalisms are essentially more powerful than cf gram-mars.
</prevsent>
</prevsection>
<citsent citstr=" J89-4001 ">
however, such an adaptation of cf algo-rithms involves their extension to possibly infi-nite nonterminal domains, which, as shieber (1985) <papid> P85-1018 </papid>and haas (1989) <papid> J89-4001 </papid>have shown, is nontriv- ial.</citsent>
<aftsection>
<nextsent>various cf algorithms make use of binary relation between goal category and the cate-gory of constituent (phrase or word) which either has just been parsed or is to be parsed next.
</nextsent>
<nextsent>different erms have been used to desig-nate this relation; kay (1980) speaks of reach- ability, while pereira/shieber (1987) and others before them use the term linking for the rela-tion.
</nextsent>
<nextsent>whatever term one takes, an important aspect of the relation is that it can be used to reduce the search space of possible syntactic analyses at an earlier point in parsing and thus serves to improve the efficiency of parser.
</nextsent>
<nextsent>shieber (1985), <papid> P85-1018 </papid>shieber (1992) follows established terminology in speaking of top-down filtering in connection with the prediction step of the earley algo- rithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F305">
<title id=" C96-2111.xml">topdown predictive linking and complexfeaturebased formalisms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we propose agen eral algorithmic method of compilation that avoids manual specification.
</prevsent>
<prevsent>the focus of this discussion is on the linking relation used to extend left-corner parsers, rath-er than on the prediction step of the earley algorithm as with shieber, although the results carry over.
</prevsent>
</prevsection>
<citsent citstr=" J90-1004 ">
whereas shieber et al (1990) <papid> J90-1004 </papid>have discussed similar techniques in the context of semantic- head-driven generation, we are concerned here with parsing.</citsent>
<aftsection>
<nextsent>we view the linking relation not simply as filter to increase fficiency within the domain of syntactic analysis--this aspect is stressed by shieber (1985) <papid> P85-1018 </papid>and other investiga-tors such as bouma (1991)--<papid> E91-1031 </papid>but rather as device for the top-down predictive instantiation of information, as shieber et al (1990) <papid> J90-1004 </papid>have shown for semantic-head-driven eration.</nextsent>
<nextsent>in this paper we are concerned especially with morphosyntactic information and illustrate the relevance of predictive linking for morphologi-cal analysis and for the analysis of  unknown  or  new  lexical items.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F309">
<title id=" C96-2111.xml">topdown predictive linking and complexfeaturebased formalisms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the focus of this discussion is on the linking relation used to extend left-corner parsers, rath-er than on the prediction step of the earley algorithm as with shieber, although the results carry over.
</prevsent>
<prevsent>whereas shieber et al (1990) <papid> J90-1004 </papid>have discussed similar techniques in the context of semantic- head-driven generation, we are concerned here with parsing.</prevsent>
</prevsection>
<citsent citstr=" E91-1031 ">
we view the linking relation not simply as filter to increase fficiency within the domain of syntactic analysis--this aspect is stressed by shieber (1985) <papid> P85-1018 </papid>and other investiga-tors such as bouma (1991)--<papid> E91-1031 </papid>but rather as device for the top-down predictive instantiation of information, as shieber et al (1990) <papid> J90-1004 </papid>have shown for semantic-head-driven eration.</citsent>
<aftsection>
<nextsent>in this paper we are concerned especially with morphosyntactic information and illustrate the relevance of predictive linking for morphologi-cal analysis and for the analysis of  unknown  or  new  lexical items.
</nextsent>
<nextsent>658
</nextsent>
<nextsent>2.1 the left-corner parsing algorithm.
</nextsent>
<nextsent>the so-called left-corner (lc) parsing algo-rithm is generally credited to rosenkrantz/ lewis (1970).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F316">
<title id=" C96-2111.xml">topdown predictive linking and complexfeaturebased formalisms </title>
<section> left-corner parsing and linking.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast to the previous example, agreement specifications have been compiled out of the relation, but no additional convention whereby eat specifications define context-free skeleton is involved here.
</prevsent>
<prevsent>2.5 notes on implementation in prolog.
</prevsent>
</prevsection>
<citsent citstr=" C90-3080 ">
implementation the lc algorithm in prolog has been discussed by matsumoto et al (1982) for the bup system, by pereira/shieber (1987), kilbury (1990), <papid> C90-3080 </papid>and covington (1994).</citsent>
<aftsection>
<nextsent>here we present, with minor changes, the lc-based in-terpreter with linking for modified dcg for-malism as formulated by pereira/shieber (1987: 180ff); note that the interpreter itself is encoded as dcg: parse(nt) --  leaf(lc, nt), ic(lc, nt).
</nextsent>
<nextsent>leaf(cat,nt) --  \[word\], {lex(word,cat), link(nt,cat)}.
</nextsent>
<nextsent>ic(lc, nt) --  ic(lc, nt) --  \[\], {unify(lc, nt)}.
</nextsent>
<nextsent>{co ---  \[cllcats\], unify(lc, cl), link(nt,c0)}, right(cats), ic(c0,nt).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F321">
<title id=" C94-1104.xml">syntactic analysis of natural language using linguistic rules and corpus based patterns </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we are mainly concerned with exploiting the empirical data and combining two different kinds of parsers.
</prevsent>
<prevsent>*this work was done when the author worked in the research unit for computational linguistics at the uni-versity of itelsinki.
</prevsent>
</prevsection>
<citsent citstr=" C90-3030 ">
our work is based on work done with engcg, the constraint grammar parser of english \[karls- son, 1990; <papid> C90-3030 </papid>karlsson, 1994; karlsson et al, 1994; voutilainen, 1994\].</citsent>
<aftsection>
<nextsent>it is rule-h~ed tagger and surface-syntactic parser that makes very small num- her of errors but leaves some words ambiguous i.e. it prefers ambiguity to guessing wrong.
</nextsent>
<nextsent>the morpholog-ical part-of-speech analyser leaves \[voutilainen et al, 1992\] only 0.3 % of all words in running text without the correct analysis when 3-6 % of words still have two or inore analyses.
</nextsent>
<nextsent>vontilainen, ileikkil 5.
</nextsent>
<nextsent>and anttila \[1992\] reported that the syntactic analyser leaves :3-3.5 % of words without the correct syntactic tag, and 15-20 % of words remain amhiguos.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F322">
<title id=" C94-1104.xml">syntactic analysis of natural language using linguistic rules and corpus based patterns </title>
<section> knowledge acquis ition.  </section>
<citcontext>
<prevsection>
<prevsent>notice that the second subject is not actually tt,e subject of the fi-nite clause, but the subject of nontinite construction councils to spend more.
</prevsent>
<prevsent>this is inconvenient, and question arises whether there should be specific tag to mark suhjects of the nonllnite clauses.
</prevsent>
</prevsection>
<citsent citstr=" E93-1046 ">
voutilainen and tapanaincn \[1993\] <papid> E93-1046 </papid>argued that the richer set of tags could make parsing more accurate in rule-based system.</citsent>
<aftsection>
<nextsent>it may be true he.re as well.
</nextsent>
<nextsent>we can also specify an axis for verbs of the sentence.
</nextsent>
<nextsent> fhus the axis according to tim set { +fauxv +fmainv -fmainv infmai{,k  } is . . .
</nextsent>
<nextsent>kfauxv . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F324">
<title id=" C94-1104.xml">syntactic analysis of natural language using linguistic rules and corpus based patterns </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>a better tag set for surface-syntactic parsing is presented in \[voutilainen and tapanainen, 1993\].<papid> E93-1046 </papid></prevsent>
<prevsent>but we have not modified the present ag set because it is not clear whether small changes would improve the result significantly when compared to the effort needed.</prevsent>
</prevsection>
<citsent citstr=" C90-2040 ">
although it is not possible to fully disambiguate the syntax in engcg, the rate of disambiguation can be improved using more powerful linguistic rule tbrmal- ism (see \[koskenniemi el al., 1992; koskenniemi, 1990; <papid> C90-2040 </papid>tapanainen, 1991\]).</citsent>
<aftsection>
<nextsent>the results reported in this sudy can most likely be improved by writing syntactic grammar in the finite-state framework.
</nextsent>
<nextsent>the same kind of pattern parser could then be used for disam- biguating the resulting analyses.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F325">
<title id=" C96-1054.xml">semantic based transfer </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this article describes the realization of trans-fer approach based on the proposals of (abb and buschbeck-wolf, 1995; caspari and schmid, 1994) and (copestake, 1995).
</prevsent>
<prevsent>transfer-based mt 1, see e.g.
</prevsent>
</prevsection>
<citsent citstr=" J85-2001 ">
(vauquois and boi~et, 1985; nagao et al, 1985), <papid> J85-2001 </papid>is based on con~rastive bilingual corpus analyses from which bilingual lexicon of trans-fer equivalences is derived.</citsent>
<aftsection>
<nextsent>in contrast a purely *this work was funded by the german federal ministry of education, science, research and tech-nology (bmbf) in the framework of the verb mobil project under grant 01 iv 101 u. we would like to thank our colleagues of the verb mobil sub project transfer, our ims colleagues ulrich heid and c.j. rupp and our anonymous reviewers for usefltl feed- back a~ld discussions on earlier drafts of the paper.
</nextsent>
<nextsent>the responsibility for the contents of this paper lies with the authors.
</nextsent>
<nextsent>1for more detailed overview of different ap-proaches to mt, see e.g.
</nextsent>
<nextsent>(hutchins and solners, 1992).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F326">
<title id=" C96-1054.xml">semantic based transfer </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1for more detailed overview of different ap-proaches to mt, see e.g.
</prevsent>
<prevsent>(hutchins and solners, 1992).
</prevsent>
</prevsection>
<citsent citstr=" C92-2091 ">
lexical ist approach which relates bags of lexical signs, as in shake-and-bake mt (beaven, 1992; <papid> C92-2091 </papid>whitelock, 1992), <papid> C92-2117 </papid>our transfer approach operates on the level of semantic representations produced by various analysis teps.</citsent>
<aftsection>
<nextsent>the output of transfer is semantic representation for the target language which is input to the generator and speech synthe-sis to produce the target language utterance.
</nextsent>
<nextsent>our transfer equivalences abstract away from morpho-logical and syntactic idiosyncracies of source and target languages.
</nextsent>
<nextsent>the bilingual equivalences are described on the basis of semantic representations.
</nextsent>
<nextsent>since the verb mobil domain is related to dis-course rather than isolated sentences the model theoretic semantics based on kamp discourse representation theory, drt (kamp and reyle, 1993).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F327">
<title id=" C96-1054.xml">semantic based transfer </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1for more detailed overview of different ap-proaches to mt, see e.g.
</prevsent>
<prevsent>(hutchins and solners, 1992).
</prevsent>
</prevsection>
<citsent citstr=" C92-2117 ">
lexical ist approach which relates bags of lexical signs, as in shake-and-bake mt (beaven, 1992; <papid> C92-2091 </papid>whitelock, 1992), <papid> C92-2117 </papid>our transfer approach operates on the level of semantic representations produced by various analysis teps.</citsent>
<aftsection>
<nextsent>the output of transfer is semantic representation for the target language which is input to the generator and speech synthe-sis to produce the target language utterance.
</nextsent>
<nextsent>our transfer equivalences abstract away from morpho-logical and syntactic idiosyncracies of source and target languages.
</nextsent>
<nextsent>the bilingual equivalences are described on the basis of semantic representations.
</nextsent>
<nextsent>since the verb mobil domain is related to dis-course rather than isolated sentences the model theoretic semantics based on kamp discourse representation theory, drt (kamp and reyle, 1993).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F328">
<title id=" C96-1054.xml">semantic based transfer </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the bilingual equivalences are described on the basis of semantic representations.
</prevsent>
<prevsent>since the verb mobil domain is related to dis-course rather than isolated sentences the model theoretic semantics based on kamp discourse representation theory, drt (kamp and reyle, 1993).
</prevsent>
</prevsection>
<citsent citstr=" C96-1024 ">
in order to allow for under specification, variants of underspecified discourse representa-tion structures (udrs) (reyle, 1993) are em-ployed as semantic formalisms in the different analysis components (bos et al, 1996; <papid> C96-1024 </papid>egg and lebeth, 1995; copestake al., 1995).</citsent>
<aftsection>
<nextsent>together with other kinds of information, such as tense, aspect, prosody and morpho-syntax, the different semantic representations are mapped into single multi-dimensional representation called verb mobil interface term (vit) (dorna, 1996).
</nextsent>
<nextsent>this single information structure serves as input to semantic evaluation and transfer.
</nextsent>
<nextsent>the transfer output is also vit which is based on the semantics of the english grammar (el.
</nextsent>
<nextsent>copestake al.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F332">
<title id=" C96-1093.xml">analysis of japanese compound nouns by direct text scanning </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>1.2 existing methods and problems.
</prevsent>
<prevsent>compound noun analysis has been researched lbr many years because it is important for understanding natural anguage.
</prevsent>
</prevsection>
<citsent citstr=" P95-1007 ">
a concise review of this research area can be found in, for instance, lauer (1995), <papid> P95-1007 </papid>which dates back to finin (1980).</citsent>
<aftsection>
<nextsent>when applying the existing methods to japanese compound nouns in newspaper articles, however, aproblem arises: (1) all the methods are difficult to apply because they use training schemes uch as (partial)parsing of the whole corpus and counting word occun ence in word windows.
</nextsent>
<nextsent>as lauer (1995) <papid> P95-1007 </papid>pointed out, using (partial) parsing of the text is too costly.</nextsent>
<nextsent>thus, the word co-occurrence approach seems to be more appropriate.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F335">
<title id=" C96-1093.xml">analysis of japanese compound nouns by direct text scanning </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>(2) should cope with unregistered words.
</prevsent>
<prevsent>1.3 direct text scanning method.
</prevsent>
</prevsection>
<citsent citstr=" W93-0104 ">
qb satisfy the requirements mentioned above, we used direct text scanning method which collects external evidence (mcdonald, 1993) <papid> W93-0104 </papid>of modifier-modilce relationship between two words using set of simple pattern matchers.</citsent>
<aftsection>
<nextsent>in this method, japanese morphological analyzer (jma) first determines the most plausible segmentation forgiven compound noun by using an ordinary dictionary.
</nextsent>
<nextsent>at this initial stage, the segmentation often contains an over-segmentation error.
</nextsent>
<nextsent>that is, when the analyzer encounters an unregistered word, it is likely to segment the word into sequence of registered words of short length (we empirically confirmed that word boundary crossing type errors make up less than 5% of all errors caused by unregistered words).
</nextsent>
<nextsent>our method corrects many of over-segmentation errors automatically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F339">
<title id=" C96-2122.xml">an earley type recognizer for dependency grammar </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>72-73).
</prevsent>
<prevsent>723 dependency syntax is attractive because of the immediate mapping of dependency structures on the predicate-argmnents ructure (accessible by the semantic interpreter), and because of the treatment of free-word order constructs (sgall et al 1986) (mel cuk 1988) (hudson 1990).
</prevsent>
</prevsection>
<citsent citstr=" J90-4003 ">
a number of parsers have been developed for some dependency frameworks (fraser 1989) (covington 1990) (<papid> J90-4003 </papid>kwon, yoon 1991) (sleator, temperley 1993) (hahn et al 1994) (lai, huang 1995): however, no result of algorithmic efficiency has been published as far as we know.</citsent>
<aftsection>
<nextsent>the theoretical worst-case analysis of o(n 3) descends from the (weak) equivalence between projective dependency grammars (a restricted of dependency grammars) and context-free grammars (gaifman 1965), and not from an actual parsing algorithm, this paper is first attempt fill gap in the literature between the linguistic merits of the dependency approach (widely debated) and the mathematical properties of such formalisms (quite negleted).
</nextsent>
<nextsent>we describe an improved earley-type recognizer for projective dependency formalism.
</nextsent>
<nextsent>as starting point we have adopted restricted dependency formalism with context-free power, that, for the sake of clearness, is described in the notation introduced by gaifman (1965).
</nextsent>
<nextsent>the dependency grammar is translated into set of parse tables that determine the conditions of applicability of the primary parser operations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F340">
<title id=" C94-1049.xml">cooccurrence vectors from corpora vs distance vectors from dictionaries </title>
<section> distance  vectors.  </section>
<citcontext>
<prevsection>
<prevsent>((\]hurch and ll~uiks 1989) .
</prevsent>
<prevsent>l(x,v) = ,g p(x iv) p(x)   where p(x) is the occilrreilce, density of word hi whole corllus, and the conditional pro babil ty (x iv) is the density of in neight orhood of word y, llere the neighl)orhood is defined as 50 words lie.fore or after s.iiy appearance of word y.
</prevsent>
</prevsection>
<citsent citstr=" C92-2070 ">
(there is variety of neigh-borhood definitions sllch as  100 sllrrollllding words  (yarowsky 1992) <papid> C92-2070 </papid>and  within distance of no more thall 3 words igllorh/g filnction words  (i)agarl el, al. l~)n:/).)</citsent>
<aftsection>
<nextsent>the logarithm with  -t-  is dellned to be () for an ar- g;ument less than 1.
</nextsent>
<nextsent>negative sti mates were neglected because they are mostly accidental except when and are frequent enough (chnrch and lianl,:s 1989).
</nextsent>
<nextsent>a co-occurence vector of word is defined as the list of co-occtlrrellce likelihood of the word with cer- tahi set o\[ orighi words.
</nextsent>
<nextsent>we tlsed the salne set oforight words ;is for the distance vectors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F342">
<title id=" C92-3160.xml">automatic proofreading of frozen phrases in german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>\[ rozen phrases are introduced as new level of automatic proofieadiltg in between the stm,dard level of spelling verification tfl ist)lated words and tile levcl of grammar checking.
</prevsent>
<prevsent>the design and the iulplenlentatioll of corresponding proof leading system are described in detail.
</prevsent>
</prevsection>
<citsent citstr=" C86-1001 ">
european languages contain thousands (if what mauriee gross calls  frozen  or  compound words  (g ross, 1986).<papid> C86-1001 </papid></citsent>
<aftsection>
<nextsent>111 contrast to  free forms , frozen words - though being separable into several words and suffixes - lack syntactic and/or semantic omtlosition- ality.
</nextsent>
<nextsent>this  lack of conlpositionality is apparent fiom lexical restrictions  (at night, but: *at day, *at evening, etc.) as well as  by the impossibility of inserting material that is pliori plausil~lc?
</nextsent>
<nextsent>(*at {coming, tlresent, cokt, dark} night) (gross, 1986).<papid> C86-1001 </papid></nextsent>
<nextsent>now, these kinds of co-occurrence restrictions (ltaxris, 19701 determine not only the concrete lexical composition of an individual conlptltnld word but also its spelling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F348">
<title id=" C92-3160.xml">automatic proofreading of frozen phrases in german </title>
<section> status of  imp lemen tat ion.  </section>
<citcontext>
<prevsection>
<prevsent>fortunately, we have not yet come across any (signi\[icaut atllount el) data that would justify such redesign of the system.
</prevsent>
<prevsent>ac es l)e coling-92, nantes, 23-28 ^o(rr 1992 1 0 3 1 roc, ov coling-92, nantes, aug. 23-28, 1992 however, since the data captured in the system lexicon covers at present some 50 % of the relevant phenomena compared to the duden (berger 1985), the ultimate complexity of tile system has to be regarded as an open and empirical question.
</prevsent>
</prevsection>
<citsent citstr=" C90-2063 ">
a first prototype of the system described above has been developed in under unix within the esprit i1 project 2315  translator workbench  (twb) as one of several orthogonal modules checking basic as well as higher levels (like grammar and style; see (thurmair, 1990) <papid> C90-2063 </papid>and (winkelmann, 1990)) <papid> C90-1018 </papid>of various languages.</citsent>
<aftsection>
<nextsent>a derived and extended version - covering 3.000 rewriting rules and some 80 explanations - has been integrated into both proprietary text processing software under dos and microsoft wop, for windows, version 1.1.
</nextsent>
<nextsent>this extended version has been combined with conventional spelling verifier to form single proof reader for the user.
</nextsent>
<nextsent>internally, however, its hidden sub-modules are still totally independent from one another and process sentence one alter the other.
</nextsent>
<nextsent>thus, it may happen that the checkers disturb each others results by proposing antagonistic corrections with respect one and the same expression: within the correct passage  in bezug auf , tbr example,  bezug  will first be regarded as an error by the standard checker which then will propose to rewrite it as  bezug .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F349">
<title id=" C92-3160.xml">automatic proofreading of frozen phrases in german </title>
<section> status of  imp lemen tat ion.  </section>
<citcontext>
<prevsection>
<prevsent>fortunately, we have not yet come across any (signi\[icaut atllount el) data that would justify such redesign of the system.
</prevsent>
<prevsent>ac es l)e coling-92, nantes, 23-28 ^o(rr 1992 1 0 3 1 roc, ov coling-92, nantes, aug. 23-28, 1992 however, since the data captured in the system lexicon covers at present some 50 % of the relevant phenomena compared to the duden (berger 1985), the ultimate complexity of tile system has to be regarded as an open and empirical question.
</prevsent>
</prevsection>
<citsent citstr=" C90-1018 ">
a first prototype of the system described above has been developed in under unix within the esprit i1 project 2315  translator workbench  (twb) as one of several orthogonal modules checking basic as well as higher levels (like grammar and style; see (thurmair, 1990) <papid> C90-2063 </papid>and (winkelmann, 1990)) <papid> C90-1018 </papid>of various languages.</citsent>
<aftsection>
<nextsent>a derived and extended version - covering 3.000 rewriting rules and some 80 explanations - has been integrated into both proprietary text processing software under dos and microsoft wop, for windows, version 1.1.
</nextsent>
<nextsent>this extended version has been combined with conventional spelling verifier to form single proof reader for the user.
</nextsent>
<nextsent>internally, however, its hidden sub-modules are still totally independent from one another and process sentence one alter the other.
</nextsent>
<nextsent>thus, it may happen that the checkers disturb each others results by proposing antagonistic corrections with respect one and the same expression: within the correct passage  in bezug auf , tbr example,  bezug  will first be regarded as an error by the standard checker which then will propose to rewrite it as  bezug .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F350">
<title id=" C96-1021.xml">anaphora for everyone pronominal anaphora resolution without a parser </title>
<section> general outline of the algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>a particu-larly convenient implementation discourse referents is to represent them as objects in the common lisp object system, with slots which encode the following information parameters (where adjunct and embed indicate whether discourse referent was observed in either of the two syntactic ontexts discussed above): text: text form type: referential type (e.g., ref, pro, rflx) agr: person, number, gender gfun: grammatical function adjunct: o nil embed: o nil pos: text position note that each discourse referent contains information about itself and the context in which it appears, but the only information about its relation to other dis-course referents is in the form of precedence lations (as determined by text position).
</prevsent>
<prevsent>the absence of explicit information about configurational relations marks the crucial difference between our algorithm and the lap- pin/leass algorithm.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
(lappin and leass, 1994) <papid> J94-4002 </papid>use configurational information in two ways: as factor in the determination of the salience of discourse refer-ent (discussed below), and as input to set of disjoint reference filters.</citsent>
<aftsection>
<nextsent>our implementation seeks to perform exactly the same tasks by inferring hierarchical rela-tions from less rich base.
</nextsent>
<nextsent>the modifications and assumptions required to accomplish this goal will be highlighted in the following discussion.
</nextsent>
<nextsent>2.2 anaphora resolution.
</nextsent>
<nextsent>once the representation the text has been recast as set of discourse referents (ordered by offset value), it is sent to the anaphora resolution algorithm proper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F358">
<title id=" C96-1021.xml">anaphora for everyone pronominal anaphora resolution without a parser </title>
<section> general outline of the algorithm.  </section>
<citcontext>
<prevsection>
<prevsent>individual salience factors are asso-ciated with numerical values; the overall salience, or  salience weight  of coref is the sum of the values of the salience factors that are satisfied by some member of the coref class (note that values may be satisfied at most once by each member of the class).
</prevsent>
<prevsent>the salience factors used by our algorithm are defined below with their values.
</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
our salience factors mirror those used by (lappin and leass, 1994), <papid> J94-4002 </papid>with the exception of poss-s, discussed below, and cntx-s, which is sensitive to the context in which discourse referent appears, where context is topically coherent segment of text, as deter-mined by text-segmentation algorithm which follows (hearst, 1994).<papid> P94-1002 </papid></citsent>
<aftsection>
<nextsent>sent-s: 100 iff in the current sentence cntx-s: 50 iff in the current context subj-s: 80 iff gfun = subject exst-s: 70 iff in an existential construction poss-s: 65 iff gfun = possessive acc-s: 50 iff gfun = direct object dat-s: 40 iff gfun = indirect object oblq-s: 30 iff the complement of preposition head-s: 80 iff embed = nil arg-s: 50 iff adjunct = nil note that the values of salience factors are arbitrary; what is crucial, as pointed out by (lappin and leass, 1994), <papid> J94-4002 </papid>is the relational structure imposed on the factors by these values.</nextsent>
<nextsent>the relative ranking of the factors is justified both linguistically, as reflection of the role of the functional hierarchy in determining anaphoric relations (cf.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F368">
<title id=" C94-1039.xml">adjuncts and the processing of lexical rules </title>
<section> processing lexical rules.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 lex ica rules as const ra in ts on.
</prevsent>
<prevsent>lex ica categories rather than formalizing the  add-adjuncts  rule as lexical rule we propose to use re-cursive constraints on lexical categories.
</prevsent>
</prevsection>
<citsent citstr=" J91-3003 ">
such lexical constraints are then processed using de-layed ewduation techniques, such an approach is more promising than an off-line approach that pre computes the effect arefer to carpenter (1991) <papid> J91-3003 </papid>for proof of turillg equivalence of simple eategorial grammar with recur- slve lexical rules.</citsent>
<aftsection>
<nextsent>252 verbal 1 sc : ? :~ sere : sere0 vi,;rbai, sc :   .
</nextsent>
<nextsent>( wod : ar~l : sem~) ) . va/: sere .n(? gq, : ~oill figure 3: lexieal rule that adds single adjunct to the sul)cat list of  verb.
</nextsent>
<nextsent>in the.
</nextsent>
<nextsent>case of ~uljuncts the rule applies times.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F369">
<title id=" C96-1031.xml">gram check a grammar and style checker </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>
<prevsent>ulmer standing by comtmters.
</prevsent>
<prevsent>many of the nlu systems developed in the 70 indu(le(l kind of error recovery inechanisln ranging flom the treat-ment only of spelling e.rrors, parry (1)arkin - son t al., 1977), to tile inclusion also of incom-plete int)ut containing some kind of ellipsis, lad- dell,/lifell (hendrix et al, 1977).
</prevsent>
</prevsection>
<citsent citstr=" J83-3005 ">
the interest in the 80 begun to turn consid-ering grammar checking as an enterprise of its own right (carbonell &amp; hayes, 1983), (ilayes &amp; mouradian, 1981), (heidorn et al, 1982), (.lensen at al., 1983), though many of the approaches were still in i;t1(: nlu tradition ((\]harniak, 198a), (granger, 1983), (<papid> J83-3005 </papid>kwasny &amp; sondheimer, 1981), (weischedel &amp; black, \]980), (weisehedel &amp; sond-heimer, 1983).</citsent>
<aftsection>
<nextsent>a 1985 ovum report on nal;ll- ral language applications (.lohnson, 1985) already identifies grammar and style checking as one of the seven major apt)lications of nlp.
</nextsent>
<nextsent>currently, every project in grammar checking has as its goal the creation of writing aid rather than robust man-machine interface (adriaens, 1994), (llolioli ctal . , 1992), (vosse, 1992).<papid> A92-1015 </papid></nextsent>
<nextsent>current systems dealillg with grammatical de-viance have be(m inainly involve(t in the integi~  don of special techniques to detect and correct, when possible, these, deviances.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F370">
<title id=" C96-1031.xml">gram check a grammar and style checker </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>
<prevsent>the interest in the 80 begun to turn consid-ering grammar checking as an enterprise of its own right (carbonell &amp; hayes, 1983), (ilayes &amp; mouradian, 1981), (heidorn et al, 1982), (.lensen at al., 1983), though many of the approaches were still in i;t1(: nlu tradition ((\]harniak, 198a), (granger, 1983), (<papid> J83-3005 </papid>kwasny &amp; sondheimer, 1981), (weischedel &amp; black, \]980), (weisehedel &amp; sond-heimer, 1983).</prevsent>
<prevsent>a 1985 ovum report on nal;ll- ral language applications (.lohnson, 1985) already identifies grammar and style checking as one of the seven major apt)lications of nlp.</prevsent>
</prevsection>
<citsent citstr=" A92-1015 ">
currently, every project in grammar checking has as its goal the creation of writing aid rather than robust man-machine interface (adriaens, 1994), (llolioli ctal . , 1992), (vosse, 1992).<papid> A92-1015 </papid></citsent>
<aftsection>
<nextsent>current systems dealillg with grammatical de-viance have be(m inainly involve(t in the integi~  don of special techniques to detect and correct, when possible, these, deviances.
</nextsent>
<nextsent>in some case.s, these have be.en incorporated to traditional pars-ing techniques, as it is the case with feature re-laxation in the context of unification-based for-malisms (bolioli et al, 1992), <papid> C92-3155 </papid>or the addition of set of catching error rules si)ecially handling the deviant constructions (thurlnair, 1990).</nextsent>
<nextsent>in other eases, the relaxation component has heen included as new add-in feature to the parsing algoril,hm, as in the ibm plnl   ai)proach (heidorn et al, 1982), or in the work developed for tim tra.nsla- tor workbench t)roject using the metal mt- system (twb, 1992).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F371">
<title id=" C96-1031.xml">gram check a grammar and style checker </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>
<prevsent>currently, every project in grammar checking has as its goal the creation of writing aid rather than robust man-machine interface (adriaens, 1994), (llolioli ctal . , 1992), (vosse, 1992).<papid> A92-1015 </papid></prevsent>
<prevsent>current systems dealillg with grammatical de-viance have be(m inainly involve(t in the integi~  don of special techniques to detect and correct, when possible, these, deviances.</prevsent>
</prevsection>
<citsent citstr=" C92-3155 ">
in some case.s, these have be.en incorporated to traditional pars-ing techniques, as it is the case with feature re-laxation in the context of unification-based for-malisms (bolioli et al, 1992), <papid> C92-3155 </papid>or the addition of set of catching error rules si)ecially handling the deviant constructions (thurlnair, 1990).</citsent>
<aftsection>
<nextsent>in other eases, the relaxation component has heen included as new add-in feature to the parsing algoril,hm, as in the ibm plnl   ai)proach (heidorn et al, 1982), or in the work developed for tim tra.nsla- tor workbench t)roject using the metal mt- system (twb, 1992).
</nextsent>
<nextsent>besides, an increasing concern in current projects is that of linguistic relevance of the anal-ysis t)erformed by the grammar correction system.
</nextsent>
<nextsent>in this sense, the adequate integration of error detection and correction techniques within main- stream grammm  formalisms has l)een addressed by nunl|)er of these projects (\[iolioli eta/., 1992), (vosse, 1992), ((\]<papid> A92-1015 </papid>enthia.l ctal., t992), (o(~uthial et al., 1994).</nextsent>
<nextsent>l~bllowing this concern, this paper presents re- suits fl om the project gram check (a gram-mar and style checker, mlap93-11), flmded by the cec.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F373">
<title id=" C96-1031.xml">gram check a grammar and style checker </title>
<section> brief grammar error typology.  </section>
<citcontext>
<prevsection>
<prevsent>the demonstrator checks whether document contains grammar errors or style weaknesses and, if found any, users are provided with messages, suggestions and, for grammar errors only, auto- inatic correction(s).
</prevsent>
<prevsent>for spanish the linguistic statements made by developers of current grammar checkers based on nlp ted  niques are often contradictory egarding the types of errors that grammar checkers must correct au-tomatically.
</prevsent>
</prevsection>
<citsent citstr=" C88-2146 ">
(veronis, 1988) <papid> C88-2146 </papid>claims that native writers are unlikely to produce errors involving morphological features, while (vosse, 1992) <papid> A92-1015 </papid>ac- ce.t)ts uch morpho-syntactic errors, inspite of tile fact that an examination of texts by the author revealed that their appearance in native writer texts is not frequent.</citsent>
<aftsection>
<nextsent>both authors agree in char-acterizing morpho-syntactic errors as sainple of lack of competence.
</nextsent>
<nextsent>on the other hand, an examination of real texts produced by spanish writers revealed that they do produce morpho-syntactic errors . spanish is an inflectiolml anguage, which increases the possi-bilities of such exrors.
</nextsent>
<nextsent>nevertheless, other errors related to structural configuration of the language ark: produced as well.
</nextsent>
<nextsent>errors found fall into one of the following sub- types, assuming that featurization is the technique used in t)arsing sentences: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F376">
<title id=" C94-2196.xml">discourse and deliberation  testing a collaborative strategy </title>
<section> design.world.  </section>
<citcontext>
<prevsection>
<prevsent>agents ri{ji, .( : ra proposal if delibefalion leads lhenl 1o believe lhal lhey know t)l bellm option or if they believe the precondilions for tile proposal do not hold.
</prevsent>
<prevsent>the con- toni of rt~jc.clions is dctcf,nined by the (:()i.i.ai;()rki iv){ pi.annin(; prin( ii ij{s, abslfacled frolll analyzing fotlf different types of pt oblem solving dialogues \[walker and whitlakef, 1990; walker, 1994bj.
</prevsent>
</prevsection>
<citsent citstr=" C92-1054 ">
per example, in 3-4 kiln fejecls the proposal ill 3-3, and gives its her reason that oplion-s6 is teenier-proposal, pml)osals 1 airl 2 ~ue infeffed io be implicilly ac- 3.;he\]) because they are not rejected \[walker ~md whil- taker, 1991); walker, 1992<papid> C92-1054 </papid>1.</citsent>
<aftsection>
<nextsent>i1 pfol)osal is a(:t ei tt,. i), eilhef implicitly or explicitly, then the oplion ihat wits ihe content of tile pfoposal hecollles mtnlual intenlitm thai conlrihutes io ihe iinal design plan ii ower, 1984; sidner, 1992i.
</nextsent>
<nextsent>a polenlial final design plan negolialed via dialogue is shown in ligure 2.
</nextsent>
<nextsent>3.2 varying ) scourse l ra teg ies.
</nextsent>
<nextsent>the l)esign-wodd experimenls reporlcd here compare 1he all-hnplicit slratcgy with the explicii-wmrant strat-egy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F377">
<title id=" C96-2114.xml">linguistic indeterminacy as a source of errors in tagging </title>
<section> manual and automatic markup.  </section>
<citcontext>
<prevsection>
<prevsent>the entire corpus of 1 million words has passed through this stage of manual disambiguation and annotation, which makes it an important standard that can be used as tool, e.g., when training probabilistic taggers.
</prevsent>
<prevsent>the goal of the experiment reported in kallgren (1996) was, however, to compare  sheer  machine tagging to the performance of human annotators.
</prevsent>
</prevsection>
<citsent citstr=" A92-1018 ">
the tagger used is thus one that does not need tagged and disambiguated material to be trained on, namely the xpost originally constructed at xerox parc (cutting et al  1992, <papid> A92-1018 </papid>cutting and pedersen 1993).</citsent>
<aftsection>
<nextsent>the xpost algorithm has been transferred to other languages than english.
</nextsent>
<nextsent>douglass cutting himself made the first swedish version of it (cutting 1993) and later version has been implemented by gunnar eriksson (eriksson 1995) and refined by tomas svensson (svensson 1996).
</nextsent>
<nextsent>it is this latter version that has been used in the experiment.
</nextsent>
<nextsent>starting from set of texts and lexicon, the xpost looks up all words in the texts and assigns to them set of one or more readings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F378">
<title id=" C96-2114.xml">linguistic indeterminacy as a source of errors in tagging </title>
<section> manual and automatic markup.  </section>
<citcontext>
<prevsection>
<prevsent>the words are then classified into so-called ambiguity classes according to which set of readings they have been assigned.
</prevsent>
<prevsent>the training is performed on ambiguity classes and not on individual word tokens.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
kallgren (1996) gives more covering description of how xpost is used on the swedish material and also sketches the major differences between this algorithm and some others used for tagging, such as parts (church 1988) <papid> A88-1019 </papid>and vols unga (derose 1988).<papid> J88-1003 </papid></citsent>
<aftsection>
<nextsent>a characteristic tbature of the suc is its high number of different tags.
</nextsent>
<nextsent>the number of part-of- speech tags used in the suc is 21.
</nextsent>
<nextsent>with the addition of category for foreign words the number of major categories used is 22 (plus three tags for punctuation), which is in no way remarkable amount, but the suc tags are composite.
</nextsent>
<nextsent>this means that all words have one tag for part-of-speech, but for many parts-of speech this tag is followed by other tags for various morphological features, where, e.g., english nouns have variation between two possible values, singular and plural, the swedish pattern allows for 1 2 2 2 3 = 24 different ags, specifying not only part-of- speech but also gender, number, definite ness, and case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F379">
<title id=" C96-2114.xml">linguistic indeterminacy as a source of errors in tagging </title>
<section> manual and automatic markup.  </section>
<citcontext>
<prevsection>
<prevsent>the words are then classified into so-called ambiguity classes according to which set of readings they have been assigned.
</prevsent>
<prevsent>the training is performed on ambiguity classes and not on individual word tokens.
</prevsent>
</prevsection>
<citsent citstr=" J88-1003 ">
kallgren (1996) gives more covering description of how xpost is used on the swedish material and also sketches the major differences between this algorithm and some others used for tagging, such as parts (church 1988) <papid> A88-1019 </papid>and vols unga (derose 1988).<papid> J88-1003 </papid></citsent>
<aftsection>
<nextsent>a characteristic tbature of the suc is its high number of different tags.
</nextsent>
<nextsent>the number of part-of- speech tags used in the suc is 21.
</nextsent>
<nextsent>with the addition of category for foreign words the number of major categories used is 22 (plus three tags for punctuation), which is in no way remarkable amount, but the suc tags are composite.
</nextsent>
<nextsent>this means that all words have one tag for part-of-speech, but for many parts-of speech this tag is followed by other tags for various morphological features, where, e.g., english nouns have variation between two possible values, singular and plural, the swedish pattern allows for 1 2 2 2 3 = 24 different ags, specifying not only part-of- speech but also gender, number, definite ness, and case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F380">
<title id=" C96-2114.xml">linguistic indeterminacy as a source of errors in tagging </title>
<section> manual and automatic markup.  </section>
<citcontext>
<prevsection>
<prevsent>since major concern of the treebank is to avoid requiring annotators to make arbitrary decisions, we allow words to be associated with more than one pos tag.
</prevsent>
<prevsent>such multiple tagging indicates either that the word part of speech simply cannot be decided or that the annotator is unsure which of the alternative tags is the correct one.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
(marcus et al  1993, <papid> J93-2004 </papid>316.)</citsent>
<aftsection>
<nextsent>the british national corpus:  in order to provide more useful results insubstantial proportion of the residual words which cannot be successfully tagged, we have introduced portmanteau tags.
</nextsent>
<nextsent>a portmanteau tag is used ill situation where there is insufficient evidence for claws to make clear distinction between two tags.
</nextsent>
<nextsent>thus, in the notoriously difficult choice between past participle and the past tense of verb, if there is insufficient probabilistic evidence to choose between the two claws marks the word as vvn-vvd.
</nextsent>
<nextsent>a set of fifteen such portmanteau tags have been declared, covering the major pairs of conf usable tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F381">
<title id=" C96-2114.xml">linguistic indeterminacy as a source of errors in tagging </title>
<section> manual and automatic markup.  </section>
<citcontext>
<prevsection>
<prevsent>(garside 1995.)
</prevsent>
<prevsent>constraint grammar:  in the rare cases where two analyses were regarded as equally legitimate, both could be marked.
</prevsent>
</prevsection>
<citsent citstr=" E95-1029 ">
(voutilainen and jfirvinen 1995, <papid> E95-1029 </papid>212.)</citsent>
<aftsection>
<nextsent>it is, however, important hat the s/tuations where underspecified tags can be used are restricted to well- defined cases and that the reasons for using them are quite clear.
</nextsent>
<nextsent>they should have what call  mirror  character, in that the interchange goes in both directions, and they should concern clearly distinct pairs of tags even when word has several other tags as well.
</nextsent>
<nextsent>such situations are more common in automatic tagging but they occur in manual tagging as well.
</nextsent>
<nextsent>the reasons for situation being undecidable can, however, vary.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F382">
<title id=" C94-2149.xml">xtag system  a wide coverage grammar for english </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the parser titan composes the structures to obtain the parse(s) of the sentence.
</prevsent>
<prevsent>2.1 morphological analyzer.
</prevsent>
</prevsection>
<citsent citstr=" C92-3145 ">
the morphology database \[karp et al, 1992<papid> C92-3145 </papid>1 was originally exlracted from 1979 edition of the collins english dictionary and oxford adwmced learner l)ictionary of current english, and then cleaned up and auglnentcd by hand.</citsent>
<aftsection>
<nextsent>it consists of approximately 317,000 inltected items, along with their root forms and intlectional intbrmalion (such as case, num- 922 bet, tense).
</nextsent>
<nextsent>thirteen parts of speech are difleren- tiated: noun, proper noun, pronoun, verb, verb particle, adverb, adjective, preposition, comple- men tizer, determiner, conjunction, lntmjection, and noun/verb contraction.
</nextsent>
<nextsent>notms and verhs are the largest categories, with approximately 213,000 and 46,500 inflected forms, respectively.
</nextsent>
<nextsent> \[ he access time forgiven inflected entry is 0.6 msec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F383">
<title id=" C94-2149.xml">xtag system  a wide coverage grammar for english </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent> \[ he access time forgiven inflected entry is 0.6 msec.
</prevsent>
<prevsent>2.2 part -of -speech tagger.
</prevsent>
</prevsection>
<citsent citstr=" A88-1019 ">
a trigram part-of-speech tagger \[church, 1988<papid> A88-1019 </papid>1, trained on the wall street jotlrilal corpus, is incor-porated in xtag.</citsent>
<aftsection>
<nextsent>the trigraln tagger has been ex-tended to output he n-best parts-of-speech sequences \[soong and huang, 1990\].
</nextsent>
<nextsent>xtag uses this infer mat|on io reduce the number of specious parses by filtering the possible parts-of-speech provided by the morphological nalyzer for each word.
</nextsent>
<nextsent>the tagger decreases tile time to parse sentence by an average of 93%.
</nextsent>
<nextsent>2.3 parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F384">
<title id=" C94-2149.xml">xtag system  a wide coverage grammar for english </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>j 2.3.1 lleuristics for ranking the 1 arses the parser generates the parses in rank order.
</prevsent>
<prevsent>this ranking is determined using combination ofheuris- tics, which are expressed as structural preferences for deriwttion, e..g. attachment si es of adjuncts, right- vs. left- branching structures, topical ized sentences, etc. similar hem istics have been used for other parsers.
</prevsent>
</prevsection>
<citsent citstr=" H93-1025 ">
see recent work by ihobbs and bear, 199411, \[mc- cord, 1993<papid> H93-1025 </papid>1,and \[nagao, 1994t.</citsent>
<aftsection>
<nextsent>a partial istel ~ the heuristics used in xtag fol- lows: 1.
</nextsent>
<nextsent>prefer argument positions to adjunct positions.
</nextsent>
<nextsent>(here, this amotmts io preferring fewer adjunc- t|on operations).
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F385">
<title id=" C94-2149.xml">xtag system  a wide coverage grammar for english </title>
<section> corpus parsing and evalu-.  </section>
<citcontext>
<prevsection>
<prevsent>we will present more complete and rigorous results by the time of the conference and compare them with other 2sentences of length  = 15 words 4.1 comparison with ibm parser.
</prevsent>
<prevsent>a more detailed experiment to measure the crossing bracket accuracy of the xtag-parsed ibm-manual sentences has been performed.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
of the 1600 ibm sentences that have been parsed (those available from the penn treebank \[marcus et al, 1993<papid> J93-2004 </papid>1), only 67 overlapped with the ibm-manual treebank that was bracketed by university of lancaster.</citsent>
<aftsection>
<nextsent>3 the xtag- parses for these 67 sentences were compared 4 with the lancaster ibm-manual treebank.
</nextsent>
<nextsent>table 3 shows the results obtained in this experi-ment.
</nextsent>
<nextsent>it also shows the crossing bracket accuracy of the latest ibm statistical parser \[jelinek el al., 1994\] on the same genre of sentences.
</nextsent>
<nextsent>recall is measure of the number of bracketed constituents he system got right divided by the number of constituents in the corresponding treebank sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F386">
<title id=" C96-2132.xml">zero pronouns and condition als in japanese instruction manuals </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since recently there are many machines whose operating pro-cedures are complicated, we have much trouble in many cases including translating their manuals into other languages, maintaining consistency be-tween the description in manuals and the actual behavior of the machines.
</prevsent>
<prevsent>to solve these prob-lems, we have to have computer assisted system tbr processing japanese manual sentences, espe-cially tbr understanding manual sentences.
</prevsent>
</prevsection>
<citsent citstr=" P92-1016 ">
a large number of researchers have gotten to grip with the method of understanding some types of text inehlding instruction lanuals(abe al., 1988; nomura, 1992; eugenio, 1992).<papid> P92-1016 </papid></citsent>
<aftsection>
<nextsent>one of the most important matters of concern in tliese types of system is how we can fix ambiguities in seman-tic representations and fill uuderspecified parts of them.
</nextsent>
<nextsent>generally speaking, almost all systems de-scribed above take the following scheme, irstly, each sentence in text is translated into seman-tic representation, hi this process, the system uses only non-defeasible syntactic and semantic coll- straints.
</nextsent>
<nextsent>most of pragmatic information and coln- rnousense knowledge are not used here, because the result of these knowledge would be overrid-den by some other information such as contex-tual intbrmation.
</nextsent>
<nextsent>therefore the semantic repre-sentation would include some undetermined parts which would be fixed by other kind of information including context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F387">
<title id=" C96-2132.xml">zero pronouns and condition als in japanese instruction manuals </title>
<section> zero pronouns  in manua l.  </section>
<citcontext>
<prevsection>
<prevsent>his approach utilizes honorific ex-pressions and the speaker point of view.
</prevsent>
<prevsent>since the constraints are efl ective in the (lifferent arget from ours, the accuracy of identifying the referents of zero pronouns would be improved much more by using both of his constraints and the constraint we proposed.
</prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
as for the identifying method available in general discourses, the centering the- ory(brennan et al, 1987; <papid> P87-1022 </papid>walker et al, 1990) and the property sharing theory(kameyama, 1988) are proposed.</citsent>
<aftsection>
<nextsent>although this kind of theory has good point that it is independent of the type o17 discourse, the linguistic constraints spe citic to ex-pressions like the pragmatic onstraints l/roposed by dohsaka or us are more accurate than theirs when the speeitlc constraints are applicable.
</nextsent>
<nextsent>prinmry constraints in this section, we consider the general ontology which can be used in ,dl types of manuals.
</nextsent>
<nextsent>we shouhl consider two types of information as the parts of ontology: the properties of the ob-jects in manuals and the discourse situation that is characterized by linguistic roles like writer and reader.
</nextsent>
<nextsent>const ra in 1 (objects) user has intention.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F388">
<title id=" C96-1069.xml">an automatic clustering of articles using dictionary definitions </title>
<section> framework.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 word-sense isambiguat ion.
</prevsent>
<prevsent>every sense of words in artmes which should be (:lustered is automatically disambiguated in advance.
</prevsent>
</prevsection>
<citsent citstr=" C92-2070 ">
word-sense dismnl)iguation (wsd in short) is serious problem for nlp, and wlri( ty of al)l)roaches have been 1)roposed for solving it (ih own, 1991), (yarowsky, 1992).<papid> C92-2070 </papid></citsent>
<aftsection>
<nextsent>our disalnbiguation method is based on niwa method which used the similarity 1)etween sen- tenee containing t)olysemous noun and sen= tence of dictionary-definition.
</nextsent>
<nextsent>let be t)olyse- mous noun and sentence be   ? ?
</nextsent>
<nextsent>~ 3 : -n~ ? ?
</nextsent>
<nextsent>~   - ~ ~1:~ ~1:1 , ?     ~ ilyn~       the vector representation of is v(x) = ~ v(xi) where v(xi) is v(xi) = (mu(xi,o~),...,mu(xi,om)) here, mu(x, y) is the ,due of mutual information proposed by (church, 1991).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F389">
<title id=" C96-1069.xml">an automatic clustering of articles using dictionary definitions </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent> method  shows our proposed method.
</prevsent>
<prevsent>4.1 data.
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
the training tort)us we have used ix the 1988, 1!)89 wsj ill acl /dci cd-i{om whi(.h ( onsists of al)out 280,000 1)art-of-spee( tagged sentences (brill, 1992).<papid> A92-1021 </papid></citsent>
<aftsection>
<nextsent>from this eorlmx, we seh,cted at random 49 (lifferent articles for test data, each of which (-onsixts of 3,500 sentences and has dif-ferent tel)it ilallle wlfich is tagging in the ws,i. we classified 49 artmes into eight categories, e,g. sin our experiments, equals to 238.
</nextsent>
<nextsent> market news ,  food.
</nextsent>
<nextsent>restaurant  , etc. the di( tio- nary we have used is collins english dictionary in acl /dci cd-rom.
</nextsent>
<nextsent>in wsd nwthod, the (:o-occurrence of and f or cah:ulating mu is that the two words (x,y) al)- pear in the training (:orl)us in this order in win-dow of 100 words, i.e. a: is folh)wed by within 100-word distance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F390">
<title id=" C96-2105.xml">parallel replacement infinite state calculus </title>
<section> introduction.  </section>
<citcontext>
<prevsection>

<prevsent>a replacement expression specifies that given symbol or sequence of symbols hould be replaced by another one in certain context or contexts.
</prevsent>
</prevsection>
<citsent citstr=" J94-3001 ">
phonological rewrite-rules (kaplan and kay, 1994), <papid> J94-3001 </papid>two-level rules (koskenniemi 1983), syntactic dis- arnbiguation rules (kar\]sson et al 1994, kosken-niemi, tapanainen, and voutilainen 1992), and part-of-speech assignment rules (brill 1992, <papid> A92-1021 </papid>roche and schabes 1995) <papid> J95-2004 </papid>are examples of replacement in context of finite-state grammars.</citsent>
<aftsection>
<nextsent>kaplan and kay (1994) <papid> J94-3001 </papid>describe general method representing replacement procedure as finite-state transduction.</nextsent>
<nextsent>karttunen (1995) <papid> P95-1003 </papid>takes somewhat simpler approach by introducing to the calculus of regular expression replacement opera-tor that is defined just in terms of the other regular expression operators.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F391">
<title id=" C96-2105.xml">parallel replacement infinite state calculus </title>
<section> introduction.  </section>
<citcontext>
<prevsection>

<prevsent>a replacement expression specifies that given symbol or sequence of symbols hould be replaced by another one in certain context or contexts.
</prevsent>
</prevsection>
<citsent citstr=" A92-1021 ">
phonological rewrite-rules (kaplan and kay, 1994), <papid> J94-3001 </papid>two-level rules (koskenniemi 1983), syntactic dis- arnbiguation rules (kar\]sson et al 1994, kosken-niemi, tapanainen, and voutilainen 1992), and part-of-speech assignment rules (brill 1992, <papid> A92-1021 </papid>roche and schabes 1995) <papid> J95-2004 </papid>are examples of replacement in context of finite-state grammars.</citsent>
<aftsection>
<nextsent>kaplan and kay (1994) <papid> J94-3001 </papid>describe general method representing replacement procedure as finite-state transduction.</nextsent>
<nextsent>karttunen (1995) <papid> P95-1003 </papid>takes somewhat simpler approach by introducing to the calculus of regular expression replacement opera-tor that is defined just in terms of the other regular expression operators.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F392">
<title id=" C96-2105.xml">parallel replacement infinite state calculus </title>
<section> introduction.  </section>
<citcontext>
<prevsection>

<prevsent>a replacement expression specifies that given symbol or sequence of symbols hould be replaced by another one in certain context or contexts.
</prevsent>
</prevsection>
<citsent citstr=" J95-2004 ">
phonological rewrite-rules (kaplan and kay, 1994), <papid> J94-3001 </papid>two-level rules (koskenniemi 1983), syntactic dis- arnbiguation rules (kar\]sson et al 1994, kosken-niemi, tapanainen, and voutilainen 1992), and part-of-speech assignment rules (brill 1992, <papid> A92-1021 </papid>roche and schabes 1995) <papid> J95-2004 </papid>are examples of replacement in context of finite-state grammars.</citsent>
<aftsection>
<nextsent>kaplan and kay (1994) <papid> J94-3001 </papid>describe general method representing replacement procedure as finite-state transduction.</nextsent>
<nextsent>karttunen (1995) <papid> P95-1003 </papid>takes somewhat simpler approach by introducing to the calculus of regular expression replacement opera-tor that is defined just in terms of the other regular expression operators.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F396">
<title id=" C96-2105.xml">parallel replacement infinite state calculus </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>phonological rewrite-rules (kaplan and kay, 1994), <papid> J94-3001 </papid>two-level rules (koskenniemi 1983), syntactic dis- arnbiguation rules (kar\]sson et al 1994, kosken-niemi, tapanainen, and voutilainen 1992), and part-of-speech assignment rules (brill 1992, <papid> A92-1021 </papid>roche and schabes 1995) <papid> J95-2004 </papid>are examples of replacement in context of finite-state grammars.</prevsent>
<prevsent>kaplan and kay (1994) <papid> J94-3001 </papid>describe general method representing replacement procedure as finite-state transduction.</prevsent>
</prevsection>
<citsent citstr=" P95-1003 ">
karttunen (1995) <papid> P95-1003 </papid>takes somewhat simpler approach by introducing to the calculus of regular expression replacement opera-tor that is defined just in terms of the other regular expression operators.</citsent>
<aftsection>
<nextsent>we follow here the latter ap-proach.
</nextsent>
<nextsent>in the regular expression calculus, the replace-ment operator, - , is similar to cross product, in that replacement expression describes rela-tion between two simple regular languages.
</nextsent>
<nextsent>con-sequently, regular expresmons can be conveniently combined with other kinds of cope rations, uch as composition and union to form complex expres-sions.
</nextsent>
<nextsent>a replacement relation consists of pairs of strings that are related to one another in the manner sketched below: u.~ y, u~ upper string \[1\] 1~ 1~ lower string we use i and u~ to represent instances of ui (with c \[1, n\])and 1~ and 1~ to represent instances of li.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F419">
<title id=" C94-1009.xml">building an mt dictionary from parallel texts based on linguistic and statistical information </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>our research interest lies in automatic gen-eration of translation dictionaries from parallel texts.
</prevsent>
<prevsent>in this perspective, finding corresponding words or phrases in bilingual texts will be the fun-damental factor for accurate translation.
</prevsent>
</prevsection>
<citsent citstr=" P93-1002 ">
statistics-based processing has proven to be very powerful for aligning sentences and words in paral-lel corpora (brown, 1991; gale, 1993; chen, 1993).<papid> P93-1002 </papid></citsent>
<aftsection>
<nextsent>kupiec proposes an mgorithm for finding ~loun phras-es in bilingual corpora (kupiec, 1993).<papid> P93-1003 </papid></nextsent>
<nextsent>in this algorithm, noui~-phrase candidates are extracted from tagged and aligned parallel texts using noun phrase recognizer and tile correspondences of these nonn phrases are calculated based on the em algorithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F420">
<title id=" C94-1009.xml">building an mt dictionary from parallel texts based on linguistic and statistical information </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>in this perspective, finding corresponding words or phrases in bilingual texts will be the fun-damental factor for accurate translation.
</prevsent>
<prevsent>statistics-based processing has proven to be very powerful for aligning sentences and words in paral-lel corpora (brown, 1991; gale, 1993; chen, 1993).<papid> P93-1002 </papid></prevsent>
</prevsection>
<citsent citstr=" P93-1003 ">
kupiec proposes an mgorithm for finding ~loun phras-es in bilingual corpora (kupiec, 1993).<papid> P93-1003 </papid></citsent>
<aftsection>
<nextsent>in this algorithm, noui~-phrase candidates are extracted from tagged and aligned parallel texts using noun phrase recognizer and tile correspondences of these nonn phrases are calculated based on the em algorithm.
</nextsent>
<nextsent>accuracy of around 90% has been attained for the imndred highest ranking con espondenccs.
</nextsent>
<nextsent>statistics- based processing is effective when relatively large amount of parallel texts is available, i.e. when high frequencies are obtained.
</nextsent>
<nextsent>on the other hand, existing linguistic knowl-edge can be used for finding corresponding words or phrases in parallel texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F423">
<title id=" C92-2114.xml">lexical choice in context generating procedural texts </title>
<section> lexical functions of the ecd for creating.  </section>
<citcontext>
<prevsection>
<prevsent>iput the t~_ef in the i~iling waterl b. retirer la viande ml bout de 20 minutes.
</prevsent>
<prevsent>\[remove the meat aftc 20 minutes\] this somewhat suri)rising i)henomenon can be analysed with the help of the notion of basic level object proposed by roseh et al (1976).
</prevsent>
</prevsection>
<citsent citstr=" W90-0104 ">
the imlx)rtance of the basic level distinction for text generation has recently been shown by reiter (1990<papid> W90-0104 </papid></citsent>
<aftsection>
<nextsent>rosch et al demonstrated that the taxonomy of concepts could be organized using stnlcture with three levels: superordiuate, haste and subordinate.
</nextsent>
<nextsent>they define the basic level as follows:  basic objects a~e the most inclusive categories whose members: (a) possess ignificant numbers of attributes in cmmnon, (b) have motor programs which are similar to one another, (c) have similar shapes, and (d) can be identified from averaged shapes of members of the class  (rosch et al 1976: 382) it has been shown that lexemes correspomling to basic level objects seem to be the most natural terms to introduce referents already idcntified.
</nextsent>
<nextsent>for example, if one wants to refer to some champignons de paris \[button mushrootos\], one would prctk:r to call them champignons \[nmshrooms\], provided that there is no potcntial amttiguity with auy other mushrooms.
</nextsent>
<nextsent>champignons de paris would sccm too specific in this context and vegetables would seem too vague.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F425">
<title id=" C92-2114.xml">lexical choice in context generating procedural texts </title>
<section> lexical functions of the ecd for creating.  </section>
<citcontext>
<prevsection>
<prevsent>for lack of space, however, we leave out the model of state change management (needed to describe recipe ingredients being mixed together and transformed (kosseim 1992)), a~ld the focus model used.
</prevsent>
<prevsent>4.1 input.
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
we limit our scope to the linguistic part of generation; therefore, we assume that onr input is the ontput of text planner, which has already grouped actions into discourse structures as proposed by grosz and sidner (1986) <papid> J86-3001 </papid>and (dale 1988), the input is thus sequence of actions and states in which participants (ingredients, instruments and agent) are represented by indices.</citsent>
<aftsection>
<nextsent>4.2 dictionary of concepts.
</nextsent>
<nextsent>the dictionary of concepts has been inspired by nirenburg and raskin 1987; <papid> J87-3007 </papid>concepts are mainly subdivided into actions or objects.</nextsent>
<nextsent>we have added category of properties, needed to describe relations between concepts (e.g., temporal limit) or attributes (e.g. size).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F426">
<title id=" C92-2114.xml">lexical choice in context generating procedural texts </title>
<section> lexical functions of the ecd for creating.  </section>
<citcontext>
<prevsection>
<prevsent>we limit our scope to the linguistic part of generation; therefore, we assume that onr input is the ontput of text planner, which has already grouped actions into discourse structures as proposed by grosz and sidner (1986) <papid> J86-3001 </papid>and (dale 1988), the input is thus sequence of actions and states in which participants (ingredients, instruments and agent) are represented by indices.</prevsent>
<prevsent>4.2 dictionary of concepts.</prevsent>
</prevsection>
<citsent citstr=" J87-3007 ">
the dictionary of concepts has been inspired by nirenburg and raskin 1987; <papid> J87-3007 </papid>concepts are mainly subdivided into actions or objects.</citsent>
<aftsection>
<nextsent>we have added category of properties, needed to describe relations between concepts (e.g., temporal limit) or attributes (e.g. size).
</nextsent>
<nextsent>relations between concepts are isa, part-o for result, the latter one useftd in domain where state changes are frequent.
</nextsent>
<nextsent>thus, one can relate the action  cut  to the concept  piece  which is the result of  cut .
</nextsent>
<nextsent>the dictiouary of concepts is not copy of the language and there are concepts without any corresponding lexicalization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F429">
<title id=" C96-1088.xml">centering in dynamic semantics </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J95-2003 ">
centering (grosz et al, 1995) <papid> J95-2003 </papid>and dynamic semantics* both concern the sequential process-ing of discourses, with particular emphasis on the resolution of pronouns.</citsent>
<aftsection>
<nextsent>in dynamic semantics, the semantic structure of discourse gives rise to constraints on the resolution of anaphoric expres-sions.
</nextsent>
<nextsent>centering theory claims that discourse always has single topic, or center.
</nextsent>
<nextsent>constraints on the resolution of anaphoric expressions arise, in part, from the ways in which the center can change in discourse.
</nextsent>
<nextsent>there is an important dif-ference in the way discourses are viewed in cen-tering and in dynamic semantics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F430">
<title id=" C96-2141.xml">hmm based word alignment in statistical translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe the details of the mod-el and test the model on several bilingual corpora.
</prevsent>
<prevsent>in this paper, we address the problem of word alignments for bilingual corpus.
</prevsent>
</prevsection>
<citsent citstr=" W93-0301 ">
in the recent years, there have been number of papers con-sidering this or similar problems: (brown et al, 1990), (dagan et al, 1993), (<papid> W93-0301 </papid>kay et al, 1993), (fung et al, 1993).</citsent>
<aftsection>
<nextsent>in our approach, we use first-order hidden markov model (hmm) (aelinek, 1976), which is similar, but not identical to those used in speech recognition.
</nextsent>
<nextsent>the key component of this approach is to make the alignment probabilities dependent not on the absolute position of the word align-ment, but on its relative position; i.e. we consider the differences in the index of the word positions rather than the index itself.
</nextsent>
<nextsent>the organization of the paper is as follows.
</nextsent>
<nextsent>after reviewing the statistical approach to ma-chine translation, we first describe the convention-al model (mixture model).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F432">
<title id=" C96-1036.xml">nth order ergodic multi gram hmm for modeling of languages without marked word boundaries </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>results on its applicw lion on chinese corpus are reported.
</prevsent>
<prevsent>statistical language modeling offers advantages including minimal domain specific knowledge and hand-written rules, tra inability and scala bility given language corpus.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
language models, such as n-gram class models (brown et al, 1992) <papid> J92-4003 </papid>and ergodic hidden markov models (kuhn el, al., 1994) were proposed and used in applications such as syntactic lass (pos) tagging for english (cut- ting et al, 1992), <papid> A92-1018 </papid>clustering and scoring of recog-nizer sentence hypotheses.</citsent>
<aftsection>
<nextsent>iiowever, in chinese and many other oriental languages, there are no boundary markers, such as space, between words.
</nextsent>
<nextsent>therefore pre processors have to be used to perform word segmentation order to identify individual words before applying these word-based language models.
</nextsent>
<nextsent>as result current approaches to modeling these languages are separated into two seperated processes.
</nextsent>
<nextsent>word segmentation is by no means trivial pro-cess, since ambiguity often exists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F433">
<title id=" C96-1036.xml">nth order ergodic multi gram hmm for modeling of languages without marked word boundaries </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>results on its applicw lion on chinese corpus are reported.
</prevsent>
<prevsent>statistical language modeling offers advantages including minimal domain specific knowledge and hand-written rules, tra inability and scala bility given language corpus.
</prevsent>
</prevsection>
<citsent citstr=" A92-1018 ">
language models, such as n-gram class models (brown et al, 1992) <papid> J92-4003 </papid>and ergodic hidden markov models (kuhn el, al., 1994) were proposed and used in applications such as syntactic lass (pos) tagging for english (cut- ting et al, 1992), <papid> A92-1018 </papid>clustering and scoring of recog-nizer sentence hypotheses.</citsent>
<aftsection>
<nextsent>iiowever, in chinese and many other oriental languages, there are no boundary markers, such as space, between words.
</nextsent>
<nextsent>therefore pre processors have to be used to perform word segmentation order to identify individual words before applying these word-based language models.
</nextsent>
<nextsent>as result current approaches to modeling these languages are separated into two seperated processes.
</nextsent>
<nextsent>word segmentation is by no means trivial pro-cess, since ambiguity often exists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F434">
<title id=" C96-1036.xml">nth order ergodic multi gram hmm for modeling of languages without marked word boundaries </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>llowever, since this is still two stage model, the parameters of the whole model cannot be optimized together, and an n- best interface is inadequate for processing outputs from recognizers which can be highly ambiguous.
</prevsent>
<prevsent>a better approach :is to keep all possible seg- ment ations in lattice form, score the lattice with language model, and finally retrieve the best candidate by dynamic programming or some searching algorithms.
</prevsent>
</prevsection>
<citsent citstr=" C94-1032 ">
n-gram models arc usu-ally used for scoring (gu et al, 1991) (nagata, 1994), <papid> C94-1032 </papid>but their training requires the sentences of the corpus to be manumly segmented, and even class-tagged if class-based n-gram is used, as in (nagata, 1994).<papid> C94-1032 </papid></citsent>
<aftsection>
<nextsent>a language model which considers segmenta-tion ambiguities and integrates this with n- gram model, and able to be trained and tested on raw, unsegmented and untagged corpus, is highly desirable for processing languages without marked word boundaries.
</nextsent>
<nextsent>model 2.1 overview.
</nextsent>
<nextsent>based on the hidden markov model, the er- godic multi gram llidden markov model (l,aw and chan, 1996), when applied as language model, can process directly on unsegmented input corpus 204 as it l lows var iab le mmf )e o characters in each word class.
</nextsent>
<nextsent>other than that its prol)erties are sin  liar to ;rgodic l idden markov models (kuhn ct al., 1994), that both training and scoring can be done directly on raw, uncagged corpus, given lexicon with word classes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F436">
<title id=" C96-1039.xml">identification and classification of proper nouns in chinese texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when the former two types are regarded as category, the performance becomes (81.46%, 91.22%).
</prevsent>
<prevsent>compared with other approaches, our approach as better performance and our classification is automatic.
</prevsent>
</prevsection>
<citsent citstr=" C90-2009 ">
a chinese sentence is composed of string of characters without any word boundaries, so that to segment chinese sentences is indispensable in chinese language processing (chen, 1990; <papid> C90-2009 </papid>chen, 1994).</citsent>
<aftsection>
<nextsent>many word segmentation techniques (chen &amp; liu, 1992; <papid> C92-1019 </papid>chiang et al, 1992; sproat &amp; shih, 1990) have been developed.</nextsent>
<nextsent>however, the resolution of unknown words, i.e., those words not in the dictionaries, form the bottleneck.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F437">
<title id=" C96-1039.xml">identification and classification of proper nouns in chinese texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>compared with other approaches, our approach as better performance and our classification is automatic.
</prevsent>
<prevsent>a chinese sentence is composed of string of characters without any word boundaries, so that to segment chinese sentences is indispensable in chinese language processing (chen, 1990; <papid> C90-2009 </papid>chen, 1994).</prevsent>
</prevsection>
<citsent citstr=" C92-1019 ">
many word segmentation techniques (chen &amp; liu, 1992; <papid> C92-1019 </papid>chiang et al, 1992; sproat &amp; shih, 1990) have been developed.</citsent>
<aftsection>
<nextsent>however, the resolution of unknown words, i.e., those words not in the dictionaries, form the bottleneck.
</nextsent>
<nextsent>some papers (fung &amp; wu, 1994; wang et al, 1994) based on smadja paradigm (1993) learned an aided dictionary from corpus to reduce the possibility of unknown words.
</nextsent>
<nextsent>chang et al (1992) proposed method to extract chinese personal names from an 11,000-word corpus, and reported 91.87% precision and 80.67% recall.
</nextsent>
<nextsent>wang et al (1992) <papid> C92-4199 </papid>recognized unregistered names on the basis of titles and surname-driven rule.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F438">
<title id=" C96-1039.xml">identification and classification of proper nouns in chinese texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some papers (fung &amp; wu, 1994; wang et al, 1994) based on smadja paradigm (1993) learned an aided dictionary from corpus to reduce the possibility of unknown words.
</prevsent>
<prevsent>chang et al (1992) proposed method to extract chinese personal names from an 11,000-word corpus, and reported 91.87% precision and 80.67% recall.
</prevsent>
</prevsection>
<citsent citstr=" C92-4199 ">
wang et al (1992) <papid> C92-4199 </papid>recognized unregistered names on the basis of titles and surname-driven rule.</citsent>
<aftsection>
<nextsent>l inet al.
</nextsent>
<nextsent>(1993) presented model to tackle very restrictive form of unknown words.
</nextsent>
<nextsent>sproat et al (1994) <papid> P94-1010 </papid>considered chinese personal names and transliterations of foreign words.</nextsent>
<nextsent>their performance was 61.83% precision and 80.99% recall on an 12,000-chinese-character corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F439">
<title id=" C96-1039.xml">identification and classification of proper nouns in chinese texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>l inet al.
</prevsent>
<prevsent>(1993) presented model to tackle very restrictive form of unknown words.
</prevsent>
</prevsection>
<citsent citstr=" P94-1010 ">
sproat et al (1994) <papid> P94-1010 </papid>considered chinese personal names and transliterations of foreign words.</citsent>
<aftsection>
<nextsent>their performance was 61.83% precision and 80.99% recall on an 12,000-chinese-character corpus.
</nextsent>
<nextsent>this paper deals with three kinds of proper nouns - say, chinese personal names, transliterated personal names and organization ames.
</nextsent>
<nextsent>we not only tell if an unknown word is proper noun, but also assign it suitable semantic feature.
</nextsent>
<nextsent>in other words,  ~?~4~ ~  (george bush) will have feature of male transliterated personal name when it is identified.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F440">
<title id=" C96-1039.xml">identification and classification of proper nouns in chinese texts </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>in the experiment of the gender assignment, 3/4 of chinese personal name corpus is regarded as training data, and the ren mining l/4 is for testing.
</prevsent>
<prevsent>the correct rate is 89%.
</prevsent>
</prevsection>
<citsent citstr=" C94-1026 ">
sentence alignment (chen &amp; chen, 1994) <papid> C94-1026 </papid>is important in 228 setup of bilingual corpus.</citsent>
<aftsection>
<nextsent>personal name is one of important clues.
</nextsent>
<nextsent>its use in aligning english- chinese text is shown in the paper (chen &amp; wu, 1995\].
</nextsent>
<nextsent>7, conc lud ing remarks this paper proposes various strategies to identify and classify chinese proper nouns.
</nextsent>
<nextsent>the perfornmnce evahmtion criterion is very strict not only are the proper nouns identified, but also suitable features are assigned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F442">
<title id=" C96-1090.xml">issues in communication game </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even if were unsin- cere and misunderstood s message on purpose, 2 the non natural meaning is still properly conveyed, because otherwise the intended misunderstanding would be impossible.
</prevsent>
<prevsent>the present study concerns this aspect of com-munication, the non natural meaning in there- stricted sense, which is core of intended commu-nication.
</prevsent>
</prevsection>
<citsent citstr=" J80-3003 ">
lies, ironies, indirect speech acts, and so forth (perrault, 1990; perrault and allen, 1980) <papid> J80-3003 </papid>all share this core.</citsent>
<aftsection>
<nextsent>our understanding about it will hence help us understand basic workings of natural communication systems.
</nextsent>
<nextsent>as an example, centering theory (grosz et al, 1995) <papid> J95-2003 </papid>could be at-tributed to game-theoretic accounts, as demon-strated l~ter in this paper.</nextsent>
<nextsent>communication has been discussed in the game- theory literature.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F443">
<title id=" C96-1090.xml">issues in communication game </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lies, ironies, indirect speech acts, and so forth (perrault, 1990; perrault and allen, 1980) <papid> J80-3003 </papid>all share this core.</prevsent>
<prevsent>our understanding about it will hence help us understand basic workings of natural communication systems.</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
as an example, centering theory (grosz et al, 1995) <papid> J95-2003 </papid>could be at-tributed to game-theoretic accounts, as demon-strated l~ter in this paper.</citsent>
<aftsection>
<nextsent>communication has been discussed in the game- theory literature.
</nextsent>
<nextsent>a signaling game consists of sender s sending message (or signal) to re-ceiver and s doing some action in response to that message.
</nextsent>
<nextsent>here knows something that did not know before receiving the message.
</nextsent>
<nextsent>this is formulated by assuming that belongs to some type, which knows but does not know at first.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F444">
<title id=" C96-1090.xml">issues in communication game </title>
<section> meaning  game.  </section>
<citcontext>
<prevsection>
<prevsent>(2) natural-language meaning games are played at their pareto-optimal equilibria.
</prevsent>
<prevsent>an equilibrium is pareto optimal iff no other equi-librium is pareto superior to it.
</prevsent>
</prevsection>
<citsent citstr=" J94-2003 ">
note that we have derived an essence of centering theory (joshi and weinstein, 1981; kamcyama, 1986; walker et al, 1994; <papid> J94-2003 </papid>grosz et al, 1995).<papid> J95-2003 </papid></citsent>
<aftsection>
<nextsent>centering theory is to explain anaphora in natural language.
</nextsent>
<nextsent>it considers list cf(ui ) of forward-looking centers, which are the semantic entities realize~ in ui, where ul is the i-th utte  ance.
</nextsent>
<nextsent>the forward-looking centers of utterance 7for the sake of simplicity, here we assume that us and u~ arc equal.
</nextsent>
<nextsent>see section 4 for discussion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F446">
<title id=" C96-1090.xml">issues in communication game </title>
<section> compos te  game.  </section>
<citcontext>
<prevsection>
<prevsent>this preference is accounted for by the prefer-ence for parallelism concerning the combination of semantic ontent and grammatical function: in both ul and u~.
</prevsent>
<prevsent>fred is realized by the subject np and max is realized by the object np.
</prevsent>
</prevsection>
<citsent citstr=" P86-1031 ">
this is the same sort of preference that is addressed by property-sharing constraint (kameyama, 1986).<papid> P86-1031 </papid></citsent>
<aftsection>
<nextsent>this effect is attributed to the utility assignment as shown in figure 5.
</nextsent>
<nextsent>that is, the utility u1 of associating he proposition angry(fred, max) (that l~ed is angry with max) with the sentence  the man was angry with him  is greater than the util-ity (/2 of associating angry(max,fred) (the propo-sition that max is angry with fred) with the same 11lewis (1979) discusses everal types of accommo-dation for conversationm score, of which the most rel-evant here is accommodation for comparative salience: becomes more salient han when something is said which presupposes to be more salient han y. probability: /91 ~ p2 angry(fred,max) angry(max,fred) utility:  the man was angry with him  figure 5: meaning ame about propositions and sentences.
</nextsent>
<nextsent>sentence.
</nextsent>
<nextsent>this game might involve other possible associations such as that between angry(max,fred) and  the man made him angry,  but as mentioned at the end of section 4 contents and messages other than included in figure 5 probably accom-pany great costs and hence may be neglected.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F447">
<title id=" C94-1026.xml">a partofspeechbased alignment algorithm </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>al., 1992); bilingual corpus could form bilingual dictionary (brown et al, 1988) and terminology correspondence bank (eijk, 1993); refined bilingual corpus could be formed the examples for machine translation systems (sumita et al., 1990).
</prevsent>
<prevsent>to do such kinds of researches, the most impmlant task is to align the bilingual texts.
</prevsent>
</prevsection>
<citsent citstr=" P91-1022 ">
many length-based alignment algorithms have been proposed (brown et al, 1991; <papid> P91-1022 </papid>gale and church, 1991<papid> P91-1023 </papid>a).</citsent>
<aftsection>
<nextsent>the correct rates are good.
</nextsent>
<nextsent>however, the languages they processed belong to occidental family.
</nextsent>
<nextsent>when these algorithms are applied to other rtmning texts from different families, will the performance keep on tile same level?
</nextsent>
<nextsent>other translation-based alignments (kay, 199l; chen, 1993) <papid> P93-1002 </papid>show the difficulty in determining the word correspondence and are very complex.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F448">
<title id=" C94-1026.xml">a partofspeechbased alignment algorithm </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>al., 1992); bilingual corpus could form bilingual dictionary (brown et al, 1988) and terminology correspondence bank (eijk, 1993); refined bilingual corpus could be formed the examples for machine translation systems (sumita et al., 1990).
</prevsent>
<prevsent>to do such kinds of researches, the most impmlant task is to align the bilingual texts.
</prevsent>
</prevsection>
<citsent citstr=" P91-1023 ">
many length-based alignment algorithms have been proposed (brown et al, 1991; <papid> P91-1022 </papid>gale and church, 1991<papid> P91-1023 </papid>a).</citsent>
<aftsection>
<nextsent>the correct rates are good.
</nextsent>
<nextsent>however, the languages they processed belong to occidental family.
</nextsent>
<nextsent>when these algorithms are applied to other rtmning texts from different families, will the performance keep on tile same level?
</nextsent>
<nextsent>other translation-based alignments (kay, 199l; chen, 1993) <papid> P93-1002 </papid>show the difficulty in determining the word correspondence and are very complex.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F452">
<title id=" C94-1026.xml">a partofspeechbased alignment algorithm </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>however, the languages they processed belong to occidental family.
</prevsent>
<prevsent>when these algorithms are applied to other rtmning texts from different families, will the performance keep on tile same level?
</prevsent>
</prevsection>
<citsent citstr=" P93-1002 ">
other translation-based alignments (kay, 199l; chen, 1993) <papid> P93-1002 </papid>show the difficulty in determining the word correspondence and are very complex.</citsent>
<aftsection>
<nextsent>in tiffs paper, we will introduce part-of-speech (pos)-based alignment algorithm.
</nextsent>
<nextsent>section 2 will touch on the level of alignment and define the sentence terminators.
</nextsent>
<nextsent>in section 3, we will propose tile criterion of critical poses and investigate the distribution of these poses in the chinese-english texts.
</nextsent>
<nextsent>section ,l will describe fifir and rigorous method for evaluating performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F457">
<title id=" C96-2155.xml">generation of paraphrases from ambiguous logical forms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the method allows simultaneous generation from multiple interpretations, without hindering the genera-tion process or causing any work to be super flu ously duplicated.
</prevsent>
<prevsent>this paper describes new generation method that produces multiple paraphrases from semantic input which may contain ambiguities.
</prevsent>
</prevsection>
<citsent citstr=" P96-1027 ">
the method is an extension of the chart based generation algorithm described in kay (1996).<papid> P96-1027 </papid></citsent>
<aftsection>
<nextsent>the focus in this presentation is on generating multiple paraphrases and the ability to operate on logical forms that contain more than one semantic analysis.
</nextsent>
<nextsent>the lnotivation for this is to enable situation (particularly in machine translation) where the resolution of ambiguity is postponed to after the generation process.
</nextsent>
<nextsent>this may open the possibility for considering target language statistics (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>dagan et al, 1991) <papid> P91-1017 </papid>or more generally for applying other criteria to select he  best  translation, which take into account properties of both languages - for example, prefering ambiguity preserv-ing translations.</nextsent>
<nextsent>it may also enable different kinds of interactions between the translation system and the human expert who operates t - tbr instance, disambig-uation by monolingual in the target language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F459">
<title id=" C96-2155.xml">generation of paraphrases from ambiguous logical forms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the focus in this presentation is on generating multiple paraphrases and the ability to operate on logical forms that contain more than one semantic analysis.
</prevsent>
<prevsent>the lnotivation for this is to enable situation (particularly in machine translation) where the resolution of ambiguity is postponed to after the generation process.
</prevsent>
</prevsection>
<citsent citstr=" P95-1034 ">
this may open the possibility for considering target language statistics (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>dagan et al, 1991) <papid> P91-1017 </papid>or more generally for applying other criteria to select he  best  translation, which take into account properties of both languages - for example, prefering ambiguity preserv-ing translations.</citsent>
<aftsection>
<nextsent>it may also enable different kinds of interactions between the translation system and the human expert who operates t - tbr instance, disambig-uation by monolingual in the target language.
</nextsent>
<nextsent>the first demonstration using charts for genera-tion appeared in shieber (1988).<papid> C88-2128 </papid></nextsent>
<nextsent>in that paper the emphasis was to show that uniform architecture can be used for both parsing and generation, however the conception of the chart was limited and the generation algorithm did not appear to be sufficiently attractive.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F460">
<title id=" C96-2155.xml">generation of paraphrases from ambiguous logical forms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the focus in this presentation is on generating multiple paraphrases and the ability to operate on logical forms that contain more than one semantic analysis.
</prevsent>
<prevsent>the lnotivation for this is to enable situation (particularly in machine translation) where the resolution of ambiguity is postponed to after the generation process.
</prevsent>
</prevsection>
<citsent citstr=" P91-1017 ">
this may open the possibility for considering target language statistics (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>dagan et al, 1991) <papid> P91-1017 </papid>or more generally for applying other criteria to select he  best  translation, which take into account properties of both languages - for example, prefering ambiguity preserv-ing translations.</citsent>
<aftsection>
<nextsent>it may also enable different kinds of interactions between the translation system and the human expert who operates t - tbr instance, disambig-uation by monolingual in the target language.
</nextsent>
<nextsent>the first demonstration using charts for genera-tion appeared in shieber (1988).<papid> C88-2128 </papid></nextsent>
<nextsent>in that paper the emphasis was to show that uniform architecture can be used for both parsing and generation, however the conception of the chart was limited and the generation algorithm did not appear to be sufficiently attractive.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F461">
<title id=" C96-2155.xml">generation of paraphrases from ambiguous logical forms </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this may open the possibility for considering target language statistics (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>dagan et al, 1991) <papid> P91-1017 </papid>or more generally for applying other criteria to select he  best  translation, which take into account properties of both languages - for example, prefering ambiguity preserv-ing translations.</prevsent>
<prevsent>it may also enable different kinds of interactions between the translation system and the human expert who operates t - tbr instance, disambig-uation by monolingual in the target language.</prevsent>
</prevsection>
<citsent citstr=" C88-2128 ">
the first demonstration using charts for genera-tion appeared in shieber (1988).<papid> C88-2128 </papid></citsent>
<aftsection>
<nextsent>in that paper the emphasis was to show that uniform architecture can be used for both parsing and generation, however the conception of the chart was limited and the generation algorithm did not appear to be sufficiently attractive.
</nextsent>
<nextsent>kay (1996) <papid> P96-1027 </papid>provides mole general view of the chart structure which is designed to provide for generation advantages comparable to those it provides for pars- ing.</nextsent>
<nextsent>neumann (1994) proposes another version of uniform chart architecture where the same data struc-tures are used for both generation and parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F465">
<title id=" C96-1077.xml">compiling a partition based two level formalism </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" J94-3001 ">
two-level formalisins based on that introduced by (koskenniemi, 1983) (see also (ritchie et al, 1992) and (kaplan and kay, 1994)) <papid> J94-3001 </papid>are widely used in practical nlp systems, and are deservedly regarded as something of standard.</citsent>
<aftsection>
<nextsent>however, there is at least one serious rival two-level notation in existence, developed in response to practical difficulties encountered in writing large-scale mor-phological descriptions using koskenniemi nota-tion.
</nextsent>
<nextsent>tile formalism was first introduced in (black et al, 1987), <papid> E87-1003 </papid>was adapted by (ruessink, 1989), and an extended version of it was proposed for use in the european commission alep language engineering platform (pulman, 1991).</nextsent>
<nextsent>a flmther extension to the formalisln was described in (pul- man and hepple, 1993).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F466">
<title id=" C96-1077.xml">compiling a partition based two level formalism </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>two-level formalisins based on that introduced by (koskenniemi, 1983) (see also (ritchie et al, 1992) and (kaplan and kay, 1994)) <papid> J94-3001 </papid>are widely used in practical nlp systems, and are deservedly regarded as something of standard.</prevsent>
<prevsent>however, there is at least one serious rival two-level notation in existence, developed in response to practical difficulties encountered in writing large-scale mor-phological descriptions using koskenniemi nota- tion.</prevsent>
</prevsection>
<citsent citstr=" E87-1003 ">
tile formalism was first introduced in (black et al, 1987), <papid> E87-1003 </papid>was adapted by (ruessink, 1989), and an extended version of it was proposed for use in the european commission alep language engineering platform (pulman, 1991).</citsent>
<aftsection>
<nextsent>a flmther extension to the formalisln was described in (pul- man and hepple, 1993).
</nextsent>
<nextsent>the alternative partition tbrmalism was mo-tivated by several perceived practical disadvan- *supported by serc studentship no. 92313384.
</nextsent>
<nextsent>tsupported by benefactors  studentship from st john college.
</nextsent>
<nextsent>rages to koskenniemi notation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F468">
<title id=" C96-1077.xml">compiling a partition based two level formalism </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>descriptions of 9 eu languages arc t)eing develot)e(1.
</prevsent>
<prevsent>a version has also be, en im-plemented within si{.i core l,anguage engine (carl;er, 1995) and has been used to develot) de-scriptions of english, french, spanish, polish, swedish, and korean morphology.
</prevsent>
</prevsection>
<citsent citstr=" C94-1029 ">
an n-level ex-tension of the formalism has also been developed by (kiraz, 1994; <papid> C94-1029 </papid>kiraz, 1996b) arrd used to de.-.</citsent>
<aftsection>
<nextsent>scribe t;he morphology of syria(: and other semitic languages, arrd by (bowden an(t kiraz, 1995) <papid> P95-1004 </papid>for error dete( ,tion in noncon(:atenative strings.</nextsent>
<nextsent>this 1)m. tition-l)ased two-level formalism is thus seri-ous riwll to the standard koskcnniemi notation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F469">
<title id=" C96-1077.xml">compiling a partition based two level formalism </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>a version has also be, en im-plemented within si{.i core l,anguage engine (carl;er, 1995) and has been used to develot) de-scriptions of english, french, spanish, polish, swedish, and korean morphology.
</prevsent>
<prevsent>an n-level ex-tension of the formalism has also been developed by (kiraz, 1994; <papid> C94-1029 </papid>kiraz, 1996b) arrd used to de.-.</prevsent>
</prevsection>
<citsent citstr=" P95-1004 ">
scribe t;he morphology of syria(: and other semitic languages, arrd by (bowden an(t kiraz, 1995) <papid> P95-1004 </papid>for error dete( ,tion in noncon(:atenative strings.</citsent>
<aftsection>
<nextsent>this 1)m. tition-l)ased two-level formalism is thus seri-ous riwll to the standard koskcnniemi notation.
</nextsent>
<nextsent>liowever, until now, the koskenniemi notation has had one clear advantage in that it was clear how t;o compile it into transducers, with all the consequent gains in etliciency and portability and with |;ire ability t;o construct lexical transducers as in (karttunen, 1.994).<papid> C94-1066 </papid></nextsent>
<nextsent>this paper sets out to remedy (ha|; defect by descril)ing comtfilation algorithm for the i)artition-bas( two-level nora- lion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F470">
<title id=" C96-1077.xml">compiling a partition based two level formalism </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>scribe t;he morphology of syria(: and other semitic languages, arrd by (bowden an(t kiraz, 1995) <papid> P95-1004 </papid>for error dete( ,tion in noncon(:atenative strings.</prevsent>
<prevsent>this 1)m. tition-l)ased two-level formalism is thus seri-ous riwll to the standard koskcnniemi notation.</prevsent>
</prevsection>
<citsent citstr=" C94-1066 ">
liowever, until now, the koskenniemi notation has had one clear advantage in that it was clear how t;o compile it into transducers, with all the consequent gains in etliciency and portability and with |;ire ability t;o construct lexical transducers as in (karttunen, 1.994).<papid> C94-1066 </papid></citsent>
<aftsection>
<nextsent>this paper sets out to remedy (ha|; defect by descril)ing comtfilation algorithm for the i)artition-bas( two-level nora- lion.
</nextsent>
<nextsent>we use tapes, where tim first tapes are \]exical and the remaining are surface, -- q m. in practi(:e, :: 1.
</nextsent>
<nextsent>we write ei for the alphabet of sylnbols used on tape i, and :: (er {el) ... (e,~ {c}), so that e* is the set of string-tuples representing possible con-tents of the tapes.
</nextsent>
<nextsent>a proi)er subset of regular n-relations have the property that they are ex- pres sible as the cartesian product of regular languages, h. = 1~1 ? ... l~n; we call such re= lations  orthogonal .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F471">
<title id=" C96-1077.xml">compiling a partition based two level formalism </title>
<section> i t roduct ion   </section>
<citcontext>
<prevsection>
<prevsent>for example, the rule (e* (g, g), x e~, e~ v, e*) ( change  to aft;re  g ) would not disallow string-tuple partitioned as ...(.(i, g), (e, c), (u, u)...
</prevsent>
<prevsent>- assmning some cr rule allows (e, e).
</prevsent>
</prevsection>
<citsent citstr=" E95-1028 ">
earlier versions of the partition fbrmalism could not (in practice) cope with multiple lexical char- actors in sc rules , see (carter, 1995, <papid> E95-1028 </papid>4.1).</citsent>
<aftsection>
<nextsent>this is not tit(; case here.
</nextsent>
<nextsent>the tbllowing rules illustrate the formalism: b - * =  ri: b * - - * =  r2: b * d ?  r3: b r1 and r2 illustrate the iterative application of rules on strings: they sanction the lexical-surface strings (vbbb,vbbb), where the second (b,b) pair serves as the centre of the first application of r2 and as the left context of the second ap-plication of the same rule.
</nextsent>
<nextsent>r,a is an cpenthetic rule which also demonstrates centres of unequal length.
</nextsent>
<nextsent>(we assume that  v,v), (c,c) and (d,d) are sanctioned by other identity rules.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F477">
<title id=" C96-1059.xml">a corpus study of negative imperatives in natural language instructions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>itorn (1989)).
</prevsent>
<prevsent>hnpera- rives, on the other hand, have not (for notahle exception, see davies (1986)).
</prevsent>
</prevsection>
<citsent citstr=" J89-4002 ">
in computational linguistics, on the other hand, positive imperatives have been extensively inves-tigated, both from the point of view of interpre-tation (vere and bickmore, 1990; alt erman et al, 1991; chapman, 1991; di eugenio, 1993) and gen-eration (mellish and evans, 1989; <papid> J89-4002 </papid>mckeown et al., 1990; paris et al, 1995; vander linden and martin, 1995).</citsent>
<aftsection>
<nextsent>little work, however, has been (ti- rected at negative imt)eratives.
</nextsent>
<nextsent>(for exceptions see the work of vere and bickmore (1990) in interpre-tation and of ansari (1995) in generation).
</nextsent>
<nextsent>3 pr io i hypotheses di eugenio (1993) lint forward the following hy-pothesis concerning the realization of preventative expressions.
</nextsent>
<nextsent>in this discussion, refers to the in-structor (speaker / writer) who is referred to with feminine pronouns, and to the agent (hearer / reader), referred to with masculine t)ronouns: ? dont imperatives . dont imperative is used when expects to be aware of cer-tain choice point, but to be likely to choose the wrong alternative among many possi-bly infinite ones, as in: (4) dust-mop or vacuum your parquet floor as you would carpeting.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F478">
<title id=" C96-1058.xml">three new probabilistic models for dependency parsing an exploration </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" C92-2066 ">
in recent years, the statistical parsing community has begun to reach out; for syntactic formalisms that recognize the individuality of words, l,ink grammars (sleator and  pemperley, 1991) and lex-icalized tree-adjoining ranunars (schabes, 1992) <papid> C92-2066 </papid>have now received stochastic treatments.</citsent>
<aftsection>
<nextsent>other researchers, not wishing to abandon context-flee grammar (ci g) but disillusioned with its lexica\] blind spot, have tried to re-parameterize stochas-tic ci in context-sensitive ways (black et al, 1992) <papid> H92-1026 </papid>or have augmented the formalism with lex-ical headwords (magerman, 1995; collins, 11996).</nextsent>
<nextsent>in this paper, we 1)resent \[lexible l)robat)ilistic parser that simultaneously assigns both part-of- sl)eech tags and bare-bones dependency struc-ture (illustrate.d in l! igure 1).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F479">
<title id=" C96-1058.xml">three new probabilistic models for dependency parsing an exploration </title>
<section> in roduct ion.  </section>
<citcontext>
<prevsection>

<prevsent>in recent years, the statistical parsing community has begun to reach out; for syntactic formalisms that recognize the individuality of words, l,ink grammars (sleator and  pemperley, 1991) and lex-icalized tree-adjoining ranunars (schabes, 1992) <papid> C92-2066 </papid>have now received stochastic treatments.</prevsent>
</prevsection>
<citsent citstr=" H92-1026 ">
other researchers, not wishing to abandon context-flee grammar (ci g) but disillusioned with its lexica\] blind spot, have tried to re-parameterize stochas-tic ci in context-sensitive ways (black et al, 1992) <papid> H92-1026 </papid>or have augmented the formalism with lex-ical headwords (magerman, 1995; collins, 11996).</citsent>
<aftsection>
<nextsent>in this paper, we 1)resent \[lexible l)robat)ilistic parser that simultaneously assigns both part-of- sl)eech tags and bare-bones dependency struc-ture (illustrate.d in l! igure 1).
</nextsent>
<nextsent>the choice t  simple syntactic structure is deliberate: we would like to ask some basic questions about where x- ical relationships al)pear and how best, to exploit *this materia.l is based upon work supported un-der national science i%undation graduate fellow-ship, and has benefited greatly from discussions with mike collins, dan m(:lame(l, mitch marcus and ad- wait ratnaparkhi.
</nextsent>
<nextsent>(a) tile man in the coiner taught his dachsht , ld io play gol i ;os dt nn in dt nn vbd pp.p$ nn to vh nn /?
</nextsent>
<nextsent>man ~..
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F480">
<title id=" C96-1060.xml">the discourse functions of italian subjects a centering approach </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>hiterpreting referential expressions is importatlt for any large coverage nl system; while such sys-tems do exist for italian, e.g.
</prevsent>
<prevsent>(stock et al, 1993; lombardo and lesmo, 1994), to my knowledge not mudi attention has been devoted to the inter-pretation of italian referential expressions.
</prevsent>
</prevsection>
<citsent citstr=" C90-2047 ">
some exceptions are (samek-lodovici and strapparava, 1990), that discusses interpretation of referential expressions within dialogues to access videodisc on italimi art; (not and zancanaro, 1995), that adopts systemic gra,nmar approadi (halliday, 1976); and (di eugenio, 1990), <papid> C90-2047 </papid>which uses center-ing theory (grosz et al, 1995) <papid> J95-2003 </papid>to account for the alternation of null and strong subjects.</citsent>
<aftsection>
<nextsent>hi this paper, build on and expand (di eu-genio, 1990) <papid> C90-2047 </papid>in several ways.</nextsent>
<nextsent>first, reanalyzc the hypotheses proposed earlier with respect a corl)us of naturally occurring data} show that those hypotheses are basically supported, ithe examples in (di euge.nio, 199{)) were constructed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F481">
<title id=" C96-1060.xml">the discourse functions of italian subjects a centering approach </title>
<section> introduction.  </section>
<citcontext>
<prevsection>
<prevsent>hiterpreting referential expressions is importatlt for any large coverage nl system; while such sys-tems do exist for italian, e.g.
</prevsent>
<prevsent>(stock et al, 1993; lombardo and lesmo, 1994), to my knowledge not mudi attention has been devoted to the inter-pretation of italian referential expressions.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
some exceptions are (samek-lodovici and strapparava, 1990), that discusses interpretation of referential expressions within dialogues to access videodisc on italimi art; (not and zancanaro, 1995), that adopts systemic gra,nmar approadi (halliday, 1976); and (di eugenio, 1990), <papid> C90-2047 </papid>which uses center-ing theory (grosz et al, 1995) <papid> J95-2003 </papid>to account for the alternation of null and strong subjects.</citsent>
<aftsection>
<nextsent>hi this paper, build on and expand (di eu-genio, 1990) <papid> C90-2047 </papid>in several ways.</nextsent>
<nextsent>first, reanalyzc the hypotheses proposed earlier with respect a corl)us of naturally occurring data} show that those hypotheses are basically supported, ithe examples in (di euge.nio, 199{)) were constructed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="F486">
<title id=" C96-1060.xml">the discourse functions of italian subjects a centering approach </title>
<section> centering theory.  </section>
<citcontext>
<prevsection>
<prevsent>transitions between two adjacent utterances u, _i and u,~ can be characterized asa function of looking backward whether cb(un) is the same as cb(un 1) - attd of looking forward whether cb(ur~) is the same as cp(u,~).
</prevsent>
<prevsent>table 1 illustrates the pour transitions that are detined according to diese constraints.
</prevsent>
</prevsection>
<citsent citstr=" P87-1022 ">
(brennan et al, 1987) <papid> P87-1022 </papid>proposes default ordering on transitions which correlates with discourse coherence: continue is preferred to retain is prelbrred to smooth-shift is pre- 2the version of centering presem; here is ti om (brennan et al, 1987).<papid> P87-1022 </papid></citsent>
<aftsection>
<nextsent>352 cb(uu) = cb(wn ,) ct,(un) 7 ~- ct)(w,,.
</nextsent>
<nextsent>1) cb(u,~) = ct)(u,~) (x)ntinui,; smootii-sitlh  cb(u,,) ? cp(u,~) i{etain ii.()u(ili-siiift tat)le 1: ceutering transitions ferred to i{()i\](\[iii-siill. t.
</nextsent>
<nextsent>3 the saliency ordering on the cf list, which is generally equated with grmnmatieal function, for wes(;ern language.s is subje(,t   oilji,;( ,t2   ()lb .iect 7  oti1ers, where otiteii.s includes pret)osi- tional phrases and adjuncts.
</nextsent>
<nextsent>(kameyama, 1985) was the first; (,o point out that for languages uch ;ts .japanese mt)athy and topi(: lnarking alfe(:t the cf ordering, mid t)roposed the fl)lh)wing ranking (1) empathy   siiilie(:t   ()ilie(:t2   ()bje(h    ()tiiei{s folh, (turan, 1995) in adopting (1) also for westerl hmguages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
</paper>