it is also notable the study reported in (lin and hovy, 2003b) discussing the usefulness and limitations of automatic sentence extraction for summarization, which emphasizes the need of accurate tools for sentence extraction, as an integral part of automatic summarization systems. 
for evaluation, we are using the rouge evaluation toolkit1, which is a method based on ngram statistics, found to be highly correlated with human evaluations (lin and hovy, 2003a). 
these findings are additionally supported by the fact that automatic n-gram-based evaluation measures now being used to assess predominately extractive multi-document summarization systems correlate strongly with human judgments when restricted to the usage of unigrams and bigrams, but correlate weakly when longer n-grams are factored into the equation (lin & hovy, 2003). 
