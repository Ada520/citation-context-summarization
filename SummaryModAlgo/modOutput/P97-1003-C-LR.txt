these confidence values can be derived in a number of sensible ways; the technique used by collins was adapted from that used in bikel et al (1997), which makes use of a quantity called the diversity of the history context (witten and bell 1991), which is equal to the number of unique futures observed in training for that history context. 
deterministic parsing algorithms for building dependency graphs (kudo and matsumoto, 2002; yamada and matsumoto, 2003; nivre, 2003) 2. history-based models for predicting the next parser action (black et al, 1992; magerman, 1995; ratnaparkhi, 1997; collins, 1999) 3. discriminative learning to map histories to parser actions (kudo and matsumoto, 2002; yamada and matsumoto, 2003; nivre et al, 2004) in this section we will define dependency graphs, describe the parsing algorithm used in the experiments and finally explain the extraction of features for the history-based models. 
another consequence of not generating posthead conjunctions and punctuation as first-class words is that they 19 in fact, if punctuation occurs before the head, it is not generated at allâ€”a deficiency in the parsing model that appears to be a holdover from the deficient punctuation handling in the model of collins (1997). 
as in most other statistical parsing systems we therefore use the pruning technique described in goodman (1997) and collins (1999: 263-264) which assigns a score to each item in the chart equal to the product of the inside probability of the item and its prior probability. 
in particular, the model in collins (1997) failed to generate punctuation, a deficiency of the model. 
