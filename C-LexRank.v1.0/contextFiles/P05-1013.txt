an alternative method, used by charniak in the adaptation of his parser for czech 6 and used by nivre and nilsson (2005), alters the dependency links by raising the governor to a higher node in the tree whenever 5 bilexical dependencies are components of both the collins and charniak parsers and effectively model the types of syntactic subordination that we wish to extract in a dependency tree. 
recent work by nivre and nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (nivre and nilsson, 2005). 
moreover, the study of formal grammarsisonly partially relevant for research on data-driven dependency parsing, where most systems are not grammar-based but rely on inductive inference from treebank data (yamada and matsumoto, 2003; nivre et al, 2004; mcdonald et al, 2005a). 
it should be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in themselves (nivre and nilsson, 2005). 
most of this work has so far focused either on post-processing to recover non-local dependencies from context-free parse trees (johnson, 2002; jijkoun and de rijke, 2004; levy and manning, 2004; campbell, 2004), or on incorporating nonlocal dependency information in nonterminal categories in constituency representations (dienes and dubey, 2003; hockenmaier, 2003; cahill et al, 2004) or in the categories used to label arcs in dependency representations (nivre and nilsson, 2005). 
for handling non-projective relations, nivre and nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective. 
the following treebanks were used for training the parser: (afonso et al, 2002; atalay et al, 2003; b√∂hmov√† et al, 2003; brants et al, 2002; chen et al, 2003; civit torruella and mart√¨ anton√¨n, 2002; d≈æeroski et al, 2006; haji√ß et al, 2004; kawata and bartels, 2000; kromann, 2003; nilsson et al, 2005; oflazer et al, 2003; simov et al, 2005; van der beek et al, 2002). 
you could map a non-projective dependency tree to a projective one, learn and predict the tree, then bring it back to the non-projective dependency tree (nivre and nilsson, 2005). 
our experiments were conducted on conll-x shared task, with various datasets (hajiÀác et al, 2004; simov et al, 2005; simov and osenova, 2003; chen et al, 2003; b¬®ohmov¬¥a et al, 2003; kromann, 2003; van der beek et al, 2002; brants et al, 2002; kawata and bartels, 2000; afonso et al, 2002; dÀázeroski et al, 2006; civit torruella and mart¬¥ƒ± anton¬¥ƒ±n, 2002; nilsson et al, 2005; oflazer et al, 2003; atalay et al, 2003) . 
jin et al (2005) is an example of it for chinese, where the authors describe an adaptation of nivre's parser to bidirectionality. 
we trained the models on projectivizedù graphs following nivre and nilsson (2005) method. 
this work was made possible because of the annotated corpora that were kindly provided to us: arabic (hajiÀác et al, 2004), bulgarian (simov et al, 2005; simov and osenova, 2003), chinese (chen et al, 2003), czech (b√∂hmov√° et al, 2003), danish (kromann, 2003), dutch (van der beek et al, 2002), german (brants et al, 2002), japanese (kawata and bartels, 2000), portuguese (afonso et al, 2002), slovene (d≈æeroski et al, 2006), spanish (civit torruella and mart√≠ anton√≠n, 2002), swedish (nilsson et al, 2005), and turkish (oflazer et al, 2003; atalay et al, 2003). 
we see that pseudo-projective parsing brings a very consistent increase in accuracy of at least 1.5 percentage points, which is more than that reported by nivre and nilsson (2005), and that the addition of the ps-to-ms transformations increases accuracy with about the same margin. 
in this section we combine the best results from the previous section with the graph transformations proposed by nivre and nilsson (2005) to recover non-projective dependencies. 
thus, nivre and nilsson (2005) improve parsing accuracy for maltparser by projectivizing training data and applying an inverse transformation to the output of the parser, while hall and nov¬¥ak (2005) apply post-processing to the output of charniak‚Äôs parser (charniak, 2000). 
in addition, we replace mbl with svm, a learning algorithm that tends to give higher accuracy in classifier-based parsing although it is more 6more precisely, we use the variant called path in nivre and nilsson (2005). 
whether better parsing accuracy can be obtained by transforming 1about 2% of all dependencies are non-projective and about 25% of all sentences have a non-projective dependency graph (nivre and nilsson, 2005). 
in section 4.2 we use mbl, again with the same settings as nivre and nilsson (2005),3 and in section 4.2 we use svm with a polynomial kernel of degree 2.4 the metrics for evaluation are the attachment score (as) (labeled and unlabeled), i.e., the proportion of words that are assigned the correct head, and the exact match (em) score (labeled and unlabeled), i.e., the proportion of sentences that are assigned a completely correct analysis. 
maltparser (nivre and hall, 2005; nivre et al, 2006) is a data-driven parser-generator, which can induce a dependency parser from a treebank, and which supports several parsing algorithms and learning algorithms. 
the parser used is maltparser (nivre and hall, 2005; nivre et al, 2006), a freely available system that combines a deterministic parsing strategy with discriminative classifiers for predicting the next parser action. 
table 2: transformations; t = transformation; as = attachment score (unlabeled) of œÑ‚àí1(œÑ(‚àÜt)) compared to ‚àÜt maltparser is used with the parsing algorithm of nivre (2003) together with the feature model used for parsing czech by nivre and nilsson (2005). 
to deal with non-projective languages, we use a similar approach of (nivre and nilsson, 2005) to map non-projective trees to projective trees. 
the resources provided for 12 languages are described in: (haji c et al, 2004; chen et al, 2003; bcurrency1ohmov¬∑a et al, 2003; kromann, 2003; van der beek et al, 2002; brants et al, 2002; kawata and bartels, 2000; afonso et al, 2002; d zeroski et al, 2006; civit torruella and mart¬∑ anton¬∑ n, 2002; nilsson et al, 2005; o azer et al, 2003; atalay et al, 2003). 
most previous dependency parsing models have focused on projective trees, including the work of eisner (1996), collins et al (1999), yamada and matsumoto (2003), nivre and scholz (2004), and mcdonald et al (2005). 
nivre and nilsson (2005) presented a parsing model that allows for the introduction of non-projective edges into dependency trees through learned edge transformations within their memory-based parser. 
this is in contrast to other non-projective methods, such as that of nivre and nilsson (2005), who implement non-projectivity in a pseudo-projective parser with edge transformations. 
the pseudo-projective parser of nivre and nilsson (2005). 
as a general result, our experiments confirm previous studies on non-projective dependency parsing (nivre and nilsson, 2005; hall and nov√°k, 2005; 512 mcdonald and pereira, 2006): the phenomenon of non-projectivity cannot be ignored without also ignoring a significant portion of real-world data (around 15a37for ddt, and 23a37for pdt). 
dependency-based representations have become increasingly popular in syntactic parsing, especially for languages that exhibit free or flexible word order, such as czech (collins et al, 1999), bulgarian (marinov and nivre, 2005), and turkish (eryiÀògit and oflazer, 2006). 
however, recent results in non-projective dependency parsing, especially using data-driven methods, indicate that most non-projective structures required for the analysis of natural language are very nearly projective, differing only minimally from the best projective approximation (nivre and nilsson, 2005; hall and nov√°k, 2005; mcdonald and pereira, 2006). 
the pseudo-projective approach (nivre and nilsson, 2005): transform non-projective training trees to projective ones but encode the information necessary to make the inverse transformation in the deprel, so that this inverse transformation can also be carried out on the test trees (nivre et al, 2006). 
many thanks to the sdt people for granting the special license for conll-x and to tomaÀáz erjavec for converting the danish dependency treebank13 (kromann, 2003); swedish: talbanken0514 (teleman, 1974; einarsson, 1976; nilsson et al, 2005); turkish: metusabancƒ± treebank15 (oflazer et al, 2003; atalay et al, 2003). 
nivre's parser has been tested for swedish (nivre et al, 2004), english (nivre and scholz, 2004), czech (nivre and nilsson, 2005), bulgarian (marinov and nivre, 2005) and chinese cheng et al (2005), while mcdonald‚Äôs parser has been applied to english (mcdonald et al, 2005a), czech (mcdonald et al, 2005b) and, very recently, danish (mcdonald and pereira, 2006). 
following nivre and nilsson (2005) we use the following definition: ‚Äúan arc (i, j) is projective iff all nodes occurring between i and j are dominated by i (where dominates is the transitive closure of the arc rela26many thanks to montserrat civit and toni mart¬¥ƒ± for allowing us to use cast3lb for conll-x and to amit dubey for converting the treebank. 
although the parser only derives projective graphs, the fact that graphs are labeled allows non-projective dependencies to be captured using the pseudoprojective approach of nivre and nilsson (2005) . 
typical examples are bulgarian (simov et al, 2005; simov and osenova, 2003), chinese (chen et al, 2003), danish (kromann, 2003), and swedish (nilsson et al, 2005). 
pseudo-projective parsing was proposed by nivre and nilsson (2005) as a way of dealing with non-projective structures in a projective data-driven parser. 
we projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called head by nivre and nilsson (2005), which means that a lifted arc is assigned the label r‚Üëh, where r is the original label and h is the label of the original head in the nonprojective dependency graph. 
graph transformations for recovering non-projective structures (nivre and nilsson, 2005). 
with the emergence of the important role of word-to-word relations in parsing (charniak, 2000; collins, 1996), dependency grammars have gained acertain popularity; e.g., yamada and matsumoto (2003) for english, kudo and matsumoto (2000; 2002), sekine et al (2000) for japanese, chung and rim (2004) for korean, nivre et al (2004) for swedish, nivre and nilsson (2005) for czech, among others. 
