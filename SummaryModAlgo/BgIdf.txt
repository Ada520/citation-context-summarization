sources .	1
requirement has	1
tags supplied	1
its context-free	1
block a9	1
that favoring	1
pragmatic justification	1
approach the	1
pairs ,	2
pairs .	2
optimization criterion	1
for disambiguation	1
input and	1
introduce some	1
also a	3
the probable	1
a phrase	4
are syntax-directed	1
s1 =	1
bilingual phrases	3
with collins	1
of paired	1
main functional	1
of algorithms	1
each question	1
to permeate	1
stories and	1
between positive	1
sentence fusion	2
and riloff	1
has high	1
statement here	1
collins and	2
the chinese	1
section 2.2	1
for learning	2
both directions	2
such lexicalist	1
knowledge processing	1
for paraphrasing	2
noisy-or� combination	1
and document	1
lin 's	1
edges are	1
than three	1
are pruned	1
bikel’s implementation	1
distinct when	1
of basic	2
non-projective methods	1
a97a100a21 is	1
general result	1
point a	1
are an	1
n-gram based	1
limited extend	1
already been	2
annotation of	1
below to	1
morphological analysis	1
in syntax-based	1
of relation	1
constraints which	1
distance needed	1
aspects of	1
nonheadwords bod	2
the former	1
in predicting	1
dependency parsing	4
uses an	1
measures include	1
handcrafted weights	1
in cubic	1
also ignoring	1
on both	1
extent to	1
abstract on	1
aspect of	2
not been	1
{ lim	1
447 sentence	1
picks passages	1
to label	1
that limits	1
whenever 5	1
motivated dependencies	1
tree in	1
to finite-state	1
links involving	1
hypergraph •	1
simple part-of-speech	1
ideal summaries	1
tree is	1
on that	3
utilized by	1
therefore use	1
that graphs	1
functions to	1
techniques used	1
, arabic	2
and available	1
the weight	1
rote extractors	1
recursively generalize	1
for granting	1
performing binary	1
theorem prover	1
accurate facing	1
unlabeled dependencies	1
engines in	1
, dutch	1
aspects :	1
verb entailment	2
word-to-word dictionary	1
are extraction	1
: search	1
language generation	2
significantly higher	1
those surveyed	1
input re1see	1
the dramatic	1
statistical parsers	1
morphemes as	1
in training	2
have defined	1
collins’ model	2
evaluation was	1
cues of	1
; we	1
of 94-97	1
estimated by	1
sets we	1
applies a	2
do include	1
determinization ,	1
% accuracy	2
or ,	1
the mean	3
17 sentence	1
these phrases	1
encouraged natural	1
the mead	1
learning algorithms	1
be captured	2
charniak ,	2
around a	1
charniak .	1
charniak )	2
briefly factored	1
use scfgs	1
summary of	1
charniak &	1
predicate-argument information	2
factor to	1
learning exactly	1
to align	1
and marcu	2
for quite	1
or a	1
first time	1
current smt	2
punctuation occurs	1
to correlate	1
directions and	2
variable ranking	1
combinations reported	1
a state	1
exploit parallel	1
can be	17
and nilsson	1
94-97 %	1
subsequent researchers1	2
sentence extraction	3
we combine	1
in terms	1
notable exceptions	2
theory ,	2
the word-level	1
1 charniak	1
analysis of	5
is well	3
purposes .	1
purposes ,	1
systems outperform	1
of good	1
loglinear model	1
matching systems	1
submodels have	1
been applied	7
little ,	1
positive ,	1
syntax directed	1
the relationships	1
questions ,	3
, word-sense	1
questions .	1
, necessitating	1
discriminative fashion	1
first introduced	1
decoder use	1
: parsing	1
or use	1
of occurrence	1
system we	1
statistical mt	2
ludwig van	1
topic-oriented multi-document	1
that prior	1
for structuring	1
significance of	1
more nonhead	1
phrasal reordering	1
selected in	1
p from	1
algorithm from	1
from smoothed	1
two and	1
a head	2
where several	2
first system	1
mcdonald papers	1
pos tags	4
another example	1
to alignment	1
contrasts to	1
new method	1
providing a	1
entailment acquisition	2
it nevertheless	1
word and	2
chinese and	2
chiang is	1
~n~wer sentence	1
nivre and	4
is more	3
; swedish	1
are not	3
alignment produced	1
original algorithm	1
extracts many	1
reparsing we	1
are additionally	1
pseudo-code for	1
for regular	1
a starting	1
randomly picks	1
that most	2
addressed by	2
look for	1
among all	1
available decoder	1
text corpora	1
training mcdonald	1
most of	5
plaehn ,	1
knight and	2
for czech	3
fact ,	3
its parse	1
decisions has	1
on data	1
the modifiers	1
translations on	2
by 4.	1
• when	1
as surface	2
created by	3
processing of	2
has some	1
the eisner	2
useful for	1
results based	1
for weighting	1
treebank is	3
web for	2
phrase-pairs are	1
a lot	1
corpora and	2
required to	1
extentions to	2
occuring n-grams	1
is to	6
sentences inaccessible	1
and reported	1
smoothing over	1
hierarchical features	1
substring of	1
country party	1
improve parsing	1
previously parsed	1
data-driven parsing	1
see fleischman	1
collected in	1
probability ,	1
probability .	2
, implemented	1
improve disambiguation	1
phrase-based systems	2
of morpheme	1
of reinventing	1
although none	1
1685 1869	1
chinese ,	1
avoid favoring	1
systems for	1
sides ,	1
the more	2
complemented by	1
confidence measures	1
, klein	2
settings ,	1
num uniq	1
collins 1996	2
designed these	1
phrase-structure parser	1
probability p	2
original label	1
assuming the	1
to find	5
using training	1
, including	11
the documents	1
comparison .	2
outlined by	1
a string	1
we review	1
languages ,	2
syntactic interpretations	1
guarantee that	1
a workshop	1
, choi	1
languages :	2
that starts	1
sub-events rather	1
entity recognition	2
we provided	1
see that	2
better codification	1
are plaehn	1
in trec	1
average #	1
impose some	1
to productions	1
section of	1
have tried	2
a clear	1
only handle	1
intervening between	1
sentences to	3
to gather	1
which will	1
such as	15
precisely reflect	2
work the	2
for glass-box	2
a rule-based	1
a deterministic	2
since we	1
naacl task	1
, confer	1
parsing complexities	1
popular and	1
discriminating between	1
proposed ,	4
assigned a	1
favoring short	1
generalizations ,	1
simple set	1
for one	1
quite loose	1
it quite	1
2.1 %	1
in nonterminal	1
methods we	1
and many	3
like czech	1
aim at	1
larger the	1
the past	3
and mani	1
word-based ibm	1
detail in	1
an o	1
of scfgs	1
headwords charniak	2
generic patterns	1
are constructed	1
the year	1
and hypothesis	2
patterns can	1
∈ iff	1
benefit significantly	1
was calculated	1
including concept	2
translation pairs	3
using additional	1
correlation between	1
dyna language	1
follows mcdonald	1
to learn	8
k-best parsing	1
met with	1
differs from	2
chiang use	1
word-to-word translation	1
grammatical outputs	1
the row	1
single words	2
sentiment classification	1
subjectivity or	1
using ravichandran	1
pruning to	1
, ``	1
on models	1
an heuristic	1
of ˜t	1
ravichandran also	1
estimates in	1
binary feature	1
of unrestricted	1
with loss	1
4. the	1
systems are	9
and target	4
underlying model	3
that small	1
the dutch	1
to approximate	1
the story	1
the predicate-argument	2
the srilm	1
projectivized� graphs	1
or one	1
for mt	1
or focuses	1
: gold	1
increase in	4
a per-sentence	1
patterns as	1
hierarchies and	1
using a	4
while maintaining	1
features containing	1
oflazer .	1
a sentence-level	1
treatment and	1
result of	1
default reranker	1
both labeled	2
without modification	1
broadcast precision	1
within the	1
baseline pharaoh	2
a4 a19	1
to normal	1
culminated in	1
this alternative	1
pure dependency	1
allows model	1
allowing each	1
discussion of	2
improve performance	1
node h	1
to adapt	1
modelling toolkit5	1
an emerging	1
information extracted	1
looking at	1
relying solely	1
lexicalization while	2
phrase-based translation	4
we presented	1
correctly attached	1
, describes	1
tag parsergov	1
this permits	1
newspaper articles	1
long sentences	2
, according	3
, described	2
question-answer datasets	1
vertex in	1
reduced sentences	1
become distinct	1
of positive	1
at least	2
which computes	1
simplification and	1
incorporate the	1
achieved using	2
on just	1
s→ np	1
it covers	1
sentences are	1
alignments using	2
distance classes	2
adjectives .	1
, presenting	1
template .	1
model is	1
structural support	1
perfect segmentation/tagging	1
details about	1
hypothesis when	1
preprocessing step	2
trained from	1
model essentially	1
of those	3
scoring functions	1
are using	1
trees in	1
run time	1
, taken	1
to both	1
model in	6
1998 .	1
cell ,	1
the orientation	2
training is	1
with both	1
context-free property	1
, any	1
the fully	1
nonterminal :	2
fig .	1
here a	1
of candidate	2
: mead	1
other work	2
in many	4
rely only	1
, and	24
removed .	1
it comes	1
probability a36a37a4a39a38	1
errors .	1
of bilingual	2
a consideration	1
similarity score	1
interpretation of	1
simplified training	1
data .	8
pair of	1
data ,	3
exercise for	1
on statistical	3
and nov´ak	1
the discriminative	1
≈ 1−	1
distribution over	1
weights in	1
program a45a47a113a115a114	1
of relations	1
in eisner	1
, czech	4
we describe	2
projective parse	1
• counters	1
bys imply	1
of importance	1
algorithm is	3
systems as	1
, koehn	2
higher precision	1
are of	1
of both	4
of unigrams	1
t1 1	1
our overall	1
, until	1
texts to	1
frequencies is	1
chosen task	1
decide which	1
qa system	2
similar idea	1
of their	4
koehn et	2
spmt models	2
structure y	1
in discussing	1
hovy 's	1
dependencies are	1
work most	1
for these	1
parse czech	1
keywords in	1
grefenstette et	1
where most	2
a treebank	1
: using	2
is re-framed	1
: <	1
syntactic phrase	1
this work	5
set :	1
of very	1
v pp-vp	1
model will	1
among the	1
have experimented	1
weighting and	1
as hiero	1
structure ,	3
structure .	1
more precisely	3
references .	1
whether better	1
translation schemata	1
and recall	2
parameter settings	1
be reduced	1
lets the	2
testbeds to	1
tree becomes	1
subtitle generation	1
assuming that	1
workshop devoted	1
helped to	1
head by	1
the amount	1
's non-projective	1
is widely	1
is in	3
summationdisplay a	1
turkish .	2
each link	2
summarization model	1
combines a	1
defining scms	2
dl6 26.34	1
psyco 1.3	1
parsing are	1
or koehn	1
wordaligned corpus	1
schema .	1
utility ,	1
the space	1
asking point	1
task of	3
we refer	1
cluster is	1
subjects ,	1
be carried	1
their human	1
we extended	1
used instead	1
encoding scheme	1
lifted arcs	1
3 morpheme	1
in future	1
riloff )	1
the heuristic	1
attachment score	3
eisner 1996	2
single-sentence “headlines”	1
reference file	1
s and	1
at each	1
in human-written	1
person is	1
: question-answering	1
little overhead	1
terminals and	1
and “es	1
wide margin	1
out that	1
relations for	2
symmetrized word	1
answering systems	1
are minor	1
inter-sentence features	1
combined in	1
: metusabancı	1
pp ,	1
yu and	1
dependencies previously	1
136 objects	1
is monotonic	1
benefit from	2
methods in	1
required for	1
for section	1
source french	1
of phrasebased	3
the refined	1
that reorderings	1
are pursuing	1
standard evaluation	1
the frequency	1
than once	1
in comparison	1
mean p1/p2	1
4 :	3
motivating our	1
that ,	4
phrases was	1
4 .	3
4 ,	1
deprel ,	1
xcat all	2
first of	1
approach into	1
we chose	2
complex relationships	1
between verbs	2
for handling	1
decoders ,	1
paraphrase acquisition	1
than individual	1
, introduce	1
evaluate automatic	1
the algorithms	1
central .	1
importance between	1
feature model	1
tillmann ,	1
grandparent nodes/rules	2
applicable to	2
typical examples	1
aligned at	1
an implementation	2
that s	1
defined a	1
xj .	1
that a	1
construction of	3
applied in	3
of chiang	1
proper nouns	1
and around	1
techniques as	1
weights to	1
languages with	1
for languages	3
prevent a	1
and tested	2
induce a	1
phrase extractor	1
a180 a178	1
heuristic and	1
compression avglen	1
generalisation is	1
rate ,	1
including theorem	1
texts in	1
entropy model	1
ullman 's	1
favoring syntactic	1
for domain-specificity	1
algorithms or	1
very brief	1
to devise	1
and neighboring	1
more specifically	1
additional attributes	1
are different	1
consists of	1
belongs to	1
papers but	1
, reasoning	1
axioms .	2
mst parsers	1
parsers and	1
charniak in	1
section 3.4	1
made the	2
overcome this	2
other papers	1
phrasebased translation	1
with bootstrapping	1
great deal	1
the notion	3
checks the	1
reduced pos	1
are evaluated	2
provides a	1
may also	1
an interesting	1
work in	10
ˆaj ∈	1
in section	7
, most	4
n where	1
phrase level	4
appendices of	1
, summarization	1
treebank of	1
a33 denotes	1
produces results	1
work is	2
the degree	1
the confidence	1
free or	2
d )	1
< verb	1
in different	2
different sources	1
definition :	1
we take	1
phrases recent	1
this representation	1
existing phrase	1
probabilistic approaches	1
a probability	1
definition 1	2
subjects 95	1
employ so-called	1
a141a44a9a44a122a25a20 a35	1
projectivity into	1
but not	1
pos-based features	1
subjects 98	1
241 over	1
to translation	2
pattern derivation	1
the structural	1
other are	1
create an	1
dutch due	1
of default	1
has shown	2
hovy’s algorithm	1
n-gram probabilities	1
package tiburon	1
the part-of-speech	1
in f-measure	1
a77a54a78a102a77a134a118a98a135a136a78a75a137 subject	1
between word	1
summaries and	1
a particular	4
are retained	1
wsj .	1
results show	1
aligned .	1
translations are	1
framework on	2
annotated corpora	1
while phrases	1
2 commas	1
the german	1
other research	2
derivation is	1
location :	1
hiding in	1
for main	1
the case	3
experiment ,	1
vector w	1
target phrases	2
uni-gram co-occurrence	1
likely to	2
datasets .	2
these modifiers	1
phrases :	1
model to	2
relative influence	1
yamada and	8
components of	3
vector f	1
phrase-based approaches	1
formed by	1
phrases .	5
phrases ,	7
to smt	2
, turney	1
approximating sentence	1
objectively .	2
the lexical	4
recognize instances	1
figure 7.15	1
hatzivassiloglou ,	1
state-of-theart alignment-template	1
various datasets	1
wealth of	1
, anchor	1
entire parse	1
levels .	1
corpus using	1
a similar	11
, research	2
's parser	4
m-gram integrated	1
is actually	1
any word	2
learn these	2
the set	5
the underlying	2
bpm outperforms	1
other projective	1
research has	1
first identify	2
overhead even	1
to linear-time	1
revising summaries	1
text by	1
each chart	1
data using	3
relationships inventor	1
generate features	1
classification in	1
categorization under	1
methods call	1
has seen	1
ranking .	1
phrase based	2
art performance	1
reduction that	1
include features	1
increasingly popular	3
sentiment information	1
computational linguistics	1
the glue	2
most phrase-based	2
learn a	2
works on	2
shorter derivations	1
on tackling	1
applied or	2
here for	1
alignment template	2
expressing relations	1
within parse	2
adverbs etc	1
account for	1
a manner	1
opinions .	1
opinions ,	1
monotone search	1
combination techniques	1
have culminated	1
paraphrases in	1
although explicitly	1
for parsing	2
please refer	1
are studies	1
and its	2
the field	6
the mst	2
sensible ways	1
probably ,	1
relation patterns	1
constraints for	1
ontology for	1
to indicate	1
learn ,	2
learning methods	3
is shown	2
entity type	1
been scaled	1
ones as	2
a tag	1
word-based approach	1
have recently	2
also compared	3
for of	1
questions from	1
large-margin dependency	1
in koehn	1
complex tasks	1
find that	2
algorithm proposed	1
advanced the	1
specific problem	1
pharaoh decoder	1
relationships while	1
being used	2
a lifted	1
motivated constraint	1
opinions contain	1
essentially belongs	1
inside probability	1
the research	2
redundancy can	1
as phrase	1
with semantic	1
be returned	1
best results	5
dependency grammar	2
filter out	1
recall of	2
sentences based	1
from opinions	1
4.2 we	1
broader range	1
's syntax-directed	1
recall on	1
minimally from	1
input completely	1
modifications to	1
will try	1
in making	1
a relative	1
identify answers	1
automated efforts	1
learning in	1
out noise	1
smt system	3
most highly	1
for relation	1
under this	1
's instance/concept	1
pairs using	2
here “phrase-based”	1
that learns	1
in dependency	4
dealing with	1
hr ,	1
2 shows	1
pairs are	4
motivated does	1
with those	2
more detail	2
, whether	2
words that	6
“train :	1
lexical features	2
either on	1
a way	3
chinese-english and	1
major operations	1
limit ,	1
templates consider	1
word-aligned training	1
web page	3
argmaxe pr	1
apply question	1
any equivalence	1
has attracted	1
, all	6
t2 1	1
opinion in	1
accuracy over	1
a set	10
taking a	1
such identified	1
sure alignments	1
, bigrams	2
textual inference	1
simulation :	2
by jing	2
decade .	1
the pp	1
the other	8
use expensive	1
of larger	1
information sources	1
57 literature	1
al applies	1
smooth a	1
be formalized	1
their head	1
training on	2
standard natural	1
new hierarchical	1
from prior	1
which require	1
10 million	1
induction algorithm	1
relations using	1
art by	1
two-level bigrams	2
and world	1
would think	1
bestknown heuristic	1
growdiag-final� shows	1
well to	1
in prior	1
weights of	1
, textual	1
tends to	2
messages in	1
each component	1
the asking	1
sentence shortening	1
, seeds	1
in α	1
recent implementation	1
it on	1
translation pair	1
sentence compression	2
similarity metric	1
clean-room model	1
built systems	1
even dependency	1
the expected	1
sentence if	1
spans on	1
between words	3
sentence in	1
necessary .	1
sentence is	1
and zeman	1
reranking algorithm	1
hlt-naacl 2003	1
search algorithm	1
or the	4
naturally ,	1
we get	2
is possible	2
subjectivity ,	1
tiburon .	1
receive different	1
on syntactic	2
theory .	1
correct head	3
by chiang	1
processing to	1
variant called	1
to performing	1
heuristic of	1
been identified	1
a lexical	1
also focusing	1
to score	2
introduction ,	1
use bootstrapping	1
results for	4
ne recognizer	1
split of	1
the best	11
or coarse	2
obtain conditional	1
obtain one-to-many	1
have led	3
that the	12
ways ;	1
distributional candidates	1
label for	1
the 22,500	1
prover .	1
semantic correspondence	1
assign probability	1
case too	1
can show	1
system similar	1
allowed rewrite	1
, resulting	1
algorithm can	1
french file	1
edges in	2
89.6 89.5	1
other subjective	1
others )	1
the highest	4
using such	1
long tradition	1
, there	6
al mention	1
that reorders	3
popular in	4
the phrasetable	1
including removing	1
it at	1
it as	2
: did	1
annotated on	1
a check	1
constituency parse	1
our model	3
quarc to	1
quite low	1
scms the	2
or word	1
binary distinction	1
language models	1
and there	1
bilingual lexicons	1
ef cient	1
to maximize	1
weighting scheme	1
which they	1
classes using	1
total error	1
our features	1
to 1/	1
a weighted	1
test logical	1
relatedness dectors	1
scaling relation	1
ie relationships	1
methods on	2
exact match	1
point ,	1
so-called phrase	1
an analysis	1
study opinion	1
that sentiment	1
higher recall	1
, fusing	1
considered three	1
taking advantage	1
of full	1
pseudo-projective parsing	1
block set	1
aligning to	1
been made	2
runtime of	2
, relative	2
experimental evaluation	1
al used	2
common approach	3
as summarization	1
chinese documents	1
of dealing	1
morphemic representation	1
the inverse	2
algo .	1
sentences of	1
data collins	1
classifying the	1
61 tags	1
original proposal	1
accuracy further	1
˜iproductdisplay i=1	1
of syntactic	4
conducted on	1
features over	1
tags since	1
al decide	1
in either	1
method that	1
confirm previous	1
the pascal	1
hatzivassiloglou identified	1
answer 127	1
portuguese ,	1
discussion our	1
, syntactic	2
a30 a32	1
to maximum	1
which was	2
wish to	2
classes of	1
address this	1
of ravichandran	1
for longer	1
exploit morphological	2
with head	1
need for	1
were achieved	1
deliver increasingly	1
czech parser	1
point machine	1
perceptron ,	1
fragments are	2
's decoder	1
intricacies of	1
and generalise	1
or lemmas	1
on the	18
being the	1
effective training	1
textual units	1
study of	3
in other	2
, lexical	3
and lexico-syntactic	1
string ,	2
provided for	3
step at	1
biographical information	1
on adjectives	1
model shows	1
of single	2
deleting unimportant	1
minimal transformation	1
of binary	1
view of	1
other systems	1
of newspaper	1
pairs which	1
, subtitle	1
research nlp	1
we did	1
: projf	1
rules described	1
eisner gave	1
multi-document summarization	2
proving .	1
reports on	1
, japanese	1
improve upon	1
and generation	1
two block	1
contexts of	1
document level	1
weighted average	1
and describe	1
applying it	1
work we	3
a coarse	1
answering ,	1
answering .	4
since it	1
seeds only	1
similarly to	3
to ours	2
phrases after	1
models in	2
various aspects	1
and complete	1
both uses	1
to reducing	1
in coverage	1
the relations	1
alignment method	1
few efforts	1
those motivating	1
was 13	1
f-to-e ;	1
2 which	1
of sensible	1
american english	1
labeled constituencies	1
a19 for	2
> for	1
and mira	1
a modified	1
by czech	1
& tsujii	1
out procedure	1
al focus	1
ours but	1
employed .	1
the danish	1
be syntactically	1
part-of-speech patterns	1
item and	1
assign handcrafted	1
a different	2
in fact	3
of first-order	1
directed monotonic	1
1.93 bt-2-step	1
of surface	1
production rules	1
when asking	1
wordnet regarding	1
second experiment	1
current article	2
negra treebank	1
grow-diag-final .	1
synchronous cfg	1
states’ relationship	1
or by	1
special license	1
al proposed	1
: giza++	1
increase the	1
central concepts	1
from filled	1
implement the	2
two models	1
summarization method	1
words or	1
considerably more	1
commonly used	3
field is	1
,3 and	1
describe a	4
lindek/minipar.htm 5	1
reason for	2
on distance	1
then reported	1
for two	1
our base	1
217 online	1
a wider	1
evaluation metric	1
sets with	1
extracting binary	2
no entity	1
, although	3
written summaries	1
so we	2
assumptions are	1
) compared	1
chart associated	1
the m	1
conditional parsing	1
for computational	1
svm-lighttk to	1
% 91	1
% 92	1
% 93	1
indicates the	1
only derives	1
% 96	1
greater than	1
an automatic	1
busiest airports	1
certain words	1
h =	1
have used	5
schemata ,	1
guarantees to	1
this way	2
contain the	1
lemmas ,	1
syntactic transformation	1
subject shift	1
this was	2
poor .	1
more accurate	4
; this	1
measure ,	1
transfer rules	1
by allowing	1
score is	1
were used	1
) time	1
3 shows	1
, dependency	2
experiments used	1
2.2 automatically	1
; union	1
dividing the	1
dependency frameworks	1
very well	1
`` take	1
metric correlates	1
for information	1
inspired by	4
can infer	2
online perceptron	1
learn surface	1
696 precision	1
, ppicker�	1
factorization of	1
lex phrase-decoder	2
parsing up	1
to look	1
alignments between	1
's state-of-the-art	1
add up	1
evaluation to	1
head child	1
word blocks	1
cast3lb for	1
by ldc	1
the readme	1
expensive o	1
find lexical	1
context for	1
the word-aligned	1
an edge	1
categories used	1
accuracy to	2
quality is	1
word-pair probabilities	1
a possible	1
unigram cooccurrence	1
large margin	1
two aspects	1
is illustrated	1
uses humsent	1
frontier lexicalization	2
the actual	1
al propose	1
restrict that	1
, target-phrase-conditioned	1
these axioms	1
the proposed	2
arabic .	2
chiang reported	1
is strictly	1
of vocabularies	1
the distortion	2
generation techniques	1
non-projective dependency	2
nilsson for	1
tagging used	1
swedish .	1
us :	1
occurring between	2
party .	1
which take	1
data mining	1
wordnet similarities	1
describes several	1
swedish ,	2
measure that	1
phrases as	1
transformations .	1
exception to	1
story ''	1
the wn	1
bleu and	1
transformations ;	1
lexicalized approach	1
the conditional	2
automated ,	1
and eventually	1
logical rules	1
a non-discriminative	1
of och	2
relationship between	2
the initial	2
attributes .	1
several qa	1
: s	1
an appropriate	2
ra using	1
parsing systems	2
: treebanks	1
phrase being	1
consist of	1
lexical weights	1
estimation from	1
50 %	1
sentences have	1
project .	1
methods and	1
let us	1
be the	3
morphemes ,	1
dubey for	1
is almost	2
f-score on	1
dating back	1
multiple syntactic	1
added to	1
structures or	1
frequencies :	1
probabilistic phrase	1
brevity )	1
frequencies .	1
frequencies ,	1
go beyond	2
quantities of	1
linguistically motivated	3
be removed	1
calculus axioms	1
chiang addresses	1
especially between	2
analysis to	1
training procedures	1
syntactic information	3
so their	1
in nlp	1
ranking/selection in	1
contrast with	1
at best	1
whether a	2
considered .	1
approach has	1
non-projective relations	1
of ts	1
a10 a30	1
structuring terminology	1
that phrases	1
an initial	1
question .	1
question ,	2
experiments and	1
> to	1
training corpora	1
of paraphrase	1
sentence-extraction summarization	1
extraction techniques	1
methods )	1
precision recall	2
similar performance	1
, later	2
methods ,	4
1.5 percentage	1
be chosen	1
be a	5
npa is	1
dual roles	1
addition ,	4
treebank tree	1
formal models	1
them ;	1
hovy shown	1
a simple-yet-effective	1
identities of	2
a 20.2	1
best parser	2
but only	1
attention after	1
about the	4
word alignments	2
those given	1
them ,	1
and answer	1
storage cost	1
limited the	1
syntax-based mt	1
our baseline	2
joint probability	3
of parsers	1
the special	2
that revising	1
: phrases	1
not yet	1
which p	1
no parsing	1
has difficulty	1
at phrase	1
translations that	2
keyword indexing	1
anchor approaches	1
errors made	1
learn feature	1
relying on	1
mira has	1
nitestate methods	1
received lots	1
division of	1
answer extraction	1
by which	3
the attachment	3
equal to	1
to his	1
consequence of	1
sub-strings ,	2
60.4 %	2
a precise	1
special knowledge	1
the mutual	1
attempt to	4
attention from	2
al .3	1
parsing accuracy	3
new <	1
translation tasks	1
of unpublished	1
beyond the	1
hovy report	1
models described	1
bag-of-word fashion	1
o algorithm	1
repeatedly ,	1
the goal-verb	1
operations that	1
in modeling	3
uses frontier	2
object mentioned	1
strong state	1
previous stochastic	1
evaluation toolkit1	1
bases ,	1
with 97.0	1
text logical	2
mt machine	1
regular parsing	1
also limited	1
corresponding words	1
the non-spanish	1
package to	1
phrase in	1
a probabilistic	2
scheme called	1
capture much	2
once on	1
τ−1 )	1
experiments with	1
yet been	1
translation piggyback	1
sentence-level subjectivity	1
of nlp	1
in data	1
collins czech	1
introduces a	1
for decoding	1
this information	1
develop several	1
beyond keyword	1
is easily	1
years have	1
parameters for	1
is tried	1
statements of	1
the important	1
slightly underperformed	1
but implemented	1
non-projective trees	2
erroneously stated	1
above ,	2
adhere to	1
signature is	1
on phrase-based	1
a discriminative	2
the works	1
% 118	1
opinion analyzers	1
not lead	1
and about	1
have shown	2
each phrase	1
reduced .	1
3. determining	1
removing extraneous	1
score functions	1
improvements in	1
first followed	1
effective approach	1
makes use	1
submitted to	1
minipar downloaded	1
more sophisticated	1
expression level	1
nist measure	1
different information	1
paraphrase similarity	1
by following	1
model differs	1
assigning unreasonable	1
an equivalent	1
style of	1
use svm	1
pharaoh with	2
idea relying	1
task where	1
a data-driven	2
statistical phrase-based	1
a rich	1
phrases that	2
problem to	1
an approach	1
expansion of	2
visualized as	1
allows non-projective	1
reasons .	1
their strength	1
consistent alignments	1
, discoverer	1
of classes	1
by precision	1
but tune	1
a syntactic	2
that occur	1
languages that	2
under a	2
released by	1
the verb	1
call for	1
= log	1
relations in	1
on document-level	1
prepositional phrases	1
the context	5
annotating the	1
, scrutinized	2
derivations ,	1
examples of	3
many standard	1
and allows	1
step of	1
vector-spacebased patterns	1
non-monotonic phrase	2
all projective	1
to phrases	2
component from	1
efficiency and	1
computed independently	1
reflect the	2
implementation and	1
containing likely	1
disambiguate the	1
out the	1
n∈ bracerightbig	1
al and	5
that utilizes	1
en-es es-en	1
with dependency	2
editing extracted	1
was modified	1
of labels	1
of restriction	1
system as	1
comparing with	1
engines are	1
a task	1
choose between	1
to appear	1
to exploit	2
: s1	1
treats the	1
of articles	1
tagging and	1
to have	4
higher than	2
translations for	1
the quadratic	1
and applying	2
of neuhaus	1
to give	2
name/instance lists	1
2.64 bleu	1
in yu	1
discourse representation	1
, various	5
and bears	1
on conll-x	1
across all	1
different from	1
sentiment classifications	1
for qa	1
than 2	1
corpus which	1
on labeling	1
by hf	1
deterministic 85.4	1
time ,	3
the 14	1
time .	2
define a	1
evaluate our	1
equation and	1
where topic	1
parameter tuning	1
time ;	1
as empirical	1
existing statistical	1
nodes in	2
attempts to	4
‘diag-growthfinal’ •	1
online large-margin	2
than d	1
, charniak	2
translations avg	1
faster to	1
the chu-liuedmonds	1
integrated syntax	1
to assess	1
method to	5
through trec	1
in supervised	1
a source-to-target	1
transformation ;	1
feature space	1
analysis include	1
approach :	1
concepts such	1
) or	1
clause in	2
model pr	1
approach .	5
approach ,	4
are extracted	2
of uses	1
through various	2
that are	9
course problematic	1
train and	1
such instances	1
using kneser-ney	1
the diversity	1
each training	1
of factoid	1
used to	12
to miss	1
on frequencies	1
gr~rarn~tical structure	1
: p∈uniontextui=1	1
carried out	2
be complemented	1
negative semantic	1
most probable	1
some seed	1
called path	1
to sequential	1
a model	2
mt systems’	1
smoothing .	2
translating sequences	1
the parsers	1
translation probability	1
, 2000	1
the appendices	1
and showed	1
, indicate	1
1about 2	1
translated into	1
from mcdonald	1
that deal	1
language annotation	1
analysis and	2
training (	1
basis .	1
training ,	2
considered each	1
training .	2
line parse	1
5 :	1
of fleischman	1
given alignment	1
obtained by	1
any verbs	1
charniak 89.5	1
5 .	2
5 ,	1
especially using	1
produced by	4
mckeown and	2
translation methods	1
that clusters	1
was used	3
phrases are	3
that attempt	2
reported improvements	1
, very	2
etzioni )	1
effectively model	1
pay closer	1
generate n-best	1
higher nodes	2
elusive .	1
esp- :	1
can operate	1
recent works	2
rules to	2
increase of	2
experiments which	1
words tend	1
quality on	1
with structures	1
so-called document-level	1
or neutral	1
quality of	4
decreases .	1
approaches pay	1
text processing	1
2note that	1
studies 404	1
works that	1
preference for	1
o .	2
o )	1
broadly categorized	1
if the	5
due to	4
french/english data	1
in that	3
to favourable	1
alignment variable	1
, y	2
alignments generated	1
for multilingual	1
for extensions	1
called head	1
many dependency	1
on experiments	1
tbl templates	1
optimal strategies	1
sources used	1
, focusing	2
prototype that	1
“is usually”	1
87.5 86.3	1
language question	1
collins which	1
for tree-structured	1
calculated from	1
in are	1
with translations	1
is assigned	1
question parsing	2
the training	2
by bikel	2
our feature	1
argmaxe ,	1
and runtime	1
8 of	1
textual contexts	1
on classification	1
establish the	1
models represent	1
performance little	1
known phrase-based	1
algorithm by	2
add constraints	1
c uses	1
is employed	1
similarity captures	1
string contain	1
, using	4
chineseenglish translation	1
current state	2
modeling translations	1
the two	4
typical named	1
in goodman	1
a web	1
analysis start	1
parses .	2
φh .	1
main advantage	1
reformulation is	1
translated source	2
between ”london”	1
syntactic or	2
task-independent system	1
signature introduced	1
learning extraction	1
languages .	3
of glass-box	1
is generated	1
and gravano’s	1
humsent accuracy	1
but rely	2
suggesting that	1
enable rapid	1
improvements to	2
harvesting shallow	1
the easy	1
all these	1
compressionsnally ,	1
log-linear model	2
two concepts	1
idf is	1
extensions to	2
, facts	2
is based	7
2003 hltnaacl	1
cfg for	1
parsers tested	1
that extrinsic	1
today 's	2
and textual	2
bootstrapping technique	1
aimed at	1
prior-polarity lexicons	1
module .	1
during decoding	1
re-implemented by	1
, bulgarian	3
better constituent	1
recent years	4
adapted version	1
we give	1
lexicon model	1
with variable	1
see appendix	1
· f	1
nodes occurring	1
films ,	1
results the	1
several recent	1
, ravichandran	1
also include	1
still takes	1
that state	1
to three	1
to what	1
procedure is	1
cross-sentence informational	1
of these	6
stochastic parsers	2
och et	1
huang and	1
opinion expression	1
initial word	1
, coordination	2
features :	1
lots of	1
giza++ model	1
templates are	1
be ignored	1
features .	3
with that	1
features ,	3
which includes	1
component weights	1
, part-of	2
modified weighting	1
encode the	2
hierarchical phrase-based	1
words in	4
non-projective parses	2
of interest	3
model and	4
when phrases	1
possible head-dependent	1
tree as	1
banks of	1
first submitted	1
file and	1
words is	1
and manning	2
very comparable	1
acquiring entailment	1
without using	1
pantel and	1
induced by	1
previous dependency	4
must be	2
starts from	1
89.5 23	1
compression relies	1
segments containing	1
those presented	2
the ps-to-ms	1
markovization :	1
extend ,	1
which forms	1
includes some	1
perceptron training	1
strong impact	1
for those	1
dangerous if	1
framework which	1
as central	1
that provide	2
multi-sentence text	1
would cause	1
and knowitall	1
compensate for	1
constraining the	1
few modifications	1
and cluster	1
• use-knowledge	1
researchers proposed	1
birthyear >	1
a131a71a132a133 a116a117	1
for choosing	1
very little	1
train on	2
improvement over	2
type defined	1
of huang	1
and we	2
showed that	4
extend a	1
large quantities	1
which searches	1
employs a	1
and named	1
more ef	1
and wu	2
extracted contiguous	1
parsing strategy	1
pp parameters	1
the similar	1
whereas language	1
for pdt	1
rank the	1
length n	1
defined on	1
margin approach	1
phrases independently	3
answer validation	1
10.6 %	1
for pdg	1
training trees	1
including longer	1
to go	1
to statistical	1
3.21 spade	1
% 136	1
some kind	2
was noted	1
for the	17
unrestricted english	1
model can	1
obtained for	1
arabic-english translation	1
uses a	6
entropy ,	1
incorporate .	1
maximum margin	1
details in	1
improved significantly	1
have integrated	1
k are	1
or learned	1
with no	3
between nouns	1
stochastic parsing	1
presents a	2
parsing —	1
iff j	1
a8 ,	1
is usually	2
as those	3
phrasal machine	1
approaches to	4
in several	1
obtain the	3
that maximises	1
complete translations	1
83.8 <	1
these methods	2
: matrix	1
selected as	1
adapted from	1
be determined	1
on their	2
word vectors	1
; phrase	1
a translation	2
output the	1
not described	1
, subjectivity	1
bloedorn .	1
p. pattern	1
in used	1
we select	1
tree parsing	1
to parser	1
task is	2
translation schema	1
structure on	1
any relation	1
an object-oriented	1
be easier	2
tags intervening	1
applies to	1
predict gr~rarn~tical	1
made considerable	2
not reach	1
cluster centroids	1
described above	1
to restrict	2
trec ,	1
theory that	1
entailment relationships	1
< birthyear	1
of chapters	1
a test	1
gandhi john	1
feature set	2
structures ,	1
their computations	1
generated at	1
such semantic	1
“headlines” for	1
between hypothesis	1
the definition	1
dependency-based representations	2
distributional inclusion	1
in one	1
refined and	1
relations between	4
weighting the	1
method similar	1
sentences from	1
uses publicly	1
traditional beam	1
evaluation results	1
the tease	1
has gained	1
words to	1
the backed-off	1
unk bod	1
to conclude	1
increasingly larger	1
we achieved	1
models similar	1
other nitestate	1
“there is”	1
airports in	1
for answer	1
answer-point identification	1
is set	1
of children	2
models has	1
extracting phrases	1
linearly-scored dependency	1
also propose	1
problems ;	1
danish .	2
danish ,	1
pw and	1
reordering .	1
we adhere	1
past work	1
as observed	1
the numerator	1
spans may	1
text compression	1
is done	1
only adding	1
two of	1
concrete semantic	1
the language’s	1
obtain improved	1
p is	2
morphemes until	1
factoid questions	1
the annotations	1
is much	2
an ibm	1
define the	2
substrings with	1
similar to	8
hatzivassiloglou are	1
and mann	1
phrase decoder	1
ˆe =	1
improved the	3
jing propose	2
all subsequent	1
, opinion-oriented	1
phrases which	1
per-sentence basis	1
a higher	1
times in	2
asking for	1
labeled precision	1
and using	2
determine the	2
englishto-german ,	1
knowitall .	1
assigned the	3
hlex =	1
are used	4
external parsing	1
relative clauses	1
computation is	1
< name	1
a state-of-the-art	4
to select	2
average of	1
technique described	2
proof by	2
, key	1
length .	1
grammars do	1
highest number	1
have seen	1
the chosen	1
a cluster	1
of valuable	1
. }	1
described here	1
find the	2
k-best paths	1
to help	1
several steps	1
probability distribution	1
per fl	1
from left-to-right	1
search to	1
with psyco	1
margin learning	1
using the	9
nonheadwords :	1
some approaches	1
not generating	1
probabilities and	2
some dependency	1
next-best derivation	1
margin loss	1
with great	1
87.8 87.9	1
and related	1
uses hierarchical	1
information can	2
identify initial	2
> of	1
for building	1
nivre 's	2
phrasal boundaries	1
similarities between	1
and nominals	1
for φem	1
of sorts	1
demonstrated that	1
: example	1
local scores	2
phrases has	1
distinction of	1
all begin	1
to significant	2
benefits from	1
distributional similarity	1
extracted phrasal	1
by humans	2
on all	1
created the	1
art phrase-based	1
3 the	1
, i.e	4
factored into	1
“subsequence-based” ,	1
chiang who	1
now been	2
we would	2
increases in	2
above 90	1
and section	1
flat rules	1
's default	1
that each	1
tag ,	1
is different	2
add it	1
english phrases	1
technique as	1
judgments when	1
action .	1
, extraction	1
types :	1
all wordnet	1
several resources	2
of constraining	1
types ,	3
we focused	1
types .	2
% 57	1
than from	1
the wsj	2
the margin	1
translational alignments	1
literature ;	1
dependencies by	2
first proposed	1
= 1	2
5 features	1
or some	1
literature ,	4
co-occurrence matching	1
our constraints	1
terminology in	1
of minipar	1
annotated phrasal	1
, dl4	1
, dl6	1
as for	1
over sentence-parse	1
and discriminative	2
the compositional	1
refer to	4
geography domain	1
trees it	1
data and	1
q/a system	1
, their	4
description form	1
sentence reduction	2
case .	2
case ,	1
probabilities based	1
model that	6
the k	1
did try	1
are relevant	1
editing the	1
for type	1
92 %	1
prospects .	1
probably not	1
override syntactic	1
real-world data	1
constituents ,	1
corresponding to	1
phenomenon of	1
each vertex	1
edge factorization	1
questions as	1
use linguistic	1
recent computational	1
of chinese	1
sets ,	2
sets .	3
lost dependencies	1
their content	3
sentence testing	1
here ,	3
a0 a30	1
here .	2
o time	2
parse the	1
in response	1
our engine	1
and mcdonald	5
and another	1
equivalence relation	1
trained on	4
the development	2
using pharaoh	1
nonterminals merged	2
as other	1
define cluster-based	1
focus on	3
opinion on	1
under categories	1
methods to	1
which we	2
% and	1
applied it	1
is discarded	1
words improve	1
evaluation models	2
the increase	2
an inverse	1
a minimal	1
-th target	1
the central	1
have also	5
ibm4 alignments	1
computed which	1
which occur	1
yield efficient	1
it will	1
parsergov g	1
7 .	1
constitute a	1
basic model	1
for automatically	1
contrast to	2
than focusing	2
7 :	1
on generative	1
null alignments	1
for natural	1
. 1	1
al applied	2
: ~cogentex	1
its subject	1
facts ,	2
extraction we	1
lists described	1
to this	1
n subjects	1
of verb	1
aligned to	1
automatic pattern	1
are dropped	1
published results	2
signs has	1
minimum error	1
limitations of	3
context has	1
or implicit	1
aligners.1 4.2	1
reordering the	1
correlate weakly	1
are dominated	1
clear picture	1
. )	2
train several	1
so-called alignment	1
strategies to	1
definition questions	1
possible parse	1
the grammar	1
articles could	1
informational sub-sumption	1
turney )	1
clusters of	1
offline construction	1
edges into	1
choi et	1
fleischman 's	1
from marcu	1
tree kernel	1
the technique	2
simplification systems	1
method focuses	1
and trigram	1
the tagset	1
evaluation :	1
utilized lexical	2
beyond linguistically	1
are more	3
currently the	1
5-15 that	1
other tree-based	1
a pr	1
language-dependent knowledge	1
lexicalized phrase-structure	1
counts of	1
to filter	1
of compressing	1
mining ,	1
words of	2
trained the	1
frequency of	2
are grateful	1
include fujio	1
in more	1
improvements using	1
to outperform	2
treebank ,	4
relative distortion	1
treebank .	4
needed to	1
) include	1
that history	1
23 for	1
and discriminating	1
been extended	1
the entire	1
systems’ output	1
= 2	1
85.0 85.9	1
shift of	1
then use	2
is an	8
other dependency	1
paired production	1
predefined training	1
sentence-level subjective	1
explored statistical	1
features used	4
be taken	1
works and	1
is unreliable	1
to recover	1
: •	4
determine their	1
a6 a29	1
arc rela26many	1
the range	1
obtained high-frequency	1
we nd	1
valuable knowledge	1
parsing the	3
special case	2
significant performance	1
clean up	1
latter of	1
deterministic parsers	1
a dependency	4
modified to	2
generating 15	1
discriminative reranking	1
original document	1
by stochastic	2
optimize in	1
prominence as	1
the 50	1
and non-projective	2
account different	1
below 10	1
produce concise	2
parsing based	1
tag as	1
a single-parameter	1
urls ,	1
knowledge .	1
treebanks 1punctuation	1
knowledge ,	1
“phrasebased” or	1
two new	1
a when	1
facing pruning	1
observed in	4
patterns were	1
license for	1
variant on	1
combination method	1
b set	1
bracketing transduction	1
instead use	2
but rather	1
a solution	1
nonterminals ,	1
2. this	1
finite-state processing	1
following resources	1
’s algorithm	1
a runtime	2
analysis have	1
of non-projectivity	1
which identify	1
process .	2
) to	1
3.2 questions	1
, but	13
imitation instead	1
stateof-the-art quality	1
: :similarity	1
3.4 .	1
since exhaustive	1
chains ,	1
jin }	1
use particular	1
inference from	2
available giza++	2
view has	1
ne .	1
the offline	1
parser leads	1
and ullman	1
on cohesion	1
knowledge axioms�as	1
we believe	1
sentences in	2
has motivated	1
least tesni~re	1
general-purpose algorithm	1
held at	1
dependencytree parser	1
parallel texts	3
: “an	1
and all	2
to parse	4
trees scope	2
are similar	2
, k-best	1
involving the	1
, kudo	1
hypothesis and	1
26.64 5-gram	1
14 in	1
the rouge	1
generative probabilistic	1
the sentences	2
orientation .	1
“grow-diagfinal” .	1
compare alternative	1
to derive	2
the inclusion	1
to achieve	2
are above	1
orientation ,	1
head out-ward	1
one aspect	1
two extremes	1
community as	1
all sentences	1
applications ,	2
positive vs.	1
the base	1
rank them	1
such ,	1
applications :	1
for maltparser	1
learning approach	2
or similarity	1
clearly the	1
and etzioni	2
approximate a	1
any commas	1
morphological tag	1
phrases involving	1
rules discussed	1
source phrases	2
better than	1
eisner describes	1
all terms	1
neighboring morphemes	1
gibt” in	1
text-to-text generation	1
such a	2
collins’ parser	1
, researchers	3
forms written	1
learned by	1
systems use	2
2 rule	1
way by	1
a of	1
only details	1
adaptation .	1
reach the	1
, word	1
paraphrase learning	1
, particularly	1
gravano ,	1
a corresponding	1
this concern	1
word-level and	1
tag classification	1
neighboring unaligned	1
tree structure	1
introduced in	4
we maximize	1
the pdt	2
dependency labels	1
an improved	1
rate of	1
sequential natural	1
where f	1
formalisms that	1
that will	1
shown to	3
where a	2
probabilistic models	1
where l	1
been lauded	1
and tries	1
where t	1
where r	1
to use	3
scored according	1
dependency structure	1
distinction is	1
“phrase-based” means	1
ciently use	1
test set	4
is equivalent	1
of conjuncts	1
did not	2
and accurate	1
the reference	1
as compared	1
a36a37a4a39a38 a33a41a40a43a42a44a33a46a45	1
comes to	1
”london” and	1
beginning with	1
lexical cues	1
by external	1
background knowledge	1
the exact	2
our templates	1
both the	3
where ,	1
for which	1
measures described	1
factual questions	1
overcome the	2
relationships .	1
relationships ,	1
portions of	1
where :	1
for approximating	1
, wilson	1
was run	1
modelbuilding and	2
and rlifferent	1
appropriate for	1
including context	2
used for	9
hypothesis sentences	2
appendix a	1
most current	2
and first	1
, since	5
best accuracy	1
word instances	1
pr and	1
compared a	1
pp-attachment or	1
an effective	1
indicates positive	1
to languages	1
2. history-based	1
we also	7
graph theory	1
generative model	4
of headwords	1
as semantic	1
expect it	1
e-to-f and	1
strongly with	1
of collins	4
algorithm provides	1
the resulting	2
2/ the	1
, number	1
efficient parsing	1
algorithm using	1
phrase-table .	1
achieves an	1
over our	1
in practice	1
syntax-directed as	1
employing some	1
, slovene	1
phrase-based frameworks	1
brin ,	1
algorithm and	1
well or	1
well illustrated	2
and that	1
compared .	1
k constraints	1
interpolation of	1
neg-log lexical	1
the post-processing	1
work either	1
4. we	1
so that	3
been published	2
the hiero	1
three features	1
such that	2
grammars .	4
appear in	2
a33a53a45 a32	1
language pair	1
recent systems	1
to deal	2
models are	3
, recent	2
and child	1
precision but	1
which can	3
plan to	3
nature ,	1
other resources	1
the formally	1
its head	1
phraseextract algorithm	1
that selects	1
high as	1
of his	1
83.3 88.6	1
this measure	2
be compared	1
phrases and	1
% 72	1
for conll-x	1
also become	2
• relative-count	1
different source	1
is lower	1
ep :	1
times the	1
97.0 %	1
low ;	1
a synchronous	1
find this	1
however ,	10
the independence	1
, answer	1
retrieved text	2
are components	1
observation that	1
lfgbased system	1
but has	1
existing rule	1
to set	1
deal of	1
try different	1
research rewards	1
algorithm described	4
relations involving	1
learning that	1
their computational	1
inference engines	1
positive or	1
for probabilistic	1
distances ,	1
an advantage	1
especially sensitive	1
word tokens	1
a138 a20a102a139	1
a research	1
highest-scoring trees	1
mean ratings	1
here due	1
parsing framework	2
derivationally relation	1
parameter training	1
charniak’s parser	1
sequence analysis	1
“holes” for	1
used a	6
knowledge that	1
, a3a5a4a35a29	1
and long	1
projection ≡	1
frequencies of	1
the tsa	1
a preprocessing	2
baseline :	1
almost as	1
following approximate	1
compare against	1
an instance	1
baseline ,	3
elements within	1
and derivationally	1
order to	11
check for	1
translation probabilities	1
nlp and	1
used 3	1
a kind	1
dependency scores	1
: ˆam1	1
previous approaches	3
the worst	1
for this	3
hard-wiring projectivity	1
surface text	1
summationdisplay ∈a	1
matcher from	1
, of	1
heads in	1
often insufficient	2
following definition	1
head and	1
being aligned	1
learn the	1
results across	1
as phrases	1
summationdisplay ∈y	2
al report	1
in python	1
to combine	1
stack-based machine	1
} ,	1
model does	1
} )	1
with his	1
general for	1
our summary	1
phrase-based system	3
applying heuristic-based	1
bogart mohandas	1
coarse distance	2
document meta�	1
a time	2
recent approaches	2
gibt ,	1
source of	2
than in	2
it appears	1
2003 .	1
result produces	1
2003 chinese-english	1
preferences ,	1
rewrite rules	1
a convergence	2
that requiring	1
collins .	2
a33a50a8 a36a51a4a39a38	1
collins ,	3
collins )	1
data set	3
opinion-bearing words	1
query ,	1
are linguistically	1
collins ;	1
and charniak	2
has used	2
non-projective languages	1
dateline is	1
likely answers	1
detail about	1
one way	1
introduces hiero	1
idf where	1
usually refer	1
80 %	1
a178 .	1
last four	2
basic and	1
obtained a	1
section 4.	1
distortion of	1
dropped .	1
absolute improvement	1
parser from	1
single-parameter distortion	1
f as	1
and sentences	2
, analogous	1
a highly	1
mohandas gandhi	1
bikel 's	2
resemble the	1
relation prec	1
free style	1
to how	1
al describe	2
decoding 2	1
transforms the	1
* to	1
c3 c4	1
better ,	1
illustrated in	2
faster than	2
the tree	3
parsers above	1
decoding ,	1
their jump	2
model are	1
researches )	1
to directly	1
on nondeterministic	1
more than	3
a40a52a42 a33a53a45	1
facilitate comparison	1
obtained .	1
structures in	2
are also	3
one phrase	2
permits the	1
structures is	1
its own	2
deemed to	1
the cubic-time	1
without also	1
extracted sentences	2
and extension	2
application ,	1
parallel parsing	1
, endeavored	1
which either	1
translated or	1
then bring	1
it is	13
phrase reordering	1
p r	1
the earlier	2
intermediate step	1
not possible	1
contiguous phrase	1
which resemble	1
the extraction	2
further information	1
is measured	2
transcripts and	1
mira algorithm	1
some generic	1
weak to	1
p l	1
the ones	2
representations are	1
technique where	1
% 244	1
was pharaoh	1
given input	1
a specific	1
gave a	1
limitation to	1
commas ?	1
by computing	1
giza out	1
to optimize	1
the governor	1
e∗ =	1
system up	1
used pairs	1
similarity or	1
of concrete	1
level are	1
p =	2
probabilities from	1
the form	1
the hypothesis	2
currently ,	2
, again	1
a combination	1
extraction systems	1
p .	1
class-based target-language	1
the placement	1
, comparisons	1
added features	1
liu ,	1
the shorter	1
possible to	3
first described	1
trained with	1
not generated	1
tasks require	1
cubic parsing	1
shown here	1
trained for	1
more detailed	1
the spanish	1
than 10	1
that contain	1
normalization .	1
each existing	1
reported significant	1
individual words	1
arcs in	1
more intuitive	1
derived using	1
$ ,	1
adequate in	1
not considered	1
alignment—detection of	1
of 2other	1
this framework	2
we can	5
so-called “phrasebased”	1
and score	1
extremes ,	1
empirical evaluations	1
cross-pair similarity	1
also more	1
two verbs	1
on deriving	2
typically expressed	1
7 summaries	1
are aimed	1
ambiguous ,	1
a valiation	1
pruning that	1
{ $	1
this confirms	1
to some	1
al or	1
we erroneously	1
automatic summaries/translations	1
values of	1
same category	1
has sought	2
sets using	1
thistask .	1
; studies	1
conjoined with	1
time phrase-based	1
of efficient	1
any one	1
particular answers	1
nilsson we	1
gives statistics	1
model described	1
, microsoft	1
summarization algo	1
extraction was	1
recognize opinions	1
the head	3
were conducted	1
and geographical	1
applying an	1
features it	1
the phrasal	1
f }	1
accuracy is	2
use alternative	1
more informative	1
: left-handside-conditioned	1
employment9 ,	1
of phrase	1
investigated two	1
colons ?	1
models outperform	1
or right	1
• keep	1
computations or	1
quantifiable .	1
lexical-based distance	1
of morphemes	1
tree algorithms	1
of iterations	1
simple task	1
a looser	1
other applications	1
beneficial to	1
addressed as	1
focusing on	4
linguistic and	1
reported to	2
, parsing	3
dependency structures	3
overview of	2
major difference	2
corpus consisting	1
maximum/minimum spanning	1
by empirical	1
filtering to	1
target projection	1
within german	1
answer anchors	1
in wu	1
seed list	1
obviously ,	1
c/summationtext˜s c	1
and define	1
classifications )	1
to automatically	3
tokenized corpus	1
kappa .	1
coverage in	2
and takes	1
test-set that	1
reorders phrases	3
sets are	1
using phrase	2
spite of	1
by fleischman	1
have by	2
be included	1
for combination	1
phrases to	2
the heuristics	1
from german	1
directly meaning	1
training scheme	1
length 5-15	1
points on	1
from its	2
automatically harvesting	1
one nonterminal	1
a ne-supported	1
completely —	1
of structured	1
hypothesis with	1
semantics of	1
86.5 81.2	1
considering the	2
therefore ,	1
showed the	2
and bloedorn	1
ratnaparkhi 87.5	1
an alternative	3
similar approach	1
we scaled	1
, maximum-likelihood	1
for allowing	1
accuracy and	1
a variant	1
, whereas	1
in two	3
chinese-to-english alignments	1
a query	1
regimen for	1
us imagine	1
is the	13
methods have	2
lie in	1
periphery ,	1
the sdt	1
vocabularies .	1
generic ,	1
of document	1
:similarity package	1
of an	2
mt system	3
using different	2
grammarsisonly partially	2
for all	1
of at	1
formalized as	1
different scores	1
corpus to	1
turney proposed	1
nlp tasks	1
phrase-based baseline	1
translation using	1
x bought	2
the benton	1
well as	5
conjunction ,	1
success to	1
ignoring a	1
structures required	1
maxyprime s	1
bethard et	1
for standard	1
a parser	1
local context	1
performance for	1
terms of	1
to paraphrase	1
occur very	1
each list	1
two methods	1
tomaˇz erjavec	1
alignment templates	2
on incorporating	1
and arabic-english	1
toolkit5 performs	1
quality and	1
solution .	1
paraphrasing .	1
address the	1
achieved that	1
88 %	1
string of	1
is consistent	2
corpus ,	3
corpus .	4
such methods	1
alignments produced	2
hidden word	1
will be	5
syntactic and	1
, to	9
pharaoh phrase-based	1
related terms	1
passages .	1
allows for	1
roles ,	1
relevant data	1
use one	1
which ``	2
significantly less	1
, portuguese	1
comprehension examinations	1
and assume	2
: rst	1
grammars have	3
default feature	1
shows an	1
for an	2
by data	1
derived by	1
answering has	1
with varying	2
and compare	1
if we	3
for kbest	1
paraphrasing x	2
require a	2
metrics used	1
nilsson presented	1
scores obtained	1
mds .	1
training set	2
of postprocessing	1
two high-accuracy	2
is relevant	1
often used	1
toward the	1
to estimate	1
monotonic hypergraphs	1
gravano’s work	1
articles .	1
to handle	1
then refined	1
statistical framework	1
here we	2
this ,	3
or how	1
heuristic rules	1
concern in	1
between and	1
both algorithms	1
computational reasons	1
relative-count based	1
i.e .	4
their successful	1
surge of	1
where δk	1
progress on	1
the dyna	1
approach extends	1
movie and	1
, compute	1
experiment differs	1
than all	1
recent efforts	2
a family	1
often precedes/follows	1
pr systems	1
potentially exponential	1
been avoided	1
= summationdisplay	3
a machine	2
, decoding	1
smt decoder	1
that purpose	1
assigns a	1
) and	5
components ,	1
components .	1
we followed	1
to implement	1
and grefenstette	1
powerful lexicalized	1
systems to	2
improvement in	2
to their	4
yet they	2
dutch alpino	1
2. determining	1
the optimal	2
pair is	1
systems make	1
determined through	1
where every	1
which treats	1
we define	3
converting the	1
events .	1
generally met	1
approximation .	1
nonterminal to	1
, are	4
nonlocal dependency	1
adaptation of	2
or utilized	2
idea by	1
current stateof-the-art	1
improved word	1
4 of	1
the recent	3
text level	1
complete emulation	1
trec8 through	1
handling in	1
rouge variant	1
employed successfully	2
born in	1
rule with	2
pair in	1
39.7 %	1
takes all	2
, calculate	1
notable the	1
this problem	2
automatically generated	1
syntax-directed translation	1
tree constructor	1
the strengths	1
partial parsing	1
and exact	1
96.9 %	1
lim }	1
model parameters	1
modest amount	1
opinion sentences	1
shallow methods	1
raina et	1
and moldovan	1
expressions at	1
conforms to	1
the particular	1
our parser	1
context-free phrasestructure	1
another smart	1
cutting and	1
essentially scripts	1
could not	1
believed to	2
otherwise noted	1
facilitate comparisons	1
or train	1
data sets	2
its phrase	1
and gamon	1
cky-based hiero	1
maximize the	1
by eisner	1
length num	1
extracted sentence	1
marcu and	3
this formalism	1
; scenario	1
utility is	1
leaving it	1
compression process	1
performs well	1
pcfg model	1
were commonly	1
but do	1
correspondence between	1
is ef	1
for computation	1
smaller data	1
trec showed	1
applications such	2
treatment of	2
in single-document	1
unreasonable probabilities	1
possible parses	1
ones used	1
strategy of	1
there is〉	1
this combined	1
to recognize	2
represent any	1
source projection	1
a less	1
with pure	1
scenario description	1
wildcard matches	1
88.0 %	1
= c/summationtext˜s	1
on paraphrasing	1
; as	1
source and	4
or below	1
for training	4
comparisons across	1
accurate than	1
because of	2
; an	1
lexicons .	1
which in	2
phrase alignments	1
0 t3	1
those previously	1
˜t ,	1
complete space	1
to model	2
components have	1
relative-frequency estimates	1
techniques are	1
with phrasedbased	1
automatic acquisition	1
of τ−1	1
and is	2
and it	1
already prevent	1
may just	1
1* tsuruoka	1
: “i	1
and english	1
and ie	1
to compute	4
designed to	1
on fleischman	1
techniques to	2
translation community	1
good phrase	1
and in	2
well .	3
compared to	5
well ,	1
results reported	1
sentence which	1
work was	1
romanian-english corpus	1
very similar	2
and hovy	3
synchronous binarization	1
sets the	1
inventory of	1
and vice	1
on 10,000	1
uses of	1
items that	1
correlates highly	1
a dynamic	1
extracted text	1
applied textual	1
bleu scores	2
the intervening	2
dependency graph	3
statistics of	1
collins/bikel parser	1
a span	1
word-to-word relations	1
as indicators	1
get final	1
then it	1
is distortion	2
are uncontroversial	1
world knowledge	1
information to	1
highly with	1
to more	2
the method	5
parsing models	5
rules used	1
document is	1
, yet	2
= transformation	1
the ability	2
some linguistically	1
or urls	1
supported by	2
corresponds to	1
several contexts	1
more efficient	1
contexts that	1
problem posed	1
the polarity	1
used :	2
treebank using	1
posed in	1
high recall	1
indicated with	1
been developed	1
names and	1
but arguably	1
restricts the	1
were applied	1
two basic	1
, rank	1
% 195	1
problems 727	1
of mcdonald	1
pr can	1
allowing the	1
on about	1
also used	3
new features	1
to phrase-table	1
scores are	1
calculate the	1
and acquisition	1
; our	1
marcu .	1
errors ,	1
bi-phrases .	1
creating prior-polarity	1
8 :	2
hierarchical rules	1
original head	1
constraint ,	1
and linguistic	1
to keep	1
the treebank	2
that maximum	1
past to	1
been word	1
that randomly	1
based word	2
former subsumes	1
coordinate such	1
a word-aligned	1
containing the	1
the node	2
only two	1
previous works	1
speech of	1
of degree	1
of researchers	1
another strategy	1
up training	1
as question	2
models that	3
approach exploits	1
more appealing	1
reliable translations	1
weights since	1
from sentences	1
, maximum/minimum	1
subtree set	1
chiang that	1
are derived	2
the seed	1
web-based method	1
limiting phrase	1
dl4 20.51	1
¯ak−1 =	1
resulted more	1
determining document	1
use cast3lb	1
conditional distribution	1
generate the	1
several transformations	2
unaligned word	1
evaluate the	1
to distinguish	1
summarizer that	1
maximise equation	1
contiguous phrases	1
of applied	1
p of	2
transitive closure	1
cant improvements	1
which smoothed	1
of entities	1
above the	3
phrase tables	1
is realized	1
align with	1
figures reported	1
dependency relations	1
: sim	1
failed to	1
2004 and	1
points in	1
and thelen	1
are too	1
→ vp	1
: many	1
exact matching	1
the default	1
provide a	3
method ‘diag-growthfinal’	1
we restrict	1
involing proper	1
include text	1
discuss related	1
instance .	2
instance ,	5
acquiring a	1
19.09 3.10	1
compressing long	1
basis of	2
: hlex	1
each other—is	1
acquiring context	1
for any	1
that our	2
statistical translation	1
in common	1
such concrete	1
4 to	1
indicate the	1
capturing local	1
treelets is	1
penn treebank	3
name >	1
means to	1
topic signatures	3
stages :	1
imposed on	1
document to	2
results when	1
have very	1
phrase table	2
involving coordination	1
alignments based	1
the fact	3
could be	4
and evaluate	1
which removed	1
valiation of	1
to very	2
is introduced	1
parsing have	2
bigrams ,	3
convey a	1
its reimplementation	2
mxparse parser	1
chiang’s synchronous	1
noted recently	1
has suggested	1
jing and	2
are consistent	1
phrase-based smt	3
between i	1
reviews and	1
, headwords	2
, grandparent	2
chain consists	1
between a	1
produce an	1
following .	1
bilingual phrase	1
but koehn	1
1 for	1
, information	2
tables were	1
method for	5
30.3 mira	1
provided to	1
and relations	1
productions of	1
244 objects	1
entailments ,	2
models and	4
, based	2
words share	1
table 4.	1
, maximum	1
approach presented	1
related work	2
that phrase-based	1
generalizes well	1
1this is	1
least 1.5	1
call constellations	1
therefore impose	1
bruce and	1
on bilingual	3
version of	2
to take	1
most works	1
, despite	1
why question	1
standard division	1
, riloff	2
we created	1
results that	1
only the	4
and parsing	1
rst ,	2
humsent as	1
a grammar	1
reaches 82	1
the goal	1
is scored	1
models appears	1
reduction strategy	2
less data	1
dependency treebank13	1
feature representation	2
a relation	1
data lemma	1
nodes/rules ,	2
a frequency	1
is〉 as	1
p∈uniontextui=1 {	1
translation operations	1
maltparser ,	1
a10 and	1
decoding algorithm	1
of our	4
higher node	1
assumption that	1
during the	2
trial set	1
for letting	1
are compared	2
target-to-source alignment	1
frequently in	1
same time	2
not be	3
other hand	4
the recall	3
talbanken0514 ;	1
pharaoh training	1
in both	4
the system	7
achieve the	2
complex methods	1
theorem proving	1
textual unit	1
are assigned	4
wordnet to	1
response ,	1
through their	1
an f-measure	1
which has	4
word-aligned sentences	1
we assume	4
al compare	1
linear combination	1
somewhat surprising	1
multi-class training	1
eisner ,	5
recently by	1
eisner .	1
performing classifications	1
score the	1
been based	1
through suitable	1
ensuring grammaticality	1
and extending	1
from parse	1
we simply	1
mead :	1
generated pos	1
automatic recognition	1
may benefit	1
additional heuristically-induced	1
models have	7
against an	1
more powerful	2
their polarity	1
kernel methods	1
general ones	2
her system	1
it .	2
manually in	1
relevant previous	1
the accuracy	3
hovy present	1
from words	1
semantic connectivity	1
lemma ,	1
expertise directly	1
penalty .	1
projective ,	2
candidate was	1
others have	1
we discuss	2
was first	3
y are	1
has made	1
edge from	1
; e.g.	1
think of	1
only considers	1
constituents in	1
year of	1
making use	2
now standard	1
dependency analysis	1
an extracted	1
lemma l	1
wordnet ,	1
c2 c3	1
local translations	2
headwords of	1
sentiments ,	1
feature sets	1
sentiments :	1
into a	5
constituents can	1
time which	1
its ability	2
directly ,	1
family of	1
other facts	1
output of	2
and signature	1
retained ,	1
and mbl	1
a38 a33	1
technique used	1
question-answer pairs	2
the manually	1
equivalent to	2
1a notable	1
systems exploit	1
exploiting all	1
the probability	3
the parser	6
head-child� in	1
the ra	1
wsj with	1
phrase-structure parsers	1
pieces of	1
words at	1
language modelling	1
into dependency	1
learning parsing	1
results extracting	1
set from	2
high quality	2
originally known	1
on our	1
appropriate heuristic	1
co-occurrence was	1
a sample	1
thus propose	1
phrase-based ,	1
contained the	1
negative language	1
discuss a	1
current paper	1
permits us	1
a term	1
unigram co-occurrence	1
pseudo-projective .	1
each of	3
the lexical-weighting	1
extraction is	1
is hiding	1
improves upon	1
the loss	1
stan156 en-es	1
sorts ,	1
on sentence	3
markov model	1
score for	1
is phrase-based	1
and bigrams	1
chu-liuedmonds algorithm	1
all nodes	1
systems rely	2
multilingual use	1
for isi’s	1
the well	1
unrestrictedly incorrect	1
been successful	1
their system	1
incorporating syntactic	1
best unlabeled	1
sought to	2
the phrase-based-like	1
in centroid-based	1
otherwise δk	1
as =	1
a lexicalized	2
similarity approach	1
the usefulness	1
applying a	2
negative .	1
negative ,	1
various phrase	1
a high-dimensional	1
nonprobabilistic approaches	1
as searching	1
on cross-sentence	1
document frequency	1
and time	1
similarity siml	1
using morphological	1
unlike most	2
either assuming	1
alpino corpus	1
steps must	1
— typically	1
particular text	1
for non-projective	1
pattern and	1
both projective	1
for dutch	1
differences over	1
provided more	1
head repeatedly	1
interest recently	1
concepts of	1
human-written abstracts	1
surprising ,	1
uses part	1
and component	1
language used	1
concepts or	1
compiled rules	1
and storage	1
the noisy-channel	1
, negative	1
information necessary	1
random sampling	1
reduction rules	1
example of	4
revising the	1
the individual	1
seed words	1
also use	1
1 t2	1
constituencies using	1
removed all	1
baseline mt	1
developing more	1
approach parallels	1
training data	5
parameters bys	1
combination of	3
account the	2
< 1*	1
in spite	1
best phrase-structure	1
the addition	6
words used	1
to facilitate	1
the task	4
al perform	1
depth .	1
zeman uses	1
negative reviews	1
accelerated with	1
models objectively	2
% when	1
task as	2
many heuristics	1
initial rules	1
were based	1
not contain	1
of including	3
statistics on	1
nlp group	1
polynomial and	1
packed parse	1
considers unigrams	1
is explored	1
than five	1
relation between	2
the rules	2
of rules	1
see ,	1
the material	1
see .	4
other evaluation	1
parsing greatly	1
a stochastic	1
indices at	1
, ryan	1
but even	1
suggested that	1
additionally ,	2
between translation	1
only included	1
topic signature	1
using relative	1
machines for	1
using machine	1
i=1 )	1
a utility-based	1
out experiments	1
non-editorial news	1
presented signi	1
words automatically	1
the improvements	1
have explored	3
7.15 in	1
approach was	1
separated facts	1
follows the	1
can also	2
questions following	1
parsing with	1
the phrases	1
on explicit	1
common in	1
or with	1
pharaoh .	1
on lexical	2
pharaoh ,	2
are only	1
, keep	1
h ∈	1
, apply	1
automatically learning	1
on questions	1
90.7 90.7	1
text expresses	1
n-gram language	1
parser and	5
matching ,	1
of analysis	1
making one	1
phrase-table smoothing	1
p and	1
on 7.2m+9.2m	1
should allow	1
and training	1
initial phrase	2
way of	3
20.51 26.64	1
of documents	4
, new	1
studies instead	2
as previously	1
: precision	1
components include	1
ran our	1
content .	2
which provide	2
content ,	3
the de	1
standard scoring	1
> the	1
of pruning	1
fully inflected	1
by charniak	1
may be	3
experiments reported	1
was designed	1
a straightforward	1
ldc ,	1
a limited	2
phrasal translations	1
utilizes a	1
statistical-based mt	1
build a	1
such components	1
treebank15 .	1
so instead	1
centroid-based summarization	1
the decoding	2
from higher	2
t3 0	1
evaluate neuralign	1
to apply	3
our second	1
include a	1
within a	2
length of	1
harvested ,	2
% 88.6	1
published inspired	2
5 bilexical	1
% 88.0	1
a better	2
between training	2
max s	1
called grow-diag-final	1
can play	1
loglinear combination	1
graehl for	1
on its	2
= attachment	1
the alignments	1
work using	1
projective and	2
following treebanks	1
to pharaoh’s	1
jing was	1
publicly available	2
words ,	6
words .	4
words )	2
across phrasal	1
answers using	1
english as	1
graphical structure	1
bleu .	1
signatures and	2
we designed	1
more advanced	1
% were	1
as k	1
for determining	2
parts did	1
drs language	1
and language	2
on sentence-level	1
same test	3
originally used	1
in moldovan	1
from treebank	2
mcdonald et	5
max ,	1
to eisner	1
chose the	1
from different	1
interrogatives with	1
ie we	1
% represents	1
, many-to-many	1
single-document case	1
year >	1
on those	1
that stage	1
for searching	2
and high-level	1
q &	1
entailment has	1
applied for	2
bikel et	1
despite stringent	1
projf =	1
λs are	1
modeled .	1
in pos	1
help a	1
recent syntax-based	1
no sentiments	1
sentence ‘subjectivity’	1
word counts	1
of how	2
and future	1
smt via	1
, pp	1
training approach	1
non-discriminative setting	1
measures which	1
web as	1
motivated ,	1
and 2005	1
sophisticated and	1
length limit	1
= argmaxe	1
be introduced	1
each pattern	1
of part-of-speech	1
number 4	1
various applications	1
degree of	1
nist evaluations	1
and knight	4
post-processing .	1
and tree	1
needed in	2
dan bikel	2
many other	2
hypotheses that	1
mainstream approaches	1
recent approach	1
this section	5
dominates is	1
symbol ,	1
class of	1
achieve results	1
finding the	1
user 's	1
and pedersen	1
advantage of	2
few years	1
differing complexities	1
mention german	1
type queries	1
och ,	2
acquisition were	1
templates in	1
first step	1
and y	2
answer sentences	1
automatic evaluation	1
unaligned node	1
fr )	1
and p	3
quickly and	1
and j	1
neither mira	1
and h	2
to lie	1
feasible ,	1
a pre-existing	1
phrasal statistical	1
not affected	1
and a	16
compositional bi-phrase	1
questions it	1
by and	2
binary from	1
syntactic knowledge	1
metusabancı treebank15	1
algorithms for	4
framework ,	1
they can	2
” $	1
's inside�	1
and 8	1
and 7	1
and 3	1
ir against	1
and 1	1
¯ak −	1
goal-verb only	1
and ,	12
dependency links	2
usually addressed	1
which conforms	1
bayes point	1
the text	3
unsupervised method	2
a person	1
, chiang	1
recent research	2
heads correctly	1
ei2i1 and	1
end position	1
has emerged	1
is closely	1
pcfg parser	1
learning entailment	1
show that	2
has not	1
2000 ;	1
successfully employed	1
reading the	1
on derivations	1
following components	1
heuristic filtering	1
phrases with	2
usually been	1
translation accuracy	3
the target	4
emerging area	1
to include	2
to determine	5
this algorithm	2
decodings are	1
subjective or	1
some limits	1
the query	1
phrases without	2
the pseudoprojective	1
word alignment	4
, popular	1
to compensate	1
most existing	1
supervised parsing	2
many dependency-based	1
to define	2
terms that	1
mira nor	1
sequence translation	1
labelled precision	1
inference .	1
any hypothesis	1
connectivity of	1
nlp/speech community	1
function hcomp	1
difficult ,	2
to that	3
a19a86a92a93a21 is	1
in their	1
chinese strings	1
a feature	1
and mihalcea	1
answers ,	1
different word-order	2
answers .	1
family relations	1
to capture	3
keller and	1
when we	1
of naturally	1
be discussed	1
hovy described	1
a target	3
sense .	1
findings of	1
achieved results	1
easier to	2
items with	1
to dependency	2
, bottom-up	1
inflected word	1
applying statistical	1
a31a32a4a33a2a142a20a68a17 which	1
very good	2
acquire state-of-the-art	2
first a	1
final numbers.2	1
extended the	1
the lfgbased	1
according to	6
document )	1
train a77	1
modifier word	1
target sense	1
very consistent	1
looser notion	1
previous best	1
we incorporate	1
include two	1
target-language models	1
representation module	1
baseline accuracy	1
section 2.	1
bracerightbig if	1
benefited from	1
proved useful	1
decoder provided	1
pλ ∝	1
their use	1
, keller	1
first ,	6
sentence level	3
consideration of	1
, weighted	1
acquisition appears	1
system that	5
converting dependency	1
collins in	1
, locations	1
utilizes manually	1
four morphemes	1
methods are	1
details are	1
comparative analysis	1
feature vector	1
for surveys	1
structures from	1
signatures in	1
dependencies model	2
machine learning	1
shown through	1
would have	1
algorithms whose	1
, discriminative	1
modifiers ,	1
extraction of	3
corpus are	1
in bikel	1
proposes an	1
in which	6
the performance	7
95 %	1
lexical based	2
a list	2
an unsmoothed	1
propose to	2
of terminals	1
thames” :	1
into grammatical	1
handle non-contiguous	1
from a	6
answering opinion	1
document ,	1
, marcu	2
as pharaoh	1
a vertex	1
dave et	1
treebank data	4
to contiguous	1
phrase models	2
, except	1
translation table	2
a simple	5
o exact	1
from relative	1
by minimum	1
designed for	1
at ensuring	1
2.4 the	1
underlying word	1
partitioned into	1
while hall	1
the transitive	1
representations .	3
been observed	1
mckeown use	1
as well	9
it trained	1
, identify	1
expensive and	1
length to	1
those produced	1
from .	1
; 2.	1
edge transformations	1
translations produced	1
closely resembles	1
ranked sentences	1
of hiero	1
model which	4
; svm-lighttk	1
from 1	1
etzioni et	1
a cross-document	1
were translated	1
child annotated	1
coordinated phrases	1
experiments using	1
hypothesis along	1
: does	1
original sentences	1
novel technique	1
phrase length	2
for multi-document	1
some novel	1
computed similarly	1
a reasonably	1
the synchronous	1
be able	1
radev ,	1
word-based machine	1
microsoft research	1
applied with	1
> after	1
cause the	1
determine how	1
between two	2
modification of	1
standard model	1
a 447	1
over previous	1
product of	2
very often	1
word “is	1
study investigated	1
french-english shared	1
decoder described	1
dagan that	1
generates synchronous	1
reuse the	1
addressed revision	1
an important	1
algorithm ,	3
algorithm .	4
pos p	1
a32 a34a35a4	1
we ran	1
a constituency-based	1
; hard-wiring	1
proposed forcapturing	1
recently shown	1
by deleting	1
not combine	1
represent generatively	1
where discontinuous	1
context ,	1
context .	1
algorithm 3	1
sentence-level and	1
most successful	1
with lhs	2
1 ...	1
that choosing	1
including a	1
labels in	1
pp-attachment resolution	1
of questions	2
are :	1
german-english europarl	1
representation our	1
candidate ,	1
algorithm based	1
advances in	2
use this	1
structures makes	1
successfully replicated	1
mira performs	1
adding an	1
structures are	2
using english	1
are a	1
corley and	1
are first	1
also true	1
collins developed	2
headwords ,	2
rela26many thanks	1
the methods	1
89.5 89.6	1
where or	1
given stage	1
but ourmethodis	1
reasoning for	1
relationships from	1
accuracies of	1
future ,	2
is maltparser	1
of manual	1
with pharaoh	2
see for	3
metrics for	1
here was	2
typically using	1
of 96.9	1
at that	1
much faster	2
this model	1
links by	1
relations involing	1
feature functions	2
syntactic theory	1
target event	1
the derivationally	1
cant improvement	1
aer .	1
a2 a33	1
and f-to-e	1
begin by	1
a2 a30	1
exceptions being	1
ibm alignment	2
proposed where	2
input question	1
for parameter	1
remove a	1
, lifting	1
unlabeled representations	2
to encode	1
agreement a	1
major part-of-speech	1
added a	1
we present	5
addresses similar	1
semantics-poor techniques	1
anchor-based learning	2
bankrupt” “bin	1
n-best list	1
discarded .	1
aligned phrase	1
on subject	1
reparsing in	1
and relative	1
context-free grammars	2
parse forest	1
as koehn	1
if not	2
, david	1
distributed .	1
patterns automatically	1
linguistic features	1
in appendix	1
agreement )	1
of bikel	1
47 feature	1
merged into	2
and nonprobabilistic	1
several probability	1
be parsed	1
93.4 %	1
realization that	1
a27 a14a12a91	1
well the	1
high accuracy	1
a27 a14a12a94	1
added .	1
is entailed	1
insight of	1
g true	1
`` takes	2
as by	1
transformation can	1
usage of	2
in except	1
these clue	1
, och	2
the same	14
node 's	2
many years	1
smt .	1
test sentences	1
from this	2
using data	1
news articles	1
successfully for	1
answer to	1
ondatadriven dependency	1
translation have	1
maximises the	1
from cut-and-paste	1
often in	2
proved fairly	1
case of	4
third question	1
while we	1
2 dependency	1
gives a	1
weights as	1
statistical word-to-word	1
a comprehensive	1
be expected	1
the late	1
learner to	2
overall test	1
and english-to-chinese	1
the adaptation	2
model table	1
in recovering	1
, nivre	4
was also	1
, hu	1
decoder is	2
technique ,	1
subject to	1
seminal work	1
from templates	1
actually harmful	1
accuracy significantly	1
weighting like	1
of experiments	1
clauses might	1
al incorporates	1
while other	1
from recent	1
, gates	1
patterns much	1
by mcdonald	1
following opinions	1
different relation	1
trigram language	1
t. we	1
what we	1
this kind	2
on ngram	1
analyzing opinions	1
complete statistical	1
growing the	1
explain the	1
before being	1
phrase structure	2
into existing	1
with such	1
to contain	1
text meaning	1
these retrieved	2
idf rather	1
for automatic	1
a maximalist	2
es-en joint	1
the use	6
were split	1
under the	1
to simplify	1
patterns which	1
by koehn	1
definition for	1
of films	1
traditional word	2
pcfg ,	1
our own	1
a graph	1
in web	1
computational and	1
phrase dependent	1
mckeown have	1
summaries .	3
at any	1
l is	1
fashion or	1
a language	1
techniques ,	6
techniques .	1
space induced	1
customer feedback	1
collins explicitly	1
human evaluation	1
been achieved	1
here is	1
also discuss	1
last decade	1
we add	1
9 :	1
, development	1
framework of	2
achieving 60.4	2
union of	1
way similar	1
summaries receive	1
considers n-gram	1
tags used	1
r=1 λrhr	1
grateful to	1
learned for	1
and functional	1
maximum conditional	1
it difficult	2
the level	1
is subjective	1
uses the	3
morpheme groups	1
thematic areas	1
fleischman et	1
random baseline	1
girju et	1
swedish :	1
a tagger	1
standard method	1
potential opinion-bearing	1
and sometimes	1
data were	2
a2 first	1
jump distance	2
every word	1
parameterize a	1
supervised algorithms	1
czech treebank	1
for that	4
with about	1
part-of-speech tags	2
syntactic/phrasal structure	2
number ofcorrect	1
of using	4
it should	1
either directions	1
that appears	1
m∈ bracerightbig	1
not have	1
just on	1
smoothed phrase	1
no seed	1
the statistics	2
knowledge bases	2
lexico-syntactic patterns	1
are bulgarian	1
the morphological	1
collect bidirectional	1
again with	1
or co-occurrence	1
& conrath	1
manual references	1
probability for	1
cut-and-paste summarization	1
once in	1
, 672	1
now being	1
: here	1
reputation tracking	1
technique— as	1
in summarization	1
processing tasks	1
distribution pr	1
empirical methods	1
factored mira	1
c1 c2	1
proje where	1
done using	1
structure grammar	1
to smooth	1
n-best translations	1
relatively modest	1
e.g ,	1
systems we	1
there has	3
a29 a92a93a21	1
various works	2
in support	1
e.g .	1
use no	1
mira )	1
the deprel	1
europarl corpus	1
quite popular	2
performance was	1
the only	1
by moving	1
work question	1
as syntactic	2
nowadays ,	3
and assigned	1
where paraphrases	2
moving from	1
) where	1
in chinese-english	1
the maximal	1
first part	1
nuggets ,	1
labels to	1
o parsing	2
parser often	1
, a	15
as syntax	1
computed word	1
projective parser	1
standard summaries	1
is supported	1
the named	1
, s	2
, r	1
automatic summarization	1
the customer	1
text types	1
parses ,	1
f is	1
: baseline	1
will probably	1
evidenced in	1
potentially o	1
by evaluating	2
are “phrasebased”	1
results ,	1
phrases into	1
begins with	1
pasting segments	1
: n-best	1
grammar-based system	1
, .	4
, ,	6
and found	2
ones .	2
non-projective and	1
, $	1
function .	1
compared our	5
function ,	1
r ,	1
many attempts	1
research ideas	1
in contrast	5
which phrase	1
exploit the	1
tags from	1
evaluate these	1
, 2	1
, 1	1
concept lists	2
resembles that	1
we show	2
by hearst	1
62.50 %	1
under different	1
generation we	1
annotations in	1
one sentence	1
a suf	1
deal with	3
model phrases	1
different ways	2
state-of-the-art constituency-based	1
a sum	2
3.10 humans	1
distortion penalty	1
pharaoh to	1
extraneous phrase	1
eisner context-free	2
recently tapped	1
were obtained	2
of local	2
used without	1
similar modification	1
by pure	1
turkish by	1
reordering ,	2
models to	2
step in	1
group includes	1
give a	1
give higher	1
of bootstrapping	1
tree substitution	1
of the	21
syntactic analysis	1
are quite	1
too weak	1
lexical entailment	2
detect speci	1
algorithms from	1
level ,	5
, i.e.	2
level .	2
obtained with	3
partitions .	1
who ,	1
for textual	1
j-c similarity	1
framework to	1
parsed in	1
head in	1
system follows	1
comprehension task	1
large corpus	2
al examines	1
subjective portions	1
for converting	1
it back	1
this amounts	1
besides ,	1
: s→	1
argument applies	1
patterns (	1
which makes	1
us to	4
lexical weighting	1
part-of-speech and	1
where ¯sj	1
the jiang-conrath	1
the score	2
modeled on	1
via hierarchical	1
pattern instantiated	1
consistent with	4
supplied with	1
happen to	1
united states’	1
giza++ word	1
decoder extracts	1
how to	1
speech patterns	1
the scoring	1
probability phrasebased	1
information retrieval	3
motivated by	1
for search	1
which use	1
functions for	1
φem slightly	1
1 shows	2
results presented	1
in chineseenglish	1
improvement observed	1
edge based	1
patterns resulted	1
11.0 %	1
between successively	2
alignment models	2
has proved	1
weuseapublicly-available phrase-based	1
detail by	1
as and	1
11* table	1
he restricts	1
with india	1
the sentence	5
multi-stack algorithm	1
combine these	1
a positive	1
extract automatically	1
mihalcea .	1
be combined	1
8.1 effects	1
because the	1
sentence reformulation	1
use complex	1
rerun ravichandran	1
information into	1
goal-noun ,	1
ing over	1
affected by	1
alignment by	1
less .	1
alternative approaches	1
of 1.07	1
extension by	2
structured margin	1
substrings and	1
based phrase	1
knight ,	2
could map	1
those described	4
retrieval .	2
infer the	2
times that	1
later being	1
discusses them	1
signi cant	1
intra-pair similarities	1
degree 2.4	1
a47 a33a49a48	1
growdiag-final )	1
have delivered	1
be most	1
¯sj is	1
the rte	1
derive the	1
, eisner	2
but for	1
is o	1
only minimally	1
non-spanish geography	1
where idf	1
the translation	3
, on	3
improvement from	1
system based	2
morpheme groupings	1
the membership	1
was perhaps	1
including eugene	1
having consistent	1
constellations .	1
tree 696	1
1899 ludwig	1
, or	11
additional features	1
cut-and-paste strategy	2
present an	3
toolkit for	1
is similar	3
of work	4
32 although	1
answer types	1
will have	1
and addressed	1
an incremental	1
threshold on	1
, learn	1
to build	1
and evaluated	1
404 computational	1
constraint also	1
binary-branching synchronous	1
answer points	1
of knowledge	3
there exist	1
from context-free	1
the southern	1
only to	2
a re-implementation	2
hovy ’s	1
see fig	1
be more	1
anchors .	1
various summaries	1
to incorporate	3
informative and	1
coarse measure	1
mt systems	3
and lee	1
parsing techniques	2
can induce	1
the parse	1
processing components	1
, phrase	1
reordering models	1
parser’s output	1
having the	1
a crucial	1
in our	6
the source	6
only fewer	1
patterns to	2
contain disjunctions	1
a180 a10	1
and use	1
each consults	1
and ney	2
engine seeks	1
lhs x	2
features have	2
determine these	1
representative one	1
used topic	1
ziff-davis corpus	1
a proxy	1
different then	1
etc .	4
parameters ,	1
, refer	1
parameters .	1
for more	2
to extend	1
or category	1
acquire hyponymy	1
alignment refinement	1
rule ;	1
of charniak	1
how we	1
first-order logic	1
grammars and	1
pdt ,	1
data-driven methods	1
3 online	1
futures observed	1
should be	3
distance ,	1
grammars several	1
experimentation with	1
that obtains	1
with it	1
captured .	1
expressed using	1
accuracy in	1
text categorization	1
lexical translation	1
conclude that	2
% by	1
as do	1
alignment —henceforth	1
imply reading	1
i and	1
initial lexical	2
lexicalist approaches	1
pseudoprojective approach	1
features extracted	1
scores sentences	1
towards a	2
of it	1
ability to	4
summaries/translations has	1
major impact	1
these atomic	1
to 1this	1
of ie	1
, often	1
on phrasal	1
logical form	2
allows the	1
precedes/follows the	1
4 training	2
works of	1
phrase alignment	2
selection algorithm	1
case is	1
with little	1
sms text	1
of lifted	1
sa4a68a77a75a9a44a122a25a20a68a17a126a101 sa4a68a77a102a9	1
in or	1
to amit	1
into equation	1
, baseline	1
this result	1
also the	2
to data-driven	1
a heuristic	2
children in	2
fair to	1
in on	1
slovene ,	1
modeling the	2
several definitions	1
high-frequency bigrams	1
, attempts	1
17 deterministic	1
the representative	1
results than	1
exceptions are	1
then incorporate	1
out-ward process	1
past decades	1
95.3 %	1
, leaving	1
evaluate summaries	1
as model	1
approach —	1
scfg :	1
and very	2
also notable	1
compares these	1
and entailment	1
our decoder	1
individual errors	1
representations or	1
measure as	2
scfg .	1
o factor	1
heuristically-induced alignments	1
desired ,	1
ppicker� shows	1
can only	1
kindly provided	1
we first	2
bilexical dependencies	1
restricting the	1
to a138	1
we expect	1
recall-based unigram	1
best ,	1
best .	1
in takes	1
smt similar	1
is derived	1
some unaligned	1
model by	3
been a	2
engine .	1
that performed	1
probabilities are	2
at all	4
work has	3
none of	2
n-gram-based evaluation	1
studied in	1
analyze large	1
a holdover	1
lower than	2
rewards passages	1
translations of	1
only syntactic	1
parallel corpora	1
confirms the	1
define dependency	1
translation systems	4
information needed	2
unsupervised methods	1
which accuracies	1
and overall	1
iff ¯ak	1
the shortened	1
by other	1
we evaluate	1
in smt	2
of seed	1
bayesian classification	1
third ,	1
attracted much	1
performs at	1
not notice	1
named entity	4
performs as	1
detecting thematic	1
6this f-measure	1
algorithm to	4
semantic calculus	1
, such	12
summarization has	2
on rule	1
system .	4
system ,	4
relation by	1
recently in	1
dirt and	1
shortening ,	1
1− ˜iproductdisplay	1
system :	2
abstracting and	2
predictors of	1
nilsson introduces	1
revision in	1
equivalent ilp	1
the first	8
correspondence .	1
remain elusive	1
compared an	1
previously such	1
to dutch	1
included if	1
conll-x and	1
resulting phrase	1
analysis .	4
included in	1
our experiment	1
this deficit	2
same task	1
by combining	3
determine projections	1
exact parsing	1
the specific	1
• gi03	1
tables using	1
alignment software	1
reimplementation and	2
tree dependency	1
conditional model	1
constructed parallel	1
similar graphical	1
compression algorithm	1
words between	1
particularly promising	1
head-dependent relation	1
particular component	2
the group	1
node in	1
the standard	2
make them	1
a prototype	1
is likely	1
typically qa	1
are presented	1
entailment .	1
solve the	1
similar method	2
and limitations	1
which simply	1
as follows	2
problem as	1
different data	1
type preference	1
similarly ,	3
portion of	1
mcdonald and	1
report the	1
training tool	1
training problem	1
compare the	5
be exploited	1
x nonterminal	2
likelihood for	1
of charniak’s	1
for applications	1
a29 a0a22a33	1
web .	2
web ,	2
generatively the	1
output is	1
noticing that	1
signatures for	1
evaluation 8.1	1
eisner proposed	1
, by	3
reduce to	1
text summarisation	2
scaled to	1
if neither	1
ratio increases	1
r w	1
learning question-answering	1
have gained	1
suitable real	1
the deterministic	2
czech 6	1
polarities only	1
conversation ,	1
the syntactic	1
opinions and	1
sentences into	1
19 in	1
deficit through	2
distortion decoder	1
strategies and	1
representation theory	1
czech .	3
by restricting	1
czech ,	4
collins et	5
results is	1
our experiments	3
role in	1
p are	1
from text	2
the impact	4
the stem	1
except that	2
they still	2
signal the	1
work by	2
: bikel’s	1
means that	1
many subsequent	2
quite well	1
r =	1
results in	4
, both	2
or shallow	1
building dependency	1
introduce multiple	1
made very	1
level than	1
areas is	1
not occur	1
classifiers for	1
the approach	3
tool ,	1
marginal relevance	1
but simpler	1
to reuse	1
improved version	1
called grow-diagfinal	1
exploiting the	1
extraction )	1
a learning	1
great success	1
and czech	1
measured by	2
show comparable	1
parts-of-speech ,	1
mixed system	1
a series	1
formalization generalizes	1
% 87.9	1
was similar	1
addition of	6
assesses the	1
different models	3
trees a	1
and an	3
the expansion	1
error compared	1
literature precision	1
patterns following	1
1642 1685	1
and at	1
0.28 points	1
head child�	1
well despite	1
europarl corpora	1
different inflected	1
almost impossible	1
represents a	1
unsmoothed phrase-table	1
discontinuous phrase	1
with generative	1
; the	5
4. schematic	2
implementation )	1
with two	2
whether probabilistically	2
hatzivassiloglou compared	1
treebank13 ;	1
trees ,	5
a hypothesis	2
trees .	6
assigned polarities	1
followed .	1
learns rules	1
and a0	1
of hyponym	1
easy exchange	1
for multi-sentence	1
pereira describe	1
with discriminative	1
been tested	2
algorithms and	2
two types	2
, used	1
to calculate	1
the freely	2
transformations proposed	1
reliability measures	1
similar set	1
extraction .	2
where only	1
on corpus	1
functions quite	1
we call	1
we <	1
given subjective	1
concepts in	1
, named	3
parser with	3
the analysis	3
requires no	1
are pairs	2
heuristic .	1
for supervised	2
evaluated our	1
the observation	1
distance instead	2
approaches by	1
together with	1
, mcdonald	2
introduce a	1
is penalized	2
type questions	1
alternatively ,	1
accuracy can	1
both bleu	1
automatically from	2
governor by	1
: first	1
at performing	1
scores .	2
presented by	3
editing in	1
linguistic expertise	1
query formulation	1
prompted researchers	2
the traditional	3
the semantic	1
using simple	1
2. pr04	1
in general	3
particular ,	6
lexicalization rules	1
accuracy with	3
do not	6
models involve	1
“water always	1
are statistical	1
reordering feature	1
paths problem	1
parsing ,	8
the clause	1
translation models	3
on learning	3
following fleischman	1
n-best ranking	1
projective approximation	1
dependency tree	2
parsing :	1
nilsson ,3	1
the random	1
, rote	1
nlp systems	2
who also	1
that data	1
to parsing	1
training error	1
91 %	1
, if	2
lexicons ,	2
pedersen described	1
hovy patterns	1
instantiated with	1
we showed	1
, is	5
by ,	1
context and	2
, it	4
symmetrical ,	1
strength of	1
czech results	1
to phrase	1
explored a	1
using ibm	1
linking terms	1
with another	1
the runtime	1
hiero smt	1
that translation	1
the test-set	1
nominals .	1
giza++ is	1
added three	1
study are	1
ranks translations	1
they appear	1
on nlp	1
supervised nature	1
can not	3
inclusion of	1
very important	2
volume 28	1
of any	1
over their	1
whom considered	2
grammar parser	1
patterns instantiated	1
geffet and	1
is one	3
rules must	1
of modeling	1
by recent	1
larger-scale and	1
continuing with	1
of and	2
and add	1
history-based models	1
resulting in	1
the europarl	1
these results	1
we added	2
takes the	1
requiring constituents	1
the united	1
context-free grammar	1
show how	1
of strings	1
the item	1
summarisation ,	1
summarisation .	1
anchor words	1
5.3 related	1
training begins	1
yet ,	1
a why	1
a29 a97a100a21	1
problematic .	1
the literature	5
a tree	2
specific to	1
giza++ in	1
br¨oker ,	1
ef ciently	1
most recently	2
strings by	1
a0 into	1
the observations	1
hovy learns	1
bach isaac	1
extrinsic ,	1
fully automated	1
who exploited	1
parser of	6
are very	2
who implement	1
in quarc	1
corpus that	1
by using	4
n-gram key	1
among these	1
judgments shows	1
matches with	1
many stochastic	1
the quality	4
pairs of	4
is visualized	1
first-class words	1
to yamada	1
dependency-based models	1
passages that	2
pairs extracted	1
standard phrase-based	3
baseline compression	1
braceleftbig ep	1
that sj	1
's web	3
manually compiled	1
observations in	1
linear-time parsing	1
hardware environments	2
their supervised	1
by shortening	1
, finally	1
inventor ,	1
recovering labeled	1
best-first classifier-based	1
the mira	1
haruno et	1
kbest parsing	1
overall frequencies	1
, three	1
wiebe et	1
very different	2
somewhat related	1
is desired	1
compression in	1
in is	1
an improvement	1
is largely	1
time in	1
these features	2
bigrams from	1
of which	2
by projectivizing	1
these approaches	1
hyponym relations	1
objects 94	1
to be	13
various implementations	2
and <	1
top-down model	1
's phrase	1
approximation to	1
provided —	1
writing and	1
have free	1
22.06 3.21	1
of evaluation	1
a 37	1
for tasks	1
word has	1
the usage	2
point machines	1
search the	1
are translations	1
91.3 90.6	1
evaluate children’s	1
ontologies ,	1
bilingual parallel	1
significantly improves	1
most easily	1
to which	2
how this	1
achieves 61.2	2
used measures	1
quality phrase	2
a parse	1
many researchers	2
for summarization	2
in large	2
probabilities ,	1
language parser	1
's system	1
solving the	1
following phrases	1
citation observed	1
probabilities ;	1
parsing .	5
van beethoven	1
tackle the	1
glass-box smoothing	2
of topic	1
k-best trees	1
by applying	2
context from	2
ravichandran and	1
comparison was	1
reordering rule	2
into the	4
surface pattern	1
50 definition	1
( approx	1
hltnaacl workshop	1
targets for	1
these algorithms	1
multitext grammars	1
carry out	2
collins parser	2
a77 we	1
lavie 86.0	1
the complete	1
seems to	2
contiguous word	1
phrases used	1
arc label	1
reduction module	1
dps ,	1
far research	1
criterion can	1
tried to	2
group of	1
outset ,	1
description the	1
projections of	1
set is	1
system which	1
set in	1
of hypotheses	1
both generative	2
feature types	2
as using	1
attention as	1
the introduction	4
template systems	1
the equation	1
al to	2
a theorem	1
as there	1
given for	1
fact that	3
quite differently	1
the need	2
, in	9
two nonterminal	1
initial aligners.1	1
translation quality	3
of treelets	1
parsing requires	1
language have	1
entailed by	1
newspaper precision	1
aligned with	1
based machine	1
review the	1
different combined	1
syntax ,	1
a9 a72	1
combined alignment	1
shows that	2
predict those	1
recognizer to	1
first to	1
between the	2
currently demonstrates	1
different measures	1
another consequence	1
template system	1
kim and	1
the resources	1
on arabic	1
by increasingly	1
their results	1
focused either	1
gerunds .	1
extract the	2
isa hierarchies	1
in english	3
estimates with	1
: english	2
constituent lexicalization	2
parsing using	1
parsers for	1
for examples	1
in classifier-based	1
the phrase-based	2
and galley	1
and hatzivassiloglou	1
combined .	1
c4 c5	1
system trained	1
and data	1
very likely	1
extractions of	1
crossing brackets	1
co-developed several	1
a0 a33	1
`` happen	1
mutual bootstrapping	1
kernel of	1
the grammar-based	1
better parsing	1
machines .	1
of determinization	1
identify themes	1
systems have	4
is important	1
identify these	1
analysis technique	1
a sequence	1
but no	2
retrieval and	1
thus far	1
; therefore	1
like ,	1
a3a5a4a35a29 a0	1
simple surface	1
decade ,	2
corpora for	1
projectivity constraint	1
success .	1
recovering non-projective	1
set the	1
identified semantic	1
whichincorporates null	1
renewed attention	1
source phrase	1
a clause	1
about twice	1
instead of	6
an approximation	1
results of	3
using some	1
from which	1
results on	5
t1” is	1
hence the	1
toni mart´ı	1
: talbanken0514	1
pure word-based	1
produce a	1
binarization for	1
syntax-based system	1
we thus	1
a freely	2
a proof	2
increases efficiency	1
clustering and	1
are combined	1
following example	1
types are	1
synchronous tree	1
distance kernel	1
minimal set	1
ranking of	1
a complete	3
topic representation	1
best projective	1
88.3 88.1	1
processing beyond	1
in quality	1
we note	1
holdover from	1
also part	1
hiero system	1
, before	1
is equal	1
, tillmann	1
tats may	1
with koehn	1
lexical and	1
been attempts	1
extracted following	1
or sentence	1
exp ;	1
ngram statistics	1
one reason	2
nonetheless ,	1
exp ,	1
johnson 91.3	1
co-occurrence patterns	1
given phrase	1
ures patterns	1
approaches in	1
important and	2
parse trees	5
the proj	1
or otherwise	1
was competitive	1
be highly	1
constructed from	1
as of	1
two texts	1
run on	1
3 model	1
alignments are	2
metric is	1
available system	1
h by	1
: /	1
: .	1
children ;	1
representation of	4
of rote	1
to obtain	4
polarity based	1
tags .	1
it necessary	1
cooccurrence automatic	1
is about	1
kproductdisplay k=1	1
with phrase	1
view this	1
their relative	1
deterministic dependency	2
closely related	3
and the	15
and dagan	1
test to	1
or rules	1
hidden markov	2
tasks ,	2
our future	1
vector machines	1
axioms�as in	1
semantic axioms	2
with sections	1
accuracy for	3
: o	1
: a	2
into phrase-based	2
strategy that	1
: p	1
side� contents	1
extract candidate	1
to tackle	1
that takes	1
; or	1
bulgarian ,	2
evaluating sentence	1
phrase pair	2
span .	1
for japanese	1
“the gap	1
existing phrase-based	1
unlike the	2
by growing	1
detailed and	1
rules .	3
in 32	1
rules ,	3
based decoder	1
the categories	2
a bottom-up	1
allowing us	1
a bilingual	1
templates .	1
independently of	4
alignment is	3
part-of-speech tag	1
depending on	1
substrings obtained	1
a mixed	1
evaluation on	1
of yamada	2
programming ,	1
all pairs	1
decoding speed	1
the deficient	1
the 17	1
, where	12
and liu	1
into account	4
1.07 ,	1
these confidence	1
been addressed	1
modeling 3	1
the pseudo-projective	1
, 450	1
widl-expressions from	1
extraction ,	2
of heuristic	1
paper ,	3
in mcdonald	1
alignment if	1
proposed automatically	1
world is	1
measure similarity	1
as governor	1
on building	1
constructor .	1
no hidden	1
shortening that	1
no such	1
sebastian bach	1
followed the	1
on extraction	1
model referred	1
to “flatten”	1
known that	2
report results	1
initial empty	1
approach for	4
in chiang	1
was limited	1
with maximal	1
tree transducers	1
och and	2
other researches	1
were originally	1
of all	2
takes over	1
types of	2
of methods	3
( see	1
arbitrary binary	1
= 1−p	1
approx .	1
reported by	3
line subtree	1
term is	1
remedy this	2
word aligning	1
humans 20.07	1
model the	4
chiang reports	1
9 components	1
searching textual	2
o and	2
a0a22a33 a6	1
ryan mcdonald	1
the formulation	1
this makes	1
conll-x shared	1
state-of-the-art parsing	1
following discussion	1
algorithms exploit	1
recognition has	1
those words	1
fine-grained comparative	1
seen as	1
different than	1
compared several	1
where a38	1
their reduced	1
exist important	1
include counts	1
are linked	1
the previous	4
taking into	1
a description	1
analogous techniques	1
have exploited	1
comparison purposes	1
is also	9
entailment prototype	2
an extension	2
then transformed	1
machine learner	1
the document	1
our 1.63	1
combined alignments	1
the hierarchical	2
anchors for	1
is projective	1
contain claims	1
words are	1
used by	7
art in	1
of meaning	1
parser is	2
output unique	1
parser in	1
summarization .	1
from ibm	2
summarization ,	3
art is	2
of mt	1
within their	1
semantic preferences	1
the hash-table	1
which uses	1
x is	1
the answer	2
r↑h ,	1
and product	1
decoding process	1
word-based alignments	1
shown useful	1
from very	2
of anchors	1
this idea	1
out of	1
the co-occurrence	1
summarization systems	2
on n-gram	1
trees are	1
not capture	1
concerning the	1
and computes	1
those introduced	1
outperform word-to-word	1
consistency for	1
all—a deficiency	1
need to	1
employed to	1
and manual	1
pruning methods	1
the precision	3
observation consistent	1
either the	1
concerns to	1
editorials and	1
useful in	3
intervening material	2
used rouge-1	1
parser reaches	1
web to	2
pruning techniques	1
is not	7
find other	1
we selected	1
stem is	1
to collect	1
by 2.64	1
and fleischman	1
an example	3
simw×idf summationdisplay	1
research project	1
web in	1
two parse	1
precision on	2
hovy evaluated	1
neglected ,	1
precision of	2
identify surface	1
alignments in	2
its prior	1
including single	1
use statistical	1
summaries created	1
arbitrary non-projective	1
a20a97a9a44a122a140a20a100a17a103a118 sa4a68a77a75a9a44a122a25a20a68a17a126a101	1
some elements	1
is” in	1
the experimental	1
much lowerorder	1
of acquiring	1
given that	1
polarity judgments	1
reordering in	1
sentences our	1
human counterpart	1
not simple	1
and polarity	1
although it	3
prec .	1
for who-is	1
generation is	1
or positive/negative	1
chu-liu-edmonds decoder	1
exponential in	1
efforts to	1
extraction to	1
to evaluate	4
aswellassequencesofwordsthatcontaingaps .	1
and evaluation	1
a distortion	1
to maximise	1
focused only	1
that such	1
web by	1
with sri	1
on simple	1
just be	1
an integral	1
generalise a	1
done in	4
extracted as	1
both of	1
the next	2
85.1 <	1
non-projective training	1
answer based	1
several statistical	1
replace mbl	1
and wong	2
> 1642	1
to overcome	3
in combination	1
, graph	1
is somewhat	1
simpler distortion	1
pairs with	3
the nonprojective	1
multiple edges	1
various techniques	2
admittedly ,	1
subsequently ,	1
constituencies and	1
lr model	1
work that	1
a method	5
not found	1
96.0 %	1
won5even when	1
hiero decoder	1
more likely	1
's domain	1
for comparing	1
: extract	1
and pasting	1
rules of	1
to ,	3
removes the	1
promising results	1
the uni-gram	1
in svm-light	1
examples are	1
and semantic	1
a version	2
al experiments	1
to 5	1
best tree	1
to 3	1
czech would	1
common substring	1
used part	1
problem ,	1
problem .	2
: definition	2
word w	1
a noisy-or�	1
using edge	1
) charac	1
is passed	1
which indicate	1
summaries recall	1
phrase-based mt	3
the dag-like	1
to 100	1
hierarchical phrases	1
to a	14
joint counts	1
, tats	1
module designed	1
to p	1
per sentence	1
in all	2
german negra	1
a cut-and-paste	2
models 1	1
similar fashion	1
candidates .	2
a general-purpose	1
of real-world	1
by corley	1
of 50	2
models .	6
but their	1
models ,	7
other phrase	1
models of	1
python 2.4	1
probability of	2
eisner’s algorithm	1
are employed	1
perform better	1
studies such	1
mentioned in	1
stochastic treatment	1
and extracted	1
workshop .	1
combining a	1
“i believe	1
of stories	1
postprocessing should	1
processing researchers	1
minipar dependency	1
bootstrapping approaches	1
trained aquarea	1
discriminative classifiers	1
to for	1
both yamada	1
these parsers	1
attempts on	1
, sentence	1
question tends	1
complexities have	1
of each	4
technologies ,	1
expected ,	1
exactly what	1
provided by	1
to explore	2
made to	2
at a	3
the algorithm	3
very sensitive	1
precisely one	1
we found	2
newspaper 95.3	1
map a	1
a text	3
smt statistical	2
adding longer	1
as ir-based	1
adopted a	1
, “refers	1
summarization in	2
a single	2
quabs automatically	1
for k-best	1
smt systems	3
the extent	1
perceptron 82.9	1
tools for	1
bilingual word	1
for testing	1
particular topic	1
training corpus	2
score function	1
extract part-of-speech	1
were proposed	2
sms language	1
50 our	1
based on	17
simple subordinate	1
a. smith	1
, adverbs	1
to our	2
is difficult	1
non-projective arcs	1
head-lexicalized stochastic	1
describe the	2
tsa in	1
solely on	3
of terms	1
over for	1
process without	1
their translations	1
moldovan et	1
next ,	1
whether to	1
successively translated	2
concentrates just	1
the name/instance	1
chiang has	1
exemplified by	1
wordnet and	1
although these	1
eisner algorithm	2
grammars in	1
accuracy achieved	1
template translation	1
a relationship-based	1
because it	1
ours .	1
fujio and	1
the hypergraph	1
the intersection	2
pruning technique	1
not provide	1
use two	1
a logical	2
pairs from	2
of collins’	1
the identities	2
construct summaries	1
either focuses	1
numbers.2 4	1
identify phrases	1
the ibm	2
parser to	4
same data	2
the outset	1
interpretations .	1
and flat	1
mcdonald 's	1
highest probability	1
researchers .	1
formulation follows	1
89 %	1
favorably compared	1
forms in	1
the river	1
to know	1
starting point	1
such systems	2
a technique	1
a score	3
this field	1
training sentence	2
, needs	1
sentences until	1
for both	4
text of	1
an extremely	1
more attractive	1
are induced	1
semantic parsing	1
by out	1
were those	1
flat reordering	1
projective english	1
add the	1
incremental ilp	1
be very	1
patterns for	1
parsing increases	1
categories in	1
fairly reliable	1
employ some	1
hearst was	1
traditional intra-pair	1
other potential	1
features rely	1
given language	1
czech are	1
proje =	1
topic or	1
phrasal smt	1
p major	1
p •	1
larger training	1
non-projective nature	1
the input	4
relevance reranker	1
mckeown .	1
topic of	1
in recent	5
clue words	1
graphs are	3
, two-level	2
is potentially	1
, semantic	1
. 2.2.2	1
grammar has	1
to measure	1
of constituents	2
conjunctions and	1
a data-source	1
pattern matcher	1
improves the	1
hovy 58	1
be handled	1
parsing can	1
impressive speed	2
tokens at	1
by first	1
limits based	1
studies on	2
transform non-projective	1
believe the	1
use their	1
pang and	1
between presenting	1
labeled and	3
recently applied	1
difference between	2
supervised algorithm	1
planning to	1
which constituents	1
which maximize	1
two approaches	1
assume a	1
list to	1
and improved	1
matsumoto .	1
matsumoto ,	5
transformed into	1
has so	1
been especially	1
ne-supported q	1
rule generation	1
this extension	1
as could	1
knowledge sources	1
a community-wide	1
describes this	1
s l	1
suffix tree	1
take reading	1
s a	1
ebmt system	1
are created	1
the ne	1
patterns using	1
s x	1
statistical natural	2
future work	2
best performing	1
between instances	1
proposed system	1
s s	1
features for	2
to produce	4
the so-called	2
88.1 87.8	1
modifications with	1
ravichandran described	1
, 23	1
than that	1
projective tree	1
grammars model	1
and discusses	1
another recent	1
the 2003	1
in particular	6
the 2004	1
what dependency	1
the alignment	3
applied to	7
s .	1
possible ones	1
implements the	1
text segments	1
s =	2
many errors	1
word link	1
conjunctions .	1
phrase .	2
the error	1
on standard	1
on post-processing	1
is utilized	1
parsers have	1
parse .	1
, vpp-vp	1
parse ,	1
complexity ,	1
4 show	1
to large	1
the busiest	1
tracks at	1
of dynamic	1
edited version	1
that we	5
picture of	1
employed for	1
was done	4
from that	1
years .	1
runtime information	1
linguistic generalizations	1
two gaps	1
classification ,	2
classification .	1
able to	1
models rely	1
al which	2
is generally	2
extract phrases	1
the pair	1
however the	1
the collins/bikel	1
are reported	3
precision a	1
children’s reading	1
the trec2003	1
block sequence	1
and more	4
systems by	2
scores whether	1
series of	1
parser on	1
to aggregate	1
is best	1
concept-instance pairs	1
strength ,	1
in in	1
al 80.0	1
strictly comparable	1
answers at	1
figure 8	2
the seminal	1
best to	1
contiguous spans	1
scores with	1
entailment but	1
given in	1
figure 2	4
all past	1
in eq	1
of koehn	2
figure 7	2
for subjectivity	1
syntactically motivated	1
precision ,	1
binarization system	1
projective graphs	1
a large	6
some of	4
of topic-relevant	1
note that	3
binary features	1
procedure are	1
collins 's	2
, agichtein	1
, global	1
al )	2
al .	9
al ,	10
we therefore	2
search engines	1
with ibm	1
accumulated by	1
al ;	2
al :	3
study reported	1
final results	1
, ratnaparkhi’s	1
precision in	1
the interpretation	1
are searched	2
full document	1
and unlabeled	2
disambiguation ,	2
key concepts	1
quality metric	1
maximal context	1
could benefit	1
1 iff	1
syntactic constraints	1
as our	2
dictionary to	1
concepts and	1
2 or	1
english has	1
inverse document	1
originally introduced	1
maximize bleu	1
surface patterns	2
between sentences	1
87.9 17	1
mt decoder	1
additional linguistic	1
have presented	2
their sentiment	1
hovy for	1
6 and	1
phrase-based model	2
system might	1
the high	1
— the	1
for dependency	3
english-to-chinese alignments	1
grandparent nodes	2
model summaries	1
childcount c	1
, family	1
online learner	1
a33a49a48 a32	1
our results	1
question concerning	1
and short	1
the p	1
investigate the	2
on scaling	1
development in	1
reasonably simple	1
both in	1
received considerable	1
extractor from	1
be used	6
fusion ,	1
formulation of	1
simplify part-of-speech	1
seen phrasal	1
number and	1
to different	2
in inversion-transduction	1
complex if	1
, jing	2
, naive	1
they induce	1
by reordering	1
identified within	1
the proportion	3
source-to-target alignment	1
cfg-based log-linear	1
produced with	1
bulk of	1
and implementation	1
for identifying	2
the <	1
gap is	1
value for	2
or weakly	1
while growdiag-final�	1
not improve	1
extractor in	1
accepted that	1
that use	3
discovering lexico-semantic	1
based translation	1
several researchers	1
benton foundation	1
on test	1
be modified	1
provide information	1
4 models	1
correlate strongly	1
, alignment	1
successfully in	2
corpus data	2
pr where	1
best systems	1
considerable advances	2
pakistan” “water	1
dectors :	1
using bayes	1
statistics decide	2
mean attachment	2
to test	1
at either	1
[ dipl	1
as was	1
machine 84.0	1
compression were	1
86.1 86.0	1
classes when	2
or more	2
and pharaoh	1
the pruning	3
univ-avignon ,	1
90.7 145*	1
input to	1
be potential	1
evaluation ,	3
highly successful	1
expected to	1
studied )	1
deficiency in	1
will usually	1
problem of	3
our two-step	1
and are	4
well with	1
with higher	1
computational work	1
more flexible	1
of 1,755	1
are those	2
in and	4
in any	1
experiment was	1
or for	2
: shallow	1
annotation problems	1
, either	1
many state-of-the-art	1
then formed	1
spirit to	1
no task-specific	2
, pharaoh	2
some resemblance	1
uas ,	1
later models	2
or templates	1
86.3 86.9	1
for improving	1
strategy as	2
substantially lower	2
approaches use	1
the importance	2
tagging or	1
an increase	1
baseline for	1
improving performance	1
also shown	3
the romanian-english	1
subjectivity annotation	1
dependency parser	7
default parameters	1
p ,	1
one step	1
theme of	1
wsj treebank	2
child� in	1
treating it	1
reported in	10
in efforts	1
make crucial	1
which corresponds	1
the thirties3	1
review of	1
follow and	2
combination approach	1
work ,	4
“refers to”	1
introducing a	1
decide whether	2
handled by	1
on projectivized�	1
22,500 sentences	1
6more precisely	1
are completely	1
then considered	2
work :	1
672 ,	1
the evaluation	4
probable analysis	1
seen a	1
scoring sentences	1
the second	2
the most	4
little success	1
as giza++	1
general ,	1
, spanish	3
performance comparable	1
being linguistically	1
the one	2
uniform probability	1
page to	1
general ;	1
the reading	1
ph ,	1
we propose	1
show an	1
unique strings	1
3 for	1
numerator of	1
y table	1
concise sentences	2
arcs using	1
significantly by	1
a parallel	1
many constraints	1
easily automated	1
reranker and	1
occurrence contexts	1
punctuation handling	1
grammars of	1
mckeown also	1
lexical items	1
on smaller	1
be treated	1
been presented	1
upon a	1
are considered	1
are typically	1
same margin	1
the insight	1
mbl models	1
of chinese-to-english	1
performance to	1
probability that	1
different ideal	1
longer phrases	1
in discourse	1
avg trans	1
and scholz	4
ones described	1
defined ,	1
any particular	1
believe its	1
a sentence-extraction	1
available toolkit	1
of heuristics	1
corpus ravichandran	1
multidocument summarization	1
syntax-based smt	1
projective trees	4
the idf	1
alignment ˆam1	1
generating posthead	1
one cell	1
and continuing	1
of dps	1
) have	1
pp-vp vpp-vp	1
like yu	1
language processing	8
or shorter	1
text as	1
proposes a	1
are symmetrical	1
did it	1
wildcard *	1
unless otherwise	1
categories ,	1
automatic sentence	1
dependency converter	1
and constant-time	1
define as	1
than times	1
pharaoh’s default	1
method was	2
//www.cs.ualberta.ca/ lindek/minipar.htm	1
apply post-processing	1
a phrase-pair	1
a certain	2
set ,	3
template matching	1
set .	4
this point	1
> web	1
have presupposed	1
appear more	1
using online	1
score each	1
deletion of	1
constituency-based parsing	1
determining whether	1
hatzivassiloglou extend	1
of word-to-word	1
translation resources	1
such groups	1
that dependency	2
each nonterminal	2
topic is	1
it contain	1
has been	12
pr =	1
four times	2
subjective words	1
, have	3
times ,	1
seeks ˆe	1
turkish :	1
2 general	1
pr ,	1
this inverse	1
extremely challenging	1
data hidden	1
bracerightbig proje	1
to prove	1
one noun	1
o decoder	1
hypothesis .	1
discriminative parsing	2
rules treat	1
model explicitly	1
parser has	2
tokens or	1
shortcomings by	1
trans length	1
capture the	1
most closely	1
languages like	1
projectivity is	1
text from	1
short sentences	2
the lexicalized	1
alignment ,	3
each language	1
normal english	1
lexical-weighting features	1
described in	15
make exact	1
which gives	1
performed in	1
of different	2
consecutive words	1
we re-implemented	1
paraphrases is	1
dramatic improvement	1
of jing	2
evolved into	1
hypothesis h	1
and contrast	1
, kim	1
link .	2
novel block	1
: summary	1
present in	1
many thanks	1
impact of	4
stories as	1
extracting frequently	1
dependency relationships	1
impact on	2
has received	1
governor–raising technique	1
detailed analysis	1
workshop on	1
hiero by	1
we want	1
including chunking	1
observe an	1
upon .	1
commas or	1
text patterns	1
shows similar	1
probability models	1
a very	2
source corpus	1
relative frequencies	1
an accuracy	1
measure used	2
arabic using	1
from word-aligned	2
necessitating question	1
on analyzing	1
the limitation	1
finite-state phrase-based	1
are equivalent	1
does the	1
challenging task	1
led to	3
glue rule	2
has usually	1
on context-free	1
research into	1
discovering the	1
left-handside-conditioned ,	1
chiang’s cky-based	1
is specific	1
functional words	1
synonyms of	1
language pairs	2
metrics the	1
we applied	1
people ,	1
or objective�	1
similar phrase-based	1
grammaticality of	1
on qa	1
denoted as	1
by for	1
paraphrases ,	2
. distributional	1
be adequate	1
approaches have	5
translation problem	1
linear interpolation	1
groups of	1
avoided ,	1
use the	9
effectively doing	1
this type	1
captured using	1
a34a35a4 a29	1
that is	8
defined in	1
our discriminative	2
eisner introduced	1
methods that	4
manually generated	2
examines briefly	1
88.6 31.3	1
considerable attention	1
words and	4
previous section	1
variations of	1
some question	1
learned from	3
known alignment	1
in fig	1
not :	1
score per	2
a54 -th	1
retain only	1
per word	2
not .	2
not ,	3
> we	1
sentence based	1
state-of-the-art systems	1
to do	2
reinventing a	1
the phenomenon	1
c ie	1
which a	1
apply generative	1
these implications	1
penalty to	1
, concentrated	1
; however	1
sdt people	1
of “grow-diagfinal”	1
unit is	2
collins 88.3	1
conditioned on	1
rely on	7
, model	1
results comparing	1
a fixed	1
grammar .	1
at both	1
the maximum	4
loss of	1
classification task	1
argmax h∈hf	1
wu and	1
not a	1
method show	1
trained her	1
alignment combination	1
; 1	1
enforce a	1
backed-off statistics	1
this ''	1
by natural	1
derives projective	1
penalizes non-monotonic	1
all measures	1
employ a	1
built using	1
analyzed a	1
scores and	1
aquarea $	1
moreover ,	3
relative utility	1
have f	1
at all—a	1
alignment strategy	1
have a	5
all with	2
presenting the	1
testing .	2
nist 2003	1
as better	1
be estimated	1
subjectivity classification	1
dependency graphs	3
of words	9
a first-order	1
answer sentence	1
final-and� method	1
and answering	1
2 refer	1
point for	1
frequencies are	1
; t	1
that cover	1
of tagged	1
, german	3
similar tasks	1
; a	1
their parameters	1
helpful to	1
set was	2
whole task	1
calculus the	1
a pseudo-projective	1
so there	1
evaluated the	1
thelen improved	1
alignments with	1
have .	1
4 overall	1
the french-english	1
context free	1
propose using	1
t =	1
more expressive	1
and extentions	2
as head-word	1
, originally	1
article were	1
was born	1
, notable	1
the parallel	1
of .	4
of ,	3
set of	15
on extracting	2
searches among	1
of 1	1
the correspondence	1
a broader	1
of 9	1
smt that	1
positions .	1
play a	1
word distance-based	2
training scripts	1
alignment rather	1
reliable ,	1
have implemented	2
parser achieves	1
compression ,	1
account non-adjectival	1
constant-time deterministic	1
these structures	2
of a	13
of o	2
if projectivity	1
of k	1
when compared	4
projective parsing	1
of t	2
= proje	1
and word	2
many different	1
we conclude	1
token pair	1
the left	2
recall and	4
the centroid	1
update with	1
descriptions ,	1
proj operator	1
type is	1
concentrated on	1
another use	1
type id	1
a question	2
we apply	2
, however	4
from online	1
earlier approaches	1
a dictionary	1
, the	20
captures a	1
a8 -th	1
basic unit	1
summarizer the	1
sentence-parse pairs	1
of particular	3
, ...	1
constraints imposed	1
functional dependencies	1
to indicates	1
automatically learn	1
entailment relations	1
handling non-projective	1
as itg	1
that could	1
jonathan graehl	1
are good	2
provide good	1
rouge evaluation	1
with previous	2
up to	4
∈a simw×idf	1
when the	1
problem is	2
are found	2
typically denoted	1
jobs on	1
graph .	2
. 5	1
a novel	4
. 2	1
be given	1
% 140	1
is partitioned	1
deficiency of	1
with svm	1
mining .	1
as entailments	2
rule set	1
the 447	1
that application	1
of distributional	1
development of	1
the candidate	1
we are	6
this as	2
a means	1
search engine	1
likely that	1
past decade	2
extended to	1
japanese ,	2
supervised models	1
five times	1
a summary	3
spanning tree	2
shown promising	1
structure proposed	1
, bruce	1
utility .	1
the giza++	1
implemented the	1
are believed	2
that distributional	1
unk tsuruoka	1
cover a	1
identify sentiments	1
apply a	1
automatically determined	1
lexical probability	1
language specific	1
method proposed	2
speed and	2
bi-phrase feature	1
community-wide exercise	1
diag-and� method	1
noun >	1
tsujii :	1
following such	1
the methodology	1
pruning ,	1
that projective	1
we computed	1
morpheme could	1
the state	3
but rarely	1
two different	2
26.34 27.17	1
, found	2
hard limits	1
we find	2
with k	1
with h	1
factorization method	1
have no	1
these languages	1
for expansion	1
, whichincorporates	1
way .	1
mira for	1
with respect	2
chinese-english data	1
sentences and	2
probability estimates	1
recovering dependency	1
problem where	1
language model	4
eugene charniak	1
similarity with	1
classification for	1
popular .	1
very specific	2
and might	1
a uniform	1
81.2 83.8	1
obtain more	1
: :similaritypackage	1
integrated decoding	1
by ravichandran	1
a given	5
k=1 pr	1
constituency representations	1
variety of	4
$ .	1
is most	3
a humanbased	1
$ (	1
on top	2
in translation	3
hiero .	2
of research	3
a preference	1
of allowed	1
factoid type	1
isi has	1
and discussion	1
placement of	1
w parameters	1
furthermore ,	1
collins give	1
software .	1
report very	1
identify anchors	1
we determine	1
software 3	1
promising ,	1
adjusted by	1
and incongruent	1
this includes	1
tradition in	1
the output	2
contain any	1
% bleu	1
issues :	1
method called	1
isi’s tree	1
88.2 39	1
strategy with	1
resources were	1
of improvements	1
as discussed	1
top of	2
our system	5
closure of	1
hovy’s method	1
“phrasebased” statistical	1
significant improvement	1
by geffet	1
the extracted	3
the results	7
it allows	1
to ungrammatical	1
, judging	1
shows performance	1
translation approach	4
exploiting syntactic	1
based solely	2
1 •	1
a loglinear	1
contrast them	1
constituent pairs	1
word-level correspondences	1
text has	1
penalty on	1
relation to	1
2.2 .	1
multi-document named	1
pages w/	1
1 by	1
correct rules	1
this sentence	1
: flow	1
discuss early-style	1
unique futures	1
d1-test :	1
other if	1
tagger .	1
usually” ,	1
a log-linear	2
hypothesis logical	2
incorporates features	1
this al-gorithm	1
additional related	1
our approach	8
the types	1
training techniques	1
subjective vs.	1
other is	1
one presented	1
for human	1
czech and	3
generated over	1
the why	1
found it	1
but often	2
, an	5
the appropriate	1
, as	14
found in	5
following patterns	1
set were	1
other models	2
their automatic	2
we used	6
these findings	1
tested with	1
all models	1
23 collins	1
from wordfigure	1
and och	1
treat phrases	1
information estimated	1
six major	1
co-occurrence metric	1
is presented	2
research ondatadriven	1
describes a	2
is typically	2
classification has	1
same head	1
an additional	2
interest to	1
the given	1
relationship-based method	1
largely not	1
modelling the	1
centroid of	1
an online	1
acquisition by	1
how the	2
and provide	1
answering task	1
as instances	1
of sentence	3
or conversation	1
findings are	1
graphs following	1
algorithm shown	1
several statistical-based	1
, inthispaper	1
alignment approach	1
the decoder	1
strong assumptions	1
parser that	1
one to	1
and newswire	1
who considered	1
our translation	1
$ on	1
replicated the	1
2* sagae	1
standard phrase	1
performs similarly	1
can generate	1
good performance	1
phrases from	3
and similar	1
for his	1
jiang &	1
on automatically	1
3 in	1
mcle and	1
50 sentences	1
other statistical	2
lemma mtag	1
cutoff ,	1
noun is	1
rules that	2
of dependencies	1
to solving	1
eisner 's	1
a35 a31a32a4a33a2a142a20a68a17	1
regard toward	1
bottom-up projective	1
first approach	1
split into	1
on decoding	1
or employs	1
content-independency of	1
english reference	1
limits on	1
isaac newton	1
reorderings are	1
mt output	1
evaluation in	1
evaluation is	1
called topic	1
is true	1
groups and	1
large-margin learning	1
on a	7
these probabilities	1
obtain such	1
extract phrasal	1
: inclusion	1
how well	1
discoverer and	1
literature 96.0	1
which restrict	1
was observed	1
of we	1
% relative	1
extension algorithm	1
that implements	2
of against	1
with some	1
tesni~re 's	1
learn such	1
is greater	1
pseudo-projective approach	1
and develop	1
grammar of	1
english section	1
significant improvements	1
from chiang	1
30.9 table	1
10 %	1
data directly	1
posthead conjunctions	1
3 of	1
the framework	1
a hmm	1
non-projective structures	1
allow independent	1
systems must	1
capture information	1
including modelbuilding	2
unit of	1
quadratic program	1
( e.g	1
appropriate method	1
david a.	1
dop model	2
in an	4
and jonathan	1
svm-light .	1
improve some	1
neuralign ,	1
translation decoders	1
to detect	1
parsers typically	1
to bidirectionality	1
, clause	1
human-written summaries	1
original ibm	1
longer n-grams	1
sim =	1
are uniquely	1
entities .	1
entities ,	3
sagae &	1
• probabilities	1
top result	1
sentences may	1
do ,	1
94 %	1
espresso algorithm	1
contrast ,	3
illustrated by	2
derivationally related	1
37 figure	1
a multi-stack	1
models showed	2
use a	7
german clauses	1
are closely	1
in sentences	1
one described	2
for a	9
probabilistic dependency	1
manual evaluation	1
parsers trained	1
combined into	1
much attention	1
evaluated using	1
inductive inference	2
automatically ,	1
alignment model	1
matching the	1
in id	1
percentage points	1
using nlp	1
concepts are	1
modification was	1
ibm translation	1
2 the	1
deciding if	1
use .	1
system to	3
a42 a33a53a45	1
using phrase-based	1
we abstract	1
has primarily	1
our method	2
parsing and	3
word order	2
nonprojective dependency	2
that guarantees	1
t4 1	1
these technologies	1
the j-c	1
such complex	1
basic ones	1
reimplemented the	1
few recent	1
many recent	2
newswire article	1
ra approach	1
bikel intricacies	1
a rote	1
also implemented	1
, production	1
the idea	3
results .	1
probabilistic top-down	1
we investigated	1
where messages	1
not at	3
approximately 10	1
for synchronous	1
those targets	1
accuracy ,	4
of not	1
accuracy .	3
accuracy )	2
out on	1
the 6this	1
manner similar	1
given the	1
, dating	1
automatic abstracting	2
of text	5
documents ,	1
holder’s positive	1
documents .	2
modelling techniques	1
compared on	1
birth years	1
broadcast 93.4	1
a variety	3
head rules	1
details of	1
different pairs	1
an attempt	1
a word-based	1
of patterns	2
constraining parse	1
ontology to	1
question tend	1
to develop	2
as table	1
that applying	1
cut-and-paste generation.�	1
and gravano	1
takes approximately	1
the non-terminals	1
qa systems	2
noted ,	1
filtering methods	1
examine two	1
success ,	2
simple distortion	3
, chinese	3
several fast	1
alignments for	1
have generally	1
t a	1
weight vector	1
96 %	1
, complete	1
standard projective	1
used online	1
parser using	1
positive semantic	1
system described	3
models maximize	1
the lemma	1
other instances	1
weight a27	1
delivered state-of-the-art	1
processing chain	1
a relatively	1
time required	1
galley et	1
separately considered	1
of formalizing	1
synchronous grammars	2
processing and	1
links between	1
several existing	1
t ;	1
they model	1
by one	2
includes the	1
over multiple	1
of for	1
, these	4
t ,	1
for multidocument	1
attempted bootstrapping	1
basic issues	1
far focused	1
treebanks were	1
pharaoh perform	1
: learning	1
transformations within	1
that compare	1
syntax-based translation	1
top scoring	1
richer linguistic	1
that exhibit	2
model probabilities	1
when predicting	2
phrasal translation	2
learns patterns	1
by parser	1
only on	2
and generating	1
utility method	1
around 1998	1
these scores	2
to constituents	1
by .	1
to czech	2
patterns .	2
identified the	1
query is	1
are allowed	1
parsing although	1
and extend	1
concept and	1
: arabic	1
syntax translation	1
to stipulate	1
rote extractor	1
state-of-the-art performance	3
with potential	1
compression algorithms	1
a substantial	1
evaluation against	1
incorporate paraphrase	1
computation .	1
suf ciently	1
such sentences	1
for turkish	1
present the	1
: alignment	1
a pbm	1
by a	2
while others	1
sekine et	1
several similar	1
by i	1
relativefrequency ones	1
we collect	1
counterpart .	1
these feature	2
extension to	1
wh∈wh idf	1
cross-document structure	1
art systems	1
speed .	1
36.3 %	1
named entities	2
correspondences ;	1
and 0.28	1
discrepancies between	2
phrase translated	1
globalized insertion/deletion	1
deletion decisions	1
0.3035 .	1
binary rules	1
a subtree	1
corpus and	1
other commonly	1
sophisticated levels	1
adjacent phrases	1
is that	4
second is	1
to thistask	1
hierarchical phrase	2
alignments phrase	1
phrase-based machine	2
a training	2
are formally	1
or consider	1
presupposed language-dependent	1
until recently	1
identification only	1
a cutoff	1
surface distances	1
for linearly-scored	1
in question	1
another notable	1
predicatives 97	1
predicatives 96	1
predicatives 92	1
similar text	1
of word-based	1
there are	3
uniq average	1
translation has	3
form as	1
data-source for	1
finally explain	1
in footnote	1
by each	1
proportion of	3
collins parser’s	1
conditional models	1
word distribution	1
and ra	1
incorporate features	1
y. anchor-based	2
2003 naacl	1
summaries can	1
the normalization	1
parsers thus	2
documentation for	1
a conditional	1
years >	1
is sufficient	1
experiments were	1
by incorporating	1
as exemplified	1
years ,	4
use for	1
a qa	2
pages in	1
simply extract	1
, two	3
constituency-based parser	1
a45a47a113a115a114 a131a71a132a133	1
be obtained	1
we start	1
the clean-room	1
learn to	1
the parsergov	1
recent extensions	1
94.1 %	1
filled templates	1
patterns could	1
evaluating the	1
well in	1
hyponymy relations	1
a completely	2
subset of	2
label arcs	1
estimate how	1
influence of	1
automatic methods	1
, clauses	2
ilp formulation	1
, gamon	1
generation ,	1
this shallow	1
: flat	1
other researchers	2
p1/p2 over	1
an adaptation	1
similarity and	1
this method	2
2. we	1
hierarchical model	2
we compare	3
source-channel approach	1
the similarities	1
will define	1
our initial	1
only distributional	1
extractive methods	1
20.2 %	1
∆t maltparser	1
limited distortion	1
probabilities have	1
developed a	1
the weights	1
and will	1
exp {	1
, p	1
statistical parsing	3
are logical	1
the automatically	1
dutch is	1
present results	1
test trees	1
al relabel	1
, reduced	1
exploited to	1
introducing the	1
one can	3
matches unrestrictedly	1
area in	1
integral part	1
, respectively	1
considerable amount	1
generation systems	1
to two	1
evaluation are	1
semantic resources	1
limited to	1
identifying the	1
nilsson improve	1
equivalence and	1
% uas	1
dependency reparsing	1
explore our	2
is very	4
=summationdisplayw ·f	1
relations ,	4
attractive in	1
relations .	4
involving proper	1
independently ,	1
and web	1
the final	3
model or	2
typically have	3
for extracted	1
automatically retrieved	1
parser performs	1
who introduces	1
qa results	1
that minimizing	1
tagging distributed	1
the te/ase	1
a natural	1
feature extraction	1
c5 t1	1
, obtained	2
in various	1
no difference	1
, documents	1
who introduced	1
translated using	1
10,000 sentences	1
searched in	2
, chung	1
while mcdonald’s	2
data for	2
: they	1
heuristics that	1
number of	12
not impossible	2
directly finding	1
and effectively	1
other on	2
here were	1
perform ir	1
of 0.3035	1
< birth	1
symbols in	1
annotation approaches	1
grammar formalisms	1
algorithms presented	1
prover and	1
insertion/deletion of	1
tasks .	1
appropriate value	1
studied a	1
the baseline	2
or all	1
or other	2
suggested to	1
the pharaoh	1
state of	4
te/ase algorithm	1
given token	1
successful use	1
parser trained	1
question several	1
both pure	1
be projective	1
models for	3
differently from	1
second ,	3
but none	1
phrase-pair selection	1
chunking ,	1
of 94.1	1
lifted arc	1
at trec	1
a sentence	7
that it	4
; for	1
japanese analysis	1
which one	4
additional baseline	1
when relying	1
to sentence	1
in phrase-based	2
that if	1
their translation	1
phrase-based methods	1
started to	1
that in	3
that phrasal	1
focus of	1
parser :	1
marcu have	1
symbolic reduction	1
p1/p2 for	1
and swedish	1
parser ,	6
apply this	1
parser .	4
this allows	1
using generic	1
we address	1
initiatives which	1
of features	5
also been	4
only assesses	1
patterns expressing	1
direct comparison	1
question-answering ,	1
significantly from	1
achieved a	1
position of	1
of length	2
118 predicatives	1
% of	2
be beneficial	1
to xj	1
and a42	1
linguistically and	1
researchers to	3
many studies	1
an aligned	2
90.6 91.0	1
the pattern	1
a full	3
know which	1
phrasebased model	1
extraction engines	1
sets of	3
bulgarian and	2
issue in	1
both czech	1
implemented algorithms	1
specifically for	1
co-occurrence pattern-based	1
have identified	1
on phrase	1
incremental constraint	1
the study	4
an evaluation	1
and subjective	1
... :	1
approach resembling	1
conrath distance	1
in-depth discussion	1
question whether	1
large number	1
implementations and	2
our starting	1
demonstrates the	1
of differing	1
as paraphrases	1
bleu score	1
extraction candidates	1
nl substrings	1
extraction algorithm	1
just one	1
or even	3
trees into	1
relabel coordinated	1
, below	1
framework that	1
the itc-irst	1
giza++ ,	2
giza++ .	1
intuitions to	1
correct errors	1
we obtained	2
... r	1
english using	1
152 ,	1
and matsumoto	5
strengths of	1
translations according	2
• giza++	1
the length	1
pr exploiting	1
approach and	4
system built	1
search terms	1
hatzivassiloglou separated	1
and other	5
several kernel	1
well-studied in	1
interest .	1
stated that	1
in detail	2
results have	1
complete mrs	1
candidate answers	1
parsing methods	1
compression ratio	1
translation should	1
previously bestknown	1
gained acertain	1
or individual	1
generative and	2
we should	2
the spmt	2
summaries to	2
such algorithms	1
discriminative models	1
alignment systems	1
best available	2
a subset	2
lexical semantic	1
, some	1
more effective	1
support used	1
probabilistic lr	1
sufficient to	1
recent work	4
nivre together	1
bears similarity	1
estimate phrases	1
of non-projective	1
various interrogatives	1
to non-projective	1
potential applications	1
sentence pair	2
5 experimental	1
counts c	1
on word	2
be broadly	1
wilson et	1
also closely	1
pursuing is	1
parser only	1
prague dependency	3
both training	2
generate punctuation	1
our current	1
described ,	1
projective ones	1
to koehn	1
np v	1
mead is	1
non-local dependencies	1
and run	1
technique for	1
into constituency	1
eisner is	1
structure to	1
or spanish	1
make it	3
counts ,	1
the chu-liu-edmonds	2
can already	1
or sequences	1
a19 a20a33a17	1
scfgs go	1
2003 question	1
develop automatic	1
of trees	1
mckeown proposed	1
promise to	1
ney ,	2
constraints ,	1
ney .	2
get a	2
scores of	1
nouns .	2
the simple	1
1996 ;	2
with human	1
the larger	2
phrase induction	1
distribution in	1
corpus for	2
very large	1
1996 )	2
systems such	3
first group	1
a web-based	1
used sentences	1
facts from	1
: ˆaj	1
gamon .	1
related form	1
> and	1
seen set	1
86 %	1
general or	1
parsing algorithm	5
21 for	1
this minimal	1
% 103	1
scrutinized by	2
although we	1
as “ra.”	1
project looking	1
no results	1
considered as	1
directions )	1
and learning	1
are estimated	1
has lead	1
by introducing	2
72 newspaper	1
generate a	2
template model	2
on high	2
the structure	2
there is	7
place ''	1
extracting semantic	2
with other	1
provide an	1
sentence deemed	1
the generative	1
to establish	2
material :	1
our phrase-based	1
for mds	1
not relevant	1
category as	1
sub-sumption .	1
or when	1
material .	1
ones that	1
from researchers	1
the state-of-theart	2
in greater	1
for example	11
classifier-based parsing	1
instance of	1
following models	1
word-sense disambiguation	1
reported on	1
bases to	1
eisner for	1
pair .	1
progress in	2
pair ,	2
answering include	1
between “there	1
translated strings	1
phrase translations	1
of manually	1
web is	1
ibm models	1
tsuruoka &	1
practice a	1
bilingual corpus	1
list of	2
hiero ,	1
we implement	1
sentences using	1
word distance	2
, yu	1
sentence-level analysis	1
section we	3
their evaluation	1
full distortion	2
tries to	1
first be	1
validation ,	1
that automatic	1
, treating	1
on unlabeled	1
exchange positions	1
, who	4
's dynamic	1
wiebe and	1
< 1	1
in melamed	1
forms of	1
the trees	1
or as	2
summaries in	1
for many	1
3 to	1
in unsupervised	1
in tatu	1
for noun	1
the issue	2
classifications at	1
a deficiency	1
the emergence	1
comparison to	1
text spans	1
1,755 sentences	1
more in-depth	1
of results	2
tree with	1
the number	9
persons ,	1
and ravichandran	1
∈y w·f	1
section 4	1
section 5	2
the binary	3
finally the	1
section 2	1
performs translation	1
section ,	2
arabic ,	1
and tree-to-tree	1
represents a1	1
sentences ;	1
as shown	1
take the	1
of possible	1
parsing in	4
be derived	2
to parameterize	1
relations ranging	2
highly ranked	1
rule ,	2
to 26.8	1
; and	2
resemblance to	1
parsing is	2
by the	14
the dependency	4
it starts	1
typically first	1
these ,	2
ignored without	1
5-15 to	1
pseudo-projective parser	1
and haruno	1
described below	1
bikel ,	3
phrase-reordering model	1
task-dependent accuracy	2
hovy have	1
with good	2
ed labelled	1
concrete lexical	1
explored ,	1
a wordaligned	1
feature that	1
generated for	1
a supervised	3
prototype relations	2
oriented words	1
makes any	1
analogous to	1
differ from	1
proposed in	8
clauses were	1
explicitly added	1
n-best phrase	1
simple-yet-effective extension	1
checking component	1
the czech	3
non-projective example	3
pattern was	1
for machine	1
no parse	1
the humsent	1
particularly attractive	1
lexicalized reordering	1
work uses	1
should note	2
question semantics	1
their ability	1
by is	1
list contained	1
each item	1
work used	1
different alignments	1
constituencybased parsers	1
this case	2
lead parts	1
parse has	1
% 89	1
% 88	1
words using	1
probabilistic and	1
% 83	1
explicit or	1
to remedy	2
% 86	1
various nlp	1
its main	1
that term	1
shown significant	1
large-scale nlp	1
atomic features	1
paraphrases of	2
a non-projective	4
positive and	1
subordinate clause	1
, jonathan	1
a33 a40a52a42	1
log-linear translation	1
are generated	1
the limitations	2
generating biographical	1
relations can	1
determined by	1
words such	1
dominated by	1
: transformations	1
from syntax	1
of content-independency	1
, projection	1
us use	1
sentences achieves	1
cubic-time algorithm	1
eventually one	1
dictionary or	1
in automatic	1
finding in	1
we focus	1
the jiang	1
vp pp	1
makes it	1
previous parsing	1
'' .	3
stochastic grammars	1
'' ,	1
hypothesis to	1
projective iff	1
or phrases	1
specific descriptions	1
forms the	1
matching technique	1
for case/number	1
formulation ,	1
transformations are	4
systems )	1
relevant topic	1
systems .	11
systems ,	2
been determined	1
of distortion	1
al described	1
and phrases	2
systems ;	1
systems :	3
analysis will	1
those of	2
categories of	1
compute similarity	1
items .	1
the lexicalization	1
or hierarchical	1
generation has	1
a1 and	1
important .	1
in corley	1
of formal	2
obtained as	1
compared with	2
4 alignments	1
several million	1
dag-like nature	1
2.2.2 projective	1
current work	1
linked to	1
conditional likelihood	1
nlp .	2
of course	1
binary semantic	2
explicit statements	1
as reported	1
and parameter	1
nondeterministic parsing	1
more appropriate	1
labeled allows	1
the probabilistic	3
extraction process	1
compressed to	1
: examples	1
binary scfg	1
rules :	1
reorderings and	2
limits the	1
fewer constituent	1
empirical evaluation	1
aue and	1
gained renewed	1
when longer	1
automatic compressionsnally	1
term are	1
models our	1
candidate answer	1
phrasal categories	1
testing data	1
original treatment	1
to form	1
than by	1
) applied	2
, while	4
that of	8
of nivre	1
estimated in	1
whose packed	1
answers in	1
in constituency	1
long and	1
novel analysis	1
development and	1
caching feature	1
for english	5
document polarity	1
nature of	1
f-score time	1
% .	2
% ,	2
model from	2
% (	1
marker-based ebmt	1
use surface	1
restrict grammar	1
{ jin	1
clause .	1
id description	1
motivated work	1
necessary to	1
evaluation and	1
a number	7
features between	1
pattern-based approach	1
subjective/objective classifications	1
ngrams )	1
scored independently	1
were learned	1
that has	2
and cut-and-paste	1
are accumulated	1
reordering technique	1
al are	2
on projective	4
head of	1
is heuristic	1
is computed	1
expressive than	1
during parsing	1
true if	1
〈es gibt	1
humans .	2
potential <	1
to note	2
why questions	1
word overlap	2
closer attention	1
automatic items	1
word-based lexicon	1
that appear	1
is no	3
probabilistically motivated	2
much of	3
, aim	1
has one	1
to reduce	1
procedures ,	1
answering and	1
task-oriented evaluation	1
on classifying	1
, yamada	6
as presented	2
characters to	1
this workshop	1
+ lex	1
evaluation of	3
graph transformations	1
and compares	1
is mostly	1
technique to	1
contain 0	1
handle factual	1
and compared	1
emulation of	1
• neg-log	1
terms .	1
terms ,	2
smoothing contrasts	1
as referred	1
initial alignment	1
over the	5
as good	1
, perform	1
below in	1
and collins	3
kappa and	1
capture directly	1
results constitute	1
linguistic intuitions	1
segmented into	1
can achieve	1
generation from	1
been quite	1
instances .	1
the current	6
an unsupervised	1
entity tagging	1
the mcdonald	1
type of	3
large but	1
have proposed	1
two-step model	1
morphological and/or	2
from chinese	1
terms {	1
terms x	1
mt method	1
their rule	1
memory-based parser	1
jing ,	1
jing .	1
probability model	1
cient and	1
exchange of	1
some research	1
between our	2
the bikel	1
rules from	2
different similarity	1
this formalization	1
was made	1
devise o	1
idea is	1
collins conditioned	1
many publicly	1
a bootstrapping	1
neg-log relative	1
seek to	1
automatic q/a	1
through 21	1
for sms	1
task that	1
common with	1
for smt	2
generated using	1
frequencies ;	1
combination technique—	1
block sets	1
start with	3
pair with	1
that happen	1
to 61	1
algorithm were	1
automatic opinion	1
acquisition ,	1
goal was	1
which consists	1
between language	2
the distance	1
90 %	1
reduced lemma	1
miniature bilingual	1
as part-of-speech	1
, chapter	1
cubic time	1
translation performance	1
alignment or	2
for brevity	1
word-based mt	1
if candidate	1
sentences were	1
unambiguous set	1
the german-english	1
a similarity	1
different events	1
, 223	1
nov´ak apply	1
decoder ,	3
decoder .	2
semantic relations	4
heuristics in	1
state-of-the-art phrase-based	3
of 500	1
recent times	1
a modi	1
frames ,	1
following distortion	1
result ,	2
nonterminal categories	1
popularity ;	1
m characters	1
the annotated	1
any sentence	1
hmm tagging	1
two languages	1
collins we	1
al was	1
left-to-right or	1
readme le	1
between t	1
but context-free	1
opinionated documents	1
sum of	2
nasr©lia ,	1
user or	1
incongruent structure	1
reported .	1
for conditional	1
include topic	1
: pλ	1
implicit expression	1
human evaluations	1
sequence of	3
individual opinion	1
followed by	1
either allowing	1
expected answer	1
approach as	1
matching words	1
such work	1
four years	2
story that	1
figure 2.	3
been studied	2
system has	2
global constraints	1
predict the	1
using multiple	1
also has	1
state-of-theart in	1
many previous	2
back to	3
the start	1
among others	3
traditionally ,	1
which extends	1
occuring less	1
be extracted	2
mal statement	1
vs. negative	1
following ,	1
exploiting a	1
between case	1
the clustering	1
issue of	2
if a	1
or on	1
proposal ,	1
bottom-up deterministic	1
meta-evaluation of	1
or they	1
on punctuation	1
specific resources	1
reported here	4
a significant	2
certain relation	1
of to	2
river thames.”	1
o parsers	1
further to	1
, score	1
found that	2
supports several	1
evaluation initiatives	1
ciently uni	1
polarity classification	1
without recourse	1
the claim	1
schematic overview	2
a definition	1
similarities )	1
known as	1
quite large	1
operator which	1
a quantity	1
of correct	1
80.0 %	1
generate both	1
uniquely aligned	1
for korean	1
: t1”	1
topic-relevant passages	1
the trec8	1
tree .	4
of modifying	1
tree ,	5
generated by	1
his parser	2
into formulas	1
strings matching	1
translation including	1
of sub-strings	2
of pattern	2
binary reordering	2
a116a117 a77a54a78a102a77a134a118a98a135a136a78a75a137	1
tags as	1
82.9 88.0	1
subsequent work	1
( jan	1
's automatic	1
text is	1
values can	1
the french/english	1
diag-growthfinal lex	1
: rates	1
penalizes translations	2
would like	1
substitution grammars	1
compared the	1
between pairs	1
or relatedness	1
constraints can	1
measures .	3
noun entailment	1
define it	1
good nuggets	1
of reappearance	1
shown not	1
shallow semantic	1
, which	18
obtains the	1
score to	2
model c	2
scheme to	1
: the	7
sentences ,	7
lexical weight	1
of related	1
a binary-branching	1
sentences .	6
takes into	2
extracted from	5
using parallel	1
a8 and	1
incorrect sentences	1
coll1999 :	1
input template	1
seems fair	1
german to	1
set accuracy	1
probabilistic parsing	2
prior work	3
90s ,	1
these patterns	2
despite the	1
increasing the	1
component .	1
, signature	1
and second	1
reordering model	3
modi ed	1
that scores	1
source side	1
text and	2
lee ,	3
structured data	1
methods .	3
collins used	1
clauses ,	2
distortion model	4
as reasoning	1
probabilities logp	1
in order	12
deep parsing	1
but correlate	1
variations .	1
instance reliability	1
3. discriminative	1
work extends	1
michael collins	1
experimental results	3
very encouraging	1
sentence condensation	1
automatic scoring	1
often hard	1
: ˆh	1
well when	1
frequently occuring	1
mckeown which	1
inversion-transduction grammar	1
3.2 scaling	1
= arg	1
danish dependency	1
achieve stateof-the-art	1
papers .	1
we made	1
normalization is	1
model presented	1
learning .	1
then we	1
entropy combinations	1
better reordering	1
locality of	1
translate the	1
over all	3
be successfully	1
or better	1
conditional probabilities	1
paper we	1
140 predicatives	1
jing proposes	1
which allows	1
system isi	1
detailed in	1
the lp	1
in machine	4
1 .88	1
letting us	1
engines ,	1
only 37	1
lower recall	1
structures we	1
as we	1
phrasal alignments	1
i.e. ,	2
lexicalized phrase	1
, more	3
λrhr }	1
with and	1
as input	1
algorithm as	1
is phrase	1
approach over	1
the classes	1
to appraisal	1
been tremendous	1
) 38	1
field .	1
field ,	1
for 12	1
patterns of	2
a target-to-source	1
the relevant	2
as defined	1
on ie	1
resulting estimates	1
alternative ontology	1
from ferret	1
for extracting	2
all a141a44a9a44a122a25a20	1
by lin	1
a new	3
parser-generator ,	1
method created	1
example )	1
select the	4
then add	1
translation is	2
aggregate reduced	1
example ,	10
translation in	2
as “unknown.”	1
the effect	1
rapid experimentation	1
all rules	1
been several	1
learn and	1
correct answer	1
to enforce	1
builder with	1
are modeled	1
models proposed	2
for research	2
classifier-based 88.1	1
siml as	1
a92a93a21 of	1
is precisely	1
point and	1
on paraphrases	1
next parser	2
flexible themes	1
unimportant words	1
try to	1
choosing different	1
, taking	2
is interesting	2
from any	1
system can	1
been re-implemented	1
tremendous progress	1
phrase-based decoder	2
of progress	1
promising aspect	1
is evidenced	1
, patterns	1
segments of	1
relations from	3
clause conjunction	1
real valued	1
correspondences between	1
that used	2
an explicit	1
: d1-test	1
98 %	1
text on	1
semantic correlation	1
across various	1
mani ,	1
that uses	4
million times	1
so far	2
this dependency	2
reordering-feature •	2
community .	1
similar approaches	1
chiang both	1
in japanese	1
from surface	1
extraction methods	1
pw ;	1
h either	1
hierarchical smt	1
systems analyze	1
an extended	1
collins attempts	1
, univ-avignon	1
aho and	1
pharaoh 's	1
case m-gram	1
several alignment	1
phrasal alignment	1
hash-table this	1
which penalizes	2
baseline model	1
details see	1
in german	1
matching module	1
fj2j1 are	1
of one	2
is inspired	1
tagged words	1
segmentation/tagging ,	1
strategy to	2
lexical chains	1
be found	3
between tokens	1
turns out	2
flow chart	1
extraction method	2
analyses derived	1
as implemented	1
isi 's	1
such surface	1
articles and	1
criterion as	2
quality with	2
substrings linking	1
models prompted	2
in most	1
matching or	1
more fully	1
rating baseline	1
text or	1
ed view	1
84.0 88.8	1
jonathan may	1
specific ones	2
and information	3
both source	1
finding answers	1
this data	1
brackets rate	1
, our	5
additionally supported	1
last several	1
good candidate	2
ts for	1
baseline is	1
models were	1
% for	1
for question	1
alma ,	1
recently .	1
recently ,	5
it considers	1
impossible ,	2
agichtein and	1
the n-best	2
accurate of	1
is subjectivity	1
stepfurther ,	1
of yu	1
has explored	1
train a	2
disambiguating such	1
28 ,	1
of translation	2
of lost	1
module ,	2
most previous	5
phrase structures	1
measures of	1
input text	1
to tomaˇz	1
also ,	2
are then	5
∝ exp	1
tagset compressed	1
a constraining	1
where all	2
recall broadcast	1
example compressions	1
methods may	2
reached on	1
quite influential	1
— for	1
simple baseline	1
full description	1
we achieve	1
engström and	1
in o	3
in a	14
parsing approach	1
we projectivize	1
non-adjectival parts-of-speech	1
freely available	3
qa tracks	1
other options	1
emergence of	1
entities and	1
lexical patterns	1
the findings	1
exact comparisons	1
an intermediate	1
binary synchronous	1
translation when	1
lin and	1
2. most	3
ilp for	1
sentence to	2
important statistical	1
eisner made	1
in ;	2
in :	4
a user	1
in <	1
the relative	2
effects of	1
binary links	1
a recent	1
well known	3
in )	1
we observed	1
in ,	12
in .	15
computing “holes”	1
and rim	1
supply of	1
the machine	1
even for	2
search .	1
clause ,	1
lexicalized phrase-reordering	1
minimizing is	1
state-of-the-art smt	3
but without	1
accuracy when	1
automatically constructed	1
fixed length	1
al but	1
parsers of	2
projectivization transformation	1
, usually	1
structures .	3
our synchronous	1
we extract	1
to 40	1
to 42	1
chapters 7	1
successfully applied	1
approach that	1
difficult to	2
influential in	1
matter ;	1
notion of	5
most relevant	1
late 90s	1
also be	1
all ,	1
all .	3
, differing	1
when there	1
into penn	1
arg maxyprime	1
labelled version2	1
available components	1
similarity model	1
jin et	1
part of	5
significant differences	1
many semantic	2
and applied	1
and nlp/speech	1
express knowledge	1
produce improvement	1
algorithm that	2
rules in	1
relations identified	1
syntax-based models	1
of paragraph-long	1
summarization and	1
and views	1
amount of	4
of unique	2
model considers	1
a crossing	1
dataset is	1
decoded using	1
the string	1
for further	1
, when	3
derive a	1
is 80	1
> a	1
a stepfurther	1
discovered by	1
their paraphrases	1
generalize each	1
# translations	1
, similarly	1
may won5even	1
nilsson to	1
systems and	1
described a	1
by exploiting	1
23 instead	1
directed hidden	1
1.3 .	1
an dynamic	1
that rely	2
increases ,	1
and human	1
be done	2
al measured	1
contains any	1
decoder our	1
that all	2
to better	1
kernel function	1
highest count	1
while earlier	1
these issues	1
perform favorably	1
from dependencies	1
of accurate	1
the parts-of-speech	1
figure 4.	2
trained and	1
related to	5
computational complexity	1
run a	1
, many	3
phrases directly	1
as such	1
gather the	1
85.9 2*	1
a parsing	2
, recall	1
, algorithms	2
to projective	1
generalizes standard	1
model was	2
corpora that	1
and lets	2
to create	2
on dependency	1
one of	5
of them	2
in-coverage examples	1
them in	1
the directed	1
out using	1
one or	2
more data	1
rule-based algorithm	1
attached broadcast	1
qa received	1
, popescu	1
the top	3
lexical distance	1
probabilities was	1
ideal candidate	1
in applications	2
framework called	1
hu and	1
≈ argmaxe	1
parse can	1
been shown	4
in themselves	1
classification can	1
very common	1
than the	4
10 minutes	1
consisting of	1
been proved	1
our algorithm	1
and distortion	1
versa for	1
uses many	1
mtag t	1
α translate	1
occurs before	1
its complete	1
the bracketing	1
of people	1
we replace	1
searching for	1
and used	2
“clean-room” implementation	1
file ,	1
for text	4
82 %	1
weakly supervised	1
and uses	3
which appear	1
best published	2
h is	1
learning surface	1
grammar parsing	1
31.3 bayes	1
free transfer	1
mer training	1
pages with	1
positive movie	1
output for	1
human annotators	1
138 2	1
either subjective/objective	1
crosslanguage information	1
expression in	1
from graph	1
s =summationdisplayw	1
recall using	1
performance level	1
very nearly	1
a summarizer	1
successful in	2
advantage over	1
used with	2
> was	1
log kproductdisplay	1
> in	1
= max	2
with mature	1
models by	2
entailment with	1
previously observed	1
semantic similarity	1
`` this	1
using giza++	1
86.0 11*	1
slowly converge	1
similar ,	1
other patterns	1
dataset “train	1
be decomposed	2
, riezler	1
reduction the	1
in figure	5
dynamic programming	3
information available	1
the dateline	1
precision and	2
significant increases	2
actions in	1
while uses	1
, wu	1
while used	1
to knowledge-rich	1
is represented	2
the hidden	1
keep asking	1
al showed	1
less detailed	1
of substrings	1
be computationally	1
language :	1
large k	1
, yi	1
non-projective in	1
as publicly	1
language ,	3
speaker adaptation	1
lead to	1
suggested as	1
based factorization	1
we experimented	1
listed as	1
manually choosing	1
gamon et	1
signature ,	1
weights are	1
incorporate knowledge	1
combine the	3
a wide	1
passed to	1
signature :	1
linguistics volume	1
• p	1
for maximum	1
logic ,	1
x ,	3
reduced version	1
right sentences	1
models once	1
loss to	1
differing only	1
most other	3
produce initial	1
local dependency	1
footnote 3	1
that length	1
its human	1
evaluation methods	1
recognition is	1
we obtain	2
hovy presents	1
determining the	2
koehn 's	1
text reduction	1
give results	2
decoding and	1
margin training	1
signature }	1
the koehn	1
into two	1
we implemented	2
other—is usually	1
'' ``	1
no guarantee	1
and type	1
gives good	1
• lexicalized	1
algorithm of	2
al find	1
syntactic matching	1
classifications or	1
algorithm on	1
a projective	2
right periphery	1
ps-to-ms transformations	1
english sentences	1
body of	3
• a	1
these opinion	1
al as	2
's semantics	1
, weusethelog-likelihoodstatisticsuggested	1
the banks	1
chiang presents	1
attention to	2
template approach	2
uses binary-branching	1
maximum entropy	4
s goes	1
a20a33a17 for	1
version in	1
matsumoto and	1
predict dependency	1
phrase contains	1
how much	1
derived from	3
p for	1
subtree of	1
re1see the	1
larger b	1
to decide	1
isa relation	2
≡ f	1
completely correct	1
after converting	1
matrices resulting	1
riezler et	1
performing systems	1
w ·	1
iterations ,	1
section 4.1	1
section 4.2	1
judgments .	1
parsers to	1
100 and	1
nearly projective	1
results lexical	1
use different	2
hierarchical translation	1
indicate that	2
map histories	1
are to	1
, typically	2
the neighboring	1
analysis :	1
we introduce	1
more often	1
al separately	1
training for	1
, pang	1
translation by	1
, here	1
research efforts	2
parsed .	1
is often	1
model would	1
scholz ,	4
focused on	7
length 7	2
length 1	1
recall f-score	1
length ,	2
the techniques	2
to date	2
imagine ,	1
chinese model	1
for acquiring	2
the model	3
used syntax	1
ones discovered	1
w .	1
civit and	1
considered the	1
rules based	1
from bitext	1
root 3	1
wiebe ,	1
in och	1
constituents only	1
= 0	1
bikel have	2
develop algorithms	1
training algorithm	1
measures ,	2
1 of	1
is well-studied	1
paper is	2
alternative method	1
boundaries .	1
all nonterminals	2
the metrics	1
in answering	1
especially for	2
tree-tostring models	1
but uses	1
pers .	1
cfg based	1
data sparseness	1
high-dimensional binary	1
text fragment	1
chinese-english test	1
> with	1
quality reported	1
different approaches	1
efforts analyze	1
up the	1
simply penalizes	1
learning information	1
other than	1
propose a	4
or specific	1
than for	1
91.0 unk	1
clustering to	1
ones but	1
we view	1
this translation	1
have focused	4
phrase ,	1
phrase )	1
chose giza++	1
jiang-conrath distance	1
differently tokenized	1
basis for	1
accuracy that	1
rte problem	1
birth year	1
their analysis	1
while the	2
topic .	2
we carry	1
topic ,	1
outside the	1
in analyzing	1
maximum spanning	1
their edit	1
far ,	2
and accuracy	1
and to	4
not in	1
current training	1
for statistical	2
to jing	1
use clustering	1
graph alignment	1
the editor	1
typically are	1
models advanced	1
: as	1
non-contiguous phrases	1
—henceforth referred	1
”river thames”	1
the collins	3
single x	2
to avoid	1
minutes to	1
of eisner	4
phrasestructure grammars	1
bidirectional refined	1
scaled the	1
ˆam1 :	1
unpublished details	1
we analyzed	1
provides state-of-the-art	1
using data-driven	1
set itself	1
detail .	1
are sufficient	1
to 39.7	1
pure relativefrequency	1
topic representations	1
noted that	2
the k-best	3
, pers	1
and qa	1
nilsson suggested	1
the 1.13	1
between concepts	1
relationship with	1
1 much	1
learned edge	1
quarc utilizes	1
faster and	1
compute these	1
nor bpm	1
a statistical	1
precise description	1
input relation	1
at ibm	1
verbs and	1
perhaps the	1
themes ,	1
tracking ,	1
scfgs as	1
longest common	1
existing works	1
a generative	4
, awards	1
's bottom-up-span	1
parsers in	1
, considering	1
be dangerous	1
a phrasal	1
0 1	1
0 0	1
finite-state dependency	1
with more	2
parallel corpus	1
the union	1
3.83 table	1
phrases rather	2
the holder’s	1
textual entailment	3
sentencetrial set	1
0 .	1
0 ,	1
jing trained	1
, hence	1
: description	1
relation that	1
relation and	2
word cooccurrences	1
our miniature	1
al still	1
of eisner’s	1
make use	1
along one	1
varied patterns	1
believe it	1
which extracts	1
tree-based models	1
word level	1
the huge	1
yprime =	1
as represented	1
that words	1
joint model	1
% absolute	1
research reported	1
hemisphere” like	1
appraisal theory	1
after figure	1
state-of-the-art hierarchical	1
other links	1
those obtained	1
to us	1
straightforward approach	1
match score	1
& a	1
method .	5
predicting the	3
method ,	3
system performs	2
functions ,	1
original word-based	1
we then	2
transforming 1about	1
child .	1
and quantifiable	1
by imitation	1
either attempts	1
these parameter	1
other sentences	1
amit dubey	1
, factoid	1
material or	2
• sourceand	1
field as	1
classified as	1
: pbmt	1
scripts provided	1
translation :	1
interest in	2
, please	1
translation ,	4
translation .	4
starts by	1
with an	2
lies in	1
the isa	2
the non-projective	1
h∈hf s	1
the reduced	1
respectively .	1
the isi	1
induced from	1
: percentages	1
entity labels	1
more traditional	1
statistical machine	4
lexicalization .	2
hcomp :	1
full template	1
with their	1
measures now	1
which non-monotonic	2
chinese-english translation	1
novel concepts	1
task ,	4
task .	4
korean ,	1
or less	1
one is	2
those pairs	1
directed translation	1
test data	1
have harvested	2
compression problem	1
top ibm4	1
longer or	1
score )	1
, weuseapublicly-available	1
score ,	5
score .	1
al for	4
was a	2
yi et	1
on each	1
; turkish	1
score :	2
which is	10
: e∗	1
a cky-based	1
crucial role	1
and kappa	1
phrases learned	1
to ∆t	1
from xi	1
results are	3
a hash-table	1
latter .	1
page ,	2
is encoded	1
beam decoder	1
form :	1
appealing .	1
sentence utility	1
final patterns	1
simpler and	1
pair country	1
distance as	2
many applications	1
parsing or	3
formal grammarsisonly	2
ours ,	2
1.63 value	1
from extracted	1
machine 255	1
parsing of	1
and chiang’s	1
xi to	1
a slight	1
and decoded	1
while most	2
deterministic 86.5	1
proposed deterministic	1
represented by	3
317 citation	1
as :	1
, compression	1
as proposed	2
the dop	2
as ,	1
coordination .	1
as .	3
include .	1
and for	3
from giza++	1
correct analysis	1
available in	1
is better	1
with very	3
several approaches	1
to map	2
to mal	1
numbers in	1
a hierarchical	2
extensive knowledge	1
pairs having	1
be poor	1
crucial use	1
systems correlate	1
issues and	1
the linear	1
lexicalized pcfg	2
in to	2
al have	2
as a	12
advanced translation	1
for discussion	1
phrase-structure parsing	1
by collins	3
in disambiguating	1
meta� summarization	1
sensitive to	1
iff all	1
acquisition promise	1
http :	1
resembling ours	1
rim for	1
weighted abduction	1
bootstrapping ,	1
algorithm has	1
various probabilistic	2
measure precision	1
at the	5
recent study	1
queries .	1
, multi-document	1
models tested	2
best metric	1
other relations	2
start position	1
computational process	2
tree problem	1
feature function	2
dependency parsers	2
, especially	4
refinement heuristic	1
hall and	1
, 1999	1
that tends	1
of noun	2
the espresso	1
documents and	2
1 recent	1
projectivizing training	1
tag set	1
hovy’s paraphrase	1
we reimplemented	1
metric turns	1
results with	3
parse given	1
punctuation signs	1
monotonously segmented	1
rate training	1
as lafferty	1
framework has	1
answer is	1
fl phrase	1
lex .	1
alternative 66	1
or sentiment	1
rouge-1 ,	1
root accuracy	1
extension could	1
anchors in	1
for our	5
related works	1
assess predominately	1
the patterns	1
applied the	2
detailed treatment	1
are sentence-level	1
structure of	1
shared data	1
of by	2
a pragmatic	1
state-of-the-art dependency	1
technique and	1
which currently	1
shortened sentences	1
chu-liu-edmonds algorithm	1
we collected	1
for phrase-based	1
target language	3
39 ratnaparkhi	1
szpektor et	1
a parsing-based	1
and answers	2
rules charniak	2
ilp approach	1
knowledge to	3
that probabilistic	1
discussed in	3
103 predicatives	1
results we	1
itc-irst system	1
mira 83.3	1
and chinese	2
relation in	3
hovy focus	1
significant portion	1
9.70 1.93	1
, serve	1
a8 where	1
: relation	1
research on	5
charniak parser	2
more precise	1
techniques useful	1
sembled ,	1
automatically discovering	1
extractive summarizer	1
subsequences ei2i1	1
axioms express	1
the marker-based	1
parsing proposed	1
humanbased quality	1
directions or	1
charniak for	1
pipeline .	1
document orientation	1
the drs	1
when restricted	1
a32 a8	1
use in	2
a32 a6	1
qa ,	1
is particularly	1
tackling this	1
thirties3 recently	1
details concerning	1
and informative	1
bod 90.8	1
sentence simplification	1
φem differ	1
“flatten” it	1
label and	1
and 2/	1
following slight	1
any direct	1
translation system	4
method diag-growthfinal	1
as described	9
extracted .	1
answers on	1
lexical rules	2
bring it	1
applications could	1
good at	2
trec2003 question	1
wider range	1
good as	1
calculated by	1
a32 denotes	1
forest and	1
our case	2
this requirement	1
vertex ,	1
a2 a33a50a8	1
judging document-level	1
recently proposed	1
each table	1
table and	1
both dirt	1
are capable	2
that mst	1
generated rules	1
> sentences	1
competitive at	1
the diag-and�	1
popular with	1
et al	15
methods defines	1
spoken transcripts	1
implications are	1
analysis ;	1
brings a	1
empirically provides	1
23 figure	1
words :	1
greater depth	1
of solving	1
therefore adopted	1
the latter	2
probable and	1
subordination that	1
a reduced	2
a4a53a54 a40a56a55	1
feature ;	1
data provided	1
opinion ,	1
• the	1
work reported	2
there have	2
relations inventor	1
no bootstrapping	1
additional constraints	1
dependencies from	1
feature .	1
will give	2
wordfigure 3	1
and syntax-inspired	1
but the	3
a cubic	1
other language	1
our work	4
the constituency	1
in yamada	1
implementation 1	1
approaches ,	3
the rich	1
approaches .	3
much in	1
∈y w	1
naive bayesian	1
, danish	2
coreference ,	1
for nonprojective	1
sri language	1
hajiˇc ,	1
models typically	3
been used	5
english ,	5
english .	3
good results	2
a detailed	2
lower when	2
statistical systems	1
languages are	2
mann and	1
thus ,	3
our reimplementation	1
in parsing	2
constraints are	1
made by	1
derivations .	1
by giza++	1
precision figures	1
use only	1
and surface	1
x having	1
86.8 85.0	1
statistical methods	2
made possible	1
: intersection	1
the inversion	1
into treelets	1
awards ,	1
fast and	1
t must	1
kind of	5
exclusively aligned	1
} m∈	1
a centroid-based	1
3rd iwp	1
that were	1
l the	1
on other	1
source text	1
an ideal	1
we learn	1
more frequently	1
tried following	1
these transformations	1
and turkish	2
many summarization	1
: in	1
true of	2
precisely ,	3
models presented	1
non-projectivity in	1
relations is	2
sentences can	1
: it	1
idea of	3
was on	1
the function	1
our processing	1
certain type	1
same translation	1
metric in	1
comparing the	1
then phrase	1
is due	2
extracts phrases	1
taken ,	1
% task-dependent	2
matrix for	1
a scale	1
of statistical	4
during training	1
• comparing	1
transformations for	1
techniques for	3
describe an	2
punctuation dependency	1
scores for	3
all fragments	2
2 through	1
system performance	1
downloaded from	1
denotes the	1
and negative	1
, several	4
diversity of	1
al 's	2
annotated every	2
step ,	1
possibly segment	1
accuracy of	3
go back	1
the reordering	1
systems from	1
pruned from	1
collins’ parsing	1
∈ ph	1
formalism ,	1
to address	2
intersection of	2
information for	1
than those	2
that some	1
way around	1
include agichtein	1
∈ pt	1
fragments and	2
the anchor	1
considering only	1
and show	1
are described	2
to .	2
corpus most	1
after that	1
extending the	1
between names	1
uncontroversial ,	1
expressly opinionated	1
refined word	1
subjective text	1
parser childcount	1
task for	1
smoothed relative-frequency	1
4 features	1
standard notion	1
structure theory	1
the cle	1
knowledge-rich problems	1
rsummationdisplay r=1	1
on penn	1
certain length	1
margin perceptron	1
system against	3
where he	1
shown the	1
loss is	1
at 84	1
approach of	2
's o	1
both languages	1
the nist	2
three additional	1
42 translate	1
is what	1
surface features	1
, concentrates	1
two alignments	1
a120 a4	1
instances in	2
all words	2
every textual	1
of effectively	1
uni ed	1
leads to	2
as illustrated	1
these n-gram	1
noun phrases	2
extraction and	3
ones are	1
czech dependencytree	1
experiments confirm	1
when using	1
are other	1
for answer-point	1
, objects	1
to <	1
packed representations	1
fusion can	1
similar measure	1
's ,	1
time best-first	1
what points	1
of that	1
implements online	1
to follow	1
corley &	1
of lead	1
group that	1
birth of	1
or in	1
a team	1
we include	1
is aligned	1
a topic	1
> extractions	1
translations must	1
by modeling	1
and punctuation	2
obtain translations	1
1/ the	1
be defined	1
the general	3
for recovering	1
strings at	1
·f where	1
word-based approaches	1
parts-of-speech of	1
greatly improve	1
work at	1
the morphemic	1
data fleischman	1
rich tags	1
mbl ,	1
wsj is	2
performed decoding	1
evaluation method	2
community-wide evaluation	1
improve accuracy	1
as high	1
tested on	4
, inc.	1
has produced	1
heuristic combination	1
and conjunctions	1
non-projective edges	1
to consist	1
this for	1
alters the	1
collins parsing	1
end we	1
different feature	2
wordnet synonyms	1
a bleu	1
12 languages	1
to coordinate	1
then our	1
comparison with	2
syntactic constituents	1
higher accuracy	1
to exchange	1
in nivre	1
but higher	1
grammar checking	1
or features	1
decades ,	1
commissioned a	1
and mckeown	2
which translation	1
nature makes	1
they do	1
the last	2
governor to	1
also two	1
for other	2
are exponentially	1
for techniques	1
:similaritypackage to	1
that permits	1
the edge	1
combining these	2
such patterns	1
results from	2
word penalty	2
natural language	10
was to	2
restriction is	1
proposed as	2
related issues	1
word form	1
projective data-driven	1
the prague	2
shown that	3
an input	1
after a	1
relationships between	1
bootstrapping 88	1
new evaluation	1
proposed an	1
runtime .	1
2. as	1
on symbolic	1
a “clean-room”	1
be binary	1
and classifying	1
resolution ,	1
takes two	1
nonhead words	1
translation model	4
which assigns	1
observed data	1
in penn	1
727 such	1
δk =	1
against the	2
% 23	1
we compared	4
, suggesting	1
the problems	1
related ,	1
( where	1
alignments by	1
outperforms the	1
both sequence	1
algorithm similar	1
are adjusted	1
iwp workshop	1
and dependency	1
the advantage	1
learning algorithm	1
systems either	1
several strategies	1
dagan was	1
overlap measures	2
neither phrase	1
approximate optimization	1
adapted across	1
tapped the	1
weights and	1
larger question-answer	1
: φem	1
are factored	1
easily adapted	1
related s	1
features passed	2
incorporating nonlocal	1
english text	1
substrings that	1
constraints between	1
pdg .	1
the sure	1
distortion probability	1
which means	1
the sms	1
interesting approach	1
features are	3
of categorizing	1
4 gives	2
lafferty et	1
extracts its	1
’s .	1
segment resulting	1
identifying opinionated	1
not feasible	1
the search	3
factoid question	1
error of	1
question of	1
} n∈	1
wu ,	1
precise as	1
referred to	3
presented .	2
toolkit .	1
toolkit ,	1
disjunctions or	1
language are	2
be conjoined	1
translation of	3
smart reordering	1
phrasebased smt	1
of context	1
works by	1
and corpus	1
german .	1
team taking	1
german ,	3
been previously	1
condensation module	1
than charniak	2
we wish	2
this edge	1
, attachment	1
a suffix	1
vpp-vp →	1
presented a	2
about 25	1
are word	1
context are	1
gaps extracted	1
word aligned	1
particular lexicosyntactic	1
understood as	1
explicitly do	1
= argmax	1
probability a27	1
the structured	1
signatures topic	1
the strength	1
similarity to	1
not grammar-based	2
nevertheless seems	1
models :	1
toinfinitives ,	1
different variants	1
40,000 sentences	1
and gerunds	1
were classified	1
on non-projective	1
appears to	3
suggest limiting	1
word-aligned corpus	1
extract of	1
efforts have	3
inverse transformation	1
to output	1
given sentence	2
axioms combine	1
lexical information	1
statistics ,	2
compute a	2
previously formulated	1
subjective ;	1
, after	1
recognizer .	1
a signi	1
testing set	1
a general	1
treated as	1
using surface	1
go bankrupt”	1
language’s non-projective	1
as czech	2
, derived	1
line with	1
same settings	1
have successfully	1
cluster-based translation	1
refined alignments	1
addressing some	1
extraction during	1
of e-to-f	1
target-conditioned neg-log	1
membership of	1
decoder and	2
to signal	1
a greater	1
or syntactic	1
lexical heads	1
europarl test	1
of synchronous	1
new string	1
reduction as	1
on significantly	1
probabilistic context-free	1
single set	1
projective dependency	1
: mean	1
tackling these	1
variant that	1
representations like	1
to solve	1
directions .	1
directions ,	2
approach to	6
reduce sparseness	1
to collins	1
researchers in	2
to matching	1
high-accuracy systems	2
structures to	1
most prior	1
% newspaper	1
bod all	2
of punctuation	1
searches in	1
in deciding	1
defines the	1
1 t4	1
where x	1
other non-projective	1
k-best mira	1
the goal-noun	1
phrase translation	4
to represent	2
novel algorithm	1
training treebank	1
tree that	1
evaluation purposes	1
pair so	1
alignment matrices	1
where the	6
3 with	1
t and	1
for algorithms	1
an individual-preference	1
lapata )	1
and f-score	1
results concerning	1
a33 a6	1
to around	1
that go	1
parse tree	3
whether or	1
ratnaparkhi’s mxparse	1
or to	1
passed up	2
model like	1
with lexical	2
with the	14
in newspaper	1
the models	6
kudo and	1
parameter .	1
; •	1
computationally expensive	1
about phrases	1
pr ≈	1
capable of	2
”london ,	1
project we	1
recently become	1
the history-based	1
but discrepancies	2
validated their	1
that reported	1
need of	1
model many	1
semantic representation	1
arc is	1
have much	1
german 〈es	1
raising the	1
in sentence	2
1 introduction	2
directly from	2
his dependency	1
4.1 ,	1
does not	2
of constraints	1
local reorderings	1
the context-free	1
we denote	1
surveyed in	1
phrase from	1
evolved from	2
is selected	1
syntactic subordination	1
scoring metric	2
a local	1
following sequence	1
of phrases	2
in where	3
models use	2
so-called phrase-based	2
, words	1
even a	2
are essentially	1
by finding	1
computed to	1
the components	1
before the	1
as context	1
fp :	1
1while the	1
pp-vp ,	1
successful alternative	1
a strong	2
are called	1
definitions for	1
nilsson method	1
value than	1
maximize s	1
been proposed	8
about persons	1
patterns and	1
for details	4
, details	1
discriminative framework	2
basic tree	1
recent interest	2
form p.	1
are non-projective	1
to clean	1
tease algorithm	1
notice significant	1
important for	1
fragments within	2
restrict reorderings	1
entity recognizer	1
the core	1
selected the	1
that this	3
french ,	2
but did	1
, similar	2
pos features	2
complexities :	1
using semantically	1
k phrase	1
czech by	1
“es gibt”	1
otherwise revising	1
positive prospects	1
and precision	3
i co-developed	1
following nivre	1
the encoding	1
summary ,	2
summary .	2
be translated	1
language modeling	3
we follow	3
occur more	2
judges to	1
dataset of	1
part in	1
traditional approach	2
and their	4
apply the	2
compute the	1
in use	1
task-specific information	2
of automatic	3
or right-to-left	1
1 to	1
transformation ,	2
unlabeled attachment	2
functions listed	1
questions and	2
previous research	1
analyzers ,	1
single document	1
performed to	1
generate widl-expressions	1
the pos	2
by dunning	1
function over	1
perform experiments	1
order the	1
of similarity	1
respect to	2
category .	1
approach is	7
in state-of-the-art	1
approach in	2
used successfully	1
that was	2
world ,	1
our learning	1
included for	1
that assign	1
and attempted	1
of dependency	3
system supported	1
and correct	1
context-free parse	1
want to	1
dagan but	1
sentences by	1
histories to	1
ways by	2
label r↑h	1
pereira .	1
learn simple	1
. •	1
of resources	1
the sum	2
method has	1
orientation and	1
probabilities of	1
> <	1
to make	3
segments .	1
penalty exp	1
evaluation measures	2
“bin laden	1
has a	5
to perform	1
around this	1
we proceeded	1
paper presents	1
which emphasizes	1
the projective	2
condensation approaches	1
component of	3
decoder which	1
similarity does	1
comparable results	1
= braceleftbig	1
good amount	1
the future	2
in table	1
restricted to	1
with sentence	1
also leads	1
recall ,	1
used phrase-based	1
al use	1
this approach	5
answer type	1
texts held	1
introduced a	1
comparable to	4
translation pipeline	1
alignments and	2
importance of	2
here has	1
completely unsupervised	1
arcs to	1
denote by	1
a cfg-based	1
indicators of	1
returned in	1
parsers that	2
has also	2
this cross-pair	1
de nitions	1
the problem	3
step to	1
based models	2
direct customer	1
, collins	5
have any	1
subject matter	1
instead .	1
system hiero	2
automated systems	1
post-processing to	1
better understood	1
combination with	2
bitext ,	1
representation was	1
question answering	7
word subsequences	1
the question	3
as construction	1
pharaoh feature	1
: monotonic	1
a great	1
union similar	1
appears in	1
~cogentex ,	1
when it	1
syntax-based methods	1
each other	2
form ,	1
decoding mcdonald	1
form .	2
million instances	1
cost of	1
a19 a20a97a9a44a122a140a20a100a17a103a118	1
english shows	1
tree-to-tree models	1
answers to	1
to in	1
our corpus	1
in corpus-based	1
from word-pair	1
but encode	1
1.13 value	1
a particularly	1
avglen rating	1
and/or syntactic/phrasal	2
have evolved	2
level or	2
results using	2
a system	3
form f	1
for translation	2
have developed	1
and have	1
lifting non-projective	1
level of	1
or wildcards	1
the sets	1
lr scores	1
for word	2
an observation	1
style constituencies	1
of refined	1
semantic ones	1
, english	2
editor than	1
phrase learning	1
$ ”	1
reduced sentence	1
∈y s	2
parametric form	1
logical entailment	1
k (	1
get the	1
7 and	3
some qa	1
the inside	1
of being	1
: experimental	1
and then	5
about 40,000	1
algorithm for	6
collins treebank	1
chiang introduces	1
functions hr	1
1 :	4
part-of-speech tagging	2
learning subjective	1
the features	3
: positive	1
techniques and	2
1 0	1
1 1	1
recall alignments	1
method should	1
and flexible	1
highly correlated	1
1 .	4
that pseudo-projective	1
1 ,	3
1 %	1
1 [	1
from lexicalized	1
nodes collins	2
czech prague	3
using these	1
pattern mining	1
a special	1
but also	3
the main	1
, one	1
parsing czech	2
the p1/p2	1
and report	2
‘subjectivity’ ,	1
for such	1
by pantel	1
model has	1
predominately extractive	1
extract an	1
synchronous grammar	1
sa4a68a77a102a9 a19	1
metric may	1
sources of	1
exact algorithms	1
to identify	4
similarity within	1
in with	2
following features	1
f-measure error	1
on an	2
: this	1
these sets	1
a multiparallel	1
and jing	2
le of	1
, models	1
modeling such	1
a source	1
certain features	1
al that	1
discriminative learning	1
path in	1
translate input	1
a33 a8	1
the relevance	1
reappearance of	1
translation as	1
source documents	1
as yamada	1
2005 nist	1
hovy proposed	1
previous studies	3
more surface	1
unreliable at	1
see collins	1
any sequence	1
follow the	4
empty hypothesis	1
achieves a	1
documents from	1
this might	1
key area	1
first class	1
to carry	1
an n-best	1
to extensive	1
's side�	1
of birth	1
the penn	3
alignment such	2
the workshop	1
srilm toolkit	1
, we	21
parsers ,	1
parsers .	3
smt has	1
and binary	1
at hlt-naacl	1
find such	1
is ,	3
, against	1
vectors related	1
sentences that	4
constraints corresponding	1
, learning	1
be noted	1
translation and	2
earlier qa	1
, providing	1
locations ,	1
synchronous parsing	1
estimated using	1
a ,	1
using constituencybased	1
search 86.8	1
the deletion	1
templates our	2
a <	1
to to	1
the feature	2
generated ,	1
a 1	1
the total	1
a shared	1
or exploiting	1
his grammar	1
statistical disambiguation	1
the block	1
is a	16
links ,	1
links .	1
performance wassubstantially	1
single-document summaries	1
3.1 feature	1
large body	2
maximum-likelihood estimation	1
learning techniques	2
and question	2
converter to	1
word alignment—detection	1
work from	2
and sure	1
doing a	1
parsing algorithms	3
candidate analyses	1
assume that	4
qa researchers	1
, language	1
pascal rte	1
with maximum	2
highest scoring	1
word similarity	2
37 sentencetrial	1
pattern ranking/selection	1
the joint	4
the multitext	1
another set	1
reviews or	1
of hierarchical	1
alignment error	1
of complete	1
into syntax-based	1
version2 of	1
corpus is	1
in addressing	1
in pakistan”	1
transformation is	1
southern hemisphere”	1
results very	1
j are	1
implemented in	3
being added	1
a major	3
we need	1
key phrases	1
for bi-phrases	1
have built	1
for projective	2
791 and	1
a key	1
word matches	1
are based	4
and different	1
reimplementation of	1
the state-of-the-art	5
, instead	1
a30 a47	1
speci c	1
weights which	1
sentence with	2
; see	1
phrase-based-like submodels	1
satisfy :	1
unigrams to	1
of projective	1
on translation	1
refined alignment	1
n-grams are	1
learn predictors	1
parse accuracy	1
grammars can	1
chart-based parsing	1
the 3rd	1
the morphologically	1
aggressive pruning	1
list generated	1
a one-to-many	1
that currently	1
translations under	1
disambiguation such	1
1999 )	1
mostly used	1
the focus	1
experiments ;	1
experiments :	1
it has	4
word-aligned bilingual	1
makes ures	1
bilingual text	1
and no	1
exponentially many	1
called the	2
experiments ,	2
experiments .	1
and ne	1
pt :	1
and inter-sentence	1
words have	1
professionals construct	1
ir-based include	1
willbeconsideredsimilariftheyhavelargecommon sets	1
, source-phrase-conditioned	1
mrs are	1
isi syntax-based	1
extract hierarchical	1
john sebastian	1
main scoring	1
derived for	1
single nonterminal	1
is extracted	1
the later	1
performance in	1
moldovan .	1
2other models	1
of american	2
from an	3
outperform word-based	2
points ,	2
constituency parsing	1
reference performance	1
; eisner	2
asking until	1
parse and	3
criterion in	1
but as	1
but an	1
by giza	1
issues ,	1
a 2.1	1
wn :	1
set to	1
were carried	1
effect of	1
nding patterns	1
and limited	1
than our	1
the experiments	2
our models	1
to” ,	1
accuracy remains	1
systems based	1
provide testbeds	1
requires an	1
context-free rules	2
26.8 %	1
and inference	1
to enable	1
presented in	6
; 3.	1
improve punctuation	1
components :	1
related phrase-based	1
whereas the	1
then search	1
concepts ,	1
concepts .	2
of special	1
two semantic	1
, those	1
sample of	1
this paper	4
and observe	1
from spoken	1
the entailment	1
approach called	1
information from	2
the user	1
ney and	1
} the	1
it to	2
are exclusively	1
to improve	5
with edge	1
considered intervening	2
abduction ,	1
ideas have	1
of keyword	1
more words	1
answering for	1
was substantially	1
: 1	1
classification see	1
previous attempts	2
as first-class	1
induce their	1
representation ,	2
co-selected sentences	1
prior probability	1
notable development	1
where question	1
either generate	1
recall problem	1
letters to	1
published numbers	1
learn arbitrary	1
, unlike	1
goes into	1
: following	1
computes translation	1
word indicates	1
share the	1
operate in	1
data released	1
transformation to	1
error minimized	1
resources ,	3
resources .	1
translation can	1
being trained	1
data by	1
piggyback on	1
grammar rules	1
so is	1
regarding employment9	1
resources :	1
field of	3
90.8 90.7	1
structure parsers	1
) used	1
with non-projective	2
through learned	1
heuristic for	1
that add	1
transformation in	1
88 ravichandran	1
a pure	1
be seen	1
a named	1
exhibit free	2
a wordnet-based	1
chart item	1
table 3	2
table 2	3
table 1	4
signatures are	1
table 5	2
manner ,	2
such links	1
o ,	1
probabilities in	1
be performed	1
table .	2
table ,	3
parse of	2
corresponding word	1
re-framed into	1
on labeled	1
for automated	1
up from	2
we seek	1
koehn .	1
sentence ,	5
details )	2
sentence .	1
same criterion	2
details ,	1
by •	1
only one	1
area of	1
handled with	1
of natural	3
deficient punctuation	1
to acquire	3
another .	1
, smt	1
ferret 's	1
the projectivization	1
1−p ≈	1
in computational	1
chiang .	1
parsing brings	1
chiang ,	1
and methods	1
written by	1
since then	1
system pharaoh	1
see engström	1
reranker of	1
kneser-ney smoothing	1
alternative to	1
the hmm	1
problems such	1
to disambiguate	1
emphasizes the	1
the correct	4
sentence x	1
e.g. ,	5
most non-projective	1
dependency treebank	3
learning components	1
sentence s	1
which along	1
how professionals	1
categories covered	1
and which	1
has benefited	1
86.0 86.1	1
phrase was	1
words found	1
of corresponding	1
a vecto	1
3-gram ,	1
reduced clauses	1
found to	2
the minipar	1
model figure	2
in questions	1
source-phrase-conditioned •	1
polynomial kernel	1
automatic n-gram-based	1
huge increase	1
applied a	1
parsergov feature	1
contents .	2
some heuristic	1
• xcat	2
remains below	1
a much	1
used pharaoh	1
can use	1
to override	1
for mcle	1
section describes	1
and semantically	1
grammar employed	1
each system	1
very general	2
available on	1
this has	1
• esp-	1
, e.g.	4
pure algorithmic	1
works used	1
gives considerably	1
theory and	1
newton <	1
inclusion ,	1
pdt training	1
those used	2
while this	1
extract a	3
are 36.3	1
is tested	1
itg .	1
found thatthe	2
variants of	1
lexical similarity	3
25 %	1
domain of	1
human judgments	2
maintaining the	1
evaluating an	1
the end	1
method correct	1
people for	1
methods for	7
standard similarity	1
feedback .	1
model our	1
realized as	1
address others	1
of consistency	1
modification .	2
translation approaches	1
automatically entailment	1
tractable .	1
dependency trees	3
255 length	1
link grammar	1
shallow approach	1
a good	2
cluster are	1
“an arc	1
translation made	2
bought y.	2
α .	1
linguistic methods	1
to the	21
rte dataset	1
system with	4
for sentiment	1
pairs to	2
either morphemes	1
parser action	2
used in	11
bottom-up-span algorithm	1
of subjectivity	1
discriminative spanning	1
of segments	1
used is	2
as an	6
parsing model	4
introduced to	1
inversion transduction	1
system is	3
system including	2
measured yield�	1
to each	4
previously found	1
graphs ,	3
uses aggressive	1
the whole	1
algorithm used	1
training and	4
use pos	1
system in	1
categories would	1
to sub-events	1
phrase penalty	1
many stack-based	1
, nonheadwords	2
al in	1
models based	2
an n-gram	1
vice versa	1
predicting children	2
data redundancy	1
rules learned	1
becomes pseudo-projective	1
are discovering	1
shows .	1
between entities	2
nuclei in	1
for swedish	2
entailment relation	2
constituency trees	1
collins .6	1
: phrase	1
giza++ and	1
phrase probabilities	1
research in	2
allowed to	1
extracted information	1
and finite-state	1
better with	1
∈ .	1
language and	1
the world	2
of question-answer	2
used giza++	1
alignment a180	1
with various	3
maximum phrase	2
: ”london	1
been employed	2
training the	1
action 3.	1
then and	1
, topic	3
pattern matching	2
target concept	1
f we	1
al reported	1
optimal parse	1
jan hajiˇc	1
until the	1
: transform	1
so ,	1
, tree-tostring	1
label of	1
children agreement	1
models from	1
note ,	1
a corpus	3
t ∈	1
certain relationship	1
manning ,	2
of recent	2
use mbl	1
many reliable	1
determine which	1
same answer	1
by mihalcea	1
use of	10
are labeled	3
similar model	1
the correspondences	1
and 41	1
extracted by	3
group for	1
al is	2
exploits only	1
distortion models	2
by developing	1
his n-best	1
usually followed	1
is given	2
several dependency-based	1
process of	3
newspaper editorials	1
parsing for	2
was adapted	1
constraint generation	1
produced promising	1
maximum score	1
flexible word	2
contain more	1
documents which	1
gi03 :	1
language .	1
who-is type	1
that for	1
of sentiment	1
to other	1
morphemes and	1
pp vp	1
candidate for	2
from lexical	2
possible because	1
indexing ,	1
dependencies that	2
and finally	1
exclusively on	1
probable .	1
which are	5
amounts to	1
decide ''	2
a14a12a91 a19a86a92a93a21	1
more details	2
sj is	1
systems start	1
context in	1
f where	1
units ;	1
obtain p	1
statistics about	1
features of	1
particular span	1
a72 a14a12a91	1
naacl shared	1
defines measures	1
parser described	2
time attempt	1
that have	4
have been	15
parallels work	1
semantics needs	1
ˆam1 is	1
the annotation	1
have improved	2
correct sentences	1
longer than	1
sequences of	2
verbs ,	2
proposed :	1
pair which	1
are scored	1
a40a56a55 a8	1
it into	1
is used	3
proposed .	1
to montserrat	1
these terms	1
high performance	1
n-best parser	1
subsumes that	1
generative one	1
j ∈	1
and analysis	1
worst case	1
gains prominence	1
mbl with	1
comparisons with	2
his software	1
examinations designed	1
labels are	1
by detecting	1
collins was	1
markov models	1
parsers perform	1
alternative training	1
and aue	1
proposed a	4
computes both	1
support vector	1
al considered	1
orientation of	2
like those	1
are weights	1
usually an	1
details found	1
dutch ,	1
of more	1
substituting phrases	1
whether there	1
the parsing	4
test corpus	2
and hardware	2
left or	2
semantic lexicons	1
approaches for	1
as incremental	1
anotherpromisingprospectofourmodelseems to	1
researchers1 annotated	2
algorithms have	1
miss many	1
is decomposed	1
and rough	1
1 table	1
and rouge	1
, wordnet	1
the english	1
tasks include	1
other stochastic	1
product reputation	1
most similar	2
performance on	3
word-order .	2
consistent increase	1
performance of	6
claim about	1
the areas	1
to collins’	2
or statistical	1
syntactic phrases	1
parsing has	1
scale from	1
tree automata	1
important component	1
combination :	1
additional o	1
models can	1
is worth	1
impossible .	1
, phrases	3
1 gives	1
84 %	1
the concepts	2
a surge	1
called growdiag-final	1
combination ,	1
justification for	1
word-based models	2
nilsson as	1
statistical models	5
of phrasal	1
{ topic	1
include the	2
capture linguistic	2
rough assumption	1
also included	1
hidden data	1
be successful	1
88.6 %	1
cfg ,	1
entity ,	1
formulated ones	1
shallow parsing	2
25.2 %	1
adapt the	1
generate quabs	1
to deliver	1
of lin	1
english analysis	1
, allowing	1
x and	2
been performed	1
output ,	1
we generated	1
and ngrams	1
decoding can	1
in englishto-german	1
patterns are	2
pedersen .	1
or of	1
ways .	1
notable exception	1
impossible to	1
zeman that	1
others :	1
that they	1
combine probabilities	1
studies of	2
experiments in	1
building and	1
to remain	1
patterns in	1
and validated	1
others .	4
wong ,	2
answer .	1
f the	1
the phrase	4
and lr	1
of pre-defined	1
most number	1
extraction patterns	1
observed by	1
synchronous context-free	1
morphologically reduced	1
including product	1
indeed ,	1
and instance	1
a word	4
final result	1
to rank	1
method method	1
is ambiguous	1
text passages	1
consider document	1
eq .	1
which extractive	1
take into	1
domain-specificity of	1
phrase-based alignment	1
testing split	1
similarity lists	2
which supports	1
phrases themselves	2
rules are	1
same techniques	1
baseline system	2
rather than	6
identify important	1
instances of	4
, that	3
system are	2
function scores	1
that changing	1
times faster	2
the stan156	1
training with	2
probability a34a35a4	1
these are	1
the word-based	1
case/number agreement	1
of vector-spacebased	1
, linguistic	1
relies exclusively	1
where nonprojective	1
these anchors	1
a computational	2
two sentences	1
to account	1
particularly in	1
similarity between	2
informative level	1
example by	1
parser uses	1
approaches of	1
transducers .	1
rlifferent for	1
positive words	1
all contiguous	2
lexicosyntactic patterns	1
error-driven training	1
information in	1
parse in	1
parser used	1
flushes anti-clockwise	1
nonterminal symbol	1
n-grams of	1
seed questions	1
extract semantic	1
goal-verb and	1
comprehensive review	1
simple ;	1
introduces syntactic	1
ˆh =	1
concerning punctuation	1
the predefined	1
document compression	1
extract particular	1
ibm ,	1
it was	2
& lavie	1
in each	1
, french	2
from 25.2	1
a common	3
that detailed	1
& mihalcea	1
they provide	1
classifier against	1
proceeded with	1
, probabilities	1
frameworks .	1
frameworks ,	1
the a4a53a54	1
target phrase	1
model builder	1
links are	1
model popular	1
evaluations .	3
training regimen	1
particular concepts	1
create dependency	1
one parse	1
dependencies to	2
, no	1
tested it	1
the charniak	2
, np	1
stipulate that	1
more of	2
input from	1
basic word-based	2
use judges	1
more on	1
widely considered	1
standard translation	1
arguably at	1
online data	1
alternative has	1
syntactic similarity	1
much like	1
, translation	1
used ,	3
that allows	1
uninformed baseline	1
to four	1
finally ,	3
, achieving	2
for online	1
are in	1
give the	1
to mt	1
first employ	1
be applied	1
pair and	1
: results	1
to generate	6
efficient o	1
and identified	1
too ,	1
have rerun	1
only information	1
information .	5
in learning	2
information ,	3
of semantic	5
three feature	1
cle algorithm	1
among text	1
spade 19.09	1
phrases or	1
opinion questions	1
means “subsequence-based”	1
the topic	3
own implementation	1
and bilingual	2
approach described	1
the widely	1
, ontologies	1
a dataset	1
it tractable	1
the in	1
are computed	3
dependency-based parsing	1
we see	1
collect statistics	1
including the	6
error rate	2
a document	1
in addition	7
the projectivity	1
when tested	1
acertain popularity	1
laden is	1
or flexible	2
extends previously	1
interesting to	2
non-terminals of	1
with its	3
data-driven parser	1
large-margin multi-class	1
to tree	1
efforts in	1
methodology proposed	1
to pharaoh	1
was produced	1
phrases decreases	1
13 ,	1
noisy-channel model	1
the shared	1
all dependencies	1
tree a19	2
collins lexicalized	1
we plan	3
all partitions	1
investigate many	2
and enhanced	1
three words	1
have found	1
system on	1
were kindly	1
summarization algorithm	1
system of	3
provide methods	1
on question	1
more general	2
endeavored to	1
used the	7
: //www.cs.ualberta.ca/	1
in the	21
be helpful	1
the monotone	1
only adjacent	1
of such	1
utility allows	1
are promising	1
all of	2
identifying paraphrases	1
4 evaluation	1
corpus-based qa	1
which there	1
noise .	1
also see	1
y a	1
data-driven dependency	3
cheng et	2
redundancy analysis	1
of its	2
learning lexical	1
model for	5
al we	1
out to	1
of three	1
collects in	1
r is	1
of as	1
algorithm summarization	1
not to	2
has addressed	1
ranging from	3
a polynomial	1
experiments we	1
algorithms .	3
algorithms ,	3
words occuring	1
algorithms 2	1
templates and	1
overall parsing	1
blocks in	1
trees while	1
nd that	1
a36a51a4a39a38 a33	1
97 %	1
each possible	1
resources has	1
and select	1
resulting documents	1
categorizing expressly	1
analyzing human-written	1
advantage lies	1
y .	1
y ,	1
, class-based	1
mst parsing	1
feature type	1
sampling and	1
have started	1
pharaoh performed	1
question set	1
neuhaus and	1
the subjective	1
for their	2
underperformed φh	1
similar concerns	1
on this	1
using only	3
one .	1
in accuracy	2
function we	1
nonprojective languages	1
, so	5
that ranks	1
case frames	1
expresses a	1
of additional	2
test sets	1
and wiebe	1
reduced forms	1
tokens based	1
incorporate richer	1
sufficient for	2
use an	2
answering factoid	1
the data	3
keep 3	1
introduction during	1
resulting from	1
the finite-state	1
line for	1
for sentence-level	1
both terminals	1
of previously	1
trees through	1
purpose :	1
to slowly	1
scaling up	1
an edited	1
keep a	1
typically used	1
inaccessible to	1
of <	1
considered to	1
completely monotonic	1
, toinfinitives	1
describe how	2
a tagging	1
for negative	1
been suggested	1
answering based	1
collected the	1
similar update	1
a refined	1
has encouraged	1
has helped	1
, eg	1
w·f 2note	1
or colons	1
topic-relevant concepts	1
features is	1
of several	2
all possible	1
reduction for	1
of successively	1
space of	2
modeling and	3
are handled	1
of co-selected	1
using synchronous	1
also compare	1
weakly when	1
recall n	1
table is	1
minimized in	1
by extracting	1
l where	1
450 ,	1
summarization by	1
to machine	1
text in	2
of writing	1
is flat”	1
methods reported	1
has already	2
keyword search	1
question concepts	1
can then	1
two ;	1
sparseness takes	1
also focused	2
ie .	1
5-gram ,	1
c from	1
and increase	1
best czech	1
23 single	1
signatures was	1
introduction dependency	1
independence between	1
the outsourcing	1
a search	1
we reduce	1
estimated ,	1
given by	2
in view	1
monotonic and	1
the bulk	1
feature computation	1
tend to	2
take as	1
outperform a	1
disambiguation that	1
semantics as	1
: instead	1
2 %	1
from http	1
improve the	4
rh02 :	1
2 ,	2
a standard	4
2 .	2
are given	1
method based	2
: a2	1
an experimental	1
2 :	4
extract have	1
based evaluation	1
set and	2
contexts ,	1
which forces	1
annotators with	1
all word	1
simulation of	2
maximum number	1
, edges	1
workshop held	1
statistical dependency	1
target-phrase-conditioned ,	1
re-implementation of	3
joint 3-gram	1
monotonically translated	1
model used	2
data-driven parser-generator	1
or sentences	1
report that	1
the part	1
novel kernel	1
: an	1
its head-child�	1
meaning equivalence	1
and s	1
our best	3
, swedish	1
in ravichandran	1
a maximum	1
l w	1
learning local	2
translation from	1
acquisition of	1
were added	1
hovy requires	1
by dividing	1
tested for	2
explicitly describes	1
then ,	2
hand ,	4
the history	1
fusing ,	1
fragment and	1
researchers have	5
to and	1
objective� ,	1
direction we	1
of pos	1
core while	1
system benefits	1
we rely	1
extractors ,	1
for extraction	1
these 4	1
of matching	1
sources that	1
a considerable	1
alignment as	1
relative weights	1
metric that	2
while based	1
; then	2
after annotating	1
translated to	1
to choose	1
, given	2
systems that	1
but have	1
high inter-annotator	1
discovering a	1
since most	3
and c	1
like the	2
linguistic parsing	1
, gives	1
aligned corpus	2
parsers do	1
three binary	1
model uses	3
of lexical	1
followed for	1
early-style parsers	1
formalizing syntax-based	1
unique translated	1
phrase pairs	3
a more	6
extend the	1
dependency accuracy	2
investigated the	2
projective lexicalized	1
generative parsing	1
and with	1
various feature	1
binary ,	1
an extract	1
every node	2
exhaustive processing	1
a29 a2	1
a29 a0	1
become quite	2
which collects	1
, substituting	1
phrases does	1
manually annotated	1
and by	3
search ing	1
learn phrasal	1
but ,	1
incorporated into	1
that only	2
of common	1
for evaluation	2
can learn	1
tune their	1
article .	1
c the	1
head-word lexicalized	1
wildcards .	1
small values	1
article 1	1
high-level ie	1
our syntax-based	1
results similar	1
of direct	1
trec 2003	1
nilsson ,	1
in non-editorial	1
modifiers within	1
following the	2
) as	1
large texts	1
nilsson .	1
of modifiers	1
( $	1
it for	1
words occurring	1
erjavec for	1
cooccurrences .	1
the source-channel	1
a bag-of-word	1
of concept-instance	1
of either	1
88.1 88.2	1
serve as	1
, alters	1
as nivre	1
identified morpheme	1
we retain	1
rather a	1
implement non-projectivity	1
a rouge	1
framework .	1
components for	1
al introduce	1
property in	1
two levels	2
bootstrapping method	1
mst algorithm	1
because a	1
be much	1
the tats	1
approaches as	1
2 to	1
the graph	1
that certain	1
retrieved topic	1
that include	1
implementation of	5
done for	2
information on	1
smoothing as	1
operations introduced	1
which go	1
which similarity	1
to dan	2
sentence often	1
phrase-based models	2
of items	1
difficulty learning	1
polarity ,	1
the documentation	1
nonterminal symbols	1
an 11.0	1
assuming perfect	1
the final-and�	1
models will	1
a20a102a139 a120	1
to bilingual	1
knowledge in	1
been neglected	1
for sentence	3
when caching	1
we generate	1
similar argument	1
relevant to	2
explored cutting	1
f-measure of	1
extend this	1
phrases longer	1
generally applicable	1
scan the	2
bleu points	1
helpful feature	1
facts were	1
between long	1
each differently	1
for nlp	1
to yield	1
and .	2
are commonly	1
lists ,	3
question type	1
lists .	2
in positive	1
first creating	1
semantically oriented	1
is on	1
nonterminal no	1
is chiang	1
then applies	1
that exploiting	1
when or	1
1770 1899	1
maximal marginal	1
found manually	1
, use	1
deterministic parsing	3
penn wsj	2
, wiebe	1
understanding ,	1
efficient to	1
their decodings	1
include hierarchical	2
the processing	1
web search	1
, kt	1
approaches can	1
or where	1
shown in	6
this may	1
several parsing	1
is markovization	1
the realization	1
several years	1
127 sentence	1
are ``	1
customer has	1
naturally capturing	1
attempts have	4
lauded for	1
a few	2
allows us	2
use ilp	1
bikel re-implementation	1
word pairs	1
ibm model	3
the label	1
only group	1
66 figure	1
monotonic ,	2
very useful	1
wordnet 50	1
typically supported	1
present a	2
most systems	2
to c1	1
38 our	1
of english	2
rules with	1
other languages	1
groupings by	1
correlate well	1
one root	1
of this	8
employ and	1
of word	1
the implementation	1
been reported	2
features to	5
processing ,	2
of languages	2
processing .	3
czech data	1
the summary	1
the previously	1
processing 4	1
, bethard	1
rarely seen	1
negative opinion	1
derived in	1
table 4	4
eisner and	1
the chart	1
smith for	1
we do	2
in experiments	1
important because	1
limited by	1
trees extracted	1
where different	2
humphrey bogart	1
objects 89	1
study and	1
perform parsing	1
take place	1
although semantics-poor	1
that translate	1
: n.o	1
gives pseudo-code	1
chiang where	1
become increasingly	3
mature phrase-based	1
in text	2
while error-driven	1
outputs .	1
one language	1
supervised manner	2
by understanding	1
in wordnet	2
figure 9	1
context-free deletion	1
results and	1
part-of ,	2
examples that	1
forcapturing lexical	1
reading levels	1
play dual	1
eg ,	1
alignment-template approach	1
tats extracted	1
bilingual synchronous	2
an inventory	1
the large	1
koehn ,	1
since the	2
domain and	1
spanish )	1
for instance	6
compressions compression	1
spanish ,	3
figure 1	1
algorithmic context	1
by increasing	1
various modifications	1
, redundancy	1
in line	1
figure 3	1
lowerorder polynomial	1
as they	2
figure 4	2
2.4 accelerated	1
right-to-left .	1
themselves ,	2
to get	3
themselves .	1
setting :	1
and λs	1
scripts that	1
in collins	2
decoder for	2
syntax at	1
the criterion	1
hypergraphs .	1
to remove	1
coordination and	2
and eisner	1
estimates to	1
nonterminal play	1
entailment between	2
svm with	1
accurate tools	1
with standard	1
be better	1
88.0 30.3	1
identify the	1
heuristic-based combination	1
of techniques	1
usually employing	1
was the	2
for in-coverage	1
phrase extraction	1
this finding	1
61.2 %	2
sentence combination	1
model with	4
link extension	1
much larger	1
themes of	1
primarily addressed	1
distortion and	1
also produce	1
trees to	1
each sentence	1
the compression	2
best aer	1
in context	1
< noun	1
answers a	1
are aware	1
features which	1
of parallel	2
toolkit1 ,	1
collins context-free	2
the bleu	1
ratings for	1
from these	2
metric ,	1
text :	1
learning to	1
and chiang	1
be collected	1
rule size	1
explored syntax-based	1
15 biographical	1
statistical components	1
melamed ,	1
and output	1
bt-2-step 22.06	1
these two	2
text .	4
text ,	4
single nonheadwords	1
cohesion information	1
and testing	2
general reasoning	1
extraction rules	1
be manually	1
this experiment	1
learn instances	1
non-projectivity can	1
2 related	1
shorter the	1
which any	1
pair based	1
more 6more	1
of previous	1
and predict	1
article is	1
translation process	1
second one	1
which shows	1
semantic orientation	1
person >	1
are the	2
include kappa	1
not raina	1
chapter 4	1
work as	1
bilingual units	1
full parsing	1
between nuclei	1
paper .	1
for similar	2
web or	2
to investigate	4
& johnson	1
associated to	1
collins failed	1
to contrast	1
al automatically	1
successful such	1
the art	4
include shallow	1
from word	2
word ,	2
27.17 +	1
recover non-local	1
the arc	1
training sets	3
58 our	1
right ,	1
word 's	1
our rules	1
another direction	1
, query	1
of knight	1
for predicting	2
between all	1
although the	4
inc. 1	1
of bottom-up	1
converge to	1
and pereira	1
with symmetrized	1
aligned is	1
pbmt ,	1
possible .	1
and four	2
usefulness and	1
matsumoto for	2
83 %	1
by oflazer	1
word x	1
nitions in	1
assigned to	1
performance .	2
if punctuation	1
phrasetable ,	1
schemata are	1
correlated with	1
sentence trial	1
are applied	2
comparison of	2
has relied	1
particular semantics	1
be applicable	1
extraneous phrases	2
in non-projective	1
on certain	1
many ways	1
scoring label	1
formally syntax-based	1
factorization can	1
tasks such	1
decomposed as	3
opinionated text	1
general summarization	1
labeling accuracy	1
are calculated	1
, ranging	2
inclusion precision	1
counters :	1
and mer	1
works have	3
, task-oriented	1
that t	1
topic words	1
previous state	1
in its	3
this difficulty	1
been recently	1
centroid-based extractive	1
and text	2
with high	1
all prepositional	1
cky-based decoder	1
the next-best	1
of performance	1
have not	1
3 and	1
foundation and	1
extracted at	1
there seems	2
in syntactic	3
there was	2
the wildcard	1
collins transforms	1
search through	1
binary relations	2
as the	15
extension of	3
state-of-the-art results	1
phrases per	1
with tree	1
without considering	2
an extraction	1
first feature	1
stateof-the-art parser	1
while some	1
restrict phrases	1
information that	2
a baseline	1
a third	1
data is	1
training chiang	1
text fragments	2
d times	1
permeate question	1
projection of	2
percentages of	1
units are	1
increases accuracy	1
subjectivity gains	1
an existing	1
that empirically	1
to phrase-based	2
extracted phrases	1
spanish geography	1
a linear	2
trained quickly	1
probability lower	1
state-of-the-art method	1
from wordnet	1
cient to	1
shows the	4
we employ	1
with arbitrary	1
tagging accuracy	1
reported that	1
treelets ;	1
depends on	1
their memory-based	1
recover non-projective	1
in •	1
collins for	1
techniques of	1
which words	1
transformations increases	1
devoted to	1
count ,	1
fscore reached	1
alignment .	1
and fj2j1	1
use-knowledge :	1
open question	1
summarization techniques	1
would benefit	1
other nonterminals	1
alignment 1	1
that functions	1
are selected	1
variable a	1
in statistical	5
by transforming	1
entire training	1
components such	1
, then	3
large corpora	1
, they	3
meaning similarity	1
graph is	1
are graphs	1
rules and	1
c in	1
grammar ,	1
mt .	2
mt ,	1
to study	2
were provided	1
must first	1
prove the	1
motivated or	2
size ,	1
arcs one	1
for modelling	1
is-a ,	2
question-answering patterns	1
also made	1
as ours	1
: deterministic	1
no longer	1
as being	1
sometimes a	1
feature weights	1
standard pharaoh	1
needs to	2
through wordnet	1
summarization )	1
loose notion	1
question sets	1
make the	1
the cluster	1
signatures ,	2
signatures .	1
signatures (	1
hearst while	1
parse rather	1
mihalcea and	2
with d	1
with a	10
hmm translation	1
machine translation	6
and some	1
on conditional	1
alignments from	1
work presented	2
projectivize training	1
development set	2
proposed the	1
formulas of	1
inflected forms	1
english dependency	1
subjective language	1
the restriction	1
very recently	2
the full	1
with <	1
, alma	1
statistical dependencies	2
k highest-scoring	1
important role	1
sentiment analysis	1
those features	1
f-measure is	1
research motivated	1
with ,	1
dunning and	1
forces one	1
itself rather	1
query words	1
the parameter	1
than search	1
syntax into	1
described by	5
dependency parse	1
be sufficient	1
, combining	1
ones in	1
recognition ,	2
also explored	1
tuning ,	1
approximate extension	1
dependency information	1
to compare	3
and successfully	1
we use	10
of categories	1
learning these	2
= 2.	1
authors describe	1
greater variety	1
in these	1
similarities indicated	1
publicly distributed	1
, probably	1
on inductive	2
they 19	1
to as	2
a publicly	1
complete match	1
but substantially	1
to at	1
type .	1
3 indices	1
grow-diagfinal for	1
is among	1
to an	1
history context	1
are somewhat	1
proxy for	1
has commissioned	1
of equation	1
constituents to	1
3.1 decoding	1
discussion is	1
has contiguous	1
patterns ,	1
w and	1
addition to	3
flexible model	1
4. based	1
for 1	1
i (	1
c and	1
entity coreference	1
outsourcing of	1
recent larger-scale	1
gold standard	1
translation tables	1
edit distance	1
for some	2
of coverage	2
are planning	1
, deep	1
model of	5
dependency types	2
section 23	2
sections 2	1
presenting recent	1
graphs 2.	1
the recall-based	1
in lifting	1
frequency threshold	1
determined to	1
entropy framework	1
general framework	2
which look	1
rewriting ,	1
1punctuation {	1
is monotonously	1
, lies	1
of systems	1
fashion to	1
is complex	1
complete soundness	1
are possible	1
or not	7
of sentences	3
utility relative	1
verb >	1
extract in	1
40 %	1
recent results	1
phrasebased models	1
scoring maximum	1
kt ,	1
corpus of	3
selects a	1
phrase-decoder simulation	2
is comparable	1
such transformations	1
extracting named	1
from discovering	1
our underlying	2
and pw	1
coverage of	1
bidirectionality .	1
weusethelog-likelihoodstatisticsuggested by	1
braceleftbig fp	1
a helpful	1
american jobs	1
, describe	1
and letters	1
relation .	2
a surface	1
relation ,	1
more recently	3
areas of	1
and extraction	2
: comparison	1
charniak 's	1
all edges	1
the test	3
state-of-the-art ,	1
statistical significance	1
than english	1
by och	2
enhanced topic	1
refer only	1
response to	1
includes methods	1
and location	1
text normalization	1
sentence as	1
generative models	1
's work	1
extends the	3
same summaries	1
similarity ,	2
similarity .	3
last few	1
extracted using	3
longer depends	1
translate sentences	1
id 152	1
implementation described	1
increasingly sophisticated	1
section with	1
to convey	1
two-level rules	2
of speech	2
decoding algorithms	1
not think	1
translation engine	1
considers only	1
many algorithms	1
performance reported	1
reading comprehension	1
using this	2
wassubstantially lower	1
svm ,	1
taking part	1
for generative	1
vp in	1
this distinction	1
previous results	2
have noted	1
w/ <	1
and lexical	1
decoding using	1
the task-independent	1
covers ,	1
popescu and	1
for evaluating	1
extended version	1
1 otherwise	1
to previous	2
evaluated on	1
process is	2
only .	2
that can	7
model 1	1
model 2	2
model 4	3
focuses on	2
as subjective	1
has recently	1
ofcorrect summaries	1
500 sentences	1
model ;	1
only checks	1
quantity called	1
levels of	3
specific object	1
model ,	6
model .	5
stringent constraints	1
algorithms is	1
must therefore	1
include precision	1
have investigated	1
context of	4
along with	1
phrases instead	1
for pp-attachment	1
, among	3
its shortcomings	1
93 %	1
pbm ,	1
phrases improves	1
powerful model	1
heuristic way	1
has focused	1
discussing the	1
using spanning	1
a phrase-based	3
corpora to	1
set outlined	1
﻿ )	1
the generalisation	1
problem labeled	1
harmful to	1
and br¨oker	1
in spirit	1
charniak context-free	2
extracted automatically	1
earlier version	1
goodman and	1
by rst	1
you could	1
syntactic preferences	1
granting the	1
work on	7
learn model	1
data task	1
used link	1
work of	7
by now	2
concepts that	1
soundness has	1
same development	1
% literature	1
one should	1
think it	1
dependency grammars	3
for each	7
target sides	1
schiehlen used	1
automatically identify	2
, because	2
more popular	1
: topic	1
using one	1
syntactic categories	1
chosen for	1
and take	1
of heads	1
automata package	1
punctuation as	1
not use	2
in isi	1
treebank and	1
the unsupervised	1
in isa	1
object-oriented parallel	1
set used	1
the npa	1
parser actions	1
quality .	1
these models	4
than to	1
final-and� approaches	1
we trained	3
models such	2
− ¯ak−1	1
this article	2
lies on	1
the reorderings	2
performance improvements	1
twice as	1
codification of	1
individual-preference classifier	1
tatu and	1
thatthe performance	2
framework is	2
on data-driven	3
chart equal	1
emerged as	1
derivation of	1
an open	1
anchors using	1
changing the	1
for comparison	2
reorderings of	2
modifiers with	1
used pos	1
, schiehlen	1
use constituent	2
article sentences	1
examples include	2
consists in	1
and combine	1
previously reported	1
bilexical statistics	1
worth noticing	1
identify a	2
the right	2
distance-based reordering	2
the distributional	1
evaluation toolkit	1
same problem	1
claims but	1
has evolved	2
linear model	1
tags to	1
but it	2
to search	1
like that	2
most related	1
, can	2
lp and	1
performance qa	1
scope of	2
5 semantic	1
but in	2
actual modifier	1
85.4 84.8	1
the scores	1
classification of	1
confer .	1
distance between	3
the locality	1
with many	1
passages from	1
uses only	1
categorized as	1
transduction grammars	2
montserrat civit	1
on one	1
is other	2
are learned	1
to probabilistic	1
this is	11
of other	1
and others	2
an adapted	1
1 on	1
is modeled	1
phrase-based statistical	3
qa is	1
riloff and	2
parser for	4
choosing the	2
both topic	1
reasoning as	1
while only	1
thanks to	1
experiments on	1
opinion-oriented summarization	1
, phrase-based	2
syntactic hierarchical	1
co-selection measures	1
to predict	2
meaning .	1
rouge are	1
a packed	1
compare our	3
constraints leads	1
for nding	1
parallel training	1
below we	1
to scan	2
answers )	1
matching as	1
and feature	2
similarity metrics	1
chiang uses	1
represent the	1
sourceand target-conditioned	1
logp ,	1
many research	1
taken from	2
but didn’t	1
al all	1
languages other	1
compare a	1
any given	1
state-of-the-art phrasebased	1
generally accepted	1
including two	1
the construction	2
a14a12a91 a29	1
syntax-inspired formal	1
common information	1
obvious which	1
form relation	1
relevant for	3
of two	2
summarizer is	1
to english	3
pdt dependency	1
consults a	1
of relative	1
% figure	1
mira 217	1
mine the	1
given a	2
, propose	1
method described	3
ourmethodis simpler	1
, training	1
across languages	1
preference and	1
have become	2
of opinion	1
thus there	2
then be	1
to recursively	1
the lexical-based	1
the relationship	1
by an	1
neutral regard	1
of phrase-based	2
systems employ	1
from s	1
that every	1
programming algorithm	3
base line	1
they proposed	1
algorithms to	1
two other	1
in natural	1
addressed learning	1
> substrings	1
a wealth	1
motivated in	1
's statistical	2
al dependency	1
punctuation ,	1
punctuation .	2
accurate filtering	1
relations employ	1
substantial body	1
allow reordering	1
unfortunately ,	1
value assuming	1
identified from	1
detection is	1
better value	1
punctuation :	1
mead summarizer	1
dependency-based statistical	2
until up	1
attractive alternative	1
translations ,	1
made in	1
to those	4
which have	2
on two	1
, see	4
search for	1
information extraction	3
sentences with	3
deriving a	2
translations :	1
performance measures	1
anti-clockwise in	1
still capture	2
product reviews	1
which give	1
for fine-grained	1
happen ''	1
surface phrases	1
approach by	1
87.9 %	1
an empirical	1
the following	7
considered good	2
of most	1
then those	1
from collins	1
deciding e.g	1
match scores	1
’s extracts	1
distinguish the	1
by radev	1
opinion expressions	1
on parsing	2
pre-existing set	1
very impressive	2
, identifying	1
presented here	4
distance or	1
this project	2
all substrings	1
parsing was	1
klein and	2
by translating	1
20.07 3.83	1
the language	2
distance of	1
abstracts .	1
wu .	2
matching between	1
of information	2
alignments .	2
alignment and	2
alignments ,	2
patterns has	1
also rely	1
brief pieces	1
quality as	1
alignments :	2
alignments ;	1
of 62.50	1
paragraph-long answers	1
we have	8
equation 1	1
one may	1
favourable parsing	1
with phrases	2
nivre et	1
head ,	3
head .	2
best scoring	1
human written	1
3 ,	1
projective variations	1
improvement for	1
corpora .	2
% increase	1
text data	1
to adding	1
task was	1
3 :	3
and speaker	1
allowing ,	1
best we	1
is monotonically	1
and also	3
and hovy’s	1
are expected	1
good accuracy	2
phrases in	2
binary text	1
ungrammatical mt	1
al demonstrated	1
of editing	1
bottom-up is	1
date ,	2
flat” “the	1
reasoning and	1
final output	1
phrases is	1
: chart-based	1
form representation	2
may for	1
mann ,	1
obtain varied	1
relied on	1
503 bikel	1
proposed model	1
where dominates	1
dependencies is	2
rates for	1
opinion recognition	1
inside� contents	1
calculate probabilities	1
phrases extracted	2
yield� ,	1
insufficient in	2
seed lists	1
data from	1
non-projective parsing	1
( lin	1
study ,	1
phrasedbased smt	1
pos tag	1
method is	1
generative modelling	1
called lexicalized	1
conjuncts and	1
web corpus	1
proposed by	8
for chinese	1
different training	1
a first	2
model 2.	2
much more	1
as previous	3
and extract	1
lexico-semantic information	1
unsupervised or	1
223 and	1
intervening pos	1
as in	10
multiple source	1
this table	1
the single-document	1
bootstrapping for	1
restriction would	1
an ~n~wer	1
combination described	1
models become	1
as it	2
as is	1
morphemes or	1
as hidden	1
; like	1
item is	1
used as	1
surveys )	1
documents identified	1
the variant	1
against our	2
item in	1
summary sentence	1
corpus in	1
scores under	1
phrasebased approach	1
can make	1
and most	3
the basis	3
objective and	1
and crosslanguage	1
best parse	1
and phrase	2
that make	1
allows to	1
multiparallel corpus	1
online large	1
s is	1
the basic	4
s mcdonald	1
features and	1
the now	1
145* charniak	1
competitive smt	1
alignment workshop	1
accordingly ,	1
text summarization	3
intuitive results	1
and combined	1
the prior	1
summationdisplay wh∈wh	1
of test	1
the words	4
dependent .	1
previous systems	2
beethoven humphrey	1
inthispaper ,	1
of attention	1
as that	2
to ravichandran	1
categories objective	1
statistical syntax-based	1
independent rewriting	1
model called	1
sentence or	1
c =	1
input word	1
relevant set	1
) :	1
) ;	1
which achieves	2
from the	17
questions about	1
vs. objective	1
and yamada	1
charniak collins	2
description of	1
) .	7
definition in	1
) ,	8
complete spanning	2
pre-defined sets	1
hatzivassiloglou provide	1
parallel chinese-english	1
parsing method	1
's method	1
that combines	1
fleischman and	1
al-gorithm has	1
represent globalized	1
accurate information	1
the governor–raising	1
comparing mt	1
hovy .	2
environments make	2
hovy ,	3
word co-occurrence	1
grammar and	2
extract .	1
obtained higher	1
centroids .	1
which allow	1
by raising	1
good progress	1
to extract	8
this procedure	1
the original	6
good supply	1
row labelled	1
) can	1
treebank style	1
dependencies ,	1
reducing the	1
dependencies .	3
relative improvement	1
mcdonald’s parser	2
one-to-many word	2
paper has	1
decoding instead	1
we run	1
first used	1
unigrams and	1
be improved	1
encoded in	1
the ”river	1
geographical background	1
re-implemented eisner	1
resources provided	1
gates ,	1
output .	1
previous work	7
vpp-vp has	1
establish a	1
phrase as	1
kernel kl	1
a8 a10	1
2 question	1
larger phrases	1
decoder reorder	1
1869 1770	1
hatzivassiloglou )	1
then extracted	2
since neither	1
hf the	1
the additional	1
inter-annotator agreement	1
verbs willbeconsideredsimilariftheyhavelargecommon	1
, for	7
workshop for	1
convergence towards	2
mcdonald for	1
of directed	1
charniak parsers	1
instance/concept relations	1
involve either	1
best known	1
always flushes	1
41 %	1
often assigning	1
be incorporated	1
the phraseextract	1
we examine	1
an entire	1
two stages	1
a 10.6	1
so i	1
an approximate	1
chiang and	1
settings as	1
al suggest	1
two state-of-the-art	2
to assign	1
the authors	1
non-projective dependencies	2
are comparable	1
been many	1
the wordnet	1
paraphrase detection	1
binary-branching scfg	1
co-occurrence of	1
data acquisition	1
into bilingual	1
• lex	1
domain .	1
stage .	2
them takes	1
one ,	2
for editing	1
the bitext	1
implemented a	3
the statistical	4
particular relevance	2
the word	4
representations have	2
against a	3
those .	1
patterns extracted	1
the work	9
analysis as	1
partially relevant	2
the information	3
developed for	3
extraction for	2
tree-structured translation	1
analysis has	1
86.9 unk	1
of whom	2
are typical	1
also removes	1
including machine	1
in studies	2
to train	5
more recent	2
heuristics have	1
on these	2
weights pw	1
the syntax	1
the process	1
order ,	2
results were	1
covered by	1
each candidate	1
parsing-based mt	1
we adopted	1
paper extends	1
> figure	1
to opinions	1
was proposed	5
range of	3
, lee	2
india .	1
polarity of	1
{ rsummationdisplay	1
smt aswellassequencesofwordsthatcontaingaps	1
smt is	1
by many	1
combining the	1
that work	1
smt and	2
tree t.	1
recently this	1
dependency fscore	1
penalized based	2
; research	1
employed by	1
parsers are	1
consider consecutive	1
get more	1
pharaoh implementation	1
relevance is	2
general theme	1
when trained	2
, with	8
and has	4
sparseness ,	1
, sekine	1
a quite	1
to aho	1
parsing results	1
map non-projective	1
in his	2
again ,	1
tree to	1
preferences with	1
an uninformed	1
web pages	1
approaches tackling	1
evaluation will	2
comparison impossible	1
that significantly	1
and lapata	1
form from	2
recourse to	1
objects ,	1
dependency representations	1
and learn	1
wordnet-based similarity	1
more complex	1
not incorporate	1
experimented with	2
proposed for	1
extract and	1
give this	2
`` story	1
them more	1
score of	4
syntactic parsing	2
paper are	1
learn translational	1
measures or	1
rules across	1
efforts .	1
fashion .	1
and relationships	1
distortion ,	1
between these	2
introduction of	3
modifiers .	1
models on	2
words from	2
word outside	1
conditional probability	1
distortion :	1
widely used	1
ie in	1
do this	2
probabilistic evaluation	2
argmaxe summationdisplay	1
semantically motivated	1
is taken	1
< person	1
this issue	1
them to	1
labeled with	2
and toni	1
utility-based evaluation	1
confidence values	1
detailed set	1
eisner originally	1
especially ,	1
approach followed	1
the product	2
less than	1
generate single-sentence	1
by running	1
concerning parsing	1
by girju	1
rich feature	1
hovy mine	1
valued functions	1
a14a12a94 a29	1
in this	12
extract query	1
the bilingual	2
the a54	1
this so-called	1
may not	1
chung and	1
aware of	1
by manually	1
constituents during	1
from such	1
lot of	1
model trained	2
english and	2
combine two	1
modifying subjects	1
available parsers	2
performed very	1
— full	1
introduced the	1
for using	2
constituency-based parsers	1
a long	1
own reordering-feature	2
has to	2
, this	6
a comparison	2
scheme following	1
. we	1
statistical language	2
slight modification	2
and reordering	1
the dataset	1
mart´ı for	1
shared task	2
extractors have	1
447 test	1
analyze opinion	1
strings :	1
node with	2
formally productions	1
dipl .	1
a co-occurrence	1
this study	1
document-level subjectivity	1
logic translation	1
grammar-based but	2
until we	1
only a	1
might be	4
, is-a	2
patterns from	1
maltparser by	1
consequently ,	2
event rather	1
88.8 30.9	1
in p	1
art algorithm	1
it turns	1
identified six	1
sentiment and	1
by nivre	1
performance ,	2
novel way	1
many probabilistic	2
terminals in	1
follows :	2
difficulty is	1
by making	2
2 and	1
reorder the	1
suggested applying	1
minor ,	1
chinese cheng	2
distributed with	1
4.2 tbl	1
extractive multi-document	1
features based	1
relation extraction	1
vecto related	1
kl shows	1
many-to-many word	1
role of	1
with our	1
, possible	1
for chinese-english	1
projective one	1
remove extraneous	1
195 objects	1
these nl	1
equation .	1
, possibly	1
that satisfy	1
by random	1
probabilities instead	1
recent attention	1
side .	1
which estimate	1
observed the	1
the web	3
84.8 85.1	1
we will	5
at learning	2
exploited the	2
our various	2
not obvious	1
options :	1
, large-scale	1
possible phrase	1
encouraging results	1
a binary	2
documents or	1
, root	1
identified as	1
has the	2
, fr	1
relevance of	1
standard measure	2
a33a41a40a43a42a44a33a46a45 a32	1
in parse	1
didn’t combine	1
improvements between	1
of machine	1
texts .	2
texts ,	1
much and	1
by brin	1
maltparser is	1
agreement between	1
to ef	1
highly competitive	1
adopted in	1
views :	1
n.o .	1
the longest	1
this parser	2
: simulation	2
the parametric	1
engine in	1
interestingly ,	1
maximalist model	2
varying success	2
al than	1
where yprime	1
baseline 9.70	1
should work	1
positive/negative sentiment	1
similar in	1
, etc	3
hash-table of	1
pr04 :	1
is present	1
phrasal unit	1
margin .	2
a negative	1
a simplified	1
tree whenever	1
the qa	1
of approach	1
train .	1
, statistical	1
example from	3
and koehn	1
, much	1
precision shows	1
method on	1
running a	1
and corresponds	1
method of	4
an unambiguous	1
s the	1
