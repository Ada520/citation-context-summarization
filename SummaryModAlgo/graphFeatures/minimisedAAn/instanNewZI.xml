<paper>
<cited id="ZI0">
<title id=" W11-2010.xml">giving instructions in virtual environments by corpus based selection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one is the selection approach, in which the task is to pickthe appropriate output from corpus of possible outputs.
</prevsent>
<prevsent>the other is the generation approach, in which the output is dynamically assembled using some composition procedure, e.g. grammar rules.
</prevsent>
</prevsection>
<citsent citstr=" W06-1303 ">
these lection approach to generation has only been used in conversational systems that are not task-oriented such as negotiating agents (gandhe and traum, 2007a), question answering characters (kenny et al, 2007), and virtual patients (leuski et al, 2006).<papid> W06-1303 </papid></citsent>
<aftsection>
<nextsent>to the best of our knowledge, our algorithm is the first one proposed for doing corpus based generation and interaction management for task-oriented systems.
</nextsent>
<nextsent>the advantages of corpus based generation are many.
</nextsent>
<nextsent>to start with, it affords the use of complex and human-like sentences without detailed analysis.moreover, the system may easily use recorded audio clips rather than speech synthesis and recorded video for animating virtual humans.
</nextsent>
<nextsent>finally, no 68rule writing by dialogue expert or manual annotations is needed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1">
<title id=" W11-2010.xml">giving instructions in virtual environments by corpus based selection </title>
<section> the give corpus.  </section>
<citcontext>
<prevsection>
<prevsent>finally, section 7 discusses the weaknesses of the approach for developing instruction giving agents, as well as its advantages and drawbacks with respect to hand-coded systems.
</prevsent>
<prevsent>in this last section we also discuss improvements on our algorithms designed as result of our error analysis.
</prevsent>
</prevsection>
<citsent citstr=" W10-4233 ">
the challenge on generating instructions in virtual environments (give; koller et al (2010)) <papid> W10-4233 </papid>isa shared task in which natural language generation systems must generate real-time instructions that guide user in virtual world.</citsent>
<aftsection>
<nextsent>in this paper, we use the give-2 corpus (gargett et al, 2010), freely available corpus of human instruction giving in virtual environments.
</nextsent>
<nextsent>we use the english part of the corpus which consists of 63 american english written discourses in which one subject guided an other in treasure hunting task in 3 different 3d worlds.
</nextsent>
<nextsent>the task setup involved pairs of human partners, each of whom played one of two different roles.
</nextsent>
<nextsent>the direction follower?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3">
<title id=" W11-2010.xml">giving instructions in virtual environments by corpus based selection </title>
<section> the unsupervised conversational model.  </section>
<citcontext>
<prevsection>
<prevsent>we also measured the average time until task completion, and the average number of utterances users received from each system.
</prevsent>
<prevsent>to ensure comparability, we only counted successfully completed games.in terms of task success, our system performs better than all hand-coded systems.
</prevsent>
</prevsection>
<citsent citstr=" P09-2076 ">
we duly notice that,for the give challenge in particular (and probably for human evaluations in general) the success rates in the laboratory tend to be higher than the success rate online (this is also the case for completion times) (koller et al, 2009).<papid> P09-2076 </papid></citsent>
<aftsection>
<nextsent>koller et al justify this difference by stating that the laboratory subject is being discouraged from canceling frustrating task while the online user is not.
</nextsent>
<nextsent>however, it is also possible that people canceled less because they found the interaction more natural and engaging as suggested by the results of the subjective metrics (see next section).
</nextsent>
<nextsent>in any case, our results are preliminary given the amount of subjects that we tested, but they are indeed encouraging.
</nextsent>
<nextsent>in particular, our system helped users to identify better the objects that they needed to manipulate in the virtual world, as shown by the low number of mouse actions required to complete the task (a high number indicates that the user must have manipulated wrong objects).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4">
<title id=" W11-2010.xml">giving instructions in virtual environments by corpus based selection </title>
<section> the unsupervised conversational model.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, we plan to take orientation into account during selection.
</prevsent>
<prevsent>as result of these extensions however we may need to enlarge the corpus we used so as not to increase the number of situations in which the system does not find any thing to say.
</prevsent>
</prevsection>
<citsent citstr=" W10-4329 ">
finally, if we could identify corrections automatically, as suggested in (raux and nakano,2010), <papid> W10-4329 </papid>we could get an increase in performance, be cause we would be able to treat them as corrections and not as instructions as we do now.in sum, this paper presents the first existing algorithm for fully-automatically prototyping task oriented virtual agents from corpora.</citsent>
<aftsection>
<nextsent>the generated agents are able to effectively and naturally help user complete task in virtual world by giving her/him instructions.
</nextsent>
<nextsent>2http://www.give-challenge.org/research 75
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5">
<title id=" W12-0115.xml">can machine learning algorithms improve phrase selection in hybrid machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>still, each technological paradigm seems to suffer from its own particular kinds of errors: statistical mt (smt) engines often show poor syntax, while rule-based mt systems suffer from missing data in their vocabularies.
</prevsent>
<prevsent>hybrid approaches try to overcome these typical errors by combining techniques from both (or even more) paradigms in an optimal manner.
</prevsent>
</prevsection>
<citsent citstr=" W11-2141 ">
in this paper we report on experiments with an extended version of the hybrid system we develop in our group (federmann and hunsicker, 2011; <papid> W11-2141 </papid>federmann et al, 2010).<papid> W10-1708 </papid></citsent>
<aftsection>
<nextsent>we take the output from an rbmt engine as translation template?
</nextsent>
<nextsent>for our hybrid translations and substitute noun phrases1 by translations from one or several mt engines2.
</nextsent>
<nextsent>even though general increase in quality could be observed in previous work, our system introduced errors of its own during the substitution process.
</nextsent>
<nextsent>in an internal error analysis, these degradations could be classified in the following way: - external translations were incorrect; - the structure degraded through substitution; - phrase substitution failed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI6">
<title id=" W12-0115.xml">can machine learning algorithms improve phrase selection in hybrid machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>still, each technological paradigm seems to suffer from its own particular kinds of errors: statistical mt (smt) engines often show poor syntax, while rule-based mt systems suffer from missing data in their vocabularies.
</prevsent>
<prevsent>hybrid approaches try to overcome these typical errors by combining techniques from both (or even more) paradigms in an optimal manner.
</prevsent>
</prevsection>
<citsent citstr=" W10-1708 ">
in this paper we report on experiments with an extended version of the hybrid system we develop in our group (federmann and hunsicker, 2011; <papid> W11-2141 </papid>federmann et al, 2010).<papid> W10-1708 </papid></citsent>
<aftsection>
<nextsent>we take the output from an rbmt engine as translation template?
</nextsent>
<nextsent>for our hybrid translations and substitute noun phrases1 by translations from one or several mt engines2.
</nextsent>
<nextsent>even though general increase in quality could be observed in previous work, our system introduced errors of its own during the substitution process.
</nextsent>
<nextsent>in an internal error analysis, these degradations could be classified in the following way: - external translations were incorrect; - the structure degraded through substitution; - phrase substitution failed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI7">
<title id=" W12-0115.xml">can machine learning algorithms improve phrase selection in hybrid machine translation </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>our experiments with the classifier-based, hybrid mt system are reported in section 4.
</prevsent>
<prevsent>we conclude by giving summary of our work and then provide an outlook to related future work in section 5.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
our hybrid machine translation system combines translation output from: a) the lucy rbmt system, described in more detail in (alonso and thurmair, 2003), and b) one or several other mt systems, e.g. moses (koehn et al, 2007), <papid> P07-2045 </papid>or joshua (li et al., 2009).<papid> W09-0424 </papid></citsent>
<aftsection>
<nextsent>the rule-based component of our hybrid system is described in more detail in section 2.2 while we provide more detailed information on the other?
</nextsent>
<nextsent>systems in section 2.3.
</nextsent>
<nextsent>2.1 basic approach.
</nextsent>
<nextsent>we first identify noun phrases inside the rule based translation and compute the most probable correspondences in the translation output from the other systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI8">
<title id=" W12-0115.xml">can machine learning algorithms improve phrase selection in hybrid machine translation </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>our experiments with the classifier-based, hybrid mt system are reported in section 4.
</prevsent>
<prevsent>we conclude by giving summary of our work and then provide an outlook to related future work in section 5.
</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
our hybrid machine translation system combines translation output from: a) the lucy rbmt system, described in more detail in (alonso and thurmair, 2003), and b) one or several other mt systems, e.g. moses (koehn et al, 2007), <papid> P07-2045 </papid>or joshua (li et al., 2009).<papid> W09-0424 </papid></citsent>
<aftsection>
<nextsent>the rule-based component of our hybrid system is described in more detail in section 2.2 while we provide more detailed information on the other?
</nextsent>
<nextsent>systems in section 2.3.
</nextsent>
<nextsent>2.1 basic approach.
</nextsent>
<nextsent>we first identify noun phrases inside the rule based translation and compute the most probable correspondences in the translation output from the other systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI9">
<title id=" W12-0115.xml">can machine learning algorithms improve phrase selection in hybrid machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>using the annotated dataset, we then trained adecision tree and integrated it into our hybrid system.
</prevsent>
<prevsent>to evaluate translation quality, we created translations of the wmt12 newstest2012?
</prevsent>
</prevsection>
<citsent citstr=" W11-2134 ">
test set, for the language pair english german, witha) baseline hybrid system using hand-crafted decision rules and b) an extended version of our hybrid system using the decision tree.both hybrid systems relied on lucy translation template and were given additional translation candidates from another rule-based system (aleksic and thurmair, 2011), <papid> W11-2134 </papid>statistical system based on the moses decoder, and statistical system based on joshua.</citsent>
<aftsection>
<nextsent>if more than onegood?
</nextsent>
<nextsent>translation was found, we used the handcrafted rules to determine the single, winning translation candidate (implementing select best in the simplest, possible way).table 2 shows results for our two hybrid system variants as well as for the individual base line systems.
</nextsent>
<nextsent>we report results from automatic bleu (papineni et al, 2001) scoring and also from its case-sensitive variant, bleu-cased.
</nextsent>
<nextsent>4.3 discussion of results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI10">
<title id=" W11-1908.xml">multi metric optimization for coreference the unitn  iitp  essex submission to the 2011 conll shared task </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W11-1901 ">
because there is no generally accepted metric for measuring the performance of anaphora resolution systems, combination of metrics was proposed to evaluate submissions to the 2011 conll shared task (pradhan etal., 2011).<papid> W11-1901 </papid></citsent>
<aftsection>
<nextsent>we investigate therefore multi objective function optimization (moo) techniques based on genetic algorithms to optimize models according to multiple metrics simultaneously.
</nextsent>
<nextsent>many evaluation metrics have been proposed for anaphora resolution (vilain et al, 1995; <papid> M95-1005 </papid>bagga and baldwin, 1998; doddington et al, 2000; luo, 2005; <papid> H05-1004 </papid>recasens and hovy, 2011).</nextsent>
<nextsent>each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of hlt, nonehas really taken over.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI11">
<title id=" W11-1908.xml">multi metric optimization for coreference the unitn  iitp  essex submission to the 2011 conll shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>because there is no generally accepted metric for measuring the performance of anaphora resolution systems, combination of metrics was proposed to evaluate submissions to the 2011 conll shared task (pradhan etal., 2011).<papid> W11-1901 </papid></prevsent>
<prevsent>we investigate therefore multi objective function optimization (moo) techniques based on genetic algorithms to optimize models according to multiple metrics si multaneously.</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
many evaluation metrics have been proposed for anaphora resolution (vilain et al, 1995; <papid> M95-1005 </papid>bagga and baldwin, 1998; doddington et al, 2000; luo, 2005; <papid> H05-1004 </papid>recasens and hovy, 2011).</citsent>
<aftsection>
<nextsent>each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of hlt, nonehas really taken over.
</nextsent>
<nextsent>this makes it difficult to compare systems, as dramatically demonstrated by the results of the coreference task at semeval 2010 (recasens et al, 2010).<papid> S10-1001 </papid></nextsent>
<nextsent>it was therefore wise of the conll organizers to use basket of metrics to assess performance instead of single one.this situation suggests using methods to optimize systems according to more than one metric at once.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI12">
<title id=" W11-1908.xml">multi metric optimization for coreference the unitn  iitp  essex submission to the 2011 conll shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>because there is no generally accepted metric for measuring the performance of anaphora resolution systems, combination of metrics was proposed to evaluate submissions to the 2011 conll shared task (pradhan etal., 2011).<papid> W11-1901 </papid></prevsent>
<prevsent>we investigate therefore multi objective function optimization (moo) techniques based on genetic algorithms to optimize models according to multiple metrics si multaneously.</prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
many evaluation metrics have been proposed for anaphora resolution (vilain et al, 1995; <papid> M95-1005 </papid>bagga and baldwin, 1998; doddington et al, 2000; luo, 2005; <papid> H05-1004 </papid>recasens and hovy, 2011).</citsent>
<aftsection>
<nextsent>each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of hlt, nonehas really taken over.
</nextsent>
<nextsent>this makes it difficult to compare systems, as dramatically demonstrated by the results of the coreference task at semeval 2010 (recasens et al, 2010).<papid> S10-1001 </papid></nextsent>
<nextsent>it was therefore wise of the conll organizers to use basket of metrics to assess performance instead of single one.this situation suggests using methods to optimize systems according to more than one metric at once.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI13">
<title id=" W11-1908.xml">multi metric optimization for coreference the unitn  iitp  essex submission to the 2011 conll shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>many evaluation metrics have been proposed for anaphora resolution (vilain et al, 1995; <papid> M95-1005 </papid>bagga and baldwin, 1998; doddington et al, 2000; luo, 2005; <papid> H05-1004 </papid>recasens and hovy, 2011).</prevsent>
<prevsent>each of these metrics seems to capture some genuine intuition about the the task, so that, unlike in other areas of hlt, nonehas really taken over.</prevsent>
</prevsection>
<citsent citstr=" S10-1001 ">
this makes it difficult to compare systems, as dramatically demonstrated by the results of the coreference task at semeval 2010 (recasens et al, 2010).<papid> S10-1001 </papid></citsent>
<aftsection>
<nextsent>it was therefore wise of the conll organizers to use basket of metrics to assess performance instead of single one.this situation suggests using methods to optimize systems according to more than one metric at once.
</nextsent>
<nextsent>and as it happens, techniques for doing just that have been developed in the area of genetic algorithmsso-called multi-objective optimization techniques (moo) (deb, 2001).
</nextsent>
<nextsent>the key idea of our submission is to use moo technique sto optimize our anaphora resolution system according to three metrics simultaneously: the muc scorer (a member of what one might call the link-basedcluster of metrics) and the two ceaf metrics (representative of the entity-based?
</nextsent>
<nextsent>cluster).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI14">
<title id=" W11-1908.xml">multi metric optimization for coreference the unitn  iitp  essex submission to the 2011 conll shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>cluster).
</prevsent>
<prevsent>in previous study (saha et al, 2011), we show that our moo-based approach yields more robust results than single-objective optimization.we test two types of optimization: feature selection and architecture whether to learn single model for all types of anaphors, or to learn separate models for pronouns and for other nominals.
</prevsent>
</prevsection>
<citsent citstr=" L08-1328 ">
we also discuss how the default mention extraction techniques of the system we used for this submission, bart (versley et al, 2008), <papid> L08-1328 </papid>were modified to handle the all-mention annotation in the ontonotes corpus.in this paper, we first briefly provide some back ground on optimization for anaphora resolution, on genetic algorithms, and on the method for multi objective optimization we used, non-dominatedsorting genetic algorithm ii (deb et al, 2002).</citsent>
<aftsection>
<nextsent>after that we discuss our experiments, and present our results.
</nextsent>
<nextsent>2.1 optimization for anaphora resolution.
</nextsent>
<nextsent>there have only been few attempts at optimization for anaphora resolution, and with few exceptions, this was done by hand.the first systematic attempt at automatic optimization of anaphora resolution we are aware of was carried out by hoste (2005), who used genetic algorithms for automatic optimization of both feature selection and of learning parameters, also considering 61 two different machine learners, timbl and ripper.her results suggest that such techniques yield improvements on the muc-6/7 datasets.
</nextsent>
<nextsent>recasens and hovy (2009) carried out an investigation of feature selection for spanish using the ancora corpus.a form of multi-objective optimization was applied to coreference by munson et al (2005).<papid> H05-1068 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI16">
<title id=" W11-1908.xml">multi metric optimization for coreference the unitn  iitp  essex submission to the 2011 conll shared task </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 optimization for anaphora resolution.
</prevsent>
<prevsent>there have only been few attempts at optimization for anaphora resolution, and with few exceptions, this was done by hand.the first systematic attempt at automatic optimization of anaphora resolution we are aware of was carried out by hoste (2005), who used genetic algorithms for automatic optimization of both feature selection and of learning parameters, also considering 61 two different machine learners, timbl and ripper.her results suggest that such techniques yield improvements on the muc-6/7 datasets.
</prevsent>
</prevsection>
<citsent citstr=" H05-1068 ">
recasens and hovy (2009) carried out an investigation of feature selection for spanish using the ancora corpus.a form of multi-objective optimization was applied to coreference by munson et al (2005).<papid> H05-1068 </papid></citsent>
<aftsection>
<nextsent>munson et al (2005) <papid> H05-1068 </papid>did not propose to train models soas to simultaneously optimize according to multiple metrics; instead, they used ensemble selection to learn to choose among previously trained models thebest model for each example.</nextsent>
<nextsent>their general conclusion was negative, stating that ensemble selection seems too unreliable for use in nlp?, but they did see some improvements for coreference.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI20">
<title id=" W11-1908.xml">multi metric optimization for coreference the unitn  iitp  essex submission to the 2011 conll shared task </title>
<section> using moo for optimization in.  </section>
<citcontext>
<prevsection>
<prevsent>we considered 42 features, including 7 classifying mention type, 8for string matching of different subparts and different levels of exactness, 2 for alia sing, 4 for agreement, 12 for syntactic information including also binding constraints, 3 encoding salience, 1 encoding patterns extracted from the web, 3 for proximity,and 2 for 1st and 2nd person pronouns.
</prevsent>
<prevsent>again be cause of time considerations, we used decision trees as implemented in weka as our classification model instead of maximum-entropy or svms.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
finally, we used simple mention-pair model without ranking as in (soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>62 3.2 mention detection.
</nextsent>
<nextsent>bart supports several solutions to the mention detection (md) task.
</nextsent>
<nextsent>the users can input pre computed mentions, thus, experimenting with gold boundaries or system boundaries computed by external modules (e.g., carafe).
</nextsent>
<nextsent>bart also has built-in mention extraction module, computing boundaries heuristic ally from the output of parser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI21">
<title id=" W11-1908.xml">multi metric optimization for coreference the unitn  iitp  essex submission to the 2011 conll shared task </title>
<section> using moo for optimization in.  </section>
<citcontext>
<prevsection>
<prevsent>the process of mention detection involves two steps.
</prevsent>
<prevsent>first, we create list of candidate mentions by merging basic np chunks with named entities.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
np chunks are computed from the parse trees provided in the conll distribution, named entities are extracted with the stanford ner tool (finkel et al,2005).<papid> P05-1045 </papid></citsent>
<aftsection>
<nextsent>for each candidate mention, we store it minimal and maximal span.
</nextsent>
<nextsent>the former is used for computing feature values (e.g., for string matching); it corresponds to either the basic np chunk or the ne, depending on the mention type.
</nextsent>
<nextsent>the latter is used for alignment with conll mentions; it is computed by climbing up the parse tree.
</nextsent>
<nextsent>this procedure, combined with the perfect (gold) coreference resolution, gives us an f-score of 91.56% for the mention detection task on the conll development set1.at the second step, we aim at discarding mentions that are unlikely to participate in coreference chains.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI25">
<title id=" W11-1908.xml">multi metric optimization for coreference the unitn  iitp  essex submission to the 2011 conll shared task </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>we have collected sets of chromosomes for each sub-sample and evaluated them on the whole train/development set, picking the solution with the highest final2 score for our conll submission.
</prevsent>
<prevsent>4.1 development set.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
table 1 compares the performance level obtained using all the features with that of loose re implementations of the systems proposed by soon et al (2001) <papid> J01-4004 </papid>and ng and cardie (2002),<papid> P02-1014 </papid>commonly used as baselines.</citsent>
<aftsection>
<nextsent>our re implementation of the ng &amp; cardie model uses only subset of features.
</nextsent>
<nextsent>the results in table 1 show that our system witha rich feature set does not outperform simpler baselines (and, in fact, yields poorer results).
</nextsent>
<nextsent>a similar trend has been observed by ng and cardie (2002),<papid> P02-1014 </papid>where the improvement was only possible after manual feature selection.</nextsent>
<nextsent>the last line of table 1 shows the performance level of the best chromosome found through the moo technique.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI31">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>local emergency response services were inoperable, but 70-80% of cell-towers were quickly restored.
</prevsent>
<prevsent>with 83% of men and 67% of women possessing cell phones, the nation remained largely connected.
</prevsent>
</prevsection>
<citsent citstr=" W11-0309 ">
people within haiti were texting, calling, and interacting with social media, primarily in haitian kreyo`l (munro, 2011).<papid> W11-0309 </papid></citsent>
<aftsection>
<nextsent>yet, most of the aid that was being delivered to the country ? initially,soley by the american military ? was being delivered by groups that did not communicate in kreyo`l.it was the first time that the world has seen large scale sudden onset crisis in region with productive digital communications in an under-resourced language, but it certainly will not be the last.we strongly believe that mt is an important technology to facilitate communication in crisis situations, crucially since it can make content in language spoken or written by local population accessible to those that do not know the language, in particular aid agencies.
</nextsent>
<nextsent>multiple groups saw mt as grand challenge in the haitian crisis, and theyset to work to make mt available as soon as possible after the crisis.
</nextsent>
<nextsent>within two weeks of the crisis, the first two mt engines were built and were available to those who needed them.
</nextsent>
<nextsent>we believe that we can make mt available just as quickly in future crises, and, with the right preparation, tightly integrate mt into the communication infrastructure that is deployed (e.g., the text messaging infrastructure).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI32">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>partly, this is due to the growth of the web, which has proven to be surpisingly diverse multi-lingual resource.
</prevsent>
<prevsent>but it also stems crucially from work that had been done in the past on kreyo`l, specifically, the work that was done in the diplomat and nespole!
</prevsent>
</prevsection>
<citsent citstr=" W97-0409 ">
projects at cmu (frederking et al, 1997).<papid> W97-0409 </papid></citsent>
<aftsection>
<nextsent>it was possible to assemble reasonable sample of data for the language in very short order (i.e., days).
</nextsent>
<nextsent>further, since the language itself is fairly reduced morphologically, it is an easier target for smt.
</nextsent>
<nextsent>in contrast, if one were to sample language at random from the set of the 7,000 languages spoken on the earth, one ismore likely to find language that is morphologically richer (e.g., fus ional, aggutinating, polysyn thetic).
</nextsent>
<nextsent>morphological richness compounds the datasparsity problem, reducing the quality of the resulting smt engines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI33">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>repairing and evaluation ? in this scenario, the crowd would be used to repair data that is obviously noisy, evaluate problems with particular data points, or even make simple determinations as to whether the data in question is actually in the lan guage(s) of interest or too noisy to use.
</prevsent>
<prevsent>translating content, generating new data given crowd sourced, micro-tasking platforms such as amazons mechanical turk and crowd flower, one can now easily tapthe crowd to generate new data.
</prevsent>
</prevsection>
<citsent citstr=" P11-1122 ">
the major challenge will be identifying if speakers of the target language(s) are available on the desired platform, and if not, if they could be motivated to particpate.10 likewise, infrastructure and resources will be needed to evaluate the quality of the resulting translations (zaidan and callison burch, 2011).<papid> P11-1122 </papid></citsent>
<aftsection>
<nextsent>active crowd translation ? this method combines active learning with crowdsourcing for annotation of parallel data incomparable resources, and can be used to increase the amount of data that isfound (ambati et al, 2011).<papid> W11-1210 </papid></nextsent>
<nextsent>active learning might be applicable to other crowdsourcing tasks as well, such as being used in crowdsourcing for translating content or repairing translated content.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI34">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>translating content, generating new data given crowd sourced, micro-tasking platforms such as amazons mechanical turk and crowd flower, one can now easily tapthe crowd to generate new data.
</prevsent>
<prevsent>the major challenge will be identifying if speakers of the target language(s) are available on the desired platform, and if not, if they could be motivated to particpate.10 likewise, infrastructure and resources will be needed to evaluate the quality of the resulting translations (zaidan and callison burch, 2011).<papid> P11-1122 </papid></prevsent>
</prevsection>
<citsent citstr=" W11-1210 ">
active crowd translation ? this method combines active learning with crowdsourcing for annotation of parallel data incomparable resources, and can be used to increase the amount of data that isfound (ambati et al, 2011).<papid> W11-1210 </papid></citsent>
<aftsection>
<nextsent>active learning might be applicable to other crowdsourcing tasks as well, such as being used in crowdsourcing for translating content or repairing translated content.
</nextsent>
<nextsent>tapping non-traditional sources ? critical to traditional approaches of smt is parallel training data.
</nextsent>
<nextsent>parallel data is difficult to impossible to come by for large number of the worlds 10based on the results of an informal survey, there may be speakers of hundred or more languages on mechanical turk.
</nextsent>
<nextsent>see http://www.junglelightspeed.com/amt language/ for list of the languages that may be available on turk.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI35">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>505 languages.
</prevsent>
<prevsent>tapping non-traditional sources ofdata can help increase the supply of ever valuable training data for language:?
</prevsent>
</prevsection>
<citsent citstr=" E09-1091 ">
mining comparable sources of data ? mining comparable data for parallel data hasa long history, including mining comparable sources for named entities (udupa etal., 2009; <papid> E09-1091 </papid>irvine et al, 2010; hewavitharana and vogel, 2008; hewavitharana and vogel, 2011), <papid> W11-1209 </papid>mining wikipedia for parallel content, including sentences (smith et al., 2010), <papid> N10-1063 </papid>and many more too numerous to list.</citsent>
<aftsection>
<nextsent>there is always room for improvement and hybridization in this space, as well as tapping additional sources of data, such as the volumes of noisy comparable data on the web.?
</nextsent>
<nextsent>monolingual ? more recent work has focused on mining monolingual sources ofdata, treating mt as decipher ment problem (ravi and knight, 2011), <papid> P11-1002 </papid>rather than source-target mapping problem.?</nextsent>
<nextsent>dictionary bootstraps and back offs ? despite the absence of context, dictionaries can be useful, especially for resolving out-of-vocabulary items (oovs).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI36">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>505 languages.
</prevsent>
<prevsent>tapping non-traditional sources ofdata can help increase the supply of ever valuable training data for language:?
</prevsent>
</prevsection>
<citsent citstr=" W11-1209 ">
mining comparable sources of data ? mining comparable data for parallel data hasa long history, including mining comparable sources for named entities (udupa etal., 2009; <papid> E09-1091 </papid>irvine et al, 2010; hewavitharana and vogel, 2008; hewavitharana and vogel, 2011), <papid> W11-1209 </papid>mining wikipedia for parallel content, including sentences (smith et al., 2010), <papid> N10-1063 </papid>and many more too numerous to list.</citsent>
<aftsection>
<nextsent>there is always room for improvement and hybridization in this space, as well as tapping additional sources of data, such as the volumes of noisy comparable data on the web.?
</nextsent>
<nextsent>monolingual ? more recent work has focused on mining monolingual sources ofdata, treating mt as decipher ment problem (ravi and knight, 2011), <papid> P11-1002 </papid>rather than source-target mapping problem.?</nextsent>
<nextsent>dictionary bootstraps and back offs ? despite the absence of context, dictionaries can be useful, especially for resolving out-of-vocabulary items (oovs).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI37">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>505 languages.
</prevsent>
<prevsent>tapping non-traditional sources ofdata can help increase the supply of ever valuable training data for language:?
</prevsent>
</prevsection>
<citsent citstr=" N10-1063 ">
mining comparable sources of data ? mining comparable data for parallel data hasa long history, including mining comparable sources for named entities (udupa etal., 2009; <papid> E09-1091 </papid>irvine et al, 2010; hewavitharana and vogel, 2008; hewavitharana and vogel, 2011), <papid> W11-1209 </papid>mining wikipedia for parallel content, including sentences (smith et al., 2010), <papid> N10-1063 </papid>and many more too numerous to list.</citsent>
<aftsection>
<nextsent>there is always room for improvement and hybridization in this space, as well as tapping additional sources of data, such as the volumes of noisy comparable data on the web.?
</nextsent>
<nextsent>monolingual ? more recent work has focused on mining monolingual sources ofdata, treating mt as decipher ment problem (ravi and knight, 2011), <papid> P11-1002 </papid>rather than source-target mapping problem.?</nextsent>
<nextsent>dictionary bootstraps and back offs ? despite the absence of context, dictionaries can be useful, especially for resolving out-of-vocabulary items (oovs).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI38">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>mining comparable sources of data ? mining comparable data for parallel data hasa long history, including mining comparable sources for named entities (udupa etal., 2009; <papid> E09-1091 </papid>irvine et al, 2010; hewavitharana and vogel, 2008; hewavitharana and vogel, 2011), <papid> W11-1209 </papid>mining wikipedia for parallel content, including sentences (smith et al., 2010), <papid> N10-1063 </papid>and many more too numerous to list.</prevsent>
<prevsent>there is always room for improvement and hybridization in this space, as well as tapping additional sources of data, such as the volumes of noisy comparable data on the web.?</prevsent>
</prevsection>
<citsent citstr=" P11-1002 ">
monolingual ? more recent work has focused on mining monolingual sources ofdata, treating mt as decipher ment problem (ravi and knight, 2011), <papid> P11-1002 </papid>rather than source-target mapping problem.?</citsent>
<aftsection>
<nextsent>dictionary bootstraps and back offs ? despite the absence of context, dictionaries can be useful, especially for resolving out-of-vocabulary items (oovs).
</nextsent>
<nextsent>many bilingual dictionaries also contain example sentences, which can be harvested and used in training.?
</nextsent>
<nextsent>field data from linguists ? given that linguists have variously studied large percentage of the worlds languages, tapping the supply of data that they have accumulated could prove quite fruitful.
</nextsent>
<nextsent>some recent work tapping annotated bitexts (atthis time, for over 1,200 languages) produced by linguists may prove useful in the future (lewis and xia, 2010), if for nothing more than to provide information about linguistic structure (e.g., morphological complexity or divergences, potential distortion rates, and structural divergence (a la fox (2002))).<papid> W02-1039 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI39">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>many bilingual dictionaries also contain example sentences, which can be harvested and used in training.?
</prevsent>
<prevsent>field data from linguists ? given that linguists have variously studied large percentage of the worlds languages, tapping the supply of data that they have accumulated could prove quite fruitful.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
some recent work tapping annotated bitexts (atthis time, for over 1,200 languages) produced by linguists may prove useful in the future (lewis and xia, 2010), if for nothing more than to provide information about linguistic structure (e.g., morphological complexity or divergences, potential distortion rates, and structural divergence (a la fox (2002))).<papid> W02-1039 </papid></citsent>
<aftsection>
<nextsent>engaging with the documentary linguistic community and providing tools to facilitate the collection of data might produce additional data, especially data where alignment is assisted through human input (monson et al., 2008).<papid> L08-1581 </papid></nextsent>
<nextsent>novel ways of countering data sparsity ? systematizing data cleaning heuristics undoubtedly, the same kinds of filtration and data cleaning heuristics used for kreyo`l could prove useful for speeding up the processing of data for new languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI40">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>field data from linguists ? given that linguists have variously studied large percentage of the worlds languages, tapping the supply of data that they have accumulated could prove quite fruitful.
</prevsent>
<prevsent>some recent work tapping annotated bitexts (atthis time, for over 1,200 languages) produced by linguists may prove useful in the future (lewis and xia, 2010), if for nothing more than to provide information about linguistic structure (e.g., morphological complexity or divergences, potential distortion rates, and structural divergence (a la fox (2002))).<papid> W02-1039 </papid></prevsent>
</prevsection>
<citsent citstr=" L08-1581 ">
engaging with the documentary linguistic community and providing tools to facilitate the collection of data might produce additional data, especially data where alignment is assisted through human input (monson et al., 2008).<papid> L08-1581 </papid></citsent>
<aftsection>
<nextsent>novel ways of countering data sparsity ? systematizing data cleaning heuristics undoubtedly, the same kinds of filtration and data cleaning heuristics used for kreyo`l could prove useful for speeding up the processing of data for new languages.
</nextsent>
<nextsent>applying machine learning techniques to data filtration and data cleaning could aid and generalize the process, thus decreasing overall latency from acquisition to training.
</nextsent>
<nextsent>strategies to make the source look more like the target (or vice versa) ? corollary to data sparsity is faulty word alignment, where low frequency words fail to get good alignments because there is not enough data to reinforce fairly weak hypotheses, or where source-target distortion is high.
</nextsent>
<nextsent>both problems disfavor what alignments do exist.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI41">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>both problems disfavor what alignments do exist.
</prevsent>
<prevsent>if the source and target are reordered so that one side more closely matches the other, or one side is enriched?
</prevsent>
</prevsection>
<citsent citstr=" P10-1047 ">
to be more like the other, one can reduce distortion related effects, and might also counter the large number of forms in morphologically rich languages(e.g., (yeniterzi and oflazer, 2010; <papid> P10-1047 </papid>gen zel, 2010), <papid> C10-1043 </papid>and many others).</citsent>
<aftsection>
<nextsent>strategies to systematically deal with complex morphology ? this is one on-going area of research that could still net large returns, since, even with some relatively high-data languages, such as finnish, data is made sparser due to the multiplication of possible forms.
</nextsent>
<nextsent>there is too long literature to really do justice here, butsome recent work includes discrimitative lexicons (jeong et al, 2010), sub-word alignment strategies (bodrumlu et al, 2009), <papid> W09-1804 </papid>learning the morphological variants in language (oflazerand el-kahlout, 2007), using off-the-shelf morphological tools, e.g., morfessor 11, etc. ? use syntax or linguistic knowledge in the translation task ? by reducing the hypothesis space for possible alignments, syntax-based 11http://www.cis.hut.fi/projects/morpho/ 506approaches can do better in lower-data situations and can handle source-target discontinuities better than straight phrase-based systems (e.g., (quirk and menezes, 2006; li et al, 2010)).<papid> W10-1718 </papid></nextsent>
<nextsent>7 the mt crisis cookbook.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI42">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>both problems disfavor what alignments do exist.
</prevsent>
<prevsent>if the source and target are reordered so that one side more closely matches the other, or one side is enriched?
</prevsent>
</prevsection>
<citsent citstr=" C10-1043 ">
to be more like the other, one can reduce distortion related effects, and might also counter the large number of forms in morphologically rich languages(e.g., (yeniterzi and oflazer, 2010; <papid> P10-1047 </papid>gen zel, 2010), <papid> C10-1043 </papid>and many others).</citsent>
<aftsection>
<nextsent>strategies to systematically deal with complex morphology ? this is one on-going area of research that could still net large returns, since, even with some relatively high-data languages, such as finnish, data is made sparser due to the multiplication of possible forms.
</nextsent>
<nextsent>there is too long literature to really do justice here, butsome recent work includes discrimitative lexicons (jeong et al, 2010), sub-word alignment strategies (bodrumlu et al, 2009), <papid> W09-1804 </papid>learning the morphological variants in language (oflazerand el-kahlout, 2007), using off-the-shelf morphological tools, e.g., morfessor 11, etc. ? use syntax or linguistic knowledge in the translation task ? by reducing the hypothesis space for possible alignments, syntax-based 11http://www.cis.hut.fi/projects/morpho/ 506approaches can do better in lower-data situations and can handle source-target discontinuities better than straight phrase-based systems (e.g., (quirk and menezes, 2006; li et al, 2010)).<papid> W10-1718 </papid></nextsent>
<nextsent>7 the mt crisis cookbook.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI43">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>to be more like the other, one can reduce distortion related effects, and might also counter the large number of forms in morphologically rich languages(e.g., (yeniterzi and oflazer, 2010; <papid> P10-1047 </papid>gen zel, 2010), <papid> C10-1043 </papid>and many others).</prevsent>
<prevsent>strategies to systematically deal with complex morphology ? this is one on-going area of research that could still net large returns, since, even with some relatively high-data languages, such as finnish, data is made sparser due to the multiplication of possible forms.</prevsent>
</prevsection>
<citsent citstr=" W09-1804 ">
there is too long literature to really do justice here, butsome recent work includes discrimitative lexicons (jeong et al, 2010), sub-word alignment strategies (bodrumlu et al, 2009), <papid> W09-1804 </papid>learning the morphological variants in language (oflazerand el-kahlout, 2007), using off-the-shelf morphological tools, e.g., morfessor 11, etc. ? use syntax or linguistic knowledge in the translation task ? by reducing the hypothesis space for possible alignments, syntax-based 11http://www.cis.hut.fi/projects/morpho/ 506approaches can do better in lower-data situations and can handle source-target discontinuities better than straight phrase-based systems (e.g., (quirk and menezes, 2006; li et al, 2010)).<papid> W10-1718 </papid></citsent>
<aftsection>
<nextsent>7 the mt crisis cookbook.
</nextsent>
<nextsent>given the relatively narrow domain context of crisis mtgenerally the needed vocabulary and data should be centered on relief work, medical interactions, and communicating with the affected population sit may be possible to approach crisis mt as we would mt for any domain (e.g., news, government, etc.).
</nextsent>
<nextsent>with enough data relevant to particular domain or sub-domain (e.g., earthquake, tsunami, nuclear disaster, flooding, etc.), it wouldbe possible to build the relevant translation memories (tms) and train highly domain-specific mt engines to produce translations of reasonable quality and utility.
</nextsent>
<nextsent>even with highly inflected languages, domain-specific approach may get around many of the data sparsity issues.it is also crucial that no data be thrown out.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI44">
<title id=" W11-2164.xml">crisis mt developing a cookbook for mt in crisis situations </title>
<section> mission 4636.  </section>
<citcontext>
<prevsection>
<prevsent>to be more like the other, one can reduce distortion related effects, and might also counter the large number of forms in morphologically rich languages(e.g., (yeniterzi and oflazer, 2010; <papid> P10-1047 </papid>gen zel, 2010), <papid> C10-1043 </papid>and many others).</prevsent>
<prevsent>strategies to systematically deal with complex morphology ? this is one on-going area of research that could still net large returns, since, even with some relatively high-data languages, such as finnish, data is made sparser due to the multiplication of possible forms.</prevsent>
</prevsection>
<citsent citstr=" W10-1718 ">
there is too long literature to really do justice here, butsome recent work includes discrimitative lexicons (jeong et al, 2010), sub-word alignment strategies (bodrumlu et al, 2009), <papid> W09-1804 </papid>learning the morphological variants in language (oflazerand el-kahlout, 2007), using off-the-shelf morphological tools, e.g., morfessor 11, etc. ? use syntax or linguistic knowledge in the translation task ? by reducing the hypothesis space for possible alignments, syntax-based 11http://www.cis.hut.fi/projects/morpho/ 506approaches can do better in lower-data situations and can handle source-target discontinuities better than straight phrase-based systems (e.g., (quirk and menezes, 2006; li et al, 2010)).<papid> W10-1718 </papid></citsent>
<aftsection>
<nextsent>7 the mt crisis cookbook.
</nextsent>
<nextsent>given the relatively narrow domain context of crisis mtgenerally the needed vocabulary and data should be centered on relief work, medical interactions, and communicating with the affected population sit may be possible to approach crisis mt as we would mt for any domain (e.g., news, government, etc.).
</nextsent>
<nextsent>with enough data relevant to particular domain or sub-domain (e.g., earthquake, tsunami, nuclear disaster, flooding, etc.), it wouldbe possible to build the relevant translation memories (tms) and train highly domain-specific mt engines to produce translations of reasonable quality and utility.
</nextsent>
<nextsent>even with highly inflected languages, domain-specific approach may get around many of the data sparsity issues.it is also crucial that no data be thrown out.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI46">
<title id=" W11-2708.xml">discriminative features in reversible stochastic attribute value grammars </title>
<section> feature selection.  </section>
<citcontext>
<prevsection>
<prevsent>in that work, it was found that the gain-informed selection method outperforms frequency-based and correlation selection.
</prevsent>
<prevsent>for this reason we exclude the latter two methods from ourexperiments.
</prevsent>
</prevsection>
<citsent citstr=" W04-3223 ">
other commonly used selection methods for maximum entropy models include `1 regularization (tibshirani, 1996), grafting (perkins et al,2003; riezler and vasserman, 2004), <papid> W04-3223 </papid>and grafting light (zhu et al, 2010).</citsent>
<aftsection>
<nextsent>in the following sections,we will give description of these selection methods.
</nextsent>
<nextsent>2.1 `1 regularization during the training of maximum entropy models, regularization is often applied to avoid unconstrained feature weights and overfitting.
</nextsent>
<nextsent>if l(w) isthe objective function that is minimized during training, regularizer q(w) is added as penalty for extreme weights (tibshirani, 1996): c(w) = l(w) + q(w) (4)given that the maximum entropy training procedure attempts to minimize the negative log likelihood of the model, the penalized objective function is: c(w) = ? ?
</nextsent>
<nextsent>c,d p?(c, d)log(p(d|c)) + q(w) (5) the regularizer has the following form: q(w) = ? n? i=1 |wi| setting = 1 in the regularizer function gives so-called `1 regularizer and amounts to applying double-exponential prior distribution with ? = 0.since the double-exponential puts much of its probability mass near its mean, the `1 regularizer has tendency to force weights towards zero, providing integral feature selection and avoiding unbounded weights.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI48">
<title id=" W11-2708.xml">discriminative features in reversible stochastic attribute value grammars </title>
<section> feature selection.  </section>
<citcontext>
<prevsection>
<prevsent>l(wsfi) (8) during each selection step, the feature that gives the highest gain is selected.
</prevsent>
<prevsent>the calculation of l(psfi) requires full optimization over the weights of the features in ? fi.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
since it is computationally intractable to do this for every fi in z, berger et al (1996) <papid> J96-1002 </papid>propose to estimate the weight wi of the candidate feature fi, while assuming that the weights of features in stay constant.</citsent>
<aftsection>
<nextsent>under this assumption, wi can be estimated using simple line search method.however, zhou et al (2003) <papid> W03-1020 </papid>observe that, despite this simplification, the gain-informed selection method proposed by berger et al (1996) <papid> J96-1002 </papid>still recalculates the weights of all the candidate features during every cycle.</nextsent>
<nextsent>they observe that the gains of candidate features rarely increase.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI50">
<title id=" W11-2708.xml">discriminative features in reversible stochastic attribute value grammars </title>
<section> feature selection.  </section>
<citcontext>
<prevsection>
<prevsent>the calculation of l(psfi) requires full optimization over the weights of the features in ? fi.
</prevsent>
<prevsent>since it is computationally intractable to do this for every fi in z, berger et al (1996) <papid> J96-1002 </papid>propose to estimate the weight wi of the candidate feature fi, while assuming that the weights of features in stay constant.</prevsent>
</prevsection>
<citsent citstr=" W03-1020 ">
under this assumption, wi can be estimated using simple line search method.however, zhou et al (2003) <papid> W03-1020 </papid>observe that, despite this simplification, the gain-informed selection method proposed by berger et al (1996) <papid> J96-1002 </papid>still recalculates the weights of all the candidate features during every cycle.</citsent>
<aftsection>
<nextsent>they observe that the gains of candidate features rarely increase.
</nextsent>
<nextsent>if it is assumed thatthe gain of adding feature does indeed never in crease as result of adding another feature, the gains of features during the previous iteration can be kept.
</nextsent>
<nextsent>56 to account for features that become ineffective, the gain of the highest ranked feature is recalculated.
</nextsent>
<nextsent>the highest ranked feature is selected if it remains the best feature after this recalculation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI53">
<title id=" W11-2708.xml">discriminative features in reversible stochastic attribute value grammars </title>
<section> experimental setup and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>in our experiments, we use the features described in de kok et al (2011).
</prevsent>
<prevsent>in this section, we provide short summarization of the types of features that are used.word adjacency.
</prevsent>
</prevsection>
<citsent citstr=" A00-2021 ">
word and alpino part-ofspeech tag trigram models are used as auxiliary distributions (johnson and riezler, 2000).<papid> A00-2021 </papid></citsent>
<aftsection>
<nextsent>in both models, linear interpolation smoothing is applied to handle unknown trigrams, and laplacian smoothing for unknown unigrams.
</nextsent>
<nextsent>the trigram models have 1http://www.inl.nl/corpora/ eindhoven-corpus 2http://www.let.rug.nl/vannoord/trees/ 3http://hmi.ewi.utwente.nl/twnc 4http://www.inl.nl/corpora/lassy-corpusbeen trained on the twente nieuws corpus (approx imately 100 million words), excluding the trouw2001 corpus.
</nextsent>
<nextsent>in parsing, the value of the word trigram model is constant across derivations of given input sentence.lexical frames.
</nextsent>
<nextsent>the parser applies lexical analysis to find all possible subcategorization frames for tokens in the input sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI54">
<title id=" W11-2708.xml">discriminative features in reversible stochastic attribute value grammars </title>
<section> experimental setup and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>due to limit on generation time, some longer sentences and corresponding dependency structures are excluded from the data.
</prevsent>
<prevsent>the average sentence length was 15.7 tokens, with maximum of 26 tokens.
</prevsent>
</prevsection>
<citsent citstr=" N03-2021 ">
since the sentence in the treebank cannot always be produced exactly, we estimate the quality of each realization using the general text matcher (gtm) method (melamed et al, 2003).<papid> N03-2021 </papid></citsent>
<aftsection>
<nextsent>the best-scoringderivations are marked as correct, the other derivations are marked as incorrect.
</nextsent>
<nextsent>finally, features are extracted from these derivations.the general text matcher method marks all corresponding tokens of candidate realization and the correct realization ingrid, and finds the maximum matching (the largest subset of marks, such that no marks are in the same row or column).
</nextsent>
<nextsent>the size of the matchingm is then determined using the lengths of runs in the matching (a run is diagonal of marks), rewarding longer runs: size(m) = ? ?
</nextsent>
<nextsent>rm length(r)2 (10) this method has been shown to have the highest correlation with human judgments in related language (german), using comparable system (cahill, 2009).<papid> P09-2025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI55">
<title id=" W11-2708.xml">discriminative features in reversible stochastic attribute value grammars </title>
<section> experimental setup and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>finally, features are extracted from these derivations.the general text matcher method marks all corresponding tokens of candidate realization and the correct realization ingrid, and finds the maximum matching (the largest subset of marks, such that no marks are in the same row or column).
</prevsent>
<prevsent>the size of the matchingm is then determined using the lengths of runs in the matching (a run is diagonal of marks), rewarding longer runs: size(m) = ? ?
</prevsent>
</prevsection>
<citsent citstr=" P09-2025 ">
rm length(r)2 (10) this method has been shown to have the highest correlation with human judgments in related language (german), using comparable system (cahill, 2009).<papid> P09-2025 </papid></citsent>
<aftsection>
<nextsent>3.5 training.
</nextsent>
<nextsent>models are trained by extracting an informative sample of ?(c) for each in the training data (os borne, 2000).<papid> C00-1085 </papid></nextsent>
<nextsent>this informative sample consists of at most 100 randomly selected derivations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI56">
<title id=" W11-2708.xml">discriminative features in reversible stochastic attribute value grammars </title>
<section> experimental setup and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>rm length(r)2 (10) this method has been shown to have the highest correlation with human judgments in related language (german), using comparable system (cahill, 2009).<papid> P09-2025 </papid></prevsent>
<prevsent>3.5 training.</prevsent>
</prevsection>
<citsent citstr=" C00-1085 ">
models are trained by extracting an informative sample of ?(c) for each in the training data (os borne, 2000).<papid> C00-1085 </papid></citsent>
<aftsection>
<nextsent>this informative sample consists of at most 100 randomly selected derivations.
</nextsent>
<nextsent>we then apply feature selection on the training data.
</nextsent>
<nextsent>we let each method select 1711 features.
</nextsent>
<nextsent>this number is derived from the number of non-zero features that training model with `1 norm coefficient of 0.0002 gives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI57">
<title id=" W12-2003.xml">automatic grading of scientific inquiry </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, this benefit can only be realized if we can make sense of the stream of data and text produced by the students.
</prevsent>
<prevsent>in this paper, we attempt to automate the process of grading students in save science assessments, tomake the evaluations as cost-effective as standardized tests.
</prevsent>
</prevsection>
<citsent citstr=" W09-2509 ">
unlike most previous systems for automated grading (sukkarieh and stoyanchev, 2009; <papid> W09-2509 </papid>sukkarieh et al , 2004; higgins et al , 2004; <papid> N04-1024 </papid>wang et al , 2008), the data for this task includes short paragraph (usually 50-60 words) natural language response stating hypothesis and evidence in support of it.</citsent>
<aftsection>
<nextsent>in addition, there is wealth of relational data about student behavior in virtual environment.we develop novel predictors for automatically grading the written responses using wide variety of natural language features, as well as features from the data on student behavior in the virtual world.
</nextsent>
<nextsent>on student data from two virtual worlds, our best automated grader has correlations of = 0.58 and 0.44 with human judgments, improving over the closest 22 technique from previous work by 56% for the first world, and by 120% for the second.
</nextsent>
<nextsent>the rest of the paper is organized as follows.the next section contrasts this project with previous work.
</nextsent>
<nextsent>section 3 describes the save science project and the student data it has produced.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI58">
<title id=" W12-2003.xml">automatic grading of scientific inquiry </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, this benefit can only be realized if we can make sense of the stream of data and text produced by the students.
</prevsent>
<prevsent>in this paper, we attempt to automate the process of grading students in save science assessments, tomake the evaluations as cost-effective as standardized tests.
</prevsent>
</prevsection>
<citsent citstr=" N04-1024 ">
unlike most previous systems for automated grading (sukkarieh and stoyanchev, 2009; <papid> W09-2509 </papid>sukkarieh et al , 2004; higgins et al , 2004; <papid> N04-1024 </papid>wang et al , 2008), the data for this task includes short paragraph (usually 50-60 words) natural language response stating hypothesis and evidence in support of it.</citsent>
<aftsection>
<nextsent>in addition, there is wealth of relational data about student behavior in virtual environment.we develop novel predictors for automatically grading the written responses using wide variety of natural language features, as well as features from the data on student behavior in the virtual world.
</nextsent>
<nextsent>on student data from two virtual worlds, our best automated grader has correlations of = 0.58 and 0.44 with human judgments, improving over the closest 22 technique from previous work by 56% for the first world, and by 120% for the second.
</nextsent>
<nextsent>the rest of the paper is organized as follows.the next section contrasts this project with previous work.
</nextsent>
<nextsent>section 3 describes the save science project and the student data it has produced.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI59">
<title id=" W12-2003.xml">automatic grading of scientific inquiry </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in part, we improve by including more sophisticated language processing features in our model than the unigram and bigram features they use; as others have noted, bag-of-words representations and latent semantic indexing become less useful as word order and causal relationships become important for judging an essays quality (malatesta et al , 2002; wiemer hastings et al , 2005).
</prevsent>
<prevsent>a secondary reason for our improvement is that we also have access to non linguistic data about the students that we can mine for additional patterns.
</prevsent>
</prevsection>
<citsent citstr=" E09-1065 ">
most previous research on automated grading of written text focuses on short, factual text (wiemer hastings et al , 1999; mohler and mihalcea, 2009;<papid> E09-1065 </papid>leacock and chodorow, 2003; sukkarieh and stoyanchev, 2009; <papid> W09-2509 </papid>sukkarieh et al , 2004; mitchell et al , 2002; pulman and sukkarieh, 2005), <papid> W05-0202 </papid>whereas save sciences texts are only partly factual.</citsent>
<aftsection>
<nextsent>responses are meant to convey scientific explanation of amystery, and therefore, correct responses contain inferences, observations of the world, and causal links between observations and inferences.
</nextsent>
<nextsent>automatic systems for grading longer responses typically grade essays for coherence and discourse structure (burstein et al , 2001; higgins et al , 2004), <papid> N04-1024 </papid>but these global discourse criteria are only partially indicative of the quality of students response to the save science assessments.</nextsent>
<nextsent>to be considered fully correct in these tests, student responses must contain factually correct information, as well as causal relationships that justify the students inferences, such as the balls dont bounce outside because its cold, and lower temperatures decrease pressure.?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI61">
<title id=" W12-2003.xml">automatic grading of scientific inquiry </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in part, we improve by including more sophisticated language processing features in our model than the unigram and bigram features they use; as others have noted, bag-of-words representations and latent semantic indexing become less useful as word order and causal relationships become important for judging an essays quality (malatesta et al , 2002; wiemer hastings et al , 2005).
</prevsent>
<prevsent>a secondary reason for our improvement is that we also have access to non linguistic data about the students that we can mine for additional patterns.
</prevsent>
</prevsection>
<citsent citstr=" W05-0202 ">
most previous research on automated grading of written text focuses on short, factual text (wiemer hastings et al , 1999; mohler and mihalcea, 2009;<papid> E09-1065 </papid>leacock and chodorow, 2003; sukkarieh and stoyanchev, 2009; <papid> W09-2509 </papid>sukkarieh et al , 2004; mitchell et al , 2002; pulman and sukkarieh, 2005), <papid> W05-0202 </papid>whereas save sciences texts are only partly factual.</citsent>
<aftsection>
<nextsent>responses are meant to convey scientific explanation of amystery, and therefore, correct responses contain inferences, observations of the world, and causal links between observations and inferences.
</nextsent>
<nextsent>automatic systems for grading longer responses typically grade essays for coherence and discourse structure (burstein et al , 2001; higgins et al , 2004), <papid> N04-1024 </papid>but these global discourse criteria are only partially indicative of the quality of students response to the save science assessments.</nextsent>
<nextsent>to be considered fully correct in these tests, student responses must contain factually correct information, as well as causal relationships that justify the students inferences, such as the balls dont bounce outside because its cold, and lower temperatures decrease pressure.?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI63">
<title id=" W12-2003.xml">automatic grading of scientific inquiry </title>
<section> predictors for scientific inquiry grades.  </section>
<citcontext>
<prevsection>
<prevsent>as result, standard topic modeling techniques may have difficulty identifying the appropriate structure.
</prevsent>
<prevsent>we therefore also consider hidden markov models (hmms) (ra biner, 1989), generative models which rely both on cooccurrence within sentence and on sequence information for determining model parameters.
</prevsent>
</prevsection>
<citsent citstr=" W11-0315 ">
following recent work by huang et al  (2011) <papid> W11-0315 </papid>onusing hmms to build representations, we estimate parameters for fully-connected hmm with100 latent states over the free form responses using expectation-maximization.</citsent>
<aftsection>
<nextsent>we then decode the hmm over the corpus to produce viterbi-optimal latent state for each word.
</nextsent>
<nextsent>finally, we use counts of these 100 latent states to produce 100 new features for each free form response.
</nextsent>
<nextsent>4.3.3 detecting disengagementa small number of students show little enthusiasm for the test, and their responses and general performance are quite poor.
</nextsent>
<nextsent>often their free form responses are short, or they repeat the same text multiple times.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI64">
<title id=" W12-1515.xml">reformulating student contributions in tutorial dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a marking is reformulation that emphasizes what is most important in what the student said and attempt sto direct the student to focus his/her continued discussion on the reformulation.
</prevsent>
<prevsent>although neither of these examples are revoicings in the sense of at and the first seems more like repetition to acknowledge rather than reformulate,both are still important to consider for tutorial dialogue.
</prevsent>
</prevsection>
<citsent citstr=" W11-0133 ">
they may help lessen the students cognitive load (walker, 1996) by drawing attention to what is most important in what the student said (becker et al., 2011).<papid> W11-0133 </papid></citsent>
<aftsection>
<nextsent>the other recent study of tutorial dialogue that considers re voicing collected corpus using human tutors who were trained to use qta and who fill infor conversational virtual tutor in science education system (becker et al, 2011).<papid> W11-0133 </papid></nextsent>
<nextsent>this corpus hasbeen annotated along multiple dimensions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI67">
<title id=" W11-1825.xml">msrnlp entry in bionlp shared task 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>generally this was the token inside the protein that is closest to the root of the dependency parse.
</prevsent>
<prevsent>in the case of ties, we picked the rightmost such node.
</prevsent>
</prevsection>
<citsent citstr=" P08-2026 ">
2.1.1 mcclosky-charniak-stanford parses the organizers provide parses from version of the mcclosky-charniak parser, mccc (mcclosky and charniak, 2008), <papid> P08-2026 </papid>which is two-stage parser/reranker trained on the genia corpus.</citsent>
<aftsection>
<nextsent>in addition, we used an improved set of parsing models that leverage unsupervised data, mccc-i (mcclosky, 2010).
</nextsent>
<nextsent>in both cases, the stanford parser was used to convert constituency trees in the penn treebank format into labeled dependency parses: we used the collapsed dependency format.
</nextsent>
<nextsent>2.1.2 dependency posteriors effectively maintaining and leveraging the ambiguity present in the underlying parser has improved task accuracy in some downstream tasks (e.g., mi et al 2008).<papid> P08-1023 </papid></nextsent>
<nextsent>mcclosky-charniak parses in two passes: the first pass is generative model that produces set of n-best candidates, and the second pass is discriminative reranker that uses rich set of features including non-local information.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI68">
<title id=" W11-1825.xml">msrnlp entry in bionlp shared task 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, we used an improved set of parsing models that leverage unsupervised data, mccc-i (mcclosky, 2010).
</prevsent>
<prevsent>in both cases, the stanford parser was used to convert constituency trees in the penn treebank format into labeled dependency parses: we used the collapsed dependency format.
</prevsent>
</prevsection>
<citsent citstr=" P08-1023 ">
2.1.2 dependency posteriors effectively maintaining and leveraging the ambiguity present in the underlying parser has improved task accuracy in some downstream tasks (e.g., mi et al 2008).<papid> P08-1023 </papid></citsent>
<aftsection>
<nextsent>mcclosky-charniak parses in two passes: the first pass is generative model that produces set of n-best candidates, and the second pass is discriminative reranker that uses rich set of features including non-local information.
</nextsent>
<nextsent>we re normalized the outputs from this log-linear discriminative model to get posterior distribution over the 50-best parses.
</nextsent>
<nextsent>this set of parses preserved some of the syntactic ambiguity present in the sentence.
</nextsent>
<nextsent>the stanford parser deterministically converts phrase-structure trees into labeled dependency graphs (de marneffe et al, 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI69">
<title id=" W11-1825.xml">msrnlp entry in bionlp shared task 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the shortest path algorithm used in feature finding was supplied uniform positive edge weights.
</prevsent>
<prevsent>we could also weight edges by the negative log probability to find the shortest, most likely path.
</prevsent>
</prevsection>
<citsent citstr=" J08-1002 ">
2.1.3 enju we also experimented with the enju parses (miyao and tsujii, 2008) <papid> J08-1002 </papid>provided by the shared task organizers.</citsent>
<aftsection>
<nextsent>the distribution contained the output of the enju parser in format consistent with the stanford typed dependency representation . 2.1.4 multiple parsers we know that even the best modern parsers are prone to errors.
</nextsent>
<nextsent>including features from multiple parsers helps mitigate these errors.
</nextsent>
<nextsent>when different parsers agree, they can reinforce certain classification decisions.
</nextsent>
<nextsent>the features that were extracted from dependency parse have names that include an identifier for the parser that produced them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI70">
<title id=" W11-1825.xml">msrnlp entry in bionlp shared task 2011 </title>
<section> agent -  nsubj.  </section>
<citcontext>
<prevsection>
<prevsent>to train clusters, we downloaded all the pubmed abstracts (http://pubmed.gov), parsed them with simple dependency parser (a re implementation of mcdonald, 2006 trained on the genia corpus), and extracted dependency relations to use in clustering: words that occur in similar contexts should fall into the same cluster.
</prevsent>
<prevsent>an example sentence and the relations that were extracted for distributional similarity computation are presented in figure 2.
</prevsent>
</prevsection>
<citsent citstr=" D09-1098 ">
we ran distributional similarity clustering algorithm (pantel et al, 2009) <papid> D09-1098 </papid>to group words into clusters.</citsent>
<aftsection>
<nextsent>tfidf features.
</nextsent>
<nextsent>this set of features was intended to capture the salience of term in the medical and general?
</nextsent>
<nextsent>domain, with the aim of being able to distinguish domain-specific terms from more ambiguous terms.
</nextsent>
<nextsent>we calculated the tf.idf score for each term in the set of all pubmed abstracts and did the same for each term in wikipedia.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI71">
<title id=" W11-1825.xml">msrnlp entry in bionlp shared task 2011 </title>
<section> agent -  nsubj.  </section>
<citcontext>
<prevsection>
<prevsent>for feature reduction we tried number of simple approaches that typically work well in text classification.
</prevsent>
<prevsent>the latter is similar to the task at hand, in that there is very large but sparse feature set.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
we tried two feature reduction methods: simple count cutoff, and selection of the top features in terms of log likelihood ratio (dunning, 1993) <papid> J93-1003 </papid>with the target values.</citsent>
<aftsection>
<nextsent>for count cutoff, we used cutoffs from 3 to 10, but we failed to observe any consistent gains.
</nextsent>
<nextsent>only low cutoffs (3 and occasionally 5) would ever produce any small improvements on the development set.
</nextsent>
<nextsent>using log likelihood ratio (as determined on the training set), we reduced the total number of features to between 10,000 and 75,000.
</nextsent>
<nextsent>none of these experiments improved results, however.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI72">
<title id=" W11-1825.xml">msrnlp entry in bionlp shared task 2011 </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>this might result either in modification of the annotation protocols, or an opportunity for all systems to learn more.
</prevsent>
<prevsent>after certain amount of feature engineering, we found it difficult to achieve further improvements in f1.
</prevsent>
</prevsection>
<citsent citstr=" N10-1123 ">
perhaps we need significant shift in architecture, such as shift to joint inference (poon and vanderwende, 2010).<papid> N10-1123 </papid></citsent>
<aftsection>
<nextsent>our system may be limited by the pipeline architecture.
</nextsent>
<nextsent>1 our system output for the 2011development set can be.
</nextsent>
<nextsent>downloaded from http://research.microsoft.com/bionlp/ mwes (multi-word entities) are challenge.
</nextsent>
<nextsent>better multi-word triggers accuracy may improve system performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI73">
<title id=" W11-1819.xml">using kybots for extracting events in biomedical texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system applies kybots (knowledge yielding robots) on annotated texts to extract bio-events involving proteins or genes.
</prevsent>
<prevsent>the main goal of this work is to verify the usefulness and portability of the ky bot technology to the domain of biomedicine.
</prevsent>
</prevsection>
<citsent citstr=" W11-1802 ">
the aim of the bionlp11 genia shared task (kim et al, 2011<papid> W11-1802 </papid>b) concerns the detection of molecular biology events in biomedical texts using nlp tools and methods.</citsent>
<aftsection>
<nextsent>it requires the identification of events together with their gene or protein arguments.
</nextsent>
<nextsent>nine event types are considered: localization, binding, gene expression, transcription, protein catabolism, phosphorylation, regulation, positive regulation and negative regulation.
</nextsent>
<nextsent>when identifying the events related to the given proteins, it is mandatory to detect also the event triggers, together with its associated event-type, and recognize their primary arguments.
</nextsent>
<nextsent>there are sim ple?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI77">
<title id=" W12-0113.xml">bootstrapping method for chunk alignment in phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the parallel corpus is modified by considering the mwes as single tokens.
</prevsent>
<prevsent>source and target language nes are aligned using statistical transliteration technique.
</prevsent>
</prevsection>
<citsent citstr=" W10-3707 ">
these automatically aligned nes and complex predicates are treated as translation examples, i.e., as additional entries in the phrase table (pal.et al 2010, <papid> W10-3707 </papid>2011).</citsent>
<aftsection>
<nextsent>using this augmented phrase table each individual source chunk is translated into the target chunk and then validated with the target chunks on the target side.
</nextsent>
<nextsent>the validated source-target chunks are con 93 sidered as further parallel examples, which in effect are instances of atomic translation pairs to the parallel corpus.
</nextsent>
<nextsent>this is well-known practice in domain adaptation in smt (eck et al , 2004; <papid> C04-1114 </papid>wu et al , 2008).<papid> C08-1125 </papid></nextsent>
<nextsent>the preprocessing of the parallel corpus results in improved mt quality in terms of automatic mt evaluation metrics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI78">
<title id=" W12-0113.xml">bootstrapping method for chunk alignment in phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using this augmented phrase table each individual source chunk is translated into the target chunk and then validated with the target chunks on the target side.
</prevsent>
<prevsent>the validated source-target chunks are con 93 sidered as further parallel examples, which in effect are instances of atomic translation pairs to the parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" C04-1114 ">
this is well-known practice in domain adaptation in smt (eck et al , 2004; <papid> C04-1114 </papid>wu et al , 2008).<papid> C08-1125 </papid></citsent>
<aftsection>
<nextsent>the preprocessing of the parallel corpus results in improved mt quality in terms of automatic mt evaluation metrics.
</nextsent>
<nextsent>the remainder of the paper is organized as follows.
</nextsent>
<nextsent>section 2 briefly elaborates the related work.
</nextsent>
<nextsent>the pb-smt system is described in section 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI79">
<title id=" W12-0113.xml">bootstrapping method for chunk alignment in phrase based smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using this augmented phrase table each individual source chunk is translated into the target chunk and then validated with the target chunks on the target side.
</prevsent>
<prevsent>the validated source-target chunks are con 93 sidered as further parallel examples, which in effect are instances of atomic translation pairs to the parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" C08-1125 ">
this is well-known practice in domain adaptation in smt (eck et al , 2004; <papid> C04-1114 </papid>wu et al , 2008).<papid> C08-1125 </papid></citsent>
<aftsection>
<nextsent>the preprocessing of the parallel corpus results in improved mt quality in terms of automatic mt evaluation metrics.
</nextsent>
<nextsent>the remainder of the paper is organized as follows.
</nextsent>
<nextsent>section 2 briefly elaborates the related work.
</nextsent>
<nextsent>the pb-smt system is described in section 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI80">
<title id=" W12-0113.xml">bootstrapping method for chunk alignment in phrase based smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>zhu and chang (2008) extracted dictionary from the aligned corpus, used the dictionary to re-align the corpus and then extracted the new dictionary from the new alignment result.
</prevsent>
<prevsent>the process goes on until the threshold is reached.
</prevsent>
</prevsection>
<citsent citstr=" W09-2907 ">
an automatic extraction of bilingual mwes is carried out by ren et al  (2009), <papid> W09-2907 </papid>using log likelihood ratio based hierarchical reducing algorithm to investigate the usefulness of bilingual mwes in smt by integrating bilingual mwes into the moses decoder (koehn et al , 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>the system has observed the highest improvement with an additional feature that identifies whether or not bilingual phrase contains bilingual mwes.
</nextsent>
<nextsent>this approach was generalized in carpuat and diab (2010) <papid> N10-1029 </papid>where the binary feature is replaced by count feature which is representing the number of mwes in the source language phrase.</nextsent>
<nextsent>mwes on the source and the target sides should be both aligned in the parallel corpus and translated as whole.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI81">
<title id=" W12-0113.xml">bootstrapping method for chunk alignment in phrase based smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>zhu and chang (2008) extracted dictionary from the aligned corpus, used the dictionary to re-align the corpus and then extracted the new dictionary from the new alignment result.
</prevsent>
<prevsent>the process goes on until the threshold is reached.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
an automatic extraction of bilingual mwes is carried out by ren et al  (2009), <papid> W09-2907 </papid>using log likelihood ratio based hierarchical reducing algorithm to investigate the usefulness of bilingual mwes in smt by integrating bilingual mwes into the moses decoder (koehn et al , 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>the system has observed the highest improvement with an additional feature that identifies whether or not bilingual phrase contains bilingual mwes.
</nextsent>
<nextsent>this approach was generalized in carpuat and diab (2010) <papid> N10-1029 </papid>where the binary feature is replaced by count feature which is representing the number of mwes in the source language phrase.</nextsent>
<nextsent>mwes on the source and the target sides should be both aligned in the parallel corpus and translated as whole.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI83">
<title id=" W12-0113.xml">bootstrapping method for chunk alignment in phrase based smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>an automatic extraction of bilingual mwes is carried out by ren et al  (2009), <papid> W09-2907 </papid>using log likelihood ratio based hierarchical reducing algorithm to investigate the usefulness of bilingual mwes in smt by integrating bilingual mwes into the moses decoder (koehn et al , 2007).<papid> P07-2045 </papid></prevsent>
<prevsent>the system has observed the highest improvement with an additional feature that identifies whether or not bilingual phrase contains bilingual mwes.</prevsent>
</prevsection>
<citsent citstr=" N10-1029 ">
this approach was generalized in carpuat and diab (2010) <papid> N10-1029 </papid>where the binary feature is replaced by count feature which is representing the number of mwes in the source language phrase.</citsent>
<aftsection>
<nextsent>mwes on the source and the target sides should be both aligned in the parallel corpus and translated as whole.
</nextsent>
<nextsent>however, in the state-of the-art pb-smt systems, the constituents of an mwe are marked and aligned as parts of consecutive phrases, since pb-smt (or any other approaches to smt) does not generally treat mwes as special tokens.
</nextsent>
<nextsent>another problem with smt systems is the wrong translation of some phrases.
</nextsent>
<nextsent>sometimes some phrases are not found in the output sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI84">
<title id=" W12-0113.xml">bootstrapping method for chunk alignment in phrase based smt </title>
<section> pb-smt system description.  </section>
<citcontext>
<prevsection>
<prevsent>alignment the initial english-bengali parallel corpus is cleaned and filtered using semi-automatic process.
</prevsent>
<prevsent>complex predicates are first extracted on both sides of the parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" W10-3706 ">
the analysis and identification of various complex predicates like, compound verbs (verb + verb), conjunct verbs (noun /adjective/adverb + verb) and serial verbs (verb + verb + verb) in bengali are done following the strategy in das.et al  (2010).<papid> W10-3706 </papid></citsent>
<aftsection>
<nextsent>named-entities and complex predicates are aligned following similar technique as reported in pal.et al (2011).
</nextsent>
<nextsent>re duplicated phrases do not occur very frequently in the english corpus; some of them (like cor relatives, semantic redu plications) are not found in english (chakraborty 94 and bandyopadhyay, 2010).
</nextsent>
<nextsent>but reduplication plays crucial role on the target bengali side as they occur with high frequency.
</nextsent>
<nextsent>these redupli cated phrases are considered as single-token so that they may map to single word on the source side.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI86">
<title id=" W12-0113.xml">bootstrapping method for chunk alignment in phrase based smt </title>
<section> tools and resources used.  </section>
<citcontext>
<prevsection>
<prevsent>the sentences on the target side (bengali) are parsed and pos-tagged by using the tools obtained from the consortium mode project development of indian language to indian language machine translation (il-ilmt) system phase ii?.
</prevsent>
<prevsent>nes in bengali are identified using the ner system of ekbal and bandyopadhyay (2008).
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the effectiveness of the mwe-aligned and chunk aligned parallel corpus is demonstrated by using the standard log-linear pb-smt model as our baseline system: giza++ implementation of ibm word alignment model 4, phrase-extraction heuristics described in (koehn et al , 2003), <papid> N03-1017 </papid>minimum-error-rate training (och, 2003) <papid> P03-1021 </papid>on held-out development set, target language model trained using srilm toolkit (stolcke, 2002) with kneser-ney smoothing (kneser and ney, 1995) and the moses decoder (koehn et al , 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we have randomly identified 500 sentences each for the development set and the test set from the initial parallel corpus.
</nextsent>
<nextsent>the rest are considered as the training corpus.
</nextsent>
<nextsent>the training corpus was filtered with the maximum allowable sentence length of 100 words and sentence length ratio of 1:2 (either way).
</nextsent>
<nextsent>finally the training corpus contains 13,176 sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI87">
<title id=" W12-0113.xml">bootstrapping method for chunk alignment in phrase based smt </title>
<section> tools and resources used.  </section>
<citcontext>
<prevsection>
<prevsent>the sentences on the target side (bengali) are parsed and pos-tagged by using the tools obtained from the consortium mode project development of indian language to indian language machine translation (il-ilmt) system phase ii?.
</prevsent>
<prevsent>nes in bengali are identified using the ner system of ekbal and bandyopadhyay (2008).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the effectiveness of the mwe-aligned and chunk aligned parallel corpus is demonstrated by using the standard log-linear pb-smt model as our baseline system: giza++ implementation of ibm word alignment model 4, phrase-extraction heuristics described in (koehn et al , 2003), <papid> N03-1017 </papid>minimum-error-rate training (och, 2003) <papid> P03-1021 </papid>on held-out development set, target language model trained using srilm toolkit (stolcke, 2002) with kneser-ney smoothing (kneser and ney, 1995) and the moses decoder (koehn et al , 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we have randomly identified 500 sentences each for the development set and the test set from the initial parallel corpus.
</nextsent>
<nextsent>the rest are considered as the training corpus.
</nextsent>
<nextsent>the training corpus was filtered with the maximum allowable sentence length of 100 words and sentence length ratio of 1:2 (either way).
</nextsent>
<nextsent>finally the training corpus contains 13,176 sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI90">
<title id=" W12-0113.xml">bootstrapping method for chunk alignment in phrase based smt </title>
<section> experiments and evaluation results.  </section>
<citcontext>
<prevsection>
<prevsent>(the ???
</prevsent>
<prevsent>marked systems produce statistically significant improvements on bleu over the baseline system) intrinsic evaluation of the chunk alignment could not be performed as gold-standard word alignment was not available.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
thus, extrinsic evaluation was carried out on the mt quality using the well known automatic mt evaluation metrics: bleu (papineni et al , 2002) <papid> P02-1040 </papid>and nist (doddington, 2002).</citsent>
<aftsection>
<nextsent>bengali is morphologically rich language and has relatively free phrase order.
</nextsent>
<nextsent>proper evaluation of the english-bengali 98 mt evaluation ideally requires multiple set of reference translations.
</nextsent>
<nextsent>moreover, the training set was smaller in size.
</nextsent>
<nextsent>a methodology has been presented in this paper to show how the simple yet effective preprocessing of various types of mwes and alignment of nes, complex predicates and chunks can boost the performance of pb-smt system on an eng lishbengali translation task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI91">
<title id=" W12-2007.xml">measuring the use of factual information in test taker essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>implications for development of automated essay scoring systems are discussed.
</prevsent>
<prevsent>automated scoring of essays deals with various aspects of writing, such as grammar, usage, mechanics, as well as organization and content (attali and burstein, 2006).
</prevsent>
</prevsection>
<citsent citstr=" W10-1013 ">
for assessment of content, the focus is traditionally on topical appropriateness of the vocabulary (attali and burstein, 2006; landauer et al, 2003; louis and higgins, 2010; <papid> W10-1013 </papid>chen et al, 2010; de and kopparapu, 2011; higgins et al., 2006; ishioka and kameda, 2006; <papid> P06-1030 </papid>kakkonen et al., 2005; <papid> W05-0206 </papid>kakkonen and sutinen, 2004; lemaire and dessus, 2001; rose?</citsent>
<aftsection>
<nextsent>et al, 2003; larkey, 1998), although recently other aspects, such as detection of sentiment or figurative language, have started to attract attention (beigman klebanov et al, 2012; chang et al, 2006).the nature of factual information used in an essay has not so far been addressed, to our knowledge; yet misleading premise, insufficient factual basis, or an example that flies in the face of the readers knowledge clearly detract from an essays quality.
</nextsent>
<nextsent>this paper presents study on assessing the useof factual knowledge in argumentative essays on general topics written for graduate school entranceexam.
</nextsent>
<nextsent>we propose definition of fact, and an ope rationalization thereof.
</nextsent>
<nextsent>we find that the proposed measure has positive medium-strength correlation with essay grade, which remains significant after the impact of essay length is factored out.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI92">
<title id=" W12-2007.xml">measuring the use of factual information in test taker essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>implications for development of automated essay scoring systems are discussed.
</prevsent>
<prevsent>automated scoring of essays deals with various aspects of writing, such as grammar, usage, mechanics, as well as organization and content (attali and burstein, 2006).
</prevsent>
</prevsection>
<citsent citstr=" P06-1030 ">
for assessment of content, the focus is traditionally on topical appropriateness of the vocabulary (attali and burstein, 2006; landauer et al, 2003; louis and higgins, 2010; <papid> W10-1013 </papid>chen et al, 2010; de and kopparapu, 2011; higgins et al., 2006; ishioka and kameda, 2006; <papid> P06-1030 </papid>kakkonen et al., 2005; <papid> W05-0206 </papid>kakkonen and sutinen, 2004; lemaire and dessus, 2001; rose?</citsent>
<aftsection>
<nextsent>et al, 2003; larkey, 1998), although recently other aspects, such as detection of sentiment or figurative language, have started to attract attention (beigman klebanov et al, 2012; chang et al, 2006).the nature of factual information used in an essay has not so far been addressed, to our knowledge; yet misleading premise, insufficient factual basis, or an example that flies in the face of the readers knowledge clearly detract from an essays quality.
</nextsent>
<nextsent>this paper presents study on assessing the useof factual knowledge in argumentative essays on general topics written for graduate school entranceexam.
</nextsent>
<nextsent>we propose definition of fact, and an ope rationalization thereof.
</nextsent>
<nextsent>we find that the proposed measure has positive medium-strength correlation with essay grade, which remains significant after the impact of essay length is factored out.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI93">
<title id=" W12-2007.xml">measuring the use of factual information in test taker essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>implications for development of automated essay scoring systems are discussed.
</prevsent>
<prevsent>automated scoring of essays deals with various aspects of writing, such as grammar, usage, mechanics, as well as organization and content (attali and burstein, 2006).
</prevsent>
</prevsection>
<citsent citstr=" W05-0206 ">
for assessment of content, the focus is traditionally on topical appropriateness of the vocabulary (attali and burstein, 2006; landauer et al, 2003; louis and higgins, 2010; <papid> W10-1013 </papid>chen et al, 2010; de and kopparapu, 2011; higgins et al., 2006; ishioka and kameda, 2006; <papid> P06-1030 </papid>kakkonen et al., 2005; <papid> W05-0206 </papid>kakkonen and sutinen, 2004; lemaire and dessus, 2001; rose?</citsent>
<aftsection>
<nextsent>et al, 2003; larkey, 1998), although recently other aspects, such as detection of sentiment or figurative language, have started to attract attention (beigman klebanov et al, 2012; chang et al, 2006).the nature of factual information used in an essay has not so far been addressed, to our knowledge; yet misleading premise, insufficient factual basis, or an example that flies in the face of the readers knowledge clearly detract from an essays quality.
</nextsent>
<nextsent>this paper presents study on assessing the useof factual knowledge in argumentative essays on general topics written for graduate school entranceexam.
</nextsent>
<nextsent>we propose definition of fact, and an ope rationalization thereof.
</nextsent>
<nextsent>we find that the proposed measure has positive medium-strength correlation with essay grade, which remains significant after the impact of essay length is factored out.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI94">
<title id=" W12-2007.xml">measuring the use of factual information in test taker essays </title>
<section> open information extraction.  </section>
<citcontext>
<prevsection>
<prevsent>the knowledge contained in the www atlarge, reaching not only statements explicitly contributed to an encyclopedia but also those made by people on their blogs ? is perhaps as close as it gets to working model of the universal audience.recent developments in open information extraction make it possible to tap into this vast know ledge resource.
</prevsent>
<prevsent>indeed, fact-checking is one of the applications the developers of openie have in mind for their emergent technology (etzioni et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" J93-3001 ">
traditionally, the goal of an information extraction system is automated population of structured databases of events or concepts of interest and their properties by analyzing large corpora of text (chin chor et al, 1993; <papid> J93-3001 </papid>onyshkevych, 1993; <papid> M93-1003 </papid>grishman and sundheim, 1995; <papid> M95-1001 </papid>ravichandran and hovy, 2002;<papid> P02-1006 </papid>agichtein and gravano, 2000; davidov and rappoport, 2009).<papid> D09-1028 </papid>1for example, barack obama picks out precisely one person, and the same one in 2010 as it did in 1990.</citsent>
<aftsection>
<nextsent>in contrast, the current us president picks out different people every 4-8 years.
</nextsent>
<nextsent>for indeteminacy of boundaries, consider statement like us officials are wealthy.
</nextsent>
<nextsent>to determine its truth, one must first secure agreement on acceptable referents of us officials.in contrast, the recently proposed open information extraction paradigm aims to detect related pairs of entities without knowing in advance what kinds of relations exist between entities in the source data and without any seeding (banko and etzioni, 2008).<papid> P08-1004 </papid></nextsent>
<nextsent>the possibility of such extraction in english is attributed by the authors to small number of syntactic patterns that realize binary relations between entities.in particular, they found that almost 40% of such relations are realized by the argument-verb-argument pattern (henceforth, ava) (see table 1 in banko and etzioni (2008)).<papid> P08-1004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI95">
<title id=" W12-2007.xml">measuring the use of factual information in test taker essays </title>
<section> open information extraction.  </section>
<citcontext>
<prevsection>
<prevsent>the knowledge contained in the www atlarge, reaching not only statements explicitly contributed to an encyclopedia but also those made by people on their blogs ? is perhaps as close as it gets to working model of the universal audience.recent developments in open information extraction make it possible to tap into this vast know ledge resource.
</prevsent>
<prevsent>indeed, fact-checking is one of the applications the developers of openie have in mind for their emergent technology (etzioni et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" M93-1003 ">
traditionally, the goal of an information extraction system is automated population of structured databases of events or concepts of interest and their properties by analyzing large corpora of text (chin chor et al, 1993; <papid> J93-3001 </papid>onyshkevych, 1993; <papid> M93-1003 </papid>grishman and sundheim, 1995; <papid> M95-1001 </papid>ravichandran and hovy, 2002;<papid> P02-1006 </papid>agichtein and gravano, 2000; davidov and rappoport, 2009).<papid> D09-1028 </papid>1for example, barack obama picks out precisely one person, and the same one in 2010 as it did in 1990.</citsent>
<aftsection>
<nextsent>in contrast, the current us president picks out different people every 4-8 years.
</nextsent>
<nextsent>for indeteminacy of boundaries, consider statement like us officials are wealthy.
</nextsent>
<nextsent>to determine its truth, one must first secure agreement on acceptable referents of us officials.in contrast, the recently proposed open information extraction paradigm aims to detect related pairs of entities without knowing in advance what kinds of relations exist between entities in the source data and without any seeding (banko and etzioni, 2008).<papid> P08-1004 </papid></nextsent>
<nextsent>the possibility of such extraction in english is attributed by the authors to small number of syntactic patterns that realize binary relations between entities.in particular, they found that almost 40% of such relations are realized by the argument-verb-argument pattern (henceforth, ava) (see table 1 in banko and etzioni (2008)).<papid> P08-1004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI96">
<title id=" W12-2007.xml">measuring the use of factual information in test taker essays </title>
<section> open information extraction.  </section>
<citcontext>
<prevsection>
<prevsent>the knowledge contained in the www atlarge, reaching not only statements explicitly contributed to an encyclopedia but also those made by people on their blogs ? is perhaps as close as it gets to working model of the universal audience.recent developments in open information extraction make it possible to tap into this vast know ledge resource.
</prevsent>
<prevsent>indeed, fact-checking is one of the applications the developers of openie have in mind for their emergent technology (etzioni et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" M95-1001 ">
traditionally, the goal of an information extraction system is automated population of structured databases of events or concepts of interest and their properties by analyzing large corpora of text (chin chor et al, 1993; <papid> J93-3001 </papid>onyshkevych, 1993; <papid> M93-1003 </papid>grishman and sundheim, 1995; <papid> M95-1001 </papid>ravichandran and hovy, 2002;<papid> P02-1006 </papid>agichtein and gravano, 2000; davidov and rappoport, 2009).<papid> D09-1028 </papid>1for example, barack obama picks out precisely one person, and the same one in 2010 as it did in 1990.</citsent>
<aftsection>
<nextsent>in contrast, the current us president picks out different people every 4-8 years.
</nextsent>
<nextsent>for indeteminacy of boundaries, consider statement like us officials are wealthy.
</nextsent>
<nextsent>to determine its truth, one must first secure agreement on acceptable referents of us officials.in contrast, the recently proposed open information extraction paradigm aims to detect related pairs of entities without knowing in advance what kinds of relations exist between entities in the source data and without any seeding (banko and etzioni, 2008).<papid> P08-1004 </papid></nextsent>
<nextsent>the possibility of such extraction in english is attributed by the authors to small number of syntactic patterns that realize binary relations between entities.in particular, they found that almost 40% of such relations are realized by the argument-verb-argument pattern (henceforth, ava) (see table 1 in banko and etzioni (2008)).<papid> P08-1004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI97">
<title id=" W12-2007.xml">measuring the use of factual information in test taker essays </title>
<section> open information extraction.  </section>
<citcontext>
<prevsection>
<prevsent>the knowledge contained in the www atlarge, reaching not only statements explicitly contributed to an encyclopedia but also those made by people on their blogs ? is perhaps as close as it gets to working model of the universal audience.recent developments in open information extraction make it possible to tap into this vast know ledge resource.
</prevsent>
<prevsent>indeed, fact-checking is one of the applications the developers of openie have in mind for their emergent technology (etzioni et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
traditionally, the goal of an information extraction system is automated population of structured databases of events or concepts of interest and their properties by analyzing large corpora of text (chin chor et al, 1993; <papid> J93-3001 </papid>onyshkevych, 1993; <papid> M93-1003 </papid>grishman and sundheim, 1995; <papid> M95-1001 </papid>ravichandran and hovy, 2002;<papid> P02-1006 </papid>agichtein and gravano, 2000; davidov and rappoport, 2009).<papid> D09-1028 </papid>1for example, barack obama picks out precisely one person, and the same one in 2010 as it did in 1990.</citsent>
<aftsection>
<nextsent>in contrast, the current us president picks out different people every 4-8 years.
</nextsent>
<nextsent>for indeteminacy of boundaries, consider statement like us officials are wealthy.
</nextsent>
<nextsent>to determine its truth, one must first secure agreement on acceptable referents of us officials.in contrast, the recently proposed open information extraction paradigm aims to detect related pairs of entities without knowing in advance what kinds of relations exist between entities in the source data and without any seeding (banko and etzioni, 2008).<papid> P08-1004 </papid></nextsent>
<nextsent>the possibility of such extraction in english is attributed by the authors to small number of syntactic patterns that realize binary relations between entities.in particular, they found that almost 40% of such relations are realized by the argument-verb-argument pattern (henceforth, ava) (see table 1 in banko and etzioni (2008)).<papid> P08-1004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI98">
<title id=" W12-2007.xml">measuring the use of factual information in test taker essays </title>
<section> open information extraction.  </section>
<citcontext>
<prevsection>
<prevsent>the knowledge contained in the www atlarge, reaching not only statements explicitly contributed to an encyclopedia but also those made by people on their blogs ? is perhaps as close as it gets to working model of the universal audience.recent developments in open information extraction make it possible to tap into this vast know ledge resource.
</prevsent>
<prevsent>indeed, fact-checking is one of the applications the developers of openie have in mind for their emergent technology (etzioni et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" D09-1028 ">
traditionally, the goal of an information extraction system is automated population of structured databases of events or concepts of interest and their properties by analyzing large corpora of text (chin chor et al, 1993; <papid> J93-3001 </papid>onyshkevych, 1993; <papid> M93-1003 </papid>grishman and sundheim, 1995; <papid> M95-1001 </papid>ravichandran and hovy, 2002;<papid> P02-1006 </papid>agichtein and gravano, 2000; davidov and rappoport, 2009).<papid> D09-1028 </papid>1for example, barack obama picks out precisely one person, and the same one in 2010 as it did in 1990.</citsent>
<aftsection>
<nextsent>in contrast, the current us president picks out different people every 4-8 years.
</nextsent>
<nextsent>for indeteminacy of boundaries, consider statement like us officials are wealthy.
</nextsent>
<nextsent>to determine its truth, one must first secure agreement on acceptable referents of us officials.in contrast, the recently proposed open information extraction paradigm aims to detect related pairs of entities without knowing in advance what kinds of relations exist between entities in the source data and without any seeding (banko and etzioni, 2008).<papid> P08-1004 </papid></nextsent>
<nextsent>the possibility of such extraction in english is attributed by the authors to small number of syntactic patterns that realize binary relations between entities.in particular, they found that almost 40% of such relations are realized by the argument-verb-argument pattern (henceforth, ava) (see table 1 in banko and etzioni (2008)).<papid> P08-1004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI99">
<title id=" W12-2007.xml">measuring the use of factual information in test taker essays </title>
<section> open information extraction.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, the current us president picks out different people every 4-8 years.
</prevsent>
<prevsent>for indeteminacy of boundaries, consider statement like us officials are wealthy.
</prevsent>
</prevsection>
<citsent citstr=" P08-1004 ">
to determine its truth, one must first secure agreement on acceptable referents of us officials.in contrast, the recently proposed open information extraction paradigm aims to detect related pairs of entities without knowing in advance what kinds of relations exist between entities in the source data and without any seeding (banko and etzioni, 2008).<papid> P08-1004 </papid></citsent>
<aftsection>
<nextsent>the possibility of such extraction in english is attributed by the authors to small number of syntactic patterns that realize binary relations between entities.in particular, they found that almost 40% of such relations are realized by the argument-verb-argument pattern (henceforth, ava) (see table 1 in banko and etzioni (2008)).<papid> P08-1004 </papid></nextsent>
<nextsent>the text runner system (banko and etzioni, 2008) <papid> P08-1004 </papid>is trained using crf classifier on s-v-o tuples from parsed corpus as positive examples, and tuples that violate phrasal structure as negative ones.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI103">
<title id=" W12-2007.xml">measuring the use of factual information in test taker essays </title>
<section> building queries from essays.  </section>
<citcontext>
<prevsection>
<prevsent>we use the pattern of predicate matches against the text runner database to assess the degree and the equivocality of the connection between ne and np.
</prevsent>
<prevsent>5.1 named entities in test-taker essay.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
we use the stanford named entity recognizer(finkel et al, 2005) <papid> P05-1045 </papid>that tags named entities as people, locations, organizations, and miscellaneous.</citsent>
<aftsection>
<nextsent>we annotated sample of 90 essays for named entities; the sample yielded 442 tokens, which we classified as shown in table 2.
</nextsent>
<nextsent>the enamex classes (people, locations, organizations) account for 58% of all the entities in the sample.
</nextsent>
<nextsent>the recognizers recall of people and locations is excellent (though they arenot always classified correctly ? see caption of table 2), although test-taker essays feature additional entity types that are not detected as well.
</nextsent>
<nextsent>category recall examples location 0.98 iraq, usa person 0.96 george w. bush, freud org.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI104">
<title id=" W12-2007.xml">measuring the use of factual information in test taker essays </title>
<section> building queries from essays.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 selection of nps.
</prevsent>
<prevsent>we employ grammar-based approach for selecting nps.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we use the stanford dependency parser (de marneffe et al, 2006; klein and manning, 2003) <papid> P03-1054 </papid>to determine dependency relations.in order to find out which dependency paths connect between named entities and clearly related nps in essays, we manually marked concepts related to 95 nes in 10 randomly sampled essays.</citsent>
<aftsection>
<nextsent>we marked.
</nextsent>
<nextsent>210 query-able concepts in total.
</nextsent>
<nextsent>the resulting 210 dependency paths were classified according to the direction of the movement.
</nextsent>
<nextsent>out of the 210 paths, 51 (24%) contain single upward or downard step, that is, are cases where the ne is the head of the constituent in which the np is embedded, or the other way around.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI105">
<title id=" W12-1906.xml">using senses in hmm word alignment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we test preliminary version ofthis model on english-french data.
</prevsent>
<prevsent>we compare different ways of generating senses and assess the quality of the alignments relative tothe ibm hmm model, as well as the generated sense probabilities, in order to gauge the usefulness in word sense disambiguation.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
modern machine translation is dominated by statistical methods, most of which are trained on word aligned parallel corpora (koehn et al, 2007; <papid> P07-2045 </papid>koehn, 2004), which need to be generated separately.</citsent>
<aftsection>
<nextsent>one of the most commonly used methods to generate these word alignments is to use the ibm models 1-5, which generate one-directional alignments.
</nextsent>
<nextsent>although the ibm models perform well, they failto take into account certain situations.
</nextsent>
<nextsent>for example, if an alignment between two words f1 and e1 is considered, and f1 is an uncommon translation for e1, the translation probability will be low.
</nextsent>
<nextsent>it might happen, that an alignment to different nearby word is preferred by the model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI106">
<title id=" W12-1906.xml">using senses in hmm word alignment </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>machine translation is no exception, and whether or not wsd systems can improve performance of mt systems is debated.
</prevsent>
<prevsent>furthermore, it is unclear how parallel corp uses can be exploited for wsd systems.in this section we will present brief overview of related work.
</prevsent>
</prevsection>
<citsent citstr=" D07-1007 ">
(carpuat and wu, 2007) <papid> D07-1007 </papid>report an improvement in translation quality by incorporating wsd system directly in phrase-based translation system.this is in response to earlier work done, where incorporating the output of traditional wsd system gave disappointing results (carpuat and wu, 2005).<papid> P05-1048 </papid></citsent>
<aftsection>
<nextsent>the wsd task is redefined, to be similar to choosing the correct phrasal translation for word, instead of choosing sense from sense inventory.
</nextsent>
<nextsent>this system is trained on the same data as the smt system is. the output of this model is incorporated into the machine translation system by providing the wsd probabilities for phrase translation as extra features in log-linear model (carpuat and wu, 2007).<papid> D07-1007 </papid></nextsent>
<nextsent>this system consistently outperforms the baseline system (the same system, but without wsd component), on multiple metrics, which seems to indicate that wsdcan make useful contribution to machine transla tion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI107">
<title id=" W12-1906.xml">using senses in hmm word alignment </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>machine translation is no exception, and whether or not wsd systems can improve performance of mt systems is debated.
</prevsent>
<prevsent>furthermore, it is unclear how parallel corp uses can be exploited for wsd systems.in this section we will present brief overview of related work.
</prevsent>
</prevsection>
<citsent citstr=" P05-1048 ">
(carpuat and wu, 2007) <papid> D07-1007 </papid>report an improvement in translation quality by incorporating wsd system directly in phrase-based translation system.this is in response to earlier work done, where incorporating the output of traditional wsd system gave disappointing results (carpuat and wu, 2005).<papid> P05-1048 </papid></citsent>
<aftsection>
<nextsent>the wsd task is redefined, to be similar to choosing the correct phrasal translation for word, instead of choosing sense from sense inventory.
</nextsent>
<nextsent>this system is trained on the same data as the smt system is. the output of this model is incorporated into the machine translation system by providing the wsd probabilities for phrase translation as extra features in log-linear model (carpuat and wu, 2007).<papid> D07-1007 </papid></nextsent>
<nextsent>this system consistently outperforms the baseline system (the same system, but without wsd component), on multiple metrics, which seems to indicate that wsdcan make useful contribution to machine transla tion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI110">
<title id=" W12-1906.xml">using senses in hmm word alignment </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>if such code is found, it represents the sense index of both words.otherwise, the closest ili code to the two most similar ili codes is found, and that is taken as the sense for the word.
</prevsent>
<prevsent>the current work however only uses lexical resource for one of the languages, and as such has fewer places to fail, and less demanding requirements.
</prevsent>
</prevsection>
<citsent citstr=" P03-1058 ">
other similar work includes that in (ng et al,2003), <papid> P03-1058 </papid>where sense-annotated corpus was automatically generated from parallel corpus.</citsent>
<aftsection>
<nextsent>this is doneby word-aligning the parallel corpus, and then finding the senses according to wordnet given list of nouns.
</nextsent>
<nextsent>two senses are lumped together if they are translated into the same chinese word.
</nextsent>
<nextsent>the selection of correct translations is done manually.
</nextsent>
<nextsent>only those occurrences of the chosen nouns that translate to one of the chosen chinese words are considered sense-tagged by the translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI111">
<title id=" W12-1906.xml">using senses in hmm word alignment </title>
<section> senses model.  </section>
<citcontext>
<prevsection>
<prevsent>only those occurrences of the chosen nouns that translate to one of the chosen chinese words are considered sense-tagged by the translation.
</prevsent>
<prevsent>although similar in approach to what the current system would do, this system uses much more simple approach to generate sense annotations and it depends on previously word-aligned corpus, whereas the current approach would integrate alignment and sense-tagging, whis may give higher accuracy.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
the current model is based on the hmm alignment model (vogel et al, 1996), <papid> C96-2141 </papid>as it is less complex model than ibm models 3 and above, but still finds acceptable alignments.</citsent>
<aftsection>
<nextsent>the hmm alignment model is defined as hmm model, where the observed 40 a2a1 fmf1 f2 am figure 1: diagram of hmm model.
</nextsent>
<nextsent>arrows indicate dependencies, grey nodes indicate known values, white nodes indicate hidden variables.
</nextsent>
<nextsent>variables are the words of sentence in the french language f, and the hidden variables are alignments to words in the english sentence e, or to null state.
</nextsent>
<nextsent>see figure 1 for diagram of the standard hmm model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI112">
<title id=" W11-2158.xml">lium8217s smt machine translation systems for wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes the statistical machine translation systems developed by the computer science laboratory at the university of lemans (lium) for the 2011 wmt shared task evaluation.
</prevsent>
<prevsent>we only considered the translation between french and english (in both directions).
</prevsent>
</prevsection>
<citsent citstr=" W10-1716 ">
the main differences with respect to previous years system (lambert et al., 2010) <papid> W10-1716 </papid>are as follows: use of more training data as provided by the organizers, improved translation model adaptation by unsupervised training, continuous space language model for the translation into french, some attempts to automatically induce translations of unknown words and first experiments with hierarchical systems.</citsent>
<aftsection>
<nextsent>these different points are described in the rest of the paper, together with summary of the experimental results showing the impact of each component.
</nextsent>
<nextsent>the following sections describe how the resources provided or allowed in the shared task were used totrain the translation and language models of the system.
</nextsent>
<nextsent>2.1 bilingual data.
</nextsent>
<nextsent>our system was developed in two stages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI113">
<title id=" W11-2158.xml">lium8217s smt machine translation systems for wmt 2011 </title>
<section> resources used.  </section>
<citcontext>
<prevsection>
<prevsent>we also took as training data subset of the french english gigaword (109) corpus.
</prevsent>
<prevsent>we applied the same filters as last year to select this subset.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the first one is lexical filter based on the ibm model 1 cost (brown et al, 1993) <papid> J93-2003 </papid>of each side of sentence pair given the other side, normalised with respect to both sentence lengths.</citsent>
<aftsection>
<nextsent>this filter was trained on corpus composed of eparl, nc, and un data.
</nextsent>
<nextsent>the other filter is an n-gram language model(lm) cost of the target sentence (see section 3), normalised with respect to its length.
</nextsent>
<nextsent>this filter was trained with all monolingual resources available except the 109 data.
</nextsent>
<nextsent>we generated two subsets, bothby selecting sentence pairs with lexical cost inferior to 4, and an lm cost respectively inferior to 2.3 (1091, 115 million english words) and 2.6 (10 9 2, 232 million english words).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI114">
<title id=" W11-2158.xml">lium8217s smt machine translation systems for wmt 2011 </title>
<section> resources used.  </section>
<citcontext>
<prevsection>
<prevsent>for wmt11, we directly used the word-to-word alignments produced by the decoder at the output instead of gizas alignments.
</prevsent>
<prevsent>this speeds-up the procedure and yields thesame results in our experiments.
</prevsent>
</prevsection>
<citsent citstr=" W11-2132 ">
a detailed comparison is given in (lambert et al, 2011).<papid> W11-2132 </papid>second, as in last years evaluation, we automatically extracted and aligned parallel sentences from comparable in-domain corpora.</citsent>
<aftsection>
<nextsent>we used the afp and apw news texts since there are available in the french and english ldc gigaword corpora.
</nextsent>
<nextsent>the general architecture of our parallel sentence extraction system is described in detail by abdul-rauf and schwenk (2009).
</nextsent>
<nextsent>we first translated 91m words from french into english using our first stage smt system.
</nextsent>
<nextsent>these english sentences were then used to search for translations in the english afp and apwtexts of the gigaword corpus using information retrieval techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI115">
<title id=" W11-2158.xml">lium8217s smt machine translation systems for wmt 2011 </title>
<section> architecture of the smt system.  </section>
<citcontext>
<prevsection>
<prevsent>allour models are case sensitive and include punctuation.
</prevsent>
<prevsent>the bleu scores reported in this paper were calculated with the tool multi-bleu.perl and are case sensitive.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the goal of statistical machine translation (smt) isto produce target sentence from source sentence . our main system is phrase-based system (koehn et al, 2003; och and ney, 2003), <papid> J03-1002 </papid>but wehave also performed some experiments with hierarchical system (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>both use log linear framework in order to introduce several models explaining the translation process: e?
</nextsent>
<nextsent>= argmax p(e|f) = argmax {exp( ? ihi(e, f))} (1) the feature functions hi are the system model sand the weights are typically optimized to maximize scoring function on development set (ochand ney, 2002).<papid> P02-1038 </papid></nextsent>
<nextsent>the phrase-based system uses fourteen features functions, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI116">
<title id=" W11-2158.xml">lium8217s smt machine translation systems for wmt 2011 </title>
<section> architecture of the smt system.  </section>
<citcontext>
<prevsection>
<prevsent>allour models are case sensitive and include punctuation.
</prevsent>
<prevsent>the bleu scores reported in this paper were calculated with the tool multi-bleu.perl and are case sensitive.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
the goal of statistical machine translation (smt) isto produce target sentence from source sentence . our main system is phrase-based system (koehn et al, 2003; och and ney, 2003), <papid> J03-1002 </papid>but wehave also performed some experiments with hierarchical system (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>both use log linear framework in order to introduce several models explaining the translation process: e?
</nextsent>
<nextsent>= argmax p(e|f) = argmax {exp( ? ihi(e, f))} (1) the feature functions hi are the system model sand the weights are typically optimized to maximize scoring function on development set (ochand ney, 2002).<papid> P02-1038 </papid></nextsent>
<nextsent>the phrase-based system uses fourteen features functions, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI117">
<title id=" W11-2158.xml">lium8217s smt machine translation systems for wmt 2011 </title>
<section> architecture of the smt system.  </section>
<citcontext>
<prevsection>
<prevsent>the goal of statistical machine translation (smt) isto produce target sentence from source sentence . our main system is phrase-based system (koehn et al, 2003; och and ney, 2003), <papid> J03-1002 </papid>but wehave also performed some experiments with hierarchical system (chiang, 2007).<papid> J07-2003 </papid></prevsent>
<prevsent>both use log linear framework in order to introduce several models explaining the translation process: e?</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
= argmax p(e|f) = argmax {exp( ? ihi(e, f))} (1) the feature functions hi are the system model sand the weights are typically optimized to maximize scoring function on development set (ochand ney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>the phrase-based system uses fourteen features functions, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).
</nextsent>
<nextsent>the hierarchical system uses only 8 features: lm weight, word penalty and six weights for the translation model.
</nextsent>
<nextsent>both systems are based on the moses smt toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and constructed as follows.</nextsent>
<nextsent>465first, word alignments in both directions are cal culated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI118">
<title id=" W11-2158.xml">lium8217s smt machine translation systems for wmt 2011 </title>
<section> architecture of the smt system.  </section>
<citcontext>
<prevsection>
<prevsent>the phrase-based system uses fourteen features functions, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty and target language model (lm).
</prevsent>
<prevsent>the hierarchical system uses only 8 features: lm weight, word penalty and six weights for the translation model.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
both systems are based on the moses smt toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and constructed as follows.</citsent>
<aftsection>
<nextsent>465first, word alignments in both directions are calculated.
</nextsent>
<nextsent>we used multi-threaded version of the giza++ tool (gao and vogel, 2008).<papid> W08-0509 </papid>1 this speeds up the process and corrects an error of giza++ that can appear with rare words.</nextsent>
<nextsent>phrases, lexical reorderings or hierarchical rules are extracted using the default settings of the moses toolkit.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI119">
<title id=" W11-2158.xml">lium8217s smt machine translation systems for wmt 2011 </title>
<section> architecture of the smt system.  </section>
<citcontext>
<prevsection>
<prevsent>both systems are based on the moses smt toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and constructed as follows.</prevsent>
<prevsent>465first, word alignments in both directions are cal culated.</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
we used multi-threaded version of the giza++ tool (gao and vogel, 2008).<papid> W08-0509 </papid>1 this speeds up the process and corrects an error of giza++ that can appear with rare words.</citsent>
<aftsection>
<nextsent>phrases, lexical reorderings or hierarchical rules are extracted using the default settings of the moses toolkit.
</nextsent>
<nextsent>the parameters of moses were tuned onnewstest2009, using the new?
</nextsent>
<nextsent>mert tool.
</nextsent>
<nextsent>we repeated the training process three times, each with different seed value for the optimisation algorithm.in this way we have an rough idea of the error introduced by the tuning process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI120">
<title id=" W11-2158.xml">lium8217s smt machine translation systems for wmt 2011 </title>
<section> treatment of unknown words.  </section>
<citcontext>
<prevsection>
<prevsent>the continuous space language model is interpolated with the 4-gram back-off model and used to rescore n-bestlists.
</prevsent>
<prevsent>this reduces the perplexity by about 8% relative.
</prevsent>
</prevsection>
<citsent citstr=" P08-2015 ">
finally, we propose method to actually add new translations to the system inspired from (habash, 2008).<papid> P08-2015 </papid></citsent>
<aftsection>
<nextsent>for this, we propose to identity unknown words and propose possible translations.moses has two options when encountering an unknown word in the source language: keep it as it is or drop it.
</nextsent>
<nextsent>the first option may be good choice for languages that use the same writing system since the unknown word may be proper name.
</nextsent>
<nextsent>the second option is usually used when translating between language based on different scripts, e.g. translating 1the source is available at http://www.cs.cmu.edu/ qing/ source language source language target language french stemmed form english finies fini finished effaces efface?
</nextsent>
<nextsent>erased hawaienne hawaien hawaiian ...
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI122">
<title id=" W11-2158.xml">lium8217s smt machine translation systems for wmt 2011 </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>final system in both translation directions our best system was theone trained on eparl+nc+1092+news+ir.
</prevsent>
<prevsent>we further achieved small improvements by pruning the phrase-table and by increasing the beam size.
</prevsent>
</prevsection>
<citsent citstr=" D07-1103 ">
to prune the phrase-table, we used the sigtest-filteravailable in moses (johnson et al, 2007), <papid> D07-1103 </papid>more precisely the ??</citsent>
<aftsection>
<nextsent> filter3.
</nextsent>
<nextsent>we also build hierarchical systems on the various human translated corpora, using up to 323m words(corpora eparl+nc+1092).
</nextsent>
<nextsent>the systems yielded similar results than the phrase-based approach, but required much more computational resources, in particular large amounts of main memory to perform the translations.
</nextsent>
<nextsent>running the decoder was actually only possible with binarized rule-tables.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI123">
<title id=" W11-1910.xml">supervised coreference resolution with sucre </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W11-1901 ">
in this paper we present sucre (kobdaniand schutze, 2010) that is modular coreference resolution system participating in theconll-2011 shared task: modeling unrestricted coreference in ontonote (pradhan et al., 2011).<papid> W11-1901 </papid></citsent>
<aftsection>
<nextsent>the sucres modular architecture provides clean separation between data storage, feature engineering and machine learning algorithms.
</nextsent>
<nextsent>noun phrase coreference resolution is the process of finding markables (noun phrase) referring to the same real world entity or concept.
</nextsent>
<nextsent>in other words, this process groups the markables of document into entities (equivalence classes) so that all markables in an entity are coreferent.
</nextsent>
<nextsent>examples of applications of coreference resolution are information extraction, question answering and automatic summarization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI124">
<title id=" W11-1910.xml">supervised coreference resolution with sucre </title>
<section> feature engineering.  </section>
<citcontext>
<prevsection>
<prevsent>in recent years there has been substantial work onthe problem of coreference resolution.
</prevsent>
<prevsent>most methods present and report on the benchmark datasets for english.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
the feature sets they use are based on(soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>these features consist of string based features, distance features, span features, partof-speech features, grammatical features, and agreement features.
</nextsent>
<nextsent>we defined comprehensive set of features basedon previous coreference resolution systems for english, e.g.
</nextsent>
<nextsent>(bengtson and roth, 2008).<papid> D08-1031 </papid></nextsent>
<nextsent>in the common approach to coreference resolution we have chosen, features are link features, i.e., features are defined over pair of markables.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI126">
<title id=" W11-1910.xml">supervised coreference resolution with sucre </title>
<section> feature engineering.  </section>
<citcontext>
<prevsection>
<prevsent>these features consist of string based features, distance features, span features, partof-speech features, grammatical features, and agreement features.
</prevsent>
<prevsent>we defined comprehensive set of features basedon previous coreference resolution systems for english, e.g.
</prevsent>
</prevsection>
<citsent citstr=" D08-1031 ">
(bengtson and roth, 2008).<papid> D08-1031 </papid></citsent>
<aftsection>
<nextsent>in the common approach to coreference resolution we have chosen, features are link features, i.e., features are defined over pair of markables.
</nextsent>
<nextsent>for link feature definition and extraction, the headwords of mark ables are usually used, but in some cases the headword is not suitable choice.
</nextsent>
<nextsent>for example, consider these two markables: the book and book, in both cases book is the head word but to distinguish which mark able is definite and which indefinite additional information about the markables has to betaken into account.
</nextsent>
<nextsent>now consider these two mark ables: the university students in germany and the university students in france in this case the headwords and the first four words of each mark able are the same but they cannot be co referent, and this could be detected only by looking at the entire nounphrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI127">
<title id=" W11-1910.xml">supervised coreference resolution with sucre </title>
<section> feature engineering.  </section>
<citcontext>
<prevsection>
<prevsent>some features require complex pre process 71ing or complex definitions.
</prevsent>
<prevsent>consider the two mark ables the members of parliament and the members of the european union.
</prevsent>
</prevsection>
<citsent citstr=" S10-1018 ">
the semantic class of members is person in the first case and country in the second.to cover all such cases, we introduced feature definition language (kobdani et al, 2010).<papid> S10-1018 </papid></citsent>
<aftsection>
<nextsent>with the feature definition language we will be able to access all information that is connected to mark able, including the first, last and headwords of the two mark ables; all other words of the two markables; and the two markables as atomic elements.
</nextsent>
<nextsent>after defining new features (new definition from scratch or definition by combination of existing fea tures), we have to evaluate them.
</nextsent>
<nextsent>in principle, wecould use any figure of merit to evaluate the usefulness of feature or to compare two similar features, including gini coefficient, mutual information, and correlation coefficient.
</nextsent>
<nextsent>in our current system, expected information gain (ig) and information gain ratio (igr) are used.as an example, consider the following two features, which can be considered different attempts to formalize the same linguistic property: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI133">
<title id=" W11-1910.xml">supervised coreference resolution with sucre </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>3.6 link feature definition and extraction.
</prevsent>
<prevsent>the output of the link generator, which is the list of the generated links, is the input to the link feature extractor for creating train and test datasets.
</prevsent>
</prevsection>
<citsent citstr=" P11-1079 ">
to do this, the feature definitions are used to extract the feature values of the links (kobdani et al, 2011).<papid> P11-1079 </papid></citsent>
<aftsection>
<nextsent>3.7 learning.
</nextsent>
<nextsent>for learning we implemented decision tree classifier (quinlan, 1993).
</nextsent>
<nextsent>to achieve state-of-the-art performance, in addition to decision tree we also tried support vector machine and maximum entropy that did not perform better than decision tree.
</nextsent>
<nextsent>3.8 classification and clustering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI134">
<title id=" W11-1910.xml">supervised coreference resolution with sucre </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the automatically preprocessed part consists of 303 documents containing total of 136257 tokens, 52189 automatically detected markables, 14291 true markables and 3752 chains.
</prevsent>
<prevsent>the gold preprocessed part consists of 303 documents containing total of 136257 tokens, 52262 automatically detected markables, 13789 true markables and 3752 chains.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
we report recall, precision, and f1 for muc (vi lain et al, 1995), <papid> M95-1005 </papid>b3 (bagga and baldwin, 1998),ceafm /ceafe (luo, 2005) <papid> H05-1004 </papid>and blanc (re casens et al, 2010).<papid> S10-1001 </papid></citsent>
<aftsection>
<nextsent>table 1 presents results of our system for the automatically detected markables.
</nextsent>
<nextsent>it is apparent from this table that the application of the gold preprocessed documents slightly improves the performance (md-f1: +1.51; muc-f1: +2.15; b3-f1: 1http://www.bbn.com/ontonotes/ automatic gold rec.
</nextsent>
<nextsent>prec.
</nextsent>
<nextsent>f1 rec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI135">
<title id=" W11-1910.xml">supervised coreference resolution with sucre </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the automatically preprocessed part consists of 303 documents containing total of 136257 tokens, 52189 automatically detected markables, 14291 true markables and 3752 chains.
</prevsent>
<prevsent>the gold preprocessed part consists of 303 documents containing total of 136257 tokens, 52262 automatically detected markables, 13789 true markables and 3752 chains.
</prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
we report recall, precision, and f1 for muc (vi lain et al, 1995), <papid> M95-1005 </papid>b3 (bagga and baldwin, 1998),ceafm /ceafe (luo, 2005) <papid> H05-1004 </papid>and blanc (re casens et al, 2010).<papid> S10-1001 </papid></citsent>
<aftsection>
<nextsent>table 1 presents results of our system for the automatically detected markables.
</nextsent>
<nextsent>it is apparent from this table that the application of the gold preprocessed documents slightly improves the performance (md-f1: +1.51; muc-f1: +2.15; b3-f1: 1http://www.bbn.com/ontonotes/ automatic gold rec.
</nextsent>
<nextsent>prec.
</nextsent>
<nextsent>f1 rec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI136">
<title id=" W11-1910.xml">supervised coreference resolution with sucre </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the automatically preprocessed part consists of 303 documents containing total of 136257 tokens, 52189 automatically detected markables, 14291 true markables and 3752 chains.
</prevsent>
<prevsent>the gold preprocessed part consists of 303 documents containing total of 136257 tokens, 52262 automatically detected markables, 13789 true markables and 3752 chains.
</prevsent>
</prevsection>
<citsent citstr=" S10-1001 ">
we report recall, precision, and f1 for muc (vi lain et al, 1995), <papid> M95-1005 </papid>b3 (bagga and baldwin, 1998),ceafm /ceafe (luo, 2005) <papid> H05-1004 </papid>and blanc (re casens et al, 2010).<papid> S10-1001 </papid></citsent>
<aftsection>
<nextsent>table 1 presents results of our system for the automatically detected markables.
</nextsent>
<nextsent>it is apparent from this table that the application of the gold preprocessed documents slightly improves the performance (md-f1: +1.51; muc-f1: +2.15; b3-f1: 1http://www.bbn.com/ontonotes/ automatic gold rec.
</nextsent>
<nextsent>prec.
</nextsent>
<nextsent>f1 rec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI137">
<title id=" W11-1905.xml">exploring lexicalized features for coreference resolution </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>in this paper, we describe coreference solver based on the extensive use of lexical features and features extracted from dependency graphs of the sentences.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
the solver uses soon et al (2001)<papid> J01-4004 </papid>s classical resolution algorithm based on pairwise classification of the men tions.</citsent>
<aftsection>
<nextsent>we applied this solver to the closed track of the conll 2011 shared task (pradhan et al,2011).<papid> W11-1901 </papid></nextsent>
<nextsent>we carried out systematic optimization of the feature set using cross-validation that led us to retain 24 features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI141">
<title id=" W11-1905.xml">exploring lexicalized features for coreference resolution </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we describe coreference solver based on the extensive use of lexical features and features extracted from dependency graphs of the sentences.
</prevsent>
<prevsent>the solver uses soon et al (2001)<papid> J01-4004 </papid>s classical resolution algorithm based on pairwise classification of the men tions.</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
we applied this solver to the closed track of the conll 2011 shared task (pradhan et al,2011).<papid> W11-1901 </papid></citsent>
<aftsection>
<nextsent>we carried out systematic optimization of the feature set using cross-validation that led us to retain 24 features.
</nextsent>
<nextsent>using this set, we reached muc score of 58.61 on the test set of the shared task.
</nextsent>
<nextsent>we analyzed the impact of the features on the development set and we show the importance of lexicalization as well as of properties related to dependency links in coreference resolution.
</nextsent>
<nextsent>in this paper, we present our contribution to the closed track of the 2011 conll shared task (prad han et al, 2011).<papid> W11-1901 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI147">
<title id=" W11-1905.xml">exploring lexicalized features for coreference resolution </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>in the preprocessing step, we assigned number and gender to each mention.
</prevsent>
<prevsent>for the pronominal mentions, we used manually compiled lists of pronouns, where we marked the number and gender.
</prevsent>
</prevsection>
<citsent citstr=" P06-1005 ">
45 for non pronominal mentions, we used the number and gender data (bergsma and lin, 2006) <papid> P06-1005 </papid>provided by the task organizers and queried it for the head word of the mention.</citsent>
<aftsection>
<nextsent>in cases of ambiguity (e.g. the pronoun you), or missing entries in the data for non pronominals, we assigned an unknown value.
</nextsent>
<nextsent>2.1 generation of training examples.
</nextsent>
<nextsent>to create set of training examples, we used pairs of mentions following the method outlined by soon et al (2001)<papid> J01-4004 </papid>.</nextsent>
<nextsent>for each anaphoric mention mj andits closest preceding antecedent mi, we built positive example: = {(mi,mj)}.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI156">
<title id=" W11-1905.xml">exploring lexicalized features for coreference resolution </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>the decoding algorithm devised by soon et al (2001)<papid> J01-4004 </papid> selects the closest preceding mention deemed to be co referent by the classifier.</prevsent>
<prevsent>this clustering algorithm is commonly referred to as closest-firstclustering.</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
ng and cardie (2002) <papid> P02-1014 </papid>suggested different clustering procedure, commonly referred to as best-first clustering.</citsent>
<aftsection>
<nextsent>this algorithm selects the most likely antecedent classified as co referent with the anaphoric mention.
</nextsent>
<nextsent>during early experiments, we found that while the best-first method increases the performance on non pronominal anaphoric expressions, it has the opposite effect on pronominal anaphoric expressions.
</nextsent>
<nextsent>consequently, we settled onusing the closest-first clustering method for pronominal mentions, and the best-first clustering method otherwise.
</nextsent>
<nextsent>for the best-first clustering, we used the probability output from our logistic classifiers and threshold of 0.5.after clustering mentions in document, we discard all remaining singleton mentions, as they were excluded from the annotation in the conll 2011 shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI163">
<title id=" W11-1905.xml">exploring lexicalized features for coreference resolution </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 semantic role features.
</prevsent>
<prevsent>we tried to exploit the semantic roles that were included in the conll 2011 dataset.
</prevsent>
</prevsection>
<citsent citstr=" E06-2015 ">
ponzetto and strube (2006) <papid> E06-2015 </papid>suggested using the concatenation of the predicate and the role label for mention that has semantic role in predicate.</citsent>
<aftsection>
<nextsent>they introduced two new features, semrole and semrole, that correspond to the semantic roles filled by each of the mentions in pair.
</nextsent>
<nextsent>we included these features in our pool of feature templates, but we could not see any contribution from them during the feature selection.
</nextsent>
<nextsent>we also introduced number of feature templates that only applied to pairs of mentions that occur in the same semantic role proposition.
</nextsent>
<nextsent>these templates included the concatenation of the two labels of the arguments and the predicate sense label, and variations of these that also included the headwords of either the antecedent or anaphor, or both.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI176">
<title id=" W11-1916.xml">mention detection heuristics for the ontonotes annotations </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" N10-1061 ">
our submission was reduced version of the system described in haghighi and klein (2010), <papid> N10-1061 </papid>with extensions to improve mention detection to suit the ontonotes annotation scheme.</citsent>
<aftsection>
<nextsent>including exact matching mention detection in this shared task added new and challenging dimension to the problem, particularly for our system, which previously useda very permissive detection method.
</nextsent>
<nextsent>we improved this aspect of the system by adding filters based on the annotation scheme for ontonotes and analysis of system behavior onthe development set.
</nextsent>
<nextsent>these changes led to improvements in coreference f-score of 10.06, 5.71, 6.78, 6.63 and 3.09 on the muc, b3,ceaf-e, ceaf-m and blanc, metrics, respectively, and final task score of 47.10.
</nextsent>
<nextsent>coreference resolution is concerned with identifying mentions of entities in text and determining which mentions are referring to the same entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI178">
<title id=" W11-1916.xml">mention detection heuristics for the ontonotes annotations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>previously the focus in the field has been on the latter task.
</prevsent>
<prevsent>typically, mentions were considered correct if their span was within the true span of gold mention, and contained the head word.
</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
this task (pradhan et al, 2011) <papid> W11-1901 </papid>has set harder challenge by only considering exact matches to be correct.</citsent>
<aftsection>
<nextsent>our system uses an unsupervised approach based on generative model.
</nextsent>
<nextsent>unlike previous work, we did not use the bllip or wikipedia data described in haghighi and klein (2010).<papid> N10-1061 </papid></nextsent>
<nextsent>this was necessary for the system to be eligible for the closed task.the system detects mentions by finding the maximal projection of every noun and pronoun.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI184">
<title id=" W11-1916.xml">mention detection heuristics for the ontonotes annotations </title>
<section> mention detection extensions.  </section>
<citcontext>
<prevsection>
<prevsent>the standard approach used in the system to detect mentions is to consider each word and its maximal projection, accepting it only if the span is an np orthe word is pronoun.
</prevsent>
<prevsent>this approach will introduce spurious mentions if the parser makes mistake, or if the np is not considered mention in the ontonotes corpus.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
in this work, we considered the provided parses and parses produced by the berkeley parser (petrov et al, 2006) <papid> P06-1055 </papid>trained on the provided training data.</citsent>
<aftsection>
<nextsent>we added set of filters based on the annotation scheme described by pradhan et al (2007).
</nextsent>
<nextsent>some filters are applied before coreference resolution and others afterward, as described below.
</nextsent>
<nextsent>103 dataset filters r dev none 37.59 76.93 50.50 pre 39.49 76.83 52.17 post 59.05 68.08 63.24 all 58.69 67.98 63.00 test all 56.97 69.77 62.72 table 1: mention detection performance with various subsets of the filters.
</nextsent>
<nextsent>3.2 before coreference resolution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI188">
<title id=" W11-1921.xml">coreference resolution system using maximum entropy classifier </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>in this paper, we present our supervised learning approach to coreference resolution in conll corpus.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
the system relies on maximum entropy-based classifier for pairs of mentions, and adopts rich linguisitical- ly motivated feature set, which mostly has been introduced by soon et al(2001), <papid> J01-4004 </papid>and experiment with alter naive resolution proc-ess, preprocessing tools,and classifiers.</citsent>
<aftsection>
<nextsent>we optimize the systems performance for m- uc (vilain et al 1995), bcub (bagga and baldwin, 1998) and ceaf (luo, 2005) .<papid> H05-1004 </papid></nextsent>
<nextsent>the coreference resolution is the task in which all expressions refer to the same entity in discourse will be identified.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI189">
<title id=" W11-1921.xml">coreference resolution system using maximum entropy classifier </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present our supervised learning approach to coreference resolution in conll corpus.
</prevsent>
<prevsent>the system relies on maximum entropy-based classifier for pairs of mentions, and adopts rich linguisitical- ly motivated feature set, which mostly has been introduced by soon et al(2001), <papid> J01-4004 </papid>and experiment with alter naive resolution proc-ess, preprocessing tools,and classifiers.</prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
we optimize the systems performance for m- uc (vilain et al 1995), bcub (bagga and baldwin, 1998) and ceaf (luo, 2005) .<papid> H05-1004 </papid></citsent>
<aftsection>
<nextsent>the coreference resolution is the task in which all expressions refer to the same entity in discourse will be identified.
</nextsent>
<nextsent>as the core of natural language processing, coreference resolution is significant to message understanding, information extraction, text summarization, information retrieval, information filtration, and machine translation.
</nextsent>
<nextsent>a considerable engineering efforts is needed for the full coreference resolution task, and significant part of this effort concerns feature engineering.
</nextsent>
<nextsent>the backbone of our system can be split into two subproblems: mention detection and creation of entitly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI191">
<title id=" W11-2138.xml">improving translation model by monolingual data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this paper builds upon the idea outlined in bojar and tamchyna (2011), describing how this technique was incorporated in the wmtshared task and extending the experimental evaluation of reverse self-training in several directions ? the examined language pairs (section 4.2), data size (section 4.3) and back-off techniques (section 4.4).
</prevsent>
<prevsent>the idea of using monolingual data for improving the translation model has been explored in several previous works.
</prevsent>
</prevsection>
<citsent citstr=" W09-0432 ">
bertoldi and federico (2009) <papid> W09-0432 </papid>used monolingual data for adapting existing translation models to translation of data from different domains.</citsent>
<aftsection>
<nextsent>in their experiments, the most effective approach was to train new translation model from fake?
</nextsent>
<nextsent>parallel data consisting of target-side monolingual data and their machine translation into the source language by baseline system.ueffing et al (2007) used boot-strapping technique to extend translation models using monolingual data.
</nextsent>
<nextsent>they gradually translated additional source-side sentences and selectively incorporated them and their translations in the model.our technique also bears similarity to de gispert et al (2005), in that we try to use back-offfor surface forms to generalize our model and produce translations with word forms never seen in the original parallel data.
</nextsent>
<nextsent>however, instead of rule based approach, we take advantage of the available 330 source english target czech czech lemmatized parallel (small) cat chased.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI192">
<title id=" W11-2138.xml">improving translation model by monolingual data </title>
<section> reverse self-training.  </section>
<citcontext>
<prevsection>
<prevsent>using available parallel data, we first train an mt system to translate from the target to the source language.
</prevsent>
<prevsent>since we want to gather new word forms from the monolingual data, this reverse model needs the ability to translate them.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
for that purpose we use factored translation model (koehn and hoang, 2007) <papid> D07-1091 </papid>with two alternative decoding paths: form form and back-offform.</citsent>
<aftsection>
<nextsent>we experimented with several options for the back-off (simple stemming by trun cation or full lemmatization), see section 4.4.
</nextsent>
<nextsent>the decoder can thus use less sparse representation of words if their exact forms are not available in the parallel data.
</nextsent>
<nextsent>we use this reverse model to translate (much larger) target-side monolingual data into the source language.
</nextsent>
<nextsent>we preserve the word alignments of the phrases as used in the decoding so we directly obtain the word alignment in the new parallel?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI193">
<title id=" W11-2138.xml">improving translation model by monolingual data </title>
<section> reverse self-training.  </section>
<citcontext>
<prevsection>
<prevsent>corpus.
</prevsent>
<prevsent>this gives us enough information to proceed with the standard mt system training ? we extract and score the phrases consistent with the constructed word alignment and create the phrase table.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we combine this enlarged translation model with model trained on the true parallel data and use minimum error rate training (och, 2003) <papid> P03-1021 </papid>to find the balance between the two models.</citsent>
<aftsection>
<nextsent>the final model has four separate components ? two language models (one trained on parallel and one on monolingual data) and the two translation models.we do not expect the translation quality to improve simply because more data is included in training ? by adding translations generated using known data, the model could gain only new combinations of known words.
</nextsent>
<nextsent>however, by using back-off to less sparse units (e.g. lemmas) in the factored target source translation, we enable the decoder to produce previously unseen surface forms.
</nextsent>
<nextsent>these translations are then included in the model, reducing the data sparseness of the target-side surface forms.
</nextsent>
<nextsent>we used common tools for phrase-based translation ? moses (koehn et al, 2007) <papid> P07-2045 </papid>decoder and tools, srilm (stolcke, 2002) and kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and giza++ (och and ney, 2000) <papid> P00-1056 </papid>for word alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI194">
<title id=" W11-2138.xml">improving translation model by monolingual data </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>however, by using back-off to less sparse units (e.g. lemmas) in the factored target source translation, we enable the decoder to produce previously unseen surface forms.
</prevsent>
<prevsent>these translations are then included in the model, reducing the data sparseness of the target-side surface forms.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we used common tools for phrase-based translation ? moses (koehn et al, 2007) <papid> P07-2045 </papid>decoder and tools, srilm (stolcke, 2002) and kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and giza++ (och and ney, 2000) <papid> P00-1056 </papid>for word alignments.</citsent>
<aftsection>
<nextsent>for reverse self-training, we needed moses to also output word alignments between source sentences and their translations.
</nextsent>
<nextsent>as we were not able to make the existing version of this feature work, we added new option and re-implemented this funcionality.we relyon automatic translation quality evaluation throughout our paper, namely the well established bleu metric (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
<nextsent>we estimate 95% confidence bounds for the scores as described in koehn (2004).<papid> W04-3250 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI195">
<title id=" W11-2138.xml">improving translation model by monolingual data </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>however, by using back-off to less sparse units (e.g. lemmas) in the factored target source translation, we enable the decoder to produce previously unseen surface forms.
</prevsent>
<prevsent>these translations are then included in the model, reducing the data sparseness of the target-side surface forms.
</prevsent>
</prevsection>
<citsent citstr=" W11-2123 ">
we used common tools for phrase-based translation ? moses (koehn et al, 2007) <papid> P07-2045 </papid>decoder and tools, srilm (stolcke, 2002) and kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and giza++ (och and ney, 2000) <papid> P00-1056 </papid>for word alignments.</citsent>
<aftsection>
<nextsent>for reverse self-training, we needed moses to also output word alignments between source sentences and their translations.
</nextsent>
<nextsent>as we were not able to make the existing version of this feature work, we added new option and re-implemented this funcionality.we relyon automatic translation quality evaluation throughout our paper, namely the well established bleu metric (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
<nextsent>we estimate 95% confidence bounds for the scores as described in koehn (2004).<papid> W04-3250 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI196">
<title id=" W11-2138.xml">improving translation model by monolingual data </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>however, by using back-off to less sparse units (e.g. lemmas) in the factored target source translation, we enable the decoder to produce previously unseen surface forms.
</prevsent>
<prevsent>these translations are then included in the model, reducing the data sparseness of the target-side surface forms.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we used common tools for phrase-based translation ? moses (koehn et al, 2007) <papid> P07-2045 </papid>decoder and tools, srilm (stolcke, 2002) and kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and giza++ (och and ney, 2000) <papid> P00-1056 </papid>for word alignments.</citsent>
<aftsection>
<nextsent>for reverse self-training, we needed moses to also output word alignments between source sentences and their translations.
</nextsent>
<nextsent>as we were not able to make the existing version of this feature work, we added new option and re-implemented this funcionality.we relyon automatic translation quality evaluation throughout our paper, namely the well established bleu metric (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
<nextsent>we estimate 95% confidence bounds for the scores as described in koehn (2004).<papid> W04-3250 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI197">
<title id=" W11-2138.xml">improving translation model by monolingual data </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we used common tools for phrase-based translation ? moses (koehn et al, 2007) <papid> P07-2045 </papid>decoder and tools, srilm (stolcke, 2002) and kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and giza++ (och and ney, 2000) <papid> P00-1056 </papid>for word alignments.</prevsent>
<prevsent>for reverse self-training, we needed moses to also output word alignments between source sentences and their translations.</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
as we were not able to make the existing version of this feature work, we added new option and re-implemented this funcionality.we relyon automatic translation quality evaluation throughout our paper, namely the well established bleu metric (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>we estimate 95% confidence bounds for the scores as described in koehn (2004).<papid> W04-3250 </papid></nextsent>
<nextsent>we evaluated our translations on lower-cased sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI198">
<title id=" W11-2138.xml">improving translation model by monolingual data </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for reverse self-training, we needed moses to also output word alignments between source sentences and their translations.
</prevsent>
<prevsent>as we were not able to make the existing version of this feature work, we added new option and re-implemented this funcionality.we relyon automatic translation quality evaluation throughout our paper, namely the well established bleu metric (papineni et al, 2002).<papid> P02-1040 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
we estimate 95% confidence bounds for the scores as described in koehn (2004).<papid> W04-3250 </papid></citsent>
<aftsection>
<nextsent>we evaluated our translations on lower-cased sentences.
</nextsent>
<nextsent>4.1 data sources.
</nextsent>
<nextsent>aside from the wmt 2011 translation task data, we also used several additional data sources for the experiments aimed at evaluating various aspects of reverse self-training.
</nextsent>
<nextsent>jrc-acquis we used the jrc-acquis 3.0 corpus (steinbergeret al, 2006) mainly because of the number of available languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI199">
<title id=" W11-2210.xml">unsupervised mining of lexical variants from noisy text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the text found in these media can deviate wildly from the standard rules of orthography, syntax and even semantics and present significant problems to downstream applications which make use of this noisy?
</prevsent>
<prevsent>data.
</prevsent>
</prevsection>
<citsent citstr=" W11-0704 ">
in social this work was done while the first author was visiting student at isi from the mih media labat stellenbosch university, south africa.media this noise might result from the need for social identity, simple spelling errors due to high in put cost associated with the device (e.g. typing on mobile phone), space constraints imposed by the specific medium or even users location (gouws et al., 2011).<papid> W11-0704 </papid></citsent>
<aftsection>
<nextsent>in machine-generated texts, noise might result from imperfect inputs, imperfect conversion algorithms, or various degrees of each.recently, several works have looked at the process of normalizing these noisy?
</nextsent>
<nextsent>types of text into more standard english, or in other words, to convert the various forms of idiosyncratic spelling and writing errors found in these media into what would normally be considered standard english orthography.
</nextsent>
<nextsent>many of these works relyon supervised methods which share the common burden of requiring training data in the form of noisy input and clean output pairs.
</nextsent>
<nextsent>the problem with developing large amounts of annotated training data is that it is costly andre quires annotators with sufficient expertise.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI200">
<title id=" W11-2210.xml">unsupervised mining of lexical variants from noisy text </title>
<section> training pair mining.  </section>
<citcontext>
<prevsection>
<prevsent>our implementation, which makes use of hadoops map reduce distributed programming paradigm, can efficiently compute all pairs distributional similarity over very large corpora (e.g., the twitter pairs we use later were mined from corpus of half billion twitter messages).
</prevsent>
<prevsent>using similar strategy as pasca and dienes, we define term contexts as the bigrams that appear to the left and to the right of given word (pasca anddienes, 2005).
</prevsent>
</prevsection>
<citsent citstr=" P08-1077 ">
following standard practice, the contextual vectors are weighted according to pointwise mutual information and the similarity between the vectors is computed using the cosine similarity metric (lin and pantel, 2001; bhagat and ravichandran, 2008).<papid> P08-1077 </papid></citsent>
<aftsection>
<nextsent>it is important to note that there are many other possible ways to compute distributional and semantic similarity, and that just about any approach can be used within our framework.
</nextsent>
<nextsent>the approach used here was chosen because we had an existing implementation.
</nextsent>
<nextsent>indeed, other approaches may be more apt for other datasets and tasks.this approach is applied to both the common english corpus and the domain corpus.
</nextsent>
<nextsent>this yields two sets of semantically (distributionally) similar word pairs that will ultimately be used to distill unsupervised lexical variants.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI203">
<title id=" W11-2210.xml">unsupervised mining of lexical variants from noisy text </title>
<section> negations: e.g. could? and couldnt?..  </section>
<citcontext>
<prevsection>
<prevsent>this process requires function with which to compute the similarity or alternatively, distance, between two words.
</prevsent>
<prevsent>more traditional string-similarity functions like the simple lehvenshtein string edit distance do not fare too well in this domain.
</prevsent>
</prevsection>
<citsent citstr=" C10-2022 ">
we implement the ibm-similarity (contractor et al., 2010) <papid> C10-2022 </papid>which employs slightly more advanced similarity function.</citsent>
<aftsection>
<nextsent>it finds the length of the longest common sub sequence (lcs) between two strings s1and s2, normalized by the edit distance (ed) between the consonants in each string (referred to as the consonant skeleton?
</nextsent>
<nextsent>(cs)), thus sim(s1, s2) = lcs(s1, s2) ed(cs(s1),cs(s2)) finally, the decoding step takes an input word lattice (lattice of concatenated, weighted confusion sets), and produces new lattice by incorporating the probabilities from an n-gram language model with the prior probabilities in the lattice to produce reranked posterior lattice.
</nextsent>
<nextsent>the most likely (viterbi) path through this lattice represents the decoded clean output.
</nextsent>
<nextsent>we use sri-lm (stolcke, 2002) for this.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI205">
<title id=" W11-2210.xml">unsupervised mining of lexical variants from noisy text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, their method is still trained on annotated training pairs, and hence supervised.
</prevsent>
<prevsent>a related direction is transliteration mining?
</prevsent>
</prevsection>
<citsent citstr=" W10-2405 ">
(jiampojamarn et al, 2010) <papid> W10-2405 </papid>which aims to automatically obtain bilingual lists of names written in different scripts.</citsent>
<aftsection>
<nextsent>they also employ string-similaritymeasures to find similar string pairs written in different scripts.
</nextsent>
<nextsent>however, their input data is constrained 88 to wikipedia articles written in different languages, whereas we impose no constrains on our input data, and merely require large collection thereof.
</nextsent>
<nextsent>noisy text normalization, on the other hand, has recently received lot of focus.
</nextsent>
<nextsent>most works construe the problem in the metaphors of either machine translation (mt) (bangalore et al, 2002; <papid> C02-1134 </papid>aw et al, 2006; <papid> P06-2005 </papid>kaufmann and kalita, 2010), spelling correction (choudhury et al, 2007; cookand stevenson, 2009), <papid> W09-2010 </papid>or automated speech recognition (asr) (kobus et al, 2008).<papid> C08-1056 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI206">
<title id=" W11-2210.xml">unsupervised mining of lexical variants from noisy text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, their input data is constrained 88 to wikipedia articles written in different languages, whereas we impose no constrains on our input data, and merely require large collection thereof.
</prevsent>
<prevsent>noisy text normalization, on the other hand, has recently received lot of focus.
</prevsent>
</prevsection>
<citsent citstr=" C02-1134 ">
most works construe the problem in the metaphors of either machine translation (mt) (bangalore et al, 2002; <papid> C02-1134 </papid>aw et al, 2006; <papid> P06-2005 </papid>kaufmann and kalita, 2010), spelling correction (choudhury et al, 2007; cookand stevenson, 2009), <papid> W09-2010 </papid>or automated speech recognition (asr) (kobus et al, 2008).<papid> C08-1056 </papid></citsent>
<aftsection>
<nextsent>for our evaluation, we developed an implementation of contractor (2010) which works on the same general approach as han (2011).
</nextsent>
<nextsent>the ability to automatically extract lexical variants from large noisy corpora has many practical applications, including noisy text normalization, query spelling suggestion, fixing ocr errors, and so on.this paper developed novel methodology for automatically mining such pairs from large domain specific corpus.
</nextsent>
<nextsent>the approach makes use of distributional similarity for measuring semantic similarity, novel approach for filtering common english pairs by comparing against pairs mined from large news corpus, and substring similarity measure forre-ordering the pairs according to their lexical similarity.
</nextsent>
<nextsent>to demonstrate the utility of the method, we used automatically mined pairs to construct an unsupervised exception dictionary, that was used in conjunction with string similarity measure, to form highly effective hybrid noisy text normalization technique.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI207">
<title id=" W11-2210.xml">unsupervised mining of lexical variants from noisy text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, their input data is constrained 88 to wikipedia articles written in different languages, whereas we impose no constrains on our input data, and merely require large collection thereof.
</prevsent>
<prevsent>noisy text normalization, on the other hand, has recently received lot of focus.
</prevsent>
</prevsection>
<citsent citstr=" P06-2005 ">
most works construe the problem in the metaphors of either machine translation (mt) (bangalore et al, 2002; <papid> C02-1134 </papid>aw et al, 2006; <papid> P06-2005 </papid>kaufmann and kalita, 2010), spelling correction (choudhury et al, 2007; cookand stevenson, 2009), <papid> W09-2010 </papid>or automated speech recognition (asr) (kobus et al, 2008).<papid> C08-1056 </papid></citsent>
<aftsection>
<nextsent>for our evaluation, we developed an implementation of contractor (2010) which works on the same general approach as han (2011).
</nextsent>
<nextsent>the ability to automatically extract lexical variants from large noisy corpora has many practical applications, including noisy text normalization, query spelling suggestion, fixing ocr errors, and so on.this paper developed novel methodology for automatically mining such pairs from large domain specific corpus.
</nextsent>
<nextsent>the approach makes use of distributional similarity for measuring semantic similarity, novel approach for filtering common english pairs by comparing against pairs mined from large news corpus, and substring similarity measure forre-ordering the pairs according to their lexical similarity.
</nextsent>
<nextsent>to demonstrate the utility of the method, we used automatically mined pairs to construct an unsupervised exception dictionary, that was used in conjunction with string similarity measure, to form highly effective hybrid noisy text normalization technique.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI208">
<title id=" W11-2210.xml">unsupervised mining of lexical variants from noisy text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, their input data is constrained 88 to wikipedia articles written in different languages, whereas we impose no constrains on our input data, and merely require large collection thereof.
</prevsent>
<prevsent>noisy text normalization, on the other hand, has recently received lot of focus.
</prevsent>
</prevsection>
<citsent citstr=" W09-2010 ">
most works construe the problem in the metaphors of either machine translation (mt) (bangalore et al, 2002; <papid> C02-1134 </papid>aw et al, 2006; <papid> P06-2005 </papid>kaufmann and kalita, 2010), spelling correction (choudhury et al, 2007; cookand stevenson, 2009), <papid> W09-2010 </papid>or automated speech recognition (asr) (kobus et al, 2008).<papid> C08-1056 </papid></citsent>
<aftsection>
<nextsent>for our evaluation, we developed an implementation of contractor (2010) which works on the same general approach as han (2011).
</nextsent>
<nextsent>the ability to automatically extract lexical variants from large noisy corpora has many practical applications, including noisy text normalization, query spelling suggestion, fixing ocr errors, and so on.this paper developed novel methodology for automatically mining such pairs from large domain specific corpus.
</nextsent>
<nextsent>the approach makes use of distributional similarity for measuring semantic similarity, novel approach for filtering common english pairs by comparing against pairs mined from large news corpus, and substring similarity measure forre-ordering the pairs according to their lexical similarity.
</nextsent>
<nextsent>to demonstrate the utility of the method, we used automatically mined pairs to construct an unsupervised exception dictionary, that was used in conjunction with string similarity measure, to form highly effective hybrid noisy text normalization technique.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI209">
<title id=" W11-2210.xml">unsupervised mining of lexical variants from noisy text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, their input data is constrained 88 to wikipedia articles written in different languages, whereas we impose no constrains on our input data, and merely require large collection thereof.
</prevsent>
<prevsent>noisy text normalization, on the other hand, has recently received lot of focus.
</prevsent>
</prevsection>
<citsent citstr=" C08-1056 ">
most works construe the problem in the metaphors of either machine translation (mt) (bangalore et al, 2002; <papid> C02-1134 </papid>aw et al, 2006; <papid> P06-2005 </papid>kaufmann and kalita, 2010), spelling correction (choudhury et al, 2007; cookand stevenson, 2009), <papid> W09-2010 </papid>or automated speech recognition (asr) (kobus et al, 2008).<papid> C08-1056 </papid></citsent>
<aftsection>
<nextsent>for our evaluation, we developed an implementation of contractor (2010) which works on the same general approach as han (2011).
</nextsent>
<nextsent>the ability to automatically extract lexical variants from large noisy corpora has many practical applications, including noisy text normalization, query spelling suggestion, fixing ocr errors, and so on.this paper developed novel methodology for automatically mining such pairs from large domain specific corpus.
</nextsent>
<nextsent>the approach makes use of distributional similarity for measuring semantic similarity, novel approach for filtering common english pairs by comparing against pairs mined from large news corpus, and substring similarity measure forre-ordering the pairs according to their lexical similarity.
</nextsent>
<nextsent>to demonstrate the utility of the method, we used automatically mined pairs to construct an unsupervised exception dictionary, that was used in conjunction with string similarity measure, to form highly effective hybrid noisy text normalization technique.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI210">
<title id=" W11-1911.xml">ets an error tolerable system for coreference resolution </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W11-1901 ">
this paper presents our error tolerable system for coreference resolution in conll 2011(pradhan et al , 2011) <papid> W11-1901 </papid>shared task (closed track).</citsent>
<aftsection>
<nextsent>different from most previous reported work, we detect mention candidates based on packed forest instead of single parse tree, and we use beam search algorithm based on thebell tree to create entities.
</nextsent>
<nextsent>experimental results show that our methods achieve promising results on the development set.
</nextsent>
<nextsent>over last decades, there has been increasing interest on coreference resolution within nlp community.
</nextsent>
<nextsent>the task of coreference resolution is to identify expressions in text that refer to the same discourse entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI211">
<title id=" W11-1911.xml">ets an error tolerable system for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, according to statistics, almost 3%mentions have no corresponding constituents in automatic parse trees.
</prevsent>
<prevsent>since only automatic parse trees will be provided in the final test set, the effect of parsing errors are inevitable.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
to alleviate this issue, based on given automatic parse trees, we modify state-of-the-art parser (charniak and johnson, 2005) <papid> P05-1022 </papid>to generate packed forest, and determine mention candidates among all constituents from both given parse tree and packed forest.</citsent>
<aftsection>
<nextsent>the packed forest is compact representation of all parse trees forgiven sentence.
</nextsent>
<nextsent>readers can refer to (mi et al , 2008) for detailed definitions.
</nextsent>
<nextsent>once the mentions are identified, the left step isto group mentions referring to same object into similar entity.
</nextsent>
<nextsent>this problem can be viewed as binary classification problem of determining whether each mention pairs corefer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI212">
<title id=" W11-1911.xml">ets an error tolerable system for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this problem can be viewed as binary classification problem of determining whether each mention pairs corefer.
</prevsent>
<prevsent>we use maximum entropy classifier to predict the possibility that two mentions refer to the similar entity.
</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
and mainly following the work of luo et al  (2004), <papid> P04-1018 </papid>we use beam search algorithm based on bell tree to obtain the global optimal classification.as this is the first time we participate competition of coreference resolution, we mainly concentrate on developing fault tolerant capability of our system while omitting feature engineering and other helpful technologies.</citsent>
<aftsection>
<nextsent>the first step of the coreference resolution tries to recognize occurrences of mentions in documents.
</nextsent>
<nextsent>note that we recognize mention boundaries only on development and test set while generating training 76figure 1: left side is parse tree extracted from development set, and right side is forest.
</nextsent>
<nextsent>my daughter?
</nextsent>
<nextsent>is amen tion in this discourse, however it has no corresponding constituent in parse tree, but it has corresponding constituent np0 in forest.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI213">
<title id=" W11-1911.xml">ets an error tolerable system for coreference resolution </title>
<section> determining coreference.  </section>
<citcontext>
<prevsection>
<prevsent>we train maximum entropy classifier (le, 2004) to decide whether two mentions are coreferent.
</prevsent>
<prevsent>we use the method proposed by soon, etal.s to generate the training instances, where positive instance is formed between current mention mjand its closest preceding antecedent mi, and negative instance is created by paring mj with each of the intervening mentions, mi+1, mi+2,...,mj1.we use the following features to train our classifier.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
features in soon et al work (soon et al , 2001) <papid> J01-4004 </papid>lexical features is prefix: whether the string of one mention is prefix of the other; is suffix: whether the string of one mention is suffix of the other; acronym: whether one mention is the acronym of the other; distance features sent dist: distance between the sentences containing the two mentions; men dist: number of mentions between two mentions; grammatical featuresij pronoun: whether both mentions are pro noun;i nested: whether mention is nested in an other mention;j nested: whether mention is nested in an other mention; syntax features head: whether the heads of two mentions have the same string; head pos: whether the heads of two mentions have the same pos;hea pos pairs: pairs of pos of the two men tions?</citsent>
<aftsection>
<nextsent>heads; 77 semantic features wndist: distance between two mentions in wordnet; arg0: whether mention has the semantic role of arg0; arg0: whether mention has the semantic role of arg0;ij args: whether two mentions have the semantic roles for similar predicate;in the submitted results, we use the l-bfgs parameter estimation algorithm with gaussian prior smoothing (chen and rosenfeld, 1999).
</nextsent>
<nextsent>we set the gaussian prior to 2 and train the model in 100 iterations.
</nextsent>
<nextsent>3.1 creation of entities.
</nextsent>
<nextsent>this stage aims to create the mentions detected inthe first stage into entities, according to the prediction of classifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI214">
<title id=" W11-1911.xml">ets an error tolerable system for coreference resolution </title>
<section> determining coreference.  </section>
<citcontext>
<prevsection>
<prevsent>this stage aims to create the mentions detected inthe first stage into entities, according to the prediction of classifier.
</prevsent>
<prevsent>one simple method is to use greedy algorithm, by comparing each mention to its previous mentions and refer to the one that has the highest probability.
</prevsent>
</prevsection>
<citsent citstr=" P10-1142 ">
in principle, this algorithm is too greedy and sometimes results in unreasonable partition (ng, 2010).<papid> P10-1142 </papid></citsent>
<aftsection>
<nextsent>to address this problem, we follow the literature (luo et al , 2004) <papid> P04-1018 </papid>and propose to use beam search to find global optimal partition.</nextsent>
<nextsent>intuitively, creation of entities can be casted as partition problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI217">
<title id=" W11-1911.xml">ets an error tolerable system for coreference resolution </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 data preparation.
</prevsent>
<prevsent>the shared task provided data includes information of lemma, pos, parse tree, word sense, predicate arguments, named entity and so on.
</prevsent>
</prevsection>
<citsent citstr=" P08-1067 ">
in addition to those information, we use modified in house parser to generate packed forest for each sentence in development set, and prune the packed forest with threshold p=3 (huang, 2008).<papid> P08-1067 </papid></citsent>
<aftsection>
<nextsent>since the ontonotes involves multiple genre data, we merge all files and 78 mention muc bcubed ceafm ceafe blanc baseline 58.97% 44.17% 63.24% 45.08% 37.13% 62.44% baseline gold 59.18% 44.48% 63.46% 45.37% 37.47% 62.36% sys forest 59.07% 44.4% 63.39% 45.29% 37.41% 62.41% sys btree 59.44% 44.66% 63.77% 45.62% 37.82% 62.47% sys forest btree 59.71% 44.97% 63.95% 45.91% 37.96% 62.52% table 1: experimental results on development set (f score).
</nextsent>
<nextsent>mention muc bcubed ceafm ceafe blanc sys1 54.5% 39.15% 63.91% 45.32% 37.16% 63.18% sys2 53.06% 35.55% 59.68% 38.24% 32.03% 50.13% table 2: experimental results on development set with different training division (f score).take it as our training corpus.
</nextsent>
<nextsent>we use the supplied score toolkit 3 to compute muc, bcubed, ceafm, ceafe and blanc metrics.
</nextsent>
<nextsent>4.2 experimental results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI218">
<title id=" W11-2314.xml">experimental identification of the use of hedges in the simplification of numerical expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>adaptation to particular types of users is beyond the scope of this paper.
</prevsent>
<prevsent>text simplification, relative new task in natural language processing, has been directed mainly at syntactic constructions and lexical choices that some readers find difficult, such as long sentences,passives, coordinate and subordinate clauses, abstract words, low frequency words, and abbreviations.
</prevsent>
</prevsection>
<citsent citstr=" C96-2183 ">
chandrasekar et al (1996) <papid> C96-2183 </papid>introduced two stage process, first transforming from sentence to syntactic tree, then from syntactic tree to new sentence; siddharthan (2002) instead proposed three stage process comprising analysis, transformation and generation.</citsent>
<aftsection>
<nextsent>in 1998, the project pset (carroll et al, 1998) employed lexical as well as syntactic simplifications.
</nextsent>
<nextsent>other researchers have focused on the generation of readable texts for readers with low basic skills (williams and reiter, 2005), <papid> W05-1616 </papid>and for teaching foreign languages (petersen and ostendorf, 2007).</nextsent>
<nextsent>there has been some previous work on numerical expressions but more for experts than for people who have difficulties with numeracy (ellen peters and dieckmann, 2007), (nathan f. dieckmann and peters, 2009), (ann m. bisantz and munch, 2005), (mishra h, 2011).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI219">
<title id=" W11-2314.xml">experimental identification of the use of hedges in the simplification of numerical expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>chandrasekar et al (1996) <papid> C96-2183 </papid>introduced two stage process, first transforming from sentence to syntactic tree, then from syntactic tree to new sentence; siddharthan (2002) instead proposed three stage process comprising analysis, transformation and generation.</prevsent>
<prevsent>in 1998, the project pset (carroll et al, 1998) employed lexical as well as syntactic simplifications.</prevsent>
</prevsection>
<citsent citstr=" W05-1616 ">
other researchers have focused on the generation of readable texts for readers with low basic skills (williams and reiter, 2005), <papid> W05-1616 </papid>and for teaching foreign languages (petersen and ostendorf, 2007).</citsent>
<aftsection>
<nextsent>there has been some previous work on numerical expressions but more for experts than for people who have difficulties with numeracy (ellen peters and dieckmann, 2007), (nathan f. dieckmann and peters, 2009), (ann m. bisantz and munch, 2005), (mishra h, 2011).
</nextsent>
<nextsent>however,to our knowledge, there have been no previous attempts to automatically simplify numerical information in texts.
</nextsent>
<nextsent>a corpus of numerical expressions was collected for the numgen project (williams and power,2009).<papid> W09-0620 </papid></nextsent>
<nextsent>the corpus contains 10 sets of newspaper articles and scientific papers (110 texts in total).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI220">
<title id=" W11-2314.xml">experimental identification of the use of hedges in the simplification of numerical expressions </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>there has been some previous work on numerical expressions but more for experts than for people who have difficulties with numeracy (ellen peters and dieckmann, 2007), (nathan f. dieckmann and peters, 2009), (ann m. bisantz and munch, 2005), (mishra h, 2011).
</prevsent>
<prevsent>however,to our knowledge, there have been no previous attempts to automatically simplify numerical information in texts.
</prevsent>
</prevsection>
<citsent citstr=" W09-0620 ">
a corpus of numerical expressions was collected for the numgen project (williams and power,2009).<papid> W09-0620 </papid></citsent>
<aftsection>
<nextsent>the corpus contains 10 sets of newspaper articles and scientific papers (110 texts in total).
</nextsent>
<nextsent>each set is collection of articles on the same topic ? e.g., the increased risk of breast cancer in red meat eaters, and the decline in the puffin population onthe isle of may. within each set, identical numerical facts are presented in variety of linguistic and mathematical forms.
</nextsent>
<nextsent>our survey took the form of questionnaire inwhich participants were shown sentence containing one or more numerical expressions which they were asked to simplify using hedges if necessary.
</nextsent>
<nextsent>3.1 materials.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI221">
<title id=" W11-2107.xml">meteor 13 automatic metric for reliable optimization and evaluation of machine translation systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>new metric features include improved text normalization, higher-precisionparaphrase matching, and discrimination between content and function words.
</prevsent>
<prevsent>we include ranking and adequacy versions of the metric shown to have high correlation with human judgments of translation quality as well as amore balanced tuning version shown to out perform bleu in minimum error rate training for phrase-based urdu-english system.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
the meteor1 metric (banerjee and lavie, 2005; <papid> W05-0909 </papid>denkowski and lavie, 2010<papid> W10-1751 </papid>b) has been shown tohave high correlation with human judgments in evaluations such as the 2010 acl workshop on statistical machine translation and nist metrics matr (callison-burch et al, 2010).</citsent>
<aftsection>
<nextsent>however, previous versions of the metric are still limited by lack of punctuation handling, noise in paraphrase matching, and lack of discrimination between word types.
</nextsent>
<nextsent>we introduce new resources for all wmt languages including text normalizers, filtered paraphrase tables, and function word lists.
</nextsent>
<nextsent>we show that the addition of these resources to meteor allows tuning versions of the metric that show higher correlation with human translation rankings and adequacy scores on unseen1the metric name has previously been stylized as me teor?
</nextsent>
<nextsent>or meteor?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI222">
<title id=" W11-2107.xml">meteor 13 automatic metric for reliable optimization and evaluation of machine translation systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>new metric features include improved text normalization, higher-precisionparaphrase matching, and discrimination between content and function words.
</prevsent>
<prevsent>we include ranking and adequacy versions of the metric shown to have high correlation with human judgments of translation quality as well as amore balanced tuning version shown to out perform bleu in minimum error rate training for phrase-based urdu-english system.
</prevsent>
</prevsection>
<citsent citstr=" W10-1751 ">
the meteor1 metric (banerjee and lavie, 2005; <papid> W05-0909 </papid>denkowski and lavie, 2010<papid> W10-1751 </papid>b) has been shown tohave high correlation with human judgments in evaluations such as the 2010 acl workshop on statistical machine translation and nist metrics matr (callison-burch et al, 2010).</citsent>
<aftsection>
<nextsent>however, previous versions of the metric are still limited by lack of punctuation handling, noise in paraphrase matching, and lack of discrimination between word types.
</nextsent>
<nextsent>we introduce new resources for all wmt languages including text normalizers, filtered paraphrase tables, and function word lists.
</nextsent>
<nextsent>we show that the addition of these resources to meteor allows tuning versions of the metric that show higher correlation with human translation rankings and adequacy scores on unseen1the metric name has previously been stylized as me teor?
</nextsent>
<nextsent>or meteor?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI224">
<title id=" W11-2107.xml">meteor 13 automatic metric for reliable optimization and evaluation of machine translation systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the evaluation resources are modular, usable with any other evaluation metric or mt software.
</prevsent>
<prevsent>we also conduct mt system tuning experiment on urdu-english data to compare the effectiveness of using multiple versions of meteor in minimum error rate training.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
while versions tuned to various types of human judgments do not perform as well as the widely used bleu metric (papineni et al,2002), <papid> P02-1040 </papid>balanced tuning version of meteor consistently outperforms bleu over multiple end-to-end tune-test runs on this data set.</citsent>
<aftsection>
<nextsent>the versions of meteor corresponding to the translation evaluation task submissions, (ranking and adequacy), are described in sections 3 through 5 while the submission to the tunable metrics task, (tuning), is described in section 6.
</nextsent>
<nextsent>2.1 meteor normalizer.
</nextsent>
<nextsent>whereas previous versions of meteor simply strip punctuation characters prior to scoring, version 1.3includes new text normalizer intended specifically for translation evaluation.
</nextsent>
<nextsent>the normalizer first replicates the behavior of the tokenizer distributed with the moses toolkit (hoang et al, 2007), including handling of non-breaking prefixes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI228">
<title id=" W11-2107.xml">meteor 13 automatic metric for reliable optimization and evaluation of machine translation systems </title>
<section> mt system tuning experiments.  </section>
<citcontext>
<prevsection>
<prevsent>as h-ter evaluation is ultimately limited by the ter aligner, there is no distinction between content and function words, and words sharing stems are considered non matches.
</prevsent>
<prevsent>as such, these features do not help meteor improve correlation, but rather act as source of additional possibility for overfitting.
</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
the 2011 wmt tunable metrics task consists of using z-mert (zaidan, 2009) to tune pre-built urdu-english joshua (li et al, 2009) <papid> W09-0424 </papid>system to anew evaluation metric on tuning set with 4 reference translations and decoding test set using there sulting parameter set.</citsent>
<aftsection>
<nextsent>as this task does not provide 88 language ? ?
</nextsent>
<nextsent>wexact wstem wsyn wpar english 0.85 0.20 0.60 0.75 1.00 0.60 0.80 0.60 czech 0.95 0.20 0.60 0.80 1.00 ? ?
</nextsent>
<nextsent>0.40 french 0.90 1.40 0.60 0.65 1.00 0.20 ? 0.40 german 0.95 1.00 0.55 0.55 1.00 0.80 ? 0.20 spanish 0.65 1.30 0.50 0.80 1.00 0.80 ? 0.60 table 4: optimal meteor parameters for wmt target languages on 2009 and 2010 data (meteor 1.3 ranking)devtest set, we select version of meteor by exploring the effectiveness of using multiple versions of the metric to tune phrase-based translation systems for the same language pair.we use the 2009 nist open machine translation evaluation urdu-english parallel data (przy bocki, 2009) plus 900m words of monolingual data from the english gigaword corpus (parker et al, 2009) to build standard moses system (hoang et al., 2007) as follows.
</nextsent>
<nextsent>parallel data is word aligned using the mgiza++ toolkit (gao and vogel, 2008)<papid> W08-0509 </papid>and alignments are symmetrized using the growdiag-final-and?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI229">
<title id=" W11-2107.xml">meteor 13 automatic metric for reliable optimization and evaluation of machine translation systems </title>
<section> mt system tuning experiments.  </section>
<citcontext>
<prevsection>
<prevsent>wexact wstem wsyn wpar english 0.85 0.20 0.60 0.75 1.00 0.60 0.80 0.60 czech 0.95 0.20 0.60 0.80 1.00 ? ?
</prevsent>
<prevsent>0.40 french 0.90 1.40 0.60 0.65 1.00 0.20 ? 0.40 german 0.95 1.00 0.55 0.55 1.00 0.80 ? 0.20 spanish 0.65 1.30 0.50 0.80 1.00 0.80 ? 0.60 table 4: optimal meteor parameters for wmt target languages on 2009 and 2010 data (meteor 1.3 ranking)devtest set, we select version of meteor by exploring the effectiveness of using multiple versions of the metric to tune phrase-based translation systems for the same language pair.we use the 2009 nist open machine translation evaluation urdu-english parallel data (przy bocki, 2009) plus 900m words of monolingual data from the english gigaword corpus (parker et al, 2009) to build standard moses system (hoang et al., 2007) as follows.
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
parallel data is word aligned using the mgiza++ toolkit (gao and vogel, 2008)<papid> W08-0509 </papid>and alignments are symmetrized using the growdiag-final-and?</citsent>
<aftsection>
<nextsent>heuristic.
</nextsent>
<nextsent>phrases are extracted using standard phrase-based heuristics (koehn et al,2003) <papid> N03-1017 </papid>and used to build translation table and lexicalized reordering model.</nextsent>
<nextsent>a standard sri 5-gram language model (stolke, 2002) is estimated from monolingual data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI230">
<title id=" W11-2107.xml">meteor 13 automatic metric for reliable optimization and evaluation of machine translation systems </title>
<section> mt system tuning experiments.  </section>
<citcontext>
<prevsection>
<prevsent>parallel data is word aligned using the mgiza++ toolkit (gao and vogel, 2008)<papid> W08-0509 </papid>and alignments are symmetrized using the growdiag-final-and?</prevsent>
<prevsent>heuristic.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
phrases are extracted using standard phrase-based heuristics (koehn et al,2003) <papid> N03-1017 </papid>and used to build translation table and lexicalized reordering model.</citsent>
<aftsection>
<nextsent>a standard sri 5-gram language model (stolke, 2002) is estimated from monolingual data.
</nextsent>
<nextsent>using z-mert, we tune this system to baseline metrics as well as the versions of meteor discussed in previous sections.
</nextsent>
<nextsent>we also tune to balanced tuning version of meteor designed to minimize bias.
</nextsent>
<nextsent>this dataset provides single set of reference translations for mert.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI231">
<title id=" W12-1504.xml">referring in installments a corpus study of spoken object references in an interactive virtual environment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a first study of object descriptions in this corpus shows that references in installments are quite common in this scenario and suggests that contextual factors partly determine their use.
</prevsent>
<prevsent>we discuss what new challenges this creates for nlg systems.
</prevsent>
</prevsection>
<citsent citstr=" J12-1006 ">
referring expression generation is classically considered to be the problem of producing single noun phrase that uniquely identifies referent (krahmer and van deemter, 2012).<papid> J12-1006 </papid></citsent>
<aftsection>
<nextsent>this approach is well suited for non-interactive, static contexts, but recently, there has been increased interest in generation for situated dialog (stoia, 2007; striegnitz et al, 2011).
</nextsent>
<nextsent>most human language use takes place in dynamic situations, and psycho linguistic research on human?
</nextsent>
<nextsent>human dialog has proposed that the production of referring expressions should rather be seen as process that not only depends on the context and the choices of the speaker, but also on the reactions of the addressee.
</nextsent>
<nextsent>thus the result is often not single noun phrase but sequence of installments (clarkand wilkes-gibbs, 1986), consisting of multiple utterances which may be interleaved with feedback from the addressee.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI232">
<title id=" W12-1504.xml">referring in installments a corpus study of spoken object references in an interactive virtual environment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>stoia (2007) studies instruction giving in virtual environment and finds that references to target objects are often not made when they first become visible.
</prevsent>
<prevsent>instead interaction partners are navigated to spot from where an easier description is possible.
</prevsent>
</prevsection>
<citsent citstr=" P10-1159 ">
garoufi and koller(2010) <papid> P10-1159 </papid>develop planning-based approach of this be havior.</citsent>
<aftsection>
<nextsent>but once their system decides to generate referring expression, it is delivered in one unit.
</nextsent>
<nextsent>thompson (2009), on the other hand, proposes game-theoretic model to predict how noun phrases are split up into installments.
</nextsent>
<nextsent>while thompson did not specify how the necessary parameters to calculate the utility of an utterance are derived from the context and did not implement the model, it provides good theoretical basis for an implementation.the give challenge is recent shared task on situated generation (striegnitz et al, 2011).
</nextsent>
<nextsent>in the give scenario human user goes on treasure hunt in virtual environment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI234">
<title id=" W11-2116.xml">the upvprhlt combination system for wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>probability distributions.
</prevsent>
<prevsent>instead of reranking the translations provided by the component systems, we search for the hypothesis with the minimum expected translation error among all the possible finite-length strings in the target language.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
by using loss function based on bleu (papineni etal., 2002), <papid> P02-1040 </papid>we avoid the hypothesis alignment problem that is central to standard system combination approaches (rosti et al, 2007).<papid> N07-1029 </papid></citsent>
<aftsection>
<nextsent>mbrsc assumes only that each translation model can produce expectations of n-gram counts; the latent derivation structures of the component systems can differ arbitrary.
</nextsent>
<nextsent>this flexibility allows us to combine great variety of mt systems.
</nextsent>
<nextsent>smt can be described as mapping of word sequence in source language to word sequence in target language; this mapping is produced by the mt decoder d(f).
</nextsent>
<nextsent>if the reference translatione is known, the decoder performance can be measured by the loss function l(e,d(f)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI235">
<title id=" W11-2116.xml">the upvprhlt combination system for wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>probability distributions.
</prevsent>
<prevsent>instead of reranking the translations provided by the component systems, we search for the hypothesis with the minimum expected translation error among all the possible finite-length strings in the target language.
</prevsent>
</prevsection>
<citsent citstr=" N07-1029 ">
by using loss function based on bleu (papineni etal., 2002), <papid> P02-1040 </papid>we avoid the hypothesis alignment problem that is central to standard system combination approaches (rosti et al, 2007).<papid> N07-1029 </papid></citsent>
<aftsection>
<nextsent>mbrsc assumes only that each translation model can produce expectations of n-gram counts; the latent derivation structures of the component systems can differ arbitrary.
</nextsent>
<nextsent>this flexibility allows us to combine great variety of mt systems.
</nextsent>
<nextsent>smt can be described as mapping of word sequence in source language to word sequence in target language; this mapping is produced by the mt decoder d(f).
</nextsent>
<nextsent>if the reference translatione is known, the decoder performance can be measured by the loss function l(e,d(f)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI236">
<title id=" W11-2116.xml">the upvprhlt combination system for wmt 2011 </title>
<section> minimum bayes risk decoding.  </section>
<citcontext>
<prevsection>
<prevsent>given such aloss function l(e, e?)
</prevsent>
<prevsent>between an automatic translation e?
</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
and reference e, and an underlying probability model (e|f), mbr decoding has the following form (goel and byrne, 2000; kumar and byrne, 2004): <papid> N04-1022 </papid>e?</citsent>
<aftsection>
<nextsent>= arg min ee r(e?)
</nextsent>
<nextsent>(1) = arg min ee ? ee (e|f) ? l(e, e?)
</nextsent>
<nextsent>, (2) where r(e?) denotes the bayes risk of candidate translation e?
</nextsent>
<nextsent>under loss function l, and represents the space of translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI237">
<title id=" W11-2116.xml">the upvprhlt combination system for wmt 2011 </title>
<section> mbr system combination.  </section>
<citcontext>
<prevsection>
<prevsent>, (8) where is the total number of component systems, eh represents the hypotheses space where the sear chis performed, gn(e?) is the bayes gain of hypothesis e?
</prevsent>
<prevsent>given by the nth component system and is scaling factor introduced to take into account the differences in quality of the component models.
</prevsent>
</prevsection>
<citsent citstr=" C10-1036 ">
it is worth mentioning that by using linear combination instead of mixture model, we avoid the problem of component systems not sharing the same search space (duan et al, 2010).<papid> C10-1036 </papid></citsent>
<aftsection>
<nextsent>3.1 computing bleu-based gain.
</nextsent>
<nextsent>we are interested in performing mbrsc under bleu.
</nextsent>
<nextsent>therefore, we rewrite the gain function g(?)using single evidence (or reference) bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>as the similarity function: gn(e?) = ? edn(f) pn(e|f) ? bleu(e, e?)</nextsent>
<nextsent>(9) bleu = 4?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI239">
<title id=" W11-2116.xml">the upvprhlt combination system for wmt 2011 </title>
<section> mbr system combination.  </section>
<citcontext>
<prevsection>
<prevsent>the evidences space dn(f) may contain huge number of hypotheses1 which often make impractical to compute eq.
</prevsent>
<prevsent>(9) directly.
</prevsent>
</prevsection>
<citsent citstr=" D08-1065 ">
to avoid this problem, tromble et al (2008) <papid> D08-1065 </papid>propose linear bleu, an approximation to the bleu score to efficiently perform mbr decoding on the lattices provided by the component systems.</citsent>
<aftsection>
<nextsent>however, we want to explore ahypotheses space not restricted to the evidences provided by the systems.
</nextsent>
<nextsent>in eq.
</nextsent>
<nextsent>(9), we have one hypothesis e?
</nextsent>
<nextsent>that is to be compared to set of evidences ? dn(f) which follow probability distribution pn(e|f).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI240">
<title id=" W11-2116.xml">the upvprhlt combination system for wmt 2011 </title>
<section> mbr system combination.  </section>
<citcontext>
<prevsection>
<prevsent>(9))with summation over polynomial number of ngrams that occur in the evidences2.
</prevsent>
<prevsent>both, the expected length of the evidences r?
</prevsent>
</prevsection>
<citsent citstr=" P09-1019 ">
and their expected n-gram counts mk can be pre-computed efficiently from -best lists and translation lattices (kumar et al., 2009; <papid> P09-1019 </papid>denero et al, 2010).<papid> N10-1141 </papid></citsent>
<aftsection>
<nextsent>3.2 model training.
</nextsent>
<nextsent>the scaling factors in eq.
</nextsent>
<nextsent>(8) denote the quality?
</nextsent>
<nextsent>of each system with respect to the rest of them, i.e. the relative importance of each system in the bayes gain computation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI241">
<title id=" W11-2116.xml">the upvprhlt combination system for wmt 2011 </title>
<section> mbr system combination.  </section>
<citcontext>
<prevsection>
<prevsent>(9))with summation over polynomial number of ngrams that occur in the evidences2.
</prevsent>
<prevsent>both, the expected length of the evidences r?
</prevsent>
</prevsection>
<citsent citstr=" N10-1141 ">
and their expected n-gram counts mk can be pre-computed efficiently from -best lists and translation lattices (kumar et al., 2009; <papid> P09-1019 </papid>denero et al, 2010).<papid> N10-1141 </papid></citsent>
<aftsection>
<nextsent>3.2 model training.
</nextsent>
<nextsent>the scaling factors in eq.
</nextsent>
<nextsent>(8) denote the quality?
</nextsent>
<nextsent>of each system with respect to the rest of them, i.e. the relative importance of each system in the bayes gain computation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI242">
<title id=" W11-2116.xml">the upvprhlt combination system for wmt 2011 </title>
<section> mbr system combination.  </section>
<citcontext>
<prevsection>
<prevsent>this scaling factors must be carefully tuned to obtain good translations.
</prevsent>
<prevsent>we compute the scaling factor of each system as the number of times the hypothesis of the system isthe best ter-scoring translation in the tuning corpora.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
previous works show that this measure obtains the best translation results among other heuristic measures (gonzalez-rubio et al, 2010) and even as good results as more complex methods such as mert (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>a normalization is performed to transform these counts into the range [0.0, 1.0].after the normalization, weight value of 0.0 is assigned to the lowest-scoring system, i.e. the lowest scoring system is discarded and not taken into account in the computation of the bayes gain.
</nextsent>
<nextsent>3.3 model decoding.
</nextsent>
<nextsent>in most mbr algorithms, the hypotheses space isequal to the evidences space.
</nextsent>
<nextsent>however, we are interested in extend the hypotheses space by including new sentences created using fragments of the hypotheses in the evidences spaces of the componentmodels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI243">
<title id=" W11-2115.xml">many improvements for wmt11 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>1many is available at the following address http:// www-lium.univ-lemans.fr/barrault/many
</prevsent>
<prevsent>many is system combination software (bar rault, 2010) based on the decoding of lattice made of several confusion networks (cn).
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
thisis widespread approach in mt system combination (rosti et al, 2007; <papid> P07-1040 </papid>shen et al, 2008; karakos et al, 2008; <papid> P08-2021 </papid>rosti et al, 2009).<papid> W09-0409 </papid></citsent>
<aftsection>
<nextsent>many can be decomposed in two main modules.
</nextsent>
<nextsent>the first oneis the alignment module which actually is modified version of terp (snover et al, 2009).
</nextsent>
<nextsent>its role is to incrementally align the hypotheses against backbone in order to create confusion network.those confusion networks are then connected together to create lattice.
</nextsent>
<nextsent>this module uses different costs (which corresponds to match, an insertion, deletion, substitution, shift, synonym and stem) to compute the best alignment and incrementally build confusion network.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI244">
<title id=" W11-2115.xml">many improvements for wmt11 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>1many is available at the following address http:// www-lium.univ-lemans.fr/barrault/many
</prevsent>
<prevsent>many is system combination software (bar rault, 2010) based on the decoding of lattice made of several confusion networks (cn).
</prevsent>
</prevsection>
<citsent citstr=" P08-2021 ">
thisis widespread approach in mt system combination (rosti et al, 2007; <papid> P07-1040 </papid>shen et al, 2008; karakos et al, 2008; <papid> P08-2021 </papid>rosti et al, 2009).<papid> W09-0409 </papid></citsent>
<aftsection>
<nextsent>many can be decomposed in two main modules.
</nextsent>
<nextsent>the first oneis the alignment module which actually is modified version of terp (snover et al, 2009).
</nextsent>
<nextsent>its role is to incrementally align the hypotheses against backbone in order to create confusion network.those confusion networks are then connected together to create lattice.
</nextsent>
<nextsent>this module uses different costs (which corresponds to match, an insertion, deletion, substitution, shift, synonym and stem) to compute the best alignment and incrementally build confusion network.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI245">
<title id=" W11-2115.xml">many improvements for wmt11 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>1many is available at the following address http:// www-lium.univ-lemans.fr/barrault/many
</prevsent>
<prevsent>many is system combination software (bar rault, 2010) based on the decoding of lattice made of several confusion networks (cn).
</prevsent>
</prevsection>
<citsent citstr=" W09-0409 ">
thisis widespread approach in mt system combination (rosti et al, 2007; <papid> P07-1040 </papid>shen et al, 2008; karakos et al, 2008; <papid> P08-2021 </papid>rosti et al, 2009).<papid> W09-0409 </papid></citsent>
<aftsection>
<nextsent>many can be decomposed in two main modules.
</nextsent>
<nextsent>the first oneis the alignment module which actually is modified version of terp (snover et al, 2009).
</nextsent>
<nextsent>its role is to incrementally align the hypotheses against backbone in order to create confusion network.those confusion networks are then connected together to create lattice.
</nextsent>
<nextsent>this module uses different costs (which corresponds to match, an insertion, deletion, substitution, shift, synonym and stem) to compute the best alignment and incrementally build confusion network.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI246">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even though many nlp algorithms treat words as indivisible abstract atoms, think that much can be gained by considering smallerunits: morphemes, phonemes, syllables, and letters.
</prevsent>
<prevsent>words that are similar at the sub-word level often exhibit similarities on the syntactic and semantic level as well.
</prevsent>
</prevsection>
<citsent citstr=" C02-1016 ">
even more important, as wemove beyond written text towards speech and pronunciation, the make-up of words cannot be ignored anymore.i commenced my nlp research by investigating ways of developing computer programs for various stages of the language reconstruction process (kondrak, 2002<papid> C02-1016 </papid>a).</citsent>
<aftsection>
<nextsent>from the very start, iaimed at proposing language-independent solutions grounded in the current advances in nlp, bio informatics, and computer science in general.the algorithms were evaluated on authentic linguistic data and compared quantitatively to previous proposals.
</nextsent>
<nextsent>the projects directly related to language histories still form an important part of my research.
</nextsent>
<nextsent>in section 2, refer to several of my publications on the subject, while in section 3, focus on other nlp applications contributions that originate from my research on dia chronic linguistics.
</nextsent>
<nextsent>the comparative method is the technique applied by linguists for reconstructing proto-languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI247">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> dia chronic nlp.  </section>
<citcontext>
<prevsection>
<prevsent>49 2.1 alignment.
</prevsent>
<prevsent>identification of the corresponding segments in sequences of phonemes is necessary step inmany applications in both dia chronic and syn chronic phonology.
</prevsent>
</prevsection>
<citsent citstr=" A00-2038 ">
aline (kondrak, 2000) <papid> A00-2038 </papid>was originally developed for aligning corresponding phonemes in cognate pairs.</citsent>
<aftsection>
<nextsent>it combines dynamic programming alignment algorithm with scoring scheme based on multi-valued phonetic features.
</nextsent>
<nextsent>aline has been shown to generate more accurate alignments than comparable algorithms (kondrak, 2003b).bhargava and kondrak (2009) <papid> N09-3008 </papid>propose different method of alignment, which is an adaptation of profile hidden markov models developed for biological sequence analysis.</nextsent>
<nextsent>they find that profile hmms work well on the tasks of multiple cognate alignment and cognate set matching.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI248">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> dia chronic nlp.  </section>
<citcontext>
<prevsection>
<prevsent>aline (kondrak, 2000) <papid> A00-2038 </papid>was originally developed for aligning corresponding phonemes in cognate pairs.</prevsent>
<prevsent>it combines dynamic programming alignment algorithm with scoring scheme based on multi-valued phonetic features.</prevsent>
</prevsection>
<citsent citstr=" N09-3008 ">
aline has been shown to generate more accurate alignments than comparable algorithms (kondrak, 2003b).bhargava and kondrak (2009) <papid> N09-3008 </papid>propose different method of alignment, which is an adaptation of profile hidden markov models developed for biological sequence analysis.</citsent>
<aftsection>
<nextsent>they find that profile hmms work well on the tasks of multiple cognate alignment and cognate set matching.
</nextsent>
<nextsent>2.2 phonetic similarity.
</nextsent>
<nextsent>in many applications, it is necessary to algorith mically quantify the similarity exhibited by two strings composed of symbols from finite alphabet.
</nextsent>
<nextsent>probably the most well-known measure of string similarity is the edit distance, which isthe number of insertions, deletions and substitutions required to transform one string into another.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI249">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> dia chronic nlp.  </section>
<citcontext>
<prevsection>
<prevsent>kondrak (2005b) introduces notion of gram similarity and distance, and shows that edit distance and the length of the longest common sub sequence are special cases of n-gram distance and similarity, respectively.another class of similarity measures are specifically for phonetic comparison.
</prevsent>
<prevsent>the aline algorithm chooses the optimal alignment on the basis of similarity score, and therefore can also be used for computing phonetic similarity of words.
</prevsent>
</prevsection>
<citsent citstr=" N01-1014 ">
kondrak (2001) <papid> N01-1014 </papid>shows that it performs well on the task of cognate identification.the above algorithms have the important advantage of not requiring training data, but they cannot adapt to specific task or language.</citsent>
<aftsection>
<nextsent>researchers have therefore investigated adaptive measures that are learned from set of trainingpairs.
</nextsent>
<nextsent>mackay and kondrak (2005) <papid> W05-0606 </papid>propose system for computing string similarity based on pairhmms.</nextsent>
<nextsent>the parameters of the model are automatically learned from training data that consists of pairs of strings that are known to be similar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI251">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> dia chronic nlp.  </section>
<citcontext>
<prevsection>
<prevsent>kondrak (2001) <papid> N01-1014 </papid>shows that it performs well on the task of cognate identification.the above algorithms have the important advantage of not requiring training data, but they cannot adapt to specific task or language.</prevsent>
<prevsent>researchers have therefore investigated adaptive measures that are learned from set of trainingpairs.</prevsent>
</prevsection>
<citsent citstr=" W05-0606 ">
mackay and kondrak (2005) <papid> W05-0606 </papid>propose system for computing string similarity based on pairhmms.</citsent>
<aftsection>
<nextsent>the parameters of the model are automatically learned from training data that consists of pairs of strings that are known to be similar.
</nextsent>
<nextsent>kondrak and sherif (2006) <papid> W06-1107 </papid>test representatives of the two principal approaches to computing phonetic similarity on the task of identifying cog nates among indo european languages, both in the supervised and unsupervised context.</nextsent>
<nextsent>their results suggest that given sufficiently large training set of positive examples, the learning algorithms achieve higher accuracy than manually designed metrics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI252">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> dia chronic nlp.  </section>
<citcontext>
<prevsection>
<prevsent>mackay and kondrak (2005) <papid> W05-0606 </papid>propose system for computing string similarity based on pairhmms.</prevsent>
<prevsent>the parameters of the model are automatically learned from training data that consists of pairs of strings that are known to be similar.</prevsent>
</prevsection>
<citsent citstr=" W06-1107 ">
kondrak and sherif (2006) <papid> W06-1107 </papid>test representatives of the two principal approaches to computing phonetic similarity on the task of identifying cog nates among indo european languages, both in the supervised and unsupervised context.</citsent>
<aftsection>
<nextsent>their results suggest that given sufficiently large training set of positive examples, the learning algorithms achieve higher accuracy than manually designed metrics.
</nextsent>
<nextsent>techniques such as pair hmms improve on the baseline approaches by using set of similar words to re-weight the costs of edit operations or the score of sequence matches.
</nextsent>
<nextsent>a more flexible approach is to learn from both positive and negative examples of word pairs.
</nextsent>
<nextsent>bergsma and kondrak (2007<papid> P07-1083 </papid>a) propose such discriminative algorithm, which achieves exceptional performance on the task of cognate identification.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI253">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> dia chronic nlp.  </section>
<citcontext>
<prevsection>
<prevsent>techniques such as pair hmms improve on the baseline approaches by using set of similar words to re-weight the costs of edit operations or the score of sequence matches.
</prevsent>
<prevsent>a more flexible approach is to learn from both positive and negative examples of word pairs.
</prevsent>
</prevsection>
<citsent citstr=" P07-1083 ">
bergsma and kondrak (2007<papid> P07-1083 </papid>a) propose such discriminative algorithm, which achieves exceptional performance on the task of cognate identification.</citsent>
<aftsection>
<nextsent>2.3 recurrent sound correspondences.
</nextsent>
<nextsent>an important phenomenon that allows us to distinguish between cognates and borrowings or chance resemblances is the regularity of sound change.
</nextsent>
<nextsent>the regularity principle states that change in pronunciation applies to sounds in given phonological context across all words in the language.
</nextsent>
<nextsent>regular sound changes tend to produce recurrent sound correspondences of phonemes in corresponding cognates.although it may not be immediately apparent, there is strong similarity between the taskof matching phonetic segments in pair of cog nate words, and the task of matching words in two sentences that are mutual translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI258">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> dia chronic nlp.  </section>
<citcontext>
<prevsection>
<prevsent>2.5 cognate sets.
</prevsent>
<prevsent>when data from several related languages is available, it is preferable to identify cognate sets simultaneously across all languages rather than perform pairwise analysis.
</prevsent>
</prevsection>
<citsent citstr=" W07-1317 ">
kondrak et al (2007) <papid> W07-1317 </papid>apply several of the algorithms described above to set of diverse dictionaries of languages belonging to the totonac-tepehua family in mexico.</citsent>
<aftsection>
<nextsent>they show that by combining expert linguistic knowledge with computational analysis, it is possible to quickly identify large number of cognate sets within the family, resulting in basic comparative dictionary.
</nextsent>
<nextsent>the dictionary subsequently serv edas starting point for generating lists of putative cognates between the totonacan and mixezoquean families.
</nextsent>
<nextsent>the project eventually culminated in proposal for establishing super-family dubbed totozoquean (brown et al, 2011).
</nextsent>
<nextsent>bergsma and kondrak (2007<papid> P07-1083 </papid>b) present method for identifying sets of cognates across groups of languages using the global inference framework of integer linear programming.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI261">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> nlp applications.  </section>
<citcontext>
<prevsection>
<prevsent>kondrak (2005a) further investigates word alignment in bitexts, focusing on on identifyingcognates on the basis of their orthographic similarity.
</prevsent>
<prevsent>he concludes that word alignment links can be used as substitute for cognates for the purpose of evaluating word similarity measures.many hundreds of drugs have names that either look or sound so much alike that doctors,nurses and pharmacists sometimes get them confused, dispensing the wrong one in errors that may 51 injure or even kill patients.
</prevsent>
</prevsection>
<citsent citstr=" C04-1137 ">
kondrak and dorr (2004) <papid> C04-1137 </papid>apply anumber of similarity measures to the task of identifying conf usable drug names.</citsent>
<aftsection>
<nextsent>they find that combination of several measures outperforms all individual measures.cognate lists can also assist in second language learning, especially in vocabulary expansion and reading comprehension.
</nextsent>
<nextsent>on the other hand, the learner needs to pay attention to false friends, which are pairs of similar-looking words that have different meanings.
</nextsent>
<nextsent>inkpen et al (2005) propose method to automatically classify pairs of words as cognates or false friends, with focus on french and english.
</nextsent>
<nextsent>the results show that it is possible to achieve very good accuracy even with out any training data by employing orthographic measures of word similarity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI262">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> nlp applications.  </section>
<citcontext>
<prevsection>
<prevsent>transliteration is the task of converting words from one writing script to another.
</prevsent>
<prevsent>transliteration mining aims at automatically constructing bilingual lists of names for the purpose of training transliteration programs.
</prevsent>
</prevsection>
<citsent citstr=" P07-1109 ">
the task of detectingphonetically-similar words across different writing scripts is quite similar to that of identifyingcognates, sherif and kondrak (2007) <papid> P07-1109 </papid>applies several methods, including aline, to the task of extracting transliterations from an english-arabic bitext, and show that it performs better than edit distance, but not as well as bootstrapping approach to training memoriless stochastic trans ducer.</citsent>
<aftsection>
<nextsent>jiampojamarn et al (2009) <papid> W09-3504 </papid>employ aline for aligning transliterations from distinct scripts by mapping every character to phoneme that is the most likely to be produced by that character.they observe that even such an imprecise mapping is sufficient for aline to produce high quality alignments.</nextsent>
<nextsent>dwyer and kondrak (2009) <papid> P09-1015 </papid>apply the aline algorithm to the task of grapheme-to-phoneme conversion, which is the process of producing the correct phoneme sequence for word given its orthographic form.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI263">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> nlp applications.  </section>
<citcontext>
<prevsection>
<prevsent>transliteration mining aims at automatically constructing bilingual lists of names for the purpose of training transliteration programs.
</prevsent>
<prevsent>the task of detectingphonetically-similar words across different writing scripts is quite similar to that of identifyingcognates, sherif and kondrak (2007) <papid> P07-1109 </papid>applies several methods, including aline, to the task of extracting transliterations from an english-arabic bitext, and show that it performs better than edit distance, but not as well as bootstrapping approach to training memoriless stochastic trans ducer.</prevsent>
</prevsection>
<citsent citstr=" W09-3504 ">
jiampojamarn et al (2009) <papid> W09-3504 </papid>employ aline for aligning transliterations from distinct scripts by mapping every character to phoneme that is the most likely to be produced by that character.they observe that even such an imprecise mapping is sufficient for aline to produce high quality alignments.</citsent>
<aftsection>
<nextsent>dwyer and kondrak (2009) <papid> P09-1015 </papid>apply the aline algorithm to the task of grapheme-to-phoneme conversion, which is the process of producing the correct phoneme sequence for word given its orthographic form.</nextsent>
<nextsent>they find aline to be an excellent substitute for the expectation-maximization (em) algorithm when the quantity of the training data is small.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI264">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> nlp applications.  </section>
<citcontext>
<prevsection>
<prevsent>the task of detectingphonetically-similar words across different writing scripts is quite similar to that of identifyingcognates, sherif and kondrak (2007) <papid> P07-1109 </papid>applies several methods, including aline, to the task of extracting transliterations from an english-arabic bitext, and show that it performs better than edit distance, but not as well as bootstrapping approach to training memoriless stochastic trans ducer.</prevsent>
<prevsent>jiampojamarn et al (2009) <papid> W09-3504 </papid>employ aline for aligning transliterations from distinct scripts by mapping every character to phoneme that is the most likely to be produced by that character.they observe that even such an imprecise mapping is sufficient for aline to produce high quality alignments.</prevsent>
</prevsection>
<citsent citstr=" P09-1015 ">
dwyer and kondrak (2009) <papid> P09-1015 </papid>apply the aline algorithm to the task of grapheme-to-phoneme conversion, which is the process of producing the correct phoneme sequence for word given its orthographic form.</citsent>
<aftsection>
<nextsent>they find aline to be an excellent substitute for the expectation-maximization (em) algorithm when the quantity of the training data is small.
</nextsent>
<nextsent>jiampojamarn and kondrak (2010) <papid> P10-1080 </papid>confirm that aline is highly accurate on the task of letterphoneme alignment.</nextsent>
<nextsent>when evaluated on manually aligned lexicon, its precision was very close to the theoretical upper bound, with the number of incorrect links less than one in thousand.lastly, aline has also been used for the mapping of annotations, including syllable break sand stress marks, from the phonetic to orthographic forms (bartlett et al, 2008; <papid> P08-1065 </papid>dou et al, 2009).<papid> P09-1014 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI265">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> nlp applications.  </section>
<citcontext>
<prevsection>
<prevsent>dwyer and kondrak (2009) <papid> P09-1015 </papid>apply the aline algorithm to the task of grapheme-to-phoneme conversion, which is the process of producing the correct phoneme sequence for word given its orthographic form.</prevsent>
<prevsent>they find aline to be an excellent substitute for the expectation-maximization (em) algorithm when the quantity of the training data is small.</prevsent>
</prevsection>
<citsent citstr=" P10-1080 ">
jiampojamarn and kondrak (2010) <papid> P10-1080 </papid>confirm that aline is highly accurate on the task of letterphoneme alignment.</citsent>
<aftsection>
<nextsent>when evaluated on manually aligned lexicon, its precision was very close to the theoretical upper bound, with the number of incorrect links less than one in thousand.lastly, aline has also been used for the mapping of annotations, including syllable break sand stress marks, from the phonetic to orthographic forms (bartlett et al, 2008; <papid> P08-1065 </papid>dou et al, 2009).<papid> P09-1014 </papid></nextsent>
<nextsent>the problems involved in language reconstruction are easy to state but surprisingly hard to solve.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI266">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> nlp applications.  </section>
<citcontext>
<prevsection>
<prevsent>they find aline to be an excellent substitute for the expectation-maximization (em) algorithm when the quantity of the training data is small.
</prevsent>
<prevsent>jiampojamarn and kondrak (2010) <papid> P10-1080 </papid>confirm that aline is highly accurate on the task of letterphoneme alignment.</prevsent>
</prevsection>
<citsent citstr=" P08-1065 ">
when evaluated on manually aligned lexicon, its precision was very close to the theoretical upper bound, with the number of incorrect links less than one in thousand.lastly, aline has also been used for the mapping of annotations, including syllable break sand stress marks, from the phonetic to orthographic forms (bartlett et al, 2008; <papid> P08-1065 </papid>dou et al, 2009).<papid> P09-1014 </papid></citsent>
<aftsection>
<nextsent>the problems involved in language reconstruction are easy to state but surprisingly hard to solve.
</nextsent>
<nextsent>assuch, they lead to the development of new methods and insights that are not restricted in application to historical linguistics.
</nextsent>
<nextsent>although the goal of developing program that performs fully automatic reconstruction of proto-language has yet to been attained, the research conducted towards this goal has been, and is likely to continue to influence other areas of nlp.
</nextsent>
<nextsent>acknowledgments this paper refers to research projects that were conducted jointly with the following colleagues: susan bartlett, david beck, shane bergsma, aditya bhargava, cecil brown, colin cherry, philip dilts, bonnie dorr, qing dou, elan dresher, ken dwyer, jessica enright, oana frunza, bradley hauer, graeme hirst, diana inkpen, sittichai jiampojamarn, kevin knight, wesley mackay, daniel marcu, and tarek sherif.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI267">
<title id=" W12-0208.xml">similarity patterns in words invited talk </title>
<section> nlp applications.  </section>
<citcontext>
<prevsection>
<prevsent>they find aline to be an excellent substitute for the expectation-maximization (em) algorithm when the quantity of the training data is small.
</prevsent>
<prevsent>jiampojamarn and kondrak (2010) <papid> P10-1080 </papid>confirm that aline is highly accurate on the task of letterphoneme alignment.</prevsent>
</prevsection>
<citsent citstr=" P09-1014 ">
when evaluated on manually aligned lexicon, its precision was very close to the theoretical upper bound, with the number of incorrect links less than one in thousand.lastly, aline has also been used for the mapping of annotations, including syllable break sand stress marks, from the phonetic to orthographic forms (bartlett et al, 2008; <papid> P08-1065 </papid>dou et al, 2009).<papid> P09-1014 </papid></citsent>
<aftsection>
<nextsent>the problems involved in language reconstruction are easy to state but surprisingly hard to solve.
</nextsent>
<nextsent>assuch, they lead to the development of new methods and insights that are not restricted in application to historical linguistics.
</nextsent>
<nextsent>although the goal of developing program that performs fully automatic reconstruction of proto-language has yet to been attained, the research conducted towards this goal has been, and is likely to continue to influence other areas of nlp.
</nextsent>
<nextsent>acknowledgments this paper refers to research projects that were conducted jointly with the following colleagues: susan bartlett, david beck, shane bergsma, aditya bhargava, cecil brown, colin cherry, philip dilts, bonnie dorr, qing dou, elan dresher, ken dwyer, jessica enright, oana frunza, bradley hauer, graeme hirst, diana inkpen, sittichai jiampojamarn, kevin knight, wesley mackay, daniel marcu, and tarek sherif.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI268">
<title id=" W12-2009.xml">prefer using a graph based approach to generate paraphrases for language learning </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these findings indicate that efl students have problems in paraphrasing.
</prevsent>
<prevsent>in view of this, we develop prefer, paraphrase reference tool, for helping english learners with their writing.
</prevsent>
</prevsection>
<citsent citstr=" J10-3003 ">
paraphrase generation, on the other hand, has been an area of active research and the related work has been thoroughly surveyed in androutsopoulos and malakasiotis (2010) as well as in madnani and dorr (2010).<papid> J10-3003 </papid></citsent>
<aftsection>
<nextsent>in the rest of this section, we focus on reviewing the methods related to our work.
</nextsent>
<nextsent>one prominent approach to paraphrase generation is based on bilingual parallel corpora.
</nextsent>
<nextsent>for example, bannard and callison-burch (2005) propose the pivot approach to generate phrasal paraphrases from an english-german parallel corpus.
</nextsent>
<nextsent>with the advantage of its parallel and bilingual natures of such corpus, the output paraphrases do preserve semantic similarity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI269">
<title id=" W12-2009.xml">prefer using a graph based approach to generate paraphrases for language learning </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we generate paraphrases adopting the pivot-based method proposed by bannard and callison-burch (2005) in the first round.
</prevsent>
<prevsent>then we use graph-based approach to further ensure paraphrase candidates preserve both meaning and grammaticality.
</prevsent>
</prevsection>
<citsent citstr=" N10-1017 ">
in study more closely related to our work, kok and brockett (2010) <papid> N10-1017 </papid>take graphical view of the pivot-based approach.</citsent>
<aftsection>
<nextsent>they propose the hitting time paraphrase algorithm (htp) to measure similarities between phrases.
</nextsent>
<nextsent>the smaller the number of steps random walker goes from one node to the other, the more likely these two nodes are paraphrases.
</nextsent>
<nextsent>the main difference between their work and ours lies in the definition of the graph.
</nextsent>
<nextsent>while they treat multilingual phrases as nodes, we treat only english phrases as nodes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI271">
<title id=" W12-2009.xml">prefer using a graph based approach to generate paraphrases for language learning </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>then evaluation results are reported.
</prevsent>
<prevsent>4.1 experimental setting.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
in this paper, word alignments were produced by giza++ toolkit (och and ney, 2003) <papid> J03-1002 </papid>over set of danish-english section (containing 1,236,427 sentences) of the europarl corpus, version 2 (koehn, 2002).</citsent>
<aftsection>
<nextsent>we compared our graph-based approach with strong baseline, the pivot-based method with syntactic constraint (sbp) (callison-burch, 2008) utilizing the same danish-english corpus.
</nextsent>
<nextsent>we also investigate the contribution of adding the edge weights to the page rank algorithm by building two models, pr representing the method of the page rank algorithm without weights and prw representing the method of the weighted page rank algorithm, for comparison.
</nextsent>
<nextsent>to assess the performance of our method, we conducted manual evaluation.
</nextsent>
<nextsent>we asked an experienced english lecturer to randomly select 100 most commonly used and meaningful phrases from 30 research articles in the discipline of computer-assisted language learning (call).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI274">
<title id=" W12-2009.xml">prefer using a graph based approach to generate paraphrases for language learning </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>in order to conduct more comprehensive evaluation, we plan to adapt the in-context evaluation metric introduced by callison-burch et. al (2008).
</prevsent>
<prevsent>a larger test set would be generated manually to evaluate the performance of our paraphrase system.
</prevsent>
</prevsection>
<citsent citstr=" W11-2504 ">
in addition, we will implement various kinds of baseline systems such as kok and brockett (2010) <papid> N10-1017 </papid>and chan et al (2011) <papid> W11-2504 </papid>to provide more competitive comparison.</citsent>
<aftsection>
<nextsent>many avenues exist for future research and improvement.
</nextsent>
<nextsent>for example, we would like to extend paraphrasing consecutive n-gram phrases to in consecutive ones such as ones with incomplete transitive verbs (e.g., provide someone with something?).
</nextsent>
<nextsent>besides, we are interested in weighting edges using syntactic and semantic relation in our graph-based method to further improve the quality of generated paraphrases.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI275">
<title id=" W11-2145.xml">the karlsruhe institute of technology translation systems for the wmt 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>this includes normalizing special symbols, smart-casing the first words of each sentence and removing long sentences and sentences with length mismatch.
</prevsent>
<prevsent>for the german parts of the training corpus we use the hunspell1 lexicon to map words written according to old german spelling to new german spelling, to obtain corpus with homogenous spelling.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
compound splitting as described in koehn and knight (2003) <papid> E03-1076 </papid>is applied to the german part of the corpus for the german-to-english system to reduce the out-of-vocabulary problem for german compound words.</citsent>
<aftsection>
<nextsent>2.3 special filtering of the giga parallel corpus.
</nextsent>
<nextsent>the giga corpus incorporates non-neglegibleamounts of noise even after our usual preprocessing.
</nextsent>
<nextsent>this noise may be due to different causes.
</nextsent>
<nextsent>for instance: non-standard html characters, meaningless parts composed of only hypertext codes, sentences which are only partial translation of the source, or eventually not correct translation at all.such noisy pairs potentially degrade the translation model quality, therefore it seemed more convenient to eliminate them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI276">
<title id=" W11-2145.xml">the karlsruhe institute of technology translation systems for the wmt 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>for instance: non-standard html characters, meaningless parts composed of only hypertext codes, sentences which are only partial translation of the source, or eventually not correct translation at all.such noisy pairs potentially degrade the translation model quality, therefore it seemed more convenient to eliminate them.
</prevsent>
<prevsent>given the size of the corpus, this task could not be performed manually.
</prevsent>
</prevsection>
<citsent citstr=" J05-4003 ">
consequently, we used an automatic classifier inspired by the work of munteanu and marcu (2005) <papid> J05-4003 </papid>on comparable corpora.</citsent>
<aftsection>
<nextsent>this clas 1http://hunspell.sourceforge.net/ sifier should be able to filter out the pairs which likely are not beneficial for the translation model.
</nextsent>
<nextsent>in order to reliably decide about the classifier to use, we evaluated several techniques.
</nextsent>
<nextsent>the training and test sets for this evaluation were built respectively from nc-dev2007 and nc-devtest2007.
</nextsent>
<nextsent>in each set, about 30% randomly selected source sentences switch positions with the immediate following sothat they form negative examples.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI277">
<title id=" W11-2145.xml">the karlsruhe institute of technology translation systems for the wmt 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>2.4.1 pos-based reordering model to model reordering we first learn probabilistic rules from the pos tags of the words in the training corpus and the alignment information.
</prevsent>
<prevsent>continuous reordering rules are extracted as described in rottmann and vogel (2007) to model short-range reorderings.
</prevsent>
</prevsection>
<citsent citstr=" W09-0435 ">
when translating between german and english, we apply modified reordering model withnon-continuous rules to cover also long-range reorderings (niehues and kolss, 2009).<papid> W09-0435 </papid></citsent>
<aftsection>
<nextsent>the reordering rules are applied to the source text and the original order of words and the reordered sentence variants generated by the rules are encoded in word lattice which is used as input to the decoder.
</nextsent>
<nextsent>2.4.2 lattice phrase extraction for the test sentences, the pos-based reordering allows us to change the word order in the source sentence so that the sentence can be translated more easily.
</nextsent>
<nextsent>if we apply this also to the training sentences, wewould be able to extract the phrase pairs for originally discontinuous phrases and could apply them during translation of reordered test sentences.
</nextsent>
<nextsent>therefore, we build reordering lattices for all training sentences and then extract phrase pairs fromthe monotone source path as well as from there ordered paths.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI278">
<title id=" W11-2145.xml">the karlsruhe institute of technology translation systems for the wmt 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the word alignments are generated in both directions and the grow-diag-final-andheuristic is used to combine them.
</prevsent>
<prevsent>the phrase extraction is then done based on this word alignment.
</prevsent>
</prevsection>
<citsent citstr=" W08-0303 ">
in the english-german system we applied the discriminative word alignment approach as described in niehues and vogel (2008) <papid> W08-0303 </papid>instead.</citsent>
<aftsection>
<nextsent>this alignment model is trained on small corpus of hand-aligned data and uses the lexical probability as well as the fertilities generated by the pgiza++ toolkit and pos information.
</nextsent>
<nextsent>2.5.2 bilingual language model in phrase-based systems the source sentence is segmented by the decoder according to the best combination of phrases that maximize the translation and language model scores.
</nextsent>
<nextsent>this segmentation into phrases leads to the loss of context information at the phrase boundaries.
</nextsent>
<nextsent>although more target side context is available to the language model, source 4http://www.cs.cmu.edu/qing/ 381 side context would also be valuable for the decoder when searching for the best translation hypothesis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI279">
<title id=" W11-2145.xml">the karlsruhe institute of technology translation systems for the wmt 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>2.5.4 pos language models in addition to surface word language models, we did experiments with language models based on part-of-speech for english-german.
</prevsent>
<prevsent>we expect that having additional information in form of probabilities of part-of-speech sequences should help especially in case of the rich morphology of german and #pairs(g) moses 103(s) kit 103(s) 0.203 25.99 17.58 1.444 184.19 103.41 1.693 230.97 132.79 table 2: comparison of moses and kit phrase extraction systems therefore the more difficult target language generation.
</prevsent>
</prevsection>
<citsent citstr=" C08-1098 ">
the part-of-speeches were generated using the tree tagger and the rftagger (schmid and laws, 2008), <papid> C08-1098 </papid>which produces more fine-grained tags that include also person, gender and case information.</citsent>
<aftsection>
<nextsent>while the tree tagger assigns 54 different pos tagsto the 357k german words in the corpus, the rf tagger produces 756 different fine-grained tags on the same corpus.we tried n-gram lengths of 4 and 7.
</nextsent>
<nextsent>while no improvement in translation quality could be achieved using the pos language models based on the normal pos tags, the 4-gram pos language model based on fine-grained tags could improve the translation system by 0.2 bleu points as shown in table 3.surprisingly, increasing the n-gram length to 7 decreased the translation quality again.
</nextsent>
<nextsent>to investigate the impact of context length, we performed an analysis on the outputs of two different systems, one without pos language model and one with the 4-gram fine-grained pos language model.for each of the translations we calculated the average length of the n-grams in the translation when applying one of the two language models using 4grams of surface words or parts-of-speech.
</nextsent>
<nextsent>there sults are also shown in table 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI280">
<title id=" W11-2119.xml">expected bleu training for graphs bbn system description for wmt11 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hr0011-06-c-0022 under the gale program (approved for public release, distribution unlimited).
</prevsent>
<prevsent>the views, opinions, and/or findings contained in this article/presentation are those ofthe author/presenter and should not be interpreted as representing the official views or policies, either expressed or implied,of the defense advanced research projects agency or the department of defense.
</prevsent>
</prevsection>
<citsent citstr=" W09-0409 ">
with flexible matching (rosti et al, 2009).<papid> W09-0409 </papid></citsent>
<aftsection>
<nextsent>a novel bi-gram count feature was used in addition to the standard decoder features.
</nextsent>
<nextsent>the n-best list based expected bleu tuning (rosti et al, 2010), <papid> W10-1748 </papid>similar to the one proposed by smith and eisner (2006), <papid> P06-2101 </papid>was extended to operate on word lattices.</nextsent>
<nextsent>this method is closely related to the consensus bleu (cobleu)proposed by pauls et al (2009).<papid> D09-1147 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI281">
<title id=" W11-2119.xml">expected bleu training for graphs bbn system description for wmt11 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with flexible matching (rosti et al, 2009).<papid> W09-0409 </papid></prevsent>
<prevsent>a novel bi-gram count feature was used in addition to the standard decoder features.</prevsent>
</prevsection>
<citsent citstr=" W10-1748 ">
the n-best list based expected bleu tuning (rosti et al, 2010), <papid> W10-1748 </papid>similar to the one proposed by smith and eisner (2006), <papid> P06-2101 </papid>was extended to operate on word lattices.</citsent>
<aftsection>
<nextsent>this method is closely related to the consensus bleu (cobleu)proposed by pauls et al (2009).<papid> D09-1147 </papid></nextsent>
<nextsent>the minimum operation used to compute the clipped counts (matches)in the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>was replaced by differentiable function, so there was no need to use sub-gradient ascent as in cobleu.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI282">
<title id=" W11-2119.xml">expected bleu training for graphs bbn system description for wmt11 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with flexible matching (rosti et al, 2009).<papid> W09-0409 </papid></prevsent>
<prevsent>a novel bi-gram count feature was used in addition to the standard decoder features.</prevsent>
</prevsection>
<citsent citstr=" P06-2101 ">
the n-best list based expected bleu tuning (rosti et al, 2010), <papid> W10-1748 </papid>similar to the one proposed by smith and eisner (2006), <papid> P06-2101 </papid>was extended to operate on word lattices.</citsent>
<aftsection>
<nextsent>this method is closely related to the consensus bleu (cobleu)proposed by pauls et al (2009).<papid> D09-1147 </papid></nextsent>
<nextsent>the minimum operation used to compute the clipped counts (matches)in the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>was replaced by differentiable function, so there was no need to use sub-gradient ascent as in cobleu.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI283">
<title id=" W11-2119.xml">expected bleu training for graphs bbn system description for wmt11 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a novel bi-gram count feature was used in addition to the standard decoder features.
</prevsent>
<prevsent>the n-best list based expected bleu tuning (rosti et al, 2010), <papid> W10-1748 </papid>similar to the one proposed by smith and eisner (2006), <papid> P06-2101 </papid>was extended to operate on word lattices.</prevsent>
</prevsection>
<citsent citstr=" D09-1147 ">
this method is closely related to the consensus bleu (cobleu)proposed by pauls et al (2009).<papid> D09-1147 </papid></citsent>
<aftsection>
<nextsent>the minimum operation used to compute the clipped counts (matches)in the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>was replaced by differentiable function, so there was no need to use sub-gradient ascent as in cobleu.</nextsent>
<nextsent>the expected bleu (xbleu) naturally generalize sto hypergraphs by simply replacing the forward backward algorithm with inside-outside algorithm when computing the expected n-gram counts and sufficient statistics for the gradient.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI284">
<title id=" W11-2119.xml">expected bleu training for graphs bbn system description for wmt11 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the n-best list based expected bleu tuning (rosti et al, 2010), <papid> W10-1748 </papid>similar to the one proposed by smith and eisner (2006), <papid> P06-2101 </papid>was extended to operate on word lattices.</prevsent>
<prevsent>this method is closely related to the consensus bleu (cobleu)proposed by pauls et al (2009).<papid> D09-1147 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the minimum operation used to compute the clipped counts (matches)in the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>was replaced by differentiable function, so there was no need to use sub-gradient ascent as in cobleu.</citsent>
<aftsection>
<nextsent>the expected bleu (xbleu) naturally generalize sto hypergraphs by simply replacing the forward backward algorithm with inside-outside algorithm when computing the expected n-gram counts and sufficient statistics for the gradient.
</nextsent>
<nextsent>the gradient ascent optimization of the xbleuappears to be more stable than the gradient-free direct 1-best bleu tuning or -best list based minimum error rate training (och, 2003), <papid> P03-1021 </papid>especially when tuning large number of weights.</nextsent>
<nextsent>on the official wmt11 language pairs with up to 30 weights, there was no significant benefit from maximizing xbleu.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI285">
<title id=" W11-2119.xml">expected bleu training for graphs bbn system description for wmt11 system combination task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the minimum operation used to compute the clipped counts (matches)in the bleu score (papineni et al, 2002) <papid> P02-1040 </papid>was replaced by differentiable function, so there was no need to use sub-gradient ascent as in cobleu.</prevsent>
<prevsent>the expected bleu (xbleu) naturally generalize sto hypergraphs by simply replacing the forward backward algorithm with inside-outside algorithm when computing the expected n-gram counts and sufficient statistics for the gradient.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the gradient ascent optimization of the xbleuappears to be more stable than the gradient-free direct 1-best bleu tuning or -best list based minimum error rate training (och, 2003), <papid> P03-1021 </papid>especially when tuning large number of weights.</citsent>
<aftsection>
<nextsent>on the official wmt11 language pairs with up to 30 weights, there was no significant benefit from maximizing xbleu.
</nextsent>
<nextsent>however, on 39 system multi-sourcecombination (43 weights total), it yielded significant gain over gradient-free bleu tuning and best list based expected bleu tuning.
</nextsent>
<nextsent>the incremental hypothesis alignment with flexible matching (rosti et al, 2009) <papid> W09-0409 </papid>produces confusion network for each system output acting as skeleton hypothesis for the ith source sentence.</nextsent>
<nextsent>a confusion network is graph where all paths visit all 159 vertices.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI287">
<title id=" W11-2119.xml">expected bleu training for graphs bbn system description for wmt11 system combination task </title>
<section> hypothesis alignment and features.  </section>
<citcontext>
<prevsection>
<prevsent>consecutive vertices are connected by one or more edges representing alternatives.
</prevsent>
<prevsent>each edgel is associated with token and set of scores.
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
a token may be word, punctuation symbol, or special null token indicating deletion in the alignment.the set of scores includes vector ofns system specific confidences, siln, indicating whether the token was aligned from the output of the system n.1 other scores may include language model (lm) score as well as non-null and null token indicators (rosti et al, 2007).<papid> P07-1040 </papid></citsent>
<aftsection>
<nextsent>as rosti et al (2010) <papid> W10-1748 </papid>described, the networks for all skeletons are connected to start and end vertex with null tokens in order to form joint lattice with multiple parallel networks.</nextsent>
<nextsent>the edges connecting the start vertex to the initial vertices in each network have heuristic prior estimated from the alignment statistics at the confidence corresponding to the skeleton system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI298">
<title id=" W11-2119.xml">expected bleu training for graphs bbn system description for wmt11 system combination task </title>
<section> weight optimization.  </section>
<citcontext>
<prevsection>
<prevsent>)( ? jji pij ? gn cijgn ) hnik = ? lli sil ??
</prevsent>
<prevsent>j:lji pij ? gn cijgnwhere ??(x, c) is the derivative of ?(x, c) with respect to x, and the parentheses in the equations for mnik and nik signify that the second terms do not depend on the edge l. 3.3 forward-backward algorithm under.
</prevsent>
</prevsection>
<citsent citstr=" D09-1005 ">
expectation semi ring the sufficient statistics for graph expected bleu can be computed using expectation semi rings (li and eisner, 2009).<papid> D09-1005 </papid></citsent>
<aftsection>
<nextsent>instead of computing singleforward/backward or inside/outside scores, additional n-gram elements are tracked for matches andcounts.
</nextsent>
<nextsent>for example in bi-gram graph, the elements for edge are represented by 5-tuple7 sl = pl, r1lh, 2 lh, 1 lm, 2 lm?
</nextsent>
<nextsent>where pl = sil and: rnlh = ? gn ?(cnil, n)esil (16) rnlm = ? gn igne sil (17)assuming the lattice is topologically sorted, the forward algorithm8 under expectation semi ring for 3 7the sentence index is dropped for brevity.
</nextsent>
<nextsent>8for inside-outside algorithm, see (li and eisner, 2009).<papid> D09-1005 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI305">
<title id=" W11-2707.xml">exciting and interesting issues in the generation of binomials </title>
<section> evaluating models of binomial ordering.  </section>
<citcontext>
<prevsection>
<prevsent>this means that we require relatively large corpora to obtain good estimates in order to evaluate model.of course, if we are interested in ana logical models of binomial ordering, as mentioned at the end of 2, we need reasonably large corpus of binomialsto develop the model.
</prevsent>
<prevsent>ideally this should be different corpus from the one used for evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P99-1018 ">
wenote that some experiments on pre modifier ordering have found considerable drop in performance when testing on different domain (shaw and hatzivassiloglou, 1999).<papid> P99-1018 </papid></citsent>
<aftsection>
<nextsent>using single corpus split into training and test data would, of course, be problematic when working with binomial types.
</nextsent>
<nextsent>we have thus developed relatively novel methodology of using an automatically parsed corpus in combination with frequencies from web data.
</nextsent>
<nextsent>this is discussed in the next section.
</nextsent>
<nextsent>48
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI306">
<title id=" W11-2707.xml">exciting and interesting issues in the generation of binomials </title>
<section> binomial corpora and corpus.  </section>
<citcontext>
<prevsection>
<prevsent>the latter point is demonstrated by comparison with large dataset: the google gram corpus (brants and franz, 2006).
</prevsent>
<prevsent>although the google data is not suitable for the actual task of extracting binomials, because it is not parsed, we hypothesize it is usable to predict the preferred order of given binomial and to estimate the extent to which it is reversible.
</prevsent>
</prevsection>
<citsent citstr=" P10-1036 ">
in order to build corpus of binomials, we process the parsed wikipedia dump produced by kummerfeld et al(2010).<papid> P10-1036 </papid></citsent>
<aftsection>
<nextsent>the parse consists of grammatical relations of the following form: (gr word1 word2 ... wordn z) where gr is the name of the grammatical relation, word1...n are the arguments of the relation, andx, y...z are the positions of the arguments in the sentence.
</nextsent>
<nextsent>the lemmatised forms of the arguments, as well as their part of speech, are available separately.
</nextsent>
<nextsent>we used the first one million and coordinations in the corpus in these experiments.
</nextsent>
<nextsent>the conjuncts are required to have the same part of speech and to directly precede and follow the coordination.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI307">
<title id=" W11-2707.xml">exciting and interesting issues in the generation of binomials </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>in the long term, we would like to in 9available from http://www.cl.cam.ac.uk/ research/nl/nl-download/binomials/ 52 b+l google accuracy b+l (%) accuracy google (%) overall 380 305 69 79 bigram 187 185 79 89 pos prob 184 117 61 65 unknown 9 3 33 0 lexicalised 34 34 87 94 non-lexicalised 346 271 67 77 table 1: evaluation of initial model, showing effects of lexicalisation.
</prevsent>
<prevsent>(n b+l and google indicates the number of binomial types evaluated) accuracy b+l (%) accuracy google (%)google count 0 75 59 11000 71 56 68 100110000 81 70 67   10000 153 80 91 google ratio 0 11 64 64 00.1 41 94 93 0.10.25 33 75 85   0.25 220 68 76 table 2: evaluation of initial model, showing effects of frequency and reversibility.
</prevsent>
</prevsection>
<citsent citstr=" P09-1092 ">
vesti gate using such models in conjunction with grammar-based realizer (cf (velldal, 2007), (cahilland riester, 2009)).<papid> P09-1092 </papid></citsent>
<aftsection>
<nextsent>however, for an initial investigation of the role of semantics and lexicalisation, looking at the binomial construction in isolation is more tractable.
</nextsent>
<nextsent>acknowledgments this work was partially supported by fellowship to aurelie herbelot from the alexander von humboldt foundation.
</nextsent>
<nextsent>we are grateful to the reviewers for their comments.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI308">
<title id=" W11-2113.xml">regression and ranking based optimisation for sentence level mt evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>human judgements of translation quality are veryexpensive.
</prevsent>
<prevsent>for this reason automatic mt evaluation metrics are used to as an approximation by comparing predicted translations to human authored references.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
an early mt evaluation metric, bleu (papineni et al, 2002), <papid> P02-1040 </papid>is still the most commonly used metric in automatic machine translation evalu ation.</citsent>
<aftsection>
<nextsent>however, several drawbacks have been stated by many researchers (chiang et al, 2008<papid> D08-1064 </papid>a; callison burch et al, 2006; banerjee and lavie, 2005),<papid> W05-0909 </papid>most notably that it omits recall (substituting this with penalty for overly short output) and not being easily applied at the sentence level.</nextsent>
<nextsent>later heuristic metrics such as meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and ter (snover et al, 2006) account for both precision and recall, but their relative weights are difficult to determine manually.in contrast to heuristic metrics, trained metrics use supervised learning to model directly human judgements.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI309">
<title id=" W11-2113.xml">regression and ranking based optimisation for sentence level mt evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for this reason automatic mt evaluation metrics are used to as an approximation by comparing predicted translations to human authored references.
</prevsent>
<prevsent>an early mt evaluation metric, bleu (papineni et al, 2002), <papid> P02-1040 </papid>is still the most commonly used metric in automatic machine translation evalu ation.</prevsent>
</prevsection>
<citsent citstr=" D08-1064 ">
however, several drawbacks have been stated by many researchers (chiang et al, 2008<papid> D08-1064 </papid>a; callison burch et al, 2006; banerjee and lavie, 2005),<papid> W05-0909 </papid>most notably that it omits recall (substituting this with penalty for overly short output) and not being easily applied at the sentence level.</citsent>
<aftsection>
<nextsent>later heuristic metrics such as meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and ter (snover et al, 2006) account for both precision and recall, but their relative weights are difficult to determine manually.in contrast to heuristic metrics, trained metrics use supervised learning to model directly human judgements.</nextsent>
<nextsent>this allows the combination of different features and can better fit specific tasks, such as evaluation focusing more on flu ency/adequacy/relative ranks or post editing effort.previous work includes approaches using classification (corston-oliver et al, 2001), regression (alber cht and hwa, 2008; specia and gimenez, 2010), and ranking (duh, 2008).<papid> W08-0331 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI313">
<title id=" W11-2113.xml">regression and ranking based optimisation for sentence level mt evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for this reason automatic mt evaluation metrics are used to as an approximation by comparing predicted translations to human authored references.
</prevsent>
<prevsent>an early mt evaluation metric, bleu (papineni et al, 2002), <papid> P02-1040 </papid>is still the most commonly used metric in automatic machine translation evalu ation.</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
however, several drawbacks have been stated by many researchers (chiang et al, 2008<papid> D08-1064 </papid>a; callison burch et al, 2006; banerjee and lavie, 2005),<papid> W05-0909 </papid>most notably that it omits recall (substituting this with penalty for overly short output) and not being easily applied at the sentence level.</citsent>
<aftsection>
<nextsent>later heuristic metrics such as meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and ter (snover et al, 2006) account for both precision and recall, but their relative weights are difficult to determine manually.in contrast to heuristic metrics, trained metrics use supervised learning to model directly human judgements.</nextsent>
<nextsent>this allows the combination of different features and can better fit specific tasks, such as evaluation focusing more on flu ency/adequacy/relative ranks or post editing effort.previous work includes approaches using classification (corston-oliver et al, 2001), regression (alber cht and hwa, 2008; specia and gimenez, 2010), and ranking (duh, 2008).<papid> W08-0331 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI316">
<title id=" W11-2113.xml">regression and ranking based optimisation for sentence level mt evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, several drawbacks have been stated by many researchers (chiang et al, 2008<papid> D08-1064 </papid>a; callison burch et al, 2006; banerjee and lavie, 2005),<papid> W05-0909 </papid>most notably that it omits recall (substituting this with penalty for overly short output) and not being easily applied at the sentence level.</prevsent>
<prevsent>later heuristic metrics such as meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>and ter (snover et al, 2006) account for both precision and recall, but their relative weights are difficult to determine manually.in contrast to heuristic metrics, trained metrics use supervised learning to model directly human judgements.</prevsent>
</prevsection>
<citsent citstr=" W08-0331 ">
this allows the combination of different features and can better fit specific tasks, such as evaluation focusing more on flu ency/adequacy/relative ranks or post editing effort.previous work includes approaches using classification (corston-oliver et al, 2001), regression (alber cht and hwa, 2008; specia and gimenez, 2010), and ranking (duh, 2008).<papid> W08-0331 </papid></citsent>
<aftsection>
<nextsent>most of which achieved good results and better correlations with human judgments than heuristic baseline methods.overall automatic metrics must find balance between several key issues: a) applicability to different sized texts (documents vs sentences), b) easyof portability to different languages, c) runtime requirements and d) correlation with human judgement data.
</nextsent>
<nextsent>previous work has typically ignored at least one of these issues, e.g., bleu which applies only to documents (a), trained metrics (albercht and hwa, 2008; specia and gimenez, 2010) which tend to ignore and c. this paper presents rose, trained metric whichis loosely based on bleu, but seeks to further simplify its components such that it can be used for sentence level evaluation.
</nextsent>
<nextsent>this contrasts with bleu which is defined over large documents, and must 123 be coarsely approximated to allow sentence levelapplication.
</nextsent>
<nextsent>the increased flexibility of rose allows the metric to be used in wider range of situations, including during decoding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI318">
<title id=" W11-2113.xml">regression and ranking based optimisation for sentence level mt evaluation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in order to reduce repeatedly generating the same word, bleu clips the counts of each candidate n-gram to the maximum counts of that n-gram that in references, and witha brevity penalty to down-scale the score for output shorter than the reference.
</prevsent>
<prevsent>in bleu, each gram precision is given equal weight in geometric mean, while nist (doddington and george, 2002)extended bleu by assigning more informative grams higher weight.however, bleu and nist have several drawbacks, the first being that bleu uses geometric mean over all n-grams which makes bleu almost unusable for sentence level evaluations 1.
</prevsent>
</prevsection>
<citsent citstr=" C04-1072 ">
secondly, 1note that various approximations exits (lin and och, 2004;<papid> C04-1072 </papid>bleu and nist both use the brevity penalty to replace recall, but banerjee and lavie (2005) <papid> W05-0909 </papid>in experiments show that the brevity penalty is poor substitute for recall.</citsent>
<aftsection>
<nextsent>banerjee and lavie (2005) <papid> W05-0909 </papid>proposed meteor metric, which that uses recall instead of the bp.</nextsent>
<nextsent>callison-burch et al (2007; callison-burch et al (2008) show that meteor does not perform well in out of english task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI330">
<title id=" W11-2113.xml">regression and ranking based optimisation for sentence level mt evaluation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>and yes/no? tasks.
</prevsent>
<prevsent>english punctuation and 100 common function words list of four languages in this experiment were generated.
</prevsent>
</prevsection>
<citsent citstr=" P04-3031 ">
english pos was tagged by nltk (bird and loper, 2004).<papid> P04-3031 </papid></citsent>
<aftsection>
<nextsent>4.2 results and discussion.
</nextsent>
<nextsent>table 3 shows the results of rose-reg with three different svm kernel functions.
</nextsent>
<nextsent>performance are similar among three different kernel functions.
</nextsent>
<nextsent>however, the linear kernel is the fastest and simple stand there is no overall winner.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI331">
<title id=" W12-0405.xml">building a data collection for deception research </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we believe that many of the issues holding back deception research could be resolved through the construction of standardized corpora that would provide base for expanding deception studies, comparing different approaches and testing new methods.
</prevsent>
<prevsent>as first step towards standardization, we offer set of practical guidelines for building corpora that are customized for studies of high stakes deception.
</prevsent>
</prevsection>
<citsent citstr=" C08-1006 ">
the guidelines are based on our experiences in creating corpus of real world language data that we used for testing the deception detection approach described in bachenko et al (2008), <papid> C08-1006 </papid>fitzpatrick and bachenko (2010).</citsent>
<aftsection>
<nextsent>we hope that our experience will encourage other researchers to build and contribute corpora with the goal of establishing shared resource that passes the test of ecological validity.
</nextsent>
<nextsent>section 2 of the paper describes the data collection initiative we are engaged in, section 3 describes the methods used to corroborate the claims in the data, section 4 concludes our account and covers lessons learned.
</nextsent>
<nextsent>we should point out that the ethical considerations that govern our data collection are subject to the united states code of federal 31 regulations (cfrs) for the protection of human subjects and may differ in some respects from those in other countries.
</nextsent>
<nextsent>we are building corpus of spoken and written narrative data used in real world high stakes cases in which many of the claims in the corpus have been corroborated as true or false.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI333">
<title id=" W11-2140.xml">noisy sms machine translation in low density languages </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>the rest of this paper is structured as follows.
</prevsent>
<prevsent>first, we provide brief overview of our baseline system in section 2, followed by an examination of issues posed by this task and the steps we have takento address them in section 3, and finally we conclude with experimental results and additional analysis.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
our baseline system is based on hierarchical phrase-based translation model, which can formally be described as synchronous context-free grammar (scfg) (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>our system is implemented in cdec, an open source framework for aligning, training, and decoding with number of different translation models, including scfgs.
</nextsent>
<nextsent>(dyer et al., 2010).<papid> P10-4002 </papid></nextsent>
<nextsent>1 scfg grammars contain pairs of cfg rules with aligned nonterminals, where by introducing these nonterminals into the grammar, such system is able to utilize both word and phrase level reordering to capture the hierarchical structure of lan guage.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI334">
<title id=" W11-2140.xml">noisy sms machine translation in low density languages </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>our baseline system is based on hierarchical phrase-based translation model, which can formally be described as synchronous context-free grammar (scfg) (chiang, 2007).<papid> J07-2003 </papid></prevsent>
<prevsent>our system is implemented in cdec, an open source framework for aligning, training, and decoding with number of different translation models, including scfgs.</prevsent>
</prevsection>
<citsent citstr=" P10-4002 ">
(dyer et al., 2010).<papid> P10-4002 </papid></citsent>
<aftsection>
<nextsent>1 scfg grammars contain pairs of cfg rules with aligned nonterminals, where by introducing these nonterminals into the grammar, such system is able to utilize both word and phrase level reordering to capture the hierarchical structure of language.
</nextsent>
<nextsent>scfg translation models have been shownto produce state-of-the-art translation for most language pairs, as they are capable of both exploiting lexical information for and efficiently computing all possible reorderings using cky-based decoder (dyer et al, 2009).<papid> W09-0426 </papid></nextsent>
<nextsent>1http://cdec-decoder.org 344 one benefit of cdec is the flexibility allowed with regard to the input format, as it expects either astring, lattice, or context-free forest, and subsequently generates hypergraph representing the full translation forest without any pruning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI335">
<title id=" W11-2140.xml">noisy sms machine translation in low density languages </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>(dyer et al., 2010).<papid> P10-4002 </papid></prevsent>
<prevsent>1 scfg grammars contain pairs of cfg rules with aligned nonterminals, where by introducing these nonterminals into the grammar, such system is able to utilize both word and phrase level reordering to capture the hierarchical structure of lan guage.</prevsent>
</prevsection>
<citsent citstr=" W09-0426 ">
scfg translation models have been shownto produce state-of-the-art translation for most language pairs, as they are capable of both exploiting lexical information for and efficiently computing all possible reorderings using cky-based decoder (dyer et al, 2009).<papid> W09-0426 </papid></citsent>
<aftsection>
<nextsent>1http://cdec-decoder.org 344 one benefit of cdec is the flexibility allowed with regard to the input format, as it expects either astring, lattice, or context-free forest, and subsequently generates hypergraph representing the full translation forest without any pruning.
</nextsent>
<nextsent>this forest can now be rescored, by intersecting it with language model for instance, to obtain output translations.
</nextsent>
<nextsent>these capabilities of cdec allow us to perform the experiments described below, which may have otherwise proven to be quite impractical to carry out in another system.
</nextsent>
<nextsent>the set of features used in our model were the rule translation relative frequency (e|f), target n-gram language model (e), lexical translation probabilities plex(e|f) and plex(f |e), count of the total number of rules used, target word penalty, and count of the number of times the glue rule is used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI337">
<title id=" W11-2140.xml">noisy sms machine translation in low density languages </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>the set of features used in our model were the rule translation relative frequency (e|f), target n-gram language model (e), lexical translation probabilities plex(e|f) and plex(f |e), count of the total number of rules used, target word penalty, and count of the number of times the glue rule is used.
</prevsent>
<prevsent>the number of non-terminals allowed in synchronous grammar rule was restricted to two, and the non-terminal span limit was 12 for non-gluegrammars.
</prevsent>
</prevsection>
<citsent citstr=" D07-1104 ">
the hierarchical phrase-based translation grammar was extracted using suffix array rule extractor (lopez, 2007).<papid> D07-1104 </papid></citsent>
<aftsection>
<nextsent>to optimize the feature weights for our model, we used an implementation of the hypergraph minimum error rate training (mert) algorithm (dyer et al, 2010; <papid> P10-4002 </papid>och, 2003) <papid> P03-1021 </papid>for training with an arbitrary lossfunction.</nextsent>
<nextsent>the error function we used was bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>and the decoder was configured to use cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>with limit of 100 candidates at each node.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI339">
<title id=" W11-2140.xml">noisy sms machine translation in low density languages </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>the number of non-terminals allowed in synchronous grammar rule was restricted to two, and the non-terminal span limit was 12 for non-gluegrammars.
</prevsent>
<prevsent>the hierarchical phrase-based translation grammar was extracted using suffix array rule extractor (lopez, 2007).<papid> D07-1104 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
to optimize the feature weights for our model, we used an implementation of the hypergraph minimum error rate training (mert) algorithm (dyer et al, 2010; <papid> P10-4002 </papid>och, 2003) <papid> P03-1021 </papid>for training with an arbitrary lossfunction.</citsent>
<aftsection>
<nextsent>the error function we used was bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>and the decoder was configured to use cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>with limit of 100 candidates at each node.</nextsent>
<nextsent>2.1 data preparation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI340">
<title id=" W11-2140.xml">noisy sms machine translation in low density languages </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>the hierarchical phrase-based translation grammar was extracted using suffix array rule extractor (lopez, 2007).<papid> D07-1104 </papid></prevsent>
<prevsent>to optimize the feature weights for our model, we used an implementation of the hypergraph minimum error rate training (mert) algorithm (dyer et al, 2010; <papid> P10-4002 </papid>och, 2003) <papid> P03-1021 </papid>for training with an arbitrary lossfunction.</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the error function we used was bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>and the decoder was configured to use cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>with limit of 100 candidates at each node.</citsent>
<aftsection>
<nextsent>2.1 data preparation.
</nextsent>
<nextsent>the sms messages were originally translated by english speaking volunteers for the purpose of providing first responders with information and locations requiring their assistance.
</nextsent>
<nextsent>as such, in order to create suitable parallel training corpus from which to extract translation grammar, number of step shad to be taken in addition to lower casing and tokenizing both sides of training data.
</nextsent>
<nextsent>many of the english translations had additional notes sections that were added by the translator to the messages with either personal notes or further informative remarks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI341">
<title id=" W11-2140.xml">noisy sms machine translation in low density languages </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>the hierarchical phrase-based translation grammar was extracted using suffix array rule extractor (lopez, 2007).<papid> D07-1104 </papid></prevsent>
<prevsent>to optimize the feature weights for our model, we used an implementation of the hypergraph minimum error rate training (mert) algorithm (dyer et al, 2010; <papid> P10-4002 </papid>och, 2003) <papid> P03-1021 </papid>for training with an arbitrary lossfunction.</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
the error function we used was bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>and the decoder was configured to use cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>with limit of 100 candidates at each node.</citsent>
<aftsection>
<nextsent>2.1 data preparation.
</nextsent>
<nextsent>the sms messages were originally translated by english speaking volunteers for the purpose of providing first responders with information and locations requiring their assistance.
</nextsent>
<nextsent>as such, in order to create suitable parallel training corpus from which to extract translation grammar, number of step shad to be taken in addition to lower casing and tokenizing both sides of training data.
</nextsent>
<nextsent>many of the english translations had additional notes sections that were added by the translator to the messages with either personal notes or further informative remarks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI343">
<title id=" W11-2140.xml">noisy sms machine translation in low density languages </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>as these sections do not correspond to any text on the source side, and would therefore degrade the alignment process, these had to be identified andre moved.
</prevsent>
<prevsent>furthermore, the anonymization of the data resulted in tokens such as first name and phone num ber which were prevalent and had to be preserve das they were.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
since the total amount of haitian english parallel data provided is quite limited, we found additional data and augmented the available set with data gathered by the crisis commons group and made it available to other wmt participants.the combined training corpus from which we extracted our grammar consisted of 123,609 sentence pairs, which was then filtered for length and aligned using the giza++ implementation of ibm model4 (och and ney, 2003) <papid> J03-1002 </papid>to obtain one-to-many alignments in either direction and symmetrized using the grow-diag-final-and method (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>we trained 5-gram language model using the sri language modeling toolkit (stolcke, 2002) from the english monolingual news commentary andnews crawl language modeling training data provided for the shared task and the english portion ofthe parallel data with modified kneser-ney smoothing (chen and goodman, 1996).<papid> P96-1041 </papid></nextsent>
<nextsent>we have previously found that since the beginnings and ends of sentences often display unique characteristics that are not easily captured within the context of the model, explicitly annotating beginning and end of sentence markers as part of our translation process leads to significantly improved performance (dyer et al, 2009).<papid> W09-0426 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI344">
<title id=" W11-2140.xml">noisy sms machine translation in low density languages </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>as these sections do not correspond to any text on the source side, and would therefore degrade the alignment process, these had to be identified andre moved.
</prevsent>
<prevsent>furthermore, the anonymization of the data resulted in tokens such as first name and phone num ber which were prevalent and had to be preserve das they were.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
since the total amount of haitian english parallel data provided is quite limited, we found additional data and augmented the available set with data gathered by the crisis commons group and made it available to other wmt participants.the combined training corpus from which we extracted our grammar consisted of 123,609 sentence pairs, which was then filtered for length and aligned using the giza++ implementation of ibm model4 (och and ney, 2003) <papid> J03-1002 </papid>to obtain one-to-many alignments in either direction and symmetrized using the grow-diag-final-and method (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>we trained 5-gram language model using the sri language modeling toolkit (stolcke, 2002) from the english monolingual news commentary andnews crawl language modeling training data provided for the shared task and the english portion ofthe parallel data with modified kneser-ney smoothing (chen and goodman, 1996).<papid> P96-1041 </papid></nextsent>
<nextsent>we have previously found that since the beginnings and ends of sentences often display unique characteristics that are not easily captured within the context of the model, explicitly annotating beginning and end of sentence markers as part of our translation process leads to significantly improved performance (dyer et al, 2009).<papid> W09-0426 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI345">
<title id=" W11-2140.xml">noisy sms machine translation in low density languages </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, the anonymization of the data resulted in tokens such as first name and phone num ber which were prevalent and had to be preserve das they were.
</prevsent>
<prevsent>since the total amount of haitian english parallel data provided is quite limited, we found additional data and augmented the available set with data gathered by the crisis commons group and made it available to other wmt participants.the combined training corpus from which we extracted our grammar consisted of 123,609 sentence pairs, which was then filtered for length and aligned using the giza++ implementation of ibm model4 (och and ney, 2003) <papid> J03-1002 </papid>to obtain one-to-many alignments in either direction and symmetrized using the grow-diag-final-and method (koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
we trained 5-gram language model using the sri language modeling toolkit (stolcke, 2002) from the english monolingual news commentary andnews crawl language modeling training data provided for the shared task and the english portion ofthe parallel data with modified kneser-ney smoothing (chen and goodman, 1996).<papid> P96-1041 </papid></citsent>
<aftsection>
<nextsent>we have previously found that since the beginnings and ends of sentences often display unique characteristics that are not easily captured within the context of the model, explicitly annotating beginning and end of sentence markers as part of our translation process leads to significantly improved performance (dyer et al, 2009).<papid> W09-0426 </papid></nextsent>
<nextsent>a further difficulty of the task stems from the fact that there are two versions of the sms test set, raw version, which contains the original messages, and clean version which was post-edited by humans.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI348">
<title id=" W11-2140.xml">noisy sms machine translation in low density languages </title>
<section> experimental variation.  </section>
<citcontext>
<prevsection>
<prevsent>since we do not necessarily know in advance which segmentation is the correct one for better quality translation, it may be of use to be able to utilize both segment ations and allow the decoder to learn the appropriate one.
</prevsent>
<prevsent>in previous work, word segmentation lattices have been used to address the problem of productive compounding in morphologically rich languages, such as german, where morphemes are combined to make words but the orthography does not delineate the morpheme boundaries.
</prevsent>
</prevsection>
<citsent citstr=" N09-1046 ">
these lattices encode alternative ways of segmenting compound words, and allow the decoder to automatically choose which segmentation is bestfor translation, leading to significantly improved results (dyer, 2009).<papid> N09-1046 </papid></citsent>
<aftsection>
<nextsent>as opposed to building word segmentation lattices from linguistic morphological analysis of compound word, we propose to utilize the lattice to encode all alternative ways of segmenting word as presented to us in either the clean or raw versions of sentence.
</nextsent>
<nextsent>as the task requires us to produce separate clean and raw output on the test set, we tune one system on lattice built from the clean and raw dev set, and use the single system to decode both the clean and raw test set separately.
</nextsent>
<nextsent>table 5 presents the results of using segmentation lattices.
</nextsent>
<nextsent>3.5 raw-to-clean transformation lattice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI349">
<title id=" W11-2033.xml">multi policy dialogue management </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>for the policy currently in focus.
</prevsent>
<prevsent>the focus of attention?
</prevsent>
</prevsection>
<citsent citstr=" J86-3001 ">
is indeed crucial in verbal interactions, and in linguistic discourse in general (grosz and sidner, 1986) ? <papid> J86-3001 </papid>humans do not arbitrarily switch from one topic to another and back, but rather concentrate on the most salient elements.the set of constraints holding between the activation values of hierarchical and concurrent policies is encoded in simplified bayesian network.</citsent>
<aftsection>
<nextsent>3.4 execution algorithm.
</nextsent>
<nextsent>algorithm 1 illustrates how the activation values are exploited to select the optimal action for multiple policies.
</nextsent>
<nextsent>the algorithm relies on set of processes , where process is associated with specific policy, current state si for the policy, and current activation value b(i) ? b?.
</nextsent>
<nextsent>as we have seen, each policy is fully described with five func tions: likelihood(s, o), obs-update(s, o), pi(s), act-update(s, a), and activation(s).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI350">
<title id=" W11-2033.xml">multi policy dialogue management </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>instead, we treat the activation/termination status of given policy as hidden variable which is only indirectly observed and whose value at each turn is determined via probabilistic reasoning operations.the idea of combining different dialogue management frameworks in single execution process has also been explored in previous work such as(williams, 2008), but only as filtering mechanism ? one policy constraining the results of an other.
</prevsent>
<prevsent>related to the idea of concurrent policies,(turunen et al, 2005) describes software framework for distributed dialogue management, mostly focussing on architectural aspects.
</prevsent>
</prevsection>
<citsent citstr=" W02-0216 ">
in the same vein, (lemon et al, 2002; <papid> W02-0216 </papid>nakano et al, 2008) <papid> W08-0114 </papid>describe techniques for dialogue management respectively based on multi-threading and multi-expert models.</citsent>
<aftsection>
<nextsent>(cuayahuitl et al, 2010) describe an reinforcement learning approach for the optimisation of hierarchical mdp policies, but is not extended to other types of policies.
</nextsent>
<nextsent>closest to our approach is the polca+ algorithm for hierarchical pomdps presented in (pineau, 2004), but unlike our approach, her method does not support temporally extended actions, as the top-down trace is repeated after each time step.
</nextsent>
<nextsent>we introduced new approach to dialogue management based on multiple, interconnected policies controlled by activation values.
</nextsent>
<nextsent>the values are updated at the beginning and the end of each turn to reflect the part of the interaction currently in focus.it is worth noting that the only modification required in the policy specifications to let them run in multi-policy setting is the introduction of the two functions likelihood(s, o) and activation(s).the rest remains untouched and can be defined independently.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI351">
<title id=" W11-2033.xml">multi policy dialogue management </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>instead, we treat the activation/termination status of given policy as hidden variable which is only indirectly observed and whose value at each turn is determined via probabilistic reasoning operations.the idea of combining different dialogue management frameworks in single execution process has also been explored in previous work such as(williams, 2008), but only as filtering mechanism ? one policy constraining the results of an other.
</prevsent>
<prevsent>related to the idea of concurrent policies,(turunen et al, 2005) describes software framework for distributed dialogue management, mostly focussing on architectural aspects.
</prevsent>
</prevsection>
<citsent citstr=" W08-0114 ">
in the same vein, (lemon et al, 2002; <papid> W02-0216 </papid>nakano et al, 2008) <papid> W08-0114 </papid>describe techniques for dialogue management respectively based on multi-threading and multi-expert models.</citsent>
<aftsection>
<nextsent>(cuayahuitl et al, 2010) describe an reinforcement learning approach for the optimisation of hierarchical mdp policies, but is not extended to other types of policies.
</nextsent>
<nextsent>closest to our approach is the polca+ algorithm for hierarchical pomdps presented in (pineau, 2004), but unlike our approach, her method does not support temporally extended actions, as the top-down trace is repeated after each time step.
</nextsent>
<nextsent>we introduced new approach to dialogue management based on multiple, interconnected policies controlled by activation values.
</nextsent>
<nextsent>the values are updated at the beginning and the end of each turn to reflect the part of the interaction currently in focus.it is worth noting that the only modification required in the policy specifications to let them run in multi-policy setting is the introduction of the two functions likelihood(s, o) and activation(s).the rest remains untouched and can be defined independently.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI352">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we present progress on joshua, an open source decoder for hierarchical and syntax based machine translation.
</prevsent>
<prevsent>the main focus is describing thrax, flexible, open source synchronous context-free grammar extractor.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
thrax extracts both hierarchical (chi ang, 2007) <papid> J07-2003 </papid>and syntax-augmented machine translation (zollmann and venugopal, 2006) <papid> W06-3119 </papid>grammars.</citsent>
<aftsection>
<nextsent>it is built on apache hadoop for efficient distributed performance, and can easily be extended with support for new grammars, feature functions, and output formats.
</nextsent>
<nextsent>joshua is an open-source1 toolkit for hierarchical machine translation of human languages.
</nextsent>
<nextsent>the original version of joshua (li et al, 2009) <papid> W09-0424 </papid>was re implementation of the python-based hiero machine translation system (chiang, 2007); <papid> J07-2003 </papid>it was later extended (li et al, 2010) <papid> W10-1718 </papid>to support richer formalisms, such as samt (zollmann and venugopal, 2006).<papid> W06-3119 </papid></nextsent>
<nextsent>the main focus of this paper is to describe this past years work in developing thrax (weese, 2011), an open-source grammar extractor for hiero and samt grammars.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI353">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>we present progress on joshua, an open source decoder for hierarchical and syntax based machine translation.
</prevsent>
<prevsent>the main focus is describing thrax, flexible, open source synchronous context-free grammar extractor.
</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
thrax extracts both hierarchical (chi ang, 2007) <papid> J07-2003 </papid>and syntax-augmented machine translation (zollmann and venugopal, 2006) <papid> W06-3119 </papid>grammars.</citsent>
<aftsection>
<nextsent>it is built on apache hadoop for efficient distributed performance, and can easily be extended with support for new grammars, feature functions, and output formats.
</nextsent>
<nextsent>joshua is an open-source1 toolkit for hierarchical machine translation of human languages.
</nextsent>
<nextsent>the original version of joshua (li et al, 2009) <papid> W09-0424 </papid>was re implementation of the python-based hiero machine translation system (chiang, 2007); <papid> J07-2003 </papid>it was later extended (li et al, 2010) <papid> W10-1718 </papid>to support richer formalisms, such as samt (zollmann and venugopal, 2006).<papid> W06-3119 </papid></nextsent>
<nextsent>the main focus of this paper is to describe this past years work in developing thrax (weese, 2011), an open-source grammar extractor for hiero and samt grammars.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI355">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is built on apache hadoop for efficient distributed performance, and can easily be extended with support for new grammars, feature functions, and output formats.
</prevsent>
<prevsent>joshua is an open-source1 toolkit for hierarchical machine translation of human languages.
</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
the original version of joshua (li et al, 2009) <papid> W09-0424 </papid>was re implementation of the python-based hiero machine translation system (chiang, 2007); <papid> J07-2003 </papid>it was later extended (li et al, 2010) <papid> W10-1718 </papid>to support richer formalisms, such as samt (zollmann and venugopal, 2006).<papid> W06-3119 </papid></citsent>
<aftsection>
<nextsent>the main focus of this paper is to describe this past years work in developing thrax (weese, 2011), an open-source grammar extractor for hiero and samt grammars.
</nextsent>
<nextsent>grammar extraction has shown itself to be something of black art, with decoding performance depending crucially on variety of features and options that are not always clearly described in papers.
</nextsent>
<nextsent>this hindered direct comparison both between and within grammatical formalisms.
</nextsent>
<nextsent>thrax standardizes joshuas grammar ex 1http://github.com/joshua-decoder/joshuatraction procedures by providing flexible and configurable means of specifying these settings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI358">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is built on apache hadoop for efficient distributed performance, and can easily be extended with support for new grammars, feature functions, and output formats.
</prevsent>
<prevsent>joshua is an open-source1 toolkit for hierarchical machine translation of human languages.
</prevsent>
</prevsection>
<citsent citstr=" W10-1718 ">
the original version of joshua (li et al, 2009) <papid> W09-0424 </papid>was re implementation of the python-based hiero machine translation system (chiang, 2007); <papid> J07-2003 </papid>it was later extended (li et al, 2010) <papid> W10-1718 </papid>to support richer formalisms, such as samt (zollmann and venugopal, 2006).<papid> W06-3119 </papid></citsent>
<aftsection>
<nextsent>the main focus of this paper is to describe this past years work in developing thrax (weese, 2011), an open-source grammar extractor for hiero and samt grammars.
</nextsent>
<nextsent>grammar extraction has shown itself to be something of black art, with decoding performance depending crucially on variety of features and options that are not always clearly described in papers.
</nextsent>
<nextsent>this hindered direct comparison both between and within grammatical formalisms.
</nextsent>
<nextsent>thrax standardizes joshuas grammar ex 1http://github.com/joshua-decoder/joshuatraction procedures by providing flexible and configurable means of specifying these settings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI362">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> thrax: grammar extraction.  </section>
<citcontext>
<prevsection>
<prevsent>section 3 presents systematic comparison of the two grammars using identical feature sets.in addition, joshua now includes single parameterized script that implements the entire mt pipeline, from data preparation to evaluation.
</prevsent>
<prevsent>this script is built on top of module called cachepipe.cachepipe is simple wrapper around shell commands that uses sha-1 hashes and explicitly provided lists of dependencies to determine whethera command needs to be run, saving time both in running and debugging machine translation pipelines.
</prevsent>
</prevsection>
<citsent citstr=" P10-4002 ">
in modern machine translation systems such as joshua (li et al, 2009) <papid> W09-0424 </papid>and cdec (dyer et al, 2010), <papid> P10-4002 </papid>translation model is represented as synchronous context-free grammar (scfg).</citsent>
<aftsection>
<nextsent>formally, an scfg may be considered as tuple (n,s, t?, t?
</nextsent>
<nextsent>, g) where is set of nonterminal symbols of the grammar, ? is the goal symbol, t?
</nextsent>
<nextsent>and tare the source- and target-side terminal symbol vocabularies, respectively, and is set of production rules of the grammar.
</nextsent>
<nextsent>each rule in is of the form ? ??, ?,where ? is nonterminal symbol, ? is sequence of symbols from ? t?, ? is sequence of 478symbols from ? t? , and ? is one-to-one correspondence between the nonterminal symbols of ? and ?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI367">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> thrax: grammar extraction.  </section>
<citcontext>
<prevsection>
<prevsent>samt additionally requires that the target side of the corpus be parsed.there are several parameters that can make significant difference in grammars overall translationperformance.
</prevsent>
<prevsent>each of these parameters is easily adjustable in thrax by changing its value in configuration file.
</prevsent>
</prevsection>
<citsent citstr=" C08-1064 ">
maximum rule span ? maximum span of consistent phrase pairs ? maximum number of nonterminals ? minimum number of aligned terminals in rule 2http://aws.amazon.com/elasticmapreduce/ ? whether to allow adjacent nonterminals on source side ? whether to allow unaligned words at the edges of consistent phrase pairs chiang (2007) <papid> J07-2003 </papid>gives reasonable heuristic choices for these parameters when extracting hiero grammar, and lopez (2008) <papid> C08-1064 </papid>confirms some of them (maximum rule span of 10, maximum number of source side symbols at 5, and maximum number of nonterminals at 2 per rule).</citsent>
<aftsection>
<nextsent>provided comparisons among phrase-based, hierarchical, and syntax-based models, but did not report extensive experimentation with the model parameterizations.when extracting hiero- or samt-style grammars, the first hadoop job in the thrax workflow takes in parallel corpus and produces set of rules.
</nextsent>
<nextsent>but in fact thraxs extraction mechanism is more general than that; all it requires is function that maps string to set of rules.
</nextsent>
<nextsent>this makes it easy to implement new grammars and extract them using thrax.
</nextsent>
<nextsent>2.4 feature functions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI368">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> thrax: grammar extraction.  </section>
<citcontext>
<prevsection>
<prevsent>is the number of times given event was extracted.
</prevsent>
<prevsent>lexical weighting plex(?|?,a) and plex(?|?,a).
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
we calculate these weights as given in (koehn et al, 2003): <papid> N03-1017 </papid>let be the alignment between ? and ?, so (i, j) ? if and only if the ith word of ? is aligned to the jth word of ?.</citsent>
<aftsection>
<nextsent>then we can define plex(?|?)
</nextsent>
<nextsent>as n?
</nextsent>
<nextsent>i=1 1 |{j : (i, j) ? a}| ?
</nextsent>
<nextsent>(i,j)a w(j |i) (3) where is the ith word of ?, is the jth word of ?, and w(y|x) is the relative frequency of seeing word given x. ? rarity penalty, given by exp(1?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI371">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the data.
</prevsent>
<prevsent>we also removed any sentences longer than 50 tokens (after tokenization).
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
for samt grammar extraction, we parsed the english training data using the berkeley parser (petrov et al, 2006) <papid> P06-1055 </papid>with the provided treebank-trained grammar.</citsent>
<aftsection>
<nextsent>we tuned the model weights against thewmt08 test set (news-test2008) using zmert (zaidan, 2009), an implementation of minimum error-rate training included with joshua.
</nextsent>
<nextsent>we decoded the test set to produce 300-best list of unique translations, then chose the best candidate for each sentence using minimum bayes risk reranking(kumar and byrne, 2004).<papid> N04-1022 </papid></nextsent>
<nextsent>figure 2 shows an example derivation with an samt grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI372">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for samt grammar extraction, we parsed the english training data using the berkeley parser (petrov et al, 2006) <papid> P06-1055 </papid>with the provided treebank-trained grammar.</prevsent>
<prevsent>we tuned the model weights against thewmt08 test set (news-test2008) using zmert (zaidan, 2009), an implementation of minimum error-rate training included with joshua.</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
we decoded the test set to produce 300-best list of unique translations, then chose the best candidate for each sentence using minimum bayes risk reranking(kumar and byrne, 2004).<papid> N04-1022 </papid></citsent>
<aftsection>
<nextsent>figure 2 shows an example derivation with an samt grammar.
</nextsent>
<nextsent>to re-casethe 1-best test set output, we trained true-case 5 gram language model using the same lm training data as before, and used an scfg translation model to translate from the lower cased to true-case output.the translation model used rules limited to five tokens in length, and contained no hierarchical rules.
</nextsent>
<nextsent>machine translation pipelines involve the specification and execution of many different datasets, training procedures, and pre- and post-processing techniques that can have large effects on translation out come, and which make direct comparisons between systems difficult.
</nextsent>
<nextsent>the complexity of managing these pipelines and experimental environments has led to anumber of different experimental management systems, such as experiment.perl,6 joshua 2.0s make file system (li et al, 2010), <papid> W10-1718 </papid>and loony bin (clark and lavie, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI374">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>it also serves asthe foundation of new script in joshua 3.0 that implements the complete joshua pipeline, from data preparation to evaluation.
</prevsent>
<prevsent>thrax is currently limited to scfg-based translation models.
</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
a natural development would be to extractghkm grammars (galley et al, 2004) <papid> N04-1035 </papid>or more recent tree-to-tree models (zhang et al, 2008; <papid> P08-1064 </papid>liu et al., 2009; <papid> P09-1063 </papid>chiang, 2010).<papid> P10-1146 </papid></citsent>
<aftsection>
<nextsent>we also hope that thraxwill continue to be extended with more feature functions as researchers develop and contribute them.
</nextsent>
<nextsent>acknowledgements this research was supported by in part by the euromatrixplus project funded by the european commission (7th framework programme), and by thensf under grant iis-0713448.
</nextsent>
<nextsent>opinions, interpretations, and conclusions are the authors?
</nextsent>
<nextsent>alone.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI375">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>it also serves asthe foundation of new script in joshua 3.0 that implements the complete joshua pipeline, from data preparation to evaluation.
</prevsent>
<prevsent>thrax is currently limited to scfg-based translation models.
</prevsent>
</prevsection>
<citsent citstr=" P08-1064 ">
a natural development would be to extractghkm grammars (galley et al, 2004) <papid> N04-1035 </papid>or more recent tree-to-tree models (zhang et al, 2008; <papid> P08-1064 </papid>liu et al., 2009; <papid> P09-1063 </papid>chiang, 2010).<papid> P10-1146 </papid></citsent>
<aftsection>
<nextsent>we also hope that thraxwill continue to be extended with more feature functions as researchers develop and contribute them.
</nextsent>
<nextsent>acknowledgements this research was supported by in part by the euromatrixplus project funded by the european commission (7th framework programme), and by thensf under grant iis-0713448.
</nextsent>
<nextsent>opinions, interpretations, and conclusions are the authors?
</nextsent>
<nextsent>alone.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI376">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>it also serves asthe foundation of new script in joshua 3.0 that implements the complete joshua pipeline, from data preparation to evaluation.
</prevsent>
<prevsent>thrax is currently limited to scfg-based translation models.
</prevsent>
</prevsection>
<citsent citstr=" P09-1063 ">
a natural development would be to extractghkm grammars (galley et al, 2004) <papid> N04-1035 </papid>or more recent tree-to-tree models (zhang et al, 2008; <papid> P08-1064 </papid>liu et al., 2009; <papid> P09-1063 </papid>chiang, 2010).<papid> P10-1146 </papid></citsent>
<aftsection>
<nextsent>we also hope that thraxwill continue to be extended with more feature functions as researchers develop and contribute them.
</nextsent>
<nextsent>acknowledgements this research was supported by in part by the euromatrixplus project funded by the european commission (7th framework programme), and by thensf under grant iis-0713448.
</nextsent>
<nextsent>opinions, interpretations, and conclusions are the authors?
</nextsent>
<nextsent>alone.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI377">
<title id=" W11-2160.xml">joshua 30 syntax based machine translation with the thrax grammar extractor </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>it also serves asthe foundation of new script in joshua 3.0 that implements the complete joshua pipeline, from data preparation to evaluation.
</prevsent>
<prevsent>thrax is currently limited to scfg-based translation models.
</prevsent>
</prevsection>
<citsent citstr=" P10-1146 ">
a natural development would be to extractghkm grammars (galley et al, 2004) <papid> N04-1035 </papid>or more recent tree-to-tree models (zhang et al, 2008; <papid> P08-1064 </papid>liu et al., 2009; <papid> P09-1063 </papid>chiang, 2010).<papid> P10-1146 </papid></citsent>
<aftsection>
<nextsent>we also hope that thraxwill continue to be extended with more feature functions as researchers develop and contribute them.
</nextsent>
<nextsent>acknowledgements this research was supported by in part by the euromatrixplus project funded by the european commission (7th framework programme), and by thensf under grant iis-0713448.
</nextsent>
<nextsent>opinions, interpretations, and conclusions are the authors?
</nextsent>
<nextsent>alone.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI378">
<title id=" W12-0413.xml">modelling fixated discourse in chats with cyber pedophiles </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>we believe that lexical chains are appropriate to model the fixated discourse of the predators chats.
</prevsent>
<prevsent>4.1 lexical chains.
</prevsent>
</prevsection>
<citsent citstr=" J91-1002 ">
a lexical chain is sequence of semantically related terms (morris and hirst, 1991).<papid> J91-1002 </papid></citsent>
<aftsection>
<nextsent>it has applications in many tasks including word sense disambiguation(wsd) (galley and mckeown, 2003) and text summarization (barzilay and elhadad, 1997).<papid> W97-0703 </papid></nextsent>
<nextsent>to estimate semantic similarity we used two metrics: the similarity of leacock and chodorow (leacock and chodorow, 2003), and that of resnik (resnik, 1995).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI379">
<title id=" W12-0413.xml">modelling fixated discourse in chats with cyber pedophiles </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 lexical chains.
</prevsent>
<prevsent>a lexical chain is sequence of semantically related terms (morris and hirst, 1991).<papid> J91-1002 </papid></prevsent>
</prevsection>
<citsent citstr=" W97-0703 ">
it has applications in many tasks including word sense disambiguation(wsd) (galley and mckeown, 2003) and text summarization (barzilay and elhadad, 1997).<papid> W97-0703 </papid></citsent>
<aftsection>
<nextsent>to estimate semantic similarity we used two metrics: the similarity of leacock and chodorow (leacock and chodorow, 2003), and that of resnik (resnik, 1995).
</nextsent>
<nextsent>leacock and chodorows semantic similarity measure is defined as: siml&ch;(c1, c2) = log length(c1, c2) 2 ? depth where length(c1, c2) is the length of the shortest path between the concepts c1 and c2 and depth is depth of the taxonomy.
</nextsent>
<nextsent>the semantic similarity measure that was proposed by resnik (resnik, 1995) relies on the information content concept: ic(c) = logp (c) where p(c) is the probability of encountering the concept in large corpus.
</nextsent>
<nextsent>thus, resniks similarity measure is defined as follows: simresnik(c1, c2) = ic(lcs(c1, c2)) where lcs(c1, c2) is the least common subsumer of c1 and c2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI380">
<title id=" W12-0413.xml">modelling fixated discourse in chats with cyber pedophiles </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>behavior differ from the responses of real children (egan et al, 2011).
</prevsent>
<prevsent>their goal is to build legal case against the pedophile and, therefore, they are more willing to provoke the predator than to avoid sex-related conversation.
</prevsent>
</prevsection>
<citsent citstr=" W11-1713 ">
another way to distinguish cyber sex fixed topic from the predators unwillingness to step out of it is could be to use emotion classification based on the leary rose model proposed by vaassen and daelemans (vaassen and daelemans, 2011).<papid> W11-1713 </papid></citsent>
<aftsection>
<nextsent>their approach is based on interpersonal circumplex suggested by leary (leary, 1957).
</nextsent>
<nextsent>this is model of interpersonal communication that reflects whether one of the participants is dominant and whether the participants arecooperative.
</nextsent>
<nextsent>it was already mentioned that cyberpe dophiles tend to be dominant.
</nextsent>
<nextsent>therefore, we believe that the leary rose model can be useful in detecting online sexual predation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI381">
<title id=" W11-1821.xml">detecting entity relations as a supporting task for biomolecular event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as supporting task for the bionlp st11, we have studied two types ofsuch entity relations: subunit-complex and protein component.
</prevsent>
<prevsent>these relationships may occur within single noun phrase, but also between two different noun phrases.
</prevsent>
</prevsection>
<citsent citstr=" W11-1812 ">
a few examples are listed in table 1; more details on the datasets and definitions of entity relations can be found in (pyysalo et al, 2011).<papid> W11-1812 </papid></citsent>
<aftsection>
<nextsent>valid entity relations involve one ggp (gene orgene product) and one domain term (e.g. promoter?)
</nextsent>
<nextsent>and they always occur within single sentence.
</nextsent>
<nextsent>in the first step towards classification of entity relations, we have calculated the semantic similarity between domain terms (section 2).
</nextsent>
<nextsent>supervised learning techniques are then applied to select sentences likely to contain entity relations (section 3).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI382">
<title id=" W11-1821.xml">detecting entity relations as a supporting task for biomolecular event extraction </title>
<section> semantic analysis.  </section>
<citcontext>
<prevsection>
<prevsent>we have implemented two strategies to capture this textual variation, grouping semantically similar words together.the first method takes advantage of manual annotations of semantic categories in the genia event corpus.
</prevsent>
<prevsent>this corpus contains manual annotation of various domain terms such as promoters, complexes and other biological entities in 1000 pubmed articles (kim et al, 2008).the second method relies on statistical properties of nearly 15.000 articles, collected by searching pubmed articles involving human transcription factor blood cells.
</prevsent>
</prevsection>
<citsent citstr=" P10-4006 ">
from these articles, we have then calculated semantic space using latent semantic analysis (lsa) as implemented by the s-spacepackage (jurgens and stevens, 2010).<papid> P10-4006 </papid></citsent>
<aftsection>
<nextsent>the algorithm results in high-dimensional vectors that represent word contexts, and similar vectors then refer to semantically similar words.
</nextsent>
<nextsent>we have applied the markov cluster algorithm (mcl) (van dongen, 2000) to group semantically similar terms together.
</nextsent>
<nextsent>147 type of relation examples subunit-complex the c-fos content of [ap-1]?
</nextsent>
<nextsent>/ c-jun, component of the transcription factor [ap-1]?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI383">
<title id=" W12-1604.xml">enhancing referential success by tracking hearer gaze </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for utterances that involve references to objects in the current environment, one can therefore ask whether eye tracking can be used to reliably judge the communicative success of the utterance.
</prevsent>
<prevsent>this would be of practical interest for implemented dialog systems once eye tracking becomes mainstream technology; and even today, asystem that reliably monitors communicative success using eye tracking could serve as testbed for exploring monitoring and repair strategies.in this paper, we present an interactive natural language generation (nlg) system that uses eye 30 tracking to monitor communicative success.
</prevsent>
</prevsection>
<citsent citstr=" W10-4233 ">
our system gives real-time instructions that are designed to help the user perform treasure-hunt task in the virtual 3d environments of the recent challenges on generating instructions in virtual environments (give; koller et al  (2010)).<papid> W10-4233 </papid></citsent>
<aftsection>
<nextsent>it monitors how theuser resolves referring expressions (res) by mapping the users gaze to objects in the virtual environment.
</nextsent>
<nextsent>the system takes gaze to the intended referent as evidence of successful understanding, and gives the user positive feedback; by contrast, gaze to other objects triggers negative feedback.
</nextsent>
<nextsent>crucially, this feedback comes before the user interacts with the object in the virtual environment, keeping the user from making mistakes before they happen.
</nextsent>
<nextsent>we evaluate our system against one baseline that gives no feedback, and another that bases its feed back on monitoring the users movements and their field of view.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI384">
<title id=" W12-1604.xml">enhancing referential success by tracking hearer gaze </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a full solution may require plan recognition or abductive or epistemic reasoning (see e.g. young et al  (1994), hirst et al  (1994)); in practice, many systems use more streamlined (traum, 1994) or statistical methods (paek and horvitz, 1999).
</prevsent>
<prevsent>most dialog systems focus on the verbal interaction of the system and user, and the users utterances are therefore the primary source of evidence in the monitoring process.
</prevsent>
</prevsection>
<citsent citstr=" E09-1085 ">
some incremental dialog system scan monitor the users verbal reactions to the systems utterances in real time, and continuously up date the grounding state while the system utterance is still in progress (skantze and schlangen, 2009; <papid> E09-1085 </papid>buss and schlangen, 2010).</citsent>
<aftsection>
<nextsent>in this paper, we focus on the generation side of adialog system the user is the hearer and on monitoring the users extra linguistic reactions, in particular their gaze.
</nextsent>
<nextsent>tanenhaus et al  (1995) and allo penna et al  (1998) showed that subjects in psy cho linguistic experiments who hear an re visually attend to the object to which they resolve there.
</nextsent>
<nextsent>the visual world?
</nextsent>
<nextsent>experimental paradigm exploits this by presenting objects on computer screen and using an eye tracker to monitor the subjects gaze.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI385">
<title id=" W12-1604.xml">enhancing referential success by tracking hearer gaze </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to our knowledge, there has been no research on this; in particular, not in dynamic 3d environments.
</prevsent>
<prevsent>the closest earlier work of which weare aware comes from the context of the give challenge, shared task for interactive, situated natural language generation systems.
</prevsent>
</prevsection>
<citsent citstr=" W10-4203 ">
these systems typically approximate hearer gaze as visibility of objects on the screen and monitor grounding based on this (denis, 2010; <papid> W10-4203 </papid>racca et al , 2011).</citsent>
<aftsection>
<nextsent>31 figure 1: first-person view of virtual 3d environment.
</nextsent>
<nextsent>in virtual environment sin this paper, we consider the communicative situation of the give challenge (koller et al , 2010; <papid> W10-4233 </papid>striegnitz et al , 2011).</nextsent>
<nextsent>in this task, human user can move about freely in virtual indoor environment featuring several interconnected rooms and corri dors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI387">
<title id=" W12-1604.xml">enhancing referential success by tracking hearer gaze </title>
<section> interactive natural-language generation.  </section>
<citcontext>
<prevsection>
<prevsent>a typical nlg system used 32 figure 3: the scene of fig.
</prevsent>
<prevsent>1, after the user moved and turned in response to referring expression.
</prevsent>
</prevsection>
<citsent citstr=" W09-0610 ">
in the give challenge (e.g., dionne et al  (2009), <papid> W09-0610 </papid>denis (2010), <papid> W10-4203 </papid>racca et al  (2011)) may try to predict how the user might resolve there based on the visibility of objects, timing data, or distances.</citsent>
<aftsection>
<nextsent>relying only on such data, however, even human observer could have difficulties in interpreting the users reac tion; the user in fig.
</nextsent>
<nextsent>3 ended up closer to the green and blue buttons, but the other buttons (the two blue ones) are, to similar degrees, visually in focus.
</nextsent>
<nextsent>the contribution of this paper is to present method for monitoring the communicative success of an rebased on eyetracking.
</nextsent>
<nextsent>we start from the hypothesis that when the user resolves an re to certain object, they will tend to gaze at this object.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI389">
<title id=" W11-1912.xml">an incremental model for coreference resolution with restrictive antecedent accessibility </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we do not apply machine learning, instead the system uses an empirically derived salience measure based on the dependency labels of thetrue mentions.
</prevsent>
<prevsent>our experiments seem to indicate that such system already is on par with machine learning approaches.
</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
with notable exceptions (luo et al , 2004; <papid> P04-1018 </papid>yang et al ., 2004; <papid> C04-1033 </papid>daume iii and marcu, 2005; culotta et al ., 2007; <papid> N07-1011 </papid>klenner, 2007; rahman and ng, 2009; klenner and ailloud, 2009; cai and strube, 2010; <papid> W10-4305 </papid>raghunathan et al , 2010) <papid> D10-1048 </papid>supervised approaches to coreference resolution are often realized by pairwise classification of anaphor-antecedent candidates.</citsent>
<aftsection>
<nextsent>apopular and often reimplemented approach is presented in (soon et al , 2001).<papid> J01-4004 </papid></nextsent>
<nextsent>as recently discussed in (ng, 2010), <papid> P10-1142 </papid>the so called mention-pair model suffers from several design flaws which originate from the locally confined perspective of the model: ? generation of (transitively) redundant pairs, as the formation of coreference sets (coreference clustering) is done after pairwise classification ? thereby generation of skewed training sets which lead to classifiers biased towards negative classification ? no means to enforce global constraints such as transit ivity ? under specification of antecedent candidates these problems can be remedied by an incremental entity-mention model, where candidate pairs are evaluated on the basis of the emerging coreferencesets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI390">
<title id=" W11-1912.xml">an incremental model for coreference resolution with restrictive antecedent accessibility </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we do not apply machine learning, instead the system uses an empirically derived salience measure based on the dependency labels of thetrue mentions.
</prevsent>
<prevsent>our experiments seem to indicate that such system already is on par with machine learning approaches.
</prevsent>
</prevsection>
<citsent citstr=" C04-1033 ">
with notable exceptions (luo et al , 2004; <papid> P04-1018 </papid>yang et al ., 2004; <papid> C04-1033 </papid>daume iii and marcu, 2005; culotta et al ., 2007; <papid> N07-1011 </papid>klenner, 2007; rahman and ng, 2009; klenner and ailloud, 2009; cai and strube, 2010; <papid> W10-4305 </papid>raghunathan et al , 2010) <papid> D10-1048 </papid>supervised approaches to coreference resolution are often realized by pairwise classification of anaphor-antecedent candidates.</citsent>
<aftsection>
<nextsent>apopular and often reimplemented approach is presented in (soon et al , 2001).<papid> J01-4004 </papid></nextsent>
<nextsent>as recently discussed in (ng, 2010), <papid> P10-1142 </papid>the so called mention-pair model suffers from several design flaws which originate from the locally confined perspective of the model: ? generation of (transitively) redundant pairs, as the formation of coreference sets (coreference clustering) is done after pairwise classification ? thereby generation of skewed training sets which lead to classifiers biased towards negative classification ? no means to enforce global constraints such as transit ivity ? under specification of antecedent candidates these problems can be remedied by an incremental entity-mention model, where candidate pairs are evaluated on the basis of the emerging coreferencesets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI391">
<title id=" W11-1912.xml">an incremental model for coreference resolution with restrictive antecedent accessibility </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we do not apply machine learning, instead the system uses an empirically derived salience measure based on the dependency labels of thetrue mentions.
</prevsent>
<prevsent>our experiments seem to indicate that such system already is on par with machine learning approaches.
</prevsent>
</prevsection>
<citsent citstr=" N07-1011 ">
with notable exceptions (luo et al , 2004; <papid> P04-1018 </papid>yang et al ., 2004; <papid> C04-1033 </papid>daume iii and marcu, 2005; culotta et al ., 2007; <papid> N07-1011 </papid>klenner, 2007; rahman and ng, 2009; klenner and ailloud, 2009; cai and strube, 2010; <papid> W10-4305 </papid>raghunathan et al , 2010) <papid> D10-1048 </papid>supervised approaches to coreference resolution are often realized by pairwise classification of anaphor-antecedent candidates.</citsent>
<aftsection>
<nextsent>apopular and often reimplemented approach is presented in (soon et al , 2001).<papid> J01-4004 </papid></nextsent>
<nextsent>as recently discussed in (ng, 2010), <papid> P10-1142 </papid>the so called mention-pair model suffers from several design flaws which originate from the locally confined perspective of the model: ? generation of (transitively) redundant pairs, as the formation of coreference sets (coreference clustering) is done after pairwise classification ? thereby generation of skewed training sets which lead to classifiers biased towards negative classification ? no means to enforce global constraints such as transit ivity ? under specification of antecedent candidates these problems can be remedied by an incremental entity-mention model, where candidate pairs are evaluated on the basis of the emerging coreferencesets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI392">
<title id=" W11-1912.xml">an incremental model for coreference resolution with restrictive antecedent accessibility </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we do not apply machine learning, instead the system uses an empirically derived salience measure based on the dependency labels of thetrue mentions.
</prevsent>
<prevsent>our experiments seem to indicate that such system already is on par with machine learning approaches.
</prevsent>
</prevsection>
<citsent citstr=" W10-4305 ">
with notable exceptions (luo et al , 2004; <papid> P04-1018 </papid>yang et al ., 2004; <papid> C04-1033 </papid>daume iii and marcu, 2005; culotta et al ., 2007; <papid> N07-1011 </papid>klenner, 2007; rahman and ng, 2009; klenner and ailloud, 2009; cai and strube, 2010; <papid> W10-4305 </papid>raghunathan et al , 2010) <papid> D10-1048 </papid>supervised approaches to coreference resolution are often realized by pairwise classification of anaphor-antecedent candidates.</citsent>
<aftsection>
<nextsent>apopular and often reimplemented approach is presented in (soon et al , 2001).<papid> J01-4004 </papid></nextsent>
<nextsent>as recently discussed in (ng, 2010), <papid> P10-1142 </papid>the so called mention-pair model suffers from several design flaws which originate from the locally confined perspective of the model: ? generation of (transitively) redundant pairs, as the formation of coreference sets (coreference clustering) is done after pairwise classification ? thereby generation of skewed training sets which lead to classifiers biased towards negative classification ? no means to enforce global constraints such as transit ivity ? under specification of antecedent candidates these problems can be remedied by an incremental entity-mention model, where candidate pairs are evaluated on the basis of the emerging coreferencesets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI393">
<title id=" W11-1912.xml">an incremental model for coreference resolution with restrictive antecedent accessibility </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we do not apply machine learning, instead the system uses an empirically derived salience measure based on the dependency labels of thetrue mentions.
</prevsent>
<prevsent>our experiments seem to indicate that such system already is on par with machine learning approaches.
</prevsent>
</prevsection>
<citsent citstr=" D10-1048 ">
with notable exceptions (luo et al , 2004; <papid> P04-1018 </papid>yang et al ., 2004; <papid> C04-1033 </papid>daume iii and marcu, 2005; culotta et al ., 2007; <papid> N07-1011 </papid>klenner, 2007; rahman and ng, 2009; klenner and ailloud, 2009; cai and strube, 2010; <papid> W10-4305 </papid>raghunathan et al , 2010) <papid> D10-1048 </papid>supervised approaches to coreference resolution are often realized by pairwise classification of anaphor-antecedent candidates.</citsent>
<aftsection>
<nextsent>apopular and often reimplemented approach is presented in (soon et al , 2001).<papid> J01-4004 </papid></nextsent>
<nextsent>as recently discussed in (ng, 2010), <papid> P10-1142 </papid>the so called mention-pair model suffers from several design flaws which originate from the locally confined perspective of the model: ? generation of (transitively) redundant pairs, as the formation of coreference sets (coreference clustering) is done after pairwise classification ? thereby generation of skewed training sets which lead to classifiers biased towards negative classification ? no means to enforce global constraints such as transit ivity ? under specification of antecedent candidates these problems can be remedied by an incremental entity-mention model, where candidate pairs are evaluated on the basis of the emerging coreferencesets.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI394">
<title id=" W11-1912.xml">an incremental model for coreference resolution with restrictive antecedent accessibility </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiments seem to indicate that such system already is on par with machine learning approaches.
</prevsent>
<prevsent>with notable exceptions (luo et al , 2004; <papid> P04-1018 </papid>yang et al ., 2004; <papid> C04-1033 </papid>daume iii and marcu, 2005; culotta et al ., 2007; <papid> N07-1011 </papid>klenner, 2007; rahman and ng, 2009; klenner and ailloud, 2009; cai and strube, 2010; <papid> W10-4305 </papid>raghunathan et al , 2010) <papid> D10-1048 </papid>supervised approaches to coreference resolution are often realized by pairwise classification of anaphor-antecedent candidates.</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
apopular and often reimplemented approach is presented in (soon et al , 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>as recently discussed in (ng, 2010), <papid> P10-1142 </papid>the so called mention-pair model suffers from several design flaws which originate from the locally confined perspective of the model: ? generation of (transitively) redundant pairs, as the formation of coreference sets (coreference clustering) is done after pairwise classification ? thereby generation of skewed training sets which lead to classifiers biased towards negative classification ? no means to enforce global constraints such as transit ivity ? under specification of antecedent candidates these problems can be remedied by an incremental entity-mention model, where candidate pairs are evaluated on the basis of the emerging coreferencesets.</nextsent>
<nextsent>a clustering phase on top of the pairwise classifier no longer is needed and the number of candidate pairs is reduced, since from each coreference set (be it large or small) only one mention (the most representative one) needs to be compared to new anaphor candidate.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI395">
<title id=" W11-1912.xml">an incremental model for coreference resolution with restrictive antecedent accessibility </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with notable exceptions (luo et al , 2004; <papid> P04-1018 </papid>yang et al ., 2004; <papid> C04-1033 </papid>daume iii and marcu, 2005; culotta et al ., 2007; <papid> N07-1011 </papid>klenner, 2007; rahman and ng, 2009; klenner and ailloud, 2009; cai and strube, 2010; <papid> W10-4305 </papid>raghunathan et al , 2010) <papid> D10-1048 </papid>supervised approaches to coreference resolution are often realized by pairwise classification of anaphor-antecedent candidates.</prevsent>
<prevsent>apopular and often reimplemented approach is presented in (soon et al , 2001).<papid> J01-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" P10-1142 ">
as recently discussed in (ng, 2010), <papid> P10-1142 </papid>the so called mention-pair model suffers from several design flaws which originate from the locally confined perspective of the model: ? generation of (transitively) redundant pairs, as the formation of coreference sets (coreference clustering) is done after pairwise classification ? thereby generation of skewed training sets which lead to classifiers biased towards negative classification ? no means to enforce global constraints such as transit ivity ? under specification of antecedent candidates these problems can be remedied by an incremental entity-mention model, where candidate pairs are evaluated on the basis of the emerging coreferencesets.</citsent>
<aftsection>
<nextsent>a clustering phase on top of the pairwise classifier no longer is needed and the number of candidate pairs is reduced, since from each coreference set (be it large or small) only one mention (the most representative one) needs to be compared to new anaphor candidate.
</nextsent>
<nextsent>we form virtual prototype?
</nextsent>
<nextsent>that collects information from all the members ofeach coreference set in order to maximize repre sentativeness?.
</nextsent>
<nextsent>constraints such as transit ivity and morphological agreement can be assured by just asingle comparison.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI396">
<title id=" W11-1912.xml">an incremental model for coreference resolution with restrictive antecedent accessibility </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we designed our system to work purely with simple, yet empirically derived salience measure.
</prevsent>
<prevsent>it turned out that it outperformed (for german and english, using ceaf, b-cubed and blanc) the systems from the 2010s semeval shared task1 on coreference resolution in multiple languages?.
</prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
only with the more and more questioned (luo, 2005; <papid> H05-1004 </papid>cai and 1we have carried out post task evaluation with the data provided on the semeval web page.</citsent>
<aftsection>
<nextsent>81 strube, 2010) muc measure our system performed worse (at least for english).
</nextsent>
<nextsent>our system uses real preprocessing (i.e. dependency parser (schneider,2008)) and extracts markables (nouns, named entities and pronouns) from the chunks and based on pos tags delivered by the preprocessing pipeline.
</nextsent>
<nextsent>since we are using parser, we automatically take part in the open regular session.
</nextsent>
<nextsent>please note that the dependency labels are the only additional information being used by our system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI397">
<title id=" W11-1912.xml">an incremental model for coreference resolution with restrictive antecedent accessibility </title>
<section> our incremental model.  </section>
<citcontext>
<prevsection>
<prevsent>2.4 an empirically-based salience measure.
</prevsent>
<prevsent>since we look for simple and fast salience measure and do not apply machine learning in our baseline system, our measure is solely based on the grammatical functions (given by the dependency labels) of the true mentions.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
grammatical functions have 3if we do not apply this restriction too many false positives are produced.played major role in calculating salience, especially in rule based system such as (hobbs, 1976;lappin and leass, 1994; <papid> J94-4002 </papid>mitkov et al , 2002; siddharthan, 2003).</citsent>
<aftsection>
<nextsent>instead of manually specifying the weights for the dependency labels like (lappin and leass, 1994), <papid> J94-4002 </papid>we derived them empirically fromthe coreference conll 2011 gold standard (train ing data).</nextsent>
<nextsent>the salience of dependency label, d, is estimated by the number of true mentions in the gold standard that bear (i.e. are connected to their heads with d), divided by the total number of true mentions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI402">
<title id=" W11-2206.xml">unsupervised language independent name translation mining from wikipedia info boxes </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>for example, thepair of (yctc /????)
</prevsent>
<prevsent>was successfully mined although its english full name yeh-chiang technology corp.?
</prevsent>
</prevsection>
<citsent citstr=" H05-1055 ">
did not appear in the infoboxes.huang (2005) <papid> H05-1055 </papid>also pointed out that name translation benefited from origin-specific features.</citsent>
<aftsection>
<nextsent>in contrast, our approach is able to discover name pairs from any origins.
</nextsent>
<nextsent>for example, we discovered the person name pair (seishi yokomizo / ????)
</nextsent>
<nextsent>in which seishi yokomizo?
</nextsent>
<nextsent>was transliterated based on japanese pronunciation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI403">
<title id=" W11-2206.xml">unsupervised language independent name translation mining from wikipedia info boxes </title>
<section> comparison with previous methods and.  </section>
<citcontext>
<prevsection>
<prevsent>2.
</prevsent>
<prevsent>comparable corpora.
</prevsent>
</prevsection>
<citsent citstr=" W09-3107 ">
we implemented an information extraction driven approach as described in ji (2009) <papid> W09-3107 </papid>to extract name pairs from comparable corpora.this approach is based on extracting information graphs from each language and align names by graph traverse algorithm.</citsent>
<aftsection>
<nextsent>the corpora used for this approach were 2000 english documents and 2000 chinese documents from the gigaword corpora.
</nextsent>
<nextsent>3.
</nextsent>
<nextsent>using patterns for web mining.
</nextsent>
<nextsent>we constructed heuristic patterns such as parenthetical structure chinese name (english name)?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI404">
<title id=" W11-2206.xml">unsupervised language independent name translation mining from wikipedia info boxes </title>
<section> comparison with previous methods and.  </section>
<citcontext>
<prevsection>
<prevsent>using patterns for web mining.
</prevsent>
<prevsent>we constructed heuristic patterns such as parenthetical structure chinese name (english name)?
</prevsent>
</prevsection>
<citsent citstr=" P08-1113 ">
(lin et al, 2008) <papid> P08-1113 </papid>to extract name pairs from web data with mixed chinese and en glish.</citsent>
<aftsection>
<nextsent>we used about 1,000 web pages for this experiment.
</nextsent>
<nextsent>4.
</nextsent>
<nextsent>bilingual gazetteer.
</nextsent>
<nextsent>we exploited an ldc bilingual name dictionary (ldc2005t34) and japanese-english person name dictionary including 20126japanese names written in chinese characters (kurohashi et al, 1994).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI405">
<title id=" W11-2206.xml">unsupervised language independent name translation mining from wikipedia info boxes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>table 5 shows the number of correct and unique pairs mined pairs from each of the above approaches, as well as how these name mining methods can be augmented using the infobox name mining described in this paper.
</prevsent>
<prevsent>the names mined fromour approach greatly extend the total number of correct translations with only small number of conflicting name translations.
</prevsent>
</prevsection>
<citsent citstr=" N04-1036 ">
most of the previous name translation work combined supervised transliteration approaches with language model based re-scoring (al-onaizan and knight, 2002; huang et al, 2004; <papid> N04-1036 </papid>huang, 2005).<papid> H05-1055 </papid></citsent>
<aftsection>
<nextsent>our goal of addressing name translation for large number of languages is similar to the pan lingual lexical translation project (etzioni et al, 2007).
</nextsent>
<nextsent>some recent research used comparable corpora to re-scorename transliterations (sproat et al, 2006; klementiev and roth, 2006) or mine new word translations (udupa et al, 2009; <papid> E09-1091 </papid>ji, 2009; <papid> W09-3107 </papid>fung and yee, 1998; <papid> P98-1069 </papid>rapp, 1999; <papid> P99-1067 </papid>shao and ng, 2004; hassan et al, 2007).</nextsent>
<nextsent>however, most of these approaches needed large amount of seeds and suffered from information extraction errors, and thus relied on phonetic similarity or document similarity to re-score candidate name translation pairs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI407">
<title id=" W11-2206.xml">unsupervised language independent name translation mining from wikipedia info boxes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most of the previous name translation work combined supervised transliteration approaches with language model based re-scoring (al-onaizan and knight, 2002; huang et al, 2004; <papid> N04-1036 </papid>huang, 2005).<papid> H05-1055 </papid></prevsent>
<prevsent>our goal of addressing name translation for large number of languages is similar to the pan lingual lexical translation project (etzioni et al, 2007).</prevsent>
</prevsection>
<citsent citstr=" E09-1091 ">
some recent research used comparable corpora to re-scorename transliterations (sproat et al, 2006; klementiev and roth, 2006) or mine new word translations (udupa et al, 2009; <papid> E09-1091 </papid>ji, 2009; <papid> W09-3107 </papid>fung and yee, 1998; <papid> P98-1069 </papid>rapp, 1999; <papid> P99-1067 </papid>shao and ng, 2004; hassan et al, 2007).</citsent>
<aftsection>
<nextsent>however, most of these approaches needed large amount of seeds and suffered from information extraction errors, and thus relied on phonetic similarity or document similarity to re-score candidate name translation pairs.
</nextsent>
<nextsent>some recent cross-lingual information access work explored attribute mining from wikipediapages.
</nextsent>
<nextsent>for example, bouma et al (2009) <papid> W09-1604 </papid>aligned attributes in wikipedia info boxes based on cross-pagelinks.</nextsent>
<nextsent>navigli and ponzetto (2010) <papid> P10-1023 </papid>built multilingual semantic network by integrating the cross lingual wikipedia page links and wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI409">
<title id=" W11-2206.xml">unsupervised language independent name translation mining from wikipedia info boxes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most of the previous name translation work combined supervised transliteration approaches with language model based re-scoring (al-onaizan and knight, 2002; huang et al, 2004; <papid> N04-1036 </papid>huang, 2005).<papid> H05-1055 </papid></prevsent>
<prevsent>our goal of addressing name translation for large number of languages is similar to the pan lingual lexical translation project (etzioni et al, 2007).</prevsent>
</prevsection>
<citsent citstr=" P98-1069 ">
some recent research used comparable corpora to re-scorename transliterations (sproat et al, 2006; klementiev and roth, 2006) or mine new word translations (udupa et al, 2009; <papid> E09-1091 </papid>ji, 2009; <papid> W09-3107 </papid>fung and yee, 1998; <papid> P98-1069 </papid>rapp, 1999; <papid> P99-1067 </papid>shao and ng, 2004; hassan et al, 2007).</citsent>
<aftsection>
<nextsent>however, most of these approaches needed large amount of seeds and suffered from information extraction errors, and thus relied on phonetic similarity or document similarity to re-score candidate name translation pairs.
</nextsent>
<nextsent>some recent cross-lingual information access work explored attribute mining from wikipediapages.
</nextsent>
<nextsent>for example, bouma et al (2009) <papid> W09-1604 </papid>aligned attributes in wikipedia info boxes based on cross-pagelinks.</nextsent>
<nextsent>navigli and ponzetto (2010) <papid> P10-1023 </papid>built multilingual semantic network by integrating the cross lingual wikipedia page links and wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI410">
<title id=" W11-2206.xml">unsupervised language independent name translation mining from wikipedia info boxes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most of the previous name translation work combined supervised transliteration approaches with language model based re-scoring (al-onaizan and knight, 2002; huang et al, 2004; <papid> N04-1036 </papid>huang, 2005).<papid> H05-1055 </papid></prevsent>
<prevsent>our goal of addressing name translation for large number of languages is similar to the pan lingual lexical translation project (etzioni et al, 2007).</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
some recent research used comparable corpora to re-scorename transliterations (sproat et al, 2006; klementiev and roth, 2006) or mine new word translations (udupa et al, 2009; <papid> E09-1091 </papid>ji, 2009; <papid> W09-3107 </papid>fung and yee, 1998; <papid> P98-1069 </papid>rapp, 1999; <papid> P99-1067 </papid>shao and ng, 2004; hassan et al, 2007).</citsent>
<aftsection>
<nextsent>however, most of these approaches needed large amount of seeds and suffered from information extraction errors, and thus relied on phonetic similarity or document similarity to re-score candidate name translation pairs.
</nextsent>
<nextsent>some recent cross-lingual information access work explored attribute mining from wikipediapages.
</nextsent>
<nextsent>for example, bouma et al (2009) <papid> W09-1604 </papid>aligned attributes in wikipedia info boxes based on cross-pagelinks.</nextsent>
<nextsent>navigli and ponzetto (2010) <papid> P10-1023 </papid>built multilingual semantic network by integrating the cross lingual wikipedia page links and wordnet.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI411">
<title id=" W11-2206.xml">unsupervised language independent name translation mining from wikipedia info boxes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, most of these approaches needed large amount of seeds and suffered from information extraction errors, and thus relied on phonetic similarity or document similarity to re-score candidate name translation pairs.
</prevsent>
<prevsent>some recent cross-lingual information access work explored attribute mining from wikipediapages.
</prevsent>
</prevsection>
<citsent citstr=" W09-1604 ">
for example, bouma et al (2009) <papid> W09-1604 </papid>aligned attributes in wikipedia info boxes based on cross-pagelinks.</citsent>
<aftsection>
<nextsent>navigli and ponzetto (2010) <papid> P10-1023 </papid>built multilingual semantic network by integrating the cross lingual wikipedia page links and wordnet.</nextsent>
<nextsent>ji et 50 # name infobox mining method pairs # new # conflicting automatic (1) bitexts 2,451 8,673 78 (2) comparable corpora 288 8,780 13 (3) patterns for web mining 194 8799 0 manual (4) bilingual gazetteer 59,886 8,689 74(5) ace2007 training data 1,541 8,718 52 table 5: name pairs mined using previous methodsal.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI412">
<title id=" W11-2206.xml">unsupervised language independent name translation mining from wikipedia info boxes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>some recent cross-lingual information access work explored attribute mining from wikipediapages.
</prevsent>
<prevsent>for example, bouma et al (2009) <papid> W09-1604 </papid>aligned attributes in wikipedia info boxes based on cross-pagelinks.</prevsent>
</prevsection>
<citsent citstr=" P10-1023 ">
navigli and ponzetto (2010) <papid> P10-1023 </papid>built multilingual semantic network by integrating the cross lingual wikipedia page links and wordnet.</citsent>
<aftsection>
<nextsent>ji et 50 # name infobox mining method pairs # new # conflicting automatic (1) bitexts 2,451 8,673 78 (2) comparable corpora 288 8,780 13 (3) patterns for web mining 194 8799 0 manual (4) bilingual gazetteer 59,886 8,689 74(5) ace2007 training data 1,541 8,718 52 table 5: name pairs mined using previous methodsal.
</nextsent>
<nextsent>(2009) described various approaches to automatically mine name translation pairs from aligned phrases (e.g. cross-lingual wikipedia title links) or aligned sentences (bi-texts).
</nextsent>
<nextsent>g et al (2009)mined candidate words from wikipedia and validated translations based on parallecl corpora.
</nextsent>
<nextsent>some other work mined name translations from monolingual documents that include foreign language texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI414">
<title id=" W11-2206.xml">unsupervised language independent name translation mining from wikipedia info boxes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>g et al (2009)mined candidate words from wikipedia and validated translations based on parallecl corpora.
</prevsent>
<prevsent>some other work mined name translations from monolingual documents that include foreign language texts.
</prevsent>
</prevsection>
<citsent citstr=" D10-1042 ">
for example, lin et al (2008) <papid> P08-1113 </papid>described parenthesis translation mining method; you et al(2010) <papid> D10-1042 </papid>applied graph alignment algorithm to obtain name translation pairs based on co-occurrence statistics.</citsent>
<aftsection>
<nextsent>this kind of data does not commonly exist for low-density languages.
</nextsent>
<nextsent>sorg and cimiano (2008) discovered cross-lingual links between english and german using supervised classification based on support vector machines.
</nextsent>
<nextsent>adar et al (2009) aligned cross-lingual info boxes using boolean classifier based on self-supervised training with various linguistic features.
</nextsent>
<nextsent>in contrast, our approach described in this paper is entirely based on unsupervised learning without using any linguistic features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI415">
<title id=" W11-2206.xml">unsupervised language independent name translation mining from wikipedia info boxes </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>adar et al (2009) aligned cross-lingual info boxes using boolean classifier based on self-supervised training with various linguistic features.
</prevsent>
<prevsent>in contrast, our approach described in this paper is entirely based on unsupervised learning without using any linguistic features.
</prevsent>
</prevsection>
<citsent citstr=" P10-1087 ">
de melo and weikum (2010) <papid> P10-1087 </papid>described an approach to detect imprecise or wrong cross-lingual wikipedia links based on graph repair operations.</citsent>
<aftsection>
<nextsent>our algorithm can help recover those missing cross-lingual links.
</nextsent>
<nextsent>in this paper we described simple, cheap and effective self-boosting approach to mine name translation pairs from wikipedia infoboxes.
</nextsent>
<nextsent>this method is implemented incompletely unsupervised fashion, without using any manually created seed set, training data, transliteration or pre-knowledge about the language pair.
</nextsent>
<nextsent>the underlying motivation is that some certain expressions, such as numbers and dates, are written in language-independent forms among large majority of languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI416">
<title id=" W11-1917.xml">coreference resolution with loose transit ivity constraints </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>our system treats coreference resolution as an integer linear programming (ilp) problem.
</prevsent>
</prevsection>
<citsent citstr=" N07-1030 ">
extending denis and baldridge (2007) <papid> N07-1030 </papid>and finkel and manning (2008)<papid> P08-2012 </papid>s work, we exploit loose transit ivity constraints on coreference pairs.</citsent>
<aftsection>
<nextsent>instead of enforcing transit ivity closure constraints, which brings o(n3) complexity, we employ strategy to reduce the number of constraints without large performance decrease, i.e., eliminating coreference pairs with probability below threshold .
</nextsent>
<nextsent>experimental results show that it achieves better performance than pairwise classifiers.
</nextsent>
<nextsent>this paper describes our coreference resolution system participating in the close track of conll 2011 shared task (pradhan et al , 2011).<papid> W11-1901 </papid></nextsent>
<nextsent>the task aims to identify all mentions of entities and events and cluster them into equivalence classes in ontonotes corpus (pradhan et al , 2007a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI418">
<title id=" W11-1917.xml">coreference resolution with loose transit ivity constraints </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>our system treats coreference resolution as an integer linear programming (ilp) problem.
</prevsent>
</prevsection>
<citsent citstr=" P08-2012 ">
extending denis and baldridge (2007) <papid> N07-1030 </papid>and finkel and manning (2008)<papid> P08-2012 </papid>s work, we exploit loose transit ivity constraints on coreference pairs.</citsent>
<aftsection>
<nextsent>instead of enforcing transit ivity closure constraints, which brings o(n3) complexity, we employ strategy to reduce the number of constraints without large performance decrease, i.e., eliminating coreference pairs with probability below threshold .
</nextsent>
<nextsent>experimental results show that it achieves better performance than pairwise classifiers.
</nextsent>
<nextsent>this paper describes our coreference resolution system participating in the close track of conll 2011 shared task (pradhan et al , 2011).<papid> W11-1901 </papid></nextsent>
<nextsent>the task aims to identify all mentions of entities and events and cluster them into equivalence classes in ontonotes corpus (pradhan et al , 2007a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI419">
<title id=" W11-1917.xml">coreference resolution with loose transit ivity constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>instead of enforcing transit ivity closure constraints, which brings o(n3) complexity, we employ strategy to reduce the number of constraints without large performance decrease, i.e., eliminating coreference pairs with probability below threshold .
</prevsent>
<prevsent>experimental results show that it achieves better performance than pairwise classifiers.
</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
this paper describes our coreference resolution system participating in the close track of conll 2011 shared task (pradhan et al , 2011).<papid> W11-1901 </papid></citsent>
<aftsection>
<nextsent>the task aims to identify all mentions of entities and events and cluster them into equivalence classes in ontonotes corpus (pradhan et al , 2007a).
</nextsent>
<nextsent>during the last decade, several machine learning methods for coreference resolution have been developed, from local pairwise classifiers (soon et al , 2001) <papid> J01-4004 </papid>to global learning methods (luo et al , 2004; <papid> P04-1018 </papid>ng, 2005; denis and baldridge, 2007), <papid> N07-1030 </papid>from simple morphological,grammatical features to more liguistically rich features on syntactic structures and semantic relations (pradhan et al , 2007b; haghighi and klein, 2009).<papid> D09-1120 </papid></nextsent>
<nextsent>our system supports both local classifiers and global learning.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI420">
<title id=" W11-1917.xml">coreference resolution with loose transit ivity constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes our coreference resolution system participating in the close track of conll 2011 shared task (pradhan et al , 2011).<papid> W11-1901 </papid></prevsent>
<prevsent>the task aims to identify all mentions of entities and events and cluster them into equivalence classes in ontonotes corpus (pradhan et al , 2007a).</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
during the last decade, several machine learning methods for coreference resolution have been developed, from local pairwise classifiers (soon et al , 2001) <papid> J01-4004 </papid>to global learning methods (luo et al , 2004; <papid> P04-1018 </papid>ng, 2005; denis and baldridge, 2007), <papid> N07-1030 </papid>from simple morphological,grammatical features to more liguistically rich features on syntactic structures and semantic relations (pradhan et al , 2007b; haghighi and klein, 2009).<papid> D09-1120 </papid></citsent>
<aftsection>
<nextsent>our system supports both local classifiers and global learning.
</nextsent>
<nextsent>maximum entropy model is used for anaphoricity and coreference, because it assigns probability mass to mentions and coreference pairs directly.
</nextsent>
<nextsent>in global phase, instead of determining each coreference pair independently in greedy fashion, we employ an integer linear programming(ilp) formulation for this problem.
</nextsent>
<nextsent>extending (de nis and baldridge, 2007) <papid> N07-1030 </papid>and (finkel and manning,2008)<papid> P08-2012 </papid>s work, we introduce loose selection strategy for transit ivity constraints, attempting to overcome huge computation complexity brought by tran sit ivity closure constraints.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI421">
<title id=" W11-1917.xml">coreference resolution with loose transit ivity constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes our coreference resolution system participating in the close track of conll 2011 shared task (pradhan et al , 2011).<papid> W11-1901 </papid></prevsent>
<prevsent>the task aims to identify all mentions of entities and events and cluster them into equivalence classes in ontonotes corpus (pradhan et al , 2007a).</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
during the last decade, several machine learning methods for coreference resolution have been developed, from local pairwise classifiers (soon et al , 2001) <papid> J01-4004 </papid>to global learning methods (luo et al , 2004; <papid> P04-1018 </papid>ng, 2005; denis and baldridge, 2007), <papid> N07-1030 </papid>from simple morphological,grammatical features to more liguistically rich features on syntactic structures and semantic relations (pradhan et al , 2007b; haghighi and klein, 2009).<papid> D09-1120 </papid></citsent>
<aftsection>
<nextsent>our system supports both local classifiers and global learning.
</nextsent>
<nextsent>maximum entropy model is used for anaphoricity and coreference, because it assigns probability mass to mentions and coreference pairs directly.
</nextsent>
<nextsent>in global phase, instead of determining each coreference pair independently in greedy fashion, we employ an integer linear programming(ilp) formulation for this problem.
</nextsent>
<nextsent>extending (de nis and baldridge, 2007) <papid> N07-1030 </papid>and (finkel and manning,2008)<papid> P08-2012 </papid>s work, we introduce loose selection strategy for transit ivity constraints, attempting to overcome huge computation complexity brought by tran sit ivity closure constraints.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI423">
<title id=" W11-1917.xml">coreference resolution with loose transit ivity constraints </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes our coreference resolution system participating in the close track of conll 2011 shared task (pradhan et al , 2011).<papid> W11-1901 </papid></prevsent>
<prevsent>the task aims to identify all mentions of entities and events and cluster them into equivalence classes in ontonotes corpus (pradhan et al , 2007a).</prevsent>
</prevsection>
<citsent citstr=" D09-1120 ">
during the last decade, several machine learning methods for coreference resolution have been developed, from local pairwise classifiers (soon et al , 2001) <papid> J01-4004 </papid>to global learning methods (luo et al , 2004; <papid> P04-1018 </papid>ng, 2005; denis and baldridge, 2007), <papid> N07-1030 </papid>from simple morphological,grammatical features to more liguistically rich features on syntactic structures and semantic relations (pradhan et al , 2007b; haghighi and klein, 2009).<papid> D09-1120 </papid></citsent>
<aftsection>
<nextsent>our system supports both local classifiers and global learning.
</nextsent>
<nextsent>maximum entropy model is used for anaphoricity and coreference, because it assigns probability mass to mentions and coreference pairs directly.
</nextsent>
<nextsent>in global phase, instead of determining each coreference pair independently in greedy fashion, we employ an integer linear programming(ilp) formulation for this problem.
</nextsent>
<nextsent>extending (de nis and baldridge, 2007) <papid> N07-1030 </papid>and (finkel and manning,2008)<papid> P08-2012 </papid>s work, we introduce loose selection strategy for transit ivity constraints, attempting to overcome huge computation complexity brought by tran sit ivity closure constraints.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI426">
<title id=" W11-1917.xml">coreference resolution with loose transit ivity constraints </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>coreference resolution can benefit from accurate mention detection since it might eliminate the non-anaphoric mentions.
</prevsent>
<prevsent>we take mention detection as the first step, and then combine coreference classifier into one system.
</prevsent>
</prevsection>
<citsent citstr=" C02-1139 ">
total 70 candidate features are used for mention detection, including lexical, syntactic, semantic features (ng and cardie, 2002).<papid> C02-1139 </papid></citsent>
<aftsection>
<nextsent>features are selected according to the information gain ratio (han and kamber, 2006) gainration(a) = gain(a) splitinfo(a) the top 10 features with highest gain ratio are:string match, head word match, all upper case, pronoun, starting with article, number, following preposition, nesting in verb phrase, nesting in preposition, 107and starting with definite article.
</nextsent>
<nextsent>many string features that cannot be calculated by gain ratio method are also added.
</nextsent>
<nextsent>2.2 coreference determination.
</nextsent>
<nextsent>for coreference determination, we first build several baseline systems with different training instance generation methods and clustering algorithms.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI427">
<title id=" W11-1917.xml">coreference resolution with loose transit ivity constraints </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>detailed description can be found in ng (2005). training instance generation methods: mccarthy and lehner ts method, soon et al method, ng and cardies method.
</prevsent>
<prevsent> clustering algorithms: closest-first clustering,best-first clustering, and aggressive merge clustering.
</prevsent>
</prevsection>
<citsent citstr=" W02-1040 ">
overall 65 features are considered in our system.features are extracted from various linguistic information, including: distance: sentence distance, minimum edit distance (strube et al , 2002)  <papid> W02-1040 </papid>lexical: string match, partial match, head word match (daume?</citsent>
<aftsection>
<nextsent>iii and marcu, 2005) grammar: gender agreement, number agree ment(soon et al , 2001) <papid> J01-4004 </papid> syntactic: same head, path (yang et al , 2006)  <papid> P06-1006 </papid>semantic: semantic class agreement, predicate (ponzetto and strube, 2006; <papid> E06-2015 </papid>ng, 2007) combining different training instance generation methods and clustering algorithms, we get total 9 baseline systems.</nextsent>
<nextsent>for each system, we use greedy forward approach to select features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI429">
<title id=" W11-1917.xml">coreference resolution with loose transit ivity constraints </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent> clustering algorithms: closest-first clustering,best-first clustering, and aggressive merge clustering.
</prevsent>
<prevsent>overall 65 features are considered in our system.features are extracted from various linguistic information, including: distance: sentence distance, minimum edit distance (strube et al , 2002)  <papid> W02-1040 </papid>lexical: string match, partial match, head word match (daume?</prevsent>
</prevsection>
<citsent citstr=" P06-1006 ">
iii and marcu, 2005) grammar: gender agreement, number agree ment(soon et al , 2001) <papid> J01-4004 </papid> syntactic: same head, path (yang et al , 2006)  <papid> P06-1006 </papid>semantic: semantic class agreement, predicate (ponzetto and strube, 2006; <papid> E06-2015 </papid>ng, 2007) combining different training instance generation methods and clustering algorithms, we get total 9 baseline systems.</citsent>
<aftsection>
<nextsent>for each system, we use greedy forward approach to select features.
</nextsent>
<nextsent>starting from base feature set (soon et al , 2001), <papid> J01-4004 </papid>each feature out of the base set is added one by one according tothe performance change on development data.</nextsent>
<nextsent>finally, the procedure is ended until the performance is not improved.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI430">
<title id=" W11-1917.xml">coreference resolution with loose transit ivity constraints </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent> clustering algorithms: closest-first clustering,best-first clustering, and aggressive merge clustering.
</prevsent>
<prevsent>overall 65 features are considered in our system.features are extracted from various linguistic information, including: distance: sentence distance, minimum edit distance (strube et al , 2002)  <papid> W02-1040 </papid>lexical: string match, partial match, head word match (daume?</prevsent>
</prevsection>
<citsent citstr=" E06-2015 ">
iii and marcu, 2005) grammar: gender agreement, number agree ment(soon et al , 2001) <papid> J01-4004 </papid> syntactic: same head, path (yang et al , 2006)  <papid> P06-1006 </papid>semantic: semantic class agreement, predicate (ponzetto and strube, 2006; <papid> E06-2015 </papid>ng, 2007) combining different training instance generation methods and clustering algorithms, we get total 9 baseline systems.</citsent>
<aftsection>
<nextsent>for each system, we use greedy forward approach to select features.
</nextsent>
<nextsent>starting from base feature set (soon et al , 2001), <papid> J01-4004 </papid>each feature out of the base set is added one by one according tothe performance change on development data.</nextsent>
<nextsent>finally, the procedure is ended until the performance is not improved.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI436">
<title id=" W12-1803.xml">position paper towards standardized metrics and tools for spoken and multimodal dialog system evaluation </title>
<section> user-perceived quality prediction.  </section>
<citcontext>
<prevsection>
<prevsent>the diagnosis can be based on perceptual dimensions (effectiveness, efficiency, mental effort, etc.) or on technical characteristics (error rates, vocabulary coverage, etc.) or both.
</prevsent>
<prevsent>approaches in this direction are welcome and would significantly increase the usefulness of evaluation exercises for the system developers.
</prevsent>
</prevsection>
<citsent citstr=" P97-1035 ">
the first approach to predict user judgments on the basis of interaction metrics is the well-known paradise model (walker et al, 1997).<papid> P97-1035 </papid></citsent>
<aftsection>
<nextsent>the main challenge to date is the low generalizability of such models.
</nextsent>
<nextsent>the reason is that many of the underlying input parameters are interdependent, and that simple linear combination does not account for more complex relationships (e.g. there might be an optimum length for dialog, which cannot be easily described by purely linear model).
</nextsent>
<nextsent>however, other algorithms such as non-linear regression, classification trees or markov models, have not shown significantly improved performance (mller et al, 2008; engelbrecht, 2011).
</nextsent>
<nextsent>the latter are however adequate to describe the evolution of user opinion during the dialog, and thus might have principled advantages over models which use aggregated interaction performance metrics as an input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI437">
<title id=" W12-1805.xml">statistical user simulation for spoken dialogue systems what for which data which future </title>
<section> is user simulation useful?.  </section>
<citcontext>
<prevsection>
<prevsent>do we have to conclude that user simulation is useless?
</prevsent>
<prevsent>it is commonly admitted that learning parameters ofuser simulation models is hard because most of variables are hidden (user goal, mental states etc.) and tricky to annotate.
</prevsent>
</prevsection>
<citsent citstr=" N07-2038 ">
this is why current user simulators are trainable but rarely trained (pietquin, 2006; schatzmann et al, 2007).<papid> N07-2038 </papid></citsent>
<aftsection>
<nextsent>do we really need to train user simulation models?
</nextsent>
<nextsent>if so, which data and annotation schemes do we need?
</nextsent>
<nextsent>4 does simulation reach the target?.
</nextsent>
<nextsent>user simulation aims at reproducing plausible interactions but in contexts that were not seen in the data 9 collected to train the model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI438">
<title id=" W12-2005.xml">exploring grammatical error correction with notsocrummy machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one of the anonymous reviewers for this paper makes the point eloquently: given the frequent complexity of learner errors, less holistic, error-type specific approaches are often unable to 44disentangle compounded errors of style and grammar.?
</prevsent>
<prevsent>below we discuss related work that uses machine translation to address targeted errors and some recent work that also focused on whole-sentence error correction.
</prevsent>
</prevsection>
<citsent citstr=" P06-1032 ">
brockett et al (2006) <papid> P06-1032 </papid>use information about mass noun errors from chinese learner corpus to engineer parallel?</citsent>
<aftsection>
<nextsent>corpus with sentences containing mass noun errors on one side and their corrected counterparts on the other.
</nextsent>
<nextsent>with this parallel corpus,the authors use standard statistical machine translation (smt) framework to learn translation (correction) model which can then be applied to unseen sentences containing mass noun errors.
</nextsent>
<nextsent>this approach was able to correct almost 62% of the errors found in test set of 150 errors.
</nextsent>
<nextsent>in our approach, we do not treat correction directly as translation problem but instead relyon an mt system to round-trip translate an english sentence back to english.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI439">
<title id=" W12-2005.xml">exploring grammatical error correction with notsocrummy machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this approach was able to correct almost 62% of the errors found in test set of 150 errors.
</prevsent>
<prevsent>in our approach, we do not treat correction directly as translation problem but instead relyon an mt system to round-trip translate an english sentence back to english.
</prevsent>
</prevsection>
<citsent citstr=" P11-1094 ">
park and levy (2011) <papid> P11-1094 </papid>use noisy channel model to achieve whole-sentence grammar correction; they learn noise model from dataset of error ful sentences but do not relyon smt.</citsent>
<aftsection>
<nextsent>they show that the corrections produced by their model generally have higher n-gram overlap with human-authored reference corrections than the original error ful sentences.the previous work that is most directly relevant to our approach is that of hermet and desi lets (2009) who focused only on sentences containingpre-marked preposition errors and generated single round-trip translation for such sentences via single pivot language (french).
</nextsent>
<nextsent>they then simply posited this round-trip translation as the correc tion?
</nextsent>
<nextsent>for the original sentence.
</nextsent>
<nextsent>in their evaluation on sentences containing 133 unique preposition errors, their round-trip translation system was able to correct 66.4% of the cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI440">
<title id=" W12-2005.xml">exploring grammatical error correction with notsocrummy machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, we use novel alignment algorithm that allows us to combine different parts of different round-trip translations and explore whole new set of corrections that go beyond the translations themselves.
</prevsent>
<prevsent>finally, we do not restrict our analysis to any single type oferror.
</prevsent>
</prevsection>
<citsent citstr=" N07-1029 ">
in fact, our test sentences contain several different types of grammatical errors.outside of the literature on grammatical error detection, our combination approach is directly related to the research on machine translation system combination wherein translation hypotheses produced by different smt systems are combined to allow the extraction of better, combined hypothesis (ban galore et al, 2001; rosti et al, 2007; <papid> N07-1029 </papid>feng et al,2009).<papid> D09-1115 </papid></citsent>
<aftsection>
<nextsent>however, our combination approach is different in that all the round-trip translations are produced by single system but via different pivot languages.
</nextsent>
<nextsent>finally, the idea of combining multiple surface renderings with the same meaning has also been explored in paraphrase generation.
</nextsent>
<nextsent>pang et al (2003)<papid> N03-1024 </papid>propose an algorithm to align sets of parallel sentences driven entirely by the syntactic representations of the sentences.</nextsent>
<nextsent>the alignment algorithm outputs merged lattice from which lexical, phrasal, and sentential paraphrases could simply be read off.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI441">
<title id=" W12-2005.xml">exploring grammatical error correction with notsocrummy machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, we use novel alignment algorithm that allows us to combine different parts of different round-trip translations and explore whole new set of corrections that go beyond the translations themselves.
</prevsent>
<prevsent>finally, we do not restrict our analysis to any single type oferror.
</prevsent>
</prevsection>
<citsent citstr=" D09-1115 ">
in fact, our test sentences contain several different types of grammatical errors.outside of the literature on grammatical error detection, our combination approach is directly related to the research on machine translation system combination wherein translation hypotheses produced by different smt systems are combined to allow the extraction of better, combined hypothesis (ban galore et al, 2001; rosti et al, 2007; <papid> N07-1029 </papid>feng et al,2009).<papid> D09-1115 </papid></citsent>
<aftsection>
<nextsent>however, our combination approach is different in that all the round-trip translations are produced by single system but via different pivot languages.
</nextsent>
<nextsent>finally, the idea of combining multiple surface renderings with the same meaning has also been explored in paraphrase generation.
</nextsent>
<nextsent>pang et al (2003)<papid> N03-1024 </papid>propose an algorithm to align sets of parallel sentences driven entirely by the syntactic representations of the sentences.</nextsent>
<nextsent>the alignment algorithm outputs merged lattice from which lexical, phrasal, and sentential paraphrases could simply be read off.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI442">
<title id=" W12-2005.xml">exploring grammatical error correction with notsocrummy machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, our combination approach is different in that all the round-trip translations are produced by single system but via different pivot languages.
</prevsent>
<prevsent>finally, the idea of combining multiple surface renderings with the same meaning has also been explored in paraphrase generation.
</prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
pang et al (2003)<papid> N03-1024 </papid>propose an algorithm to align sets of parallel sentences driven entirely by the syntactic representations of the sentences.</citsent>
<aftsection>
<nextsent>the alignment algorithm outputs merged lattice from which lexical, phrasal, and sentential paraphrases could simply be read off.
</nextsent>
<nextsent>barzilay and lee (2003) <papid> N03-1003 </papid>cluster topically related sentences into slotted word lattices by using multiple sequence alignment for the purpose of downstream paraphrase generation from comparable cor pora.</nextsent>
<nextsent>more recently, zhao et al (2010) <papid> C10-1149 </papid>performround-trip translation of english sentences via different pivot languages and different off-the-shelf smt systems to generate candidate paraphrases.however, they do not combine the candidate paraphrases in any way.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI443">
<title id=" W12-2005.xml">exploring grammatical error correction with notsocrummy machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>pang et al (2003)<papid> N03-1024 </papid>propose an algorithm to align sets of parallel sentences driven entirely by the syntactic representations of the sentences.</prevsent>
<prevsent>the alignment algorithm outputs merged lattice from which lexical, phrasal, and sentential paraphrases could simply be read off.</prevsent>
</prevsection>
<citsent citstr=" N03-1003 ">
barzilay and lee (2003) <papid> N03-1003 </papid>cluster topically related sentences into slotted word lattices by using multiple sequence alignment for the purpose of downstream paraphrase generation from comparable cor pora.</citsent>
<aftsection>
<nextsent>more recently, zhao et al (2010) <papid> C10-1149 </papid>performround-trip translation of english sentences via different pivot languages and different off-the-shelf smt systems to generate candidate paraphrases.however, they do not combine the candidate paraphrases in any way.</nextsent>
<nextsent>a detailed survey of paraphrase generation techniques can be found in (androut sopoulos and malakasiotis, 2010) and (madnani and dorr, 2010).<papid> J10-3003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI444">
<title id=" W12-2005.xml">exploring grammatical error correction with notsocrummy machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the alignment algorithm outputs merged lattice from which lexical, phrasal, and sentential paraphrases could simply be read off.
</prevsent>
<prevsent>barzilay and lee (2003) <papid> N03-1003 </papid>cluster topically related sentences into slotted word lattices by using multiple sequence alignment for the purpose of downstream paraphrase generation from comparable cor pora.</prevsent>
</prevsection>
<citsent citstr=" C10-1149 ">
more recently, zhao et al (2010) <papid> C10-1149 </papid>performround-trip translation of english sentences via different pivot languages and different off-the-shelf smt systems to generate candidate paraphrases.however, they do not combine the candidate paraphrases in any way.</citsent>
<aftsection>
<nextsent>a detailed survey of paraphrase generation techniques can be found in (androut sopoulos and malakasiotis, 2010) and (madnani and dorr, 2010).<papid> J10-3003 </papid></nextsent>
<nextsent>the basic idea underlying our error correction technique is quite simple: if we can automatically generate alternative surface renderings of the meaning expressed in the original sentence and then pick the one that is most fluent, we are likely to have pickeda version of the sentence in which the original grammatical errors have been fixed.in this paper, we propose generating such alternative formulations using statistical machine trans lation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI445">
<title id=" W12-2005.xml">exploring grammatical error correction with notsocrummy machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>barzilay and lee (2003) <papid> N03-1003 </papid>cluster topically related sentences into slotted word lattices by using multiple sequence alignment for the purpose of downstream paraphrase generation from comparable cor pora.</prevsent>
<prevsent>more recently, zhao et al (2010) <papid> C10-1149 </papid>performround-trip translation of english sentences via different pivot languages and different off-the-shelf smt systems to generate candidate paraphrases.however, they do not combine the candidate paraphrases in any way.</prevsent>
</prevsection>
<citsent citstr=" J10-3003 ">
a detailed survey of paraphrase generation techniques can be found in (androut sopoulos and malakasiotis, 2010) and (madnani and dorr, 2010).<papid> J10-3003 </papid></citsent>
<aftsection>
<nextsent>the basic idea underlying our error correction technique is quite simple: if we can automatically generate alternative surface renderings of the meaning expressed in the original sentence and then pick the one that is most fluent, we are likely to have pickeda version of the sentence in which the original grammatical errors have been fixed.in this paper, we propose generating such alternative formulations using statistical machine translation.
</nextsent>
<nextsent>for example, we take the original sentence eand translate it to chinese using the google trans 45 original both experience and books are very important about living.
</nextsent>
<nextsent>swedish both experience and books are very important in live.
</nextsent>
<nextsent>italian both books are very important experience and life.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI446">
<title id=" W12-2005.xml">exploring grammatical error correction with notsocrummy machine translation </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>we posit that better approach will be to combine the evidence of correction produced by each independent translation model and increase the likelihood of producing final whole-sentence correction.
</prevsent>
<prevsent>additionally, by engineering such combination, we increase the likelihood that the final correction will preserve the meaning of the original sentence.
</prevsent>
</prevsection>
<citsent citstr=" W09-0441 ">
in order to combine the round-trip translations, we developed heuristic alignment algorithm that uses the terp machine translation metric (snoveret al, 2009).<papid> W09-0441 </papid></citsent>
<aftsection>
<nextsent>the terp metric takes pair of sentences and computes the least number of edit operations that can be employed to turn one sentence into the other.2 as by-product of computing the edit sequence, terp produces an alignment between the two sentences where each alignment link is defined by an edit operation.
</nextsent>
<nextsent>figure 2 shows an example ofthe alignment produced by terp between the original sentence from figure 1 and its russian round trip translation.
</nextsent>
<nextsent>note that terp also allows shifting words and phrases in the second sentence in orderto obtain smaller edit cost (as indicated by the asterisk next to the word book which has shifted fromits original position in the russian round-trip trans lation).our algorithm starts by treating the original sentence as the backbone of lattice.
</nextsent>
<nextsent>first, it cre2edit operations in terp include matches, substitutions, insertion, deletions, paraphrase, synonymy and stemming.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI447">
<title id=" W12-0801.xml">preservation of recognizability for weighted linear extended topdown tree transducers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is the weighted fores tin which each tree has weight 1] is not recogniz ablein this contribution, we thus investigate preservation of recognizability (under forward application) for linear extended top-down tree transducers with regular look-ahead (engelfriet, 1977), which are equivalent to linear weighted extended tree transducers by fulop et al (2011).
</prevsent>
<prevsent>we show that they always preserve recognizability, thus confirming the implicit hypothesis of fulop et al (2011).
</prevsent>
</prevsection>
<citsent citstr=" J08-3004 ">
the essential tool for our construction is the inside weight (lari and young, 1990; graehl et al, 2008) <papid> J08-3004 </papid>of the states of the weighted tree grammar (alexandrakis and bozapalidis, 1987) representing the parses.</citsent>
<aftsection>
<nextsent>the inside weight of state is the sum of all weights of trees accepted in this state.
</nextsent>
<nextsent>in our main construction (see section 5) we first compose the input weighted tree grammar with the transducer (input restriction).
</nextsent>
<nextsent>this is particularly simple since we just abuse the look-ahead of the initial rules.
</nextsent>
<nextsent>in second step, we normalize the obtained transducer, which yields the standard product construction typically used for input restriction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI448">
<title id=" W12-0801.xml">preservation of recognizability for weighted linear extended topdown tree transducers </title>
<section> weighted tree grammars.  </section>
<citcontext>
<prevsection>
<prevsent>in this section, we will recall weighted tree grammars (alexandrakis and bozapalidis, 1987)[see (fulop and vogler, 2009) for modern treatment and complete historical account].
</prevsent>
<prevsent>in general, weighted tree grammars (wtgs) offer an efficient representation of weighted forests, which are sets of trees such that each individual tree is equipped with weight.
</prevsent>
</prevsection>
<citsent citstr=" P08-1023 ">
the representation is even more efficient than packed forests (mi et al., 2008) <papid> P08-1023 </papid>and moreover can represent an infinite number of weighted trees.</citsent>
<aftsection>
<nextsent>to avoid confusion between the nonterminals of parser, which produces the forests considered here, and our wtgs, we will refer to the nonterminals of our wtg as states.
</nextsent>
<nextsent>definition 1.
</nextsent>
<nextsent>a weighted tree grammar (wtg) is system (q,?, q0, ) where ? is finite set of states (nonterminals), ? ?
</nextsent>
<nextsent>is the alphabet of symbols, ? q0 ? is the starting state, and ? is finite set of productions a ? t, where ? q, ? a, and ? t?(q).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI450">
<title id=" W12-0801.xml">preservation of recognizability for weighted linear extended topdown tree transducers </title>
<section> computation of inside weights.  </section>
<citcontext>
<prevsection>
<prevsent>6.2 numerical approximation.
</prevsent>
<prevsent>next, we show how to obtain numerical approximation of the inside weights (up to any desired precision) in the probability semi ring, which is the most important of all semi rings discussed here.
</prevsent>
</prevsection>
<citsent citstr=" J95-2002 ">
a similar approach was used by stolcke (1995) <papid> J95-2002 </papid>for context-free grammars.</citsent>
<aftsection>
<nextsent>to keep the presentation simple, let us suppose thatg = (q,?, q0, ) is in normal form (see theorem 5).
</nextsent>
<nextsent>the method works just as well in the general case.
</nextsent>
<nextsent>we first observe an important property of the inside weights.
</nextsent>
<nextsent>for every state ? ing(q) = ? a ??(q1,...,qn)p ? ing(q1) ? .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI451">
<title id=" W11-2112.xml">tine a metric to assess mt adequacy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a number of metrics have been proposed in the last two decades, mostly measuring some form of matching between the mt output (hypothesis) and one or more human (reference) translations.
</prevsent>
<prevsent>however, most of these metrics focus on fluency aspects, as opposed to adequacy.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
therefore, measuring whether the meaning of the hypothesis and reference translation are the same or similar is still an under studied problem.the most commonly used metrics, bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and alike, perform simple exact matching of n-grams between hypothesis and reference translations.</citsent>
<aftsection>
<nextsent>such simple matching procedure has well known limitations, including that the matching of non-content words counts as much as the matching of content words, that variations of words with the same meaning are disregarded, and that perfect matching can happen even if the orderof sequences of n-grams in the hypothesis and reference translation are very different, changing completely the meaning of the translation.
</nextsent>
<nextsent>a number of other metrics have been proposed to address these limitations, for example, by allowing for the matching of synonyms or paraphrases of content words, such as in meteor (denkowski and lavie, 2010).<papid> W10-1751 </papid></nextsent>
<nextsent>other attempts have been madeto capture whether the reference translation and hypothesis translations share the same meaning using shallow semantics, i.e., semantic role labeling (gimenez and marquez, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI452">
<title id=" W11-2112.xml">tine a metric to assess mt adequacy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, measuring whether the meaning of the hypothesis and reference translation are the same or similar is still an under studied problem.the most commonly used metrics, bleu (pap ineni et al, 2002) <papid> P02-1040 </papid>and alike, perform simple exact matching of n-grams between hypothesis and reference translations.</prevsent>
<prevsent>such simple matching procedure has well known limitations, including that the matching of non-content words counts as much as the matching of content words, that variations of words with the same meaning are disregarded, and that perfect matching can happen even if the orderof sequences of n-grams in the hypothesis and reference translation are very different, changing completely the meaning of the translation.</prevsent>
</prevsection>
<citsent citstr=" W10-1751 ">
a number of other metrics have been proposed to address these limitations, for example, by allowing for the matching of synonyms or paraphrases of content words, such as in meteor (denkowski and lavie, 2010).<papid> W10-1751 </papid></citsent>
<aftsection>
<nextsent>other attempts have been madeto capture whether the reference translation and hypothesis translations share the same meaning using shallow semantics, i.e., semantic role labeling (gimenez and marquez, 2007).
</nextsent>
<nextsent>however, these are limited to the exact matching of semantic roles and their fillers.we propose tine, new metric that complements lexical matching with shallow semantic component to better address adequacy.
</nextsent>
<nextsent>the main contribution of such metric is to provide more flexible way of measuring the overlap between shallow semantic representations that considers both the semantic structure of the sentence and the content of the semantic elements.
</nextsent>
<nextsent>the metric uses srls such as in (gimenez and marquez, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI454">
<title id=" W11-2112.xml">tine a metric to assess mt adequacy </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, it analyses the content of predicates and arguments seeking for either exact or similar?
</prevsent>
<prevsent>matches.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
the 116 inexact matching is based on the use of ontologies such as verbnet (schuler, 2006) and distributional semantics similarity metrics, such as dekang lins thesaurus (lin, 1998) . <papid> P98-2127 </papid>in the remainder of this paper we describe some related work (section 2), present our metric - tine- (section 3) and its performance compared to previous work (section 4) as well as some further im provements.</citsent>
<aftsection>
<nextsent>we then provide an analysis of these results and discuss the limitations of the metric (sec tion 5) and present conclusions and future work (section 6).
</nextsent>
<nextsent>a few metrics have been proposed in recent yearsto address the problem of measuring whether hypothesis and reference translation share the same meaning.
</nextsent>
<nextsent>the most well-know metric is probably meteor (banerjee and lavie, 2005; <papid> W05-0909 </papid>denkowski and lavie, 2010).<papid> W10-1751 </papid></nextsent>
<nextsent>meteor is based on generalized concept of unigram matching between the hypothesis and the reference translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI455">
<title id=" W11-2112.xml">tine a metric to assess mt adequacy </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we then provide an analysis of these results and discuss the limitations of the metric (sec tion 5) and present conclusions and future work (section 6).
</prevsent>
<prevsent>a few metrics have been proposed in recent yearsto address the problem of measuring whether hypothesis and reference translation share the same meaning.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
the most well-know metric is probably meteor (banerjee and lavie, 2005; <papid> W05-0909 </papid>denkowski and lavie, 2010).<papid> W10-1751 </papid></citsent>
<aftsection>
<nextsent>meteor is based on generalized concept of unigram matching between the hypothesis and the reference translation.
</nextsent>
<nextsent>alignments are based on exact, stem, synonym, and paraphrase matches between words and phrases.
</nextsent>
<nextsent>however, the structure of the sentences is not considered.
</nextsent>
<nextsent>wong and kit (2010) <papid> W10-1755 </papid>measure word choice and word order by the matching of words based on surface forms, stems, senses and semantic similar ity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI457">
<title id=" W11-2112.xml">tine a metric to assess mt adequacy </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>alignments are based on exact, stem, synonym, and paraphrase matches between words and phrases.
</prevsent>
<prevsent>however, the structure of the sentences is not considered.
</prevsent>
</prevsection>
<citsent citstr=" W10-1755 ">
wong and kit (2010) <papid> W10-1755 </papid>measure word choice and word order by the matching of words based on surface forms, stems, senses and semantic similar ity.</citsent>
<aftsection>
<nextsent>the informative ness of matched and unmatched words is also weighted.liu et al (2010) <papid> W10-1754 </papid>propose to match bags of unigrams, bigrams and trigrams considering both recall and precision and f-measure giving more importance to recall, but also using wordnet synonyms.tratz and hovy (2008) use transformations in order to match short syntactic units defined as basic elements (be).</nextsent>
<nextsent>the be are minimal-length syntactically well defined units.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI458">
<title id=" W11-2112.xml">tine a metric to assess mt adequacy </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, the structure of the sentences is not considered.
</prevsent>
<prevsent>wong and kit (2010) <papid> W10-1755 </papid>measure word choice and word order by the matching of words based on surface forms, stems, senses and semantic similar ity.</prevsent>
</prevsection>
<citsent citstr=" W10-1754 ">
the informative ness of matched and unmatched words is also weighted.liu et al (2010) <papid> W10-1754 </papid>propose to match bags of unigrams, bigrams and trigrams considering both recall and precision and f-measure giving more importance to recall, but also using wordnet synonyms.tratz and hovy (2008) use transformations in order to match short syntactic units defined as basic elements (be).</citsent>
<aftsection>
<nextsent>the be are minimal-length syntactically well defined units.
</nextsent>
<nextsent>for example,nouns, verbs, adjectives and adverbs can be considered be-unigrams, while be-bigram could be formed from syntactic relation (e.g. subject+verb,verb+object).
</nextsent>
<nextsent>bes can be lexically different, but semantically similar.pado?
</nextsent>
<nextsent>et al (2009) uses textual entailment features extracted from the stand ford entailment recognizer (maccartney et al, 2006).<papid> N06-1006 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI459">
<title id=" W11-2112.xml">tine a metric to assess mt adequacy </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for example,nouns, verbs, adjectives and adverbs can be considered be-unigrams, while be-bigram could be formed from syntactic relation (e.g. subject+verb,verb+object).
</prevsent>
<prevsent>bes can be lexically different, but semantically similar.pado?
</prevsent>
</prevsection>
<citsent citstr=" N06-1006 ">
et al (2009) uses textual entailment features extracted from the stand ford entailment recognizer (maccartney et al, 2006).<papid> N06-1006 </papid></citsent>
<aftsection>
<nextsent>the textual entailment recognizer computes matching and mis matching features over dependency parses.
</nextsent>
<nextsent>the metric then predicts the mt quality with regression model.
</nextsent>
<nextsent>the alignment is improved using ontologies.
</nextsent>
<nextsent>he et al (2010) <papid> W10-1753 </papid>measure the similarity between hypothesis and reference translation in terms ofthe lexical functional grammar (lfg) represen tation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI460">
<title id=" W11-2112.xml">tine a metric to assess mt adequacy </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the metric then predicts the mt quality with regression model.
</prevsent>
<prevsent>the alignment is improved using ontologies.
</prevsent>
</prevsection>
<citsent citstr=" W10-1753 ">
he et al (2010) <papid> W10-1753 </papid>measure the similarity between hypothesis and reference translation in terms ofthe lexical functional grammar (lfg) represen tation.</citsent>
<aftsection>
<nextsent>the representation uses dependency graphs to generate unordered sets of dependency triples.
</nextsent>
<nextsent>calculating precision, recall, and f-score on the sets of triples corresponding to the hypothesis and reference segments allows measuring similarity at the lexical and syntactic levels.
</nextsent>
<nextsent>the measure also matches wordnet synonyms.
</nextsent>
<nextsent>the closest related metric to the one proposed in this paper is that by gimenez and marquez (2007) and gimenez et al (2010), which also uses shallow semantic representations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI463">
<title id=" W11-2112.xml">tine a metric to assess mt adequacy </title>
<section> metric description.  </section>
<citcontext>
<prevsection>
<prevsent>that is specially interesting when core arguments get merged with modifiers due to bad semantic role labeling (e.g. [a0 i] [t bought] [a1 something to eatyesterday] instead of [a0 i] [t bought] [a1 some thing to eat] [am-tmp yesterday]).
</prevsent>
<prevsent>a(h,r) = ? vv verb score(hv, rv) |vr| (3) in the adequacy component, is the set of verbs aligned between and r, and |vr| is the number of verbs in r. hereafter the indexes and stand for hypothesis and reference translations, respectively.
</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
verbs are aligned using verbnet (schuler, 2006) and verb ocean (chklovski and pantel, 2004).<papid> W04-3205 </papid></citsent>
<aftsection>
<nextsent>a verb inthe hypothesis vh is aligned to verb in the reference vr if they are related according to the following heuristics: (i) the pair of verbs share at least one class in verbnet; or (ii) the pair of verbs holds relation in verbocean.for example, in verbnet the verbs spook and terrify share the same class amuse-31.1, and in verbo cean the verb dress is related to the verb wear.
</nextsent>
<nextsent>verb score(hv, rv) = ? aarat arg score(ha, ra) |ar| (4) the similarity between the arguments of verb pair (vh, vr) in is measured as defined in equation (4), where ah and at are the sets of labeled arguments of the hypothesis and the reference respectively and |ar| is the number of arguments of the verb in r. in other words, we only measure the similarity of arguments in pair of sentences that are annotated with the same role.
</nextsent>
<nextsent>this ensures that the structure of the sentence is taken into account (for example, an argument in the role of agent would notbe compared against an argument in role of experi encer).
</nextsent>
<nextsent>additionally, by restricting the comparison to arguments of given verb pair, we avoid argument confusion in sentences with multiple verbs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI471">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, context information is also investigated to add additional relevant information to the summary.
</prevsent>
<prevsent>meetings are an important way for information sharing and collaboration, where people can discuss problems and make concrete decisions.
</prevsent>
</prevsection>
<citsent citstr=" J02-4003 ">
not surprisingly, there is an increasing interest in developing methods for extractive summarization for meetings and conversations (zechner, 2002; <papid> J02-4003 </papid>maskey and hirschberg, 2005; galley, 2006; <papid> W06-1643 </papid>lin and chen, 2010; <papid> P10-1009 </papid>murray et al , 2010<papid> W10-4211 </papid>a).</citsent>
<aftsection>
<nextsent>carenini et al  (2011) describe the specific need for focused summaries of meetings, i.e., summaries of particular aspect of meeting rather than of the meeting as whole.
</nextsent>
<nextsent>for example, the decisions made, the action items that emerged and the problems arised are all important outcomes of meetings.
</nextsent>
<nextsent>in particular, decision summaries would allow participants to review decisions from previous meetings and understand the related topics quickly, which facilitates preparation for the upcoming meetings.
</nextsent>
<nextsent>a:we decided our target group is the focus on who can afford it , (1) b:uh im kinda liking the idea of latex , if if spongy is the in thing .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI472">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, context information is also investigated to add additional relevant information to the summary.
</prevsent>
<prevsent>meetings are an important way for information sharing and collaboration, where people can discuss problems and make concrete decisions.
</prevsent>
</prevsection>
<citsent citstr=" W06-1643 ">
not surprisingly, there is an increasing interest in developing methods for extractive summarization for meetings and conversations (zechner, 2002; <papid> J02-4003 </papid>maskey and hirschberg, 2005; galley, 2006; <papid> W06-1643 </papid>lin and chen, 2010; <papid> P10-1009 </papid>murray et al , 2010<papid> W10-4211 </papid>a).</citsent>
<aftsection>
<nextsent>carenini et al  (2011) describe the specific need for focused summaries of meetings, i.e., summaries of particular aspect of meeting rather than of the meeting as whole.
</nextsent>
<nextsent>for example, the decisions made, the action items that emerged and the problems arised are all important outcomes of meetings.
</nextsent>
<nextsent>in particular, decision summaries would allow participants to review decisions from previous meetings and understand the related topics quickly, which facilitates preparation for the upcoming meetings.
</nextsent>
<nextsent>a:we decided our target group is the focus on who can afford it , (1) b:uh im kinda liking the idea of latex , if if spongy is the in thing .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI474">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, context information is also investigated to add additional relevant information to the summary.
</prevsent>
<prevsent>meetings are an important way for information sharing and collaboration, where people can discuss problems and make concrete decisions.
</prevsent>
</prevsection>
<citsent citstr=" P10-1009 ">
not surprisingly, there is an increasing interest in developing methods for extractive summarization for meetings and conversations (zechner, 2002; <papid> J02-4003 </papid>maskey and hirschberg, 2005; galley, 2006; <papid> W06-1643 </papid>lin and chen, 2010; <papid> P10-1009 </papid>murray et al , 2010<papid> W10-4211 </papid>a).</citsent>
<aftsection>
<nextsent>carenini et al  (2011) describe the specific need for focused summaries of meetings, i.e., summaries of particular aspect of meeting rather than of the meeting as whole.
</nextsent>
<nextsent>for example, the decisions made, the action items that emerged and the problems arised are all important outcomes of meetings.
</nextsent>
<nextsent>in particular, decision summaries would allow participants to review decisions from previous meetings and understand the related topics quickly, which facilitates preparation for the upcoming meetings.
</nextsent>
<nextsent>a:we decided our target group is the focus on who can afford it , (1) b:uh im kinda liking the idea of latex , if if spongy is the in thing .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI475">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, context information is also investigated to add additional relevant information to the summary.
</prevsent>
<prevsent>meetings are an important way for information sharing and collaboration, where people can discuss problems and make concrete decisions.
</prevsent>
</prevsection>
<citsent citstr=" W10-4211 ">
not surprisingly, there is an increasing interest in developing methods for extractive summarization for meetings and conversations (zechner, 2002; <papid> J02-4003 </papid>maskey and hirschberg, 2005; galley, 2006; <papid> W06-1643 </papid>lin and chen, 2010; <papid> P10-1009 </papid>murray et al , 2010<papid> W10-4211 </papid>a).</citsent>
<aftsection>
<nextsent>carenini et al  (2011) describe the specific need for focused summaries of meetings, i.e., summaries of particular aspect of meeting rather than of the meeting as whole.
</nextsent>
<nextsent>for example, the decisions made, the action items that emerged and the problems arised are all important outcomes of meetings.
</nextsent>
<nextsent>in particular, decision summaries would allow participants to review decisions from previous meetings and understand the related topics quickly, which facilitates preparation for the upcoming meetings.
</nextsent>
<nextsent>a:we decided our target group is the focus on who can afford it , (1) b:uh im kinda liking the idea of latex , if if spongy is the in thing .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI479">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>consequently another challenge would be to add complementary knowledge when the drdas cannot provide complete information.
</prevsent>
<prevsent>therefore, we need summarization approach that is tolerant of dialogue phenomena, can determine the key semantic content and is easily transferable between domains.
</prevsent>
</prevsection>
<citsent citstr=" N09-1041 ">
recently, topic modeling approaches have been investigated and achievedstate-of-the-art results in multi-document summarization (haghighi and vanderwende, 2009; <papid> N09-1041 </papid>celiky 1these drdas are annotated in the ami corpus and usually contain the decision content.</citsent>
<aftsection>
<nextsent>they are similar, but not completely equivalent, to the decision dialogue acts (ddas) of bui et al  (2009), <papid> W09-3934 </papid>fernandez et al  (2008), frampton et al  (2009).<papid> D09-1118 </papid>ilmaz and hakkani-tur, 2010).</nextsent>
<nextsent>thus, topic models appear to be better ref for document similarity w.r.t. semantic concepts than simple literal word matching.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI481">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, we need summarization approach that is tolerant of dialogue phenomena, can determine the key semantic content and is easily transferable between domains.
</prevsent>
<prevsent>recently, topic modeling approaches have been investigated and achievedstate-of-the-art results in multi-document summarization (haghighi and vanderwende, 2009; <papid> N09-1041 </papid>celiky 1these drdas are annotated in the ami corpus and usually contain the decision content.</prevsent>
</prevsection>
<citsent citstr=" W09-3934 ">
they are similar, but not completely equivalent, to the decision dialogue acts (ddas) of bui et al  (2009), <papid> W09-3934 </papid>fernandez et al  (2008), frampton et al  (2009).<papid> D09-1118 </papid>ilmaz and hakkani-tur, 2010).</citsent>
<aftsection>
<nextsent>thus, topic models appear to be better ref for document similarity w.r.t. semantic concepts than simple literal word matching.
</nextsent>
<nextsent>however, very little work has investigated its role in spoken document summarization (chen and chen, 2008; hazen, 2011), and much less conducted comparisons among topic modeling approaches for focused summarization in meetings.in contrast to previous work, we study theun supervised token-level decision summarization in meetings by identifying concise set of key wordsor phrases, which can either be output as compact summary or be starting point to generate ab str active summaries.
</nextsent>
<nextsent>this paper addresses problems mentioned above and make contributions as follows:?
</nextsent>
<nextsent>as step towards creating the abs tractive summaries that people prefer when dealing with spoken language (murray et al , 2010<papid> W10-4211 </papid>b), we propose token-level rather than sentence-level framework for identifying components of the summary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI482">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>therefore, we need summarization approach that is tolerant of dialogue phenomena, can determine the key semantic content and is easily transferable between domains.
</prevsent>
<prevsent>recently, topic modeling approaches have been investigated and achievedstate-of-the-art results in multi-document summarization (haghighi and vanderwende, 2009; <papid> N09-1041 </papid>celiky 1these drdas are annotated in the ami corpus and usually contain the decision content.</prevsent>
</prevsection>
<citsent citstr=" D09-1118 ">
they are similar, but not completely equivalent, to the decision dialogue acts (ddas) of bui et al  (2009), <papid> W09-3934 </papid>fernandez et al  (2008), frampton et al  (2009).<papid> D09-1118 </papid>ilmaz and hakkani-tur, 2010).</citsent>
<aftsection>
<nextsent>thus, topic models appear to be better ref for document similarity w.r.t. semantic concepts than simple literal word matching.
</nextsent>
<nextsent>however, very little work has investigated its role in spoken document summarization (chen and chen, 2008; hazen, 2011), and much less conducted comparisons among topic modeling approaches for focused summarization in meetings.in contrast to previous work, we study theun supervised token-level decision summarization in meetings by identifying concise set of key wordsor phrases, which can either be output as compact summary or be starting point to generate ab str active summaries.
</nextsent>
<nextsent>this paper addresses problems mentioned above and make contributions as follows:?
</nextsent>
<nextsent>as step towards creating the abs tractive summaries that people prefer when dealing with spoken language (murray et al , 2010<papid> W10-4211 </papid>b), we propose token-level rather than sentence-level framework for identifying components of the summary.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI490">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a primary goal for most speech summarization system sis to account for the special characteristics of dialogue.
</prevsent>
<prevsent>early work in this area investigated supervised learning methods, including maximum entropy, conditional random fields (crfs), and support vector machines (svms) (buist et al , 2004; galley, 2006; <papid> W06-1643 </papid>xie et al , 2008).</prevsent>
</prevsection>
<citsent citstr=" N10-1006 ">
for unsupervised methods, maximal marginal relevance (mmr) is investigated in (zechner, 2002) <papid> J02-4003 </papid>and (xie and liu,2010).<papid> N10-1006 </papid></citsent>
<aftsection>
<nextsent>gillick et al  (2009) introduce concept based global optimization framework by using integer linear programming (ilp).only in very recent works has decision summarization been addressed in (fernandez et al , 2008), (bui et al , 2009) <papid> W09-3934 </papid>and (wang and cardie, 2011).<papid> W11-0503 </papid></nextsent>
<nextsent>(fernandez et al , 2008) and (bui et al , 2009) <papid> W09-3934 </papid>utilize semantic parser to identify candidate phrases for decision summaries and employ svm to rank those phrases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI493">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>early work in this area investigated supervised learning methods, including maximum entropy, conditional random fields (crfs), and support vector machines (svms) (buist et al , 2004; galley, 2006; <papid> W06-1643 </papid>xie et al , 2008).</prevsent>
<prevsent>for unsupervised methods, maximal marginal relevance (mmr) is investigated in (zechner, 2002) <papid> J02-4003 </papid>and (xie and liu,2010).<papid> N10-1006 </papid></prevsent>
</prevsection>
<citsent citstr=" W11-0503 ">
gillick et al  (2009) introduce concept based global optimization framework by using integer linear programming (ilp).only in very recent works has decision summarization been addressed in (fernandez et al , 2008), (bui et al , 2009) <papid> W09-3934 </papid>and (wang and cardie, 2011).<papid> W11-0503 </papid></citsent>
<aftsection>
<nextsent>(fernandez et al , 2008) and (bui et al , 2009) <papid> W09-3934 </papid>utilize semantic parser to identify candidate phrases for decision summaries and employ svm to rank those phrases.</nextsent>
<nextsent>they also train hmm and svm directly on set of decision-related dialogue acts on token level and use the classifiers to identify summary-worthy words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI497">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(fernandez et al , 2008) and (bui et al , 2009) <papid> W09-3934 </papid>utilize semantic parser to identify candidate phrases for decision summaries and employ svm to rank those phrases.</prevsent>
<prevsent>they also train hmm and svm directly on set of decision-related dialogue acts on token level and use the classifiers to identify summary-worthy words.</prevsent>
</prevsection>
<citsent citstr=" I08-1018 ">
wang and cardie (2011)<papid> W11-0503 </papid>provide an exploration on supervised and unsupervised learning for decision summarization on both utterance- and token- level.our work also arises out of applying topic models to text summarization (bhandari et al , 2008; <papid> I08-1018 </papid>haghighi and vanderwende, 2009; <papid> N09-1041 </papid>celikyilmaz and hakkani-tur, 2010; celikyilmaz and hakkani-tur, 2010).</citsent>
<aftsection>
<nextsent>mostly, the sentences are ranked according to importance based on latent topic structures, and top ones are selected as the summary.
</nextsent>
<nextsent>there are some works for applying document-level topic models to speech summarization (kong and shan leek, 2006; chen and chen, 2008; hazen, 2011).
</nextsent>
<nextsent>different from their work, we further investigate the topic models offine granularity on sentence level and leverage context information for decision summarization task.most existing approaches for speech summarization result in selection of utterances from the dialogue, which cannot remove the redundancy within utterances.
</nextsent>
<nextsent>to eliminate the superfluous words, our work is also inspired by key phrase extraction of meetings (liu et al , 2009; <papid> N09-1070 </papid>liu et al , 2011) and key phrase based summarization (riedhammer et al , 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI500">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>there are some works for applying document-level topic models to speech summarization (kong and shan leek, 2006; chen and chen, 2008; hazen, 2011).
</prevsent>
<prevsent>different from their work, we further investigate the topic models offine granularity on sentence level and leverage context information for decision summarization task.most existing approaches for speech summarization result in selection of utterances from the dialogue, which cannot remove the redundancy within utterances.
</prevsent>
</prevsection>
<citsent citstr=" N09-1070 ">
to eliminate the superfluous words, our work is also inspired by key phrase extraction of meetings (liu et al , 2009; <papid> N09-1070 </papid>liu et al , 2011) and key phrase based summarization (riedhammer et al , 2010).</citsent>
<aftsection>
<nextsent>however, small set of key phrases are not enough to concretely display the content.
</nextsent>
<nextsent>instead of only picking up key phrases, our work identifies allof the summary-worthy words and phrases, andre moves redundancies within utterances.
</nextsent>
<nextsent>in this section, we first present our proposed token level decision summarization framework ? domsum ? which utilizes latent topic structure in utterances to extract words from dominant topic (seedetails in section 3.1) to form summaries.
</nextsent>
<nextsent>in section 3.2, we describe four existing sentence scoring metrics denoted as one topic, multi topic, tmm sum and klsum which are also based on latent topic distributions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI505">
<title id=" W12-1605.xml">unsupervised topic modeling approaches to decision summarization in spoken meetings </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>as better approaches for drda clustering become available, they could be employed instead.
</prevsent>
<prevsent>evaluation metric.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
to evaluate the performance of various summarization approaches, we use the widely accepted rouge (lin and hovy, 2003) <papid> N03-1020 </papid>met rics.</citsent>
<aftsection>
<nextsent>we use the stemming option of the rouge software at http://berouge.com/ and remove stop words from both the system and gold-standard summaries, same as riedhammer et al  (2010) do.inference and hyper parameters we use the implementation from (lu et al , 2011) for the three topic models in section 4.
</nextsent>
<nextsent>the collapsed gibbs sampling approach (griffiths and steyvers, 2004) is exploited for inference.
</nextsent>
<nextsent>hyper parameters are chosen according to (brody and elhadad, 2010), (titov and mcdonald, 2008) and (du et al , 2010).
</nextsent>
<nextsent>in lda and local lda, ? and ? are both set to 0.1 . for mg-lda, gl, loc and mix are set to 0.1; ? is 0.1 44and the window size is 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI509">
<title id=" W11-2146.xml">cmu haitian creole english translation system for wmt 2011 </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>the primary in domain data comprises the translated (noisy) sms messages.
</prevsent>
<prevsent>the additional data contains newswire text, medical dialogs, the bible, several bilingual dictionaries, and parallel sentences from wikipedia.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
corpus sentences tokens (ht/en) sms messages 16,676 351k / 324k newswire text 13,517 336k / 292k medical dialog 1,619 10k / 10k dictionaries 42,178 97k / 92k other 41,872 939k / 865k wikipedia 8,476 77k / 90k total 124,338 1.81m / 1.67m table 1: haitian creole (ht) and english (en) parallel data provide by wmt11we preprocessed the data by separating the punctuations, and converting both sides into lower case.sms data was further processed to normalize quotations and other punctuation marks, and to remove all markups.to build baseline translation system we followed the recommended steps: generate word align 1www.speech.cs.cmu.edu/haitian/ ments using giza++ (och and ney, 2003) <papid> J03-1002 </papid>and phrase extraction using moses (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we built 4-gram language model with the sri lm toolkit (stolcke, 2002) using english side ofthe training corpus.
</nextsent>
<nextsent>model parameters for the language model, phrase table, and lexicalized reordering model were optimized via minimum error-rate (mer) training (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>the sms test sets were provided in two formats: raw (r) and cleaned (cl), where the latter had been manually cleaned.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI510">
<title id=" W11-2146.xml">cmu haitian creole english translation system for wmt 2011 </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>the primary in domain data comprises the translated (noisy) sms messages.
</prevsent>
<prevsent>the additional data contains newswire text, medical dialogs, the bible, several bilingual dictionaries, and parallel sentences from wikipedia.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
corpus sentences tokens (ht/en) sms messages 16,676 351k / 324k newswire text 13,517 336k / 292k medical dialog 1,619 10k / 10k dictionaries 42,178 97k / 92k other 41,872 939k / 865k wikipedia 8,476 77k / 90k total 124,338 1.81m / 1.67m table 1: haitian creole (ht) and english (en) parallel data provide by wmt11we preprocessed the data by separating the punctuations, and converting both sides into lower case.sms data was further processed to normalize quotations and other punctuation marks, and to remove all markups.to build baseline translation system we followed the recommended steps: generate word align 1www.speech.cs.cmu.edu/haitian/ ments using giza++ (och and ney, 2003) <papid> J03-1002 </papid>and phrase extraction using moses (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we built 4-gram language model with the sri lm toolkit (stolcke, 2002) using english side ofthe training corpus.
</nextsent>
<nextsent>model parameters for the language model, phrase table, and lexicalized reordering model were optimized via minimum error-rate (mer) training (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>the sms test sets were provided in two formats: raw (r) and cleaned (cl), where the latter had been manually cleaned.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI511">
<title id=" W11-2146.xml">cmu haitian creole english translation system for wmt 2011 </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>corpus sentences tokens (ht/en) sms messages 16,676 351k / 324k newswire text 13,517 336k / 292k medical dialog 1,619 10k / 10k dictionaries 42,178 97k / 92k other 41,872 939k / 865k wikipedia 8,476 77k / 90k total 124,338 1.81m / 1.67m table 1: haitian creole (ht) and english (en) parallel data provide by wmt11we preprocessed the data by separating the punctuations, and converting both sides into lower case.sms data was further processed to normalize quotations and other punctuation marks, and to remove all markups.to build baseline translation system we followed the recommended steps: generate word align 1www.speech.cs.cmu.edu/haitian/ ments using giza++ (och and ney, 2003) <papid> J03-1002 </papid>and phrase extraction using moses (koehn et al, 2007).<papid> P07-2045 </papid></prevsent>
<prevsent>we built 4-gram language model with the sri lm toolkit (stolcke, 2002) using english side ofthe training corpus.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
model parameters for the language model, phrase table, and lexicalized reordering model were optimized via minimum error-rate (mer) training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>the sms test sets were provided in two formats: raw (r) and cleaned (cl), where the latter had been manually cleaned.
</nextsent>
<nextsent>we used the sms dev clean to optimize the decoder parameters and the sms devtest clean and sms devtest raw as held-out evaluation sets.
</nextsent>
<nextsent>each set contains 900 sentences.
</nextsent>
<nextsent>a separate sms test, with 1274 sentences, was used as the unseen test set in the final evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI512">
<title id=" W11-2146.xml">cmu haitian creole english translation system for wmt 2011 </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>each set contains 900 sentences.
</prevsent>
<prevsent>a separate sms test, with 1274 sentences, was used as the unseen test set in the final evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for each experiment we report the case-insensitive bleu (papineni et al., 2002) <papid> P02-1040 </papid>score.</citsent>
<aftsection>
<nextsent>using the available training data we built several baseline systems: the first system (parallel-ood), uses all the out-of-domain parallel data except the wikipedia sentences.
</nextsent>
<nextsent>the second system, in addition, includes wikipedia data.
</nextsent>
<nextsent>the third system uses all available parallel training data (including both the out-of-domain data as well as in-domain sms data).
</nextsent>
<nextsent>we used the third system as the baseline for later experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI513">
<title id=" W11-2146.xml">cmu haitian creole english translation system for wmt 2011 </title>
<section> preprocessing of sms data.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 spelling normalization.
</prevsent>
<prevsent>one of the most problematic issues in haitian creole sms translation system is misspelled words.
</prevsent>
</prevsection>
<citsent citstr=" N10-1064 ">
when training data contains misspelled words, the translation system performance will be affected at several levels, such as word alignment, phrase/rule extractions, and tuning parameters (bertoldi et al, 2010).<papid> N10-1064 </papid></citsent>
<aftsection>
<nextsent>therefore, it is desirable to perform spelling correction on the data.
</nextsent>
<nextsent>spelling correction based on the noisy channel model has been explored in (kernighan et al, 1990; brill and moore, 2000;<papid> P00-1037 </papid>toutanova and moore, 2002).<papid> P02-1019 </papid></nextsent>
<nextsent>the model is generally presented in the following form: p(c?|h) = argmax p(h|c)p(c) (1)where is the haitian creole word, and is possible correction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI514">
<title id=" W11-2146.xml">cmu haitian creole english translation system for wmt 2011 </title>
<section> preprocessing of sms data.  </section>
<citcontext>
<prevsection>
<prevsent>when training data contains misspelled words, the translation system performance will be affected at several levels, such as word alignment, phrase/rule extractions, and tuning parameters (bertoldi et al, 2010).<papid> N10-1064 </papid></prevsent>
<prevsent>therefore, it is desirable to perform spelling correction on the data.</prevsent>
</prevsection>
<citsent citstr=" P00-1037 ">
spelling correction based on the noisy channel model has been explored in (kernighan et al, 1990; brill and moore, 2000;<papid> P00-1037 </papid>toutanova and moore, 2002).<papid> P02-1019 </papid></citsent>
<aftsection>
<nextsent>the model is generally presented in the following form: p(c?|h) = argmax p(h|c)p(c) (1)where is the haitian creole word, and is possible correction.
</nextsent>
<nextsent>p(c) is source model which is prior of word probabilities.
</nextsent>
<nextsent>p(h|c) is an error model or noisy channel model that accounts for spelling transformations on letter sequences.
</nextsent>
<nextsent>unfortunately, in the case of haitian creole sms we do not have sufficient data to estimate p(h|c) and p(c).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI515">
<title id=" W11-2146.xml">cmu haitian creole english translation system for wmt 2011 </title>
<section> preprocessing of sms data.  </section>
<citcontext>
<prevsection>
<prevsent>when training data contains misspelled words, the translation system performance will be affected at several levels, such as word alignment, phrase/rule extractions, and tuning parameters (bertoldi et al, 2010).<papid> N10-1064 </papid></prevsent>
<prevsent>therefore, it is desirable to perform spelling correction on the data.</prevsent>
</prevsection>
<citsent citstr=" P02-1019 ">
spelling correction based on the noisy channel model has been explored in (kernighan et al, 1990; brill and moore, 2000;<papid> P00-1037 </papid>toutanova and moore, 2002).<papid> P02-1019 </papid></citsent>
<aftsection>
<nextsent>the model is generally presented in the following form: p(c?|h) = argmax p(h|c)p(c) (1)where is the haitian creole word, and is possible correction.
</nextsent>
<nextsent>p(c) is source model which is prior of word probabilities.
</nextsent>
<nextsent>p(h|c) is an error model or noisy channel model that accounts for spelling transformations on letter sequences.
</nextsent>
<nextsent>unfortunately, in the case of haitian creole sms we do not have sufficient data to estimate p(h|c) and p(c).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI516">
<title id=" W11-2146.xml">cmu haitian creole english translation system for wmt 2011 </title>
<section> corpus expansion using semantic role.  </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, none of systems with spelling normalization outperformed the system trained on the original data.
</prevsent>
<prevsent>restricting the spelling correction only to infrequent words (s2) performed better for the devtest sets, but not for the dev set, although all the test sets come from the same domain.
</prevsent>
</prevsection>
<citsent citstr=" P11-2051 ">
labeling to address the problem of limited resources, we tried to expand the training corpus by applying the corpus expansion method described in (gao and vogel, 2011).<papid> P11-2051 </papid></citsent>
<aftsection>
<nextsent>first, we parsed and labeled the semantic roles of the english side of the corpus, using the assert labeler (pradhan et al, 2004).<papid> N04-1030 </papid></nextsent>
<nextsent>next, using the word alignment models of the parallel corpus, we extracted semantic role label (srl) substitution rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI519">
<title id=" W11-2146.xml">cmu haitian creole english translation system for wmt 2011 </title>
<section> corpus expansion using semantic role.  </section>
<citcontext>
<prevsection>
<prevsent>restricting the spelling correction only to infrequent words (s2) performed better for the devtest sets, but not for the dev set, although all the test sets come from the same domain.
</prevsent>
<prevsent>labeling to address the problem of limited resources, we tried to expand the training corpus by applying the corpus expansion method described in (gao and vogel, 2011).<papid> P11-2051 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1030 ">
first, we parsed and labeled the semantic roles of the english side of the corpus, using the assert labeler (pradhan et al, 2004).<papid> N04-1030 </papid></citsent>
<aftsection>
<nextsent>next, using the word alignment models of the parallel corpus, we extracted semantic role label (srl) substitution rules.
</nextsent>
<nextsent>srl rules consist of source and target phrases that cover whole constituents of semantic roles, the verb frames they belong to, and the role labels of the constituents.
</nextsent>
<nextsent>the source and target phrases must comply with the restrictions detailed in (gao and vogel, 2011).<papid> P11-2051 </papid></nextsent>
<nextsent>third, for each sentence, we replace done of embedded srl substitution rules with equivalent rules that have the same verb frame and the same role label.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI526">
<title id=" W11-2146.xml">cmu haitian creole english translation system for wmt 2011 </title>
<section> extracting parallel data from.  </section>
<citcontext>
<prevsection>
<prevsent>hence parallel sentence detection technique was necessary to process the data.
</prevsent>
<prevsent>because the sms messages are related to the disaster relief effort, which may include many words in the medical domain, we believe the newly extracted data may help improve translation performance.
</prevsent>
</prevsection>
<citsent citstr=" J05-4003 ">
following munteanu and marcu (2005), <papid> J05-4003 </papid>we useda maximum entropy classifier to identify comparable sentence.</citsent>
<aftsection>
<nextsent>to avoid the problem of having different sentence orderings in the article pair, we take every source-target sentence pair in the two articles,and apply the classifier to detect if they are parallel.
</nextsent>
<nextsent>the classifier approach is appealing to low resource language such as haitian creole, because the features for the classifier can be generated with minimal translation resources (i.e. translation lex icon).
</nextsent>
<nextsent>5.1 maximum entropy classifier.
</nextsent>
<nextsent>the classifier probability can be defined as: pr(ci|s, ) = exp (n j=1 jfij(ci, s, ) ) z(s, ) (2) where (s, ) is sentence pair, ci is the class, fijare feature functions and z(s) is normalizing factor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI527">
<title id=" W11-2146.xml">cmu haitian creole english translation system for wmt 2011 </title>
<section> extracting parallel data from.  </section>
<citcontext>
<prevsection>
<prevsent>rather than computing word alignment between the two sentences, we use lexical probabilities to determine alignment point sas follows: source word is aligned to target word if p(s|t)   0.5.
</prevsent>
<prevsent>target word alignment is computed similarly.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we defined feature set which includes: length ratio and length difference between source and target sentences, lexical probability scores similar to ibm model 1 (brown et al, 1993), <papid> J93-2003 </papid>number of aligned/unaligned words and the length of the longest aligned word sequence.</citsent>
<aftsection>
<nextsent>lexical probability score, and alignment features generate two sets of features based on translation lexica obtained by training in both directions.
</nextsent>
<nextsent>features are normalized with respect to the sentence length.
</nextsent>
<nextsent>5.2 training and testing the classifier.
</nextsent>
<nextsent>to train the model we need training examples that belong to each of the two classes: parallel and non parallel.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI529">
<title id=" W11-2304.xml">trap hunting finding personal data management issues in next generation aac devices </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such devices are designed to give communication impaired people greater independence and improved opportunities of social integration.
</prevsent>
<prevsent>the devices enable users to construct utterances, many of which describe themselves or aspects of their lives, including their actions with others and, as such, can be considered personal data?.
</prevsent>
</prevsection>
<citsent citstr=" W10-1301 ">
recent work by patel and radhakrishnan (2007), black et al (2010), <papid> W10-1301 </papid>reiter et al (2009), <papid> W09-0601 </papid>and reddington and tintarev (2011) makes explicit use of personal data (about both the user and other parties) to improve the functionality of aac devices.</citsent>
<aftsection>
<nextsent>depending on context, the use of these utterances, in an institutional setting, may be controlled under data protection legislation, or (e.g. domestically) their use may be influenced more by social norms within the context.
</nextsent>
<nextsent>a key factor in personal data management is the highly contextual nature of privacy related issues; privacy concerns and practices are situated in their context (nissenbaum, 2009) and influenced by cultural issues (milberg et al., 2000).
</nextsent>
<nextsent>the diversity of technology in the aac sector is set to increase dramatically.
</nextsent>
<nextsent>apples ipad1 has caused huge investment in tablet technology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI530">
<title id=" W11-2304.xml">trap hunting finding personal data management issues in next generation aac devices </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such devices are designed to give communication impaired people greater independence and improved opportunities of social integration.
</prevsent>
<prevsent>the devices enable users to construct utterances, many of which describe themselves or aspects of their lives, including their actions with others and, as such, can be considered personal data?.
</prevsent>
</prevsection>
<citsent citstr=" W09-0601 ">
recent work by patel and radhakrishnan (2007), black et al (2010), <papid> W10-1301 </papid>reiter et al (2009), <papid> W09-0601 </papid>and reddington and tintarev (2011) makes explicit use of personal data (about both the user and other parties) to improve the functionality of aac devices.</citsent>
<aftsection>
<nextsent>depending on context, the use of these utterances, in an institutional setting, may be controlled under data protection legislation, or (e.g. domestically) their use may be influenced more by social norms within the context.
</nextsent>
<nextsent>a key factor in personal data management is the highly contextual nature of privacy related issues; privacy concerns and practices are situated in their context (nissenbaum, 2009) and influenced by cultural issues (milberg et al., 2000).
</nextsent>
<nextsent>the diversity of technology in the aac sector is set to increase dramatically.
</nextsent>
<nextsent>apples ipad1 has caused huge investment in tablet technology.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI534">
<title id=" W11-2304.xml">trap hunting finding personal data management issues in next generation aac devices </title>
<section> examples.  </section>
<citcontext>
<prevsection>
<prevsent>narratives are groups of messages that together relate an experience or tell story.
</prevsent>
<prevsent>this adds the problem of creating narrative structure and consistent style to the data-mining exercise (fornlg work on the importance of narrative information exchange see e.g.
</prevsent>
</prevsection>
<citsent citstr=" W08-1119 ">
(reiter et al, 2008)).<papid> W08-1119 </papid></citsent>
<aftsection>
<nextsent>an example might be: had my breakfast quickly because was excited to go to the arcade.
</nextsent>
<nextsent>i got on the bus, went to the arcade, played in the arcade and won cuddly bear.
</nextsent>
<nextsent>now consider that alice and charlie are joined by bob, who is also an aac user on the same system as alice.
</nextsent>
<nextsent>alice and bobs devices are capable of sharing data at all levels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI535">
<title id=" W11-1822.xml">a pattern approach for biomedical event annotation </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>heuristic rules extracted from training corpus are used to identify candidate triggers.
</prevsent>
<prevsent>those rules are, for instance, nn/nns + of + protein, vbn + protein and so on.
</prevsent>
</prevsection>
<citsent citstr=" W09-1403 ">
event triggers are diverse in lexical and ambiguous in classification (bjrne et al (2009) and buyko et al (2009)).<papid> W09-1403 </papid></citsent>
<aftsection>
<nextsent>candidate triggers are classified by dictionary.
</nextsent>
<nextsent>the dictionary containing words of triggers with their corresponding classes is built from training corpus.
</nextsent>
<nextsent>for ambiguous trigger classes, the class that has the highest rate of appearance is chosen.
</nextsent>
<nextsent>2.3 event annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI536">
<title id=" W11-2133.xml">topic adaptation for lecture translation through bilingual latent semantic models </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in section 5, we describe our new bilingual topic modeling based adaptation technique.
</prevsent>
<prevsent>in section 6, we report adaptation experiments, followed by conclusions and future work in section 7.
</prevsent>
</prevsection>
<citsent citstr=" C04-1059 ">
zhao et al  (2004) <papid> C04-1059 </papid>construct baseline smt system using large background language model and use itto retrieve relevant documents from large monolin 294gual corpora and subsequently interpol ate the resulting small domain-specific language model with the background language model.</citsent>
<aftsection>
<nextsent>in sethy et al  (2006), <papid> N06-2037 </papid>domain-specific language models are obtained by including only the sentences that are similar to the ones in the target domain via relative entropy based criterion.</nextsent>
<nextsent>researchers such as foster and kuhn (2007) <papid> W07-0717 </papid>andkoehn and schroeder (2007) <papid> W07-0733 </papid>have investigated mixture model approaches to adaptation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI537">
<title id=" W11-2133.xml">topic adaptation for lecture translation through bilingual latent semantic models </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in section 6, we report adaptation experiments, followed by conclusions and future work in section 7.
</prevsent>
<prevsent>zhao et al  (2004) <papid> C04-1059 </papid>construct baseline smt system using large background language model and use itto retrieve relevant documents from large monolin 294gual corpora and subsequently interpol ate the resulting small domain-specific language model with the background language model.</prevsent>
</prevsection>
<citsent citstr=" N06-2037 ">
in sethy et al  (2006), <papid> N06-2037 </papid>domain-specific language models are obtained by including only the sentences that are similar to the ones in the target domain via relative entropy based criterion.</citsent>
<aftsection>
<nextsent>researchers such as foster and kuhn (2007) <papid> W07-0717 </papid>andkoehn and schroeder (2007) <papid> W07-0733 </papid>have investigated mixture model approaches to adaptation.</nextsent>
<nextsent>foster andkuhn (2007) <papid> W07-0717 </papid>use mixture model approach that involves splitting training corpus into different components, training separate models on each component, and applying mixture weights as function of the distances of each component to the source text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI538">
<title id=" W11-2133.xml">topic adaptation for lecture translation through bilingual latent semantic models </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>zhao et al  (2004) <papid> C04-1059 </papid>construct baseline smt system using large background language model and use itto retrieve relevant documents from large monolin 294gual corpora and subsequently interpol ate the resulting small domain-specific language model with the background language model.</prevsent>
<prevsent>in sethy et al  (2006), <papid> N06-2037 </papid>domain-specific language models are obtained by including only the sentences that are similar to the ones in the target domain via relative entropy based criterion.</prevsent>
</prevsection>
<citsent citstr=" W07-0717 ">
researchers such as foster and kuhn (2007) <papid> W07-0717 </papid>andkoehn and schroeder (2007) <papid> W07-0733 </papid>have investigated mixture model approaches to adaptation.</citsent>
<aftsection>
<nextsent>foster andkuhn (2007) <papid> W07-0717 </papid>use mixture model approach that involves splitting training corpus into different components, training separate models on each component, and applying mixture weights as function of the distances of each component to the source text.</nextsent>
<nextsent>koehn and schroeder (2007) <papid> W07-0733 </papid>learn mixture weights for language models trained with in-domain and outof-domain data respectively by minimizing the perplexity of tuning (development) set and interpol at ing the models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI539">
<title id=" W11-2133.xml">topic adaptation for lecture translation through bilingual latent semantic models </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>zhao et al  (2004) <papid> C04-1059 </papid>construct baseline smt system using large background language model and use itto retrieve relevant documents from large monolin 294gual corpora and subsequently interpol ate the resulting small domain-specific language model with the background language model.</prevsent>
<prevsent>in sethy et al  (2006), <papid> N06-2037 </papid>domain-specific language models are obtained by including only the sentences that are similar to the ones in the target domain via relative entropy based criterion.</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
researchers such as foster and kuhn (2007) <papid> W07-0717 </papid>andkoehn and schroeder (2007) <papid> W07-0733 </papid>have investigated mixture model approaches to adaptation.</citsent>
<aftsection>
<nextsent>foster andkuhn (2007) <papid> W07-0717 </papid>use mixture model approach that involves splitting training corpus into different components, training separate models on each component, and applying mixture weights as function of the distances of each component to the source text.</nextsent>
<nextsent>koehn and schroeder (2007) <papid> W07-0733 </papid>learn mixture weights for language models trained with in-domain and outof-domain data respectively by minimizing the perplexity of tuning (development) set and interpol at ing the models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI544">
<title id=" W11-2133.xml">topic adaptation for lecture translation through bilingual latent semantic models </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>federico (2002) combines probabilistic latent semantic analysis (plsa) (hofmann,1999) for topic modeling with the minimum discrimination information (mdi) estimation criterion for speech recognition and notes an improvement in terms of perplexity and word error rate (wer).
</prevsent>
<prevsent>latent dirichlet allocation (lda) techniques have been proposed as an alternative to plsa to construct purely generative models.
</prevsent>
</prevsection>
<citsent citstr=" W06-1644 ">
lda techniques include variational bayes (blei et al , 2003) and hmm-lda (hsu and glass, 2006).<papid> W06-1644 </papid>recently, bilingual approaches to topic modeling have also been proposed.</citsent>
<aftsection>
<nextsent>a hidden markov bilingual topic admixture (hm-bitam) model is proposed by zhao and xing (2008), which constructs generative model in which words from target language are sampled from mixture of topics drawn from dirichlet distribution.
</nextsent>
<nextsent>foreign words are sampled via alignment links from first-ordermarkov process and topic specific translation lexicon.
</nextsent>
<nextsent>while hm-bitam has been used for bilingual topic extraction and topic-specific lexicon mapping in the context of smt, zhao and xing (2008) note that hm-bitam can generate unigram language models for both the source and target language and thus can be used for language model adaptation through mdi in similar manner as outlined in federico (2002).
</nextsent>
<nextsent>another bilingual lsa approach is proposed by tam et al  (2007), which consists oftwo hierarchical lda models, constructed from parallel document corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI545">
<title id=" W11-2133.xml">topic adaptation for lecture translation through bilingual latent semantic models </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>their work is extended in tam and schultz (2009) by constructing parallel document clusters formed by monolingual documents using parallel seed documents.additionally, gong et al  (2010) propose translation model adaptation via monolingual lda training.
</prevsent>
<prevsent>a monolingual lda model is trained from either the source or target side of the training corpus and each phrase pair is assigned phrase-topic distribution based on: m?
</prevsent>
</prevsection>
<citsent citstr=" D09-1092 ">
ji = wjk j m k=1w k , (1) where j is the topic distribution of document and wk is the number of occurrences of phrase pair xk in document j.mimno et al  (2009) <papid> D09-1092 </papid>extend the original concept of lda to support poly lingual topic models (pltm), both on parallel (such as europarl) and partly comparable documents (such as wikipedia ar ticles).</citsent>
<aftsection>
<nextsent>documents are grouped into tuples = (w1, ...,wl) for each language = 1, ..., l. each document wl in tuple is assumed to have the same topic distribution, drawn from an asymmetric dirichlet prior.
</nextsent>
<nextsent>tuple-specific topic distributions are learned using lda with distinct topic-word concentration parameters l. mimno et al  (2009) <papid> D09-1092 </papid>show that pltm sufficiently aligns topics in parallel corpora.</nextsent>
<nextsent>295</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI549">
<title id=" W11-2133.xml">topic adaptation for lecture translation through bilingual latent semantic models </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the ted test data consists of transcriptions created via 1-best asr outputs from the kit quaero evaluation system.
</prevsent>
<prevsent>it consists of 758 sentences and27,432 and 27,307 english and french words, respectively.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the ted talk data is segmented at the clause level, rather than at the level of sentences.our smt systems are built upon the moses open source smt toolkit (koehn et al , 2007)<papid> P07-2045 </papid>3.</citsent>
<aftsection>
<nextsent>the translation and lexicalized reordering models have been trained on parallel data.
</nextsent>
<nextsent>one 5-gram background lm was constructed from the french side of the ted training data (740k words), smoothed with the improved kneser-ney technique (chen and good man, 1999) and computed with the irstlm toolkit (federico et al , 2008).
</nextsent>
<nextsent>the weights of the log-linear interpolation model were optimized via minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the ted development set, using 200 best translations at each tuning iteration.</nextsent>
<nextsent>this paper investigates the effects of language model adaptation via bilingual latent semantic modeling on the ted background lm against baseline model that uses only the ted lm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI550">
<title id=" W11-2133.xml">topic adaptation for lecture translation through bilingual latent semantic models </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the translation and lexicalized reordering models have been trained on parallel data.
</prevsent>
<prevsent>one 5-gram background lm was constructed from the french side of the ted training data (740k words), smoothed with the improved kneser-ney technique (chen and good man, 1999) and computed with the irstlm toolkit (federico et al , 2008).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the weights of the log-linear interpolation model were optimized via minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>on the ted development set, using 200 best translations at each tuning iteration.</citsent>
<aftsection>
<nextsent>this paper investigates the effects of language model adaptation via bilingual latent semantic modeling on the ted background lm against baseline model that uses only the ted lm.
</nextsent>
<nextsent>6.1 bilingual latent semantic model.
</nextsent>
<nextsent>using the technique outlined in section 5, we construct bilingual documents by splitting the parallel ted training corpus into 41,847 documents of 5 lines each.
</nextsent>
<nextsent>while each individual ted lecture could be used as document, our experimental goal is to simulate near-time translation of speeches; thus, we prefer to construct small documents to simulate topic modeling on spoken language scenario in which the length of talk is not known priori.we annotate the english source text for removal after inference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI551">
<title id=" W12-0206.xml">automating second language acquisition research integrating information visualisation and machine learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the investigation of discriminative features can offer insights into assessment and into the linguistic properties characterising the relevant cefr level.
</prevsent>
<prevsent>however, the amount and variety of data potentially made available by the classifier is considerable, as it typically finds hundreds of thousands of discriminative feature instances.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
evenif investigation is restricted to the most discriminative ones, calculations of relationships be 3briscoe et al (2010) pos tagged and parsed the data using the rasp toolkit (briscoe et al, 2006).<papid> P06-4020 </papid></citsent>
<aftsection>
<nextsent>pos tags are based on the claws tagset.
</nextsent>
<nextsent>35tween features can rapidly grow and become overwhelming.
</nextsent>
<nextsent>discriminative features typically capture relatively low-level, specific and local properties of texts, so features need to be linked to the scripts they appear in to allow investigation of the contexts in which they occur.
</nextsent>
<nextsent>the scripts, in turn,need to be searched for further linguistic properties in order to formulate and evaluate higher level, more general and comprehensible hypotheses which can inform reference level descriptions and understanding of learner grammars.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI552">
<title id=" W12-0206.xml">automating second language acquisition research integrating information visualisation and machine learning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>tions we describe in detail the visualiser, illustrate how it can support the investigation of individual features, and discuss how such investigations can shed light on the relationships between features and developmental aspects of learner grammars.
</prevsent>
<prevsent>to the best of our knowledge, this is the first attempt to visually analyse as well as per forma linguistic interpretation of discriminative features that characterise learner english.
</prevsent>
</prevsection>
<citsent citstr=" P11-1019 ">
we also apply our visualiser to set of 1,244 publically available fce esol texts (yannakoudakis et al, 2011) <papid> P11-1019 </papid>and make it available as web service to other researchers5.</citsent>
<aftsection>
<nextsent>we use texts produced by candidates taking thefce exam, which assesses english at an upper intermediate level.
</nextsent>
<nextsent>the fce texts, which arepart of the cambridge learner corpus6, are produced by english language learners from around the world sitting cambridge assessments esol examinations7.
</nextsent>
<nextsent>the texts are manually tagged with information about linguistic errors (nicholls, 2003) and linked to meta-data about the learners (e.g., age and native language) and the exam (e.g., grade).
</nextsent>
<nextsent>3.1 basic structure and front-end.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI554">
<title id=" W12-0206.xml">automating second language acquisition research integrating information visualisation and machine learning </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>docu burst is an interactive visualisation of document content, which spatially organizes words using an expert-created ontology (e.g., wordnet).
</prevsent>
<prevsent>parallel tag clouds combine keyword extraction and coordinated visualisations to provide comparative overviews across subsets of faceted text corpus.
</prevsent>
</prevsection>
<citsent citstr=" P11-2053 ">
recently, rohrdantz et al (2011) <papid> P11-2053 </papid>proposed new approach to detecting and investigating changes in word senses by visually modelling and plotting aggregated views about the dia chronic development in word contexts.visualisation techniques have been successfully used in other areas including the humanities (e.g., plaisant et al (2006) and don et al (2007)), as well as genomics (e.g., meyer et al (2010a) and meyer et al (2010b)).</citsent>
<aftsection>
<nextsent>for example, meyer 41 et al (2010a) present system that supports the inspection and cur ation of datasets showing gene expression over time, in conjunction with the spatial location of the cells where the genes are expressed.
</nextsent>
<nextsent>graph layouts have been effectively used in the analysis of domains such as social networks(e.g., terrorism network) to allow for systematic exploration of variety of social network analysis measures (e.g., gao et al (2009) and perer and shneiderman (2006)).
</nextsent>
<nextsent>heer and boyd (2005) have implemented vizster, visualisation system for the exploration of on-line social networks (e.g., facebook) designed to facilitate the discovery of people, promote awareness of community structure etc. van ham et al (2009) introduce phrase net, system that analyses unstructured text by taking as input predefined pattern and displaying graph whose nodes are words and whose edges link the words that are found as matches.
</nextsent>
<nextsent>we believe our integration of highly-weighted discriminative features identified by supervised classifier into graph-based visualiser to support linguistic sla research is, however, novel.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI555">
<title id=" W12-1523.xml">midge generating descriptions of images </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>there is still much work to be done, but we believe that the basic architecture used by this system is solid starting point for generating wide variety of descriptive content, and makes clear some of the issues vision to-language system must handle in order to generate natural-sounding descriptions.
</prevsent>
<prevsent>previous work on generating image descriptions can be characterized as prioritizing among several goals:?
</prevsent>
</prevsection>
<citsent citstr=" W11-0326 ">
creating language that is poetic or metaphorical (li et al, 2011) ? <papid> W11-0326 </papid>creating automatic captions with syntactic variation based on semantic visual information (farhadi et al, 2010)?</citsent>
<aftsection>
<nextsent>creating language describing the scene in basic template-driven way, utilizing attribute detections (kulkarni et al, 2011) or likely verbs from language model (yang et al, 2011)<papid> D11-1041 </papid>to meet one goal, other goals are often compro mised.</nextsent>
<nextsent>yang et al (2011) <papid> D11-1041 </papid>fill in likely verbs to form complete sentences, but limit the generated structures to simple template, without capturing natural variation in sentence length or surface structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI556">
<title id=" W12-1523.xml">midge generating descriptions of images </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>previous work on generating image descriptions can be characterized as prioritizing among several goals:?
</prevsent>
<prevsent>creating language that is poetic or metaphorical (li et al, 2011) ? <papid> W11-0326 </papid>creating automatic captions with syntactic variation based on semantic visual information (farhadi et al, 2010)?</prevsent>
</prevsection>
<citsent citstr=" D11-1041 ">
creating language describing the scene in basic template-driven way, utilizing attribute detections (kulkarni et al, 2011) or likely verbs from language model (yang et al, 2011)<papid> D11-1041 </papid>to meet one goal, other goals are often compro mised.</citsent>
<aftsection>
<nextsent>yang et al (2011) <papid> D11-1041 </papid>fill in likely verbs to form complete sentences, but limit the generated structures to simple template, without capturing natural variation in sentence length or surface structure.</nextsent>
<nextsent>131li et al (2011) <papid> W11-0326 </papid>aim at more metaphorical and varied language, but the generated structures are often syntactically and semantically ill-formed.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI559">
<title id=" W12-1523.xml">midge generating descriptions of images </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>reg comes into play at this step.
</prevsent>
<prevsent>step 6: create all trees that combine following the given trees until all object nouns in group are under one node (either np or s).step 7: order selected adjectives.
</prevsent>
</prevsection>
<citsent citstr=" P11-2041 ">
we use the top scoring ngram model from (mitchell et al, 2011).<papid> P11-2041 </papid></citsent>
<aftsection>
<nextsent>step 8: choose final tree from set of generated trees.
</nextsent>
<nextsent>users can select longest-string or cross entropy calculation.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI560">
<title id=" W12-0802.xml">deciding the twins property for weighted tree automata over extremal semi fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this property is crucial for determinizing such an automaton, andit has been argued that determinization improves the output of parsers and translation systems.
</prevsent>
<prevsent>we show that the twins property for weighted tree automata over extremal semi fields is decidable.
</prevsent>
</prevsection>
<citsent citstr=" N06-1045 ">
in natural-language processing (nlp), language and translation are often modeled using some kind of grammar, automaton or transducer, suchas probabilistic context-free grammar, synchronous context-free grammar, weighted tree automaton, or tree transducer, among others(may and knight, 2006; <papid> N06-1045 </papid>petrov et al, 2006; <papid> P06-1055 </papid>chiang, 2007; <papid> J07-2003 </papid>graehl, knight and may, 2008; zhanget al, 2008; <papid> P08-1064 </papid>pauls and klein, 2009).<papid> P09-1108 </papid></citsent>
<aftsection>
<nextsent>in statistical nlp, the structure of the grammar is extractedheuristically from large corpus of example sentences or sentence pairs, and the rule weights are estimated using methods from statistics or machine learning.
</nextsent>
<nextsent>in general, grammar such as those named above will be ambiguous, i.e., offering sever always of deriving the same object (sentence or sentence pair).
</nextsent>
<nextsent>while the derivation of an object is crucial to the intrinsics of system, it is neither relevant to the user nor observed in the corpus.hence, we speak of spurious ambiguity (li, eisner and khudanpur, 2009).
</nextsent>
<nextsent>as consequence, the true importance of an object can only be assessed by aggregating allits derivations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI561">
<title id=" W12-0802.xml">deciding the twins property for weighted tree automata over extremal semi fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this property is crucial for determinizing such an automaton, andit has been argued that determinization improves the output of parsers and translation systems.
</prevsent>
<prevsent>we show that the twins property for weighted tree automata over extremal semi fields is decidable.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
in natural-language processing (nlp), language and translation are often modeled using some kind of grammar, automaton or transducer, suchas probabilistic context-free grammar, synchronous context-free grammar, weighted tree automaton, or tree transducer, among others(may and knight, 2006; <papid> N06-1045 </papid>petrov et al, 2006; <papid> P06-1055 </papid>chiang, 2007; <papid> J07-2003 </papid>graehl, knight and may, 2008; zhanget al, 2008; <papid> P08-1064 </papid>pauls and klein, 2009).<papid> P09-1108 </papid></citsent>
<aftsection>
<nextsent>in statistical nlp, the structure of the grammar is extractedheuristically from large corpus of example sentences or sentence pairs, and the rule weights are estimated using methods from statistics or machine learning.
</nextsent>
<nextsent>in general, grammar such as those named above will be ambiguous, i.e., offering sever always of deriving the same object (sentence or sentence pair).
</nextsent>
<nextsent>while the derivation of an object is crucial to the intrinsics of system, it is neither relevant to the user nor observed in the corpus.hence, we speak of spurious ambiguity (li, eisner and khudanpur, 2009).
</nextsent>
<nextsent>as consequence, the true importance of an object can only be assessed by aggregating allits derivations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI562">
<title id=" W12-0802.xml">deciding the twins property for weighted tree automata over extremal semi fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this property is crucial for determinizing such an automaton, andit has been argued that determinization improves the output of parsers and translation systems.
</prevsent>
<prevsent>we show that the twins property for weighted tree automata over extremal semi fields is decidable.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
in natural-language processing (nlp), language and translation are often modeled using some kind of grammar, automaton or transducer, suchas probabilistic context-free grammar, synchronous context-free grammar, weighted tree automaton, or tree transducer, among others(may and knight, 2006; <papid> N06-1045 </papid>petrov et al, 2006; <papid> P06-1055 </papid>chiang, 2007; <papid> J07-2003 </papid>graehl, knight and may, 2008; zhanget al, 2008; <papid> P08-1064 </papid>pauls and klein, 2009).<papid> P09-1108 </papid></citsent>
<aftsection>
<nextsent>in statistical nlp, the structure of the grammar is extractedheuristically from large corpus of example sentences or sentence pairs, and the rule weights are estimated using methods from statistics or machine learning.
</nextsent>
<nextsent>in general, grammar such as those named above will be ambiguous, i.e., offering sever always of deriving the same object (sentence or sentence pair).
</nextsent>
<nextsent>while the derivation of an object is crucial to the intrinsics of system, it is neither relevant to the user nor observed in the corpus.hence, we speak of spurious ambiguity (li, eisner and khudanpur, 2009).
</nextsent>
<nextsent>as consequence, the true importance of an object can only be assessed by aggregating allits derivations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI563">
<title id=" W12-0802.xml">deciding the twins property for weighted tree automata over extremal semi fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this property is crucial for determinizing such an automaton, andit has been argued that determinization improves the output of parsers and translation systems.
</prevsent>
<prevsent>we show that the twins property for weighted tree automata over extremal semi fields is decidable.
</prevsent>
</prevsection>
<citsent citstr=" P08-1064 ">
in natural-language processing (nlp), language and translation are often modeled using some kind of grammar, automaton or transducer, suchas probabilistic context-free grammar, synchronous context-free grammar, weighted tree automaton, or tree transducer, among others(may and knight, 2006; <papid> N06-1045 </papid>petrov et al, 2006; <papid> P06-1055 </papid>chiang, 2007; <papid> J07-2003 </papid>graehl, knight and may, 2008; zhanget al, 2008; <papid> P08-1064 </papid>pauls and klein, 2009).<papid> P09-1108 </papid></citsent>
<aftsection>
<nextsent>in statistical nlp, the structure of the grammar is extractedheuristically from large corpus of example sentences or sentence pairs, and the rule weights are estimated using methods from statistics or machine learning.
</nextsent>
<nextsent>in general, grammar such as those named above will be ambiguous, i.e., offering sever always of deriving the same object (sentence or sentence pair).
</nextsent>
<nextsent>while the derivation of an object is crucial to the intrinsics of system, it is neither relevant to the user nor observed in the corpus.hence, we speak of spurious ambiguity (li, eisner and khudanpur, 2009).
</nextsent>
<nextsent>as consequence, the true importance of an object can only be assessed by aggregating allits derivations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI564">
<title id=" W12-0802.xml">deciding the twins property for weighted tree automata over extremal semi fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this property is crucial for determinizing such an automaton, andit has been argued that determinization improves the output of parsers and translation systems.
</prevsent>
<prevsent>we show that the twins property for weighted tree automata over extremal semi fields is decidable.
</prevsent>
</prevsection>
<citsent citstr=" P09-1108 ">
in natural-language processing (nlp), language and translation are often modeled using some kind of grammar, automaton or transducer, suchas probabilistic context-free grammar, synchronous context-free grammar, weighted tree automaton, or tree transducer, among others(may and knight, 2006; <papid> N06-1045 </papid>petrov et al, 2006; <papid> P06-1055 </papid>chiang, 2007; <papid> J07-2003 </papid>graehl, knight and may, 2008; zhanget al, 2008; <papid> P08-1064 </papid>pauls and klein, 2009).<papid> P09-1108 </papid></citsent>
<aftsection>
<nextsent>in statistical nlp, the structure of the grammar is extractedheuristically from large corpus of example sentences or sentence pairs, and the rule weights are estimated using methods from statistics or machine learning.
</nextsent>
<nextsent>in general, grammar such as those named above will be ambiguous, i.e., offering sever always of deriving the same object (sentence or sentence pair).
</nextsent>
<nextsent>while the derivation of an object is crucial to the intrinsics of system, it is neither relevant to the user nor observed in the corpus.hence, we speak of spurious ambiguity (li, eisner and khudanpur, 2009).
</nextsent>
<nextsent>as consequence, the true importance of an object can only be assessed by aggregating allits derivations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI565">
<title id=" W12-0802.xml">deciding the twins property for weighted tree automata over extremal semi fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as consequence, the true importance of an object can only be assessed by aggregating allits derivations.
</prevsent>
<prevsent>unfortunately, this proves computationally intractable in almost all cases: for instance, finding the best string of probabilistic regular grammar is np hard (simaan, 1996; casacuberta and de la higuera, 2000).
</prevsent>
</prevsection>
<citsent citstr=" W05-1506 ">
finding the best derivation, on the other hand, is possible in polynomial time (eppstein, 1998; huang and chiang, 2005), <papid> W05-1506 </papid>and thus, most nlp systems approximate the importance of an object by its best derivation (li, eisner and khudanpur, 2009).</citsent>
<aftsection>
<nextsent>there is, however, line of research that deals with the costly aggregating approach, and it is closely related to determinization techniques from automata theory.
</nextsent>
<nextsent>for instance, may and knight (2006) <papid> N06-1045 </papid>argue that the output of parser or syntax-based translation system can be represented by weighted tree automaton (wta), which assigns weight to each parse tree.</nextsent>
<nextsent>under some circumstances, the wta can be determinized, yielding an equivalent, but unambiguous wta, which offers at most one derivation for each object.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI567">
<title id=" W12-0108.xml">presemt pattern recognition based statistically enhanced mt </title>
<section> experiments &amp; evaluation results.  </section>
<citcontext>
<prevsection>
<prevsent>to date mt systems based on the presemt methodology have been created for total of 8 languages, indicating the flexibility of the proposed approach.
</prevsent>
<prevsent>table 1 illustrates an indicative set of results obtained by running automatic evaluation metrics on test data translated by the 1st presemt prototype for selection of language pairs, due to space restrictions.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
in the case of the language pair english-to german, these results are contrasted to the ones obtained when translating the same test set with moses (koehn et al, 2007).<papid> P07-2045 </papid>it is observed that for the english-to-german language pair, presemt achieved approximately 50% of the moses bleu score and 80% of the moses with respect to the meteor and ter scores.</citsent>
<aftsection>
<nextsent>these are reasonably competitive results compared to an established system such as moses.
</nextsent>
<nextsent>furthermore, it should taken into consideration that (a) the presemt results were obtained by the 1st system prototype, (b) presemt is still under development and (c) only one reference translation was used per sentence.
</nextsent>
<nextsent>newer versions of the presemt system, incorporating more advanced versions of the different modules are expected to result in substantially improved translation accuracies.
</nextsent>
<nextsent>in particular, the second translation phase will be further researched.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI568">
<title id=" W11-2039.xml">an incremental architecture for the semantic annotation of dialogue corpora with high level structures a case of study for the media corpus </title>
<section> the architecture.  </section>
<citcontext>
<prevsection>
<prevsent>the corpus manager is in charge of the resources management.
</prevsent>
<prevsent>last but not least, two annotation tools were built: one for the srl gold standard (web-based) and the other for the hls gold standard (standalone).syntactic analysis.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
we decided to employ statistical approaches that could learn the irregularities of spoken language: the french tree-tagger5 and the dependency-based malt-parser (nivre et al,2007).<papid> D07-1096 </papid></citsent>
<aftsection>
<nextsent>the parser has been trained with 1449 utterances annotated according to the annotation guidelines described in (cerisara and gardent, 2009).
</nextsent>
<nextsent>5http://www.ims.uni-stuttgart.de/ schmid/ figure 2: general architecture for the hls annotation.
</nextsent>
<nextsent>definition of frames.
</nextsent>
<nextsent>frame semantics, (bakeret al, 1998) <papid> P98-1013 </papid>arranges common background knowledge for situations by grouping verbal, nominal causative and non-causative predicates.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI569">
<title id=" W11-2039.xml">an incremental architecture for the semantic annotation of dialogue corpora with high level structures a case of study for the media corpus </title>
<section> the architecture.  </section>
<citcontext>
<prevsection>
<prevsent>5http://www.ims.uni-stuttgart.de/ schmid/ figure 2: general architecture for the hls annotation.
</prevsent>
<prevsent>definition of frames.
</prevsent>
</prevsection>
<citsent citstr=" P98-1013 ">
frame semantics, (bakeret al, 1998) <papid> P98-1013 </papid>arranges common background knowledge for situations by grouping verbal, nominal causative and non-causative predicates.</citsent>
<aftsection>
<nextsent>nevertheless, paraphrases are more used in spoken language than explicitly uttered nouns, adjectives or verbs for referring to situation (e.g.ask?, request?
</nextsent>
<nextsent>or demand?).
</nextsent>
<nextsent>here we introduce the term: frame evoking phrase (fep) for evoking frames and we include syntactic templates that mirror these phrase sin frames and frame elements (fe).
</nextsent>
<nextsent>table 1 summarizes the differences between port-media frames and framenet (baker et al, 1998).<papid> P98-1013 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI572">
<title id=" W12-2012.xml">on using context for automatic correction of nonword misspellings in student essays </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the area of automatic assessment of writing, detection of misspellings is utilized in computer aided language learning applications and in some automatic scoring systems, especially when feed back to users is involved (dikli, 2006; war schauer and ware, 2006).
</prevsent>
<prevsent>yet spelling errors may have deeper influence on automated text assessment.
</prevsent>
</prevsection>
<citsent citstr=" P11-1121 ">
as noted by nagata, et al (2011), <papid> P11-1121 </papid>sub-optimal automatic detection of grammar and mechanics errors may be attributed to poor performance of nlp tools over noisy text.</citsent>
<aftsection>
<nextsent>presence of spelling errors also hinders systems that require only lexical analysis of text (landauer, et al , 2003; prez, et al, 2004).
</nextsent>
<nextsent>granger and wynne (1999) have shown that spelling errors can affect automated estimates of lexical variation, which in turn are used as predictors of text quality (crossley, et al, 2008; yu, 2010).
</nextsent>
<nextsent>in the context of automated preposition and determiner error correction in l2 english, de felice and pulman (2008) noted that the process is often disrupted by misspellings.
</nextsent>
<nextsent>futagi (2010) described how misspellings pose problems in development of tool for detection of phraseological collocation errors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI573">
<title id=" W12-2012.xml">on using context for automatic correction of nonword misspellings in student essays </title>
<section> spelling correction systems.  </section>
<citcontext>
<prevsection>
<prevsent>chairs,tables?, but all cases where missing spaces result infused words were marked in annotation (e.g. inthe?).
</prevsent>
<prevsent>eral recent studies used web-scale language model (google web1t n-gram corpus ? brants and franz, 2006) for context-sensitive?
</prevsent>
</prevsection>
<citsent citstr=" D09-1129 ">
(i.e. real words) spelling correction (bergsma, et al, 2009; islam and inkpen, 2009; <papid> D09-1129 </papid>carlson and fette, 2007).</citsent>
<aftsection>
<nextsent>chen, et al (2007) <papid> D07-1019 </papid>used lm for pruning candidate corrections for non-words in web queries.</nextsent>
<nextsent>whitelaw, et al (2009) <papid> D09-1093 </papid>used lm for correcting non-word and real-word errors without dictionary and using statistically trained error model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI574">
<title id=" W12-2012.xml">on using context for automatic correction of nonword misspellings in student essays </title>
<section> spelling correction systems.  </section>
<citcontext>
<prevsection>
<prevsent>eral recent studies used web-scale language model (google web1t n-gram corpus ? brants and franz, 2006) for context-sensitive?
</prevsent>
<prevsent>(i.e. real words) spelling correction (bergsma, et al, 2009; islam and inkpen, 2009; <papid> D09-1129 </papid>carlson and fette, 2007).</prevsent>
</prevsection>
<citsent citstr=" D07-1019 ">
chen, et al (2007) <papid> D07-1019 </papid>used lm for pruning candidate corrections for non-words in web queries.</citsent>
<aftsection>
<nextsent>whitelaw, et al (2009) <papid> D09-1093 </papid>used lm for correcting non-word and real-word errors without dictionary and using statistically trained error model.</nextsent>
<nextsent>our study extends the use of language models to automatic correction of non-word errors, with dictionary, but without any explicit error model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI575">
<title id=" W12-2012.xml">on using context for automatic correction of nonword misspellings in student essays </title>
<section> spelling correction systems.  </section>
<citcontext>
<prevsection>
<prevsent>(i.e. real words) spelling correction (bergsma, et al, 2009; islam and inkpen, 2009; <papid> D09-1129 </papid>carlson and fette, 2007).</prevsent>
<prevsent>chen, et al (2007) <papid> D07-1019 </papid>used lm for pruning candidate corrections for non-words in web queries.</prevsent>
</prevsection>
<citsent citstr=" D09-1093 ">
whitelaw, et al (2009) <papid> D09-1093 </papid>used lm for correcting non-word and real-word errors without dictionary and using statistically trained error model.</citsent>
<aftsection>
<nextsent>our study extends the use of language models to automatic correction of non-word errors, with dictionary, but without any explicit error model.
</nextsent>
<nextsent>3.2 conspel system.
</nextsent>
<nextsent>the conspel system was designed and implemented as fully automatic system for detection and correction of spelling errors.
</nextsent>
<nextsent>the current version is focused on non-word misspellings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI576">
<title id=" W12-2012.xml">on using context for automatic correction of nonword misspellings in student essays </title>
<section> spelling correction systems.  </section>
<citcontext>
<prevsection>
<prevsent>local context (several words around the misspelled word in the text) provides lots of information for choosing the adequate correction.
</prevsent>
<prevsent>for each candidate, we check the frequency of its cooccurrence (in language model) with the adjacent words in the text.
</prevsent>
</prevsection>
<citsent citstr=" W04-3238 ">
this approach borrows from the family of noisy-channel error-correction models (zhang, et al, 2006; cucerzan and brill, 2004; <papid> W04-3238 </papid>kernigham, et al, 1990).</citsent>
<aftsection>
<nextsent>with the advent of very large word n-gram language models, we can utilize large contexts (about 4 words on each side of misspelling).
</nextsent>
<nextsent>our current language model uses filtered version of the google web1t collection, containing 1,881,244,352 n-gram types of size 1-5, with punctuation included.2 notably, conspel does not use any statistical error model.
</nextsent>
<nextsent>a second context-sensitive algorithm utilizes non-local context in the essay.
</nextsent>
<nextsent>the idea is quite simple ? given misspelled token in text and set of correction-candidates for that word, for each candidate we check whether that candidate string occurs elsewhere in the text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI577">
<title id=" W12-2012.xml">on using context for automatic correction of nonword misspellings in student essays </title>
<section> comparative evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>for aspell, use of the larger spelling dictionary improved detection precision (fewer false alarms ? see table 2), but it has led to degradation in error correction ? as shown in table 3 (possibly ranking of candidates is affected by larger dictionaries).
</prevsent>
<prevsent>system recall precision f-score aspell 61.53 53.62 57.30 aspell+ 54.17 49.68 51.83 conspel-a 72.65 71.94 72.29 conspel-b 78.32 77.55 77.93 ms word 73.34 66.49 69.74 ms word+ 71.71 69.44 70.56 table 3.
</prevsent>
</prevsection>
<citsent citstr=" P00-1037 ">
evaluation results: non-word error correction (top ranked candidates only) an additional way to evaluate automatic spelling correction is to consider how often the adequate target correction is found among the k-best of the candidate suggestions (mitton, 2009; brill and moore, 2000).<papid> P00-1037 </papid></citsent>
<aftsection>
<nextsent>figure 1 shows error-correction recall and precision results for four systems6 using k-best values 1-5 and 10.
</nextsent>
<nextsent>when two-or-more best-ranked candidates are considered for each misspelling, the baseline con spel-a system shows better performance than ms word.
</nextsent>
<nextsent>aspell results lag significantly below the other systems, although it catches up with ms word beyond k=5.
</nextsent>
<nextsent>conspel-b system outperforms all other systems, in both recall and precision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI578">
<title id=" W12-2012.xml">on using context for automatic correction of nonword misspellings in student essays </title>
<section> conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>acknowledgments many thanks to chong min lee and daniel blanchard for assisting in evaluation with aspell and microsoft office 2007; to our annotators, nicole dicrecchio, julia farnum, melissa lopez, susanne miller, matthew mulholland, sarah ohls, and wave rely vanwinkle.
</prevsent>
<prevsent>the manuscript has also benefited from the comments of three anonymous reviewers.
</prevsent>
</prevsection>
<citsent citstr=" N09-3006 ">
9 boyd (2009) <papid> N09-3006 </papid>used non-native (japanese ell) pronunciation.</citsent>
<aftsection>
<nextsent>modeling to improve speller that uses just an orthographic error-model.
</nextsent>
<nextsent>her combined system achieved 65% correction precision at k=1, and 82.6% at k=5.
</nextsent>
<nextsent>our context-informed system achieves 77.5% and 91.4% respectively.
</nextsent>
<nextsent>113
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI579">
<title id=" W12-1620.xml">a mixed initiative conversational dialogue system for healthcare </title>
<section> supporting mixed initiative dialogues.  </section>
<citcontext>
<prevsection>
<prevsent>system initiative also usually makes it easier for domain expert to design dialogue policy that will behave as desired.1 such systems can work well if the limited options available to theuser are what the user wants to do, but can be problematic otherwise, especially if the user has choice of whether or not to use the system.
</prevsent>
<prevsent>in particular,this approach may not be well suited to an application like simcoach.
</prevsent>
</prevsection>
<citsent citstr=" W06-1303 ">
at the other extreme, some systems allow the user to say anything at any time, but have fairly flat dialogue policies, e.g., (leuski et al., 2006).<papid> W06-1303 </papid></citsent>
<aftsection>
<nextsent>these systems can work well when the user is naturally in charge, such as in interviewing character, but may not be suitable for situations in which character is asking the user questions, or mixed initiative is desired.
</nextsent>
<nextsent>true mixed initiative is notoriously difficult for manually constructed call-flow graph, in which the system might want to take different actions in response to similar stimuli, depending on local utilities.
</nextsent>
<nextsent>reinforcement learning approaches (williams and young, 2007; english and heeman, 2005) <papid> H05-1127 </papid>can be very useful at learning local policy optimizations, but they require large amounts of training data and well-defined global reward structure, are difficult to apply to large state-space and remove some of the control, which can be undesirable (paek and pieraccini, 2008).</nextsent>
<nextsent>our approach to this problem is forward-looking reward seeking agent, similar to that described in (liu and schubert, 2010), though with support for complex dialogue interaction and its authoring.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI580">
<title id=" W12-1620.xml">a mixed initiative conversational dialogue system for healthcare </title>
<section> supporting mixed initiative dialogues.  </section>
<citcontext>
<prevsection>
<prevsent>these systems can work well when the user is naturally in charge, such as in interviewing character, but may not be suitable for situations in which character is asking the user questions, or mixed initiative is desired.
</prevsent>
<prevsent>true mixed initiative is notoriously difficult for manually constructed call-flow graph, in which the system might want to take different actions in response to similar stimuli, depending on local utilities.
</prevsent>
</prevsection>
<citsent citstr=" H05-1127 ">
reinforcement learning approaches (williams and young, 2007; english and heeman, 2005) <papid> H05-1127 </papid>can be very useful at learning local policy optimizations, but they require large amounts of training data and well-defined global reward structure, are difficult to apply to large state-space and remove some of the control, which can be undesirable (paek and pieraccini, 2008).</citsent>
<aftsection>
<nextsent>our approach to this problem is forward-looking reward seeking agent, similar to that described in (liu and schubert, 2010), though with support for complex dialogue interaction and its authoring.
</nextsent>
<nextsent>authoring involves design of local sub dialogue networks with pre-conditions and effects, and also qualitative reward categories (goals), which can be in stantiated with specific reward values.
</nextsent>
<nextsent>the dialogue manager, called flores, can locally optimize policy decisions, by calculating the highest overall expected reward for the best sequence of sub dialogues from given point.
</nextsent>
<nextsent>within sub dialogue, authors can craft the specific structure of interaction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI581">
<title id=" W11-1919.xml">a machine learning based coreference detection system for ontonotes </title>
<section> data preparation.  </section>
<citcontext>
<prevsection>
<prevsent>in our algorithm, we only detect the closest antecedent for each entity, instead of all co references, of each entity.
</prevsent>
<prevsent>specifically, we define each training and testing instance as pair of entities.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
during the training process, for each entity encountered by the system, we create positive instance by pairing an entity with its closest antecedent (soon et al, 2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>in addition, set of negative instances are also created by pairing the entity with any preceding entities that exist between its closest antecedent and the entity itself (note that the antecedent must be coreference of the current entity, whereas preceding entities may not be coref erential).
</nextsent>
<nextsent>for example, in the entity sequence a, b, c, d, e?, let us assume that a? is the closest antecedent of d?.
</nextsent>
<nextsent>then, for entity d?, a-d?
</nextsent>
<nextsent>is considered positive instance, whereas b-d?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI585">
<title id=" W11-2503.xml">distributional semantics from text and images </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>such models learn the statistical models which characterize the joint statistical distribution of observed visual features and verbal image tags (hofmann, 2001; hareet al, 2008).
</prevsent>
<prevsent>this line of research is pursuing the reverse of what we are interested in: using text to im prove the semantic description of images, whereas we want to exploit images to improve our approximation to word meaning.
</prevsent>
</prevsection>
<citsent citstr=" N10-1011 ">
feng and lapata are the first trying to integrate authentic visual information in text-based distributional model (feng and lapata, 2010).<papid> N10-1011 </papid></citsent>
<aftsection>
<nextsent>using collection of bbc news with pictures as corpus, they train topic model where text and visual words are represented in terms of the same shared latent dimensions (topics).
</nextsent>
<nextsent>in this framework, word meaning is modeled as probability distribution over set of latent multimodal topics and the similarity between two words can be estimated by measuring the topics they have in common.
</nextsent>
<nextsent>a better correlation with semantic intuitions is obtainable when visual modality is taken into account, in comparison to estimating the topic structure from text only.although feng and lapatas work is very promising and the main inspiration for our own, their method requires the extraction of single distributional model from the same mixed-media corpus.this has two important drawbacks: first, the textual model must be extracted from the same corpus images are taken from, and the text context extraction methods must be compatible with the overall multimodal approach.
</nextsent>
<nextsent>thus, image features cannot be added to state-of-the-art text-based distributional model ? e.g., model computed on the whole wikipedia or larger corpora using syntactic dependency information ? to assess whether visual information is helping even when purely textual features are already very good.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI586">
<title id=" W11-2503.xml">distributional semantics from text and images </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 the dm text-based model.
</prevsent>
<prevsent>dm has been shown to be near or at the state of the art in great variety of semantic tasks, ranging from modeling similarity judgments to concept categorization, predicting selectional preferences, relation classification and more.
</prevsent>
</prevsection>
<citsent citstr=" J10-4006 ">
the dm model is described in detail by baroni and lenci (2010), <papid> J10-4006 </papid>where it is referred to as typedm.</citsent>
<aftsection>
<nextsent>in brief, the model is trained on large corpus of about 2.8 billion tokens that include web documents, the wikipedia and the bnc.
</nextsent>
<nextsent>dm is structured model, where the collocates are labeled with the link that connect them to the target words.
</nextsent>
<nextsent>the links are determined by mixture of dependency parse information and lexico-syntactic patterns, resulting in distributional features (the dimensions of the semantic space) such as subject kill, with gun oras sharp as.
</nextsent>
<nextsent>the score of target word with feature is not based on the absolute number of times they co-occur in the corpus, but on the variety of different surface realizations of the feature the word co-occurs with.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI588">
<title id=" W11-2503.xml">distributional semantics from text and images </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the wordsim results for our models across dimen sionalities as well as for the full dm are summarized in figure 3.
</prevsent>
<prevsent>+4k +8k +12k +16k +20k +24k +28k +32k25 30 35 40 45 50 55 adding more features to top 32k dm spear ma c oef fici ent (% ) performance of distributional models on wordsim dm combined text image text+figure 3: performance of distributional models on word sim the purely image-based model is having the worst performance in all settings, although even the lowest image-based spearman score (0.29) is significantly above chance (p.   0.05), suggesting that the model does capture some semantic information.contrarily, adding image-based dimensions to textual model (combined) consistently reaches the best performance, also better ? for all choices of dimensionality ? than adding an equal number of text features (text+) or using the full dm matrix.
</prevsent>
</prevsection>
<citsent citstr=" N09-1003 ">
interestingly, the same overall result pattern is observed if we limit evaluation to the wordsim subsets that agirre et al (2009) <papid> N09-1003 </papid>have identified as semantically similar (e.g., synonyms or coordinate terms) and semantically related (e.g., meronyms or topically related concepts).based on the results reported in figure 3, further analyses will focus on the combined model with +20k image-based features, since performance of combined does not seem to be greatly affected by the dimensionality parameter, and performance around this value looks quite stable (it is better only at the boundary +4k value, and with +28k, where, how ever, there is dip for the image model).</citsent>
<aftsection>
<nextsent>the text+performance is not essentially affected by the dimensionality parameter, and we pick the +20k version for maximum comparability with combined.the difference between combined and text+, although consistent, is not statistically significant according to two-tailed paired permutation test(moore and mccabe, 2005) conducted on there sults for the +20k versions of the models.
</nextsent>
<nextsent>still, very interesting qualitative differences emerge.
</nextsent>
<nextsent>table 1 reports those wordsim pairs (among the ones with above-median human-judged similarity) that havethe highest and lowest combined-to-text+ cosine ratios, i.e., pairs that are correctly treated as similar by combined but not by text+, and vice versa.
</nextsent>
<nextsent>strikingly, the pairs characterizing the image-feature enriched combined are all made of concrete, highly image able concepts, whereas the text+ pairs refer tovery abstract notions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI589">
<title id=" W11-1808.xml">model combination for event extraction in bionlp 2011 </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we describe the faust entry to the bionlp2011 shared task on biomolecular event extraction.
</prevsent>
</prevsection>
<citsent citstr=" W11-1807 ">
the faust system explores several stacking models for combination usingas base models the umass dual decomposition (riedel and mccallum, 2011) <papid> W11-1807 </papid>and stanford event parsing (mcclosky et al, 2011<papid> P11-1163 </papid>b) approaches.</citsent>
<aftsection>
<nextsent>we show that using stacking isa straightforward way to improving performance for event extraction and find that it ismost effective when using small set of stacking features and the base models use slightly different representations of the input data.
</nextsent>
<nextsent>the faust system obtained 1st place in three out of four tasks: 1st place in genia task 1 (56.0% f-score) and task 2 (53.9%), 2nd place in theepigenetics and post-translational modifications track (35.0%), and 1st place in the infectious diseases track (55.6%).
</nextsent>
<nextsent>to date, most approaches to the bionlp event extraction task (kim et al, 2011<papid> W11-1802 </papid>a) use single modelto produce their output.</nextsent>
<nextsent>however, model combination techniques such as voting, stacking, and reranking have been shown to consistently produce higher performing systems by taking advantage of multiple views of the same data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI590">
<title id=" W11-1808.xml">model combination for event extraction in bionlp 2011 </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we describe the faust entry to the bionlp2011 shared task on biomolecular event extraction.
</prevsent>
</prevsection>
<citsent citstr=" P11-1163 ">
the faust system explores several stacking models for combination usingas base models the umass dual decomposition (riedel and mccallum, 2011) <papid> W11-1807 </papid>and stanford event parsing (mcclosky et al, 2011<papid> P11-1163 </papid>b) approaches.</citsent>
<aftsection>
<nextsent>we show that using stacking isa straightforward way to improving performance for event extraction and find that it ismost effective when using small set of stacking features and the base models use slightly different representations of the input data.
</nextsent>
<nextsent>the faust system obtained 1st place in three out of four tasks: 1st place in genia task 1 (56.0% f-score) and task 2 (53.9%), 2nd place in theepigenetics and post-translational modifications track (35.0%), and 1st place in the infectious diseases track (55.6%).
</nextsent>
<nextsent>to date, most approaches to the bionlp event extraction task (kim et al, 2011<papid> W11-1802 </papid>a) use single modelto produce their output.</nextsent>
<nextsent>however, model combination techniques such as voting, stacking, and reranking have been shown to consistently produce higher performing systems by taking advantage of multiple views of the same data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI592">
<title id=" W11-1808.xml">model combination for event extraction in bionlp 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that using stacking isa straightforward way to improving performance for event extraction and find that it ismost effective when using small set of stacking features and the base models use slightly different representations of the input data.
</prevsent>
<prevsent>the faust system obtained 1st place in three out of four tasks: 1st place in genia task 1 (56.0% f-score) and task 2 (53.9%), 2nd place in theepigenetics and post-translational modifications track (35.0%), and 1st place in the infectious diseases track (55.6%).
</prevsent>
</prevsection>
<citsent citstr=" W11-1802 ">
to date, most approaches to the bionlp event extraction task (kim et al, 2011<papid> W11-1802 </papid>a) use single modelto produce their output.</citsent>
<aftsection>
<nextsent>however, model combination techniques such as voting, stacking, and reranking have been shown to consistently produce higher performing systems by taking advantage of multiple views of the same data.
</nextsent>
<nextsent>the netflix prize (ben nett et al, 2007) is prime example of this.
</nextsent>
<nextsent>system combination essentially allows systems to regularize each other, smoothing over the artifacts of each (c.f. nivre and mcdonald (2008), <papid> P08-1108 </papid>surdeanu and manning (2010)).<papid> N10-1091 </papid></nextsent>
<nextsent>to our knowledge, the only previous example of model combination for the bionlpshared task was performed by kim et al (2009).<papid> W09-1401 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI596">
<title id=" W11-1808.xml">model combination for event extraction in bionlp 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, model combination techniques such as voting, stacking, and reranking have been shown to consistently produce higher performing systems by taking advantage of multiple views of the same data.
</prevsent>
<prevsent>the netflix prize (ben nett et al, 2007) is prime example of this.
</prevsent>
</prevsection>
<citsent citstr=" P08-1108 ">
system combination essentially allows systems to regularize each other, smoothing over the artifacts of each (c.f. nivre and mcdonald (2008), <papid> P08-1108 </papid>surdeanu and manning (2010)).<papid> N10-1091 </papid></citsent>
<aftsection>
<nextsent>to our knowledge, the only previous example of model combination for the bionlpshared task was performed by kim et al (2009).<papid> W09-1401 </papid></nextsent>
<nextsent>using weighted voting scheme to combine the outputs from the top six systems, they obtained 4%absolute f-score improvement over the best individual system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI597">
<title id=" W11-1808.xml">model combination for event extraction in bionlp 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, model combination techniques such as voting, stacking, and reranking have been shown to consistently produce higher performing systems by taking advantage of multiple views of the same data.
</prevsent>
<prevsent>the netflix prize (ben nett et al, 2007) is prime example of this.
</prevsent>
</prevsection>
<citsent citstr=" N10-1091 ">
system combination essentially allows systems to regularize each other, smoothing over the artifacts of each (c.f. nivre and mcdonald (2008), <papid> P08-1108 </papid>surdeanu and manning (2010)).<papid> N10-1091 </papid></citsent>
<aftsection>
<nextsent>to our knowledge, the only previous example of model combination for the bionlpshared task was performed by kim et al (2009).<papid> W09-1401 </papid></nextsent>
<nextsent>using weighted voting scheme to combine the outputs from the top six systems, they obtained 4%absolute f-score improvement over the best individual system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI598">
<title id=" W11-1808.xml">model combination for event extraction in bionlp 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the netflix prize (ben nett et al, 2007) is prime example of this.
</prevsent>
<prevsent>system combination essentially allows systems to regularize each other, smoothing over the artifacts of each (c.f. nivre and mcdonald (2008), <papid> P08-1108 </papid>surdeanu and manning (2010)).<papid> N10-1091 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
to our knowledge, the only previous example of model combination for the bionlpshared task was performed by kim et al (2009).<papid> W09-1401 </papid></citsent>
<aftsection>
<nextsent>using weighted voting scheme to combine the outputs from the top six systems, they obtained 4%absolute f-score improvement over the best individual system.
</nextsent>
<nextsent>this paper shows that using straightforward model combination strategy on two competitive systems produces new system with substantially higher accuracy.
</nextsent>
<nextsent>this is achieved with the framework of stacking: stacking model uses the output of stacked model as additional features.while we initially considered voting and reranking model combination strategies, it seemed that given the performance gap between the umass and stanford systems that the best option was to include the predictions from the stanford system intothe umass system (e.g., as in nivre and mcdonald (2008)).<papid> P08-1108 </papid></nextsent>
<nextsent>this has the advantage that one model (umass) determines how to integrate the outputs of the other model (stanford) into its own structure, whereas in reranking, for example, the combined model is required to output complete structure produced by only one of the input models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI601">
<title id=" W11-1808.xml">model combination for event extraction in bionlp 2011 </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>here hs (i) is the event label given to token according to s. these features allow different weights to be given to each possible combination of type t?
</prevsent>
<prevsent>that we want to assign, and type ts that predicts.
</prevsent>
</prevsection>
<citsent citstr=" D10-1001 ">
inference in this model amounts to maximizing (e,a,b) over . our approach to solving this problem is dual decomposition (komodakis et al, 2007; rush et al, 2010).<papid> D10-1001 </papid></citsent>
<aftsection>
<nextsent>we divide the problem into three subproblems: (1) finding the best trigger label and set of outgoing edges for each candidate trigger; (2) finding the best trigger label and set of incoming edges for each candidate trigger; (3) finding the best pairs of entities to appear in the same binding.
</nextsent>
<nextsent>due to space limitations we refer the reader to riedel and mccallum (2011) <papid> W11-1807 </papid>for further details.</nextsent>
<nextsent>2.2 stacked model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI605">
<title id=" W11-1808.xml">model combination for event extraction in bionlp 2011 </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 stacked model.
</prevsent>
<prevsent>for the stacked model, we use system based on an event parsing framework (mcclosky et al, 2011<papid> P11-1163 </papid>a) referred to as the stanford model in this paper.</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
this model converts event structures to dependency trees which are parsed using mst parser (mcdonald et al., 2005).<papid> H05-1066 </papid>1 once parsed, the resulting dependency tree is converted back to event structures.</citsent>
<aftsection>
<nextsent>using the stanford model as the stacked model is helpful since it captures tree structure which is not the focus inthe umass model.
</nextsent>
<nextsent>of course, this is also limitation since actual bionlp event graphs are dags,but the model does well considering these restrictions.
</nextsent>
<nextsent>additionally, this constraint encourages the stanford model to provide different (and thus more useful for stacking) results.
</nextsent>
<nextsent>of particular interest to this paper are the four possible decoders in mstparser.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI612">
<title id=" W11-1808.xml">model combination for event extraction in bionlp 2011 </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>this helps to avoid scenario where the stacking model learns to relyon high accuracy at training time that cannot be matched at test time.
</prevsent>
<prevsent>note that, unlike stanfords individual submission in this shared task, the stacked models in this paper do not include the stanford reranker.
</prevsent>
</prevsection>
<citsent citstr=" W11-1803 ">
this is because it would have required making reranker model for each cross validation fold.we made 19 cross validation training folds forge nia (ge) (kim et al, 2011<papid> W11-1802 </papid>b), 12 for epi genetics (epi), and 17 for infectious diseases (id) (kim et al., 2011<papid> W11-1802 </papid>b; ohta et al, 2011; <papid> W11-1803 </papid>pyysalo et al, 2011, <papid> W11-1804 </papid>respectively).</citsent>
<aftsection>
<nextsent>note that while id is the smallest and would seem like it would have the fewest folds, we combined the training data of id with the training and development data from ge.
</nextsent>
<nextsent>to produce predictions over the test data, we combined the training folds with 6 development folds forge, 4 for epi, and 1 for id.
</nextsent>
<nextsent>table 1 gives an overview of our results on the test sets for all four tasks we submitted to.
</nextsent>
<nextsent>note that for the epi and id tasks we show the core metric next to the official full metric.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI613">
<title id=" W11-1808.xml">model combination for event extraction in bionlp 2011 </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>this helps to avoid scenario where the stacking model learns to relyon high accuracy at training time that cannot be matched at test time.
</prevsent>
<prevsent>note that, unlike stanfords individual submission in this shared task, the stacked models in this paper do not include the stanford reranker.
</prevsent>
</prevsection>
<citsent citstr=" W11-1804 ">
this is because it would have required making reranker model for each cross validation fold.we made 19 cross validation training folds forge nia (ge) (kim et al, 2011<papid> W11-1802 </papid>b), 12 for epi genetics (epi), and 17 for infectious diseases (id) (kim et al., 2011<papid> W11-1802 </papid>b; ohta et al, 2011; <papid> W11-1803 </papid>pyysalo et al, 2011, <papid> W11-1804 </papid>respectively).</citsent>
<aftsection>
<nextsent>note that while id is the smallest and would seem like it would have the fewest folds, we combined the training data of id with the training and development data from ge.
</nextsent>
<nextsent>to produce predictions over the test data, we combined the training folds with 6 development folds forge, 4 for epi, and 1 for id.
</nextsent>
<nextsent>table 1 gives an overview of our results on the test sets for all four tasks we submitted to.
</nextsent>
<nextsent>note that for the epi and id tasks we show the core metric next to the official full metric.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI614">
<title id=" W11-2108.xml">approximating a deep syntactic metric for mt evaluation and tuning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in section 3 we propose four methods which approximate t-lemmas and sem poses without the deep syntactic analysis.
</prevsent>
<prevsent>these methods require only part-of-speech tagging and therefore they are not only faster but also easier to adapt for other languages, not requiring more advanced linguistic tools.
</prevsent>
</prevsection>
<citsent citstr=" W10-1705 ">
gimenez and marquez (2007) and bojar et al (2010) <papid> W10-1705 </papid>used different formulas to calculate the final overlapping.1 in section 4, we examine variations of the formula, adding one version of our own.by combining one of the approximation techniques with one of the overlapping formulas, we ob 1in fact, gimenez and marquez (2007) released two versions of the paper.</citsent>
<aftsection>
<nextsent>both of them are nearly identical except for the formula for overlapping, so we asked the authors which of the two versions is correct.
</nextsent>
<nextsent>it turns out that bojar et al (2010), <papid> W10-1705 </papid>unaware of the second version of the paper, used the wrong one but still obtained good results.</nextsent>
<nextsent>we therefore (re-)examine both versions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI618">
<title id=" W11-2108.xml">approximating a deep syntactic metric for mt evaluation and tuning </title>
<section> approximations of sempos.  </section>
<citcontext>
<prevsection>
<prevsent>denot, n.pron.indef.
</prevsent>
<prevsent>3.4 t-lemma and sempos tagging our last approximation method differs lot from the previous three approximations.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
we use the sequence labeling algorithm (collins, 2002) <papid> W02-1001 </papid>as implemented in featurama2 to choose the t-lemma and sempos tag.</citsent>
<aftsection>
<nextsent>the czeng corpus (bojar and zabokrtsky?, 2009) serves to train two taggers: one for czech and 2http://sourceforge.net/projects/ featurama/ 94 tag r. fr.
</nextsent>
<nextsent>min.
</nextsent>
<nextsent>max.
</nextsent>
<nextsent>avg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI619">
<title id=" W11-2108.xml">approximating a deep syntactic metric for mt evaluation and tuning </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the first two columns denote the combination of an approximation method and an overlapping formula.
</prevsent>
<prevsent>for conciseness, we report only the minimum, maximum and average value among correlations of all test sets.to compare metrics to original sempos, theta ble includes non-approximated variant orig where the t-lemmas and sem poses are assigned by the tectomt framework.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for the purposes of comparison, we also report the correlations of bleu (papineni et al, 2002) <papid> P02-1040 </papid>and linear combination of ap reduction overlapping min.</citsent>
<aftsection>
<nextsent>max.
</nextsent>
<nextsent>avg.
</nextsent>
<nextsent>approx-restr cap-macro 0.400 0.800 0.608 tagger cap-macro 0.143 0.800 0.428 orig cap-macro 0.143 0.800 0.423 approx-restr cap-micro 0.086 0.769 0.413 tagger cap-micro 0.086 0.769 0.413 orig cap-micro 0.086 0.741 0.406 approx-stopwords cap-micro 0.086 0.790 0.368 approx cap-micro 0.086 0.734 0.354 approx-stopwords cap-macro 0.086 0.503 0.347 sempos-bleu 0.086 0.676 0.340 approx cap-macro 0.086 0.469 0.338 tagger boost-micro 0.086 0.664 0.337 bleu 0.029 0.490 0.279 orig boost-micro -0.200 0.692 0.273 approx-stopwords boost-micro -0.200 0.685 0.271 approx boost-micro -0.200 0.664 0.266 approx-restr boost-micro -0.200 0.664 0.266table 6: metric correlations for czech as target language prox+cap-micro and bleu (even weights) under the name sempos-bleu since this metric was used in tunable metric task (section 6).
</nextsent>
<nextsent>the best performing metric is the combination of approximation approx and overlapping capmicro.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI620">
<title id=" W11-2108.xml">approximating a deep syntactic metric for mt evaluation and tuning </title>
<section> tunable metric wmt11 shared task.  </section>
<citcontext>
<prevsection>
<prevsent>we see that the best correlation arises when no words are thrown away.
</prevsent>
<prevsent>one possible explanation is that auxiliary words are recognized by the morphological tag well enough anyway and stop words lists remove also important content words, decreasing the overall accuracy of the overlapping.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the goal of the tunable metric task in wmt11 was to use the custom metric in mert optimization (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>the target language was english.
</nextsent>
<nextsent>we choose approx + cap-micro since this combination correlates best with human judgments.
</nextsent>
<nextsent>based on the experience of bojar and kos (2010),we combine this metric with bleu.
</nextsent>
<nextsent>in our opinion, the sempos metric and its variants alone areare good at comparing systems?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI621">
<title id=" W11-2148.xml">the value of monolingual crowdsourcing in a real world translation scenario simulation using haitian creole emergency sms messages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>what about scenario, e.g. the march 2011 earthquake and tsunami in japan, in which there are many people worldwide who wishto help but are not fluent in both the source and target languages?
</prevsent>
<prevsent>for the last few years, we have been exploring the idea of monolingual crowdsourcing for translation?
</prevsent>
</prevsection>
<citsent citstr=" W10-0735 ">
that is, technology-assisted collaborative translation involving crowds of participants who know only the source or target language (buzek et al , 2010; <papid> W10-0735 </papid>hu, 2009; hu et al , 2010; hu et al , 2011; resniket al , 2010).<papid> D10-1013 </papid></citsent>
<aftsection>
<nextsent>our monotrans2 framework has previously shown very promising results on childrensbooks: on test set where google translate produced correct translations for only 10% of the input sentences, monolingual german and spanish speakers using our framework produced translations that were fully correct (as judged by two independent bilinguals) nearly 70% of the time (hu et al , 2011).
</nextsent>
<nextsent>we used the same framework in the wmt 2011haitian-english translation task.
</nextsent>
<nextsent>for this experiment, we hired haitian creole speakers located in haiti, and recruited english speakers located in the u.s., to serve as the monolingual crowds.
</nextsent>
<nextsent>monotrans2 is translation system that combines machine translation (mt) with human computation(quinn et al , 2011) using two crowds?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI622">
<title id=" W11-2148.xml">the value of monolingual crowdsourcing in a real world translation scenario simulation using haitian creole emergency sms messages </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>what about scenario, e.g. the march 2011 earthquake and tsunami in japan, in which there are many people worldwide who wishto help but are not fluent in both the source and target languages?
</prevsent>
<prevsent>for the last few years, we have been exploring the idea of monolingual crowdsourcing for translation?
</prevsent>
</prevsection>
<citsent citstr=" D10-1013 ">
that is, technology-assisted collaborative translation involving crowds of participants who know only the source or target language (buzek et al , 2010; <papid> W10-0735 </papid>hu, 2009; hu et al , 2010; hu et al , 2011; resniket al , 2010).<papid> D10-1013 </papid></citsent>
<aftsection>
<nextsent>our monotrans2 framework has previously shown very promising results on childrensbooks: on test set where google translate produced correct translations for only 10% of the input sentences, monolingual german and spanish speakers using our framework produced translations that were fully correct (as judged by two independent bilinguals) nearly 70% of the time (hu et al , 2011).
</nextsent>
<nextsent>we used the same framework in the wmt 2011haitian-english translation task.
</nextsent>
<nextsent>for this experiment, we hired haitian creole speakers located in haiti, and recruited english speakers located in the u.s., to serve as the monolingual crowds.
</nextsent>
<nextsent>monotrans2 is translation system that combines machine translation (mt) with human computation(quinn et al , 2011) using two crowds?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI623">
<title id=" W11-2148.xml">the value of monolingual crowdsourcing in a real world translation scenario simulation using haitian creole emergency sms messages </title>
<section> system.  </section>
<citcontext>
<prevsection>
<prevsent>the english speakers then can take any of the following actions for candidate translations: ? mark phrase in the candidate as an error ? suggest new translation candidate ? vote candidates up or down identifying likely errors and voting for candidates are things monolinguals can do reasonably well: even without knowing the intended interpretation, you can often identify when some part of sentence doesnt make sense, or when one sentence seems more fluent or plausible than another.
</prevsent>
<prevsent>sometimes rather than identifying errors, it is easier to suggest an entirely new translation candidate based on the information available on the target side, variant of monolingual post-editing (callison-burch et al , 2004).any new translation candidates are then back translated into haitian creole, and any spans marked as translation errors are projected back to identify the corresponding spans in the source sentence, using word alignments as the bridge (cf.
</prevsent>
</prevsection>
<citsent citstr=" P02-1050 ">
hwa et al (2002), <papid> P02-1050 </papid>yarowsky et al  (2001)).<papid> H01-1035 </papid>2 the haitian creole speakers can then: ? rephrase the entire source sentence (cf.</citsent>
<aftsection>
<nextsent>(morita and ishida, 2009)) ? explain?
</nextsent>
<nextsent>spans marked as errors?
</nextsent>
<nextsent>vote candidates up or down (based on the back translation)source speakers can explain?
</nextsent>
<nextsent>error spans by offering different way of phrasing that piece of the source sentence (resnik et al , 2010), <papid> D10-1013 </papid>in order to produce new source sentence, or by annotating the spans with images (e.g. via google image search) or web links (e.g. to wikipedia).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI624">
<title id=" W11-2148.xml">the value of monolingual crowdsourcing in a real world translation scenario simulation using haitian creole emergency sms messages </title>
<section> system.  </section>
<citcontext>
<prevsection>
<prevsent>the english speakers then can take any of the following actions for candidate translations: ? mark phrase in the candidate as an error ? suggest new translation candidate ? vote candidates up or down identifying likely errors and voting for candidates are things monolinguals can do reasonably well: even without knowing the intended interpretation, you can often identify when some part of sentence doesnt make sense, or when one sentence seems more fluent or plausible than another.
</prevsent>
<prevsent>sometimes rather than identifying errors, it is easier to suggest an entirely new translation candidate based on the information available on the target side, variant of monolingual post-editing (callison-burch et al , 2004).any new translation candidates are then back translated into haitian creole, and any spans marked as translation errors are projected back to identify the corresponding spans in the source sentence, using word alignments as the bridge (cf.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
hwa et al (2002), <papid> P02-1050 </papid>yarowsky et al  (2001)).<papid> H01-1035 </papid>2 the haitian creole speakers can then: ? rephrase the entire source sentence (cf.</citsent>
<aftsection>
<nextsent>(morita and ishida, 2009)) ? explain?
</nextsent>
<nextsent>spans marked as errors?
</nextsent>
<nextsent>vote candidates up or down (based on the back translation)source speakers can explain?
</nextsent>
<nextsent>error spans by offering different way of phrasing that piece of the source sentence (resnik et al , 2010), <papid> D10-1013 </papid>in order to produce new source sentence, or by annotating the spans with images (e.g. via google image search) or web links (e.g. to wikipedia).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI626">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task has relevance to cognitive scientists and linguists attempting to gauge the lear nabil ity of natural language by human children, and also natural language processing researchers who seek syntactic representations for languages with few linguistic resources.
</prevsent>
<prevsent>grammar learning has been popular in previous challenges.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
for example the conll shared tasks in 2006 and 2007 (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivreet al, 2007) <papid> D07-1096 </papid>involved supervised learning of dependency parsers across wide range of different languages.</citsent>
<aftsection>
<nextsent>our challenge has many similarities to these, in that we focus on dependency grammars,however we seek to evaluate unsupervised algorithms only using syntactically annotated data for evaluation and not for training.
</nextsent>
<nextsent>additionally we also consider the related task of part-of-speech (pos) induction, and the next logical challenge: the joint task of pos and dependency induction.
</nextsent>
<nextsent>other related challenges can be found in the formal grammar community (e.g., the omphalos1 competition)in which competitors seek to learn synthetic languages.
</nextsent>
<nextsent>in contrast we seek to model natural language text, which entails many different challenges.research into unsupervised grammar and pos induction holds considerable promise, although current approaches are still long way from solving the general problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI627">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the task has relevance to cognitive scientists and linguists attempting to gauge the lear nabil ity of natural language by human children, and also natural language processing researchers who seek syntactic representations for languages with few linguistic resources.
</prevsent>
<prevsent>grammar learning has been popular in previous challenges.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
for example the conll shared tasks in 2006 and 2007 (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivreet al, 2007) <papid> D07-1096 </papid>involved supervised learning of dependency parsers across wide range of different languages.</citsent>
<aftsection>
<nextsent>our challenge has many similarities to these, in that we focus on dependency grammars,however we seek to evaluate unsupervised algorithms only using syntactically annotated data for evaluation and not for training.
</nextsent>
<nextsent>additionally we also consider the related task of part-of-speech (pos) induction, and the next logical challenge: the joint task of pos and dependency induction.
</nextsent>
<nextsent>other related challenges can be found in the formal grammar community (e.g., the omphalos1 competition)in which competitors seek to learn synthetic languages.
</nextsent>
<nextsent>in contrast we seek to model natural language text, which entails many different challenges.research into unsupervised grammar and pos induction holds considerable promise, although current approaches are still long way from solving the general problem.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI628">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>other related challenges can be found in the formal grammar community (e.g., the omphalos1 competition)in which competitors seek to learn synthetic languages.
</prevsent>
<prevsent>in contrast we seek to model natural language text, which entails many different challenges.research into unsupervised grammar and pos induction holds considerable promise, although current approaches are still long way from solving the general problem.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
for example, the majority of recent research into dependency grammar induction has adopted the evaluation setting of klein and manning (2004) <papid> P04-1061 </papid>who learn grammars on strings of pos tags, rather than on words themselves.</citsent>
<aftsection>
<nextsent>one aim of this challenge is to popularise the more difficult and ambitious task of inducing grammars directly from text, which can be viewed as integrating the pos and grammar induction tasks.
</nextsent>
<nextsent>a second aim is to foster grammar and pos induction research across wider variety of languages, and improving the standard of evaluation.
</nextsent>
<nextsent>we have collated data from existing treebanks ina variety of different languages, domains and linguistic formalisms.
</nextsent>
<nextsent>this gives diverse range of 1see http://www.irisa.fr/omphalos 64data upon which to test induction algorithms, yielding deeper insight into their strengths and shortcomings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI629">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>predictions given that often many different analyses are linguistically plausible, e.g., the choice of whether determiners or nouns should head noun phrases, or how to represent coordination.
</prevsent>
<prevsent>simply comparing against single gold standard often results in poor reported performance because the model has discovered different analysis to that used when annotating the treebank.
</prevsent>
</prevsection>
<citsent citstr=" P11-1067 ">
for this reason it has been popular to use lenient measures for comparing predicted trees to the treebank gold standard trees, such as undirected accuracy and the neutral edge distance (schwartz et al., 2011).<papid> P11-1067 </papid></citsent>
<aftsection>
<nextsent>as well as evaluating using these popular metrics, we also propose new method of evaluation which is also lenient in that it rewards different typesof linguistically plausible output, but requires consistency in the output, something the previous methods cannot do.the paper is organised as follows.
</nextsent>
<nextsent>section 2 describes the tasks and our data format and section 3outlines the different treebanks used for the challenge.
</nextsent>
<nextsent>the baselines, our own benchmark systems and the competitors entries are described in section 5.
</nextsent>
<nextsent>in section 6 we present and analyse the results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI630">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>the first is the many-to-one metric (m-1) (also known as cluster purity), which is widely used for cluster evaluation as well as evaluation of pos induction.
</prevsent>
<prevsent>this metric assigns each word cluster to its most common tag, and then measures the proportion of correctly tagged words.
</prevsent>
</prevsection>
<citsent citstr=" N06-1041 ">
the second metric is the one-to-one mapping (1-1), constrained version of many-to-one mapping in which each predicted tag is associated with only one gold-standard tag andvice versa (haghighi and klein, 2006).<papid> N06-1041 </papid></citsent>
<aftsection>
<nextsent>word clusters are assigned greedily to tags, and in the event of there being more word classes than tags, some word classes will be left unassigned.
</nextsent>
<nextsent>another metric that was used is variation of information (vi)(meila, 2003), which is based the conditional entropy of between the two different clusterings (johnson, 2007).<papid> D07-1031 </papid></nextsent>
<nextsent>lastly, we use the v-measure (vm) metric (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>which is an other entropy-based measure, but defined in terms of f score to balance precision and recall terms (we use equal weighting of the two factors).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI631">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>the second metric is the one-to-one mapping (1-1), constrained version of many-to-one mapping in which each predicted tag is associated with only one gold-standard tag andvice versa (haghighi and klein, 2006).<papid> N06-1041 </papid></prevsent>
<prevsent>word clusters are assigned greedily to tags, and in the event of there being more word classes than tags, some word classes will be left unassigned.</prevsent>
</prevsection>
<citsent citstr=" D07-1031 ">
another metric that was used is variation of information (vi)(meila, 2003), which is based the conditional entropy of between the two different clusterings (johnson, 2007).<papid> D07-1031 </papid></citsent>
<aftsection>
<nextsent>lastly, we use the v-measure (vm) metric (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>which is an other entropy-based measure, but defined in terms of f score to balance precision and recall terms (we use equal weighting of the two factors).</nextsent>
<nextsent>please see christodoulopoulos et al (2010) <papid> D10-1056 </papid>for further details about these metrics.3 for these metrics, higher score is better, with the exception of vi.for all these metrics, the induced tags are evaluated against the universal pos tags, as this means there are consistent number of tags across the lan guages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI632">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>word clusters are assigned greedily to tags, and in the event of there being more word classes than tags, some word classes will be left unassigned.
</prevsent>
<prevsent>another metric that was used is variation of information (vi)(meila, 2003), which is based the conditional entropy of between the two different clusterings (johnson, 2007).<papid> D07-1031 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
lastly, we use the v-measure (vm) metric (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>which is an other entropy-based measure, but defined in terms of f score to balance precision and recall terms (we use equal weighting of the two factors).</citsent>
<aftsection>
<nextsent>please see christodoulopoulos et al (2010) <papid> D10-1056 </papid>for further details about these metrics.3 for these metrics, higher score is better, with the exception of vi.for all these metrics, the induced tags are evaluated against the universal pos tags, as this means there are consistent number of tags across the lan guages.</nextsent>
<nextsent>using these metrics, the results will vary as result of predicting different number of tags (inparticular, more tags will mean higher score for 1, and the converse is true for 1-1).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI633">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>another metric that was used is variation of information (vi)(meila, 2003), which is based the conditional entropy of between the two different clusterings (johnson, 2007).<papid> D07-1031 </papid></prevsent>
<prevsent>lastly, we use the v-measure (vm) metric (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>which is an other entropy-based measure, but defined in terms of f score to balance precision and recall terms (we use equal weighting of the two factors).</prevsent>
</prevsection>
<citsent citstr=" D10-1056 ">
please see christodoulopoulos et al (2010) <papid> D10-1056 </papid>for further details about these metrics.3 for these metrics, higher score is better, with the exception of vi.for all these metrics, the induced tags are evaluated against the universal pos tags, as this means there are consistent number of tags across the lan guages.</citsent>
<aftsection>
<nextsent>using these metrics, the results will vary as result of predicting different number of tags (inparticular, more tags will mean higher score for 1, and the converse is true for 1-1).
</nextsent>
<nextsent>however, using the universal pos tags, we think will make results less sensitive to large differences in pos inventory between languages (such as for the dutch dataset).
</nextsent>
<nextsent>2.3 dependency induction.
</nextsent>
<nextsent>for the dependency induction track, the training data consisted of the original treebank data, but without dependency annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI635">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> treebanks.  </section>
<citcontext>
<prevsection>
<prevsent>czech the prague dependency treebank 2.0 (bohmova?
</prevsent>
<prevsent>et al, 2001).7 danish the copenhagen dependency treebank version 2 (buch-kromann et al, 2007).
</prevsent>
</prevsection>
<citsent citstr=" W07-0604 ">
english the childes us/brown sub corpus (sagae et al, 2007).<papid> W07-0604 </papid></citsent>
<aftsection>
<nextsent>slovene the jos500k treebank (erjavec et al., 2010).
</nextsent>
<nextsent>8 swedish the tal banken treebank (nivre et al, 2006).
</nextsent>
<nextsent>the conversion of each of these treebanks was quite straightforward as they were already annotated for dependencies.
</nextsent>
<nextsent>moreover, many of these corpora had been used previously in the conll 2006 and 2007 shared tasks, and therefor ewe were able to reuse this data and/or their conversion scripts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI637">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> treebanks.  </section>
<citcontext>
<prevsection>
<prevsent>our testing and development sets were drawn from the first 15 eve files which were manually annotated for de-.
</prevsent>
<prevsent>pendency structure.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the rest of the corpus, which had not been manually annotated for syntax, was merged to form the training set.phrase-structure treebanks as well as dependency treebanks, we used three different phrase structure treebanks: the dutch alpino treebank (bouma et al, 2000), the english penn treebankv3 (marcus et al, 1993),<papid> J93-2004 </papid>9 and the portuguese flo resta sinta?(c)tica treebank (afonso et al, 2002).</citsent>
<aftsection>
<nextsent>asthese treebanks do not explicitly mark dependencies, we automatically extracted these using head finding heuristics.
</nextsent>
<nextsent>thankfully the difficult work of creating such scripts has already been done as part of the conll shared tasks.
</nextsent>
<nextsent>we have reused their scripts to create dependency representations ofthese treebanks, before converting into our file format and augmenting with upos annotation.
</nextsent>
<nextsent>in the case of dutch, we have reused the same conll 2006 data; note that this dataset includes predicted part-of-speech rather than gold standard annotation (buchholz and marsi, 2006).<papid> W06-2920 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI639">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> treebanks.  </section>
<citcontext>
<prevsection>
<prevsent>67 ar cs da en-childes en-ptb eu nl pt sl sv annotation d d d p d training data tokens 106.6k 1.2m 68.5k 312.8k 1.1m 124.7k 192.2k 196.4k 193k 184.6k sentences 2.8k 68.5k 3.6k 57.4k 45.4k 9.1k 13k 8.7k 9.4k 10.7k tokens/sent 38.4 17.1 18.8 5.5 23.9 13.7 14.8 22.6 20.5 17.3 cpostag 15 12 25 31 31 16 13 16 13 41 postag 21 61 141 76 45 50 300 22 31 41 feats 22 75 338 29 0 269 310 146 46 0 development data tokens 5.1k 159k 17k 25.3k 32.9k 12.6k 2.9k 10.3k 20.2k 6.9k sentences 139 9.3k 1k 5k 1.3k 1k 386 400 1k 389 tokens/sent 36.8 17.1 17 5.1 24.4 12.5 7.4 25.8 20.2 17.6 % new words 27.5 26 49.8 9.8 11.4 46.1 18.8 27.5 38.7 13.8 test data tokens 5.1k 173.6k 14.7k 28.4k 56.7k 14.3k 5.6k 5.9k 22.6k 5.7k sentences 131 10.1k 1k 5.2k 2.4k 1.1k 386 288 1k 389 tokens/sent 39.1 17.1 14.7 5.4 23.5 12.7 14.5 20.4 22.6 14.5 % new words 24.3 25.3 43.7 9 12.1 51.5 40.5 25.2 37.1 34.6 table 1: properties of the treebanks.
</prevsent>
<prevsent>we report the linguistic annotation method (dependency vs. phrase-structure), the size of each treebank, the number of types for the different granularities of part-of-speech tags and morphological features (note that upos has fixed set of 12 tags), and the proportion of word types that were not present in training.
</prevsent>
</prevsection>
<citsent citstr=" P07-1031 ">
the treebank to include np-internal structure usingvadas and currans annotations (vadas and curran, 2007), <papid> P07-1031 </papid>which was then converted to dependency structures using the penn-converter11 script(johansson and nugues, 2007).</citsent>
<aftsection>
<nextsent>this tool has number of options controlling the linguistic decisions in converting from phrase-structure to dependency trees, e.g., the treatment of coordination.
</nextsent>
<nextsent>we extracted five versions of the treebank, each encoding each different sets of linguistic assumptions (tsarfaty et al, 2011).<papid> D11-1036 </papid>12 these are denoted default, old lth, conll-2007, functional and lexical; for the main results we used the standard options, we also report separately evaluations using each of the five variants.</nextsent>
<nextsent>the treebank was partitioned into training (sections 0-22), development (sec.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI640">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> treebanks.  </section>
<citcontext>
<prevsection>
<prevsent>the treebank to include np-internal structure usingvadas and currans annotations (vadas and curran, 2007), <papid> P07-1031 </papid>which was then converted to dependency structures using the penn-converter11 script(johansson and nugues, 2007).</prevsent>
<prevsent>this tool has number of options controlling the linguistic decisions in converting from phrase-structure to dependency trees, e.g., the treatment of coordination.</prevsent>
</prevsection>
<citsent citstr=" D11-1036 ">
we extracted five versions of the treebank, each encoding each different sets of linguistic assumptions (tsarfaty et al, 2011).<papid> D11-1036 </papid>12 these are denoted default, old lth, conll-2007, functional and lexical; for the main results we used the standard options, we also report separately evaluations using each of the five variants.</citsent>
<aftsection>
<nextsent>the treebank was partitioned into training (sections 0-22), development (sec.
</nextsent>
<nextsent>24) and testing sets (sec.
</nextsent>
<nextsent>23).
</nextsent>
<nextsent>a number of standard baselines and previously published benchmark systems were implemented for each task in order to place the submitted systems in context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI643">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> baselines and benchmarks.  </section>
<citcontext>
<prevsection>
<prevsent>we provide results for this model trained on each of the coarse (dmvc), fine(dmvp), and universal (dmvu) pos tag sets, all ini tial ised with the original harmonic initialiser.
</prevsent>
<prevsent>as further baseline we also evaluated the dependency trees resulting from directly using the harmonic ini tialiser without any training (h).
</prevsent>
</prevsection>
<citsent citstr=" D10-1117 ">
as strong benchmark we include the results ofthe non-parametric bayesian model previously published in blunsom and cohn (2010) (<papid> D10-1117 </papid>bc).</citsent>
<aftsection>
<nextsent>the stated results are for the un lexicalised model described in that paper where the final analysis is formed by choosing the maximum marginal probability dependency links estimated from forty independent gibbs sampler runs.
</nextsent>
<nextsent>for part-of-speech tagging we include results from an implementation of the brown word clustering algorithm (brown et al, 1992) (<papid> J92-4003 </papid>bc,p,u), and the mkcls tool written by franz och (och, 1999) (<papid> E99-1010 </papid>mkc,p,u).</nextsent>
<nextsent>both of these benchmarks were trained with the number of classes matching the number in the gold standard of each of the tagsets in turn: coarse (c), fine (p), and universal (u).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI645">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> baselines and benchmarks.  </section>
<citcontext>
<prevsection>
<prevsent>as strong benchmark we include the results ofthe non-parametric bayesian model previously published in blunsom and cohn (2010) (<papid> D10-1117 </papid>bc).</prevsent>
<prevsent>the stated results are for the un lexicalised model described in that paper where the final analysis is formed by choosing the maximum marginal probability dependency links estimated from forty independent gibbs sampler runs.</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
for part-of-speech tagging we include results from an implementation of the brown word clustering algorithm (brown et al, 1992) (<papid> J92-4003 </papid>bc,p,u), and the mkcls tool written by franz och (och, 1999) (<papid> E99-1010 </papid>mkc,p,u).</citsent>
<aftsection>
<nextsent>both of these benchmarks were trained with the number of classes matching the number in the gold standard of each of the tagsets in turn: coarse (c), fine (p), and universal (u).
</nextsent>
<nextsent>a notable 68 property of both of these word class models is that they enforce one-tag-per-type restriction that ensures there is one-to-one mapping between word types and classes.for pos tagging we also provide benchmark results from two previously published models.
</nextsent>
<nextsent>the first of these is the pitman-yor hmm model described in (blunsom and cohn, 2011), <papid> P11-1087 </papid>which incorporates ta one-tag-per-type restriction (bc).</nextsent>
<nextsent>this model was trained with the same number of tags as in the gold standard fine tag set for each corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI646">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> baselines and benchmarks.  </section>
<citcontext>
<prevsection>
<prevsent>as strong benchmark we include the results ofthe non-parametric bayesian model previously published in blunsom and cohn (2010) (<papid> D10-1117 </papid>bc).</prevsent>
<prevsent>the stated results are for the un lexicalised model described in that paper where the final analysis is formed by choosing the maximum marginal probability dependency links estimated from forty independent gibbs sampler runs.</prevsent>
</prevsection>
<citsent citstr=" E99-1010 ">
for part-of-speech tagging we include results from an implementation of the brown word clustering algorithm (brown et al, 1992) (<papid> J92-4003 </papid>bc,p,u), and the mkcls tool written by franz och (och, 1999) (<papid> E99-1010 </papid>mkc,p,u).</citsent>
<aftsection>
<nextsent>both of these benchmarks were trained with the number of classes matching the number in the gold standard of each of the tagsets in turn: coarse (c), fine (p), and universal (u).
</nextsent>
<nextsent>a notable 68 property of both of these word class models is that they enforce one-tag-per-type restriction that ensures there is one-to-one mapping between word types and classes.for pos tagging we also provide benchmark results from two previously published models.
</nextsent>
<nextsent>the first of these is the pitman-yor hmm model described in (blunsom and cohn, 2011), <papid> P11-1087 </papid>which incorporates ta one-tag-per-type restriction (bc).</nextsent>
<nextsent>this model was trained with the same number of tags as in the gold standard fine tag set for each corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI647">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> baselines and benchmarks.  </section>
<citcontext>
<prevsection>
<prevsent>both of these benchmarks were trained with the number of classes matching the number in the gold standard of each of the tagsets in turn: coarse (c), fine (p), and universal (u).
</prevsent>
<prevsent>a notable 68 property of both of these word class models is that they enforce one-tag-per-type restriction that ensures there is one-to-one mapping between word types and classes.for pos tagging we also provide benchmark results from two previously published models.
</prevsent>
</prevsection>
<citsent citstr=" P11-1087 ">
the first of these is the pitman-yor hmm model described in (blunsom and cohn, 2011), <papid> P11-1087 </papid>which incorporates ta one-tag-per-type restriction (bc).</citsent>
<aftsection>
<nextsent>this model was trained with the same number of tags as in the gold standard fine tag set for each corpus.
</nextsent>
<nextsent>the second benchmark is the hmm with sparsity constraints trained using posterior regularization (pr) described in (graca et al, 2011).
</nextsent>
<nextsent>in this mode lthe hmm emission probabilitiy distribution are estimated using small maximum entropy models (features set described in the original paper).
</nextsent>
<nextsent>the models were trained for 200 iterations of pr using both the same number of hidden states as the coarse gc and universal gu gold standard.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI648">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> submissions.  </section>
<citcontext>
<prevsection>
<prevsent>in the following sections we summarise the approaches taken by the systems submitted for each task.
</prevsent>
<prevsent>5.1 part-of-speech induction.
</prevsent>
</prevsection>
<citsent citstr=" W12-1913 ">
the part-of-speech induction challenge received two submission, (chrupaa, 2012; christodoulopoulos etal., 2012).<papid> W12-1913 </papid></citsent>
<aftsection>
<nextsent>both of these submissions based their induction systems on lda inspired models for clustering word types by the contexts in which they appear.
</nextsent>
<nextsent>notably, the strongest of the provided benchmarks and the two submissions modelled part-of-speech tags at the type level, thus restricting all tokens of given word type to share the same tag.
</nextsent>
<nextsent>though clearly out of step with the gold standard tagging, this one-tag-per-type restriction has previously been shown to be crude but effective way of regularisingmodels towards good solution.
</nextsent>
<nextsent>below we summarise the approach of each submission, identified by the surname of the first author on the submitted system description.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI651">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> submissions.  </section>
<citcontext>
<prevsection>
<prevsent>the first stage usedan lda style probabilistic model to induce distribution over possible tags forgiven word type.these distributions were then hierarchically clustered and the final tags selected using the prefix of the path from the root node to the word type in the cluster tree.
</prevsent>
<prevsent>the length of the prefixes, and thus the number of tags, was tuned on the labelled development data.
</prevsent>
</prevsection>
<citsent citstr=" D11-1059 ">
the system of christodoulopoulos et al (2012) <papid> W12-1913 </papid>was based upon an lda type model which included both contexts and other conditionally independent features (christodoulopoulos et al, 2011).<papid> D11-1059 </papid></citsent>
<aftsection>
<nextsent>this base system was then iterated with dmv system and with the resultant dependencies being repeatedly fedback into the pos model as features.
</nextsent>
<nextsent>this submission is notable for being one of the first to attempt joint pos and dependency induction rather than taking pipeline approach.
</nextsent>
<nextsent>5.2 dependency induction.
</nextsent>
<nextsent>the dependency parsing task saw variety of approaches with only couple based on the previously dominant dmv system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI652">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> submissions.  </section>
<citcontext>
<prevsection>
<prevsent>obviously the merits of such supervision would depend on the desired application for the induced parser.
</prevsent>
<prevsent>the direct comparison of models which include form of universal prior syntactic information with those that dont does permit interesting development linguistic questions to be explored in future.
</prevsent>
</prevsection>
<citsent citstr=" W12-1912 ">
bisk and hockenmaier (2012) <papid> W12-1912 </papid>chose to induce restricted form of combinatory categorial grammar (ccg), the parses of which were then mapped to dependency structures.</citsent>
<aftsection>
<nextsent>restrictions on head-childdependencies were encoded in the allowable cate 69 gories for each pos tag and the heads of sentences.
</nextsent>
<nextsent>key features of their approach were maximum likelihood objective function and an iterative procedure for generating composite categories from simple ones.
</nextsent>
<nextsent>such composite categories allow the pa rameterisation of larger units than just head-childdependencies, improving over the more limited conditioning of dmv.
</nextsent>
<nextsent>maracek and zabokrtsky?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI653">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> submissions.  </section>
<citcontext>
<prevsection>
<prevsent>wikipedia articles were used to quantify the reducibility of word types, the degree to which the word could be removed from sentence and grammaticality maintained.
</prevsent>
<prevsent>this metric was then used, along with model of child fertility and dependency distance, within probabilistic model.
</prevsent>
</prevsection>
<citsent citstr=" W12-1910 ">
inference was performed by using local gibbs sampler to approximate the marginal distribution over head-child links.sgaard (2012) <papid> W12-1910 </papid>presented two model-free heuristic algorithms.</citsent>
<aftsection>
<nextsent>the first was based on heuristicallyadding dependency edges based on rules such as adjacency, function words, and morphology.
</nextsent>
<nextsent>the resulting structure is then run through page rank algorithm and another heuristic is used to select tree from the resulting ranked dependency edges.
</nextsent>
<nextsent>the second approach takes the universal rules of naseem et al (2010) <papid> D10-1120 </papid>but rather than estimating probabilistic model with these rules, rule based heuristic is used to select parse rather.</nextsent>
<nextsent>this second model-free approach in particular provides strong baseline for probabilistic models built upon hand-specified dependency rules.tu (2012) <papid> W12-1915 </papid>described system based on an extended dmv model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI654">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> submissions.  </section>
<citcontext>
<prevsection>
<prevsent>the first was based on heuristicallyadding dependency edges based on rules such as adjacency, function words, and morphology.
</prevsent>
<prevsent>the resulting structure is then run through page rank algorithm and another heuristic is used to select tree from the resulting ranked dependency edges.
</prevsent>
</prevsection>
<citsent citstr=" D10-1120 ">
the second approach takes the universal rules of naseem et al (2010) <papid> D10-1120 </papid>but rather than estimating probabilistic model with these rules, rule based heuristic is used to select parse rather.</citsent>
<aftsection>
<nextsent>this second model-free approach in particular provides strong baseline for probabilistic models built upon hand-specified dependency rules.tu (2012) <papid> W12-1915 </papid>described system based on an extended dmv model.</nextsent>
<nextsent>their work focussed on the exploration of multiple forms of regular isation, including dirichlet priors and posterior regular isation, to favour both sparse conditional distributions and low ambiguity in the induced parse charts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI655">
<title id=" W12-1909.xml">the pascal challenge on grammar induction </title>
<section> submissions.  </section>
<citcontext>
<prevsection>
<prevsent>the resulting structure is then run through page rank algorithm and another heuristic is used to select tree from the resulting ranked dependency edges.
</prevsent>
<prevsent>the second approach takes the universal rules of naseem et al (2010) <papid> D10-1120 </papid>but rather than estimating probabilistic model with these rules, rule based heuristic is used to select parse rather.</prevsent>
</prevsection>
<citsent citstr=" W12-1915 ">
this second model-free approach in particular provides strong baseline for probabilistic models built upon hand-specified dependency rules.tu (2012) <papid> W12-1915 </papid>described system based on an extended dmv model.</citsent>
<aftsection>
<nextsent>their work focussed on the exploration of multiple forms of regular isation, including dirichlet priors and posterior regular isation, to favour both sparse conditional distributions and low ambiguity in the induced parse charts.
</nextsent>
<nextsent>while many previous works have included sparse pri orson the conditional head-child distributions the additional regular isation of the ambiguity over parse trees is novel and interesting addition.
</nextsent>
<nextsent>the labelled development sets were employed to both select between models employing different regula risa tion, and to tune model parameters.
</nextsent>
<nextsent>5.3 pos and dependency induction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI664">
<title id=" W12-0215.xml">using context and phonetic features in models of etymological sound change </title>
<section> data and related work.  </section>
<citcontext>
<prevsection>
<prevsent>word-forms, which may contain extraneous morphological material, whereas starling data is mostly stemmed.one traditional arrangement of the uralic languages1 is shown in figure 1.
</prevsent>
<prevsent>we model etymo logical processes using these uralic datasets.
</prevsent>
</prevsection>
<citsent citstr=" C02-1016 ">
the methods in (kondrak, 2002) <papid> C02-1016 </papid>learn regular one-to-one sound correspondences between pairs of related languages in the data.</citsent>
<aftsection>
<nextsent>the methods in (kondrak, 2003; wettig et al , 2011) find more complex (one-to-many) correspondences.
</nextsent>
<nextsent>these models operate on one language pair at time; also, they do not model the context of the sound changes, while most etymological changes are conditioned on context.
</nextsent>
<nextsent>the mcmc-based model proposed in (bouchard-cote?
</nextsent>
<nextsent>et al , 2007) explicitly aims to model the context of changes, and op 1adapted from encyclopedia britannica and (anttila, 1989) erates on more than pair of languages.2we should note that our models at present operate at the phonetic level only, they leave semantic judgements of the database creators unquestioned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI669">
<title id=" W12-0215.xml">using context and phonetic features in models of etymological sound change </title>
<section> data and related work.  </section>
<citcontext>
<prevsection>
<prevsent>there is extensive work on alignment in the machine-translation (mt) community, and it has been observed that methods from mt alignment may be projected onto alignment in etymology.
</prevsent>
<prevsent>the intuition is that translation sentences in mt correspond to cognate words in etymology, while words in mt correspond to sounds in etymology.the notion of regularity of sound change in etymology, which is what our models try to capture, is loosely similar to contextually conditioned correspondence of translation words across languages.
</prevsent>
</prevsection>
<citsent citstr=" W97-0311 ">
for example, (kondrak, 2002) <papid> C02-1016 </papid>employs mt alignment from (melamed, 1997; <papid> W97-0311 </papid>melamed, 2000); <papid> J00-2004 </papid>one might employ the ibm models for mt alignment, (brown et al , 1993), <papid> J93-2003 </papid>or the hmm model, (vogel et al , 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>of the mt-related models, (bodrumlu et al , 2009) <papid> W09-1804 </papid>is similar to oursin that it is based on mdl (the minimum description length principle, introduced below).</nextsent>
<nextsent>2using this method, we found that the running time did not scale well for more than three languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI670">
<title id=" W12-0215.xml">using context and phonetic features in models of etymological sound change </title>
<section> data and related work.  </section>
<citcontext>
<prevsection>
<prevsent>there is extensive work on alignment in the machine-translation (mt) community, and it has been observed that methods from mt alignment may be projected onto alignment in etymology.
</prevsent>
<prevsent>the intuition is that translation sentences in mt correspond to cognate words in etymology, while words in mt correspond to sounds in etymology.the notion of regularity of sound change in etymology, which is what our models try to capture, is loosely similar to contextually conditioned correspondence of translation words across languages.
</prevsent>
</prevsection>
<citsent citstr=" J00-2004 ">
for example, (kondrak, 2002) <papid> C02-1016 </papid>employs mt alignment from (melamed, 1997; <papid> W97-0311 </papid>melamed, 2000); <papid> J00-2004 </papid>one might employ the ibm models for mt alignment, (brown et al , 1993), <papid> J93-2003 </papid>or the hmm model, (vogel et al , 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>of the mt-related models, (bodrumlu et al , 2009) <papid> W09-1804 </papid>is similar to oursin that it is based on mdl (the minimum description length principle, introduced below).</nextsent>
<nextsent>2using this method, we found that the running time did not scale well for more than three languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI671">
<title id=" W12-0215.xml">using context and phonetic features in models of etymological sound change </title>
<section> data and related work.  </section>
<citcontext>
<prevsection>
<prevsent>there is extensive work on alignment in the machine-translation (mt) community, and it has been observed that methods from mt alignment may be projected onto alignment in etymology.
</prevsent>
<prevsent>the intuition is that translation sentences in mt correspond to cognate words in etymology, while words in mt correspond to sounds in etymology.the notion of regularity of sound change in etymology, which is what our models try to capture, is loosely similar to contextually conditioned correspondence of translation words across languages.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
for example, (kondrak, 2002) <papid> C02-1016 </papid>employs mt alignment from (melamed, 1997; <papid> W97-0311 </papid>melamed, 2000); <papid> J00-2004 </papid>one might employ the ibm models for mt alignment, (brown et al , 1993), <papid> J93-2003 </papid>or the hmm model, (vogel et al , 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>of the mt-related models, (bodrumlu et al , 2009) <papid> W09-1804 </papid>is similar to oursin that it is based on mdl (the minimum description length principle, introduced below).</nextsent>
<nextsent>2using this method, we found that the running time did not scale well for more than three languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI672">
<title id=" W12-0215.xml">using context and phonetic features in models of etymological sound change </title>
<section> data and related work.  </section>
<citcontext>
<prevsection>
<prevsent>there is extensive work on alignment in the machine-translation (mt) community, and it has been observed that methods from mt alignment may be projected onto alignment in etymology.
</prevsent>
<prevsent>the intuition is that translation sentences in mt correspond to cognate words in etymology, while words in mt correspond to sounds in etymology.the notion of regularity of sound change in etymology, which is what our models try to capture, is loosely similar to contextually conditioned correspondence of translation words across languages.
</prevsent>
</prevsection>
<citsent citstr=" C96-2141 ">
for example, (kondrak, 2002) <papid> C02-1016 </papid>employs mt alignment from (melamed, 1997; <papid> W97-0311 </papid>melamed, 2000); <papid> J00-2004 </papid>one might employ the ibm models for mt alignment, (brown et al , 1993), <papid> J93-2003 </papid>or the hmm model, (vogel et al , 1996).<papid> C96-2141 </papid></citsent>
<aftsection>
<nextsent>of the mt-related models, (bodrumlu et al , 2009) <papid> W09-1804 </papid>is similar to oursin that it is based on mdl (the minimum description length principle, introduced below).</nextsent>
<nextsent>2using this method, we found that the running time did not scale well for more than three languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI673">
<title id=" W12-0215.xml">using context and phonetic features in models of etymological sound change </title>
<section> data and related work.  </section>
<citcontext>
<prevsection>
<prevsent>the intuition is that translation sentences in mt correspond to cognate words in etymology, while words in mt correspond to sounds in etymology.the notion of regularity of sound change in etymology, which is what our models try to capture, is loosely similar to contextually conditioned correspondence of translation words across languages.
</prevsent>
<prevsent>for example, (kondrak, 2002) <papid> C02-1016 </papid>employs mt alignment from (melamed, 1997; <papid> W97-0311 </papid>melamed, 2000); <papid> J00-2004 </papid>one might employ the ibm models for mt alignment, (brown et al , 1993), <papid> J93-2003 </papid>or the hmm model, (vogel et al , 1996).<papid> C96-2141 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-1804 ">
of the mt-related models, (bodrumlu et al , 2009) <papid> W09-1804 </papid>is similar to oursin that it is based on mdl (the minimum description length principle, introduced below).</citsent>
<aftsection>
<nextsent>2using this method, we found that the running time did not scale well for more than three languages.
</nextsent>
<nextsent>109
</nextsent>
<nextsent>we begin with pairwise alignment: aligning pairs of words, from two related languages in our corpus of cognates.
</nextsent>
<nextsent>for each word pair, the task of alignment means finding exactly which symbols correspond.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI674">
<title id=" W11-1826.xml">from graphs to events a subgraph matching approach for information extraction from biomedical text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to date, most of the biological knowledge about these events has only been available in the form of unstructured text in scientific articles (abulaish and dey, 2007; ananiadou et al, 2010).
</prevsent>
<prevsent>when biological event is described in text, it canbe analyzed by recognizing its type, the trigger that signals the event, and one or more event arguments.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
the bionlp-st 2009 (kim et al, 2009) <papid> W09-1401 </papid>focused on the recognition of semantically typed, complex events in the biological literature.</citsent>
<aftsection>
<nextsent>although the best-performing system achieved 51.95% f-score in identifying events across nine types, only 4 of the rest 23 participating teams obtained an f-score in the 40% range.
</nextsent>
<nextsent>this suggests that the problem of biological event extraction is difficult and far from solved.
</nextsent>
<nextsent>graphs provide powerful primitive for modeling biological data such as pathways and protein interaction networks (tian et al, 2007; yan et al, 2006).
</nextsent>
<nextsent>more recently, the dependency representations obtained from full syntactic parsing, with its ability to reveal lon grange dependencies, has shown an advantage in biological relation extraction over the traditional penn treebank-style phrase structure trees (miyao et al, 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI675">
<title id=" W11-1826.xml">from graphs to events a subgraph matching approach for information extraction from biomedical text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more recently, the dependency representations obtained from full syntactic parsing, with its ability to reveal lon grange dependencies, has shown an advantage in biological relation extraction over the traditional penn treebank-style phrase structure trees (miyao et al, 2009).
</prevsent>
<prevsent>since the dependency representation maps straightforwardly onto directed graph, operations on graphs can be naturally applied to the problem of biological event extraction.
</prevsent>
</prevsection>
<citsent citstr=" W11-1802 ">
we participated in the bionlp-st 2011 (kim et al, 2011<papid> W11-1802 </papid>a), and applied graph matching-based approach(liu et al, 2010) to tackling the task 1 of the genia event extraction (ge) task (kim et al, 2011<papid> W11-1802 </papid>b), and the core task of the epi genetics and post-translational modifications (epi) task (ohta et al, 2011), <papid> W11-1803 </papid>two main tasks of the bionlp-st 2011.</citsent>
<aftsection>
<nextsent>event recognition is performed by searching for an isomorphism between dependency representations of automatically learned event rules and complete sentences in the input texts.
</nextsent>
<nextsent>this process is treated as subgraph matching problem,which corresponds to the search for subgraph isomor phic to rule graph within sentence graph.
</nextsent>
<nextsent>while we explored methods such as performance-based rule ranking to improve the precision of the ge and epi tasks, we merged rules across multiple event types in order to increase the recall of the epi task.the rest of the paper is organized as follows: in section 2, we introduce the bionlp shared task 2011.
</nextsent>
<nextsent>section 3 describes the subgraph matching-based event extraction method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI687">
<title id=" W11-1826.xml">from graphs to events a subgraph matching approach for information extraction from biomedical text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more recently, the dependency representations obtained from full syntactic parsing, with its ability to reveal lon grange dependencies, has shown an advantage in biological relation extraction over the traditional penn treebank-style phrase structure trees (miyao et al, 2009).
</prevsent>
<prevsent>since the dependency representation maps straightforwardly onto directed graph, operations on graphs can be naturally applied to the problem of biological event extraction.
</prevsent>
</prevsection>
<citsent citstr=" W11-1803 ">
we participated in the bionlp-st 2011 (kim et al, 2011<papid> W11-1802 </papid>a), and applied graph matching-based approach(liu et al, 2010) to tackling the task 1 of the genia event extraction (ge) task (kim et al, 2011<papid> W11-1802 </papid>b), and the core task of the epi genetics and post-translational modifications (epi) task (ohta et al, 2011), <papid> W11-1803 </papid>two main tasks of the bionlp-st 2011.</citsent>
<aftsection>
<nextsent>event recognition is performed by searching for an isomorphism between dependency representations of automatically learned event rules and complete sentences in the input texts.
</nextsent>
<nextsent>this process is treated as subgraph matching problem,which corresponds to the search for subgraph isomor phic to rule graph within sentence graph.
</nextsent>
<nextsent>while we explored methods such as performance-based rule ranking to improve the precision of the ge and epi tasks, we merged rules across multiple event types in order to increase the recall of the epi task.the rest of the paper is organized as follows: in section 2, we introduce the bionlp shared task 2011.
</nextsent>
<nextsent>section 3 describes the subgraph matching-based event extraction method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI696">
<title id=" W11-1826.xml">from graphs to events a subgraph matching approach for information extraction from biomedical text </title>
<section> results and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>when the dependency graphs of two rules of different event types are isomorphic to each other, and two rules share same event trigger, we examine the (ti|e) of each event type, and only retain the rule for which the (ti|e) is higher.
</prevsent>
<prevsent>compared to the once trigger, always trigger?
</prevsent>
</prevsection>
<citsent citstr=" W09-1418 ">
method employed in other work (buyko et al, 2009; kilicoglu and bergler, 2009), <papid> W09-1418 </papid>triggers are treated in amore flexible way in our work.</citsent>
<aftsection>
<nextsent>a token is not necessarily always trigger unless it appears in the appropriate context.
</nextsent>
<nextsent>also, the same token can serve as trigger for different event types as long as it appears in the different context.
</nextsent>
<nextsent>a trigger will only be classified into afixed event type when it could serve as trigger for different event types in the same context.
</nextsent>
<nextsent>5.1.3 performance-based rule ranking in addition to the process of refining rules across event types, we proposed performance-based rule ranking method to evaluate each rule under one eventtype.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI697">
<title id=" W11-1826.xml">from graphs to events a subgraph matching approach for information extraction from biomedical text </title>
<section> results and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, if the nested sub-events arenot correctly identified, the main events will not be extracted due to the compound error effect.
</prevsent>
<prevsent>(3) anaphora and coreference: since our system focuses on extracting events from sentences, events that contain protein names spanning multiple sentences will not be captured.
</prevsent>
</prevsection>
<citsent citstr=" C08-1033 ">
recognition of these events requires the ability to do anaphora and coreference resolution in biological text (gasperin and briscoe, 2008).<papid> C08-1033 </papid></citsent>
<aftsection>
<nextsent>5.4 false positives.
</nextsent>
<nextsent>three major causes of false positives are generalized from our analysis.
</nextsent>
<nextsent>(1) assignment of overlapping event rules: the conditional probability-based method to assign overlapped rules of different event types effectively reduces the number of event candidates but leads to errors.
</nextsent>
<nextsent>for instance, methylation?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI700">
<title id=" W12-0707.xml">dependency parsing domain adaptation using transductive svm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency parsing is the task of identifying syntactic relationships between words of sentence and labeling them according to their type.
</prevsent>
<prevsent>typically, the dependency relationships are not defined by an explicit grammar, rather implicitly through human-annotated corpus which is then processed by machine learning procedure, yielding parser trained on that corpus.
</prevsent>
</prevsection>
<citsent citstr=" C04-1010 ">
shift-reduce parsers (yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>attardi, 2006) <papid> W06-2922 </papid>arean accurate and efficient (linear complexity) approach to this task: they scan the words of sentence while updating an internal state by means of shift-reduce actions selected by classifier trained on the annotated corpus.since the training corpora are made by human annotators, they are expensive to produce and are typically only available for few domains that dont adequately cover the whole spectrum of the lan guage.</citsent>
<aftsection>
<nextsent>parsers typically lose significant accuracy when applied on text from domains not covered by their training corpus.
</nextsent>
<nextsent>several techniques have been proposed to adapt parser to new domain, even when only unannotated samples from it are available (attardi et al , 2007<papid> D07-1119 </papid>a; sagae and tsujii, 2007).<papid> D07-1111 </papid></nextsent>
<nextsent>in this work we present domain adaptation based on the semi-supervised training of the classifier of shift-reduce parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI701">
<title id=" W12-0707.xml">dependency parsing domain adaptation using transductive svm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dependency parsing is the task of identifying syntactic relationships between words of sentence and labeling them according to their type.
</prevsent>
<prevsent>typically, the dependency relationships are not defined by an explicit grammar, rather implicitly through human-annotated corpus which is then processed by machine learning procedure, yielding parser trained on that corpus.
</prevsent>
</prevsection>
<citsent citstr=" W06-2922 ">
shift-reduce parsers (yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>attardi, 2006) <papid> W06-2922 </papid>arean accurate and efficient (linear complexity) approach to this task: they scan the words of sentence while updating an internal state by means of shift-reduce actions selected by classifier trained on the annotated corpus.since the training corpora are made by human annotators, they are expensive to produce and are typically only available for few domains that dont adequately cover the whole spectrum of the lan guage.</citsent>
<aftsection>
<nextsent>parsers typically lose significant accuracy when applied on text from domains not covered by their training corpus.
</nextsent>
<nextsent>several techniques have been proposed to adapt parser to new domain, even when only unannotated samples from it are available (attardi et al , 2007<papid> D07-1119 </papid>a; sagae and tsujii, 2007).<papid> D07-1111 </papid></nextsent>
<nextsent>in this work we present domain adaptation based on the semi-supervised training of the classifier of shift-reduce parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI703">
<title id=" W12-0707.xml">dependency parsing domain adaptation using transductive svm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>shift-reduce parsers (yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>attardi, 2006) <papid> W06-2922 </papid>arean accurate and efficient (linear complexity) approach to this task: they scan the words of sentence while updating an internal state by means of shift-reduce actions selected by classifier trained on the annotated corpus.since the training corpora are made by human annotators, they are expensive to produce and are typically only available for few domains that dont adequately cover the whole spectrum of the lan guage.</prevsent>
<prevsent>parsers typically lose significant accuracy when applied on text from domains not covered by their training corpus.</prevsent>
</prevsection>
<citsent citstr=" D07-1119 ">
several techniques have been proposed to adapt parser to new domain, even when only unannotated samples from it are available (attardi et al , 2007<papid> D07-1119 </papid>a; sagae and tsujii, 2007).<papid> D07-1111 </papid></citsent>
<aftsection>
<nextsent>in this work we present domain adaptation based on the semi-supervised training of the classifier of shift-reduce parser.
</nextsent>
<nextsent>we implement the classifier as multi-class svm and train it with transductive svm algorithm that handles both labeled examples (generated from the source-domain annotated corpus) and unlabeled examples (generated from the the target-domain unannotated corpus).
</nextsent>
<nextsent>2.1 shift-reduce parsing.
</nextsent>
<nextsent>a shift-reduce dependency parser is essentially push down automaton that scans the sentence one token at time in fixed direction, while updating stack of tokens and also updating set of directed, labeled edges that is eventually returned as the dependency parse graph of the sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI704">
<title id=" W12-0707.xml">dependency parsing domain adaptation using transductive svm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>shift-reduce parsers (yamada and matsumoto, 2003; nivre and scholz, 2004; <papid> C04-1010 </papid>attardi, 2006) <papid> W06-2922 </papid>arean accurate and efficient (linear complexity) approach to this task: they scan the words of sentence while updating an internal state by means of shift-reduce actions selected by classifier trained on the annotated corpus.since the training corpora are made by human annotators, they are expensive to produce and are typically only available for few domains that dont adequately cover the whole spectrum of the lan guage.</prevsent>
<prevsent>parsers typically lose significant accuracy when applied on text from domains not covered by their training corpus.</prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
several techniques have been proposed to adapt parser to new domain, even when only unannotated samples from it are available (attardi et al , 2007<papid> D07-1119 </papid>a; sagae and tsujii, 2007).<papid> D07-1111 </papid></citsent>
<aftsection>
<nextsent>in this work we present domain adaptation based on the semi-supervised training of the classifier of shift-reduce parser.
</nextsent>
<nextsent>we implement the classifier as multi-class svm and train it with transductive svm algorithm that handles both labeled examples (generated from the source-domain annotated corpus) and unlabeled examples (generated from the the target-domain unannotated corpus).
</nextsent>
<nextsent>2.1 shift-reduce parsing.
</nextsent>
<nextsent>a shift-reduce dependency parser is essentially push down automaton that scans the sentence one token at time in fixed direction, while updating stack of tokens and also updating set of directed, labeled edges that is eventually returned as the dependency parse graph of the sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI707">
<title id=" W12-0707.xml">dependency parsing domain adaptation using transductive svm </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>various classification algorithms have been successfully used, including maximum entropy, multi-layer perceptron, averaged perceptron, svm, etc. in our approach, the classifier is always multi-class svm composed of multiple (one-per-parsing-action) two-class svms in one-versus-all configuration.
</prevsent>
<prevsent>2.2 parse graph revision.
</prevsent>
</prevsection>
<citsent citstr=" N07-1049 ">
attardi and ciaramita (2007<papid> N07-1049 </papid>b) developed method for improving parsing accuracy using parse graph revision: the output of the parser is fed to procedure that scans the parsed sentence in fixed direction and, at each step, possibly revises the current node (rerouting or relabeling its unique outgoing edge) based on the classifiers output.training is performed by parsing the training corpus and comparing the outcome against the anno tation: for each sentence, sequence of actions necessary to transform the machine-generated parse into the reference parse is computed and itis used to train the classifier.</citsent>
<aftsection>
<nextsent>(usually, lower quality parser is used during training, assuming that it will generate more errors and hence more revision opportunities).this method tends to produce robust parsers: errors in the first stage have the opportunity to be corrected in the revision stage, thus, even if itdoes not learn from unlabeled data, it nevertheless performs well in domain adaptation tasks (at tardi et al , 2007<papid> D07-1119 </papid>a).</nextsent>
<nextsent>in our experiments we used parse graph revision both as baseline for accuracy comparison, and in conjunction with our approach (using transductive svm classifier in the revision stage).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI711">
<title id=" W12-0707.xml">dependency parsing domain adaptation using transductive svm </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this is consistent with the results obtained by the self-training approaches, where first parser is trained on the labeled set, which is used to parse the unlabeled set which is then included intothe training set of second parser.
</prevsent>
<prevsent>(in fact, self training is performed in the first step of the svm light tsvm algorithm).
</prevsent>
</prevsection>
<citsent citstr=" W10-2606 ">
despite earlier negative results, (sagae, 2010) <papid> W10-2606 </papid>showed that even naive self-training can provide accuracy benefits (about 2%) in domain adaptation, although these results are not directly comparable to ours because they refer to constituency parsing rather than dependency parsing.</citsent>
<aftsection>
<nextsent>(mc closky et al , 2006) <papid> P06-1043 </papid>obtain even better results (5% f-score gain) using more sophisticated form of self-training, involving n-best generative parsing and discriminative reranking.</nextsent>
<nextsent>(sagae and tsujii,2007) <papid> D07-1111 </papid>obtain similar gains (about 3 %) for dependency parsing domain adaptation, using self training on subset of the target-domain instances selected on the basis of agreement between two different parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI712">
<title id=" W12-0707.xml">dependency parsing domain adaptation using transductive svm </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>(in fact, self training is performed in the first step of the svm light tsvm algorithm).
</prevsent>
<prevsent>despite earlier negative results, (sagae, 2010) <papid> W10-2606 </papid>showed that even naive self-training can provide accuracy benefits (about 2%) in domain adaptation, although these results are not directly comparable to ours because they refer to constituency parsing rather than dependency parsing.</prevsent>
</prevsection>
<citsent citstr=" P06-1043 ">
(mc closky et al , 2006) <papid> P06-1043 </papid>obtain even better results (5% f-score gain) using more sophisticated form of self-training, involving n-best generative parsing and discriminative reranking.</citsent>
<aftsection>
<nextsent>(sagae and tsujii,2007) <papid> D07-1111 </papid>obtain similar gains (about 3 %) for dependency parsing domain adaptation, using self training on subset of the target-domain instances selected on the basis of agreement between two different parsers.</nextsent>
<nextsent>(the results are not directly comparable to ours because they were obtained on different corpus in different language).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI714">
<title id=" W12-2008.xml">utilizing cumulative logit model and human computation on automated speech assessment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for new responses, the trained statistical models are applied to predict machine scores.
</prevsent>
<prevsent>the performance of current automated speech scoring systems, especially for spontaneous speech responses, still lags markedly behind the performance of human scoring.
</prevsent>
</prevsection>
<citsent citstr=" P11-1073 ">
to improve the performance of automated speech scoring, an increasing number of research studies have been undertaken (jang, 2009; chen and zechner, 2011; <papid> P11-1073 </papid>chen and yoon, 2011).<papid> W11-1405 </papid></citsent>
<aftsection>
<nextsent>however, these studies have mostly focused on exploring additional speech features, not on building alternative scoring models.
</nextsent>
<nextsent>hence, in this paper, we will report on two new linesof research focusing on the scoring model part of au 73 tomated speech scoring systems.
</nextsent>
<nextsent>in particular, we will introduce the cumulative logit model (clm),which is not widely used in nlp, and compare it systematically with other widely-used modeling methods.
</nextsent>
<nextsent>in addition, we will propose hybrid scoring system inspired by the recent trend of involving human computation in machine learning tasks (quinn et al, 2010), which consists of both human scoring and machine scoring to achieve balance of scoring accuracy, speed, and cost.the remainder of the paper is organized as follows: section 2 reviews the previous research ef forts; section 3 describes both the test from which our experimental data were collected and the automated speech scoring system; section 4 introduces the cumulative logit model (clm) and reports systematic comparison with two other widely used modeling approaches; section 5 proposes using both human scoring and machine scoring to achieve trade-off between scoring accuracy, speed, and cost,and shows simulation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI715">
<title id=" W12-2008.xml">utilizing cumulative logit model and human computation on automated speech assessment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for new responses, the trained statistical models are applied to predict machine scores.
</prevsent>
<prevsent>the performance of current automated speech scoring systems, especially for spontaneous speech responses, still lags markedly behind the performance of human scoring.
</prevsent>
</prevsection>
<citsent citstr=" W11-1405 ">
to improve the performance of automated speech scoring, an increasing number of research studies have been undertaken (jang, 2009; chen and zechner, 2011; <papid> P11-1073 </papid>chen and yoon, 2011).<papid> W11-1405 </papid></citsent>
<aftsection>
<nextsent>however, these studies have mostly focused on exploring additional speech features, not on building alternative scoring models.
</nextsent>
<nextsent>hence, in this paper, we will report on two new linesof research focusing on the scoring model part of au 73 tomated speech scoring systems.
</nextsent>
<nextsent>in particular, we will introduce the cumulative logit model (clm),which is not widely used in nlp, and compare it systematically with other widely-used modeling methods.
</nextsent>
<nextsent>in addition, we will propose hybrid scoring system inspired by the recent trend of involving human computation in machine learning tasks (quinn et al, 2010), which consists of both human scoring and machine scoring to achieve balance of scoring accuracy, speed, and cost.the remainder of the paper is organized as follows: section 2 reviews the previous research ef forts; section 3 describes both the test from which our experimental data were collected and the automated speech scoring system; section 4 introduces the cumulative logit model (clm) and reports systematic comparison with two other widely used modeling approaches; section 5 proposes using both human scoring and machine scoring to achieve trade-off between scoring accuracy, speed, and cost,and shows simulation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI716">
<title id=" W12-2008.xml">utilizing cumulative logit model and human computation on automated speech assessment </title>
<section> data and automated scoring system.  </section>
<citcontext>
<prevsection>
<prevsent>table 1 describes the data size and final score distribution of the four score levels.
</prevsent>
<prevsent>n 1(%) 2(%) 3(%) 4 (%) 49813 4.56 37.96 47.74 9.74 table 1: human score distribution of the aest datasets 3.2 automated scoring system.
</prevsent>
</prevsection>
<citsent citstr=" N09-1050 ">
to automatically score spontaneous speech, we used the method proposed in chen et al (2009).<papid> N09-1050 </papid></citsent>
<aftsection>
<nextsent>in this method, speech recognizer is used to recognizenon-native speech and forced alignment is conducted based on the obtained recognition hypotheses.
</nextsent>
<nextsent>from the recognition and alignment outputs,a number of features were extracted from multiple aspects, such as the timing profiles, recognition confidence scores, alignment likelihoods, etc. for speech recognition and forced alignment, weused gender-independent, fully continuous hidden markov model (hmm) speech recognizer.
</nextsent>
<nextsent>our asr system was trained from about 800 hours of non-native speech data and its corresponding word transcriptions.
</nextsent>
<nextsent>we extracted the following two types of features, including (1) fluency and intonation features based on the speech recognition output as described in xi et al (2008) and (2) pronunciation features that indicated the quality of phonemes and phoneme durations as described in chen et al (2009).<papid> N09-1050 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI720">
<title id=" W12-2008.xml">utilizing cumulative logit model and human computation on automated speech assessment </title>
<section> data and automated scoring system.  </section>
<citcontext>
<prevsection>
<prevsent>methods in automated speech scoring we will briefly introduce clm and then compare it with two other widely used scoring methods, i.e., linear regression and cart.
</prevsent>
<prevsent>in most of the related previous investigations, several machine learning algorithms were compared using fixed number of instances.
</prevsent>
</prevsection>
<citsent citstr=" P11-1093 ">
however, as shown in recent studies, suchas rozovskaya and roth (2011), <papid> P11-1093 </papid>judging an algorithm requires consideration of the impact of the sizeof the training data set.</citsent>
<aftsection>
<nextsent>therefore, in our experiment, we compared three algorithms on different sizes of training samples.
</nextsent>
<nextsent>let the responses holistic score be = 1, 2, ...j (j is 4 in our study on the aest data) and let the associated probabilities be pi1, pi2, ...pij . therefore the probability of predicted score is not larger than p (y ? j) = pi1 + pi2 + ...+ pij (1) the logit of this probability can be estimated as log (y ? j) 1?
</nextsent>
<nextsent>p (y ? j) = + k?
</nextsent>
<nextsent>k=1 kxk (2) where is the number of speech features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI721">
<title id=" W12-2008.xml">utilizing cumulative logit model and human computation on automated speech assessment </title>
<section> data and automated scoring system.  </section>
<citcontext>
<prevsection>
<prevsent>k=1 kxk (2) where is the number of speech features.
</prevsent>
<prevsent>we cansee that clm contains s where each ? is associated with one feature.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
in addition, for each score j, there is an intercept . the clm is special case of multinomial logistic regression, which is named maximum entropy (maxent) model (berger et al, 1996) <papid> J96-1002 </papid>and is well known by nlp researchers.</citsent>
<aftsection>
<nextsent>in clm, the ranking order of the labels being predicted is emphasized.
</nextsent>
<nextsent>however, in maxent models, there is no assumption about the relationship of the labels being predicted.for clm, we used the yes vgam package (yee, 2010) as our implementation.
</nextsent>
<nextsent>for ordinary linear regression and cart methods, we used corresponding implementations in the weka toolkit (hall et al, 2009), i.e., lm and j48 tree, through the rweka package (hornik et al, 2009) so that we could run these three algorithms inside r. 75 from the available speech features, we first run an inter-correlation analysis among these features.
</nextsent>
<nextsent>then, two feature selection approaches implemented in the caret package (kuhn, 2008) we reused to select useful features from about 80 features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI722">
<title id=" W11-2121.xml">description of the jhu system combination scheme for wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(b) align further system outputs to the skeleton, thus forming confusion network.
</prevsent>
<prevsent>(c) rescore the final confusion network using language model, then pick the best path as the output of combination.a textual representation (where each line contains the words and counts of each bin) is usually the most convenient for machine process ing.fusion network, this method considers all system outputs at once instead of incrementally.
</prevsent>
</prevsection>
<citsent citstr=" W09-0408 ">
then log-linear model is used to derive costs, followed by search algorithm to explore the combination space (jayaraman et al, 2005; heafield et al, 2009; <papid> W09-0408 </papid>he et al, 2009).</citsent>
<aftsection>
<nextsent>3.
</nextsent>
<nextsent>hypothesis selection based: this method only.
</nextsent>
<nextsent>includes algorithms that output one of the input translations, and no word selection from multiple systems is performed.
</nextsent>
<nextsent>typical algorithms can be found in (rosti et al, 2007).<papid> P07-1040 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI723">
<title id=" W11-2121.xml">description of the jhu system combination scheme for wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hypothesis selection based: this method only.
</prevsent>
<prevsent>includes algorithms that output one of the input translations, and no word selection from multiple systems is performed.
</prevsent>
</prevsection>
<citsent citstr=" P07-1040 ">
typical algorithms can be found in (rosti et al, 2007).<papid> P07-1040 </papid></citsent>
<aftsection>
<nextsent>171this paper describes the jhu system combination submitted to the sixth workshop on statistical machine translation (wmt-11) (http://statmt.org/wmt11/index.html ).
</nextsent>
<nextsent>the jhu system combination is confusion network based as described above, following the basic system combination framework described in (karakos et al., 2008).
</nextsent>
<nextsent>however, instead of itg alignments that were used in (karakos et al, 2008), alignments based on ter-plus (snover et al, 2009) <papid> W09-0441 </papid>were used now as the core system alignment algorithm.</nextsent>
<nextsent>the rest of the paper is organized as follows: section 2 introduces the application of ter-plus in system combination.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI724">
<title id=" W11-2121.xml">description of the jhu system combination scheme for wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>171this paper describes the jhu system combination submitted to the sixth workshop on statistical machine translation (wmt-11) (http://statmt.org/wmt11/index.html ).
</prevsent>
<prevsent>the jhu system combination is confusion network based as described above, following the basic system combination framework described in (karakos et al., 2008).
</prevsent>
</prevsection>
<citsent citstr=" W09-0441 ">
however, instead of itg alignments that were used in (karakos et al, 2008), alignments based on ter-plus (snover et al, 2009) <papid> W09-0441 </papid>were used now as the core system alignment algorithm.</citsent>
<aftsection>
<nextsent>the rest of the paper is organized as follows: section 2 introduces the application of ter-plus in system combination.
</nextsent>
<nextsent>section 3 introduces the jhu system combination pipeline.
</nextsent>
<nextsent>section 4 presents the combination results and concluding remarks appear in section 5.
</nextsent>
<nextsent>alignment given the outputs of multiple mt systems, we would like to reorder and align the words of different hypothesis in way such that an objective function is optimized, thus reaching better translations by making use of more information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI726">
<title id=" W11-2121.xml">description of the jhu system combination scheme for wmt 2011 </title>
<section> the jhu system combination pipeline.  </section>
<citcontext>
<prevsection>
<prevsent>since the confusion network is just sequence of bins and each bin is super position of single words, the cn-fst can be built as linear fst in straightforward way (see figure 1).
</prevsent>
<prevsent>a 5-gram language model fst (lm-fst) is then built for each sentence.
</prevsent>
</prevsection>
<citsent citstr=" P03-1006 ">
to build the lm-fst, we refer to the methodology described in (allauzen et al., 2003).<papid> P03-1006 </papid></citsent>
<aftsection>
<nextsent>in brief, the lm-fst is constructed in the following way: 1.
</nextsent>
<nextsent>extract the vocabulary of each segment..
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>each state of the fst encodes an n-gram his-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI727">
<title id=" W11-2121.xml">description of the jhu system combination scheme for wmt 2011 </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>from the results we see the improvements on ter and bleu scores of both development and test sets almost doubled compared with the best results of single language pairs.
</prevsent>
<prevsent>to make comparison with the old technique we used in wmt10 system combination task, we ran the wmt11 system combination task using itg with surface matching.
</prevsent>
</prevsection>
<citsent citstr=" W10-1746 ">
the detailed implementation is described in (narsale, 2010).<papid> W10-1746 </papid></citsent>
<aftsection>
<nextsent>table 3 and 4 showthe wmt11 results using itg for alignment respectively.
</nextsent>
<nextsent>it can be seen that ter-plus outperforms itg 174 system fr-en de-en cz-en es-en xx-en ter bleu ter bleu ter bleu ter bleu ter bleu best single system 56.2 28.1 60.1 23.6 54.9 27.9 51.8 30.2 51.8 30.2 primary combination 49.2 32.6 58.1 25.7 55.1 28.7 48.3 33.7 44.9 35.5 contrastive combination 49.8 32.3 58.2 25.6 54.9 28.9 49.1 33.3 45.0 37.2 table 1: results for all language pairs on development set.
</nextsent>
<nextsent>the best number in each column is shown in bold.
</nextsent>
<nextsent>system fr-en de-en cz-en es-en xx-en ter bleu ter bleu ter bleu ter bleu ter bleu best single system 58.2 30.5 65.1 23.5 59.7 29.1 60.0 28.9 58.2 30.5 primary combination 55.9 31.9 64.4 25.0 60.1 29.6 55.4 33.5 51.7 36.3 contrastive combination 56.5 31.6 65.7 24.4 59.9 29.8 56.5 33.4 52.5 36.5 table 2: results for all language pairs on test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI728">
<title id=" W11-2106.xml">tesla at wmt 2011 translation evaluation and tunable metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes the submission from the national university of singapore to the wmt 2011 shared evaluation task and the tunable metric task.
</prevsent>
<prevsent>our entry is tesla in three different configurations: tesla-m, tesla-f, and the new tesla-b.
</prevsent>
</prevsection>
<citsent citstr=" W10-1754 ">
tesla (translation evaluation of sentences withlinear-programming-based analysis) was first proposed in liu et al (2010)<papid> W10-1754 </papid></citsent>
<aftsection>
<nextsent>the simplest variant,tesla-m (m stands for minimal), is based on ngram matching, and utilizes light-weight linguistic analysis including lemmatization, part-of-speechtagging, and wordnet synonym relations.
</nextsent>
<nextsent>teslab (b stands for basic) additionally takes advantage of bilingual phrase tables to model phrase synonyms.
</nextsent>
<nextsent>it is new configuration proposed in this paper.
</nextsent>
<nextsent>the most sophisticated configuration tesla-f(f stands for full) additionally uses language models and ranking support vector machine instead of simple averaging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI740">
<title id=" W11-2106.xml">tesla at wmt 2011 translation evaluation and tunable metric </title>
<section> tesla-b.  </section>
<citcontext>
<prevsection>
<prevsent>their matching is done in the same way as described for btngs in the previous section.
</prevsent>
<prevsent>3.1 phrase level semantic representation.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
given sentence-aligned bitext between the target language and pivot language, we can align the text at the word level using well known tools such as giza++ (och and ney, 2003) <papid> J03-1002 </papid>or the berkeley aligner (liang et al, 2006; <papid> N06-1014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></citsent>
<aftsection>
<nextsent>we observe that the distribution of aligned phrases in pivot language can serve as semantic representation of target language phrase.
</nextsent>
<nextsent>that is, if two target language phrases are often aligned to the same pivot language phrase, then they can be inferred to be similar in meaning.
</nextsent>
<nextsent>similar observations have been made by previous researchers (ban nard and callison-burch, 2005; callison-burch et al., 2006; snover et al, 2009).<papid> W09-0441 </papid>we note here two differences from wordnet syn onyms: (1) the relationship is not restricted to theword level only, and (2) the relationship is not bi nary.</nextsent>
<nextsent>the degree of similarity can be measured bythe percentage of overlap between the semantic rep resentations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI741">
<title id=" W11-2106.xml">tesla at wmt 2011 translation evaluation and tunable metric </title>
<section> tesla-b.  </section>
<citcontext>
<prevsection>
<prevsent>their matching is done in the same way as described for btngs in the previous section.
</prevsent>
<prevsent>3.1 phrase level semantic representation.
</prevsent>
</prevsection>
<citsent citstr=" N06-1014 ">
given sentence-aligned bitext between the target language and pivot language, we can align the text at the word level using well known tools such as giza++ (och and ney, 2003) <papid> J03-1002 </papid>or the berkeley aligner (liang et al, 2006; <papid> N06-1014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></citsent>
<aftsection>
<nextsent>we observe that the distribution of aligned phrases in pivot language can serve as semantic representation of target language phrase.
</nextsent>
<nextsent>that is, if two target language phrases are often aligned to the same pivot language phrase, then they can be inferred to be similar in meaning.
</nextsent>
<nextsent>similar observations have been made by previous researchers (ban nard and callison-burch, 2005; callison-burch et al., 2006; snover et al, 2009).<papid> W09-0441 </papid>we note here two differences from wordnet syn onyms: (1) the relationship is not restricted to theword level only, and (2) the relationship is not bi nary.</nextsent>
<nextsent>the degree of similarity can be measured bythe percentage of overlap between the semantic rep resentations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI742">
<title id=" W11-2106.xml">tesla at wmt 2011 translation evaluation and tunable metric </title>
<section> tesla-b.  </section>
<citcontext>
<prevsection>
<prevsent>their matching is done in the same way as described for btngs in the previous section.
</prevsent>
<prevsent>3.1 phrase level semantic representation.
</prevsent>
</prevsection>
<citsent citstr=" P09-1104 ">
given sentence-aligned bitext between the target language and pivot language, we can align the text at the word level using well known tools such as giza++ (och and ney, 2003) <papid> J03-1002 </papid>or the berkeley aligner (liang et al, 2006; <papid> N06-1014 </papid>haghighi et al, 2009).<papid> P09-1104 </papid></citsent>
<aftsection>
<nextsent>we observe that the distribution of aligned phrases in pivot language can serve as semantic representation of target language phrase.
</nextsent>
<nextsent>that is, if two target language phrases are often aligned to the same pivot language phrase, then they can be inferred to be similar in meaning.
</nextsent>
<nextsent>similar observations have been made by previous researchers (ban nard and callison-burch, 2005; callison-burch et al., 2006; snover et al, 2009).<papid> W09-0441 </papid>we note here two differences from wordnet syn onyms: (1) the relationship is not restricted to theword level only, and (2) the relationship is not bi nary.</nextsent>
<nextsent>the degree of similarity can be measured bythe percentage of overlap between the semantic rep resentations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI743">
<title id=" W11-2106.xml">tesla at wmt 2011 translation evaluation and tunable metric </title>
<section> tesla-b.  </section>
<citcontext>
<prevsection>
<prevsent>we observe that the distribution of aligned phrases in pivot language can serve as semantic representation of target language phrase.
</prevsent>
<prevsent>that is, if two target language phrases are often aligned to the same pivot language phrase, then they can be inferred to be similar in meaning.
</prevsent>
</prevsection>
<citsent citstr=" W09-0441 ">
similar observations have been made by previous researchers (ban nard and callison-burch, 2005; callison-burch et al., 2006; snover et al, 2009).<papid> W09-0441 </papid>we note here two differences from wordnet syn onyms: (1) the relationship is not restricted to theword level only, and (2) the relationship is not bi nary.</citsent>
<aftsection>
<nextsent>the degree of similarity can be measured bythe percentage of overlap between the semantic representations.
</nextsent>
<nextsent>3.2 segmenting sentence into phrases.
</nextsent>
<nextsent>to extend the concept of this semantic representation of phrases to sentences, we segment sentence in the target language into phrases.
</nextsent>
<nextsent>given phrase table, we can approximate the probability of phrase by: pr(p) = n(p) ? p? n(p ?)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI745">
<title id=" W11-2106.xml">tesla at wmt 2011 translation evaluation and tunable metric </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>interestingly, all participating metrics in wmt 2009 had low system-level correlation for the english-german language pair.
</prevsent>
<prevsent>en-fr en-de en-es overall tesla-m 0.64 0.59 0.59 0.60 tesla-b 0.65 0.59 0.60 0.61 tesla-f 0.68 0.57 0.60 0.61 wpf 0.66 0.60 0.61 0.61 wpbleu 0.60 0.47 0.49 0.51 table 3: out-of-english sentence-level consistency on wmt 2009 data 82 en-fr en-de en-es avg tesla-m 0.93 0.86 0.79 0.86 tesla-b 0.91 0.05 0.63 0.53 tesla-f 0.85 0.78 0.67 0.77 wpf 0.90 -0.06 0.58 0.47 wpbleu 0.92 0.07 0.63 0.54 table 4: out-of-english system-level spear mans rank correlation on wmt 2009 data 6.2 tunable metric task.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the goal of the new tunable metric task is to explore mt tuning with metrics other than bleu (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>to allow for fair comparison, thewmt organizers provided participants with complete joshua mt system for an urdu-english translation task.
</nextsent>
<nextsent>we tuned models for each variant of tesla, using z-mert in the default configuration provided by the organizers.
</nextsent>
<nextsent>there are four reference translations for each urdu source sentence.
</nextsent>
<nextsent>the size of the n-best list is set to 300.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI746">
<title id=" W11-2106.xml">tesla at wmt 2011 translation evaluation and tunable metric </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the best result in each column is printed in bold.
</prevsent>
<prevsent>ranked 7th out of 8 participating systems, but when evaluated with score2, tesla-f is ranked second best.
</prevsent>
</prevsection>
<citsent citstr=" D11-1035 ">
these findings differ from previous results that we reported in liu et al (2011) <papid> D11-1035 </papid>where mtsystems tuned with tesla-m and tesla-f consistently outperform two other systems tuned with bleu and ter for translations from french, german, and spanish into english on the wmt 2010 news data set.</citsent>
<aftsection>
<nextsent>a manual inspection of the references in the tunable metric task shows that the translations are of lower quality compared to the news datasets used in wmt.
</nextsent>
<nextsent>as the svm model in tesla-f is trained with rankings from wmt 2008, it is possible that the model is less robust when applied to urdu english translations.
</nextsent>
<nextsent>this could explain the mixed performance of tesla-f in the tunable metric task.
</nextsent>
<nextsent>we introduce tesla-b, new variant of the tesla machine translation metric and present experimental results for all tesla variants in the setting of the wmt evaluation task and tunable metric task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI747">
<title id=" W12-1643.xml">markov logic networks for situated incremental natural language understanding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in many, if not most, conversational situations speaker and addressee are co-located in space, and their speech may refer to their shared situation.
</prevsent>
<prevsent>most current spoken dialogue systems attempt to abstract from this fact, however.
</prevsent>
</prevsection>
<citsent citstr=" E09-1081 ">
they work in domains where physical co-location is not necessary, such as information look-up, and they quantize time into discrete turn units by end pointing utterances (see discussion in (aist et al, 2007; schlangen and skantze, 2009)).<papid> E09-1081 </papid>in this paper we present our current work on overcoming these abstractions for the task of natural language understanding (nlu).</citsent>
<aftsection>
<nextsent>we have created statistical model that can be trained on conversational data and which can be used as an nlu module for an incremental, situated dialogue system (such as that described in (bu?
</nextsent>
<nextsent>et al, 2010)).
</nextsent>
<nextsent>we show that this model beats baseline approaches by wide margin, and that making available the full set of information comprising visual context, discourse context,and linguistic structure gives significantly better results than any subset of these information sources on their own.the paper is structured as follows: we first discuss related work and introduce some background, and then describe in detail our set of experiments, and present and analyse our results.
</nextsent>
<nextsent>we close with general discussion of this work and possible future extensions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI748">
<title id=" W12-1643.xml">markov logic networks for situated incremental natural language understanding </title>
<section> related work and background.  </section>
<citcontext>
<prevsection>
<prevsent>we close with general discussion of this work and possible future extensions.
</prevsent>
<prevsent>the work in this paper builds on, connects and extends several strands of research: grounded semantics (roy, 2005), which worries about the connection between language and the situation in which it is used, but often does not go beyond the word level to include linguistic structure information and does not work incrementally;1 statistical nlu (see e.g.
</prevsent>
</prevsection>
<citsent citstr=" P09-1110 ">
(zettlemoyer and collins, 2009; <papid> P09-1110 </papid>liang et al,1but see (spranger et al, 2010); for recent attempts that partially overcome these limitations.</citsent>
<aftsection>
<nextsent>3142011)), which tries to infer linguistic structures automatically, but normally stops at generating, not interpreting semantic representations, and works with (the text of) full utterances and not incrementally on speech data; and incremental nlu, which is less intensely studied field, but where previous contributions (such as (devault et al, 2009; <papid> W09-3902 </papid>devault et al., 2011; aist et al, 2007; schlangen and skantze,2009)) <papid> E09-1081 </papid>have not dealt with learned grounded seman tics.</nextsent>
<nextsent>we go beyond this earlier work in that we studya model that is incremental, can use linguistic structure, and learns from conversational data semantics that connects the utterance to its visual and discourse context.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI749">
<title id=" W12-1643.xml">markov logic networks for situated incremental natural language understanding </title>
<section> related work and background.  </section>
<citcontext>
<prevsection>
<prevsent>the work in this paper builds on, connects and extends several strands of research: grounded semantics (roy, 2005), which worries about the connection between language and the situation in which it is used, but often does not go beyond the word level to include linguistic structure information and does not work incrementally;1 statistical nlu (see e.g.
</prevsent>
<prevsent>(zettlemoyer and collins, 2009; <papid> P09-1110 </papid>liang et al,1but see (spranger et al, 2010); for recent attempts that partially overcome these limitations.</prevsent>
</prevsection>
<citsent citstr=" W09-3902 ">
3142011)), which tries to infer linguistic structures automatically, but normally stops at generating, not interpreting semantic representations, and works with (the text of) full utterances and not incrementally on speech data; and incremental nlu, which is less intensely studied field, but where previous contributions (such as (devault et al, 2009; <papid> W09-3902 </papid>devault et al., 2011; aist et al, 2007; schlangen and skantze,2009)) <papid> E09-1081 </papid>have not dealt with learned grounded seman tics.</citsent>
<aftsection>
<nextsent>we go beyond this earlier work in that we studya model that is incremental, can use linguistic structure, and learns from conversational data semantics that connects the utterance to its visual and discourse context.
</nextsent>
<nextsent>we have looked at individual components of this before (grounded semantics in (siebert and schlangen, 2008); <papid> W08-0113 </papid>incremental reference resolution in (schlangen et al, 2009); <papid> W09-3905 </papid>incremental general nluin (heintze et al, 2010); interaction between incremental parsing and reference resolution in (peldszus et al, 2012)), but use more sophisticated model in this work and show that tackling these tasks jointly improves performance.</nextsent>
<nextsent>mln system context/world language/rmrs context/discourse prediction:actionobjectresult figure 1: nlu data flow we apply markov logic networks (mlns, (richardson and domingos, 2006)) as the machine learning technique in our experiments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI751">
<title id=" W12-1643.xml">markov logic networks for situated incremental natural language understanding </title>
<section> related work and background.  </section>
<citcontext>
<prevsection>
<prevsent>3142011)), which tries to infer linguistic structures automatically, but normally stops at generating, not interpreting semantic representations, and works with (the text of) full utterances and not incrementally on speech data; and incremental nlu, which is less intensely studied field, but where previous contributions (such as (devault et al, 2009; <papid> W09-3902 </papid>devault et al., 2011; aist et al, 2007; schlangen and skantze,2009)) <papid> E09-1081 </papid>have not dealt with learned grounded seman tics.</prevsent>
<prevsent>we go beyond this earlier work in that we studya model that is incremental, can use linguistic structure, and learns from conversational data semantics that connects the utterance to its visual and discourse context.</prevsent>
</prevsection>
<citsent citstr=" W08-0113 ">
we have looked at individual components of this before (grounded semantics in (siebert and schlangen, 2008); <papid> W08-0113 </papid>incremental reference resolution in (schlangen et al, 2009); <papid> W09-3905 </papid>incremental general nluin (heintze et al, 2010); interaction between incremental parsing and reference resolution in (peldszus et al, 2012)), but use more sophisticated model in this work and show that tackling these tasks jointly improves performance.</citsent>
<aftsection>
<nextsent>mln system context/world language/rmrs context/discourse prediction:actionobjectresult figure 1: nlu data flow we apply markov logic networks (mlns, (richardson and domingos, 2006)) as the machine learning technique in our experiments.
</nextsent>
<nextsent>mlns have recently received attention in language processing fields like co-reference resolution (chen, 2009), semantic role labeling (meza-ruiz and riedel, 2009), spoken (albeit neither situational nor incremental)nlu (meurs et al, 2008), and web information extraction (satpal et al, 2011).
</nextsent>
<nextsent>the framework offers convenient way of specifying factor functions on sets of random variables for undirected graphical models (markov random fields, see (kindermann and snell, 1980)), in such way that the factors correspond to weighted first order formulae and the joint distribution of random variables corresponds to probabilities of groundings of formulae.
</nextsent>
<nextsent>in this way,mlns offer helpful bridge between symbolic representation and stochastic inference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI752">
<title id=" W12-1643.xml">markov logic networks for situated incremental natural language understanding </title>
<section> related work and background.  </section>
<citcontext>
<prevsection>
<prevsent>3142011)), which tries to infer linguistic structures automatically, but normally stops at generating, not interpreting semantic representations, and works with (the text of) full utterances and not incrementally on speech data; and incremental nlu, which is less intensely studied field, but where previous contributions (such as (devault et al, 2009; <papid> W09-3902 </papid>devault et al., 2011; aist et al, 2007; schlangen and skantze,2009)) <papid> E09-1081 </papid>have not dealt with learned grounded seman tics.</prevsent>
<prevsent>we go beyond this earlier work in that we studya model that is incremental, can use linguistic structure, and learns from conversational data semantics that connects the utterance to its visual and discourse context.</prevsent>
</prevsection>
<citsent citstr=" W09-3905 ">
we have looked at individual components of this before (grounded semantics in (siebert and schlangen, 2008); <papid> W08-0113 </papid>incremental reference resolution in (schlangen et al, 2009); <papid> W09-3905 </papid>incremental general nluin (heintze et al, 2010); interaction between incremental parsing and reference resolution in (peldszus et al, 2012)), but use more sophisticated model in this work and show that tackling these tasks jointly improves performance.</citsent>
<aftsection>
<nextsent>mln system context/world language/rmrs context/discourse prediction:actionobjectresult figure 1: nlu data flow we apply markov logic networks (mlns, (richardson and domingos, 2006)) as the machine learning technique in our experiments.
</nextsent>
<nextsent>mlns have recently received attention in language processing fields like co-reference resolution (chen, 2009), semantic role labeling (meza-ruiz and riedel, 2009), spoken (albeit neither situational nor incremental)nlu (meurs et al, 2008), and web information extraction (satpal et al, 2011).
</nextsent>
<nextsent>the framework offers convenient way of specifying factor functions on sets of random variables for undirected graphical models (markov random fields, see (kindermann and snell, 1980)), in such way that the factors correspond to weighted first order formulae and the joint distribution of random variables corresponds to probabilities of groundings of formulae.
</nextsent>
<nextsent>in this way,mlns offer helpful bridge between symbolic representation and stochastic inference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI753">
<title id=" W12-1643.xml">markov logic networks for situated incremental natural language understanding </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the language of the corpus is german.
</prevsent>
<prevsent>figure 2: example pentomino board for this study, we were interested in the potential contribution of linguistic structure to the nlu task.
</prevsent>
</prevsection>
<citsent citstr=" W07-1210 ">
315to this end, we produced for each utterance an incremental sequence of parses and corresponding semantic representations (as rmrs structures (copestake, 2007), <papid> W07-1210 </papid>i.e. underspecified semantic representa tions), using the parser described in (peldszus et al,2012).</citsent>
<aftsection>
<nextsent>these representations were not further manually checked for appropriateness, and hence do not necessarily represent ground truth.as in (peldszus et al, 2012), we discarded utterances without clear semantic alignments.
</nextsent>
<nextsent>one major difference from them is that we do include the 661 utterances that used pronouns to refer to pieces, leaving us with 1687 utterances, 5.43 words per utterance (sd 2.36), with vocabulary of 237 distinct words.
</nextsent>
<nextsent>these were transcribed utterances andnot automatic speech recognition output, so our results represent an upper-bound on real world performance.
</nextsent>
<nextsent>the task that we wanted our model to tackle can then be stated as follows: given information about the current state of the world (i.e., the game board), the previous system action, and about the (possiblystill not-yet completed) utterance, predict an interpretation for the utterance, in the form of such aframe.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI755">
<title id=" W11-2027.xml">embedded wizardry </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>between humans and machines, however, verbal interaction has much higher rate of linguistic misunderstandings because the channel is noisy, and machines are not as adept at using spoken language.
</prevsent>
<prevsent>it is difficult to arrive at accurate rates for misunderstandings of form versus intent in human conversation, because the two types cannot always be distinguished (schlangen and fernandez,2005).
</prevsent>
</prevsection>
<citsent citstr=" W01-1616 ">
however, one estimate of the rate of misunderstandings of literal meaning between humans,based on text transcripts of the british national corpus, is in the low range of 4% (purver et al, 2001), <papid> W01-1616 </papid>compared with 30% estimate for human-computer dialogue (rieser and lemon, 2011).</citsent>
<aftsection>
<nextsent>the thesis of our work is that misunderstandings of linguistic form in human-machine dialogue are more effectively resolved through greater reliance on context, and through closer integration of spoken language understanding (slu) with dialogue management (dm).
</nextsent>
<nextsent>we investigate these claims by focusing on noisy speech recognition for utterances where the users specific intent requires little additional inference, given sufficient understanding of the form.this paper presents three experiments that progressively address slu methods to compensate forpoor automated speech recognition (asr), and complementary dm strategies.
</nextsent>
<nextsent>in two of the experiments, human wizards are embedded in the spoken dialogue system while run-time slu features are collected.
</nextsent>
<nextsent>many wizard-of-oz investigations have addressed the noisy channel issue for sds (zollo, 1999; skantze, 2003; williams and young, 2004; skantze, 2005; rieser and lemon, 2006; <papid> P06-2085 </papid>schlangen and fernandez, 2005; rieser and lemon, 2011).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI756">
<title id=" W11-2027.xml">embedded wizardry </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we investigate these claims by focusing on noisy speech recognition for utterances where the users specific intent requires little additional inference, given sufficient understanding of the form.this paper presents three experiments that progressively address slu methods to compensate forpoor automated speech recognition (asr), and complementary dm strategies.
</prevsent>
<prevsent>in two of the experiments, human wizards are embedded in the spoken dialogue system while run-time slu features are collected.
</prevsent>
</prevsection>
<citsent citstr=" P06-2085 ">
many wizard-of-oz investigations have addressed the noisy channel issue for sds (zollo, 1999; skantze, 2003; williams and young, 2004; skantze, 2005; rieser and lemon, 2006; <papid> P06-2085 </papid>schlangen and fernandez, 2005; rieser and lemon, 2011).</citsent>
<aftsection>
<nextsent>like them, we study how human wizards solve the joint problem of interpreting users?
</nextsent>
<nextsent>words and inferring users?
</nextsent>
<nextsent>intents.
</nextsent>
<nextsent>our work differs in its exploration of the role context can play in the literal interpretation of noisy language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI760">
<title id=" W11-2027.xml">embedded wizardry </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to limit communication errors incurred by faulty asr, an sds can relyon strategies to detect andre spond to incorrect recognition output (bohus, 2004).
</prevsent>
<prevsent>the sds can repeatedly request user confirmation to avoid misunderstanding, or ask for confirmation using language that elicits responses from the user that the system can handle (raux and eskenazi,2004).
</prevsent>
</prevsection>
<citsent citstr=" W09-0506 ">
when the user adds unanticipated information in response to system prompt, two-pass recognition can relyon concept-specific language model to improve the recognition of the domain concepts within the utterance containing unknown words, and thereby achieve better recognition (stoyanchev and stent, 2009).<papid> W09-0506 </papid></citsent>
<aftsection>
<nextsent>an sds could take this approach onestep further and use context-specific language for incremental understanding of noisy input throughout the dialogue (aist et al, 2007).
</nextsent>
<nextsent>current work on error recovery and grounding for sds assumes that the primary responsibility of dialogue management strategy is to understand the users intent.
</nextsent>
<nextsent>errors of understanding are addressed by ignoring the utterances where understanding failures occur, asking users to repeat, or pursuing clarifications about intent.
</nextsent>
<nextsent>these strategies typically relyon knowledge sources that follow the slu stage.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI761">
<title id=" W11-2027.xml">embedded wizardry </title>
<section> checkitout.  </section>
<citcontext>
<prevsection>
<prevsent>sds modules communicate via message passing, controlled by central hub.
</prevsent>
<prevsent>however, the information flow is largely apipeline, as depicted in figure 1(a).
</prevsent>
</prevsection>
<citsent citstr=" H94-1039 ">
the pocket sphinx recognizer (huggins-daines et al, 2006) receives acoustic data segmented by the audio manager, and passes single recognition hypothesis to the phoenix parser (ward and issar, 1994).<papid> H94-1039 </papid></citsent>
<aftsection>
<nextsent>phoenix sends one or more equivalently ranked semantic parses to the helios confidence annotator (bohusand rudnicky, 2002), which selects parse and assigns confidence score.
</nextsent>
<nextsent>the apollo interaction manager (raux and eskenazi, 2007) monitors the three slu modules the recognizer, the semantic parser, and the confidence annotator to determine whether the user or sds has the current turn.
</nextsent>
<nextsent>toa limited degree, apollo can override the early segmentation decisions based solely on pause length.
</nextsent>
<nextsent>250 confidence-annotated concepts from the semantic parse are passed to the raven claw dm, which decides when to prompt the user, present information to her, or query the backend database.a wizard server communicates with other modules via the hub, as shown in figure 1(b).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI762">
<title id=" W11-2027.xml">embedded wizardry </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>to avoid the brittleness of exact string cfg rules, and the massive over-generation of bow cfg rules, we wrote transducer that mapped dependency parses of book titles to cfg rules.
</prevsent>
<prevsent>when asr words are skipped, book title parses can consist of multiple slots.
</prevsent>
</prevsection>
<citsent citstr=" N09-2047 ">
we used mica, broad-coverage dependency grammar (bangalore et al, 2009) <papid> N09-2047 </papid>to parse the entire book title database.</citsent>
<aftsection>
<nextsent>when setof titles is selected for an experiment, the corresponding mica parses are transduced to the relevant cfg productions, and inserted into phoenix grammar.
</nextsent>
<nextsent>productions for the author subgrammar2bow phoenix rules for book titles are used in more recent olympus/ravenclaw system inspired in part by check itout (lee et al, 2010), with database of 15,088 ebooks.
</nextsent>
<nextsent>251 exp. am adapted # titles for lm lm grammar rules wer title pilot wsj1 16khz na 500 unigram na 0.76 turn exchange wsj1 16khz na 7,500 trigram title strings 0.71 full woz wsj1 8khz 10 hr.
</nextsent>
<nextsent>3,000 logios + book data mica-based 0.50 (est) table 1: slu settings across experiments consist largely of first name slot followed by last name slot.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI763">
<title id=" W11-2027.xml">embedded wizardry </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>4.3 turn exchange.
</prevsent>
<prevsent>the offline title pilot suggested that voice search could lead to far fewer non-understandings, given some predictions as to the actual words noisy asr string might represent.
</prevsent>
</prevsection>
<citsent citstr=" N10-1126 ">
the next experiment addressed, in real time, the question of what level of accuracy might be achieved through an online implementation of voice search for book requests by title (passonneau et al, 2010; <papid> N10-1126 </papid>ligorio et al, 2010b).</citsent>
<aftsection>
<nextsent>we embedded wizards into the checkitout sds to present them with live asr, and to collect runtime recognition features.
</nextsent>
<nextsent>on the gui, variations in the display fonts for asr and voice search returns cuedthe wizard to gross differences in word-level recognition confidence, and similarities between an asr string and each candidate returned by the search.
</nextsent>
<nextsent>learned models of wizard actions indicated that 252 recognition features such as acoustic model fit and speech rate, along with various measures of similarity between the asr output string and candidate titles, number of books ordered thus far (recentsuccess), and number of relatively close candidate matches, were useful in modeling the most accurate wizards.
</nextsent>
<nextsent>these results show that dm strategy for determing what actions to take, given an interpretation of user request, can depend on subtle recognition metrics.in turn exchange, users requested books by title from embedded wizards.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI764">
<title id=" W11-2038.xml">paradise style evaluation of a human human library corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for human-human task-based dialogues, we hypothesized that user satisfaction would not be predicted well by measures of success and dialogue costs alone.
</prevsent>
<prevsent>we expected that qualitative characteristics of human-human dialogue, such as the manner in which dialogue goal is pursued, could counterbalance high dialogue costs.
</prevsent>
</prevsection>
<citsent citstr=" N10-1126 ">
to test this hypothesis, we performed paradise-like evaluation of corpus of human-human library transaction dialogues that was originally collected to support the design of our sds (passonneau, et al 2010).<papid> N10-1126 </papid></citsent>
<aftsection>
<nextsent>the communicative task we examine is to identify specific set of books of interest from the librarys holdings.
</nextsent>
<nextsent>this can be straightforward if the patron requests book by catalogue number.
</nextsent>
<nextsent>it can be complex if the patron does not have complete bibliographic information, or if the request is non-specific.
</nextsent>
<nextsent>a book request is successful when the librarian identifies specific book that addresses the patrons request.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI765">
<title id=" W11-2038.xml">paradise style evaluation of a human human library corpus </title>
<section> loqui human-human corpus.  </section>
<citcontext>
<prevsection>
<prevsent>these were transcribed with an xml transcription tool, and utterances were aligned with the speech signal.
</prevsent>
<prevsent>the total number of words is approximately 24,670, or about 300 words per dialogue.
</prevsent>
</prevsection>
<citsent citstr=" W09-3953 ">
our transcription conventions are documented on our website.1 to facilitate analysis of the interactive structure of many types of interaction, such as spontaneous spoken dialogue, email, and task-oriented dialogue, we previously developed dialogue function unit (dfu) annotation (hu, et al 2009).<papid> W09-3953 </papid></citsent>
<aftsection>
<nextsent>the primary motivation was to capture information about adja cency pairs, sequences of communicative acts in which an initial utterance calls forth responding one (sacks, et al 1974).
</nextsent>
<nextsent>dfus encode links between the elements of an adjacency pair, andre stricted set of dialogue acts designed to generalize across genres of interaction.
</nextsent>
<nextsent>trained annotators applied dfu annotations to all 82 dialogues.
</nextsent>
<nextsent>to measure task success and dialogue costs, we developed an additional annotation process that builds on dfu annotation, as described next.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI766">
<title id=" W11-1810.xml">bionlp shared task 2011 8211 bacteria gene interactions and renaming </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>both issued from pubmed scientific literature abstracts, the rename task aims at extracting gene name synonyms, and the gi task aims at extracting genic interaction events, mainly about gene transcript ional regulations in bacteria.
</prevsent>
<prevsent>the extraction of biological events from scientific literature is the most popular task in information extraction (ie) challenges applied to molecular biology, such as in lll (nedellec, 2005), bio creative protein-protein interaction task (krallinger et al, 2008), or bionlp (demner-fushman et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
since the bionlp 2009 shared task (kim et al, 2009), <papid> W09-1401 </papid>this field has evolved from the extraction of unique binary interaction relation between proteinsand/or genes towards broader accept ation of biological events including localization and transformation (kim et al, 2008).</citsent>
<aftsection>
<nextsent>in the same way, the tasks bacteria gene interactions and bacteria gene renaming deal with the extraction of various molecular events capturing the mechanisms relevant to gene regulation in prokaryotes.
</nextsent>
<nextsent>the study of bacteria has numerous applications for health, food and industry, and overall, they are considered as organisms of choice for the recent integrative approaches in systems biology, because of their relative simplicity.
</nextsent>
<nextsent>compared to eukaryotes, they allow easier and more in-depth analysis of biological functions and of their related molecular mechanisms.processing literature on bacteria raises linguistic and semantic specificities that impact text analysis.
</nextsent>
<nextsent>first of all, gene renaming is frequent phenomenon, especially for model bacteria.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI767">
<title id=" W11-1810.xml">bionlp shared task 2011 8211 bacteria gene interactions and renaming </title>
<section> rename task description.  </section>
<citcontext>
<prevsection>
<prevsent>this step was used to refine the guidelines according to the methodology described in (bonneau-maynard et al, 2005).
</prevsent>
<prevsent>severalinter-annotator agreements coefficients were computed to measure the discrepancy between annotators (fort et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
with kappa and pi scores (for more details on those, see (artstein and poesio, 2008)), <papid> J08-4004 </papid>the results can be considered satisfactory.</citsent>
<aftsection>
<nextsent>the manual analysis of the 18 discrepancies led to enrich the annotation guidelines.
</nextsent>
<nextsent>the first hundreds of documents of the second set did not mention any renaming, leading to concentrate the annotation efforts on the first set.
</nextsent>
<nextsent>these documents actually contained rena mings, but nearly exclusively concerning other kinds of biological entities (protein domains, molecules, cellular ultra structures, etc.).
</nextsent>
<nextsent>guidelines in order to simplify the task, only short names of gene/protein/groups in b. subtilis were considered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI768">
<title id=" W11-2024.xml">using performance trajectories to analyze the immediate impact of user state misclassification in an adaptive spoken dialogue system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our tutoring system results illustrate the case where user state misclassification increases the likelihood of negative performance trajectories ascom pared to accurate classification.
</prevsent>
<prevsent>spoken dialogue systems research has shown that natural language processing errors can negatively impact global system performance.
</prevsent>
</prevsection>
<citsent citstr=" A00-2028 ">
for example, automatic speech recognition errors have been shown to negatively correlate with user satisfaction surveys taken after the system interaction is over (e.g., (walker et al , 2000<papid> A00-2028 </papid>a; pon-barry et al , 2004)).</citsent>
<aftsection>
<nextsent>automatic user state classification errors have also been shown to negatively impact global performance in spoken dialogue systems (e.g., (pon barry et al , 2006)).
</nextsent>
<nextsent>for example, in our prior work with an uncertainty-adaptive spoken dialogue computer tutoring system, we found that recognizing and adapting to the users state of uncertainty, over and above his/her state of correctness, significantly improved global learning over all users (as measured by tests taken before and after the system interac tion).
</nextsent>
<nextsent>however, this was only true when the user uncertainty was manually labeled during the interaction by an unseen human wizard of oz?
</nextsent>
<nextsent>(forbes riley and litman, 2011b); it was not true when the uncertainty was automatically labeled by the system.further analysis showed that uncertainty classification errors largely accounted for the global performance decrease in our fully automated system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI772">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the rest of this paper is structured as follows:section 2 is related work, section 3 presents linguistic challenges and motivation, section 4 details our approach and section 5 presents results evaluating our approach under variety of conditions.
</prevsent>
<prevsent>dialectal arabic nlp much work has been donein the context of msa nlp (habash, 2010).
</prevsent>
</prevsection>
<citsent citstr=" N04-4015 ">
specifically for arabic-to-english smt, the importance of tokenization using morphological analysis has been shown by many researchers (lee, 2004; <papid> N04-4015 </papid>zollmann et al, 2006; <papid> N06-2051 </papid>habash and sadat, 2006).<papid> N06-2013 </papid></citsent>
<aftsection>
<nextsent>in contrast,research on da nlp is still in its early stages: (ki lany et al, 2002; kirchhoff et al, 2003; duh and kirchhoff, 2005; <papid> W05-0708 </papid>habash and rambow, 2006; <papid> P06-1086 </papid>chiang et al, 2006).<papid> E06-1047 </papid></nextsent>
<nextsent>several researchers have explored the idea of exploiting existing msa rich resources to build tools for da nlp, e.g., chiang et al (2006)<papid> E06-1047 </papid>built syntactic parsers for da trained on msa treebanks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI773">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the rest of this paper is structured as follows:section 2 is related work, section 3 presents linguistic challenges and motivation, section 4 details our approach and section 5 presents results evaluating our approach under variety of conditions.
</prevsent>
<prevsent>dialectal arabic nlp much work has been donein the context of msa nlp (habash, 2010).
</prevsent>
</prevsection>
<citsent citstr=" N06-2051 ">
specifically for arabic-to-english smt, the importance of tokenization using morphological analysis has been shown by many researchers (lee, 2004; <papid> N04-4015 </papid>zollmann et al, 2006; <papid> N06-2051 </papid>habash and sadat, 2006).<papid> N06-2013 </papid></citsent>
<aftsection>
<nextsent>in contrast,research on da nlp is still in its early stages: (ki lany et al, 2002; kirchhoff et al, 2003; duh and kirchhoff, 2005; <papid> W05-0708 </papid>habash and rambow, 2006; <papid> P06-1086 </papid>chiang et al, 2006).<papid> E06-1047 </papid></nextsent>
<nextsent>several researchers have explored the idea of exploiting existing msa rich resources to build tools for da nlp, e.g., chiang et al (2006)<papid> E06-1047 </papid>built syntactic parsers for da trained on msa treebanks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI774">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the rest of this paper is structured as follows:section 2 is related work, section 3 presents linguistic challenges and motivation, section 4 details our approach and section 5 presents results evaluating our approach under variety of conditions.
</prevsent>
<prevsent>dialectal arabic nlp much work has been donein the context of msa nlp (habash, 2010).
</prevsent>
</prevsection>
<citsent citstr=" N06-2013 ">
specifically for arabic-to-english smt, the importance of tokenization using morphological analysis has been shown by many researchers (lee, 2004; <papid> N04-4015 </papid>zollmann et al, 2006; <papid> N06-2051 </papid>habash and sadat, 2006).<papid> N06-2013 </papid></citsent>
<aftsection>
<nextsent>in contrast,research on da nlp is still in its early stages: (ki lany et al, 2002; kirchhoff et al, 2003; duh and kirchhoff, 2005; <papid> W05-0708 </papid>habash and rambow, 2006; <papid> P06-1086 </papid>chiang et al, 2006).<papid> E06-1047 </papid></nextsent>
<nextsent>several researchers have explored the idea of exploiting existing msa rich resources to build tools for da nlp, e.g., chiang et al (2006)<papid> E06-1047 </papid>built syntactic parsers for da trained on msa treebanks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI775">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>dialectal arabic nlp much work has been donein the context of msa nlp (habash, 2010).
</prevsent>
<prevsent>specifically for arabic-to-english smt, the importance of tokenization using morphological analysis has been shown by many researchers (lee, 2004; <papid> N04-4015 </papid>zollmann et al, 2006; <papid> N06-2051 </papid>habash and sadat, 2006).<papid> N06-2013 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-0708 ">
in contrast,research on da nlp is still in its early stages: (ki lany et al, 2002; kirchhoff et al, 2003; duh and kirchhoff, 2005; <papid> W05-0708 </papid>habash and rambow, 2006; <papid> P06-1086 </papid>chiang et al, 2006).<papid> E06-1047 </papid></citsent>
<aftsection>
<nextsent>several researchers have explored the idea of exploiting existing msa rich resources to build tools for da nlp, e.g., chiang et al (2006)<papid> E06-1047 </papid>built syntactic parsers for da trained on msa treebanks.</nextsent>
<nextsent>such approaches typically expect the presence of tools/resources to relate da words to their msa variants or translations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI776">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>dialectal arabic nlp much work has been donein the context of msa nlp (habash, 2010).
</prevsent>
<prevsent>specifically for arabic-to-english smt, the importance of tokenization using morphological analysis has been shown by many researchers (lee, 2004; <papid> N04-4015 </papid>zollmann et al, 2006; <papid> N06-2051 </papid>habash and sadat, 2006).<papid> N06-2013 </papid></prevsent>
</prevsection>
<citsent citstr=" P06-1086 ">
in contrast,research on da nlp is still in its early stages: (ki lany et al, 2002; kirchhoff et al, 2003; duh and kirchhoff, 2005; <papid> W05-0708 </papid>habash and rambow, 2006; <papid> P06-1086 </papid>chiang et al, 2006).<papid> E06-1047 </papid></citsent>
<aftsection>
<nextsent>several researchers have explored the idea of exploiting existing msa rich resources to build tools for da nlp, e.g., chiang et al (2006)<papid> E06-1047 </papid>built syntactic parsers for da trained on msa treebanks.</nextsent>
<nextsent>such approaches typically expect the presence of tools/resources to relate da words to their msa variants or translations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI780">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>dialectal arabic nlp much work has been donein the context of msa nlp (habash, 2010).
</prevsent>
<prevsent>specifically for arabic-to-english smt, the importance of tokenization using morphological analysis has been shown by many researchers (lee, 2004; <papid> N04-4015 </papid>zollmann et al, 2006; <papid> N06-2051 </papid>habash and sadat, 2006).<papid> N06-2013 </papid></prevsent>
</prevsection>
<citsent citstr=" E06-1047 ">
in contrast,research on da nlp is still in its early stages: (ki lany et al, 2002; kirchhoff et al, 2003; duh and kirchhoff, 2005; <papid> W05-0708 </papid>habash and rambow, 2006; <papid> P06-1086 </papid>chiang et al, 2006).<papid> E06-1047 </papid></citsent>
<aftsection>
<nextsent>several researchers have explored the idea of exploiting existing msa rich resources to build tools for da nlp, e.g., chiang et al (2006)<papid> E06-1047 </papid>built syntactic parsers for da trained on msa treebanks.</nextsent>
<nextsent>such approaches typically expect the presence of tools/resources to relate da words to their msa variants or translations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI782">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the context of arabic dialect translation, sawaf (2010) built ahybrid mt system that uses both statistical and rule based approaches for da-to-english mt. in his approach, da is normalized into msa using dialectal morphological analyzer.
</prevsent>
<prevsent>this use of resource rich?
</prevsent>
</prevsection>
<citsent citstr=" N07-1061 ">
related languages is specific variant of themore general approach of using pivot/bridge languages (utiyama and isahara, 2007; <papid> N07-1061 </papid>kumar et al, 2007).<papid> D07-1005 </papid></citsent>
<aftsection>
<nextsent>in the case of msa and da variants, it is plausible to consider the msa variants of da phrase as monolingual paraphrases (callison-burch et al, 2006; habash, 2008; <papid> P08-2015 </papid>du et al, 2010).this paper presents results on rule-based system to generate alternative paraphrases for da oov words and low frequency words to help improve smt from highly dialectal arabic to english.</nextsent>
<nextsent>our work is most similar to sawaf (2010)s approach to da normalization into msa, although we shy away from the term in our work since we do not produce asingle msa version of the input to pass on to msa english mt. instead we pass multiple paraphrases (or alternative normalizations) as lattice to an smt system, in manner similar to du et al (2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI783">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the context of arabic dialect translation, sawaf (2010) built ahybrid mt system that uses both statistical and rule based approaches for da-to-english mt. in his approach, da is normalized into msa using dialectal morphological analyzer.
</prevsent>
<prevsent>this use of resource rich?
</prevsent>
</prevsection>
<citsent citstr=" D07-1005 ">
related languages is specific variant of themore general approach of using pivot/bridge languages (utiyama and isahara, 2007; <papid> N07-1061 </papid>kumar et al, 2007).<papid> D07-1005 </papid></citsent>
<aftsection>
<nextsent>in the case of msa and da variants, it is plausible to consider the msa variants of da phrase as monolingual paraphrases (callison-burch et al, 2006; habash, 2008; <papid> P08-2015 </papid>du et al, 2010).this paper presents results on rule-based system to generate alternative paraphrases for da oov words and low frequency words to help improve smt from highly dialectal arabic to english.</nextsent>
<nextsent>our work is most similar to sawaf (2010)s approach to da normalization into msa, although we shy away from the term in our work since we do not produce asingle msa version of the input to pass on to msa english mt. instead we pass multiple paraphrases (or alternative normalizations) as lattice to an smt system, in manner similar to du et al (2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI784">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this use of resource rich?
</prevsent>
<prevsent>related languages is specific variant of themore general approach of using pivot/bridge languages (utiyama and isahara, 2007; <papid> N07-1061 </papid>kumar et al, 2007).<papid> D07-1005 </papid></prevsent>
</prevsection>
<citsent citstr=" P08-2015 ">
in the case of msa and da variants, it is plausible to consider the msa variants of da phrase as monolingual paraphrases (callison-burch et al, 2006; habash, 2008; <papid> P08-2015 </papid>du et al, 2010).this paper presents results on rule-based system to generate alternative paraphrases for da oov words and low frequency words to help improve smt from highly dialectal arabic to english.</citsent>
<aftsection>
<nextsent>our work is most similar to sawaf (2010)s approach to da normalization into msa, although we shy away from the term in our work since we do not produce asingle msa version of the input to pass on to msa english mt. instead we pass multiple paraphrases (or alternative normalizations) as lattice to an smt system, in manner similar to du et al (2010).
</nextsent>
<nextsent>certain aspects of our approach are similar to riesaand yarowsky (2006)s, in that we use morphological analysis for da to help da-english mt; but unlike them and similar to sawaf (2010), we use rule-based approach to model da morphology.
</nextsent>
<nextsent>our morphological analysis implementation is quite similar to the approach taken by abo bakr et al (2008), which extend existing msa analyzers through rules;however, unlike them, we are not interested in generating msa perse, but rather to use it as bridge to english mt. our interest in oov words is similar to habash (2008), <papid> P08-2015 </papid>who compared multiple techniques for handling msa oovs; however, unlike him, we target dialectal phenomena and we use lattices as input to the smt system.</nextsent>
<nextsent>also related is the recent work by nakov and ng (2011), <papid> P11-1130 </papid>who use morphological knowledge to generate paraphrases for morphologically rich language, malay, to extend the phrase table in malay-to-english smt system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI786">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>certain aspects of our approach are similar to riesaand yarowsky (2006)s, in that we use morphological analysis for da to help da-english mt; but unlike them and similar to sawaf (2010), we use rule-based approach to model da morphology.
</prevsent>
<prevsent>our morphological analysis implementation is quite similar to the approach taken by abo bakr et al (2008), which extend existing msa analyzers through rules;however, unlike them, we are not interested in generating msa perse, but rather to use it as bridge to english mt. our interest in oov words is similar to habash (2008), <papid> P08-2015 </papid>who compared multiple techniques for handling msa oovs; however, unlike him, we target dialectal phenomena and we use lattices as input to the smt system.</prevsent>
</prevsection>
<citsent citstr=" P11-1130 ">
also related is the recent work by nakov and ng (2011), <papid> P11-1130 </papid>who use morphological knowledge to generate paraphrases for morphologically rich language, malay, to extend the phrase table in malay-to-english smt system.</citsent>
<aftsection>
<nextsent>we are primarily interested in improving arabic english smt on highly dialectal text.
</nextsent>
<nextsent>this particular type of text has many challenges.
</nextsent>
<nextsent>we discuss these challenges and motivate our research approach with an analysis of da oov terms in state-of-the art smt system.
</nextsent>
<nextsent>3.1 arabic linguistic challenges.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI787">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> challenge and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, some letters in arabic are often spelled inconsistently which leads to an increase in both sparsity (multiple forms of thesame word) and ambiguity (same form corresponding to multiple words), e.g., variants of hamza ted alif, @ ? or @ a?, are often written without their hamza (z ?): @ a; and the alif-maqsura (or dotless ya) ? ?
</prevsent>
<prevsent>and the regular dotted ya ? are often used interchangeably in word final position (kholy and habash, 2010).
</prevsent>
</prevsection>
<citsent citstr=" P05-1071 ">
arabic complex morphology and ambiguity are handled using tools for disambiguation and tokenization (habash and rambow, 2005;<papid> P05-1071 </papid>diab et al, 2007).</citsent>
<aftsection>
<nextsent>for our smt system, we pre process the arabic text so that it is tokenized in the penn arabic treebank tokenization (maamouri et al, 2004), alif/ya normalized and undiacritized.these measures have an important effect on reducing overall oov rate (habash, 2008).<papid> P08-2015 </papid></nextsent>
<nextsent>3.2 dialectal arabic challenges.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI796">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>forms of the target analyses.
</prevsent>
<prevsent>the core steps of analysis-transfer-generation are similar to generic transfer-based mt (dorr et al, 1999).
</prevsent>
</prevsection>
<citsent citstr=" W07-0728 ">
in essence our approach can be thought of as mini-rule-based system that is used to hybridize an smt system (simard et al, 2007; <papid> W07-0728 </papid>sawaf, 2010).</citsent>
<aftsection>
<nextsent>4.1 selection.
</nextsent>
<nextsent>the most obvious set of words to select for paraphrasing is the phrase-table oov words.
</nextsent>
<nextsent>we identify them by comparing each word in the source text against all phrase-table singletons.
</nextsent>
<nextsent>another set of words to consider includes low frequency words (da or msa), which are less likely to be associated with good phrase-table translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI806">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>weonly focus on extensions that address dialectal af fixes and clitics, as opposed to stems, which we planto address in future work.
</prevsent>
<prevsent>this approach to extending an msa analyzer is similar to work done by abo bakr et al (2008) and it contrasts as rather shallow/quick-and-dirty solution compared to other more demanding efforts on building dialectal analyzers from scratch, such as the magead system (habash and rambow, 2006; <papid> P06-1086 </papid>altantawy et al, 2011).</prevsent>
</prevsection>
<citsent citstr=" P08-2030 ">
4.2.1 adam: analyzer for dialectal arabic morphology adam is built on the top of bama database(buckwalter, 2004) as used in the almor morphological analyzer/generator (habash, 2007), which is the rule-based component of the mada system for morphological analysis and disambiguation of arabic (habash and rambow, 2005;<papid> P05-1071 </papid> roth et al, 2008).<papid> P08-2030 </papid></citsent>
<aftsection>
<nextsent>the almor system presents analyses as lemma and feature-value pairs including clitics.
</nextsent>
<nextsent>the bama databases contain three tables of arabic stems, complex prefixes and complex suf fixes2 and three additional tables with constraints on matching them.
</nextsent>
<nextsent>msa, according to the bamadatabases, has 1,208 complex prefixes and 940 complex suffixes, which correspond to 49 simple prefixes/proclitics and 177 simple suffixes/enclitics, respectively.
</nextsent>
<nextsent>the number of combinations in prefixes is lot bigger than in suffixes, which explains the different proportions of complex affixes to simple affixes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI807">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> evaluation on machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>the various generated forms are added in the lattices, which are then input to the smt system.
</prevsent>
<prevsent>5.1 experimental setup.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we use the open-source moses toolkit (koehn et al., 2007) <papid> P07-2045 </papid>to build two phrase-based smt system strained on two different data conditions: medium scale msa-only system trained using newswire (msa-english) parallel text with 12m words on the arabic side (ldc2007e103) and large-scale msa/da-mixed system (64m words on the arabic side) trained using several ldc corpora including some limited da data.</citsent>
<aftsection>
<nextsent>both systems use standard phrase-based architecture.
</nextsent>
<nextsent>the parallel corpus is word-aligned using giza++ (och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>phrase translations of up to 10 words are extracted in the moses phrase table.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI808">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> evaluation on machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>we use the open-source moses toolkit (koehn et al., 2007) <papid> P07-2045 </papid>to build two phrase-based smt system strained on two different data conditions: medium scale msa-only system trained using newswire (msa-english) parallel text with 12m words on the arabic side (ldc2007e103) and large-scale msa/da-mixed system (64m words on the arabic side) trained using several ldc corpora including some limited da data.</prevsent>
<prevsent>both systems use standard phrase-based architecture.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the parallel corpus is word-aligned using giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>phrase translations of up to 10 words are extracted in the moses phrase table.
</nextsent>
<nextsent>the language model for both systems is trained on the english may be complicated to explain given the allotted space, as such we present only the functional description of the trs.side of the large bitext augmented with english gigaword data.
</nextsent>
<nextsent>we use 5-gram language model with modified kneser-ney smoothing.
</nextsent>
<nextsent>feature weights are tuned to maximize bleu on the nist mteval 2006 test set using minimum error rate training(och, 2003).<papid> P03-1021 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI809">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> evaluation on machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>the language model for both systems is trained on the english may be complicated to explain given the allotted space, as such we present only the functional description of the trs.side of the large bitext augmented with english gigaword data.
</prevsent>
<prevsent>we use 5-gram language model with modified kneser-ney smoothing.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
feature weights are tuned to maximize bleu on the nist mteval 2006 test set using minimum error rate training(och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>this is only done on the baseline sys tems.for all systems, the english data is tokenized using simple punctuation-based rules.
</nextsent>
<nextsent>the arabic sideis segmented according to the arabic treebank tokenization scheme (maamouri et al, 2004) using themada+tokan morphological analyzer and tok enizer (habash and rambow, 2005) ? <papid> P05-1071 </papid>v3.1 (roth etal., 2008).<papid> P08-2030 </papid></nextsent>
<nextsent>the arabic text is also alif/ya normalized (habash, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI812">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> evaluation on machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>the arabic text is also alif/ya normalized (habash, 2010).
</prevsent>
<prevsent>mada-produced arabic lem mas are used for word alignment.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
results are presented in terms of bleu (papineniet al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002) and meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>metrics.4 how ever, all optimizations were done against the bleu metric.</citsent>
<aftsection>
<nextsent>all evaluation results are case insensitive.
</nextsent>
<nextsent>all of the systems we present use the lattice input format to moses (dyer et al, 2008), <papid> P08-1115 </papid>including the baselines which do not need them.</nextsent>
<nextsent>we do not report on the non-lattice baselines, but in initial experiments we conducted, they did not perform as well as the degenerate lattice version.the devtest set our devtest set consists of sentences containing at least one non-msa segment (asannotated by ldc)5 in the dev10 audio development data under the darpa gale program.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI813">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> evaluation on machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>the arabic text is also alif/ya normalized (habash, 2010).
</prevsent>
<prevsent>mada-produced arabic lem mas are used for word alignment.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
results are presented in terms of bleu (papineniet al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002) and meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>metrics.4 how ever, all optimizations were done against the bleu metric.</citsent>
<aftsection>
<nextsent>all evaluation results are case insensitive.
</nextsent>
<nextsent>all of the systems we present use the lattice input format to moses (dyer et al, 2008), <papid> P08-1115 </papid>including the baselines which do not need them.</nextsent>
<nextsent>we do not report on the non-lattice baselines, but in initial experiments we conducted, they did not perform as well as the degenerate lattice version.the devtest set our devtest set consists of sentences containing at least one non-msa segment (asannotated by ldc)5 in the dev10 audio development data under the darpa gale program.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI814">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> evaluation on machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>results are presented in terms of bleu (papineniet al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002) and meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>metrics.4 how ever, all optimizations were done against the bleu metric.</prevsent>
<prevsent>all evaluation results are case insensitive.</prevsent>
</prevsection>
<citsent citstr=" P08-1115 ">
all of the systems we present use the lattice input format to moses (dyer et al, 2008), <papid> P08-1115 </papid>including the baselines which do not need them.</citsent>
<aftsection>
<nextsent>we do not report on the non-lattice baselines, but in initial experiments we conducted, they did not perform as well as the degenerate lattice version.the devtest set our devtest set consists of sentences containing at least one non-msa segment (asannotated by ldc)5 in the dev10 audio development data under the darpa gale program.
</nextsent>
<nextsent>thedata contains broadcast conversational (bc) segments (with three reference translations), and broadcast news (bn) segments (with only one reference, replicated three times).
</nextsent>
<nextsent>the dataset contained amix of arabic dialects, with levantine arabic being the most common variety.
</nextsent>
<nextsent>the particular nature of the devtest being transcripts of audio data adds some challenges to mt systems trained on primarily written data in news genre.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI817">
<title id=" W11-2602.xml">dialectal to standard arabic paraphrasing to improve arabic english statistical machine translation </title>
<section> evaluation on machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>that said, our best result with oov handling produces higher bleu score (36.61) which is nice result for doing the right thing and not just deleting problem words.
</prevsent>
<prevsent>all differences in bleu scores in the large system are statistically significant above the 95% level.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
statistical significance is computed using paired bootstrap re sampling (koehn, 2004).<papid> W04-3250 </papid></citsent>
<aftsection>
<nextsent>16 large (64m words) medium (12m words) system bleu prec-1 prec-2 nist meteor bleu prec-1 prec-2 nist meteor baseline 36.16 74.56 45.04 8.9958 52.59 20.09 63.69 30.89 6.0039 40.85 adam only 36.50 74.79 45.22 9.0655 52.95 20.51 64.37 31.22 6.1994 41.80 adam+transfer 36.61 74.85 45.37 9.0825 53.02 20.60 64.70 31.48 6.1740 41.77 table 1: results for the dev set under large and medium training conditions.
</nextsent>
<nextsent>the baseline is compared to using dialectal morphological analysis only and analysis plus transfer to msa.
</nextsent>
<nextsent>bleu and meteor scores are presented as percentages.
</nextsent>
<nextsent>large (64m words) system bleu prec-1 prec-2 nist meteor baseline 36.16 74.56 45.04 8.9958 52.59 adam+transfer 36.61 74.85 45.37 9.0825 53.02 + freq ? 10 36.71 74.89 45.50 9.0821 52.97 + freq xmsa ? 10 36.62 74.86 45.38 9.0816 52.96 + freq xdiamsa ? 13 36.66 74.86 45.43 9.0836 53.01 + freq xdia ? 45 36.73 75.00 45.57 9.0961 53.03 + freq xmsa ? 10 + xdiamsa ? 13 + xdia ? 45 36.78 74.96 45.61 9.0926 52.96 table 2: results for the dev set under large training condition, varying the set of words selected for msa paraphrasing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI821">
<title id=" W12-0803.xml">ttt a tree transduction language for syntactic and semantic processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pattern matching and pattern-driven transformations of list-structured symbolic expressions or trees are fundamental tools in ai.
</prevsent>
<prevsent>they facilitate many symbol manipulation tasks, including operations on parse trees and logical forms, and even inference and aspects of dialogue and translation.the ttt system allows concise and transparent specification of rules for such tasks, in particular (as we will show), parse tree refinement and correction, predicate disambiguation, logical form refinement, inference, and verbal ization into english.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
in parse tree refinement, our particular focus has been on repair of malformed parses of image captions, as obtained by the charniak-johnson parser (charniak and johnson, 2005).<papid> P05-1022 </papid></citsent>
<aftsection>
<nextsent>this has encompassed such tasks as distinguishing passive participles from past participles and temporal nominals from non-temporal ones, among other tasks which will be discussed later.
</nextsent>
<nextsent>for example, standard treebank parses tag both past participles (as in has written?)
</nextsent>
<nextsent>and passive participles (as in was written?)
</nextsent>
<nextsent>as vbn.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI822">
<title id=" W12-0803.xml">ttt a tree transduction language for syntactic and semantic processing </title>
<section> ttt.  </section>
<citcontext>
<prevsection>
<prevsent>a good 25 overview of the dimensions of variability among formal tree transducers is given in (knight, 2007).
</prevsent>
<prevsent>the main properties are restrictions on the height of the tree fragments allowed in rules, linearity,and whether the rules can delete arbitrary subtrees.
</prevsent>
</prevsection>
<citsent citstr=" N04-1035 ">
among the more popular and recent ones, synchronous tree substitution grammars (stsg), synchronous tree sequence substitution grammars(stssg), and multi bottom-up tree transducers (mbot) constrain their rules to be linear and non-deleting, which is important for efficient rule learning and transduction execution (chiang, 2004; galley et. al, 2004; <papid> N04-1035 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>zhang et. al, 2008; <papid> P08-1064 </papid>maletti, 2010).<papid> N10-1130 </papid></citsent>
<aftsection>
<nextsent>the language ttt does not have any such restrictions, as it is intended as general programming aid, with concise syntax for potentially radical transformations, rather than amodel of particular classes of linguistic operations.
</nextsent>
<nextsent>thus, for example, the 5-element pattern (!
</nextsent>
<nextsent>((* a) b) ((* a) c) ((* a) d)((* a) e) ((* a))) applied to the expression (a a a) rescans the latter 5 times, implying quadratic complexity.
</nextsent>
<nextsent>(our current implementation does not attempt regular expression reduction for efficient recognition.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI823">
<title id=" W12-0803.xml">ttt a tree transduction language for syntactic and semantic processing </title>
<section> ttt.  </section>
<citcontext>
<prevsection>
<prevsent>a good 25 overview of the dimensions of variability among formal tree transducers is given in (knight, 2007).
</prevsent>
<prevsent>the main properties are restrictions on the height of the tree fragments allowed in rules, linearity,and whether the rules can delete arbitrary subtrees.
</prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
among the more popular and recent ones, synchronous tree substitution grammars (stsg), synchronous tree sequence substitution grammars(stssg), and multi bottom-up tree transducers (mbot) constrain their rules to be linear and non-deleting, which is important for efficient rule learning and transduction execution (chiang, 2004; galley et. al, 2004; <papid> N04-1035 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>zhang et. al, 2008; <papid> P08-1064 </papid>maletti, 2010).<papid> N10-1130 </papid></citsent>
<aftsection>
<nextsent>the language ttt does not have any such restrictions, as it is intended as general programming aid, with concise syntax for potentially radical transformations, rather than amodel of particular classes of linguistic operations.
</nextsent>
<nextsent>thus, for example, the 5-element pattern (!
</nextsent>
<nextsent>((* a) b) ((* a) c) ((* a) d)((* a) e) ((* a))) applied to the expression (a a a) rescans the latter 5 times, implying quadratic complexity.
</nextsent>
<nextsent>(our current implementation does not attempt regular expression reduction for efficient recognition.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI824">
<title id=" W12-0803.xml">ttt a tree transduction language for syntactic and semantic processing </title>
<section> ttt.  </section>
<citcontext>
<prevsection>
<prevsent>a good 25 overview of the dimensions of variability among formal tree transducers is given in (knight, 2007).
</prevsent>
<prevsent>the main properties are restrictions on the height of the tree fragments allowed in rules, linearity,and whether the rules can delete arbitrary subtrees.
</prevsent>
</prevsection>
<citsent citstr=" P08-1064 ">
among the more popular and recent ones, synchronous tree substitution grammars (stsg), synchronous tree sequence substitution grammars(stssg), and multi bottom-up tree transducers (mbot) constrain their rules to be linear and non-deleting, which is important for efficient rule learning and transduction execution (chiang, 2004; galley et. al, 2004; <papid> N04-1035 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>zhang et. al, 2008; <papid> P08-1064 </papid>maletti, 2010).<papid> N10-1130 </papid></citsent>
<aftsection>
<nextsent>the language ttt does not have any such restrictions, as it is intended as general programming aid, with concise syntax for potentially radical transformations, rather than amodel of particular classes of linguistic operations.
</nextsent>
<nextsent>thus, for example, the 5-element pattern (!
</nextsent>
<nextsent>((* a) b) ((* a) c) ((* a) d)((* a) e) ((* a))) applied to the expression (a a a) rescans the latter 5 times, implying quadratic complexity.
</nextsent>
<nextsent>(our current implementation does not attempt regular expression reduction for efficient recognition.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI825">
<title id=" W12-0803.xml">ttt a tree transduction language for syntactic and semantic processing </title>
<section> ttt.  </section>
<citcontext>
<prevsection>
<prevsent>a good 25 overview of the dimensions of variability among formal tree transducers is given in (knight, 2007).
</prevsent>
<prevsent>the main properties are restrictions on the height of the tree fragments allowed in rules, linearity,and whether the rules can delete arbitrary subtrees.
</prevsent>
</prevsection>
<citsent citstr=" N10-1130 ">
among the more popular and recent ones, synchronous tree substitution grammars (stsg), synchronous tree sequence substitution grammars(stssg), and multi bottom-up tree transducers (mbot) constrain their rules to be linear and non-deleting, which is important for efficient rule learning and transduction execution (chiang, 2004; galley et. al, 2004; <papid> N04-1035 </papid>yamada and knight, 2001; <papid> P01-1067 </papid>zhang et. al, 2008; <papid> P08-1064 </papid>maletti, 2010).<papid> N10-1130 </papid></citsent>
<aftsection>
<nextsent>the language ttt does not have any such restrictions, as it is intended as general programming aid, with concise syntax for potentially radical transformations, rather than amodel of particular classes of linguistic operations.
</nextsent>
<nextsent>thus, for example, the 5-element pattern (!
</nextsent>
<nextsent>((* a) b) ((* a) c) ((* a) d)((* a) e) ((* a))) applied to the expression (a a a) rescans the latter 5 times, implying quadratic complexity.
</nextsent>
<nextsent>(our current implementation does not attempt regular expression reduction for efficient recognition.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI826">
<title id=" W12-0803.xml">ttt a tree transduction language for syntactic and semantic processing </title>
<section> some linguistic examples.  </section>
<citcontext>
<prevsection>
<prevsent>(/ (_* (most _!.1 (_!.1 (!.p pred?)) (_!.1 (!.q pred?))) _* (most _!.2 (_!.2 !.q) (_!.2 (!.r pred?))) _*) (many _!.1 (_!.1 !.p) (_!.1 !.r))) for example, ((most (x dog.n) (x pet.n)) (most (y pet.n) (x friendly.a))) yields the default inference (many (x dog.n) (x friendly.a)).the assumption here is that the two most formulas are embedded in list of formulas (se lected by the inference algorithm), and the three occurrences of * allow for miscellaneous surrounding formulas.
</prevsent>
<prevsent>(to allow for arbitrary ordering of formulas in the working set, we also provide variant with the two most-formulas in reverse order.)
</prevsent>
</prevsection>
<citsent citstr=" P10-1004 ">
inference with tree transduction rules has also been performed by (koller and stefan, 2010).<papid> P10-1004 </papid></citsent>
<aftsection>
<nextsent>predicate disambiguation: the following rules are applicable to patterns of predica tion such as ((det dog.n have.v (det tail.n)), ((det bird.n have.v (det nest.n)), and ((det man.n) have.v (det accident.n)).
</nextsent>
<nextsent>(think of det as an unspecified, uns coped quantifier.)
</nextsent>
<nextsent>the rules simultaneously introduce plausible patterns of quantification and plausible disambiguations of the various senses of have.v (e.g., have as part, possess, eat, experience): (/ ((det (!
</nextsent>
<nextsent>animal?)) have.v (det (!1 animal-part?))) (all-or-most (x !)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI827">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is especially true in situated settings, where sudden changes of context can occur at anytime.
</prevsent>
<prevsent>sources of uncertainty include (a) the situational context, such as visible objects, or task complexity, (b) the user, including their behaviour and reactions, and (c) the dialogue history, including shared knowledge or patterns of linguistic consistency (halliday and hasan, 1976) and alignment (pickering and garrod, 2004).
</prevsent>
</prevsection>
<citsent citstr=" W06-1412 ">
previous work on context-sensitive generation in situated domains includes stoia et al (2006) <papid> W06-1412 </papid>and garoufi and koller (2010).<papid> P10-1159 </papid></citsent>
<aftsection>
<nextsent>stoia et al present supervised learning approach for situated referring expression generation (reg).
</nextsent>
<nextsent>garoufi and koller use techniques from ai planning for the combined generation of navigation instructions and referring expressions (re).
</nextsent>
<nextsent>more generally, the nlg problem of non-deterministic decisionmaking has been addressed from many different angles, including penman-style choosers (mann and matthiessen,1983), corpus-based statistical knowledge (langk ilde and knight, 1998), <papid> P98-1116 </papid>tree-based stochastic models(bangalore and rambow, 2000), <papid> C00-1007 </papid>maximum entropy based ranking (ratnaparkhi, 2000), <papid> A00-2026 </papid>combinatorial pattern discovery (duboue and mckeown, 2001),<papid> P01-1023 </papid>instance-based ranking (varges, 2003), chart generation (white, 2004), planning (koller and stone, 2007), <papid> P07-1043 </papid>or probabilistic generation spaces (belz, 2008) to name just few.</nextsent>
<nextsent>more recently, there have been several approaches towards using reinforcement learning (rl) (rieseret al, 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010) <papid> P10-1008 </papid>or hierarchical reinforcement learning (hrl) (dethlefs and cuayahuitl, 2010) for nlg decision mak ing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI828">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is especially true in situated settings, where sudden changes of context can occur at anytime.
</prevsent>
<prevsent>sources of uncertainty include (a) the situational context, such as visible objects, or task complexity, (b) the user, including their behaviour and reactions, and (c) the dialogue history, including shared knowledge or patterns of linguistic consistency (halliday and hasan, 1976) and alignment (pickering and garrod, 2004).
</prevsent>
</prevsection>
<citsent citstr=" P10-1159 ">
previous work on context-sensitive generation in situated domains includes stoia et al (2006) <papid> W06-1412 </papid>and garoufi and koller (2010).<papid> P10-1159 </papid></citsent>
<aftsection>
<nextsent>stoia et al present supervised learning approach for situated referring expression generation (reg).
</nextsent>
<nextsent>garoufi and koller use techniques from ai planning for the combined generation of navigation instructions and referring expressions (re).
</nextsent>
<nextsent>more generally, the nlg problem of non-deterministic decisionmaking has been addressed from many different angles, including penman-style choosers (mann and matthiessen,1983), corpus-based statistical knowledge (langk ilde and knight, 1998), <papid> P98-1116 </papid>tree-based stochastic models(bangalore and rambow, 2000), <papid> C00-1007 </papid>maximum entropy based ranking (ratnaparkhi, 2000), <papid> A00-2026 </papid>combinatorial pattern discovery (duboue and mckeown, 2001),<papid> P01-1023 </papid>instance-based ranking (varges, 2003), chart generation (white, 2004), planning (koller and stone, 2007), <papid> P07-1043 </papid>or probabilistic generation spaces (belz, 2008) to name just few.</nextsent>
<nextsent>more recently, there have been several approaches towards using reinforcement learning (rl) (rieseret al, 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010) <papid> P10-1008 </papid>or hierarchical reinforcement learning (hrl) (dethlefs and cuayahuitl, 2010) for nlg decision mak ing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI829">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>stoia et al present supervised learning approach for situated referring expression generation (reg).
</prevsent>
<prevsent>garoufi and koller use techniques from ai planning for the combined generation of navigation instructions and referring expressions (re).
</prevsent>
</prevsection>
<citsent citstr=" P98-1116 ">
more generally, the nlg problem of non-deterministic decisionmaking has been addressed from many different angles, including penman-style choosers (mann and matthiessen,1983), corpus-based statistical knowledge (langk ilde and knight, 1998), <papid> P98-1116 </papid>tree-based stochastic models(bangalore and rambow, 2000), <papid> C00-1007 </papid>maximum entropy based ranking (ratnaparkhi, 2000), <papid> A00-2026 </papid>combinatorial pattern discovery (duboue and mckeown, 2001),<papid> P01-1023 </papid>instance-based ranking (varges, 2003), chart generation (white, 2004), planning (koller and stone, 2007), <papid> P07-1043 </papid>or probabilistic generation spaces (belz, 2008) to name just few.</citsent>
<aftsection>
<nextsent>more recently, there have been several approaches towards using reinforcement learning (rl) (rieseret al, 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010) <papid> P10-1008 </papid>or hierarchical reinforcement learning (hrl) (dethlefs and cuayahuitl, 2010) for nlg decision mak ing.</nextsent>
<nextsent>all of these approaches have demonstrated thathrl/rl offers powerful mechanism for learning generation policies in the absence of complete knowledge about the environment or the user.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI830">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>stoia et al present supervised learning approach for situated referring expression generation (reg).
</prevsent>
<prevsent>garoufi and koller use techniques from ai planning for the combined generation of navigation instructions and referring expressions (re).
</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
more generally, the nlg problem of non-deterministic decisionmaking has been addressed from many different angles, including penman-style choosers (mann and matthiessen,1983), corpus-based statistical knowledge (langk ilde and knight, 1998), <papid> P98-1116 </papid>tree-based stochastic models(bangalore and rambow, 2000), <papid> C00-1007 </papid>maximum entropy based ranking (ratnaparkhi, 2000), <papid> A00-2026 </papid>combinatorial pattern discovery (duboue and mckeown, 2001),<papid> P01-1023 </papid>instance-based ranking (varges, 2003), chart generation (white, 2004), planning (koller and stone, 2007), <papid> P07-1043 </papid>or probabilistic generation spaces (belz, 2008) to name just few.</citsent>
<aftsection>
<nextsent>more recently, there have been several approaches towards using reinforcement learning (rl) (rieseret al, 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010) <papid> P10-1008 </papid>or hierarchical reinforcement learning (hrl) (dethlefs and cuayahuitl, 2010) for nlg decision mak ing.</nextsent>
<nextsent>all of these approaches have demonstrated thathrl/rl offers powerful mechanism for learning generation policies in the absence of complete knowledge about the environment or the user.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI831">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>stoia et al present supervised learning approach for situated referring expression generation (reg).
</prevsent>
<prevsent>garoufi and koller use techniques from ai planning for the combined generation of navigation instructions and referring expressions (re).
</prevsent>
</prevsection>
<citsent citstr=" A00-2026 ">
more generally, the nlg problem of non-deterministic decisionmaking has been addressed from many different angles, including penman-style choosers (mann and matthiessen,1983), corpus-based statistical knowledge (langk ilde and knight, 1998), <papid> P98-1116 </papid>tree-based stochastic models(bangalore and rambow, 2000), <papid> C00-1007 </papid>maximum entropy based ranking (ratnaparkhi, 2000), <papid> A00-2026 </papid>combinatorial pattern discovery (duboue and mckeown, 2001),<papid> P01-1023 </papid>instance-based ranking (varges, 2003), chart generation (white, 2004), planning (koller and stone, 2007), <papid> P07-1043 </papid>or probabilistic generation spaces (belz, 2008) to name just few.</citsent>
<aftsection>
<nextsent>more recently, there have been several approaches towards using reinforcement learning (rl) (rieseret al, 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010) <papid> P10-1008 </papid>or hierarchical reinforcement learning (hrl) (dethlefs and cuayahuitl, 2010) for nlg decision mak ing.</nextsent>
<nextsent>all of these approaches have demonstrated thathrl/rl offers powerful mechanism for learning generation policies in the absence of complete knowledge about the environment or the user.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI832">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>stoia et al present supervised learning approach for situated referring expression generation (reg).
</prevsent>
<prevsent>garoufi and koller use techniques from ai planning for the combined generation of navigation instructions and referring expressions (re).
</prevsent>
</prevsection>
<citsent citstr=" P01-1023 ">
more generally, the nlg problem of non-deterministic decisionmaking has been addressed from many different angles, including penman-style choosers (mann and matthiessen,1983), corpus-based statistical knowledge (langk ilde and knight, 1998), <papid> P98-1116 </papid>tree-based stochastic models(bangalore and rambow, 2000), <papid> C00-1007 </papid>maximum entropy based ranking (ratnaparkhi, 2000), <papid> A00-2026 </papid>combinatorial pattern discovery (duboue and mckeown, 2001),<papid> P01-1023 </papid>instance-based ranking (varges, 2003), chart generation (white, 2004), planning (koller and stone, 2007), <papid> P07-1043 </papid>or probabilistic generation spaces (belz, 2008) to name just few.</citsent>
<aftsection>
<nextsent>more recently, there have been several approaches towards using reinforcement learning (rl) (rieseret al, 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010) <papid> P10-1008 </papid>or hierarchical reinforcement learning (hrl) (dethlefs and cuayahuitl, 2010) for nlg decision mak ing.</nextsent>
<nextsent>all of these approaches have demonstrated thathrl/rl offers powerful mechanism for learning generation policies in the absence of complete knowledge about the environment or the user.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI833">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>stoia et al present supervised learning approach for situated referring expression generation (reg).
</prevsent>
<prevsent>garoufi and koller use techniques from ai planning for the combined generation of navigation instructions and referring expressions (re).
</prevsent>
</prevsection>
<citsent citstr=" P07-1043 ">
more generally, the nlg problem of non-deterministic decisionmaking has been addressed from many different angles, including penman-style choosers (mann and matthiessen,1983), corpus-based statistical knowledge (langk ilde and knight, 1998), <papid> P98-1116 </papid>tree-based stochastic models(bangalore and rambow, 2000), <papid> C00-1007 </papid>maximum entropy based ranking (ratnaparkhi, 2000), <papid> A00-2026 </papid>combinatorial pattern discovery (duboue and mckeown, 2001),<papid> P01-1023 </papid>instance-based ranking (varges, 2003), chart generation (white, 2004), planning (koller and stone, 2007), <papid> P07-1043 </papid>or probabilistic generation spaces (belz, 2008) to name just few.</citsent>
<aftsection>
<nextsent>more recently, there have been several approaches towards using reinforcement learning (rl) (rieseret al, 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010) <papid> P10-1008 </papid>or hierarchical reinforcement learning (hrl) (dethlefs and cuayahuitl, 2010) for nlg decision mak ing.</nextsent>
<nextsent>all of these approaches have demonstrated thathrl/rl offers powerful mechanism for learning generation policies in the absence of complete knowledge about the environment or the user.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI834">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>garoufi and koller use techniques from ai planning for the combined generation of navigation instructions and referring expressions (re).
</prevsent>
<prevsent>more generally, the nlg problem of non-deterministic decisionmaking has been addressed from many different angles, including penman-style choosers (mann and matthiessen,1983), corpus-based statistical knowledge (langk ilde and knight, 1998), <papid> P98-1116 </papid>tree-based stochastic models(bangalore and rambow, 2000), <papid> C00-1007 </papid>maximum entropy based ranking (ratnaparkhi, 2000), <papid> A00-2026 </papid>combinatorial pattern discovery (duboue and mckeown, 2001),<papid> P01-1023 </papid>instance-based ranking (varges, 2003), chart generation (white, 2004), planning (koller and stone, 2007), <papid> P07-1043 </papid>or probabilistic generation spaces (belz, 2008) to name just few.</prevsent>
</prevsection>
<citsent citstr=" P10-1103 ">
more recently, there have been several approaches towards using reinforcement learning (rl) (rieseret al, 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010) <papid> P10-1008 </papid>or hierarchical reinforcement learning (hrl) (dethlefs and cuayahuitl, 2010) for nlg decision mak ing.</citsent>
<aftsection>
<nextsent>all of these approaches have demonstrated thathrl/rl offers powerful mechanism for learning generation policies in the absence of complete knowledge about the environment or the user.
</nextsent>
<nextsent>it overcomes the need for large amounts of handcrafted knowledge or data in rule-based or supervised learning accounts.
</nextsent>
<nextsent>on the other hand, rl can have difficulties to find an optimal policy in large search space, and is therefore often limited to small-scale applications.
</nextsent>
<nextsent>pruning the search space of learning agent by including prior knowledge is therefore attractive, since it finds solutions faster, reduces computational demands, incorporates expert knowledge, and scales to complex problems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI835">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>garoufi and koller use techniques from ai planning for the combined generation of navigation instructions and referring expressions (re).
</prevsent>
<prevsent>more generally, the nlg problem of non-deterministic decisionmaking has been addressed from many different angles, including penman-style choosers (mann and matthiessen,1983), corpus-based statistical knowledge (langk ilde and knight, 1998), <papid> P98-1116 </papid>tree-based stochastic models(bangalore and rambow, 2000), <papid> C00-1007 </papid>maximum entropy based ranking (ratnaparkhi, 2000), <papid> A00-2026 </papid>combinatorial pattern discovery (duboue and mckeown, 2001),<papid> P01-1023 </papid>instance-based ranking (varges, 2003), chart generation (white, 2004), planning (koller and stone, 2007), <papid> P07-1043 </papid>or probabilistic generation spaces (belz, 2008) to name just few.</prevsent>
</prevsection>
<citsent citstr=" P10-1008 ">
more recently, there have been several approaches towards using reinforcement learning (rl) (rieseret al, 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010) <papid> P10-1008 </papid>or hierarchical reinforcement learning (hrl) (dethlefs and cuayahuitl, 2010) for nlg decision mak ing.</citsent>
<aftsection>
<nextsent>all of these approaches have demonstrated thathrl/rl offers powerful mechanism for learning generation policies in the absence of complete knowledge about the environment or the user.
</nextsent>
<nextsent>it overcomes the need for large amounts of handcrafted knowledge or data in rule-based or supervised learning accounts.
</nextsent>
<nextsent>on the other hand, rl can have difficulties to find an optimal policy in large search space, and is therefore often limited to small-scale applications.
</nextsent>
<nextsent>pruning the search space of learning agent by including prior knowledge is therefore attractive, since it finds solutions faster, reduces computational demands, incorporates expert knowledge, and scales to complex problems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI836">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, rl can have difficulties to find an optimal policy in large search space, and is therefore often limited to small-scale applications.
</prevsent>
<prevsent>pruning the search space of learning agent by including prior knowledge is therefore attractive, since it finds solutions faster, reduces computational demands, incorporates expert knowledge, and scales to complex problems.
</prevsent>
</prevsection>
<citsent citstr=" C00-1073 ">
sug 78gestions to use such prior knowledge include litman et al (2000) <papid> C00-1073 </papid>and singh et al (2002), who hand-craft rules of prior knowledge obvious to the system designer.</citsent>
<aftsection>
<nextsent>cuayahuitl (2009) suggests using hierarchical abstract machines to partially pre specify dialogue strategies, and heeman (2007) <papid> N07-1034 </papid>uses combination of rl and information state (is) to also pre-specify dialogue strategies.</nextsent>
<nextsent>williams(2008) presents an approach of combining partially observable markov decision processes with conventional dialogue systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI837">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pruning the search space of learning agent by including prior knowledge is therefore attractive, since it finds solutions faster, reduces computational demands, incorporates expert knowledge, and scales to complex problems.
</prevsent>
<prevsent>sug 78gestions to use such prior knowledge include litman et al (2000) <papid> C00-1073 </papid>and singh et al (2002), who hand-craft rules of prior knowledge obvious to the system designer.</prevsent>
</prevsection>
<citsent citstr=" N07-1034 ">
cuayahuitl (2009) suggests using hierarchical abstract machines to partially pre specify dialogue strategies, and heeman (2007) <papid> N07-1034 </papid>uses combination of rl and information state (is) to also pre-specify dialogue strategies.</citsent>
<aftsection>
<nextsent>williams(2008) presents an approach of combining partially observable markov decision processes with conventional dialogue systems.
</nextsent>
<nextsent>the information state approach is well-established in dialogue management (e.g., bohlin et al (1999) and larsson and traum (2000)).
</nextsent>
<nextsent>it allows the system designer to specify dialogue strategies in principled and systematic way.
</nextsent>
<nextsent>a disadvantage is that random design decisions need to be made in cases where the best action, or sequence of actions, is not obvious.the contribution of this paper consists in comprehensive account of constrained hierarchical reinforcement learning through combination witha hierarchical information state (his), which is informed by prior knowledge induced from decision trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI838">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> the generation tasks.  </section>
<citcontext>
<prevsection>
<prevsent>phrase (path, straight, etc.) inserted table 1: corpus annotation features that were used as knowledge of the learning agent and the information state.
</prevsent>
<prevsent>features are presented in groups, describing the properties of referents in the environment (f1...f13) and their dis tractors (f14...f15), features of high- and low-level navigation (f16...f18), the user (f19...f23), and grammatical information about constituents (f24...f27).with respect to the referent) to be natural and distinguishing.
</prevsent>
</prevsection>
<citsent citstr=" W08-1109 ">
we also considered the visual salience of objects, and the type of spatial relation involved, since recent studies indicate the potential relevance of these features (viethen and dale, 2008).<papid> W08-1109 </papid></citsent>
<aftsection>
<nextsent>given these observations, we aim to optimise the task success and linguistic consistency of instructions.
</nextsent>
<nextsent>task success is measured from user reactions after each instruction (section 5.1).
</nextsent>
<nextsent>linguistic consistency is achieved by rewarding the agent for generating instructions that belong to the same user model as the previous one.
</nextsent>
<nextsent>the agent has the same probability for choosing any pattern, but is then rewarded forconsistency.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI839">
<title id=" W11-2011.xml">optimising natural language generation decisionmaking for situated dialogue </title>
<section> constrained hierarchical reinforcement.  </section>
<citcontext>
<prevsection>
<prevsent>for this purpose we define the informational components of an is to represent the (situational and linguistic) knowledge of the generator (section 4.2).
</prevsent>
<prevsent>update rules are triggered by generator actions, such as the decision to insert new constituent into the current logical form, or the decision to prefer oneword order sequence over another.
</prevsent>
</prevsection>
<citsent citstr=" W03-2123 ">
we use the dipper toolkit (bos et al, 2003)<papid> W03-2123 </papid>3 for our implementation of the is. 3.3 combining hierarchical reinforcement.</citsent>
<aftsection>
<nextsent>learning and information state previous work has suggested the hsmq-learning algorithm for optimizing text generation strategies (dethlefs and cuayahuitl, 2010).
</nextsent>
<nextsent>because such an algorithm uses all available actions in each state, an important extension is to constrain the actions available with some prior expert knowledge, aiming to combine behaviour specified by human designers and behaviour automatically inferred by reinforcement learning agents.
</nextsent>
<nextsent>to that end, we sug 3http://www.ltg.ed.ac.uk/dipper 81 figure 2: (left:) hierarchy of learning agents executed from top to bottom for generating instructions.
</nextsent>
<nextsent>(right:) state representations for the agents shown in the hierarchy on the left.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI840">
<title id=" W12-0602.xml">the role of emotional stability in twitter conversations </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>those practices enhance the visibility of the posts or the users.
</prevsent>
<prevsent>in recent years the interest towards twitter raised in the scientific community, especially in information retrieval.
</prevsent>
</prevsection>
<citsent citstr=" W10-0713 ">
for example pak and paroubek (2010) developed sentiment analysis classifier from twitter data, finin et al (2010) <papid> W10-0713 </papid>performed named entity recognition on twitter using crowdsourcing services such as mechanical turk1 and crowdflower2, and zhao et al (2011) <papid> P11-1039 </papid>proposed ranking algorithm for extracting topic keyphrasesfrom tweets.</citsent>
<aftsection>
<nextsent>of course also in the personality recog 1https://www.mturk.com/mturk/welcome 2http://crowdflower.com 10nition field there is great interest towards the analysis of twitter.
</nextsent>
<nextsent>for example quercia et al (2011) analyzed the correlations between personality traits and the behaviour of four types of users: listeners, popular, hi-read and influential.in this paper, we describe personality recognition tool we developed in order to annotate data from twitter and we analyze how emotional stability affects interactions in twitter.
</nextsent>
<nextsent>in the next section, given an overview of personality recognition and emotional stability, we will describe our personality recognition system in detail and we present the dataset we collected from twitter.
</nextsent>
<nextsent>in the last two sections we report and discuss the results of the experiment and we provide some provisional conclusions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI841">
<title id=" W12-0602.xml">the role of emotional stability in twitter conversations </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>those practices enhance the visibility of the posts or the users.
</prevsent>
<prevsent>in recent years the interest towards twitter raised in the scientific community, especially in information retrieval.
</prevsent>
</prevsection>
<citsent citstr=" P11-1039 ">
for example pak and paroubek (2010) developed sentiment analysis classifier from twitter data, finin et al (2010) <papid> W10-0713 </papid>performed named entity recognition on twitter using crowdsourcing services such as mechanical turk1 and crowdflower2, and zhao et al (2011) <papid> P11-1039 </papid>proposed ranking algorithm for extracting topic keyphrasesfrom tweets.</citsent>
<aftsection>
<nextsent>of course also in the personality recog 1https://www.mturk.com/mturk/welcome 2http://crowdflower.com 10nition field there is great interest towards the analysis of twitter.
</nextsent>
<nextsent>for example quercia et al (2011) analyzed the correlations between personality traits and the behaviour of four types of users: listeners, popular, hi-read and influential.in this paper, we describe personality recognition tool we developed in order to annotate data from twitter and we analyze how emotional stability affects interactions in twitter.
</nextsent>
<nextsent>in the next section, given an overview of personality recognition and emotional stability, we will describe our personality recognition system in detail and we present the dataset we collected from twitter.
</nextsent>
<nextsent>in the last two sections we report and discuss the results of the experiment and we provide some provisional conclusions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI842">
<title id=" W12-0602.xml">the role of emotional stability in twitter conversations </title>
<section> personality recognition.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 previous work and state of the art.
</prevsent>
<prevsent>computational linguistics community started to pay attention to personality recognition only recently.a pioneering work by argamon et al (2005) classified neurotic ism and extra version using linguistic features such as function words, deictics, appraisal expressions and modal verbs.
</prevsent>
</prevsection>
<citsent citstr=" P06-2081 ">
oberlander and nowson (2006) <papid> P06-2081 </papid>classified extra version, emotional stability, agreeable ness and conscientiousness of blog authors?</citsent>
<aftsection>
<nextsent>using n-grams as features.
</nextsent>
<nextsent>mairesse et al (2007) <papid> P07-1063 </papid>reported long list of correlations between big5 personality traits and 2 feature sets, one from linguistics (liwc, see penne baker et al (2001) fordetails) and one from psychology (rmc, see colt heart (1981)).</nextsent>
<nextsent>those sets included features such as punctuation, length and frequency of words used.they obtained those correlations from psychological factor analysis on corpus of essays (see pen nebaker and king (1999) for details) annotated with personality, and developed supervisd system for personality recognition available online as demo3.in recent work, iacobelli et al (2011) tested different feature sets, extracted from corpus of blogs, and found that bigrams and stop words treated as boolean features yield very good results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI843">
<title id=" W12-0602.xml">the role of emotional stability in twitter conversations </title>
<section> personality recognition.  </section>
<citcontext>
<prevsection>
<prevsent>oberlander and nowson (2006) <papid> P06-2081 </papid>classified extra version, emotional stability, agreeable ness and conscientiousness of blog authors?</prevsent>
<prevsent>using n-grams as features.</prevsent>
</prevsection>
<citsent citstr=" P07-1063 ">
mairesse et al (2007) <papid> P07-1063 </papid>reported long list of correlations between big5 personality traits and 2 feature sets, one from linguistics (liwc, see penne baker et al (2001) fordetails) and one from psychology (rmc, see colt heart (1981)).</citsent>
<aftsection>
<nextsent>those sets included features such as punctuation, length and frequency of words used.they obtained those correlations from psychological factor analysis on corpus of essays (see pen nebaker and king (1999) for details) annotated with personality, and developed supervisd system for personality recognition available online as demo3.in recent work, iacobelli et al (2011) tested different feature sets, extracted from corpus of blogs, and found that bigrams and stop words treated as boolean features yield very good results.
</nextsent>
<nextsent>as is stated by the authors themselves, their model may overfit the data, since the n-grams extracted are very few in very large corpus.
</nextsent>
<nextsent>quercia et al (2011) predicted personality scores of twitter users by means of network statistics like following count and retweet count, but they report root mean squared error, not accuracy.
</nextsent>
<nextsent>finally golbeck et al (2011) predicted the personality of 279 users from face book using either linguistic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI852">
<title id=" W11-2406.xml">representing and resolving ambiguities in ontology based question answering </title>
<section> preliminaries.  </section>
<citcontext>
<prevsection>
<prevsent>2.
</prevsent>
<prevsent>(a) dp det no np state (b) dp hawaii 3.
</prevsent>
</prevsection>
<citsent citstr=" W09-3726 ">
s dp det no np state vp borders dp hawaii as semantic representations we take dudes(cimiano, 2009), <papid> W09-3726 </papid>representations similar to structures from underspecified discourse representation theory (udrt (reyle, 1993)), extended with some additional information that allows for flexible meaning composition in parallel to the construction of ltag trees.</citsent>
<aftsection>
<nextsent>the dude for the verb to border, for example, would be the following (in slightly simplified version): geo:borders (x, y) (dp1, x), (dp2, y) 41it provides the predicate geo:borders corresponding to the intended concept in the ontology.
</nextsent>
<nextsent>this correspondence is ensured by using the vocabulary of the ontology, i.e. by using the uri4 of the concept instead of more generic predicate.
</nextsent>
<nextsent>the prefix geo specifies the nam espace, in this case the oneof the geobase ontology.
</nextsent>
<nextsent>furthermore, the semantic representation contains information about which substitution nodes in the syntactic structure provide the semantic arguments and y. that is, the semantic referent provided by the meaning of the tree substituted for dp1 corresponds to the first argument xof the semantic predicate, while the semantic referent provided by the meaning of the tree substituted for dp2 corresponds to the second argument y. the uppermost row of the box contains the referent that is introduced by the expression.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI853">
<title id=" W12-0501.xml">experiments on hybrid corpus based sentiment lexicon acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>knowing someones attitude towards events, entities, and phenomena can be very important in various areas of human activity.
</prevsent>
<prevsent>sentiment analysis is an area of computational linguistics that aims to recognize the subjectivity and attitude expressed in natural language texts.
</prevsent>
</prevsection>
<citsent citstr=" W06-1652 ">
applications of sentiment analysis are numerous, including sentiment-based document classification (riloffet al, 2006), <papid> W06-1652 </papid>opinion-oriented information extraction (hu and liu, 2004), and question answering (somasundaran et al, 2007).sentiment analysis combines subjectivity analysis and polarity analysis.</citsent>
<aftsection>
<nextsent>subjectivity analysis answers whether the text unit is subjective or neutral, while polarity analysis determines whether subjective text unit is positive or negative.
</nextsent>
<nextsent>the majority of research approaches (hatzi vassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman, 2003; wilson et al, 2009) <papid> J09-3003 </papid>see subjectivity and polarity as categorical terms (i.e., classification problems).</nextsent>
<nextsent>intuitively, not all words express the sentiment with the same intensity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI854">
<title id=" W12-0501.xml">experiments on hybrid corpus based sentiment lexicon acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>applications of sentiment analysis are numerous, including sentiment-based document classification (riloffet al, 2006), <papid> W06-1652 </papid>opinion-oriented information extraction (hu and liu, 2004), and question answering (somasundaran et al, 2007).sentiment analysis combines subjectivity analysis and polarity analysis.</prevsent>
<prevsent>subjectivity analysis answers whether the text unit is subjective or neutral, while polarity analysis determines whether subjective text unit is positive or negative.</prevsent>
</prevsection>
<citsent citstr=" P97-1023 ">
the majority of research approaches (hatzi vassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman, 2003; wilson et al, 2009) <papid> J09-3003 </papid>see subjectivity and polarity as categorical terms (i.e., classification problems).</citsent>
<aftsection>
<nextsent>intuitively, not all words express the sentiment with the same intensity.
</nextsent>
<nextsent>accordingly, there has been some research effort in assessing subjectivity and polarity as graded values (baccianella et al, 2010; andreevskaia and bergler, 2006).<papid> E06-1027 </papid></nextsent>
<nextsent>most of the work on sentence or document level sentiment makes usage of sentiment annotated lexicon providing subjectivity and polarity information for individual words (wilson et al, 2009; <papid> J09-3003 </papid>taboada et al, 2011).<papid> J11-2001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI855">
<title id=" W12-0501.xml">experiments on hybrid corpus based sentiment lexicon acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>applications of sentiment analysis are numerous, including sentiment-based document classification (riloffet al, 2006), <papid> W06-1652 </papid>opinion-oriented information extraction (hu and liu, 2004), and question answering (somasundaran et al, 2007).sentiment analysis combines subjectivity analysis and polarity analysis.</prevsent>
<prevsent>subjectivity analysis answers whether the text unit is subjective or neutral, while polarity analysis determines whether subjective text unit is positive or negative.</prevsent>
</prevsection>
<citsent citstr=" J09-3003 ">
the majority of research approaches (hatzi vassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman, 2003; wilson et al, 2009) <papid> J09-3003 </papid>see subjectivity and polarity as categorical terms (i.e., classification problems).</citsent>
<aftsection>
<nextsent>intuitively, not all words express the sentiment with the same intensity.
</nextsent>
<nextsent>accordingly, there has been some research effort in assessing subjectivity and polarity as graded values (baccianella et al, 2010; andreevskaia and bergler, 2006).<papid> E06-1027 </papid></nextsent>
<nextsent>most of the work on sentence or document level sentiment makes usage of sentiment annotated lexicon providing subjectivity and polarity information for individual words (wilson et al, 2009; <papid> J09-3003 </papid>taboada et al, 2011).<papid> J11-2001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI856">
<title id=" W12-0501.xml">experiments on hybrid corpus based sentiment lexicon acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the majority of research approaches (hatzi vassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman, 2003; wilson et al, 2009) <papid> J09-3003 </papid>see subjectivity and polarity as categorical terms (i.e., classification problems).</prevsent>
<prevsent>intuitively, not all words express the sentiment with the same intensity.</prevsent>
</prevsection>
<citsent citstr=" E06-1027 ">
accordingly, there has been some research effort in assessing subjectivity and polarity as graded values (baccianella et al, 2010; andreevskaia and bergler, 2006).<papid> E06-1027 </papid></citsent>
<aftsection>
<nextsent>most of the work on sentence or document level sentiment makes usage of sentiment annotated lexicon providing subjectivity and polarity information for individual words (wilson et al, 2009; <papid> J09-3003 </papid>taboada et al, 2011).<papid> J11-2001 </papid></nextsent>
<nextsent>in this paper we present hybrid approach for automated acquisition of sentiment lexicon.the method is language independent and corpus based and therefore suitable for languages lacking general lexical resources such as wordnet(fellbaum, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI858">
<title id=" W12-0501.xml">experiments on hybrid corpus based sentiment lexicon acquisition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>intuitively, not all words express the sentiment with the same intensity.
</prevsent>
<prevsent>accordingly, there has been some research effort in assessing subjectivity and polarity as graded values (baccianella et al, 2010; andreevskaia and bergler, 2006).<papid> E06-1027 </papid></prevsent>
</prevsection>
<citsent citstr=" J11-2001 ">
most of the work on sentence or document level sentiment makes usage of sentiment annotated lexicon providing subjectivity and polarity information for individual words (wilson et al, 2009; <papid> J09-3003 </papid>taboada et al, 2011).<papid> J11-2001 </papid></citsent>
<aftsection>
<nextsent>in this paper we present hybrid approach for automated acquisition of sentiment lexicon.the method is language independent and corpus based and therefore suitable for languages lacking general lexical resources such as wordnet(fellbaum, 2010).
</nextsent>
<nextsent>the two-step hybrid process combines semi-supervised graph-based algorithms and supervised learning models.we consider three different tasks, each capturing different aspect of sentiment lexicon: 1.
</nextsent>
<nextsent>polarity ranking task ? determine the relative.
</nextsent>
<nextsent>rankings of words, i.e., order lexicon items descendingly by positivity and negativity;absolute scores (between 0 and 1) for positivity and negativity; 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI859">
<title id=" W12-0501.xml">experiments on hybrid corpus based sentiment lexicon acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 6 concludes the paper and outlines future work.
</prevsent>
<prevsent>several approaches have been proposed for determining the prior polarity of words.
</prevsent>
</prevsection>
<citsent citstr=" P07-1054 ">
most of the approaches can be classified as either dictionary based (kamps et al, 2004; esuli and sebastiani, 2007; <papid> P07-1054 </papid>baccianella et al, 2010) or corpus-based (hatzivassiloglou and mckeown, 1997; <papid> P97-1023 </papid>turney and littman, 2003).</citsent>
<aftsection>
<nextsent>regardless of the resource used, most of the approaches focus on bootstrapping, starting from small seed set of manually labeled words (hatzivassiloglou and mckeown,1997; <papid> P97-1023 </papid>turney and littman, 2003; esuli and sebastiani, 2007).<papid> P07-1054 </papid></nextsent>
<nextsent>in this paper we also follow this idea of the semi-supervised bootstrapping as the first step of the sentiment lexicon acquisition.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI865">
<title id=" W12-0501.xml">experiments on hybrid corpus based sentiment lexicon acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in their pioneering work, hatzivassiloglou and mckeown (1997) <papid> P97-1023 </papid>attempt to determine the polarity of adjectives based on their co-occurrencesin conjunctions.</prevsent>
<prevsent>they start with small manually labeled seed set and build on the observation that adjectives of the same polarity are often conjoined with the conjunction and, while adjectives of the opposite polarity are conjoined with the conjunction but.</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
turney and littman (2003) use pointwise mutual information (pmi) (church and hanks, 1990) <papid> J90-1003 </papid>and latent semantic analysis (lsa) (dumais, 2004) to determine the similarity of the word of unknown polarity with the wordsin both positive and negative seed sets.</citsent>
<aftsection>
<nextsent>the aforementioned work presumes that there is correlation between lexical semantics and sentiment.
</nextsent>
<nextsent>we base our work on the same assumption, but instead of directly comparing the words with the seed sets, we use distributional semantics to builda word similarity graph.
</nextsent>
<nextsent>in contrast to the approaches above, this allows us to potentially account for similarities between all pairs of words from corpus.
</nextsent>
<nextsent>to the best of our knowledge, such an approach that combines corpus-based lexical semantics with graph-based propagation has notyet been applied to the task of building sentiment lexicon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI866">
<title id=" W12-0501.xml">experiments on hybrid corpus based sentiment lexicon acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast to the approaches above, this allows us to potentially account for similarities between all pairs of words from corpus.
</prevsent>
<prevsent>to the best of our knowledge, such an approach that combines corpus-based lexical semantics with graph-based propagation has notyet been applied to the task of building sentiment lexicon.
</prevsent>
</prevsection>
<citsent citstr=" W06-3808 ">
however, similar approaches have been proven rather efficient on other tasks suchas document level sentiment classification (goldberg and zhu, 2006) <papid> W06-3808 </papid>and word sense disambiguation (agirre et al, 2006).<papid> W06-1669 </papid></citsent>
<aftsection>
<nextsent>methods the structure of graph in general provides agood framework for propagation of object properties, which, in our case, are the sentiment values of the words.
</nextsent>
<nextsent>in word similarity graph, weights of edges represent the degree of semantic similarity between words.
</nextsent>
<nextsent>in the work presented in this paper we build graphs from corpus, using different notions of 2word similarity.
</nextsent>
<nextsent>each vertex in the graph represents word from corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI867">
<title id=" W12-0501.xml">experiments on hybrid corpus based sentiment lexicon acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast to the approaches above, this allows us to potentially account for similarities between all pairs of words from corpus.
</prevsent>
<prevsent>to the best of our knowledge, such an approach that combines corpus-based lexical semantics with graph-based propagation has notyet been applied to the task of building sentiment lexicon.
</prevsent>
</prevsection>
<citsent citstr=" W06-1669 ">
however, similar approaches have been proven rather efficient on other tasks suchas document level sentiment classification (goldberg and zhu, 2006) <papid> W06-3808 </papid>and word sense disambiguation (agirre et al, 2006).<papid> W06-1669 </papid></citsent>
<aftsection>
<nextsent>methods the structure of graph in general provides agood framework for propagation of object properties, which, in our case, are the sentiment values of the words.
</nextsent>
<nextsent>in word similarity graph, weights of edges represent the degree of semantic similarity between words.
</nextsent>
<nextsent>in the work presented in this paper we build graphs from corpus, using different notions of 2word similarity.
</nextsent>
<nextsent>each vertex in the graph represents word from corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI869">
<title id=" W12-0512.xml">methods combination and mlbased reranking of multiple hypothesis for question answering systems </title>
<section> the question-answering systems.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 general overview.
</prevsent>
<prevsent>the ritel system (see figure 1) which we used in these experiments is fully described in (bernardet al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" L08-1378 ">
this system has been developed within the framework of the ritel project which aimed at building human-machine dialogue system for question-answering in open do main (toney et al, 2008).<papid> L08-1378 </papid></citsent>
<aftsection>
<nextsent>the same multilevel analysis is carried out on both queries and documents.
</nextsent>
<nextsent>the objective of this analysis is to find the bits of information that maybe of use for search and extraction, called pertinent information chunks.
</nextsent>
<nextsent>these can be of different categories: named entities, linguistic entities (e.g., verbs, prepositions), or specific entities (e.g., scores).
</nextsent>
<nextsent>all words that do not fall into such chunks are automatically grouped into chunks viaa longest-match strategy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI870">
<title id=" W12-0512.xml">methods combination and mlbased reranking of multiple hypothesis for question answering systems </title>
<section> machine-learning-based method for.  </section>
<citcontext>
<prevsection>
<prevsent>the result of this method isthat the answers extracted by more than one system are favored.
</prevsent>
<prevsent>an answer found by only one system, even with very high confidence score, may be downgraded.
</prevsent>
</prevsection>
<citsent citstr=" P07-1098 ">
answer re-rankingto solve re-ranking problem, machine learning approaches can be used (for example (mos chitti et al, 2007)).<papid> P07-1098 </papid></citsent>
<aftsection>
<nextsent>but in most of the cases, the objective is to re-rank answers provided byone system, that means to re-rank multiple hypotheses from one system.
</nextsent>
<nextsent>in our case, we wantto re-rank multiple answers from different systems.
</nextsent>
<nextsent>we decided to use an svm-based approach, namely svmrank (joachims, 2006), which is well adapted to our problem.
</nextsent>
<nextsent>an important aspect is then to choose the pertinent features for such task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI871">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we also outline some ways in which this framework has allowed our group to analyze reordering errors for english to japanese machine translation.
</prevsent>
<prevsent>statistical machine translation systems can perform poorly on distant language pairs such as english and japanese.
</prevsent>
</prevsection>
<citsent citstr=" D10-1092 ">
reordering errors are major source of poor or misleading translations in such systems(isozaki et al, 2010).<papid> D10-1092 </papid></citsent>
<aftsection>
<nextsent>unfortunately the standard evaluation metrics used by the statistical machine translation community are relatively insensitive to the long-distance reordering phenomena encountered when translating between such languages (birch et al, 2010).
</nextsent>
<nextsent>the ability to rapidly evaluate the impact of changes on system can significantly accelerate the experimental cycle.
</nextsent>
<nextsent>in large statistical machine translation system, we should ideally be able to experiment with separate components without retraining the complete system.
</nextsent>
<nextsent>measures such as perplexity have been successfully used to evaluate language models independently in speech recognition eliminating some of the need for end-to-end speech recognition experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI874">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in large statistical machine translation system, we should ideally be able to experiment with separate components without retraining the complete system.
</prevsent>
<prevsent>measures such as perplexity have been successfully used to evaluate language models independently in speech recognition eliminating some of the need for end-to-end speech recognition experiments.
</prevsent>
</prevsection>
<citsent citstr=" J07-3002 ">
in machine translation, alignment error rate has been used with some mixed success to evaluate word-alignment algorithms but no standard evaluation frameworks exist for other components of machine translation system (fraser and marcu, 2007).<papid> J07-3002 </papid></citsent>
<aftsection>
<nextsent>unfortunately, bleu (papineni et al, 2001) and other metrics that work with the final output of machine translation system are both insensitive to reordering phenomena and relatively time-consuming to compute: changes to the system may require the realignment of the parallel training data, extraction of phrasal statistics and translation of test set.
</nextsent>
<nextsent>as training sets grow in size, the cost of end-to-end experimentation can become significant.
</nextsent>
<nextsent>however, it is not clear that measurements made on any single partof the system will correlate well with human judgments of the translation quality of the whole system.
</nextsent>
<nextsent>following collins et al (2005<papid> P05-1066 </papid>a) and wang (2007), xu et al (2009) <papid> N09-1028 </papid>showed that when translating from english to japanese (and to other sov languages such as korean and turkish) applying reordering as 12a preprocessing step that manipulates source sentence parse tree can significantly outperform state of-the-art phrase-based and hierarchical machine translation systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI875">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as training sets grow in size, the cost of end-to-end experimentation can become significant.
</prevsent>
<prevsent>however, it is not clear that measurements made on any single partof the system will correlate well with human judgments of the translation quality of the whole system.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
following collins et al (2005<papid> P05-1066 </papid>a) and wang (2007), xu et al (2009) <papid> N09-1028 </papid>showed that when translating from english to japanese (and to other sov languages such as korean and turkish) applying reordering as 12a preprocessing step that manipulates source sentence parse tree can significantly outperform state of-the-art phrase-based and hierarchical machine translation systems.</citsent>
<aftsection>
<nextsent>this result is corroborated by birch et al (2009) <papid> W09-0434 </papid>whose results suggest that both phrase-based and hierarchical translation systems fail to capture long-distance reordering phenomena.</nextsent>
<nextsent>in this paper we describe lightweight framework for measuring the quality of the reordering components in machine translation system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI876">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as training sets grow in size, the cost of end-to-end experimentation can become significant.
</prevsent>
<prevsent>however, it is not clear that measurements made on any single partof the system will correlate well with human judgments of the translation quality of the whole system.
</prevsent>
</prevsection>
<citsent citstr=" N09-1028 ">
following collins et al (2005<papid> P05-1066 </papid>a) and wang (2007), xu et al (2009) <papid> N09-1028 </papid>showed that when translating from english to japanese (and to other sov languages such as korean and turkish) applying reordering as 12a preprocessing step that manipulates source sentence parse tree can significantly outperform state of-the-art phrase-based and hierarchical machine translation systems.</citsent>
<aftsection>
<nextsent>this result is corroborated by birch et al (2009) <papid> W09-0434 </papid>whose results suggest that both phrase-based and hierarchical translation systems fail to capture long-distance reordering phenomena.</nextsent>
<nextsent>in this paper we describe lightweight framework for measuring the quality of the reordering components in machine translation system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI877">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, it is not clear that measurements made on any single partof the system will correlate well with human judgments of the translation quality of the whole system.
</prevsent>
<prevsent>following collins et al (2005<papid> P05-1066 </papid>a) and wang (2007), xu et al (2009) <papid> N09-1028 </papid>showed that when translating from english to japanese (and to other sov languages such as korean and turkish) applying reordering as 12a preprocessing step that manipulates source sentence parse tree can significantly outperform state of-the-art phrase-based and hierarchical machine translation systems.</prevsent>
</prevsection>
<citsent citstr=" W09-0434 ">
this result is corroborated by birch et al (2009) <papid> W09-0434 </papid>whose results suggest that both phrase-based and hierarchical translation systems fail to capture long-distance reordering phenomena.</citsent>
<aftsection>
<nextsent>in this paper we describe lightweight framework for measuring the quality of the reordering components in machine translation system.
</nextsent>
<nextsent>while our framework can be applied to any translation system in which it is possible to derive token-levelalignment from the input source tokens to the out put target tokens, it is of particular practical interest when applied to system that performs reordering as preprocessing step (xia and mccord, 2004).<papid> C04-1073 </papid></nextsent>
<nextsent>in this case, as we show, it allows for extremely rapid and sensitive analysis of changes to parser, reordering rules and other reordering components.in our framework we evaluate the reordering proposed by system separately from its choice of target words by comparing it to reference reordering of the sentence generated from manually word aligned translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI878">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this result is corroborated by birch et al (2009) <papid> W09-0434 </papid>whose results suggest that both phrase-based and hierarchical translation systems fail to capture long-distance reordering phenomena.</prevsent>
<prevsent>in this paper we describe lightweight framework for measuring the quality of the reordering components in machine translation system.</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
while our framework can be applied to any translation system in which it is possible to derive token-levelalignment from the input source tokens to the out put target tokens, it is of particular practical interest when applied to system that performs reordering as preprocessing step (xia and mccord, 2004).<papid> C04-1073 </papid></citsent>
<aftsection>
<nextsent>in this case, as we show, it allows for extremely rapid and sensitive analysis of changes to parser, reordering rules and other reordering components.in our framework we evaluate the reordering proposed by system separately from its choice of target words by comparing it to reference reordering of the sentence generated from manually word aligned translation.
</nextsent>
<nextsent>unlike previous work (isozakiet al, 2010), <papid> D10-1092 </papid>our approach does not relyon the systems output matching the reference translation lexi cally.</nextsent>
<nextsent>this makes the evaluation more robustas there may be many ways to render source phrase in the target language and we would not wish to penalize one that simply happens not to match the reference.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI880">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we describe ways in which the framework has facilitated development of the reordering components in our system.
</prevsent>
<prevsent>2.1 evaluating reordering.
</prevsent>
</prevsection>
<citsent citstr=" D08-1078 ">
the ability to automatically evaluate machine translation output has driven progress in statistical machine translation; however, shortcomings of the dominant metric, bleu (papineni et al, 2001) , particularly with respect to reordering, have long been recognized (callison-burch and osborne, 2006).reordering has also been identified as major factor in determining the difficulty of statistical machine translation between two languages (birch etal., 2008) <papid> D08-1078 </papid>hence bleu scores may be most unreliable precisely for those language pairs for which statistical machine translation is most difficult (isozaki et al, 2010).<papid> D10-1092 </papid>there have been many results showing that metrics that account for reordering are better correlated with human judgements of translation quality (lavie and denkowski, 2009; birch and osborne, 2010; <papid> W10-1749 </papid>isozaki et al, 2010).<papid> D10-1092 </papid></citsent>
<aftsection>
<nextsent>examples given in isozaki et al.
</nextsent>
<nextsent>(2010) where object and subject arguments are reversed in japanese to english statistical machine translation system demonstrate how damaging reordering errors can be and it should therefore notcome as surprise that word order is strong predictor of translation quality; however, there are other advantages to be gained by focusing on this specific aspect of the translation process in isolation.
</nextsent>
<nextsent>one problem for all automatic evaluation metric sis that multiple equally good translations can be constructed for most input sentences and typically our reference data will contain only small fraction of these.
</nextsent>
<nextsent>equally good translations for sentence may differ both in terms of lexical choice and word order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI884">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, we describe ways in which the framework has facilitated development of the reordering components in our system.
</prevsent>
<prevsent>2.1 evaluating reordering.
</prevsent>
</prevsection>
<citsent citstr=" W10-1749 ">
the ability to automatically evaluate machine translation output has driven progress in statistical machine translation; however, shortcomings of the dominant metric, bleu (papineni et al, 2001) , particularly with respect to reordering, have long been recognized (callison-burch and osborne, 2006).reordering has also been identified as major factor in determining the difficulty of statistical machine translation between two languages (birch etal., 2008) <papid> D08-1078 </papid>hence bleu scores may be most unreliable precisely for those language pairs for which statistical machine translation is most difficult (isozaki et al, 2010).<papid> D10-1092 </papid>there have been many results showing that metrics that account for reordering are better correlated with human judgements of translation quality (lavie and denkowski, 2009; birch and osborne, 2010; <papid> W10-1749 </papid>isozaki et al, 2010).<papid> D10-1092 </papid></citsent>
<aftsection>
<nextsent>examples given in isozaki et al.
</nextsent>
<nextsent>(2010) where object and subject arguments are reversed in japanese to english statistical machine translation system demonstrate how damaging reordering errors can be and it should therefore notcome as surprise that word order is strong predictor of translation quality; however, there are other advantages to be gained by focusing on this specific aspect of the translation process in isolation.
</nextsent>
<nextsent>one problem for all automatic evaluation metric sis that multiple equally good translations can be constructed for most input sentences and typically our reference data will contain only small fraction of these.
</nextsent>
<nextsent>equally good translations for sentence may differ both in terms of lexical choice and word order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI899">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to create the word-aligned translations from which we generate our reference reordering data, we used novel alignment-oriented translation method.
</prevsent>
<prevsent>the method (described in more detail below) seeks to generate reference reorderings that machine translation system might reasonably be expected to achieve.
</prevsent>
</prevsection>
<citsent citstr=" W02-1039 ">
fox (2002) <papid> W02-1039 </papid>has analyzed the extent to which translations seen in parallel corpus can be broken down into clean phrasal units: they found that most sentence pairs contain examples of reordering that violate phrasal cohesion, i.e. the corresponding words in the target language are not completely contiguous or solely aligned to the corresponding source phrase.</citsent>
<aftsection>
<nextsent>these reordering phenomena are difficult for current statistical translation models to learn directly.
</nextsent>
<nextsent>we therefore deliberately chose to create reference data that avoids these phenomena as much as possible by having single annotator generate both the translation and its wordalignment.
</nextsent>
<nextsent>our word-aligned translations are created with bias towards simple phrasal reordering.our analysis of the correlation between reordering scores computed on reference data created from such alignment-oriented translations with scores computed on references generated from standard professional translations of the same sentences suggests that the alignment-oriented translations are more useful for evaluating current state-of-the-artsystem.
</nextsent>
<nextsent>we note also that while prior work has conjectured that automatically generated alignments are suitable replacement for manual alignments in the 14 context of reordering evaluation (birch et al, 2008), <papid> D08-1078 </papid>our results suggest that this is not the case at least for the language pair we consider, english-japanese.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI908">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> experimental set-up.  </section>
<citcontext>
<prevsection>
<prevsent>we also believe sentence-level correlation is more important than corpus-level correlation since good sentence-level correlation implies that metric can be used for detailed analysis of system and potentially to optimize it.
</prevsent>
<prevsent>4.1 systems.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we carried out all our experiments using state-of the-art phrase-based statistical english-to-japanesemachine translation system (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>during both training and testing, the system re orders source-language sentences in preprocessing step using set of rules written in the framework proposed by (xu et al, 2009) <papid> N09-1028 </papid>that reorder an english dependency tree into target word order.</nextsent>
<nextsent>during decoding, we set the reordering window to 4 words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI911">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> experimental set-up.  </section>
<citcontext>
<prevsection>
<prevsent>during both training and testing, the system re orders source-language sentences in preprocessing step using set of rules written in the framework proposed by (xu et al, 2009) <papid> N09-1028 </papid>that reorder an english dependency tree into target word order.</prevsent>
<prevsent>during decoding, we set the reordering window to 4 words.</prevsent>
</prevsection>
<citsent citstr=" W06-3108 ">
in addition to the regular distance distortion model,we incorporate maximum entropy based lexicalized phrase reordering model (zens and ney, 2006).<papid> W06-3108 </papid>for parallel training data, we use an in-house collection of parallel documents.</citsent>
<aftsection>
<nextsent>these come from various sources with substantial portion coming fromthe web after using simple heuristics to identify potential document pairs.
</nextsent>
<nextsent>we trained our system on about 300 million source words.the reordering rules applied to the english dependency tree define precedence order for the children of each head category (a coarse-grained part of speech).
</nextsent>
<nextsent>for example, simplified version of the precedence order for child labels of verbal head he adverb is: advcl, nsubj, prep, [other children], dobj, prt, aux, neg, he adverb, mark, ref, compl.the dependency parser we use is an implementation of transition-based dependency parser (nivre,2008).<papid> J08-4003 </papid></nextsent>
<nextsent>the parser is trained using the averaged perceptron algorithm with an early update strategy as described in zhang and clark (2008).<papid> D08-1059 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI912">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> experimental set-up.  </section>
<citcontext>
<prevsection>
<prevsent>these come from various sources with substantial portion coming fromthe web after using simple heuristics to identify potential document pairs.
</prevsent>
<prevsent>we trained our system on about 300 million source words.the reordering rules applied to the english dependency tree define precedence order for the children of each head category (a coarse-grained part of speech).
</prevsent>
</prevsection>
<citsent citstr=" J08-4003 ">
for example, simplified version of the precedence order for child labels of verbal head he adverb is: advcl, nsubj, prep, [other children], dobj, prt, aux, neg, he adverb, mark, ref, compl.the dependency parser we use is an implementation of transition-based dependency parser (nivre,2008).<papid> J08-4003 </papid></citsent>
<aftsection>
<nextsent>the parser is trained using the averaged perceptron algorithm with an early update strategy as described in zhang and clark (2008).<papid> D08-1059 </papid></nextsent>
<nextsent>we created five systems using different parsers;here targeted self-training refers to training procedure proposed by katz-brown et al (2011) that uses our reordering metric and separate reference reordering data to pick parses for self-training: an nbest list of parses is generated for each english sentence for which we have reference reordering data and the parse tree that results in the highest fuzzy reordering score is added to our parsers training set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI913">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> experimental set-up.  </section>
<citcontext>
<prevsection>
<prevsent>we trained our system on about 300 million source words.the reordering rules applied to the english dependency tree define precedence order for the children of each head category (a coarse-grained part of speech).
</prevsent>
<prevsent>for example, simplified version of the precedence order for child labels of verbal head he adverb is: advcl, nsubj, prep, [other children], dobj, prt, aux, neg, he adverb, mark, ref, compl.the dependency parser we use is an implementation of transition-based dependency parser (nivre,2008).<papid> J08-4003 </papid></prevsent>
</prevsection>
<citsent citstr=" D08-1059 ">
the parser is trained using the averaged perceptron algorithm with an early update strategy as described in zhang and clark (2008).<papid> D08-1059 </papid></citsent>
<aftsection>
<nextsent>we created five systems using different parsers;here targeted self-training refers to training procedure proposed by katz-brown et al (2011) that uses our reordering metric and separate reference reordering data to pick parses for self-training: an nbest list of parses is generated for each english sentence for which we have reference reordering data and the parse tree that results in the highest fuzzy reordering score is added to our parsers training set.
</nextsent>
<nextsent>parsers p3, p4 and p5 differ in how that framework is applied and how much data is used.
</nextsent>
<nextsent>p1 penn treebank, perceptron, greedy search ? p2 penn treebank, perceptron, beam search ? p3 penn treebank, perceptron, beam search, targeted self-training on web data 16 ? p4 penn treebank, perceptron, beam search, targeted self-training on web data ? p5 penn treebank, perceptron, beam search,targeted self-training on web data, case insensitive we also created five systems using the fifth parser (p5) but with different sets of reordering rules: ? r1 no reordering ? r2 reverse reordering?
</nextsent>
<nextsent>r3 head final reordering with reverse reordering for words before the head?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI916">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> experimental set-up.  </section>
<citcontext>
<prevsection>
<prevsent>evaluation data: both manually-generated and.
</prevsent>
<prevsent>automatically-generated word alignments onboth standard professional and alignment oriented translations of the test sentences the automatic word alignments were generated using ibm model 1 in order to avoid directional biases that higher-order models such as hmms have.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
results presented in square parentheses are 95 percent confidence intervals estimated by bootstrap re sampling on the test corpus (koehn, 2004).<papid> W04-3250 </papid></citsent>
<aftsection>
<nextsent>our test set contains 500 sentences randomly sampled from the web.
</nextsent>
<nextsent>we have both profession aland alignment-friendly translations for these sentences.
</nextsent>
<nextsent>we created reference reorderings for this data using the method described in section 3.1.the lack of broad domain and publically available japanese test corpus makes the use of this nonstandard test set unfortunately unavoidable.
</nextsent>
<nextsent>the human raters were presented with the source sentence, the human reference translation and the translations of the various systems simultaneously, blind and in random order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI917">
<title id=" W11-2102.xml">a lightweight evaluation framework for machine translation reordering </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>to identify which words are most frequently reordered incorrectly ? to identify systematic parser and/or pos errors ? to identify the worst reordered sentences ? to evaluate individual reordering rules figures 1 and 2 show pairs of parse trees together with their resulting reorderings and scores against figure 2: p1 and p5s parse trees and automatic reordering (using r5 ruleset) and fuzzy score.the reference.
</prevsent>
<prevsent>these are typical of the parser errors that impact reordering and which are correctly identified by our framework.
</prevsent>
</prevsection>
<citsent citstr=" D11-1138 ">
in related joint work (katz-brown et al, 2011) and (hall et al, 2011), <papid> D11-1138 </papid>it is shown that the framework can be used to optimize reordering components automatically.</citsent>
<aftsection>
<nextsent>we have presented lightweight framework for evaluating reordering in machine translation and demonstrated that this is able to accurately distinguish significant changes in translation quality due to changes in preprocessing components such as the parser or reordering rules used by the system.
</nextsent>
<nextsent>the sentence level correlation of our metric with judgements of human translation quality was shown to be higher than other standard evaluation metrics while our evaluation has the significant practical advantage ofnot requiring an end-to-end machine translation experiment when used to evaluate separate reordering component.
</nextsent>
<nextsent>our analysis has also highlighted the benefits of creating focused evaluation data that attempts to factor out some of the phenomena found in real human translation.
</nextsent>
<nextsent>while previous work has provided meta-analysis of reordering metrics across quite independent systems, ours is we believe the first to provide detailed comparison of systems 20 that differ only in small but realistic aspects such as parser quality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI918">
<title id=" W12-0604.xml">topic classification of blog posts using distant supervision </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they use the frequency of words more often used in personal blogs versus those more frequently used in general blogs, pronouns, in-links, out-links and hosts as the features for the blogs.
</prevsent>
<prevsent>they then perform supervised training on the data using set of 152 manually labeled blogs to train their classifier.
</prevsent>
</prevsection>
<citsent citstr=" P08-2018 ">
the results show that the decision tree method produced the highest accuracy at about 90% (elgersma and de rijke, 2008).a work which looks at true topic classification of blogs, as is being done here, is that of hashimoto and kurohashi (2008), <papid> P08-2018 </papid>who use domain dictionary to classify blog posts without machine learning (i.e., using rule-based system).</citsent>
<aftsection>
<nextsent>they use keywords for each domain, or category as the basis for classification.
</nextsent>
<nextsent>they then create score of blog post based on the number of keywords from each domain; the domain with the highest count becomes the category for that post.
</nextsent>
<nextsent>they also expand the keywords in their domain by adding new words on the fly.
</nextsent>
<nextsent>this is done by taking an unknown word (one that does not currently exist in domain) and attempting to categorize it using its online search results and/or wikipediaarticle.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI919">
<title id=" W12-0604.xml">topic classification of blog posts using distant supervision </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>for the binary classifications, we used 50blogs as positive examples and 200 blogs randomly chosen from the other topics as negative examples.
</prevsent>
<prevsent>for the multi-class experiment, we use the 350 blogs corresponding to the 7 categories.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
both the blogs and the wikipedia articles we retagged using the stanford named entity recognizer (finkel et al, 2005), <papid> P05-1045 </papid>which labels the entities according to these types: time, location, organization, person, money, percent, date, and miscellaneous.</citsent>
<aftsection>
<nextsent>after several tests, we found that location, organization, person and miscellaneous were the most useful for topic classification, and we thus ignored the rest for there sults presented here.
</nextsent>
<nextsent>as mentioned above, we use only the named entities in both the training and test data, which, in our experiments, consisted of 14,995 unique entities.
</nextsent>
<nextsent>classifiers.
</nextsent>
<nextsent>we performed all our tests using the weka suite (hall et al, 2009), and we tested the following classifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI920">
<title id=" W12-0514.xml">incorporating linguistic knowledge in statistical machine translation translating prepositions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>li et al (2005) focus on three english prepositions (on, in and at) and use wordnet to infer semantic properties of the immediate context of the preposition in order to correctly translate it to chinese.
</prevsent>
<prevsent>again, this requires language resources that are unavailable to us.
</prevsent>
</prevsection>
<citsent citstr=" W06-2113 ">
wordnet (and parser) are used also by naskar and bandyopadhyay (2006), <papid> W06-2113 </papid>who work on english-to bengali translation.</citsent>
<aftsection>
<nextsent>the closest work to ours is agirre et al (2009),who translate from spanish to basque in rule based framework.
</nextsent>
<nextsent>like us, they focus on prepositional phrases that modify verbs, and include also the direct object (and the subject) in their approach.
</nextsent>
<nextsent>they propose three techniques for correctly translating prepositions, based on information that is automatically extracted from monolingual resources (including verb-preposition-head dependency triplets and verb subcategorization) as well as manually-crafted selection rules that rely on lexical, syntactic and semantic information.
</nextsent>
<nextsent>our method is similar in principle, themain differences being: (i) we incorporate linguistic knowledge in statistical decoder, facilitating scala bility of the mt system, (ii) we use much more modest resources (in particular, we do not parse either of the two languages), and (iii) we report standard evaluation measures.much work has been done regarding the automatic acquisition of subcategorization frames in english (brent, 1991; <papid> P91-1027 </papid>manning, 1993; <papid> P93-1032 </papid>briscoe and carroll, 1997; <papid> A97-1052 </papid>korhonen, 2002), czech (sarkar and zeman, 2000), <papid> C00-2100 </papid>french (chesley and salmon-alt, 2006), and several other languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI921">
<title id=" W12-0514.xml">incorporating linguistic knowledge in statistical machine translation translating prepositions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>like us, they focus on prepositional phrases that modify verbs, and include also the direct object (and the subject) in their approach.
</prevsent>
<prevsent>they propose three techniques for correctly translating prepositions, based on information that is automatically extracted from monolingual resources (including verb-preposition-head dependency triplets and verb subcategorization) as well as manually-crafted selection rules that rely on lexical, syntactic and semantic information.
</prevsent>
</prevsection>
<citsent citstr=" P91-1027 ">
our method is similar in principle, themain differences being: (i) we incorporate linguistic knowledge in statistical decoder, facilitating scala bility of the mt system, (ii) we use much more modest resources (in particular, we do not parse either of the two languages), and (iii) we report standard evaluation measures.much work has been done regarding the automatic acquisition of subcategorization frames in english (brent, 1991; <papid> P91-1027 </papid>manning, 1993; <papid> P93-1032 </papid>briscoe and carroll, 1997; <papid> A97-1052 </papid>korhonen, 2002), czech (sarkar and zeman, 2000), <papid> C00-2100 </papid>french (chesley and salmon-alt, 2006), and several other languages.</citsent>
<aftsection>
<nextsent>the technique that we use here (section 6) can now be considered standard.
</nextsent>
<nextsent>the method we propose is implemented in the framework of stat-xfer (lavie, 2008), statistical machine translation engine that includes adeclarative formalism for symbolic transfer grammars.
</nextsent>
<nextsent>a grammar consists of collection of synchronous context-free rules, which can be augmented by unification-style feature constraints.these transfer rules specify how phrase structures in source-language correspond and transfer to phrase structures in target language, and the constraints under which these rules shouldapply.
</nextsent>
<nextsent>the framework also includes transfer engine that applies the transfer grammar to source-language input sentence at runtime, and produces collections of scored word- andphrase-level translations according to the grammar. scores are based on log-linear combination of several features, and beam-search controls the underlying parsing and transfer process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI922">
<title id=" W12-0514.xml">incorporating linguistic knowledge in statistical machine translation translating prepositions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>like us, they focus on prepositional phrases that modify verbs, and include also the direct object (and the subject) in their approach.
</prevsent>
<prevsent>they propose three techniques for correctly translating prepositions, based on information that is automatically extracted from monolingual resources (including verb-preposition-head dependency triplets and verb subcategorization) as well as manually-crafted selection rules that rely on lexical, syntactic and semantic information.
</prevsent>
</prevsection>
<citsent citstr=" P93-1032 ">
our method is similar in principle, themain differences being: (i) we incorporate linguistic knowledge in statistical decoder, facilitating scala bility of the mt system, (ii) we use much more modest resources (in particular, we do not parse either of the two languages), and (iii) we report standard evaluation measures.much work has been done regarding the automatic acquisition of subcategorization frames in english (brent, 1991; <papid> P91-1027 </papid>manning, 1993; <papid> P93-1032 </papid>briscoe and carroll, 1997; <papid> A97-1052 </papid>korhonen, 2002), czech (sarkar and zeman, 2000), <papid> C00-2100 </papid>french (chesley and salmon-alt, 2006), and several other languages.</citsent>
<aftsection>
<nextsent>the technique that we use here (section 6) can now be considered standard.
</nextsent>
<nextsent>the method we propose is implemented in the framework of stat-xfer (lavie, 2008), statistical machine translation engine that includes adeclarative formalism for symbolic transfer grammars.
</nextsent>
<nextsent>a grammar consists of collection of synchronous context-free rules, which can be augmented by unification-style feature constraints.these transfer rules specify how phrase structures in source-language correspond and transfer to phrase structures in target language, and the constraints under which these rules shouldapply.
</nextsent>
<nextsent>the framework also includes transfer engine that applies the transfer grammar to source-language input sentence at runtime, and produces collections of scored word- andphrase-level translations according to the grammar. scores are based on log-linear combination of several features, and beam-search controls the underlying parsing and transfer process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI923">
<title id=" W12-0514.xml">incorporating linguistic knowledge in statistical machine translation translating prepositions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>like us, they focus on prepositional phrases that modify verbs, and include also the direct object (and the subject) in their approach.
</prevsent>
<prevsent>they propose three techniques for correctly translating prepositions, based on information that is automatically extracted from monolingual resources (including verb-preposition-head dependency triplets and verb subcategorization) as well as manually-crafted selection rules that rely on lexical, syntactic and semantic information.
</prevsent>
</prevsection>
<citsent citstr=" A97-1052 ">
our method is similar in principle, themain differences being: (i) we incorporate linguistic knowledge in statistical decoder, facilitating scala bility of the mt system, (ii) we use much more modest resources (in particular, we do not parse either of the two languages), and (iii) we report standard evaluation measures.much work has been done regarding the automatic acquisition of subcategorization frames in english (brent, 1991; <papid> P91-1027 </papid>manning, 1993; <papid> P93-1032 </papid>briscoe and carroll, 1997; <papid> A97-1052 </papid>korhonen, 2002), czech (sarkar and zeman, 2000), <papid> C00-2100 </papid>french (chesley and salmon-alt, 2006), and several other languages.</citsent>
<aftsection>
<nextsent>the technique that we use here (section 6) can now be considered standard.
</nextsent>
<nextsent>the method we propose is implemented in the framework of stat-xfer (lavie, 2008), statistical machine translation engine that includes adeclarative formalism for symbolic transfer grammars.
</nextsent>
<nextsent>a grammar consists of collection of synchronous context-free rules, which can be augmented by unification-style feature constraints.these transfer rules specify how phrase structures in source-language correspond and transfer to phrase structures in target language, and the constraints under which these rules shouldapply.
</nextsent>
<nextsent>the framework also includes transfer engine that applies the transfer grammar to source-language input sentence at runtime, and produces collections of scored word- andphrase-level translations according to the grammar. scores are based on log-linear combination of several features, and beam-search controls the underlying parsing and transfer process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI924">
<title id=" W12-0514.xml">incorporating linguistic knowledge in statistical machine translation translating prepositions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>like us, they focus on prepositional phrases that modify verbs, and include also the direct object (and the subject) in their approach.
</prevsent>
<prevsent>they propose three techniques for correctly translating prepositions, based on information that is automatically extracted from monolingual resources (including verb-preposition-head dependency triplets and verb subcategorization) as well as manually-crafted selection rules that rely on lexical, syntactic and semantic information.
</prevsent>
</prevsection>
<citsent citstr=" C00-2100 ">
our method is similar in principle, themain differences being: (i) we incorporate linguistic knowledge in statistical decoder, facilitating scala bility of the mt system, (ii) we use much more modest resources (in particular, we do not parse either of the two languages), and (iii) we report standard evaluation measures.much work has been done regarding the automatic acquisition of subcategorization frames in english (brent, 1991; <papid> P91-1027 </papid>manning, 1993; <papid> P93-1032 </papid>briscoe and carroll, 1997; <papid> A97-1052 </papid>korhonen, 2002), czech (sarkar and zeman, 2000), <papid> C00-2100 </papid>french (chesley and salmon-alt, 2006), and several other languages.</citsent>
<aftsection>
<nextsent>the technique that we use here (section 6) can now be considered standard.
</nextsent>
<nextsent>the method we propose is implemented in the framework of stat-xfer (lavie, 2008), statistical machine translation engine that includes adeclarative formalism for symbolic transfer grammars.
</nextsent>
<nextsent>a grammar consists of collection of synchronous context-free rules, which can be augmented by unification-style feature constraints.these transfer rules specify how phrase structures in source-language correspond and transfer to phrase structures in target language, and the constraints under which these rules shouldapply.
</nextsent>
<nextsent>the framework also includes transfer engine that applies the transfer grammar to source-language input sentence at runtime, and produces collections of scored word- andphrase-level translations according to the grammar. scores are based on log-linear combination of several features, and beam-search controls the underlying parsing and transfer process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI925">
<title id=" W12-0514.xml">incorporating linguistic knowledge in statistical machine translation translating prepositions </title>
<section> introduction to stat-xfer.  </section>
<citcontext>
<prevsection>
<prevsent>the framework also includes transfer engine that applies the transfer grammar to source-language input sentence at runtime, and produces collections of scored word- andphrase-level translations according to the grammar. scores are based on log-linear combination of several features, and beam-search controls the underlying parsing and transfer process.
</prevsent>
<prevsent>crucially, stat-xfer is statistical mt framework, which uses statistical information to weigh word translations, phrase cor respon 107dences and target-language hypotheses; in contrast to other paradigms, however, it can utilize both automatically-created and manually-craftedlanguage resources, including dictionaries, morphological processors and transfer rules.
</prevsent>
</prevsection>
<citsent citstr=" W09-0425 ">
statxfer has been used as platform for developing mt systems for hindi-to-english (lavie et al., 2003), hebrew-to-english (lavie et al, 2004),chinese-to-english, french-to-english (hanne manet al, 2009) <papid> W09-0425 </papid>and many other low-resource language pairs, such as inupiaq-to-english and mapudungun-to-spanish.</citsent>
<aftsection>
<nextsent>in this work, we use the arabic-to-hebrew mt system developed by shilon et al (2010), which uses over 40 manually-crafted rules.
</nextsent>
<nextsent>other resources include arabic morphological analyze rand disambiguator (habash, 2004), hebrew morphological generator (itai and wintner, 2008) anda hebrew language model compiled from available corpora (itai and wintner, 2008).while our proposal is cast within the framework of stat-xfer, it can be in principle adapted to other syntax-based approaches to mt; specifically, williams and koehn (2011) <papid> W11-2126 </papid>show how to employ unification-based constraints to the target side of string-to-tree model, integrating constrain evaluation into the decoding process.</nextsent>
<nextsent>hebrew and arabic modern hebrew and modern standard arabic, both closely-related semitic languages, share many orthographic, lexical, morphological, syntactic and semantic similarities, but they are still not mutually comprehensible.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI926">
<title id=" W12-0514.xml">incorporating linguistic knowledge in statistical machine translation translating prepositions </title>
<section> introduction to stat-xfer.  </section>
<citcontext>
<prevsection>
<prevsent>statxfer has been used as platform for developing mt systems for hindi-to-english (lavie et al., 2003), hebrew-to-english (lavie et al, 2004),chinese-to-english, french-to-english (hanne manet al, 2009) <papid> W09-0425 </papid>and many other low-resource language pairs, such as inupiaq-to-english and mapudungun-to-spanish.</prevsent>
<prevsent>in this work, we use the arabic-to-hebrew mt system developed by shilon et al (2010), which uses over 40 manually-crafted rules.</prevsent>
</prevsection>
<citsent citstr=" W11-2126 ">
other resources include arabic morphological analyze rand disambiguator (habash, 2004), hebrew morphological generator (itai and wintner, 2008) anda hebrew language model compiled from available corpora (itai and wintner, 2008).while our proposal is cast within the framework of stat-xfer, it can be in principle adapted to other syntax-based approaches to mt; specifically, williams and koehn (2011) <papid> W11-2126 </papid>show how to employ unification-based constraints to the target side of string-to-tree model, integrating constrain evaluation into the decoding process.</citsent>
<aftsection>
<nextsent>hebrew and arabic modern hebrew and modern standard arabic, both closely-related semitic languages, share many orthographic, lexical, morphological, syntactic and semantic similarities, but they are still not mutually comprehensible.
</nextsent>
<nextsent>machine translation between these two languages can indeed benefit from the similarities, but it remains challenging task.
</nextsent>
<nextsent>our current work is situated in the framework of the only direct mt system between these two languages that we are aware of, namely shilon et al (2010).hebrew and arabic share several similar prepositions, including the frequent in, at, with?
</nextsent>
<nextsent>and to?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI927">
<title id=" W12-0514.xml">incorporating linguistic knowledge in statistical machine translation translating prepositions </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>(which occurs in the bilingual dictionary), but remove the mapping of arabic ely on?
</prevsent>
<prevsent>to hebrew in?, which does not carry the same meaning.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
table 2 lists the bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (denkowski and lavie, 2011) <papid> W11-2107 </papid>scores of both systems.</citsent>
<aftsection>
<nextsent>bleu meteor baseline 0.325 0.526 with prepositions 0.370 0.560 table 2: automatic evaluation scores.the system that incorporates linguistic knowledge on prepositions significantly (p   0.05) outperforms the baseline system.
</nextsent>
<nextsent>a detailed analysis of the obtained translations reveals that the baseline system generates prepositions that are not licensed by their head verb, and the language model fails to choose the hypothesis with the correct preposition, if such hypothesis is generated at all.
</nextsent>
<nextsent>as an example of the difference between the outputs of both systems, consider figure 3.
</nextsent>
<nextsent>the arabic input is given in (8).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI928">
<title id=" W12-0514.xml">incorporating linguistic knowledge in statistical machine translation translating prepositions </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>(which occurs in the bilingual dictionary), but remove the mapping of arabic ely on?
</prevsent>
<prevsent>to hebrew in?, which does not carry the same meaning.
</prevsent>
</prevsection>
<citsent citstr=" W11-2107 ">
table 2 lists the bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (denkowski and lavie, 2011) <papid> W11-2107 </papid>scores of both systems.</citsent>
<aftsection>
<nextsent>bleu meteor baseline 0.325 0.526 with prepositions 0.370 0.560 table 2: automatic evaluation scores.the system that incorporates linguistic knowledge on prepositions significantly (p   0.05) outperforms the baseline system.
</nextsent>
<nextsent>a detailed analysis of the obtained translations reveals that the baseline system generates prepositions that are not licensed by their head verb, and the language model fails to choose the hypothesis with the correct preposition, if such hypothesis is generated at all.
</nextsent>
<nextsent>as an example of the difference between the outputs of both systems, consider figure 3.
</nextsent>
<nextsent>the arabic input is given in (8).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI929">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in phrase-based machine translation (pbmt), the standard approach is to express the probability distribution p(a, e|f) (where is the source sentence and (a, e) is the aligned target sentence) in terms ofa linear model based on small set of feature functions p(a, e|f) ? exp ( n?
</prevsent>
<prevsent>i=1 wihi(a, e, f) ) (1) the feature functions {hi} typically include log probabilities of generative models such as translation, language and reordering, as well as non probabilistic features such as word, phrase and distortion penalties.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the feature weights = {wi} are normally trained using mert (minimum error rate training) (och, 2003), <papid> P03-1021 </papid>to maximise performance as measured by an automated metric such as bleu(papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>mert training uses parallel dataset (known as the tuning set) consisting of about 1000-2000 sentences, distinct from the dataset used to build the generative models.
</nextsent>
<nextsent>optimising the weights in equation (1) is often referred to as tuning the mt system, to differentiate it from the process of training the generative models.
</nextsent>
<nextsent>merts inability to scale beyond 20-30 features, as well as its instability (foster and kuhn, 2009) <papid> W09-0439 </papid>have led to investigation into alternative ways of tuning mt systems.</nextsent>
<nextsent>the development of tuning methods is complicated, however by, the use of bleu as an objective function.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI930">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in phrase-based machine translation (pbmt), the standard approach is to express the probability distribution p(a, e|f) (where is the source sentence and (a, e) is the aligned target sentence) in terms ofa linear model based on small set of feature functions p(a, e|f) ? exp ( n?
</prevsent>
<prevsent>i=1 wihi(a, e, f) ) (1) the feature functions {hi} typically include log probabilities of generative models such as translation, language and reordering, as well as non probabilistic features such as word, phrase and distortion penalties.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the feature weights = {wi} are normally trained using mert (minimum error rate training) (och, 2003), <papid> P03-1021 </papid>to maximise performance as measured by an automated metric such as bleu(papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>mert training uses parallel dataset (known as the tuning set) consisting of about 1000-2000 sentences, distinct from the dataset used to build the generative models.
</nextsent>
<nextsent>optimising the weights in equation (1) is often referred to as tuning the mt system, to differentiate it from the process of training the generative models.
</nextsent>
<nextsent>merts inability to scale beyond 20-30 features, as well as its instability (foster and kuhn, 2009) <papid> W09-0439 </papid>have led to investigation into alternative ways of tuning mt systems.</nextsent>
<nextsent>the development of tuning methods is complicated, however by, the use of bleu as an objective function.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI931">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mert training uses parallel dataset (known as the tuning set) consisting of about 1000-2000 sentences, distinct from the dataset used to build the generative models.
</prevsent>
<prevsent>optimising the weights in equation (1) is often referred to as tuning the mt system, to differentiate it from the process of training the generative models.
</prevsent>
</prevsection>
<citsent citstr=" W09-0439 ">
merts inability to scale beyond 20-30 features, as well as its instability (foster and kuhn, 2009) <papid> W09-0439 </papid>have led to investigation into alternative ways of tuning mt systems.</citsent>
<aftsection>
<nextsent>the development of tuning methods is complicated, however by, the use of bleu as an objective function.
</nextsent>
<nextsent>this objective in its usual form is not differentiable, and has highly non-convex error surface (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>furthermore bleu is evaluated at the corpus level rather than at the sentence level, so tuning methods either have to consider the entire corpus, or resort to sentence level approximation of bleu.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI933">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is unlikely, however, that the difficulties in discriminative mt tuning are due solely to the use of bleu as metric ? because evaluation of translation is so difficult, any reasonable gain function is likely to have complex relationship with the model parameters.gradient-based tuning methods, such as minimum risk training, have been investigated as possible alternatives to mert.
</prevsent>
<prevsent>expected bleu is normally adopted as the objective since it is differentiable and so can be optimised by form of stochastic gradient ascent.
</prevsent>
</prevsection>
<citsent citstr=" P06-2101 ">
the feature expectations required for the gradient calculation can be obtained from n-best lists or lattices (smith and eisner, 2006; <papid> P06-2101 </papid>li and eisner, 2009), <papid> D09-1005 </papid>or using sampling (arun et al,2010), <papid> W10-1756 </papid>both of which can be computationally expen sive.</citsent>
<aftsection>
<nextsent>261 margin-based techniques such as perceptron training (liang et al, 2006) <papid> P06-1096 </papid>and mira (chiang et al., 2008; <papid> D08-1024 </papid>watanabe et al, 2007) <papid> D07-1080 </papid>have also been shown to be able to tune mt systems and scale tolarge numbers of features, but these generally involve repeatedly decoding the tuning set (and soare expensive) and require sentence-level approximations to the bleu objective.</nextsent>
<nextsent>in this paper we present an alternative method of tuning mt systems known as sample rank, which has certain advantages over other methods in use to day.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI934">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is unlikely, however, that the difficulties in discriminative mt tuning are due solely to the use of bleu as metric ? because evaluation of translation is so difficult, any reasonable gain function is likely to have complex relationship with the model parameters.gradient-based tuning methods, such as minimum risk training, have been investigated as possible alternatives to mert.
</prevsent>
<prevsent>expected bleu is normally adopted as the objective since it is differentiable and so can be optimised by form of stochastic gradient ascent.
</prevsent>
</prevsection>
<citsent citstr=" D09-1005 ">
the feature expectations required for the gradient calculation can be obtained from n-best lists or lattices (smith and eisner, 2006; <papid> P06-2101 </papid>li and eisner, 2009), <papid> D09-1005 </papid>or using sampling (arun et al,2010), <papid> W10-1756 </papid>both of which can be computationally expen sive.</citsent>
<aftsection>
<nextsent>261 margin-based techniques such as perceptron training (liang et al, 2006) <papid> P06-1096 </papid>and mira (chiang et al., 2008; <papid> D08-1024 </papid>watanabe et al, 2007) <papid> D07-1080 </papid>have also been shown to be able to tune mt systems and scale tolarge numbers of features, but these generally involve repeatedly decoding the tuning set (and soare expensive) and require sentence-level approximations to the bleu objective.</nextsent>
<nextsent>in this paper we present an alternative method of tuning mt systems known as sample rank, which has certain advantages over other methods in use to day.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI935">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is unlikely, however, that the difficulties in discriminative mt tuning are due solely to the use of bleu as metric ? because evaluation of translation is so difficult, any reasonable gain function is likely to have complex relationship with the model parameters.gradient-based tuning methods, such as minimum risk training, have been investigated as possible alternatives to mert.
</prevsent>
<prevsent>expected bleu is normally adopted as the objective since it is differentiable and so can be optimised by form of stochastic gradient ascent.
</prevsent>
</prevsection>
<citsent citstr=" W10-1756 ">
the feature expectations required for the gradient calculation can be obtained from n-best lists or lattices (smith and eisner, 2006; <papid> P06-2101 </papid>li and eisner, 2009), <papid> D09-1005 </papid>or using sampling (arun et al,2010), <papid> W10-1756 </papid>both of which can be computationally expen sive.</citsent>
<aftsection>
<nextsent>261 margin-based techniques such as perceptron training (liang et al, 2006) <papid> P06-1096 </papid>and mira (chiang et al., 2008; <papid> D08-1024 </papid>watanabe et al, 2007) <papid> D07-1080 </papid>have also been shown to be able to tune mt systems and scale tolarge numbers of features, but these generally involve repeatedly decoding the tuning set (and soare expensive) and require sentence-level approximations to the bleu objective.</nextsent>
<nextsent>in this paper we present an alternative method of tuning mt systems known as sample rank, which has certain advantages over other methods in use to day.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI936">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>expected bleu is normally adopted as the objective since it is differentiable and so can be optimised by form of stochastic gradient ascent.
</prevsent>
<prevsent>the feature expectations required for the gradient calculation can be obtained from n-best lists or lattices (smith and eisner, 2006; <papid> P06-2101 </papid>li and eisner, 2009), <papid> D09-1005 </papid>or using sampling (arun et al,2010), <papid> W10-1756 </papid>both of which can be computationally expen sive.</prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
261 margin-based techniques such as perceptron training (liang et al, 2006) <papid> P06-1096 </papid>and mira (chiang et al., 2008; <papid> D08-1024 </papid>watanabe et al, 2007) <papid> D07-1080 </papid>have also been shown to be able to tune mt systems and scale tolarge numbers of features, but these generally involve repeatedly decoding the tuning set (and soare expensive) and require sentence-level approximations to the bleu objective.</citsent>
<aftsection>
<nextsent>in this paper we present an alternative method of tuning mt systems known as sample rank, which has certain advantages over other methods in use to day.
</nextsent>
<nextsent>sample rank operates by repeatedly sampling pairs of translation hypotheses (for given source sentence) and updating the feature weights if the ranking induced by the mt model (1) is different from the ranking induced by the gain function (i.e. bleu).
</nextsent>
<nextsent>by considering the translation hypotheses in batches, it is possible to directly optimise corpus level metrics like bleu without resorting to sentence level approximations.
</nextsent>
<nextsent>tuning using sample rank does not limit the size of the feature set in the same way as mert does, and indeed it will be shown that sample rank can successfully train model with several hundred features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI937">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>expected bleu is normally adopted as the objective since it is differentiable and so can be optimised by form of stochastic gradient ascent.
</prevsent>
<prevsent>the feature expectations required for the gradient calculation can be obtained from n-best lists or lattices (smith and eisner, 2006; <papid> P06-2101 </papid>li and eisner, 2009), <papid> D09-1005 </papid>or using sampling (arun et al,2010), <papid> W10-1756 </papid>both of which can be computationally expen sive.</prevsent>
</prevsection>
<citsent citstr=" D08-1024 ">
261 margin-based techniques such as perceptron training (liang et al, 2006) <papid> P06-1096 </papid>and mira (chiang et al., 2008; <papid> D08-1024 </papid>watanabe et al, 2007) <papid> D07-1080 </papid>have also been shown to be able to tune mt systems and scale tolarge numbers of features, but these generally involve repeatedly decoding the tuning set (and soare expensive) and require sentence-level approximations to the bleu objective.</citsent>
<aftsection>
<nextsent>in this paper we present an alternative method of tuning mt systems known as sample rank, which has certain advantages over other methods in use to day.
</nextsent>
<nextsent>sample rank operates by repeatedly sampling pairs of translation hypotheses (for given source sentence) and updating the feature weights if the ranking induced by the mt model (1) is different from the ranking induced by the gain function (i.e. bleu).
</nextsent>
<nextsent>by considering the translation hypotheses in batches, it is possible to directly optimise corpus level metrics like bleu without resorting to sentence level approximations.
</nextsent>
<nextsent>tuning using sample rank does not limit the size of the feature set in the same way as mert does, and indeed it will be shown that sample rank can successfully train model with several hundred features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI938">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>expected bleu is normally adopted as the objective since it is differentiable and so can be optimised by form of stochastic gradient ascent.
</prevsent>
<prevsent>the feature expectations required for the gradient calculation can be obtained from n-best lists or lattices (smith and eisner, 2006; <papid> P06-2101 </papid>li and eisner, 2009), <papid> D09-1005 </papid>or using sampling (arun et al,2010), <papid> W10-1756 </papid>both of which can be computationally expen sive.</prevsent>
</prevsection>
<citsent citstr=" D07-1080 ">
261 margin-based techniques such as perceptron training (liang et al, 2006) <papid> P06-1096 </papid>and mira (chiang et al., 2008; <papid> D08-1024 </papid>watanabe et al, 2007) <papid> D07-1080 </papid>have also been shown to be able to tune mt systems and scale tolarge numbers of features, but these generally involve repeatedly decoding the tuning set (and soare expensive) and require sentence-level approximations to the bleu objective.</citsent>
<aftsection>
<nextsent>in this paper we present an alternative method of tuning mt systems known as sample rank, which has certain advantages over other methods in use to day.
</nextsent>
<nextsent>sample rank operates by repeatedly sampling pairs of translation hypotheses (for given source sentence) and updating the feature weights if the ranking induced by the mt model (1) is different from the ranking induced by the gain function (i.e. bleu).
</nextsent>
<nextsent>by considering the translation hypotheses in batches, it is possible to directly optimise corpus level metrics like bleu without resorting to sentence level approximations.
</nextsent>
<nextsent>tuning using sample rank does not limit the size of the feature set in the same way as mert does, and indeed it will be shown that sample rank can successfully train model with several hundred features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI943">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>given the current hypothesis set ys1 = (e1, . . .
</prevsent>
<prevsent>, ek), the sample and oracle are chosen as follows.
</prevsent>
</prevsection>
<citsent citstr=" W09-1114 ">
firstly, hypothesis ej is selected randomly from ys1 , and neighbourhood of alternate hypotheses 3 ej generated using operators from arun et al (2009) (<papid> W09-1114 </papid>explained shortly).</citsent>
<aftsection>
<nextsent>model scores are calculated for all the hypotheses in , converted to probabilities using equation (1), and sample ejtaken from using these probabilities.
</nextsent>
<nextsent>the sample hypothesis set (y?) is then the current hypothesis set (ys1) with ej replaced by ej . the oracle is created, analogously chiang et al (2008), <papid> D08-1024 </papid>by choosing e+j ? to maximise the sum of gain (calculated on the batch) and model score.</nextsent>
<nextsent>the oracle hypothesis set (y+) is then ys1 with ej replaced by + .we now describe how the neighbourhood is chosen. given single hypothesis ej , neighbourhood is generated by first randomly choosing one of thetwo operators merge-split or reorder, then randomly choosing point of application for the operator, then applying it to generate the neighbour hood.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI946">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> method.  </section>
<citcontext>
<prevsection>
<prevsent>when each new batch is loaded at the start of the inner loop, period of burn in is run, analogous to the burn-in used in mcmc sampling, where no weight updates are performed and weights are not collected.in order to help the stability of the tuning algorithm, and to enable it to process the tuning data more quickly, several chains are run in parallel, each with their own set of current weights, and each processing distinct subset of the tuning data.
</prevsent>
<prevsent>the weights are mixed (averaged) after each epoch.
</prevsent>
</prevsection>
<citsent citstr=" N10-1069 ">
thesame technique is frequently adopted for the averaged perceptron (mcdonald et al, 2010).<papid> N10-1069 </papid></citsent>
<aftsection>
<nextsent>3.1 corpora and baselines.
</nextsent>
<nextsent>the experiments in this section were conducted with french-english and german-english sections of the wmt20112 shared task data.
</nextsent>
<nextsent>in particular, we used news-commentary data (nc11), and europarl data (ep11) for training the generative models.
</nextsent>
<nextsent>phrase tables were built from lower cased versions of the 2http://www.statmt.org/wmt11/ 264 parallel texts using the standard moses3 training pipeline, with the target side of the texts used to build kneser-ney smoothed language models using the srilm toolkit4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI947">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the features used in the wmt-small translation system were the five moses translation features, language model feature, word penalty feature and distortion distance feature.
</prevsent>
<prevsent>to build the wmt-large translation system, boththe ep11 dataset and the nc11 dataset were con catenated together before building the translation model out of the resulting corpus of about 2 million sentences.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
separate 5-gram language models were built from the target side of the two data setsand then they were interpolated using weights chosen to minimise the perplexity on the tuning set (koehn and schroeder, 2007).<papid> W07-0733 </papid></citsent>
<aftsection>
<nextsent>in the wmt-large system, the eight core features were supplemented with the six features of the lexicalised reordering model, which was trained on the same data as wasused to build the translation model.
</nextsent>
<nextsent>whilst training set size of 2 million sentences would not normally be sufficient to build competitive system for an mt shared task, it is sufficient to show that how sample rank training performs on realistic sized system, whilst still allowing for plenty of experime nation with the algorithms parameters.
</nextsent>
<nextsent>for tuning, the nc-devtest2007 was used, with the first half of nc-test2007 corpus used for heldout testing and nc-test2008 and newstest2010 reserved for final testing.
</nextsent>
<nextsent>the tuning and heldout sets are about 1000 sentences in size, whereas the final test sets are approximately 2000 sentences each.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI948">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>dummy phrases with parts-of-speech   and  /s  are inserted at the start and end of the sentence, and also used to construct phrase boundary features.
</prevsent>
<prevsent>the example in figure 4 shows thephrase-boundary features from typical hypothesis.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
the idea is similar to part-of-speech language model, but discriminatively trained, and targeted at how phrases are joined together in the hypothesis.the target-side part-of-speech tags are added using the brill tagger, and incorporated into the phrase table using the factored translation modelling capabilities of moses (koehn and hoang, 2007).<papid> D07-1091 </papid>adding the phrase boundary features to the wmt small system increased the feature count from 8 to around 800.</citsent>
<aftsection>
<nextsent>training experiments were run forboth the french-english and german-english models, using the same configuration as in section 3.2,varying the number of cores (8 or 16) and the number of samples per sentence (100 or 500).
</nextsent>
<nextsent>training times were similar to those for the wmt-small system.
</nextsent>
<nextsent>the mean maximum scores on heldout are shown in table 5.
</nextsent>
<nextsent>we suspect that these features are fixing some short range reordering problems which 267 l l l l l l l l l l l l l l l l 23 24 25 26 27 samples per core (thousands) bleu 0 500 1000 1500 2000 2500 (a) 1 core l l l l l l l l l l l l 23 24 25 26 27 samples per core (thousands) bleu 0 500 1000 1500 2000 2500 (b) 4 cores l l l l l l l l l l ll l 23 24 25 26 27 samples per core (thousands) bleu 0 500 1000 1500 2000 2500 (c) 16 cores figure 2: sample rank learning curves for the wmt-small german-english system, for 1, 4 and 16 cores.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI958">
<title id=" W11-2130.xml">sample rank training for phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the sampling methods introduced in this earlier work form the basis of the current work, although in using the sampler for expected bleu training, many samples must be collected before makinga parameter weight update, as opposed to the current work where weights may be updated after every sample.
</prevsent>
<prevsent>one novel feature of arun et al (2010) <papid> W10-1756 </papid>is that they were able to train to directly maximise corpus bleu, instead of its sentence-based approximation, although this only made small difference to the results.</prevsent>
</prevsection>
<citsent citstr=" P08-1024 ">
the training methods in (arun et al, 2692010) are very resource intensive, with the experiments running for 48 hours on around 40 cores, on pruned phrase table derived from europarl, and 3-gram language model.instead of using expected bleu as training objective, blunsom et al (2008) <papid> P08-1024 </papid>trained their model to directly maximise the log-likelihood of the discriminative model, estimating feature expectations from packed chart.</citsent>
<aftsection>
<nextsent>their model treats derivations as latent variable, directly modelling the translation probability.
</nextsent>
<nextsent>margin-based techniques have the advantage that they do not have to employ expensive and complex algorithms to calculate the feature expectations.
</nextsent>
<nextsent>typically, either perceptron ((liang et al, 2006), (<papid> P06-1096 </papid>arun and koehn, 2007)) or mira ((watanabe et al., 2007), (<papid> D07-1080 </papid>chiang et al, 2008)) <papid> D08-1024 </papid>is employed, butin both cases the idea is to repeatedly decode sentences from the tuning set, and update the parameter weights if the best hypothesis according to the model differs from some oracle?</nextsent>
<nextsent>sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI964">
<title id=" W12-1639.xml">a regression based approach to modeling addressee back channels </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 regression-based modeling.
</prevsent>
<prevsent>while it remains unexplored in the context of modeling back channel behaviors, regression-based approaches are commonly used in modeling complex relationships among many variables.
</prevsent>
</prevsection>
<citsent citstr=" P97-1035 ">
in the context of modeling discourse and dialog, frameworks such as paradise (paradigm for dialogue system evaluation) build on regression-based approaches to identify predictive relationships between several elements of dialog and objective or subjective outcomes of the dialog (walker et al, 1997).<papid> P97-1035 </papid></citsent>
<aftsection>
<nextsent>researchers have used these frameworks to evaluate the effectiveness of spoken dialog in interactive systems (foster et al, 2009; <papid> P09-1099 </papid>peltason et al, 2012).</nextsent>
<nextsent>due to the broad range of verbal and nonverbal back channels, we chose to focus on limited subset of verbal and nonverbal cues, including continuers and assessments as verbal back channels and head nods as nonverbal backchannels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI965">
<title id=" W12-1639.xml">a regression based approach to modeling addressee back channels </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>while it remains unexplored in the context of modeling back channel behaviors, regression-based approaches are commonly used in modeling complex relationships among many variables.
</prevsent>
<prevsent>in the context of modeling discourse and dialog, frameworks such as paradise (paradigm for dialogue system evaluation) build on regression-based approaches to identify predictive relationships between several elements of dialog and objective or subjective outcomes of the dialog (walker et al, 1997).<papid> P97-1035 </papid></prevsent>
</prevsection>
<citsent citstr=" P09-1099 ">
researchers have used these frameworks to evaluate the effectiveness of spoken dialog in interactive systems (foster et al, 2009; <papid> P09-1099 </papid>peltason et al, 2012).</citsent>
<aftsection>
<nextsent>due to the broad range of verbal and nonverbal back channels, we chose to focus on limited subset of verbal and nonverbal cues, including continuers and assessments as verbal back channels and head nods as nonverbal backchannels.
</nextsent>
<nextsent>although there are numerous possible speaker behaviors, which may predict back channels, we focused on six cues based on previous research: (1) speakers gaze (directed toward the addressee), (2) nods, (3) gestures, (4) speech (whether the speaker is speaking or not), (5) conjunctions in the speakers speech, and (6) pitch variance in the speakers speech.
</nextsent>
<nextsent>these six predictors were then used to build models for five dependent variables: (1) nonverbal back channels, (2) verbal back channels, (3) concurrent verbal and nonverbal back channels (e.g., nod and an ok? startingsimultaneously), (4) overlapping verbal and nonverbal back channels (e.g., nod followed by an ok towards the end of the nod), and (5) independent bi modal back channels (the presence of either verbal or nonverbal backchannels).
</nextsent>
<nextsent>we modeled the relationships between these predictors and dependent variables using stepwise regression.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI966">
<title id=" W11-2028.xml">toward construction of spoken dialogue system that evokes users spontaneous back channels </title>
<section> related works.  </section>
<citcontext>
<prevsection>
<prevsent>a number of studies have aimed at improving the naturalness of tts.
</prevsent>
<prevsent>though most of these have focused on means of realizing clear andeasy-to-listen-to reading-style speech, some attempts have been made at spontaneous conversational speech.
</prevsent>
</prevsection>
<citsent citstr=" W10-4318 ">
andersson (andersson et al, 2010)and marge (marge et al, 2010) <papid> W10-4318 </papid>focused on lexi 259cal phenomena such as lexical filler and acknowledgments in spontaneous speech, and showed that inserting them improves the naturalness of human computer dialogues.</citsent>
<aftsection>
<nextsent>in this work, we tackle constructing natural dialogue-style tts system focusing on prosodic phenomena such as intonation and phoneme duration.
</nextsent>
<nextsent>in the field of conversation analysis, many studies analyzed back channels in human-human dialogue focusing on lexical and non-verbal cues (koiso et al., 1998; ward and tsukahara, 2000; a. gravano and j. hirschberg, 2009).
</nextsent>
<nextsent>for instance these cues were examined in preceding utterances, such as in part-of-speech tags, length of pause, power contour pattern, and 0 contour pattern around the end of the inter-pausal units (ipus).
</nextsent>
<nextsent>(a. gravano and j. hirschberg, 2009) showed that when several of the above cues occur simultaneously, the likelihood of occurrence of back channel will increase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI967">
<title id=" W12-0608.xml">opinion and suggestion analysis for expert recommendations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>social media has enabled web users to interact through social platforms, express their opinions, comment and review various products/items.
</prevsent>
<prevsent>such user-generated content has been analysed from social as well as content-oriented point of view.
</prevsent>
</prevsection>
<citsent citstr=" P07-1053 ">
for instance, social network analysis techniques have been used to identify user roles(agarwal et al, 2008; domingos and richardson, 2001; fisher et al, 2006; zhang et al, 2007) and text or opinion mining techniques have been applied to identify positive/negative tendencies within user online review comments (ding and liu, 2007; ghose et al, 2007; <papid> P07-1053 </papid>hu and liu, 2004; leskovec et al, 2010).</citsent>
<aftsection>
<nextsent>in the applicative context, recommender systems (adomavicius andtuzhilin, 2005) make use of the opinion information (such as in star-rating systems) and recommend items (movies, products, news articles, etc.) or social elements (i.e. propositions to connect with other people or communities), that are likely to be of interest to specific user.
</nextsent>
<nextsent>typically, recommender system compares user profile with some reference characteristics, and seeks to predict the preference?
</nextsent>
<nextsent>or rating that user would give to an item not yet considered.
</nextsent>
<nextsent>these characteristics may be part of the information item (the content-based approach) or the users social environment (the collaborative filtering approach).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI969">
<title id=" W12-0608.xml">opinion and suggestion analysis for expert recommendations </title>
<section> opinion mining for expert.  </section>
<citcontext>
<prevsection>
<prevsent>the opinion extraction system is designed ontop of the xip robust syntactic parser (atmokhtar et al, 2002), which is used as fundamental component, in order to extract deep syntactic dependencies, from which semantic relations of opinion are calculated.
</prevsent>
<prevsent>these semantic relations are intermediary steps to instantiate the five place predicates which are compliant withthe aforementioned model.
</prevsent>
</prevsection>
<citsent citstr=" N06-1026 ">
having syntactic relations already extracted by general dependency grammar, we use the robust parser by combining lexical information about word polarities, subcategorization information and syntactic dependencies to extract the semantic relations that will then instantiate this model.there exist other systems, such as the one described in (kim and hovy, 2006), <papid> N06-1026 </papid>that use syntactic dependencies to link the source and target of the opinions.</citsent>
<aftsection>
<nextsent>our system (brun, 2011) belongs tothis family, since we believe that the syntactic processing of complex phenomena (negation, comparison and anaphora) is necessary step in order to perform feature-based opinion mining.
</nextsent>
<nextsent>an other characteristic of our system is that it respects two-level architecture; it relies on generic level, applicable to all domains and corpora, and on domain-dependent level, adapted for each sub-domain of application.moreover, our system includes semantic mapping between polar vocabulary and the features it corresponds to.
</nextsent>
<nextsent>for instance, the opinion word fast?
</nextsent>
<nextsent>is mapped to the feature speed?, the word expensive?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI970">
<title id=" W11-2035.xml">improving pronominal and deictic coreference resolution with multimodal features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>hence, this paper presents our first steps toward full co-reference resolution module, and ultimately, the multi-modal interface.
</prevsent>
<prevsent>co-reference resolution is likely the discourse and dialogue processing task that has received the most attention.
</prevsent>
</prevsection>
<citsent citstr=" N06-2010 ">
however, as eisenstein and davis (2006) <papid> N06-2010 </papid>notes, research on co-reference resolution has mostly been applied to written text; this task is more difficult in dialogue.</citsent>
<aftsection>
<nextsent>first, utterances may be informal, ungrammatical or disfluent; second,people spontaneously use hand gestures, body gestures and gaze.
</nextsent>
<nextsent>pointing gestures are the easiest gestures to identify, and vision researchers in our project are working on recognizing pointing and other hand gestures (di eugenio et al, 2010).
</nextsent>
<nextsent>in this paper, we replicate the results from (eisenstein and davis, 2006), <papid> N06-2010 </papid>that pointing gestures help improve co-reference, in very different domain.</nextsent>
<nextsent>other work has shown that gestures can help detect sentence boundaries (chen and harper, 2010) or user intentions (qu and chai, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI972">
<title id=" W11-2035.xml">improving pronominal and deictic coreference resolution with multimodal features </title>
<section> the elderly-at-home corpus.  </section>
<citcontext>
<prevsection>
<prevsent>we have identified grab, hold, give and receive as high-levelhaptics phonemes that may be useful from the language point of view.
</prevsent>
<prevsent>we have recently started annotating our corpus with those labels.
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
subjects tasks utterances gestures pronouns 12 114 1920 896 1635 table 2: annotated corpus size in order to test the reliability of our annotation, we double coded about 18% of the data, namely 21 sub-dialogues comprising 213 pronouns, on which we computed the kappa coefficient (carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>similar to (rodrguez et al, 2010), we measured the reliability of mark able annotations, and of link tothe antecedent annotations.
</nextsent>
<nextsent>as concerns the mark able level, we obtained ?=0.945, which is high but no surprisingly for such simple task.
</nextsent>
<nextsent>at the link to the antecedent level, we compared the links from pronouns to antecedents in specified context of 4 utterances, obtaining reasonable ?=0.723.
</nextsent>
<nextsent>308 3: pers#1(hel/nnp) : rpers#1(i/prp) do/vbp nt/rb see/vb any/dt obj#3(pasta/nn) ./.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI974">
<title id=" W11-2035.xml">improving pronominal and deictic coreference resolution with multimodal features </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>first, the corpus they used is smaller than what we used in this paper.
</prevsent>
<prevsent>their corpus was collected by themselves and consisted of 16 videos, each video was 2-3 minute sin length.
</prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
second, they used difference measurement metrics called ceaf (luo, 2005).<papid> H05-1004 </papid></citsent>
<aftsection>
<nextsent>in this paper, we presented the new elderly-athome multi-modal corpus we collected.
</nextsent>
<nextsent>a coreference resolution system for personal and deic tic pronouns has been developed on the basis of the annotated corpus.
</nextsent>
<nextsent>our results confirm that gestures improve co-reference resolution; simple notion of type also helps.
</nextsent>
<nextsent>the mark able and co-reference modules we presented are first start in developing full multi-modal co-reference resolution module.apart from completing the annotation of our corpus, we will develop an annotation scheme for hap tics, and investigate how haptics information affectsco-reference and other dialogue phenomena.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI975">
<title id=" W11-2013.xml">multiparty turn taking in situated dialog study lessons and directions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1.
</prevsent>
<prevsent>components of turn-taking model.
</prevsent>
</prevsection>
<citsent citstr=" N09-1071 ">
s(s) a(s) sensing contrib decisions behavioral control behaviors and output management system floor action ia lo m an ag em en contribute audio-visual evidence dialog context speech gaze gesture semantic input semantic output fs(p) fi(p) fa(p) ? tu rn an ag em en within the dialog systems community, efforts have been made on designing and implementing computational models for managing turn taking (e.g., traum, 1994; thorrissn, 2002; raux and eskenazi, 2009; <papid> N09-1071 </papid>selfridge and heeman, 2010).<papid> P10-1019 </papid></citsent>
<aftsection>
<nextsent>moving beyond the dyadic setting, traum and rickel (2002) describe turn management component for supporting dialog between trainee and multiple virtual humans.
</nextsent>
<nextsent>kronlid (2006) describes harel state-chart implementation of the original ssj model.
</nextsent>
<nextsent>researchers studying human-robot interaction have developed prototype robots that can interact with multiple human participants (e.g. matsusaka et al, 2001; bennewitz et al, 2005).
</nextsent>
<nextsent>in our previous work bohus and horvitz (2009; 2010a; 2010b), we describe platform that leverages multimodal perception and reasoning to support multiparty dialog in open-world settings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI976">
<title id=" W11-2013.xml">multiparty turn taking in situated dialog study lessons and directions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1.
</prevsent>
<prevsent>components of turn-taking model.
</prevsent>
</prevsection>
<citsent citstr=" P10-1019 ">
s(s) a(s) sensing contrib decisions behavioral control behaviors and output management system floor action ia lo m an ag em en contribute audio-visual evidence dialog context speech gaze gesture semantic input semantic output fs(p) fi(p) fa(p) ? tu rn an ag em en within the dialog systems community, efforts have been made on designing and implementing computational models for managing turn taking (e.g., traum, 1994; thorrissn, 2002; raux and eskenazi, 2009; <papid> N09-1071 </papid>selfridge and heeman, 2010).<papid> P10-1019 </papid></citsent>
<aftsection>
<nextsent>moving beyond the dyadic setting, traum and rickel (2002) describe turn management component for supporting dialog between trainee and multiple virtual humans.
</nextsent>
<nextsent>kronlid (2006) describes harel state-chart implementation of the original ssj model.
</nextsent>
<nextsent>researchers studying human-robot interaction have developed prototype robots that can interact with multiple human participants (e.g. matsusaka et al, 2001; bennewitz et al, 2005).
</nextsent>
<nextsent>in our previous work bohus and horvitz (2009; 2010a; 2010b), we describe platform that leverages multimodal perception and reasoning to support multiparty dialog in open-world settings.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI977">
<title id=" W11-2013.xml">multiparty turn taking in situated dialog study lessons and directions </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>as another factor, turn taking is mixed-initiative process, and other participants might vie for the floor and issue their own contributions immediately after an answer directed to the system.
</prevsent>
<prevsent>these observations bring to the fore two questions: (1) how can we minimize the number of turn-initial overlaps, and (2) how can the system gracefully handle such overlaps once they occur?
</prevsent>
</prevsection>
<citsent citstr=" W08-0101 ">
one approach to minimizing turn-initial overlaps is to reduce the systems response delays via faster processing or via the use of predictive models to anticipate the end of turns (e.g. ferrer et al, 2003; schlangen, 2006; raux and eskenazi, 2008; <papid> W08-0101 </papid>skantze and schlangen, 2009).<papid> E09-1085 </papid></citsent>
<aftsection>
<nextsent>multiparty settings require methods for forecasting not only when current speaker will finish, but also whether any participant will try to take (or release) the floor within small window of time in the future, i.e., accurately modeling all floor intentions.
</nextsent>
<nextsent>our turn taking framework includes components for representing and modeling floor intentions, but these are not used in the current system.
</nextsent>
<nextsent>we believe there is promise in learning models to predict floor intentions and the timing of ends of utterances from interaction data.
</nextsent>
<nextsent>the availability of such predictions can fuel additional turn-taking strategies and also pave the way to more graceful handling of turn initial overlaps after they occur.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI978">
<title id=" W11-2013.xml">multiparty turn taking in situated dialog study lessons and directions </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>as another factor, turn taking is mixed-initiative process, and other participants might vie for the floor and issue their own contributions immediately after an answer directed to the system.
</prevsent>
<prevsent>these observations bring to the fore two questions: (1) how can we minimize the number of turn-initial overlaps, and (2) how can the system gracefully handle such overlaps once they occur?
</prevsent>
</prevsection>
<citsent citstr=" E09-1085 ">
one approach to minimizing turn-initial overlaps is to reduce the systems response delays via faster processing or via the use of predictive models to anticipate the end of turns (e.g. ferrer et al, 2003; schlangen, 2006; raux and eskenazi, 2008; <papid> W08-0101 </papid>skantze and schlangen, 2009).<papid> E09-1085 </papid></citsent>
<aftsection>
<nextsent>multiparty settings require methods for forecasting not only when current speaker will finish, but also whether any participant will try to take (or release) the floor within small window of time in the future, i.e., accurately modeling all floor intentions.
</nextsent>
<nextsent>our turn taking framework includes components for representing and modeling floor intentions, but these are not used in the current system.
</nextsent>
<nextsent>we believe there is promise in learning models to predict floor intentions and the timing of ends of utterances from interaction data.
</nextsent>
<nextsent>the availability of such predictions can fuel additional turn-taking strategies and also pave the way to more graceful handling of turn initial overlaps after they occur.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI979">
<title id=" W12-0911.xml">get out but dont fall down verb particle constructions in child language </title>
<section> materials and methods.  </section>
<citcontext>
<prevsection>
<prevsent>given that compositionality seems to have an impact on learning, to help reduce avoidance of phrasal verbs sawyer (2000) proposes semantic driven approach for second language learning where transparent compositional cases would be presented first to help familiarization with word order variation, semi-idiomatic cases would be taught next in groups according to the contribution of the particle (e.g telicity or completive ness), and lastly the idiomatic cases that need to be memorized.in this paper we present wide coverage examination of vpc distributions in child produced and child-directed sentences, comparing whether children reproduce the linguistic environment to which they are exposed or whether they present distinct preferences in vpc usage.
</prevsent>
<prevsent>for this work we use the english corpora from the childes database (macwhinney, 1995) containing transcriptions of child-produced and child-directed speech from interactions involving children of different age groups and in variety of settings, from naturalistic longitudinal studies to task oriented latitudinal cases.
</prevsent>
</prevsection>
<citsent citstr=" P06-2006 ">
these corpora are available in raw, part-of-speech-tagged, lem matized and parsed formats (sagae et al, 2010).moreover the english childes verb construction database (ecvcd) (villavicencio et al,2012) also adds for each sentence the rasp parsing and grammatical relations (briscoe and car roll, 2006), <papid> P06-2006 </papid>verb semantic classes (levin, 1993),age of acquisition, familiarity, frequency (coltheart, 1981) and other psycho linguistic and distributional characteristics.</citsent>
<aftsection>
<nextsent>these annotated sentences are divided into two groups according to the speaker annotation available in childes, the adults set and the children set contain respectively all the sentences spoken by adults and by children1, as shown in table 1 as parsed.vpcs in these corpora are detected by looking in the rasp annotation for all occurrences of verbs followed by particles, prepositions and adverbs up to 5 words to the right, following baldwin (2005), shown as sentences with vpcs1for the latter sentences which did not contain information about age were removed.
</nextsent>
<nextsent>45 sentences children set adults set parsed 482,137 988,101 with vpcs 44,305 83,098 with vpcs cleaned 38,326 82,796 % with vpcs 7.95 8.38 table 1: vpcs in english corpora in the children and adults setsin table 1.
</nextsent>
<nextsent>the resulting sentences are subsequently automatically processed to remove noise and words mis tagged as verbs.
</nextsent>
<nextsent>for these candidates with non-alphabetic characters, like @ in a@l up, were removed as were those that did not involve verbs (e.g. di, dat,), using the comlex lexicon as reference for verb validity (macleod and grishman, 1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI980">
<title id=" W11-2161.xml">dfki hybrid machine translation system for wmt 2011  on the integration of smt and rbmt </title>
<section> individual translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>the final translation output outperforms each individual output significantly.
</prevsent>
<prevsent>2.1 phrase-based system.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we use the ibm model 1 and 4 (brown et al, 1993) <papid> J93-2003 </papid>and hidden-markov model (hmm) (vogel et al, 1996) to train the word alignment using the mgiza toolkit1.</citsent>
<aftsection>
<nextsent>we applied the ems in moses (koehn et al., 2007) to build up the phrase-based translation system.
</nextsent>
<nextsent>features in the log-linear model include translation models in two directions, language model, distortion model and sentence lengthpenalty.
</nextsent>
<nextsent>a dynamic programming beam search algorithm is used to generate the translation hypothesis with maximum probability.
</nextsent>
<nextsent>we applied 5 gram mixture language model with each sub-model trained on one fifth of the monolingual corpus withkneser-ney smoothing using srilm toolkit (stol cke, 2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI981">
<title id=" W11-2161.xml">dfki hybrid machine translation system for wmt 2011  on the integration of smt and rbmt </title>
<section> individual translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 hierarchical phrase-based system.
</prevsent>
<prevsent>for the hierarchical system, we used the open source hierarchical phrased-based system jane, developed at rwth and free for non-commercial use (vi lar et al, 2010).
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
this approach is an extension of the phrase-based approach, where the phrases are allowed to have gaps (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>in this way long-range dependencies and reorderings can be modeled inconsistent statistical framework.
</nextsent>
<nextsent>the system uses fairly standard setup, trained using the bilingual data provided by the organizers, word aligned using the mgiza.
</nextsent>
<nextsent>two 5-gram language models were used during decoding: one trained on the monolingual part of the bilingual training data, and larger one trained on the additional news data.decoding was carried out using the cube pruning algorithm.
</nextsent>
<nextsent>the tuning is performed on test2008 with out further experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI982">
<title id=" W12-0702.xml">dependency based open information extraction </title>
<section> open information extraction systems.  </section>
<citcontext>
<prevsection>
<prevsent>text runner (banko et al, 2008): the extractor is second order linear-chain crf trained on samples of triples generated from the penn treebank.
</prevsent>
<prevsent>the input of text runner are pos-tagged and np-chunked sentences, both processes performed with opennlp tools.
</prevsent>
</prevsection>
<citsent citstr=" P10-1013 ">
woe (wu and weld, 2010): <papid> P10-1013 </papid>the extractor was learned by identifying the shortest dependency paths between two noun phrases, using training examples of wikipedia.</citsent>
<aftsection>
<nextsent>the main drawback is that extraction is 30 times slower than textrunner.
</nextsent>
<nextsent>reverb (etzioni et al, 2011; fader et al, 2011): <papid> D11-1142 </papid>the extractor is logistic regression classifier trained with shallow syntactic features, which also incorporates lexical constraints to filter out over-specified relation phrases.</nextsent>
<nextsent>it takes as input the same feature sas text runner, i.e., pos-tagged and np chunked sentences analyzed with opennlp tools.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI983">
<title id=" W12-0702.xml">dependency based open information extraction </title>
<section> open information extraction systems.  </section>
<citcontext>
<prevsection>
<prevsent>woe (wu and weld, 2010): <papid> P10-1013 </papid>the extractor was learned by identifying the shortest dependency paths between two noun phrases, using training examples of wikipedia.</prevsent>
<prevsent>the main drawback is that extraction is 30 times slower than textrunner.</prevsent>
</prevsection>
<citsent citstr=" D11-1142 ">
reverb (etzioni et al, 2011; fader et al, 2011): <papid> D11-1142 </papid>the extractor is logistic regression classifier trained with shallow syntactic features, which also incorporates lexical constraints to filter out over-specified relation phrases.</citsent>
<aftsection>
<nextsent>it takes as input the same feature sas text runner, i.e., pos-tagged and np chunked sentences analyzed with opennlp tools.
</nextsent>
<nextsent>it is considered to be the best oie system up to now.
</nextsent>
<nextsent>its performance is 30% higher than woe and more than twice that of textrunner.
</nextsent>
<nextsent>one of the most discussed problems of oie systems is that about 90% of the extracted triples are not concrete facts (banko et al, 2007) expressing valid information about one or two named entities, e.g. obama was born in honolulu?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI984">
<title id=" W12-0702.xml">dependency based open information extraction </title>
<section> open information extraction systems.  </section>
<citcontext>
<prevsection>
<prevsent>its performance is 30% higher than woe and more than twice that of textrunner.
</prevsent>
<prevsent>one of the most discussed problems of oie systems is that about 90% of the extracted triples are not concrete facts (banko et al, 2007) expressing valid information about one or two named entities, e.g. obama was born in honolulu?.
</prevsent>
</prevsection>
<citsent citstr=" D10-1123 ">
however, the vast amount of high confident relational triples extracted by oie systems are very useful start point for further nlp task sand applications, such as common sense knowledge acquisition (lin et al, 2010), <papid> D10-1123 </papid>and extraction of domain-specific relations (soderland et al, 112010).</citsent>
<aftsection>
<nextsent>the objective of oie systems is not to extract concrete facts, but to transform unstructured texts into structured information, closer to ontology formats.
</nextsent>
<nextsent>nevertheless, some linguistics problems arise.
</nextsent>
<nextsent>oie systems were trained to identify only verb clauses within the sentences and, therefore, to extract just binary verb-based relations from the clause structure.
</nextsent>
<nextsent>it follows that they cannot be easily adapted to learn other non-clausal relations also found in the text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI985">
<title id=" W12-0702.xml">dependency based open information extraction </title>
<section> applications.  </section>
<citcontext>
<prevsection>
<prevsent>and organism?, discovered by our system from wikipedia.
</prevsent>
<prevsent>specific domains.
</prevsent>
</prevsection>
<citsent citstr=" P11-1147 ">
one of the goals of learning by reading is to enable computer to acquire basic knowledge of different domains in order to im prove question answering systems (hovy et al, 2011).<papid> P11-1147 </papid></citsent>
<aftsection>
<nextsent>we assume that the head expressions ofthe most frequent triples extracted from specific domain represent basic propositions (com mon knowledge) of that domain.to check this assumption, we built two domain specific corpora from wikipedia: corpus constituted by articles about sports, and another corpus with articles about biology.
</nextsent>
<nextsent>then, we extracted the triples from those corpora and, for each triple,we selected just the headwords of its three ele ments: namely the main verb (and preposition if any) of the relation and the head nouns of the twoarguments.
</nextsent>
<nextsent>it resulted in list of basic propositions of specific domain.
</nextsent>
<nextsent>table 3 shows some of the propositions acquired following this method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI986">
<title id=" W12-0507.xml">contrasting objective and subjective portuguese texts from heterogeneous sources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>yet, there is already some relevant work in this area which may be mentioned here.
</prevsent>
<prevsent>for opinions, previous studies have mainly focused in the detection and the gradation of their emotional level, and this involves three main subtasks.
</prevsent>
</prevsection>
<citsent citstr=" W03-1017 ">
the first subtask is to distinguish subjective from objectives texts (yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></citsent>
<aftsection>
<nextsent>the second subtask focuses on the classification of subjective texts into positive or negative (turney, 2002).<papid> P02-1053 </papid></nextsent>
<nextsent>the third level of refinement is trying to determine the extent to which texts are positive or negative (wilson et al, 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI987">
<title id=" W12-0507.xml">contrasting objective and subjective portuguese texts from heterogeneous sources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>for opinions, previous studies have mainly focused in the detection and the gradation of their emotional level, and this involves three main subtasks.
</prevsent>
<prevsent>the first subtask is to distinguish subjective from objectives texts (yu and hatzivassiloglou, 2003).<papid> W03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
the second subtask focuses on the classification of subjective texts into positive or negative (turney, 2002).<papid> P02-1053 </papid></citsent>
<aftsection>
<nextsent>the third level of refinement is trying to determine the extent to which texts are positive or negative (wilson et al, 2004).
</nextsent>
<nextsent>the momentum for this type of research came through events such as trec blog opinion task since 2006.
</nextsent>
<nextsent>it is also worth mentioning recent efforts to reintroduce language and discursive approaches (e.g. taking into account the modality of the speaker) in this area (asher and mathieu, 2008).
</nextsent>
<nextsent>the approaches developed for automatic analysis of subjectivity have been used in wide variety of applications, such as online monitoring of mood (lloyd et al, 2005), the classification of opinions or comments (pang et al, 2002) <papid> W02-1011 </papid>and their extraction (hu an liu, 2004) andthe semantic analysis of texts (esuli and sebastiani, 2006).<papid> E06-1025 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI988">
<title id=" W12-0507.xml">contrasting objective and subjective portuguese texts from heterogeneous sources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the momentum for this type of research came through events such as trec blog opinion task since 2006.
</prevsent>
<prevsent>it is also worth mentioning recent efforts to reintroduce language and discursive approaches (e.g. taking into account the modality of the speaker) in this area (asher and mathieu, 2008).
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
the approaches developed for automatic analysis of subjectivity have been used in wide variety of applications, such as online monitoring of mood (lloyd et al, 2005), the classification of opinions or comments (pang et al, 2002) <papid> W02-1011 </papid>and their extraction (hu an liu, 2004) andthe semantic analysis of texts (esuli and sebastiani, 2006).<papid> E06-1025 </papid></citsent>
<aftsection>
<nextsent>in (mihalcea et al, 2007), <papid> P07-1123 </papid>bilingual lexicon and manually translated parallel corpus are used to generate sentence classifier according to their level of subjectivity for romanian.</nextsent>
<nextsent>although many recent studies in the analysis of subjectivity emphasize sentiment (a type of subjectivity, positive or negative), our work focuses on the recognition of subjectivity and objectivity in general.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI989">
<title id=" W12-0507.xml">contrasting objective and subjective portuguese texts from heterogeneous sources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>the momentum for this type of research came through events such as trec blog opinion task since 2006.
</prevsent>
<prevsent>it is also worth mentioning recent efforts to reintroduce language and discursive approaches (e.g. taking into account the modality of the speaker) in this area (asher and mathieu, 2008).
</prevsent>
</prevsection>
<citsent citstr=" E06-1025 ">
the approaches developed for automatic analysis of subjectivity have been used in wide variety of applications, such as online monitoring of mood (lloyd et al, 2005), the classification of opinions or comments (pang et al, 2002) <papid> W02-1011 </papid>and their extraction (hu an liu, 2004) andthe semantic analysis of texts (esuli and sebastiani, 2006).<papid> E06-1025 </papid></citsent>
<aftsection>
<nextsent>in (mihalcea et al, 2007), <papid> P07-1123 </papid>bilingual lexicon and manually translated parallel corpus are used to generate sentence classifier according to their level of subjectivity for romanian.</nextsent>
<nextsent>although many recent studies in the analysis of subjectivity emphasize sentiment (a type of subjectivity, positive or negative), our work focuses on the recognition of subjectivity and objectivity in general.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI990">
<title id=" W12-0507.xml">contrasting objective and subjective portuguese texts from heterogeneous sources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>it is also worth mentioning recent efforts to reintroduce language and discursive approaches (e.g. taking into account the modality of the speaker) in this area (asher and mathieu, 2008).
</prevsent>
<prevsent>the approaches developed for automatic analysis of subjectivity have been used in wide variety of applications, such as online monitoring of mood (lloyd et al, 2005), the classification of opinions or comments (pang et al, 2002) <papid> W02-1011 </papid>and their extraction (hu an liu, 2004) andthe semantic analysis of texts (esuli and sebastiani, 2006).<papid> E06-1025 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-1123 ">
in (mihalcea et al, 2007), <papid> P07-1123 </papid>bilingual lexicon and manually translated parallel corpus are used to generate sentence classifier according to their level of subjectivity for romanian.</citsent>
<aftsection>
<nextsent>although many recent studies in the analysis of subjectivity emphasize sentiment (a type of subjectivity, positive or negative), our work focuses on the recognition of subjectivity and objectivity in general.
</nextsent>
<nextsent>as stressed in some work (banea etal., 2008), <papid> D08-1014 </papid>researchers have shown that in sentiment analysis, an approach in two steps is often beneficial, in which we first distinguish objective from subjective texts, and then classify subjective texts depending on their polarity (kim and hovy,2006).<papid> N06-1026 </papid></nextsent>
<nextsent>in fact, the problem of distinguishing subjective versus objective texts has often been the most difficult of the two steps.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI991">
<title id=" W12-0507.xml">contrasting objective and subjective portuguese texts from heterogeneous sources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in (mihalcea et al, 2007), <papid> P07-1123 </papid>bilingual lexicon and manually translated parallel corpus are used to generate sentence classifier according to their level of subjectivity for romanian.</prevsent>
<prevsent>although many recent studies in the analysis of subjectivity emphasize sentiment (a type of subjectivity, positive or negative), our work focuses on the recognition of subjectivity and objectivity in general.</prevsent>
</prevsection>
<citsent citstr=" D08-1014 ">
as stressed in some work (banea etal., 2008), <papid> D08-1014 </papid>researchers have shown that in sentiment analysis, an approach in two steps is often beneficial, in which we first distinguish objective from subjective texts, and then classify subjective texts depending on their polarity (kim and hovy,2006).<papid> N06-1026 </papid></citsent>
<aftsection>
<nextsent>in fact, the problem of distinguishing subjective versus objective texts has often been the most difficult of the two steps.
</nextsent>
<nextsent>improvements inthe first step will therefore necessarily have beneficial impact on the second, which is also shown in some work (takamura et al, 2006).<papid> E06-1026 </papid></nextsent>
<nextsent>objective portuguese texts to build our subjective spoken corpus (more than2,000 texts), we used parallel corpus of english portuguese speeches2 and tool to automatically classify sentences in english as objective or subjective (opinionfinder (riloff et al, 2003)).<papid> W03-0404 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI992">
<title id=" W12-0507.xml">contrasting objective and subjective portuguese texts from heterogeneous sources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>in (mihalcea et al, 2007), <papid> P07-1123 </papid>bilingual lexicon and manually translated parallel corpus are used to generate sentence classifier according to their level of subjectivity for romanian.</prevsent>
<prevsent>although many recent studies in the analysis of subjectivity emphasize sentiment (a type of subjectivity, positive or negative), our work focuses on the recognition of subjectivity and objectivity in general.</prevsent>
</prevsection>
<citsent citstr=" N06-1026 ">
as stressed in some work (banea etal., 2008), <papid> D08-1014 </papid>researchers have shown that in sentiment analysis, an approach in two steps is often beneficial, in which we first distinguish objective from subjective texts, and then classify subjective texts depending on their polarity (kim and hovy,2006).<papid> N06-1026 </papid></citsent>
<aftsection>
<nextsent>in fact, the problem of distinguishing subjective versus objective texts has often been the most difficult of the two steps.
</nextsent>
<nextsent>improvements inthe first step will therefore necessarily have beneficial impact on the second, which is also shown in some work (takamura et al, 2006).<papid> E06-1026 </papid></nextsent>
<nextsent>objective portuguese texts to build our subjective spoken corpus (more than2,000 texts), we used parallel corpus of english portuguese speeches2 and tool to automatically classify sentences in english as objective or subjective (opinionfinder (riloff et al, 2003)).<papid> W03-0404 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI993">
<title id=" W12-0507.xml">contrasting objective and subjective portuguese texts from heterogeneous sources </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>as stressed in some work (banea etal., 2008), <papid> D08-1014 </papid>researchers have shown that in sentiment analysis, an approach in two steps is often beneficial, in which we first distinguish objective from subjective texts, and then classify subjective texts depending on their polarity (kim and hovy,2006).<papid> N06-1026 </papid></prevsent>
<prevsent>in fact, the problem of distinguishing subjective versus objective texts has often been the most difficult of the two steps.</prevsent>
</prevsection>
<citsent citstr=" E06-1026 ">
improvements inthe first step will therefore necessarily have beneficial impact on the second, which is also shown in some work (takamura et al, 2006).<papid> E06-1026 </papid></citsent>
<aftsection>
<nextsent>objective portuguese texts to build our subjective spoken corpus (more than2,000 texts), we used parallel corpus of english portuguese speeches2 and tool to automatically classify sentences in english as objective or subjective (opinionfinder (riloff et al, 2003)).<papid> W03-0404 </papid></nextsent>
<nextsent>wethen projected the labels obtained for the sentences in english on the portuguese sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI994">
<title id=" W12-0507.xml">contrasting objective and subjective portuguese texts from heterogeneous sources </title>
<section> creating corpus of subjective and.  </section>
<citcontext>
<prevsection>
<prevsent>in fact, the problem of distinguishing subjective versus objective texts has often been the most difficult of the two steps.
</prevsent>
<prevsent>improvements inthe first step will therefore necessarily have beneficial impact on the second, which is also shown in some work (takamura et al, 2006).<papid> E06-1026 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-0404 ">
objective portuguese texts to build our subjective spoken corpus (more than2,000 texts), we used parallel corpus of english portuguese speeches2 and tool to automatically classify sentences in english as objective or subjective (opinionfinder (riloff et al, 2003)).<papid> W03-0404 </papid></citsent>
<aftsection>
<nextsent>wethen projected the labels obtained for the sentences in english on the portuguese sentences.
</nextsent>
<nextsent>the original parallel corpus is made of 1,783,437 pairs of parallel sentences, and after removing pervasive short sentences (e.g. the house adjourned at ...?)
</nextsent>
<nextsent>or pairs of sentences with the ratio of their respective lengths far away from one (a sign of alignment or translation error), we are left with 1,153,875 pairs.
</nextsent>
<nextsent>a random selection of contiguous 20k pairs is selected for the experiment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI995">
<title id=" W12-1635.xml">semantic specificity in spoken dialogue requests </title>
<section> 5234 4377 </section>
<citcontext>
<prevsection>
<prevsent>little work has been reported on measures of the relationship between dialogue complexity and the semantic structure of ds applications database.
</prevsent>
<prevsent>zadrozny (1995) proposes q-complexity, which roughly corresponds to vocabulary size, and is essentially the number of questions that can be asked about database.
</prevsent>
</prevsection>
<citsent citstr=" W00-0107 ">
pollard and bierman (2000) <papid> W00-0107 </papid>describe similar measure that considers the number of bits required to distinguish every object, attribute, and relationship in the semantic space.</citsent>
<aftsection>
<nextsent>gorin et al (2000) distinguish between semantic and linguistic complexity of calls to spoken ds.semantic complexity is measured by inheritance relations between call types, the number of type labels per call, and how often calls are routed to humanagents.
</nextsent>
<nextsent>linguistic complexity is measured by utterance length, vocabulary size and perplexity.popescu et al (2003) identify class of semantically tractable?
</nextsent>
<nextsent>natural language questions that can be mapped to an sql query to return the questions unique correct answer.
</nextsent>
<nextsent>ambiguous questions with multiple correct answers are not considered semantically tractable.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI996">
<title id=" W12-1635.xml">semantic specificity in spoken dialogue requests </title>
<section> 5234 4377 </section>
<citcontext>
<prevsection>
<prevsent>natural language questions that can be mapped to an sql query to return the questions unique correct answer.
</prevsent>
<prevsent>ambiguous questions with multiple correct answers are not considered semantically tractable.
</prevsent>
</prevsection>
<citsent citstr=" P08-1055 ">
polifroni and walker (2008) <papid> P08-1055 </papid>address how to present informative options to users who are exploring database, for example, to choose restaurant.</citsent>
<aftsection>
<nextsent>when query returns many options, their system summarizes the return using attribute value pairs shared by many of the members.
</nextsent>
<nextsent>the database queried by ds can be regarded asthe systems knowledge.
</nextsent>
<nextsent>consequently, the semantic structure of the database and the way it is populated constrain the requests the system can address and how much information the user must provide.
</nextsent>
<nextsent>intuitively, table 1 shows that title has higher semantic specificity than author.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI998">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for the 2011 workshop on machine translation, we built.
</prevsent>
<prevsent>a hybrid mt system, including both syntactic and non-syntactic rules, and submitted it as constrained entry to the french english translation task.
</prevsent>
</prevsection>
<citsent citstr=" W10-1709 ">
this is our fourth yearly submission to the wmt shared translation task.in design and construction, the system is similar to our submission from last years workshop(hanneman et al, 2010), <papid> W10-1709 </papid>with changes in the methods we employed for training data selection and scfg filtering.</citsent>
<aftsection>
<nextsent>continuing wmts general trend, we worked with more data than in previous years, basing our 2011 system on 13.9 million sentences of parallel french english training data and an english language model of 1.8 billion words.
</nextsent>
<nextsent>decoding was carried out in joshua (li et al, 2009), <papid> W09-0424 </papid>an open-source framework for parsing-based mt. we managed our experiments with loony bin (clark andlavie, 2010), an open-source tool for defining, modifying, and running complex experimental pipelines.</nextsent>
<nextsent>we describe our system-building process in more detail in section 2.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI999">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is our fourth yearly submission to the wmt shared translation task.in design and construction, the system is similar to our submission from last years workshop(hanneman et al, 2010), <papid> W10-1709 </papid>with changes in the methods we employed for training data selection and scfg filtering.</prevsent>
<prevsent>continuing wmts general trend, we worked with more data than in previous years, basing our 2011 system on 13.9 million sentences of parallel french english training data and an english language model of 1.8 billion words.</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
decoding was carried out in joshua (li et al, 2009), <papid> W09-0424 </papid>an open-source framework for parsing-based mt. we managed our experiments with loony bin (clark andlavie, 2010), an open-source tool for defining, modifying, and running complex experimental pipelines.</citsent>
<aftsection>
<nextsent>we describe our system-building process in more detail in section 2.
</nextsent>
<nextsent>in section 3, we evaluate the systems performance on wmt development sets and examine the aftermath of training data selection and grammar filtering.
</nextsent>
<nextsent>section 4 concludes with possible directions for future work.
</nextsent>
<nextsent>2.1 training data selection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1000">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> system construction.  </section>
<citcontext>
<prevsection>
<prevsent>the first three of these are, for the most part, clean data resources that have been successfully employed as mt corpora for number of years.
</prevsent>
<prevsent>the giga-fren corpus, though the largest, is also the least precise, as its web-crawled data sources are less homogeneous and less structured than the other corpora.
</prevsent>
</prevsection>
<citsent citstr=" W10-1722 ">
nevertheless, pino et al (2010) <papid> W10-1722 </papid>found significant improvements in french?</citsent>
<aftsection>
<nextsent>english mt output quality by including it.
</nextsent>
<nextsent>our goal for this year was to strike middle ground: to avoid computational difficulties in using the entire 36.8 million sentence pairs of training data, but to mine the giga-fren corpus for sentences to increase our systems vocabulary coverage.
</nextsent>
<nextsent>our method of training data selection proceeded as follows.
</nextsent>
<nextsent>we first tokenized all the parallel training 365 corpus released used europarl 1,825,077 1,614,111 news commentary 115,562 95,138 un documents 12,317,600 9,352,232 giga-fren 22,520,400 2,839,466 total 36,778,639 13,900,947 table 1: total number of training sentence pairs released, by corpus, and the number used in building our system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1002">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> system construction.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 grammar extraction and scoring.
</prevsent>
<prevsent>once we had assembled the final training corpus, we annotated it with statistical word alignments and constituent parse trees on both sides.
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
unidirectional word alignments were provided by mgiza++ (gao and vogel, 2008), <papid> W08-0509 </papid>then symmetrized with the grow-diag-final-and heuristic (koehn et al, 2005).</citsent>
<aftsection>
<nextsent>for generating parse trees, we used the french and english grammars of the berkeley statistical parser (petrov and klein, 2007).<papid> N07-1051 </papid>except for minor bug fixes, our method forex tracting and scoring translation grammar remains the same as in our wmt 2010 submission.</nextsent>
<nextsent>we extracted both syntactic and non-syntactic portions ofthe translation grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1003">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> system construction.  </section>
<citcontext>
<prevsection>
<prevsent>once we had assembled the final training corpus, we annotated it with statistical word alignments and constituent parse trees on both sides.
</prevsent>
<prevsent>unidirectional word alignments were provided by mgiza++ (gao and vogel, 2008), <papid> W08-0509 </papid>then symmetrized with the grow-diag-final-and heuristic (koehn et al, 2005).</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
for generating parse trees, we used the french and english grammars of the berkeley statistical parser (petrov and klein, 2007).<papid> N07-1051 </papid>except for minor bug fixes, our method forex tracting and scoring translation grammar remains the same as in our wmt 2010 submission.</citsent>
<aftsection>
<nextsent>we extracted both syntactic and non-syntactic portions ofthe translation grammar.
</nextsent>
<nextsent>the non-syntactic grammar was extracted from the parallel corpus and word alignments following the standard heuristics of phrase-based smt (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>the syntactic grammar was produced using the method of lavie et al (2008), <papid> W08-0411 </papid>which decomposes each pair of word-aligned parse trees into series of minimalscfg rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1004">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> system construction.  </section>
<citcontext>
<prevsection>
<prevsent>for generating parse trees, we used the french and english grammars of the berkeley statistical parser (petrov and klein, 2007).<papid> N07-1051 </papid>except for minor bug fixes, our method forex tracting and scoring translation grammar remains the same as in our wmt 2010 submission.</prevsent>
<prevsent>we extracted both syntactic and non-syntactic portions ofthe translation grammar.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the non-syntactic grammar was extracted from the parallel corpus and word alignments following the standard heuristics of phrase-based smt (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the syntactic grammar was produced using the method of lavie et al (2008), <papid> W08-0411 </papid>which decomposes each pair of word-aligned parse trees into series of minimalscfg rules.</nextsent>
<nextsent>the word alignments are first generalized to node alignments, where nodes and are aligned between the source and target parse trees if all word alignments in the yield of land within the yield of and vice versa.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1005">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> system construction.  </section>
<citcontext>
<prevsection>
<prevsent>we extracted both syntactic and non-syntactic portions ofthe translation grammar.
</prevsent>
<prevsent>the non-syntactic grammar was extracted from the parallel corpus and word alignments following the standard heuristics of phrase-based smt (koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" W08-0411 ">
the syntactic grammar was produced using the method of lavie et al (2008), <papid> W08-0411 </papid>which decomposes each pair of word-aligned parse trees into series of minimalscfg rules.</citsent>
<aftsection>
<nextsent>the word alignments are first generalized to node alignments, where nodes and are aligned between the source and target parse trees if all word alignments in the yield of land within the yield of and vice versa.
</nextsent>
<nextsent>minimal scfg rules are derived from adjacent levels of node alignments: the labels from each pair of aligned nodes forms rules left-hand side, and the right-hand side is made up of the labels from the frontier of aligned nodes encountered when walking the left-hand sides subtrees.
</nextsent>
<nextsent>within phrase length limit, each aligned node pair generate an all-terminal phrase pair rule as well.
</nextsent>
<nextsent>since both grammars are extracted from the same viterbi word alignments using similar alignment consistency constraints, the phrase pair rules from the syntactic grammar make up subset of the rules extracted according to phrase-based smt heuristics.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1006">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> system construction.  </section>
<citcontext>
<prevsection>
<prevsent>not syntactically labelable?
</prevsent>
<prevsent>scores (s :: = phr :: phr | rs) and (s :: = phr :: phr | rt), with additive smoothing (n = 1), for all rules.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
bidirectional lexical scores for all rules with lexical items, calculated from unigram lexicon over viterbi-aligned word pairs as in the moses decoder (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>we also included the following 10 binary indicator features using statistics local to each rule: ? three low-count features that equal 1 when the extracted frequency of the rule is exactly equal to 1, 2, or 3.
</nextsent>
<nextsent>? syntactic feature that equals 1 when the rules label is syntactic, and corresponding non syntactic feature that equals 1 when the rules label is phr::phr.
</nextsent>
<nextsent>five rule format features that equal 1 when the rules right-hand side has certain composition.
</nextsent>
<nextsent>if as and at are true when the source and target sides contain only nonterminals, respectively, our rule format features are equal to as, at, as ? at, as ? at, and as ? at.finally, our model includes glue rule indicator feature that equals 1 when the rule is generic gluerule.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1007">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> experimental results and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>we tuned each system variant on the newstest2008 dataset, using the z-mert package (zaidan, 2009) for minimum error-rate training to the bleu metric.
</prevsent>
<prevsent>we ran development tests on the newstest2009 and newstest2010 data sets; table 2 reports the results obtained according to various automatic metrics.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the evaluation consists of case-insensitive scoring according to meteor 1.0 (lavie and denkowski, 2009) tuned to hter with the exact, stemming, and synonymy modules enabled, case-insensitive bleu (papineni et al, 2002) <papid> P02-1040 </papid>as implemented by the nist mteval-v13 script, and case-insensitive ter 0.7.25 (snover et al, 2006).</citsent>
<aftsection>
<nextsent>table 2 gives comparative results for two majorsystems: one based on our wmt 2011 data selection as outlined in section 2.1, and one based on the smaller wmt 2010 training data that we used last year (8.6 million sentence pairs).
</nextsent>
<nextsent>each system was run with the two grammar filtering variants described in section 2.4: the 10,000 most frequently extracted hierarchical rules of any type (10k?), and combination of the 2000 most frequently extracted abstract rules and the 100,000 most frequently extracted partially lexicalized rules that matched the test set (2k+100k?).
</nextsent>
<nextsent>our primary submission to thewmt 2011 shared task was the fourth line of table 2 (wmt 2011 2k+100k?); we also made constrastive submission with the system from the second line (wmt 2010 2k+100k?).
</nextsent>
<nextsent>using part of the giga-fren data ? along with the additions to the europarl, news commentary, and un document courses released since last year 368 newstest2009 newstest2010 system meteor bleu ter meteor bleu ter wmt 2010 10k 54.94 24.77 56.53 56.66 25.78 55.06 wmt 2010 2k+100k 55.16 24.88 56.19 56.89 26.05 54.66 wmt 2011 10k 55.82 26.02 54.77 58.13 27.71 52.96 wmt 2011 2k+100k 55.77 26.01 54.70 57.88 27.38 53.04 table 2: development test results for systems based on wmt 2010 data (without the giga-fren corpus) and wmt 2011 data (with some giga-fren).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1008">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> experimental results and analysis.  </section>
<citcontext>
<prevsection>
<prevsent>applications 10k 2k+100k unique rules 1,305 1,994 rule instances 14,539 12,130table 3: summary of 2011 system syntactic rule applications on both test sets.
</prevsent>
<prevsent>is beneficial to translation quality, as there is clear improvement in metric scores between the2010 and 2011 systems.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
our bleu score improvements of 1.2 to 1.9 points are statistically significant according to the paired bootstrap re sampling method (koehn, 2004) <papid> W04-3250 </papid>with = 1000 and   0.01.</citsent>
<aftsection>
<nextsent>theyare also larger than the 0.7- to 1.1-point gains reported by pino et al (2010) <papid> W10-1722 </papid>when the full giga-frenwas added.</nextsent>
<nextsent>the 2011 system also shows significant reduction in the out-of-vocabulary (oov) rate on both test sets: 38% and 47% fewer oov types,and 44% and 45% fewer oov tokens, when compared to the 2010 system.differences between grammar filtering techniques, on the other hand, are much less significant according to all three metrics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1011">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we plan to experiment with larger filtering cutoffs in future work.
</prevsent>
<prevsent>a complementary solution could be to increase the number of partially lexicalized rules.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
although we found mixed results in their application within our current system, the success of hiero-derived mt systems (chiang, 2005; <papid> P05-1033 </papid>chiang, 2010) <papid> P10-1146 </papid>shows that high translation quality can be achieved with rules that are only partially abstract.</citsent>
<aftsection>
<nextsent>a major difference between such systems and our current implementation is that ours, at 102,000 rules, has much smaller grammar.
</nextsent>
<nextsent>acknowledgments this research was supported in part by u.s. national science foundation grants iis-0713402 andiis-0915327, as well as by the darpa gale program.
</nextsent>
<nextsent>thanks to kenneth heafield for processing the english monolingual data and building the language model file, and to jonathan clark for loony bin support and bug fixes.
</nextsent>
<nextsent>we also thank yahoo!for the use of the m45 research computing cluster, where we ran many steps of our experimental pipeline.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1012">
<title id=" W11-2143.xml">cmu syntax based machine translation at wmt 2011 </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>we plan to experiment with larger filtering cutoffs in future work.
</prevsent>
<prevsent>a complementary solution could be to increase the number of partially lexicalized rules.
</prevsent>
</prevsection>
<citsent citstr=" P10-1146 ">
although we found mixed results in their application within our current system, the success of hiero-derived mt systems (chiang, 2005; <papid> P05-1033 </papid>chiang, 2010) <papid> P10-1146 </papid>shows that high translation quality can be achieved with rules that are only partially abstract.</citsent>
<aftsection>
<nextsent>a major difference between such systems and our current implementation is that ours, at 102,000 rules, has much smaller grammar.
</nextsent>
<nextsent>acknowledgments this research was supported in part by u.s. national science foundation grants iis-0713402 andiis-0915327, as well as by the darpa gale program.
</nextsent>
<nextsent>thanks to kenneth heafield for processing the english monolingual data and building the language model file, and to jonathan clark for loony bin support and bug fixes.
</nextsent>
<nextsent>we also thank yahoo!for the use of the m45 research computing cluster, where we ran many steps of our experimental pipeline.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1013">
<title id=" W11-2105.xml">amber a modified bleu enhanced ranking metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic evaluation metrics for machine translation (mt) quality play critical role in the development of statistical mt systems.
</prevsent>
<prevsent>several metrics have been proposed in recent years.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
metrics such as bleu (papineni et al, 2002), <papid> P02-1040 </papid>nist (dodding ton, 2002), wer, per, and ter (snover et al, 2006) do not use any linguistic information - they only apply surface matching.</citsent>
<aftsection>
<nextsent>meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>meteor-next (denkowski and lavie 2010), <papid> W10-1751 </papid>ter-plus (snover et al, 2009), <papid> W09-0441 </papid>maxsim (chan and ng, 2008), and tesla (liu et al., 2010) <papid> W10-1754 </papid>exploit some limited linguistic resources, such as synonym dictionaries, part-of-speech tagging or paraphrasing tables.</nextsent>
<nextsent>more sophisticated metrics such as rte (pado et al, 2009) and dcu lfg (he et al, 2010) <papid> W10-1753 </papid>use higher level syntactic or semantic analysis to score translations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1014">
<title id=" W11-2105.xml">amber a modified bleu enhanced ranking metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several metrics have been proposed in recent years.
</prevsent>
<prevsent>metrics such as bleu (papineni et al, 2002), <papid> P02-1040 </papid>nist (dodding ton, 2002), wer, per, and ter (snover et al, 2006) do not use any linguistic information - they only apply surface matching.</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>meteor-next (denkowski and lavie 2010), <papid> W10-1751 </papid>ter-plus (snover et al, 2009), <papid> W09-0441 </papid>maxsim (chan and ng, 2008), and tesla (liu et al., 2010) <papid> W10-1754 </papid>exploit some limited linguistic resources, such as synonym dictionaries, part-of-speech tagging or paraphrasing tables.</citsent>
<aftsection>
<nextsent>more sophisticated metrics such as rte (pado et al, 2009) and dcu lfg (he et al, 2010) <papid> W10-1753 </papid>use higher level syntactic or semantic analysis to score translations.</nextsent>
<nextsent>though several of these metrics have shown better correlation with human judgment than bleu, bleu is still the de facto standard evaluation me tric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1015">
<title id=" W11-2105.xml">amber a modified bleu enhanced ranking metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several metrics have been proposed in recent years.
</prevsent>
<prevsent>metrics such as bleu (papineni et al, 2002), <papid> P02-1040 </papid>nist (dodding ton, 2002), wer, per, and ter (snover et al, 2006) do not use any linguistic information - they only apply surface matching.</prevsent>
</prevsection>
<citsent citstr=" W10-1751 ">
meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>meteor-next (denkowski and lavie 2010), <papid> W10-1751 </papid>ter-plus (snover et al, 2009), <papid> W09-0441 </papid>maxsim (chan and ng, 2008), and tesla (liu et al., 2010) <papid> W10-1754 </papid>exploit some limited linguistic resources, such as synonym dictionaries, part-of-speech tagging or paraphrasing tables.</citsent>
<aftsection>
<nextsent>more sophisticated metrics such as rte (pado et al, 2009) and dcu lfg (he et al, 2010) <papid> W10-1753 </papid>use higher level syntactic or semantic analysis to score translations.</nextsent>
<nextsent>though several of these metrics have shown better correlation with human judgment than bleu, bleu is still the de facto standard evaluation me tric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1016">
<title id=" W11-2105.xml">amber a modified bleu enhanced ranking metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several metrics have been proposed in recent years.
</prevsent>
<prevsent>metrics such as bleu (papineni et al, 2002), <papid> P02-1040 </papid>nist (dodding ton, 2002), wer, per, and ter (snover et al, 2006) do not use any linguistic information - they only apply surface matching.</prevsent>
</prevsection>
<citsent citstr=" W09-0441 ">
meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>meteor-next (denkowski and lavie 2010), <papid> W10-1751 </papid>ter-plus (snover et al, 2009), <papid> W09-0441 </papid>maxsim (chan and ng, 2008), and tesla (liu et al., 2010) <papid> W10-1754 </papid>exploit some limited linguistic resources, such as synonym dictionaries, part-of-speech tagging or paraphrasing tables.</citsent>
<aftsection>
<nextsent>more sophisticated metrics such as rte (pado et al, 2009) and dcu lfg (he et al, 2010) <papid> W10-1753 </papid>use higher level syntactic or semantic analysis to score translations.</nextsent>
<nextsent>though several of these metrics have shown better correlation with human judgment than bleu, bleu is still the de facto standard evaluation me tric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1017">
<title id=" W11-2105.xml">amber a modified bleu enhanced ranking metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>several metrics have been proposed in recent years.
</prevsent>
<prevsent>metrics such as bleu (papineni et al, 2002), <papid> P02-1040 </papid>nist (dodding ton, 2002), wer, per, and ter (snover et al, 2006) do not use any linguistic information - they only apply surface matching.</prevsent>
</prevsection>
<citsent citstr=" W10-1754 ">
meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>meteor-next (denkowski and lavie 2010), <papid> W10-1751 </papid>ter-plus (snover et al, 2009), <papid> W09-0441 </papid>maxsim (chan and ng, 2008), and tesla (liu et al., 2010) <papid> W10-1754 </papid>exploit some limited linguistic resources, such as synonym dictionaries, part-of-speech tagging or paraphrasing tables.</citsent>
<aftsection>
<nextsent>more sophisticated metrics such as rte (pado et al, 2009) and dcu lfg (he et al, 2010) <papid> W10-1753 </papid>use higher level syntactic or semantic analysis to score translations.</nextsent>
<nextsent>though several of these metrics have shown better correlation with human judgment than bleu, bleu is still the de facto standard evaluation me tric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1018">
<title id=" W11-2105.xml">amber a modified bleu enhanced ranking metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>metrics such as bleu (papineni et al, 2002), <papid> P02-1040 </papid>nist (dodding ton, 2002), wer, per, and ter (snover et al, 2006) do not use any linguistic information - they only apply surface matching.</prevsent>
<prevsent>meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>meteor-next (denkowski and lavie 2010), <papid> W10-1751 </papid>ter-plus (snover et al, 2009), <papid> W09-0441 </papid>maxsim (chan and ng, 2008), and tesla (liu et al., 2010) <papid> W10-1754 </papid>exploit some limited linguistic resources, such as synonym dictionaries, part-of-speech tagging or paraphrasing tables.</prevsent>
</prevsection>
<citsent citstr=" W10-1753 ">
more sophisticated metrics such as rte (pado et al, 2009) and dcu lfg (he et al, 2010) <papid> W10-1753 </papid>use higher level syntactic or semantic analysis to score translations.</citsent>
<aftsection>
<nextsent>though several of these metrics have shown better correlation with human judgment than bleu, bleu is still the de facto standard evaluation metric.
</nextsent>
<nextsent>this is probably due to the following facts: 1.
</nextsent>
<nextsent>bleu is language independent (except for.
</nextsent>
<nextsent>word segmentation decisions).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1019">
<title id=" W11-2105.xml">amber a modified bleu enhanced ranking metric </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>3.
</prevsent>
<prevsent>bleu seems to be the best tuning metric.
</prevsent>
</prevsection>
<citsent citstr=" N10-1080 ">
from quality point of view - i.e., models trained using bleu obtain the highest scores from humans and even from other metrics (cer et al, 2010).<papid> N10-1080 </papid></citsent>
<aftsection>
<nextsent>when we developed our own metric, we decided to make it modified version of bleu whose rankings of translations would (ideally) correlate even more highly with human rankings.
</nextsent>
<nextsent>thus, our metric is called amber: modified bleu, enhanced ranking?
</nextsent>
<nextsent>metric.
</nextsent>
<nextsent>some of the amber variants use an information source with mild linguistic flavour ? morphological knowledge about suffixes, roots and prefixes ? but otherwise, the metric is based entirely on surface comparisons.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1020">
<title id=" W11-2105.xml">amber a modified bleu enhanced ranking metric </title>
<section> amber.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 various penalties.
</prevsent>
<prevsent>instead of the original brevity penalty, we experimented with product of various penalties: ? = = i i ipenpenalty 1 (10) where wi is the weight of each penalty peni.
</prevsent>
</prevsection>
<citsent citstr=" D08-1064 ">
strict brevity penalty (sbp): (chiang et al, 2008) <papid> D08-1064 </papid>proposed this penalty.</citsent>
<aftsection>
<nextsent>let ti be the translation of input sentence i, and let ri be its reference (or if there is more than one, the reference whose length in words || ir is closest to length || it ).
</nextsent>
<nextsent>set ???
</nextsent>
<nextsent>i ii i rt sbp |}||,min{| || 1exp (11) strict redundancy penalty (srp): long sentences are preferred by recall.
</nextsent>
<nextsent>since we relyon both recall and precision to compute the score, it is necessary to punish the sentences that are too long.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1021">
<title id=" W11-2105.xml">amber a modified bleu enhanced ranking metric </title>
<section> amber.  </section>
<citcontext>
<prevsection>
<prevsent>long word difference penalty (lwdp): is defined similarly to swdp.
</prevsent>
<prevsent>))(# || exp( runigram dclwdp ??= (15) where and are the number of long words (those longer than 3 characters) in the translation and reference respectively.
</prevsent>
</prevsection>
<citsent citstr=" D10-1092 ">
normalized spear mans correlation penalty (nscp): we adopt this from (isozaki et al, 2010).<papid> D10-1092 </papid></citsent>
<aftsection>
<nextsent>this penalty evaluates similarity in word order between the translation and reference.
</nextsent>
<nextsent>we first determine word correspondences between the translation and reference; then, we rank words by their position in the sentences.
</nextsent>
<nextsent>finally, we compute spear mans correlation between the ranks of the words common to the translation and reference.
</nextsent>
<nextsent>)1()1(1 2 ?+ ?= ? nnn i i?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1023">
<title id=" W11-2105.xml">amber a modified bleu enhanced ranking metric </title>
<section> amber.  </section>
<citcontext>
<prevsection>
<prevsent>for example: t: bob reading book likes r: bob likes reading book the rank vector of the reference is [1, 2, 3, 4], while the translation rank vector is [1, 3, 4, 2].
</prevsent>
<prevsent>the spear mans correlation score between these two vectors is )14(4)14( )42()34()23(01 222 ???+ ?+?+?+ ? =0.90.
</prevsent>
</prevsection>
<citsent citstr=" W10-1749 ">
in order to avoid negative values, we normalized the correlation score, obtaining the penalty nscp: 2)1( /nscp += (17) normalized ken dalls correlation penalty (nkcp): this is adopted from (birch and osborne, 2010) <papid> W10-1749 </papid>and (isozaki et al, 2010).<papid> D10-1092 </papid></citsent>
<aftsection>
<nextsent>in the previous example, where the rank vector of the translation is [1, 3, 4, 2], there are 624 =c pairs of integers.
</nextsent>
<nextsent>there are 4 increasing pairs: (1),  (3), (1),  (4), (1),  (2) and (3),  and (4).
</nextsent>
<nextsent>ken dalls correlation is defined by: 1 # #2 ??= pairs all pairsasingincre ?
</nextsent>
<nextsent>(18) therefore, ken dalls correlation for the translation bob reading book likes?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1026">
<title id=" W11-2006.xml">toward learning and evaluation of dialogue policies with text examples </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the problematic steps include annotating the meaning of user utterances in some semantic formalism, developing formal representation of information state, writing detailed rules that govern dialogue management, and annotating the meaning of system utterances in support of language generation, among other tasks.in this paper, we explore data collection and machine learning techniques that enable the implementation of domain-specific conversational dialogue policies through relatively small data collection effort, and without any formal modeling.
</prevsent>
<prevsent>we present case study, which serves to illustrate some of the possibilities in our framework.
</prevsent>
</prevsection>
<citsent citstr=" N10-1020 ">
in contrast to recent work on data-driven dialogue policy learning that learns dialogue behavior from existing data sources (gandhe and traum, 2007; jafarpour et al,2009; ritter et al, 2010), <papid> N10-1020 </papid>we address the task of authoring dialogue policy from scratch with specific purpose, task and scenario in mind.</citsent>
<aftsection>
<nextsent>we examine the data collection, learning and evaluation steps.the contributions of this work include data collection and enrichment framework without formal modeling, and the creation of dialogue policies from the collected data.
</nextsent>
<nextsent>we also propose framework for evaluating learned policies.
</nextsent>
<nextsent>we show, for the scenario in our case study, that these techniques deliver promising levels of performance, and point to possible future developments in data-driven dialogue policy creation and evaluation.
</nextsent>
<nextsent>for our case study we selected an existing dialogue system scenario designed for tactical questioning training (traum et al, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1027">
<title id=" W11-2006.xml">toward learning and evaluation of dialogue policies with text examples </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>the exponential number of possible utterances and dialogue paths in even simple conversational dialogue scenario such as the amani scenario suggests that learning acceptable dialogue behavior from surface text examples without annotation or formal modeling would require seemingly insurmountable quantity of dialogues to serve as training data.we address this problem in data collection framework with four main characteristics: (1) we sidestep the problem of learning natural language generation by using fixed predefined set of utterances for thea mani character.
</prevsent>
<prevsent>this so-called utterance selection?
</prevsent>
</prevsection>
<citsent citstr=" W10-4345 ">
approach has been used in number of dialogue systems (zukerman and marom, 2006; sellberg and jnsson, 2008; kenny et al, 2007, for example) and often serves as reasonable approximation to generation (gandhe and traum, 2010); (<papid> W10-4345 </papid>2) we collect dialogues from human participants who 40 play the parts of amani and the commander in structured role play framework (section 3.1); (3) we enrich the dialogues collected in the structured role play step with additional paraphrases for the utterances of the commander, in an attempt to deal with large variability of natural language input, even for limited domain conversational dialogue scenario (section 3.2); (4) we further augment the existing dialogue data by adding acceptable alternatives to the dialogue acts of the amani role through the use of external referees (section 3.3).our data collection procedure is designed to capture the necessary information for learning dialogue policies and evaluating their quality by approximating the exponentially large dialogue variability while keeping the data collection effort tractable.</citsent>
<aftsection>
<nextsent>3.1 structured role play.
</nextsent>
<nextsent>to examine the hypothesis that dialogue policies such as amanis can be learned from examples with out explicit rules or any kind of formal modeling, we collected dialogue data through constrained form of role play, which we call structured role play,where the person playing the role of amani is encouraged, whenever possible, to only use utterances from fixed set.
</nextsent>
<nextsent>each utterance in the available set of amani replies corresponds roughly to one of the dialogue acts (consisting of an illocutionary force and some semantic content) described by artstein et al.
</nextsent>
<nextsent>(2009) for their version of the amani character.the players in the roles of amani and the commander take turns producing one utterance at time, each in separate terminal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1028">
<title id=" W11-2006.xml">toward learning and evaluation of dialogue policies with text examples </title>
<section> evaluation of dialogue policies with.  </section>
<citcontext>
<prevsection>
<prevsent>without an automated metric, development of such techniques can be only vaguely incremental, relying on either costly or, more likely, infrequent human evaluations with results that are difficult to optimize toward with current machine learning techniques.
</prevsent>
<prevsent>the use of im perfect automated metrics in situations where ideal metrics are unavailable or are impractical to deploy is fairly common in natural language processing.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
parseval (abney et al, 1991), commonly used for parser evaluation, and bleu (papineni et al, 2002), <papid> P02-1040 </papid>commonly used in machine translation, are two examples of well-known imperfect metrics that have been the subject of much criticism, but that are widely agreed to have been necessary for much ofthe progress enjoyed by their respective fields.</citsent>
<aftsection>
<nextsent>unlike bleu, however, which has been shown to correlate with certain types of human judgment on the quality of machine translation systems, our notion of weak accuracy has not yet been demonstrated to correlate with human judgments on the quality of dialogue policies, and as such it is only hypothesized 45 to have this property.
</nextsent>
<nextsent>we leave this important step of validation as future work.
</nextsent>
<nextsent>examples without formal modeling equipped with dataset with 19 dialogues in thea mani scenario (including paraphrases for the unconstrained commander utterances, and external referee annotations for the constrained amani utter ances), and an automatic evaluation framework for distinguishing quality differences in learned policies, we now describe our experiments on learning dialogue policies from data collected in structured role play sessions, and enriched with paraphrases and external referee annotations.
</nextsent>
<nextsent>in each of our experiments we attempt to learna dialogue policy as maximum entropy classifier (berger et al, 1996) <papid> J96-1002 </papid>that chooses one utterance out of the 96 possible utterances for amani after each commander utterance, given features extracted from the dialogue history.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1029">
<title id=" W11-2006.xml">toward learning and evaluation of dialogue policies with text examples </title>
<section> learning dialogue policies from.  </section>
<citcontext>
<prevsection>
<prevsent>we leave this important step of validation as future work.
</prevsent>
<prevsent>examples without formal modeling equipped with dataset with 19 dialogues in thea mani scenario (including paraphrases for the unconstrained commander utterances, and external referee annotations for the constrained amani utter ances), and an automatic evaluation framework for distinguishing quality differences in learned policies, we now describe our experiments on learning dialogue policies from data collected in structured role play sessions, and enriched with paraphrases and external referee annotations.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
in each of our experiments we attempt to learna dialogue policy as maximum entropy classifier (berger et al, 1996) <papid> J96-1002 </papid>that chooses one utterance out of the 96 possible utterances for amani after each commander utterance, given features extracted from the dialogue history.</citsent>
<aftsection>
<nextsent>this policy could be integrated in dialogue system very easily, since it chooses system utterances directly given previous user and system utterances.
</nextsent>
<nextsent>we evaluate the dialogue policies learned in each experiment through 19-fold cross-validation of our set of 19 dialogues: in each fold, we hold out one dialogue (and all of its related information, such as external referee annotations and user utterance paraphrases) and use the remaining 18 dialogues as training data.
</nextsent>
<nextsent>5.1 learning from examples.
</nextsent>
<nextsent>using only the dialogues collected in structured role play sessions, and no additional information from external referees or paraphrases, we train the maximum entropy classifier to choose system utterance si based on features extracted from the two previous user utterances ui and ui1 and the previous system utterance si1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1030">
<title id=" W11-2019.xml">exploring user satisfaction in a tutorial dialogue system </title>
<section> beetle ii tutorial dialogue system.  </section>
<citcontext>
<prevsection>
<prevsent>henceforth we will refer to this as inspire.
</prevsent>
<prevsent>163
</prevsent>
</prevsection>
<citsent citstr=" P10-4003 ">
the goal of beetle ii (dzikovska et al, 2010<papid> P10-4003 </papid>c)is to teach students conceptual knowledge in the do main of basic electricity and electronics.</citsent>
<aftsection>
<nextsent>the system is built on the premise that encouraging students to explain their answers and to talk about the domain will lead to improved learning, finding consistent with analyses of human-human tutoring in several domains (purandare and litman, 2008; litman et al., 2009).
</nextsent>
<nextsent>beetle ii has been engineered to test this hypothesis by eliciting content ful talk through explanation questions.
</nextsent>
<nextsent>the beetle ii learning material consists of twoself-contained lessons suitable for college-level students with no prior knowledge of basic electricity and electronics.
</nextsent>
<nextsent>the lessons take 4 to 5 hours to complete, and consist of reading materials and interactive exercises.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1082">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the visualisation software was also employed to show the differences between the gold annotations and those of the submitted results, allowing the participants to better understand the performance of their system.
</prevsent>
<prevsent>the resources, evaluation tools and visualisation tool are provided freely for research purposes and can be found at http://sites.google.com/site/bionlpst/
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
for the bionlp09 shared task (kim et al , 2009),<papid> W09-1401 </papid>the first in the ongoing series, the organisers provided the participants with automatically generated syntactic analyses for the sentences from the annotated data.</citsent>
<aftsection>
<nextsent>for evaluation purposes, tools were made publicly available as both distributed software and online services.
</nextsent>
<nextsent>these resources were well received.
</nextsent>
<nextsent>a majority of the participants made use of one or more of the syntactic analyses, which have remained available after the shared task ended and have been employed in at least two independent efforts studying the contribution of different tools and forms of syntactic representation to the domain of information extraction (miwa et al , 2010; <papid> C10-1088 </papid>buyko and hahn, 2010).</nextsent>
<nextsent>the evaluation software for the bionlp09shared task has also been widely adopted in subsequent studies (miwa et al , 2010; <papid> C10-1088 </papid>poon and vanderwende, 2010; <papid> N10-1123 </papid>bjorne et al , 2010).the reception and research contribution from providing these resources encouraged us to continue providing similar resources for the bionlp shared task 2011 (kim et al , 2011<papid> W11-1802 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1083">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for evaluation purposes, tools were made publicly available as both distributed software and online services.
</prevsent>
<prevsent>these resources were well received.
</prevsent>
</prevsection>
<citsent citstr=" C10-1088 ">
a majority of the participants made use of one or more of the syntactic analyses, which have remained available after the shared task ended and have been employed in at least two independent efforts studying the contribution of different tools and forms of syntactic representation to the domain of information extraction (miwa et al , 2010; <papid> C10-1088 </papid>buyko and hahn, 2010).</citsent>
<aftsection>
<nextsent>the evaluation software for the bionlp09shared task has also been widely adopted in subsequent studies (miwa et al , 2010; <papid> C10-1088 </papid>poon and vanderwende, 2010; <papid> N10-1123 </papid>bjorne et al , 2010).the reception and research contribution from providing these resources encouraged us to continue providing similar resources for the bionlp shared task 2011 (kim et al , 2011<papid> W11-1802 </papid>a).</nextsent>
<nextsent>along with the parses we also encouraged the participants and external groups to process the data with any nlp (nat ural language processing) tools of their choice and make the results available to the participants.we provided continuous verification and evaluation of the participating systems using suite of in house evaluation tools.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1087">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these resources were well received.
</prevsent>
<prevsent>a majority of the participants made use of one or more of the syntactic analyses, which have remained available after the shared task ended and have been employed in at least two independent efforts studying the contribution of different tools and forms of syntactic representation to the domain of information extraction (miwa et al , 2010; <papid> C10-1088 </papid>buyko and hahn, 2010).</prevsent>
</prevsection>
<citsent citstr=" N10-1123 ">
the evaluation software for the bionlp09shared task has also been widely adopted in subsequent studies (miwa et al , 2010; <papid> C10-1088 </papid>poon and vanderwende, 2010; <papid> N10-1123 </papid>bjorne et al , 2010).the reception and research contribution from providing these resources encouraged us to continue providing similar resources for the bionlp shared task 2011 (kim et al , 2011<papid> W11-1802 </papid>a).</citsent>
<aftsection>
<nextsent>along with the parses we also encouraged the participants and external groups to process the data with any nlp (nat ural language processing) tools of their choice and make the results available to the participants.we provided continuous verification and evaluation of the participating systems using suite of in house evaluation tools.
</nextsent>
<nextsent>lastly, we provided toolfor visualising the annotated data to enable the participants to better grasp the results of their experiments and to help gain deeper understanding of the underlying concepts and the annotated data.
</nextsent>
<nextsent>this paper presents these supporting resources.
</nextsent>
<nextsent>this section introduces the data resources provided by the organisers, participants and external groups for the shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1088">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these resources were well received.
</prevsent>
<prevsent>a majority of the participants made use of one or more of the syntactic analyses, which have remained available after the shared task ended and have been employed in at least two independent efforts studying the contribution of different tools and forms of syntactic representation to the domain of information extraction (miwa et al , 2010; <papid> C10-1088 </papid>buyko and hahn, 2010).</prevsent>
</prevsection>
<citsent citstr=" W11-1802 ">
the evaluation software for the bionlp09shared task has also been widely adopted in subsequent studies (miwa et al , 2010; <papid> C10-1088 </papid>poon and vanderwende, 2010; <papid> N10-1123 </papid>bjorne et al , 2010).the reception and research contribution from providing these resources encouraged us to continue providing similar resources for the bionlp shared task 2011 (kim et al , 2011<papid> W11-1802 </papid>a).</citsent>
<aftsection>
<nextsent>along with the parses we also encouraged the participants and external groups to process the data with any nlp (nat ural language processing) tools of their choice and make the results available to the participants.we provided continuous verification and evaluation of the participating systems using suite of in house evaluation tools.
</nextsent>
<nextsent>lastly, we provided toolfor visualising the annotated data to enable the participants to better grasp the results of their experiments and to help gain deeper understanding of the underlying concepts and the annotated data.
</nextsent>
<nextsent>this paper presents these supporting resources.
</nextsent>
<nextsent>this section introduces the data resources provided by the organisers, participants and external groups for the shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1092">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>this section introduces the data resources provided by the organisers, participants and external groups for the shared task.
</prevsent>
<prevsent>112 task provider tool co university of utah reconcile co university of zurich uzcrs co university of turku tees rel university of turku tees table 1: supporting task analyses provided, tees is the turku event extraction system and uzcrs is the university of zurich coreference resolution system 2.1 supporting task analyses.
</prevsent>
</prevsection>
<citsent citstr=" W11-1812 ">
the shared task included three supporting tasks:coreference (co) (nguyen et al , 2011), entity relations (rel) (pyysalo et al , 2011<papid> W11-1812 </papid>b) and gene renaming (ren) (jourde et al , 2011).<papid> W11-1810 </papid></citsent>
<aftsection>
<nextsent>in the shared task schedule, the supporting tasks were carried out before the main tasks (kim et al , 2011<papid> W11-1802 </papid>b; pyysalo et al , 2011<papid> W11-1812 </papid>a; ohta et al , 2011; <papid> W11-1803 </papid>bossy et al , 2011)<papid> W11-1809 </papid>in order to allow participants to make use of analyses from the systems participating in the supporting tasks for their main task event extraction systems.error analysis of bionlp09 shared task submissions indicated that coreference was the most frequent feature of events that could not be correctly extracted by any participating system.</nextsent>
<nextsent>further, events involving statements of non-trivial relations between participating entities were frequent cause of extraction errors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1096">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>this section introduces the data resources provided by the organisers, participants and external groups for the shared task.
</prevsent>
<prevsent>112 task provider tool co university of utah reconcile co university of zurich uzcrs co university of turku tees rel university of turku tees table 1: supporting task analyses provided, tees is the turku event extraction system and uzcrs is the university of zurich coreference resolution system 2.1 supporting task analyses.
</prevsent>
</prevsection>
<citsent citstr=" W11-1810 ">
the shared task included three supporting tasks:coreference (co) (nguyen et al , 2011), entity relations (rel) (pyysalo et al , 2011<papid> W11-1812 </papid>b) and gene renaming (ren) (jourde et al , 2011).<papid> W11-1810 </papid></citsent>
<aftsection>
<nextsent>in the shared task schedule, the supporting tasks were carried out before the main tasks (kim et al , 2011<papid> W11-1802 </papid>b; pyysalo et al , 2011<papid> W11-1812 </papid>a; ohta et al , 2011; <papid> W11-1803 </papid>bossy et al , 2011)<papid> W11-1809 </papid>in order to allow participants to make use of analyses from the systems participating in the supporting tasks for their main task event extraction systems.error analysis of bionlp09 shared task submissions indicated that coreference was the most frequent feature of events that could not be correctly extracted by any participating system.</nextsent>
<nextsent>further, events involving statements of non-trivial relations between participating entities were frequent cause of extraction errors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1105">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>112 task provider tool co university of utah reconcile co university of zurich uzcrs co university of turku tees rel university of turku tees table 1: supporting task analyses provided, tees is the turku event extraction system and uzcrs is the university of zurich coreference resolution system 2.1 supporting task analyses.
</prevsent>
<prevsent>the shared task included three supporting tasks:coreference (co) (nguyen et al , 2011), entity relations (rel) (pyysalo et al , 2011<papid> W11-1812 </papid>b) and gene renaming (ren) (jourde et al , 2011).<papid> W11-1810 </papid></prevsent>
</prevsection>
<citsent citstr=" W11-1803 ">
in the shared task schedule, the supporting tasks were carried out before the main tasks (kim et al , 2011<papid> W11-1802 </papid>b; pyysalo et al , 2011<papid> W11-1812 </papid>a; ohta et al , 2011; <papid> W11-1803 </papid>bossy et al , 2011)<papid> W11-1809 </papid>in order to allow participants to make use of analyses from the systems participating in the supporting tasks for their main task event extraction systems.error analysis of bionlp09 shared task submissions indicated that coreference was the most frequent feature of events that could not be correctly extracted by any participating system.</citsent>
<aftsection>
<nextsent>further, events involving statements of non-trivial relations between participating entities were frequent cause of extraction errors.
</nextsent>
<nextsent>thus, the co and rel tasks were explicitly designed to support parts of the main event extraction tasks where it had been suggested that they could improve the system per formance.table 1 shows the supporting task analyses provided to the participants.
</nextsent>
<nextsent>for the main tasks, we are currently aware of one group (emadzadeh et al , 2011) that made use of the rel task analyses in theirsystem.
</nextsent>
<nextsent>however, while number of systems involved coreference resolution in some form, we are not aware of any teams using the co task analyses specifically, perhaps due in part to the tight schedule and the somewhat limited results of the co task.these data will remain available to allow future research into the benefits of these resources for event extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1106">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>112 task provider tool co university of utah reconcile co university of zurich uzcrs co university of turku tees rel university of turku tees table 1: supporting task analyses provided, tees is the turku event extraction system and uzcrs is the university of zurich coreference resolution system 2.1 supporting task analyses.
</prevsent>
<prevsent>the shared task included three supporting tasks:coreference (co) (nguyen et al , 2011), entity relations (rel) (pyysalo et al , 2011<papid> W11-1812 </papid>b) and gene renaming (ren) (jourde et al , 2011).<papid> W11-1810 </papid></prevsent>
</prevsection>
<citsent citstr=" W11-1809 ">
in the shared task schedule, the supporting tasks were carried out before the main tasks (kim et al , 2011<papid> W11-1802 </papid>b; pyysalo et al , 2011<papid> W11-1812 </papid>a; ohta et al , 2011; <papid> W11-1803 </papid>bossy et al , 2011)<papid> W11-1809 </papid>in order to allow participants to make use of analyses from the systems participating in the supporting tasks for their main task event extraction systems.error analysis of bionlp09 shared task submissions indicated that coreference was the most frequent feature of events that could not be correctly extracted by any participating system.</citsent>
<aftsection>
<nextsent>further, events involving statements of non-trivial relations between participating entities were frequent cause of extraction errors.
</nextsent>
<nextsent>thus, the co and rel tasks were explicitly designed to support parts of the main event extraction tasks where it had been suggested that they could improve the system per formance.table 1 shows the supporting task analyses provided to the participants.
</nextsent>
<nextsent>for the main tasks, we are currently aware of one group (emadzadeh et al , 2011) that made use of the rel task analyses in theirsystem.
</nextsent>
<nextsent>however, while number of systems involved coreference resolution in some form, we are not aware of any teams using the co task analyses specifically, perhaps due in part to the tight schedule and the somewhat limited results of the co task.these data will remain available to allow future research into the benefits of these resources for event extraction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1108">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>the emphasis was put on availability for research purposes and variety of parsing models and frameworks to allow evaluation of their applicability for different tasks.
</prevsent>
<prevsent>in part following up on the results of miwa et al  (2010) <papid> C10-1088 </papid>and buyko and hahn (2010) regarding the impact on performance of event extraction systems depending on the dependency parse representation,we aimed to provide several dependency parse for mats.</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
stanford dependencies (sd) and collapsed stanford dependencies (sdc), as described by demarneffe et al  (2006), were generated by converting penn treebank (ptb)-style (marcus et al , 1993) <papid> J93-2004 </papid>output using the stanford corenlp tools2 into thetwo dependency formats.</citsent>
<aftsection>
<nextsent>we also provided conference on computational natural language learning style dependency parses (conll-x) (buchholz andmarsi, 2006) <papid> W06-2920 </papid>which were also converted from ptb style output, but for this we used the conversion tool3 from johansson and nugues (2007).</nextsent>
<nextsent>while this conversion tool was not designed with converting the output from statistical parsers in mind (butrather to convert between treebanks), it has previously been applied successfully for this task (miyao et al , 2008; <papid> P08-1006 </papid>miwa et al , 2010).<papid> C10-1088 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1109">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>in part following up on the results of miwa et al  (2010) <papid> C10-1088 </papid>and buyko and hahn (2010) regarding the impact on performance of event extraction systems depending on the dependency parse representation,we aimed to provide several dependency parse for mats.</prevsent>
<prevsent>stanford dependencies (sd) and collapsed stanford dependencies (sdc), as described by demarneffe et al  (2006), were generated by converting penn treebank (ptb)-style (marcus et al , 1993) <papid> J93-2004 </papid>output using the stanford corenlp tools2 into thetwo dependency formats.</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
we also provided conference on computational natural language learning style dependency parses (conll-x) (buchholz andmarsi, 2006) <papid> W06-2920 </papid>which were also converted from ptb style output, but for this we used the conversion tool3 from johansson and nugues (2007).</citsent>
<aftsection>
<nextsent>while this conversion tool was not designed with converting the output from statistical parsers in mind (butrather to convert between treebanks), it has previously been applied successfully for this task (miyao et al , 2008; <papid> P08-1006 </papid>miwa et al , 2010).<papid> C10-1088 </papid></nextsent>
<nextsent>the text from all documents provided were split into sentences using the genia sentence splitter4 (stre et al , 2007) and then post processed using aset of heuristics to correct frequently occurring errors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1110">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>stanford dependencies (sd) and collapsed stanford dependencies (sdc), as described by demarneffe et al  (2006), were generated by converting penn treebank (ptb)-style (marcus et al , 1993) <papid> J93-2004 </papid>output using the stanford corenlp tools2 into thetwo dependency formats.</prevsent>
<prevsent>we also provided conference on computational natural language learning style dependency parses (conll-x) (buchholz andmarsi, 2006) <papid> W06-2920 </papid>which were also converted from ptb style output, but for this we used the conversion tool3 from johansson and nugues (2007).</prevsent>
</prevsection>
<citsent citstr=" P08-1006 ">
while this conversion tool was not designed with converting the output from statistical parsers in mind (butrather to convert between treebanks), it has previously been applied successfully for this task (miyao et al , 2008; <papid> P08-1006 </papid>miwa et al , 2010).<papid> C10-1088 </papid></citsent>
<aftsection>
<nextsent>the text from all documents provided were split into sentences using the genia sentence splitter4 (stre et al , 2007) and then post processed using aset of heuristics to correct frequently occurring errors.
</nextsent>
<nextsent>the sentences were then token ised using to ken isation script created by the organisers intended to replicate the token isation of the genia tree bank (gtb) (tateisi et al , 2005).<papid> I05-2038 </papid></nextsent>
<nextsent>this token ised and sentence-split data was then used as input for all parsers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1112">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>while this conversion tool was not designed with converting the output from statistical parsers in mind (butrather to convert between treebanks), it has previously been applied successfully for this task (miyao et al , 2008; <papid> P08-1006 </papid>miwa et al , 2010).<papid> C10-1088 </papid></prevsent>
<prevsent>the text from all documents provided were split into sentences using the genia sentence splitter4 (stre et al , 2007) and then post processed using aset of heuristics to correct frequently occurring errors.</prevsent>
</prevsection>
<citsent citstr=" I05-2038 ">
the sentences were then token ised using to ken isation script created by the organisers intended to replicate the token isation of the genia tree bank (gtb) (tateisi et al , 2005).<papid> I05-2038 </papid></citsent>
<aftsection>
<nextsent>this token ised and sentence-split data was then used as input for all parsers.
</nextsent>
<nextsent>we used two deep parsers that provide phrase structure analysis enriched with deep sentence struc 1https://files.ifi.uzh.ch/cl/gschneid/parser/ 2http://nlp.stanford.edu/software/corenlp.shtml 3http://nlp.cs.lth.se/software/treebank converter/ 4http://www-tsujii.is.s.u-tokyo.ac.jp/y-matsu/geniass/ 113 name format(s) model availability bionlp09 berkeley ptb, sd, sdc, conll-x news binary, source no c&c; ccg, sd biomedical binary, source yes enju hpsg, ptb, sd, sdc, conll-x biomedical binary no gdep conll-x biomedical binary, source yes mcccj ptb, sd, sdc, conll-x biomedical source yes pro3gres pro3gres combination ? no stanford ptb, sd, sdc, conll-x combination binary, source yes table 2: parsers, the formats for which their output was provided and which type of model that was used.
</nextsent>
<nextsent>the availability column signifies public availability (without making an explicit request) for research purposes tures, for example predicate-argument structure for head-driven phrase structure grammar (hpsg).
</nextsent>
<nextsent>first we used the c&c; combinatory categorial grammar (ccg) parser5 (c&c;) by clark and curran (2004) <papid> P04-1014 </papid>using the biomedical model described in rimell and clark (2009) which was trained on gtb.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1113">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>we used two deep parsers that provide phrase structure analysis enriched with deep sentence struc 1https://files.ifi.uzh.ch/cl/gschneid/parser/ 2http://nlp.stanford.edu/software/corenlp.shtml 3http://nlp.cs.lth.se/software/treebank converter/ 4http://www-tsujii.is.s.u-tokyo.ac.jp/y-matsu/geniass/ 113 name format(s) model availability bionlp09 berkeley ptb, sd, sdc, conll-x news binary, source no c&c; ccg, sd biomedical binary, source yes enju hpsg, ptb, sd, sdc, conll-x biomedical binary no gdep conll-x biomedical binary, source yes mcccj ptb, sd, sdc, conll-x biomedical source yes pro3gres pro3gres combination ? no stanford ptb, sd, sdc, conll-x combination binary, source yes table 2: parsers, the formats for which their output was provided and which type of model that was used.
</prevsent>
<prevsent>the availability column signifies public availability (without making an explicit request) for research purposes tures, for example predicate-argument structure for head-driven phrase structure grammar (hpsg).
</prevsent>
</prevsection>
<citsent citstr=" P04-1014 ">
first we used the c&c; combinatory categorial grammar (ccg) parser5 (c&c;) by clark and curran (2004) <papid> P04-1014 </papid>using the biomedical model described in rimell and clark (2009) which was trained on gtb.</citsent>
<aftsection>
<nextsent>unlike all other parsers for which we supplied sd and sdc dependency parses, the c&c; output was converted from its native format using separate conversion script provided by the c&c; authors.
</nextsent>
<nextsent>regrettably we were unable to provide conll-x format output for this parser due to the lack of ptb style output.
</nextsent>
<nextsent>the other deep parser used was the hpsg parser enju6 by miyao and tsujii (2008), <papid> J08-1002 </papid>also trained on gtb.</nextsent>
<nextsent>we also applied the frequently adopted stanford parser7 (klein and manning, 2003) using mixed model which includes data from the biomedical do main, and the charniak johnson re-ranking parser8 (charniak and johnson, 2005) <papid> P05-1022 </papid>using the self-trained biomedical model from mcclosky (2009) (mcccj).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1114">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>unlike all other parsers for which we supplied sd and sdc dependency parses, the c&c; output was converted from its native format using separate conversion script provided by the c&c; authors.
</prevsent>
<prevsent>regrettably we were unable to provide conll-x format output for this parser due to the lack of ptb style output.
</prevsent>
</prevsection>
<citsent citstr=" J08-1002 ">
the other deep parser used was the hpsg parser enju6 by miyao and tsujii (2008), <papid> J08-1002 </papid>also trained on gtb.</citsent>
<aftsection>
<nextsent>we also applied the frequently adopted stanford parser7 (klein and manning, 2003) using mixed model which includes data from the biomedical do main, and the charniak johnson re-ranking parser8 (charniak and johnson, 2005) <papid> P05-1022 </papid>using the self-trained biomedical model from mcclosky (2009) (mcccj).</nextsent>
<nextsent>for the bionlp09 shared task it was observed that the bikel parser9 (bikel, 2004), <papid> J04-4004 </papid>which used non-biomedical model and can be argued that it uses the somewhat dated collins?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1115">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>regrettably we were unable to provide conll-x format output for this parser due to the lack of ptb style output.
</prevsent>
<prevsent>the other deep parser used was the hpsg parser enju6 by miyao and tsujii (2008), <papid> J08-1002 </papid>also trained on gtb.</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
we also applied the frequently adopted stanford parser7 (klein and manning, 2003) using mixed model which includes data from the biomedical do main, and the charniak johnson re-ranking parser8 (charniak and johnson, 2005) <papid> P05-1022 </papid>using the self-trained biomedical model from mcclosky (2009) (mcccj).</citsent>
<aftsection>
<nextsent>for the bionlp09 shared task it was observed that the bikel parser9 (bikel, 2004), <papid> J04-4004 </papid>which used non-biomedical model and can be argued that it uses the somewhat dated collins?</nextsent>
<nextsent>parsing model (collins, 1996), <papid> P96-1025 </papid>did not contribute towards event extraction performance as strongly as other parses supplied for the same data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1116">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>the other deep parser used was the hpsg parser enju6 by miyao and tsujii (2008), <papid> J08-1002 </papid>also trained on gtb.</prevsent>
<prevsent>we also applied the frequently adopted stanford parser7 (klein and manning, 2003) using mixed model which includes data from the biomedical do main, and the charniak johnson re-ranking parser8 (charniak and johnson, 2005) <papid> P05-1022 </papid>using the self-trained biomedical model from mcclosky (2009) (mcccj).</prevsent>
</prevsection>
<citsent citstr=" J04-4004 ">
for the bionlp09 shared task it was observed that the bikel parser9 (bikel, 2004), <papid> J04-4004 </papid>which used non-biomedical model and can be argued that it uses the somewhat dated collins?</citsent>
<aftsection>
<nextsent>parsing model (collins, 1996), <papid> P96-1025 </papid>did not contribute towards event extraction performance as strongly as other parses supplied for the same data.</nextsent>
<nextsent>we therefore wanted to supply aparser that can compete with the ones above in do main which is different from the biomedical domain to see whether conclusions could be drawn as to the 5http://svn.ask.it.usyd.edu.au/trac/candc/ 6http://www-tsujii.is.s.u-tokyo.ac.jp/enju/ 7http://nlp.stanford.edu/software/lex-parser.shtml 8ftp://ftp.cs.brown.edu/pub/nlparser/ 9http://www.cis.upenn.edu/dbikel/software.html importance of using biomedical model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1117">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>we also applied the frequently adopted stanford parser7 (klein and manning, 2003) using mixed model which includes data from the biomedical do main, and the charniak johnson re-ranking parser8 (charniak and johnson, 2005) <papid> P05-1022 </papid>using the self-trained biomedical model from mcclosky (2009) (mcccj).</prevsent>
<prevsent>for the bionlp09 shared task it was observed that the bikel parser9 (bikel, 2004), <papid> J04-4004 </papid>which used non-biomedical model and can be argued that it uses the somewhat dated collins?</prevsent>
</prevsection>
<citsent citstr=" P96-1025 ">
parsing model (collins, 1996), <papid> P96-1025 </papid>did not contribute towards event extraction performance as strongly as other parses supplied for the same data.</citsent>
<aftsection>
<nextsent>we therefore wanted to supply aparser that can compete with the ones above in do main which is different from the biomedical domain to see whether conclusions could be drawn as to the 5http://svn.ask.it.usyd.edu.au/trac/candc/ 6http://www-tsujii.is.s.u-tokyo.ac.jp/enju/ 7http://nlp.stanford.edu/software/lex-parser.shtml 8ftp://ftp.cs.brown.edu/pub/nlparser/ 9http://www.cis.upenn.edu/dbikel/software.html importance of using biomedical model.
</nextsent>
<nextsent>for this we used the berkeley parser10 (petrov et al , 2006).<papid> P06-1055 </papid>lastly we used native dependency parser, the genia dependency parser (gdep) by sagae and tsujii (2007).<papid> D07-1111 </papid>at least one team (choudhury et al , 2011) performed experiments on some of the provided lexical analyses and among the 14 submissions for the epi and id tasks, 13 submissions utilised tools for which resources were provided by the organisers of the shared task.</nextsent>
<nextsent>we intend to follow up on whether or not the majority of the teams ran the tools themselves or used the provided analyses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1118">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>parsing model (collins, 1996), <papid> P96-1025 </papid>did not contribute towards event extraction performance as strongly as other parses supplied for the same data.</prevsent>
<prevsent>we therefore wanted to supply aparser that can compete with the ones above in do main which is different from the biomedical domain to see whether conclusions could be drawn as to the 5http://svn.ask.it.usyd.edu.au/trac/candc/ 6http://www-tsujii.is.s.u-tokyo.ac.jp/enju/ 7http://nlp.stanford.edu/software/lex-parser.shtml 8ftp://ftp.cs.brown.edu/pub/nlparser/ 9http://www.cis.upenn.edu/dbikel/software.html importance of using biomedical model.</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
for this we used the berkeley parser10 (petrov et al , 2006).<papid> P06-1055 </papid>lastly we used native dependency parser, the genia dependency parser (gdep) by sagae and tsujii (2007).<papid> D07-1111 </papid>at least one team (choudhury et al , 2011) performed experiments on some of the provided lexical analyses and among the 14 submissions for the epi and id tasks, 13 submissions utilised tools for which resources were provided by the organisers of the shared task.</citsent>
<aftsection>
<nextsent>we intend to follow up on whether or not the majority of the teams ran the tools themselves or used the provided analyses.
</nextsent>
<nextsent>2.3 other analyses.
</nextsent>
<nextsent>the call for analyses was open to all interested parties and all forms of analysis.
</nextsent>
<nextsent>in addition to the supporting task analyses (co and rel) and syntactic analyses provided by various groups, the university of antwerp clips center (morante et al , 2010) <papid> W10-3006 </papid>responded to the call providing negation/speculation analyses in the bio scope corpus format (szarvas et al ., 2008).<papid> W08-0606 </papid>although this resource was not utilised by the participants for the main task, possibly due to lack of time, it is our hope that by keeping the data available it can lead to further development of the participating systems and analysis of bio scope and bionlp st-style hedging annotations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1119">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>parsing model (collins, 1996), <papid> P96-1025 </papid>did not contribute towards event extraction performance as strongly as other parses supplied for the same data.</prevsent>
<prevsent>we therefore wanted to supply aparser that can compete with the ones above in do main which is different from the biomedical domain to see whether conclusions could be drawn as to the 5http://svn.ask.it.usyd.edu.au/trac/candc/ 6http://www-tsujii.is.s.u-tokyo.ac.jp/enju/ 7http://nlp.stanford.edu/software/lex-parser.shtml 8ftp://ftp.cs.brown.edu/pub/nlparser/ 9http://www.cis.upenn.edu/dbikel/software.html importance of using biomedical model.</prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
for this we used the berkeley parser10 (petrov et al , 2006).<papid> P06-1055 </papid>lastly we used native dependency parser, the genia dependency parser (gdep) by sagae and tsujii (2007).<papid> D07-1111 </papid>at least one team (choudhury et al , 2011) performed experiments on some of the provided lexical analyses and among the 14 submissions for the epi and id tasks, 13 submissions utilised tools for which resources were provided by the organisers of the shared task.</citsent>
<aftsection>
<nextsent>we intend to follow up on whether or not the majority of the teams ran the tools themselves or used the provided analyses.
</nextsent>
<nextsent>2.3 other analyses.
</nextsent>
<nextsent>the call for analyses was open to all interested parties and all forms of analysis.
</nextsent>
<nextsent>in addition to the supporting task analyses (co and rel) and syntactic analyses provided by various groups, the university of antwerp clips center (morante et al , 2010) <papid> W10-3006 </papid>responded to the call providing negation/speculation analyses in the bio scope corpus format (szarvas et al ., 2008).<papid> W08-0606 </papid>although this resource was not utilised by the participants for the main task, possibly due to lack of time, it is our hope that by keeping the data available it can lead to further development of the participating systems and analysis of bio scope and bionlp st-style hedging annotations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1120">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 other analyses.
</prevsent>
<prevsent>the call for analyses was open to all interested parties and all forms of analysis.
</prevsent>
</prevsection>
<citsent citstr=" W10-3006 ">
in addition to the supporting task analyses (co and rel) and syntactic analyses provided by various groups, the university of antwerp clips center (morante et al , 2010) <papid> W10-3006 </papid>responded to the call providing negation/speculation analyses in the bio scope corpus format (szarvas et al ., 2008).<papid> W08-0606 </papid>although this resource was not utilised by the participants for the main task, possibly due to lack of time, it is our hope that by keeping the data available it can lead to further development of the participating systems and analysis of bio scope and bionlp st-style hedging annotations.</citsent>
<aftsection>
<nextsent>this section presents the tools produced by the organisers for the purpose of the shared task.
</nextsent>
<nextsent>10http://code.google.com/p/berkeleyparser/ 114 1 10411007-e1 regulation  exp regulate[26-34]  theme tnf-alpha[79-88] ? ? excerpt [regulate] an enhancer activity in the third intron of [tnf-alpha] 2 10411007-e2 gene_expression  exp activity[282-290]  theme tnf-alpha[252-261] ? ? excerpt [tnf-alpha] gene displayed weak [activity] 3 10411007-e3 +regulation  exp when[291-295]  theme e2  excerpt [when] figure 1: text output from the bionlp09 shared event viewer with line numbering and newline markings figure 2: an illustration of collective (sentence 1) and distributive reading (sentence 2).
</nextsent>
<nextsent>theme?
</nextsent>
<nextsent>is abbreviated as th?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1121">
<title id=" W11-1816.xml">bionlp shared task 2011 supporting resources </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 other analyses.
</prevsent>
<prevsent>the call for analyses was open to all interested parties and all forms of analysis.
</prevsent>
</prevsection>
<citsent citstr=" W08-0606 ">
in addition to the supporting task analyses (co and rel) and syntactic analyses provided by various groups, the university of antwerp clips center (morante et al , 2010) <papid> W10-3006 </papid>responded to the call providing negation/speculation analyses in the bio scope corpus format (szarvas et al ., 2008).<papid> W08-0606 </papid>although this resource was not utilised by the participants for the main task, possibly due to lack of time, it is our hope that by keeping the data available it can lead to further development of the participating systems and analysis of bio scope and bionlp st-style hedging annotations.</citsent>
<aftsection>
<nextsent>this section presents the tools produced by the organisers for the purpose of the shared task.
</nextsent>
<nextsent>10http://code.google.com/p/berkeleyparser/ 114 1 10411007-e1 regulation  exp regulate[26-34]  theme tnf-alpha[79-88] ? ? excerpt [regulate] an enhancer activity in the third intron of [tnf-alpha] 2 10411007-e2 gene_expression  exp activity[282-290]  theme tnf-alpha[252-261] ? ? excerpt [tnf-alpha] gene displayed weak [activity] 3 10411007-e3 +regulation  exp when[291-295]  theme e2  excerpt [when] figure 1: text output from the bionlp09 shared event viewer with line numbering and newline markings figure 2: an illustration of collective (sentence 1) and distributive reading (sentence 2).
</nextsent>
<nextsent>theme?
</nextsent>
<nextsent>is abbreviated as th?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1122">
<title id=" W12-1010.xml">parsing the past  identification of verb constructions in historical text </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the retraining was based on gold standard of 30,000 tokens, where the tokens were first pre-annotated with the contemporary tagger, and then manually corrected.adding new words to the dictionary had the highest impact on the results.
</prevsent>
<prevsent>this was done by automatically generating word forms through mapping old spelling variants to their contemporary counterparts.
</prevsent>
</prevsection>
<citsent citstr=" W11-1512 ">
pettersson and nivre (2011) <papid> W11-1512 </papid>presented study on automatically extracting verbs from swedish 17th century texts, using contemporary language technology tools combined with normalisation of the input text.</citsent>
<aftsection>
<nextsent>the verb extraction process included an iterative process of normalisation and morphological analysis, followed by part-of speech tagging for disambiguation of competing interpretations and for analysing words still unknown to the morphological analyser after all normalisation rules had been applied.
</nextsent>
<nextsent>using this method, verbs were extracted with 82% precision and 88% recall.
</nextsent>
<nextsent>the study also included there sults of using only the part-of-speech tagger forverb recognition, i.e., dropping the morphological analyser.
</nextsent>
<nextsent>this resulted in small decrease in precision to 81% and in recall to 86%.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1125">
<title id=" W12-1010.xml">parsing the past  identification of verb constructions in historical text </title>
<section> parsing.  </section>
<citcontext>
<prevsection>
<prevsent>67 3.3 part-of-speech tagging.
</prevsent>
<prevsent>the purpose of part-of-speech tagging in our experiments is both to find the verbs in the text andto prepare for the parsing step, in which the complements are identified.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
part-of-speech tagging is performed using hunpos (halacsy et al, 2007), free and open source re implementation of the hmm-based tnt-tagger by brants (2000).<papid> A00-1031 </papid></citsent>
<aftsection>
<nextsent>the tagger is used with pre-trained language model based on the stockholm-umea?
</nextsent>
<nextsent>corpus (suc), balanced, manually annotated corpus of different text types representative of the swedish language in the 1990s, comprising approximately one million tokens (gustafson-capkova?
</nextsent>
<nextsent>and hartmann, 2006).
</nextsent>
<nextsent>megyesi (2009) showed that the hunpostagger trained on suc, is one of the best performing taggers for (contemporary) swedish texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1128">
<title id=" W11-2110.xml">morphemes and pos tags for ngram based evaluation metrics </title>
<section> evaluation metrics.  </section>
<citcontext>
<prevsection>
<prevsent>morphf morpheme score: takes into account all morpheme n-grams which have counterpart both in the corresponding reference and in the hypothesis.
</prevsent>
<prevsent>posf pos score: takes into account all pos n-grams which have counterpart both inthe corresponding reference and in the hypothesis.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
bleu the standard bleu score (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>posbleu the standard bleu score calculated on pos tags.
</nextsent>
<nextsent>morphbleu the standard bleu score calculated on morphemes.
</nextsent>
<nextsent>pairwise metrics: ? wpf score of word and pos n-grams.
</nextsent>
<nextsent>wmf score of word and morpheme n-grams.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1129">
<title id=" W12-1641.xml">combining incremental language generation and incremental speech synthesis for adaptive information presentation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(a) in situations where fast system responses are important, production of output can begin before the 1we will use the term output generation?
</prevsent>
<prevsent>here to cover both natural language generation and speech synthesis.
</prevsent>
</prevsection>
<citsent citstr=" W10-4301 ">
content that is to be presented is fully specified ? even if what is being produced is just turn-taking signal (skantze and hjalmarsson, 2010).<papid> W10-4301 </papid></citsent>
<aftsection>
<nextsent>(b) system that produces its output incrementally can react to events happening while it is realising an utterance.
</nextsent>
<nextsent>this can be beneficial in domains where the state of the world that the system relays information about can change mid-utterance, so that need may arise to adapt while speaking.
</nextsent>
<nextsent>it should also improve naturalness by allowing the system to react to dialogue phenomena such as concurrent feedback signals from the user (buschmeier and kopp, 2011).we present work towards enabling such capabilities.
</nextsent>
<nextsent>we have implemented and connected component for incremental natural language generation (inlg) that works with specifications of subutterance-sized communicative intentions and component for incremental speech synthesis (iss) that can handle sub-utterance-sized input and modifications to not-yet-spoken parts of the utterance with very lowlatencies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1131">
<title id=" W12-1641.xml">combining incremental language generation and incremental speech synthesis for adaptive information presentation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>dutoit et al (2011) present an incremental hmm optimiser which allows to change pitch and tempo of upcoming phonemes.
</prevsent>
<prevsent>however, as that system is fed from (non-incrementally produced) label file, it cannot easily be used in an incremental system.
</prevsent>
</prevsection>
<citsent citstr=" W12-1814 ">
a predecessor of our iss component (which wasnot yet fully incremental on the hmm level) is described in detail in (baumann and schlangen, 2012<papid> W12-1814 </papid>a).</citsent>
<aftsection>
<nextsent>3.1 the spud micro planning framework.
</nextsent>
<nextsent>the nlg component presented here is based on the spud micro planning framework (stone et al,2003) and realised in devaults (2008) implementation java spud?.
</nextsent>
<nextsent>spud frames microplannig as constraint satisfaction problem, solving the tasks that are involved in generating sentence (lexical and syntactic choice, referring expression generation and aggregation) in an integrated manner.
</nextsent>
<nextsent>generation starts from communicative goal that specifies constraints for the final utterance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1133">
<title id=" W12-1641.xml">combining incremental language generation and incremental speech synthesis for adaptive information presentation </title>
<section> incremental and adaptive nlg.  </section>
<citcontext>
<prevsection>
<prevsent>spud frames microplannig as constraint satisfaction problem, solving the tasks that are involved in generating sentence (lexical and syntactic choice, referring expression generation and aggregation) in an integrated manner.
</prevsent>
<prevsent>generation starts from communicative goal that specifies constraints for the final utterance.
</prevsent>
</prevsection>
<citsent citstr=" W02-0111 ">
the generation process is further shaped by (a) general constraints that model pragmatic properties of language use such asthe gricean maxims (a principle called textual econ omy?); (b) specific constraints imposed through the communicative status of the propositions to be communicated (i. e., what knowledge can be presupposed and what needs to be communicated explicitly); and (c) linguistic resources (a context-free tree rewriting formalism based on ltag; stone, 2002).<papid> W02-0111 </papid></citsent>
<aftsection>
<nextsent>to deal efficiently with the infinite search space spanned by the linguistic resources, spud uses heuristic search algorithm to find an utterance that satisfies the imposed constraints (stone et al, [2003] describe the heuristic function).
</nextsent>
<nextsent>in each search step, the algorithm expands the provisional?
</nextsent>
<nextsent>utterance by adding the linguistic resource that maximally reduces the estimated distance to the final utterance.
</nextsent>
<nextsent>if the generation process runs into dead-end state,it could in principle deal with the situation by tracking back and expanding different branch.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1134">
<title id=" W12-1641.xml">combining incremental language generation and incremental speech synthesis for adaptive information presentation </title>
<section> incremental and adaptive nlg.  </section>
<citcontext>
<prevsection>
<prevsent>two provisional utterances being equal, the one exhibiting less redundancy is normally preferred.
</prevsent>
<prevsent>but similar to verbosity, redundancy serves communicative functions in actual language use.
</prevsent>
</prevsection>
<citsent citstr=" J02-4007 ">
it can highlight important information, it can increase the probability of the message being understood (reiter and sripada, 2002) <papid> J02-4007 </papid>and it is often used to repair misunderstanding (baker et al, 2008).<papid> W08-0105 </papid>in incremental micro planning, redundant information can be present both within one sub-utterance chunk (e. g., tomorrow, march 26, . . .</citsent>
<aftsection>
<nextsent>vs. tomorrow.
</nextsent>
<nextsent>or across impts.
</nextsent>
<nextsent>for the former case, we modified spuds search heuristic in order to conditionally either prefer an utterance that contains redundant information or an utterance that only contains what is absolutely necessary.
</nextsent>
<nextsent>in the latter case, redundancy only becomes an option when later impts enable the choice of repeating information previously conveyed and therefore already established as shared knowledge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1135">
<title id=" W12-1641.xml">combining incremental language generation and incremental speech synthesis for adaptive information presentation </title>
<section> incremental and adaptive nlg.  </section>
<citcontext>
<prevsection>
<prevsent>two provisional utterances being equal, the one exhibiting less redundancy is normally preferred.
</prevsent>
<prevsent>but similar to verbosity, redundancy serves communicative functions in actual language use.
</prevsent>
</prevsection>
<citsent citstr=" W08-0105 ">
it can highlight important information, it can increase the probability of the message being understood (reiter and sripada, 2002) <papid> J02-4007 </papid>and it is often used to repair misunderstanding (baker et al, 2008).<papid> W08-0105 </papid>in incremental micro planning, redundant information can be present both within one sub-utterance chunk (e. g., tomorrow, march 26, . . .</citsent>
<aftsection>
<nextsent>vs. tomorrow.
</nextsent>
<nextsent>or across impts.
</nextsent>
<nextsent>for the former case, we modified spuds search heuristic in order to conditionally either prefer an utterance that contains redundant information or an utterance that only contains what is absolutely necessary.
</nextsent>
<nextsent>in the latter case, redundancy only becomes an option when later impts enable the choice of repeating information previously conveyed and therefore already established as shared knowledge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1136">
<title id=" W12-1641.xml">combining incremental language generation and incremental speech synthesis for adaptive information presentation </title>
<section> incremental speech synthesis.  </section>
<citcontext>
<prevsection>
<prevsent>the just-in-time processing approach, combined with the increasing temporal granularity of units towards the lower levels has several advantages: (a) little utterance-initial processing (only what is necessary to produce the beginning of the signal) allows forvery responsive systems; and (b) changes to the initial plan result only in modest processing overhead because little structure has to be re-computed.
</prevsent>
<prevsent>4.3 technical overview.
</prevsent>
</prevsection>
<citsent citstr=" W10-4308 ">
as basis, we use marytts (schrder and trouvain, 2003), but replace marys internal data structures and processing strategies with structures from our incremental sds architecture, the inprotk toolkit (schlangen et al, 2010; <papid> W10-4308 </papid>baumann and schlangen,2012<papid> W12-1814 </papid>b), which implements the iu model for incremental dialogue processing (schlangen and skantze, 2009).<papid> E09-1081 </papid></citsent>
<aftsection>
<nextsent>the model conceptualises ? and the toolkit implements ? incremental processing as the processing of incremental units (ius), which are the smallest chunks?
</nextsent>
<nextsent>of information at specific level (the boxes in figure 2).
</nextsent>
<nextsent>ius are interconnected to form network (e. g., words keep links to their associated phonemes and neighbouring words and vice-versa) which represents the systems information state.the component is fed with chunk ius which contain some words to be synthesised (on their own or appended to an ongoing utterance).
</nextsent>
<nextsent>for simplicity,all units below the chunk level are currently generated using marys (non-incremental) linguistic preprocessing capabilities to obtain the target phoneme sequence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1139">
<title id=" W12-1641.xml">combining incremental language generation and incremental speech synthesis for adaptive information presentation </title>
<section> incremental speech synthesis.  </section>
<citcontext>
<prevsection>
<prevsent>the just-in-time processing approach, combined with the increasing temporal granularity of units towards the lower levels has several advantages: (a) little utterance-initial processing (only what is necessary to produce the beginning of the signal) allows forvery responsive systems; and (b) changes to the initial plan result only in modest processing overhead because little structure has to be re-computed.
</prevsent>
<prevsent>4.3 technical overview.
</prevsent>
</prevsection>
<citsent citstr=" E09-1081 ">
as basis, we use marytts (schrder and trouvain, 2003), but replace marys internal data structures and processing strategies with structures from our incremental sds architecture, the inprotk toolkit (schlangen et al, 2010; <papid> W10-4308 </papid>baumann and schlangen,2012<papid> W12-1814 </papid>b), which implements the iu model for incremental dialogue processing (schlangen and skantze, 2009).<papid> E09-1081 </papid></citsent>
<aftsection>
<nextsent>the model conceptualises ? and the toolkit implements ? incremental processing as the processing of incremental units (ius), which are the smallest chunks?
</nextsent>
<nextsent>of information at specific level (the boxes in figure 2).
</nextsent>
<nextsent>ius are interconnected to form network (e. g., words keep links to their associated phonemes and neighbouring words and vice-versa) which represents the systems information state.the component is fed with chunk ius which contain some words to be synthesised (on their own or appended to an ongoing utterance).
</nextsent>
<nextsent>for simplicity,all units below the chunk level are currently generated using marys (non-incremental) linguistic preprocessing capabilities to obtain the target phoneme sequence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1140">
<title id=" W12-1902.xml">transferring frames utilization of linked lexical resources </title>
<section> language resources.  </section>
<citcontext>
<prevsection>
<prevsent>andlapata (2005a) used word alignment in sentence aligned parallel corpora to find possible lexical units in new languages.there have been several studies of the feasibility of automatically producing the role-semantic an 9notation in new languages, although never for languages as structurally dissimilar as swedish andfinnish.
</prevsent>
<prevsent>pad?
</prevsent>
</prevsection>
<citsent citstr=" P06-2057 ">
and lapata (2005b) projected annotation from english to german, and johansson and nugues (2006) <papid> P06-2057 </papid>implemented complete pipeline for english swedish by (1) automatic annotation on the english side; (2) annotation transfer; and (3) train inga swedish semantic role labeler using the automatically produced annotation.</citsent>
<aftsection>
<nextsent>3.1 outline of the experiment.
</nextsent>
<nextsent>we start off by locating such swedish word senses that are both represented in swefn and linked to pwn in two finnish swedish parallel corpora.
</nextsent>
<nextsent>the sentences that include such word make up the evaluation dataset.
</nextsent>
<nextsent>after this, the swedish half is enriched with frame labels using the framenet-based semantic role labeler for swedish.after running the semantic labeler on the evaluation data, we pick the 20 most commonly occur ring frames from both corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1141">
<title id=" W12-1628.xml">a bottom up exploration of the dimensions of dialog state in spoken interaction </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>we also hoped that pca would separate out, as orthogonal factors, aspects of prosody that truly relate to dialog from aspects with lexical, phrasal, or other significance.
</prevsent>
<prevsent>while dialog states have apparently not previously been tackled using pca, other dimensionality reduction methods have been used.
</prevsent>
</prevsection>
<citsent citstr=" N09-2023 ">
clustering has previously been applied as way to categorize user intention-types and goals, using lexical semantic features and neighboring-turn features as inputs (lefevre and de mori, 2007; lee et al, 2009), <papid> N09-2023 </papid>among other methods (gasic and young, 2011).</citsent>
<aftsection>
<nextsent>hidden markov models have been used to identify dialog modes?
</nextsent>
<nextsent>that involve common sequences of dialog-acts (boyer et al, 2009).<papid> W09-2103 </papid></nextsent>
<nextsent>there is also work that uses pca to reduce multi-factor subjective evaluations of emotion, style, or expressiveness into few underlying dimensions, for example (barbosa, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1142">
<title id=" W12-1628.xml">a bottom up exploration of the dimensions of dialog state in spoken interaction </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>clustering has previously been applied as way to categorize user intention-types and goals, using lexical semantic features and neighboring-turn features as inputs (lefevre and de mori, 2007; lee et al, 2009), <papid> N09-2023 </papid>among other methods (gasic and young, 2011).</prevsent>
<prevsent>hidden markov models have been used to identify dialog modes?</prevsent>
</prevsection>
<citsent citstr=" W09-2103 ">
that involve common sequences of dialog-acts (boyer et al, 2009).<papid> W09-2103 </papid></citsent>
<aftsection>
<nextsent>there is also work that uses pca to reduce multi-factor subjective evaluations of emotion, style, or expressiveness into few underlying dimensions, for example (barbosa, 2009).
</nextsent>
<nextsent>in addition, clustering over low-level patterns of turn-taking has been used to identify continuum of styles (grothendieck et al, 2011).
</nextsent>
<nextsent>however analysis of dialog states based on prosodic features has not previously been attempted, nor has analysis of dialog behaviors over timeframes shorter than the discourse or the turn sequence.
</nextsent>
<nextsent>reducing the multiplicity of prosodic features to smaller underlying set has long been goal for linguists.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1143">
<title id=" W12-1628.xml">a bottom up exploration of the dimensions of dialog state in spoken interaction </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>better feature weighting could also be useful for refining the ranking of the dimensions: while our method treated one standard deviation of variance in one feature as equal in importance to one standard deviation in any other, in human perception this is certainly not the case.
</prevsent>
<prevsent>it would also be interesting to apply this method to other corpora in other domains: forex ample in task-oriented dialogs we might expect it to find additional important dimensions relating totask structure, question type, recovery from misunderstandings, uncertainty, and so on.
</prevsent>
</prevsection>
<citsent citstr=" N06-1035 ">
finally, itwould be interesting to explore which of these dimensions of state actually matter most for dialog success (tetreault and litman, 2006).<papid> N06-1035 </papid>in addition to the identification of specific dimensions of dialog in casual conversations, this paper contributes new method: that of using pca over low-level, observable features to identify important dimensions of dialog state, which could be applied more generally.while we see numerous advantages for quantitative, dimensional dialog state modeling, we do not think that this obsoletes more classical methods.</citsent>
<aftsection>
<nextsent>indeed, it would be interesting to explore how commonly used dialog states and acts relate to these di mensions; for example, to take the set of utterances labeled wh-questions in nxt switchboard and examine where they are located in the dialog space?
</nextsent>
<nextsent>defined by these dimensions (calhoun et al, 2010; ward et al, 2012 submitted).
</nextsent>
<nextsent>acknowledgments this work was supported in part by nsf award iis 0914868.
</nextsent>
<nextsent>we thank olac fuentes for suggesting pca, justin mcmanus for the prototype analysis, shreyas karkhedkar for help with the basic features, and david novick for discussion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1144">
<title id=" W11-2303.xml">towards technology assisted co construction with communication partners </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these options allow the individual to indirectly select symbol based on some process for scanning through alternatives (lesher et al, 1998).
</prevsent>
<prevsent>typing speed is challenge, yet is critically important for usability, and as result there is significant line of research intothe utility of statistical language models for improving typing speed (mccoy et al, 2007; koester and levine, 1996; koester and levine, 1997; koester and levine, 1998).
</prevsent>
</prevsection>
<citsent citstr=" N07-2044 ">
methods of word, symbol,phrase and message prediction via statistical language models are widespread in both direct selection and scanning devices (darragh et al, 1990; li and hirst, 2005; trost et al, 2005; trnka et al, 2006; trnka et al, 2007; <papid> N07-2044 </papid>wandmacher and antoine, 2007; <papid> D07-1053 </papid>todman et al, 2008).</citsent>
<aftsection>
<nextsent>to the extent that the predictions are accurate, the number of keystrokes required to type message can be dramatically reduced, greatly speeding typing.aac devices for spontaneous and novel text generation are intended to empower the user of the system, to place them in control of their own communication, and reduce their reliance on others for message formulation.
</nextsent>
<nextsent>as result, all such devices (much like standard personal computers) are built for single user, with single keyboard and/or alternative input interface, which is driven by the user ofthe system.
</nextsent>
<nextsent>the unilateral nature of these high technology solutions to aac stands in contrast to common low technology solutions, which relyon collaboration between the individual formulating themes sage and their communication partner.
</nextsent>
<nextsent>many adults with acquired neurological conditions relyon communication partners for co-construction of messages (beukelman et al, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1145">
<title id=" W11-2303.xml">towards technology assisted co construction with communication partners </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these options allow the individual to indirectly select symbol based on some process for scanning through alternatives (lesher et al, 1998).
</prevsent>
<prevsent>typing speed is challenge, yet is critically important for usability, and as result there is significant line of research intothe utility of statistical language models for improving typing speed (mccoy et al, 2007; koester and levine, 1996; koester and levine, 1997; koester and levine, 1998).
</prevsent>
</prevsection>
<citsent citstr=" D07-1053 ">
methods of word, symbol,phrase and message prediction via statistical language models are widespread in both direct selection and scanning devices (darragh et al, 1990; li and hirst, 2005; trost et al, 2005; trnka et al, 2006; trnka et al, 2007; <papid> N07-2044 </papid>wandmacher and antoine, 2007; <papid> D07-1053 </papid>todman et al, 2008).</citsent>
<aftsection>
<nextsent>to the extent that the predictions are accurate, the number of keystrokes required to type message can be dramatically reduced, greatly speeding typing.aac devices for spontaneous and novel text generation are intended to empower the user of the system, to place them in control of their own communication, and reduce their reliance on others for message formulation.
</nextsent>
<nextsent>as result, all such devices (much like standard personal computers) are built for single user, with single keyboard and/or alternative input interface, which is driven by the user ofthe system.
</nextsent>
<nextsent>the unilateral nature of these high technology solutions to aac stands in contrast to common low technology solutions, which relyon collaboration between the individual formulating themes sage and their communication partner.
</nextsent>
<nextsent>many adults with acquired neurological conditions relyon communication partners for co-construction of messages (beukelman et al, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1147">
<title id=" W11-2303.xml">towards technology assisted co construction with communication partners </title>
<section> background and related work.  </section>
<citcontext>
<prevsection>
<prevsent>or iwant to talk about paris?.
</prevsent>
<prevsent>this can speed up the conversation by providing topically-relevant responses.
</prevsent>
</prevsection>
<citsent citstr=" W09-0601 ">
perhaps the most elaborate system of this kind is the how was school today system (reiter et al, 2009).<papid> W09-0601 </papid></citsent>
<aftsection>
<nextsent>this system, which is geared towards children with severe communication disabilities, uses data from sensors, the web, and other sources as input for anat ural language generation system.
</nextsent>
<nextsent>the system acquires information about the childs day in school: which classes he or she attended, what activities there were, information about visitors, food choices at the cafeteria, and so forth.
</nextsent>
<nextsent>the data are then used 24 to generate natural language sentences, which are converted to speech via speech synthesizer.
</nextsent>
<nextsent>at theend of the day, the child uses menu to select sentences that he or she wants the system to utter, and thereby puts together narrative that describes what he/she did.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1148">
<title id=" W11-2303.xml">towards technology assisted co construction with communication partners </title>
<section> switchboard experiment.  </section>
<citcontext>
<prevsection>
<prevsent>while the switchboard corpus does represent the kind of conversational dialog we are interested in, it is spoken language corpus, yet we are modeling written (typed) language.
</prevsent>
<prevsent>the difference between written and spoken language does present something of an issue for our task.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
to mitigate this mismatch somewhat, we made use of the switchboard section of the penn treebank (marcus et al, 1993), <papid> J93-2004 </papid>which contains syntactic annotations of the switchboard transcripts, including explicit marking of disfluencies (edited?</citsent>
<aftsection>
<nextsent>non-terminals in the treebank), interjections or parentheticals such as mean?
</nextsent>
<nextsent>or you know?.
</nextsent>
<nextsent>using these syntactic annotations, we produced edited transcripts that omit much of the spoken language specific phenomena, thus providing closer approximation to the kind of written dialogs we would like to simulate.
</nextsent>
<nextsent>in addition, we de cased the corpus and removed all characters except the following: the 26 letters of the english alphabet, the apostrophe, the space, and the dash.interface figure 2 shows the graphical user interface that was created for these trials.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1149">
<title id=" W11-2026.xml">facilitating mental modeling in collaborative human robot interaction through adverbial cues </title>
<section> nl understanding and generation.  </section>
<citcontext>
<prevsection>
<prevsent>question (regarding locations) and simple yes-no? questions.
</prevsent>
<prevsent>if ? asks ? about its location in the general sense (where are you??), then one can infer that ? has an intention to know (expressed via the ik?
</prevsent>
</prevsection>
<citsent citstr=" J80-3003 ">
operator, see (perrault and allen, 1980)) <papid> J80-3003 </papid>where ? is located: [[askloc(?, ?, {})]]c := ik(?, at(?, ?)) (6) for some ?.</citsent>
<aftsection>
<nextsent>if ? asks ? whether it is at ?, then one can infer that ? has an intention to know whether ? is at ?: [[askyn(?, ?, at(?, ?), {})]]c := ik(?, at(?, ?)) (7)if ? is asked by ? whether it is still?
</nextsent>
<nextsent>at ?, ? can infer that ? believes (expressed via the b? operator) that ? is currently at ?: [[askyn(?, ?, at(?, ?), {still})]]c := (8) [[askyn(?, ?, at(?, ?), {})]]c b(?, at(?, ?)) if ? is asked by ? whether it is at ? yet?, ? can infer that ? believes that ? has goal to be at ?: [[askyn(?, ?, at(?, ?), {yet})]]c := (9) [[askyn(?, ?, at(?, ?), {})]]c b(?,g(?, at(?, ?))) 3.1.3 question-answer pairs next, we consider how discourse context as provided by question-answer pairs can further specify the pragmatic implications.
</nextsent>
<nextsent>if ? asks ? whether it is at ? with any set of adverbial modifiers ?
</nextsent>
<nextsent>(i.e., prior(askyn(?, ?, at(?, ?), ?)) ? c), and ? responds by stating that it is still?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1151">
<title id=" W12-2002.xml">identifying science concepts and student misconceptions in an interactive essay writing tutor </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>dialog-based tutoring systems, such as why2-atlas (vanlehn et al., 2002), auto tutor (graesser et al, 2004) andmetatutor (azevedo et al, 2008), interact with students via questions and answers.
</prevsent>
<prevsent>student knowledge is judged by comparing student responses to knowledge bases of domain concepts and misconceptions.these knowledge bases are typically manually curated, and new knowledge base must be constructed for each new domain where the tutor is to be used.
</prevsent>
</prevsection>
<citsent citstr=" C08-1023 ">
12 essay-based tutoring systems, such as summary street (wade-stein and kintsch, 2004) or click (de la chica et al, 2008<papid> C08-1023 </papid>b), interact with students who are writing summary or essay.</citsent>
<aftsection>
<nextsent>they compare what the student has written to domain knowledge in the form of textbooks or webpages.
</nextsent>
<nextsent>they typically do not require knowledge base to be manually constructed, instead using natural language processing techniques to compare the students essay to the information in the textbooks or webpages.
</nextsent>
<nextsent>the current work is inspired by these essay-based tutoring systems, where interaction revolves around essay writing.
</nextsent>
<nextsent>however, where summary street relies primarily upon measuring how much of textbook student essay has covered?, we aim to give more detailed assessments that pinpoint specific student misconceptions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1155">
<title id=" W12-2002.xml">identifying science concepts and student misconceptions in an interactive essay writing tutor </title>
<section> identifying student misconceptions.  </section>
<citcontext>
<prevsection>
<prevsent>a student sentence that can not be concluded from the domain knowledge is likely misconception.
</prevsent>
<prevsent>6.1 models.
</prevsent>
</prevsection>
<citsent citstr=" P11-2098 ">
we developed two models for identifying student misconceptions, inspired by work in textual entailment that showed that model that simply counts the words in that appeared in t, after expanding the words in using wordnet, achieves state-of-the-art performance (shnarch et al, 2011)<papid> P11-2098 </papid>4.</citsent>
<aftsection>
<nextsent>the coverage model scores student sentence by counting the number of its words that are also in some domain sentence.
</nextsent>
<nextsent>low-scoring sentences are likely misconceptions.
</nextsent>
<nextsent>formally: score(s) = |s ? d| |s| = ? sd expand(s?) where is student sentence (a list of words), is the set of domain sentences, and expand performs lexical expansion on the words of sentence.the retrieval model indexes the domain sentences with an information retrieval system (we use 4the paper also proposes more elaborate probabilistic model, but shows that the lexical coverage?
</nextsent>
<nextsent>model we adopt here is quite competitive both with their probabilistic model and with the top-performing systems of rte5 and rte6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1156">
<title id=" W11-2502.xml">comparison of the baseline knowledge corpus and web based similarity measures for semantic relations extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we describe analytically and compare experimentally methods, which discover set of semantic relations r?
</prevsent>
<prevsent>forgiven set of concepts c. semantic relation extraction algorithm aims to discover r?
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
r. one approach for semantic relations extraction is based on the lexico-syntactic patterns which are constructed either manually (hearst, 1992) <papid> C92-2082 </papid>or semi automatically (snow et al, 2004).</citsent>
<aftsection>
<nextsent>the alternative approach, adopted in this paper, is unsupervised (see e.g. lin (1998<papid> P98-2127 </papid>a) or sahlgren (2006)).</nextsent>
<nextsent>it relies ona similarity measure between lexical units.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1157">
<title id=" W11-2502.xml">comparison of the baseline knowledge corpus and web based similarity measures for semantic relations extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>forgiven set of concepts c. semantic relation extraction algorithm aims to discover r?
</prevsent>
<prevsent>r. one approach for semantic relations extraction is based on the lexico-syntactic patterns which are constructed either manually (hearst, 1992) <papid> C92-2082 </papid>or semi automatically (snow et al, 2004).</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
the alternative approach, adopted in this paper, is unsupervised (see e.g. lin (1998<papid> P98-2127 </papid>a) or sahlgren (2006)).</citsent>
<aftsection>
<nextsent>it relies ona similarity measure between lexical units.
</nextsent>
<nextsent>various measures are available.
</nextsent>
<nextsent>we compare 21 base line measures: 8 knowledge-based, 4 corpus-based, and 9 web-based.
</nextsent>
<nextsent>we would like to answer on twoquestions: what metric is most suitable for theun supervised relation extraction??, and does various metrics capture the same semantic relations??.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1161">
<title id=" W11-2502.xml">comparison of the baseline knowledge corpus and web based similarity measures for semantic relations extraction </title>
<section> r?? threshold(s, k, ?) ; </section>
<citcontext>
<prevsection>
<prevsent>we evaluate eight knowledge-based measures listed below.
</prevsent>
<prevsent>let us describe them in the following notations: cr is the root concept of the net work; is the height of the network; len(ci, cj) isthe length of the shortest path in the network between concepts; cij is lowest common subsumer of concepts ci and cj ; (c) is the probability of the concept, estimated from corpus (see below).
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
then,the inverted edge count measure (jurafsky and martin, 2009, p. 687) is sij = len(ci, cj) 1; (1) leacock and chodorow (1998) measure is sij = log len(ci, cj) 2h ; (2) resnik (1995) measure is sij = log(p (cij)); (3) jiang and conrath (1997) measure is sij = (2log(p (cij))?(log(p (ci))+log(p (cj)))) 1; (4) lin (1998<papid> P98-2127 </papid>b) measure is sij = ( 2log(p (cij)) log(p (ci) + log(p (cj)) ; (5) wu and palmer (1994) <papid> P94-1019 </papid>measure is sij = 2len(cr, cij) len(ci, cij) + len(cj , cij) + 2len(cr, cij) .</citsent>
<aftsection>
<nextsent>(6)extended lesk (banerjee and pedersen, 2003) measure is sij = ? cici ? cjcj simg(ci, cj), (7) where simg is gloss-based similarity measure, and setci includes concept ci and all concepts which are directly related to it.gloss vectors measure (patwardhan and pedersen, 2006) <papid> W06-2501 </papid>is calculated as cosine (9) between context vectors vi and vj of concepts ci and cj . context vector calculated as following: vi = ? j:cjgi fj .</nextsent>
<nextsent>(8) 12 here fj is first-order co-occurrence vector, derived from the corpus of all glosses, and gi is concatenation of glosses of the concept ci and all concepts which are directly related to it.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1162">
<title id=" W11-2502.xml">comparison of the baseline knowledge corpus and web based similarity measures for semantic relations extraction </title>
<section> r?? threshold(s, k, ?) ; </section>
<citcontext>
<prevsection>
<prevsent>let us describe them in the following notations: cr is the root concept of the net work; is the height of the network; len(ci, cj) isthe length of the shortest path in the network between concepts; cij is lowest common subsumer of concepts ci and cj ; (c) is the probability of the concept, estimated from corpus (see below).
</prevsent>
<prevsent>then,the inverted edge count measure (jurafsky and martin, 2009, p. 687) is sij = len(ci, cj) 1; (1) leacock and chodorow (1998) measure is sij = log len(ci, cj) 2h ; (2) resnik (1995) measure is sij = log(p (cij)); (3) jiang and conrath (1997) measure is sij = (2log(p (cij))?(log(p (ci))+log(p (cj)))) 1; (4) lin (1998<papid> P98-2127 </papid>b) measure is sij = ( 2log(p (cij)) log(p (ci) + log(p (cj)) ; (5) wu and palmer (1994) <papid> P94-1019 </papid>measure is sij = 2len(cr, cij) len(ci, cij) + len(cj , cij) + 2len(cr, cij) .</prevsent>
</prevsection>
<citsent citstr=" W06-2501 ">
(6)extended lesk (banerjee and pedersen, 2003) measure is sij = ? cici ? cjcj simg(ci, cj), (7) where simg is gloss-based similarity measure, and setci includes concept ci and all concepts which are directly related to it.gloss vectors measure (patwardhan and pedersen, 2006) <papid> W06-2501 </papid>is calculated as cosine (9) between context vectors vi and vj of concepts ci and cj . context vector calculated as following: vi = ? j:cjgi fj .</citsent>
<aftsection>
<nextsent>(8) 12 here fj is first-order co-occurrence vector, derived from the corpus of all glosses, and gi is concatenation of glosses of the concept ci and all concepts which are directly related to it.
</nextsent>
<nextsent>we experiment with measures relying on the wordnet 3.0 (miller, 1995) as semantic network and semcor as corpus (miller et al, 1993).
</nextsent>
<nextsent>2.3 corpus-based measures.
</nextsent>
<nextsent>we use four measures, which relyon the bag of-word distributional analysis (bda) (sahlgren, 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1163">
<title id=" W11-2502.xml">comparison of the baseline knowledge corpus and web based similarity measures for semantic relations extraction </title>
<section> r?? threshold(s, k, ?) ; </section>
<citcontext>
<prevsection>
<prevsent>finally, both (8) and (9)-(12), relyon the vector space model.
</prevsent>
<prevsent>2.6 experimental setup.
</prevsent>
</prevsection>
<citsent citstr=" N04-3012 ">
we experiment with the knowledge-based measures implemented in the wordnet::similarity package (pedersen et al, 2004).<papid> N04-3012 </papid></citsent>
<aftsection>
<nextsent>our own implementation is used in the experiments with the corpus based measures and the web-based measures relying on the yahoo boss search engine api.
</nextsent>
<nextsent>we use the measures of semantic relatedness web service 4 to assess the other web measures.
</nextsent>
<nextsent>the evaluation was done with the bless setof semantic relations.
</nextsent>
<nextsent>it relates 200 target concepts to some 8625 relatum concepts with 26554 semantic relations (14440 are correct and 12154 are random).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1165">
<title id=" W12-1705.xml">connectionistinspired incremental pcfg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the cognitive science community,this incremental interaction has often been modelled using recurrent neural networks (elman, 1991; mayberry and miikkulainen, 2003), which utilizea hidden context with severely bounded representational capacity (a fixed number of continuous units or dimensions), similar to models of activation based memory in the pre frontal cortex (botvinick,2007), with the interesting possibility that the distributed behavior of neural columns (horton and adams, 2005) may directly implement continuous dimensions of recurrent hidden units.
</prevsent>
<prevsent>this paper presents refinement of factored probabilistic sequence model of comprehension (schuler, 2009) in the direction of recurrent neural network model and presents some observed efficiencies due to this refinement.this paper will adopt an incremental probabilistic context-free grammar (pcfg) parser (schuler,2009) that uses right-corner variant of the left corner parsing strategy (aho and ullman, 1972) coupled with strict memory bounds, as model ofhuman-like parsing.
</prevsent>
</prevsection>
<citsent citstr=" N01-1021 ">
syntax can readily be approximated using simple pcfgs (hale, 2001; <papid> N01-1021 </papid>levy, 2008; demberg and keller, 2008), which can be easily tuned (petrov and klein, 2007).<papid> N07-1051 </papid></citsent>
<aftsection>
<nextsent>this paper will show that this representation can be streamlined to exploit the fact that right-corner parse guarantees at most one expansion and at most one reduction can take place after each word is seen (see section 2.2).the primary finding of this paper is that this property of right-corner parsing can be exploited to obtain dramatic reduction in the number of random variables in probabilistic sequence model parser (schuler, 2009) yielding simpler structure that more closely resembles connection ist models suchas trace (mcclelland and elman, 1986), short list (norris, 1994; norris and mcqueen, 2008), or recurrent models (elman, 1991; mayberry and miikkulainen, 2003) which posit functional units only for cognitively-motivated entities.
</nextsent>
<nextsent>the rest of this paper is structured as follows:section 2 gives the formal background of the right corner parser transform and probabilistic sequence 51 model parsing.
</nextsent>
<nextsent>the simplification of this model is described in section 3.
</nextsent>
<nextsent>a discussion of the interplay between cognitive theory and computational modelling in the resulting model may be found in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1166">
<title id=" W12-1705.xml">connectionistinspired incremental pcfg parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the cognitive science community,this incremental interaction has often been modelled using recurrent neural networks (elman, 1991; mayberry and miikkulainen, 2003), which utilizea hidden context with severely bounded representational capacity (a fixed number of continuous units or dimensions), similar to models of activation based memory in the pre frontal cortex (botvinick,2007), with the interesting possibility that the distributed behavior of neural columns (horton and adams, 2005) may directly implement continuous dimensions of recurrent hidden units.
</prevsent>
<prevsent>this paper presents refinement of factored probabilistic sequence model of comprehension (schuler, 2009) in the direction of recurrent neural network model and presents some observed efficiencies due to this refinement.this paper will adopt an incremental probabilistic context-free grammar (pcfg) parser (schuler,2009) that uses right-corner variant of the left corner parsing strategy (aho and ullman, 1972) coupled with strict memory bounds, as model ofhuman-like parsing.
</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
syntax can readily be approximated using simple pcfgs (hale, 2001; <papid> N01-1021 </papid>levy, 2008; demberg and keller, 2008), which can be easily tuned (petrov and klein, 2007).<papid> N07-1051 </papid></citsent>
<aftsection>
<nextsent>this paper will show that this representation can be streamlined to exploit the fact that right-corner parse guarantees at most one expansion and at most one reduction can take place after each word is seen (see section 2.2).the primary finding of this paper is that this property of right-corner parsing can be exploited to obtain dramatic reduction in the number of random variables in probabilistic sequence model parser (schuler, 2009) yielding simpler structure that more closely resembles connection ist models suchas trace (mcclelland and elman, 1986), short list (norris, 1994; norris and mcqueen, 2008), or recurrent models (elman, 1991; mayberry and miikkulainen, 2003) which posit functional units only for cognitively-motivated entities.
</nextsent>
<nextsent>the rest of this paper is structured as follows:section 2 gives the formal background of the right corner parser transform and probabilistic sequence 51 model parsing.
</nextsent>
<nextsent>the simplification of this model is described in section 3.
</nextsent>
<nextsent>a discussion of the interplay between cognitive theory and computational modelling in the resulting model may be found in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1167">
<title id=" W12-1705.xml">connectionistinspired incremental pcfg parsing </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>(3)a bottom-up incremental parsing strategy combined with the way the right-corner transform pulls each subtree into left-expanding hierarchy ensures at most single expansion (push) will occur atany given observation.
</prevsent>
<prevsent>that is, each new observation will be the left most leaf of right-expandingsubtree.
</prevsent>
</prevsection>
<citsent citstr=" J10-1001 ">
additionally, by reducing multiply right branching subtrees to single rightward branches, the transform also ensures that at most single reduction (pop) will take place at any given observation.schuler et al (2010) <papid> J10-1001 </papid>show near complete cover age of the wall street journal portion of the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>can be achieved with right-corner incremental parsing strategy using nomore than four incomplete contituents (deferred processes), in line with recent estimates of human working memory capacity (cowan, 2001).section 3 will show that, in addition to being desirable for bounded working memory restrictions, the single expansion/reduction guarantee reduces the search space between words to only two decision points ? whether to expand and whether to reduce.</citsent>
<aftsection>
<nextsent>this allows rapid processing of each candidate parse within sequence modelling framework.
</nextsent>
<nextsent>2.3 model formulation.
</nextsent>
<nextsent>this transform is then extended to pcfgs and integrated into sequence model parser.
</nextsent>
<nextsent>training on an annotated corpus yields the probability of any given syntactic state executing an expansion (creat ing syntactic subtree) or reduction (completinga syntactic subtree) to transition from every sufficiently probable (in this sense active) hypothesis in the working memory store.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1168">
<title id=" W12-1705.xml">connectionistinspired incremental pcfg parsing </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>(3)a bottom-up incremental parsing strategy combined with the way the right-corner transform pulls each subtree into left-expanding hierarchy ensures at most single expansion (push) will occur atany given observation.
</prevsent>
<prevsent>that is, each new observation will be the left most leaf of right-expandingsubtree.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
additionally, by reducing multiply right branching subtrees to single rightward branches, the transform also ensures that at most single reduction (pop) will take place at any given observation.schuler et al (2010) <papid> J10-1001 </papid>show near complete cover age of the wall street journal portion of the penn treebank (marcus et al, 1993) <papid> J93-2004 </papid>can be achieved with right-corner incremental parsing strategy using nomore than four incomplete contituents (deferred processes), in line with recent estimates of human working memory capacity (cowan, 2001).section 3 will show that, in addition to being desirable for bounded working memory restrictions, the single expansion/reduction guarantee reduces the search space between words to only two decision points ? whether to expand and whether to reduce.</citsent>
<aftsection>
<nextsent>this allows rapid processing of each candidate parse within sequence modelling framework.
</nextsent>
<nextsent>2.3 model formulation.
</nextsent>
<nextsent>this transform is then extended to pcfgs and integrated into sequence model parser.
</nextsent>
<nextsent>training on an annotated corpus yields the probability of any given syntactic state executing an expansion (creat ing syntactic subtree) or reduction (completinga syntactic subtree) to transition from every sufficiently probable (in this sense active) hypothesis in the working memory store.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1169">
<title id=" W12-1705.xml">connectionistinspired incremental pcfg parsing </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the approach described in this paper uses hidden context similar to that of recurrent network to inform the progression of the parse, except that the context is in terms of random variables with distributions over set of explicit syntactic categories.
</prevsent>
<prevsent>by framing the variable domains in linguistically-motivated fashion, the problem of acquisition can be divested from the problem of processing.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
this paper then uses the semi-supervised grammar training of petrov et al (2006)<papid> P06-1055 </papid>in order to develop simple, accurate model for broad-coverage parsing independent of scale.</citsent>
<aftsection>
<nextsent>56 p1 x1 q11 q21 q31 q41 p2 x2 q12 q22 q32 q42 p3 x3 q13 q23 q33 q43 p4 x4 q14 q24 q34 q44 p5 x5 q15 q25 q35 q45 p6 x6 q16 q26 q36 q46 p7 x7 q17 q27 q37 q47 f2 f3 f4 f5 f6 f7 f8=d =the =np/ nn =nn =fund =+ =s/v =vb =bou ght =s/v =vp/ np =dt =two =s/v =vp/ nn =jj =re giona =s/v =vp/ nn =nn =ban ks =+ =s/r =rb =toda =+ figure 2: parse using simplified model like schuler (2009), the incremental parser discussed here operates in o(n) time where is the length of the input.
</nextsent>
<nextsent>further, by its incremental nature, this parser is able to run continuously on stream of input, which allows any other processes dependent on the input (such as discourse integra tion) to run in parallel regardless of the length of the input.
</nextsent>
<nextsent>due to the decreased number of decisions required by this simplified model, it is substantially faster than previous similar models.
</nextsent>
<nextsent>to test this speed in crease, the simplified model was compared with that of schuler (2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1177">
<title id=" W12-1705.xml">connectionistinspired incremental pcfg parsing </title>
<section> computational benefit.  </section>
<citcontext>
<prevsection>
<prevsent>no tuning was done as part of the transform to sequence model.
</prevsent>
<prevsent>speed results can be seen in table 1.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
while the speed is not state-of-the-art in the field of parsing at large, it does break new ground for factored sequence model parsers.to test the accuracy of this parser, it was compared using varying beam-widths to the petrov and klein (2007) <papid> N07-1051 </papid>and roark (2001) <papid> J01-2004 </papid>parsers.</citsent>
<aftsection>
<nextsent>with the exception of the roark (2001) <papid> J01-2004 </papid>parser, all parsers used 5 iterations of the petrov et al (2006)<papid> P06-1055 </papid>split system sec/sent schuler 2009 74 current model 12table 1: speed comparison with an un factored probabilistic sequence model using beam-width of 500 elements system r roark 2001 <papid> J01-2004 </papid>86.6 86.5 86.5 current model (500) 86.6 87.3 87.0 current model (2000) 87.8 87.8 87.8 current model (5000) 87.8 87.8 87.8 petrov klein (binary) 88.1 87.8 88.0 petrov klein (+unary) 88.3 88.6 88.5table 2: accuracy comparison with state-of-the-art models.</nextsent>
<nextsent>numbers in parentheses are number of parallel activated hypothesesmerge-smooth algorithm, and the training and testing datasets remained the same.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1190">
<title id=" W12-1616.xml">dialogue act recognition using re weighted speaker adaptation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiments on real world meeting dataset show that with even only 200 speaker-specific annotated dialogue acts, the performances on dialogue act recognition are significantly improved when compared to several baseline algorithms.
</prevsent>
<prevsent>to our knowledge, this work is the first 1 to tackle this promising research direction of speaker adaptation for dialogue act recogntion.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
by representing higher level intention of utterances during human conversation, dialogue act labels are being used to enrich the information provided by spoken words (stolcke et al, 2000).<papid> J00-3003 </papid></citsent>
<aftsection>
<nextsent>dialogue act recognition is preliminary step towards deep dialogue understanding.
</nextsent>
<nextsent>it plays key role in the design of dialogue systems.
</nextsent>
<nextsent>besides, fernandez et al (2008) find certain dialogue acts are important cues for detecting decisions in multi-party dialogue.
</nextsent>
<nextsent>in 1this paper is an extended version of poster presented at semdial 2011, with new experiments and deeper analysis.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1191">
<title id=" W12-1616.xml">dialogue act recognition using re weighted speaker adaptation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>besides, fernandez et al (2008) find certain dialogue acts are important cues for detecting decisions in multi-party dialogue.
</prevsent>
<prevsent>in 1this paper is an extended version of poster presented at semdial 2011, with new experiments and deeper analysis.
</prevsent>
</prevsection>
<citsent citstr=" D09-1035 ">
ranganath et al (2009), <papid> D09-1035 </papid>dialogue acts are used as important features for flirt detection.automatic dialogue act recognition is still an active research topic.</citsent>
<aftsection>
<nextsent>the conventional approach is to train one generic classifier using large corpus of annotated utterances.
</nextsent>
<nextsent>one aspect that makes it so challenging is that people can express the same idea (or speech act) using very different set of spoken words.
</nextsent>
<nextsent>even more, people can mean different things with the exact same spoken words.
</nextsent>
<nextsent>these idiosyncratic differences in dialogue acts make the learning of generic classifiers extremely challenging.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1195">
<title id=" W12-1616.xml">dialogue act recognition using re weighted speaker adaptation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>promising results have been obtained by using regression model to combine the model weights obtained by training on switchboard damsl and icsi-mrda respectively.
</prevsent>
<prevsent>following the work by tur et al (2006), guz et al (2009) further studied the effectiveness of dialogue act domain adaptation in cascaded dialogue act segmentation and recognition system, their results prove adaptation in the intermediate step (segmentation) are also very helpful for the final output (recognition).
</prevsent>
</prevsection>
<citsent citstr=" D09-1130 ">
jeong et al(2009) <papid> D09-1130 </papid>use semi-supervised boosting algorithm to leverage labeled data from switchboard-damsl and icsi-mrda to help dialogue act recognition inemail and forums.</citsent>
<aftsection>
<nextsent>margolis et.al (2010) use structural correspondence learning technique to adapt dialogue act recognition on automatic translated spanish genre with the help of switchboard-damsl andicsi-mrda.
</nextsent>
<nextsent>kolar et al (2007) explores the difference among speakers for dialogue act segmentation in icsi-mrda dataset.
</nextsent>
<nextsent>similar to the approach taken in tur et al (2006), adaptation is performed through the combination of generic speaker independent language model and other speakers?
</nextsent>
<nextsent>language model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1198">
<title id=" W12-1616.xml">dialogue act recognition using re weighted speaker adaptation </title>
<section> icsi-mrda corpus.  </section>
<citcontext>
<prevsection>
<prevsent>from the word transcriptions, we created an extended list of linguistic features per utterance.
</prevsent>
<prevsent>from the 7 selected speakers, we computed 14653 unigram features, 158884 bigram features and 400025 trigram features.
</prevsent>
</prevsection>
<citsent citstr=" W04-2319 ">
following the work of shriberg et al (2004), <papid> W04-2319 </papid>we use the 5 general tags in our experiments: ? disruption indicates the current dialogue act is interrupted.</citsent>
<aftsection>
<nextsent>back channel are utterances which are not made directly by speaker as response and do not function in way that elicits response either.?
</nextsent>
<nextsent>floor mechanism are dialogue acts for grabbing or maintaining the floor.
</nextsent>
<nextsent>question is for eliciting listener feed back.
</nextsent>
<nextsent>and finally, unless an utterance is completely indecipherable or else can be further described by general tag, then its default status is statement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1199">
<title id=" W12-1616.xml">dialogue act recognition using re weighted speaker adaptation </title>
<section> idiosyncrasy in dialogue acts.  </section>
<citcontext>
<prevsection>
<prevsent>in all cases, using speaker-specific recognizer outperforms recognizer from other speakers.analyze the the difference among speakers.
</prevsent>
<prevsent>the experimental methodology used in this experiment is the same as the other experiments described in this paper (see section 6).
</prevsent>
</prevsection>
<citsent citstr=" W96-0213 ">
we use the maximum entropy model(maxent) for all dialogue act recogniz ers (ratnaparkhi, 1996).<papid> W96-0213 </papid></citsent>
<aftsection>
<nextsent>please refer to section 6.2for more details about the experimental methodology.
</nextsent>
<nextsent>figure 1 compares the average performances when testing on the same speaker or on some other speaker.
</nextsent>
<nextsent>we vary the number of training data for each speaker to be 200, 500, 1000, 1500 and 2000 dialogue acts.
</nextsent>
<nextsent>for all five cases, the recognizer strained on the same speaker outperforms the average performance when using recognizer from an other person.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1203">
<title id=" W11-2163.xml">hierarchical phrase based mt at the charles university for the wmt 2011 shared task </title>
<section> the translation system.  </section>
<citcontext>
<prevsection>
<prevsent>still,comparability of the results is limited, as the quality and quantity of english-czech data differs from that of the other pairs.
</prevsent>
<prevsent>496
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
our translation system belongs to the hierarchical phrase-based class (chiang, 2007), <papid> J07-2003 </papid>i.e. phrase pairs with nonterminals (rules of synchronouscontext-free grammar) are extracted from sym metrized word alignments and subsequently usedby the decoder.</citsent>
<aftsection>
<nextsent>we use joshua, java-based open source implementation of the hierarchical decoder (li et al, 2009), release 1.3.1 word alignment was computed using the first three steps of the train-factored-phrase model.perl script packed with moses2 (koehn et al., 2007).
</nextsent>
<nextsent>this includes the usual combination ofword clustering using mkcls3 (och, 1999), two way word alignment using giza++4 (och and ney, 2003), and alignment symmetrization using the grow-diag-final-and heuristic (koehn et al, 2003).
</nextsent>
<nextsent>for language modeling we use the srilmtoolkit5 (stolcke, 2002) with modified kneser ney smoothing (kneser and ney, 1995; chen and goodman, 1998).we use the z-mert implementation of minimum error rate training (zaidan, 2009).
</nextsent>
<nextsent>the following settings have been used for joshua and mert (for the sake of reproducibility, we keep the original names of the options; for their detailed explanation please refer to the documentation available on-line at the joshua project site).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1204">
<title id=" W11-2306.xml">improving the accessibility of line graphs in multimodal documents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in contrast, graphs in popular media are constructed to make point which should be obvious without complicated scientific reasoning.we are thus interested in generating textual presentation of the content of graphs in popular media.
</prevsent>
<prevsent>other research has focused on textual descriptions (e.g., ferres et al (2007)); however in that work the same information is included in the textual summary for each instance of graph type (i.e., all summaries of line graphs contain the same sorts of informa tion), and the summary does not attempt to present the overall intended message of the graph.
</prevsent>
</prevsection>
<citsent citstr=" W08-1103 ">
sight (demir et al, 2008; <papid> W08-1103 </papid>elzer et al, 2011) isa natural language system whose overall goal is providing blind users with interactive access to multimodal documents from electronically-available popular media sources.</citsent>
<aftsection>
<nextsent>to date, the sight project has concentrated on simple bar charts.
</nextsent>
<nextsent>its user interface is implemented as browser helper object within internet explorer that works with the jaws screen reader.
</nextsent>
<nextsent>when the system detects bar chart in document being read by the user, it prompts the user to use keystrokes to request brief summary of the graphic capturing its primary contribution to the overall communicative goal of the document.
</nextsent>
<nextsent>the summary text can either be read to the user with jaws or read by the user with screen magnifier tool.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1206">
<title id=" W11-2306.xml">improving the accessibility of line graphs in multimodal documents </title>
<section> message recognition for line graphs.  </section>
<citcontext>
<prevsection>
<prevsent>for figure 2, our system produces changetrend(1997, rise, 1999, fall, 2006) as the logical representation of the most probable intended message.since the dependent axis is often not explicitly labeled, series of heuristics are used to identify an appropriate referent, which we term the measurement axis descriptor.
</prevsent>
<prevsent>in figure 2, the measurement axis descriptor is identified as durango sales.
</prevsent>
</prevsection>
<citsent citstr=" W96-0501 ">
the 53 intended message and measurement axis descriptor are then passed to realization component which uses fuf/surge (elhadad and robin, 1996) <papid> W96-0501 </papid>to generate the following initial description: this graphic conveys changing trend in durango sales, rising from 1997 to 1999 and then falling to 2006.</citsent>
<aftsection>
<nextsent>in presenting multimodal document to user via ascreen reader, if the author does not specify reading order in the accessibility preferences, it is not entirely clear where the description of the graphical content should be given.
</nextsent>
<nextsent>the text of scientific articles normally makes explicit references to any graphs contained in the document; in this case, it makes sense to insert the graphical description alongside the first such reference.
</nextsent>
<nextsent>however, popular media articles rarely contain explicit references tographics.
</nextsent>
<nextsent>we hypothesize that describing the graphical content together with the most relevant portion ofthe article text will result in more coherent presentation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1207">
<title id=" W11-2306.xml">improving the accessibility of line graphs in multimodal documents </title>
<section> identifying relevant paragraph.  </section>
<citcontext>
<prevsection>
<prevsent>we compute wp from the pseudo-relevant paragraphs themselves, and we estimate wa using the word frequencies from the article text in the documents.
</prevsent>
<prevsent>finally, we compute wg by filtering-out the components ofwa fromwp.
</prevsent>
</prevsection>
<citsent citstr=" P03-1018 ">
this process is related to the work by widdows (2003) <papid> P03-1018 </papid>on orthogonal negation of vector spaces.</citsent>
<aftsection>
<nextsent>the task can be formulated as follows: 1.
</nextsent>
<nextsent>wp = wa + wg where ?   0 and ?   0,.
</nextsent>
<nextsent>which means the word frequency vector forthe pseudo-relevant paragraphs is linear combination of the background (topic) word frequency vector and the graphic word vector.
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1208">
<title id=" W11-2306.xml">improving the accessibility of line graphs in multimodal documents </title>
<section> integrating text and graphics.  </section>
<citcontext>
<prevsection>
<prevsent>this will permit the user to request quick overview in order to decide whether toread the original document, or more comprehensive synopsis to obtain the most important content without having to read the entire article.
</prevsent>
<prevsent>5.1 semantic modeling of multimodal.
</prevsent>
</prevsection>
<citsent citstr=" W00-0109 ">
documents content gathered from the article text by semantic parser and from the information graphics by our graph understanding system is combined intoa single semantic model based on typed, structured objects organized under foundational ontology (mcdonald, 2000<papid> W00-0109 </papid>a).</citsent>
<aftsection>
<nextsent>for the semantic parsing of text, we use sparser (mcdonald, 1992), <papid> A92-1027 </papid>abottom-up, phrase-structure-based chart parser, optimized for semantic grammars and partial parsing.3 using built-in model of core english grammar plus domain-specific grammars, sparser extracts information from the text and produces categorized objects as semantic representation (mcdonald, 2000<papid> W00-0109 </papid>b).</nextsent>
<nextsent>the intended message and salient additional propositions identified by our system for the information graphics are decomposed and added to the model constructed by sparser.4 model entries contain slots for attributes in the concept categorys ontology definition (fillable by other concepts or symbols), the original phrasings mentioning this concept in the text (represented as parameterized synchronous tag derivation trees), and markers recording document structure (i.e., where in the text [including title, headings, etc.] or graphic the concept appeared).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1210">
<title id=" W11-2306.xml">improving the accessibility of line graphs in multimodal documents </title>
<section> integrating text and graphics.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 semantic modeling of multimodal.
</prevsent>
<prevsent>documents content gathered from the article text by semantic parser and from the information graphics by our graph understanding system is combined intoa single semantic model based on typed, structured objects organized under foundational ontology (mcdonald, 2000<papid> W00-0109 </papid>a).</prevsent>
</prevsection>
<citsent citstr=" A92-1027 ">
for the semantic parsing of text, we use sparser (mcdonald, 1992), <papid> A92-1027 </papid>abottom-up, phrase-structure-based chart parser, optimized for semantic grammars and partial parsing.3 using built-in model of core english grammar plus domain-specific grammars, sparser extracts information from the text and produces categorized objects as semantic representation (mcdonald, 2000<papid> W00-0109 </papid>b).</citsent>
<aftsection>
<nextsent>the intended message and salient additional propositions identified by our system for the information graphics are decomposed and added to the model constructed by sparser.4 model entries contain slots for attributes in the concept categorys ontology definition (fillable by other concepts or symbols), the original phrasings mentioning this concept in the text (represented as parameterized synchronous tag derivation trees), and markers recording document structure (i.e., where in the text [including title, headings, etc.] or graphic the concept appeared).
</nextsent>
<nextsent>figure 4 shows some of the information contained in small portion of the semantic model built for an article entitled will med tronics pulse quicken??
</nextsent>
<nextsent>from the may 29,2006 edition of business week magazine5, which included line graph.
</nextsent>
<nextsent>nodes correspond to concepts 3https://github.com/charlieg/sparser4although the framework is general enough to accommodate any modality (e.g., images, video) given suitable semantic analysis tools, our prototype implementation focuses on bar charts and line graphs analyzed by sight.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1213">
<title id=" W11-2306.xml">improving the accessibility of line graphs in multimodal documents </title>
<section> integrating text and graphics.  </section>
<citcontext>
<prevsection>
<prevsent>however, the key provisions of the bill, which may individually be mentioned only once, are likely more important as greater amount of detail is provided concerning them.
</prevsent>
<prevsent>simple repetition is not necessarily indicative of the importance of concept, but if large amount of information is provided forgiven concept, it is safe to assume the concept is important in the context of that document.
</prevsent>
</prevsection>
<citsent citstr=" P97-1013 ">
document structure (wd) is another important clue in determining which elements of text are important enough to include in summary (marcu, 1997).<papid> P97-1013 </papid></citsent>
<aftsection>
<nextsent>if concept is featured prominently in the title, or appears in the first or final paragraphs, it is likely more important than concept buried in the middle of the document.
</nextsent>
<nextsent>importance is also affected by certain rhetorical devices (wr) which serve to highlight particular concepts.
</nextsent>
<nextsent>being used in an idiom, or compared to another concept by means of juxtaposition suggests that given concept may hold special significance.
</nextsent>
<nextsent>finally, the weights assigned by our graph understanding system for the additional propositions identified in the graphics are incorporated into the id of the concepts involved as wg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1214">
<title id=" W11-2306.xml">improving the accessibility of line graphs in multimodal documents </title>
<section> integrating text and graphics.  </section>
<citcontext>
<prevsection>
<prevsent>finally, the weights assigned by our graph understanding system for the additional propositions identified in the graphics are incorporated into the id of the concepts involved as wg.
</prevsent>
<prevsent>5.3 selecting content for summary.
</prevsent>
</prevsection>
<citsent citstr=" W10-4202 ">
to select concepts for inclusion in the summary, the model will then be passed to discourse-aware graph-based content selection framework (demir et al., 2010), <papid> W10-4202 </papid>which selects concepts one at time and iteratively re-weights the remaining items soas to include related concepts and avoid redun dancy.</citsent>
<aftsection>
<nextsent>this algorithm incorporates page rank (pageet al, 1999), but with several modifications.
</nextsent>
<nextsent>in addition to centrality assessment based on relationships between concepts, it includes apriori importance nodes enabling us to incorporate concept completeness, number of expressions, document structure, and rhetorical devices.
</nextsent>
<nextsent>more importantly froma summary generation perspective, the algorithm it eratively picks concepts one at time, and re-ranksthe remaining entries by increasing the weight of related items and discounting redundant ones.
</nextsent>
<nextsent>this allows us to select concepts that complement each other while simultaneously avoiding redundancy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1215">
<title id=" W11-2306.xml">improving the accessibility of line graphs in multimodal documents </title>
<section> generating an abs tractive summary of.  </section>
<citcontext>
<prevsection>
<prevsent>this allows us to select concepts that complement each other while simultaneously avoiding redundancy.
</prevsent>
<prevsent>a multimodal document figure 4 shows the two most important concepts (company1 &amp; person1) selected from the medtronic article in section 5.1.
</prevsent>
</prevsection>
<citsent citstr=" W10-4220 ">
following mcdonald and greenbacker (2010), <papid> W10-4220 </papid>we use the phrasings observed by the parser as the raw material?</citsent>
<aftsection>
<nextsent>for expressing these selected concepts.
</nextsent>
<nextsent>reusing the original phrasings reduces the reliance on built-in or canned?
</nextsent>
<nextsent>constructions, and allows the summary to reflect the style of the original text.
</nextsent>
<nextsent>the derivation trees stored in the model to realize particular concept may use different syntactic constituents (e.g., noun phrases, verb phrases).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1218">
<title id=" W12-1615.xml">a temporal simulator for developing turn taking methods for spoken dialogue systems </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>we describe the details of the simulator and demonstrate it on sample domain.
</prevsent>
<prevsent>effective turn-taking is critical for successful human-computer interaction.
</prevsent>
</prevsection>
<citsent citstr=" P10-1019 ">
recently, approaches have been proposed to improve system turn-takingbehavior that use reinforcement learning (jonsdottir et al, 2008; selfridge and heeman, 2010), <papid> P10-1019 </papid>decision theory (e.g., raux and eskenazi, 2009), <papid> N09-1071 </papid>and hard-coded policies (e.g., skantze and schlangen , 2009).<papid> E09-1085 </papid></citsent>
<aftsection>
<nextsent>some of these methods model turn-taking as content-free decisions (jonsdottir et al, 2008;skantze and schlangen, 2009), <papid> E09-1085 </papid>while others primarily relyon dialogue context (selfridge and heeman, 2010) <papid> P10-1019 </papid>and lexical cues (e.g., raux and eskenazi,2009).<papid> N09-1071 </papid></nextsent>
<nextsent>turn-taking continues to be an area of active research and its development is vital for next generation dialogue systems, especially as they allow for more mixed initiative interaction.researchers have turned to simulation since developing dialogue system with real users is expensive, time consuming, and sometimes impossi ble.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1219">
<title id=" W12-1615.xml">a temporal simulator for developing turn taking methods for spoken dialogue systems </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>we describe the details of the simulator and demonstrate it on sample domain.
</prevsent>
<prevsent>effective turn-taking is critical for successful human-computer interaction.
</prevsent>
</prevsection>
<citsent citstr=" N09-1071 ">
recently, approaches have been proposed to improve system turn-takingbehavior that use reinforcement learning (jonsdottir et al, 2008; selfridge and heeman, 2010), <papid> P10-1019 </papid>decision theory (e.g., raux and eskenazi, 2009), <papid> N09-1071 </papid>and hard-coded policies (e.g., skantze and schlangen , 2009).<papid> E09-1085 </papid></citsent>
<aftsection>
<nextsent>some of these methods model turn-taking as content-free decisions (jonsdottir et al, 2008;skantze and schlangen, 2009), <papid> E09-1085 </papid>while others primarily relyon dialogue context (selfridge and heeman, 2010) <papid> P10-1019 </papid>and lexical cues (e.g., raux and eskenazi,2009).<papid> N09-1071 </papid></nextsent>
<nextsent>turn-taking continues to be an area of active research and its development is vital for next generation dialogue systems, especially as they allow for more mixed initiative interaction.researchers have turned to simulation since developing dialogue system with real users is expensive, time consuming, and sometimes impossi ble.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1220">
<title id=" W12-1615.xml">a temporal simulator for developing turn taking methods for spoken dialogue systems </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>we describe the details of the simulator and demonstrate it on sample domain.
</prevsent>
<prevsent>effective turn-taking is critical for successful human-computer interaction.
</prevsent>
</prevsection>
<citsent citstr=" E09-1085 ">
recently, approaches have been proposed to improve system turn-takingbehavior that use reinforcement learning (jonsdottir et al, 2008; selfridge and heeman, 2010), <papid> P10-1019 </papid>decision theory (e.g., raux and eskenazi, 2009), <papid> N09-1071 </papid>and hard-coded policies (e.g., skantze and schlangen , 2009).<papid> E09-1085 </papid></citsent>
<aftsection>
<nextsent>some of these methods model turn-taking as content-free decisions (jonsdottir et al, 2008;skantze and schlangen, 2009), <papid> E09-1085 </papid>while others primarily relyon dialogue context (selfridge and heeman, 2010) <papid> P10-1019 </papid>and lexical cues (e.g., raux and eskenazi,2009).<papid> N09-1071 </papid></nextsent>
<nextsent>turn-taking continues to be an area of active research and its development is vital for next generation dialogue systems, especially as they allow for more mixed initiative interaction.researchers have turned to simulation since developing dialogue system with real users is expensive, time consuming, and sometimes impossi ble.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1225">
<title id=" W12-1615.xml">a temporal simulator for developing turn taking methods for spoken dialogue systems </title>
<section> dialogue simulator.  </section>
<citcontext>
<prevsection>
<prevsent>the recognizer will continue to output parti als from user words until the user stops speaking or the system sends message to stop recognizing.
</prevsent>
<prevsent>one critical aspect of isr which we are not modeling is partial instability, where parti als are revised as recognition progresses.
</prevsent>
</prevsection>
<citsent citstr=" N09-1043 ">
partial instability is an area of active research (e.g.baumann et al 2009) <papid> N09-1043 </papid>and, while revisions may certainly be modeled in the future, we chose not to forsimplicitys sake.</citsent>
<aftsection>
<nextsent>we feel that, at present, the recognition lag parameter is sufficient to model the time for partial to become stable.
</nextsent>
<nextsent>114 table 1: parameters and demonstration values (ms) conversant agents inter-word pause (usr) ? = 200, ? = 100 inter-word pause (sys) 100 inter-utt.
</nextsent>
<nextsent>pause ? = 1000, ? = 500 word length 400 take-turn (usr) 500/200 take-turn (sys) 750/100 isr agent recog.
</nextsent>
<nextsent>acc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1227">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this is often done by different weighting or voting schemes.
</prevsent>
<prevsent>ensemble learning (dietterich, 2000) has been used for variety of machine learning tasks and recently has been applied to dependency parsing in various ways and with different levels ofsuccess.
</prevsent>
</prevsection>
<citsent citstr=" N10-1091 ">
(surdeanu and manning, 2010; <papid> N10-1091 </papid>haffari et al, 2011) showed successful combination of parse trees through linear combination of trees with various weighting formulations.</citsent>
<aftsection>
<nextsent>tokeep their tree constraint, they applied eisners algorithm for re parsing (eisner, 1996).<papid> C96-1058 </papid></nextsent>
<nextsent>parser combination with dependency trees has been examined in terms of accuracy (sagae and lavie, 2006; <papid> N06-2033 </papid>sagae and tsujii, 2007; <papid> D07-1111 </papid>zeman andzabokrtsky?, 2005).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1228">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>ensemble learning (dietterich, 2000) has been used for variety of machine learning tasks and recently has been applied to dependency parsing in various ways and with different levels ofsuccess.
</prevsent>
<prevsent>(surdeanu and manning, 2010; <papid> N10-1091 </papid>haffari et al, 2011) showed successful combination of parse trees through linear combination of trees with various weighting formulations.</prevsent>
</prevsection>
<citsent citstr=" C96-1058 ">
tokeep their tree constraint, they applied eisners algorithm for re parsing (eisner, 1996).<papid> C96-1058 </papid></citsent>
<aftsection>
<nextsent>parser combination with dependency trees has been examined in terms of accuracy (sagae and lavie, 2006; <papid> N06-2033 </papid>sagae and tsujii, 2007; <papid> D07-1111 </papid>zeman andzabokrtsky?, 2005).</nextsent>
<nextsent>however, the various techniques have generally examined similar parsers 19 or parsers which have generated various differentmodels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1229">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(surdeanu and manning, 2010; <papid> N10-1091 </papid>haffari et al, 2011) showed successful combination of parse trees through linear combination of trees with various weighting formulations.</prevsent>
<prevsent>tokeep their tree constraint, they applied eisners algorithm for re parsing (eisner, 1996).<papid> C96-1058 </papid></prevsent>
</prevsection>
<citsent citstr=" N06-2033 ">
parser combination with dependency trees has been examined in terms of accuracy (sagae and lavie, 2006; <papid> N06-2033 </papid>sagae and tsujii, 2007; <papid> D07-1111 </papid>zeman andzabokrtsky?, 2005).</citsent>
<aftsection>
<nextsent>however, the various techniques have generally examined similar parsers 19 or parsers which have generated various differentmodels.
</nextsent>
<nextsent>to the best of our knowledge, our experiments are the first to look at the accuracy and part of speech error distribution when combining together constituent and dependency parsers that use many different techniques.
</nextsent>
<nextsent>however, pos tags were used in parser combination in (hall etal., 2007) <papid> D07-1097 </papid>for combining set of malt parser models with success.</nextsent>
<nextsent>other methods of parser combinations have shown to be successful such as using one parser to generate features for another parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1230">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(surdeanu and manning, 2010; <papid> N10-1091 </papid>haffari et al, 2011) showed successful combination of parse trees through linear combination of trees with various weighting formulations.</prevsent>
<prevsent>tokeep their tree constraint, they applied eisners algorithm for re parsing (eisner, 1996).<papid> C96-1058 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1111 ">
parser combination with dependency trees has been examined in terms of accuracy (sagae and lavie, 2006; <papid> N06-2033 </papid>sagae and tsujii, 2007; <papid> D07-1111 </papid>zeman andzabokrtsky?, 2005).</citsent>
<aftsection>
<nextsent>however, the various techniques have generally examined similar parsers 19 or parsers which have generated various differentmodels.
</nextsent>
<nextsent>to the best of our knowledge, our experiments are the first to look at the accuracy and part of speech error distribution when combining together constituent and dependency parsers that use many different techniques.
</nextsent>
<nextsent>however, pos tags were used in parser combination in (hall etal., 2007) <papid> D07-1097 </papid>for combining set of malt parser models with success.</nextsent>
<nextsent>other methods of parser combinations have shown to be successful such as using one parser to generate features for another parser.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1231">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, the various techniques have generally examined similar parsers 19 or parsers which have generated various differentmodels.
</prevsent>
<prevsent>to the best of our knowledge, our experiments are the first to look at the accuracy and part of speech error distribution when combining together constituent and dependency parsers that use many different techniques.
</prevsent>
</prevsection>
<citsent citstr=" D07-1097 ">
however, pos tags were used in parser combination in (hall etal., 2007) <papid> D07-1097 </papid>for combining set of malt parser models with success.</citsent>
<aftsection>
<nextsent>other methods of parser combinations have shown to be successful such as using one parser to generate features for another parser.
</nextsent>
<nextsent>this was shown in (nivre and mcdonald, 2008), <papid> P08-1108 </papid>in which malt parser was used as feature to mst parser.</nextsent>
<nextsent>the result was successful combination of transition-based and graph-based parser, but did not address adding other types of parsers into the framework.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1232">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, pos tags were used in parser combination in (hall etal., 2007) <papid> D07-1097 </papid>for combining set of malt parser models with success.</prevsent>
<prevsent>other methods of parser combinations have shown to be successful such as using one parser to generate features for another parser.</prevsent>
</prevsection>
<citsent citstr=" P08-1108 ">
this was shown in (nivre and mcdonald, 2008), <papid> P08-1108 </papid>in which malt parser was used as feature to mst parser.</citsent>
<aftsection>
<nextsent>the result was successful combination of transition-based and graph-based parser, but did not address adding other types of parsers into the framework.
</nextsent>
<nextsent>the following sections describe the process flow,choice of parsers, and datasets needed for others to recreate the results listed in this paper.
</nextsent>
<nextsent>although we describe the specific parsers and datasets used in this paper, this process flow should work for any number of hybrid combinations of parsers and datasets.
</nextsent>
<nextsent>3.1 process flow.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1233">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>they range from graph-based approaches to transition-based approaches to constituent parsers.
</prevsent>
<prevsent>constituency output is converted to dependency structures using converter (johansson and nugues, 2007).all parsers are integrated into the treex framework (zabokrtsky?
</prevsent>
</prevsection>
<citsent citstr=" W11-2153 ">
et al, 2008; popel et al, 2011)<papid> W11-2153 </papid>using the publicly released parsers from there spective authors but with perl wrappers to allow them to work on common tree structure.?</citsent>
<aftsection>
<nextsent>graph-based: dependency tree is special case of weighted edge graph that spawns from an artificial root and is acyclic.
</nextsent>
<nextsent>because of this we can look at large history of work in graph theory to address finding the best spanning tree for each dependency graph.
</nextsent>
<nextsent>in this paper we use mst parser (mcdonald et al, 2005) <papid> H05-1066 </papid>as an input to our ensemble parser.</nextsent>
<nextsent>transition-based: transition-based parsing creates dependency structure that is parameterized over the transitions used to create dependency tree.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1234">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>graph-based: dependency tree is special case of weighted edge graph that spawns from an artificial root and is acyclic.
</prevsent>
<prevsent>because of this we can look at large history of work in graph theory to address finding the best spanning tree for each dependency graph.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
in this paper we use mst parser (mcdonald et al, 2005) <papid> H05-1066 </papid>as an input to our ensemble parser.</citsent>
<aftsection>
<nextsent>transition-based: transition-based parsing creates dependency structure that is parameterized over the transitions used to create dependency tree.
</nextsent>
<nextsent>this is closely related to shift-reduce constituency parsing algorithms.
</nextsent>
<nextsent>the benefit of transition-based parsing is the use of greedy algorithms which have linear time complexity.
</nextsent>
<nextsent>however, due to the greedy algorithms, longer arc parse scan cause error propagation across each transition (kubler et al, 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1235">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>the benefit of transition-based parsing is the use of greedy algorithms which have linear time complexity.
</prevsent>
<prevsent>however, due to the greedy algorithms, longer arc parse scan cause error propagation across each transition (kubler et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
we make use 20 of malt parser (nivre et al, 2007<papid> D07-1096 </papid>b), which in the shared tasks was often tied with the best performing systems.</citsent>
<aftsection>
<nextsent>additionally we use zpar (zhang and clark, 2011) <papid> J11-1005 </papid>which is based on malt parser but with different set of non-local features.</nextsent>
<nextsent>constituent transformation while not atrue dependency parser, one technique often applied is to take state-of-the-art constituent parser and transform its phrase based output into dependency relations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1236">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>however, due to the greedy algorithms, longer arc parse scan cause error propagation across each transition (kubler et al, 2009).
</prevsent>
<prevsent>we make use 20 of malt parser (nivre et al, 2007<papid> D07-1096 </papid>b), which in the shared tasks was often tied with the best performing systems.</prevsent>
</prevsection>
<citsent citstr=" J11-1005 ">
additionally we use zpar (zhang and clark, 2011) <papid> J11-1005 </papid>which is based on malt parser but with different set of non-local features.</citsent>
<aftsection>
<nextsent>constituent transformation while not atrue dependency parser, one technique often applied is to take state-of-the-art constituent parser and transform its phrase based output into dependency relations.
</nextsent>
<nextsent>this hasbeen shown to also be state-of-the-art in accuracy for dependency parsing in english.
</nextsent>
<nextsent>in this paper we transformed the constituency structure into dependencies using the penn converter conversion tool (johansson and nugues, 2007).
</nextsent>
<nextsent>a version of this converter was used in the conll shared task to create dependency treebanks as well.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1237">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we transformed the constituency structure into dependencies using the penn converter conversion tool (johansson and nugues, 2007).
</prevsent>
<prevsent>a version of this converter was used in the conll shared task to create dependency treebanks as well.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
for the following ensemble experiments we make use of both (charniak and johnson, 2005) <papid> P05-1022 </papid>and stanfords (klein and manning, 2003) <papid> P03-1054 </papid>constituent parsers.</citsent>
<aftsection>
<nextsent>in addition to these 5 parsers, we also report the accuracy of an oracle parser.
</nextsent>
<nextsent>this parser is simply the best possible parse of all the edges of the combined dependency trees.
</nextsent>
<nextsent>if the reference, gold standard, tree has an edge that any of the 5parsers contain, we include that edge in the oracle parse.
</nextsent>
<nextsent>initially all nodes of the tree are attached to an artificial root in order to maintain connectedness.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1238">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we transformed the constituency structure into dependencies using the penn converter conversion tool (johansson and nugues, 2007).
</prevsent>
<prevsent>a version of this converter was used in the conll shared task to create dependency treebanks as well.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
for the following ensemble experiments we make use of both (charniak and johnson, 2005) <papid> P05-1022 </papid>and stanfords (klein and manning, 2003) <papid> P03-1054 </papid>constituent parsers.</citsent>
<aftsection>
<nextsent>in addition to these 5 parsers, we also report the accuracy of an oracle parser.
</nextsent>
<nextsent>this parser is simply the best possible parse of all the edges of the combined dependency trees.
</nextsent>
<nextsent>if the reference, gold standard, tree has an edge that any of the 5parsers contain, we include that edge in the oracle parse.
</nextsent>
<nextsent>initially all nodes of the tree are attached to an artificial root in order to maintain connectedness.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1240">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>the availability of standard competition, gold level, data has been an important factor in dependency based research.
</prevsent>
<prevsent>for this study we use the english conll data.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
this data comes from the wall street journal (wsj) section of the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>all parsers are trained on sections 02-21 of the wsj except for the stanford parser which uses sections 01-21.
</nextsent>
<nextsent>charniak, stanford and zpar use pre-trained models ec50spfinal, wsjpcfg.ser.gz,english.tar.gz respectively.
</nextsent>
<nextsent>for testing we use section 23 of the wsj for comparability reasons with other papers.
</nextsent>
<nextsent>this test data contains 56,684 tokens.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1241">
<title id=" W12-0503.xml">hybrid combination of constituency and dependency trees into an ensemble dependency parser </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>uas studies the structure of dependency tree and assesses whether the output has the correct head and dependency arcs.
</prevsent>
<prevsent>in addition to the structure score in uas, lasalso measures the accuracy of the dependency labels on each arc. third, but less common metric, is used to judge the percentage of sentences that are completely correct in regards to their lasscore.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
for this paper since we are primarily concerned with the merging of tree structures we only evaluate uas (buchholz and marsi, 2006).<papid> W06-2920 </papid></citsent>
<aftsection>
<nextsent>3.5 weighting.
</nextsent>
<nextsent>currently we are applying four weighting algorithms to the graph structure.
</nextsent>
<nextsent>first we give each parser the same uniform weight.
</nextsent>
<nextsent>second we examine weighting each parser output by the uas score of the individual parser taken from our tuning data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1242">
<title id=" W11-1920.xml">reconciling ontonotes unrestricted coreference resolution in ontonotes with reconcile </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W11-1901 ">
this paper describes our entry to the 2011 conll closed task (pradhan et al, 2011) <papid> W11-1901 </papid>on modeling unrestricted coreference in ontonotes.</citsent>
<aftsection>
<nextsent>our system isbased on the reconcile coreference resolution research platform.
</nextsent>
<nextsent>reconcile is general software infrastructure for the development of learning-based noun phrase (np) coreference resolution systems.our entry for the conll closed task is configuration of reconcile intended to do well on ontonotesdata.
</nextsent>
<nextsent>this paper describes our configuration of reconcile as well as the changes that we had to implement to integrate with the ontonotes task definition and data formats.
</nextsent>
<nextsent>we also present and discuss the performance of our system under different testing conditions on withheld validation set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1243">
<title id=" W12-1606.xml">an unsupervised approach to user simulation toward self improving dialog systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 present sand discusses the results.
</prevsent>
<prevsent>finally, section 6 concludes with brief summary and suggestions for future research.
</prevsent>
</prevsection>
<citsent citstr=" N07-2038 ">
previous user simulation studies can be roughly categorized into rule-based methods (chung, 2005; 50 lopez-cozar et al, 2006; schatzmann et al, 2007<papid> N07-2038 </papid>a) and data-driven methods (cuayahuitl et al, 2005; eckert et al, 1997; jung et al, 2009; levin et al,2000; georgila et al, 2006; pietquin, 2004).</citsent>
<aftsection>
<nextsent>rule based methods generally allow for more control over their designs for the target domain while data-driven methods afford more portability from one domain to another and are attractive for modeling user behavior based on real data.
</nextsent>
<nextsent>although development costs for data-driven methods are typically lower than those of rule-based methods, previous data-driven approaches have still required certain amount of human effort.
</nextsent>
<nextsent>most intention-level models take asemantically annotated corpus to produce user intention without introducing errors (cuayahuitl et al, 2005; jung et al, 2009).
</nextsent>
<nextsent>surface-level approaches need transcribed data to train their surface form and error generating models (jung et al, 2009; schatzmann et al, 2007<papid> N07-2038 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1245">
<title id=" W12-1606.xml">an unsupervised approach to user simulation toward self improving dialog systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>although such approaches can avoid human intervention, the sole incorporation of erroneous user action can propagate those errors to the higher-level discourse features which are computed from them, and thus could result in less realistic user behavior.
</prevsent>
<prevsent>in this work, the true user action is treated as hidden variable and, further, its associated dialog history is also viewed as latent so that the uncertainty of the true user action is properly controlled in principled manner.
</prevsent>
</prevsection>
<citsent citstr=" P08-2031 ">
syedand williams (2008) <papid> P08-2031 </papid>adopted the expectation maximization algorithm for parameter learning for latent variable model.</citsent>
<aftsection>
<nextsent>but their method still requires asmall amount of transcribed data to learn the observation conf usability, and it suffers from over fitting as general property of maximum likelihood.
</nextsent>
<nextsent>to address this problem, we propose bayesian learning method, which requires no transcribed data.
</nextsent>
<nextsent>simulation before describing each component in detail, we present the overall process of user simulation with an example in the lets go domain in figure 1.
</nextsent>
<nextsent>to begin dialog, the user simulator first sets the user figure 1: the overall process of user simulation in thelets go domain, where users call the spoken dialog system to get bus schedule information for pittsburgh goal by sampling the goal model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1246">
<title id=" W12-0209.xml">language comparison through sparse multilingual word alignment </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>it thus gives an overview of how structurally similar two languages are, where languages are considered to have more similar structure the more words they share in the alignment clusters.
</prevsent>
<prevsent>7note that the prime in this case does not stand for the transpose of matrix, as it is sometimes used.
</prevsent>
</prevsection>
<citsent citstr=" C88-1016 ">
parallel corpora have received lot of attention since the advent of statistical machine translation (brown et al, 1988) <papid> C88-1016 </papid>where they serve as training material for the underlying alignment models.</citsent>
<aftsection>
<nextsent>forthis reason, the last two decades have seen an increasing interest in the collection of parallel corpora for number of language pairs (hansard8), also including text corpora which contain texts in three or more languages (opus9, europarl10, multext-east11).
</nextsent>
<nextsent>yet there are only few resources which comprise texts for which translations are available into many different languages.
</nextsent>
<nextsent>such texts are here referred to as massively parallel texts?
</nextsent>
<nextsent>(mpt; cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1247">
<title id=" W12-0403.xml">seeing through deception a computational approach to deceit detection in written communication </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>interest.
</prevsent>
<prevsent>indeed, depaulo et al  (1996) report that people tell an average of one to two lies day, either through spoken or written language.
</prevsent>
</prevsection>
<citsent citstr=" P11-1032 ">
more recently, researchers in the field of opinion mining have become increasingly concerned with the detection of the truth condition of the opinions passed on the internet (ott et al , 2011).<papid> P11-1032 </papid></citsent>
<aftsection>
<nextsent>this issue is particularly challenging, since the researcher is provided with no information apart from the written language itself.
</nextsent>
<nextsent>within this framework, the present study attempts to explore deception cues in written language in spanish, which is something of novelty.
</nextsent>
<nextsent>the remainder of this paper is organized as follows: in section 2, related work on the topic is summarized; in section 3, we explain our methodology for analyzing data; in section 4, the evaluation framework and experimental results are presented and discussed; section 5 presents the results from bag-of-words model as basis for comparison; finally, in section 6 some conclusions and directions for further research are advanced.
</nextsent>
<nextsent>there are verbal cues to deception which form part of existing verbal lie detection tools used by professional lie catchers and scholars (vrij, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1248">
<title id=" W12-0403.xml">seeing through deception a computational approach to deceit detection in written communication </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>most commonly, researchers have used the classes of words defined in the linguistic inquiry and word count or liwc (pennebaker et al , 2001), which is text analysis program that counts words in psychologically meaningful categories.
</prevsent>
<prevsent>it includes about 2,200 words and word stems grouped into 72 categories relevant to psychological processes.
</prevsent>
</prevsection>
<citsent citstr=" N10-1096 ">
it has been used to study issues like personality (mairesse et al , 2007), psychological adjustment (alpers et al , 2005), social judgments (leshed et al , 2007), tutoring dynamics (cade et al , 2010), <papid> N10-1096 </papid>and mental health (rude et al , 2004).</citsent>
<aftsection>
<nextsent>the validation of the lexicon contained in its dictionary has been performed by means of comparison of human ratings of large number of written texts to the rating obtained through their liwc-based analyses.
</nextsent>
<nextsent>liwc was firstly used by penne bakers group for number of studies on the language of deception, being the results published in newman et al  (2003).
</nextsent>
<nextsent>for their purposes, they 15 collected corpus with true and false statements through five different studies.
</nextsent>
<nextsent>in the first three tests, the participants expressed their true opinions on abortion, as well as the opposite of their point of view.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1249">
<title id=" W12-0403.xml">seeing through deception a computational approach to deceit detection in written communication </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>liwc has been also used for the investigation of deception in written language.
</prevsent>
<prevsent>curiously enough, research in this line has been approached by computational linguists and not from the perspective of the forensic science.
</prevsent>
</prevsection>
<citsent citstr=" P09-2078 ">
first, mihalcea &amp; strapparava (2009) <papid> P09-2078 </papid>used liwc for post hoc analysis, measuring several language dimensions on corpus of 100 false and true opinions on three controversial topics ? the design of the questionnaire is indeed similar to newman et al (2003).</citsent>
<aftsection>
<nextsent>as preliminary experiment, they used two ml classifiers: nave bayes and support vector machines, using word frequencies for the training of both algorithms, similar to bag-of-words model.
</nextsent>
<nextsent>they achieved an average classification performance of 70%, which is significantly higher than the 50% baseline.
</nextsent>
<nextsent>on the basis of this information, they calculate dominance score associated with given word class inside the collection of deceptive texts as measure of saliency.
</nextsent>
<nextsent>then, they compute word coverage, which is the weight of the linguistic item in the corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1253">
<title id=" W12-0703.xml">sweeping through the topic space bad luck roll again </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>due to the randomized nature of the sampling process.in this paper, we address these issues by systematically sweeping the parameter space.
</prevsent>
<prevsent>for this, we pick lda since it is the most commonly used tm in the field of nlp.
</prevsent>
</prevsection>
<citsent citstr=" P08-2068 ">
to evaluate the contribution of the tm, we choose the task of ts: this task has received considerable interest fromthe nlp community, standard datasets and evaluation measures are available for testing, and it 19has been shown that this task considerably benefits from the use of tms, see (misra et al , 2009; sun et al , 2008; <papid> P08-2068 </papid>eisenstein, 2009).<papid> N09-1040 </papid></citsent>
<aftsection>
<nextsent>this paper is organized as follows: in the next section, we present related work regarding text segmentation using topic models and topic model parameter evaluations.
</nextsent>
<nextsent>section 3 defines the top ictiling text segmentation algorithm, which is simplified version of text tiling (hearst, 1994), <papid> P94-1002 </papid>and makes direct use of topic assignments.</nextsent>
<nextsent>its simplicity allows us to observe direct consequences of lda parameter settings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1254">
<title id=" W12-0703.xml">sweeping through the topic space bad luck roll again </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>due to the randomized nature of the sampling process.in this paper, we address these issues by systematically sweeping the parameter space.
</prevsent>
<prevsent>for this, we pick lda since it is the most commonly used tm in the field of nlp.
</prevsent>
</prevsection>
<citsent citstr=" N09-1040 ">
to evaluate the contribution of the tm, we choose the task of ts: this task has received considerable interest fromthe nlp community, standard datasets and evaluation measures are available for testing, and it 19has been shown that this task considerably benefits from the use of tms, see (misra et al , 2009; sun et al , 2008; <papid> P08-2068 </papid>eisenstein, 2009).<papid> N09-1040 </papid></citsent>
<aftsection>
<nextsent>this paper is organized as follows: in the next section, we present related work regarding text segmentation using topic models and topic model parameter evaluations.
</nextsent>
<nextsent>section 3 defines the top ictiling text segmentation algorithm, which is simplified version of text tiling (hearst, 1994), <papid> P94-1002 </papid>and makes direct use of topic assignments.</nextsent>
<nextsent>its simplicity allows us to observe direct consequences of lda parameter settings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1255">
<title id=" W12-0703.xml">sweeping through the topic space bad luck roll again </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to evaluate the contribution of the tm, we choose the task of ts: this task has received considerable interest fromthe nlp community, standard datasets and evaluation measures are available for testing, and it 19has been shown that this task considerably benefits from the use of tms, see (misra et al , 2009; sun et al , 2008; <papid> P08-2068 </papid>eisenstein, 2009).<papid> N09-1040 </papid></prevsent>
<prevsent>this paper is organized as follows: in the next section, we present related work regarding text segmentation using topic models and topic model parameter evaluations.</prevsent>
</prevsection>
<citsent citstr=" P94-1002 ">
section 3 defines the top ictiling text segmentation algorithm, which is simplified version of text tiling (hearst, 1994), <papid> P94-1002 </papid>and makes direct use of topic assignments.</citsent>
<aftsection>
<nextsent>its simplicity allows us to observe direct consequences of lda parameter settings.
</nextsent>
<nextsent>further, we describe the experimental setup, our application based evaluation methodology including the dataset and the lda parameters we vary in section 4.results of our experiments in section 5 indicate that a) there is an optimal range for the number of topics, b) there is considerable variance in performance for different runs for both model estimation and inference, c) increasing the number of sampling iterations stabilizes average performance but does not make tms more robust, but d)combining the output of several independent sampling runs does, and additionally leads to large error rate reductions.
</nextsent>
<nextsent>similar results are obtained by e) the mode method with less computational costs using the most frequent topic id that is assigned during different inference iteration steps.
</nextsent>
<nextsent>in the conclusion, we give recommendations to add stability and robustness for tms: aside from optimization of the hyper parameters, we recommend combining the topic assignments of different inference iterations, and/or of different independent inference runs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1261">
<title id=" W12-0703.xml">sweeping through the topic space bad luck roll again </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>segment boundaries are set at the positions of the highest depth scores, which is common practice in text segmentation algorithms.
</prevsent>
<prevsent>an alternative to given would be the selection of segments according to depth score threshold.
</prevsent>
</prevsection>
<citsent citstr=" A00-2004 ">
as dataset the choi dataset (choi, 2000) <papid> A00-2004 </papid>is used.</citsent>
<aftsection>
<nextsent>this dataset is an artificially generated corpus that consists of 700 documents.
</nextsent>
<nextsent>each document consists of 10 segments and each segment has 3?
</nextsent>
<nextsent>11 sentences extracted from document of the brown corpus.
</nextsent>
<nextsent>for the first setup, we perform 10-fold cross validation (cv) for estimating the tm (estimating on 630 documents at time), for the other setups we use 600 documents for tm estimation and the remaining 100 documents for testing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1262">
<title id=" W12-1907.xml">unsupervised part of speech inference with particle filters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the results suggest that the approach has potential and more advanced particle filters are likely to lead to stronger performance.
</prevsent>
<prevsent>modern research is steadily revealing more of the subtle structure of natural language to create increasingly intricate models.
</prevsent>
</prevsection>
<citsent citstr=" N10-1082 ">
many modern problems in computational linguistics require or benefit from modeling the long range correlations between latent variables, e.g. part of speech (pos) induction (lianget al, 2010), <papid> N10-1082 </papid>dependency parsing (smith and eisner, 2008), <papid> D08-1016 </papid>and coreference resolution (denis and baldridge, 2007).<papid> N07-1030 </papid></citsent>
<aftsection>
<nextsent>these correlations make inference difficult because they reflect the complicated effect variables have on each other in such tightly coupled models.sequential monte carlo (smc) methods, like particle filters, are particularly well suited to estimating tightly coupled distributions (andrieu et al, 2010).
</nextsent>
<nextsent>particle filters sample sequences of latent variable assignments by concurrently generating several representative sequences consistent with models conditional dependencies.
</nextsent>
<nextsent>the sequential nature of the sampling simplifies inference by ignoring ambiguous correlations with un sampled variables at the cost of sampling the sequence multiple times.
</nextsent>
<nextsent>the few applications of particle filters in computational linguistics generally focus on the online nature ofsmc (canini et al, 2009; borschinger and johnson, 2011).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1263">
<title id=" W12-1907.xml">unsupervised part of speech inference with particle filters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the results suggest that the approach has potential and more advanced particle filters are likely to lead to stronger performance.
</prevsent>
<prevsent>modern research is steadily revealing more of the subtle structure of natural language to create increasingly intricate models.
</prevsent>
</prevsection>
<citsent citstr=" D08-1016 ">
many modern problems in computational linguistics require or benefit from modeling the long range correlations between latent variables, e.g. part of speech (pos) induction (lianget al, 2010), <papid> N10-1082 </papid>dependency parsing (smith and eisner, 2008), <papid> D08-1016 </papid>and coreference resolution (denis and baldridge, 2007).<papid> N07-1030 </papid></citsent>
<aftsection>
<nextsent>these correlations make inference difficult because they reflect the complicated effect variables have on each other in such tightly coupled models.sequential monte carlo (smc) methods, like particle filters, are particularly well suited to estimating tightly coupled distributions (andrieu et al, 2010).
</nextsent>
<nextsent>particle filters sample sequences of latent variable assignments by concurrently generating several representative sequences consistent with models conditional dependencies.
</nextsent>
<nextsent>the sequential nature of the sampling simplifies inference by ignoring ambiguous correlations with un sampled variables at the cost of sampling the sequence multiple times.
</nextsent>
<nextsent>the few applications of particle filters in computational linguistics generally focus on the online nature ofsmc (canini et al, 2009; borschinger and johnson, 2011).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1264">
<title id=" W12-1907.xml">unsupervised part of speech inference with particle filters </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the results suggest that the approach has potential and more advanced particle filters are likely to lead to stronger performance.
</prevsent>
<prevsent>modern research is steadily revealing more of the subtle structure of natural language to create increasingly intricate models.
</prevsent>
</prevsection>
<citsent citstr=" N07-1030 ">
many modern problems in computational linguistics require or benefit from modeling the long range correlations between latent variables, e.g. part of speech (pos) induction (lianget al, 2010), <papid> N10-1082 </papid>dependency parsing (smith and eisner, 2008), <papid> D08-1016 </papid>and coreference resolution (denis and baldridge, 2007).<papid> N07-1030 </papid></citsent>
<aftsection>
<nextsent>these correlations make inference difficult because they reflect the complicated effect variables have on each other in such tightly coupled models.sequential monte carlo (smc) methods, like particle filters, are particularly well suited to estimating tightly coupled distributions (andrieu et al, 2010).
</nextsent>
<nextsent>particle filters sample sequences of latent variable assignments by concurrently generating several representative sequences consistent with models conditional dependencies.
</nextsent>
<nextsent>the sequential nature of the sampling simplifies inference by ignoring ambiguous correlations with un sampled variables at the cost of sampling the sequence multiple times.
</nextsent>
<nextsent>the few applications of particle filters in computational linguistics generally focus on the online nature ofsmc (canini et al, 2009; borschinger and johnson, 2011).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1265">
<title id=" W12-1907.xml">unsupervised part of speech inference with particle filters </title>
<section> the pyp-hmm.  </section>
<citcontext>
<prevsection>
<prevsent>particle smoothing variants of smc reduce the relative variance of marginals early in the sequence, as well improving the diversity of the final sample (fearnhead et al, 2008).
</prevsent>
<prevsent>particle markov chain monte carlo (pmcmc) formally augments classic markov chain monte carlo (mcmc) approaches, like gibbs sampling, with samples generated by particle filters (andrieu et al, 2010).
</prevsent>
</prevsection>
<citsent citstr=" P11-1087 ">
the pyp-hmm model of pos generation demonstrates the tightly coupled correlations that complicate many standard inference methods (blunsom and cohn, 2011).<papid> P11-1087 </papid></citsent>
<aftsection>
<nextsent>the model applies hierarchical pitman-yor process (pyp) prior to trigram hidden markov model (hmm) to jointly model the distribution of sequence of latent word classes, t, andword tokens, w. this model performs well on corpora in multiple languages, but the lack of closed form solution for the sample probabilities makes it astrong canditate for pg sampling.
</nextsent>
<nextsent>the joint probability defined by trigram hmm is p?(t,w) = n+1?
</nextsent>
<nextsent>n=1 p?(tl|tn1, tn2)p?(wn|tn) where = |t| = |w| and the special tag $ is addedto the boundaries on the sentence.
</nextsent>
<nextsent>the model defines transition and emission distributions, tn|tn1, tn2, ? ttn1,tn2 wn|tn, ? etnthe pyp-hmm smoothes these distributions by applying hierarchical pyp priors to them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1266">
<title id=" W12-1907.xml">unsupervised part of speech inference with particle filters </title>
<section> the pyp-hmm.  </section>
<citcontext>
<prevsection>
<prevsent>the hierarchical pyp describes back-off path of simpler pyp priors, tij |a , bt , bi ? pyp(a , bt , bi) bi|a b, bb, ? pyp(ab, bb, u) |au , bu ? pyp(au , bu ,uniform).
</prevsent>
<prevsent>ei|a , be , ? pyp(ae , be , ci),where tij , bi, and are trigram, bigram, and un igram transition distributions respectively and ci is either uniform distribution (pyp-hmm) or bigram character language model emission distribution (pyp-hmm+lm, intended to model basic mor phology).
</prevsent>
</prevsection>
<citsent citstr=" P06-1124 ">
draws from the posterior of the hierarchicalpyp can be calculated with variant of the chinese restaraunt process (crp) called the chinese restaurant franchise (crf) (teh, 2006; <papid> P06-1124 </papid>goldwater et al, 2006).</citsent>
<aftsection>
<nextsent>in the crp analogy, each latent variable in sequence is represented by customer entering restaurant and sitting at one of an infinite number of tables.
</nextsent>
<nextsent>a customer chooses to sit at table in restaurant according to the probability (zn = k|z1:n1) = { ck n1+b 1 ? ? ? ka+b n1+b = ? + 1 (1) where zn is the index of the table chosen by the nth customer to the restaurant, z1:n1 is the seating arrangement of the previous n?
</nextsent>
<nextsent>1 customers to enter, ck is the count of the customers at table k, and is the total number of tables chosen by the previous n?
</nextsent>
<nextsent>1 customers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1267">
<title id=" W12-1907.xml">unsupervised part of speech inference with particle filters </title>
<section> sequential monte carlo.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 sentence sampling.
</prevsent>
<prevsent>the sent particle filter samples blocks of tag assignments ts1:n for sentence, s, composed of tokens, ws1:n. sampling an entire sentence minimizes the risk of assigning tag with high probability given its local context but minimal probability given the entire sentence.
</prevsent>
</prevsection>
<citsent citstr=" D08-1036 ">
sentences can be sampled by ignoring table counts while sampling proposal sentence, incorporating them after the fact with ametropolis-hastings acceptance test (gao and johnson, 2008).<papid> D08-1036 </papid></citsent>
<aftsection>
<nextsent>the metropolis-hastings step simplifies the sentence block particle filter further by notre quiring the conditional smc update.while there is already tractable dynamic programming approach to sampling an entire sentence based on the forward-backward algorithm, particle filtering the sentences pyp-hmm model should prove beneficial.
</nextsent>
<nextsent>for the trigram hmm defined by the model, the forward-backward sampling approach has time complexity in o(nt 3) for sentence of length with possible tag assignment sat each site.
</nextsent>
<nextsent>particle filters with particles can approximate these samples in o(ntp ) time, which 49becomes much faster as the number of tags, , increases.
</nextsent>
<nextsent>sampling of sentence begins by removing all of the transitions and emi tions in from the table counts, z, resulting in the table counts zs of tag assignments ts the values assigned to the variables outside of s. for each site index ? [1, ] in the sentence, the particle filter chooses the new tag assignment, ts,pn , for each particle ? [1, ] from the sentence proposal distribution, qsn (t s,p |t s,p 1:n1) ? (t s,p |t s,p n2, s,p n1, s , zs) ? (ws,pn |t s,p , s , zs ,ws).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1269">
<title id=" W12-1907.xml">unsupervised part of speech inference with particle filters </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>if the variance is too high, the sampler will be slower to converge.while additional particles lower the relative variance, they also increase the run time linearly.
</prevsent>
<prevsent>it is possible that there is threshold of particles necessary to ensure that some are high likelihood sequences, beyond which inference gains are minimal the additional computational expense is wasted.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
all of the experiments in this section were run on the arabic corpus from the conll-x shared language task, which is small enough to quickly experiment with these issues (buchholz and marsi, 2006).<papid> W06-2920 </papid></citsent>
<aftsection>
<nextsent>the sentence based sampler, sent, samples froma distribution that can be exactly computed, facilitating comparisons between the exact sampler and the smc approach.
</nextsent>
<nextsent>figure 5.1 compares the posterior log-likelihoods of the sent sampler and the exact sentence sampler over 200 iterations.
</nextsent>
<nextsent>as expected, the likelihoods of the particle filters approach that of the exact sentence sampler as the number of particles increases from 25 to 100, which completely overlaps the performance of the exact sampler by the 50th iteration.
</nextsent>
<nextsent>this is impressive, because even with 99 additional sequences sampled (one for each particle) each iteration the smc approach is still faster than the exact sampler.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1271">
<title id=" W12-1629.xml">using group history to identify character directed utterances in multi child interactions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>key problems include identifying when speech is present, who is producing it, andto whom it is directed, as well as producing an appropriate response to its intended meaning.
</prevsent>
<prevsent>solving these problems is made more difficult when some or all of the participants are young children, who have high variability in language, knowledge, and behavior.
</prevsent>
</prevsection>
<citsent citstr=" W09-3935 ">
prior research has tended to look at single children (oviatt, 2000; black et al, 2009) or multi person groups of adults (bohus and horvitz, 2009<papid> W09-3935 </papid>a).</citsent>
<aftsection>
<nextsent>we are interested in interactions between animated or robotic characters and small groups of four to ten year old children.
</nextsent>
<nextsent>the interaction can be brief but should be fun.here we focus specifically on the question of deciding whether or not childs utterance is directed to the character, binary form of the addressee identification (aid) problem.
</nextsent>
<nextsent>our broad goals inthis research are to understand how childrens behavior in group interaction with character differs from adults?, how controllable aspects of the character and physical environment determine participants?
</nextsent>
<nextsent>behavior, and how an autonomous character can take advantage of these regularities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1276">
<title id=" W12-1629.xml">using group history to identify character directed utterances in multi child interactions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>use of multimodal features rests on early work by duncan and fiske who explored how gaze andhead and body orientation act as important predictors of aid in human-human interactions (duncan and fiske, 1977).
</prevsent>
<prevsent>bakx and colleagues showed that accuracy can be improved by augmenting facial orientation with acoustic features in an agents interactions with an adult dyad (bakx et al, 2003).
</prevsent>
</prevsection>
<citsent citstr=" W11-2012 ">
others have studied the cues that people use to show their interest in engaging in conversation (gravano and hirschberg, 2009) and how gesture supports selection of the next speaker in turn-taking (bergmann et al, 2011).<papid> W11-2012 </papid></citsent>
<aftsection>
<nextsent>researchers have also looked at combining visual features with lexical features like the parse ability of the utterance (katzenmaier et al, 2004), the meaning of the utterance, fluency of speech, and use of politeness terms (terken et al, 2007), and the dialog act (matsusaka et al, 2007).
</nextsent>
<nextsent>however, all use hand-annotated data in their analysis without considering the difficulty of automatically deriving the features.
</nextsent>
<nextsent>finally, prosodic features have been combined with visual and lexical features in managing the order of speaking and predicting the end-of-turn in multi-party interactions (lunsford and oviatt, 2006; chen and harper, 2009; clemens and diekhaus, 2009).<papid> W09-3914 </papid></nextsent>
<nextsent>work modeling the temporal behavior of the speaker includes the use of adjacent utterances (e.g., question-answer) to study the dynamics of the dialog (jovanovic et al, 2006), <papid> E06-1022 </papid>the prediction of addressee based on the addressee and dialog acts in previous time steps (matsusaka et al, 2007), and the use ofthe speakers features over time to predict the quality of an interaction between robot and single adult (fasel et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1277">
<title id=" W12-1629.xml">using group history to identify character directed utterances in multi child interactions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>researchers have also looked at combining visual features with lexical features like the parse ability of the utterance (katzenmaier et al, 2004), the meaning of the utterance, fluency of speech, and use of politeness terms (terken et al, 2007), and the dialog act (matsusaka et al, 2007).
</prevsent>
<prevsent>however, all use hand-annotated data in their analysis without considering the difficulty of automatically deriving the features.
</prevsent>
</prevsection>
<citsent citstr=" W09-3914 ">
finally, prosodic features have been combined with visual and lexical features in managing the order of speaking and predicting the end-of-turn in multi-party interactions (lunsford and oviatt, 2006; chen and harper, 2009; clemens and diekhaus, 2009).<papid> W09-3914 </papid></citsent>
<aftsection>
<nextsent>work modeling the temporal behavior of the speaker includes the use of adjacent utterances (e.g., question-answer) to study the dynamics of the dialog (jovanovic et al, 2006), <papid> E06-1022 </papid>the prediction of addressee based on the addressee and dialog acts in previous time steps (matsusaka et al, 2007), and the use ofthe speakers features over time to predict the quality of an interaction between robot and single adult (fasel et al, 2009).</nextsent>
<nextsent>horvitz and bohus have the most complete (and deployed) model, combining multimodal features with temporal information using system for multiparty dynamic interaction between adults and an agent (bohus and horvitz, 2009<papid> W09-3935 </papid>a; bohus and horvitz, 2009<papid> W09-3935 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1278">
<title id=" W12-1629.xml">using group history to identify character directed utterances in multi child interactions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, all use hand-annotated data in their analysis without considering the difficulty of automatically deriving the features.
</prevsent>
<prevsent>finally, prosodic features have been combined with visual and lexical features in managing the order of speaking and predicting the end-of-turn in multi-party interactions (lunsford and oviatt, 2006; chen and harper, 2009; clemens and diekhaus, 2009).<papid> W09-3914 </papid></prevsent>
</prevsection>
<citsent citstr=" E06-1022 ">
work modeling the temporal behavior of the speaker includes the use of adjacent utterances (e.g., question-answer) to study the dynamics of the dialog (jovanovic et al, 2006), <papid> E06-1022 </papid>the prediction of addressee based on the addressee and dialog acts in previous time steps (matsusaka et al, 2007), and the use ofthe speakers features over time to predict the quality of an interaction between robot and single adult (fasel et al, 2009).</citsent>
<aftsection>
<nextsent>horvitz and bohus have the most complete (and deployed) model, combining multimodal features with temporal information using system for multiparty dynamic interaction between adults and an agent (bohus and horvitz, 2009<papid> W09-3935 </papid>a; bohus and horvitz, 2009<papid> W09-3935 </papid>b).</nextsent>
<nextsent>in (bohus and horvitz, 2009<papid> W09-3935 </papid>a) the authors describe the use of automatic sensors for voice detection, face detection, head position tracking, and utterance length.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1299">
<title id=" W12-0510.xml">coupling knowledge based and data driven systems for named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>named entity recognition (ner) is an information extraction (ie) task that aims at extracting and categorizing specific entities (proper names or dedicated linguistic units as time expressions,amounts, etc.) in texts.
</prevsent>
<prevsent>these texts can be produced in diverse conditions.
</prevsent>
</prevsection>
<citsent citstr=" M98-1002 ">
in particular, theymay correspond to either electronic written documents (marsh &amp; perzanowski, 1998) <papid> M98-1002 </papid>or more recently speech transcripts provided by human expert or an automatic speech recognition (asr)system (galliano et al, 2009).</citsent>
<aftsection>
<nextsent>the recognized entities may later be used by higher-level tasks for different purposes such as information retrieval or open-domain question-answering (voorhees &amp; harman, 2000).while ner is often considered as quite simple task, there is still room for improvement when it is confronted to difficult contexts.
</nextsent>
<nextsent>for instance, ner systems may have to cope with noisy data such as word sequences containing speech recognition errors in asr.
</nextsent>
<nextsent>in addition, ner is no more circumscribed to proper names, but may also involve common nouns (e.g., the judge?)
</nextsent>
<nextsent>or complex multi-word expressions (e.g. the computer science department of the new york uni versity?).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1300">
<title id=" W12-0510.xml">coupling knowledge based and data driven systems for named entity recognition </title>
<section> context and related work.  </section>
<citcontext>
<prevsection>
<prevsent>some of them handle deep syntactic analysis which has prove nits ability to reach outstanding levels of performances (brun &amp; hage`ge, 2004; brun &amp; hage`ge, 2009; van shooten et al, 2009).
</prevsent>
<prevsent>data-driven approaches large diversity ofdata-driven approaches have been proposed during the last decade for ner.
</prevsent>
</prevsection>
<citsent citstr=" M98-1009 ">
generative models such as hidden markov models or stochastic finite state transducers (miller et al, 1998; <papid> M98-1009 </papid>favre et al., 2005) <papid> H05-1062 </papid>benefit from their ability to take into account the sequential nature of language.</citsent>
<aftsection>
<nextsent>on the other hand, discriminative classifiers such as 70support vector machines (svms) are very effective when large variety of features (isozaki &amp; kazawa, 2002) <papid> C02-1054 </papid>is used, but lack the ability to take global decision over an entire sentence.</nextsent>
<nextsent>context random fields (crfs) (lafferty et al,2001) have enabled ner to benefit from the advantages of both generative and discriminative approaches (mccallum &amp; li, 2003; zidouni et al, 2010; bechet &amp; charton, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1301">
<title id=" W12-0510.xml">coupling knowledge based and data driven systems for named entity recognition </title>
<section> context and related work.  </section>
<citcontext>
<prevsection>
<prevsent>some of them handle deep syntactic analysis which has prove nits ability to reach outstanding levels of performances (brun &amp; hage`ge, 2004; brun &amp; hage`ge, 2009; van shooten et al, 2009).
</prevsent>
<prevsent>data-driven approaches large diversity ofdata-driven approaches have been proposed during the last decade for ner.
</prevsent>
</prevsection>
<citsent citstr=" H05-1062 ">
generative models such as hidden markov models or stochastic finite state transducers (miller et al, 1998; <papid> M98-1009 </papid>favre et al., 2005) <papid> H05-1062 </papid>benefit from their ability to take into account the sequential nature of language.</citsent>
<aftsection>
<nextsent>on the other hand, discriminative classifiers such as 70support vector machines (svms) are very effective when large variety of features (isozaki &amp; kazawa, 2002) <papid> C02-1054 </papid>is used, but lack the ability to take global decision over an entire sentence.</nextsent>
<nextsent>context random fields (crfs) (lafferty et al,2001) have enabled ner to benefit from the advantages of both generative and discriminative approaches (mccallum &amp; li, 2003; zidouni et al, 2010; bechet &amp; charton, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1302">
<title id=" W12-0510.xml">coupling knowledge based and data driven systems for named entity recognition </title>
<section> context and related work.  </section>
<citcontext>
<prevsection>
<prevsent>data-driven approaches large diversity ofdata-driven approaches have been proposed during the last decade for ner.
</prevsent>
<prevsent>generative models such as hidden markov models or stochastic finite state transducers (miller et al, 1998; <papid> M98-1009 </papid>favre et al., 2005) <papid> H05-1062 </papid>benefit from their ability to take into account the sequential nature of language.</prevsent>
</prevsection>
<citsent citstr=" C02-1054 ">
on the other hand, discriminative classifiers such as 70support vector machines (svms) are very effective when large variety of features (isozaki &amp; kazawa, 2002) <papid> C02-1054 </papid>is used, but lack the ability to take global decision over an entire sentence.</citsent>
<aftsection>
<nextsent>context random fields (crfs) (lafferty et al,2001) have enabled ner to benefit from the advantages of both generative and discriminative approaches (mccallum &amp; li, 2003; zidouni et al, 2010; bechet &amp; charton, 2010).
</nextsent>
<nextsent>besides, the robustness of data-driven / machine-learning approaches explains that the latter are more appropriate on noisy data such as asr transcripts.hybrid systems considering the complementary behaviors of knowledge-based and data driven systems for ner, projects have been conducted to investigate how to conciliate both approaches.
</nextsent>
<nextsent>work has been done to automatically induce symbolic knowledge (hingston, 2002; kushmerick et al, 1997) that may be used as ne taggers.
</nextsent>
<nextsent>but in most cases, hybridization for ner relies much simpler principle: outputs ofknowledge-based systems are considered as features by machine learning algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1303">
<title id=" W12-0510.xml">coupling knowledge based and data driven systems for named entity recognition </title>
<section> context and related work.  </section>
<citcontext>
<prevsection>
<prevsent>work has been done to automatically induce symbolic knowledge (hingston, 2002; kushmerick et al, 1997) that may be used as ne taggers.
</prevsent>
<prevsent>but in most cases, hybridization for ner relies much simpler principle: outputs ofknowledge-based systems are considered as features by machine learning algorithm.
</prevsent>
</prevsection>
<citsent citstr=" W98-1118 ">
for instance, maximum entropy may be used when high diversity of knowledge sources are to be taken into account (borthwick et al, 1998).<papid> W98-1118 </papid></citsent>
<aftsection>
<nextsent>crfs also have demonstrated their ability to merge symbolic and statistic processes in machine learning framework (zidouni et al, 2010).
</nextsent>
<nextsent>we propose an approach to combine knowledge-based and data-driven approaches in modular way.
</nextsent>
<nextsent>our first concern is to implement module that automatically extracts knowledge that should be interoperable with the existing systems transducers.
</nextsent>
<nextsent>this is done by focusing, in annotated corpora, more on markers?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1305">
<title id=" W12-0510.xml">coupling knowledge based and data driven systems for named entity recognition </title>
<section> casen: knowledge-based system.  </section>
<citcontext>
<prevsection>
<prevsent>and entity.pers.hum?).
</prevsent>
<prevsent>6.2 coupling strategies.
</prevsent>
</prevsection>
<citsent citstr=" P10-1052 ">
we report results for the following hybridizations and crf-based system using wapiti (lavergne et al., 2010).<papid> P10-1052 </papid></citsent>
<aftsection>
<nextsent>casen: knowledge-based system standalone ? mxs: min extract extracts, mstruct annotates?
</nextsent>
<nextsent>hybrid: gather features from casen and minex tract, mstruct annotates ? hybrid-sel: as hybrid, but features are selected?
</nextsent>
<nextsent>casen-mxs-mine: as mxs, but text is preprocessed by casen (adding higher generalization level above lexical lists)?
</nextsent>
<nextsent>mxs-casen-vote: as mxs, plus postprocessing step as majority vote based on mxs and casen outputs?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1306">
<title id=" W12-0304.xml">google books ngram corpus used as a grammar checker </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in order to evaluate the algorithm, we applied it to solve exercises from aspanish grammar book and also tested the detection of errors in corpus of real errors made by second language learners.the paper is organised as follows: we first offer brief description of related work, and then explain our methodology for each of the experiments.
</prevsent>
<prevsent>in the next section, we show the evaluation of the results in comparison to the microsoft word grammar checker and, finally, we draw some conclusions and discuss lines of future work.
</prevsent>
</prevsection>
<citsent citstr=" A88-1027 ">
rule-based grammar checking started in the 1980s and crystallised in the implementation of different tools: papers by macdonald (1983),heidorn et al (1982) or richardson and braden harder (1988) <papid> A88-1027 </papid>describe some of them (see leacock et al, 2010, for state of the art related to studies focused on language learning).</citsent>
<aftsection>
<nextsent>this approach has continued to be used until recently (see arppe, 2000; johannessen et al, 2002; <papid> C02-2010 </papid>andmany others) and is the basis of the work related with the popular grammar checker in microsoft word (different aspects of the tool are described in dolan et al, 1993; jensen et al, 1993; gamon et al, 1997 <papid> W97-0908 </papid>and heidorn, 2000:181-207, among others).</nextsent>
<nextsent>the knowledge-rich approach needs mechanisms to take into account errors within rigid system of rules, and thus different strategies were implemented to gain flexibility (weischedel and black, 1980; douglas and dale, 1992; <papid> C92-2072 </papid>schneider and mccoy, 1998 <papid> P98-2196 </papid>and others).bolt (1992) and kohut and gorman (1995) evaluated several grammar checkers available at the time and concluded that, in general, none of the proposed strategies achieved high percentages of success.there are reasons to believe that the limitations of rule-based methods could be overcome with statistical or knowledge-poor approaches, which started to be used for natural language processing in the late 1980s and 1990s.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1307">
<title id=" W12-0304.xml">google books ngram corpus used as a grammar checker </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the next section, we show the evaluation of the results in comparison to the microsoft word grammar checker and, finally, we draw some conclusions and discuss lines of future work.
</prevsent>
<prevsent>rule-based grammar checking started in the 1980s and crystallised in the implementation of different tools: papers by macdonald (1983),heidorn et al (1982) or richardson and braden harder (1988) <papid> A88-1027 </papid>describe some of them (see leacock et al, 2010, for state of the art related to studies focused on language learning).</prevsent>
</prevsection>
<citsent citstr=" C02-2010 ">
this approach has continued to be used until recently (see arppe, 2000; johannessen et al, 2002; <papid> C02-2010 </papid>andmany others) and is the basis of the work related with the popular grammar checker in microsoft word (different aspects of the tool are described in dolan et al, 1993; jensen et al, 1993; gamon et al, 1997 <papid> W97-0908 </papid>and heidorn, 2000:181-207, among others).</citsent>
<aftsection>
<nextsent>the knowledge-rich approach needs mechanisms to take into account errors within rigid system of rules, and thus different strategies were implemented to gain flexibility (weischedel and black, 1980; douglas and dale, 1992; <papid> C92-2072 </papid>schneider and mccoy, 1998 <papid> P98-2196 </papid>and others).bolt (1992) and kohut and gorman (1995) evaluated several grammar checkers available at the time and concluded that, in general, none of the proposed strategies achieved high percentages of success.there are reasons to believe that the limitations of rule-based methods could be overcome with statistical or knowledge-poor approaches, which started to be used for natural language processing in the late 1980s and 1990s.</nextsent>
<nextsent>atwell (1987) <papid> E87-1007 </papid>was among the first to use statistical and knowledge-poor approach to detect grammatical errors in pos-tagging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1308">
<title id=" W12-0304.xml">google books ngram corpus used as a grammar checker </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the next section, we show the evaluation of the results in comparison to the microsoft word grammar checker and, finally, we draw some conclusions and discuss lines of future work.
</prevsent>
<prevsent>rule-based grammar checking started in the 1980s and crystallised in the implementation of different tools: papers by macdonald (1983),heidorn et al (1982) or richardson and braden harder (1988) <papid> A88-1027 </papid>describe some of them (see leacock et al, 2010, for state of the art related to studies focused on language learning).</prevsent>
</prevsection>
<citsent citstr=" W97-0908 ">
this approach has continued to be used until recently (see arppe, 2000; johannessen et al, 2002; <papid> C02-2010 </papid>andmany others) and is the basis of the work related with the popular grammar checker in microsoft word (different aspects of the tool are described in dolan et al, 1993; jensen et al, 1993; gamon et al, 1997 <papid> W97-0908 </papid>and heidorn, 2000:181-207, among others).</citsent>
<aftsection>
<nextsent>the knowledge-rich approach needs mechanisms to take into account errors within rigid system of rules, and thus different strategies were implemented to gain flexibility (weischedel and black, 1980; douglas and dale, 1992; <papid> C92-2072 </papid>schneider and mccoy, 1998 <papid> P98-2196 </papid>and others).bolt (1992) and kohut and gorman (1995) evaluated several grammar checkers available at the time and concluded that, in general, none of the proposed strategies achieved high percentages of success.there are reasons to believe that the limitations of rule-based methods could be overcome with statistical or knowledge-poor approaches, which started to be used for natural language processing in the late 1980s and 1990s.</nextsent>
<nextsent>atwell (1987) <papid> E87-1007 </papid>was among the first to use statistical and knowledge-poor approach to detect grammatical errors in pos-tagging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1309">
<title id=" W12-0304.xml">google books ngram corpus used as a grammar checker </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>rule-based grammar checking started in the 1980s and crystallised in the implementation of different tools: papers by macdonald (1983),heidorn et al (1982) or richardson and braden harder (1988) <papid> A88-1027 </papid>describe some of them (see leacock et al, 2010, for state of the art related to studies focused on language learning).</prevsent>
<prevsent>this approach has continued to be used until recently (see arppe, 2000; johannessen et al, 2002; <papid> C02-2010 </papid>andmany others) and is the basis of the work related with the popular grammar checker in microsoft word (different aspects of the tool are described in dolan et al, 1993; jensen et al, 1993; gamon et al, 1997 <papid> W97-0908 </papid>and heidorn, 2000:181-207, among others).</prevsent>
</prevsection>
<citsent citstr=" C92-2072 ">
the knowledge-rich approach needs mechanisms to take into account errors within rigid system of rules, and thus different strategies were implemented to gain flexibility (weischedel and black, 1980; douglas and dale, 1992; <papid> C92-2072 </papid>schneider and mccoy, 1998 <papid> P98-2196 </papid>and others).bolt (1992) and kohut and gorman (1995) evaluated several grammar checkers available at the time and concluded that, in general, none of the proposed strategies achieved high percentages of success.there are reasons to believe that the limitations of rule-based methods could be overcome with statistical or knowledge-poor approaches, which started to be used for natural language processing in the late 1980s and 1990s.</citsent>
<aftsection>
<nextsent>atwell (1987) <papid> E87-1007 </papid>was among the first to use statistical and knowledge-poor approach to detect grammatical errors in pos-tagging.</nextsent>
<nextsent>other studies, such as those by knight and chandler (1994) orhan et al.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1310">
<title id=" W12-0304.xml">google books ngram corpus used as a grammar checker </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>rule-based grammar checking started in the 1980s and crystallised in the implementation of different tools: papers by macdonald (1983),heidorn et al (1982) or richardson and braden harder (1988) <papid> A88-1027 </papid>describe some of them (see leacock et al, 2010, for state of the art related to studies focused on language learning).</prevsent>
<prevsent>this approach has continued to be used until recently (see arppe, 2000; johannessen et al, 2002; <papid> C02-2010 </papid>andmany others) and is the basis of the work related with the popular grammar checker in microsoft word (different aspects of the tool are described in dolan et al, 1993; jensen et al, 1993; gamon et al, 1997 <papid> W97-0908 </papid>and heidorn, 2000:181-207, among others).</prevsent>
</prevsection>
<citsent citstr=" P98-2196 ">
the knowledge-rich approach needs mechanisms to take into account errors within rigid system of rules, and thus different strategies were implemented to gain flexibility (weischedel and black, 1980; douglas and dale, 1992; <papid> C92-2072 </papid>schneider and mccoy, 1998 <papid> P98-2196 </papid>and others).bolt (1992) and kohut and gorman (1995) evaluated several grammar checkers available at the time and concluded that, in general, none of the proposed strategies achieved high percentages of success.there are reasons to believe that the limitations of rule-based methods could be overcome with statistical or knowledge-poor approaches, which started to be used for natural language processing in the late 1980s and 1990s.</citsent>
<aftsection>
<nextsent>atwell (1987) <papid> E87-1007 </papid>was among the first to use statistical and knowledge-poor approach to detect grammatical errors in pos-tagging.</nextsent>
<nextsent>other studies, such as those by knight and chandler (1994) orhan et al.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1311">
<title id=" W12-0304.xml">google books ngram corpus used as a grammar checker </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this approach has continued to be used until recently (see arppe, 2000; johannessen et al, 2002; <papid> C02-2010 </papid>andmany others) and is the basis of the work related with the popular grammar checker in microsoft word (different aspects of the tool are described in dolan et al, 1993; jensen et al, 1993; gamon et al, 1997 <papid> W97-0908 </papid>and heidorn, 2000:181-207, among others).</prevsent>
<prevsent>the knowledge-rich approach needs mechanisms to take into account errors within rigid system of rules, and thus different strategies were implemented to gain flexibility (weischedel and black, 1980; douglas and dale, 1992; <papid> C92-2072 </papid>schneider and mccoy, 1998 <papid> P98-2196 </papid>and others).bolt (1992) and kohut and gorman (1995) evaluated several grammar checkers available at the time and concluded that, in general, none of the proposed strategies achieved high percentages of success.there are reasons to believe that the limitations of rule-based methods could be overcome with statistical or knowledge-poor approaches, which started to be used for natural language processing in the late 1980s and 1990s.</prevsent>
</prevsection>
<citsent citstr=" E87-1007 ">
atwell (1987) <papid> E87-1007 </papid>was among the first to use statistical and knowledge-poor approach to detect grammatical errors in pos-tagging.</citsent>
<aftsection>
<nextsent>other studies, such as those by knight and chandler (1994) orhan et al.
</nextsent>
<nextsent>(2006), for instance, proved more successful than rule-based systems in the task of detecting article-related errors.
</nextsent>
<nextsent>there are also other studies (yarowsky, 1994; <papid> P94-1013 </papid>golding, 1995 <papid> W95-0104 </papid>or golding androth, 1996) that report the application of decision lists and bayesian classifiers for spell check ing; however, these models cannot be applied to grammar error detection.</nextsent>
<nextsent>burstein et al (2004) present an idea similar to the present paper, since they use n-grams for grammar checking.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1312">
<title id=" W12-0304.xml">google books ngram corpus used as a grammar checker </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>other studies, such as those by knight and chandler (1994) orhan et al.
</prevsent>
<prevsent>(2006), for instance, proved more successful than rule-based systems in the task of detecting article-related errors.
</prevsent>
</prevsection>
<citsent citstr=" P94-1013 ">
there are also other studies (yarowsky, 1994; <papid> P94-1013 </papid>golding, 1995 <papid> W95-0104 </papid>or golding androth, 1996) that report the application of decision lists and bayesian classifiers for spell check ing; however, these models cannot be applied to grammar error detection.</citsent>
<aftsection>
<nextsent>burstein et al (2004) present an idea similar to the present paper, since they use n-grams for grammar checking.
</nextsent>
<nextsent>in their case, however, the model is much more complicated since it uses machine learning approach trained on corpus of correct english and usingpos-tags bigrams as features apart from word bi grams.
</nextsent>
<nextsent>in addition, they use series of statistical association measures instead of using plain frequency.
</nextsent>
<nextsent>other proposals of similar nature are those which use the web as corpus (more?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1313">
<title id=" W12-0304.xml">google books ngram corpus used as a grammar checker </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>other studies, such as those by knight and chandler (1994) orhan et al.
</prevsent>
<prevsent>(2006), for instance, proved more successful than rule-based systems in the task of detecting article-related errors.
</prevsent>
</prevsection>
<citsent citstr=" W95-0104 ">
there are also other studies (yarowsky, 1994; <papid> P94-1013 </papid>golding, 1995 <papid> W95-0104 </papid>or golding androth, 1996) that report the application of decision lists and bayesian classifiers for spell check ing; however, these models cannot be applied to grammar error detection.</citsent>
<aftsection>
<nextsent>burstein et al (2004) present an idea similar to the present paper, since they use n-grams for grammar checking.
</nextsent>
<nextsent>in their case, however, the model is much more complicated since it uses machine learning approach trained on corpus of correct english and usingpos-tags bigrams as features apart from word bi grams.
</nextsent>
<nextsent>in addition, they use series of statistical association measures instead of using plain frequency.
</nextsent>
<nextsent>other proposals of similar nature are those which use the web as corpus (more?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1314">
<title id=" W12-0304.xml">google books ngram corpus used as a grammar checker </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, they use series of statistical association measures instead of using plain frequency.
</prevsent>
<prevsent>other proposals of similar nature are those which use the web as corpus (more?
</prevsent>
</prevsection>
<citsent citstr=" D09-1093 ">
et al,2004; yin et al, 2008; whitelaw et al, 2009), <papid> D09-1093 </papid>although the majority of these authors also apply different degrees of processing of the input text,such as lemmatisation, pos-tagging and chunk ing.</citsent>
<aftsection>
<nextsent>whitelaw et al (2009), <papid> D09-1093 </papid>working on spell checking, are among the few who disregard explicit linguistic knowledge.</nextsent>
<nextsent>sjobergh (2009) attempted similar approach for grammar checking in swedish, but with modest results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1316">
<title id=" W11-2129.xml">productive generation of compound words in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>stymne(2008) suggested merging method based on part of-speech matching, in factored translation system, where compound parts had special part-of-speech tag, and compound parts are only merged with thenext word if the part-of-speech tags match.
</prevsent>
<prevsent>this resulted in improved translation quality from english to german, and from english to swedish (stymne and holmqvist, 2008).
</prevsent>
</prevsection>
<citsent citstr=" W09-0420 ">
another method, based on several decoding runs, was investigated by fraser (2009).<papid> W09-0420 </papid>stymne (2009<papid> E09-3008 </papid>a) investigated and compared merging methods inspired by popovic?</citsent>
<aftsection>
<nextsent>et al (2006),stymne (2008) and method inspired by morphology merging (el-kahlout and oflazer, 2006; virpioja et al, 2007), where compound parts were annotated with symbols, and parts with symbols in the translation output were merged with the next word.
</nextsent>
<nextsent>if compounds are split in the training set, then there is no guarantee that translations of components willend up in contiguous positions and in the correct order.
</nextsent>
<nextsent>this is primarily language model problem,and we will model it as such by applying pos language models on specially designed part-of-speech sets, and by applying language model inspired count features.
</nextsent>
<nextsent>the approach proposed in stymne (2008) consist sin running pos tagger on the target side of the corpus, decompose only tokens with some predefined pos (e.g. nouns), and then marking with specialpos-tags whether an element is head or modifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1317">
<title id=" W11-2129.xml">productive generation of compound words in statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>stymne(2008) suggested merging method based on part of-speech matching, in factored translation system, where compound parts had special part-of-speech tag, and compound parts are only merged with thenext word if the part-of-speech tags match.
</prevsent>
<prevsent>this resulted in improved translation quality from english to german, and from english to swedish (stymne and holmqvist, 2008).
</prevsent>
</prevsection>
<citsent citstr=" E09-3008 ">
another method, based on several decoding runs, was investigated by fraser (2009).<papid> W09-0420 </papid>stymne (2009<papid> E09-3008 </papid>a) investigated and compared merging methods inspired by popovic?</citsent>
<aftsection>
<nextsent>et al (2006),stymne (2008) and method inspired by morphology merging (el-kahlout and oflazer, 2006; virpioja et al, 2007), where compound parts were annotated with symbols, and parts with symbols in the translation output were merged with the next word.
</nextsent>
<nextsent>if compounds are split in the training set, then there is no guarantee that translations of components willend up in contiguous positions and in the correct order.
</nextsent>
<nextsent>this is primarily language model problem,and we will model it as such by applying pos language models on specially designed part-of-speech sets, and by applying language model inspired count features.
</nextsent>
<nextsent>the approach proposed in stymne (2008) consist sin running pos tagger on the target side of the corpus, decompose only tokens with some predefined pos (e.g. nouns), and then marking with specialpos-tags whether an element is head or modifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1319">
<title id=" W11-2129.xml">productive generation of compound words in statistical machine translation </title>
<section> merging compounds.  </section>
<citcontext>
<prevsection>
<prevsent>and (languages?,sprachen?), then the translation model from english into decomposed-german could be able to produce: europa sollte fremd sprachen kenntnisse fordern we cast the problem of merging compounds as one of making series of correlated binary decisions,one for each pair of consecutive words, each deciding whether the whit espace between the two words should be suppressed (label 1?) or not (label 0?).in the case above, the correct labelling for the sentence would be {0,0,1,1,0}, reconstructing the correct german: europa sollte fremdsprachenkenntnisse fordern1 if conversely, components are normalized upon splitting, then labels are no longer binary, but come from set describing all local orthographic transformations possible for the language under consideration.
</prevsent>
<prevsent>in this work we limited our attention to the case when compounds are not normalized upon splitting, and labels are hence binary.
</prevsent>
</prevsection>
<citsent citstr=" W02-1001 ">
while in principle one could address each atomic merging decision independently, it seems intuitive that decision taken at one point should influence merging decisions in neighboring separation points.for this reason, instead of simple (binary or nary) classification problem, we prefer sequence labelling formulation.the array of sequence labelling algorithms potentially suitable to our problem is fairly broad, including hidden markov models (hmms) (rabiner, 1989), conditional random fields (crfs) (lafferty et al, 2001), structured perceptrons (collins, 2002), <papid> W02-1001 </papid>1nouns in german are capitalized.</citsent>
<aftsection>
<nextsent>this is normally dealt as further truecasing?
</nextsent>
<nextsent>postprocessing, and is an orthogonal problem from the one we deal with here.
</nextsent>
<nextsent>and more.
</nextsent>
<nextsent>since the focus of this work is on the application rather than on comparison among alternative structured learning approaches, we limited ourselves to single implementation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1320">
<title id=" W11-2129.xml">productive generation of compound words in statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>nevertheless they are substantially more similar to what will be observed in operations than the reference translations.
</prevsent>
<prevsent>we performed experiments on translation from english into swedish and danish on two different corpora, an automotive corpus collected from proprietary translation memory, and on europarl (koehn,2005) for the merging experiments.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
we used factored translation (koehn and hoang, 2007), <papid> D07-1091 </papid>with both surface words and part-of-speech tags on the 254 eu-sv auto-sv auto-da corpus europarl automotive automotive languages english swedish english swedish english danish compounds split n, v, adj n, v, adj pos tag-sets pos pos,rpos rpos decoder moses in-house in-house training sentences smt 1,520,549 329,090 168,047 training words smt (target) 34,282,247 3,061,282 1,553,382 training sentences crf 248,808 317,398 164,702 extra training sentences crf 3,000 3,000 163,201 table 2: overview of the experimental settings target side, with sequence model on part-of speech.</citsent>
<aftsection>
<nextsent>we used two decoders, matrax (simard etal., 2005) <papid> H05-1095 </papid>and moses (koehn et al, 2007), <papid> P07-2045 </papid>both standard statistical phrase based decoders.</nextsent>
<nextsent>for parameter optimization we used minimum error rate training (och, 2003) <papid> P03-1021 </papid>with moses and gradient ascent on smoothed nist for the in-house decoder.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1321">
<title id=" W11-2129.xml">productive generation of compound words in statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we performed experiments on translation from english into swedish and danish on two different corpora, an automotive corpus collected from proprietary translation memory, and on europarl (koehn,2005) for the merging experiments.
</prevsent>
<prevsent>we used factored translation (koehn and hoang, 2007), <papid> D07-1091 </papid>with both surface words and part-of-speech tags on the 254 eu-sv auto-sv auto-da corpus europarl automotive automotive languages english swedish english swedish english danish compounds split n, v, adj n, v, adj pos tag-sets pos pos,rpos rpos decoder moses in-house in-house training sentences smt 1,520,549 329,090 168,047 training words smt (target) 34,282,247 3,061,282 1,553,382 training sentences crf 248,808 317,398 164,702 extra training sentences crf 3,000 3,000 163,201 table 2: overview of the experimental settings target side, with sequence model on part-of speech.</prevsent>
</prevsection>
<citsent citstr=" H05-1095 ">
we used two decoders, matrax (simard etal., 2005) <papid> H05-1095 </papid>and moses (koehn et al, 2007), <papid> P07-2045 </papid>both standard statistical phrase based decoders.</citsent>
<aftsection>
<nextsent>for parameter optimization we used minimum error rate training (och, 2003) <papid> P03-1021 </papid>with moses and gradient ascent on smoothed nist for the in-house decoder.</nextsent>
<nextsent>in the merging experiments we used the crf++ toolkit.2 compounds were split before training using corpus-based method (koehn and knight, 2003;<papid> E03-1076 </papid>stymne, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1322">
<title id=" W11-2129.xml">productive generation of compound words in statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we performed experiments on translation from english into swedish and danish on two different corpora, an automotive corpus collected from proprietary translation memory, and on europarl (koehn,2005) for the merging experiments.
</prevsent>
<prevsent>we used factored translation (koehn and hoang, 2007), <papid> D07-1091 </papid>with both surface words and part-of-speech tags on the 254 eu-sv auto-sv auto-da corpus europarl automotive automotive languages english swedish english swedish english danish compounds split n, v, adj n, v, adj pos tag-sets pos pos,rpos rpos decoder moses in-house in-house training sentences smt 1,520,549 329,090 168,047 training words smt (target) 34,282,247 3,061,282 1,553,382 training sentences crf 248,808 317,398 164,702 extra training sentences crf 3,000 3,000 163,201 table 2: overview of the experimental settings target side, with sequence model on part-of speech.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we used two decoders, matrax (simard etal., 2005) <papid> H05-1095 </papid>and moses (koehn et al, 2007), <papid> P07-2045 </papid>both standard statistical phrase based decoders.</citsent>
<aftsection>
<nextsent>for parameter optimization we used minimum error rate training (och, 2003) <papid> P03-1021 </papid>with moses and gradient ascent on smoothed nist for the in-house decoder.</nextsent>
<nextsent>in the merging experiments we used the crf++ toolkit.2 compounds were split before training using corpus-based method (koehn and knight, 2003;<papid> E03-1076 </papid>stymne, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1323">
<title id=" W11-2129.xml">productive generation of compound words in statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we used factored translation (koehn and hoang, 2007), <papid> D07-1091 </papid>with both surface words and part-of-speech tags on the 254 eu-sv auto-sv auto-da corpus europarl automotive automotive languages english swedish english swedish english danish compounds split n, v, adj n, v, adj pos tag-sets pos pos,rpos rpos decoder moses in-house in-house training sentences smt 1,520,549 329,090 168,047 training words smt (target) 34,282,247 3,061,282 1,553,382 training sentences crf 248,808 317,398 164,702 extra training sentences crf 3,000 3,000 163,201 table 2: overview of the experimental settings target side, with sequence model on part-of speech.</prevsent>
<prevsent>we used two decoders, matrax (simard etal., 2005) <papid> H05-1095 </papid>and moses (koehn et al, 2007), <papid> P07-2045 </papid>both standard statistical phrase based decoders.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
for parameter optimization we used minimum error rate training (och, 2003) <papid> P03-1021 </papid>with moses and gradient ascent on smoothed nist for the in-house decoder.</citsent>
<aftsection>
<nextsent>in the merging experiments we used the crf++ toolkit.2 compounds were split before training using corpus-based method (koehn and knight, 2003;<papid> E03-1076 </papid>stymne, 2008).</nextsent>
<nextsent>for each word we explored all possible segment ations into parts that had at least 3 characters, and choose the segmentation which had the highest arithmetic mean of frequencies for each part in the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1324">
<title id=" W11-2129.xml">productive generation of compound words in statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we used two decoders, matrax (simard etal., 2005) <papid> H05-1095 </papid>and moses (koehn et al, 2007), <papid> P07-2045 </papid>both standard statistical phrase based decoders.</prevsent>
<prevsent>for parameter optimization we used minimum error rate training (och, 2003) <papid> P03-1021 </papid>with moses and gradient ascent on smoothed nist for the in-house decoder.</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
in the merging experiments we used the crf++ toolkit.2 compounds were split before training using corpus-based method (koehn and knight, 2003;<papid> E03-1076 </papid>stymne, 2008).</citsent>
<aftsection>
<nextsent>for each word we explored all possible segment ations into parts that had at least 3 characters, and choose the segmentation which had the highest arithmetic mean of frequencies for each part in the training corpus.
</nextsent>
<nextsent>we constrained the splitting based on part-of-speech by only allowing splitting options where the compound head had the same tag as the full word.
</nextsent>
<nextsent>the split compound parts kept their form, which can be special to compounds, and no symbols or other markup were added.
</nextsent>
<nextsent>the experiment setup is summarized in table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1325">
<title id=" W11-2129.xml">productive generation of compound words in statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for danish we only split nouns, andused the restricted pos-set.
</prevsent>
<prevsent>for frequency calculations of compounds and compound parts that were needed for compound splitting and some of the com 2available at http://crfpp.sourceforge.net/ pound merging strategies, we used the respective training data in all cases.
</prevsent>
</prevsection>
<citsent citstr=" W05-0908 ">
significance testing was performed using approximate randomization (rie zler and maxwell, 2005), <papid> W05-0908 </papid>with 10,000 iterations, and ?   0.05.</citsent>
<aftsection>
<nextsent>5.1 experiments: promoting compound.
</nextsent>
<nextsent>coalescence we performed experiments with factored translation models with the restricted part-of-speech set on the danish and swedish automotive corpus.
</nextsent>
<nextsent>in these experiments we compared the restricted part-of-speechset we suggest in this work to several baseline systems without any compound processing and with factored models using the extended part-of-speech set suggested by stymne (2008).
</nextsent>
<nextsent>compound parts were merged using the pos-based heuristic.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1326">
<title id=" W11-2129.xml">productive generation of compound words in statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in these experiments we compared the restricted part-of-speechset we suggest in this work to several baseline systems without any compound processing and with factored models using the extended part-of-speech set suggested by stymne (2008).
</prevsent>
<prevsent>compound parts were merged using the pos-based heuristic.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
results are reported on two standard metrics, nist (dod dington, 2002) and bleu (papineni et al, 2002), <papid> P02-1040 </papid>on lower-cased data.</citsent>
<aftsection>
<nextsent>for all sequence models we use 3-grams.results on the two automotive corpora are summarized in table 3.
</nextsent>
<nextsent>the scores are very high, which is due to the fact that it is an easy domain with many repetitive sentence types.
</nextsent>
<nextsent>on the danish dataset, we observe significant improvements in bleu andnist over the baseline for all methods where compounds were split before translation and merged afterwards.
</nextsent>
<nextsent>some of the gain is already obtained using language model on the extended part-of-speechset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1327">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we study an alternative approach based on similarity measures.these methods do not return type of the relation between words (r? ? ? c).
</prevsent>
<prevsent>however, we assume that the methods should retrieve mix of synonyms, hypernyms, and co-hyponyms for practical use in text processing applications and evaluate them accordingly.a multitude of measures was used in the previous research to extract synonyms, hypernyms, and co-hyponyms.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
five key approaches are those based on distributional analysis (lin, 1998<papid> P98-2127 </papid>b), web as corpus (cilibrasi and vitanyi, 2007), lexico-syntactic patterns (bollegala et al, 2007),semantic networks (resnik, 1995), and definitions of dictionaries or encyclopedias (zesch et al., 2008<papid> L08-1139 </papid>a).</citsent>
<aftsection>
<nextsent>still, the existing approaches based on these single measures are far from being perfect.
</nextsent>
<nextsent>for instance, curran and moens (2002) <papid> W02-0908 </papid>compared distributional measures and reported precision@1of 76% for the best one.</nextsent>
<nextsent>for improving the performance, some attempts were made to combine single measures, such as (curran, 2002; <papid> W02-1029 </papid>cederberg and widdows, 2003; <papid> W03-0415 </papid>mihalcea et al, 2006;agirre et al, 2009; yang and callan, 2009).<papid> P09-1031 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1329">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we study an alternative approach based on similarity measures.these methods do not return type of the relation between words (r? ? ? c).
</prevsent>
<prevsent>however, we assume that the methods should retrieve mix of synonyms, hypernyms, and co-hyponyms for practical use in text processing applications and evaluate them accordingly.a multitude of measures was used in the previous research to extract synonyms, hypernyms, and co-hyponyms.
</prevsent>
</prevsection>
<citsent citstr=" L08-1139 ">
five key approaches are those based on distributional analysis (lin, 1998<papid> P98-2127 </papid>b), web as corpus (cilibrasi and vitanyi, 2007), lexico-syntactic patterns (bollegala et al, 2007),semantic networks (resnik, 1995), and definitions of dictionaries or encyclopedias (zesch et al., 2008<papid> L08-1139 </papid>a).</citsent>
<aftsection>
<nextsent>still, the existing approaches based on these single measures are far from being perfect.
</nextsent>
<nextsent>for instance, curran and moens (2002) <papid> W02-0908 </papid>compared distributional measures and reported precision@1of 76% for the best one.</nextsent>
<nextsent>for improving the performance, some attempts were made to combine single measures, such as (curran, 2002; <papid> W02-1029 </papid>cederberg and widdows, 2003; <papid> W03-0415 </papid>mihalcea et al, 2006;agirre et al, 2009; yang and callan, 2009).<papid> P09-1031 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1330">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>five key approaches are those based on distributional analysis (lin, 1998<papid> P98-2127 </papid>b), web as corpus (cilibrasi and vitanyi, 2007), lexico-syntactic patterns (bollegala et al, 2007),semantic networks (resnik, 1995), and definitions of dictionaries or encyclopedias (zesch et al., 2008<papid> L08-1139 </papid>a).</prevsent>
<prevsent>still, the existing approaches based on these single measures are far from being perfect.</prevsent>
</prevsection>
<citsent citstr=" W02-0908 ">
for instance, curran and moens (2002) <papid> W02-0908 </papid>compared distributional measures and reported precision@1of 76% for the best one.</citsent>
<aftsection>
<nextsent>for improving the performance, some attempts were made to combine single measures, such as (curran, 2002; <papid> W02-1029 </papid>cederberg and widdows, 2003; <papid> W03-0415 </papid>mihalcea et al, 2006;agirre et al, 2009; yang and callan, 2009).<papid> P09-1031 </papid></nextsent>
<nextsent>how ever, most studies are still not taking into account the whole range of existing measures, combining mostly sporadically different methods.the main contribution of the paper is systematic analysis of 16 baseline measures, and their combinations with 8 fusion methods and 3 techniques for the combination set selection.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1331">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>still, the existing approaches based on these single measures are far from being perfect.
</prevsent>
<prevsent>for instance, curran and moens (2002) <papid> W02-0908 </papid>compared distributional measures and reported precision@1of 76% for the best one.</prevsent>
</prevsection>
<citsent citstr=" W02-1029 ">
for improving the performance, some attempts were made to combine single measures, such as (curran, 2002; <papid> W02-1029 </papid>cederberg and widdows, 2003; <papid> W03-0415 </papid>mihalcea et al, 2006;agirre et al, 2009; yang and callan, 2009).<papid> P09-1031 </papid></citsent>
<aftsection>
<nextsent>how ever, most studies are still not taking into account the whole range of existing measures, combining mostly sporadically different methods.the main contribution of the paper is systematic analysis of 16 baseline measures, and their combinations with 8 fusion methods and 3 techniques for the combination set selection.
</nextsent>
<nextsent>we are first to propose hybrid similarity measures based on all five extraction approaches listed above; our combined techniques are original as they exploit all key types of resources usable for semantic relation extraction ? corpus, web corpus, semantic networks, dictionaries, and encyclopedias.
</nextsent>
<nextsent>our experiments confirm that the combined measures are more precise than the single ones.
</nextsent>
<nextsent>the best found hybrid measure combines 15 baseline measures with the supervised learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1332">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>still, the existing approaches based on these single measures are far from being perfect.
</prevsent>
<prevsent>for instance, curran and moens (2002) <papid> W02-0908 </papid>compared distributional measures and reported precision@1of 76% for the best one.</prevsent>
</prevsection>
<citsent citstr=" W03-0415 ">
for improving the performance, some attempts were made to combine single measures, such as (curran, 2002; <papid> W02-1029 </papid>cederberg and widdows, 2003; <papid> W03-0415 </papid>mihalcea et al, 2006;agirre et al, 2009; yang and callan, 2009).<papid> P09-1031 </papid></citsent>
<aftsection>
<nextsent>how ever, most studies are still not taking into account the whole range of existing measures, combining mostly sporadically different methods.the main contribution of the paper is systematic analysis of 16 baseline measures, and their combinations with 8 fusion methods and 3 techniques for the combination set selection.
</nextsent>
<nextsent>we are first to propose hybrid similarity measures based on all five extraction approaches listed above; our combined techniques are original as they exploit all key types of resources usable for semantic relation extraction ? corpus, web corpus, semantic networks, dictionaries, and encyclopedias.
</nextsent>
<nextsent>our experiments confirm that the combined measures are more precise than the single ones.
</nextsent>
<nextsent>the best found hybrid measure combines 15 baseline measures with the supervised learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1333">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>still, the existing approaches based on these single measures are far from being perfect.
</prevsent>
<prevsent>for instance, curran and moens (2002) <papid> W02-0908 </papid>compared distributional measures and reported precision@1of 76% for the best one.</prevsent>
</prevsection>
<citsent citstr=" P09-1031 ">
for improving the performance, some attempts were made to combine single measures, such as (curran, 2002; <papid> W02-1029 </papid>cederberg and widdows, 2003; <papid> W03-0415 </papid>mihalcea et al, 2006;agirre et al, 2009; yang and callan, 2009).<papid> P09-1031 </papid></citsent>
<aftsection>
<nextsent>how ever, most studies are still not taking into account the whole range of existing measures, combining mostly sporadically different methods.the main contribution of the paper is systematic analysis of 16 baseline measures, and their combinations with 8 fusion methods and 3 techniques for the combination set selection.
</nextsent>
<nextsent>we are first to propose hybrid similarity measures based on all five extraction approaches listed above; our combined techniques are original as they exploit all key types of resources usable for semantic relation extraction ? corpus, web corpus, semantic networks, dictionaries, and encyclopedias.
</nextsent>
<nextsent>our experiments confirm that the combined measures are more precise than the single ones.
</nextsent>
<nextsent>the best found hybrid measure combines 15 baseline measures with the supervised learning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1334">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> single similarity measures.  </section>
<citcontext>
<prevsection>
<prevsent>the measures were selected as (a) the previous research suggests that they are able to capture synonyms, hypernyms, and co-hyponyms; (b) they relyon all main resources used to derive semantic similarity ? semantic networks, web as corpus, traditional corpora, dictionaries, and encyclopedia.
</prevsent>
<prevsent>3.1 measures based on semantic network.
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
we test 5 measures relying on wordnet semantic network (miller, 1995) to calculate the simi larities: wu and palmer (1994) (<papid> P94-1019 </papid>1), leacock and chodorow (1998) (2), resnik (1995) (3), jiang and conrath (1997) (4), and lin (1998<papid> P98-2127 </papid>a) (5).these measures exploit the lengths of the shortest paths between terms in network and probability of terms derived from corpus.</citsent>
<aftsection>
<nextsent>we use implementation of the measures available in word net::similarity (pedersen et al, 2004).<papid> N04-3012 </papid>a limitation of these measures is that similarities can only be calculated upon 155.287 english terms from wordnet 3.0.</nextsent>
<nextsent>in other words, these measures recall rather than extract similarities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1336">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> single similarity measures.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 measures based on semantic network.
</prevsent>
<prevsent>we test 5 measures relying on wordnet semantic network (miller, 1995) to calculate the simi larities: wu and palmer (1994) (<papid> P94-1019 </papid>1), leacock and chodorow (1998) (2), resnik (1995) (3), jiang and conrath (1997) (4), and lin (1998<papid> P98-2127 </papid>a) (5).these measures exploit the lengths of the shortest paths between terms in network and probability of terms derived from corpus.</prevsent>
</prevsection>
<citsent citstr=" N04-3012 ">
we use implementation of the measures available in word net::similarity (pedersen et al, 2004).<papid> N04-3012 </papid>a limitation of these measures is that similarities can only be calculated upon 155.287 english terms from wordnet 3.0.</citsent>
<aftsection>
<nextsent>in other words, these measures recall rather than extract similarities.
</nextsent>
<nextsent>therefore, they should be considered as source of common lexico-semantic knowledge for hybrid semantic similarity measure.
</nextsent>
<nextsent>3.2 web-based measures.
</nextsent>
<nextsent>web-based metrics use web search engines for calculation of similarities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1339">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> single similarity measures.  </section>
<citcontext>
<prevsection>
<prevsent>next, we select the con cor dances which contain at least two terms from the input vocabulary c. the semantic similarity sij between each two terms ci, cj ? is equal to the number of their co-occurences in the same concordance.
</prevsent>
<prevsent>the set of the patterns we used is compilation 2available at http://http://cental.fltr.ucl.ac.
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
be/team/morozova/pattern-wiki.tar.gz of the 6 classical hearst (1992) <papid> C92-2082 </papid>patterns, aiming at the extraction of hypernymic relations, as well as 3 patterns retrieving some other hypernyms and co-hyponyms and 1 synonym extraction pattern,which we found in accordance with hearsts pattern discovery algorithm.</citsent>
<aftsection>
<nextsent>the patterns are encoded in form of finite-state transducers with thehelp of corpus processing tool unitex 3 (pau mier, 2003).
</nextsent>
<nextsent>the main graph is cascade of the subgraphs, each of which encodes one of the patterns.
</nextsent>
<nextsent>for example, figure 2 presents the graph which extracts, e. g.: ? such diverse {[occupations]} as {[doctors]}, {[engineers]} and {[scientists]}[pattern=1] figure brackets mark the noun phrases, which are in the semantic relation, nouns and compound nouns stand between the square brackets.
</nextsent>
<nextsent>unitex enables the exclusion of meaningless adjectives and determiners out of the tagging, while the patterns containing them are still being recognized.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1345">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> single similarity measures.  </section>
<citcontext>
<prevsection>
<prevsent>the highest similarity score is assigned to the pairs of terms which are directly related in wiktionary.
</prevsent>
<prevsent>5 wktwiki is different to the work of zesch et al (2008<papid> L08-1139 </papid>b) in three aspects: (a) terms are represented in word space, and not in document space; (b) both texts from wiktionary and wikipedia areused; (c) relations of wiktionary are used to up date similarity scores.</prevsent>
</prevsection>
<citsent citstr=" W06-2501 ">
in addition to wktwiki, we operate with 2 baseline measures relying on wordnet glosses available in wordnet::similarity package: gloss vectors (patwardhan and pedersen, 2006) <papid> W06-2501 </papid>5we used jwktl library (zesch et al, 2008<papid> L08-1139 </papid>a), as an api towiktionary and dbpedia.org as source of wikipedia short abstracts (dumps were downloaded in october 2011).</citsent>
<aftsection>
<nextsent>(15) and extended lesk (banerjee and pedersen, 2003) (16).
</nextsent>
<nextsent>the key difference between wktwiki and wordnet-based measures is that the latter uses definitions of related terms.extraction capabilities of definition-based measures are limited by the number of available definitions.
</nextsent>
<nextsent>as of october 2011, wordnet contains 117.659 definitions (glosses); wiktionary contains 536.594 definitions in english and 4.272.902 definitions in all languages; wikipedia has 3.866.773 english articles and around 20.8 millons of articles in all languages.
</nextsent>
<nextsent>a hybrid similarity measure combines several single similarity measures described above with one of the combination methods described below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1347">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>each target?
</prevsent>
<prevsent>term has roughly the same number of meaningful and random relations.
</prevsent>
</prevsection>
<citsent citstr=" W11-2501 ">
we use two semantic relation datasets: bless (baroni and lenci, 2011) <papid> W11-2501 </papid>andsn.</citsent>
<aftsection>
<nextsent>the first is used to assess hypernyms and co hyponyms extraction.
</nextsent>
<nextsent>bless relates 200 target terms (100 animate and 100 inanimate nouns) to 8625 relatum terms with 26554 semantic relations (14440 are meaningful and 12154 are random).every relation has one of the following types: hy pernym, co-hyponym, meronym, attribute, event,or random.
</nextsent>
<nextsent>we use the second dataset to evaluate synonymy extraction.
</nextsent>
<nextsent>sn relates 462 target terms (nouns) to 5910 relatum terms with 14682 semantic relations (7341 are meaningful and 7341 are random).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1348">
<title id=" W12-0502.xml">a study of hybrid similarity measures for semantic relation extraction </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>present in wordnet and dictionaries, and empowers calculation of relations between rare terms unlisted in the handcrafted resources (e. g., bronchocele?)
</prevsent>
<prevsent>with web and corpus measures.
</prevsent>
</prevsection>
<citsent citstr=" L08-1204 ">
second, combinations work well because, as it was found in previous research (sahlgren, 2006; heylen et al, 2008), <papid> L08-1204 </papid>different measures provide complementary types of semantic relations.</citsent>
<aftsection>
<nextsent>for instance, wordnet-based measures score higherhypernyms than associative relations; distributional analysis score high co-hyponyms and synonyms, etc. in that respect, combination helps to recall more different relations.
</nextsent>
<nextsent>for example, wordnet-based measure may return hypernym salmon, seafood?, while corpus-based measure would extract co-hyponym salmon, mackerel?.
</nextsent>
<nextsent>finally, the supervised combination method works better than unsupervised ones because of two reasons.
</nextsent>
<nextsent>first, the measures generate scores which have quite different distributions on the range [0; 1].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1349">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the main attraction of these methods is that they can learn model using only unlabeled data.
</prevsent>
<prevsent>this isan important advantage, as unlabeled text in digital form is in abundance, while labeled datasets are usually expensive to construct.
</prevsent>
</prevsection>
<citsent citstr=" D08-1027 ">
while methods suchas crowdsourcing (snow et al, 2008) <papid> D08-1027 </papid>can help reduce this cost, in tasks for which specialist knowledge is required, such as part-of-speech (pos) tagging or syntactic parsing, labeling datasets in this fashion can be substantially harder.nevertheless, the advantage of requiring only unlabeled data to learn model renders the evaluation of unsupervised learning methods to be more challenging than that of their supervised counterparts.</citsent>
<aftsection>
<nextsent>this is primarily because the output of unsupervised methods does not contain labels that would be foundin manually constructed gold standard.
</nextsent>
<nextsent>simplistically expressed, no labels for model learning means that there are no labels in the output.
</nextsent>
<nextsent>as result, the standard evaluation paradigm of comparing against gold standard using performance measure such as accuracy or f-score cannot be used, at least not in the way it would be used in evaluating supervised methods.
</nextsent>
<nextsent>since methods are proposed or rejected by researchers, and papers describing these methods are assessed by their peers partly on the basis of such results, the issue of evaluation is an important one.before we proceed, it is important to characterize the unsupervised learning methods we are considering, as the term unsupervised is used in multiple ways in the literature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1350">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since methods are proposed or rejected by researchers, and papers describing these methods are assessed by their peers partly on the basis of such results, the issue of evaluation is an important one.before we proceed, it is important to characterize the unsupervised learning methods we are considering, as the term unsupervised is used in multiple ways in the literature.
</prevsent>
<prevsent>in this work we focus on methods that use only unlabeled data to learn model and do not involve any form of supervision at any stage.
</prevsent>
</prevsection>
<citsent citstr=" P09-1057 ">
thus we exclude methods that use seeds such as the dictionaries of pos tags used by ravi and knight (2009) <papid> P09-1057 </papid>and rules for producing labeled out put, e.g. those proposed by teichert and daume?</citsent>
<aftsection>
<nextsent>iii (2009).
</nextsent>
<nextsent>we also exclude methods for which the data used to learn model does not contain any of the labels we are learning to predict, but it does contain other information that we use in the learning process.
</nextsent>
<nextsent>for example, the multilingual pos induction approach of das and petrov (2011) <papid> P11-1061 </papid>assumes no supervision for the language whose pos tags are being 35 induced, but it assumes access to labeled dataset of different language.we begin by surveying recent work on unsupervised pos tagging, focusing on the issue of evaluation (section 2).</nextsent>
<nextsent>while pos tagging is not the only task for which unsupervised learning methods are popular, its relative simplicity and the variety of evaluation paradigms employed make it useful case study.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1351">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>iii (2009).
</prevsent>
<prevsent>we also exclude methods for which the data used to learn model does not contain any of the labels we are learning to predict, but it does contain other information that we use in the learning process.
</prevsent>
</prevsection>
<citsent citstr=" P11-1061 ">
for example, the multilingual pos induction approach of das and petrov (2011) <papid> P11-1061 </papid>assumes no supervision for the language whose pos tags are being 35 induced, but it assumes access to labeled dataset of different language.we begin by surveying recent work on unsupervised pos tagging, focusing on the issue of evaluation (section 2).</citsent>
<aftsection>
<nextsent>while pos tagging is not the only task for which unsupervised learning methods are popular, its relative simplicity and the variety of evaluation paradigms employed make it useful case study.
</nextsent>
<nextsent>based on this survey, we show that evaluation against pos tagging gold standard is not only difficult, but it can be misleading as well.the reason for this is that the unsupervised learning methods used, while they produce output that correlates with pos tags, perform different task,namely clustering-based word representation induction (turian et al, 2010).
</nextsent>
<nextsent>instead, we argue that in-context evaluation is more appropriate and more informative, as it takes into account the application context in which these methods are intended to beused (section 3).
</nextsent>
<nextsent>finally, bearing the issue of evaluation in mind, we propose some directions for future work in unsupervised learning for nlp (section 4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1352">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> the case of unsupervised part-of-speech.  </section>
<citcontext>
<prevsection>
<prevsent>for languages with substantial amounts of labeled data available such as english, the performance of supervised approaches has reached very high levels.1 thus, the research focus has shifted to semi supervised and unsupervised approaches which would allow the processing of languages which do not have similar resources available.
</prevsent>
<prevsent>at an abstract level, the unsupervised learning methods applied to pos tagging take as input tokenized unlabeled sentences, from which they learn model.
</prevsent>
</prevsection>
<citsent citstr=" E03-1009 ">
these models are either hidden markov models (hmms) (clark, 2003; <papid> E03-1009 </papid>goldwater and griffiths, 2007) <papid> P07-1094 </papid>or clustering models (biemann, 2006; <papid> P06-3002 </papid>abend et al, 2010).<papid> P10-1132 </papid></citsent>
<aftsection>
<nextsent>during model learning, state identifiers are assigned to the tokens (figure 1a).
</nextsent>
<nextsent>in 1according to the acl wiki, state-of-the-art performance in english is more than 97% per token accuracy.
</nextsent>
<nextsent>dependently of the learning method and the model, these identifiers are semantically void, i.e. they have no linguistic meaning.
</nextsent>
<nextsent>nevertheless, all the studies conclude that there is strong correlation between the state identifiers assigned and the pos tags in labeled gold standard (figure 1b).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1353">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> the case of unsupervised part-of-speech.  </section>
<citcontext>
<prevsection>
<prevsent>for languages with substantial amounts of labeled data available such as english, the performance of supervised approaches has reached very high levels.1 thus, the research focus has shifted to semi supervised and unsupervised approaches which would allow the processing of languages which do not have similar resources available.
</prevsent>
<prevsent>at an abstract level, the unsupervised learning methods applied to pos tagging take as input tokenized unlabeled sentences, from which they learn model.
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
these models are either hidden markov models (hmms) (clark, 2003; <papid> E03-1009 </papid>goldwater and griffiths, 2007) <papid> P07-1094 </papid>or clustering models (biemann, 2006; <papid> P06-3002 </papid>abend et al, 2010).<papid> P10-1132 </papid></citsent>
<aftsection>
<nextsent>during model learning, state identifiers are assigned to the tokens (figure 1a).
</nextsent>
<nextsent>in 1according to the acl wiki, state-of-the-art performance in english is more than 97% per token accuracy.
</nextsent>
<nextsent>dependently of the learning method and the model, these identifiers are semantically void, i.e. they have no linguistic meaning.
</nextsent>
<nextsent>nevertheless, all the studies conclude that there is strong correlation between the state identifiers assigned and the pos tags in labeled gold standard (figure 1b).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1354">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> the case of unsupervised part-of-speech.  </section>
<citcontext>
<prevsection>
<prevsent>for languages with substantial amounts of labeled data available such as english, the performance of supervised approaches has reached very high levels.1 thus, the research focus has shifted to semi supervised and unsupervised approaches which would allow the processing of languages which do not have similar resources available.
</prevsent>
<prevsent>at an abstract level, the unsupervised learning methods applied to pos tagging take as input tokenized unlabeled sentences, from which they learn model.
</prevsent>
</prevsection>
<citsent citstr=" P06-3002 ">
these models are either hidden markov models (hmms) (clark, 2003; <papid> E03-1009 </papid>goldwater and griffiths, 2007) <papid> P07-1094 </papid>or clustering models (biemann, 2006; <papid> P06-3002 </papid>abend et al, 2010).<papid> P10-1132 </papid></citsent>
<aftsection>
<nextsent>during model learning, state identifiers are assigned to the tokens (figure 1a).
</nextsent>
<nextsent>in 1according to the acl wiki, state-of-the-art performance in english is more than 97% per token accuracy.
</nextsent>
<nextsent>dependently of the learning method and the model, these identifiers are semantically void, i.e. they have no linguistic meaning.
</nextsent>
<nextsent>nevertheless, all the studies conclude that there is strong correlation between the state identifiers assigned and the pos tags in labeled gold standard (figure 1b).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1355">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> the case of unsupervised part-of-speech.  </section>
<citcontext>
<prevsection>
<prevsent>for languages with substantial amounts of labeled data available such as english, the performance of supervised approaches has reached very high levels.1 thus, the research focus has shifted to semi supervised and unsupervised approaches which would allow the processing of languages which do not have similar resources available.
</prevsent>
<prevsent>at an abstract level, the unsupervised learning methods applied to pos tagging take as input tokenized unlabeled sentences, from which they learn model.
</prevsent>
</prevsection>
<citsent citstr=" P10-1132 ">
these models are either hidden markov models (hmms) (clark, 2003; <papid> E03-1009 </papid>goldwater and griffiths, 2007) <papid> P07-1094 </papid>or clustering models (biemann, 2006; <papid> P06-3002 </papid>abend et al, 2010).<papid> P10-1132 </papid></citsent>
<aftsection>
<nextsent>during model learning, state identifiers are assigned to the tokens (figure 1a).
</nextsent>
<nextsent>in 1according to the acl wiki, state-of-the-art performance in english is more than 97% per token accuracy.
</nextsent>
<nextsent>dependently of the learning method and the model, these identifiers are semantically void, i.e. they have no linguistic meaning.
</nextsent>
<nextsent>nevertheless, all the studies conclude that there is strong correlation between the state identifiers assigned and the pos tags in labeled gold standard (figure 1b).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1356">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> the case of unsupervised part-of-speech.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, clustering evaluation measures need to balance appropriately between them.
</prevsent>
<prevsent>some authors proposed clustering evaluation techniques that first induce the mapping from state identifiers to gold standard tags automatically and then use supervised measures to compare the mapped output to the gold standard.
</prevsent>
</prevsection>
<citsent citstr=" D08-1036 ">
for example,gao and johnson (2008) <papid> D08-1036 </papid>proposed to induce many to-one mapping of state identifiers to pos tags from one half of the corpus and evaluate on the second half, which is referred to as cross-validation accuracy.</citsent>
<aftsection>
<nextsent>however, such techniques evaluate the clustering together with the induced mapping, thus the quality of the latter influences the results obtained.
</nextsent>
<nextsent>this can be misleading as unsupervised learning methods for pos tagging induce the clustering, butnot the mapping on which they are eventually evaluated.
</nextsent>
<nextsent>in order to avoid the mapping induction step,the use of information theoretic measures was proposed instead.
</nextsent>
<nextsent>these include variation of information (vi) (meila?, 2007), v-measure (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>and their respective variants nvi(reichart and rappoport, 2009) <papid> W09-1121 </papid>and v-beta (vla chos et al, 2009).<papid> W09-0210 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1357">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> the case of unsupervised part-of-speech.  </section>
<citcontext>
<prevsection>
<prevsent>this can be misleading as unsupervised learning methods for pos tagging induce the clustering, butnot the mapping on which they are eventually evaluated.
</prevsent>
<prevsent>in order to avoid the mapping induction step,the use of information theoretic measures was proposed instead.
</prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
these include variation of information (vi) (meila?, 2007), v-measure (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>and their respective variants nvi(reichart and rappoport, 2009) <papid> W09-1121 </papid>and v-beta (vla chos et al, 2009).<papid> W09-0210 </papid></citsent>
<aftsection>
<nextsent>each of these measures exhibits 36 there are 70 children there . 1 2 3 4 1 5 (a) unsupervised pos tagger output there are 70 children there . ex vbp cd nns rb .
</nextsent>
<nextsent>(b) gold standard 1 2 3 4 5 ex 1 0 0 0 0 vbp 0 1 0 0 0 cd 0 0 0 1 0 nns 0 0 1 0 0 rb 1 0 0 0 0 . 0 0 0 0 1 (c) confusion matrix figure 1: unsupervised pos tagging evaluation pipeline.
</nextsent>
<nextsent>some kind of bias towards certain solutions though, e.g. v-measure favors clusterings with large number of clusters, while vi exhibits the opposite behavior.while these biases might follow some reasonable intuitions, unsurprisingly none is universally accepted as the most appropriate.
</nextsent>
<nextsent>in order to avoid these problems, biemann et al(2007) proposed to evaluate unsupervised pos tagging as source of features for supervised learning approaches to nlp tasks, such as named entity recognition and shallow parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1358">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> the case of unsupervised part-of-speech.  </section>
<citcontext>
<prevsection>
<prevsent>this can be misleading as unsupervised learning methods for pos tagging induce the clustering, butnot the mapping on which they are eventually evaluated.
</prevsent>
<prevsent>in order to avoid the mapping induction step,the use of information theoretic measures was proposed instead.
</prevsent>
</prevsection>
<citsent citstr=" W09-1121 ">
these include variation of information (vi) (meila?, 2007), v-measure (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>and their respective variants nvi(reichart and rappoport, 2009) <papid> W09-1121 </papid>and v-beta (vla chos et al, 2009).<papid> W09-0210 </papid></citsent>
<aftsection>
<nextsent>each of these measures exhibits 36 there are 70 children there . 1 2 3 4 1 5 (a) unsupervised pos tagger output there are 70 children there . ex vbp cd nns rb .
</nextsent>
<nextsent>(b) gold standard 1 2 3 4 5 ex 1 0 0 0 0 vbp 0 1 0 0 0 cd 0 0 0 1 0 nns 0 0 1 0 0 rb 1 0 0 0 0 . 0 0 0 0 1 (c) confusion matrix figure 1: unsupervised pos tagging evaluation pipeline.
</nextsent>
<nextsent>some kind of bias towards certain solutions though, e.g. v-measure favors clusterings with large number of clusters, while vi exhibits the opposite behavior.while these biases might follow some reasonable intuitions, unsurprisingly none is universally accepted as the most appropriate.
</nextsent>
<nextsent>in order to avoid these problems, biemann et al(2007) proposed to evaluate unsupervised pos tagging as source of features for supervised learning approaches to nlp tasks, such as named entity recognition and shallow parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1359">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> the case of unsupervised part-of-speech.  </section>
<citcontext>
<prevsection>
<prevsent>this can be misleading as unsupervised learning methods for pos tagging induce the clustering, butnot the mapping on which they are eventually evaluated.
</prevsent>
<prevsent>in order to avoid the mapping induction step,the use of information theoretic measures was proposed instead.
</prevsent>
</prevsection>
<citsent citstr=" W09-0210 ">
these include variation of information (vi) (meila?, 2007), v-measure (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>and their respective variants nvi(reichart and rappoport, 2009) <papid> W09-1121 </papid>and v-beta (vla chos et al, 2009).<papid> W09-0210 </papid></citsent>
<aftsection>
<nextsent>each of these measures exhibits 36 there are 70 children there . 1 2 3 4 1 5 (a) unsupervised pos tagger output there are 70 children there . ex vbp cd nns rb .
</nextsent>
<nextsent>(b) gold standard 1 2 3 4 5 ex 1 0 0 0 0 vbp 0 1 0 0 0 cd 0 0 0 1 0 nns 0 0 1 0 0 rb 1 0 0 0 0 . 0 0 0 0 1 (c) confusion matrix figure 1: unsupervised pos tagging evaluation pipeline.
</nextsent>
<nextsent>some kind of bias towards certain solutions though, e.g. v-measure favors clusterings with large number of clusters, while vi exhibits the opposite behavior.while these biases might follow some reasonable intuitions, unsurprisingly none is universally accepted as the most appropriate.
</nextsent>
<nextsent>in order to avoid these problems, biemann et al(2007) proposed to evaluate unsupervised pos tagging as source of features for supervised learning approaches to nlp tasks, such as named entity recognition and shallow parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1360">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> the case of unsupervised part-of-speech.  </section>
<citcontext>
<prevsection>
<prevsent>in other words, better clustering evaluation scores did not always result in better features for shallow parsing.
</prevsent>
<prevsent>vangael et al noted that homogeneity correlated better with shallow parsing performance, hypothesizingit is probably worse to assign the same state identifier to tokens that belong to different pos tags, e.g. verb and adverbs, rather than to generate more than one state identifier for the same pos.
</prevsent>
</prevsection>
<citsent citstr=" D10-1056 ">
in the same spirit, christodoulopoulos et al (2010) <papid> D10-1056 </papid>used the output of number of unsupervised pos tagging methods to extract seeds for the prototype-driven model of haghighi and klein (2006).<papid> N06-1041 </papid></citsent>
<aftsection>
<nextsent>like van gael et al., they also found that better clustering evaluation scores did not result in better seeds.
</nextsent>
<nextsent>given these results, as well as remembering that unsupervised learning methods do not use any label information in model learning, one is entitled to question whether it is reasonable to expect their output to match particular labeled gold standard.
</nextsent>
<nextsent>why not assume that the state identifiers obtained correlate with named entity recognition tags or categorial grammar tags instead of pos tags, tasks for which sequential models are very common?
</nextsent>
<nextsent>even if the state identifiers induced correlate better withpos tags than with other kinds of annotation, evaluating them using pos tagging gold standard and even naming the task unsupervised pos tagging or induction is probably misleading.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1362">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> the case of unsupervised part-of-speech.  </section>
<citcontext>
<prevsection>
<prevsent>in other words, better clustering evaluation scores did not always result in better features for shallow parsing.
</prevsent>
<prevsent>vangael et al noted that homogeneity correlated better with shallow parsing performance, hypothesizingit is probably worse to assign the same state identifier to tokens that belong to different pos tags, e.g. verb and adverbs, rather than to generate more than one state identifier for the same pos.
</prevsent>
</prevsection>
<citsent citstr=" N06-1041 ">
in the same spirit, christodoulopoulos et al (2010) <papid> D10-1056 </papid>used the output of number of unsupervised pos tagging methods to extract seeds for the prototype-driven model of haghighi and klein (2006).<papid> N06-1041 </papid></citsent>
<aftsection>
<nextsent>like van gael et al., they also found that better clustering evaluation scores did not result in better seeds.
</nextsent>
<nextsent>given these results, as well as remembering that unsupervised learning methods do not use any label information in model learning, one is entitled to question whether it is reasonable to expect their output to match particular labeled gold standard.
</nextsent>
<nextsent>why not assume that the state identifiers obtained correlate with named entity recognition tags or categorial grammar tags instead of pos tags, tasks for which sequential models are very common?
</nextsent>
<nextsent>even if the state identifiers induced correlate better withpos tags than with other kinds of annotation, evaluating them using pos tagging gold standard and even naming the task unsupervised pos tagging or induction is probably misleading.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1368">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> in-context evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the approach of christodoulopoulos etal.
</prevsent>
<prevsent>(2010) falls between pre-processing and data exploration, as the clusters of tokens produced are semi-automatically processed in order to produce seeds which were then used by the prototype-driven model of haghighi and klein (2006).<papid> N06-1041 </papid>2 in-context evaluation can be used to assess the performance of unsupervised learning methods for tasks other than clustering-based word representation approaches.</prevsent>
</prevsection>
<citsent citstr=" P10-1044 ">
for example, topic modeling (blei et al, 2003) has recently been used and evaluated in approaches to learning models of selectional preferences (ritter et al., 2010; <papid> P10-1044 </papid>o?</citsent>
<aftsection>
<nextsent>seaghdha, 2010).the issues affecting the evaluation of unsupervised learning methods are not restricted to pos tagging.
</nextsent>
<nextsent>schwartz et al (2011) <papid> P11-1067 </papid>discussed similar issues in the context of unsupervised dependency parsing.note that some of them arise due to the fact unsupervised dependency parsing produces unlabeled directed edges which are interpreted as denoting head dependent relations.</nextsent>
<nextsent>however, there are linguistic phenomena where unless the edges are labeled with specific interpretation, both directions could be considered correct, e.g. the relation between modal verb and main verb.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1369">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> in-context evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>for example, topic modeling (blei et al, 2003) has recently been used and evaluated in approaches to learning models of selectional preferences (ritter et al., 2010; <papid> P10-1044 </papid>o?</prevsent>
<prevsent>seaghdha, 2010).the issues affecting the evaluation of unsupervised learning methods are not restricted to pos tag ging.</prevsent>
</prevsection>
<citsent citstr=" P11-1067 ">
schwartz et al (2011) <papid> P11-1067 </papid>discussed similar issues in the context of unsupervised dependency parsing.note that some of them arise due to the fact unsupervised dependency parsing produces unlabeled directed edges which are interpreted as denoting head dependent relations.</citsent>
<aftsection>
<nextsent>however, there are linguistic phenomena where unless the edges are labeled with specific interpretation, both directions could be considered correct, e.g. the relation between modal verb and main verb.
</nextsent>
<nextsent>even though evaluation against syntactic parsing gold standard is useful, we argue that in-context evaluation of the output of unsupervised dependency parsers is likely to be more informative and more appropriate.
</nextsent>
<nextsent>despite the criticism against clustering evaluation measures as well as other methods for comparing the2note that while evaluating in-context, these authors still refer to the task performed as pos tagging or induction and some of their conclusions are drawn via comparisons against pos tagging gold standard.
</nextsent>
<nextsent>38 output of unsupervised learning methods against gold standard, we argue that they are still useful.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1370">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> in-context evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>thus, they neither take full advantage of nor they demonstrate their main strength,which is that they can use as much data as possible.
</prevsent>
<prevsent>using the pre-processing paradigm, clustering based word representations induced from large unlabeled dataset would be evaluated according to whether they improve the performance of the downstream task they are evaluated with, whose evaluation is likely to be on different dataset.
</prevsent>
</prevsection>
<citsent citstr=" P08-1068 ">
this use of clustering-based word representation is sometimes referred to as semi-supervised learning and has been shown to be effective in variety of tasks, including named entity recognition, shallow parsing and syntactic dependency parsing (koo et al, 2008; <papid> P08-1068 </papid>turian et al, 2010).the use of large datasets would also help assess the scala bility of the unsupervised methods proposed, as the amount of data that can be handled efficiently by an unsupervised method can be as important as the range of linguistic intuitions it cancapture.</citsent>
<aftsection>
<nextsent>to examine this trade-off, it would be informative to show performance curves with different amounts of data, which should be straightforward to produce under the pre-processing evaluation paradigm.
</nextsent>
<nextsent>an added benefit is that, as discussed by ben-hur et al (2002), assessing clustering stability using multiple runs and sub-samples of dataset can help establish whether particular combination of clustering algorithm and user-defined parameters (including the number of clusters to be discovered) is able to discover an appropriate clustering of the dataset considered.avoiding comparisons against labeled gold standard would also remove the temptation of adapting it to the output of the unsupervised learning method.
</nextsent>
<nextsent>for example, in unsupervised pos tagging authors sometimes simplify the gold standard by collapsing the original 45 pos tags of the penn treebank to 17, e.g. by removing the distinctions between different noun tags.
</nextsent>
<nextsent>while such simplifications are linguistically plausible, they substitute one problem for another, as methods are no longer penalized for missing some of the finer distinctions, but they are penalized for making them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1373">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> directions for future work.  </section>
<citcontext>
<prevsection>
<prevsent>however, obtaining meaningful labels such as those found in gold standard is auseful and important goal in many nlp tasks.
</prevsent>
<prevsent>however, this purpose is better served by injecting appropriate supervision to the model, instead of trying to achieve it as an afterthought.
</prevsent>
</prevsection>
<citsent citstr=" D08-1109 ">
such approaches include the use of pos dictionaries by sequential tagging models (haghighi and klein, 2006; <papid> N06-1041 </papid>ravi and knight, 2009), <papid> P09-1057 </papid>the use of labeled data from different languages (snyder et al, 2008; <papid> D08-1109 </papid>das and petrov, 2011) <papid> P11-1061 </papid>or the (possibly indirect) assignment of label sto topics (ramage et al, 2009; <papid> D09-1026 </papid>zhu et al, 2009).</citsent>
<aftsection>
<nextsent>research in unsupervised learning methods is likely to benefit these partially supervised ones, as they both seek to take advantage of unlabeled data.
</nextsent>
<nextsent>as the out put of such methods uses the same labels as those found in the gold standard, they can be evaluated against labeled gold standard.
</nextsent>
<nextsent>in this position paper, we discussed the issue of evaluation of unsupervised learning methods for nlptasks.
</nextsent>
<nextsent>using pos tagging as our case study, we examined recent attempts of evaluating unsupervised approaches and showed that lot of confusion is caused due to evaluating their output against labeled gold standard.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1375">
<title id=" W11-2205.xml">evaluating unsupervised learning for natural language processing tasks </title>
<section> directions for future work.  </section>
<citcontext>
<prevsection>
<prevsent>however, obtaining meaningful labels such as those found in gold standard is auseful and important goal in many nlp tasks.
</prevsent>
<prevsent>however, this purpose is better served by injecting appropriate supervision to the model, instead of trying to achieve it as an afterthought.
</prevsent>
</prevsection>
<citsent citstr=" D09-1026 ">
such approaches include the use of pos dictionaries by sequential tagging models (haghighi and klein, 2006; <papid> N06-1041 </papid>ravi and knight, 2009), <papid> P09-1057 </papid>the use of labeled data from different languages (snyder et al, 2008; <papid> D08-1109 </papid>das and petrov, 2011) <papid> P11-1061 </papid>or the (possibly indirect) assignment of label sto topics (ramage et al, 2009; <papid> D09-1026 </papid>zhu et al, 2009).</citsent>
<aftsection>
<nextsent>research in unsupervised learning methods is likely to benefit these partially supervised ones, as they both seek to take advantage of unlabeled data.
</nextsent>
<nextsent>as the out put of such methods uses the same labels as those found in the gold standard, they can be evaluated against labeled gold standard.
</nextsent>
<nextsent>in this position paper, we discussed the issue of evaluation of unsupervised learning methods for nlptasks.
</nextsent>
<nextsent>using pos tagging as our case study, we examined recent attempts of evaluating unsupervised approaches and showed that lot of confusion is caused due to evaluating their output against labeled gold standard.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1376">
<title id=" W12-1001.xml">lexicon construction and corpus annotation of historical language with the cobalt editor </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>however, gate does not provide explicit support for texts encoded according to the tei p5 guidelines, which is why the germanc team spent lot of time on writing scripts to deal with formatting issues.
</prevsent>
<prevsent>as gate has automatic processing integrated into it, it is also not trivial to adapt it to new language.
</prevsent>
</prevsection>
<citsent citstr=" W10-1835 ">
the only special-purpose tools for historical corpus development we could find is e-dictor, specialized tool for encoding, applying levels of editions and assigning pos tags to ancient texts for building the tycho brahe parsed corpus of historical portuguese (de faria et al, 2010).<papid> W10-1835 </papid></citsent>
<aftsection>
<nextsent>it is similar to cobalt in that it too has wysiwyg interface and allows annotators to check transcriptions and assign several layers of annotations to the tokens.
</nextsent>
<nextsent>e-dictor enables export of the encoded text xml and the lexicon of editions in html and csv.
</nextsent>
<nextsent>this is an interesting tool although it does not seem to support lexical view of the data or merging and splitting word forms, and it is not quite clear how it interacts with automatic processing of the texts, or if user manual is available.
</nextsent>
<nextsent>as the review of related work shows, there is general lack of tools such as cobalt which can significantly simplify and speed up most historical corpus and lexicon development projects.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1377">
<title id=" W12-0205.xml">visualising typo logical relationships plotting wals with heat maps </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one line of recent work brings computational methods to bear on the formation anduse of large typo logical databases, often using sophisticated statistical techniques to discover relations between languages (cysouw, 2011; daume?
</prevsent>
<prevsent>iii and campbell, 2007; daume?
</prevsent>
</prevsection>
<citsent citstr=" C10-1044 ">
iii, 2009, amongothers), and another line of work uses typolog ical data in natural language processing (georgi et al, 2010; <papid> C10-1044 </papid>lewis and xia, 2008, <papid> I08-2093 </papid>for example).</citsent>
<aftsection>
<nextsent>the task of visually presenting the resulting data in this way has been only infrequently addressed.
</nextsent>
<nextsent>we are aware of some similar work (mayer et al,2010; <papid> W10-2110 </papid>rohrdantz et al, 2010) in visualising differences in linguistic typology, phylogeny (multitree, 2009), and geographical variation (wiel ing et al, 2011).</nextsent>
<nextsent>here, we present our method for addressing the visualisation gap, bringing together phylogeny, typology, and geography by using data from the world atlas of language structures (dryer and haspelmath, 2011) to develop heat maps that can visually show the interconnected relationships between languages and language families.the main envisioned application of our visualisations is in the area of linguistic typology.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1378">
<title id=" W12-0205.xml">visualising typo logical relationships plotting wals with heat maps </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one line of recent work brings computational methods to bear on the formation anduse of large typo logical databases, often using sophisticated statistical techniques to discover relations between languages (cysouw, 2011; daume?
</prevsent>
<prevsent>iii and campbell, 2007; daume?
</prevsent>
</prevsection>
<citsent citstr=" I08-2093 ">
iii, 2009, amongothers), and another line of work uses typolog ical data in natural language processing (georgi et al, 2010; <papid> C10-1044 </papid>lewis and xia, 2008, <papid> I08-2093 </papid>for example).</citsent>
<aftsection>
<nextsent>the task of visually presenting the resulting data in this way has been only infrequently addressed.
</nextsent>
<nextsent>we are aware of some similar work (mayer et al,2010; <papid> W10-2110 </papid>rohrdantz et al, 2010) in visualising differences in linguistic typology, phylogeny (multitree, 2009), and geographical variation (wiel ing et al, 2011).</nextsent>
<nextsent>here, we present our method for addressing the visualisation gap, bringing together phylogeny, typology, and geography by using data from the world atlas of language structures (dryer and haspelmath, 2011) to develop heat maps that can visually show the interconnected relationships between languages and language families.the main envisioned application of our visualisations is in the area of linguistic typology.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1379">
<title id=" W12-0205.xml">visualising typo logical relationships plotting wals with heat maps </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>iii, 2009, amongothers), and another line of work uses typolog ical data in natural language processing (georgi et al, 2010; <papid> C10-1044 </papid>lewis and xia, 2008, <papid> I08-2093 </papid>for example).</prevsent>
<prevsent>the task of visually presenting the resulting data in this way has been only infrequently addressed.</prevsent>
</prevsection>
<citsent citstr=" W10-2110 ">
we are aware of some similar work (mayer et al,2010; <papid> W10-2110 </papid>rohrdantz et al, 2010) in visualising differences in linguistic typology, phylogeny (multitree, 2009), and geographical variation (wiel ing et al, 2011).</citsent>
<aftsection>
<nextsent>here, we present our method for addressing the visualisation gap, bringing together phylogeny, typology, and geography by using data from the world atlas of language structures (dryer and haspelmath, 2011) to develop heat maps that can visually show the interconnected relationships between languages and language families.the main envisioned application of our visualisations is in the area of linguistic typology.
</nextsent>
<nextsent>typology has been used to derive implications about possible languages, and about the ordering of the human mind.
</nextsent>
<nextsent>different theorists have taken different views on the relationship between typology and the universality of languages.
</nextsent>
<nextsent>for example, greenberg (1963), foundational work, identifieda number of cross-linguistic typo logical properties and implications and aimed to present them as truly universal ? relevant for all languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1380">
<title id=" W11-2401.xml">evaluating answers to reading comprehension questions in context results for german and the role of information structure </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>firstly, such activities include text as an explicit context on the basis of which the questions are asked.
</prevsent>
<prevsent>secondly, answers to reading comprehension questions in foreign language teaching typically are between couple of words and several sentences in length ? too short to rely purely on the distribution of lexical material (as, e.g., inlsa, landauer et al, 1998).
</prevsent>
</prevsection>
<citsent citstr=" W08-0913 ">
the answers also exhibit significant variation in form, including high number of form errors, which makes it necessary to develop an approach which is robust enough to determine meaning correspondences in the presence of errors yet flexible enough to support the rich variation in form which language offers for expressing related meanings.there is relatively little research on content assessment for reading comprehension tasks and it so far has focused exclusively on english, including both reading comprehension questions answered by native speakers (leacock and chodorow, 2003; nielsen et al, 2009) and by language learners (bailey and meurers, 2008).<papid> W08-0913 </papid></citsent>
<aftsection>
<nextsent>the task is related to the increasingly popular strand of research on recognizing textual entailment (rte, dagan et al, 2009) and the answer validation exercise (ave, rodrigo et al,2009), which both have also generally targeted english.
</nextsent>
<nextsent>1 the rte challenge abstracts away from concrete tasks to emphasize the generic semantic inference component and it has significantly advanced the field under this perspective.
</nextsent>
<nextsent>at the same time, an investigation of the role of the context under which an inference holds requires concrete tasks, for which content assessment of reading comprehension tasks seems particularly well-suited.
</nextsent>
<nextsent>borrowing the terminology sparck jones (2007) coined in the context of evaluating automatic summarization systems, onecan say that we pursue an extrinsic, full-purpose evaluation of aspects of textual inference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1383">
<title id=" W11-2401.xml">evaluating answers to reading comprehension questions in context results for german and the role of information structure </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>table 2 gives an overview of which nlp tools we use for which task in comic de.
</prevsent>
<prevsent>in general, the components are very similar tothose used in the english system, with different statistical models and parameters where necessary.
</prevsent>
</prevsection>
<citsent citstr=" C94-1027 ">
annotation task nlp component sentence detection opennlp http://incubator.apache.org/opennlp tokenization opennlp lemmatization tree tagger (schmid, 1994) <papid> C94-1027 </papid>spell checking edit distance (levenshtein, 1966), igerman98 word list http://www.j3e.de/ispell/igerman98 part-of-speech tagging tree tagger (schmid, 1994) <papid> C94-1027 </papid>noun phrase chunking opennlp lexical relations germanet (hamp and feldweg, 1997) <papid> W97-0802 </papid>similarity scores pmi-ir (turney, 2001) dependency relations malt parser (nivre et al, 2007) table 2: nlp tools used in the german system integrating the multitude of units and their representations at different levels of abstraction poses significant challenges to the system architecture.</citsent>
<aftsection>
<nextsent>among other requirements, different representations of the same surface string need to be stored without interfering with each other, and various nlp tools need to collaborate in order to produce the final rich data structures used for answer comparison.
</nextsent>
<nextsent>to meet these requirements, we chose to implement our system in the unstructured information management architecture (uima, cf.
</nextsent>
<nextsent>ferrucci and lally, 2004).
</nextsent>
<nextsent>uima allows automatic analysis modules to access layers of stand-off annotation, and hence allows forthe coexistence of both independent and interdependent annotations, unlike traditional pipeline-style architectures, where the output of each component replaces its input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1387">
<title id=" W11-2401.xml">evaluating answers to reading comprehension questions in context results for german and the role of information structure </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>table 2 gives an overview of which nlp tools we use for which task in comic de.
</prevsent>
<prevsent>in general, the components are very similar tothose used in the english system, with different statistical models and parameters where necessary.
</prevsent>
</prevsection>
<citsent citstr=" W97-0802 ">
annotation task nlp component sentence detection opennlp http://incubator.apache.org/opennlp tokenization opennlp lemmatization tree tagger (schmid, 1994) <papid> C94-1027 </papid>spell checking edit distance (levenshtein, 1966), igerman98 word list http://www.j3e.de/ispell/igerman98 part-of-speech tagging tree tagger (schmid, 1994) <papid> C94-1027 </papid>noun phrase chunking opennlp lexical relations germanet (hamp and feldweg, 1997) <papid> W97-0802 </papid>similarity scores pmi-ir (turney, 2001) dependency relations malt parser (nivre et al, 2007) table 2: nlp tools used in the german system integrating the multitude of units and their representations at different levels of abstraction poses significant challenges to the system architecture.</citsent>
<aftsection>
<nextsent>among other requirements, different representations of the same surface string need to be stored without interfering with each other, and various nlp tools need to collaborate in order to produce the final rich data structures used for answer comparison.
</nextsent>
<nextsent>to meet these requirements, we chose to implement our system in the unstructured information management architecture (uima, cf.
</nextsent>
<nextsent>ferrucci and lally, 2004).
</nextsent>
<nextsent>uima allows automatic analysis modules to access layers of stand-off annotation, and hence allows forthe coexistence of both independent and interdependent annotations, unlike traditional pipeline-style architectures, where the output of each component replaces its input.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1390">
<title id=" W11-2401.xml">evaluating answers to reading comprehension questions in context results for german and the role of information structure </title>
<section> content assessment experiment.  </section>
<citcontext>
<prevsection>
<prevsent>to develop an understanding of those challenges, we performed more fine-grained evaluation by question types.
</prevsent>
<prevsent>to distinguish relevant sub cases, we applied the question classification scheme introduced by day and park (2005).
</prevsent>
</prevsection>
<citsent citstr=" C02-1150 ">
this scheme is more suitable here than other common answer-typing schemata such as the one in li and roth (2002), <papid> C02-1150 </papid>which tend to focus on questions asking for factual knowledge.</citsent>
<aftsection>
<nextsent>day and park (2005) distinguish five different question forms: yes/no (question to be answered with either yes or no), alternative (two or more yes/no questions connected with or), true or false (a statement to be classified as true or false),who/what/when/where/how/why (wh-question containing the respective question word), and multiple choice (choice between several answers presented with question, of any other question type).
</nextsent>
<nextsent>in addition, they introduce second dimension distinguishing the types of comprehension involved, i.e., howthe information asked for by the question can be obtained from the text: literal (questions that can be answered directly and explicitly from the text), reorganization (questions where information from various 4parts of the text must be combined), inference (ques tions where literal information and world knowledge must be combined), prediction (prediction of how story might continue), evaluation (comprehensive judgement about aspects of the text) and personal response (personal opinion or feelings about the text or the subject).
</nextsent>
<nextsent>out of the five different forms of question, our data contains questions of all forms except for the multiple choice category and the true or false category given that we are explicitly targeting free text responses.
</nextsent>
<nextsent>to obtain more detailed picture of thewh-question category, we decided to split that category into its respective wh-words and added one more category to it, for which.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1391">
<title id=" W12-0515.xml">combining different summarization techniques for legal text </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we showhow preliminary knowledge base, composed of only 23 rules, already outperforms competitive baselines.
</prevsent>
<prevsent>automatic summarization tasks are often addressed with statistical methods: first type of approach, introduced by kupiec et al(1995), involves using set of features of different types to describe sentences, and supervised learning algorithms to learn an empirical model of how those features interact to identify important sentences.
</prevsent>
</prevsection>
<citsent citstr=" W97-0713 ">
this kind of approach has been very popular in summarization; however the difficulty of this task often requires more complex representations, and different kinds of models to learn relevance in text have been proposed, such as discourse-based (marcu, 1997) <papid> W97-0713 </papid>or network-based (salton et al,1997) models and many others.</citsent>
<aftsection>
<nextsent>domain knowledge usually is present in the choice of features and algorithms, but it is still an open issue how best to capture the domain knowledge required to identify what is relevant in the text; manual approaches to build knowledge bases tend to be tedious, while automatic approaches require large amounts of training data and the result may still be inferior.in this paper we present our approach to summarize legal documents, using knowledge acquisition to combine different summarization techniques.
</nextsent>
<nextsent>in summarization, different kinds of information can be taken in account to locate important content, at the sentence level (e.g. particular terms or patterns), at the document level (e.g. frequency information, discourse information) and at the collection level (e.g. document frequencies or citation analysis); however, the way such attributes interact is likely to depend on the context of specific cases.
</nextsent>
<nextsent>for this reason we have developed set of methods for identifying important content, and we propose the creation ofa knowledge base (kb) that specifies which content should be used in different contexts, and how this should be combined.
</nextsent>
<nextsent>we propose to use the ripple down rules (rdr) (compton and jansen, 1990) methodology to build this knowledge base: rdr has already proven to be very effective way of building kbs, had has been used successfully in several nlp task (see section 2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1392">
<title id=" W12-0515.xml">combining different summarization techniques for legal text </title>
<section> dataset.  </section>
<citcontext>
<prevsection>
<prevsent>these catch phrases are used to evaluate our extracts using rouge, as described in section 4.
</prevsent>
<prevsent>to have more complete representation ofthese cases, we also included citation information.
</prevsent>
</prevsection>
<citsent citstr=" P08-1093 ">
citation analysis has proven to be very useful in automatic summarization (mei and zhai,2008; <papid> P08-1093 </papid>qazvinian and radev, 2008).<papid> C08-1087 </papid></citsent>
<aftsection>
<nextsent>we downloaded citation data from lawcite2.
</nextsent>
<nextsent>it is service provided by austlii which, forgiven case, lists cited cases and more recent cases that cite thecase.
</nextsent>
<nextsent>we downloaded the full texts and the catch phrases (where available) from austlii, of both cited (previous) cases and more recent cases that cite the current one (citing cases).
</nextsent>
<nextsent>of the 2816 cases, 1904 are cited at least by one other case 1http://www.austlii.edu.au/ 2http://www.lawcite.org (on average by 4.82 other cases).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1393">
<title id=" W12-0515.xml">combining different summarization techniques for legal text </title>
<section> dataset.  </section>
<citcontext>
<prevsection>
<prevsent>these catch phrases are used to evaluate our extracts using rouge, as described in section 4.
</prevsent>
<prevsent>to have more complete representation ofthese cases, we also included citation information.
</prevsent>
</prevsection>
<citsent citstr=" C08-1087 ">
citation analysis has proven to be very useful in automatic summarization (mei and zhai,2008; <papid> P08-1093 </papid>qazvinian and radev, 2008).<papid> C08-1087 </papid></citsent>
<aftsection>
<nextsent>we downloaded citation data from lawcite2.
</nextsent>
<nextsent>it is service provided by austlii which, forgiven case, lists cited cases and more recent cases that cite thecase.
</nextsent>
<nextsent>we downloaded the full texts and the catch phrases (where available) from austlii, of both cited (previous) cases and more recent cases that cite the current one (citing cases).
</nextsent>
<nextsent>of the 2816 cases, 1904 are cited at least by one other case 1http://www.austlii.edu.au/ 2http://www.lawcite.org (on average by 4.82 other cases).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1394">
<title id=" W12-0515.xml">combining different summarization techniques for legal text </title>
<section> evaluation method.  </section>
<citcontext>
<prevsection>
<prevsent>our dataset thus contains the initial 2816 cases with given catch phrases, and all cases related to them by incoming or outgoing citations, withcatchphrases and citing sentences explicitly identified, and the references to acts and sections of the law.
</prevsent>
<prevsent>as it was not reasonable to involve legal experts in this sort of exploratory study, we looked for simple way to evaluate candidate catchphrasesautomatically by comparing them with the author made catch phrases from our austlii corpus (con sidered as our gold standard?), to quickly assess the performances of various methods on large number of documents.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
as our system extracts sentences from text as candidate catch phrases, we propose an evaluation method which is based onrouge (lin, 2004) <papid> W04-1013 </papid>scores between extracted sentences and given catchphrases.</citsent>
<aftsection>
<nextsent>this method wasused also in (galgani et al, 2012).
</nextsent>
<nextsent>rouge includes several measures to quantitatively compare system-generated summaries to human-generated summaries, counting the number of overlapping n-grams of various lengths, word pairs and word sequences between two or more summaries.
</nextsent>
<nextsent>somewhat different from the standard use of rouge (which would involve comparing the whole block of catch phrases to the whole block of extracted sentences), we evaluated extracted sentences individually so that the utility of any one catchphrase is minimally affected by the others, or by their particular order.
</nextsent>
<nextsent>on the other handwe want to extract sentences that contain an entire individual catchphrase, while sentence that 117 contains small pieces of different catch phrases is not as useful.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1395">
<title id=" W12-1602.xml">an endtoend evaluation of two situated dialog systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>phrases.
</prevsent>
<prevsent>the second system (qa)is question/answering character model which predicts the system dialog move given players utterance (leuski and traum, 2008).
</prevsent>
</prevsection>
<citsent citstr=" W06-1303 ">
both systems use generation-by-selection strategy (leuski et al, 2006; <papid> W06-1303 </papid>gandhe and traum, 2007) where the systems utterances are selected from corpus of possible outputs based on the dialog manager output.</citsent>
<aftsection>
<nextsent>while previous work focuses on relatively short dialogs ina static setting, in our systems we consider long interactions in which dialogs occur in setting that dynamically evolves as the game unfolds.we evaluate the two dialog systems in the context of the 3d game they were developed for andseek to determine the degree to which dialog system is operational.
</nextsent>
<nextsent>to answer this question, we analyse both systems with respect not only to quantitative metrics such as accuracy but also to user- andcorpus-based metrics.
</nextsent>
<nextsent>user-based metrics are computed based on questionnaire the users filled in; while corpus-based metrics are manually extracted from the corpus of player-vc interactions collected during the user-based evaluation.
</nextsent>
<nextsent>as suggested by evaluation frameworks such as paradise (walker et al, 1997) and sassi (hone and graham, 2000), we show that multi view evaluation permits better assessment of how well the dialog system function sin the real world?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1396">
<title id=" W12-1602.xml">an endtoend evaluation of two situated dialog systems </title>
<section> dialogues in the mp game.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 dialog strategies.
</prevsent>
<prevsent>we identified four main dialog strategies underlying the 12 mp dialogs and used these to define the plans guiding the rule-based discourse management in the hybrid system.
</prevsent>
</prevsection>
<citsent citstr=" J97-1002 ">
these strategies can be seen as transactions made up of conversational games (carletta et al., 1997).<papid> J97-1002 </papid>strategy 1.</citsent>
<aftsection>
<nextsent>this strategy is used in the first dialog only and consists of single address request move by the vc followed by the players answer:lucas requests bento find the address of the plastic enterprise that must be hidden somewhere in the lab.
</nextsent>
<nextsent>ben can accept, reject or ask for help.
</nextsent>
<nextsent>lucas answers accordingly and ends the conversation.
</nextsent>
<nextsent>strategy 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1397">
<title id=" W12-1602.xml">an endtoend evaluation of two situated dialog systems </title>
<section> dialogue systems.  </section>
<citcontext>
<prevsection>
<prevsent>autres questions ? other questions?
</prevsent>
<prevsent>julie: oui quest-ce que je peux faire avec ces bouts de papier ? yes, what can do with these pieces of paper ? samir: et bien sachez quil a de plus en plus des femmes dans cette industrie ...you should know there are more and more women in this industry ...
</prevsent>
</prevsection>
<citsent citstr=" W03-0705 ">
the dialog manager we designed plan for each dialog strategy and extended midiki (burke et al, 2003) <papid> W03-0705 </papid>to support the oaa architecture and access the relational database specifying the configurations of the different dialogs in the game.</citsent>
<aftsection>
<nextsent>each time new dialog is launched, the information state is loaded with the corresponding dialog-context (e.g., speakers, list of goals to be discussed) and the plan modeling the corresponding dialog strategy.
</nextsent>
<nextsent>to support dialog management, we implemented set of update and selection rules for integrating players?
</nextsent>
<nextsent>moves, handling the information-state and for preparing the agenda according to the plan.
</nextsent>
<nextsent>more specifically, the following rules are executed at runtime: integration: integrates dialog moves (e.g., questions, answers,acknowledgments) in the information state (ques tions are listed in the question under discussion, 3the system asks the player for the goal to be discussed: ask(task(x)) and the player answers one goal in the situated dialog: goali.answers change the commond ground, player answers are integrated in response to vcs questions).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1398">
<title id=" W11-2204.xml">reducing the size of the representation for the udopestimate </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments suggest that this leads to reduction in grammar size by factor of 2.
</prevsent>
<prevsent>this paper also suggests some extensions of the original udop algorithm that are made possible or aided by the use of tree automata.
</prevsent>
</prevsection>
<citsent citstr=" W06-2912 ">
the approaches to unsupervised parsing givenby bod (2006<papid> W06-2912 </papid>a,2006b,2007) are all based on using all possible subtrees over training corpus.</citsent>
<aftsection>
<nextsent>this means that great number of subtrees hasto be represented.
</nextsent>
<nextsent>for every sentence the number of binary trees that can be proposed for that sentence1 is given by the catalan number of the length of the sentence.
</nextsent>
<nextsent>the number of subtrees acknowledgments: the author would like to thank amit kirsch baum, robert remus, anna janska and the anonymus reviewers for their remarks.
</nextsent>
<nextsent>1only single nonterminal is used for tree in this set is exponential with respect to the length of the sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1399">
<title id=" W11-2204.xml">reducing the size of the representation for the udopestimate </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the number of subtrees acknowledgments: the author would like to thank amit kirsch baum, robert remus, anna janska and the anonymus reviewers for their remarks.
</prevsent>
<prevsent>1only single nonterminal is used for tree in this set is exponential with respect to the length of the sentence.
</prevsent>
</prevsection>
<citsent citstr=" P07-1051 ">
in bod (2007) <papid> P07-1051 </papid>packed representation for all subtrees was proposed that is based on technique for supervised data oriented parsing (dop) given in goodman (2003).</citsent>
<aftsection>
<nextsent>this paper aims to relate the problem of representing an estimate for all subtrees over corpus to the field of tree automata (fulop and vogler, 2009).
</nextsent>
<nextsent>with this step it will be possible to reduce the size of the packed representation of the subtrees even further.
</nextsent>
<nextsent>this newly formulated approach will also consider working with partially bracketed corpora.
</nextsent>
<nextsent>the next step in this paper will be short discussion of udop.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1401">
<title id=" W11-2204.xml">reducing the size of the representation for the udopestimate </title>
<section> a short discussion of udop </section>
<citcontext>
<prevsection>
<prevsent>the subtree in figure 1(b) would occur twice among the parses for the sentence jimsees the french guest?, since there are two possible binary parses with the nonterminal x? for the substring the french guest?.
</prevsent>
<prevsent>one is given by x(x(x(the)x(french))x(guest)) (1) the other is given by: x(x(the)x(x(french)x(guest))) (2) in this paper small extension of the original udop algorithm is considered.
</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
the idea is well known from pereira and schabes (1992).<papid> P92-1017 </papid></citsent>
<aftsection>
<nextsent>the extension is assuming that the corpus may consist of partial parses.
</nextsent>
<nextsent>the algorithm is changed so that for every partial tree all binary trees that are completions of the partial tree are proposed.
</nextsent>
<nextsent>labels for the constituents in the partial tree are kept.
</nextsent>
<nextsent>only single nonterminal is used for the completions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1402">
<title id=" W11-2204.xml">reducing the size of the representation for the udopestimate </title>
<section> a short discussion of udop </section>
<citcontext>
<prevsection>
<prevsent>this could be used to extend udopto non binary trees.
</prevsent>
<prevsent>using the low level bracketings from the algorithms would reduce the size ofan udop grammar estimated from them.
</prevsent>
</prevsection>
<citsent citstr=" P10-1130 ">
partial bracketing could also be approximated byusing html annotation, punctuation and se mantical annotation (spitkovsky et al, 2010; <papid> P10-1130 </papid>spitkovsky et al, 2011; <papid> W11-0303 </papid>naseem and barzilay, 2011).</citsent>
<aftsection>
<nextsent>25
</nextsent>
<nextsent>this section introduces stochastic tree substitution grammars.
</nextsent>
<nextsent>it will also introduce version of probabilistic bottom up tree automata suited for representation of large stochastic tree substitution grammars.
</nextsent>
<nextsent>furthermore it gives more formal definition of the udop-estimate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1403">
<title id=" W11-2204.xml">reducing the size of the representation for the udopestimate </title>
<section> a short discussion of udop </section>
<citcontext>
<prevsection>
<prevsent>this could be used to extend udopto non binary trees.
</prevsent>
<prevsent>using the low level bracketings from the algorithms would reduce the size ofan udop grammar estimated from them.
</prevsent>
</prevsection>
<citsent citstr=" W11-0303 ">
partial bracketing could also be approximated byusing html annotation, punctuation and se mantical annotation (spitkovsky et al, 2010; <papid> P10-1130 </papid>spitkovsky et al, 2011; <papid> W11-0303 </papid>naseem and barzilay, 2011).</citsent>
<aftsection>
<nextsent>25
</nextsent>
<nextsent>this section introduces stochastic tree substitution grammars.
</nextsent>
<nextsent>it will also introduce version of probabilistic bottom up tree automata suited for representation of large stochastic tree substitution grammars.
</nextsent>
<nextsent>furthermore it gives more formal definition of the udop-estimate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1404">
<title id=" W11-2204.xml">reducing the size of the representation for the udopestimate </title>
<section> terminology.  </section>
<citcontext>
<prevsection>
<prevsent>the intermediate trees are labeled with states that guide the derivation process.
</prevsent>
<prevsent>5ensuring that the weight of the finite strings sums to one is more difficult.
</prevsent>
</prevsection>
<citsent citstr=" N06-1044 ">
see nederhof and satta (2006).<papid> N06-1044 </papid></citsent>
<aftsection>
<nextsent>definition 6 (language).
</nextsent>
<nextsent>the language of pbta denoted l(a) is the set: l(a) = {t|?(t, a) 6= 0} (11)the penultimate set of definitions is concerned with the language weight of pbta, in side and outside weights.
</nextsent>
<nextsent>definition 7 (language weight).
</nextsent>
<nextsent>the language weight for pbta = q,?, ?, q0, ?, ??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1405">
<title id=" W11-2204.xml">reducing the size of the representation for the udopestimate </title>
<section> reducing the size of the estimate.  </section>
<citcontext>
<prevsection>
<prevsent>the completed corpus is again the corpus with each tree replaced by all the trees completions.
</prevsent>
<prevsent>as second step manipulate the automaton for the set of completions in such way thatthe set of subtrees is given and they are associated with the intended relative weights.
</prevsent>
</prevsection>
<citsent citstr=" W09-3801 ">
then apply normalization similar to the one employed by maletti and satta (2009).<papid> W09-3801 </papid></citsent>
<aftsection>
<nextsent>the normalization algorithm has to be slightly changed to account for the fact that the trees are not supposed to stand on their own, but rather be used in anstsg.
</nextsent>
<nextsent>a sketch will be given.
</nextsent>
<nextsent>for all final transition with label sum up the final weight of the transition times the inside weight of allstates onthe left hand side of the transition.
</nextsent>
<nextsent>then multiply the weight of final transitions with label with the multiplication of the inside weights of their left hand side states and divide the weight by the sum for the label l. all other weights are normalized as described in maletti and satta (2009).<papid> W09-3801 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1409">
<title id=" W11-2204.xml">reducing the size of the representation for the udopestimate </title>
<section> reducing the size of the estimate.  </section>
<citcontext>
<prevsection>
<prevsent>therefore inside weight is added according to the number of embedded trees.
</prevsent>
<prevsent>normalizing the automaton afterwards gives the weights according to the udop estimator.
</prevsent>
</prevsection>
<citsent citstr=" P10-1112 ">
bansal and klein (2010) <papid> P10-1112 </papid>give transformation from parse trees to subtrees that reduces the sizeof the representation even further.</citsent>
<aftsection>
<nextsent>since version of the transformation from their paper can be applied to any representation of the full parse trees, it is complementary to the approach used here.
</nextsent>
<nextsent>for this reason it will not be discussed here and it should suffice to say that using this transformation would improve the results in this paper even further.before it is discussed how the size of the representation of all trees can be reduced further, the first step will be to present the approach by goodman (2003).
</nextsent>
<nextsent>4.1 the goodman reduction.
</nextsent>
<nextsent>the approach from goodman (2003) was intended for use with the supervised version of 9this accounts for the factor 2 ? |i|.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1412">
<title id=" W11-2204.xml">reducing the size of the representation for the udopestimate </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>this state is labeled as 1.
</prevsent>
<prevsent>the algorithm was tested in two domains.
</prevsent>
</prevsection>
<citsent citstr=" A97-1014 ">
the first one was the negra corpus (skut et al, 1997).<papid> A97-1014 </papid></citsent>
<aftsection>
<nextsent>the second one was the brown corpus(francis, 1964).
</nextsent>
<nextsent>the standard approach in unsupervised parsing is to use sequences of tags with certain punctuation removed (klein and manning, 2002).<papid> P02-1017 </papid></nextsent>
<nextsent>this is supposed to simulate spoken language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1413">
<title id=" W11-2204.xml">reducing the size of the representation for the udopestimate </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>the first one was the negra corpus (skut et al, 1997).<papid> A97-1014 </papid></prevsent>
<prevsent>the second one was the brown corpus(francis, 1964).</prevsent>
</prevsection>
<citsent citstr=" P02-1017 ">
the standard approach in unsupervised parsing is to use sequences of tags with certain punctuation removed (klein and manning, 2002).<papid> P02-1017 </papid></citsent>
<aftsection>
<nextsent>this is supposed to simulate spoken language.
</nextsent>
<nextsent>once the punctuation is removed all sequences of length 10 or less are used for most approaches in unsupervised parsing.
</nextsent>
<nextsent>this ensures that the hypothesis space is relatively small for the sentences left in the corpus.
</nextsent>
<nextsent>the same approach is chosen for this paper, as this is the context in which udop grammars are most likely to be evaluated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1416">
<title id=" W11-1913.xml">narrative schema as world knowledge for coreference resolution </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>in this paper we describe the system with which we participated in the conll-2011 shared task on modelling coreference.
</prevsent>
</prevsection>
<citsent citstr=" D09-1101 ">
our system is based on cluster-ranking model proposed by rahman and ng (2009), <papid> D09-1101 </papid>with novel semantic features based on recent research on narrative event schema (chambers and jurafsky, 2009).<papid> P09-1068 </papid></citsent>
<aftsection>
<nextsent>we demonstrate some improvements over the baseline when using schema information, although the effect varied between the metrics used.
</nextsent>
<nextsent>we also explore the impact of various features on our systems performance.
</nextsent>
<nextsent>coreference resolution is problem for automated document understanding.
</nextsent>
<nextsent>we say two segments ofa natural-language document corefer when theyre fer to the same real-world entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1418">
<title id=" W11-1913.xml">narrative schema as world knowledge for coreference resolution </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>in this paper we describe the system with which we participated in the conll-2011 shared task on modelling coreference.
</prevsent>
</prevsection>
<citsent citstr=" P09-1068 ">
our system is based on cluster-ranking model proposed by rahman and ng (2009), <papid> D09-1101 </papid>with novel semantic features based on recent research on narrative event schema (chambers and jurafsky, 2009).<papid> P09-1068 </papid></citsent>
<aftsection>
<nextsent>we demonstrate some improvements over the baseline when using schema information, although the effect varied between the metrics used.
</nextsent>
<nextsent>we also explore the impact of various features on our systems performance.
</nextsent>
<nextsent>coreference resolution is problem for automated document understanding.
</nextsent>
<nextsent>we say two segments ofa natural-language document corefer when theyre fer to the same real-world entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1420">
<title id=" W11-1913.xml">narrative schema as world knowledge for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we say two segments ofa natural-language document corefer when theyre fer to the same real-world entity.
</prevsent>
<prevsent>the segments ofa document which refer to an entity are called mentions.
</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
in coreference resolution tasks, mentions are usually restricted to noun phrases.the goal of the conll-2011 shared task (prad han et al, 2011) <papid> W11-1901 </papid>is to model unrestricted coreference using the ontonotes corpus.</citsent>
<aftsection>
<nextsent>the ontonotes corpus is annotated with several layers of syntactic and semantic information, making it rich resource for investigating coreference resolution (pradhan et al, 2007).
</nextsent>
<nextsent>we participated in both the open?
</nextsent>
<nextsent>and closed?
</nextsent>
<nextsent>tracks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1423">
<title id=" W11-1913.xml">narrative schema as world knowledge for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>supervised machine-learning approaches to coreference resolution have been researched for almost two decades.
</prevsent>
<prevsent>recently, the state of the art seems to be moving away from the early mention-pair classification model toward entity-based models.
</prevsent>
</prevsection>
<citsent citstr=" P10-1142 ">
ng (2010)<papid> P10-1142 </papid>provides an excellent overview of the history andre cent developments within the field.</citsent>
<aftsection>
<nextsent>both entity-mention and mention-pair models are formulated as binary classification problems; how ever, ranking may be more natural approach to coreference resolution (ng, 2010; <papid> P10-1142 </papid>rahman and ng,2009).</nextsent>
<nextsent>rahman and ng (2009) <papid> D09-1101 </papid>in particular propose the cluster-ranking model which we used in our baseline.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1429">
<title id=" W11-1913.xml">narrative schema as world knowledge for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>and marcu (2005) apply their learning as search optimization framework to coreference resolution, and show good results.feature selection is important for good performance in coreference resolution.
</prevsent>
<prevsent>ng (2010)<papid> P10-1142 </papid> discusses commonly used features, and analyses of the contribution of various features can be found in (daume?</prevsent>
</prevsection>
<citsent citstr=" N06-1025 ">
and marcu, 2005; rahman and ng, 2011; ponzetto and strube, 2006<papid> N06-1025 </papid>b).</citsent>
<aftsection>
<nextsent>surprisingly, rahman and ng (2011) demonstrated that system using almost exclusively lexical features could outperform 86 systems which used more traditional sets of features.
</nextsent>
<nextsent>although string features have large effect on performance, it is recognized that the use of semantic information is important for further improvement (ng, 2010; <papid> P10-1142 </papid>ponzetto and strube, 2006<papid> N06-1025 </papid>a; ponzetto and strube, 2006<papid> N06-1025 </papid>b; haghighi and klein, 2010).<papid> N10-1061 </papid></nextsent>
<nextsent>theuse of predicate-argument structure has been explored by ponzetto and strube (2006<papid> N06-1025 </papid>b), ponzetto and strube (2006<papid> N06-1025 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1449">
<title id=" W11-1913.xml">narrative schema as world knowledge for coreference resolution </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>and marcu, 2005; rahman and ng, 2011; ponzetto and strube, 2006<papid> N06-1025 </papid>b).</prevsent>
<prevsent>surprisingly, rahman and ng (2011) demonstrated that system using almost exclusively lexical features could outperform 86 systems which used more traditional sets of features.</prevsent>
</prevsection>
<citsent citstr=" N10-1061 ">
although string features have large effect on performance, it is recognized that the use of semantic information is important for further improvement (ng, 2010; <papid> P10-1142 </papid>ponzetto and strube, 2006<papid> N06-1025 </papid>a; ponzetto and strube, 2006<papid> N06-1025 </papid>b; haghighi and klein, 2010).<papid> N10-1061 </papid></citsent>
<aftsection>
<nextsent>theuse of predicate-argument structure has been explored by ponzetto and strube (2006<papid> N06-1025 </papid>b), ponzetto and strube (2006<papid> N06-1025 </papid>a).</nextsent>
<nextsent>narrative schema are extracted from large-scale corpora using coreference information to identify predicates whose arguments often corefer.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1468">
<title id=" W11-1820.xml">extracting biological events from text using simple syntactic patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, the extracted binary relations cannot fully represent the original biomedical data.
</prevsent>
<prevsent>therefore, there is an increasing need to extract fine-grained and complex relations such as biological events (miwa et al., 2010).
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
the bionlp09 shared task (kim et al., 2009) <papid> W09-1401 </papid>was the first shared task that provided consistent dataset and evaluation tools for extraction of such biological relations.</citsent>
<aftsection>
<nextsent>several approaches to extract biological events have been proposed for this shared task.
</nextsent>
<nextsent>based on their characteristics, these approaches can be divided into 3 groups.
</nextsent>
<nextsent>the first group uses rule based approach which implements set of manually defined rules developed by experts or automatically learned from training data.
</nextsent>
<nextsent>these rules are then applied on dependency parse trees to extract biological events (kaljurand et al, 2009; <papid> W09-1404 </papid>kilicoglu and bergler, 2009).<papid> W09-1418 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1469">
<title id=" W11-1820.xml">extracting biological events from text using simple syntactic patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>based on their characteristics, these approaches can be divided into 3 groups.
</prevsent>
<prevsent>the first group uses rule based approach which implements set of manually defined rules developed by experts or automatically learned from training data.
</prevsent>
</prevsection>
<citsent citstr=" W09-1404 ">
these rules are then applied on dependency parse trees to extract biological events (kaljurand et al, 2009; <papid> W09-1404 </papid>kilicoglu and bergler, 2009).<papid> W09-1418 </papid></citsent>
<aftsection>
<nextsent>the second group uses machine learning (ml)-based approach which exploits various specific features and learning algorithms to extract events (bjrne at al., 2009; miwa et al, 2010).
</nextsent>
<nextsent>the third group uses hybrid methods that combine both rule- and ml-based approaches to solve the problem (ahmed et al, 2009; <papid> W09-1413 </papid>mra et al., 2009).</nextsent>
<nextsent>among these proposed approaches, the ml achieved the best results, however, it is non trivial to apply.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1470">
<title id=" W11-1820.xml">extracting biological events from text using simple syntactic patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>based on their characteristics, these approaches can be divided into 3 groups.
</prevsent>
<prevsent>the first group uses rule based approach which implements set of manually defined rules developed by experts or automatically learned from training data.
</prevsent>
</prevsection>
<citsent citstr=" W09-1418 ">
these rules are then applied on dependency parse trees to extract biological events (kaljurand et al, 2009; <papid> W09-1404 </papid>kilicoglu and bergler, 2009).<papid> W09-1418 </papid></citsent>
<aftsection>
<nextsent>the second group uses machine learning (ml)-based approach which exploits various specific features and learning algorithms to extract events (bjrne at al., 2009; miwa et al, 2010).
</nextsent>
<nextsent>the third group uses hybrid methods that combine both rule- and ml-based approaches to solve the problem (ahmed et al, 2009; <papid> W09-1413 </papid>mra et al., 2009).</nextsent>
<nextsent>among these proposed approaches, the ml achieved the best results, however, it is non trivial to apply.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1471">
<title id=" W11-1820.xml">extracting biological events from text using simple syntactic patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these rules are then applied on dependency parse trees to extract biological events (kaljurand et al, 2009; <papid> W09-1404 </papid>kilicoglu and bergler, 2009).<papid> W09-1418 </papid></prevsent>
<prevsent>the second group uses machine learning (ml)-based approach which exploits various specific features and learning algorithms to extract events (bjrne at al., 2009; miwa et al, 2010).</prevsent>
</prevsection>
<citsent citstr=" W09-1413 ">
the third group uses hybrid methods that combine both rule- and ml-based approaches to solve the problem (ahmed et al, 2009; <papid> W09-1413 </papid>mra et al., 2009).</citsent>
<aftsection>
<nextsent>among these proposed approaches, the ml achieved the best results, however, it is non trivial to apply.
</nextsent>
<nextsent>in this paper, we propose rule-based approach which uses two syntactic patterns derived from parse tree.
</nextsent>
<nextsent>the proposed approach consists of the following components: dictionary to detect triggers, text pre-processing, and event extraction.
</nextsent>
<nextsent>2.1 dictionary for event trigger detection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1473">
<title id=" W12-1611.xml">reinforcement learning of question answering dialogue policies for virtual museum guides </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>because it is very difficult to collect such large number of dialogues with real users, instead, simulated users (sus), i.e. models that simulate the behavior of real users, are employed (georgila et al, 2006).
</prevsent>
<prevsent>through the interaction between the system and the sus thousands of dialogues can be generated and used for learning.
</prevsent>
</prevsection>
<citsent citstr=" P08-1071 ">
a good su should be able to replicate the behavior of real user in the same dialogue context (ai and litman, 2008).<papid> P08-1071 </papid></citsent>
<aftsection>
<nextsent>most research in rl for dialogue management has been done in the framework of slot-filling applications (georgila et al, 2010; <papid> W10-4321 </papid>thomson and young, 2010), largely ignoring other types of dialogue.</nextsent>
<nextsent>inthis paper we focus on the problem of learning dialogue policies for question-answering characters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1474">
<title id=" W12-1611.xml">reinforcement learning of question answering dialogue policies for virtual museum guides </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>through the interaction between the system and the sus thousands of dialogues can be generated and used for learning.
</prevsent>
<prevsent>a good su should be able to replicate the behavior of real user in the same dialogue context (ai and litman, 2008).<papid> P08-1071 </papid></prevsent>
</prevsection>
<citsent citstr=" W10-4321 ">
most research in rl for dialogue management has been done in the framework of slot-filling applications (georgila et al, 2010; <papid> W10-4321 </papid>thomson and young, 2010), largely ignoring other types of dialogue.</citsent>
<aftsection>
<nextsent>inthis paper we focus on the problem of learning dialogue policies for question-answering characters.
</nextsent>
<nextsent>with question-answering systems (or characters), the natural language understanding task is to retrieve the best response to user initiative, and the main dialogue policy decision is whether to provide this best response or some other kind of move (e.g. request for repair, clarification, or topic change), when the best answer does not seem to be good enough.note that often in the literature the term question answering is used for slot-filling dialogue system sas well, in the sense that the user asks some questions, for example, about restaurants in particular area, and the system answers by providing list of options, for example, restaurants.
</nextsent>
<nextsent>we use the termquestion-answering?
</nextsent>
<nextsent>for systems where user questions can be independent of one another (follow up questions are possible though) and do not havethe objective of reducing the search space andre trieving results from database of e.g. restaurants, flights, etc. thus examples of question-answering 84characters can be virtual interviewees (that can answer questions, e.g. about an incident), virtual scientists (that can answer general science-related ques tions), and so forth.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1475">
<title id=" W12-1611.xml">reinforcement learning of question answering dialogue policies for virtual museum guides </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 7 presents our evaluation results.
</prevsent>
<prevsent>finally section 8 presents some discussion and ideas for future work together with our conclusion.
</prevsent>
</prevsection>
<citsent citstr=" W10-4339 ">
to date, rl has mainly been used for learning dialogue policies for slot-filling applications such as restaurant recommendations (jurccek et al, 2012), sightseeing recommendations (misu et al, 2010), <papid> W10-4339 </papid>appointment scheduling (georgila et al, 2010), <papid> W10-4321 </papid>etc., largely ignoring other types of dialogue.</citsent>
<aftsection>
<nextsent>recently there have been some experiments on applying rlto the more difficult problem of learning negotiation policies (heeman, 2009; georgila and traum, 2011a; georgila and traum, 2011b).
</nextsent>
<nextsent>also, rl hasbeen applied to tutoring domains (tetreault and litman, 2008; chi et al, 2011).
</nextsent>
<nextsent>there has been lot of work on developingquestion-answering systems with dialogue capabilities, e.g.
</nextsent>
<nextsent>(jonsson et al, 2004; op den akker et al, 2005; varges et al, 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1477">
<title id=" W12-1611.xml">reinforcement learning of question answering dialogue policies for virtual museum guides </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(jonsson et al, 2004; op den akker et al, 2005; varges et al, 2009).
</prevsent>
<prevsent>most of these systems are designed for information extraction from structured or unstructured databases in closed or open domains.one could think of them as adding dialogue capabilities to standard question-answering systems such as the ones used in the trec question-answering track (voorhees, 2001).
</prevsent>
</prevsection>
<citsent citstr=" W06-1303 ">
other work has focused on different type of question-answering dialogue, i.e. question-answering dialogues that follow the form of an interview and that can be used, for example, for training purposes (leuski et al, 2006; <papid> W06-1303 </papid>gandhe et al., 2009).</citsent>
<aftsection>
<nextsent>but none of these systems uses rl.
</nextsent>
<nextsent>to our knowledge no one has used rl for learning policies for question-answering systems as defined in section 1.
</nextsent>
<nextsent>note that rieser and lemon (2009) used rl for question-answering, but in their case, question-answering refers to asking for information about songs and artists in an mp3 database, which is very much like slot-filling task, i.e. the system has to fill number of slots (e.g. name of band, etc.) in order to query database of songs and present the right information to the user.
</nextsent>
<nextsent>as discussed in section 1 our task is rather different.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1478">
<title id=" W12-0406.xml">on the use of homogenous sets of subjects in deceptive language analysis </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>psychological conditions: therefore their findings may not be generalized to deception encountered in real life.
</prevsent>
<prevsent>due to practical difficulties in collection and annotation of suitable data, in literature finding papers in which real life linguistic data are employed, where truthfulness is surely known, is less common and zhou et al  (2008) complain about the lack of dataset for evaluating deception detection models?.
</prevsent>
</prevsection>
<citsent citstr=" C08-1006 ">
just recently some studies tried to fill this gap, concerning both the english (bachenko et al , 2008; <papid> C08-1006 </papid>fitzpatrick and bachenko,2009) and italian language (fornaciari and poe sio, 2011a,b).</citsent>
<aftsection>
<nextsent>just the studies on italian language come from data which have constituted the first nucleus of the corpus analysed here.
</nextsent>
<nextsent>2.2 stylometry.
</nextsent>
<nextsent>our own work and that of other authors that recently employed machine learning techniques to detect deception in text employs techniques very similar to that of stylometry.
</nextsent>
<nextsent>stylometry is discipline which studies texts on the basis of their stylistic features, usually in order to attribute them to an author - giving rise to the branch of author attribution - or to get information about the author himself - this is the field of author profiling.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1479">
<title id=" W12-0406.xml">on the use of homogenous sets of subjects in deceptive language analysis </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>our own work and that of other authors that recently employed machine learning techniques to detect deception in text employs techniques very similar to that of stylometry.
</prevsent>
<prevsent>stylometry is discipline which studies texts on the basis of their stylistic features, usually in order to attribute them to an author - giving rise to the branch of author attribution - or to get information about the author himself - this is the field of author profiling.
</prevsent>
</prevsection>
<citsent citstr=" C08-1065 ">
stylo metric analyses, which relies mainly on machine learning algorithms, turned out to be effective in several forensic tasks: not only the classical field of author profiling (coulthard, 2004; koppel et al , 2006; peers man et al , 2011; sol anand tiersma, 2004) and author attribution (luy ckx and daelemans, 2008; <papid> C08-1065 </papid>mos teller and wallace, 1964), but also emotion detection (vaassen and daelemans, 2011) <papid> W11-1713 </papid>and plagiarism analysis (stein et al , 2007).</citsent>
<aftsection>
<nextsent>therefore, from methodological point of view, deceptive language analysis is particular application of stylometry, exactly like other branches of forensic linguistics.
</nextsent>
<nextsent>3.1 false testimonies in court.
</nextsent>
<nextsent>in order to study deceptive language, we created the decour - deception in court - corpus, better described in fornaciari and poesio (2012).decour is corpus constituted by the transcripts of 35 hearings held in four italian courts:bologna, bolzano, prato and trento.
</nextsent>
<nextsent>these transcripts report verbatim the statements issued by total of 31 different subjects - four of which have been heard twice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1480">
<title id=" W12-0406.xml">on the use of homogenous sets of subjects in deceptive language analysis </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>our own work and that of other authors that recently employed machine learning techniques to detect deception in text employs techniques very similar to that of stylometry.
</prevsent>
<prevsent>stylometry is discipline which studies texts on the basis of their stylistic features, usually in order to attribute them to an author - giving rise to the branch of author attribution - or to get information about the author himself - this is the field of author profiling.
</prevsent>
</prevsection>
<citsent citstr=" W11-1713 ">
stylo metric analyses, which relies mainly on machine learning algorithms, turned out to be effective in several forensic tasks: not only the classical field of author profiling (coulthard, 2004; koppel et al , 2006; peers man et al , 2011; sol anand tiersma, 2004) and author attribution (luy ckx and daelemans, 2008; <papid> C08-1065 </papid>mos teller and wallace, 1964), but also emotion detection (vaassen and daelemans, 2011) <papid> W11-1713 </papid>and plagiarism analysis (stein et al , 2007).</citsent>
<aftsection>
<nextsent>therefore, from methodological point of view, deceptive language analysis is particular application of stylometry, exactly like other branches of forensic linguistics.
</nextsent>
<nextsent>3.1 false testimonies in court.
</nextsent>
<nextsent>in order to study deceptive language, we created the decour - deception in court - corpus, better described in fornaciari and poesio (2012).decour is corpus constituted by the transcripts of 35 hearings held in four italian courts:bologna, bolzano, prato and trento.
</nextsent>
<nextsent>these transcripts report verbatim the statements issued by total of 31 different subjects - four of which have been heard twice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1481">
<title id=" W11-2136.xml">shallow semantic trees for smt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the use of semantic information to improve statistical machine translation (smt) is very recent research topic that has been attracting significant attention.
</prevsent>
<prevsent>in this paper we describe our participation in the shared translation task of the 6th workshop on statistical machine translation (wmt) with system that incorporates shallow syntactic and semantic information into hierarchical smt models.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the system is based on the moses toolkit (hoanget al, 2009; koehn et al, 2007) <papid> P07-2045 </papid>using hierarchical models informed with shallow syntactic (chunks) and semantic (semantic role labels) information for the source language.</citsent>
<aftsection>
<nextsent>the toolkit senna (collobert et al, 2011) is used to provide base-phrases (chunks) and semantic role labels.experiments with english-spanish and english german news datasets show promising results and highlight important issues about the use of semantic information in hierarchical models as well as number of possible directions for further research.the remaining of the paper is organized as follows: section 2 presents related work; section 3 describes the method; section 4 presents the results obtained for the english-spanish and english-germantranslation tasks; and section 5 brings some conclusions and directions for further research.
</nextsent>
<nextsent>in hierarchical smt (chiang, 2005), synchronous context free grammar (scfg) is learned from aparallel corpus.the model capitalizes on the recursive nature of language replacing sub-phrases by an unlabeled nonterminal.
</nextsent>
<nextsent>hierarchical models are known to produce high coverage rules, once they areonly constrained by the word alignment.
</nextsent>
<nextsent>nevertheless the lack of specialized vocabulary also leads to spurious ambiguity (chiang, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1482">
<title id=" W11-2136.xml">shallow semantic trees for smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>instead of having heuristic strategies to combine nonterminals in aparse tree, whenever rule cannot be retrieved be cause it does not span constituent, the extraction procedure falls back to the hierarchical approach, retrieving rule with unlabeled nonterminals.
</prevsent>
<prevsent>performance gains are reported over standard hierarchical models using both full parse trees and shallow syn tax.moving beyond syntactic information, some attempts have recently been made to add semantic annotations to smt.
</prevsent>
</prevsection>
<citsent citstr=" N09-2004 ">
wu and fung (2009) <papid> N09-2004 </papid>present two-pass model to incorporate semantic information to the phrase-based smt pipeline.</citsent>
<aftsection>
<nextsent>the method performs conventional translation in first step, followed by constituent reordering step seeking to maximize the cross-lingual match of the semantic role labels of the translation and source sentences.
</nextsent>
<nextsent>liu and gildea (2010) <papid> C10-1081 </papid>add features extracted from the source sentences annotated with semantic role labels in tree-to-string smt model.</nextsent>
<nextsent>they modify syntax-based smt system in order to penal ize/reward role reordering and role deletion.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1483">
<title id=" W11-2136.xml">shallow semantic trees for smt </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wu and fung (2009) <papid> N09-2004 </papid>present two-pass model to incorporate semantic information to the phrase-based smt pipeline.</prevsent>
<prevsent>the method performs conventional translation in first step, followed by constituent reordering step seeking to maximize the cross-lingual match of the semantic role labels of the translation and source sentences.</prevsent>
</prevsection>
<citsent citstr=" C10-1081 ">
liu and gildea (2010) <papid> C10-1081 </papid>add features extracted from the source sentences annotated with semantic role labels in tree-to-string smt model.</citsent>
<aftsection>
<nextsent>they modify syntax-based smt system in order to penal ize/reward role reordering and role deletion.
</nextsent>
<nextsent>the input sentence is parsed for semantic roles and the roles are then projected onto the target side using word alignment information at decoding time.
</nextsent>
<nextsent>they assume that one-to-one mapping between source and target roles is desirable.baker et al (2010) propose to graft semantic information, namely named entities and modalities, to syntactic tags in syntax-based model.
</nextsent>
<nextsent>the vocabulary of nonterminals is specialized using these mantic categories, for instance, noun phrase (np) whose head is geopolitical entity (gpe) will be tagged as npgpe, making the rule table less am biguous.similar to (baker et al, 2010) we specialize vocabulary of syntactic nonterminals with semantic information, however we use shallow syntax (basephrases) and semantic role labels instead of constituent parse and named entities.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1485">
<title id=" W11-2136.xml">shallow semantic trees for smt </title>
<section> proposed method.  </section>
<citcontext>
<prevsection>
<prevsent>2m sentences) and news (?
</prevsent>
<prevsent>5m sentences) corpora.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
these models were interpolated using scripts provided in moses (koehn and schroeder, 2007).<papid> W07-0733 </papid></citsent>
<aftsection>
<nextsent>at pre-processing stage, sentences longer than 80 tokens were filtered from the training/development corpus.
</nextsent>
<nextsent>the parallel corpus was then tokenized andtruecased.
</nextsent>
<nextsent>additionally, for en-de, compound splitting of the german side of the corpus was performed using frequency based method described in (koehnand knight, 2003).<papid> E03-1076 </papid></nextsent>
<nextsent>this method helps alleviate sparsity, reducing the size of the vocabulary by decomposing compounds into their base words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1486">
<title id=" W11-2136.xml">shallow semantic trees for smt </title>
<section> proposed method.  </section>
<citcontext>
<prevsection>
<prevsent>at pre-processing stage, sentences longer than 80 tokens were filtered from the training/development corpus.
</prevsent>
<prevsent>the parallel corpus was then tokenized andtruecased.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
additionally, for en-de, compound splitting of the german side of the corpus was performed using frequency based method described in (koehnand knight, 2003).<papid> E03-1076 </papid></citsent>
<aftsection>
<nextsent>this method helps alleviate sparsity, reducing the size of the vocabulary by decomposing compounds into their base words.
</nextsent>
<nextsent>re casing and detokenization, along with compound merging of the translations into german, were handled at post-processing stage.
</nextsent>
<nextsent>compound merging was performed by finding the most likely sequences of words to be merged into previously seen compounds (stymne, 2009).<papid> E09-3008 </papid></nextsent>
<nextsent>3.1 source language annotation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1487">
<title id=" W11-2136.xml">shallow semantic trees for smt </title>
<section> proposed method.  </section>
<citcontext>
<prevsection>
<prevsent>this method helps alleviate sparsity, reducing the size of the vocabulary by decomposing compounds into their base words.
</prevsent>
<prevsent>re casing and detokenization, along with compound merging of the translations into german, were handled at post-processing stage.
</prevsent>
</prevsection>
<citsent citstr=" E09-3008 ">
compound merging was performed by finding the most likely sequences of words to be merged into previously seen compounds (stymne, 2009).<papid> E09-3008 </papid></citsent>
<aftsection>
<nextsent>3.1 source language annotation.
</nextsent>
<nextsent>for rule extraction, training and test, the english sideof the corpus was annotated with semantic role labels (srl) using the toolkit senna2, which also outputs pos and base-phrase (without prepositionalattachment) tags.
</nextsent>
<nextsent>the resulting source language annotation was used to produce trees in order to build tree-to-string model in moses.
</nextsent>
<nextsent>1http://www.speech.sri.com/projects/ srilm/ 2http://ml.nec-labs.com/senna/ 317 np vp np pp np o np vp np advp prp vbz to vb dt nn to nn punc cc prp vbz rb vbd wdt rb he intends to donate this money to charity , but he has not decided which yet figure 1: example of pos tags and base-phrase annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1488">
<title id=" W11-2136.xml">shallow semantic trees for smt </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>for example, np:a0:donate,intend+vp:t:intend and np:a1:donate+a2:donate are created for the tree in figure 3.
</prevsent>
<prevsent>as baseline to compare against our proposed approach (srl), we took phrase-based smt system (pb) built using the moses toolkit with the same datasets and training conditions described in section 3.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the results are reported in terms of standard bleu (papineni et al, 2002) (<papid> P02-1040 </papid>and its case sensitive version, bleu-c) and tested for statistical significance using an approximate randomization test (rie zler and maxwell, 2005) <papid> W05-0908 </papid>with 100 iterations.</citsent>
<aftsection>
<nextsent>in addition, we included an intermediate model between these two: hierarchical model informed with source-language base-phrase information (chunk).
</nextsent>
<nextsent>for the english-spanish task we also built purely hierarchical model (hier) using moses and the same datasets and training conditions.
</nextsent>
<nextsent>for the english-german task, hierarchical models have not been shown to outperform standard phrase-based models in previous work (koehn et al, 2010).<papid> W10-1715 </papid></nextsent>
<nextsent>table 1 shows the performance achieved for the english-spanish translation task test set, where (srl)is our official submission.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1489">
<title id=" W11-2136.xml">shallow semantic trees for smt </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>for example, np:a0:donate,intend+vp:t:intend and np:a1:donate+a2:donate are created for the tree in figure 3.
</prevsent>
<prevsent>as baseline to compare against our proposed approach (srl), we took phrase-based smt system (pb) built using the moses toolkit with the same datasets and training conditions described in section 3.
</prevsent>
</prevsection>
<citsent citstr=" W05-0908 ">
the results are reported in terms of standard bleu (papineni et al, 2002) (<papid> P02-1040 </papid>and its case sensitive version, bleu-c) and tested for statistical significance using an approximate randomization test (rie zler and maxwell, 2005) <papid> W05-0908 </papid>with 100 iterations.</citsent>
<aftsection>
<nextsent>in addition, we included an intermediate model between these two: hierarchical model informed with source-language base-phrase information (chunk).
</nextsent>
<nextsent>for the english-spanish task we also built purely hierarchical model (hier) using moses and the same datasets and training conditions.
</nextsent>
<nextsent>for the english-german task, hierarchical models have not been shown to outperform standard phrase-based models in previous work (koehn et al, 2010).<papid> W10-1715 </papid></nextsent>
<nextsent>table 1 shows the performance achieved for the english-spanish translation task test set, where (srl)is our official submission.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1490">
<title id=" W11-2136.xml">shallow semantic trees for smt </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, we included an intermediate model between these two: hierarchical model informed with source-language base-phrase information (chunk).
</prevsent>
<prevsent>for the english-spanish task we also built purely hierarchical model (hier) using moses and the same datasets and training conditions.
</prevsent>
</prevsection>
<citsent citstr=" W10-1715 ">
for the english-german task, hierarchical models have not been shown to outperform standard phrase-based models in previous work (koehn et al, 2010).<papid> W10-1715 </papid></citsent>
<aftsection>
<nextsent>table 1 shows the performance achieved for the english-spanish translation task test set, where (srl)is our official submission.
</nextsent>
<nextsent>one can notice significant gain in performance (up to 6% bleu) in using tree-based models (with or without source language 3using the moses implementation relax-parse for samt 2annotation) as opposed to using standard phrase based models.
</nextsent>
<nextsent>model bleu bleu-c pb 0.2429 0.2340 srl 0.2901 0.2805 hier 0.3029 0.2933 chunk 0.3034 0.2935 table 1: english-spanish experiments - differences between all pairs of models are statistically significant with 99% confidence, except for the pair (hier, chunk) the purely hierarchical approach performs aswell as our linguistically informed tree-based models (chunk and srl).
</nextsent>
<nextsent>on the one hand this finding is somewhat disappointing as we expected that tree based models would benefit from linguistic annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1492">
<title id=" W12-1631.xml">dialog system using real time crowdsourcing and twitter largescale corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is lot of language data on the internet.
</prevsent>
<prevsent>twitter offers many apis to retrieve or search post status data, and this data is frequently used in research, such as in stockmarket prediction (bollen et al,2011), the spread of information through social media (bakshy and hofman, 2011), and representations of textual content(ramage et al, 2010).
</prevsent>
</prevsection>
<citsent citstr=" N10-1020 ">
several models for conversation using twitter data (ritter etal., 2010; <papid> N10-1020 </papid>higashinaka et al, 2011) have been proposed because of the datas vast size and conversational nature.kelly (2009) previously showed that 37% of english tweets are conversational, of which 69% aretwo-length (one status post and reply).</citsent>
<aftsection>
<nextsent>in our analysis of over 2.5 million tweets, 37.5% of all japanese tweets are conversational, which matches kellysdata.
</nextsent>
<nextsent>however, less than 58.3% of these are two length tweets.
</nextsent>
<nextsent>many chat bots are rule-based, which requires lot of human effort to create or add new rules.
</nextsent>
<nextsent>for example, a.l.i.c.e (wallace, 2009), which won the b utterance pair status post reply user utterance calculation similarity it was cold yesterday.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1493">
<title id=" W12-0203.xml">looking at word meaning an interactive visualization of semantic vector spaces for dutch synsets </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the basic assumption of the approach is that words occurring in similar contexts will have similar meaning.
</prevsent>
<prevsent>speficic implementations of this general idea have been developed for wide variety of computational linguistic tasks, including thesaurus extraction and word sense disambiguation, question answering and the modeling of human behavior in psycho linguistic experiments (see turney and pantel (2010) for general overview of applications and speficic models).
</prevsent>
</prevsection>
<citsent citstr=" W09-0214 ">
in recent years, semantic vector spaces have also seen applications in more traditional domains of linguistics, like dia chronic lexical studies (sagi et al ., 2009; <papid> W09-0214 </papid>cook and stevenson, 2010; rohrdantz et al , 2011) , <papid> P11-2053 </papid>or the study of lexical variation (peirsman et al , 2010).</citsent>
<aftsection>
<nextsent>in this paper, we want to show how semantic vector spaces can further aidthe linguistic analysis of lexical semantics, provided that they are made accessible to lexicolo gists and lexicographers through visualization of their output.although all applications mentioned above assume that distributional models can capture word meaning to some extent, most of them use svssonly in an indirect, black-box way, without analyzing which semantic properties and relations actually manifest themselves in the models.
</nextsent>
<nextsent>thisis mainly consequence of the task-based evaluation paradigm prevalent in computational lin guistics: the researchers address specific task for which there is pre-defined gold standard; they implement model with some new features,that usually stem from fairly intuitive, commonsense reasoning of why some feature might benefit the task at hand; the new model is then tested against the gold standard data and there is an evaluation in terms of precision, recall and f-score.
</nextsent>
<nextsent>in rare cases, there is also an error analysis that leads to hypotheses about semantic characteristics that are not yet properly modeled.
</nextsent>
<nextsent>yet hardly ever, there is in-depth analysis of which semantics the tested model actually captures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1494">
<title id=" W12-0203.xml">looking at word meaning an interactive visualization of semantic vector spaces for dutch synsets </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the basic assumption of the approach is that words occurring in similar contexts will have similar meaning.
</prevsent>
<prevsent>speficic implementations of this general idea have been developed for wide variety of computational linguistic tasks, including thesaurus extraction and word sense disambiguation, question answering and the modeling of human behavior in psycho linguistic experiments (see turney and pantel (2010) for general overview of applications and speficic models).
</prevsent>
</prevsection>
<citsent citstr=" P11-2053 ">
in recent years, semantic vector spaces have also seen applications in more traditional domains of linguistics, like dia chronic lexical studies (sagi et al ., 2009; <papid> W09-0214 </papid>cook and stevenson, 2010; rohrdantz et al , 2011) , <papid> P11-2053 </papid>or the study of lexical variation (peirsman et al , 2010).</citsent>
<aftsection>
<nextsent>in this paper, we want to show how semantic vector spaces can further aidthe linguistic analysis of lexical semantics, provided that they are made accessible to lexicolo gists and lexicographers through visualization of their output.although all applications mentioned above assume that distributional models can capture word meaning to some extent, most of them use svssonly in an indirect, black-box way, without analyzing which semantic properties and relations actually manifest themselves in the models.
</nextsent>
<nextsent>thisis mainly consequence of the task-based evaluation paradigm prevalent in computational lin guistics: the researchers address specific task for which there is pre-defined gold standard; they implement model with some new features,that usually stem from fairly intuitive, commonsense reasoning of why some feature might benefit the task at hand; the new model is then tested against the gold standard data and there is an evaluation in terms of precision, recall and f-score.
</nextsent>
<nextsent>in rare cases, there is also an error analysis that leads to hypotheses about semantic characteristics that are not yet properly modeled.
</nextsent>
<nextsent>yet hardly ever, there is in-depth analysis of which semantics the tested model actually captures.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1495">
<title id=" W12-0203.xml">looking at word meaning an interactive visualization of semantic vector spaces for dutch synsets </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even though task based evaluation and shared test datasets are vitalto the objective comparison of computational approaches, they are, in our opinion, not sufficient to assess whether the phenomenon of lexical semantics is modeled adequately from linguistic perspective.
</prevsent>
<prevsent>this lack of linguistic insight into the functioning of svss is also bemoaned in the community itself.
</prevsent>
</prevsection>
<citsent citstr=" W11-2501 ">
for example, baroni and lenci (2011) <papid> W11-2501 </papid>say that to gain real insight into the 16abilities of dsms (distributional semantic models, a/n) to address lexical semantics, existing benchmarks must be complemented with more intrinsically oriented approach, to perform direct tests on the specific aspects of lexical knowledge captured by the models?.</citsent>
<aftsection>
<nextsent>they go on to present their own lexical database that is similar to wordnet, but includes some additional semantic relations.
</nextsent>
<nextsent>they propose researchers test their model against the database to find out which of the encoded relations it can detect.
</nextsent>
<nextsent>however, such an analysis still boils down to checking whether amodel can replicate pre-defined structuralist semantic relations, which themselves represent quite impoverished take on lexical semantics, atleast from linguistic perspective.
</nextsent>
<nextsent>in this paper, we want to argue that more linguistically adequate investigation of how svss capture lexical semantics, should take step back from the evalution-against-gold-standard paradigm and do direct and unbiased analysis of the output of svs models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1496">
<title id=" W12-0203.xml">looking at word meaning an interactive visualization of semantic vector spaces for dutch synsets </title>
<section> token-level svs.  </section>
<citcontext>
<prevsection>
<prevsent>note that this approach first needs to construct type-level svs for the first-order context words that can then be used to create second-order token-vector.
</prevsent>
<prevsent>in our study, we therefore first constructed atype-level svs for the 573,127 words in our corpus with frequency higher than 2.
</prevsent>
</prevsection>
<citsent citstr=" L08-1204 ">
since the focus of this study is visualization rather than finding optimal svs parameter settings, we chose settings that proved optimal in our previous studies(peirsman et al , 2008; heylen et al , 2008; <papid> L08-1204 </papid>peirsman et al , 2010).</citsent>
<aftsection>
<nextsent>for the context features of this svs, we used bag-of-words approach with awindow of 4 to the left and right around the targets.
</nextsent>
<nextsent>the context feature set was restricted to the 5430 words, that were the among the 7000 most frequent words in the corpus, (minus stop list of34 high-frequent function words) and that occurred at least 50 times in both the netherlandic and belgian part of the corpus.
</nextsent>
<nextsent>the latter was done to make sure that netherlandic and belgian type vectors were not dissimilar just because of topical bias from proper names, place names or words relating to local events.
</nextsent>
<nextsent>raw co-occurrence frequencies were weighted with pointwise mutual information and negative pmis were set to zero.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1498">
<title id=" W12-0203.xml">looking at word meaning an interactive visualization of semantic vector spaces for dutch synsets </title>
<section> visualization.  </section>
<citcontext>
<prevsection>
<prevsent>future implementation may use 3dmds solutions.
</prevsent>
<prevsent>of course, other dimension reduction techniques than mds exist: pca is usedin latent semantic analysis (landauer and du mais, 1997) and has been applied by sagi et al (2009) <papid> W09-0214 </papid>for modeling token semantics.</prevsent>
</prevsection>
<citsent citstr=" E09-1013 ">
alternatively, latent dirichlect allocation (lda) is at the heart of topic models (griffiths et al , 2007) and was adapted by brody and lapata (2009) <papid> E09-1013 </papid>for modeling token semantics.</citsent>
<aftsection>
<nextsent>however, these techniques all aim at bringing out latent structure that abstracts away from the raw?
</nextsent>
<nextsent>underlying svs similarities.
</nextsent>
<nextsent>our aim, on the other hand,is precisely to investigate how svss structure semantics based on contextual distribution properties before additional latent structuring is applied.
</nextsent>
<nextsent>we therefore want 2d representation of the token similarity matrix that is as faithful as possible and that is what mds delivers 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1501">
<title id=" W11-2408.xml">discovering commonsense entailment rules implicit in sentences </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these results include entailment rules like is the author of ? wrote y?
</prevsent>
<prevsent>(which is true provided is literary work) and less dependable ones like caused ? is blamed on x?.
</prevsent>
</prevsection>
<citsent citstr=" N07-1071 ">
this work was refined by pantel et al (2007) <papid> N07-1071 </papid>by assigning the and terms semantic types (inferential selectional preferences ? isp) based on lexical abstraction from empirically observed argument types.</citsent>
<aftsection>
<nextsent>a limitation of the approach is that the conditional rules obtained are largely limited to ones expressing some rough synonymy or similarity relation.
</nextsent>
<nextsent>pekar (2006) <papid> N06-1007 </papid>developed related methods for learning the implications of an event based on the regular co-occurrence of two verbs within locally coherent text?, acquiring rules like was appointed as y?</nextsent>
<nextsent>suggests that became y?, but, as in dirt, we lack information about the types of and y, and only acquire binary relations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1502">
<title id=" W11-2408.xml">discovering commonsense entailment rules implicit in sentences </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this work was refined by pantel et al (2007) <papid> N07-1071 </papid>by assigning the and terms semantic types (inferential selectional preferences ? isp) based on lexical abstraction from empirically observed argument types.</prevsent>
<prevsent>a limitation of the approach is that the conditional rules obtained are largely limited to ones expressing some rough synonymy or similarity re lation.</prevsent>
</prevsection>
<citsent citstr=" N06-1007 ">
pekar (2006) <papid> N06-1007 </papid>developed related methods for learning the implications of an event based on the regular co-occurrence of two verbs within locally coherent text?, acquiring rules like was appointed as y?</citsent>
<aftsection>
<nextsent>suggests that became y?, but, as in dirt, we lack information about the types of and y, and only acquire binary relations.
</nextsent>
<nextsent>girju (2003) applied hearsts (1998) procedure for finding lexico-syntactic patterns to discover causal relations between nouns, as in earthquakes generate tsunami?.
</nextsent>
<nextsent>chklovski and pantel (2004) <papid> W04-3205 </papid>used pat 59 (s   (np $.</nextsent>
<nextsent>(vp   (/,/ $.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1503">
<title id=" W11-2408.xml">discovering commonsense entailment rules implicit in sentences </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>suggests that became y?, but, as in dirt, we lack information about the types of and y, and only acquire binary relations.
</prevsent>
<prevsent>girju (2003) applied hearsts (1998) procedure for finding lexico-syntactic patterns to discover causal relations between nouns, as in earthquakes generate tsunami?.
</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
chklovski and pantel (2004) <papid> W04-3205 </papid>used pat 59 (s   (np $.</citsent>
<aftsection>
<nextsent>(vp   (/,/ $.
</nextsent>
<nextsent>(s   (vp   (vbg  hoping)  (s   (vp   to)))))))) (s   (np $.
</nextsent>
<nextsent>(vp   ((cc   but) $..
</nextsent>
<nextsent>(vp   (aux   did)   (rb   /n[o]t/)))))) (s   (np $.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1504">
<title id=" W11-2408.xml">discovering commonsense entailment rules implicit in sentences </title>
<section> i disagree. </section>
<citcontext>
<prevsection>
<prevsent>lower ratings are better; see fig.
</prevsent>
<prevsent>2.
</prevsent>
</prevsection>
<citsent citstr=" A00-2018 ">
for evaluation, we used corpus of personal stories from weblogs (gordon and swanson, 2009), parsed with statistical parser (charniak, 2000).<papid> A00-2018 </papid></citsent>
<aftsection>
<nextsent>we sampled 100 output rules and rated them on scale of 15 (1 being best) based on the criteria in fig.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>to decide if rule meets the criteria, it is helpful to imagine dialogue with computer agent.
</nextsent>
<nextsent>told an instantiated form of the antecedent, the agent asks for confirmation of potential conclusion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1505">
<title id=" W11-2408.xml">discovering commonsense entailment rules implicit in sentences </title>
<section> i disagree. </section>
<citcontext>
<prevsection>
<prevsent>but in our case, (a) we are looking for broad range of (more or less strong) consequence relationships, and (b) the relationships are between entire clauses, not lexical items.
</prevsent>
<prevsent>we are simply not likely to find multiple occurrences of the same pair of clauses in variety of syntactic configurations, all indicating aconsequence relation ? youre unlikely to find multiple redundant patterns relating clauses, as in went up to the door but didnt knock on it?.there is more work to be done to arrive at reliable, inference-ready knowledge base of such rules.the primary desideratum is to produce logical representation for the rules such that they can be used in the epilog reasoner (schubert and hwang, 2000).
</prevsent>
</prevsection>
<citsent citstr=" W08-2222 ">
computing logical forms (as, e.g., in bos (2008)) <papid> W08-2222 </papid>and then deriving logically formulated rules from these rather than deriving sentential forms directly from text should also allow us to be more precise about dropping modifiers, reshaping into generic present tense from other tenses, and other issues that affect the quality of the statements.</citsent>
<aftsection>
<nextsent>we have preliminary version of logical form generator that derives lfsfrom treebank parses that can support this direction.
</nextsent>
<nextsent>further filtering techniques (based both on the surface form and the logical form) should keep the desired inference rules while improving quality.
</nextsent>
<nextsent>acknowledgements this work was supported by nsf grants iis1016735 and iis-0916599, and onr sttr subcontract n00014-10-m-0297.
</nextsent>
<nextsent>62
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1506">
<title id=" W12-1005.xml">harvesting indices to grow a controlled vocabulary towards improved access to historical legal texts </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>despite some similarities, modern legal vocabularies such as jurivoc3 or the glin subject term index4 are not readily applicable to medieval and early modern jurisdictions (e.g., they lack concepts such as feudal tenure or witchcraft).
</prevsent>
<prevsent>the vocabulaire international de la diplomatique (milagros crcel ort?, 1997) is an attempt at avocabulary for describing types of historical documents, but it is not fine-grained enough and does not consider historical regional differences.
</prevsent>
</prevsection>
<citsent citstr=" P08-1106 ">
there are various approaches for automatically generating back-of-the-book indices and thus potential descriptors (e.g., csomai and mihalcea (2008)), <papid> P08-1106 </papid>but these are intended for book-length texts in single language; in the case of historical editions, however, the documents differ widely in length, language, and age.romanello et al (2009) have parsed ocr processed indices scriptorum and extracted information to support the creation of collection of fragmentary texts.</citsent>
<aftsection>
<nextsent>even though this is completely different task, the approach is somewhat related to ours, in that it aims to utilize the valuable information contained in manually created indices.
</nextsent>
<nextsent>the collection of swiss law sources is an edition of historical legal texts created on swiss territory from the early middle ages up to 1798.
</nextsent>
<nextsent>the collection includes acts, decrees, and ordinances, but also indentures, administrative documents, court transcripts, and other types of documents.
</nextsent>
<nextsent>since 1894, the law sources foundation has edited and published more than 60,000 pages of source material and commentary in over 100 volumes.the primary users of the collection are historians, but it is also an important source for the swiss-german dictionary, which documents the 3http://bger.ch/jurisdiction-jurivoc-home 4http://glin.gov/ 25german language in switzerland from the late middle ages to the 21st century.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1507">
<title id=" W12-1005.xml">harvesting indices to grow a controlled vocabulary towards improved access to historical legal texts </title>
<section> extracting and conflating index.  </section>
<citcontext>
<prevsection>
<prevsent>subject indices.
</prevsent>
<prevsent>looking forways to further conflate the terms, we noted number of mismatches due to morphological variation (such as singular and plural forms), even though subject indices are not as inflection ally rich as normal german text.since many index terms are highly domain specific or specific to swiss german (e.g., compounds of the term anke butter?
</prevsent>
</prevsection>
<citsent citstr=" L08-1406 ">
like ankenballenor ankenhaus), we did not use rule-based morphological analyzer (such as gertwol, stripy zebra, or morphisto; for an overview see mahlow and piotrowski (2009)) but the base forms tool from the asv toolbox (biemann et al, 2008),<papid> L08-1406 </papid>which is based on pretree classifiers.</citsent>
<aftsection>
<nextsent>the base forms tool does not perform morphological analysis, but is more akin to stemmer, so that its output is not necessarily linguistically correct; however, since we are primarily interested in term conflation, this is not major problem.
</nextsent>
<nextsent>when the output of the system was empty or malformed we used the original term to ensure maximum overlap.
</nextsent>
<nextsent>we manually reviewed and, where necessary, corrected the base forms, also to get better understanding of the kind of potential conflations.
</nextsent>
<nextsent>this cut down the list of keywords from 5138 to 4881 terms, i.e., 490 terms were morphological variants that could be conflated to 233 concepts.the majority of term conflations concern variation in number (kapelle chapel?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1508">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" H05-1095 ">
a growing body of machine translation research aims to exploit lexical patterns (e.g., grams and phrase pairs) with gaps (simard et al., 2005; <papid> H05-1095 </papid>chiang, 2005; <papid> P05-1033 </papid>xiong et al, 2011).<papid> P11-1129 </papid>typically, these gappy patterns?</citsent>
<aftsection>
<nextsent>are discovered using heuristics based on word alignments or local statistics such as mutual information.
</nextsent>
<nextsent>in this paper, we develop generative models of monolingual and parallel text that build sentences using gappy patterns of arbitrary length and with arbitrarily many gaps.we exploit bayesian nonparametrics and collapsed gibbs sampling to discover salient patterns in corpus.
</nextsent>
<nextsent>we evaluate the patterns qualitatively and also add them as features toan mt system, reporting promising preliminary results.
</nextsent>
<nextsent>beginning with the success of phrase-based translation models (koehn et al, 2003), <papid> N03-1017 </papid>trend arose of modeling larger and increasingly complex structural units in translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1509">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P05-1033 ">
a growing body of machine translation research aims to exploit lexical patterns (e.g., grams and phrase pairs) with gaps (simard et al., 2005; <papid> H05-1095 </papid>chiang, 2005; <papid> P05-1033 </papid>xiong et al, 2011).<papid> P11-1129 </papid>typically, these gappy patterns?</citsent>
<aftsection>
<nextsent>are discovered using heuristics based on word alignments or local statistics such as mutual information.
</nextsent>
<nextsent>in this paper, we develop generative models of monolingual and parallel text that build sentences using gappy patterns of arbitrary length and with arbitrarily many gaps.we exploit bayesian nonparametrics and collapsed gibbs sampling to discover salient patterns in corpus.
</nextsent>
<nextsent>we evaluate the patterns qualitatively and also add them as features toan mt system, reporting promising preliminary results.
</nextsent>
<nextsent>beginning with the success of phrase-based translation models (koehn et al, 2003), <papid> N03-1017 </papid>trend arose of modeling larger and increasingly complex structural units in translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1510">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P11-1129 ">
a growing body of machine translation research aims to exploit lexical patterns (e.g., grams and phrase pairs) with gaps (simard et al., 2005; <papid> H05-1095 </papid>chiang, 2005; <papid> P05-1033 </papid>xiong et al, 2011).<papid> P11-1129 </papid>typically, these gappy patterns?</citsent>
<aftsection>
<nextsent>are discovered using heuristics based on word alignments or local statistics such as mutual information.
</nextsent>
<nextsent>in this paper, we develop generative models of monolingual and parallel text that build sentences using gappy patterns of arbitrary length and with arbitrarily many gaps.we exploit bayesian nonparametrics and collapsed gibbs sampling to discover salient patterns in corpus.
</nextsent>
<nextsent>we evaluate the patterns qualitatively and also add them as features toan mt system, reporting promising preliminary results.
</nextsent>
<nextsent>beginning with the success of phrase-based translation models (koehn et al, 2003), <papid> N03-1017 </papid>trend arose of modeling larger and increasingly complex structural units in translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1511">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we develop generative models of monolingual and parallel text that build sentences using gappy patterns of arbitrary length and with arbitrarily many gaps.we exploit bayesian nonparametrics and collapsed gibbs sampling to discover salient patterns in corpus.
</prevsent>
<prevsent>we evaluate the patterns qualitatively and also add them as features toan mt system, reporting promising preliminary results.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
beginning with the success of phrase-based translation models (koehn et al, 2003), <papid> N03-1017 </papid>trend arose of modeling larger and increasingly complex structural units in translation.</citsent>
<aftsection>
<nextsent>one thread of work has focused on the use of lexical patterns with gaps.
</nextsent>
<nextsent>simard et al.
</nextsent>
<nextsent>(2005) proposed using phrase pairs with gaps in aphrase-based translation model, providing heuristic method to extract gappy phrase pairs from word aligned parallel corpora.
</nextsent>
<nextsent>the widely-used hierarchical phrase-based translation framework was introduced by chiang (2005) <papid> P05-1033 </papid>and also relies on simple heuristic for phrase pair extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1515">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we exploit non parametric priors and use bayesian inference to discover the most salient gappy patterns in monolingual and parallel text.
</prevsent>
<prevsent>we first inspect these patterns manually and discuss the categories of phenomena that they capture.
</prevsent>
</prevsection>
<citsent citstr=" D07-1080 ">
we also add them as features in discriminatively-trained phrase-based mt system, using standard techniques to train their weights (arun and koehn, 2007; watanabe et al,2007) <papid> D07-1080 </papid>and incorporate them during decoding (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>we present experiments for spanish english and chinese-english translation, reporting encouraging preliminary results.
</nextsent>
<nextsent>there is rich history of trigger-based language modeling in the speech recognition community, typically involving the use of statistical tests to discover useful trigger-word pairs (rosenfeld, 1996; jelinek, 1997).
</nextsent>
<nextsent>xiong et al (2011) <papid> P11-1129 </papid>used rosenfelds mutual information procedure to discover trigger pairs and added single feature to phrase-based mt system that scores new words based on all potential triggers from previous parts of the derivation.</nextsent>
<nextsent>we arenot aware of prior work that uses generative modeling and bayesian nonparametrics to discover the sesame types of patterns automatically; doing so allows us to discover larger patterns with more words and gaps if they are warranted by the data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1516">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we exploit non parametric priors and use bayesian inference to discover the most salient gappy patterns in monolingual and parallel text.
</prevsent>
<prevsent>we first inspect these patterns manually and discuss the categories of phenomena that they capture.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
we also add them as features in discriminatively-trained phrase-based mt system, using standard techniques to train their weights (arun and koehn, 2007; watanabe et al,2007) <papid> D07-1080 </papid>and incorporate them during decoding (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>we present experiments for spanish english and chinese-english translation, reporting encouraging preliminary results.
</nextsent>
<nextsent>there is rich history of trigger-based language modeling in the speech recognition community, typically involving the use of statistical tests to discover useful trigger-word pairs (rosenfeld, 1996; jelinek, 1997).
</nextsent>
<nextsent>xiong et al (2011) <papid> P11-1129 </papid>used rosenfelds mutual information procedure to discover trigger pairs and added single feature to phrase-based mt system that scores new words based on all potential triggers from previous parts of the derivation.</nextsent>
<nextsent>we arenot aware of prior work that uses generative modeling and bayesian nonparametrics to discover the sesame types of patterns automatically; doing so allows us to discover larger patterns with more words and gaps if they are warranted by the data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1521">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we arenot aware of prior work that uses generative modeling and bayesian nonparametrics to discover the sesame types of patterns automatically; doing so allows us to discover larger patterns with more words and gaps if they are warranted by the data.
</prevsent>
<prevsent>in addition to the gappy phrase-based (simard et al., 2005) <papid> H05-1095 </papid>and hierarchical phrase-based (chiang, 2005) <papid> P05-1033 </papid>models mentioned earlier, other researchers have explored the use of bilingual gappy structures for machine translation.</prevsent>
</prevsection>
<citsent citstr=" N10-1140 ">
crego and yvon (2009) and 512 ?( ) = . ?( ) = baltic states it provides either too little or too much . it  neither particularly complicated nor novel . nato must either say   yes   or   no   to the baltic states . good scientific ideas formulated in bad english either die or get repackaged . nato must either say   yes   or   no   to the baltic states . ?( ) = either __ or pi????????( ) = either __ or ?( ) = to the ?( ) =   __   __   __  ?( ) = must ?( ) = yes __ no ?( ) = say?( ) = nato figure 1: sentence from the news commentary corpus, along with color assignments for the words and the pi function for each color.galley and manning (2010) <papid> N10-1140 </papid>proposed ways of incorporating phrase pairs with gaps into standard left-to right decoding algorithms familiar to phrase-basedand -gram-based mt; both used heuristics to extract phrase pairs.</citsent>
<aftsection>
<nextsent>bansal et al (2011) <papid> P11-1131 </papid>presented model and training procedure for word alignment that uses phrase pairs with gaps.</nextsent>
<nextsent>they use semi markov model with an enlarged dynamic programming state in order to represent alignment between gappy phrases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1522">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to the gappy phrase-based (simard et al., 2005) <papid> H05-1095 </papid>and hierarchical phrase-based (chiang, 2005) <papid> P05-1033 </papid>models mentioned earlier, other researchers have explored the use of bilingual gappy structures for machine translation.</prevsent>
<prevsent>crego and yvon (2009) and 512 ?( ) = . ?( ) = baltic states it provides either too little or too much . it  neither particularly complicated nor novel . nato must either say   yes   or   no   to the baltic states . good scientific ideas formulated in bad english either die or get repackaged . nato must either say   yes   or   no   to the baltic states . ?( ) = either __ or pi????????( ) = either __ or ?( ) = to the ?( ) =   __   __   __  ?( ) = must ?( ) = yes __ no ?( ) = say?( ) = nato figure 1: sentence from the news commentary corpus, along with color assignments for the words and the pi function for each color.galley and manning (2010) <papid> N10-1140 </papid>proposed ways of incorporating phrase pairs with gaps into standard left-to right decoding algorithms familiar to phrase-basedand -gram-based mt; both used heuristics to extract phrase pairs.</prevsent>
</prevsection>
<citsent citstr=" P11-1131 ">
bansal et al (2011) <papid> P11-1131 </papid>presented model and training procedure for word alignment that uses phrase pairs with gaps.</citsent>
<aftsection>
<nextsent>they use semi markov model with an enlarged dynamic programming state in order to represent alignment between gappy phrases.
</nextsent>
<nextsent>their model permits up to one gapper phrase while our models permit an arbitrary number.
</nextsent>
<nextsent>we first present model that generates sentence as set of lexical items that we will refer to as gappy patterns, or simply patterns.
</nextsent>
<nextsent>a pattern is defined as sequence containing elements of two types: word sand gaps.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1523">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>represents gap that can be filled by any non empty sequence of words.
</prevsent>
<prevsent>ing new illegal pattern during inference is always zero (eq.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
3).we also perform inference on transformed version of the corpus in which every word is replaced with its hard word class obtained from brown clustering (brown et al, 1992).<papid> J92-4003 </papid></citsent>
<aftsection>
<nextsent>one property of brown clusters is that each function word effectively receives its own class, as each ends up in cluster in which it occupies 95% of the token counts of all types in the cluster.
</nextsent>
<nextsent>we call clusters that satisfy this property singleton clusters.to obtain brown clusters for the source and target languages, we used code from liang (2005).5we used the data from the news commentary corpus along with the first 500k sentences of the additional monolingual newswire data also provided forthe wmt shared tasks.
</nextsent>
<nextsent>we used 300 clusters, ignoring words that appeared only once in this corpus.
</nextsent>
<nextsent>we did not use the hierarchical information from the clusters but merely converted each cluster name intoa unique integer, using one additional integer for unknown words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1524">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>from these patterns we can see that our models can also be usedto find collocations, but we note that these are discovered in the context of the gappy patterns.
</prevsent>
<prevsent>that is, due to the use of latent variables in our models (the color assignments), there is natural trading-offeffect whereby the gappy patterns encourage particular non-gappy patterns to be used, and vice versa.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
5.1.2 bilingual modelwe use the news commentary corpus for each language and take the intersection of giza++ (och and ney, 2003) <papid> J03-1002 </papid>word alignments in each direction, thereby ensuring that they are 1-to-1 alignments.</citsent>
<aftsection>
<nextsent>weran gibbs sampling for 300 iterations, averaging pattern counts from the last 200.
</nextsent>
<nextsent>we set ? = 100,?
</nextsent>
<nextsent>= 3, and ? = 0.5.
</nextsent>
<nextsent>we ran the model in 3 con ditions: source words, target words; source clusters, target clusters; and source clusters, target words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1526">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 quantitative evaluation.
</prevsent>
<prevsent>we consider the spanish-to-english (esen) translation task from the acl-2010 workshop on statistical machine translation (callison-burch et al., 2010).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we trained moses system (koehn et al, 2007) <papid> P07-2045 </papid>following the baseline training instructions for the shared task.7 in particular, we performed word alignment in each direction using giza++ (och and ney, 2003), <papid> J03-1002 </papid>used the grow-diag-final-and?</citsent>
<aftsection>
<nextsent>heuristic for symmetrization, and extracted phrase pairs up to maximum length of seven.
</nextsent>
<nextsent>after filtering sentence pairs with one sentence longer than 50 words, we ended up with 1.45m sentence pairs of europarl data and 91k sentence pairs of news commentary data.
</nextsent>
<nextsent>language models (n = 5) were estimated using the sri language modeling toolkit (stolcke, 2002) with modified kneser-ney smoothing (chen and good man, 1998).
</nextsent>
<nextsent>language models were trained on the target side of the parallel corpus as well as the first 5 million additional sentences from the extra english monolingual newswire data provided for the shared tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1528">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we used news-test2008 for tuning and news-test2009 for testing.
</prevsent>
<prevsent>we also consider chinese-english (zhen) and followed similar training procedure as above.
</prevsent>
</prevsection>
<citsent citstr=" W08-0336 ">
we used 303k sentence pairs from the fbis corpus (ldc2003e14) and segmented the chinese data using the stanford chinese segmenter in ctbmode (chang et al, 2008), <papid> W08-0336 </papid>giving us 7.9m chinese words and 9.4m english words.</citsent>
<aftsection>
<nextsent>a trigram language model was estimated using modified kneser ney smoothing from the english side of the parallel 7www.statmt.org/wmt10/baseline.html.corpus concatenated with 200m words of randomly selected sentences from the gigaword v4 corpus (ex cluding the ny times and la times).
</nextsent>
<nextsent>we used nist mt03 for tuning and nist mt05 for testing.
</nextsent>
<nextsent>for evaluation, we used case-insensitive ibm bleu (papineni et al, 2001).
</nextsent>
<nextsent>5.2.1 training and decoding unlike n-gram language models, our models have latent structure (the color assignments), making it difficult to compute the probability of translation during decoding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1529">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we leave this problem for future work and instead simply add feature for each ofthe most probable patterns discovered by our models.
</prevsent>
<prevsent>each feature counts the number of occurrences of its pattern in the translation.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we wish to add thousands of features to our model, but the standard training algorithm ? minimum error rate training (mert; och, 2003) ? <papid> P03-1021 </papid>cannot handle large numbers of features.</citsent>
<aftsection>
<nextsent>so, we leverage recent work on feature-rich training for mt using online discriminative learning algorithms.
</nextsent>
<nextsent>our training procedure is shown as algorithm 1.
</nextsent>
<nextsent>we find it convenient to notation ally distinguish feature weights for the standard moses features (?)
</nextsent>
<nextsent>from weights for our pattern features (?).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1530">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>from weights for our pattern features (?).
</prevsent>
<prevsent>we use h(e) to denote the feature vector for translation e. the function bi(t) returns the sentence bleu score for translation given reference ei (i.e., treating the sentence pair as corpus).8 mert is run to convergence on the tuning set to obtain weights for the standard moses features (line1).
</prevsent>
</prevsection>
<citsent citstr=" W02-1021 ">
phrase lattices (ueffing et al, 2002) <papid> W02-1021 </papid>are generated for all source sentences in the tuning set using the trained weights (line 2).</citsent>
<aftsection>
<nextsent>the lattices are used within modified version of the margin infused relaxed algorithm (mira; crammer et al,2006) for structured max-margin learning (lines 5 15).
</nextsent>
<nextsent>a k-best list is extracted from the current lattice (line 7), then the translations on the k-best list with the highest and lowest sentence-level bleu scores are found (lines 8 and 9).
</nextsent>
<nextsent>the step size is then computed using the standard mira formula (lines 10 11) and the update is made (line 12).
</nextsent>
<nextsent>the returned weights are averaged over all updates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1531">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>???, ???+ ??,??;13 end14 end15 ???,???
</prevsent>
<prevsent>1tn+1 ;16 return , ??
</prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
?,???;17 algorithm 1: train others that have been shown to be effective for mt (liang et al, 2006; <papid> P06-1096 </papid>arun and koehn, 2007; watanabe et al, 2007; <papid> D07-1080 </papid>chiang et al, 2008).<papid> D08-1024 </papid></citsent>
<aftsection>
<nextsent>though not shown in the algorithm, in practice we store the bleu-best translation on each k-best list from all previous iterations and use it as e+ if it has higher bleu score than any on the k-best list on the current iteration.
</nextsent>
<nextsent>at decoding time, we follow procedure similar to training: we generate lattices for each source sentence using moses with its standard set of feature sand using weights . we rescore the lattices using ??
</nextsent>
<nextsent>and use cube pruning (chiang, 2007; <papid> J07-2003 </papid>huang and chiang, 2007) <papid> P07-1019 </papid>to incorporate the gappy pattern features with weights ??.</nextsent>
<nextsent>cube pruning is necessary because the pattern features may match anywhere in the translation; thus they are non-local in the phrase lattice and require approximate inference.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1533">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>???, ???+ ??,??;13 end14 end15 ???,???
</prevsent>
<prevsent>1tn+1 ;16 return , ??
</prevsent>
</prevsection>
<citsent citstr=" D08-1024 ">
?,???;17 algorithm 1: train others that have been shown to be effective for mt (liang et al, 2006; <papid> P06-1096 </papid>arun and koehn, 2007; watanabe et al, 2007; <papid> D07-1080 </papid>chiang et al, 2008).<papid> D08-1024 </papid></citsent>
<aftsection>
<nextsent>though not shown in the algorithm, in practice we store the bleu-best translation on each k-best list from all previous iterations and use it as e+ if it has higher bleu score than any on the k-best list on the current iteration.
</nextsent>
<nextsent>at decoding time, we follow procedure similar to training: we generate lattices for each source sentence using moses with its standard set of feature sand using weights . we rescore the lattices using ??
</nextsent>
<nextsent>and use cube pruning (chiang, 2007; <papid> J07-2003 </papid>huang and chiang, 2007) <papid> P07-1019 </papid>to incorporate the gappy pattern features with weights ??.</nextsent>
<nextsent>cube pruning is necessary because the pattern features may match anywhere in the translation; thus they are non-local in the phrase lattice and require approximate inference.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1535">
<title id=" W11-2165.xml">generative models of monolingual and bilingual gappy patterns </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>though not shown in the algorithm, in practice we store the bleu-best translation on each k-best list from all previous iterations and use it as e+ if it has higher bleu score than any on the k-best list on the current iteration.
</prevsent>
<prevsent>at decoding time, we follow procedure similar to training: we generate lattices for each source sentence using moses with its standard set of feature sand using weights . we rescore the lattices using ??
</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
and use cube pruning (chiang, 2007; <papid> J07-2003 </papid>huang and chiang, 2007) <papid> P07-1019 </papid>to incorporate the gappy pattern features with weights ??.</citsent>
<aftsection>
<nextsent>cube pruning is necessary because the pattern features may match anywhere in the translation; thus they are non-local in the phrase lattice and require approximate inference.
</nextsent>
<nextsent>5.3 training algorithm comparison.
</nextsent>
<nextsent>before adding pattern features, we evaluate our training algorithm by comparing it to mert using the same standard moses features.
</nextsent>
<nextsent>as the ini esen zhen mert 25.64 32.47 alg.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1539">
<title id=" W12-1607.xml">hierarchical conversation structure prediction in multiparty chat </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>research on multi-party conversation structure is widely varied, due to the multifunctional nature oflanguage.
</prevsent>
<prevsent>these structures have been used in diverse fields such as computer-supported collaborative work (oneill and martin, 2003), dialogue systems (bohus and horvitz, 2011), and research on meetings (renals et al, 2012).
</prevsent>
</prevsection>
<citsent citstr=" W04-2319 ">
much work in annotation has been inspired by speech act theory and dialogue acts (traum, 1994; shriberg et al, 2004),<papid> W04-2319 </papid>which operate primarily on the granularity of individual utterances.</citsent>
<aftsection>
<nextsent>a challenge of tagging is the issue of specificity of tags, as previous work has shown that most utterances have multiple functions (bunt, 2011).
</nextsent>
<nextsent>general tagsets have attempted to capture multi-functionality through independent dimensions which produce potentially millions of possible annotations, though in practice the number of variations remains in the hundreds (jurafsky et al, 1998).
</nextsent>
<nextsent>situated work has jointly modelled speech act and domain-specific topics (laws et al, 2012).
</nextsent>
<nextsent>additional structure inspired by linguistics, such as adjacency pairs (schegloff, 2007) or dialogue games (carlson, 1983), has been used to build discourse relations between turns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1540">
<title id=" W12-1607.xml">hierarchical conversation structure prediction in multiparty chat </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>situated work has jointly modelled speech act and domain-specific topics (laws et al, 2012).
</prevsent>
<prevsent>additional structure inspired by linguistics, such as adjacency pairs (schegloff, 2007) or dialogue games (carlson, 1983), has been used to build discourse relations between turns.
</prevsent>
</prevsection>
<citsent citstr=" P04-1085 ">
this additional structure has been shown to improve performance of automated analysis (poesio and mikheev, 1998).identification of this fine-grained structure of an interaction has been studied in prior work, with applications in agreement detection (galley et al, 2004), <papid> P04-1085 </papid>addressee detection (op den akker and traum,2009), and real-world applications, such as customer service conversations (kim et al, 2010).<papid> D10-1084 </papid>higher-order structure has also been explored india logue, from complex graph-like relations (wolf and gibson, 2005) <papid> J05-2005 </papid>to simpler segmentation-based approaches (malioutov and barzilay, 2006).<papid> P06-1004 </papid></citsent>
<aftsection>
<nextsent>utterance level-tagging can take into account nearby structure,e.g. forward-looking and backward-looking functions in damsl (core and allen, 1997), while dialogue management systems in intelligent agents of ten have plan unfolding over whole dialogue (ferguson and allen, 1998).in recent years, threading and maintaining of multiple floors?
</nextsent>
<nextsent>has grown in popularity (elsner and charniak, 2010), <papid> J10-3004 </papid>especially in text-based media.</nextsent>
<nextsent>this level of analysis is designed with the goal of separating out sub-conversations which are independently coherent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1541">
<title id=" W12-1607.xml">hierarchical conversation structure prediction in multiparty chat </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>situated work has jointly modelled speech act and domain-specific topics (laws et al, 2012).
</prevsent>
<prevsent>additional structure inspired by linguistics, such as adjacency pairs (schegloff, 2007) or dialogue games (carlson, 1983), has been used to build discourse relations between turns.
</prevsent>
</prevsection>
<citsent citstr=" D10-1084 ">
this additional structure has been shown to improve performance of automated analysis (poesio and mikheev, 1998).identification of this fine-grained structure of an interaction has been studied in prior work, with applications in agreement detection (galley et al, 2004), <papid> P04-1085 </papid>addressee detection (op den akker and traum,2009), and real-world applications, such as customer service conversations (kim et al, 2010).<papid> D10-1084 </papid>higher-order structure has also been explored india logue, from complex graph-like relations (wolf and gibson, 2005) <papid> J05-2005 </papid>to simpler segmentation-based approaches (malioutov and barzilay, 2006).<papid> P06-1004 </papid></citsent>
<aftsection>
<nextsent>utterance level-tagging can take into account nearby structure,e.g. forward-looking and backward-looking functions in damsl (core and allen, 1997), while dialogue management systems in intelligent agents of ten have plan unfolding over whole dialogue (ferguson and allen, 1998).in recent years, threading and maintaining of multiple floors?
</nextsent>
<nextsent>has grown in popularity (elsner and charniak, 2010), <papid> J10-3004 </papid>especially in text-based media.</nextsent>
<nextsent>this level of analysis is designed with the goal of separating out sub-conversations which are independently coherent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1542">
<title id=" W12-1607.xml">hierarchical conversation structure prediction in multiparty chat </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>situated work has jointly modelled speech act and domain-specific topics (laws et al, 2012).
</prevsent>
<prevsent>additional structure inspired by linguistics, such as adjacency pairs (schegloff, 2007) or dialogue games (carlson, 1983), has been used to build discourse relations between turns.
</prevsent>
</prevsection>
<citsent citstr=" J05-2005 ">
this additional structure has been shown to improve performance of automated analysis (poesio and mikheev, 1998).identification of this fine-grained structure of an interaction has been studied in prior work, with applications in agreement detection (galley et al, 2004), <papid> P04-1085 </papid>addressee detection (op den akker and traum,2009), and real-world applications, such as customer service conversations (kim et al, 2010).<papid> D10-1084 </papid>higher-order structure has also been explored india logue, from complex graph-like relations (wolf and gibson, 2005) <papid> J05-2005 </papid>to simpler segmentation-based approaches (malioutov and barzilay, 2006).<papid> P06-1004 </papid></citsent>
<aftsection>
<nextsent>utterance level-tagging can take into account nearby structure,e.g. forward-looking and backward-looking functions in damsl (core and allen, 1997), while dialogue management systems in intelligent agents of ten have plan unfolding over whole dialogue (ferguson and allen, 1998).in recent years, threading and maintaining of multiple floors?
</nextsent>
<nextsent>has grown in popularity (elsner and charniak, 2010), <papid> J10-3004 </papid>especially in text-based media.</nextsent>
<nextsent>this level of analysis is designed with the goal of separating out sub-conversations which are independently coherent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1543">
<title id=" W12-1607.xml">hierarchical conversation structure prediction in multiparty chat </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>situated work has jointly modelled speech act and domain-specific topics (laws et al, 2012).
</prevsent>
<prevsent>additional structure inspired by linguistics, such as adjacency pairs (schegloff, 2007) or dialogue games (carlson, 1983), has been used to build discourse relations between turns.
</prevsent>
</prevsection>
<citsent citstr=" P06-1004 ">
this additional structure has been shown to improve performance of automated analysis (poesio and mikheev, 1998).identification of this fine-grained structure of an interaction has been studied in prior work, with applications in agreement detection (galley et al, 2004), <papid> P04-1085 </papid>addressee detection (op den akker and traum,2009), and real-world applications, such as customer service conversations (kim et al, 2010).<papid> D10-1084 </papid>higher-order structure has also been explored india logue, from complex graph-like relations (wolf and gibson, 2005) <papid> J05-2005 </papid>to simpler segmentation-based approaches (malioutov and barzilay, 2006).<papid> P06-1004 </papid></citsent>
<aftsection>
<nextsent>utterance level-tagging can take into account nearby structure,e.g. forward-looking and backward-looking functions in damsl (core and allen, 1997), while dialogue management systems in intelligent agents of ten have plan unfolding over whole dialogue (ferguson and allen, 1998).in recent years, threading and maintaining of multiple floors?
</nextsent>
<nextsent>has grown in popularity (elsner and charniak, 2010), <papid> J10-3004 </papid>especially in text-based media.</nextsent>
<nextsent>this level of analysis is designed with the goal of separating out sub-conversations which are independently coherent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1544">
<title id=" W12-1607.xml">hierarchical conversation structure prediction in multiparty chat </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this additional structure has been shown to improve performance of automated analysis (poesio and mikheev, 1998).identification of this fine-grained structure of an interaction has been studied in prior work, with applications in agreement detection (galley et al, 2004), <papid> P04-1085 </papid>addressee detection (op den akker and traum,2009), and real-world applications, such as customer service conversations (kim et al, 2010).<papid> D10-1084 </papid>higher-order structure has also been explored india logue, from complex graph-like relations (wolf and gibson, 2005) <papid> J05-2005 </papid>to simpler segmentation-based approaches (malioutov and barzilay, 2006).<papid> P06-1004 </papid></prevsent>
<prevsent>utterance level-tagging can take into account nearby structure,e.g. forward-looking and backward-looking functions in damsl (core and allen, 1997), while dialogue management systems in intelligent agents of ten have plan unfolding over whole dialogue (ferguson and allen, 1998).in recent years, threading and maintaining of multiple floors?</prevsent>
</prevsection>
<citsent citstr=" J10-3004 ">
has grown in popularity (elsner and charniak, 2010), <papid> J10-3004 </papid>especially in text-based media.</citsent>
<aftsection>
<nextsent>this level of analysis is designed with the goal of separating out sub-conversations which are independently coherent.
</nextsent>
<nextsent>there is common ground emerging in the thread detection literature on best practices for automated prediction.
</nextsent>
<nextsent>early work viewed the problem as time series analysis task (binghamet al, 2003).
</nextsent>
<nextsent>treating thread detection as clustering problem, with lines representing instances, was given great attention in shen et al (2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1545">
<title id=" W12-1607.xml">hierarchical conversation structure prediction in multiparty chat </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>early work viewed the problem as time series analysis task (binghamet al, 2003).
</prevsent>
<prevsent>treating thread detection as clustering problem, with lines representing instances, was given great attention in shen et al (2006).
</prevsent>
</prevsection>
<citsent citstr=" P11-1118 ">
subsequent researchers have treated the thread detection task as based in discourse coherence, and have pursued topic modelling (adams, 2008) or entity reference grids (elsner and charniak, 2011) <papid> P11-1118 </papid>to define that concept of coherence.</citsent>
<aftsection>
<nextsent>other work integrates local discourse structure with the topic-based threads of discourse.
</nextsent>
<nextsent>ai et al(2007) utilizes information state, dialogue management component which loosely parallels thread structure, to improve dialogue act tagging.
</nextsent>
<nextsent>in the context of twitter conversations, ritter et al (2010)<papid> N10-1020 </papid>suggests using dialogue act tags as middle layer towards conversation reconstruction.</nextsent>
<nextsent>low-level structure between utterances has also been used as foundation for modelling larger-level sociological phenomena between speakers in dialogue, for instance, identifying leadership (strzalkowski et al, 2011) and rapport between providers and patients in support groups (ogura et al, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1546">
<title id=" W12-1607.xml">hierarchical conversation structure prediction in multiparty chat </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>other work integrates local discourse structure with the topic-based threads of discourse.
</prevsent>
<prevsent>ai et al(2007) utilizes information state, dialogue management component which loosely parallels thread structure, to improve dialogue act tagging.
</prevsent>
</prevsection>
<citsent citstr=" N10-1020 ">
in the context of twitter conversations, ritter et al (2010)<papid> N10-1020 </papid>suggests using dialogue act tags as middle layer towards conversation reconstruction.</citsent>
<aftsection>
<nextsent>low-level structure between utterances has also been used as foundation for modelling larger-level sociological phenomena between speakers in dialogue, for instance, identifying leadership (strzalkowski et al, 2011) and rapport between providers and patients in support groups (ogura et al, 2008).
</nextsent>
<nextsent>these works have all pointed to the utility of incorporating sentence-level annotations, low-level interaction structure, and overarching themes into unified system.
</nextsent>
<nextsent>to our knowledge, however, this work is the first to present single system for simultaneous an 61 negotiation/threads seq user text k2 1 [m], fast question, did your son have biopsy?
</nextsent>
<nextsent>k2 1 or does that happen when he comes home k1 2 i have 3 dogs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1547">
<title id=" W12-1607.xml">hierarchical conversation structure prediction in multiparty chat </title>
<section> data and annotation.  </section>
<citcontext>
<prevsection>
<prevsent>by assigning aggregate scores over conversation, the framework also givesus notion of authoritativeness.
</prevsent>
<prevsent>this metric, defined later in section 5, allows us to test whether automated codes faithfully reproduce human judgments of information sharing behavior at per-user level.
</prevsent>
</prevsection>
<citsent citstr=" P11-1102 ">
this metric has proven to be statistically significant indicator of outcome variables in direction giving (mayfield et al, 2011) <papid> P11-1102 </papid>and collaborative learning domains (howley et al, 2011).</citsent>
<aftsection>
<nextsent>in particular, negotiation labels define whether each speaker is source or recipient of information.
</nextsent>
<nextsent>our annotation scheme has four turn-level codes and rigidly defined information sharing structure, rooted in socio linguistic observation.
</nextsent>
<nextsent>we describe 62 each in detail below.
</nextsent>
<nextsent>sentences containing new information are marked as k1, as the speaker is the primary knower,?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1549">
<title id=" W12-1607.xml">hierarchical conversation structure prediction in multiparty chat </title>
<section> conversation structure prediction.  </section>
<citcontext>
<prevsection>
<prevsent>the output of this model is distribution over the four possible sentence-level labels described in section 3.1.
</prevsent>
<prevsent>the set of features for this model consists of unigrams, bigrams, and part-of-speech bi grams.
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
part-of-speech tagging was performed using the stanford tagger (toutanova et al, 2003) <papid> N03-1033 </papid>within lightside.</citsent>
<aftsection>
<nextsent>cluster classifiers (pc, nc)we use two models of cluster assignment probability.
</nextsent>
<nextsent>the previous cluster (pc) classifier takes as input previous set of sentences = {c1, c2, . . .
</nextsent>
<nextsent>, cn} and set of new sentences = {n1, n2, . . .
</nextsent>
<nextsent>, nm}.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1552">
<title id=" W11-1902.xml">stanfords multi pass sieve coreference resolution system at the conll2011 shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we participated in both the open and closed tracks and submitted results using both predicted and gold mentions.
</prevsent>
<prevsent>our system was ranked first in both tracks, with score of 57.8 in the closed track and 58.3 in the open track.
</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
this paper describes the coreference resolution system used by stanford at the conll-2011 shared task (pradhan et al, 2011).<papid> W11-1901 </papid></citsent>
<aftsection>
<nextsent>our system extends the multi-pass sieve system of raghunathan etal.
</nextsent>
<nextsent>(2010), which applies tiers of deterministic coreference models one at time from highest to lowestprecision.
</nextsent>
<nextsent>each tier builds on the entity clusters constructed by previous models in the sieve, guaranteeing that stronger features are given precedence over weaker ones.
</nextsent>
<nextsent>furthermore, this model propagates global information by sharing attributes (e.g., gender and number) across mentions in the same cluster.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1553">
<title id=" W11-1902.xml">stanfords multi pass sieve coreference resolution system at the conll2011 shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>each tier builds on the entity clusters constructed by previous models in the sieve, guaranteeing that stronger features are given precedence over weaker ones.
</prevsent>
<prevsent>furthermore, this model propagates global information by sharing attributes (e.g., gender and number) across mentions in the same cluster.
</prevsent>
</prevsection>
<citsent citstr=" D10-1048 ">
we made three considerable extensions to the raghunathan et al (2010) <papid> D10-1048 </papid>model.</citsent>
<aftsection>
<nextsent>first, we added five additional sieves, the majority of which address the semantic similarity between mentions, e.g., using wordnet distance, and shallow discourse understanding, e.g., linking speakers to compatible pronouns.
</nextsent>
<nextsent>second, we incorporated mention detection sieve at the beginning of the processing flow.
</nextsent>
<nextsent>this sieve filters our syntactic constituents unlikely to be mentions using simple set of rules on top of the syntactic analysis of text.
</nextsent>
<nextsent>and lastly, we added apost-processing step, which guarantees that the out put of our system is compatible with the shared task and ontonotes specifications (hovy et al, 2006; pradhan et al, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1554">
<title id=" W11-1902.xml">stanfords multi pass sieve coreference resolution system at the conll2011 shared task </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>it is important to note that the first system stage,i.e., the mention detection sieve, favors recall heavily, whereas the second stage, which includes the actual coreference resolution sieves, is precision oriented.
</prevsent>
<prevsent>our results show that this design lead to state-of-the-art performance despite the simplicity of the individual components.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
this strategy hasbeen successfully used before for information extraction, e.g., in the bionlp 2009 event extraction shared task (kim et al, 2009), <papid> W09-1401 </papid>several of the top systems had first high-recall component to identify event anchors, followed by high-precision classifiers, which identified event arguments and removed unlikely event candidates (bjorne et al, 2009).</citsent>
<aftsection>
<nextsent>in the coreference resolution space, several works have shown that applying list of rules from highest to lowest precision is beneficial for coreference resolution (baldwin, 1997; <papid> W97-1306 </papid>raghunathan el al., 2010).</nextsent>
<nextsent>however, we believe we are the first to show that thishigh-recall/high-precision strategy yields competitive results for the complete task of coreference resolution, i.e., including mention detection and both nominal and pronominal coreference.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1555">
<title id=" W11-1902.xml">stanfords multi pass sieve coreference resolution system at the conll2011 shared task </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>our results show that this design lead to state-of-the-art performance despite the simplicity of the individual components.
</prevsent>
<prevsent>this strategy hasbeen successfully used before for information extraction, e.g., in the bionlp 2009 event extraction shared task (kim et al, 2009), <papid> W09-1401 </papid>several of the top systems had first high-recall component to identify event anchors, followed by high-precision classifiers, which identified event arguments and removed unlikely event candidates (bjorne et al, 2009).</prevsent>
</prevsection>
<citsent citstr=" W97-1306 ">
in the coreference resolution space, several works have shown that applying list of rules from highest to lowest precision is beneficial for coreference resolution (baldwin, 1997; <papid> W97-1306 </papid>raghunathan el al., 2010).</citsent>
<aftsection>
<nextsent>however, we believe we are the first to show that thishigh-recall/high-precision strategy yields competitive results for the complete task of coreference resolution, i.e., including mention detection and both nominal and pronominal coreference.
</nextsent>
<nextsent>2.1 mention detection sieve.
</nextsent>
<nextsent>in our particular setup, the recall of the mention detection component is more important than its precision, because any missed mentions are guaranteed to affect the final score, but spurious mentions maynot impact the overall score if they are left as singletons, which are discarded by our post-processingstep.
</nextsent>
<nextsent>therefore, our mention detection algorithm focuses on attaining high recall rather than high precision.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1561">
<title id=" W11-1902.xml">stanfords multi pass sieve coreference resolution system at the conll2011 shared task </title>
<section> exact string match sieve.  </section>
<citcontext>
<prevsection>
<prevsent>bare plurals - bare plurals are generic and cannot have co referent antecedent.
</prevsent>
<prevsent>2.3.2 semantic-similarity sieves we first extend the above system with two new sieves that exploit semantics from wordnet, wikipedia info boxes, and free base records, drawing on previous coreference work using these databases (ng &amp; cardie, 2002; daume?
</prevsent>
</prevsection>
<citsent citstr=" N06-1025 ">
&amp; marcu, 2005; ponzetto &amp; strube, 2006; <papid> N06-1025 </papid>ng, 2007; <papid> P07-1068 </papid>yang &amp; su, 30 2007; bengston &amp; roth, 2008; huang et al, 2009; <papid> D09-1128 </papid>inter alia).</citsent>
<aftsection>
<nextsent>since the input to sieve is collection of mention clusters built by the previous (more precise) sieves, we need to link mention clusters (rather than individual mentions) to records in these three knowledge bases.
</nextsent>
<nextsent>the following steps generate query for these resources from mention cluster.
</nextsent>
<nextsent>first, we select the most representative mention in cluster by preferring mentions headed by proper nouns to mentions headed by common nouns, and nominal mentions to pronominal ones.
</nextsent>
<nextsent>in case of ties, we select the longer string.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1562">
<title id=" W11-1902.xml">stanfords multi pass sieve coreference resolution system at the conll2011 shared task </title>
<section> exact string match sieve.  </section>
<citcontext>
<prevsection>
<prevsent>bare plurals - bare plurals are generic and cannot have co referent antecedent.
</prevsent>
<prevsent>2.3.2 semantic-similarity sieves we first extend the above system with two new sieves that exploit semantics from wordnet, wikipedia info boxes, and free base records, drawing on previous coreference work using these databases (ng &amp; cardie, 2002; daume?
</prevsent>
</prevsection>
<citsent citstr=" P07-1068 ">
&amp; marcu, 2005; ponzetto &amp; strube, 2006; <papid> N06-1025 </papid>ng, 2007; <papid> P07-1068 </papid>yang &amp; su, 30 2007; bengston &amp; roth, 2008; huang et al, 2009; <papid> D09-1128 </papid>inter alia).</citsent>
<aftsection>
<nextsent>since the input to sieve is collection of mention clusters built by the previous (more precise) sieves, we need to link mention clusters (rather than individual mentions) to records in these three knowledge bases.
</nextsent>
<nextsent>the following steps generate query for these resources from mention cluster.
</nextsent>
<nextsent>first, we select the most representative mention in cluster by preferring mentions headed by proper nouns to mentions headed by common nouns, and nominal mentions to pronominal ones.
</nextsent>
<nextsent>in case of ties, we select the longer string.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1563">
<title id=" W11-1902.xml">stanfords multi pass sieve coreference resolution system at the conll2011 shared task </title>
<section> exact string match sieve.  </section>
<citcontext>
<prevsection>
<prevsent>bare plurals - bare plurals are generic and cannot have co referent antecedent.
</prevsent>
<prevsent>2.3.2 semantic-similarity sieves we first extend the above system with two new sieves that exploit semantics from wordnet, wikipedia info boxes, and free base records, drawing on previous coreference work using these databases (ng &amp; cardie, 2002; daume?
</prevsent>
</prevsection>
<citsent citstr=" D09-1128 ">
&amp; marcu, 2005; ponzetto &amp; strube, 2006; <papid> N06-1025 </papid>ng, 2007; <papid> P07-1068 </papid>yang &amp; su, 30 2007; bengston &amp; roth, 2008; huang et al, 2009; <papid> D09-1128 </papid>inter alia).</citsent>
<aftsection>
<nextsent>since the input to sieve is collection of mention clusters built by the previous (more precise) sieves, we need to link mention clusters (rather than individual mentions) to records in these three knowledge bases.
</nextsent>
<nextsent>the following steps generate query for these resources from mention cluster.
</nextsent>
<nextsent>first, we select the most representative mention in cluster by preferring mentions headed by proper nouns to mentions headed by common nouns, and nominal mentions to pronominal ones.
</nextsent>
<nextsent>in case of ties, we select the longer string.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1564">
<title id=" W11-1902.xml">stanfords multi pass sieve coreference resolution system at the conll2011 shared task </title>
<section> exact string match sieve.  </section>
<citcontext>
<prevsection>
<prevsent>this explains the large difference between, say, line 6 in table 3 and line 4 in table 4.
</prevsent>
<prevsent>our scores are comparable to previously reported state-of-the-art results for coreference resolution with predicted mentions.
</prevsent>
</prevsection>
<citsent citstr=" N10-1061 ">
for example, haghighi and klein (2010) <papid> N10-1061 </papid>compare four state-of-the-art systems on three different corpora and report b3 scores between 63 and 77 points.</citsent>
<aftsection>
<nextsent>while the corpora used in (haghighi and klein, 2010) <papid> N10-1061 </papid>are different from the one in this shared task, our result of 68 b3 suggests that our systems performance is competitive.</nextsent>
<nextsent>in this task, our submissions in both the open and the closed track obtained the highest scores.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1566">
<title id=" W12-1011.xml">a classical chinese corpus with nested partofspeech tags </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we address this problem with nested pos tags, which accommodates different theories of word hood and facilitates research objectives requiring annotations of the word?
</prevsent>
<prevsent>at different levels of granularity.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
there has been much effort in enriching text corpora with linguistic information, such as parts-of-speech (francis and kuera, 1982) and syntactic structures (marcus et al, 1993).<papid> J93-2004 </papid></citsent>
<aftsection>
<nextsent>the past decade has seen the development of chinese corpora, mostly for modern chinese (mcenery &amp; xiao, 2004; xue et al, 2005), but also few for pre-modern, or classical?, chinese (wei et al. 97; huang et al 2006; hu &amp; mclaughlin 2007).
</nextsent>
<nextsent>one common design issue for any corpus of chinese, whether modern or classical, is word segmentation.
</nextsent>
<nextsent>yet, no segmentation standard has emerged in the computational linguistics research community.
</nextsent>
<nextsent>hence, two adjacent characters x1x2 may be considered single word in one corpus, but treated as two distinct words x1 and x2 in another 1; furthermore, the part-of-speech (pos) tag assigned to x1x2 in the first corpus may differ from the tag for x1 and the tag for x2 in the second.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1567">
<title id=" W12-1011.xml">a classical chinese corpus with nested partofspeech tags </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>as mentioned in section 2, common test for word segmentation is compositionality of meaning?.
</prevsent>
<prevsent>while there are clear-cut cases like sha men, many cases fall in the grey area.
</prevsent>
</prevsection>
<citsent citstr=" J96-3004 ">
indeed, even native speakers can agree on word boundaries in modern chinese only about 76% of the time (sproat et al, 1996).<papid> J96-3004 </papid></citsent>
<aftsection>
<nextsent>it is not surprising, then, that myriad of guidelines for word segmentation have been proposed for various corpora of modern chinese (liu et al, 1994; chinese knowledge information processing group, 1996; yu et al, 1998; xia 2000; sproat and emerson, 2003).<papid> W03-1719 </papid></nextsent>
<nextsent>in the rest of this section, we first review the approaches taken in three classical chinese corpora, developed respectively at jiaotong university (huang et al, 2006), university of sheffield (hu et al, 2005) and the academia sinica (wei et al, 1997).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1569">
<title id=" W12-1011.xml">a classical chinese corpus with nested partofspeech tags </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>while there are clear-cut cases like sha men, many cases fall in the grey area.
</prevsent>
<prevsent>indeed, even native speakers can agree on word boundaries in modern chinese only about 76% of the time (sproat et al, 1996).<papid> J96-3004 </papid></prevsent>
</prevsection>
<citsent citstr=" W03-1719 ">
it is not surprising, then, that myriad of guidelines for word segmentation have been proposed for various corpora of modern chinese (liu et al, 1994; chinese knowledge information processing group, 1996; yu et al, 1998; xia 2000; sproat and emerson, 2003).<papid> W03-1719 </papid></citsent>
<aftsection>
<nextsent>in the rest of this section, we first review the approaches taken in three classical chinese corpora, developed respectively at jiaotong university (huang et al, 2006), university of sheffield (hu et al, 2005) and the academia sinica (wei et al, 1997).
</nextsent>
<nextsent>we then describe in more detail modern chinese corpus, the penn chinese treebank (xue et al, 2005).
</nextsent>
<nextsent>corpus at jiaotong university.
</nextsent>
<nextsent>this treebank consists of 1000 sentences of pre-tsin classical chinese.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1572">
<title id=" W11-2122.xml">multiple stream language models for statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>text streams arise naturally on the web where millions of new documents are published each day inmany different languages.
</prevsent>
<prevsent>examples in the streaming domain include the thousands of multilingual web sites that continuously publish newswire stories, the official proceedings of governments and other bureaucratic organisations, as well as the millions of bloggers?
</prevsent>
</prevsection>
<citsent citstr=" N09-1058 ">
and host of users on social network services such as face book and twitter.recent work has shown good results using an in coming text stream as training data for either static or online language model (lm) in an smt setting (goyal et al, 2009; <papid> N09-1058 </papid>levenberg and osborne, 2009).a drawback of prior work is the oversimplified scenario that all training and test data is drawn from the same distribution using single, in-domain stream.</citsent>
<aftsection>
<nextsent>in real world scenario multiple incoming streams are readily available and test sets from dissimilar domains will be translated continuously.
</nextsent>
<nextsent>as we show,using stream data from one domain to translate an other results in poor average performance for bothstreams.
</nextsent>
<nextsent>however, combining streams naively together hurts performance further still.
</nextsent>
<nextsent>in this paper we consider this problem of multiple stream translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1573">
<title id=" W11-2122.xml">multiple stream language models for statistical machine translation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>to our knowledge our approach is the first in the literature to deal with adapting an online lm to multiple streams in small space.
</prevsent>
<prevsent>2.1 random ised lms.
</prevsent>
</prevsection>
<citsent citstr=" D07-1049 ">
random ised techniques for lms from talbot and osborne (2007) <papid> D07-1049 </papid>and talbot and brants (2008) <papid> P08-1058 </papid>are currently industry state-of-the-art for fitting very large datasets into much smaller amounts of memory than loss less representations for the data.</citsent>
<aftsection>
<nextsent>instead of representing the n-grams exactly, the random ised representation exchanges small, one-sided error of false positives for massive space savings.
</nextsent>
<nextsent>2.2 stream-based lms.
</nextsent>
<nextsent>an unbounded text stream is an input source of natural language documents that is received sequentially and so has an implicit timeline attached.
</nextsent>
<nextsent>in levenberg and osborne (2009) text stream was used to initially train and subsequently adapt an online, ran domised lm (orlm) with good results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1574">
<title id=" W11-2122.xml">multiple stream language models for statistical machine translation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>to our knowledge our approach is the first in the literature to deal with adapting an online lm to multiple streams in small space.
</prevsent>
<prevsent>2.1 random ised lms.
</prevsent>
</prevsection>
<citsent citstr=" P08-1058 ">
random ised techniques for lms from talbot and osborne (2007) <papid> D07-1049 </papid>and talbot and brants (2008) <papid> P08-1058 </papid>are currently industry state-of-the-art for fitting very large datasets into much smaller amounts of memory than loss less representations for the data.</citsent>
<aftsection>
<nextsent>instead of representing the n-grams exactly, the random ised representation exchanges small, one-sided error of false positives for massive space savings.
</nextsent>
<nextsent>2.2 stream-based lms.
</nextsent>
<nextsent>an unbounded text stream is an input source of natural language documents that is received sequentially and so has an implicit timeline attached.
</nextsent>
<nextsent>in levenberg and osborne (2009) text stream was used to initially train and subsequently adapt an online, ran domised lm (orlm) with good results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1575">
<title id=" W11-2122.xml">multiple stream language models for statistical machine translation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>no work was done on the multi-stream case where we have more than one incoming stream from arbitrary domains.
</prevsent>
<prevsent>2.3 domain adaptation for smt.
</prevsent>
</prevsection>
<citsent citstr=" C08-1125 ">
within mt there has been variety of approaches dealing with domain adaptation (for example (wu et al., 2008; <papid> C08-1125 </papid>koehn and schroeder, 2007)).<papid> W07-0733 </papid></citsent>
<aftsection>
<nextsent>our work is related to domain adaptation but differs in that we are not skewing the distribution of an out-of-domain lm to accommodate some test data for which we have little or no training data for.
</nextsent>
<nextsent>rather, we have varying amounts of training data from all the domains via the incoming streams and the lm must account for each domain appropriately.
</nextsent>
<nextsent>however, known domain adaptation techniques are potentially applicable to multi-stream translation as well.
</nextsent>
<nextsent>any source that provides continuous sequence of natural language documents over time can be thought of as an unbounded stream which is time stamped and access to it is given in strict chronological order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1576">
<title id=" W11-2122.xml">multiple stream language models for statistical machine translation </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>no work was done on the multi-stream case where we have more than one incoming stream from arbitrary domains.
</prevsent>
<prevsent>2.3 domain adaptation for smt.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
within mt there has been variety of approaches dealing with domain adaptation (for example (wu et al., 2008; <papid> C08-1125 </papid>koehn and schroeder, 2007)).<papid> W07-0733 </papid></citsent>
<aftsection>
<nextsent>our work is related to domain adaptation but differs in that we are not skewing the distribution of an out-of-domain lm to accommodate some test data for which we have little or no training data for.
</nextsent>
<nextsent>rather, we have varying amounts of training data from all the domains via the incoming streams and the lm must account for each domain appropriately.
</nextsent>
<nextsent>however, known domain adaptation techniques are potentially applicable to multi-stream translation as well.
</nextsent>
<nextsent>any source that provides continuous sequence of natural language documents over time can be thought of as an unbounded stream which is time stamped and access to it is given in strict chronological order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1577">
<title id=" W11-2122.xml">multiple stream language models for statistical machine translation </title>
<section> multi-stream retraining.  </section>
<citcontext>
<prevsection>
<prevsent>here we carry no n-grams over from the lm ct1 from the previous epoch.
</prevsent>
<prevsent>the space needed isthe number of unique n-grams present in the combined streams for each epoch.resulting lm to query the resulting lm ct during decoding with test n-gram wni = (wi, . . .
</prevsent>
</prevsection>
<citsent citstr=" D07-1090 ">
, wn) we use simple smoothing algorithm called stupid backoff (brants et al, 2007).<papid> D07-1090 </papid></citsent>
<aftsection>
<nextsent>this returns the probability of an n-gram as (wi|wi1in+1) := ? ?
</nextsent>
<nextsent>ct(wiin+1) ct(wi1in+1) if ct(wiin+1)   0 (wi|wi1in+2) otherwise (2) where ct(.)
</nextsent>
<nextsent>denotes the frequency count returned by the lm for an n-gram and ? is backoff parameter.
</nextsent>
<nextsent>the recur sion ends once the unigram is reached in which case the probability is (wi) := wi/n where is the size of the current training corpus.each stream provides distribution over the grams contained in it and, for smt, if separate lm was constructed for each domain it would most likely cause the decoder to derive different 1-best hypotheses than using lm built from all the stream data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1579">
<title id=" W11-2122.xml">multiple stream language models for statistical machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 experimental setup.
</prevsent>
<prevsent>the smt setup we employ is standard and all resources used are publicly available.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
we translate from spanish into english using phrase-based decoding with moses (koehn and hoang, 2007) <papid> D07-1091 </papid>as our decoder.</citsent>
<aftsection>
<nextsent>our parallel data came from europarl.
</nextsent>
<nextsent>we use three streams (all are timestamped): rcv1 (rose et al, 2002), europarl (ep) (koehn, 2003), and gigaword (gw) (graff et al, 2007).
</nextsent>
<nextsent>gw is taken from six distinct newswire sources but in our initial experiments we limit the incoming stream from gigaword to one of the sources (xie).
</nextsent>
<nextsent>gw and rcv1 are both newswire domain streams with high rates of incoming data whereas ep is more nuanced, smaller throughput domain of spoken transcripts taken from sessions of the european parliament.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1582">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pivot paraphrasing translates phrases of interest to other languages and back (callison-burch et al, 2006; callison-burch, 2008).
</prevsent>
<prevsent>it relies on parallel texts (or translation phrase tables) in various languages, which are typically scarce, and hence limit its applicability.
</prevsent>
</prevsection>
<citsent citstr=" D09-1040 ">
distributional paraphrasing (marton et al, 2009) <papid> D09-1040 </papid>generates paraphrases using distributional semantic distance measure computed over large monolingual corpus.1 monolingual corpora are relatively easyand inexpensive to collect, but distributional semantic distance measures are known to rank antonymous and polarity-dissimilar phrasal candidates high.</citsent>
<aftsection>
<nextsent>we therefore attempt to identify and filter out such ill suited paraphrase candidates.
</nextsent>
<nextsent>a phrase pair may have varying degree of antonymy, beyond the better-known complete opposites (hot / cold) and contradictions (did / didnot), e.g., weaker contrasts (hot / cool), contrasting trends (covered / reduced coverage), or sentiment polarity (happy / sad).
</nextsent>
<nextsent>information extraction, opinion mining and sentiment analysis literature has been grappling with identifying such pairs (pang and lee, 2008), e.g., in order to distinguish positive and negative reviews or comments, or to detect contradictions (marneffe et al, 2008; voorhees, 2008).<papid> P08-1008 </papid></nextsent>
<nextsent>we transfer some of the insights, data and techniques to the area of paraphrasing and smt.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1583">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we therefore attempt to identify and filter out such ill suited paraphrase candidates.
</prevsent>
<prevsent>a phrase pair may have varying degree of antonymy, beyond the better-known complete opposites (hot / cold) and contradictions (did / didnot), e.g., weaker contrasts (hot / cool), contrasting trends (covered / reduced coverage), or sentiment polarity (happy / sad).
</prevsent>
</prevsection>
<citsent citstr=" P08-1008 ">
information extraction, opinion mining and sentiment analysis literature has been grappling with identifying such pairs (pang and lee, 2008), e.g., in order to distinguish positive and negative reviews or comments, or to detect contradictions (marneffe et al, 2008; voorhees, 2008).<papid> P08-1008 </papid></citsent>
<aftsection>
<nextsent>we transfer some of the insights, data and techniques to the area of paraphrasing and smt.
</nextsent>
<nextsent>we distributionally expand small seed set of antonyms in an unsupervised manner, following mohammad et al (2008).<papid> D08-1103 </papid></nextsent>
<nextsent>we then present method for filtering antonymous and polarity-dissimilar distributional paraphrases using the expanded antonymous list and list of negators (e.g., cannot) and trend decreasing words (reduced).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1584">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>information extraction, opinion mining and sentiment analysis literature has been grappling with identifying such pairs (pang and lee, 2008), e.g., in order to distinguish positive and negative reviews or comments, or to detect contradictions (marneffe et al, 2008; voorhees, 2008).<papid> P08-1008 </papid></prevsent>
<prevsent>we transfer some of the insights, data and techniques to the area of paraphrasing and smt.</prevsent>
</prevsection>
<citsent citstr=" D08-1103 ">
we distributionally expand small seed set of antonyms in an unsupervised manner, following mohammad et al (2008).<papid> D08-1103 </papid></citsent>
<aftsection>
<nextsent>we then present method for filtering antonymous and polarity-dissimilar distributional paraphrases using the expanded antonymous list and list of negators (e.g., cannot) and trend decreasing words (reduced).
</nextsent>
<nextsent>we evaluate the impact of our approach in smt setting, where non 1other variants use lexical resource in conjunction with the monolingual corpus (mirkin et al, 2009; <papid> P09-1089 </papid>marton, 2010).</nextsent>
<nextsent>237baseline translation models are augmented with distributional paraphrases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1585">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we distributionally expand small seed set of antonyms in an unsupervised manner, following mohammad et al (2008).<papid> D08-1103 </papid></prevsent>
<prevsent>we then present method for filtering antonymous and polarity-dissimilar distributional paraphrases using the expanded antonymous list and list of negators (e.g., cannot) and trend decreasing words (reduced).</prevsent>
</prevsection>
<citsent citstr=" P09-1089 ">
we evaluate the impact of our approach in smt setting, where non 1other variants use lexical resource in conjunction with the monolingual corpus (mirkin et al, 2009; <papid> P09-1089 </papid>marton, 2010).</citsent>
<aftsection>
<nextsent>237baseline translation models are augmented with distributional paraphrases.
</nextsent>
<nextsent>we show gains of up to 1 bleu relative to non-filtered models (1.6 bleu.
</nextsent>
<nextsent>from non-augmented baselines) in english-chinese models trained on small and medium-large size data, but lower to no gains in english-arabic.
</nextsent>
<nextsent>the small training size simulates resource-poor languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1589">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> distributional paraphrases.  </section>
<citcontext>
<prevsection>
<prevsent>each dpphr is vector containing log likelihood ratios of the focal phrase phr and each word in the corpus.
</prevsent>
<prevsent>given paraphrase candidate phrase cand, the semantic distance between phr andcand is calculated using the cosine of their respective dps (mcdonald, 2000).
</prevsent>
</prevsection>
<citsent citstr=" C04-1146 ">
for details on dps and distributional measures, see weeds et al (2004) <papid> C04-1146 </papid>and turney and pantel (2010).the search of the corpus for paraphrase candidates is performed in the following manner: 1.</citsent>
<aftsection>
<nextsent>for each focal phrase phr, build distributional.
</nextsent>
<nextsent>profile dpphr.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>gather contexts: for each occurrence of phr,.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1596">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> antonyms, trends, sentiment polarity.  </section>
<citcontext>
<prevsection>
<prevsent>may be result of differing sentiment, new information, non-coreferent mentions, or genuinely contradictory statements.
</prevsent>
<prevsent>identifying paraphrases and contradictions are in turn useful ineffectively re-ranking target language hypotheses in machine translation, and for re-ranking query responses in information retrieval.
</prevsent>
</prevsection>
<citsent citstr=" H05-1067 ">
identifying contrasting word pairs (or short phrase pairs) is also useful for detecting humor (mihalcea and strapparava, 2005), <papid> H05-1067 </papid>as satire and jokes tend to have contradictions and oxymorons.</citsent>
<aftsection>
<nextsent>lastly, it is useful to know which words contrast focal word, even if only to filter them out.
</nextsent>
<nextsent>for example, in the automatic creation of thesaurus it is necessary to distinguishnear-synonyms from contrasting word pairs.
</nextsent>
<nextsent>distributional similarity measures typically fail to do so.
</nextsent>
<nextsent>instances of strong contrast are recorded to some extent in manually created dictionaries, but hundreds of thousands of other contrasting pairs are not.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1601">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> antonyms, trends, sentiment polarity.  </section>
<citcontext>
<prevsection>
<prevsent>the approach attains more than 80% accuracy on gre-style closest opposite questions.
</prevsent>
<prevsent>239 3.3 detecting negators.
</prevsent>
</prevsection>
<citsent citstr=" D08-1083 ">
the general inquirer (gi) (stone et al, 1966) has 11,788 words labeled with 182 categories of word tags, such as positive and negative semantic orientation, pleasure, pain, and so on.2 two of the gi categories, notlw and decreas, contain terms that negate the meaning of what follows (choi and cardie, 2008; <papid> D08-1083 </papid>kennedy and inkpen, 2005).</citsent>
<aftsection>
<nextsent>these terms (with limited added inflection variation) form our list of negators.
</nextsent>
<nextsent>augmenting the source side of smt phrase tables with paraphrases of out-of-vocabulary (oov) items was introduced by callison-burch et al (2006), and was adopted practically as-is? in consequent work (callison-burch, 2008; marton et al, 2009; <papid> D09-1040 </papid>marton, 2010).</nextsent>
<nextsent>given an oov source-side phrase , if the translation model has rule ?, e?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1603">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>we augmented translation models with paraphrases based on distributional semantic distance measures, with our novel antonym-filtering, and without it.
</prevsent>
<prevsent>we tested all models in englishto-chinese and english-to-arabic translation, augmenting the models with translation rules for unknown english phrases.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we also contrasted these models with non-augmented baseline models.for baseline we used the phrase-based smt system moses (koehn et al, 2007), <papid> P07-2045 </papid>with the default model features: 1.</citsent>
<aftsection>
<nextsent>phrase translation probability, 2.
</nextsent>
<nextsent>reverse phrase translation probability, 3.
</nextsent>
<nextsent>lexical translation probability, 4.
</nextsent>
<nextsent>reverse lexical translation probability, 5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1604">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>distortion cost, and 9.
</prevsent>
<prevsent>language model (lm) probability.
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we used giza++ (och and ney, 2000) <papid> P00-1056 </papid>for word alignment.all features were weighted in log-linear framework (och and ney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>feature weights were set with minimum error rate training (och, 2003) <papid> P03-1021 </papid>on tuning set using bleu (papineni et al, 2002) as the objective function.</nextsent>
<nextsent>test results were evaluated using bleu and ter (snover et al, 2006): the higher the bleu score, the better the result; the lower the ter score, the better the result.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1605">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>distortion cost, and 9.
</prevsent>
<prevsent>language model (lm) probability.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
we used giza++ (och and ney, 2000) <papid> P00-1056 </papid>for word alignment.all features were weighted in log-linear framework (och and ney, 2002).<papid> P02-1038 </papid></citsent>
<aftsection>
<nextsent>feature weights were set with minimum error rate training (och, 2003) <papid> P03-1021 </papid>on tuning set using bleu (papineni et al, 2002) as the objective function.</nextsent>
<nextsent>test results were evaluated using bleu and ter (snover et al, 2006): the higher the bleu score, the better the result; the lower the ter score, the better the result.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1606">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>language model (lm) probability.
</prevsent>
<prevsent>we used giza++ (och and ney, 2000) <papid> P00-1056 </papid>for word alignment.all features were weighted in log-linear framework (och and ney, 2002).<papid> P02-1038 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
feature weights were set with minimum error rate training (och, 2003) <papid> P03-1021 </papid>on tuning set using bleu (papineni et al, 2002) as the objective function.</citsent>
<aftsection>
<nextsent>test results were evaluated using bleu and ter (snover et al, 2006): the higher the bleu score, the better the result; the lower the ter score, the better the result.
</nextsent>
<nextsent>this is denoted with bleu?
</nextsent>
<nextsent>and ter?
</nextsent>
<nextsent>in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1607">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>and ter?
</prevsent>
<prevsent>in table 1.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
statistical significance of model output differences was determined using koehn (2004)<papid> W04-3250 </papid>s test on the objective function (bleu).</citsent>
<aftsection>
<nextsent>the paraphrase-augmented models were created as described in section 4.
</nextsent>
<nextsent>we used the same data and parameter settings as in marton (2010).3 weused cosine distance over dps of log-likelihood ratios (mcdonald, 2000), built with sliding win 3data preprocessing and paraphrasing code slightly differ from those used in marton et al (2009)<papid> D09-1040 </papid>and marton (2010), and hence scores are not exactly the same across these publications.</nextsent>
<nextsent>240dow of size 6, sampling threshold of 10000 occurrences, and maximal paraphrase length of 6 tokens.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1612">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>we chose chinese as the translation target language in order to compare with marton (2010), and for the same reasons it was chosen there: it is quite different from english (e.g., in word order), and four reference translation were available from nist.
</prevsent>
<prevsent>we chose arabicas another target language, because it is different from both english and chinese, and richer morphologically, which introduces additional challenges.
</prevsent>
</prevsection>
<citsent citstr=" I05-3027 ">
english-chinese: for training we used the ldc sino rama and fbis tests (ldc2005t10 and ldc2003e14), and segmented the chinese side with the stanford segmenter (tseng et al, 2005).<papid> I05-3027 </papid></citsent>
<aftsection>
<nextsent>after tokenization and filtering, this bitext contained 231,586 lines (6.4m + 5.1m tokens).
</nextsent>
<nextsent>we trained trigram language model on the chinese side, withthe srilm toolkit (stolcke, 2002), using the modified kneser-ney smoothing option.
</nextsent>
<nextsent>we followed the split in marton (2010), and constructed the reduced set of about 29,000 sentence pairs.
</nextsent>
<nextsent>the purpose of creating this subset model was to simulate aresource-poor language.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1613">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>training data.
</prevsent>
<prevsent>the sentences were extracted from arabic news (ldc2004t17), etirr (ldc2004e72), english translation of arabic treebank (ldc2005e46),and ummah (ldc2004t18).4 for arabic preprocessing, we follow previously reported best tokenization scheme (tb)5 and orthographic word normalization condition (reduced) when translating from english to arabic (el kholy and habash, 2010b).
</prevsent>
</prevsection>
<citsent citstr=" P05-1071 ">
mada (habash and rambow, 2005) <papid> P05-1071 </papid>is used to pre-process the arabic text for the translation model and 5-gram language model (lm).</citsent>
<aftsection>
<nextsent>as postprocessing step, we jointly denormalize and deto kenize the text to produce the final arabic output.
</nextsent>
<nextsent>following el kholy and habash (2010a), we use their best detokenization technique, t+r+lm.
</nextsent>
<nextsent>the technique crucially utilizes lookup table (t), mapping tokenized forms to detokenized forms, basedon our mada-fied lm.
</nextsent>
<nextsent>alternatives are given conditional probabilities, (detokenized|tokenized).tokenized words absent from the tables are deto kenized using deterministic rules (r), as backoff strategy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1622">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this paper brings together several sub-areas:smt, paraphrase generation, distributional semantic distance measures, and antonym-related work.therefore we can only briefly survey the most relevant work here.
</prevsent>
<prevsent>our work can be viewed as an extension of the line of research that seeks to augment translation tables with automatically generated paraphrases of oov words or phrases in fashion similar to section 4: callison-burch et al (2006) use pivoting technique (translating to other languages and back) in order to generate paraphrases, and the pivot translation probability as their similarity score; callison-burch (2008) filters such paraphrases using syntactic parsing information; marton et al (2009)<papid> D09-1040 </papid>use distributional paraphrasing technique that applies distributional semantic distance measure forthe paraphrase score; marton (2010) applies lexical resource / corpus-based hybrid semantic distance measure for the paraphrase score instead, approximating word senses; here, we apply distributional semantic distance measure that is similar to marton et al (2009), <papid> D09-1040 </papid>with the main difference being the filtering of the resulting paraphrases for antonymity.</prevsent>
</prevsection>
<citsent citstr=" W09-0431 ">
other work on augmentating smt: habash and hu (2009) <papid> W09-0431 </papid>show, pivoting via trilingual parallel text, that using english as pivot language between chinese and arabic outperforms translation using direct chinese-arabic bilingual parallel text.other attempts to reduce the oov rate by augmenting the phrase tables source side include habash (2009), providing an online tool for paraphrasingoov phrases by lexical and morphological expansion of known phrases and dictionary terms ? and transliteration of proper names.</citsent>
<aftsection>
<nextsent>bond et al (2008) also pivot for paraphrasing.
</nextsent>
<nextsent>they improve smt coverage by using manually crafted monolingual hpsg grammar for generating meaning and grammar-preserving paraphrases.
</nextsent>
<nextsent>this grammar allows for certain word reordering, lexical substitutions, contractions, and typo?
</nextsent>
<nextsent>corrections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1623">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this grammar allows for certain word reordering, lexical substitutions, contractions, and typo?
</prevsent>
<prevsent>corrections.
</prevsent>
</prevsection>
<citsent citstr=" P10-2001 ">
onishi et al (2010), <papid> P10-2001 </papid>du et al (2010), and others,pivot-paraphrase the input, and represent the paraphrases in lattice format, decoding it with moses.</citsent>
<aftsection>
<nextsent>work on paraphrase generation: barzilay and mckeown (2001) <papid> P01-1008 </papid>extract paraphrases from monolingual parallel corpus, containing multiple translations of the same source.</nextsent>
<nextsent>however, monolingual parallel corpora are extremely rare and small.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1624">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>corrections.
</prevsent>
<prevsent>onishi et al (2010), <papid> P10-2001 </papid>du et al (2010), and others,pivot-paraphrase the input, and represent the paraphrases in lattice format, decoding it with moses.</prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
work on paraphrase generation: barzilay and mckeown (2001) <papid> P01-1008 </papid>extract paraphrases from monolingual parallel corpus, containing multiple translations of the same source.</citsent>
<aftsection>
<nextsent>however, monolingual parallel corpora are extremely rare and small.
</nextsent>
<nextsent>dolan et al (2004) <papid> C04-1051 </papid>use edit distance for paraphrasing.max (2009) and others take the context of the paraphrased words occurrence into account.</nextsent>
<nextsent>zhao et al (2008) <papid> P08-1116 </papid>apply smt-style decoding for paraphrasing, using several loglinear weighted resources while zhao et al (2009) <papid> P09-1094 </papid>filter out paraphrase candidatesand weight paraphrase features according to the desired nlp task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1625">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>work on paraphrase generation: barzilay and mckeown (2001) <papid> P01-1008 </papid>extract paraphrases from monolingual parallel corpus, containing multiple translations of the same source.</prevsent>
<prevsent>however, monolingual parallel corpora are extremely rare and small.</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
dolan et al (2004) <papid> C04-1051 </papid>use edit distance for paraphrasing.max (2009) and others take the context of the paraphrased words occurrence into account.</citsent>
<aftsection>
<nextsent>zhao et al (2008) <papid> P08-1116 </papid>apply smt-style decoding for paraphrasing, using several loglinear weighted resources while zhao et al (2009) <papid> P09-1094 </papid>filter out paraphrase candidatesand weight paraphrase features according to the desired nlp task.</nextsent>
<nextsent>chevelu et al (2009) <papid> P09-2063 </papid>introducea new paraphrase generation tool based on monte carlo sampling.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1626">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, monolingual parallel corpora are extremely rare and small.
</prevsent>
<prevsent>dolan et al (2004) <papid> C04-1051 </papid>use edit distance for paraphrasing.max (2009) and others take the context of the paraphrased words occurrence into account.</prevsent>
</prevsection>
<citsent citstr=" P08-1116 ">
zhao et al (2008) <papid> P08-1116 </papid>apply smt-style decoding for paraphrasing, using several loglinear weighted resources while zhao et al (2009) <papid> P09-1094 </papid>filter out paraphrase candidatesand weight paraphrase features according to the desired nlp task.</citsent>
<aftsection>
<nextsent>chevelu et al (2009) <papid> P09-2063 </papid>introducea new paraphrase generation tool based on monte carlo sampling.</nextsent>
<nextsent>mirkin et al (2009), <papid> P09-1089 </papid>inter alia, frame paraphrasing as special, symmetrical case of (wordnet-based) textual entailment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1627">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, monolingual parallel corpora are extremely rare and small.
</prevsent>
<prevsent>dolan et al (2004) <papid> C04-1051 </papid>use edit distance for paraphrasing.max (2009) and others take the context of the paraphrased words occurrence into account.</prevsent>
</prevsection>
<citsent citstr=" P09-1094 ">
zhao et al (2008) <papid> P08-1116 </papid>apply smt-style decoding for paraphrasing, using several loglinear weighted resources while zhao et al (2009) <papid> P09-1094 </papid>filter out paraphrase candidatesand weight paraphrase features according to the desired nlp task.</citsent>
<aftsection>
<nextsent>chevelu et al (2009) <papid> P09-2063 </papid>introducea new paraphrase generation tool based on monte carlo sampling.</nextsent>
<nextsent>mirkin et al (2009), <papid> P09-1089 </papid>inter alia, frame paraphrasing as special, symmetrical case of (wordnet-based) textual entailment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1628">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>dolan et al (2004) <papid> C04-1051 </papid>use edit distance for paraphrasing.max (2009) and others take the context of the paraphrased words occurrence into account.</prevsent>
<prevsent>zhao et al (2008) <papid> P08-1116 </papid>apply smt-style decoding for paraphrasing, using several loglinear weighted resources while zhao et al (2009) <papid> P09-1094 </papid>filter out paraphrase candidatesand weight paraphrase features according to the desired nlp task.</prevsent>
</prevsection>
<citsent citstr=" P09-2063 ">
chevelu et al (2009) <papid> P09-2063 </papid>introducea new paraphrase generation tool based on monte carlo sampling.</citsent>
<aftsection>
<nextsent>mirkin et al (2009), <papid> P09-1089 </papid>inter alia, frame paraphrasing as special, symmetrical case of (wordnet-based) textual entailment.</nextsent>
<nextsent>see madnani and dorr (2010) <papid> J10-3003 </papid>for good paraphrasing survey.work on measuring distributional semantic dis tance: for one survey of this rich topic, see weeds et al (2004) <papid> C04-1146 </papid>and turney and pantel (2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1630">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>chevelu et al (2009) <papid> P09-2063 </papid>introducea new paraphrase generation tool based on monte carlo sampling.</prevsent>
<prevsent>mirkin et al (2009), <papid> P09-1089 </papid>inter alia, frame paraphrasing as special, symmetrical case of (wordnet-based) textual entailment.</prevsent>
</prevsection>
<citsent citstr=" J10-3003 ">
see madnani and dorr (2010) <papid> J10-3003 </papid>for good paraphrasing survey.work on measuring distributional semantic dis tance: for one survey of this rich topic, see weeds et al (2004) <papid> C04-1146 </papid>and turney and pantel (2010).</citsent>
<aftsection>
<nextsent>we use here cosine of log-likelihood ratios (mcdonald,2000).
</nextsent>
<nextsent>a recent paper (kazama et al, 2010) <papid> P10-1026 </papid>advocates bayesian approach, making rare terms have lower strength of association, as by-product of relying on their probabilistic expectation.</nextsent>
<nextsent>work on detecting antonyms: our work with antonyms can be thought of as an application-based extension of the (mohammad et al, 2008) <papid> D08-1103 </papid>method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1633">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>see madnani and dorr (2010) <papid> J10-3003 </papid>for good paraphrasing survey.work on measuring distributional semantic dis tance: for one survey of this rich topic, see weeds et al (2004) <papid> C04-1146 </papid>and turney and pantel (2010).</prevsent>
<prevsent>we use here cosine of log-likelihood ratios (mcdonald,2000).</prevsent>
</prevsection>
<citsent citstr=" P10-1026 ">
a recent paper (kazama et al, 2010) <papid> P10-1026 </papid>advocates bayesian approach, making rare terms have lower strength of association, as by-product of relying on their probabilistic expectation.</citsent>
<aftsection>
<nextsent>work on detecting antonyms: our work with antonyms can be thought of as an application-based extension of the (mohammad et al, 2008) <papid> D08-1103 </papid>method.</nextsent>
<nextsent>some of the earliest computational work in this area is by lin et al (2003) who used patterns 245 model e2z:29k e2z:232k e2a:30k e2a:135k phrase table baseline vocab.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1635">
<title id=" W11-2128.xml">filtering antonymous trend contrasting and polarity dissimilar distributional paraphrases for improving statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>such as from to ? and either or ? to distinguish between antonymous and similar word pairs.
</prevsent>
<prevsent>harabagiu et al (2006) detected antonyms by determining if their wordnet synsets are connected by the hypernymyhyponymy links and exactly one antonymy link.
</prevsent>
</prevsection>
<citsent citstr=" C08-1114 ">
turney (2008) <papid> C08-1114 </papid>proposed supervised method to solve word analogy questions that require identifying synonyms, antonyms, hyper nyms, and other lexical-semantic relations between word pairs.</citsent>
<aftsection>
<nextsent>we presented here novel method for filtering out antonymous phrasal paraphrase candidates, adapted from sentiment analysis literature, and tested in simulated low- and mid-resourced smt tasks from english to two quite different languages.
</nextsent>
<nextsent>we used an antonymous word pair list extracted distributionally by extending seed list.
</nextsent>
<nextsent>then, the extended list, together with negator list and novel heuristic, were used to filter out antonymous paraphrase candidates.finally, smt models were augmented with the filtered paraphrases, yielding english-chinese translation improvements of up to 1 bleu from the corresponding non-filtered paraphrase-augmented model (up to 1.6 bleu from the corresponding baselinemodel).
</nextsent>
<nextsent>our method proved effective for models trained on both reduced and mid-large english chinese parallel texts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1636">
<title id=" W12-2019.xml">on improving the accuracy of readability classification using insights from second language acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in some of the early works on statistical readability assessment, si and callan (2001) and collins-thompson and callan (2004) reported the impact of using unigram language models to estimate the grade level of given text.
</prevsent>
<prevsent>the models were built on united states textbook corpus.
</prevsent>
</prevsection>
<citsent citstr=" N07-1058 ">
heilman et al (2007; <papid> N07-1058 </papid>2008b; 2008a) extended this approach and worked towards retrieving relevant reading materials for language learners in the reap3 project.</citsent>
<aftsection>
<nextsent>they extended the above mentioned approach to include set of manually and later automatically extracted grammatical features.
</nextsent>
<nextsent>schwarm and ostendorf (2005) <papid> P05-1065 </papid>and petersen and ostendorf (2009) report on classification experiments with weekly reader data, considering statistical language models, traditional formulae, as well ascertain basic parse tree features in building an svm based statistical model.</nextsent>
<nextsent>feng et al (2010) <papid> C10-2032 </papid>and feng (2010) went beyond lexical and syntactic features and studied the impact of several discourse-basedfeatures, comparing their performance on the week lyre ader corpus.while the vast majority of approaches have targeted english texts, some work on other languages such as german, portuguese, french and italian (vorder bruck et al, 2008; aluisio et al, 2010; francois and watrin, 2011; dellorletta et al, 2011) is starting to emerge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1637">
<title id=" W12-2019.xml">on improving the accuracy of readability classification using insights from second language acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>heilman et al (2007; <papid> N07-1058 </papid>2008b; 2008a) extended this approach and worked towards retrieving relevant reading materials for language learners in the reap3 project.</prevsent>
<prevsent>they extended the above mentioned approach to include set of manually and later automatically extracted grammatical features.</prevsent>
</prevsection>
<citsent citstr=" P05-1065 ">
schwarm and ostendorf (2005) <papid> P05-1065 </papid>and petersen and ostendorf (2009) report on classification experiments with weekly reader data, considering statistical language models, traditional formulae, as well ascertain basic parse tree features in building an svm based statistical model.</citsent>
<aftsection>
<nextsent>feng et al (2010) <papid> C10-2032 </papid>and feng (2010) went beyond lexical and syntactic features and studied the impact of several discourse-basedfeatures, comparing their performance on the week lyre ader corpus.while the vast majority of approaches have targeted english texts, some work on other languages such as german, portuguese, french and italian (vorder bruck et al, 2008; aluisio et al, 2010; francois and watrin, 2011; dellorletta et al, 2011) is starting to emerge.</nextsent>
<nextsent>parse-tree-based features have also been used to measure the complexity of spoken swedish (roll et al, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1639">
<title id=" W12-2019.xml">on improving the accuracy of readability classification using insights from second language acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>they extended the above mentioned approach to include set of manually and later automatically extracted grammatical features.
</prevsent>
<prevsent>schwarm and ostendorf (2005) <papid> P05-1065 </papid>and petersen and ostendorf (2009) report on classification experiments with weekly reader data, considering statistical language models, traditional formulae, as well ascertain basic parse tree features in building an svm based statistical model.</prevsent>
</prevsection>
<citsent citstr=" C10-2032 ">
feng et al (2010) <papid> C10-2032 </papid>and feng (2010) went beyond lexical and syntactic features and studied the impact of several discourse-basedfeatures, comparing their performance on the week lyre ader corpus.while the vast majority of approaches have targeted english texts, some work on other languages such as german, portuguese, french and italian (vorder bruck et al, 2008; aluisio et al, 2010; francois and watrin, 2011; dellorletta et al, 2011) is starting to emerge.</citsent>
<aftsection>
<nextsent>parse-tree-based features have also been used to measure the complexity of spoken swedish (roll et al, 2007).
</nextsent>
<nextsent>the process of text comprehension and the effect of factors such as the coherence of texts have also been intensively studied (e.g., crossley et al, 2007a;2007b; graesser et al, 2004) and measures to analyze the text under this perspective have been implemented in the cohmetrix project.4 the darpa machine reading program created 3http://reap.cs.cmu.edu 4http://cohmetrix.memphis.edu 164a corpus of general text readability containing various forms of human and machine generated texts (strassel et al, 2010).5 the aim of this program is to transform natural language texts into format suit able for automatic processing by machines and to filter out poorly written documents based on the text quality.
</nextsent>
<nextsent>kate et al (2010) <papid> C10-1062 </papid>used this dataset to build coarse grained model of text readability.while in this paper we focus on comparing computational linguistic approaches to readability assessment and improving the state of the art on traditional and available dataset, nelson et al (2012)compared several research and commercially available text difficulty assessment systems in support ofthe common core standards?</nextsent>
<nextsent>goal of providing students with texts at the appropriate level of difficulty throughout their schooling.6 independent of the research on readability, the complexity of the texts produced by language learners has been extensively investigated in second language acquisition (sla) research (housen and kuiken, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1641">
<title id=" W12-2019.xml">on improving the accuracy of readability classification using insights from second language acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>parse-tree-based features have also been used to measure the complexity of spoken swedish (roll et al, 2007).
</prevsent>
<prevsent>the process of text comprehension and the effect of factors such as the coherence of texts have also been intensively studied (e.g., crossley et al, 2007a;2007b; graesser et al, 2004) and measures to analyze the text under this perspective have been implemented in the cohmetrix project.4 the darpa machine reading program created 3http://reap.cs.cmu.edu 4http://cohmetrix.memphis.edu 164a corpus of general text readability containing various forms of human and machine generated texts (strassel et al, 2010).5 the aim of this program is to transform natural language texts into format suit able for automatic processing by machines and to filter out poorly written documents based on the text quality.
</prevsent>
</prevsection>
<citsent citstr=" C10-1062 ">
kate et al (2010) <papid> C10-1062 </papid>used this dataset to build coarse grained model of text readability.while in this paper we focus on comparing computational linguistic approaches to readability assessment and improving the state of the art on traditional and available dataset, nelson et al (2012)compared several research and commercially available text difficulty assessment systems in support ofthe common core standards?</citsent>
<aftsection>
<nextsent>goal of providing students with texts at the appropriate level of difficulty throughout their schooling.6 independent of the research on readability, the complexity of the texts produced by language learners has been extensively investigated in second language acquisition (sla) research (housen and kuiken, 2009).
</nextsent>
<nextsent>recent approaches have automated and compared number of such complexity measures for learner language, specifically in english as second language learner narratives (lu, 2010; lu, 2011b).
</nextsent>
<nextsent>so far, there is hardly any work on using such insights in computational linguistics, though, with the notable exception of chen and zechner (2011) <papid> P11-1073 </papid>using sla features to evaluate spontaneous non-native speech.</nextsent>
<nextsent>given that graded corpora are also intended to be used by incremental age groups, we started to investigate whether the insights from sla research can fruitfully be applied to readability classification.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1642">
<title id=" W12-2019.xml">on improving the accuracy of readability classification using insights from second language acquisition </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>goal of providing students with texts at the appropriate level of difficulty throughout their schooling.6 independent of the research on readability, the complexity of the texts produced by language learners has been extensively investigated in second language acquisition (sla) research (housen and kuiken, 2009).
</prevsent>
<prevsent>recent approaches have automated and compared number of such complexity measures for learner language, specifically in english as second language learner narratives (lu, 2010; lu, 2011b).
</prevsent>
</prevsection>
<citsent citstr=" P11-1073 ">
so far, there is hardly any work on using such insights in computational linguistics, though, with the notable exception of chen and zechner (2011) <papid> P11-1073 </papid>using sla features to evaluate spontaneous non-native speech.</citsent>
<aftsection>
<nextsent>given that graded corpora are also intended to be used by incremental age groups, we started to investigate whether the insights from sla research can fruitfully be applied to readability classification.
</nextsent>
<nextsent>we used combined corpus of weekly reader and bbc-bitesize to develop statistical model that classifies texts into five grade levels, based on the age groups.
</nextsent>
<nextsent>weeklyreader7 is an educational newspaper, with articles targeted at four grade levels (level 2, level 3, level 4, and senior), corresponding to children 5the corpus is apparently intended to be available for public use, but does not yet seem to be so; we so far were unsuccessful in obtaining more information from the authors.
</nextsent>
<nextsent>6http://www.corestandards.org 7http://www.weeklyreader.com between ages 78, 89, 910, and 912 years.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1647">
<title id=" W12-2019.xml">on improving the accuracy of readability classification using insights from second language acquisition </title>
<section> experiments and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we also included two popular readability formulae, flesch-kincaid score (kincaid et al,1975) and coleman-liau readability formula (cole man and liau, 1975), as additional features.
</prevsent>
<prevsent>the latter will be referred as coleman below, and both formulas together as traditional formulae.
</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
we used the berkeley parser (petrov and klein, 2007) <papid> N07-1051 </papid>with the standard model they provide for building syntactic parse trees and defined the patterns for extracting various syntactic features from syntactic features from sla research (slasyn) ? mean length of clause (mlc) ? mean length of sentence (mls) ? mean length of t-unit (mlt) ? num.</citsent>
<aftsection>
<nextsent>of clauses per sentence (c/s) ? num.
</nextsent>
<nextsent>of t-units per sentence (t/s) ? num.
</nextsent>
<nextsent>of clauses per t-unit (c/t) ? num.
</nextsent>
<nextsent>of complex-t-units per t-unit (ct/t) ? dependent clause to clause ratio (dc/c) ? dependent clause to t-unit ratio (dc/t) ? co-ordinate phrases per clause (cp/c) ? co-ordinate phrases per t-unit (cp/t) ? complex nominals per clause (cn/c) ? complex nominals per t-unit (cn/t) ? verb phrases per t-unit (vp/t) other syntactic features ? num.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1658">
<title id=" W12-1503.xml">learning preferences for referring expression generation effects of domain language and algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is precisely this intuition of preferred attributes which is incorporated in the incremental algorithm (dale and reiter, 1995), arguably one of themost influential reg algorithms to date.
</prevsent>
<prevsent>the incremental algorithm (ia) assumes the existence of complete, ordered list of preferred attributes.
</prevsent>
</prevsection>
<citsent citstr=" C08-2029 ">
the algorithm basically ite rates through this list, adding an attribute (e.g., colour) to the description under construction if its value (e.g., yellow) helps ruling out one or more of the remaining distractors.even though the ia is exceptional in that it relies on complete ordering of attributes, most current reg algorithms make use of preferences in some way (fabbrizio et al , 2008; gervas et al , 2008; kelleher, 2007; spanger et al , 2008; <papid> C08-2029 </papid>viethen and dale, 2010).</citsent>
<aftsection>
<nextsent>the graph-based reg algorithm(krahmer et al , 2003), <papid> J03-1003 </papid>for example, models preferences in terms of costs, where cheaper is more preferred.</nextsent>
<nextsent>contrary to the ia, the graph-based algorithm assumes that preferences operate at the level of attribute-value pairs (or properties) rather than atthe level of attributes; in this way it becomes possible to prefer straightforward size (large) over asubtle colour (mauve, taupe).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1659">
<title id=" W12-1503.xml">learning preferences for referring expression generation effects of domain language and algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the incremental algorithm (ia) assumes the existence of complete, ordered list of preferred attributes.
</prevsent>
<prevsent>the algorithm basically ite rates through this list, adding an attribute (e.g., colour) to the description under construction if its value (e.g., yellow) helps ruling out one or more of the remaining distractors.even though the ia is exceptional in that it relies on complete ordering of attributes, most current reg algorithms make use of preferences in some way (fabbrizio et al , 2008; gervas et al , 2008; kelleher, 2007; spanger et al , 2008; <papid> C08-2029 </papid>viethen and dale, 2010).</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
the graph-based reg algorithm(krahmer et al , 2003), <papid> J03-1003 </papid>for example, models preferences in terms of costs, where cheaper is more preferred.</citsent>
<aftsection>
<nextsent>contrary to the ia, the graph-based algorithm assumes that preferences operate at the level of attribute-value pairs (or properties) rather than atthe level of attributes; in this way it becomes possible to prefer straightforward size (large) over asubtle colour (mauve, taupe).
</nextsent>
<nextsent>moreover, the graph based algorithm looks for the cheapest overall description, and may opt for description with single, relatively dis preferred property (the man with the blue eyes?)
</nextsent>
<nextsent>when the alternative would be to combine many, relatively preferred properties (the large, balding man with the bow tie and the striped tuxedo?).
</nextsent>
<nextsent>this flexibility is arguably one of the 3 reasons why the graph-based reg approach works well: it was the best performing system in the most recent reg challenge (gatt et al , 2009).<papid> W09-0629 </papid>but where do the preferences used in the algorithms come from?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1661">
<title id=" W12-1503.xml">learning preferences for referring expression generation effects of domain language and algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, the graph based algorithm looks for the cheapest overall description, and may opt for description with single, relatively dis preferred property (the man with the blue eyes?)
</prevsent>
<prevsent>when the alternative would be to combine many, relatively preferred properties (the large, balding man with the bow tie and the striped tuxedo?).
</prevsent>
</prevsection>
<citsent citstr=" W09-0629 ">
this flexibility is arguably one of the 3 reasons why the graph-based reg approach works well: it was the best performing system in the most recent reg challenge (gatt et al , 2009).<papid> W09-0629 </papid>but where do the preferences used in the algorithms come from?</citsent>
<aftsection>
<nextsent>dale and reiter point out that preferences are domain dependent, and that determining them forgiven domain is essentially an empirical question.
</nextsent>
<nextsent>unfortunately, they do not specify how this particular empirical question should be answered.
</nextsent>
<nextsent>the general preference for colour over size is experimentally well-established (pechmann, 1989), but for most other cases experimental data are not readily available.
</nextsent>
<nextsent>an alternative would be to look at human data, preferably in semantically transparent?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1662">
<title id=" W12-1503.xml">learning preferences for referring expression generation effects of domain language and algorithm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this is not an easy matter, since various factors might play role: from which dataset are example references sampled, what are the domains of interest, and, perhaps most importantly, which reg algorithm is considered?
</prevsent>
<prevsent>inthis paper, we address these questions by systematically training two reg algorithms (the incremental algorithm and the graph-based reg algorithm) on sets of human-produced descriptions of increasing size and evaluating them on held-out test set; wedo this for two different domains (people and furniture descriptions) and two datasets in two different languages (tuna and d-tuna, the dutch version of tuna).
</prevsent>
</prevsection>
<citsent citstr=" P11-2116 ">
that size of the training set may have an impact on the performance of reg algorithm was already suggested by theune et al  (2011), <papid> P11-2116 </papid>who used the english tuna corpus to determine preferences (costs)for the graph-based algorithm using similar learning curve set-up as we use here.</citsent>
<aftsection>
<nextsent>however, the current paper expands on theune et al  (2011) <papid> P11-2116 </papid>in three major ways.</nextsent>
<nextsent>firstly, and most importantly, where theune et al  reported results for only one algorithm(the graph-based one), we directly compare the performance of the graph-based algorithm and the incremental algorithm (something which, somewhat surprisingly, has not been done before).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1667">
<title id=" W12-1503.xml">learning preferences for referring expression generation effects of domain language and algorithm </title>
<section> the algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>the output of the algorithm is the cheapest distinguishing subgraph, given particular cost function assigning costs to properties (i.e., attribute-value pairs).
</prevsent>
<prevsent>by assigning zero costs to some properties graph is also capable of generating over specified descriptions, including redundant properties.
</prevsent>
</prevsection>
<citsent citstr=" L08-1090 ">
to ensure that the graph search does not terminate before the free properties are added, the search order must be explicitly controlled (viethen et al , 2008).<papid> L08-1090 </papid></citsent>
<aftsection>
<nextsent>to ensure fair comparison with the ia, we make sure that if the targets type property was not originally selected by the algorithm, it is added afterwards.
</nextsent>
<nextsent>in this study, both the costs and orders required by graph are derived from corpus data.
</nextsent>
<nextsent>we base the property order on the frequency with which eachattribute-value pair is mentioned in training corpus, relative to the number of target objects with this property.
</nextsent>
<nextsent>the properties are then listed in order of decreasing frequency.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1676">
<title id=" W12-1503.xml">learning preferences for referring expression generation effects of domain language and algorithm </title>
<section> discussion and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>moreover, the graph-based algorithm is arguably more generic than the incremental algorithm, as it can straightforwardly deal with relational properties and lends itself to various extensions (krahmer et al ., 2003).<papid> J03-1003 </papid></prevsent>
<prevsent>in short, the larger training investment required for graph in simple domains may be compensated by its versatility and better performance on more complex domains.</prevsent>
</prevsection>
<citsent citstr=" W08-1104 ">
to test this assumption, our experiment should be repeated using data from more realistic and complex domain, e.g., geographic descriptions (turner et al , 2008).<papid> W08-1104 </papid></citsent>
<aftsection>
<nextsent>unfortunately, currently no such datasets are available.finally, we found that the results of both algorithms were better for the dutch data than for the english ones.
</nextsent>
<nextsent>we think that this is not so much an ef 9 fect of the language (as english and dutch are highlycomparable) but rather of the way the tuna and dtuna corpora were constructed.
</nextsent>
<nextsent>the d-tuna corpus was collected in more controlled conditions than tuna and as result, arguably, it contains training data of higher quality.
</nextsent>
<nextsent>also, because the d-tunacorpus does not contain any location properties (x and y-dimension) its furniture and people domains are slightly less complex than their tuna counterparts, making the attribute selection task bit easier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1677">
<title id=" W12-1503.xml">learning preferences for referring expression generation effects of domain language and algorithm </title>
<section> discussion and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>one caveat of our study is that so far we have only used the standard automatic metrics on reg evaluation (albeit in accordance with many other studies in this area).
</prevsent>
<prevsent>however, it has been found that these do not always correspond to the results of human-based evaluations, so it would be interesting to see whether the same learning curve effects are obtained for extrinsic, task based evaluations involving human subjects.
</prevsent>
</prevsection>
<citsent citstr=" P08-2050 ">
following belz and gatt (2008), <papid> P08-2050 </papid>this could be done by measuring reading times, identification times or error rates as function of training set size.</citsent>
<aftsection>
<nextsent>comparing ia with fb and gr we have shown that small set sizes are sufficient to reach ceiling for the ia. but which preference orders (pos) do we find with these small set sizes?
</nextsent>
<nextsent>and how does the ias performance with these orders compare to the results obtained by alternative algorithms such as dale and reiters (1995) classic full brevity (fb) and greedy algorithm (gr)?
</nextsent>
<nextsent>a question explicitly asked by van deemter et al  (2012).
</nextsent>
<nextsent>in the furniture domain, all five english training sets of size 5 yield po for which van deemter et al  showed that it causes the ia to significantly outperform fb and gr (i.e., either c(olor)o(rientation)s(ize) or cso; note that here we abstract over type which van deemter and colleagues do not consider).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1678">
<title id=" W11-2209.xml">unsupervised concept annotation using latent dirichlet allocation and segmental methods </title>
<section> automatic induction of semantic classes.  </section>
<citcontext>
<prevsection>
<prevsent>once the parameters for the dirichlet and multinomial distributions are available, topic scores can be derived for any given document or word sequence.
</prevsent>
<prevsent>in recent years, several studies have been carried out in language processing based on lda.
</prevsent>
</prevsection>
<citsent citstr=" W10-1201 ">
for instance, (tam and schultz, 2006) worked on unsupervised language model adaptation; (celikyilmaz etal., 2010) <papid> W10-1201 </papid>ranked candidate passages in question answering system; (phan et al , 2008) implemented lda to classify short and sparse web texts.</citsent>
<aftsection>
<nextsent>74 latent dirichlet allocation ? w?
</nextsent>
<nextsent>m figure 1: graphical model representation of lda.
</nextsent>
<nextsent>the boxes are plates?
</nextsent>
<nextsent>representing replicates.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1679">
<title id=" W11-2209.xml">unsupervised concept annotation using latent dirichlet allocation and segmental methods </title>
<section> segmental annotation.  </section>
<citcontext>
<prevsection>
<prevsent>since these alignment models can align several words with single topic, only the first occurrence is kept for consecutive repetitions of the sametopic.
</prevsent>
<prevsent>these models are expected to correct some errors made by lda, and to assign in particular words previously associated with discarded topics to more likely ones.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
in our experiments the statistical word alignment toolkit giza++ (och and ney, 2003) <papid> J03-1002 </papid>is used to train the so-called ibm models 1-4 as well as thehmm model.</citsent>
<aftsection>
<nextsent>to be able to train the most informative ibm model 4, the following training pipeline was considered: 5 iterations of ibm1, 5 iterations of hmm, 3 iterations of ibm3 and 3 iterations ofibm4.
</nextsent>
<nextsent>the ibm4 model obtained at the last iteration is finally used to align words and topics.
</nextsent>
<nextsent>inorder to improve alignment, ibm models are usually trained in both directions (words towards concepts and vice versa) and symmetrised by combining them.
</nextsent>
<nextsent>for this purpose, we resorted to the default symmetrization heuristics used by moses, widely used machine translation system toolkit (koehn et al ., 2007).<papid> P07-2045 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1680">
<title id=" W11-2209.xml">unsupervised concept annotation using latent dirichlet allocation and segmental methods </title>
<section> segmental annotation.  </section>
<citcontext>
<prevsection>
<prevsent>the ibm4 model obtained at the last iteration is finally used to align words and topics.
</prevsent>
<prevsent>inorder to improve alignment, ibm models are usually trained in both directions (words towards concepts and vice versa) and symmetrised by combining them.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
for this purpose, we resorted to the default symmetrization heuristics used by moses, widely used machine translation system toolkit (koehn et al ., 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>3.3 alignment with integer linear.
</nextsent>
<nextsent>programming (ilp)another approach to the re-alignment of lda outputs is based on general optimisation technique.ilp is widely used tool for modelling and solving combinatorial optimisation problems.
</nextsent>
<nextsent>it broadly aims at modelling decision process as set of equations or in equations (called constraints) which are linear with regards to so-called decision variables.an ilp is also composed of linear objective function.
</nextsent>
<nextsent>solving an ilp consists in assigning values to decision variables, such that all constraints are satisfied and the objective function is optimised.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1681">
<title id=" W12-0508.xml">a joint named entity recognition and entity linking system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the linking process must thereafter evaluate which readings are the most probable, based on the most likely entity matches inferred from similarity measure with the context.
</prevsent>
<prevsent>ner has been widely addressed by symbolic, statistical as well as hybrid approaches.
</prevsent>
</prevsection>
<citsent citstr=" M98-1002 ">
its major part in information extraction (ie) and other nlp applications has been stated and encouraged by several editions of evaluation campaigns such as muc (marsh and perzanowski, 1998), <papid> M98-1002 </papid>the conll-2003 ner shared task (tjong kim sang and de meulder, 2003) or ace (doddington et al , 2004), where ner systems show near-human performances for the english language.</citsent>
<aftsection>
<nextsent>our system aims at benefitting from both symbolic and statistical ner techniques, which have proven efficient 52 but not necessarily over the same type of data and with different precision/recall tradeoff.
</nextsent>
<nextsent>ner considers the surface form of entities; some type disambiguation and name normalization can follow the detection to improve the result precision but do not provide referential information, which can be useful in ie applications.
</nextsent>
<nextsent>el achieves the association of ner results with uniquely identified entities, by relying on an entity repository, available to the extraction system and defined beforehand in order to serve as target for mention linking.
</nextsent>
<nextsent>knowledge about entities is gathered in dedicated knowledge base (kb) to evaluate each entitys similarity to given context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1682">
<title id=" W12-0508.xml">a joint named entity recognition and entity linking system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>el achieves the association of ner results with uniquely identified entities, by relying on an entity repository, available to the extraction system and defined beforehand in order to serve as target for mention linking.
</prevsent>
<prevsent>knowledge about entities is gathered in dedicated knowledge base (kb) to evaluate each entitys similarity to given context.
</prevsent>
</prevsection>
<citsent citstr=" D07-1074 ">
after the task of el was initiated with wikipedia-based works on entity disambiguation, in particular by cucerzan (2007) <papid> D07-1074 </papid>and bunescu and pasca (2006), numerous systems have been developed, encouraged by the tac 2009 kb population task (mcnamee and dang, 2009).</citsent>
<aftsection>
<nextsent>most often in el, wikipedia serves both as an entity repository (the set of articles referring to entities) and as kb about entities (derived from wikipedia info boxes and articles which contain text, meta data such as categories and hyperlinks).
</nextsent>
<nextsent>zhang et al  (2010) <papid> C10-1145 </papid>show how wikipedia, by providing large annotated corpus of linked ambiguous entity mentions, pertains efficiently to the el task.</nextsent>
<nextsent>evaluated el systems at tac report top accuracy rate of 0.80 on english data (mcnamee et al , 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1683">
<title id=" W12-0508.xml">a joint named entity recognition and entity linking system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>after the task of el was initiated with wikipedia-based works on entity disambiguation, in particular by cucerzan (2007) <papid> D07-1074 </papid>and bunescu and pasca (2006), numerous systems have been developed, encouraged by the tac 2009 kb population task (mcnamee and dang, 2009).</prevsent>
<prevsent>most often in el, wikipedia serves both as an entity repository (the set of articles referring to entities) and as kb about entities (derived from wikipedia info boxes and articles which contain text, meta data such as categories and hyperlinks).</prevsent>
</prevsection>
<citsent citstr=" C10-1145 ">
zhang et al  (2010) <papid> C10-1145 </papid>show how wikipedia, by providing large annotated corpus of linked ambiguous entity mentions, pertains efficiently to the el task.</citsent>
<aftsection>
<nextsent>evaluated el systems at tac report top accuracy rate of 0.80 on english data (mcnamee et al , 2010).
</nextsent>
<nextsent>entities that are unknown to the reference database, called out-of-base entities, are also considered by el, when given mention refers toan entity absent from the available wikipedia articles.
</nextsent>
<nextsent>this is addressed by various methods, such as setting threshold of minimal similarity for an entity selection (bunescu and pasca, 2006), or training separate binary classifier to judge whether the returned top candidate is the actual denot ation (zheng et al , 2010).<papid> N10-1072 </papid></nextsent>
<nextsent>our approach of this issue is closely related to the method ofdredze et al  in (2010), where the out-of-base entity is considered as another entry to rank.our task differs from el configurations outlined previously, in that its target is entity extraction from raw news wires from the news agency agence france presse (afp), and not only linking relying on goldner annotations: the inputof the linking system is the result of an automatic ner step, which will produce errors of various kinds.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1684">
<title id=" W12-0508.xml">a joint named entity recognition and entity linking system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluated el systems at tac report top accuracy rate of 0.80 on english data (mcnamee et al , 2010).
</prevsent>
<prevsent>entities that are unknown to the reference database, called out-of-base entities, are also considered by el, when given mention refers toan entity absent from the available wikipedia articles.
</prevsent>
</prevsection>
<citsent citstr=" N10-1072 ">
this is addressed by various methods, such as setting threshold of minimal similarity for an entity selection (bunescu and pasca, 2006), or training separate binary classifier to judge whether the returned top candidate is the actual denot ation (zheng et al , 2010).<papid> N10-1072 </papid></citsent>
<aftsection>
<nextsent>our approach of this issue is closely related to the method ofdredze et al  in (2010), where the out-of-base entity is considered as another entry to rank.our task differs from el configurations outlined previously, in that its target is entity extraction from raw news wires from the news agency agence france presse (afp), and not only linking relying on goldner annotations: the inputof the linking system is the result of an automatic ner step, which will produce errors of various kinds.
</nextsent>
<nextsent>in particular, spans erroneously detected as nes will have to be discarded by our el system.
</nextsent>
<nextsent>this case, which we call not-an-entity, contitute an additional type of special situations, together with out-of-base entities but specific to our setting.
</nextsent>
<nextsent>this issue, as well as others of our task specificities, will be discussed in this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1685">
<title id=" W12-1014.xml">adapting wikification to cultural heritage </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>relatedness gives measure of the similarity of two articles by comparing their incoming and outgoing links.
</prevsent>
<prevsent>the performance achieved using their approach is currently state of the art for this task.
</prevsent>
</prevsection>
<citsent citstr=" I08-1071 ">
the wikiminer software is freely available2, andhas been used as the basis for the approaches presented here.recent work on named entity linking and wikification makes use of categories and link information (bunescu and pasca, 2006; dakka and cucerzan, 2008; <papid> I08-1071 </papid>kulkarni et al, 2009).</citsent>
<aftsection>
<nextsent>wikification has also been applied to the medical do main (he et al, 2011).
</nextsent>
<nextsent>wikipedia categories and links have been used previously to find the similarity between ch items (grieser et al, 2011).
</nextsent>
<nextsent>the category retraining approach presented here differs in that it only makes use of the top-level categories.
</nextsent>
<nextsent>three approaches to improving the quality of wikipedia links added by wikiminer were developed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1686">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>may refer to the planet earth, dirt, or solid ground, depending on the context.
</prevsent>
<prevsent>the goal of word sense induction (wsi) isto automatically discover the different senses by examining how word is used.
</prevsent>
</prevsection>
<citsent citstr=" E03-1020 ">
this unsupervised discovery process produces sense inventory where the number of senses is corpus-driven and where senses may reflect additional usages not present in predefined sense inventory, such as those for medicine or law (dorow and widdows, 2003).<papid> E03-1020 </papid></citsent>
<aftsection>
<nextsent>furthermore,these discovered senses can be used to automatically expand lexical resources such as wordnet or framenet (klapaftis and manandhar, 2010).<papid> N10-1010 </papid></nextsent>
<nextsent>discovering the multiple senses is frequently confounded by the relationships between words senses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1687">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goal of word sense induction (wsi) isto automatically discover the different senses by examining how word is used.
</prevsent>
<prevsent>this unsupervised discovery process produces sense inventory where the number of senses is corpus-driven and where senses may reflect additional usages not present in predefined sense inventory, such as those for medicine or law (dorow and widdows, 2003).<papid> E03-1020 </papid></prevsent>
</prevsection>
<citsent citstr=" N10-1010 ">
furthermore,these discovered senses can be used to automatically expand lexical resources such as wordnet or framenet (klapaftis and manandhar, 2010).<papid> N10-1010 </papid></citsent>
<aftsection>
<nextsent>discovering the multiple senses is frequently confounded by the relationships between words senses.
</nextsent>
<nextsent>while homonyms such as bass?
</nextsent>
<nextsent>or bank?
</nextsent>
<nextsent>have unrelated senses, many polysemous wordshave interrelated senses, with lexicographers of ten in disagreement for the number of fine-grained senses (palmer et al, 2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1688">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>according to wordnet, shown in table 1, are similar in several aspect sand could be ascribed interchangeably in some contexts.
</prevsent>
<prevsent>the difficulty of automatically distinguishing two senses is proportional to their similarity because of the increasing likelihood of the two senses sharing similar contexts.
</prevsent>
</prevsection>
<citsent citstr=" W02-0805 ">
while the issue distinguishing between related senses is recognized issue for word sense disambiguation (chugur et al, 2002; <papid> W02-0805 </papid>mccarthy, 2006),<papid> W06-2503 </papid>which uses supervised training to learn sense distinctions, measuring the impact of sense relatedness on the harder problem of wsi remains unad dressed.</citsent>
<aftsection>
<nextsent>the recent semeval wsi tasks (agirre and soroa, 2007; <papid> W07-2002 </papid>manandhar and klapaftis, 2009) <papid> W09-2419 </papid>have provided standard framework for evaluating wsi systems, with controlled training corpus designed to limit sense ambiguity in the example contexts.</nextsent>
<nextsent>however, given the potential relatedness of words senses, we view it necessary to consider how wsi methods perform relative to the degree of contextualambiguity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1689">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>according to wordnet, shown in table 1, are similar in several aspect sand could be ascribed interchangeably in some contexts.
</prevsent>
<prevsent>the difficulty of automatically distinguishing two senses is proportional to their similarity because of the increasing likelihood of the two senses sharing similar contexts.
</prevsent>
</prevsection>
<citsent citstr=" W06-2503 ">
while the issue distinguishing between related senses is recognized issue for word sense disambiguation (chugur et al, 2002; <papid> W02-0805 </papid>mccarthy, 2006),<papid> W06-2503 </papid>which uses supervised training to learn sense distinctions, measuring the impact of sense relatedness on the harder problem of wsi remains unad dressed.</citsent>
<aftsection>
<nextsent>the recent semeval wsi tasks (agirre and soroa, 2007; <papid> W07-2002 </papid>manandhar and klapaftis, 2009) <papid> W09-2419 </papid>have provided standard framework for evaluating wsi systems, with controlled training corpus designed to limit sense ambiguity in the example contexts.</nextsent>
<nextsent>however, given the potential relatedness of words senses, we view it necessary to consider how wsi methods perform relative to the degree of contextualambiguity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1690">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the difficulty of automatically distinguishing two senses is proportional to their similarity because of the increasing likelihood of the two senses sharing similar contexts.
</prevsent>
<prevsent>while the issue distinguishing between related senses is recognized issue for word sense disambiguation (chugur et al, 2002; <papid> W02-0805 </papid>mccarthy, 2006),<papid> W06-2503 </papid>which uses supervised training to learn sense distinctions, measuring the impact of sense relatedness on the harder problem of wsi remains unad dressed.</prevsent>
</prevsection>
<citsent citstr=" W07-2002 ">
the recent semeval wsi tasks (agirre and soroa, 2007; <papid> W07-2002 </papid>manandhar and klapaftis, 2009) <papid> W09-2419 </papid>have provided standard framework for evaluating wsi systems, with controlled training corpus designed to limit sense ambiguity in the example contexts.</citsent>
<aftsection>
<nextsent>however, given the potential relatedness of words senses, we view it necessary to consider how wsi methods perform relative to the degree of contextualambiguity.
</nextsent>
<nextsent>our goal is therefore to quantify the similarity at which wsi approach is unable to distinguish between two senses, which reflects the sense granularity at which the approach operates.we propose two new evaluations.
</nextsent>
<nextsent>the first, described in section 4, uses similarity-based pseudo word discrimination task to measure the discrimination capability for related senses along graded scale of similarity.
</nextsent>
<nextsent>as second evaluation, in 113 1 the collection of rules imposed by authority 2 legal document setting forth rules governing particular kind of activity 3 rule or body of rules of conduct inherent in human nature and essential to or binding upon human society 4 generalization that describes recurring facts or events in nature table 1: definitions for the top four senses of law?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1691">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the difficulty of automatically distinguishing two senses is proportional to their similarity because of the increasing likelihood of the two senses sharing similar contexts.
</prevsent>
<prevsent>while the issue distinguishing between related senses is recognized issue for word sense disambiguation (chugur et al, 2002; <papid> W02-0805 </papid>mccarthy, 2006),<papid> W06-2503 </papid>which uses supervised training to learn sense distinctions, measuring the impact of sense relatedness on the harder problem of wsi remains unad dressed.</prevsent>
</prevsection>
<citsent citstr=" W09-2419 ">
the recent semeval wsi tasks (agirre and soroa, 2007; <papid> W07-2002 </papid>manandhar and klapaftis, 2009) <papid> W09-2419 </papid>have provided standard framework for evaluating wsi systems, with controlled training corpus designed to limit sense ambiguity in the example contexts.</citsent>
<aftsection>
<nextsent>however, given the potential relatedness of words senses, we view it necessary to consider how wsi methods perform relative to the degree of contextualambiguity.
</nextsent>
<nextsent>our goal is therefore to quantify the similarity at which wsi approach is unable to distinguish between two senses, which reflects the sense granularity at which the approach operates.we propose two new evaluations.
</nextsent>
<nextsent>the first, described in section 4, uses similarity-based pseudo word discrimination task to measure the discrimination capability for related senses along graded scale of similarity.
</nextsent>
<nextsent>as second evaluation, in 113 1 the collection of rules imposed by authority 2 legal document setting forth rules governing particular kind of activity 3 rule or body of rules of conduct inherent in human nature and essential to or binding upon human society 4 generalization that describes recurring facts or events in nature table 1: definitions for the top four senses of law?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1692">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> clustering contexts to discover senses.  </section>
<citcontext>
<prevsection>
<prevsent>we choose initial seeds at random and use the h2 criterion function (zhao and karypis, 2001).
</prevsent>
<prevsent>although k-means is efficient and widely used, it requires the number of clusters to be specified priori.
</prevsent>
</prevsection>
<citsent citstr=" N06-4007 ">
therefore, we follow the wsi model of pedersen and kulkarni (2006) <papid> N06-4007 </papid>and use the gap statistic (tibshirani et al, 2000) to automatically determine the number of clusters.</citsent>
<aftsection>
<nextsent>the gap statistic runs k-means repeatedly with different values of , ranging from 1 to some sensible maximum.
</nextsent>
<nextsent>the gap statistic first induces adata model from the feature distributions of the initial dataset and then for each , creates set of artificial datasets by sampling from the derived model.k is increased until the gap?, i.e. the distance between the objective function of the original dataset and the average objective function of the artificial datasets, is larger then the gap for the previous value.
</nextsent>
<nextsent>we calculate the gap using 10 artificial datasets sampled from the model.spectral clustering spectral clustering interprets datasets elements as vertices in graph with edges based on their similarity (ng et al, 2001).clusters are found by identifying the graph partition that produces the minimum conductance between every partition.
</nextsent>
<nextsent>this can be thought of as trying to find small islands that are connected by as few bridges as possible.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1693">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> clustering contexts to discover senses.  </section>
<citcontext>
<prevsection>
<prevsent>this can be thought of as trying to find small islands that are connected by as few bridges as possible.
</prevsent>
<prevsent>we refer the reader to (von luxburg, 2007) for further technical details.
</prevsent>
</prevsection>
<citsent citstr=" W10-4173 ">
to our knowledge, only he et al (2010) <papid> W10-4173 </papid>have applied spectral clustering to wsi, which was performed on chinese dataset.</citsent>
<aftsection>
<nextsent>however, the algorithm used by he et al requires the number of clusters to be specified.we instead use hybrid spectral clustering algorithm, first applied to information retrieval (cheng et al, 2006), that automatically selects the number of clusters.
</nextsent>
<nextsent>this algorithm recursively partitions dataset in half by finding the cut that produces the minimum conductance, which builds tree of partitions.
</nextsent>
<nextsent>this split is done until either every data point is in its own partition or maximum number of partitions is found.
</nextsent>
<nextsent>partitions are then dynamically merged, starting at leaf partitions, based on clustering criteria.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1694">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> clustering contexts to discover senses.  </section>
<citcontext>
<prevsection>
<prevsent>cbcs recur sion ensures that contexts dissimilar to the large committees are still grouped into their own smaller committees, which enables the discovery of infrequent senses with distinct contexts.
</prevsent>
<prevsent>we use ahard sense assignment for each context, i.e., context is labeled with only one sense according to the most similar cluster.streaming k-means as wsi moves into inducing senses from web-scale amounts of data, existing clustering algorithms that keep all contexts in memory become impractical.
</prevsent>
</prevsection>
<citsent citstr=" S10-1080 ">
jurgens and stevens(2010<papid> S10-1080 </papid>a) proposed an on-line hybrid clustering solution using on-line k-means and hierarchical agglomerative clustering, which automatically decided the number of clusters without retaining all the contexts.</citsent>
<aftsection>
<nextsent>to the best of our knowledge, theirs is the only work using an on-line approach.
</nextsent>
<nextsent>we extend this work by applying more theoretically sound online k-means algorithm, called streaming k-means (braverman et al, 2011), to wsi.
</nextsent>
<nextsent>we use streaming k-means to conduct direct algorithmic comparison with k-means in the hopes that online approaches can be made just as effective as off-line approaches.
</nextsent>
<nextsent>streaming k-means processes each data point only once, thus reducing the memory overhead dramatically.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1700">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> clustering contexts to discover senses.  </section>
<citcontext>
<prevsection>
<prevsent>when assigning data point, it is only assigned to an existing cluster when their similar is above some threshold, otherwise the data point becomes the centro id of new cluster.
</prevsent>
<prevsent>once reaches threshold, based on an estimate of the number of data points, or the overall k-means clustering cost reaches some limit, the centro ids are treated as new data points and re-clustered, with thegoal of merging some centroids.
</prevsent>
</prevsection>
<citsent citstr=" W97-0322 ">
we follow (jurgens and stevens, 2010<papid> S10-1080 </papid>a) and cluster the final cen troids with hierarchical agglomerative clustering,with the average link criteria as suggested by (ped ersen and bruce, 1997).<papid> W97-0322 </papid></citsent>
<aftsection>
<nextsent>for each clustering algorithm, we consider five context models that represent the types of lexical features used by the majority of wsi approaches.co-occurrence contexts formed from word cooccurrence are the most common in wsi algorithms.
</nextsent>
<nextsent>for each occurrence of word, those words within certain range are counted as features.
</nextsent>
<nextsent>prior work has used variety of context sizes, e.g. words inthe same sentence (bordag, 2006), <papid> E06-1018 </papid>in nearby lexical positions (gauch and futrelle, 1993), or within paragraph-sized context window (pedersen, 2010).<papid> S10-1081 </papid></nextsent>
<nextsent>we consider two co-occurrence context models: 5-word and 25-word window.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1701">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> modeling context.  </section>
<citcontext>
<prevsection>
<prevsent>for each clustering algorithm, we consider five context models that represent the types of lexical features used by the majority of wsi approaches.co-occurrence contexts formed from word cooccurrence are the most common in wsi algorithms.
</prevsent>
<prevsent>for each occurrence of word, those words within certain range are counted as features.
</prevsent>
</prevsection>
<citsent citstr=" E06-1018 ">
prior work has used variety of context sizes, e.g. words inthe same sentence (bordag, 2006), <papid> E06-1018 </papid>in nearby lexical positions (gauch and futrelle, 1993), or within paragraph-sized context window (pedersen, 2010).<papid> S10-1081 </papid></citsent>
<aftsection>
<nextsent>we consider two co-occurrence context models: 5-word and 25-word window.
</nextsent>
<nextsent>we note that in co-occurrence-based word space algorithms, smaller context sizes have shown to better capture paradag matic similarity, while larger sizes capture semantic associativity (peirsman et al, 2008; utsumi, 2010).dependency-relations dependency parsing creates syntax tree where words are directly linked according to their relation.
</nextsent>
<nextsent>these links refine cooccurrence based contexts by utilizing syntactic indications of how words are related.
</nextsent>
<nextsent>dependency parsed features have proven highly effective for word representations in many nlp applications, e.g., (pado?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1702">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> modeling context.  </section>
<citcontext>
<prevsection>
<prevsent>for each clustering algorithm, we consider five context models that represent the types of lexical features used by the majority of wsi approaches.co-occurrence contexts formed from word cooccurrence are the most common in wsi algorithms.
</prevsent>
<prevsent>for each occurrence of word, those words within certain range are counted as features.
</prevsent>
</prevsection>
<citsent citstr=" S10-1081 ">
prior work has used variety of context sizes, e.g. words inthe same sentence (bordag, 2006), <papid> E06-1018 </papid>in nearby lexical positions (gauch and futrelle, 1993), or within paragraph-sized context window (pedersen, 2010).<papid> S10-1081 </papid></citsent>
<aftsection>
<nextsent>we consider two co-occurrence context models: 5-word and 25-word window.
</nextsent>
<nextsent>we note that in co-occurrence-based word space algorithms, smaller context sizes have shown to better capture paradag matic similarity, while larger sizes capture semantic associativity (peirsman et al, 2008; utsumi, 2010).dependency-relations dependency parsing creates syntax tree where words are directly linked according to their relation.
</nextsent>
<nextsent>these links refine cooccurrence based contexts by utilizing syntactic indications of how words are related.
</nextsent>
<nextsent>dependency parsed features have proven highly effective for word representations in many nlp applications, e.g., (pado?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1704">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> modeling context.  </section>
<citcontext>
<prevsection>
<prevsent>and lapata, 2007; baroni et al, 2010).
</prevsent>
<prevsent>we follow pantel and lin (2002) and dorow and widdows (2003) <papid> E03-1020 </papid>using the sentence as contexts and all words with dependency path of length 3 or less, with the last word and its relation as feature.</prevsent>
</prevsection>
<citsent citstr=" S10-1078 ">
we note that recently kern et al (2010) <papid> S10-1078 </papid>achieved good wsi performance with only small, manually-tuned subset of all relations as context.</citsent>
<aftsection>
<nextsent>word ordering word ordering can provide mild form of syntactic information (jones et al,2006; sahlgren et al, 2008).
</nextsent>
<nextsent>while other syntac 115tic features may provide significantly more information, word ordering is efficient to compute and provides an alternative source of syntactic information for knowledge-lean systems or for languages where nlp tools are not readily available.because we treat word ordering as syntactic feature, we limit the context to words occurring in the same sentence.
</nextsent>
<nextsent>a feature is the combination of co-occurring word and its relative position, i.e. the same word in different positions is treated as two separate features.parts of speech part of speech tagging can provide preliminary coarse-grained sense disambiguation of words contextual features, where word may have as many senses as it does parts of speech.
</nextsent>
<nextsent>for example, consider an occurrence of house?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1706">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> wsi performance on related senses.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, we employ pseudo-word discrimination task where base word and second word, its confounder,are replaced throughout the corpus with pseudo word.
</prevsent>
<prevsent>the objective is then to determine which of the words was originally present given the context of an occurrence of the pseudo-word.
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
due to not requiring manual annotation, this type of task was initially proposed as substitute for word sense disambiguation (schutze, 1992; gale et al, 1992) <papid> H92-1045 </papid>and for selectional preferences (clark and weir, 2002).<papid> J02-2003 </papid>following the suggestions of chambers and ju festival laws offices 0.13660 interests 0.18289 play 0.13751 politics 0.20440 convention 0.20296 governments 0.29125 tournament 0.29007 regulations 0.40761 concerts 0.48348 legislation 0.56112 table 2: example confounders for festival?</citsent>
<aftsection>
<nextsent>and laws?
</nextsent>
<nextsent>and their similaritiesrafsky (2010) on designing pseudo-words, pseudo words were created from words with the same partof speech and equal frequency in the training corpus.
</nextsent>
<nextsent>we selected nouns occurring more than 5,000 times in 2009 wikipedia snapshot and then drew 5,000 contexts for each.
</nextsent>
<nextsent>the snapshot was tagged with the stanford part of speech tagger (toutanova et al, 2003) <papid> N03-1033 </papid>and parsed with the malt parser (nivre et al, 2006).to evaluate the impact of sense similarity, pseudo words were created from word pairs with broad range of lexical similarities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1707">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> wsi performance on related senses.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, we employ pseudo-word discrimination task where base word and second word, its confounder,are replaced throughout the corpus with pseudo word.
</prevsent>
<prevsent>the objective is then to determine which of the words was originally present given the context of an occurrence of the pseudo-word.
</prevsent>
</prevsection>
<citsent citstr=" J02-2003 ">
due to not requiring manual annotation, this type of task was initially proposed as substitute for word sense disambiguation (schutze, 1992; gale et al, 1992) <papid> H92-1045 </papid>and for selectional preferences (clark and weir, 2002).<papid> J02-2003 </papid>following the suggestions of chambers and ju festival laws offices 0.13660 interests 0.18289 play 0.13751 politics 0.20440 convention 0.20296 governments 0.29125 tournament 0.29007 regulations 0.40761 concerts 0.48348 legislation 0.56112 table 2: example confounders for festival?</citsent>
<aftsection>
<nextsent>and laws?
</nextsent>
<nextsent>and their similaritiesrafsky (2010) on designing pseudo-words, pseudo words were created from words with the same partof speech and equal frequency in the training corpus.
</nextsent>
<nextsent>we selected nouns occurring more than 5,000 times in 2009 wikipedia snapshot and then drew 5,000 contexts for each.
</nextsent>
<nextsent>the snapshot was tagged with the stanford part of speech tagger (toutanova et al, 2003) <papid> N03-1033 </papid>and parsed with the malt parser (nivre et al, 2006).to evaluate the impact of sense similarity, pseudo words were created from word pairs with broad range of lexical similarities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1708">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> wsi performance on related senses.  </section>
<citcontext>
<prevsection>
<prevsent>and their similaritiesrafsky (2010) on designing pseudo-words, pseudo words were created from words with the same partof speech and equal frequency in the training corpus.
</prevsent>
<prevsent>we selected nouns occurring more than 5,000 times in 2009 wikipedia snapshot and then drew 5,000 contexts for each.
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
the snapshot was tagged with the stanford part of speech tagger (toutanova et al, 2003) <papid> N03-1033 </papid>and parsed with the malt parser (nivre et al, 2006).to evaluate the impact of sense similarity, pseudo words were created from word pairs with broad range of lexical similarities.</citsent>
<aftsection>
<nextsent>we selected lexical similarity as an approximation of sense similarity in order to model the hypothesis that similar senses may appear in similar contexts.
</nextsent>
<nextsent>similarity scores were calculated using cosine similarity on contextual distributions built from sliding 2 word window over the wikipedia corpus.
</nextsent>
<nextsent>table 2 highlights several example confounders and their similarities with the base term.
</nextsent>
<nextsent>in total, we generated 5000 term confounder pairs from 98 base terms, with mean of 51 confounders per term.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1710">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> sense confusion in semeval-2 task 14.  </section>
<citcontext>
<prevsection>
<prevsent>the current method intentionally uses uniform distribution to avoid potential bias; however, word sense distributions are rarely equal, and varied distribution would more closely model real world distributions.
</prevsent>
<prevsent>similarly, the current method tested only two senses, whereas an n-way disambiguation between multiple confounders should also provide further insight into wsi approachs discriminatory abilities.
</prevsent>
</prevsection>
<citsent citstr=" S10-1011 ">
as second experiment, we analyze incorrect sense assignments on semeval-2 task 14 (manandhar etal., 2010) <papid> S10-1011 </papid>to measure whether sense-relatedness biases which sense was incorrectly selected.</citsent>
<aftsection>
<nextsent>for wsi systems, similarity bias would indicate that similar senses are more likely to be incorrectly identified as single sense.
</nextsent>
<nextsent>we summarize task 14 as follows.
</nextsent>
<nextsent>systems are provided with an unlabeled training corpus consisting of 879,807 multi-sentence contexts for 100 polysemous words, comprised of 50 nouns and 50verbs.
</nextsent>
<nextsent>systems induce sense representations for target words from the training corpus and then use those representations to label the senses of the target words in unseen contexts from test corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1711">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> sense confusion in semeval-2 task 14.  </section>
<citcontext>
<prevsection>
<prevsent>systems are provided with an unlabeled training corpus consisting of 879,807 multi-sentence contexts for 100 polysemous words, comprised of 50 nouns and 50verbs.
</prevsent>
<prevsent>systems induce sense representations for target words from the training corpus and then use those representations to label the senses of the target words in unseen contexts from test corpus.
</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
the induced senses are then evaluated against the gold standard labels ontonotes (hovy et al, 2006) <papid> N06-2015 </papid>senses labels for the test corpus.</citsent>
<aftsection>
<nextsent>for our evaluation,we use both the two contrasting unsupervised measures, the paired fscore (artiles et al, 2009) <papid> D09-1056 </papid>and the v-measure (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>and supervised measure.</nextsent>
<nextsent>for each metric, we use the evaluation framework provided by the organizers of semeval-2 task 14.1the v-measure rates the homogeneity and completeness of clustering solution.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1712">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> sense confusion in semeval-2 task 14.  </section>
<citcontext>
<prevsection>
<prevsent>systems induce sense representations for target words from the training corpus and then use those representations to label the senses of the target words in unseen contexts from test corpus.
</prevsent>
<prevsent>the induced senses are then evaluated against the gold standard labels ontonotes (hovy et al, 2006) <papid> N06-2015 </papid>senses labels for the test corpus.</prevsent>
</prevsection>
<citsent citstr=" D09-1056 ">
for our evaluation,we use both the two contrasting unsupervised measures, the paired fscore (artiles et al, 2009) <papid> D09-1056 </papid>and the v-measure (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>and supervised measure.</citsent>
<aftsection>
<nextsent>for each metric, we use the evaluation framework provided by the organizers of semeval-2 task 14.1the v-measure rates the homogeneity and completeness of clustering solution.
</nextsent>
<nextsent>solutions that have word clusters formed from one gold-standard sense are homogeneous; completeness measures the degree to which gold-standard senses instances are assigned to single cluster.
</nextsent>
<nextsent>the paired fscore measures two types of overlap of solution and thegold standard in cluster assignments for all in pairwise combination of instances.
</nextsent>
<nextsent>this score tends to penalize solutions with many small clusters and highly heterogeneous clusters (manandhar and klapaftis, 2009).<papid> W09-2419 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1713">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> sense confusion in semeval-2 task 14.  </section>
<citcontext>
<prevsection>
<prevsent>systems induce sense representations for target words from the training corpus and then use those representations to label the senses of the target words in unseen contexts from test corpus.
</prevsent>
<prevsent>the induced senses are then evaluated against the gold standard labels ontonotes (hovy et al, 2006) <papid> N06-2015 </papid>senses labels for the test corpus.</prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
for our evaluation,we use both the two contrasting unsupervised measures, the paired fscore (artiles et al, 2009) <papid> D09-1056 </papid>and the v-measure (rosenberg and hirschberg, 2007), <papid> D07-1043 </papid>and supervised measure.</citsent>
<aftsection>
<nextsent>for each metric, we use the evaluation framework provided by the organizers of semeval-2 task 14.1the v-measure rates the homogeneity and completeness of clustering solution.
</nextsent>
<nextsent>solutions that have word clusters formed from one gold-standard sense are homogeneous; completeness measures the degree to which gold-standard senses instances are assigned to single cluster.
</nextsent>
<nextsent>the paired fscore measures two types of overlap of solution and thegold standard in cluster assignments for all in pairwise combination of instances.
</nextsent>
<nextsent>this score tends to penalize solutions with many small clusters and highly heterogeneous clusters (manandhar and klapaftis, 2009).<papid> W09-2419 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1715">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> sense confusion in semeval-2 task 14.  </section>
<citcontext>
<prevsection>
<prevsent>labeling could take into account the distribution of gold standard senses labels in the corpus from which the senses are induced; however, such labels are not available in the task 14 training corpus.for each incorrect sense assignment, we measure the similarity of the confused sense to the correct sense.
</prevsent>
<prevsent>to our knowledge, no work has been done on calculating sense similarity within the ontonotes sense hierarchy.2 therefore, we approximate ontonotes sense similarity by using sense similarity in the wordnet ontology, on which has many similarity measures have been defined.
</prevsent>
</prevsection>
<citsent citstr=" J06-1003 ">
following budanitsky and hirst (2006), <papid> J06-1003 </papid>we estimate the wordnet sense similarity using the method proposed by jiang and conrath (1997).</citsent>
<aftsection>
<nextsent>each ontonotes sense si is mapped to set of wordnet 3.0 senses si = {wn1, . . .
</nextsent>
<nextsent>, wnn} using 2we suspect that this is in part because words ontonotes senses have been designed to minimize sense confusion.
</nextsent>
<nextsent>the sense mapping provided by the conll shared task.3 the sense similarity for two ontonotes senses is computed using one of two methods: sim = 1|s1||s2| ? wnis1,wnjs2 jcn(wni, wnj), (1) or sim = argmax wnis1,wnjs2 jcn(wni, wnj), (2)where jcn indicates the jiang-conrath similarity of two wordnet senses, calculated using wordnet::similarity (pedersen et al, 2004).<papid> N04-3012 </papid></nextsent>
<nextsent>eq.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1716">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> sense confusion in semeval-2 task 14.  </section>
<citcontext>
<prevsection>
<prevsent>each ontonotes sense si is mapped to set of wordnet 3.0 senses si = {wn1, . . .
</prevsent>
<prevsent>, wnn} using 2we suspect that this is in part because words ontonotes senses have been designed to minimize sense confusion.
</prevsent>
</prevsection>
<citsent citstr=" N04-3012 ">
the sense mapping provided by the conll shared task.3 the sense similarity for two ontonotes senses is computed using one of two methods: sim = 1|s1||s2| ? wnis1,wnjs2 jcn(wni, wnj), (1) or sim = argmax wnis1,wnjs2 jcn(wni, wnj), (2)where jcn indicates the jiang-conrath similarity of two wordnet senses, calculated using wordnet::similarity (pedersen et al, 2004).<papid> N04-3012 </papid></citsent>
<aftsection>
<nextsent>eq.
</nextsent>
<nextsent>1 computes similarity as the average similarity of all pairwise wordnet sense combinations, while eq.
</nextsent>
<nextsent>2 uses the highest similarity.
</nextsent>
<nextsent>the resulting ontonote sense similarities range from 0 to 1, with 1 being maximally similar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1719">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> future work and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>the results raise potential issue forclustering-based wsi approaches: sense discrimination degrades notably as the sense relatedness increases.
</prevsent>
<prevsent>we highlight three potential avenues for future research.
</prevsent>
</prevsection>
<citsent citstr=" D10-1012 ">
first, this methodology should be applied to additional wsi models, such as graph based (klapaftis and manandhar, 2008; navigli and crisafulli, 2010) <papid> D10-1012 </papid>and probabilistic models (dinu and lapata, 2010; elshamy et al, 2010).<papid> S10-1082 </papid></citsent>
<aftsection>
<nextsent>second, weplan to extend the analysis to different sense distributions, varying number of senses, and for human annotated sense similarity data.
</nextsent>
<nextsent>third, this evaluation makes the simplifying assumption of one sense per instance; however, erk et al (2009) <papid> P09-1002 </papid>note that the relations between senses may cause single word instance to evoke multiple senses within the same context.</nextsent>
<nextsent>therefore, future experiment should consider how wsi systems might address learning senses given the presence of multiple, similar senses for single instance.all models, associated datasets, testing framework, and scores have been released as part of the open-source s-space package (jurgens and stevens, 2010<papid> S10-1080 </papid>b).5 5 http://code.google.com/p/airhead-research/ 121</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1720">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> future work and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>the results raise potential issue forclustering-based wsi approaches: sense discrimination degrades notably as the sense relatedness increases.
</prevsent>
<prevsent>we highlight three potential avenues for future research.
</prevsent>
</prevsection>
<citsent citstr=" S10-1082 ">
first, this methodology should be applied to additional wsi models, such as graph based (klapaftis and manandhar, 2008; navigli and crisafulli, 2010) <papid> D10-1012 </papid>and probabilistic models (dinu and lapata, 2010; elshamy et al, 2010).<papid> S10-1082 </papid></citsent>
<aftsection>
<nextsent>second, weplan to extend the analysis to different sense distributions, varying number of senses, and for human annotated sense similarity data.
</nextsent>
<nextsent>third, this evaluation makes the simplifying assumption of one sense per instance; however, erk et al (2009) <papid> P09-1002 </papid>note that the relations between senses may cause single word instance to evoke multiple senses within the same context.</nextsent>
<nextsent>therefore, future experiment should consider how wsi systems might address learning senses given the presence of multiple, similar senses for single instance.all models, associated datasets, testing framework, and scores have been released as part of the open-source s-space package (jurgens and stevens, 2010<papid> S10-1080 </papid>b).5 5 http://code.google.com/p/airhead-research/ 121</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1721">
<title id=" W11-2214.xml">measuring the impact of sense similarity on word sense induction </title>
<section> future work and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>first, this methodology should be applied to additional wsi models, such as graph based (klapaftis and manandhar, 2008; navigli and crisafulli, 2010) <papid> D10-1012 </papid>and probabilistic models (dinu and lapata, 2010; elshamy et al, 2010).<papid> S10-1082 </papid></prevsent>
<prevsent>second, weplan to extend the analysis to different sense distributions, varying number of senses, and for human annotated sense similarity data.</prevsent>
</prevsection>
<citsent citstr=" P09-1002 ">
third, this evaluation makes the simplifying assumption of one sense per instance; however, erk et al (2009) <papid> P09-1002 </papid>note that the relations between senses may cause single word instance to evoke multiple senses within the same context.</citsent>
<aftsection>
<nextsent>therefore, future experiment should consider how wsi systems might address learning senses given the presence of multiple, similar senses for single instance.all models, associated datasets, testing framework, and scores have been released as part of the open-source s-space package (jurgens and stevens, 2010<papid> S10-1080 </papid>b).5 5 http://code.google.com/p/airhead-research/ 121</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1726">
<title id=" W11-2017.xml">the day after the day after tomorrow a machine learning approach to adaptive temporal expression generation training and evaluation with real users </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>temporal expressions are linguistic expressions that are used to refer to date and are often source of confusion in human-human, human-computer andtext interactions such as emails and instant messaging.
</prevsent>
<prevsent>for example, lets meet next sunday??
</prevsent>
</prevsection>
<citsent citstr=" J88-2003 ">
do you mean sunday this week or week on sunday??.(mccoy and strube, 1999) state that changes in temporal structure in text are often indicated by either cue words and phrases (e.g. next thursday?, this week?, tomorrow?), change in grammatical time of the verb (e.g. present tense versus future tense), or changes in aspect (e.g. atomic versus extended events versus states as defined by (moens and steedman, 1988)).<papid> J88-2003 </papid></citsent>
<aftsection>
<nextsent>in this study, we will concentrate on the first of these phenomena, generating tes with the optimal content and lexical choice.much work in the field of natural language processing concerns understanding and resolving these temporal expressions in text (gerber et al, 2002; pustejovsky et al, 2003; ahn et al, 2007; <papid> N07-1053 </papid>mazur and dale, 2007; han et al, 2006), <papid> N06-1018 </papid>however, little work has looked at how best to plan and realise temporal expressions in order to minimize ambiguity and confusion in spoken dialogue system (sds).(reiter et al, 2005) presented data driven approach to generating tes to refer to time in weather forecast information where appropriate expressions were identified using contextual features using supervised learning.</nextsent>
<nextsent>we adopt an adaptive, data-driven reinforcement learning approach instead.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1727">
<title id=" W11-2017.xml">the day after the day after tomorrow a machine learning approach to adaptive temporal expression generation training and evaluation with real users </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, lets meet next sunday??
</prevsent>
<prevsent>do you mean sunday this week or week on sunday??.(mccoy and strube, 1999) state that changes in temporal structure in text are often indicated by either cue words and phrases (e.g. next thursday?, this week?, tomorrow?), change in grammatical time of the verb (e.g. present tense versus future tense), or changes in aspect (e.g. atomic versus extended events versus states as defined by (moens and steedman, 1988)).<papid> J88-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1053 ">
in this study, we will concentrate on the first of these phenomena, generating tes with the optimal content and lexical choice.much work in the field of natural language processing concerns understanding and resolving these temporal expressions in text (gerber et al, 2002; pustejovsky et al, 2003; ahn et al, 2007; <papid> N07-1053 </papid>mazur and dale, 2007; han et al, 2006), <papid> N06-1018 </papid>however, little work has looked at how best to plan and realise temporal expressions in order to minimize ambiguity and confusion in spoken dialogue system (sds).(reiter et al, 2005) presented data driven approach to generating tes to refer to time in weather forecast information where appropriate expressions were identified using contextual features using supervised learning.</citsent>
<aftsection>
<nextsent>we adopt an adaptive, data-driven reinforcement learning approach instead.
</nextsent>
<nextsent>similardata-driven approaches have been applied to information presentation (rieser et al, 2010; <papid> P10-1103 </papid>walker et al., 2007) where each natural language generation (nlg) action is sequential decision point, based on the current dialogue context and expected long-term reward of that action.</nextsent>
<nextsent>a data-driven approach hasalso been applied to the problem of referring expression generation in dialogue for expert and novice users of sds (janarthanam and lemon, 2010).<papid> P10-1008 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1728">
<title id=" W11-2017.xml">the day after the day after tomorrow a machine learning approach to adaptive temporal expression generation training and evaluation with real users </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, lets meet next sunday??
</prevsent>
<prevsent>do you mean sunday this week or week on sunday??.(mccoy and strube, 1999) state that changes in temporal structure in text are often indicated by either cue words and phrases (e.g. next thursday?, this week?, tomorrow?), change in grammatical time of the verb (e.g. present tense versus future tense), or changes in aspect (e.g. atomic versus extended events versus states as defined by (moens and steedman, 1988)).<papid> J88-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" N06-1018 ">
in this study, we will concentrate on the first of these phenomena, generating tes with the optimal content and lexical choice.much work in the field of natural language processing concerns understanding and resolving these temporal expressions in text (gerber et al, 2002; pustejovsky et al, 2003; ahn et al, 2007; <papid> N07-1053 </papid>mazur and dale, 2007; han et al, 2006), <papid> N06-1018 </papid>however, little work has looked at how best to plan and realise temporal expressions in order to minimize ambiguity and confusion in spoken dialogue system (sds).(reiter et al, 2005) presented data driven approach to generating tes to refer to time in weather forecast information where appropriate expressions were identified using contextual features using supervised learning.</citsent>
<aftsection>
<nextsent>we adopt an adaptive, data-driven reinforcement learning approach instead.
</nextsent>
<nextsent>similardata-driven approaches have been applied to information presentation (rieser et al, 2010; <papid> P10-1103 </papid>walker et al., 2007) where each natural language generation (nlg) action is sequential decision point, based on the current dialogue context and expected long-term reward of that action.</nextsent>
<nextsent>a data-driven approach hasalso been applied to the problem of referring expression generation in dialogue for expert and novice users of sds (janarthanam and lemon, 2010).<papid> P10-1008 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1729">
<title id=" W11-2017.xml">the day after the day after tomorrow a machine learning approach to adaptive temporal expression generation training and evaluation with real users </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this study, we will concentrate on the first of these phenomena, generating tes with the optimal content and lexical choice.much work in the field of natural language processing concerns understanding and resolving these temporal expressions in text (gerber et al, 2002; pustejovsky et al, 2003; ahn et al, 2007; <papid> N07-1053 </papid>mazur and dale, 2007; han et al, 2006), <papid> N06-1018 </papid>however, little work has looked at how best to plan and realise temporal expressions in order to minimize ambiguity and confusion in spoken dialogue system (sds).(reiter et al, 2005) presented data driven approach to generating tes to refer to time in weather forecast information where appropriate expressions were identified using contextual features using supervised learning.</prevsent>
<prevsent>we adopt an adaptive, data-driven reinforcement learning approach instead.</prevsent>
</prevsection>
<citsent citstr=" P10-1103 ">
similardata-driven approaches have been applied to information presentation (rieser et al, 2010; <papid> P10-1103 </papid>walker et al., 2007) where each natural language generation (nlg) action is sequential decision point, based on the current dialogue context and expected long-term reward of that action.</citsent>
<aftsection>
<nextsent>a data-driven approach hasalso been applied to the problem of referring expression generation in dialogue for expert and novice users of sds (janarthanam and lemon, 2010).<papid> P10-1008 </papid></nextsent>
<nextsent>however, to date, there has been no previous workon adaptive data-driven approaches for temporal referring expression generation, where uncertainty in 142 the stochastic environment is explicitly modelled.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1730">
<title id=" W11-2017.xml">the day after the day after tomorrow a machine learning approach to adaptive temporal expression generation training and evaluation with real users </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we adopt an adaptive, data-driven reinforcement learning approach instead.
</prevsent>
<prevsent>similardata-driven approaches have been applied to information presentation (rieser et al, 2010; <papid> P10-1103 </papid>walker et al., 2007) where each natural language generation (nlg) action is sequential decision point, based on the current dialogue context and expected long-term reward of that action.</prevsent>
</prevsection>
<citsent citstr=" P10-1008 ">
a data-driven approach hasalso been applied to the problem of referring expression generation in dialogue for expert and novice users of sds (janarthanam and lemon, 2010).<papid> P10-1008 </papid></citsent>
<aftsection>
<nextsent>however, to date, there has been no previous workon adaptive data-driven approaches for temporal referring expression generation, where uncertainty in 142 the stochastic environment is explicitly modelled.
</nextsent>
<nextsent>the data-driven approach to temporal expression generation presented here is in the context of appointment scheduling dialogues.
</nextsent>
<nextsent>the fact that there are multiple ways that time slot can be referred to leads to an interesting nlg problem of how best to realise te for particular individual in particular context for certain domains.
</nextsent>
<nextsent>for example, the following expressions all vary in terms of length, ambiguity, redundant information and users?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1731">
<title id=" W12-1506.xml">towards a surface realization oriented corpus annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments shows that making the semantic corpora comply with the suggested principles does not need to have negative impact on the quality of the stochastic generators trained on them.
</prevsent>
<prevsent>with the increasing interest in data-driven surface realization, the question on the adequate annotation of corpora for generation also becomes increasingly important.
</prevsent>
</prevsection>
<citsent citstr=" P95-1034 ">
while in the early days of stochastic generation, annotations produced for other applications were used (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998; bangalore andrambow, 2000; <papid> C00-1007 </papid>oh and rudnicky, 2000; <papid> W00-0306 </papid>langkilde geary, 2002), the poor results obtained, e.g., by (bohnet et al, 2010)<papid> C10-1012 </papid>with the original conll 2009 corpora, show that annotations that serve well for other applications, may not do so for generation and thus need at least to be adjusted.1 this has also been acknowledged in the run-up to the surface realization challenge 2011 (belz et al, 2011), where considerable amount of work has been invested into the conversion of the annotations of the conll 2008 corpora (surdeanu et al, 2008), <papid> W08-2121 </papid>i.e., propbank (palmer et al, 2005), <papid> J05-1004 </papid>which served as the reference treebank, into more generation friendly?</citsent>
<aftsection>
<nextsent>annotation.
</nextsent>
<nextsent>however, all of the available annotations are to certain extent still syntactic.
</nextsent>
<nextsent>even propbank and its generation-oriented variants contain significant number of syntactic features (bohnet et al, 2011b).some previous approaches to data-driven generation avoid the problem related to the lack of semantic resources in that they use hybrid models that imply symbolic sub module which derives the syntactic representation that is then used by the stochastic sub module (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998).</nextsent>
<nextsent>(walker et al, 2002), (stent et al, 2004), (<papid> P04-1011 </papid>wong and mooney, 2007), <papid> N07-1022 </papid>and (mairesse et al, 2010) <papid> P10-1157 </papid>start from deeper structures: walker et aland stent et al from deep-syntactic structures (melcuk, 1988), and wong and mooney and mairesse et al from higher order predicate logic structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1733">
<title id=" W12-1506.xml">towards a surface realization oriented corpus annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments shows that making the semantic corpora comply with the suggested principles does not need to have negative impact on the quality of the stochastic generators trained on them.
</prevsent>
<prevsent>with the increasing interest in data-driven surface realization, the question on the adequate annotation of corpora for generation also becomes increasingly important.
</prevsent>
</prevsection>
<citsent citstr=" C00-1007 ">
while in the early days of stochastic generation, annotations produced for other applications were used (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998; bangalore andrambow, 2000; <papid> C00-1007 </papid>oh and rudnicky, 2000; <papid> W00-0306 </papid>langkilde geary, 2002), the poor results obtained, e.g., by (bohnet et al, 2010)<papid> C10-1012 </papid>with the original conll 2009 corpora, show that annotations that serve well for other applications, may not do so for generation and thus need at least to be adjusted.1 this has also been acknowledged in the run-up to the surface realization challenge 2011 (belz et al, 2011), where considerable amount of work has been invested into the conversion of the annotations of the conll 2008 corpora (surdeanu et al, 2008), <papid> W08-2121 </papid>i.e., propbank (palmer et al, 2005), <papid> J05-1004 </papid>which served as the reference treebank, into more generation friendly?</citsent>
<aftsection>
<nextsent>annotation.
</nextsent>
<nextsent>however, all of the available annotations are to certain extent still syntactic.
</nextsent>
<nextsent>even propbank and its generation-oriented variants contain significant number of syntactic features (bohnet et al, 2011b).some previous approaches to data-driven generation avoid the problem related to the lack of semantic resources in that they use hybrid models that imply symbolic sub module which derives the syntactic representation that is then used by the stochastic sub module (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998).</nextsent>
<nextsent>(walker et al, 2002), (stent et al, 2004), (<papid> P04-1011 </papid>wong and mooney, 2007), <papid> N07-1022 </papid>and (mairesse et al, 2010) <papid> P10-1157 </papid>start from deeper structures: walker et aland stent et al from deep-syntactic structures (melcuk, 1988), and wong and mooney and mairesse et al from higher order predicate logic structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1734">
<title id=" W12-1506.xml">towards a surface realization oriented corpus annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments shows that making the semantic corpora comply with the suggested principles does not need to have negative impact on the quality of the stochastic generators trained on them.
</prevsent>
<prevsent>with the increasing interest in data-driven surface realization, the question on the adequate annotation of corpora for generation also becomes increasingly important.
</prevsent>
</prevsection>
<citsent citstr=" W00-0306 ">
while in the early days of stochastic generation, annotations produced for other applications were used (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998; bangalore andrambow, 2000; <papid> C00-1007 </papid>oh and rudnicky, 2000; <papid> W00-0306 </papid>langkilde geary, 2002), the poor results obtained, e.g., by (bohnet et al, 2010)<papid> C10-1012 </papid>with the original conll 2009 corpora, show that annotations that serve well for other applications, may not do so for generation and thus need at least to be adjusted.1 this has also been acknowledged in the run-up to the surface realization challenge 2011 (belz et al, 2011), where considerable amount of work has been invested into the conversion of the annotations of the conll 2008 corpora (surdeanu et al, 2008), <papid> W08-2121 </papid>i.e., propbank (palmer et al, 2005), <papid> J05-1004 </papid>which served as the reference treebank, into more generation friendly?</citsent>
<aftsection>
<nextsent>annotation.
</nextsent>
<nextsent>however, all of the available annotations are to certain extent still syntactic.
</nextsent>
<nextsent>even propbank and its generation-oriented variants contain significant number of syntactic features (bohnet et al, 2011b).some previous approaches to data-driven generation avoid the problem related to the lack of semantic resources in that they use hybrid models that imply symbolic sub module which derives the syntactic representation that is then used by the stochastic sub module (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998).</nextsent>
<nextsent>(walker et al, 2002), (stent et al, 2004), (<papid> P04-1011 </papid>wong and mooney, 2007), <papid> N07-1022 </papid>and (mairesse et al, 2010) <papid> P10-1157 </papid>start from deeper structures: walker et aland stent et al from deep-syntactic structures (melcuk, 1988), and wong and mooney and mairesse et al from higher order predicate logic structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1735">
<title id=" W12-1506.xml">towards a surface realization oriented corpus annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments shows that making the semantic corpora comply with the suggested principles does not need to have negative impact on the quality of the stochastic generators trained on them.
</prevsent>
<prevsent>with the increasing interest in data-driven surface realization, the question on the adequate annotation of corpora for generation also becomes increasingly important.
</prevsent>
</prevsection>
<citsent citstr=" C10-1012 ">
while in the early days of stochastic generation, annotations produced for other applications were used (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998; bangalore andrambow, 2000; <papid> C00-1007 </papid>oh and rudnicky, 2000; <papid> W00-0306 </papid>langkilde geary, 2002), the poor results obtained, e.g., by (bohnet et al, 2010)<papid> C10-1012 </papid>with the original conll 2009 corpora, show that annotations that serve well for other applications, may not do so for generation and thus need at least to be adjusted.1 this has also been acknowledged in the run-up to the surface realization challenge 2011 (belz et al, 2011), where considerable amount of work has been invested into the conversion of the annotations of the conll 2008 corpora (surdeanu et al, 2008), <papid> W08-2121 </papid>i.e., propbank (palmer et al, 2005), <papid> J05-1004 </papid>which served as the reference treebank, into more generation friendly?</citsent>
<aftsection>
<nextsent>annotation.
</nextsent>
<nextsent>however, all of the available annotations are to certain extent still syntactic.
</nextsent>
<nextsent>even propbank and its generation-oriented variants contain significant number of syntactic features (bohnet et al, 2011b).some previous approaches to data-driven generation avoid the problem related to the lack of semantic resources in that they use hybrid models that imply symbolic sub module which derives the syntactic representation that is then used by the stochastic sub module (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998).</nextsent>
<nextsent>(walker et al, 2002), (stent et al, 2004), (<papid> P04-1011 </papid>wong and mooney, 2007), <papid> N07-1022 </papid>and (mairesse et al, 2010) <papid> P10-1157 </papid>start from deeper structures: walker et aland stent et al from deep-syntactic structures (melcuk, 1988), and wong and mooney and mairesse et al from higher order predicate logic structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1738">
<title id=" W12-1506.xml">towards a surface realization oriented corpus annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments shows that making the semantic corpora comply with the suggested principles does not need to have negative impact on the quality of the stochastic generators trained on them.
</prevsent>
<prevsent>with the increasing interest in data-driven surface realization, the question on the adequate annotation of corpora for generation also becomes increasingly important.
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
while in the early days of stochastic generation, annotations produced for other applications were used (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998; bangalore andrambow, 2000; <papid> C00-1007 </papid>oh and rudnicky, 2000; <papid> W00-0306 </papid>langkilde geary, 2002), the poor results obtained, e.g., by (bohnet et al, 2010)<papid> C10-1012 </papid>with the original conll 2009 corpora, show that annotations that serve well for other applications, may not do so for generation and thus need at least to be adjusted.1 this has also been acknowledged in the run-up to the surface realization challenge 2011 (belz et al, 2011), where considerable amount of work has been invested into the conversion of the annotations of the conll 2008 corpora (surdeanu et al, 2008), <papid> W08-2121 </papid>i.e., propbank (palmer et al, 2005), <papid> J05-1004 </papid>which served as the reference treebank, into more generation friendly?</citsent>
<aftsection>
<nextsent>annotation.
</nextsent>
<nextsent>however, all of the available annotations are to certain extent still syntactic.
</nextsent>
<nextsent>even propbank and its generation-oriented variants contain significant number of syntactic features (bohnet et al, 2011b).some previous approaches to data-driven generation avoid the problem related to the lack of semantic resources in that they use hybrid models that imply symbolic sub module which derives the syntactic representation that is then used by the stochastic sub module (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998).</nextsent>
<nextsent>(walker et al, 2002), (stent et al, 2004), (<papid> P04-1011 </papid>wong and mooney, 2007), <papid> N07-1022 </papid>and (mairesse et al, 2010) <papid> P10-1157 </papid>start from deeper structures: walker et aland stent et al from deep-syntactic structures (melcuk, 1988), and wong and mooney and mairesse et al from higher order predicate logic structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1739">
<title id=" W12-1506.xml">towards a surface realization oriented corpus annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>experiments shows that making the semantic corpora comply with the suggested principles does not need to have negative impact on the quality of the stochastic generators trained on them.
</prevsent>
<prevsent>with the increasing interest in data-driven surface realization, the question on the adequate annotation of corpora for generation also becomes increasingly important.
</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
while in the early days of stochastic generation, annotations produced for other applications were used (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998; bangalore andrambow, 2000; <papid> C00-1007 </papid>oh and rudnicky, 2000; <papid> W00-0306 </papid>langkilde geary, 2002), the poor results obtained, e.g., by (bohnet et al, 2010)<papid> C10-1012 </papid>with the original conll 2009 corpora, show that annotations that serve well for other applications, may not do so for generation and thus need at least to be adjusted.1 this has also been acknowledged in the run-up to the surface realization challenge 2011 (belz et al, 2011), where considerable amount of work has been invested into the conversion of the annotations of the conll 2008 corpora (surdeanu et al, 2008), <papid> W08-2121 </papid>i.e., propbank (palmer et al, 2005), <papid> J05-1004 </papid>which served as the reference treebank, into more generation friendly?</citsent>
<aftsection>
<nextsent>annotation.
</nextsent>
<nextsent>however, all of the available annotations are to certain extent still syntactic.
</nextsent>
<nextsent>even propbank and its generation-oriented variants contain significant number of syntactic features (bohnet et al, 2011b).some previous approaches to data-driven generation avoid the problem related to the lack of semantic resources in that they use hybrid models that imply symbolic sub module which derives the syntactic representation that is then used by the stochastic sub module (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998).</nextsent>
<nextsent>(walker et al, 2002), (stent et al, 2004), (<papid> P04-1011 </papid>wong and mooney, 2007), <papid> N07-1022 </papid>and (mairesse et al, 2010) <papid> P10-1157 </papid>start from deeper structures: walker et aland stent et al from deep-syntactic structures (melcuk, 1988), and wong and mooney and mairesse et al from higher order predicate logic structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1742">
<title id=" W12-1506.xml">towards a surface realization oriented corpus annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, all of the available annotations are to certain extent still syntactic.
</prevsent>
<prevsent>even propbank and its generation-oriented variants contain significant number of syntactic features (bohnet et al, 2011b).some previous approaches to data-driven generation avoid the problem related to the lack of semantic resources in that they use hybrid models that imply symbolic sub module which derives the syntactic representation that is then used by the stochastic sub module (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998).</prevsent>
</prevsection>
<citsent citstr=" P04-1011 ">
(walker et al, 2002), (stent et al, 2004), (<papid> P04-1011 </papid>wong and mooney, 2007), <papid> N07-1022 </papid>and (mairesse et al, 2010) <papid> P10-1157 </papid>start from deeper structures: walker et aland stent et al from deep-syntactic structures (melcuk, 1988), and wong and mooney and mairesse et al from higher order predicate logic structures.</citsent>
<aftsection>
<nextsent>however, to the best of our knowledge, 1trained on the original conll 2009 corpora, (bohnet et al, 2010)<papid> C10-1012 </papid>s svm-based generator reached bleu score of 0.12 for chinese, 0.18 for english, 0.11 for german and 0.14 for span ish.</nextsent>
<nextsent>joining the unconnected parts of the sentence annotations to connected trees (as required by stochastic realizer) improved the performance to bleu score of 0.69 for chinese, 0.66 for english, 0.61 for german and 0.68 for spanish.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1743">
<title id=" W12-1506.xml">towards a surface realization oriented corpus annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, all of the available annotations are to certain extent still syntactic.
</prevsent>
<prevsent>even propbank and its generation-oriented variants contain significant number of syntactic features (bohnet et al, 2011b).some previous approaches to data-driven generation avoid the problem related to the lack of semantic resources in that they use hybrid models that imply symbolic sub module which derives the syntactic representation that is then used by the stochastic sub module (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998).</prevsent>
</prevsection>
<citsent citstr=" N07-1022 ">
(walker et al, 2002), (stent et al, 2004), (<papid> P04-1011 </papid>wong and mooney, 2007), <papid> N07-1022 </papid>and (mairesse et al, 2010) <papid> P10-1157 </papid>start from deeper structures: walker et aland stent et al from deep-syntactic structures (melcuk, 1988), and wong and mooney and mairesse et al from higher order predicate logic structures.</citsent>
<aftsection>
<nextsent>however, to the best of our knowledge, 1trained on the original conll 2009 corpora, (bohnet et al, 2010)<papid> C10-1012 </papid>s svm-based generator reached bleu score of 0.12 for chinese, 0.18 for english, 0.11 for german and 0.14 for span ish.</nextsent>
<nextsent>joining the unconnected parts of the sentence annotations to connected trees (as required by stochastic realizer) improved the performance to bleu score of 0.69 for chinese, 0.66 for english, 0.61 for german and 0.68 for spanish.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1744">
<title id=" W12-1506.xml">towards a surface realization oriented corpus annotation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, all of the available annotations are to certain extent still syntactic.
</prevsent>
<prevsent>even propbank and its generation-oriented variants contain significant number of syntactic features (bohnet et al, 2011b).some previous approaches to data-driven generation avoid the problem related to the lack of semantic resources in that they use hybrid models that imply symbolic sub module which derives the syntactic representation that is then used by the stochastic sub module (knight and hatzivassiloglou, 1995; <papid> P95-1034 </papid>langkilde and knight, 1998).</prevsent>
</prevsection>
<citsent citstr=" P10-1157 ">
(walker et al, 2002), (stent et al, 2004), (<papid> P04-1011 </papid>wong and mooney, 2007), <papid> N07-1022 </papid>and (mairesse et al, 2010) <papid> P10-1157 </papid>start from deeper structures: walker et aland stent et al from deep-syntactic structures (melcuk, 1988), and wong and mooney and mairesse et al from higher order predicate logic structures.</citsent>
<aftsection>
<nextsent>however, to the best of our knowledge, 1trained on the original conll 2009 corpora, (bohnet et al, 2010)<papid> C10-1012 </papid>s svm-based generator reached bleu score of 0.12 for chinese, 0.18 for english, 0.11 for german and 0.14 for span ish.</nextsent>
<nextsent>joining the unconnected parts of the sentence annotations to connected trees (as required by stochastic realizer) improved the performance to bleu score of 0.69 for chinese, 0.66 for english, 0.61 for german and 0.68 for spanish.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1751">
<title id=" W12-1506.xml">towards a surface realization oriented corpus annotation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in this case, we could have node name, but elaboration is much more generic and can actually be automatically introduced without any additional information.
</prevsent>
<prevsent>obviously, the removal of syntactic features froma given standard annotation, with the goal to obtain an increasingly more semantic annotation, canonly be accepted if the quality of (deep) stochastic generation does not unacceptably decrease.
</prevsent>
</prevsection>
<citsent citstr=" C04-1097 ">
to assess this aspect, we converted automatically the propbank annotation of the wsj journal as used in the conll shared task 2009 into an annotation that complies with all of the principles sketched above for deep statistical generation and trained (bohnet et al, 2010)<papid> C10-1012 </papid>s generator on this new annotation.11 for our experiments, we used the usual training,development and test data split of the wsj corpus (langkilde-geary, 2002; ringger et al, 2004; <papid> C04-1097 </papid>bohnet et al, 2010)<papid> C10-1012 </papid>; table 1 provides an overview of the used data.</citsent>
<aftsection>
<nextsent>set section # sentences training 2 - 21 39218 development 24 1334 test 23 2400 table 1: data split of the used data in the wsj corpus the resulting bleu score of our experiment was0.64, which is comparable with the accuracy reported in (bohnet et al, 2010)<papid> C10-1012 </papid>(namely, 0.659), who used an annotation that still contained all functional nodes (such that their generation task was considerably more syntactic and thus more straightforward).</nextsent>
<nextsent>to assess furthermore whether the automatically converted propbank already offers some advantages to other applications than generation, we used it in semantic role labeling (srl) experiment with (bjo?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1757">
<title id=" W12-0111.xml">tree based hybrid machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the approach shows significant improvement over the baseline for mt systems with limited training data and structural improvement for mt systems trained on europarl.
</prevsent>
<prevsent>statistical mt (smt) and rule-based mt (rbmt) have complimentary strengths and combining their output can improve translation quality.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
the underlying models in smt lack linguistic sophistication when compared to rbmt systems and there is trend towards incorporating more linguistic knowledge by creating hybrid systems that can exploit the linguistic knowledge contained in hand-crafted rules and the knowledge extracted from large amounts of text.hierarchical phrases (chiang, 2005) <papid> P05-1033 </papid>are encoded in tree structure just as linguistic trees.</citsent>
<aftsection>
<nextsent>most rbmt systems also encode the analysis ofa sentence in tree.
</nextsent>
<nextsent>the rules generating hierarchical trees are inferred from unlabeled corpora and rbmt systems use hand-crafted rules basedin linguistic knowledge.
</nextsent>
<nextsent>while the trees are generated differently, alignments between nodes and subtrees in the generation phase can be computed.
</nextsent>
<nextsent>based on the computed alignments, substitution can be performed between the trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1758">
<title id=" W12-0111.xml">tree based hybrid machine translation </title>
<section> hybrid machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>rbmt systems arealso very costly to build, and maintenance and development can be very complex e.g. due to the interdependency of rules.the post-editing approach attempts to incorporate the linguistic knowledge encoded in target side dependency trees into hierarchical trees produced by an smt system.
</prevsent>
<prevsent>2.1 related work.
</prevsent>
</prevsection>
<citsent citstr=" W10-1708 ">
system combinations by coupling mt systems serially or in parallel have been attempted beforee.g. via hypothesis selection (hildebrand and vogel, 2008), by combining translation hypotheses locally using pos tags (federmann et al, 2010) <papid> W10-1708 </papid>or by statistical post-editing (spe) (simard et al,2007).<papid> W07-0728 </papid></citsent>
<aftsection>
<nextsent>in hypothesis selection approaches, number of mt systems produce translations for an best list and use re-ranking module to rescorethe translations.
</nextsent>
<nextsent>using this approach, the best improvements are achieved with large number of systems running in parallel and this is not feasible in practical application, mostly due to the computational resources required by the component systems.
</nextsent>
<nextsent>the translations will also not be better than the one produced by the best component system.
</nextsent>
<nextsent>tighter integration of rule-based and statistical approaches have also been proposed: adding probabilities to parse trees, pre-translation word reordering, enriching the phrase table with output phrases from rule-based system (eisele et al, jeg [jeg] 1s nom @subj #1- 2 arbejder [arbejde]  mv  pr akt @fs-sta #2- 0 hjemme [hjemme]  aloc  adv loc @ advl #3- 2 . [.]
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1759">
<title id=" W12-0111.xml">tree based hybrid machine translation </title>
<section> hybrid machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>rbmt systems arealso very costly to build, and maintenance and development can be very complex e.g. due to the interdependency of rules.the post-editing approach attempts to incorporate the linguistic knowledge encoded in target side dependency trees into hierarchical trees produced by an smt system.
</prevsent>
<prevsent>2.1 related work.
</prevsent>
</prevsection>
<citsent citstr=" W07-0728 ">
system combinations by coupling mt systems serially or in parallel have been attempted beforee.g. via hypothesis selection (hildebrand and vogel, 2008), by combining translation hypotheses locally using pos tags (federmann et al, 2010) <papid> W10-1708 </papid>or by statistical post-editing (spe) (simard et al,2007).<papid> W07-0728 </papid></citsent>
<aftsection>
<nextsent>in hypothesis selection approaches, number of mt systems produce translations for an best list and use re-ranking module to rescorethe translations.
</nextsent>
<nextsent>using this approach, the best improvements are achieved with large number of systems running in parallel and this is not feasible in practical application, mostly due to the computational resources required by the component systems.
</nextsent>
<nextsent>the translations will also not be better than the one produced by the best component system.
</nextsent>
<nextsent>tighter integration of rule-based and statistical approaches have also been proposed: adding probabilities to parse trees, pre-translation word reordering, enriching the phrase table with output phrases from rule-based system (eisele et al, jeg [jeg] 1s nom @subj #1- 2 arbejder [arbejde]  mv  pr akt @fs-sta #2- 0 hjemme [hjemme]  aloc  adv loc @ advl #3- 2 . [.]
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1760">
<title id=" W12-0111.xml">tree based hybrid machine translation </title>
<section> hybrid machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>the automatic post-editing approach proposed here does not exactly fit the classification of parallel coupling approaches in thurmair (2009).
</prevsent>
<prevsent>other coupling architectures with post-editingwork on words or phrases and generate confusion networks or add more information to identify substitution candidates, while the units focused on here are graphs and no additional information is added to the mt output.
</prevsent>
</prevsection>
<citsent citstr=" N07-1029 ">
this approach does select skeleton upon which transformations are conducted as in rosti et al (2007) <papid> N07-1029 </papid>andre quires the rbmt system to generate target side language analysis which must be available to the post-editing systems, but does not require new syntactic analysis of noisy mt output.</citsent>
<aftsection>
<nextsent>the architecture of the hybrid system used in this paper is parallel coupling with post-editing.
</nextsent>
<nextsent>a diagram of the implemented systems can be seen in figure 1.the dark grey boxes represent pre-existing modules and open source software and the light grey boxes represent the additional modules developed to implement the post-editing approach.
</nextsent>
<nextsent>2.2 rbmt component.
</nextsent>
<nextsent>the danish to english translation engine in gram trans (bick, 2007) is called through an api.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1761">
<title id=" W12-0111.xml">tree based hybrid machine translation </title>
<section> hybrid machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>this presents problem if the dependency markings are the basis for creating dependency tree because it is not straight-forward to reattach subgraph correctly, when the grammatical tags can not be relied upon.
</prevsent>
<prevsent>2.3 smt component.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
a cky+ algorithm for chart decoding is implemented in moses (koehn et al, 2007) <papid> P07-2045 </papid>for tree based models and is used as the smt component system in this paper.hierarchical phrases are phrases that can contain subphrases, i.e. hierarchical phrase contains non-terminal symbols.</citsent>
<aftsection>
<nextsent>an example rule from danish to english: x1 vrigt x2 ??
</nextsent>
<nextsent>moreover, x1 x2xn is nonterminal and the sub script identifies how the nonterminals are aligned.
</nextsent>
<nextsent>the hierarchical phrases are learned from bitext with unannotated data and are formally productions from synchronous context-free grammar (scfg) and can be viewed as move towards syntax-based smt (chiang, 2005).<papid> P05-1033 </papid></nextsent>
<nextsent>since hierarchical phrases are not linguistic, chiang makes distinction between linguistically syntax-based mt and formally syntax-based mt where hierarchical models fall in the latter category because the structures they are defined over are not linguistically informed, i.e. unannotated bitexts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1763">
<title id=" W12-0111.xml">tree based hybrid machine translation </title>
<section> hybrid machine translation.  </section>
<citcontext>
<prevsection>
<prevsent>x1, x1only these rewrite rules contain the nonterminal s. these rules are added to give the model figure 3: the matching process.the option of combining partial hypotheses serially and they make the hierarchical model as robust as the traditional phrase-based approaches.the moses chart decoder was modified to output trace information from which the n-best hierarchical trees can be reconstructed.
</prevsent>
<prevsent>the trace information contains the derivations which produce the translation hypotheses.
</prevsent>
</prevsection>
<citsent citstr=" W06-3114 ">
the sentence aligned danish-english part of europarl (koehn, 2005) was used for training, and to tune parameters with mert, the test set from the naacl wmt 2006 was used (koehn and monz, 2006).<papid> W06-3114 </papid></citsent>
<aftsection>
<nextsent>giza++ aligns hierarchical phrases which were extracted by moses to train translation model and language model was trained with srilm (stolcke, 2002).
</nextsent>
<nextsent>moses was trained using the experimental management system (ems) (koehn, 2010) and the configuration followed the standard guidelines in the syntax tutorial.1 to train srilm, the english side of eu roparl was used.
</nextsent>
<nextsent>the post-editing approach relies on structures output by the component systems.
</nextsent>
<nextsent>it is necessary to find similar structures to perform subtree substitution.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1764">
<title id=" W12-0111.xml">tree based hybrid machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the experiments have been conducted between danish and english.
</prevsent>
<prevsent>the language model trained with ems is used to re-rank translation alternatives.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
bleu (papineni et al, 2002), <papid> P02-1040 </papid>ter (snover et al, 2006) and meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>scores will be reported.</citsent>
<aftsection>
<nextsent>4.1 experimental setup.
</nextsent>
<nextsent>two sets of five experiments have been conducted.
</nextsent>
<nextsent>the first set of experiments use the initial 100,000 lines from europarl for training mose sand the second set of experiments use the full eu roparl corpus of ca.
</nextsent>
<nextsent>1.8 mio sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1765">
<title id=" W12-0111.xml">tree based hybrid machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the experiments have been conducted between danish and english.
</prevsent>
<prevsent>the language model trained with ems is used to re-rank translation alternatives.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
bleu (papineni et al, 2002), <papid> P02-1040 </papid>ter (snover et al, 2006) and meteor (banerjee and lavie, 2005) <papid> W05-0909 </papid>scores will be reported.</citsent>
<aftsection>
<nextsent>4.1 experimental setup.
</nextsent>
<nextsent>two sets of five experiments have been conducted.
</nextsent>
<nextsent>the first set of experiments use the initial 100,000 lines from europarl for training mose sand the second set of experiments use the full eu roparl corpus of ca.
</nextsent>
<nextsent>1.8 mio sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1766">
<title id=" W12-1511.xml">hidden semantics what can we learn from the names in an ontology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>is the owl terminology for relation between two entities 67 term.
</prevsent>
<prevsent>for example, in the domain of education, class intended to represent the real-world class of junior schools ought to have (in english) an identifier such as junior school or label such as junior school?.
</prevsent>
</prevsection>
<citsent citstr=" P10-2024 ">
ontology developers who follow this best practice (and, according to (power, 2010), <papid> P10-2024 </papid>the vast majority do) produce ontologies in which the entities are easily recognisable and understood by human readers who can parse these identifiers, to infer, for example, that junior school?</citsent>
<aftsection>
<nextsent>is subclass of the class school?.
</nextsent>
<nextsent>as it stands, however, machine will not make this inference.
</nextsent>
<nextsent>in order for the machine to comprehend the semantics of this example, there must additionally be an axiom equivalent to junior school is school?.the motivation for this work is the desire to identify which kinds of identifier or label are obvious in this way.
</nextsent>
<nextsent>that is to say, if we treat an owl identifier as if it were in fact multi-word natural language expression, can we infer at least some of its semantics from its properties as noun phrase, for example?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1767">
<title id=" W12-1511.xml">hidden semantics what can we learn from the names in an ontology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper addresses the first of these two purposes.
</prevsent>
<prevsent>note that the aim ofthis work is not particular to consider how best to realise entity names in verbal isation, but rather, how to use the names of entities to guide the choice and construction of sentences.
</prevsent>
</prevsection>
<citsent citstr=" W10-4222 ">
this work was undertaken in the context of the swat (semantic web authoring tool) project, which is investigating the application of nlg/nlp to ontology authoring and editing (williams et al., 2011),(williams and power, 2010),(<papid> W10-4222 </papid>power and third, 2010),(<papid> C10-2116 </papid>stevens et al, 2011), (power, 2010),(<papid> P10-2024 </papid>the swat project, 2012).</citsent>
<aftsection>
<nextsent>other researchers have attempted to take advanta geof the internal structure of ontology identifiers to infer semantics, but these have exclusively been concerned with the question of checking or improving an ontologys coverage of its domain.
</nextsent>
<nextsent>examples include (wroe et al, 2003; fernandez-breis et al, 2010; egana aranguren et al, 2008).
</nextsent>
<nextsent>to the best of our knowledge, our current research is the first totake advantage of identifier structure to infer semantics in order to improve verbal isation and produce more human-focused texts.
</nextsent>
<nextsent>informal feedback from existing work indicates that many readers are dissatisfied with the kinds of text produced by ontology verbalisers, feeling them to be somewhat fussy and unnatural.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1770">
<title id=" W12-1511.xml">hidden semantics what can we learn from the names in an ontology </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper addresses the first of these two purposes.
</prevsent>
<prevsent>note that the aim ofthis work is not particular to consider how best to realise entity names in verbal isation, but rather, how to use the names of entities to guide the choice and construction of sentences.
</prevsent>
</prevsection>
<citsent citstr=" C10-2116 ">
this work was undertaken in the context of the swat (semantic web authoring tool) project, which is investigating the application of nlg/nlp to ontology authoring and editing (williams et al., 2011),(williams and power, 2010),(<papid> W10-4222 </papid>power and third, 2010),(<papid> C10-2116 </papid>stevens et al, 2011), (power, 2010),(<papid> P10-2024 </papid>the swat project, 2012).</citsent>
<aftsection>
<nextsent>other researchers have attempted to take advanta geof the internal structure of ontology identifiers to infer semantics, but these have exclusively been concerned with the question of checking or improving an ontologys coverage of its domain.
</nextsent>
<nextsent>examples include (wroe et al, 2003; fernandez-breis et al, 2010; egana aranguren et al, 2008).
</nextsent>
<nextsent>to the best of our knowledge, our current research is the first totake advantage of identifier structure to infer semantics in order to improve verbal isation and produce more human-focused texts.
</nextsent>
<nextsent>informal feedback from existing work indicates that many readers are dissatisfied with the kinds of text produced by ontology verbalisers, feeling them to be somewhat fussy and unnatural.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1774">
<title id=" W11-2152.xml">twostep translation with grammatical postprocessing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper is joint report on two english-to-czech submissions to the wmt11 shared translation task.
</prevsent>
<prevsent>the main contribution is however the proposal and evaluation of rule-based post-processing systemdepfix aimed at correcting errors in czech grammar applicable to any mt system.
</prevsent>
</prevsection>
<citsent citstr=" N07-1064 ">
this is somewhat the converse of other approaches (e.g. simard et al (2007)) <papid> N07-1064 </papid>where statistical system was applied for the post-processing of rule-based one.</citsent>
<aftsection>
<nextsent>this section briefly describes our underlying phrase based systems.
</nextsent>
<nextsent>one of them (cu-bojar) was submitted directly to the wmt11 manual evaluation, the other one (cu-twostep) was first corrected by the proposed method (section 3 below) and then submitted under the name cu-marecek.
</nextsent>
<nextsent>this research has been supported by the european union seventh framework programme (fp7) under grant agreement n?
</nextsent>
<nextsent>247762 (faust), n?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1775">
<title id=" W11-2152.xml">twostep translation with grammatical postprocessing </title>
<section> grammatical post-processing.  </section>
<citcontext>
<prevsection>
<prevsent>the depfix system was implemented in tectomtframework (popel and zabokrtsky?, 2010).
</prevsent>
<prevsent>mt outputs were tagged by morce tagger (spoustova?
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
et al,2007) and then parsed with mst parser (mcdonald et al, 2005) <papid> H05-1066 </papid>that was trained on the prague dependency treebank (hajic?</citsent>
<aftsection>
<nextsent>and others, 2006), i.e. on correct czech sentences.
</nextsent>
<nextsent>we used an improved implementation with some additional features especially tuned for czech (novak and zabokrtsky?, 2007).
</nextsent>
<nextsent>the parser accuracy is much lower on thenoisy?
</nextsent>
<nextsent>mt output sentences, but lot of dependencies in which we are to correct grammatical agreement are determined correctly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1776">
<title id=" W11-2152.xml">twostep translation with grammatical postprocessing </title>
<section> grammatical post-processing.  </section>
<citcontext>
<prevsection>
<prevsent>if they do not, we simply change the number and gender of the predicate in agreement with the subject.4 an example of such changed predicate is in figure 1.apart from the dependency tree of the target sentence, we can also use the dependency tree of the source sentence.
</prevsent>
<prevsent>source sentences are grammatically correct and the accuracy of the tagger and the parser is accordingly higher there.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
words in the source and target sentences are aligned using giza++5 (och and ney, 2003) <papid> J03-1002 </papid>but verbose outputs of the original mt systems would be possibly better option.</citsent>
<aftsection>
<nextsent>the rules for fixing grammatical agreement between words can thus consider also the dependency relations and morphological caregories of their english counterparts in the input sentence.
</nextsent>
<nextsent>4in this case, we suppose that the number of the subject has much higher chance to be correct.
</nextsent>
<nextsent>5giza++ was run on lemmatized texts in both directions and intersection symmetrization was used.
</nextsent>
<nextsent>some people came later atr sb pred advplpl .auxk pilipredpl nkte??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1777">
<title id=" W11-2016.xml">an empirical evaluation of a statistical dialog system in public use </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we identify root causes for these differences in performance, including intrinsic properties of n-best lists, parameter settings, and the quality of statistical models.
</prevsent>
<prevsent>we synthesize our findings into set of guidelines which aim to assist researchers and practitioners employing statistical techniques in future dialog systems.
</prevsent>
</prevsection>
<citsent citstr=" P08-2019 ">
over the past decade, researchers have worked to apply statistical techniques to spoken dialog systems,and in controlled laboratory studies, statistical dialog systems have been shown to improve robustness to errors compared to conventional approaches (henderson and lemon, 2008; <papid> P08-2019 </papid>young et al, 2010; thomson and young, 2010).</citsent>
<aftsection>
<nextsent>however, statistical techniques have not yet been evaluated in publicly deployed system, and real users behave very differently to usability subjects (raux et al, 2005; ai et al., 2008).
</nextsent>
<nextsent>so there is an important open question whether statistical dialog systems improve performance with real users.this paper provides first evaluation of publically deployed statistical dialog system, at&t; letsgo (williams et al, 2010).
</nextsent>
<nextsent>at&t; lets go provides bus times for pittsburgh, and received approximately 750 calls from real bus riders during the 2010 spoken dialog challenge (black et al, 2010)..
</nextsent>
<nextsent>at&t; lets go is based on publicly available toolkit (williams, 2010a) and achieved the highest rates of successful task completion on real callers in the challenge, so it provides relevant exercise from which to draw inferences.at&t; lets go collected four types of information, or slots: bus route names, bus-stop names,dates, and times.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1778">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>both data-driven approaches (e.g., statistical mt (smt)) and knowledge-based (e.g., rule-based mt (rbmt)) have achieved comparable results shown in the evaluation campaigns (callison burch et al, 2011).
</prevsent>
<prevsent>however, according to the human evaluation, the final outputs of the mt systems are still far from satisfactory.
</prevsent>
</prevsection>
<citsent citstr=" W09-0405 ">
fortunately, recent error analysis shows that thetwo trends of the mt approaches tend to be complementary to each other, in terms of the types of the errors they made (thurmair, 2005; chen etal., 2009).<papid> W09-0405 </papid></citsent>
<aftsection>
<nextsent>roughly speaking, rbmt systems often have missing lexicon and thus lack of robustness, while handling linguistic phenomena requiring syntactic information better.
</nextsent>
<nextsent>smt systems, onthe contrary, are in general more robust, but sometimes output ungrammatical sentences.
</nextsent>
<nextsent>in fact, instead of competing with each other,there is also line of research trying to combine the advantages of the two sides using hybrid framework.
</nextsent>
<nextsent>although many system scan be put under the umbrella of hybrid?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1779">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some widely used ones are: 1) using an smt to post-edit the outputs of an rbmt; 2) selecting the best translations from several hypotheses coming from different smt/rbmt systems; and 3) selecting the best segments (phrases or words) from different hypotheses.
</prevsent>
<prevsent>for the language pair bulgarian-english, there has not been much study on it, mainly due to thelack of resources, including corpora, pre proces sors, etc. there was system published by koehn et al (2009), which was trained and tested on the european union law data, but not on other domains like news.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
they reported very high bleu score (papineni et al, 2002) <papid> P02-1040 </papid>on the bulgarian english translation direction (61.3), which inspired us to further investigate this direction.in this paper, we focus on the bulgarian-toenglish translation and mainly explore the approach of annotating the smt baseline with linguistic features derived from the preprocessing and hand-crafted grammars.</citsent>
<aftsection>
<nextsent>there are three motivations behind our approach: 1) the smt baseline trained on decent amount of parallel corpora outputs surprisingly good results, in terms of both statistical evaluation metrics and preliminary manual evaluation; 2) the augmented model gives 119 us more space for experimenting with different linguistic features without losing the basic?
</nextsent>
<nextsent>robustness; 3) the mt system can profit from continued advances in the development of the deep grammars thereby opening up further integration possibilities.the rest of the paper will be organized as fol lows: section 2 presents our work on cleaning the corpora and section 3 briefly describes the preprocessing of the data.
</nextsent>
<nextsent>section 4 introduces our factor-based smt model which allows us to incorporate various linguistic features into ansmt baseline, among which those features coming from the mrs are described in section 5 in detail.
</nextsent>
<nextsent>we show our experiments in section 6 as well as both automatic and manual evaluation ofthe results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1780">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> linguistic preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>the rules reduce the ambiguity for some of the sure cases.
</prevsent>
<prevsent>the result of this step is tagged text with some ambiguities unresolved.
</prevsent>
</prevsection>
<citsent citstr=" E12-1050 ">
the third step is application of the gtagger (georgievet al, 2012).<papid> E12-1050 </papid></citsent>
<aftsection>
<nextsent>it is trained on an ambiguous data and select the most appropriate tags from the suggested ones.
</nextsent>
<nextsent>the accuracy of the whole pipeline is 97.83%.
</nextsent>
<nextsent>in this pipeline svm pos tagger plays the role of guesser for the gtagger.?
</nextsent>
<nextsent>lemmatization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1781">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> factor-based smt model.  </section>
<citcontext>
<prevsection>
<prevsent>it is integrated in language pipe with the pos tagger and the lemmatizer.
</prevsent>
<prevsent>after the application of the language pipeline, the result is represented in table form following the conll shared task format3.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
our approach is built on top of the factor-based smt model proposed by koehn and hoang(2007), <papid> D07-1091 </papid>as an extension of the traditional phrase based smt framework.</citsent>
<aftsection>
<nextsent>instead of using only the word form of the text, it allows the system to take vector of factors to represent each token, bothfor the source and target languages.
</nextsent>
<nextsent>the vector of factors can be used for different levels of linguistic annotations, like lemma, part-of-speech (pos), or other linguistic features.
</nextsent>
<nextsent>furthermore, this extension actually allows us to incorporate various kinds of features if they can be (somehow) represented as annotations to the tokens.
</nextsent>
<nextsent>the process is quite similar to super tagging (bangalore and joshi, 1999), <papid> J99-2004 </papid>which assigns rich descriptions (supertags) that impose complex 2http://www.bultreebank.org/dpbtb/ 3http://ufal.mff.cuni.cz/conll2009-st/ task-description.html constraints in local context?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1782">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> factor-based smt model.  </section>
<citcontext>
<prevsection>
<prevsent>the vector of factors can be used for different levels of linguistic annotations, like lemma, part-of-speech (pos), or other linguistic features.
</prevsent>
<prevsent>furthermore, this extension actually allows us to incorporate various kinds of features if they can be (somehow) represented as annotations to the tokens.
</prevsent>
</prevsection>
<citsent citstr=" J99-2004 ">
the process is quite similar to super tagging (bangalore and joshi, 1999), <papid> J99-2004 </papid>which assigns rich descriptions (supertags) that impose complex 2http://www.bultreebank.org/dpbtb/ 3http://ufal.mff.cuni.cz/conll2009-st/ task-description.html constraints in local context?.</citsent>
<aftsection>
<nextsent>in our case, all the linguistic features (factors) associated with each token form super tag to that token.
</nextsent>
<nextsent>singh and bandyopadhyay (2010) <papid> W10-3811 </papid>had similar idea of incorporating linguistic features, while they worked on manipuri-english bidirectional trans lation.</nextsent>
<nextsent>our approach is slightly different from (birch et al, 2007) <papid> W07-0702 </papid>and (hassan et al, 2007), <papid> P07-1037 </papid>who mainly used the supertags on the target language side, english.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1783">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> factor-based smt model.  </section>
<citcontext>
<prevsection>
<prevsent>the process is quite similar to super tagging (bangalore and joshi, 1999), <papid> J99-2004 </papid>which assigns rich descriptions (supertags) that impose complex 2http://www.bultreebank.org/dpbtb/ 3http://ufal.mff.cuni.cz/conll2009-st/ task-description.html constraints in local context?.</prevsent>
<prevsent>in our case, all the linguistic features (factors) associated with each token form super tag to that token.</prevsent>
</prevsection>
<citsent citstr=" W10-3811 ">
singh and bandyopadhyay (2010) <papid> W10-3811 </papid>had similar idea of incorporating linguistic features, while they worked on manipuri-english bidirectional trans lation.</citsent>
<aftsection>
<nextsent>our approach is slightly different from (birch et al, 2007) <papid> W07-0702 </papid>and (hassan et al, 2007), <papid> P07-1037 </papid>who mainly used the supertags on the target language side, english.</nextsent>
<nextsent>we primarily experiment with the source language side, bulgarian.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1784">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> factor-based smt model.  </section>
<citcontext>
<prevsection>
<prevsent>in our case, all the linguistic features (factors) associated with each token form super tag to that token.
</prevsent>
<prevsent>singh and bandyopadhyay (2010) <papid> W10-3811 </papid>had similar idea of incorporating linguistic features, while they worked on manipuri-english bidirectional trans lation.</prevsent>
</prevsection>
<citsent citstr=" W07-0702 ">
our approach is slightly different from (birch et al, 2007) <papid> W07-0702 </papid>and (hassan et al, 2007), <papid> P07-1037 </papid>who mainly used the supertags on the target language side, english.</citsent>
<aftsection>
<nextsent>we primarily experiment with the source language side, bulgarian.
</nextsent>
<nextsent>this potentially huge feature space provides us with various possibilities of using our linguistic resources developed in and out of our project.
</nextsent>
<nextsent>in particular, we consider the following factors on the source language side (bulgarian):?
</nextsent>
<nextsent>wf - word form is just the original text to ken.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1785">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> factor-based smt model.  </section>
<citcontext>
<prevsection>
<prevsent>in our case, all the linguistic features (factors) associated with each token form super tag to that token.
</prevsent>
<prevsent>singh and bandyopadhyay (2010) <papid> W10-3811 </papid>had similar idea of incorporating linguistic features, while they worked on manipuri-english bidirectional trans lation.</prevsent>
</prevsection>
<citsent citstr=" P07-1037 ">
our approach is slightly different from (birch et al, 2007) <papid> W07-0702 </papid>and (hassan et al, 2007), <papid> P07-1037 </papid>who mainly used the supertags on the target language side, english.</citsent>
<aftsection>
<nextsent>we primarily experiment with the source language side, bulgarian.
</nextsent>
<nextsent>this potentially huge feature space provides us with various possibilities of using our linguistic resources developed in and out of our project.
</nextsent>
<nextsent>in particular, we consider the following factors on the source language side (bulgarian):?
</nextsent>
<nextsent>wf - word form is just the original text to ken.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1786">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the model of encoding mrs information in the corpus as additional features does not depend on the actual semantic analysis ? mrs or rmrs, because both of them provide enough semantic information.
</prevsent>
<prevsent>6.1 experiments with the bulgarian raw.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
corpus to run the experiments, we use the phrase-based translation model provided by the open-source statistical machine translation system, moses4 (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>for training the translation model, the parallel corpora (mentioned in section 2) were preprocessed with the tokenizer and lowercase converter provided by moses.
</nextsent>
<nextsent>then the procedure is quite standard:?
</nextsent>
<nextsent>we run giza++ (och and ney, 2003) <papid> J03-1002 </papid>for bidirectional word alignment, and then obtain the lexical translation table and phrase table.?</nextsent>
<nextsent>a tri-gram language model is estimated using the srilm toolkit (stolcke, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1787">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for training the translation model, the parallel corpora (mentioned in section 2) were preprocessed with the tokenizer and lowercase converter provided by moses.
</prevsent>
<prevsent>then the procedure is quite standard:?
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we run giza++ (och and ney, 2003) <papid> J03-1002 </papid>for bidirectional word alignment, and then obtain the lexical translation table and phrase table.?</citsent>
<aftsection>
<nextsent>a tri-gram language model is estimated using the srilm toolkit (stolcke, 2002).
</nextsent>
<nextsent>minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>is applied to tune the weights for theset of feature weights that maximizes the official f-score evaluation metric on the development set.</nextsent>
<nextsent>the rest of the parameters we use the default setting provided by moses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1788">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we run giza++ (och and ney, 2003) <papid> J03-1002 </papid>for bidirectional word alignment, and then obtain the lexical translation table and phrase table.?</prevsent>
<prevsent>a tri-gram language model is estimated using the srilm toolkit (stolcke, 2002).</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>is applied to tune the weights for theset of feature weights that maximizes the official f-score evaluation metric on the development set.</citsent>
<aftsection>
<nextsent>the rest of the parameters we use the default setting provided by moses.
</nextsent>
<nextsent>4http://www.statmt.org/moses/ we split the corpora into the training set, the development set and the test set.
</nextsent>
<nextsent>for setimes, the split is 100,000/500/1,000 and for emea, it is 700,000/500/1,000.
</nextsent>
<nextsent>for reference, we also run tests on the jrc-acquis corpus5.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1790">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>19 google 0 2 20 52 76 652.
</prevsent>
<prevsent>20 reference 0 0 5 51 94 689.
</prevsent>
</prevsection>
<citsent citstr=" W02-1210 ">
table 4: manual evaluation of the grammaticality exist quite extensive implemented formal hpsg grammars for english (copestake and flickinger, 2000), german (muller and kasper, 2000), and japanese (siegel, 2000; siegel and bender, 2002).<papid> W02-1210 </papid>hpsg is the underlying theory of the international initiative lingo grammar matrix (benderet al, 2002).<papid> W02-1502 </papid></citsent>
<aftsection>
<nextsent>at the moment, precise and linguistically motivated grammars, customized on the base of the grammar matrix, have been orare being developed for norwegian, french, korean, italian, modern greek, spanish, portuguese, chinese, etc. there also exists first version of the bulgarian resource grammar - burger.
</nextsent>
<nextsent>in the research reported here, we use the linguistic modeled knowledge from the existing english and bulgarian grammars.
</nextsent>
<nextsent>since the bulgarian grammar has limited coverage on news data, dependency parsing has been performed instead.
</nextsent>
<nextsent>then,mapping rules have been defined for the construction of rmrses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1791">
<title id=" W12-0116.xml">linguistically augmented bulgariantoenglish statistical machine translation model </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>19 google 0 2 20 52 76 652.
</prevsent>
<prevsent>20 reference 0 0 5 51 94 689.
</prevsent>
</prevsection>
<citsent citstr=" W02-1502 ">
table 4: manual evaluation of the grammaticality exist quite extensive implemented formal hpsg grammars for english (copestake and flickinger, 2000), german (muller and kasper, 2000), and japanese (siegel, 2000; siegel and bender, 2002).<papid> W02-1210 </papid>hpsg is the underlying theory of the international initiative lingo grammar matrix (benderet al, 2002).<papid> W02-1502 </papid></citsent>
<aftsection>
<nextsent>at the moment, precise and linguistically motivated grammars, customized on the base of the grammar matrix, have been orare being developed for norwegian, french, korean, italian, modern greek, spanish, portuguese, chinese, etc. there also exists first version of the bulgarian resource grammar - burger.
</nextsent>
<nextsent>in the research reported here, we use the linguistic modeled knowledge from the existing english and bulgarian grammars.
</nextsent>
<nextsent>since the bulgarian grammar has limited coverage on news data, dependency parsing has been performed instead.
</nextsent>
<nextsent>then,mapping rules have been defined for the construction of rmrses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1792">
<title id=" W12-1706.xml">sequential vs hierarchical syntactic models of human incremental sentence processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>following either?
</prevsent>
<prevsent>(staub and clifton, 2006); expectations of heavy noun phrase shifts (staub et al, 2006); ellipsis processing (lau et al, 2006); and syntactic priming (sturt et al, 2010).experimental evidence for the influence of syntax on human behavior is not limited to experiments carefully designed to isolate particular processing phenomenon.
</prevsent>
</prevsection>
<citsent citstr=" D09-1034 ">
several broad-coverage experimental studies have shown that surprisal under hierarchical syntactic models predicts human processing difficulty on large corpora of naturally occurring text, even after word-level factors have been taken into 61 account (boston et al, 2008; demberg and keller, 2008; roark et al, 2009).<papid> D09-1034 </papid></citsent>
<aftsection>
<nextsent>despite this evidence, in recent work frank and bod (2011) challenge the notion that hierarchical syntactic structure is strictly necessary to predict reading times.
</nextsent>
<nextsent>they compare per-word surprisalpredictions from un lexicalized hierarchical and sequential models of syntactic structure along twoaxes: linguistic accuracy (how well the model predicts the test corpus) and psychological accuracy (how well the model predicts observed reading timeson the test corpus).
</nextsent>
<nextsent>they find that, while hierarchical phrase-structure grammars (psgs) achieve better linguistic accuracy, sequential echo state networks (esns) achieve better psychological accuracy on the english dundee corpus (kennedy andpynte, 2005).
</nextsent>
<nextsent>frank and bod (2011) do not include lexicalized syntactic models in the comparison on the grounds that, once word-level factor shave been included as control predictors in the reading times model, lexicalized syntactic models do not predict reading times better than un lexicalized syntactic models (demberg and keller, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1793">
<title id=" W12-1706.xml">sequential vs hierarchical syntactic models of human incremental sentence processing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, we repeat their comparisons using additional, more robustly estimated lexical n-gram probabilities as control predictors in the baseline model.1 we show that when these additional lexical n-gram probabilities are usedas control predictors, any differences in psychological accuracy between the hierarchical and sequential models used in frank and bod (2011) vanish.second, while they restrict their comparisons to un 1by robustly estimated, we mean that these probabilities are estimated from larger corpora and use better smoothing method (kneser-ney) than the lexical n-grams of frank and bod (2011).
</prevsent>
<prevsent>lexicalized models over part-of-speech (pos) tags,we investigate the lexicalized versions of each hierarchical model, and show that lexicalization significantly improves psychological accuracy.
</prevsent>
</prevsection>
<citsent citstr=" J01-2004 ">
third,while they explore only subset of the psgs implemented under the incremental parser of roark(2001), <papid> J01-2004 </papid>we explore state-of-the-art lexicalized hierarchical model that conditions on richer contexts, and show that this model performs still better.</citsent>
<aftsection>
<nextsent>our findings demonstrate that frank and bod (2011)s strong claim that sequential models predict reading times better than hierarchical models is premature,and also that lexicalization improves the psychological accuracy of hierarchical models.
</nextsent>
<nextsent>several broad-coverage experimental studies demonstrate that surprisal under hierarchical syntactic model predicts human processing difficulty on corpus of naturally occurring text, even after word-level factors have been taken into account.
</nextsent>
<nextsent>under surprisal theory (hale, 2001; <papid> N01-1021 </papid>levy, 2008), processing difficulty at word wi is proportional to reading time at wi, which in turn is proportional tothe surprisal of wi in the context in which it is ob served: surprisal(wi) = log(pr(wi|context)).typically, context ? w1...wi1.</nextsent>
<nextsent>computing surprisal(wi) thus reduces to computing log(pr(wi|w1...wi?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1794">
<title id=" W12-1706.xml">sequential vs hierarchical syntactic models of human incremental sentence processing </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our findings demonstrate that frank and bod (2011)s strong claim that sequential models predict reading times better than hierarchical models is premature,and also that lexicalization improves the psychological accuracy of hierarchical models.
</prevsent>
<prevsent>several broad-coverage experimental studies demonstrate that surprisal under hierarchical syntactic model predicts human processing difficulty on corpus of naturally occurring text, even after word-level factors have been taken into account.
</prevsent>
</prevsection>
<citsent citstr=" N01-1021 ">
under surprisal theory (hale, 2001; <papid> N01-1021 </papid>levy, 2008), processing difficulty at word wi is proportional to reading time at wi, which in turn is proportional tothe surprisal of wi in the context in which it is ob served: surprisal(wi) = log(pr(wi|context)).typically, context ? w1...wi1.</citsent>
<aftsection>
<nextsent>computing surprisal(wi) thus reduces to computing log(pr(wi|w1...wi?
</nextsent>
<nextsent>1)).
</nextsent>
<nextsent>henceforth, we refer to this original formulation of surprisal as total surprisal.
</nextsent>
<nextsent>boston et al (2008) show that surprisal estimates from lexicalized dependency parser (nivre, 2006)and an un lexicalized pcfg are significant predictors of reading times on the german potsdam corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1813">
<title id=" W12-1706.xml">sequential vs hierarchical syntactic models of human incremental sentence processing </title>
<section> models.  </section>
<citcontext>
<prevsection>
<prevsent>psgs consists of rules expanding parent node into children nodes in the syntactic tree, with associated probabilities.
</prevsent>
<prevsent>frank and bod (2011) use psgs that generate pos tag sequences, not words.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
under such grammars, the prefix probability of tag sequence is the sum of the probabilities of all trees : yield(t ) = t1...ti, where the probability of each tree is the product of the probabilities of the rules used in the derivation of . vanilla pcfgs, special case of psgs in which the probability of rule depends only on the identity of the parent node, achieve sub-optimal parsing accuracy relative to grammars in which the probability of each rule depends on richer context (charniak, 1996; johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>to this end, frank and bod (2011) explore several variants of psgs conditioned on successively richer contexts, including ancestor models (which condition rule expansions on ancestor nodes from 1-4 levels up in the tree) and ancestor+sibling models (which condition rule expansions on the ancestors left sibling as well).
</nextsent>
<nextsent>both sets of grammars also con 63 authors model surprisal observed latent predicted context context event boston et al (2008) hier.
</nextsent>
<nextsent>pos ti....ti1 trees with yield t1...ti1 ti demberg and keller (2008) roark et al (2009) <papid> D09-1034 </papid>frank and bod (2011) this work demberg and keller (2008) hier.</nextsent>
<nextsent>total w1...wi1 trees with yield t1...ti1 wi roark et al (2009) <papid> D09-1034 </papid>this work roark et al (2009) <papid> D09-1034 </papid>hier.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1814">
<title id=" W12-1706.xml">sequential vs hierarchical syntactic models of human incremental sentence processing </title>
<section> models.  </section>
<citcontext>
<prevsection>
<prevsent>psgs consists of rules expanding parent node into children nodes in the syntactic tree, with associated probabilities.
</prevsent>
<prevsent>frank and bod (2011) use psgs that generate pos tag sequences, not words.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
under such grammars, the prefix probability of tag sequence is the sum of the probabilities of all trees : yield(t ) = t1...ti, where the probability of each tree is the product of the probabilities of the rules used in the derivation of . vanilla pcfgs, special case of psgs in which the probability of rule depends only on the identity of the parent node, achieve sub-optimal parsing accuracy relative to grammars in which the probability of each rule depends on richer context (charniak, 1996; johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>to this end, frank and bod (2011) explore several variants of psgs conditioned on successively richer contexts, including ancestor models (which condition rule expansions on ancestor nodes from 1-4 levels up in the tree) and ancestor+sibling models (which condition rule expansions on the ancestors left sibling as well).
</nextsent>
<nextsent>both sets of grammars also con 63 authors model surprisal observed latent predicted context context event boston et al (2008) hier.
</nextsent>
<nextsent>pos ti....ti1 trees with yield t1...ti1 ti demberg and keller (2008) roark et al (2009) <papid> D09-1034 </papid>frank and bod (2011) this work demberg and keller (2008) hier.</nextsent>
<nextsent>total w1...wi1 trees with yield t1...ti1 wi roark et al (2009) <papid> D09-1034 </papid>this work roark et al (2009) <papid> D09-1034 </papid>hier.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1847">
<title id=" W12-1706.xml">sequential vs hierarchical syntactic models of human incremental sentence processing </title>
<section> models.  </section>
<citcontext>
<prevsection>
<prevsent>t refers to trees; refers to pos tags; and refers to words.
</prevsent>
<prevsent>dition rule expansions on the current head node2.in addition to the grammars over pos tag sequences used by frank and bod (2011), we evaluate psgs over word sequences.
</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
we also include the state-of-the-art berkeley grammar (petrov and klein, 2007) <papid> N07-1051 </papid>in our comparison.</citsent>
<aftsection>
<nextsent>syntactic categories in the berkeley grammar are automatically split into fine-grained subcategories to improve the likelihood of the training corpus under the model.
</nextsent>
<nextsent>this increased expressivity allows the parser to achieve state-of-the-art automatic parsing accuracy, but increases grammar size considerably.3 3.2 markov models.
</nextsent>
<nextsent>frank and bod (2011) use markov models over pos tag sequences, where the prefix probability of sequence is ? pr(ti|tin+1, tin+2...ti1).they use three types of smoothing: additive, good turing, and witten-bell, and explore values of from 1 to 3.2or rightmost child node, if the head node is not yet avail able(roark, 2001).<papid> J01-2004 </papid>3to make parsing with the berkeley grammar tractable under the prefix probability parser, we prune away all rules with probability less than 104.</nextsent>
<nextsent>3.3 echo state networks.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1857">
<title id=" W12-1706.xml">sequential vs hierarchical syntactic models of human incremental sentence processing </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>we use two incremental parsers to calculate sur prisals under the hierarchical models.
</prevsent>
<prevsent>for the psgs available under the roark et al (2009) <papid> D09-1034 </papid>parser, weuse that parser to calculate approximate prefix prob 64abilities using beam search.</prevsent>
</prevsection>
<citsent citstr=" J95-2002 ">
for the berkeley grammar, we use probabilistic earley parser modified by levy4 to calculate exact prefix probabilities using the algorithm of stolcke (1995).<papid> J95-2002 </papid></citsent>
<aftsection>
<nextsent>we evaluate each hierarchical model under each type of surprisal (pos, total, lexical-only, and syntactic-only), where possible.
</nextsent>
<nextsent>4.1 datasets.
</nextsent>
<nextsent>each syntactic model is trained on sections 2-21 of the wall street journal (wsj) portion of the penn treebank (marcus et al, 1994), <papid> H94-1020 </papid>and tested on the dundee corpus (kennedy and pynte, 2005), which contains reading time measures for 10 subjects over corpus of 2,391 sentences of naturally occurringtext.</nextsent>
<nextsent>gold-standard pos tags for the dundee corpus are obtained automatically using the brill tagger (brill, 1995).<papid> J95-4004 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1858">
<title id=" W12-1706.xml">sequential vs hierarchical syntactic models of human incremental sentence processing </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluate each hierarchical model under each type of surprisal (pos, total, lexical-only, and syntactic-only), where possible.
</prevsent>
<prevsent>4.1 datasets.
</prevsent>
</prevsection>
<citsent citstr=" H94-1020 ">
each syntactic model is trained on sections 2-21 of the wall street journal (wsj) portion of the penn treebank (marcus et al, 1994), <papid> H94-1020 </papid>and tested on the dundee corpus (kennedy and pynte, 2005), which contains reading time measures for 10 subjects over corpus of 2,391 sentences of naturally occurringtext.</citsent>
<aftsection>
<nextsent>gold-standard pos tags for the dundee corpus are obtained automatically using the brill tagger (brill, 1995).<papid> J95-4004 </papid></nextsent>
<nextsent>frank and bod (2011) exclude subject/word pairs from evaluation if any of the following conditions hold true: the word was not fixated, was present edas the first or last on line, was attached to punctuation, contained more than one capital letter, or contained non-letter (this included clitics)?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1859">
<title id=" W12-1706.xml">sequential vs hierarchical syntactic models of human incremental sentence processing </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 datasets.
</prevsent>
<prevsent>each syntactic model is trained on sections 2-21 of the wall street journal (wsj) portion of the penn treebank (marcus et al, 1994), <papid> H94-1020 </papid>and tested on the dundee corpus (kennedy and pynte, 2005), which contains reading time measures for 10 subjects over corpus of 2,391 sentences of naturally occurringtext.</prevsent>
</prevsection>
<citsent citstr=" J95-4004 ">
gold-standard pos tags for the dundee corpus are obtained automatically using the brill tagger (brill, 1995).<papid> J95-4004 </papid></citsent>
<aftsection>
<nextsent>frank and bod (2011) exclude subject/word pairs from evaluation if any of the following conditions hold true: the word was not fixated, was present edas the first or last on line, was attached to punctuation, contained more than one capital letter, or contained non-letter (this included clitics)?.
</nextsent>
<nextsent>this leaves 191,380 subject/word pairs in the dataset published by frank and bod (2011).
</nextsent>
<nextsent>because we consider lexicalized hierarchical models in addition to un lexicalized ones, we additionally exclude sub ject/word pairs where the word is unknown?
</nextsent>
<nextsent>to themodel.5 this leaves us with total of 148,829 sub ject/word pairs; all of our reported results refer to this dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1868">
<title id=" W11-1824.xml">double layered learning for biological event extraction from text </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W11-1802 ">
this paper presents our approach (referred to as bioevent) for protein-level complex event extraction, developed for the genia task (kim et al, 2011<papid> W11-1802 </papid>b) of the bionlp shared task 2011 (kim et al, 2011<papid> W11-1802 </papid>a).</citsent>
<aftsection>
<nextsent>we developed double layered machine learning approach which utilizes state-of-the-art minimized feature set for each of the event types.
</nextsent>
<nextsent>we improved the best performing system of bionlp 2009 overall, and ranked first amongst 15 teams in finding localization?
</nextsent>
<nextsent>events in 201112.
</nextsent>
<nextsent>bio event is available at http://bioevent.sourceforge.net/
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1876">
<title id=" W11-1824.xml">double layered learning for biological event extraction from text </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>for the official shared task submission we used svm light (joachims, 1999).
</prevsent>
<prevsent>detailed explanation of the trigger detection process includes three main steps: pre-processing, training of the svm models, and combining svm results.pre-processing.
</prevsent>
</prevsection>
<citsent citstr=" W11-1816 ">
all tokenized documents provided by the shared task organizers (stenetorp et al,2011) <papid> W11-1816 </papid>were converted to database records.</citsent>
<aftsection>
<nextsent>then different sets of attributes were defined and calculated for words, sentences and documents.
</nextsent>
<nextsent>training svm models and combining results.
</nextsent>
<nextsent>we trained 9 different binary svm models using one-vs-many approach.
</nextsent>
<nextsent>one of the challenging tasks was to compare the results of different svm models, given that each had different feature sets and their confidence values were not directly comparable and needed to be calibrated properly before comparing.we tried three approaches: 1) selecting the svm result with highest positive distance to hyper plane, 2) using trained decision tree and 3) using another svm trained for voting.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1877">
<title id=" W12-0110.xml">atlas  human language technologies integrated within a multilingual web content management system </title>
<section> text summarization.  </section>
<citcontext>
<prevsection>
<prevsent>in the first, the available training data for statistical machine translation are extended by means of generating paraphrases (e.g. compound nouns are paraphrased into (semi-) equivalent phrases with preposition, and vice versa).
</prevsent>
<prevsent>the paraphrases can be classified as morphological (where the difference is between the forms of the phrase constituents), lexical (based on semantic similarity between constituents) and phrasal (based on syntactic transformations).
</prevsent>
</prevsection>
<citsent citstr=" J10-3003 ">
paraphrase generation methods that operate both on single monolingual corpus or on parallel corpus are discussed by madnani and dorr 2010.<papid> J10-3003 </papid></citsent>
<aftsection>
<nextsent>for instance, one of the methods for paraphrase generation from monolingual corpus considers as paraphrases all words and phrases that are distributionally similar, that is, occurring with the 0 10000000 20000000 30000000 40000000 administrative science mass media fiction informal bulgarian english 9 http://setimes.com/ 74 same sets of anchors (paca and dienes 2005).
</nextsent>
<nextsent>an approach using phrase-based alignment techniques shows how paraphrases in one language can be identified using phrase in second language as pivot (bannard and callison-burch 2005).
</nextsent>
<nextsent>the second method performs automatic generation of parallel corpora (xu and sun 2011) by means of automatic translation.
</nextsent>
<nextsent>this method can be applied for language pairs for which parallel corpora are still limited in quantity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1878">
<title id=" W12-1621.xml">towards mediating shared perceptual basis in situated dialogue </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the results demonstrate that, due to its error-tolerance nature,inexact graph matching provides potential solu 140tion to mediate shared perceptual basis for referential grounding in situated interaction.in the following sections, we first describe an empirical study based on virtual environment to examine how partners mediate their mismatched visual perceptual basis.
</prevsent>
<prevsent>we then provide details about our graph matching based approach and its evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P06-2051 ">
there has been an increasing number of published works on situated language understanding(scheutz et al, 2007a; foster et al, 2008; skubic et al,2004; huwel and wrede, 2006), <papid> P06-2051 </papid>focusing on interpretation of referents in shared environment.</citsent>
<aftsection>
<nextsent>different approaches have been developed to resolve visual referents.
</nextsent>
<nextsent>gorniak and roy present an approach that grounds referring expressions to visual objects through semantic decomposition, using context free grammar that connect linguistic structures with underlying visual properties (gorniak and roy, 2004a).
</nextsent>
<nextsent>recently, they have extended this work by including action-affordances (gorniak and roy, 2007).
</nextsent>
<nextsent>this line of work has mainly focused on grounding words to low-level visual properties.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1879">
<title id=" W12-1621.xml">towards mediating shared perceptual basis in situated dialogue </title>
<section> a graph-based approach to referential </section>
<citcontext>
<prevsection>
<prevsent>based on the arg representations, an inexact graph matching is to find graph or subgraph whose error-transformationcost with the already given graph is minimum (es hera and fu, 1984).
</prevsent>
<prevsent>motivated by the representation power of arg and the error-correcting capability of inexact graph matching, we developed graph-based approach to address the referential grounding problem.
</prevsent>
</prevsection>
<citsent citstr=" P04-1001 ">
argand probabilistic graph matching have been previously applied in multimodal reference resolution (chai et al, 2004<papid> P04-1001 </papid>a; chai et al, 2004<papid> P04-1001 </papid>b) by integrating speech and gestures.</citsent>
<aftsection>
<nextsent>here, although we use similar arg representations, our algorithm is based on inexact graph matching and our focus is on mediating shared perceptual basis.
</nextsent>
<nextsent>4.1 graph representations.
</nextsent>
<nextsent>figure 2 illustrates the key elements and the process of our graph-based method.
</nextsent>
<nextsent>the key elements of our method are two arg representations, one of which is called the discourse graph and the other called the vision graph.the discourse graph captures the information extracted from the linguistic discourse.2 to create the discourse graph, the linguistic discourse first needs 2currently we only focus on the utterances from the director.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1883">
<title id=" W12-1621.xml">towards mediating shared perceptual basis in situated dialogue </title>
<section> empirical results.  </section>
<citcontext>
<prevsection>
<prevsent>to better understand the advantages of the graph-based approach, we have compared two settings.
</prevsent>
<prevsent>in the first setting, only theobject-specific properties are considered for computing the comparability between linguistic expression and visual object, and the relations between objects are ignored.
</prevsent>
</prevsection>
<citsent citstr=" D10-1046 ">
this setting is similar to the baseline approach used in (prasov and chai,2008; prasov and chai, 2010).<papid> D10-1046 </papid></citsent>
<aftsection>
<nextsent>in the second setting, the complete graph-based approach is applied,i.e. both the objects properties and the relations between objects are considered.
</nextsent>
<nextsent>as shown in table 2, although the improvements of performance for the no-error objects and mis-segmented objects are not significant due to the small sample sizes, the performance for the mis-recognized objects is significantly improved by 27.3% (p   .001).
</nextsent>
<nextsent>the improvement for the overall performance is also significant (by 24.9%,   .001).
</nextsent>
<nextsent>the comparison between two settings have demonstrated the importance of representing and reasoning on relations between objects in referential grounding, and the graph-basedapproach provides an ideal solution to capture relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1884">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(b) sautee [food the onions] [manner gently ] [temp setting on low heat].
</prevsent>
<prevsent>the same semantic frame apply heat is evoked by verbs cook and sautee, and roles cook and food in the sentence (a) are filled by mary andthe broccoli, respectively.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
note that roles are specific to the frame, not to the individual lexical units (verbs cook and sautee, in the example).1most approaches to predicting these representations, called semantic role labeling (srl), have relied on large annotated datasets (gildea and jurafsky, 2002; <papid> J02-3001 </papid>carreras and ma`rquez, 2005; surdeanu et al, 2008; <papid> W08-2121 </papid>hajic?</citsent>
<aftsection>
<nextsent>et al, 2009).
</nextsent>
<nextsent>by far, most ofthis work has focused on propbank-style representations (palmer et al, 2005) <papid> J05-1004 </papid>where roles are defined for each individual verb, or even individual senses of verb.</nextsent>
<nextsent>the only exceptions are modifiers and roles a0 and a1 which correspond to proto-agent (a doer,or initiator of the action) and proto-patient (an affected entity), respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1885">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(b) sautee [food the onions] [manner gently ] [temp setting on low heat].
</prevsent>
<prevsent>the same semantic frame apply heat is evoked by verbs cook and sautee, and roles cook and food in the sentence (a) are filled by mary andthe broccoli, respectively.
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
note that roles are specific to the frame, not to the individual lexical units (verbs cook and sautee, in the example).1most approaches to predicting these representations, called semantic role labeling (srl), have relied on large annotated datasets (gildea and jurafsky, 2002; <papid> J02-3001 </papid>carreras and ma`rquez, 2005; surdeanu et al, 2008; <papid> W08-2121 </papid>hajic?</citsent>
<aftsection>
<nextsent>et al, 2009).
</nextsent>
<nextsent>by far, most ofthis work has focused on propbank-style representations (palmer et al, 2005) <papid> J05-1004 </papid>where roles are defined for each individual verb, or even individual senses of verb.</nextsent>
<nextsent>the only exceptions are modifiers and roles a0 and a1 which correspond to proto-agent (a doer,or initiator of the action) and proto-patient (an affected entity), respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1887">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>note that roles are specific to the frame, not to the individual lexical units (verbs cook and sautee, in the example).1most approaches to predicting these representations, called semantic role labeling (srl), have relied on large annotated datasets (gildea and jurafsky, 2002; <papid> J02-3001 </papid>carreras and ma`rquez, 2005; surdeanu et al, 2008; <papid> W08-2121 </papid>hajic?</prevsent>
<prevsent>et al, 2009).</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
by far, most ofthis work has focused on propbank-style representations (palmer et al, 2005) <papid> J05-1004 </papid>where roles are defined for each individual verb, or even individual senses of verb.</citsent>
<aftsection>
<nextsent>the only exceptions are modifiers and roles a0 and a1 which correspond to proto-agent (a doer,or initiator of the action) and proto-patient (an affected entity), respectively.
</nextsent>
<nextsent>however, the srl taskis known to be especially hard for the framenet style representations for number of reasons, including, the lack of cross-frame correspondence for most roles, fine-grain definitions of roles and frame sin framenet, and relatively small amounts of statistically representative data (erk and pado, 2006; das et al, 2010; palmer and sporleder, 2010; <papid> C10-2107 </papid>das and smith, 2011).<papid> P11-1144 </papid></nextsent>
<nextsent>another reason for reduced interest in predicting framenet representations is the lack of annotated resources for most languages, with annotated corpora available or being developed only for english (ruppenhofer et al, 2006), german (bur chardt et al, 2006), spanish (subirats, 2009) and japanese (ohara et al, 2004).due to scarcity of labeled data, purely unsupervised set-ups recently started to receive considerable attention (swier and stevenson, 2004; <papid> W04-3213 </papid>grenager and manning, 2006; <papid> W06-1601 </papid>lang and lapata, 2010; <papid> N10-1137 </papid>lang and1more accurately, framenet distinguishes core and noncore roles with non-core roles mostly corresponding to modifiers, e.g., manner in sentence (b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1888">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by far, most ofthis work has focused on propbank-style representations (palmer et al, 2005) <papid> J05-1004 </papid>where roles are defined for each individual verb, or even individual senses of verb.</prevsent>
<prevsent>the only exceptions are modifiers and roles a0 and a1 which correspond to proto-agent (a doer,or initiator of the action) and proto-patient (an affected entity), respectively.</prevsent>
</prevsection>
<citsent citstr=" C10-2107 ">
however, the srl taskis known to be especially hard for the framenet style representations for number of reasons, including, the lack of cross-frame correspondence for most roles, fine-grain definitions of roles and frame sin framenet, and relatively small amounts of statistically representative data (erk and pado, 2006; das et al, 2010; palmer and sporleder, 2010; <papid> C10-2107 </papid>das and smith, 2011).<papid> P11-1144 </papid></citsent>
<aftsection>
<nextsent>another reason for reduced interest in predicting framenet representations is the lack of annotated resources for most languages, with annotated corpora available or being developed only for english (ruppenhofer et al, 2006), german (bur chardt et al, 2006), spanish (subirats, 2009) and japanese (ohara et al, 2004).due to scarcity of labeled data, purely unsupervised set-ups recently started to receive considerable attention (swier and stevenson, 2004; <papid> W04-3213 </papid>grenager and manning, 2006; <papid> W06-1601 </papid>lang and lapata, 2010; <papid> N10-1137 </papid>lang and1more accurately, framenet distinguishes core and noncore roles with non-core roles mostly corresponding to modifiers, e.g., manner in sentence (b).</nextsent>
<nextsent>non-core roles are expected to generalize across frames.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1889">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>by far, most ofthis work has focused on propbank-style representations (palmer et al, 2005) <papid> J05-1004 </papid>where roles are defined for each individual verb, or even individual senses of verb.</prevsent>
<prevsent>the only exceptions are modifiers and roles a0 and a1 which correspond to proto-agent (a doer,or initiator of the action) and proto-patient (an affected entity), respectively.</prevsent>
</prevsection>
<citsent citstr=" P11-1144 ">
however, the srl taskis known to be especially hard for the framenet style representations for number of reasons, including, the lack of cross-frame correspondence for most roles, fine-grain definitions of roles and frame sin framenet, and relatively small amounts of statistically representative data (erk and pado, 2006; das et al, 2010; palmer and sporleder, 2010; <papid> C10-2107 </papid>das and smith, 2011).<papid> P11-1144 </papid></citsent>
<aftsection>
<nextsent>another reason for reduced interest in predicting framenet representations is the lack of annotated resources for most languages, with annotated corpora available or being developed only for english (ruppenhofer et al, 2006), german (bur chardt et al, 2006), spanish (subirats, 2009) and japanese (ohara et al, 2004).due to scarcity of labeled data, purely unsupervised set-ups recently started to receive considerable attention (swier and stevenson, 2004; <papid> W04-3213 </papid>grenager and manning, 2006; <papid> W06-1601 </papid>lang and lapata, 2010; <papid> N10-1137 </papid>lang and1more accurately, framenet distinguishes core and noncore roles with non-core roles mostly corresponding to modifiers, e.g., manner in sentence (b).</nextsent>
<nextsent>non-core roles are expected to generalize across frames.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1891">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the only exceptions are modifiers and roles a0 and a1 which correspond to proto-agent (a doer,or initiator of the action) and proto-patient (an affected entity), respectively.
</prevsent>
<prevsent>however, the srl taskis known to be especially hard for the framenet style representations for number of reasons, including, the lack of cross-frame correspondence for most roles, fine-grain definitions of roles and frame sin framenet, and relatively small amounts of statistically representative data (erk and pado, 2006; das et al, 2010; palmer and sporleder, 2010; <papid> C10-2107 </papid>das and smith, 2011).<papid> P11-1144 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-3213 ">
another reason for reduced interest in predicting framenet representations is the lack of annotated resources for most languages, with annotated corpora available or being developed only for english (ruppenhofer et al, 2006), german (bur chardt et al, 2006), spanish (subirats, 2009) and japanese (ohara et al, 2004).due to scarcity of labeled data, purely unsupervised set-ups recently started to receive considerable attention (swier and stevenson, 2004; <papid> W04-3213 </papid>grenager and manning, 2006; <papid> W06-1601 </papid>lang and lapata, 2010; <papid> N10-1137 </papid>lang and1more accurately, framenet distinguishes core and noncore roles with non-core roles mostly corresponding to modifiers, e.g., manner in sentence (b).</citsent>
<aftsection>
<nextsent>non-core roles are expected to generalize across frames.
</nextsent>
<nextsent>1 cooks mary the broccoli in small pan container cook food apply_heat figure 1: an example of semantic dependency graph.
</nextsent>
<nextsent>lapata, 2011a; lang and lapata, 2011<papid> P11-1112 </papid>b; titov and klementiev, 2012).</nextsent>
<nextsent>however, all these approaches have focused on propbank-style representations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1892">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the only exceptions are modifiers and roles a0 and a1 which correspond to proto-agent (a doer,or initiator of the action) and proto-patient (an affected entity), respectively.
</prevsent>
<prevsent>however, the srl taskis known to be especially hard for the framenet style representations for number of reasons, including, the lack of cross-frame correspondence for most roles, fine-grain definitions of roles and frame sin framenet, and relatively small amounts of statistically representative data (erk and pado, 2006; das et al, 2010; palmer and sporleder, 2010; <papid> C10-2107 </papid>das and smith, 2011).<papid> P11-1144 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-1601 ">
another reason for reduced interest in predicting framenet representations is the lack of annotated resources for most languages, with annotated corpora available or being developed only for english (ruppenhofer et al, 2006), german (bur chardt et al, 2006), spanish (subirats, 2009) and japanese (ohara et al, 2004).due to scarcity of labeled data, purely unsupervised set-ups recently started to receive considerable attention (swier and stevenson, 2004; <papid> W04-3213 </papid>grenager and manning, 2006; <papid> W06-1601 </papid>lang and lapata, 2010; <papid> N10-1137 </papid>lang and1more accurately, framenet distinguishes core and noncore roles with non-core roles mostly corresponding to modifiers, e.g., manner in sentence (b).</citsent>
<aftsection>
<nextsent>non-core roles are expected to generalize across frames.
</nextsent>
<nextsent>1 cooks mary the broccoli in small pan container cook food apply_heat figure 1: an example of semantic dependency graph.
</nextsent>
<nextsent>lapata, 2011a; lang and lapata, 2011<papid> P11-1112 </papid>b; titov and klementiev, 2012).</nextsent>
<nextsent>however, all these approaches have focused on propbank-style representations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1893">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the only exceptions are modifiers and roles a0 and a1 which correspond to proto-agent (a doer,or initiator of the action) and proto-patient (an affected entity), respectively.
</prevsent>
<prevsent>however, the srl taskis known to be especially hard for the framenet style representations for number of reasons, including, the lack of cross-frame correspondence for most roles, fine-grain definitions of roles and frame sin framenet, and relatively small amounts of statistically representative data (erk and pado, 2006; das et al, 2010; palmer and sporleder, 2010; <papid> C10-2107 </papid>das and smith, 2011).<papid> P11-1144 </papid></prevsent>
</prevsection>
<citsent citstr=" N10-1137 ">
another reason for reduced interest in predicting framenet representations is the lack of annotated resources for most languages, with annotated corpora available or being developed only for english (ruppenhofer et al, 2006), german (bur chardt et al, 2006), spanish (subirats, 2009) and japanese (ohara et al, 2004).due to scarcity of labeled data, purely unsupervised set-ups recently started to receive considerable attention (swier and stevenson, 2004; <papid> W04-3213 </papid>grenager and manning, 2006; <papid> W06-1601 </papid>lang and lapata, 2010; <papid> N10-1137 </papid>lang and1more accurately, framenet distinguishes core and noncore roles with non-core roles mostly corresponding to modifiers, e.g., manner in sentence (b).</citsent>
<aftsection>
<nextsent>non-core roles are expected to generalize across frames.
</nextsent>
<nextsent>1 cooks mary the broccoli in small pan container cook food apply_heat figure 1: an example of semantic dependency graph.
</nextsent>
<nextsent>lapata, 2011a; lang and lapata, 2011<papid> P11-1112 </papid>b; titov and klementiev, 2012).</nextsent>
<nextsent>however, all these approaches have focused on propbank-style representations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1894">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>non-core roles are expected to generalize across frames.
</prevsent>
<prevsent>1 cooks mary the broccoli in small pan container cook food apply_heat figure 1: an example of semantic dependency graph.
</prevsent>
</prevsection>
<citsent citstr=" P11-1112 ">
lapata, 2011a; lang and lapata, 2011<papid> P11-1112 </papid>b; titov and klementiev, 2012).</citsent>
<aftsection>
<nextsent>however, all these approaches have focused on propbank-style representations.
</nextsent>
<nextsent>this may seem somewhat unnatural as framenet representations, though arguably more powerful, are harder to learn in the supervised setting, harder to annotate, and annotated data is available for considerably fewer languages.
</nextsent>
<nextsent>this is the gap which we address in this preliminary study.more specifically, we extend an existing stateof-the-art bayesian model for unsupervised semantic role labeling and apply it to support framenet style semantics.
</nextsent>
<nextsent>in other words, our method jointly induces both frames and frame-specific semantic roles.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1900">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>though the scores for frame induction are not high, we argue that this is primarily due to very high granularity of framenet frames which is hard to reproduce for unsupervised systems, as the implicit supervision signal is not capable of providing these distinctions.
</prevsent>
<prevsent>in this work, we use dependency representations of frame semantics.
</prevsent>
</prevsection>
<citsent citstr=" D08-1008 ">
dependency representations for srl (johansson and nugues, 2008) <papid> D08-1008 </papid>were made popular by conll-2008 and conll-2009 shared tasks (surdeanu et al, 2008; <papid> W08-2121 </papid>hajic?</citsent>
<aftsection>
<nextsent>et al, 2009), but for english were limited to propbank.
</nextsent>
<nextsent>recently,english framenet was also released in the dependency format (bauer et al, 2012).
</nextsent>
<nextsent>instead of predicting argument spans, in dependency representation the goal is, roughly, to predict the syntactic headof the argument.
</nextsent>
<nextsent>the semantic dependency representation for sentence (a) is shown in figure 1, labels on edges denote roles and labels on words denote frames.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1909">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>in other words, our goal is to label (or cluster) edges and nodes in the dependency graph, figure 1.
</prevsent>
<prevsent>since we focus in this study on verbal predicates only, the first stage would be trivial and the second stage could be handled with heuristics as in much of previous work on unsupervised srl (lang and lapata, 2011<papid> P11-1112 </papid>a; titov and klementiev, 2012).additionally to considering only verbal predicates, we also assume that every verb belongs toa single frame.</prevsent>
</prevsection>
<citsent citstr=" S10-1011 ">
this assumption, though restrictive, may be reasonable in practice as (a) the distributions across frames (i.e. senses) are generally highly skewed, (b) current state-of-the-art techniques for word-sense induction hardly beat mostfrequent-sense baselines inaccuracy metrics (man andhar et al, 2010).<papid> S10-1011 </papid></citsent>
<aftsection>
<nextsent>this assumption, or its minor relaxations, is relatively standard in work on unsupervised semantic parsing tasks (poon and domingos, 2009; <papid> D09-1001 </papid>poon and domingos, 2010; <papid> P10-1031 </papid>titov and klementiev, 2011).<papid> P11-1145 </papid></nextsent>
<nextsent>from the modeling prospective,there are no major obstacles to relaxing this assumption, but it would lead to major explosion of the search space and, as result, slow inference.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1910">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>since we focus in this study on verbal predicates only, the first stage would be trivial and the second stage could be handled with heuristics as in much of previous work on unsupervised srl (lang and lapata, 2011<papid> P11-1112 </papid>a; titov and klementiev, 2012).additionally to considering only verbal predicates, we also assume that every verb belongs toa single frame.</prevsent>
<prevsent>this assumption, though restrictive, may be reasonable in practice as (a) the distributions across frames (i.e. senses) are generally highly skewed, (b) current state-of-the-art techniques for word-sense induction hardly beat mostfrequent-sense baselines inaccuracy metrics (man andhar et al, 2010).<papid> S10-1011 </papid></prevsent>
</prevsection>
<citsent citstr=" D09-1001 ">
this assumption, or its minor relaxations, is relatively standard in work on unsupervised semantic parsing tasks (poon and domingos, 2009; <papid> D09-1001 </papid>poon and domingos, 2010; <papid> P10-1031 </papid>titov and klementiev, 2011).<papid> P11-1145 </papid></citsent>
<aftsection>
<nextsent>from the modeling prospective,there are no major obstacles to relaxing this assumption, but it would lead to major explosion of the search space and, as result, slow inference.
</nextsent>
<nextsent>we follow previous work on unsupervised semantic role labeling (lang and lapata, 2011<papid> P11-1112 </papid>a; titov and klementiev, 2012) and associate arguments with their frame specific syntactic signatures which we refer to as argument keys: ? active or passive verb voice (act/pass).</nextsent>
<nextsent>argument position relative to predicate (left/right).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1911">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>since we focus in this study on verbal predicates only, the first stage would be trivial and the second stage could be handled with heuristics as in much of previous work on unsupervised srl (lang and lapata, 2011<papid> P11-1112 </papid>a; titov and klementiev, 2012).additionally to considering only verbal predicates, we also assume that every verb belongs toa single frame.</prevsent>
<prevsent>this assumption, though restrictive, may be reasonable in practice as (a) the distributions across frames (i.e. senses) are generally highly skewed, (b) current state-of-the-art techniques for word-sense induction hardly beat mostfrequent-sense baselines inaccuracy metrics (man andhar et al, 2010).<papid> S10-1011 </papid></prevsent>
</prevsection>
<citsent citstr=" P10-1031 ">
this assumption, or its minor relaxations, is relatively standard in work on unsupervised semantic parsing tasks (poon and domingos, 2009; <papid> D09-1001 </papid>poon and domingos, 2010; <papid> P10-1031 </papid>titov and klementiev, 2011).<papid> P11-1145 </papid></citsent>
<aftsection>
<nextsent>from the modeling prospective,there are no major obstacles to relaxing this assumption, but it would lead to major explosion of the search space and, as result, slow inference.
</nextsent>
<nextsent>we follow previous work on unsupervised semantic role labeling (lang and lapata, 2011<papid> P11-1112 </papid>a; titov and klementiev, 2012) and associate arguments with their frame specific syntactic signatures which we refer to as argument keys: ? active or passive verb voice (act/pass).</nextsent>
<nextsent>argument position relative to predicate (left/right).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1912">
<title id=" W12-1901.xml">unsupervised induction of frame semantic representations </title>
<section> task definition.  </section>
<citcontext>
<prevsection>
<prevsent>since we focus in this study on verbal predicates only, the first stage would be trivial and the second stage could be handled with heuristics as in much of previous work on unsupervised srl (lang and lapata, 2011<papid> P11-1112 </papid>a; titov and klementiev, 2012).additionally to considering only verbal predicates, we also assume that every verb belongs toa single frame.</prevsent>
<prevsent>this assumption, though restrictive, may be reasonable in practice as (a) the distributions across frames (i.e. senses) are generally highly skewed, (b) current state-of-the-art techniques for word-sense induction hardly beat mostfrequent-sense baselines inaccuracy metrics (man andhar et al, 2010).<papid> S10-1011 </papid></prevsent>
</prevsection>
<citsent citstr=" P11-1145 ">
this assumption, or its minor relaxations, is relatively standard in work on unsupervised semantic parsing tasks (poon and domingos, 2009; <papid> D09-1001 </papid>poon and domingos, 2010; <papid> P10-1031 </papid>titov and klementiev, 2011).<papid> P11-1145 </papid></citsent>
<aftsection>
<nextsent>from the modeling prospective,there are no major obstacles to relaxing this assumption, but it would lead to major explosion of the search space and, as result, slow inference.
</nextsent>
<nextsent>we follow previous work on unsupervised semantic role labeling (lang and lapata, 2011<papid> P11-1112 </papid>a; titov and klementiev, 2012) and associate arguments with their frame specific syntactic signatures which we refer to as argument keys: ? active or passive verb voice (act/pass).</nextsent>
<nextsent>argument position relative to predicate (left/right).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1932">
<title id=" W12-2014.xml">scoring spoken responses based on content accuracy </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to tackle these challenges, we propose two novel content scoring methods in this paper.the remainder of the paper is organized as follows: section 2 reviews the related previous research efforts; section 3 proposes the two content scoring methods we designed for two types of questions described above; section 4 reports the experimental results of applying the proposed methods; finally, section 5 concludes our reported research and describes our plans for future research.
</prevsent>
<prevsent>for writing tests, previous content scoring investigations can be divided into the following three groups.the first group relies on obtaining and matching patterns associated with the correct answers (leacock and chodorow, 2003; sukkarieh and blackmore, 2009).
</prevsent>
</prevsection>
<citsent citstr=" E09-1065 ">
the second group of methods, also mostly used 122 for content-scoring, is to relyon variety of text similarity measurements to compare response with either pre-defined correct answers or group of responses rated with high score (mohler and mihalcea, 2009).<papid> E09-1065 </papid></citsent>
<aftsection>
<nextsent>compared to the first group, such methods can bypass labor intensive pattern-building step.
</nextsent>
<nextsent>a widely used approach to measuring text similarity between two text strings is to convert each text string into word vector and then usethe angle between these two vectors as similarity metric.
</nextsent>
<nextsent>for example, content vector analysis (cva) has been successfully utilized to detectoff-topic essays (higgins et al, 2006) and to provide content-related features for essay scoring (attali and burstein, 2004).
</nextsent>
<nextsent>for this group of methods, measuring the semantics similarity between two terms is key question.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1933">
<title id=" W12-2014.xml">scoring spoken responses based on content accuracy </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>the pmi-ir is measure based on web query analysis using pointwise mutual information (pmi) and information retrieval (ir).
</prevsent>
<prevsent>for an answer candidate (c) and an answer key (k), their pmi-ir is computed as: ssmpmi-ir(c, k) = hits(cneark) hits(c) where the hits(x) function obtains the count of term returned by web search engine and near is query operator for proximity search, searching the pages on which both and appear within specified distance.
</prevsent>
</prevsection>
<citsent citstr=" P94-1019 ">
among many wordnet (wn) based ssms summarized in courley and mihalcea (2005), 123 we found that the wu-palmer metric proposed by wu and palmer (1994) <papid> P94-1019 </papid>worked the best in our pilot study.</citsent>
<aftsection>
<nextsent>this metric is score denoting how similar two word senses are, based on the depth of the twoword senses in the taxonomy and their least common subsumer 1 (lcs): ssmwn(c, k) = 2 ? depth(lcs) depth(c) + depth(k) for each answer key, we calculated two sets of ssms (ssmpmi-ir and ssmwn , respectively) from all candidates.
</nextsent>
<nextsent>then, we selected the largest ssmpmi-ir and ssmwn as the final ssms for this particular answer key.
</nextsent>
<nextsent>for each test question, using the corresponding responses in the training set, we built linear regression model between these ssms for all answer keys and the human judged scores.the learned regression model was applied to the responses to this particular testing question in the testing set to convert set of ssms to predictions of human scores.
</nextsent>
<nextsent>the predicted scores were then usedas content feature.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1934">
<title id=" W12-2014.xml">scoring spoken responses based on content accuracy </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>in addition, using other non-cva machine learning methods can enable us to try other types of linguistic features.
</prevsent>
<prevsent>to address the feature sparsity issue, smoothing method, which converts word-based text features into features based on other entities with much smaller vocabulary size, is used.
</prevsent>
</prevsection>
<citsent citstr=" P09-1056 ">
we usea hidden markov model (hmm) based smoothing method (huang and yates, 2009), <papid> P09-1056 </papid>which induces classes, corresponding to hidden states in the hmm model, from the observed word strings.</citsent>
<aftsection>
<nextsent>this smoothing method can use contextual information of the word sequences due to the nature of hmm.then, we convert word-entity vectors to the vectors based on the induced classes.
</nextsent>
<nextsent>tf-idf (term 1most specific ancestor node frequency and inverse document frequency) weighting is applied on the new class vectors.
</nextsent>
<nextsent>finally,the processed class vectors are used as input features (smoothed) to machine learning method.
</nextsent>
<nextsent>in this research, after comparing several widely used machine learning approaches, such as naive bayes, cart, etc., we decided to use ripper proposed by cohen (1995), rule induction method, similar to furn kranz et al (1998).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1936">
<title id=" W11-2042.xml">engagement based multiparty dialog with a human oid robot </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>when dialog system is situated in the real, physical world and used in more open settings, more effort needs to be spent on establishing and maintaining clear communication channels between the system and its users.
</prevsent>
<prevsent>e.g. the system first needs to detect that there are potential users with whom interacting would be possible, it needs to decide if detected person wants to interact with the system at all and it needs to make decisions when and how it should try to start an interaction with that person.
</prevsent>
</prevsection>
<citsent citstr=" W09-3933 ">
bohus and horvitz (2009) <papid> W09-3933 </papid>have developed model for representing the current relation of user with such system (their engagement state) and determining if they want to be involved in an interaction with the system (using explicit engagement actions and the more abstract engagement intention).</citsent>
<aftsection>
<nextsent>each user can be engaged in specific interactions(denoting different basic unit[s] of sustained, interactive problem-solving?)
</nextsent>
<nextsent>and there can be multiple such interactions, each with potentially different users.
</nextsent>
<nextsent>this demonstration shows how an engagement model inspired by these ideas was integrated intoan existing dialog system and how it helps in realizing interactive scenarios with robot that incorporate cues for the dialog from the systems environment.
</nextsent>
<nextsent>section 3 gives more details about this model and how it is used by the dialog.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1938">
<title id=" W12-0910.xml">i say have you say tem profiling verbs in children data in english and portuguese </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>for examining child-produced data we use the english and portuguese corpora from childes (macwhinney, 2000).
</prevsent>
<prevsent>the english corpora in childes have been parsed using at least three different pipelines: mor, post and megrasp (available as part of the childes distribution, the corpora are pos tagged using the mor and post programs (parisse and normand, 2000)).
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
in addition we use version annotated with therasp system (briscoe et al, 2006), <papid> P06-4020 </papid>that tokenizes, tags, lemmatizes and parses the input sentences, out putting syntactic trees and then adding grammatical relations (gr) as described by (but tery and korhonen, 2005).</citsent>
<aftsection>
<nextsent>this corpus contains 16,649 types and 76,386,369 tokens in 3,031,217 sentences distributed by age as shown in table 1.
</nextsent>
<nextsent>table 1: frequency of words and sentences by age in years in childes for english and portuguese age english portuguese words (k) sent (k) words (k) sent (k) 0 4,944 130 0 0 1 12,124 604 7 2 2 19,481 1,367 8 1 4 16,725 249 1 61 5 3,266 121 38 1 6 782 19 47 1 7 1,088 63 56 1 8 12 5 56 1 the portuguese, childes contains 3 corpora: (1) batoreo, with 60 narratives, 30 from adults and 30 from children, about two stories; (2)porto alegre with data from 5 to 9 year old children, collected both cross-sectionally and longitudinally; and (3) florianopolis with the longitudinal data for one brazilian child: 5530 utterances in broad phonetic transcription.
</nextsent>
<nextsent>0 1 2 3 4 5 6 7 800.05 0.10.15 0.20.25 0.3 noun (en) verb (pt) preposition (pt) noun (pt) (a) portuguese 0 1 2 3 4 5 6 7 800.05 0.10.15 0.20.25 0.3 verb (en) preposition (en) noun (en) verb (pt) preposition (pt) noun (pt) (b) english figure 1: verbs in relation to other frequent parts of-speech in english (1b) and portuguese (1a) the combined size of the portuguese corpora in sentences and words is in table 1.
</nextsent>
<nextsent>these were annotated with the pala vras parser, robust parser, which has reported accuracy of 99% for part-of-speech tagging, 96-97% for syntactic trees, and 91.8% for multiword expressions (bick,2000)1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1939">
<title id=" W12-0902.xml">empiricist solutions to nativist puzzles by means of unsupervised tsg </title>
<section> nativism versus empiricism.  </section>
<citcontext>
<prevsection>
<prevsent>we will show that even if linguistic phenomenon is not in childs input, it can be learned by an ideal?
</prevsent>
<prevsent>learner from tiny fraction of child directed utterances, namely by combining fragments from these utterances using the adam corpus in the childes database (macwhinney 2000).
</prevsent>
</prevsection>
<citsent citstr=" W06-2917 ">
previous work on empirically solving na tivist puzzles, focused on relatively small set of phenomena such as auxiliary fronting (reali &amp; christiansen 2005; clark and eyraud 2006) <papid> W06-2917 </papid>and anaphoric one (foraker et al  2009).</citsent>
<aftsection>
<nextsent>some of the proposed solutions were based on linear models, such as trigram models (reali &amp; christiansen 2005), though kam et al  (2008) showed that the success of these models depend on accidental english facts.
</nextsent>
<nextsent>other empiricist approaches have taken the notion of structural dependency together with 10 combination operation as minimal requirements (e.g. bod 2009), which overcomes the problems raised by kam et al  (2008).
</nextsent>
<nextsent>yet, it remains an open question which of the many other syntactic phenomena in the nativist literature can be acquired by such general learning method on the basis of child-directed speech.
</nextsent>
<nextsent>in this paper we will deal with much larger set of problems than used before in empiricist computational models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1940">
<title id=" W12-0902.xml">empiricist solutions to nativist puzzles by means of unsupervised tsg </title>
<section> grammar induction with tsg: the.  </section>
<citcontext>
<prevsection>
<prevsent>in section 9 we will discuss the shortcomings of our approach and suggest some improvements for future research.
</prevsent>
<prevsent>best-ranked k-shortest derivation for our induced grammar, we use the formalism of tree-substitution grammar.
</prevsent>
</prevsection>
<citsent citstr=" P06-1109 ">
this formalism has recently generated considerable interest in the field of grammar induction (e.g. bod 2006; <papid> P06-1109 </papid>odonnell et al  2009; post and gildea 2009; <papid> P09-2012 </papid>cohn et al  2010).</citsent>
<aftsection>
<nextsent>as noted by cohn et al  (2010) and others, this formalism has number of advantages.
</nextsent>
<nextsent>for example, its productive units (elementary trees of arbitrary size) allow for both structural and lexical sensitivity (see bod et al  2003), while grammars in this formalism are still efficiently learn able from corpus of sentences in cubic time and space.
</nextsent>
<nextsent>as an example, figure 1 gives two tsg derivations and parse trees for the sentence she saw the dress with the telescope.
</nextsent>
<nextsent>note that the first derivation corresponds to the shortest derivation, as it consists of only two elementary trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1941">
<title id=" W12-0902.xml">empiricist solutions to nativist puzzles by means of unsupervised tsg </title>
<section> grammar induction with tsg: the.  </section>
<citcontext>
<prevsection>
<prevsent>in section 9 we will discuss the shortcomings of our approach and suggest some improvements for future research.
</prevsent>
<prevsent>best-ranked k-shortest derivation for our induced grammar, we use the formalism of tree-substitution grammar.
</prevsent>
</prevsection>
<citsent citstr=" P09-2012 ">
this formalism has recently generated considerable interest in the field of grammar induction (e.g. bod 2006; <papid> P06-1109 </papid>odonnell et al  2009; post and gildea 2009; <papid> P09-2012 </papid>cohn et al  2010).</citsent>
<aftsection>
<nextsent>as noted by cohn et al  (2010) and others, this formalism has number of advantages.
</nextsent>
<nextsent>for example, its productive units (elementary trees of arbitrary size) allow for both structural and lexical sensitivity (see bod et al  2003), while grammars in this formalism are still efficiently learn able from corpus of sentences in cubic time and space.
</nextsent>
<nextsent>as an example, figure 1 gives two tsg derivations and parse trees for the sentence she saw the dress with the telescope.
</nextsent>
<nextsent>note that the first derivation corresponds to the shortest derivation, as it consists of only two elementary trees.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1943">
<title id=" W12-0902.xml">empiricist solutions to nativist puzzles by means of unsupervised tsg </title>
<section> grammar induction with tsg: the.  </section>
<citcontext>
<prevsection>
<prevsent>while we will use bods method of assigning all binary trees to set of sentences, we will not compute the most probable tree or sentence.
</prevsent>
<prevsent>instead we compute the k-shortest derivations for each sentence after which the sum of ranks of the subtrees in the derivations determines the best-ranked shortest derivation (bod 2000).
</prevsent>
</prevsection>
<citsent citstr=" P11-2127 ">
this last step is important, since the shortest derivation alone is known to perform poorly (bansal and klein 2011).<papid> P11-2127 </papid></citsent>
<aftsection>
<nextsent>in zollmann and simaan (2005) it is shown that training by means of shortest derivations corresponds to maximum likelihood training in the limit if the corpus grows to infinity.
</nextsent>
<nextsent>our approach to focus on the shortest derivation rather than the most probable tree or most probable sentence is partly motivated by our different task: it is well-known that the probability of sentence decreases exponentially with sentence length.
</nextsent>
<nextsent>this is problematic since, when choosing among alternative sentences, the longest sentence may be (the most) grammatical.
</nextsent>
<nextsent>instead, by focusing on the (k-) shortest derivations this problem can ? at least partly ? be overcome.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1944">
<title id=" W12-0902.xml">empiricist solutions to nativist puzzles by means of unsupervised tsg </title>
<section> grammar induction with tsg: the.  </section>
<citcontext>
<prevsection>
<prevsent>130-133).
</prevsent>
<prevsent>the k-shortest derivations can be computed by viterbi by assigning each elementary tree equal probability (bod 2000).
</prevsent>
</prevsection>
<citsent citstr=" W05-1506 ">
we follow the third algorithm in huang and chiang (2005), <papid> W05-1506 </papid>where first traditional viterbi-chart is created, which enumerates in an efficient way all possible subderivations.</citsent>
<aftsection>
<nextsent>next, the algorithm starts at the root node andre cursively looks for the k-best derivations, where we used = 100.
</nextsent>
<nextsent>in addition, we employed the size reduction technique developed in teichmann (2011) <papid> W11-2204 </papid>for u-dop/tsg.</nextsent>
<nextsent>we used all 12k child-directed utterances in the adam corpus from the childes database (macwhinney 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1945">
<title id=" W12-0902.xml">empiricist solutions to nativist puzzles by means of unsupervised tsg </title>
<section> grammar induction with tsg: the.  </section>
<citcontext>
<prevsection>
<prevsent>we follow the third algorithm in huang and chiang (2005), <papid> W05-1506 </papid>where first traditional viterbi-chart is created, which enumerates in an efficient way all possible subderivations.</prevsent>
<prevsent>next, the algorithm starts at the root node andre cursively looks for the k-best derivations, where we used = 100.</prevsent>
</prevsection>
<citsent citstr=" W11-2204 ">
in addition, we employed the size reduction technique developed in teichmann (2011) <papid> W11-2204 </papid>for u-dop/tsg.</citsent>
<aftsection>
<nextsent>we used all 12k child-directed utterances in the adam corpus from the childes database (macwhinney 2000).
</nextsent>
<nextsent>these utterances come with pos-tags, which were stripped off the sentences and fed to our tsg induction algorithm.
</nextsent>
<nextsent>the child directed sentences were randomly split into 50% ec and 50% hc.
</nextsent>
<nextsent>the subtrees from ec were used to derive tsg for the pos-strings from hc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1947">
<title id=" W11-2020.xml">modeling and predicting quality in spoken human computer interaction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a linear modeling approach of iq by use of multivariate linear regression will be 173presented and discussed in section 9 to obtain comparability with paradise.
</prevsent>
<prevsent>this study closes with conclusion and discussion in section 10.
</prevsent>
</prevsection>
<citsent citstr=" W09-3926 ">
models predicting user satisfaction at any point in an sds have only been deficiently explored to date.(engelbrecht et al, 2009) <papid> W09-3926 </papid>modeled user satisfaction as process evolving over time with hidden markov models (hmm).</citsent>
<aftsection>
<nextsent>in the experiment, users were asked to interact with wizard-of-oz restaurant information system.
</nextsent>
<nextsent>each participant followed dialogues which have previously been defined following predefined scripts, i.e. specific scenarios.
</nextsent>
<nextsent>this resulted in equally long dialogue transcripts for each scenario.
</nextsent>
<nextsent>the users were constrained to rate their satisfaction on 5-point scale with bad?,poor?, fair?, good?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI1949">
<title id=" W11-2020.xml">modeling and predicting quality in spoken human computer interaction </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>after each dialogue step.
</prevsent>
<prevsent>the interaction was halted while the user voted.
</prevsent>
</prevsection>
<citsent citstr=" W10-4304 ">
in similar spirit, (higashinaka et al, 2010<papid> W10-4304 </papid>a)developed model for predicting turn-wise ratings, which was evaluated on human-machine and human-human dialogues.</citsent>
<aftsection>
<nextsent>the data employed was not spoken dialogue but text dialogues from chat system and transcribed conversation between humans.
</nextsent>
<nextsent>the labels in the model originated fromtwo expert raters that listened to the recorded interactions and provided turn-wise scores from 1-7 on smoothness (smoothness of the conversation?), closeness (closeness perceived by the user towards the system?)
</nextsent>
<nextsent>and willingness (willingness to continue the conversation?).
</nextsent>
<nextsent>rater-independent performance scores of the model reached about 0.2-0.24 unweighted average recall, which is about 0.1 points above the baseline of app.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2033">
<title id=" W11-2020.xml">modeling and predicting quality in spoken human computer interaction </title>
<section> input features.  </section>
<citcontext>
<prevsection>
<prevsent>one of garbage, non-angry, slightly angry, very angry.
</prevsent>
<prevsent>the same annotation scheme as in our previous work on anger detection has been applied, see e.g.
</prevsent>
</prevsection>
<citsent citstr=" W09-3918 ">
(schmitt et al, 2009).<papid> W09-3918 </papid></citsent>
<aftsection>
<nextsent>from all 4,832 user turns, 68.5% were non-angry, 14.3% slightly angry, 5.0%very angry and 12.2% contained garbage, i.e. non speech events.
</nextsent>
<nextsent>in total, the number of interaction parameters servings as input variables for the model amounts to 52.
</nextsent>
<nextsent>vector machines the iq scores are classified with support vector machines (bennett and campbell, 2000).
</nextsent>
<nextsent>in short, an svm uses set of training examples (x1, y1) . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2054">
<title id=" W12-1640.xml">improving sentence completion in dialogues with multimodal features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we trained asystem based on interrupted but resumed sentences, in order to find plausible completions for incomplete sentences.
</prevsent>
<prevsent>our promising results are based on multi-modal features.
</prevsent>
</prevsection>
<citsent citstr=" W11-2035 ">
our project, called robo helper, focuses on developing an interface for elderly people to effectively communicate with robotic assistants that can help them perform activities of daily living (adls) (krapp, 2002), so that they can safely remain living in their home (di eugenio et al, 2010; chen et al, 2011).<papid> W11-2035 </papid></citsent>
<aftsection>
<nextsent>we are developing multi-modal interface since people communicate with each other using variety of verbal and non-verbal signals, including haptics, i.e., force exchange (as when one person hands bowl to another person, and lets go only when s/he senses that the other is holding it).
</nextsent>
<nextsent>we collected medium size multi-modal human-human dialogue corpus, then processed and analyzed it.
</nextsent>
<nextsent>we observed that fair number of sentences are incomplete, namely, the speaker does not finish the utterance.
</nextsent>
<nextsent>because of that, we developed core component of our multi-modal interface, sentence completion system, trained on the set of interrupted but eventually completed sentences from our corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2055">
<title id=" W12-1640.xml">improving sentence completion in dialogues with multimodal features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentence completion has been addressed within information retrieval, to satisfy users information needs (grabski and scheffer, 2004).
</prevsent>
<prevsent>completing sentences in human-human dialogue is more difficult than in written text.
</prevsent>
</prevsection>
<citsent citstr=" J11-1004 ">
first, utterances may be informal, ungrammatical or dis-fluent; second, people interrupt each other during conversations (devault et al, 2010; yang et al, 2011).<papid> J11-1004 </papid></citsent>
<aftsection>
<nextsent>additionally, the interaction is complex, as people spontaneously usehand gestures, body language and gaze besides spoken language.
</nextsent>
<nextsent>as noticed by (bolden, 2003), during face-to-face interaction, the completion problem is not only an exclusively verbal phenomenon but an action embedded within complex web of different meaning-making fields?.
</nextsent>
<nextsent>accordingly, among our features, we will include pointing gestures, and haptic-ostensive (h-o) actions, e.g., referring to an object by manipulating it in the real world (landra gin et al, 2002; foster et al, 2008).
</nextsent>
<nextsent>the paper is organized as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2056">
<title id=" W12-1640.xml">improving sentence completion in dialogues with multimodal features </title>
<section> dataset.  </section>
<citcontext>
<prevsection>
<prevsent>and close?.
</prevsent>
<prevsent>in order to verify the reliability of our annotations, we double coded 15% ofthe pointing gestures and h-o actions.
</prevsent>
</prevsection>
<citsent citstr=" N12-1058 ">
kappa values of 0.751 for pointing gestures, and of 0.703 for h-o actions, are considered acceptable, especially considering the complexity of these real life tasks (chen and di eugenio, 2012).<papid> N12-1058 </papid></citsent>
<aftsection>
<nextsent>in this paper, we focus on specific sub-dialoguesin the corpus, which we call interruptions.
</nextsent>
<nextsent>an interruption can occur at any point in human-human dia logues: it happens when presumably the interrupter (itr) thinks s/he has already understood what the speaker (spk) means before listening to the entire sentence.
</nextsent>
<nextsent>by observing the data from our corpus, we conclude that there are generally three cases ofinterruptions.
</nextsent>
<nextsent>first, the speaker (spk) stops speaking and does not complete the sentence ? these are the incomplete sentences whose completion robot would need to infer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2057">
<title id=" W12-1640.xml">improving sentence completion in dialogues with multimodal features </title>
<section> candidate pairs generation.  </section>
<citcontext>
<prevsection>
<prevsent>to generate additional interrupted sentences, candidate structure  pairs, we need to match an interrupted sentence ints with its potential completions ? basically, to check whether ints can match the prefix of other sentence sin the corpus.
</prevsent>
<prevsent>we do so by comparing the posse quence and parse tree of ints with the pos sequence and parse tree of the prefix of another sentence.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
both ints and other sentences in the corpus are parsed via the stanford parser (klein and manning, 2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>before discussing the details though, we needto deal with one potential problem: the posse quence for the incomplete portion of ints may notbe correctly assigned.
</nextsent>
<nextsent>for example, when the sentence the/dt, top/jj, cabinet/nn.?
</nextsent>
<nextsent>is interrupted as the/dt, top/nn?, the pos tag of nn is assigned to top?; this is incorrect, and engenders noise for finding correct completions.
</nextsent>
<nextsent>we first pre-process dialogue by splitting turns into sentences, tokenizing sentences into tokens, and pos tagging tokens.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2059">
<title id=" W12-0601.xml">unsupervised partofspeech tagging in noisy and esoteric domains with a syntactic semantic bayesian hmm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the explosion of social media in recent years has led to the need for nlp tools like part-of-speech (pos) taggers that are robust enough to handle data that is becoming increasingly noisy.?
</prevsent>
<prevsent>unfortunately, many nlp systems fail at out-of-domain data and struggle with the informal style of socialtext.
</prevsent>
</prevsection>
<citsent citstr=" N10-1020 ">
with spelling errors, abbreviations, uncommon acronyms, and excessive use of slang, systems that are designed for traditional corpora such as news articles may perform poorly when given difficult input such as twitter feed (ritter et al , 2010).<papid> N10-1020 </papid>recognizing the limitations of existing systems, gimpel et al  (2011) <papid> P11-2008 </papid>develop pos tagger specifically for twitter, by creating training corpus as well as devising tag set that includes partsof speech that are uniquely found in online language, such as emoticons (smilies).</citsent>
<aftsection>
<nextsent>this is an important step forward, but pos tagger tailored to twitter cannot tackle the social web as whole.
</nextsent>
<nextsent>other online communities have their own styles,slang, memes, and other idiosyncrasies, so system trained for one community may not apply to others.for example, the 140-character limit of twitter encourages abbreviations and word-dropping that may not be found in less restrictive venues.the first-person subject is often assumed in status messages?
</nextsent>
<nextsent>that one finds in twitter and face book, so the pronominal subject can be dropped, even in english (weir, 2012), leading to messages like went out?
</nextsent>
<nextsent>instead of went out.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2060">
<title id=" W12-0601.xml">unsupervised partofspeech tagging in noisy and esoteric domains with a syntactic semantic bayesian hmm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the explosion of social media in recent years has led to the need for nlp tools like part-of-speech (pos) taggers that are robust enough to handle data that is becoming increasingly noisy.?
</prevsent>
<prevsent>unfortunately, many nlp systems fail at out-of-domain data and struggle with the informal style of socialtext.
</prevsent>
</prevsection>
<citsent citstr=" P11-2008 ">
with spelling errors, abbreviations, uncommon acronyms, and excessive use of slang, systems that are designed for traditional corpora such as news articles may perform poorly when given difficult input such as twitter feed (ritter et al , 2010).<papid> N10-1020 </papid>recognizing the limitations of existing systems, gimpel et al  (2011) <papid> P11-2008 </papid>develop pos tagger specifically for twitter, by creating training corpus as well as devising tag set that includes partsof speech that are uniquely found in online language, such as emoticons (smilies).</citsent>
<aftsection>
<nextsent>this is an important step forward, but pos tagger tailored to twitter cannot tackle the social web as whole.
</nextsent>
<nextsent>other online communities have their own styles,slang, memes, and other idiosyncrasies, so system trained for one community may not apply to others.for example, the 140-character limit of twitter encourages abbreviations and word-dropping that may not be found in less restrictive venues.the first-person subject is often assumed in status messages?
</nextsent>
<nextsent>that one finds in twitter and face book, so the pronominal subject can be dropped, even in english (weir, 2012), leading to messages like went out?
</nextsent>
<nextsent>instead of went out.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2063">
<title id=" W12-0601.xml">unsupervised partofspeech tagging in noisy and esoteric domains with a syntactic semantic bayesian hmm </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for these reasons, pos parameters learned from twitter data will not necessarily fit other social data.
</prevsent>
<prevsent>in general, concerns about the limitations of domain-dependent models have motivated the useof sophisticated unsupervised methods.
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
interest in unsupervised pos induction has been revived in recent years after bayesian hmms are shown to increase accuracy by up to 14 percentage points over basic maximum-likelihood estimation (goldwater and griffiths, 2007).<papid> P07-1094 </papid></citsent>
<aftsection>
<nextsent>despite falling well short of the accuracy obtained with supervised taggers, unsupervised approaches are preferred in situations where there is no access to 1large quantities of training data in specific do main, which is increasingly common with web data.
</nextsent>
<nextsent>we therefore hope to continue improving accuracy with unsupervised approaches by introducing semantics as an additional source of information for this task.
</nextsent>
<nextsent>the ambiguities of language are amplified through social media, where new words or spellings of words are routinely invented.
</nextsent>
<nextsent>forex ample, ow?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2071">
<title id=" W12-0601.xml">unsupervised partofspeech tagging in noisy and esoteric domains with a syntactic semantic bayesian hmm </title>
<section> part-of-speech lda (poslda).  </section>
<citcontext>
<prevsection>
<prevsent>(con) ci,ziin topic models, it is generally true that common function words may overwhelm the word distributions, leading to sub optimal results thatare difficult to interpret.
</prevsent>
<prevsent>this is usually accommodated by data pre-processing (e.g. stop word removal), by backing off to background?
</prevsent>
</prevsection>
<citsent citstr=" N10-1070 ">
word models (chemudugunta et al , 2006), or by performing term re-weighting (wilson and chew, 2010).<papid> N10-1070 </papid></citsent>
<aftsection>
<nextsent>in the case of poslda, these common words are naturally captured by the functional classes.
</nextsent>
<nextsent>3.1 relations to other models.
</nextsent>
<nextsent>the idea of having multinomials for the cross products of topics and classes is related to multifaceted topic models where word tokens are associated with multiple latent variables (paul and girju, 2010; ahmed and xing, 2010).<papid> D10-1111 </papid></nextsent>
<nextsent>under such models, words can be explained by latent topic as well as second underlying variable such as the perspective or dialect of the author, and words may depend on both factors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2072">
<title id=" W12-0601.xml">unsupervised partofspeech tagging in noisy and esoteric domains with a syntactic semantic bayesian hmm </title>
<section> part-of-speech lda (poslda).  </section>
<citcontext>
<prevsection>
<prevsent>in the case of poslda, these common words are naturally captured by the functional classes.
</prevsent>
<prevsent>3.1 relations to other models.
</prevsent>
</prevsection>
<citsent citstr=" D10-1111 ">
the idea of having multinomials for the cross products of topics and classes is related to multifaceted topic models where word tokens are associated with multiple latent variables (paul and girju, 2010; ahmed and xing, 2010).<papid> D10-1111 </papid></citsent>
<aftsection>
<nextsent>under such models, words can be explained by latent topic as well as second underlying variable such as the perspective or dialect of the author, and words may depend on both factors.
</nextsent>
<nextsent>in our case, the second variable is the part-of-speech ? or functional purpose ? of the token.
</nextsent>
<nextsent>we note that poslda is generalization of many existing models.
</nextsent>
<nextsent>poslda becomes bayesian hmm when the number of topics = 1; the original lda model when the number of 3classes = 1; and the hmmlda model of griffiths et al  (2005) when the number of content word classes scon = 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2088">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the rest of the question indicates that karl malden?
</prevsent>
<prevsent>is related to as being starred?
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
by, and that san francisco is substring of a. many factoid questions explicitly express an hyponymy relation about the answer type, and also several other relations describing its context (i.e. spatial, temporal, etc.).the qa problem can be approached from several points of view, ranging from simple surface pattern matching (ravichandran and hovy, 2002), <papid> P02-1006 </papid>to automated reasoning (moldovan et al, 2007) or supercomputing (ferrucci et al, 2010).</citsent>
<aftsection>
<nextsent>in this work, we propose to use statistical machine translation (smt) for the task of factoid qa.
</nextsent>
<nextsent>under this perspective, the answer is translation of the question.
</nextsent>
<nextsent>it is not the first time that smt isused for qa tasks, several works have been using translation models to determine the answers (berger et al, 2000; cui et al, 2005; surdeanu et al, 2011).
</nextsent>
<nextsent>but to our knowledge this is the first 20approach that uses full machine translation system for generating answers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2089">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> translation models in qa.  </section>
<citcontext>
<prevsection>
<prevsent>the use of machine translation in ir is not new.berger and lafferty (1999) firstly propose probabilistic approach to ir based on methods of smt.
</prevsent>
<prevsent>under their perspective, the human user has an information need that is satisfied by an ideal?
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
theoretical document from which the user draws important query words q. this process can be mirrored by translation model: given the query q, they find the documents in the collection with words most likely to translate to q. the key ingredient is the set of translation probabilities p(q|a) from ibm model 1 (brown et al, 1993).<papid> J93-2003 </papid>in posterior work, berger et al also introduce the formulation of the qa problem in terms of smt (berger et al, 2000).</citsent>
<aftsection>
<nextsent>they estimate the likelihood that given answer containing word ai corresponds to question containing word qj . this estimation relies on an ibm model 1.the method is tested with collection of closed domain usenet and call-center questions, where each question must be paired with one of the recorded answers.
</nextsent>
<nextsent>soricut and brill (2004) <papid> N04-1008 </papid>implement similar strategy but with richer formulation and targeted to open-domain qa.</nextsent>
<nextsent>given question q, web-search engine is used to retrieve 3-sentence-long answer texts from faqpages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2090">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> translation models in qa.  </section>
<citcontext>
<prevsection>
<prevsent>theoretical document from which the user draws important query words q. this process can be mirrored by translation model: given the query q, they find the documents in the collection with words most likely to translate to q. the key ingredient is the set of translation probabilities p(q|a) from ibm model 1 (brown et al, 1993).<papid> J93-2003 </papid>in posterior work, berger et al also introduce the formulation of the qa problem in terms of smt (berger et al, 2000).</prevsent>
<prevsent>they estimate the likelihood that given answer containing word ai corresponds to question containing word qj . this estimation relies on an ibm model 1.the method is tested with collection of closed domain usenet and call-center questions, where each question must be paired with one of the recorded answers.</prevsent>
</prevsection>
<citsent citstr=" N04-1008 ">
soricut and brill (2004) <papid> N04-1008 </papid>implement similar strategy but with richer formulation and targeted to open-domain qa.</citsent>
<aftsection>
<nextsent>given question q, web-search engine is used to retrieve 3-sentence-long answer texts from faqpages.
</nextsent>
<nextsent>these texts are later ranked with the likelihood of containing the answer to q, and this likelihood is estimated via noisy-channel architecture.
</nextsent>
<nextsent>the work of murdock and croft (2005) applies the same strategy to trec data.
</nextsent>
<nextsent>they evaluate the trec 2003 passage retrieval task.in this task, the system must output single sentence containing the answer to factoid question.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2091">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> translation models in qa.  </section>
<citcontext>
<prevsection>
<prevsent>the work of murdock and croft (2005) applies the same strategy to trec data.
</prevsent>
<prevsent>they evaluate the trec 2003 passage retrieval task.in this task, the system must output single sentence containing the answer to factoid question.
</prevsent>
</prevsection>
<citsent citstr=" P07-1059 ">
murdock and croft tackle the length disparity in question-answer pairs and show that this mt-based approach outperforms traditional query likelihood techniques.riezler et al (2007) <papid> P07-1059 </papid>define the problem of answer retrieval from faq and social q/a web sites as query expansion problem.</citsent>
<aftsection>
<nextsent>smt is used to translate the original query terms to the language of the answers, thus obtaining an expanded list of terms usable in standard ir techniques.
</nextsent>
<nextsent>they also use smt to perform question paraphrasing.
</nextsent>
<nextsent>in the same context, lee et al (2008) <papid> D08-1043 </papid>study methods for improving the translation quality removing noise from the parallel corpus.smt can be also applied to sentence representations different than words.</nextsent>
<nextsent>cui et al (2005) approach the task of passage retrieval for qa with translations of dependency parsing relations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2092">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> translation models in qa.  </section>
<citcontext>
<prevsection>
<prevsent>smt is used to translate the original query terms to the language of the answers, thus obtaining an expanded list of terms usable in standard ir techniques.
</prevsent>
<prevsent>they also use smt to perform question paraphrasing.
</prevsent>
</prevsection>
<citsent citstr=" D08-1043 ">
in the same context, lee et al (2008) <papid> D08-1043 </papid>study methods for improving the translation quality removing noise from the parallel corpus.smt can be also applied to sentence representations different than words.</citsent>
<aftsection>
<nextsent>cui et al (2005) approach the task of passage retrieval for qa with translations of dependency parsing relations.
</nextsent>
<nextsent>they extract the sequences of relations that link each pair of words in the question and, using the ibm translation model 1, score their similarity to the relations extracted from the candidate passage.
</nextsent>
<nextsent>thus, an approximate relation matching score is obtained.
</nextsent>
<nextsent>surdeanu et al (2011) extend the scope of this approach by combining together the translation probabilities of words, dependency relations, and semantic roles in the context of answer searching in faq collections.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2093">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> translation models in qa.  </section>
<citcontext>
<prevsection>
<prevsent>they are really doing document retrieval and sentence retrieval rather than question answering, because every document/sentence is known to be the answer of question written in the form of an answer, and no further information extraction is necessary, they just select the best answer from given pool of answers.
</prevsent>
<prevsent>the difference with standard ir task is that these systems are not searching for relevant documents but for answer documents.
</prevsent>
</prevsection>
<citsent citstr=" P03-1003 ">
in contrast, echihabi and marcu (2003) <papid> P03-1003 </papid>introduce an smt-based method for extracting the concrete answer in factoid qa.</citsent>
<aftsection>
<nextsent>first, they use standard ir engine to retrieve candidate sentences and process them with constituent parser.
</nextsent>
<nextsent>then, an elaborated process simplifies these parse trees converting them into sequences of relevant words and/or syntactic tags.
</nextsent>
<nextsent>this process reduces the length disparity between questions and answers.
</nextsent>
<nextsent>for the answer extraction, special tag marking the position of the answer is sequentially added to all suitable positions inthe sentence, thus yielding several candidate answers for each sentence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2095">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> question-to-answer translation.  </section>
<citcontext>
<prevsection>
<prevsent>the translation model quantifies the appropriateness of each segment of being answered by a; the language model is measure of the fluency of the answer sentence and does not take into account which is the question.
</prevsent>
<prevsent>since we are interested in identifying the concrete string that answers the question and not full sentence, this probability is not as important as it is in the translation problem.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
the log-linear model (och and ney, 2002), <papid> P02-1038 </papid>ageneralisation of the original noisy-channel approach (eq.</citsent>
<aftsection>
<nextsent>1), estimates the final probability as the logarithmic sum of several terms that depend on both the question and the answer sentencea.
</nextsent>
<nextsent>using just two of the features, the model reproduces the noisy-channel approach but written in this way one can include as many features as desired at the cost of introducing the same number of free parameters.
</nextsent>
<nextsent>the model in its traditional form includes 8 terms: a(q) = a?
</nextsent>
<nextsent>= argmaxa logp (a|q) = + lm logp (a) + logpd(a,q) + lg log lex(q|a) + ld log lex(a|q) + logpt(q|a) + logpt(a|q) + ph log ph(a) + logw(a) , (2)where (a) is the language model probability, lex(q|a) and lex(a|q) are the generative and discriminative lexical translation probabilities respectively, pt(q|a) the generative translation model, pt(a|q) the discriminative one, pd(a,q)the distortion model, and ph(a) and w(a) correspond to the phrase and word penalty models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2096">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> question-to-answer translation.  </section>
<citcontext>
<prevsection>
<prevsent>westart by using this form for the answer probability and analyse the importance and validity of the terms in the experiments section.
</prevsent>
<prevsent>the ? weights, which account for the relative importance of each feature in the log-linear probabilistic model, are commonly estimated by optimising the translation performance on development set.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
for this optimisation one may use minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>where bleu (papineni et al, 2002) <papid> P02-1040 </papid>is the reference evaluation.once the weights are determined and the probabilities estimated from corpus of question answer pairs (a parallel corpus in this task), decoder uses eq.</citsent>
<aftsection>
<nextsent>2 to score the possible outputs and to find the best answer sentence given question or, in general, an n-best list of answers.
</nextsent>
<nextsent>this formulation, although possible from an abstract point of view, is not feasible in practice.
</nextsent>
<nextsent>the corpus from which probabilities are estimated is finite, and therefore new questions may not be represented.
</nextsent>
<nextsent>there is no chance that smt can generate ex nihilo the knowledge necessary to answer questions such as q1201: what planet has the strongest magnetic field of all the planets?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2097">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> question-to-answer translation.  </section>
<citcontext>
<prevsection>
<prevsent>westart by using this form for the answer probability and analyse the importance and validity of the terms in the experiments section.
</prevsent>
<prevsent>the ? weights, which account for the relative importance of each feature in the log-linear probabilistic model, are commonly estimated by optimising the translation performance on development set.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for this optimisation one may use minimum error rate training (mert) (och, 2003) <papid> P03-1021 </papid>where bleu (papineni et al, 2002) <papid> P02-1040 </papid>is the reference evaluation.once the weights are determined and the probabilities estimated from corpus of question answer pairs (a parallel corpus in this task), decoder uses eq.</citsent>
<aftsection>
<nextsent>2 to score the possible outputs and to find the best answer sentence given question or, in general, an n-best list of answers.
</nextsent>
<nextsent>this formulation, although possible from an abstract point of view, is not feasible in practice.
</nextsent>
<nextsent>the corpus from which probabilities are estimated is finite, and therefore new questions may not be represented.
</nextsent>
<nextsent>there is no chance that smt can generate ex nihilo the knowledge necessary to answer questions such as q1201: what planet has the strongest magnetic field of all the planets?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2099">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> the question answering system.  </section>
<citcontext>
<prevsection>
<prevsent>finally, each candidate is evaluated assessing the similarity of the source sentence with the n-best translations.for this assessment we use two different metrics.
</prevsent>
<prevsent>one of them is lexical metric commonly used in machine translation, bleu (papineni etal., 2002).<papid> P02-1040 </papid></prevsent>
</prevsection>
<citsent citstr=" P04-1077 ">
a smoothed version is used to evaluate the pairs at sentence level yielding the score b. the other metric is rouge (lin and och, 2004),<papid> P04-1077 </papid>here named r. we use the skip-bigram overlapping measure with maximum skip distance of 4 unigrams (rouge-s4).</citsent>
<aftsection>
<nextsent>contrary to bleu, rouge-s does not require consecutive matches but is still sensitive to word order.both bleu and rouge are well-known metrics that are useful for finding partial matchings in long strings of words.
</nextsent>
<nextsent>therefore it is an easy wayof implementing an approximated pattern matching algorithm with off-the-shelf components.although these scores can determine if sentence is candidate for asserting certain property of certain object, they do not have the powerto discriminate if these objects are the actually required by the question.
</nextsent>
<nextsent>level2 representation isvery coarse and, for example, treats all named entities of the same categories as the same word.
</nextsent>
<nextsent>thus, it is prone to introduce noise in the formof totally irrelevant answers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2100">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the number of trec evaluation from which are obtained is indicated.
</prevsent>
<prevsent>tokens vocabulary a a trainl1 97028 393978 3232 32013 trainl2 91567 373008 540 9130table 2: statistics for the 12,116 q-a pairs in the training corpus according to the annotation level.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
we use the tnt pos tagger (brants, 2000),<papid> A00-1031 </papid>wordnet (fellbaum, 1998), the yamcha chun ker (kudo and matsumoto, 2003), <papid> P03-1004 </papid>the stanfordnerc (finkel et al, 2005), <papid> P05-1045 </papid>and an in-house temporal expressions recogniser.</citsent>
<aftsection>
<nextsent>table 2 shows some statistics for the parallel corpus and the two different levels of annotation.
</nextsent>
<nextsent>from the smt point of view the corpus is small in order to estimate the translation probabilities ina reliable way but, as stated before, level2 representation diminishes the vocabulary considerably and alleviates the problem.
</nextsent>
<nextsent>5.2 smt system.
</nextsent>
<nextsent>the statistical system is state-of-the-art phrase based smt system trained on the previously introduced corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2101">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the number of trec evaluation from which are obtained is indicated.
</prevsent>
<prevsent>tokens vocabulary a a trainl1 97028 393978 3232 32013 trainl2 91567 373008 540 9130table 2: statistics for the 12,116 q-a pairs in the training corpus according to the annotation level.
</prevsent>
</prevsection>
<citsent citstr=" P03-1004 ">
we use the tnt pos tagger (brants, 2000),<papid> A00-1031 </papid>wordnet (fellbaum, 1998), the yamcha chun ker (kudo and matsumoto, 2003), <papid> P03-1004 </papid>the stanfordnerc (finkel et al, 2005), <papid> P05-1045 </papid>and an in-house temporal expressions recogniser.</citsent>
<aftsection>
<nextsent>table 2 shows some statistics for the parallel corpus and the two different levels of annotation.
</nextsent>
<nextsent>from the smt point of view the corpus is small in order to estimate the translation probabilities ina reliable way but, as stated before, level2 representation diminishes the vocabulary considerably and alleviates the problem.
</nextsent>
<nextsent>5.2 smt system.
</nextsent>
<nextsent>the statistical system is state-of-the-art phrase based smt system trained on the previously introduced corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2102">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the number of trec evaluation from which are obtained is indicated.
</prevsent>
<prevsent>tokens vocabulary a a trainl1 97028 393978 3232 32013 trainl2 91567 373008 540 9130table 2: statistics for the 12,116 q-a pairs in the training corpus according to the annotation level.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
we use the tnt pos tagger (brants, 2000),<papid> A00-1031 </papid>wordnet (fellbaum, 1998), the yamcha chun ker (kudo and matsumoto, 2003), <papid> P03-1004 </papid>the stanfordnerc (finkel et al, 2005), <papid> P05-1045 </papid>and an in-house temporal expressions recogniser.</citsent>
<aftsection>
<nextsent>table 2 shows some statistics for the parallel corpus and the two different levels of annotation.
</nextsent>
<nextsent>from the smt point of view the corpus is small in order to estimate the translation probabilities ina reliable way but, as stated before, level2 representation diminishes the vocabulary considerably and alleviates the problem.
</nextsent>
<nextsent>5.2 smt system.
</nextsent>
<nextsent>the statistical system is state-of-the-art phrase based smt system trained on the previously introduced corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2103">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the statistical system is state-of-the-art phrase based smt system trained on the previously introduced corpus.
</prevsent>
<prevsent>its development has been done using standard freely available software.the language model is estimated using interpolated kneser-ney discounting with srilm (stol cke, 2002).
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
word alignment is done with giza++ (och and ney, 2003) <papid> J03-1002 </papid>and both phrase extraction and decoding are done with the moses package (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>the model weights are optimised with moses?
</nextsent>
<nextsent>script of mert against the bleu evaluation metric.
</nextsent>
<nextsent>for the full model, we consider the language model, direct and inverse phrase probabilities, direct and inverse lexical probabilities, phrase and word penalties, and non-lexicalised reordering.
</nextsent>
<nextsent>5.3 qa system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2104">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the statistical system is state-of-the-art phrase based smt system trained on the previously introduced corpus.
</prevsent>
<prevsent>its development has been done using standard freely available software.the language model is estimated using interpolated kneser-ney discounting with srilm (stol cke, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
word alignment is done with giza++ (och and ney, 2003) <papid> J03-1002 </papid>and both phrase extraction and decoding are done with the moses package (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>the model weights are optimised with moses?
</nextsent>
<nextsent>script of mert against the bleu evaluation metric.
</nextsent>
<nextsent>for the full model, we consider the language model, direct and inverse phrase probabilities, direct and inverse lexical probabilities, phrase and word penalties, and non-lexicalised reordering.
</nextsent>
<nextsent>5.3 qa system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2107">
<title id=" W12-0103.xml">full machine translation for factoid question answering </title>
<section> discussion and conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>several other levels combining this information canbe also tested in order to find the most appropriate degree of abstraction for each kind of word.
</prevsent>
<prevsent>the development part of the smt system is adeli cate issue.
</prevsent>
</prevsection>
<citsent citstr=" N10-1080 ">
mert is currently optimising towards bleu, but the final score for ranking the answers is combination of smoothed bleu,rouge, and e. it has been shown that optimising towards the same metric used to evaluate the system is beneficial for translation, but also that bleu is one of the most robust metrics to be used (cer et al, 2010), <papid> N10-1080 </papid>so the issue has tobe investigated for the qa problem.</citsent>
<aftsection>
<nextsent>also, refining bleu and rouge for this specific problem can be useful.
</nextsent>
<nextsent>a first approximation could be an adaptation of the n-gram counting of bleu and rouge so that it is weighted by its distance tothe answer; this way sentences that differ only because of the candidate answer string would be better differentiated.
</nextsent>
<nextsent>related to this, the generation of the candidate answer strings is exhaustive; the suppression ofthe less frequent candidates could help to eliminate noise in the form of irrelevant answer sentences.
</nextsent>
<nextsent>besides, the system correlates these answer strings with the expected answer type of the question (coincidence measured with e).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2109">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we discuss how the dataset was created, andhow it can be used in generate-and-rank abs tractive sentence compressors.
</prevsent>
<prevsent>we also report experimental results with novel abstrac tive sentence compressor that uses the dataset.
</prevsent>
</prevsection>
<citsent citstr=" A00-1043 ">
sentence compression is the task of producing ashorter form of grammatical source (input) sentence, so that the new form will still be grammatical and it will retain the most important information of the source (jing, 2000).<papid> A00-1043 </papid></citsent>
<aftsection>
<nextsent>sentence compression is useful in many applications, such as text summarization (madnani et al , 2007) and subtitle generation(corston-oliver, 2001).
</nextsent>
<nextsent>methods for sentence compression can be divided in two categories: extractive methods produce compress ions by only removing words, whereas abs tractive methods may additionally rephrase expressions of the source sentence.
</nextsent>
<nextsent>extractive methods are generally simpler and have dominated the sentence compression literature (jing, 2000; <papid> A00-1043 </papid>knight and marcu, 2002; mcdonald, 2006; <papid> E06-1038 </papid>cohn and lapata, 2007; <papid> D07-1008 </papid>clarke and lapata, 2008; cohn and lapata, 2009; nomoto, 2009; <papid> D09-1041 </papid>galanis and androutsopoulos, 2010; <papid> N10-1131 </papid>yamangil and shieber,2010).<papid> P10-1096 </papid></nextsent>
<nextsent>abs tractive methods, however, can in principle produce shorter compress ions that convey thesame information as longer extractive ones.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2111">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentence compression is useful in many applications, such as text summarization (madnani et al , 2007) and subtitle generation(corston-oliver, 2001).
</prevsent>
<prevsent>methods for sentence compression can be divided in two categories: extractive methods produce compress ions by only removing words, whereas abs tractive methods may additionally rephrase expressions of the source sentence.
</prevsent>
</prevsection>
<citsent citstr=" E06-1038 ">
extractive methods are generally simpler and have dominated the sentence compression literature (jing, 2000; <papid> A00-1043 </papid>knight and marcu, 2002; mcdonald, 2006; <papid> E06-1038 </papid>cohn and lapata, 2007; <papid> D07-1008 </papid>clarke and lapata, 2008; cohn and lapata, 2009; nomoto, 2009; <papid> D09-1041 </papid>galanis and androutsopoulos, 2010; <papid> N10-1131 </papid>yamangil and shieber,2010).<papid> P10-1096 </papid></citsent>
<aftsection>
<nextsent>abs tractive methods, however, can in principle produce shorter compress ions that convey thesame information as longer extractive ones.
</nextsent>
<nextsent>furthermore, humans produce mostly abs tractive compres sions (cohn and lapata, 2008); <papid> C08-1018 </papid>hence, abs tractive compressors may generate more natural outputs.</nextsent>
<nextsent>when evaluating extractive methods, it suffice sto have single human gold extractive compression per source sentence, because it has been shown that measuring the similarity (as f1-measure of de pendencies) between the dependency tree of the gold compression and that of machine-generated compression correlates well with human judgements (riezler et al , 2003; <papid> N03-1026 </papid>clarke and lapata, 2006<papid> P06-2019 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2112">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentence compression is useful in many applications, such as text summarization (madnani et al , 2007) and subtitle generation(corston-oliver, 2001).
</prevsent>
<prevsent>methods for sentence compression can be divided in two categories: extractive methods produce compress ions by only removing words, whereas abs tractive methods may additionally rephrase expressions of the source sentence.
</prevsent>
</prevsection>
<citsent citstr=" D07-1008 ">
extractive methods are generally simpler and have dominated the sentence compression literature (jing, 2000; <papid> A00-1043 </papid>knight and marcu, 2002; mcdonald, 2006; <papid> E06-1038 </papid>cohn and lapata, 2007; <papid> D07-1008 </papid>clarke and lapata, 2008; cohn and lapata, 2009; nomoto, 2009; <papid> D09-1041 </papid>galanis and androutsopoulos, 2010; <papid> N10-1131 </papid>yamangil and shieber,2010).<papid> P10-1096 </papid></citsent>
<aftsection>
<nextsent>abs tractive methods, however, can in principle produce shorter compress ions that convey thesame information as longer extractive ones.
</nextsent>
<nextsent>furthermore, humans produce mostly abs tractive compres sions (cohn and lapata, 2008); <papid> C08-1018 </papid>hence, abs tractive compressors may generate more natural outputs.</nextsent>
<nextsent>when evaluating extractive methods, it suffice sto have single human gold extractive compression per source sentence, because it has been shown that measuring the similarity (as f1-measure of de pendencies) between the dependency tree of the gold compression and that of machine-generated compression correlates well with human judgements (riezler et al , 2003; <papid> N03-1026 </papid>clarke and lapata, 2006<papid> P06-2019 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2113">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentence compression is useful in many applications, such as text summarization (madnani et al , 2007) and subtitle generation(corston-oliver, 2001).
</prevsent>
<prevsent>methods for sentence compression can be divided in two categories: extractive methods produce compress ions by only removing words, whereas abs tractive methods may additionally rephrase expressions of the source sentence.
</prevsent>
</prevsection>
<citsent citstr=" D09-1041 ">
extractive methods are generally simpler and have dominated the sentence compression literature (jing, 2000; <papid> A00-1043 </papid>knight and marcu, 2002; mcdonald, 2006; <papid> E06-1038 </papid>cohn and lapata, 2007; <papid> D07-1008 </papid>clarke and lapata, 2008; cohn and lapata, 2009; nomoto, 2009; <papid> D09-1041 </papid>galanis and androutsopoulos, 2010; <papid> N10-1131 </papid>yamangil and shieber,2010).<papid> P10-1096 </papid></citsent>
<aftsection>
<nextsent>abs tractive methods, however, can in principle produce shorter compress ions that convey thesame information as longer extractive ones.
</nextsent>
<nextsent>furthermore, humans produce mostly abs tractive compres sions (cohn and lapata, 2008); <papid> C08-1018 </papid>hence, abs tractive compressors may generate more natural outputs.</nextsent>
<nextsent>when evaluating extractive methods, it suffice sto have single human gold extractive compression per source sentence, because it has been shown that measuring the similarity (as f1-measure of de pendencies) between the dependency tree of the gold compression and that of machine-generated compression correlates well with human judgements (riezler et al , 2003; <papid> N03-1026 </papid>clarke and lapata, 2006<papid> P06-2019 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2114">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentence compression is useful in many applications, such as text summarization (madnani et al , 2007) and subtitle generation(corston-oliver, 2001).
</prevsent>
<prevsent>methods for sentence compression can be divided in two categories: extractive methods produce compress ions by only removing words, whereas abs tractive methods may additionally rephrase expressions of the source sentence.
</prevsent>
</prevsection>
<citsent citstr=" N10-1131 ">
extractive methods are generally simpler and have dominated the sentence compression literature (jing, 2000; <papid> A00-1043 </papid>knight and marcu, 2002; mcdonald, 2006; <papid> E06-1038 </papid>cohn and lapata, 2007; <papid> D07-1008 </papid>clarke and lapata, 2008; cohn and lapata, 2009; nomoto, 2009; <papid> D09-1041 </papid>galanis and androutsopoulos, 2010; <papid> N10-1131 </papid>yamangil and shieber,2010).<papid> P10-1096 </papid></citsent>
<aftsection>
<nextsent>abs tractive methods, however, can in principle produce shorter compress ions that convey thesame information as longer extractive ones.
</nextsent>
<nextsent>furthermore, humans produce mostly abs tractive compres sions (cohn and lapata, 2008); <papid> C08-1018 </papid>hence, abs tractive compressors may generate more natural outputs.</nextsent>
<nextsent>when evaluating extractive methods, it suffice sto have single human gold extractive compression per source sentence, because it has been shown that measuring the similarity (as f1-measure of de pendencies) between the dependency tree of the gold compression and that of machine-generated compression correlates well with human judgements (riezler et al , 2003; <papid> N03-1026 </papid>clarke and lapata, 2006<papid> P06-2019 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2115">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>sentence compression is useful in many applications, such as text summarization (madnani et al , 2007) and subtitle generation(corston-oliver, 2001).
</prevsent>
<prevsent>methods for sentence compression can be divided in two categories: extractive methods produce compress ions by only removing words, whereas abs tractive methods may additionally rephrase expressions of the source sentence.
</prevsent>
</prevsection>
<citsent citstr=" P10-1096 ">
extractive methods are generally simpler and have dominated the sentence compression literature (jing, 2000; <papid> A00-1043 </papid>knight and marcu, 2002; mcdonald, 2006; <papid> E06-1038 </papid>cohn and lapata, 2007; <papid> D07-1008 </papid>clarke and lapata, 2008; cohn and lapata, 2009; nomoto, 2009; <papid> D09-1041 </papid>galanis and androutsopoulos, 2010; <papid> N10-1131 </papid>yamangil and shieber,2010).<papid> P10-1096 </papid></citsent>
<aftsection>
<nextsent>abs tractive methods, however, can in principle produce shorter compress ions that convey thesame information as longer extractive ones.
</nextsent>
<nextsent>furthermore, humans produce mostly abs tractive compres sions (cohn and lapata, 2008); <papid> C08-1018 </papid>hence, abs tractive compressors may generate more natural outputs.</nextsent>
<nextsent>when evaluating extractive methods, it suffice sto have single human gold extractive compression per source sentence, because it has been shown that measuring the similarity (as f1-measure of de pendencies) between the dependency tree of the gold compression and that of machine-generated compression correlates well with human judgements (riezler et al , 2003; <papid> N03-1026 </papid>clarke and lapata, 2006<papid> P06-2019 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2116">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>extractive methods are generally simpler and have dominated the sentence compression literature (jing, 2000; <papid> A00-1043 </papid>knight and marcu, 2002; mcdonald, 2006; <papid> E06-1038 </papid>cohn and lapata, 2007; <papid> D07-1008 </papid>clarke and lapata, 2008; cohn and lapata, 2009; nomoto, 2009; <papid> D09-1041 </papid>galanis and androutsopoulos, 2010; <papid> N10-1131 </papid>yamangil and shieber,2010).<papid> P10-1096 </papid></prevsent>
<prevsent>abs tractive methods, however, can in principle produce shorter compress ions that convey thesame information as longer extractive ones.</prevsent>
</prevsection>
<citsent citstr=" C08-1018 ">
furthermore, humans produce mostly abs tractive compres sions (cohn and lapata, 2008); <papid> C08-1018 </papid>hence, abs tractive compressors may generate more natural outputs.</citsent>
<aftsection>
<nextsent>when evaluating extractive methods, it suffice sto have single human gold extractive compression per source sentence, because it has been shown that measuring the similarity (as f1-measure of de pendencies) between the dependency tree of the gold compression and that of machine-generated compression correlates well with human judgements (riezler et al , 2003; <papid> N03-1026 </papid>clarke and lapata, 2006<papid> P06-2019 </papid>a).</nextsent>
<nextsent>with abs tractive methods, however, there is much wider range of acceptable abs tractive compress ions of each source sentence, to the extent that single gold compression per source is insufficient.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2117">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>abs tractive methods, however, can in principle produce shorter compress ions that convey thesame information as longer extractive ones.
</prevsent>
<prevsent>furthermore, humans produce mostly abs tractive compres sions (cohn and lapata, 2008); <papid> C08-1018 </papid>hence, abs tractive compressors may generate more natural outputs.</prevsent>
</prevsection>
<citsent citstr=" N03-1026 ">
when evaluating extractive methods, it suffice sto have single human gold extractive compression per source sentence, because it has been shown that measuring the similarity (as f1-measure of de pendencies) between the dependency tree of the gold compression and that of machine-generated compression correlates well with human judgements (riezler et al , 2003; <papid> N03-1026 </papid>clarke and lapata, 2006<papid> P06-2019 </papid>a).</citsent>
<aftsection>
<nextsent>with abs tractive methods, however, there is much wider range of acceptable abs tractive compress ions of each source sentence, to the extent that single gold compression per source is insufficient.
</nextsent>
<nextsent>indeed,to the best of our knowledge no measure to compare machine-generated abs tractive compression to single human gold compression has been shown to correlate well with human judgements.
</nextsent>
<nextsent>one might attempt to provide multiple human gold abs tractive compress ions per source sentence and employ measures from machine translation, for example bleu (papineni et al , 2002), <papid> P02-1040 </papid>to compare each machine-generated compression to all the corresponding gold ones.</nextsent>
<nextsent>however, large number of gold compress ions would be necessary to capture all(or at least most) of the acceptable shorter rephras 1 ings of the source sentences, and it is questionable if human judges could provide (or even think of) all the acceptable rephrasings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2118">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>abs tractive methods, however, can in principle produce shorter compress ions that convey thesame information as longer extractive ones.
</prevsent>
<prevsent>furthermore, humans produce mostly abs tractive compres sions (cohn and lapata, 2008); <papid> C08-1018 </papid>hence, abs tractive compressors may generate more natural outputs.</prevsent>
</prevsection>
<citsent citstr=" P06-2019 ">
when evaluating extractive methods, it suffice sto have single human gold extractive compression per source sentence, because it has been shown that measuring the similarity (as f1-measure of de pendencies) between the dependency tree of the gold compression and that of machine-generated compression correlates well with human judgements (riezler et al , 2003; <papid> N03-1026 </papid>clarke and lapata, 2006<papid> P06-2019 </papid>a).</citsent>
<aftsection>
<nextsent>with abs tractive methods, however, there is much wider range of acceptable abs tractive compress ions of each source sentence, to the extent that single gold compression per source is insufficient.
</nextsent>
<nextsent>indeed,to the best of our knowledge no measure to compare machine-generated abs tractive compression to single human gold compression has been shown to correlate well with human judgements.
</nextsent>
<nextsent>one might attempt to provide multiple human gold abs tractive compress ions per source sentence and employ measures from machine translation, for example bleu (papineni et al , 2002), <papid> P02-1040 </papid>to compare each machine-generated compression to all the corresponding gold ones.</nextsent>
<nextsent>however, large number of gold compress ions would be necessary to capture all(or at least most) of the acceptable shorter rephras 1 ings of the source sentences, and it is questionable if human judges could provide (or even think of) all the acceptable rephrasings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2120">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with abs tractive methods, however, there is much wider range of acceptable abs tractive compress ions of each source sentence, to the extent that single gold compression per source is insufficient.
</prevsent>
<prevsent>indeed,to the best of our knowledge no measure to compare machine-generated abs tractive compression to single human gold compression has been shown to correlate well with human judgements.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
one might attempt to provide multiple human gold abs tractive compress ions per source sentence and employ measures from machine translation, for example bleu (papineni et al , 2002), <papid> P02-1040 </papid>to compare each machine-generated compression to all the corresponding gold ones.</citsent>
<aftsection>
<nextsent>however, large number of gold compress ions would be necessary to capture all(or at least most) of the acceptable shorter rephras 1 ings of the source sentences, and it is questionable if human judges could provide (or even think of) all the acceptable rephrasings.
</nextsent>
<nextsent>in machine translation, n-gram-based evaluation measures like bleu have been criticized exactly because they cannot cope sufficiently well with paraphrases (callison-burch et al , 2006), which play central role in abs tractive sentence compression (zhao et al , 2009<papid> P09-1094 </papid>a).1 although it is difficult to construct datasets forend-to-end automatic evaluation of abs tractive sentence compression methods, it is possible to construct datasets to evaluate the ranking components of generate-and-rank abs tractive sentence compressors, i.e., compressors that first generate large setof candidate abs tractive (and possibly also extrac tive) compress ions of the source and then rank them to select the best one.</nextsent>
<nextsent>in previous work (galanis and androutsopoulos, 2010), <papid> N10-1131 </papid>we presented generate and-rank extractive sentence compressor, hereafter called ga-extr, which achieved state-of-the art re sults.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2121">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one might attempt to provide multiple human gold abs tractive compress ions per source sentence and employ measures from machine translation, for example bleu (papineni et al , 2002), <papid> P02-1040 </papid>to compare each machine-generated compression to all the corresponding gold ones.</prevsent>
<prevsent>however, large number of gold compress ions would be necessary to capture all(or at least most) of the acceptable shorter rephras 1 ings of the source sentences, and it is questionable if human judges could provide (or even think of) all the acceptable rephrasings.</prevsent>
</prevsection>
<citsent citstr=" P09-1094 ">
in machine translation, n-gram-based evaluation measures like bleu have been criticized exactly because they cannot cope sufficiently well with paraphrases (callison-burch et al , 2006), which play central role in abs tractive sentence compression (zhao et al , 2009<papid> P09-1094 </papid>a).1 although it is difficult to construct datasets forend-to-end automatic evaluation of abs tractive sentence compression methods, it is possible to construct datasets to evaluate the ranking components of generate-and-rank abs tractive sentence compressors, i.e., compressors that first generate large setof candidate abs tractive (and possibly also extrac tive) compress ions of the source and then rank them to select the best one.</citsent>
<aftsection>
<nextsent>in previous work (galanis and androutsopoulos, 2010), <papid> N10-1131 </papid>we presented generate and-rank extractive sentence compressor, hereafter called ga-extr, which achieved state-of-the art re sults.</nextsent>
<nextsent>we aim to construct similar abs tractive generate-and-rank sentence compressor.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2126">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>each pair (source and candidate compression) was then scored by human judge for grammaticality and meaningpreservation.
</prevsent>
<prevsent>we discuss how the dataset was constructed and how we established upper and lower performance boundaries for ranking components of compressors that may use it.
</prevsent>
</prevsection>
<citsent citstr=" W06-1610 ">
we also present the1ways to extend n-gram measures to account for paraphrases have been proposed (zhou et al , 2006; <papid> W06-1610 </papid>kauchak and barzilay, 2006; <papid> N06-1058 </papid>pado?</citsent>
<aftsection>
<nextsent>et al , 2009), but they require accurate paraphrase recognizers (androutsopoulos and malakasiotis, 2010), which are not yet available; or they assume that the same paraphrase generation resources (madnani and dorr, 2010), <papid> J10-3003 </papid>for example paraphrasing rules, that some abstractivesentence compressors (including ours) use always produce acceptable paraphrases, which is not the case as discussed below.</nextsent>
<nextsent>2the new dataset and ga-extr are freely available from http://nlp.cs.aueb.gr/software.html.current version of our abs tractive sentence compressor, and we discuss how its ranking component was improved by performing experiments on the dataset.section 2 below summarizes prior work on ab str active sentence compression.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2127">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>each pair (source and candidate compression) was then scored by human judge for grammaticality and meaningpreservation.
</prevsent>
<prevsent>we discuss how the dataset was constructed and how we established upper and lower performance boundaries for ranking components of compressors that may use it.
</prevsent>
</prevsection>
<citsent citstr=" N06-1058 ">
we also present the1ways to extend n-gram measures to account for paraphrases have been proposed (zhou et al , 2006; <papid> W06-1610 </papid>kauchak and barzilay, 2006; <papid> N06-1058 </papid>pado?</citsent>
<aftsection>
<nextsent>et al , 2009), but they require accurate paraphrase recognizers (androutsopoulos and malakasiotis, 2010), which are not yet available; or they assume that the same paraphrase generation resources (madnani and dorr, 2010), <papid> J10-3003 </papid>for example paraphrasing rules, that some abstractivesentence compressors (including ours) use always produce acceptable paraphrases, which is not the case as discussed below.</nextsent>
<nextsent>2the new dataset and ga-extr are freely available from http://nlp.cs.aueb.gr/software.html.current version of our abs tractive sentence compressor, and we discuss how its ranking component was improved by performing experiments on the dataset.section 2 below summarizes prior work on ab str active sentence compression.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2128">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we discuss how the dataset was constructed and how we established upper and lower performance boundaries for ranking components of compressors that may use it.
</prevsent>
<prevsent>we also present the1ways to extend n-gram measures to account for paraphrases have been proposed (zhou et al , 2006; <papid> W06-1610 </papid>kauchak and barzilay, 2006; <papid> N06-1058 </papid>pado?</prevsent>
</prevsection>
<citsent citstr=" J10-3003 ">
et al , 2009), but they require accurate paraphrase recognizers (androutsopoulos and malakasiotis, 2010), which are not yet available; or they assume that the same paraphrase generation resources (madnani and dorr, 2010), <papid> J10-3003 </papid>for example paraphrasing rules, that some abstractivesentence compressors (including ours) use always produce acceptable paraphrases, which is not the case as discussed below.</citsent>
<aftsection>
<nextsent>2the new dataset and ga-extr are freely available from http://nlp.cs.aueb.gr/software.html.current version of our abs tractive sentence compressor, and we discuss how its ranking component was improved by performing experiments on the dataset.section 2 below summarizes prior work on ab str active sentence compression.
</nextsent>
<nextsent>section 3 discusses the dataset we constructed.
</nextsent>
<nextsent>section 4 describes our abs tractive sentence compressor.
</nextsent>
<nextsent>section 5 presents our experimental results, and section 6 concludes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2136">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> prior work on abs tractive compression.  </section>
<citcontext>
<prevsection>
<prevsent>that was identical to the input.
</prevsent>
<prevsent>2 is the author of ? ?
</prevsent>
</prevsection>
<citsent citstr=" P08-1116 ">
x wrote ?) obtained from parallel and comparable corpora (zhao et al , 2008).<papid> P08-1116 </papid></citsent>
<aftsection>
<nextsent>the decoder uses log-linear objective function, the weights of which are estimated with minimum error rate training approach (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>the objective function combines language model, paraphrase model (combining the quality scores of the paraphrasing rules that turn the source into the candidate paraphrase), and task-specific model; in thecase of sentence compression, the latter model rewards shorter candidate paraphrases.we note that zhao et al method (2009a) is intended to produce paraphrases, even when configured to prefer shorter paraphrases, i.e., the compress ions are still intended to convey the same information as the source sentences.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2137">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> prior work on abs tractive compression.  </section>
<citcontext>
<prevsection>
<prevsent>2 is the author of ? ?
</prevsent>
<prevsent>x wrote ?) obtained from parallel and comparable corpora (zhao et al , 2008).<papid> P08-1116 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the decoder uses log-linear objective function, the weights of which are estimated with minimum error rate training approach (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>the objective function combines language model, paraphrase model (combining the quality scores of the paraphrasing rules that turn the source into the candidate paraphrase), and task-specific model; in thecase of sentence compression, the latter model rewards shorter candidate paraphrases.we note that zhao et al method (2009a) is intended to produce paraphrases, even when configured to prefer shorter paraphrases, i.e., the compress ions are still intended to convey the same information as the source sentences.
</nextsent>
<nextsent>by contrast, most sentence compression methods (both extractive and ab str active, including ours) are expected to retain onlythe most important information of the source sentence, in order to achieve better compression rates.
</nextsent>
<nextsent>hence, zhao et al sentence compression task is not the same as the task we are concerned with, and the compress ions we aim for are significantly shorter.
</nextsent>
<nextsent>to construct the new dataset, we used source sentences from the 570 pairs of cohn and lapata (section 2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2146">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> the new dataset.  </section>
<citcontext>
<prevsection>
<prevsent>compress ions from source sentence (si).
</prevsent>
<prevsent>likely to be paraphrases and, hence, can be treated as paraphrasing rule 1 ? 2.
</prevsent>
</prevsection>
<citsent citstr=" P07-1059 ">
this pivoting was used, for example, by bannard and callison-burch (2005), and it underlies several other paraphrase extraction methods (riezler et al , 2007; <papid> P07-1059 </papid>callison burch, 2008; kok and brockett, 2010).<papid> N10-1017 </papid></citsent>
<aftsection>
<nextsent>zhao et al .
</nextsent>
<nextsent>(2009b) provide approximately one million rules, but we use only approximately half of them, because we use only rules that can shorten sentence, and only in the direction that shortens the sentence.from each extractive candidate eij , we produced abs tractive candidates aij.1, aij.2, . . .
</nextsent>
<nextsent>, aij.mij (figure 1) by applying single (each time different) applicable paraphrasing rule to eij . from each of the resulting abs tractive candidates aij.l, we produced further abs tractive candidatesaij.l.1, aij.l.2, . . .
</nextsent>
<nextsent>, aij.l.mij.l by applying again single (each time different) rule.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2147">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> the new dataset.  </section>
<citcontext>
<prevsection>
<prevsent>compress ions from source sentence (si).
</prevsent>
<prevsent>likely to be paraphrases and, hence, can be treated as paraphrasing rule 1 ? 2.
</prevsent>
</prevsection>
<citsent citstr=" N10-1017 ">
this pivoting was used, for example, by bannard and callison-burch (2005), and it underlies several other paraphrase extraction methods (riezler et al , 2007; <papid> P07-1059 </papid>callison burch, 2008; kok and brockett, 2010).<papid> N10-1017 </papid></citsent>
<aftsection>
<nextsent>zhao et al .
</nextsent>
<nextsent>(2009b) provide approximately one million rules, but we use only approximately half of them, because we use only rules that can shorten sentence, and only in the direction that shortens the sentence.from each extractive candidate eij , we produced abs tractive candidates aij.1, aij.2, . . .
</nextsent>
<nextsent>, aij.mij (figure 1) by applying single (each time different) applicable paraphrasing rule to eij . from each of the resulting abs tractive candidates aij.l, we produced further abs tractive candidatesaij.l.1, aij.l.2, . . .
</nextsent>
<nextsent>, aij.l.mij.l by applying again single (each time different) rule.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2156">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> the new dataset.  </section>
<citcontext>
<prevsection>
<prevsent>5) are less frequent than higher scores (610), but this is not surprising given that we selected pairs whose cij had high language model scores, that we used the kmax extractive compress ions of eachsi that ga-extr considered best, and that we assigned higher preference to applying paraphrasing rules with higher scores.
</prevsent>
<prevsent>we note, however, that applying paraphrasing rule does not necessarily preserve neither grammaticality nor meaning, even if the rule has high score.
</prevsent>
</prevsection>
<citsent citstr=" P08-1078 ">
szpektor et al  (2008) <papid> P08-1078 </papid>point out that, for example, rule like acquire ??</citsent>
<aftsection>
<nextsent>x buy ? may work well in many contexts, butnot in children acquire language quickly?.
</nextsent>
<nextsent>similarly, charged with?
</nextsent>
<nextsent>x accused of?
</nextsent>
<nextsent>should not be applied to sentences about batteries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2159">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> our abs tractive compressor.  </section>
<citcontext>
<prevsection>
<prevsent>i,j pmi(wi, wj)in our second svr-based ranking component, svr pmi, we compute pmi(si), pmi(e), and pmi(cij), and we include them as three additional features; otherwise svr-pmi is identical to svr-base.
</prevsent>
<prevsent>14we used texts from tipster and aquaint, total of 953 million tokens, to estimate pmi(w1, w2).15a problem with pmi is that two frequent and completely dependent words receive lower scores than two other, less frequent completely dependent words (manning and schutze, 2000).
</prevsent>
</prevsection>
<citsent citstr=" P05-2003 ">
pecina (2005), <papid> P05-2003 </papid>however, found pmi to be the best collocation extraction measure; and newman et al  (2010) <papid> N10-1012 </papid>found it to be the best measure of topical coherence?</citsent>
<aftsection>
<nextsent>for sets of words.
</nextsent>
<nextsent>7 4.4 additional lda-based features.
</nextsent>
<nextsent>our third svr-based ranking component includes features from latent dirichlet allocation (lda) model (blei et al , 2003).
</nextsent>
<nextsent>roughly speaking, lda models assume that each document of |d| words w1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2160">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> our abs tractive compressor.  </section>
<citcontext>
<prevsection>
<prevsent>i,j pmi(wi, wj)in our second svr-based ranking component, svr pmi, we compute pmi(si), pmi(e), and pmi(cij), and we include them as three additional features; otherwise svr-pmi is identical to svr-base.
</prevsent>
<prevsent>14we used texts from tipster and aquaint, total of 953 million tokens, to estimate pmi(w1, w2).15a problem with pmi is that two frequent and completely dependent words receive lower scores than two other, less frequent completely dependent words (manning and schutze, 2000).
</prevsent>
</prevsection>
<citsent citstr=" N10-1012 ">
pecina (2005), <papid> P05-2003 </papid>however, found pmi to be the best collocation extraction measure; and newman et al  (2010) <papid> N10-1012 </papid>found it to be the best measure of topical coherence?</citsent>
<aftsection>
<nextsent>for sets of words.
</nextsent>
<nextsent>7 4.4 additional lda-based features.
</nextsent>
<nextsent>our third svr-based ranking component includes features from latent dirichlet allocation (lda) model (blei et al , 2003).
</nextsent>
<nextsent>roughly speaking, lda models assume that each document of |d| words w1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2161">
<title id=" W11-2701.xml">a new sentence compression dataset and its use in an abs tractive generateandrank sentence compressor </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>table 3: examples of good (upper five) and bad (lower three) compress ions generated by our abs tractive compressor.
</prevsent>
<prevsent>rules.
</prevsent>
</prevsection>
<citsent citstr=" C10-1149 ">
an approach of this kind has been proposed for sentence paraphrasing (zhao et al , 2010).<papid> C10-1149 </papid>the right diagram of figure 2 shows how the performance of svr-pmi-lda is affected when using 33% or 63% of the training si, ci?</citsent>
<aftsection>
<nextsent>pairs.
</nextsent>
<nextsent>as more examples are used, the performance improves, suggesting that better results could be obtained by using more training data.
</nextsent>
<nextsent>finally, table 3 shows examples of good and bad compress ions the abs tractive compressor produced with svr-pmi-lda.
</nextsent>
<nextsent>we presented new dataset that can be used to train and evaluate the ranking components of generate and-rank abs tractive sentence compressors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2165">
<title id=" W12-0603.xml">towards scalable speech act recognition in twitter tackling insufficient training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>then we report and discuss the results of our experiments in section 5.
</prevsent>
<prevsent>finally, section 6 concludes the paper and outlines future directions.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
the automatic recognition of speech act, also known as dialogue act?, has attracted sustained interest in computational linguistics and speech technology for over decade (searle 1975; stolcke et al  2000).<papid> J00-3003 </papid></citsent>
<aftsection>
<nextsent>a few annotated corpora such as switchboard-damsl (jurafsky et al  1997) and meeting recorder dialog act (dhillon et al  2004) are widely used, with data transcribed from telephone or face-to-face conversation.
</nextsent>
<nextsent>prior to the flourish of microblogging services such as twitter, speech act recognition has been extended to electronic media such as email and discussion forum (cohen et al  2004; <papid> W04-3240 </papid>feng et al  2006) <papid> N06-1027 </papid>in order to study the behavior of email or message senders.</nextsent>
<nextsent>the annotated corpora for ordinary verbal communications and the methods developed for email, or discussion forum cannot be directly used for our task because twitter text has distinctive net speak style that is situated between speech and text but resembles neither (crystal 2006, 2011).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2166">
<title id=" W12-0603.xml">towards scalable speech act recognition in twitter tackling insufficient training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the automatic recognition of speech act, also known as dialogue act?, has attracted sustained interest in computational linguistics and speech technology for over decade (searle 1975; stolcke et al  2000).<papid> J00-3003 </papid></prevsent>
<prevsent>a few annotated corpora such as switchboard-damsl (jurafsky et al  1997) and meeting recorder dialog act (dhillon et al  2004) are widely used, with data transcribed from telephone or face-to-face conversation.</prevsent>
</prevsection>
<citsent citstr=" W04-3240 ">
prior to the flourish of microblogging services such as twitter, speech act recognition has been extended to electronic media such as email and discussion forum (cohen et al  2004; <papid> W04-3240 </papid>feng et al  2006) <papid> N06-1027 </papid>in order to study the behavior of email or message senders.</citsent>
<aftsection>
<nextsent>the annotated corpora for ordinary verbal communications and the methods developed for email, or discussion forum cannot be directly used for our task because twitter text has distinctive net speak style that is situated between speech and text but resembles neither (crystal 2006, 2011).
</nextsent>
<nextsent>compared with email or forum post, it is rife with linguistic noises such as spelling mistakes, random coin ages, mixed use of letters and symbols.
</nextsent>
<nextsent>speech act recognition in twitter is fairly new task.
</nextsent>
<nextsent>in our pioneering work (zhang et al  2011), we show that twitter text normalization is unnecessary and even counterproductive for this task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2167">
<title id=" W12-0603.xml">towards scalable speech act recognition in twitter tackling insufficient training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the automatic recognition of speech act, also known as dialogue act?, has attracted sustained interest in computational linguistics and speech technology for over decade (searle 1975; stolcke et al  2000).<papid> J00-3003 </papid></prevsent>
<prevsent>a few annotated corpora such as switchboard-damsl (jurafsky et al  1997) and meeting recorder dialog act (dhillon et al  2004) are widely used, with data transcribed from telephone or face-to-face conversation.</prevsent>
</prevsection>
<citsent citstr=" N06-1027 ">
prior to the flourish of microblogging services such as twitter, speech act recognition has been extended to electronic media such as email and discussion forum (cohen et al  2004; <papid> W04-3240 </papid>feng et al  2006) <papid> N06-1027 </papid>in order to study the behavior of email or message senders.</citsent>
<aftsection>
<nextsent>the annotated corpora for ordinary verbal communications and the methods developed for email, or discussion forum cannot be directly used for our task because twitter text has distinctive net speak style that is situated between speech and text but resembles neither (crystal 2006, 2011).
</nextsent>
<nextsent>compared with email or forum post, it is rife with linguistic noises such as spelling mistakes, random coin ages, mixed use of letters and symbols.
</nextsent>
<nextsent>speech act recognition in twitter is fairly new task.
</nextsent>
<nextsent>in our pioneering work (zhang et al  2011), we show that twitter text normalization is unnecessary and even counterproductive for this task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2168">
<title id=" W12-0603.xml">towards scalable speech act recognition in twitter tackling insufficient training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>19 as in many practical applications, sufficient annotated data are hard to obtain.
</prevsent>
<prevsent>therefore, unsupervised and semi-supervised learning methods are actively pursued.
</prevsent>
</prevsection>
<citsent citstr=" P07-1125 ">
while unsupervised sentence classification is rule-based and domain-dependent (deshpande et al  2010), semi-supervised methods that both alleviate the data deficiency problem and leverage the power of state-of-the-art classifiers hold more promises for different domains (medlock and briscoe 2007; <papid> P07-1125 </papid>erkan et al  2007).<papid> D07-1024 </papid></citsent>
<aftsection>
<nextsent>in the machine learning literature, classic semi-supervised learning scheme is proposed by yarowsky (1995), <papid> P95-1026 </papid>which is classical self teaching process that makes no use of labeled data before they are classified.</nextsent>
<nextsent>more theoretical analyses are made by (culp and michailidis 2007) and (haffari and sarkar 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2169">
<title id=" W12-0603.xml">towards scalable speech act recognition in twitter tackling insufficient training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>19 as in many practical applications, sufficient annotated data are hard to obtain.
</prevsent>
<prevsent>therefore, unsupervised and semi-supervised learning methods are actively pursued.
</prevsent>
</prevsection>
<citsent citstr=" D07-1024 ">
while unsupervised sentence classification is rule-based and domain-dependent (deshpande et al  2010), semi-supervised methods that both alleviate the data deficiency problem and leverage the power of state-of-the-art classifiers hold more promises for different domains (medlock and briscoe 2007; <papid> P07-1125 </papid>erkan et al  2007).<papid> D07-1024 </papid></citsent>
<aftsection>
<nextsent>in the machine learning literature, classic semi-supervised learning scheme is proposed by yarowsky (1995), <papid> P95-1026 </papid>which is classical self teaching process that makes no use of labeled data before they are classified.</nextsent>
<nextsent>more theoretical analyses are made by (culp and michailidis 2007) and (haffari and sarkar 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2170">
<title id=" W12-0603.xml">towards scalable speech act recognition in twitter tackling insufficient training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, unsupervised and semi-supervised learning methods are actively pursued.
</prevsent>
<prevsent>while unsupervised sentence classification is rule-based and domain-dependent (deshpande et al  2010), semi-supervised methods that both alleviate the data deficiency problem and leverage the power of state-of-the-art classifiers hold more promises for different domains (medlock and briscoe 2007; <papid> P07-1125 </papid>erkan et al  2007).<papid> D07-1024 </papid></prevsent>
</prevsection>
<citsent citstr=" P95-1026 ">
in the machine learning literature, classic semi-supervised learning scheme is proposed by yarowsky (1995), <papid> P95-1026 </papid>which is classical self teaching process that makes no use of labeled data before they are classified.</citsent>
<aftsection>
<nextsent>more theoretical analyses are made by (culp and michailidis 2007) and (haffari and sarkar 2007).
</nextsent>
<nextsent>transductive svm (joachims 1999) extends the state-of-the-art inductive svm by explicitly considering the relationship between labeled and unlabeled data.
</nextsent>
<nextsent>the graph-based label propagation model (zhu et al  2003; zhou et al  2004) using harmonic function also accommodates the knowledge about unlabeled data.
</nextsent>
<nextsent>we will adapt both of them to our multiclass classification task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2171">
<title id=" W12-0603.xml">towards scalable speech act recognition in twitter tackling insufficient training data </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the graph-based label propagation model (zhu et al  2003; zhou et al  2004) using harmonic function also accommodates the knowledge about unlabeled data.
</prevsent>
<prevsent>we will adapt both of them to our multiclass classification task.
</prevsent>
</prevsection>
<citsent citstr=" D09-1130 ">
jeong et al  (2009) <papid> D09-1130 </papid>report semi-supervised approach to classifying speech acts in emails and online forums.</citsent>
<aftsection>
<nextsent>but their subtree-based method is not applicable to our task because twitters noisy textual quality cannot be found in the much cleaner email or forum texts.
</nextsent>
<nextsent>types supervised learning of speech act types in twitter relies heavily on good set of features that capture the textual characteristics of both twitter and speech act utterances.
</nextsent>
<nextsent>as in our previous work, we use speech act-specific cues, special words (abbreviations and acronyms, opinion words, vulgar words, and emoticons), and special characters (twitter-specific characters and few punctuations).
</nextsent>
<nextsent>tweet external features such as tweeter profile may also help, but that is beyond the focus of this paper.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2173">
<title id=" W12-1703.xml">why long words take longer to read the role of uncertainty about word length </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>some of the most robust effects of linguistic variables on eye movements in reading are those of word length.
</prevsent>
<prevsent>their leading explanation states that they are caused by visual acuity limitations on word recognition.
</prevsent>
</prevsection>
<citsent citstr=" P10-1119 ">
however, bicknell (2011) presented data showing that model of eye movement control in reading that includes visual acuity limitations and models the process of word identification from visual input (bicknell &amp; levy, 2010) <papid> P10-1119 </papid>does not produce human like word length effects, providing evidence against the visual acuity account.</citsent>
<aftsection>
<nextsent>here, we argue that uncertainty about word length in early word identification can drive word length effects.
</nextsent>
<nextsent>we present an extension of bicknell and levys model that incorporates word length uncertainty, and show that it produces more human like word length effects.
</nextsent>
<nextsent>controlling the eyes while reading is complex task, and doing so efficiently requires rapid decisions about when and where to move the eyes 3?
</nextsent>
<nextsent>4 times per second.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2199">
<title id=" W12-1703.xml">why long words take longer to read the role of uncertainty about word length </title>
<section> a rational model of reading </section>
<citcontext>
<prevsection>
<prevsent>on each time step, the model obtains visual input string as described above and calculates the likelihood of generating that string from each possible identity of the text.
</prevsent>
<prevsent>the model then updates its beliefs about the text via standard bayesian inference: multiplying the probability of each text identity under its prior beliefs by the likelihood of generating the visual input string from that text identity and normalizing.
</prevsent>
</prevsection>
<citsent citstr=" J97-2003 ">
we compactly represent all of these distributions using weighted finite-state transducers (mohri, 1997) <papid> J97-2003 </papid>using the openfst library (allauzen, riley, schalkwyk, skut, &amp; mohri, 2007), and implement belief update with transducer composition and weight pushing.</citsent>
<aftsection>
<nextsent>3.5 behavior policy.
</nextsent>
<nextsent>the model uses simple policy with two parameters, ? and ? , to decide between actions based onthe marginal probability of the most likely character in each position j, m( j) = max p(w = c)where j indicates the character in the jth position.
</nextsent>
<nextsent>a high value of indicates relative confidence about the characters identity, and low value relative uncertainty.
</nextsent>
<nextsent>because our extension has uncertainty about the absolute position of its eyes within the text, each position is now defined relative to the centrally fixated character.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2211">
<title id=" W12-1625.xml">probabilistic dialogue models with prior domain knowledge </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we empirically demonstrate the benefits of such an approach learning dialogue policy for human-robot interaction domain based on wizard-of-oz dataset.
</prevsent>
<prevsent>spoken dialogue systems increasingly relyon probabilistic models at various stages of their pipeline.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
statistical methods have notably been applied to tasks such as dis fluency detection (lease et al, 2006), semantic parsing (erdogan et al, 2002; heand young, 2005), dialogue act recognition (stolcke et al, 2000; <papid> J00-3003 </papid>lan et al, 2008), dialogue management (frampton and lemon, 2009; young et al,2010), natural language generation (oh and rudnicky, 2002; lemon, 2011) and speech synthesis (zen et al, 2009).there are two compelling reasons for this growing interest in statistical approaches: first, spoken dialogue is pervaded with noise and uncertainty (due to e.g. speech recognition errors, linguistic and pragmatic ambiguities, and unknown user in tentions), which must be dealt with at all processingstages.</citsent>
<aftsection>
<nextsent>second, decisive advantage of probabilistic models lies in their ability to be automatically optimised from data, enabling statistically-based dialogue systems to exhibit conversational behaviours that are often more robust, flexible and adaptive than hand-crafted systems (lemon and pietquin, 2007).
</nextsent>
<nextsent>despite their success, the use of probabilistic models also presents number of challenges.
</nextsent>
<nextsent>the most pressing issue is the paucity of appropriate datasets.
</nextsent>
<nextsent>stochastic models often require large amounts of training data to estimate their parameters ? either directly (henderson et al, 2008) <papid> J08-4002 </papid>or indirectly by way of user simulator (schatzmann et al, 2007;<papid> N07-2038 </papid>cuayahuitl et al, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2212">
<title id=" W12-1625.xml">probabilistic dialogue models with prior domain knowledge </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>despite their success, the use of probabilistic models also presents number of challenges.
</prevsent>
<prevsent>the most pressing issue is the paucity of appropriate datasets.
</prevsent>
</prevsection>
<citsent citstr=" J08-4002 ">
stochastic models often require large amounts of training data to estimate their parameters ? either directly (henderson et al, 2008) <papid> J08-4002 </papid>or indirectly by way of user simulator (schatzmann et al, 2007;<papid> N07-2038 </papid>cuayahuitl et al, 2010).</citsent>
<aftsection>
<nextsent>unfortunately, real interaction data is scarce, expensive to acquire, and difficult to transfer from one domain to another.
</nextsent>
<nextsent>moreover, many dialogue domains are inherently open-ended, which means they are not limited to the completion of single task with predefined features but have to represent varying number of tasks, complex user models and rich, dynamic environment.
</nextsent>
<nextsent>examples of such domains include human-robot interaction (kruijff et al, 2010), cognitive assistants and companions (nguyen, 2005; cavazza et al, 2010), <papid> W10-4353 </papid>and tutoring systems (litman and silliman, 2004;<papid> N04-3002 </papid>eskenazi, 2009).</nextsent>
<nextsent>in such settings, the dialogue system might need to track large number of variables in the course of the interaction, which quickly leads to combinatorial explosion of the state space.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2213">
<title id=" W12-1625.xml">probabilistic dialogue models with prior domain knowledge </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>despite their success, the use of probabilistic models also presents number of challenges.
</prevsent>
<prevsent>the most pressing issue is the paucity of appropriate datasets.
</prevsent>
</prevsection>
<citsent citstr=" N07-2038 ">
stochastic models often require large amounts of training data to estimate their parameters ? either directly (henderson et al, 2008) <papid> J08-4002 </papid>or indirectly by way of user simulator (schatzmann et al, 2007;<papid> N07-2038 </papid>cuayahuitl et al, 2010).</citsent>
<aftsection>
<nextsent>unfortunately, real interaction data is scarce, expensive to acquire, and difficult to transfer from one domain to another.
</nextsent>
<nextsent>moreover, many dialogue domains are inherently open-ended, which means they are not limited to the completion of single task with predefined features but have to represent varying number of tasks, complex user models and rich, dynamic environment.
</nextsent>
<nextsent>examples of such domains include human-robot interaction (kruijff et al, 2010), cognitive assistants and companions (nguyen, 2005; cavazza et al, 2010), <papid> W10-4353 </papid>and tutoring systems (litman and silliman, 2004;<papid> N04-3002 </papid>eskenazi, 2009).</nextsent>
<nextsent>in such settings, the dialogue system might need to track large number of variables in the course of the interaction, which quickly leads to combinatorial explosion of the state space.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2214">
<title id=" W12-1625.xml">probabilistic dialogue models with prior domain knowledge </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, real interaction data is scarce, expensive to acquire, and difficult to transfer from one domain to another.
</prevsent>
<prevsent>moreover, many dialogue domains are inherently open-ended, which means they are not limited to the completion of single task with predefined features but have to represent varying number of tasks, complex user models and rich, dynamic environment.
</prevsent>
</prevsection>
<citsent citstr=" W10-4353 ">
examples of such domains include human-robot interaction (kruijff et al, 2010), cognitive assistants and companions (nguyen, 2005; cavazza et al, 2010), <papid> W10-4353 </papid>and tutoring systems (litman and silliman, 2004;<papid> N04-3002 </papid>eskenazi, 2009).</citsent>
<aftsection>
<nextsent>in such settings, the dialogue system might need to track large number of variables in the course of the interaction, which quickly leads to combinatorial explosion of the state space.
</nextsent>
<nextsent>there is an extensive body of work in the machine 179 learning and planning literature that shows how to address this issue by relying on more expressive representations, able to capture relevant aspects of the problem structure in compact manner.
</nextsent>
<nextsent>by taking advantage of hierarchical or relational abstractions,system developers can leverage their domain knowledge to yield probabilistic models that are easier to learn (due to reduced number of parameters) andmore efficient to use (since the structure can be exploited by the inference algorithm).
</nextsent>
<nextsent>the contributions of this paper are twofold.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2215">
<title id=" W12-1625.xml">probabilistic dialogue models with prior domain knowledge </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, real interaction data is scarce, expensive to acquire, and difficult to transfer from one domain to another.
</prevsent>
<prevsent>moreover, many dialogue domains are inherently open-ended, which means they are not limited to the completion of single task with predefined features but have to represent varying number of tasks, complex user models and rich, dynamic environment.
</prevsent>
</prevsection>
<citsent citstr=" N04-3002 ">
examples of such domains include human-robot interaction (kruijff et al, 2010), cognitive assistants and companions (nguyen, 2005; cavazza et al, 2010), <papid> W10-4353 </papid>and tutoring systems (litman and silliman, 2004;<papid> N04-3002 </papid>eskenazi, 2009).</citsent>
<aftsection>
<nextsent>in such settings, the dialogue system might need to track large number of variables in the course of the interaction, which quickly leads to combinatorial explosion of the state space.
</nextsent>
<nextsent>there is an extensive body of work in the machine 179 learning and planning literature that shows how to address this issue by relying on more expressive representations, able to capture relevant aspects of the problem structure in compact manner.
</nextsent>
<nextsent>by taking advantage of hierarchical or relational abstractions,system developers can leverage their domain knowledge to yield probabilistic models that are easier to learn (due to reduced number of parameters) andmore efficient to use (since the structure can be exploited by the inference algorithm).
</nextsent>
<nextsent>the contributions of this paper are twofold.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2216">
<title id=" W12-1625.xml">probabilistic dialogue models with prior domain knowledge </title>
<section> discussion and related work.  </section>
<citcontext>
<prevsection>
<prevsent>as in our approach, most of these frameworks relyon the use of expressive representations as templates for grounded probabilistic models.
</prevsent>
<prevsent>in the dialogue management literature, most structural approaches relyon clear-cut task decomposition into goals and sub-goals (allen et al, 2000; steedman and petrick, 2007; bohus and rudnicky, 2009), where the completion of each goal is assumed to be fully observable, discarding any remaining uncertainty.
</prevsent>
</prevsection>
<citsent citstr=" W03-2123 ">
information-state approaches to dialogue management (larsson and traum, 2000; bos et al, 2003) <papid> W03-2123 </papid>also relyon shared state updated according to rich repository of rules, but contrary to the approach presented here, these rules are generally deterministic and do not include learn able parameters.</citsent>
<aftsection>
<nextsent>185 the literature on dialogue policy optimisation with reinforcement learning also contains several approaches dedicated to dimensionality reduction for large state-action spaces, such as function approximation (henderson et al, 2008), <papid> J08-4002 </papid>hierarchical reinforcement learning (cuayahuitl et al, 2010) and summary pomdps (young et al, 2010).</nextsent>
<nextsent>most ofthese approaches relyon large but weakly structured state spaces (generally encoded as large listsof features), which are suited for slot-filling dialogue applications but are difficult to transfer to more open-ended or relational domains.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2218">
<title id=" W12-1625.xml">probabilistic dialogue models with prior domain knowledge </title>
<section> discussion and related work.  </section>
<citcontext>
<prevsection>
<prevsent>185 the literature on dialogue policy optimisation with reinforcement learning also contains several approaches dedicated to dimensionality reduction for large state-action spaces, such as function approximation (henderson et al, 2008), <papid> J08-4002 </papid>hierarchical reinforcement learning (cuayahuitl et al, 2010) and summary pomdps (young et al, 2010).</prevsent>
<prevsent>most ofthese approaches relyon large but weakly structured state spaces (generally encoded as large listsof features), which are suited for slot-filling dialogue applications but are difficult to transfer to more open-ended or relational domains.</prevsent>
</prevsection>
<citsent citstr=" W10-4336 ">
the idea ofstate space partitioning, implemented here via high level conditions, has also been explored in recent papers (williams, 2010; crook and lemon, 2010).<papid> W10-4336 </papid></citsent>
<aftsection>
<nextsent>finally, cuayahuitl (2011) describes closely-related approach using logic-based representations of thestate-action space for relational mdps.
</nextsent>
<nextsent>his approach is however based on reinforcement learning with user simulator, while the learning procedure presented here relies on supervised learning from limited dataset.
</nextsent>
<nextsent>he also reduced his belief state to fully observable variables, whereas we retain the partial observability associated with each variable.an important side benefit of structured representations in probabilistic models is their improved readability for human designers, who are able to use these powerful abstractions to encode their prior knowledge of the dialogue domain in the form of pragmatic rules, generic background knowledge, ortask-specific constraints.
</nextsent>
<nextsent>there has been previous work on integrating expert knowledge into dialogue policy learning, using finite-state policies or ad-hoc constraints to filter plain statistical model(williams, 2008; henderson et al, 2008).<papid> J08-4002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2220">
<title id=" W12-1812.xml">a belief tracking challenge task for spoken dialog systems </title>
<section> introduction and background.  </section>
<citcontext>
<prevsection>
<prevsent>in dialog systems, belief tracking refers to maintaining distribution over multiple dialog states as dialog progresses.
</prevsent>
<prevsent>belief tracking is desirable because it provides robustness to errors in speech recognition, which can be quite common.
</prevsent>
</prevsection>
<citsent citstr=" P03-1031 ">
this distribution can be modeled in variety of ways, including heuristic scores (higashinaka et al., 2003), <papid> P03-1031 </papid>bayesian networks (paek and horvitz,2000; williams and young, 2007), and discriminative models (bohus and rudnicky, 2006).</citsent>
<aftsection>
<nextsent>techniques have been fielded which scale to realistically sized dialog problems and operate in real time (young et al, 2009; thomson and young, 2010; williams, 2010; mehta et al, 2010).<papid> W10-4306 </papid></nextsent>
<nextsent>in lab settings, belief tracking has been shown to improve overall system performance (young et al, 2009; thomson and young, 2010).despite this progress, there are still important unresolved issues.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2221">
<title id=" W12-1812.xml">a belief tracking challenge task for spoken dialog systems </title>
<section> introduction and background.  </section>
<citcontext>
<prevsection>
<prevsent>belief tracking is desirable because it provides robustness to errors in speech recognition, which can be quite common.
</prevsent>
<prevsent>this distribution can be modeled in variety of ways, including heuristic scores (higashinaka et al., 2003), <papid> P03-1031 </papid>bayesian networks (paek and horvitz,2000; williams and young, 2007), and discriminative models (bohus and rudnicky, 2006).</prevsent>
</prevsection>
<citsent citstr=" W10-4306 ">
techniques have been fielded which scale to realistically sized dialog problems and operate in real time (young et al, 2009; thomson and young, 2010; williams, 2010; mehta et al, 2010).<papid> W10-4306 </papid></citsent>
<aftsection>
<nextsent>in lab settings, belief tracking has been shown to improve overall system performance (young et al, 2009; thomson and young, 2010).despite this progress, there are still important unresolved issues.
</nextsent>
<nextsent>for example, deployment with real callers (williams, 2011) <papid> W11-2016 </papid>found that belief tracking sometimes degraded performance due to modelmis-matches that are difficult to anticipate at training time.</nextsent>
<nextsent>what is lacking is careful comparison of methods to determine their relative strengths, in terms of generalization, sample efficiency, speed, etc. this position paper argues for belief tracking challenge task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2222">
<title id=" W12-1812.xml">a belief tracking challenge task for spoken dialog systems </title>
<section> introduction and background.  </section>
<citcontext>
<prevsection>
<prevsent>techniques have been fielded which scale to realistically sized dialog problems and operate in real time (young et al, 2009; thomson and young, 2010; williams, 2010; mehta et al, 2010).<papid> W10-4306 </papid></prevsent>
<prevsent>in lab settings, belief tracking has been shown to improve overall system performance (young et al, 2009; thomson and young, 2010).despite this progress, there are still important unresolved issues.</prevsent>
</prevsection>
<citsent citstr=" W11-2016 ">
for example, deployment with real callers (williams, 2011) <papid> W11-2016 </papid>found that belief tracking sometimes degraded performance due to modelmis-matches that are difficult to anticipate at training time.</citsent>
<aftsection>
<nextsent>what is lacking is careful comparison of methods to determine their relative strengths, in terms of generalization, sample efficiency, speed, etc. this position paper argues for belief tracking challenge task.
</nextsent>
<nextsent>a corpus of labeled dialogs and scoring code would be released.
</nextsent>
<nextsent>research teams would enter one or more belief tracking algorithms, which would be evaluated on held-out test set.
</nextsent>
<nextsent>the spoken dialog challenge corpus is an attractive corpus for this challenge.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2224">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 rwth aachen single systems.
</prevsent>
<prevsent>for the wmt 2011 evaluation the rwth utilizedrwths state-of-the-art phrase-based and hierarchical translation systems.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
giza++ (och and ney,2003) <papid> J03-1002 </papid>was employed to train word alignments, language models have been created with the srilm toolkit (stolcke, 2002).</citsent>
<aftsection>
<nextsent>2.1.1 phrase-based system the phrase-based translation (pbt) system is similar to the one described in zens and ney (2008).
</nextsent>
<nextsent>after phrase pair extraction from the word-alignedbilingual corpus, the translation probabilities are estimated by relative frequencies.
</nextsent>
<nextsent>the standard feature set al includes an n-gram language model, phrase level ibm-1 and word-, phrase- and distortion penalties, which are combined in log-linear fashion.
</nextsent>
<nextsent>parameters are optimized with the downhill simplex algorithm (nelder and mead, 1965) on the word graph.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2225">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>the standard feature set al includes an n-gram language model, phrase level ibm-1 and word-, phrase- and distortion penalties, which are combined in log-linear fashion.
</prevsent>
<prevsent>parameters are optimized with the downhill simplex algorithm (nelder and mead, 1965) on the word graph.
</prevsent>
</prevsection>
<citsent citstr=" W10-1738 ">
358 2.1.2 hierarchical system for the hierarchical setups described in this paper, the open source jane toolkit (vilar et al , 2010) <papid> W10-1738 </papid>is employed.</citsent>
<aftsection>
<nextsent>jane has been developed at rwthand implements the hierarchical approach as introduced by chiang (2007) <papid> J07-2003 </papid>with some state-of-the-art extensions.</nextsent>
<nextsent>in hierarchical phrase-based translation,a weighted synchronous context-free grammar is induced from parallel text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2226">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>parameters are optimized with the downhill simplex algorithm (nelder and mead, 1965) on the word graph.
</prevsent>
<prevsent>358 2.1.2 hierarchical system for the hierarchical setups described in this paper, the open source jane toolkit (vilar et al , 2010) <papid> W10-1738 </papid>is employed.</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
jane has been developed at rwthand implements the hierarchical approach as introduced by chiang (2007) <papid> J07-2003 </papid>with some state-of-the-art extensions.</citsent>
<aftsection>
<nextsent>in hierarchical phrase-based translation,a weighted synchronous context-free grammar is induced from parallel text.
</nextsent>
<nextsent>in addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted.
</nextsent>
<nextsent>the search is typically carried out using the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></nextsent>
<nextsent>the model weights are optimized with standard mert (och, 2003) <papid> P03-1021 </papid>on 100-best lists.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2227">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>in hierarchical phrase-based translation,a weighted synchronous context-free grammar is induced from parallel text.
</prevsent>
<prevsent>in addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted.
</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
the search is typically carried out using the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></citsent>
<aftsection>
<nextsent>the model weights are optimized with standard mert (och, 2003) <papid> P03-1021 </papid>on 100-best lists.</nextsent>
<nextsent>2.1.3 phrase model training for some pbt systems forced alignment procedure was applied to train the phrase translation model as described in wuebker et al  (2010).<papid> P10-1049 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2229">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>in addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted.
</prevsent>
<prevsent>the search is typically carried out using the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the model weights are optimized with standard mert (och, 2003) <papid> P03-1021 </papid>on 100-best lists.</citsent>
<aftsection>
<nextsent>2.1.3 phrase model training for some pbt systems forced alignment procedure was applied to train the phrase translation model as described in wuebker et al  (2010).<papid> P10-1049 </papid></nextsent>
<nextsent>a modified version of the translation decoder is usedto produce phrase alignment on the bilingual training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2230">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>the search is typically carried out using the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></prevsent>
<prevsent>the model weights are optimized with standard mert (och, 2003) <papid> P03-1021 </papid>on 100-best lists.</prevsent>
</prevsection>
<citsent citstr=" P10-1049 ">
2.1.3 phrase model training for some pbt systems forced alignment procedure was applied to train the phrase translation model as described in wuebker et al  (2010).<papid> P10-1049 </papid></citsent>
<aftsection>
<nextsent>a modified version of the translation decoder is usedto produce phrase alignment on the bilingual training data.
</nextsent>
<nextsent>the phrase translation probabilities are estimated from their relative frequencies in the phrase aligned training data.
</nextsent>
<nextsent>in addition to providing statistically well-founded phrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid and less memory consuming experiments with better translation quality.
</nextsent>
<nextsent>2.1.4 final systems for the german english task, rwth conducted experiments comparing the standard phrase extraction with the phrase training technique described in section 2.1.3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2231">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>2.1.4 final systems for the german english task, rwth conducted experiments comparing the standard phrase extraction with the phrase training technique described in section 2.1.3.
</prevsent>
<prevsent>further experiments included the useof additional language model training data, reranking of n-best lists generated by the phrase-based system, and different optimization criteria.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
a considerable increase in translation quality can be achieved by application of german compound splitting (koehn and knight, 2003).<papid> E03-1076 </papid></citsent>
<aftsection>
<nextsent>in comparison to standard heuristic phrase extraction techniques, performing force alignment phrase training (fa) gives an improvement in bleu on newstest2008 and newstest2009, but degradation inter.
</nextsent>
<nextsent>the addition of ldc gigaword corpora (+gw) to the language model training data shows improvements in both bleu and ter.
</nextsent>
<nextsent>reranking was done on 1000-best lists generated by the the best available system (pbt (fa)+gw).
</nextsent>
<nextsent>following models were applied: n-gram posteriors (zens and ney, 2006),<papid> W06-3110 </papid>sentence length model, 6-gram lm and ibm-1 lexicon models in both normal and inverse direction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2232">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>the addition of ldc gigaword corpora (+gw) to the language model training data shows improvements in both bleu and ter.
</prevsent>
<prevsent>reranking was done on 1000-best lists generated by the the best available system (pbt (fa)+gw).
</prevsent>
</prevsection>
<citsent citstr=" W06-3110 ">
following models were applied: n-gram posteriors (zens and ney, 2006),<papid> W06-3110 </papid>sentence length model, 6-gram lm and ibm-1 lexicon models in both normal and inverse direction.</citsent>
<aftsection>
<nextsent>these models are combined in log-linear fashion and the scaling factors are tuned in the same manner as the baseline system (using ter4bleu on newstest2009).the final table includes two identical jane systems which are optimized on different criteria.
</nextsent>
<nextsent>the one optimized on terbleu yields much lower ter.
</nextsent>
<nextsent>2.2 karlsruhe institute of technology single.
</nextsent>
<nextsent>system 2.2.1 preprocessing we pre process the training data prior to training the system, first by normalizing symbols such as quotes, dashes and apostrophes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2234">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>the individual models are described briefly in the following.
</prevsent>
<prevsent>2.2.3 pos-based reordering modelwe use reordering model that is based on parts of-speech (pos) and learn probabilistic rules from the pos tags of the words in the training corpus andthe alignment information.
</prevsent>
</prevsection>
<citsent citstr=" W09-0435 ">
in addition to continuous reordering rules that model short-range reordering (rottmann and vogel, 2007), we apply non continuous rules to address long-range reorderings as typical for german-english translation (niehues and kolss, 2009).<papid> W09-0435 </papid></citsent>
<aftsection>
<nextsent>the reordering rules are applied to the source sentences and the reordered sentence variants as well as the original sequence are encoded in word lattice which is used as input to the decoder.
</nextsent>
<nextsent>2.2.4 lattice phrase extraction for the test sentences, the pos-based reordering allows us to change the word order in the source sentence so that the sentence can be translated more easily.
</nextsent>
<nextsent>if we apply this also to the training sentences, wewould be able to extract also phrase pairs for originally discontinuous phrases and could apply them during translation of reordered test sentences.
</nextsent>
<nextsent>therefore, we build reordering lattices for all training sentences and then extract phrase pairs fromthe monotone source path as well as from there ordered paths.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2235">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 limsi-cnrs single system.
</prevsent>
<prevsent>2.3.1 system overview the limsi system is built with n-code2, an open source statistical machine translation system based on bilingual n-grams.
</prevsent>
</prevsection>
<citsent citstr=" J04-2004 ">
2.3.2 n-code overview in nutshell, the translation model is implemented as stochastic finite-state transducer trained using n-gram model of (source,target) pairs (casacuberta and vidal, 2004).<papid> J04-2004 </papid></citsent>
<aftsection>
<nextsent>training this model requires to reorder source sentences so as to match the target word order.
</nextsent>
<nextsent>this is performed by stochastic finite-state reordering model, which uses part-of-speech information3 to generalize reordering patterns beyond lexical regularities.in addition to the translation model, eleven feature functions are combined: target-languagemodel; four lexicon models; two lexicalized reordering models (tillmann, 2004) <papid> N04-4026 </papid>aiming at predicting the orientation of the next translation unit; weakdistance-based distortion model; and finally word bonus model and tuple-bonus model which compensate for the system preference for short transla tions.</nextsent>
<nextsent>the four lexicon models are similar to the ones use in standard phrase based system: two scores correspond to the relative frequencies of the tuplesand two lexical weights estimated from the automatically generated word alignments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2236">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>2.3.2 n-code overview in nutshell, the translation model is implemented as stochastic finite-state transducer trained using n-gram model of (source,target) pairs (casacuberta and vidal, 2004).<papid> J04-2004 </papid></prevsent>
<prevsent>training this model requires to reorder source sentences so as to match the target word order.</prevsent>
</prevsection>
<citsent citstr=" N04-4026 ">
this is performed by stochastic finite-state reordering model, which uses part-of-speech information3 to generalize reordering patterns beyond lexical regularities.in addition to the translation model, eleven feature functions are combined: target-languagemodel; four lexicon models; two lexicalized reordering models (tillmann, 2004) <papid> N04-4026 </papid>aiming at predicting the orientation of the next translation unit; weakdistance-based distortion model; and finally word bonus model and tuple-bonus model which compensate for the system preference for short transla tions.</citsent>
<aftsection>
<nextsent>the four lexicon models are similar to the ones use in standard phrase based system: two scores correspond to the relative frequencies of the tuplesand two lexical weights estimated from the automatically generated word alignments.
</nextsent>
<nextsent>the weights associated to feature functions are optimally combined using discriminative training framework (och, 2003), <papid> P03-1021 </papid>using the newstest2009 data as development set.</nextsent>
<nextsent>the overall search is based on beam-searchstrategy on top of dynamic programming algo rithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2238">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>361 ? phrase pairs appearing less than 2 times were pruned.
</prevsent>
<prevsent>the spe language model was trained 15m phrases from the news/europarl corpora, provided as training data for wmt 2011.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
weights for these separate models were tuned by the mert algorithm provided in the moses toolkit (p. koehn et al , 2007), <papid> P07-2045 </papid>using the provided news development set.</citsent>
<aftsection>
<nextsent>system combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in termsof translation quality than any of the individual hypotheses.
</nextsent>
<nextsent>the basic concept of rwths approach to machine translation system combination has been described by matusov et al  (2006), <papid> E06-1005 </papid>matusov et al  (2008).</nextsent>
<nextsent>this approach includes an enhanced alignment and reordering framework.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2239">
<title id=" W11-2142.xml">joint wmt submission of the quaero project </title>
<section> rwth aachen system combination.  </section>
<citcontext>
<prevsection>
<prevsent>weights for these separate models were tuned by the mert algorithm provided in the moses toolkit (p. koehn et al , 2007), <papid> P07-2045 </papid>using the provided news development set.</prevsent>
<prevsent>system combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in termsof translation quality than any of the individual hy potheses.</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
the basic concept of rwths approach to machine translation system combination has been described by matusov et al  (2006), <papid> E06-1005 </papid>matusov et al  (2008).</citsent>
<aftsection>
<nextsent>this approach includes an enhanced alignment and reordering framework.
</nextsent>
<nextsent>a lattice is built from the input hypotheses.
</nextsent>
<nextsent>the translation with the best score with inthe lattice according to couple of statistical models is selected as consensus translation.
</nextsent>
<nextsent>a deeper description will be also given in the wmt11 system combination paper of rwth aachen university.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2240">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>historically, most work in statistical machine translation (smt) has focused on translation into english.
</prevsent>
<prevsent>languages with richer inflectional mor phologies pose additional challenges for translation and conventional smt approaches tend to perform poorly when either source or target language has rich morphology (koehn, 2005).for complex source inflection, successful approach has been to cluster inflectional variants into equivalence classes.
</prevsent>
</prevsection>
<citsent citstr=" H05-1085 ">
this removes information that is redundant for translation and can be performed asa preprocessing step for input to conventional surface form based translation model (nieen and ney, 2001; goldwater and mcclosky, 2005; <papid> H05-1085 </papid>talbot and osborne, 2006).</citsent>
<aftsection>
<nextsent>for complex target inflection,minkov et al (2007) <papid> P07-1017 </papid>investigate how postprocessing can be used to generate inflection for asystem that produces uninflected output.</nextsent>
<nextsent>their approach is successfully applied to english-arabic and english-russian systems by toutanova et al (2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2241">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>languages with richer inflectional mor phologies pose additional challenges for translation and conventional smt approaches tend to perform poorly when either source or target language has rich morphology (koehn, 2005).for complex source inflection, successful approach has been to cluster inflectional variants into equivalence classes.
</prevsent>
<prevsent>this removes information that is redundant for translation and can be performed asa preprocessing step for input to conventional surface form based translation model (nieen and ney, 2001; goldwater and mcclosky, 2005; <papid> H05-1085 </papid>talbot and osborne, 2006).</prevsent>
</prevsection>
<citsent citstr=" P07-1017 ">
for complex target inflection,minkov et al (2007) <papid> P07-1017 </papid>investigate how postprocessing can be used to generate inflection for asystem that produces uninflected output.</citsent>
<aftsection>
<nextsent>their approach is successfully applied to english-arabic and english-russian systems by toutanova et al (2008).
</nextsent>
<nextsent>another promising line of research involves the direct integration of linguistic information into smt models.
</nextsent>
<nextsent>koehn and hoang (2007) <papid> D07-1091 </papid>generalise the phrase-based models representation of the word from string to vector, allowing additional features such as part-of-speech and morphology to be associated with, or even to replace, surface forms during search.</nextsent>
<nextsent>luong et al (2010) decompose words into morphemes and use this extended representation throughout the training, tuning, and testing pipeline.departing further from traditional smt models, the transfer-based systems of riezler and maxwell (2006), <papid> N06-1032 </papid>bojar and hajic?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2242">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>their approach is successfully applied to english-arabic and english-russian systems by toutanova et al (2008).
</prevsent>
<prevsent>another promising line of research involves the direct integration of linguistic information into smt models.
</prevsent>
</prevsection>
<citsent citstr=" D07-1091 ">
koehn and hoang (2007) <papid> D07-1091 </papid>generalise the phrase-based models representation of the word from string to vector, allowing additional features such as part-of-speech and morphology to be associated with, or even to replace, surface forms during search.</citsent>
<aftsection>
<nextsent>luong et al (2010) decompose words into morphemes and use this extended representation throughout the training, tuning, and testing pipeline.departing further from traditional smt models, the transfer-based systems of riezler and maxwell (2006), <papid> N06-1032 </papid>bojar and hajic?</nextsent>
<nextsent>(2008), and graham et al (2009) employ rich feature structure representations for linguistic attributes, but haveso far been limited by their dependence on non stochastic parsers with limited coverage.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2243">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>another promising line of research involves the direct integration of linguistic information into smt models.
</prevsent>
<prevsent>koehn and hoang (2007) <papid> D07-1091 </papid>generalise the phrase-based models representation of the word from string to vector, allowing additional features such as part-of-speech and morphology to be associated with, or even to replace, surface forms during search.</prevsent>
</prevsection>
<citsent citstr=" N06-1032 ">
luong et al (2010) decompose words into morphemes and use this extended representation throughout the training, tuning, and testing pipeline.departing further from traditional smt models, the transfer-based systems of riezler and maxwell (2006), <papid> N06-1032 </papid>bojar and hajic?</citsent>
<aftsection>
<nextsent>(2008), and graham et al (2009) employ rich feature structure representations for linguistic attributes, but haveso far been limited by their dependence on non stochastic parsers with limited coverage.
</nextsent>
<nextsent>the stat xfer transfer-based framework (lavie, 2008) is neutral with regard to the rule acquisition method and the author describes manually developed hebrew-english transfer grammar, which includes asmall number of constraints between agreement features.
</nextsent>
<nextsent>in hanneman et al (2009) <papid> W09-0425 </papid>the framework is used with large automatically-extracted grammar, though this does not use feature constraints.</nextsent>
<nextsent>in this paper we propose model that retains the use of surface forms during decoding whilst also checking linguistic constraints defined over associated feature structures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2244">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2008), and graham et al (2009) employ rich feature structure representations for linguistic attributes, but haveso far been limited by their dependence on non stochastic parsers with limited coverage.
</prevsent>
<prevsent>the stat xfer transfer-based framework (lavie, 2008) is neutral with regard to the rule acquisition method and the author describes manually developed hebrew-english transfer grammar, which includes asmall number of constraints between agreement features.
</prevsent>
</prevsection>
<citsent citstr=" W09-0425 ">
in hanneman et al (2009) <papid> W09-0425 </papid>the framework is used with large automatically-extracted grammar, though this does not use feature constraints.</citsent>
<aftsection>
<nextsent>in this paper we propose model that retains the use of surface forms during decoding whilst also checking linguistic constraints defined over associated feature structures.
</nextsent>
<nextsent>specifically, we extend string-to-tree model by adding unification-based 217 constraints to the target-side of the synchronous grammar.
</nextsent>
<nextsent>we suggest that such constraint system can: ? improve the model by enforcing inflectional consistency in combinations unseen by the language model?
</nextsent>
<nextsent>improve search by allowing the early elimination of morphologically-inconsistent hypotheses to evaluate the approach, we develop system forenglish-german with constraints to enforce intranp/pp and subject-verb agreement, and with simple probabilistic model for np case.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2245">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> preliminaries.  </section>
<citcontext>
<prevsection>
<prevsent>there is an extensive literature on constraint-based approaches to grammar, employing rich variety of terminology and linguistic devices.
</prevsent>
<prevsent>we use only few of the core ideas, which we briefly describe in this section.
</prevsent>
</prevsection>
<citsent citstr=" P84-1075 ">
we borrow the terminology and notation of patr-ii (shieber, 1984), <papid> P84-1075 </papid>minimal constraint-based formalism that extends context-free grammar.</citsent>
<aftsection>
<nextsent>central to our model are the concepts of feature structures and unification.
</nextsent>
<nextsent>feature structures are of two kinds:?
</nextsent>
<nextsent>atomic feature structures are untyped, indivisible values, such as np, nom, or sg ? complex feature structures are partial functions mapping features to values, the values themselves being feature structures.complex feature structures are conventionally written as attribute-value matrices.
</nextsent>
<nextsent>for example, the following might represent lexical entries for the german definite article, die, and the german noun, katze, meaning cat: die ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2246">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> grammar.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 synchronous grammar.
</prevsent>
<prevsent>our translation model is based on synchronouscontext-free grammar (scfg) learned from parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
rule extraction follows the hierarchical phrase-based algorithm of chiang (2005), <papid> P05-1033 </papid>algorithm of chiang (2007).</citsent>
<aftsection>
<nextsent>source non-terminals are given the undistinguished label x, whereas the target non-terminals are given part-of-speech and constituent labels obtained from 218 parse of the target-side of the parallel corpus.
</nextsent>
<nextsent>rules in which the target span is not covered by parse tree constituent are discarded.
</nextsent>
<nextsent>compared with the hierarchical phrase-based model, the restriction to constituent target phrases reduces the total grammar size and the addition of linguistic labels reduces the problem of spurious ambiguity.
</nextsent>
<nextsent>we therefore relax chiangs (2007) rule filtering in the following ways: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2247">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> grammar.  </section>
<citcontext>
<prevsection>
<prevsent>whilst the constraint model described above is language-independent, the actual form ofthe constraints will largely be language- and corpus specific.
</prevsent>
<prevsent>in this work, the linguistic annotation is obtained from statistical parser and morphological analyser.
</prevsent>
</prevsection>
<citsent citstr=" C04-1024 ">
we use the bitpar parser (schmid, 2004) <papid> C04-1024 </papid>trained on the tiger treebank (brants et al, 2002)and the morphisto morphological analyser (zielin ski and simon, 2009).</citsent>
<aftsection>
<nextsent>we find that we can extract useful constraints for german based on minimal set of simple manually-developed heuristics.
</nextsent>
<nextsent>base np/pp agreement german determiners and adjectives are inflected to agree in gender and number with the nouns that they modify.
</nextsent>
<nextsent>as in english, distinction is made between singular and plural number, with most nouns having separate forms for each.
</nextsent>
<nextsent>grammatical gender has three values: masculine, feminine, and neuter.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2248">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> model.  </section>
<citcontext>
<prevsection>
<prevsent>p(rhss|rhst,lhs), the noisy-channel translation probability.
</prevsent>
<prevsent>p(rhst|rhss,lhs), the direct translation probability, which we further condition on the root label of the target tree fragment.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
plex (rhst|rhss) and plex (rhss|rhst), the direct and indirect lexical weights (koehn et al, 2003).?<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>ppcfg(fragt), the monolingual pcfg probability of the tree fragment from which the rule was extracted.
</nextsent>
<nextsent>this is defined as i=1 p(ri), where r1 . . .
</nextsent>
<nextsent>rn are the constituent cfg rulesof the fragment.
</nextsent>
<nextsent>the pcfg parameters are estimated from the parse of the target-side trainingdata.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2249">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> model.  </section>
<citcontext>
<prevsection>
<prevsent>the pcfg parameters are estimated from the parse of the target-side trainingdata.
</prevsent>
<prevsent>all lexical rules are given the probability 1.
</prevsent>
</prevsection>
<citsent citstr=" W06-1606 ">
this is similar to the pcfg feature used inmarcu et al (2006) <papid> W06-1606 </papid>and is intended to encourage the production of syntactically well-formed derivations.</citsent>
<aftsection>
<nextsent>exp(1), rule penalty.
</nextsent>
<nextsent>221 4.2 constraint model features.
</nextsent>
<nextsent>in addition to the string-to-tree features, we add two features related to constraint evaluation: ? exp(f), where is the derivations constraint set failure count.
</nextsent>
<nextsent>this serves as penalty feature in soft constraint variant of the model: for each constraint set in which unification failure occurs, this count is increased and an empty feature structure is produced, permitting decoding to continue.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2250">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> decoding.  </section>
<citcontext>
<prevsection>
<prevsent>n pcase(cn), the product of the derivations case model probabilities.
</prevsent>
<prevsent>where the case valueis ambiguous we take the highest possible probability.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we use the moses (koehn et al, 2007) <papid> P07-2045 </papid>decoder, bottom-up synchronous parser that implements the cyk+ algorithm (chappelier and rajman, 1998) with cube pruning (chiang, 2007).</citsent>
<aftsection>
<nextsent>the constraint model requires some changes to decoding, which we briefly describe here: 5.1 hypothesis state.
</nextsent>
<nextsent>bottom-up constraint evaluation requires feature structure set for every rule element that participates in constraint.
</nextsent>
<nextsent>for lexical rule elements these are obtained from the lexicon.
</nextsent>
<nextsent>for non-lexical rule elements these are obtained from predecessor hypotheses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2251">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>these were interpolated using weights optimised against the development set and there sulting language model was used in experiments.
</prevsent>
<prevsent>we used the srilm toolkit (stolcke, 2002) with kneser-ney smoothing (chen and goodman, 1998).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the baseline systems feature weights were tuned on the news-test2008 dev set (2,051 sentence pairs) using minimum error rate training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>6.2 constraint model setup.
</nextsent>
<nextsent>a feature structure lexicon was generated by running the morphisto3 morphological analyser over the training vocabulary and then extracting feature values from the output.
</nextsent>
<nextsent>the constraint rules were extracted using the agreement relation identification and filtering methods described in section 3.3.we tested two constraint model systems, one using the rules as hard constraints and the other as soft constraints.
</nextsent>
<nextsent>the former discarded all hypotheses that failed constraints and used the modified cube pruning search algorithm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2252">
<title id=" W11-2126.xml">agreement constraints for statistical machine translation into german </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we evaluated translation quality using case-sensitive bleu-4 (papineni 3http://code.google.com/p/morphisto/ (np-ag der (adja regelmaigen) (adja taglichen) (nn handel)) (pp-mo nach angaben der (adja ortlichen) (nn index)) (np-cj die (adja amerikanischen) (nn blutbad)) (pp-mnr fur die (adja asiatischen) (nn handel)) (top (np-sb der (nn vorsprung) des (nn razor)) (vvfin kampfen) (cnp-oa : (nn mp3-player) (kon und) (nn mobiltelefone)) .)figure 5: tree fragments containing the first five constraint failures found on the baseline 1-best output et al, 2002) with single reference.
</prevsent>
<prevsent>table 2 shows the results for the three constrained test tests.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
the p-values were calculated using paired bootstrap re sampling (koehn, 2004).<papid> W04-3250 </papid></citsent>
<aftsection>
<nextsent>we suspect that the substantially lower baseline scores on thenewstest2011 test set are largely due to recency effects (since we use 2010 data for training).
</nextsent>
<nextsent>to gauge the frequency of agreement violations in the baseline output we matched constraint rules to the 1-best baseline derivations and performed bottom-up evaluation for each target-side tree.
</nextsent>
<nextsent>forthe three constrained test sets, newstest2009, new stest2010, and newstest2011, we found that 15.5%,14.4%, and 15.6% of sentences, respectively, contained one or more constraint failures.
</nextsent>
<nextsent>figure 5 shows the tree fragments for the first five failures found in newstest2009.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2253">
<title id=" W11-2705.xml">exploring linguistically rich patterns for question generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are hundreds of ways to express an idea, to describe fact.
</prevsent>
<prevsent>but language also comprises several regularities, or patterns, that denote the presence of certain information.
</prevsent>
</prevsection>
<citsent citstr=" P02-1006 ">
for example, parisis located in france is common way to say that parisis in france, indicated by the words located in.the use of patterns is widely accepted as an effective approach in the field of natural language processing (nlp), in tasks like question-answering (qa) (soubbotin, 2001; ravichandran and hovy,2002) <papid> P02-1006 </papid>or question generation (qg) (wyse and pi wek, 2009; mendes et al, 2011).</citsent>
<aftsection>
<nextsent>particularly, qg aims at generating questions from text and has became vibrant line of research.
</nextsent>
<nextsent>generating questions (and answers), on one hand, allows qa or dialogue systems to be easily ported to different domains, by quickly providing new questions to train the systems.
</nextsent>
<nextsent>on the other hand, it is useful for knowledge assessment-related tasks, by reducing the amount of time allocated for the creation of tests by teachers (a time consuming and tedious task if done manually), or by allowing the self evaluation of knowledge acquired by learn ers.most systems dedicated to qg are based on handcrafted rules and relyon pattern matching to generate questions.
</nextsent>
<nextsent>for example, in (chen et al, 2009), after the identification of key points, situation model is built and question templates are used to generate questions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2255">
<title id=" W11-2705.xml">exploring linguistically rich patterns for question generation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>however, understanding the characteristics of pair that makes it good seed is an important and pertinent question and direction for future work.
</prevsent>
<prevsent>gid: 1 syntactic structure: whnp vbd np semantic category: human:individual who wrote hamlet??/shakespeare who painted guernica??/picasso who painted the starry night??/van gogh gid: 2 syntactic structure: whadvp vbd np vbn semantic category: numeric:date when was hamlet written??/1601 when was guernica painted??/1937 when was the starry night painted??/1889 table 1: seeds used in the experiments.
</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
the syntactic analysis of the questions was done by the berkeley parser (petrov and klein, 2007) <papid> N07-1051 </papid>trained on the question bank (judge et al, 2006).<papid> P06-1063 </papid></citsent>
<aftsection>
<nextsent>for question classification, we used li and roth (2002) <papid> C02-1150 </papid>taxonomy and machine learning-based classifier fed with features derived from rule-based classifier (silva et al, 2011).</nextsent>
<nextsent>for the learning of patterns we used the top64 documents retrieved by google and to recognize the named entities in the pattern we apply several strategies, namely: 1) the stanfords conditional random-field-based named entity recognizer (finkel et al, 2005) <papid> P05-1045 </papid>to detect entities of type human; 2) regular expressions to detect numeric and date type entities; 3) gazette ers to detect entities of type location.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2257">
<title id=" W11-2705.xml">exploring linguistically rich patterns for question generation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>however, understanding the characteristics of pair that makes it good seed is an important and pertinent question and direction for future work.
</prevsent>
<prevsent>gid: 1 syntactic structure: whnp vbd np semantic category: human:individual who wrote hamlet??/shakespeare who painted guernica??/picasso who painted the starry night??/van gogh gid: 2 syntactic structure: whadvp vbd np vbn semantic category: numeric:date when was hamlet written??/1601 when was guernica painted??/1937 when was the starry night painted??/1889 table 1: seeds used in the experiments.
</prevsent>
</prevsection>
<citsent citstr=" P06-1063 ">
the syntactic analysis of the questions was done by the berkeley parser (petrov and klein, 2007) <papid> N07-1051 </papid>trained on the question bank (judge et al, 2006).<papid> P06-1063 </papid></citsent>
<aftsection>
<nextsent>for question classification, we used li and roth (2002) <papid> C02-1150 </papid>taxonomy and machine learning-based classifier fed with features derived from rule-based classifier (silva et al, 2011).</nextsent>
<nextsent>for the learning of patterns we used the top64 documents retrieved by google and to recognize the named entities in the pattern we apply several strategies, namely: 1) the stanfords conditional random-field-based named entity recognizer (finkel et al, 2005) <papid> P05-1045 </papid>to detect entities of type human; 2) regular expressions to detect numeric and date type entities; 3) gazette ers to detect entities of type location.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2258">
<title id=" W11-2705.xml">exploring linguistically rich patterns for question generation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>gid: 1 syntactic structure: whnp vbd np semantic category: human:individual who wrote hamlet??/shakespeare who painted guernica??/picasso who painted the starry night??/van gogh gid: 2 syntactic structure: whadvp vbd np vbn semantic category: numeric:date when was hamlet written??/1601 when was guernica painted??/1937 when was the starry night painted??/1889 table 1: seeds used in the experiments.
</prevsent>
<prevsent>the syntactic analysis of the questions was done by the berkeley parser (petrov and klein, 2007) <papid> N07-1051 </papid>trained on the question bank (judge et al, 2006).<papid> P06-1063 </papid></prevsent>
</prevsection>
<citsent citstr=" C02-1150 ">
for question classification, we used li and roth (2002) <papid> C02-1150 </papid>taxonomy and machine learning-based classifier fed with features derived from rule-based classifier (silva et al, 2011).</citsent>
<aftsection>
<nextsent>for the learning of patterns we used the top64 documents retrieved by google and to recognize the named entities in the pattern we apply several strategies, namely: 1) the stanfords conditional random-field-based named entity recognizer (finkel et al, 2005) <papid> P05-1045 </papid>to detect entities of type human; 2) regular expressions to detect numeric and date type entities; 3) gazette ers to detect entities of type location.</nextsent>
<nextsent>for the generation of questions we used the top 16documents retrieved by the google for 9 personalities from several domains, like literature (e.g., jane austen) and politics (e.g., adolf hitler).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2259">
<title id=" W11-2705.xml">exploring linguistically rich patterns for question generation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the syntactic analysis of the questions was done by the berkeley parser (petrov and klein, 2007) <papid> N07-1051 </papid>trained on the question bank (judge et al, 2006).<papid> P06-1063 </papid></prevsent>
<prevsent>for question classification, we used li and roth (2002) <papid> C02-1150 </papid>taxonomy and machine learning-based classifier fed with features derived from rule-based classifier (silva et al, 2011).</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
for the learning of patterns we used the top64 documents retrieved by google and to recognize the named entities in the pattern we apply several strategies, namely: 1) the stanfords conditional random-field-based named entity recognizer (finkel et al, 2005) <papid> P05-1045 </papid>to detect entities of type human; 2) regular expressions to detect numeric and date type entities; 3) gazette ers to detect entities of type location.</citsent>
<aftsection>
<nextsent>for the generation of questions we used the top 16documents retrieved by the google for 9 personalities from several domains, like literature (e.g., jane austen) and politics (e.g., adolf hitler).
</nextsent>
<nextsent>we do nothave influence on the content of the retrieved documents, nor perform any pre-processing (like text simplification or anaphora resolution).
</nextsent>
<nextsent>the berkeley parser (petrov and klein, 2007) <papid> N07-1051 </papid>was used to parse the sentences, trained with the wall street journal.</nextsent>
<nextsent>3.2 pattern learning results.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2262">
<title id=" W11-2702.xml">gre3d7 a corpus of distinguishing descriptions for objects in visual scenes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of course, it is also central when machin eis charged with the task of generating natural language, which makes referring expression generation (reg) an important subtask in any natural language generation (nlg) system.
</prevsent>
<prevsent>it is therefore not surprising that reg has attracted great deal of attention from the nlg community over the past three decades.
</prevsent>
</prevsection>
<citsent citstr=" P02-1013 ">
a key factor that hasled to the popularity of regis the widespread agreement that the central task involved is content selec tion: choosing those attributes of target referent that best distinguish it from other dis tractor entities around it (dale and reiter, 1995; van deemter,2000; gardent, 2002; <papid> P02-1013 </papid>krahmer et al, 2003; <papid> J03-1003 </papid>horacek, 2003; <papid> E03-1017 </papid>vander sluis, 2005; kelleher and kruijff, 2006; <papid> P06-1131 </papid>gatt, 2007; viethen and dale, 2008).<papid> W08-1109 </papid></citsent>
<aftsection>
<nextsent>recent work in particular has concentrated on the development of algorithms concerned with the generation of context-free identifying descriptions of objects, as emphasised by three shared-task evaluation competitions (stecs) targeting this particular problem (belz and gatt, 2007; gatt et al, 2008; <papid> W08-1131 </papid>gatt et al, 2009).<papid> W09-0629 </papid></nextsent>
<nextsent>referring expressions of this kind are often referred to as distinguishing descriptions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2264">
<title id=" W11-2702.xml">gre3d7 a corpus of distinguishing descriptions for objects in visual scenes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of course, it is also central when machin eis charged with the task of generating natural language, which makes referring expression generation (reg) an important subtask in any natural language generation (nlg) system.
</prevsent>
<prevsent>it is therefore not surprising that reg has attracted great deal of attention from the nlg community over the past three decades.
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
a key factor that hasled to the popularity of regis the widespread agreement that the central task involved is content selec tion: choosing those attributes of target referent that best distinguish it from other dis tractor entities around it (dale and reiter, 1995; van deemter,2000; gardent, 2002; <papid> P02-1013 </papid>krahmer et al, 2003; <papid> J03-1003 </papid>horacek, 2003; <papid> E03-1017 </papid>vander sluis, 2005; kelleher and kruijff, 2006; <papid> P06-1131 </papid>gatt, 2007; viethen and dale, 2008).<papid> W08-1109 </papid></citsent>
<aftsection>
<nextsent>recent work in particular has concentrated on the development of algorithms concerned with the generation of context-free identifying descriptions of objects, as emphasised by three shared-task evaluation competitions (stecs) targeting this particular problem (belz and gatt, 2007; gatt et al, 2008; <papid> W08-1131 </papid>gatt et al, 2009).<papid> W09-0629 </papid></nextsent>
<nextsent>referring expressions of this kind are often referred to as distinguishing descriptions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2265">
<title id=" W11-2702.xml">gre3d7 a corpus of distinguishing descriptions for objects in visual scenes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of course, it is also central when machin eis charged with the task of generating natural language, which makes referring expression generation (reg) an important subtask in any natural language generation (nlg) system.
</prevsent>
<prevsent>it is therefore not surprising that reg has attracted great deal of attention from the nlg community over the past three decades.
</prevsent>
</prevsection>
<citsent citstr=" E03-1017 ">
a key factor that hasled to the popularity of regis the widespread agreement that the central task involved is content selec tion: choosing those attributes of target referent that best distinguish it from other dis tractor entities around it (dale and reiter, 1995; van deemter,2000; gardent, 2002; <papid> P02-1013 </papid>krahmer et al, 2003; <papid> J03-1003 </papid>horacek, 2003; <papid> E03-1017 </papid>vander sluis, 2005; kelleher and kruijff, 2006; <papid> P06-1131 </papid>gatt, 2007; viethen and dale, 2008).<papid> W08-1109 </papid></citsent>
<aftsection>
<nextsent>recent work in particular has concentrated on the development of algorithms concerned with the generation of context-free identifying descriptions of objects, as emphasised by three shared-task evaluation competitions (stecs) targeting this particular problem (belz and gatt, 2007; gatt et al, 2008; <papid> W08-1131 </papid>gatt et al, 2009).<papid> W09-0629 </papid></nextsent>
<nextsent>referring expressions of this kind are often referred to as distinguishing descriptions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2266">
<title id=" W11-2702.xml">gre3d7 a corpus of distinguishing descriptions for objects in visual scenes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of course, it is also central when machin eis charged with the task of generating natural language, which makes referring expression generation (reg) an important subtask in any natural language generation (nlg) system.
</prevsent>
<prevsent>it is therefore not surprising that reg has attracted great deal of attention from the nlg community over the past three decades.
</prevsent>
</prevsection>
<citsent citstr=" P06-1131 ">
a key factor that hasled to the popularity of regis the widespread agreement that the central task involved is content selec tion: choosing those attributes of target referent that best distinguish it from other dis tractor entities around it (dale and reiter, 1995; van deemter,2000; gardent, 2002; <papid> P02-1013 </papid>krahmer et al, 2003; <papid> J03-1003 </papid>horacek, 2003; <papid> E03-1017 </papid>vander sluis, 2005; kelleher and kruijff, 2006; <papid> P06-1131 </papid>gatt, 2007; viethen and dale, 2008).<papid> W08-1109 </papid></citsent>
<aftsection>
<nextsent>recent work in particular has concentrated on the development of algorithms concerned with the generation of context-free identifying descriptions of objects, as emphasised by three shared-task evaluation competitions (stecs) targeting this particular problem (belz and gatt, 2007; gatt et al, 2008; <papid> W08-1131 </papid>gatt et al, 2009).<papid> W09-0629 </papid></nextsent>
<nextsent>referring expressions of this kind are often referred to as distinguishing descriptions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2267">
<title id=" W11-2702.xml">gre3d7 a corpus of distinguishing descriptions for objects in visual scenes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>of course, it is also central when machin eis charged with the task of generating natural language, which makes referring expression generation (reg) an important subtask in any natural language generation (nlg) system.
</prevsent>
<prevsent>it is therefore not surprising that reg has attracted great deal of attention from the nlg community over the past three decades.
</prevsent>
</prevsection>
<citsent citstr=" W08-1109 ">
a key factor that hasled to the popularity of regis the widespread agreement that the central task involved is content selec tion: choosing those attributes of target referent that best distinguish it from other dis tractor entities around it (dale and reiter, 1995; van deemter,2000; gardent, 2002; <papid> P02-1013 </papid>krahmer et al, 2003; <papid> J03-1003 </papid>horacek, 2003; <papid> E03-1017 </papid>vander sluis, 2005; kelleher and kruijff, 2006; <papid> P06-1131 </papid>gatt, 2007; viethen and dale, 2008).<papid> W08-1109 </papid></citsent>
<aftsection>
<nextsent>recent work in particular has concentrated on the development of algorithms concerned with the generation of context-free identifying descriptions of objects, as emphasised by three shared-task evaluation competitions (stecs) targeting this particular problem (belz and gatt, 2007; gatt et al, 2008; <papid> W08-1131 </papid>gatt et al, 2009).<papid> W09-0629 </papid></nextsent>
<nextsent>referring expressions of this kind are often referred to as distinguishing descriptions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2268">
<title id=" W11-2702.xml">gre3d7 a corpus of distinguishing descriptions for objects in visual scenes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is therefore not surprising that reg has attracted great deal of attention from the nlg community over the past three decades.
</prevsent>
<prevsent>a key factor that hasled to the popularity of regis the widespread agreement that the central task involved is content selec tion: choosing those attributes of target referent that best distinguish it from other dis tractor entities around it (dale and reiter, 1995; van deemter,2000; gardent, 2002; <papid> P02-1013 </papid>krahmer et al, 2003; <papid> J03-1003 </papid>horacek, 2003; <papid> E03-1017 </papid>vander sluis, 2005; kelleher and kruijff, 2006; <papid> P06-1131 </papid>gatt, 2007; viethen and dale, 2008).<papid> W08-1109 </papid></prevsent>
</prevsection>
<citsent citstr=" W08-1131 ">
recent work in particular has concentrated on the development of algorithms concerned with the generation of context-free identifying descriptions of objects, as emphasised by three shared-task evaluation competitions (stecs) targeting this particular problem (belz and gatt, 2007; gatt et al, 2008; <papid> W08-1131 </papid>gatt et al, 2009).<papid> W09-0629 </papid></citsent>
<aftsection>
<nextsent>referring expressions of this kind are often referred to as distinguishing descriptions.
</nextsent>
<nextsent>we are still far from full understanding of how such descriptions should best be generated.
</nextsent>
<nextsent>much work remains to be done before many issues, such as, for example, the generation of relational descriptions and over-specified descriptions or the number of the surrounding objects to be taken into account in visual settings, can be considered resolved.although many authors have explicitly or implicitly acknowledged the importance of generating referring expressions that sound natural (dale, 1989;<papid> P89-1009 </papid>dale and reiter, 1995; gardent et al, 2004; horacek, 2004; vander sluis and krahmer, 2004; kelleher and kruijff, 2006; <papid> P06-1131 </papid>gatt, 2007; gatt et al,2007), much of the original work in reg was neither developed based on empirical evidence about 12 figure 1: the screen showing the first stimulus scene.how humans refer, nor evaluated against human produced referring expressions.</nextsent>
<nextsent>the reg stecs onthe task of content determination form part of recent trend towards more data-oriented development and evaluation of reg algorithms that responds directly to this concern (gupta and stent, 2005; jordan and walker, 2005; gatt et al, 2007; viethen et al, 2010; belz and gatt, 2007; gatt et al, 2008; <papid> W08-1131 </papid>gatt et al., 2009).<papid> W09-0629 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2270">
<title id=" W11-2702.xml">gre3d7 a corpus of distinguishing descriptions for objects in visual scenes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>it is therefore not surprising that reg has attracted great deal of attention from the nlg community over the past three decades.
</prevsent>
<prevsent>a key factor that hasled to the popularity of regis the widespread agreement that the central task involved is content selec tion: choosing those attributes of target referent that best distinguish it from other dis tractor entities around it (dale and reiter, 1995; van deemter,2000; gardent, 2002; <papid> P02-1013 </papid>krahmer et al, 2003; <papid> J03-1003 </papid>horacek, 2003; <papid> E03-1017 </papid>vander sluis, 2005; kelleher and kruijff, 2006; <papid> P06-1131 </papid>gatt, 2007; viethen and dale, 2008).<papid> W08-1109 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-0629 ">
recent work in particular has concentrated on the development of algorithms concerned with the generation of context-free identifying descriptions of objects, as emphasised by three shared-task evaluation competitions (stecs) targeting this particular problem (belz and gatt, 2007; gatt et al, 2008; <papid> W08-1131 </papid>gatt et al, 2009).<papid> W09-0629 </papid></citsent>
<aftsection>
<nextsent>referring expressions of this kind are often referred to as distinguishing descriptions.
</nextsent>
<nextsent>we are still far from full understanding of how such descriptions should best be generated.
</nextsent>
<nextsent>much work remains to be done before many issues, such as, for example, the generation of relational descriptions and over-specified descriptions or the number of the surrounding objects to be taken into account in visual settings, can be considered resolved.although many authors have explicitly or implicitly acknowledged the importance of generating referring expressions that sound natural (dale, 1989;<papid> P89-1009 </papid>dale and reiter, 1995; gardent et al, 2004; horacek, 2004; vander sluis and krahmer, 2004; kelleher and kruijff, 2006; <papid> P06-1131 </papid>gatt, 2007; gatt et al,2007), much of the original work in reg was neither developed based on empirical evidence about 12 figure 1: the screen showing the first stimulus scene.how humans refer, nor evaluated against human produced referring expressions.</nextsent>
<nextsent>the reg stecs onthe task of content determination form part of recent trend towards more data-oriented development and evaluation of reg algorithms that responds directly to this concern (gupta and stent, 2005; jordan and walker, 2005; gatt et al, 2007; viethen et al, 2010; belz and gatt, 2007; gatt et al, 2008; <papid> W08-1131 </papid>gatt et al., 2009).<papid> W09-0629 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2271">
<title id=" W11-2702.xml">gre3d7 a corpus of distinguishing descriptions for objects in visual scenes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>referring expressions of this kind are often referred to as distinguishing descriptions.
</prevsent>
<prevsent>we are still far from full understanding of how such descriptions should best be generated.
</prevsent>
</prevsection>
<citsent citstr=" P89-1009 ">
much work remains to be done before many issues, such as, for example, the generation of relational descriptions and over-specified descriptions or the number of the surrounding objects to be taken into account in visual settings, can be considered resolved.although many authors have explicitly or implicitly acknowledged the importance of generating referring expressions that sound natural (dale, 1989;<papid> P89-1009 </papid>dale and reiter, 1995; gardent et al, 2004; horacek, 2004; vander sluis and krahmer, 2004; kelleher and kruijff, 2006; <papid> P06-1131 </papid>gatt, 2007; gatt et al,2007), much of the original work in reg was neither developed based on empirical evidence about 12 figure 1: the screen showing the first stimulus scene.how humans refer, nor evaluated against human produced referring expressions.</citsent>
<aftsection>
<nextsent>the reg stecs onthe task of content determination form part of recent trend towards more data-oriented development and evaluation of reg algorithms that responds directly to this concern (gupta and stent, 2005; jordan and walker, 2005; gatt et al, 2007; viethen et al, 2010; belz and gatt, 2007; gatt et al, 2008; <papid> W08-1131 </papid>gatt et al., 2009).<papid> W09-0629 </papid></nextsent>
<nextsent>however, the existing datasets used in these experiments involve very simple and usually abstract visual displays of objects rather than coherent scenes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2283">
<title id=" W12-0202.xml">lexical semantics and distribution of suffixes  a visual analysis </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one question we asked ourselves is whether we could predict from the context the likelihood of the suffixes -gate, -geddon and -athon and whether one can identify the lexical semantic content of the suffixes more precisely.
</prevsent>
<prevsent>this task can be formulated as topic modeling problem for which we chose to employ latent dirichlet allocation (lda) (blei et al, 2003).
</prevsent>
</prevsection>
<citsent citstr=" P11-2053 ">
it has recently been used to perform word sense induction from small word contexts (e.g. brody (2009)) and has also proven successful when detecting changes in word meanings over time on small word contexts in dia chronic corpora (rohrdantz et al, 2011).<papid> P11-2053 </papid>we applied an optimized topic model and combined the statistical results with methods from visual analytics.</citsent>
<aftsection>
<nextsent>visual analytics is based on the tight coupling of algorithms for automatic data analysis and interactive visual components (thomas and cook, 2005; keim et al, 2010).
</nextsent>
<nextsent>the idea is to exploit human perceptive abilities to support the detection of interesting patterns (seecard et al (1999) for details).
</nextsent>
<nextsent>examples for visualizations used previously to investigate linguistic questions are mayer et al (2010<papid> W10-2110 </papid>a) on vowel harmony, mayer et al (2010<papid> W10-2110 </papid>b) on consonant patterns, honkela et al (1995) on syntactic categories, rohrdantz et al (2011) <papid> P11-2053 </papid>on lexical semantics across time.we also used visualizations to look at cross linguistic use and productivity of the suffixes.</nextsent>
<nextsent>prominent theoretical work on the productivity of morphemes has been done by baayen (1992) and plag (1999), most computational approaches have worked on english due to the availability of large enough corpora (nishimoto, 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2284">
<title id=" W12-0202.xml">lexical semantics and distribution of suffixes  a visual analysis </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>visual analytics is based on the tight coupling of algorithms for automatic data analysis and interactive visual components (thomas and cook, 2005; keim et al, 2010).
</prevsent>
<prevsent>the idea is to exploit human perceptive abilities to support the detection of interesting patterns (seecard et al (1999) for details).
</prevsent>
</prevsection>
<citsent citstr=" W10-2110 ">
examples for visualizations used previously to investigate linguistic questions are mayer et al (2010<papid> W10-2110 </papid>a) on vowel harmony, mayer et al (2010<papid> W10-2110 </papid>b) on consonant patterns, honkela et al (1995) on syntactic categories, rohrdantz et al (2011) <papid> P11-2053 </papid>on lexical semantics across time.we also used visualizations to look at cross linguistic use and productivity of the suffixes.</citsent>
<aftsection>
<nextsent>prominent theoretical work on the productivity of morphemes has been done by baayen (1992) and plag (1999), most computational approaches have worked on english due to the availability of large enough corpora (nishimoto, 2004).
</nextsent>
<nextsent>to the best of our knowledge, no large-scale quantitative study has been performed which takes into account boththe dia chronic as well as the cross-linguistic dimension of the development.
</nextsent>
<nextsent>3.1 research questions &amp; analysis tasks.
</nextsent>
<nextsent>the object of research are three productive suffixes, namely -gate, geddon and -athon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2289">
<title id=" W12-0504.xml">describing video contents in natural language </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>baiget et al (2007) performed human identification and scene modelling manually and focused on human behaviour description for crosswalk scenes.
</prevsent>
<prevsent>yao et al (2010)introduced their work on video to text description which is dependent on the significant amount of annotated data, requirement that is avoided in this paper.
</prevsent>
</prevsection>
<citsent citstr=" D11-1041 ">
yang et al (2011) <papid> D11-1041 </papid>presented 27framework for static images to textual descriptions where they contained to image with up to two objects.</citsent>
<aftsection>
<nextsent>in contrast, this paper presents work on video streams, handling not only objects but also other features such as actions, age, gender and emotions.
</nextsent>
<nextsent>the study presented in this paper is concerned with production of natural language description for visual scenes in time series using bottom up approach.
</nextsent>
<nextsent>initially high level features (hlfs)are identified in video frames.
</nextsent>
<nextsent>they may be keywords?, such as particular object and its posi tion/moves, used for semantic indexing task in video retrieval.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2290">
<title id=" W12-0504.xml">describing video contents in natural language </title>
<section> natural language generation.  </section>
<citcontext>
<prevsection>
<prevsent>cfg is formalised by 4-tuple: = (t,n, s,r) where is set of terminals (lexicon) shown in figure 3, is set of non-terminals (usually pos tags), is start symbol (one of non-terminals).
</prevsent>
<prevsent>finally is rules / productions of the form ??, where is non-terminal and ? is sequence of terminals and non-terminals which may be empty.
</prevsent>
</prevsection>
<citsent citstr=" W09-0613 ">
for implementing the templates, simple nlg is used (gatt and reiter, 2009).<papid> W09-0613 </papid></citsent>
<aftsection>
<nextsent>it also performs some extra processing automatically: (1) the first letter of each sentence is capitalised, (2) ?-ing?
</nextsent>
<nextsent>isadded to the end of verb as the progressive aspect of the verb is desired, (3) all words are put together in grammatical form, (4) appropriate white spaces are inserted between words, and (5) full stop is placed at the end of the sentence.
</nextsent>
<nextsent>4.3 hierarchical sentence generation.
</nextsent>
<nextsent>in this work we define cfg based presentation for expressing activities by multiple humans.ryoo and aggarwal (2009) used cfg for hierarchical presentation of human actions where complex actions were composed of simpler actions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2291">
<title id=" W12-0504.xml">describing video contents in natural language </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>5.2 evaluation with rouge.
</prevsent>
<prevsent>difficulty in evaluating natural language descriptions stems from the fact that it is not simple task to define the criteria.
</prevsent>
</prevsection>
<citsent citstr=" W04-1013 ">
we adopted rouge,widely used for evaluating automatic sum marisa tion (lin, 2004), <papid> W04-1013 </papid>to calculate the overlap between machine generated and hand annotations.</citsent>
<aftsection>
<nextsent>table 4 shows the results where higher rouge score indicates closer match between them.in overall scores were not very high, demonstrating the fact that humans have different observations and interests while watching the samevideo.
</nextsent>
<nextsent>descriptions were often subjective, de 33 action closeup in/outdoor grouping meeting news traffic rouge-1 0.4369 0.5385 0.2544 0.3067 0.3330 0.4321 0.3121 rouge-2 0.3087 0.3109 0.1877 0.2619 0.2462 0.3218 0.1268 rouge-3 0.2994 0.2106 0.1302 0.1229 0.2400 0.2219 0.1250 rouge-l 0.4369 0.4110 0.2544 0.3067 0.3330 0.3321 0.3121 rouge-w 0.4147 0.4385 0.2877 0.3619 0.3265 0.3318 0.3147 rouge-s 0.3563 0.4193 0.2302 0.2229 0.2648 0.3233 0.3236 rouge-su 0.3686 0.4413 0.2544 0.3067 0.2754 0.3419 0.3407 table 4: rouge scores between machine generated descriptions (reference) and 13 hand annotations (model).
</nextsent>
<nextsent>rouge 1-3 shows n-gram overlap similarity between reference and model descriptions.
</nextsent>
<nextsent>rouge-l is based on longest common sub sequence (lcs).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2292">
<title id=" W11-2015.xml">predicting the micro timing of user input for an incremental spoken dialogue system that completes a users ongoing turn </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>turn completion, that is, finishing users ongoing utterance, can be considered an ideal test-case of incremental spoken language processing, as it requires that all levels of language understanding and production are carried out in real time, without any noticeable lags and with proper timing and even with the ability to predict what will come.
</prevsent>
<prevsent>spoken dialogue systems, especially incremental ones, have come long way towards reducing lags at turn changes (e. g.
</prevsent>
</prevsection>
<citsent citstr=" N09-1071 ">
(raux and eskenazi, 2009; <papid> N09-1071 </papid>skantze and schlangen, 2009)), <papid> E09-1085 </papid>or even predicting upcoming turn changes (schlangen,2006; baumann, 2008; ward et al, 2010).</citsent>
<aftsection>
<nextsent>compared to regular turn changes, where short pauses or overlaps occur frequently (weilhammer and rabold,2003), turn completions in natural dialogues are typically precisely aligned and prosodically highly integrated with the turn that is being completed (lo cal, 2007).
</nextsent>
<nextsent>with ever more incremental (and hence quicker) spoken dialogue systems, the phenomenon of completion comes into reach for sdss, and hence questions of micro-timing become important.
</nextsent>
<nextsent>while completing someone elses turn ? especially for computer ? may be considered impolite or even annoying, being able to do so can be useful capability.
</nextsent>
<nextsent>some tasks where it might be helpful are ? negotiation training to induce stress in human trainee as presented by devault et al (2009), <papid> W09-3902 </papid>or ? pronunciation aids for language learners, in which hard to pronounce words could be spoken simultaneously by the system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2293">
<title id=" W11-2015.xml">predicting the micro timing of user input for an incremental spoken dialogue system that completes a users ongoing turn </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>turn completion, that is, finishing users ongoing utterance, can be considered an ideal test-case of incremental spoken language processing, as it requires that all levels of language understanding and production are carried out in real time, without any noticeable lags and with proper timing and even with the ability to predict what will come.
</prevsent>
<prevsent>spoken dialogue systems, especially incremental ones, have come long way towards reducing lags at turn changes (e. g.
</prevsent>
</prevsection>
<citsent citstr=" E09-1085 ">
(raux and eskenazi, 2009; <papid> N09-1071 </papid>skantze and schlangen, 2009)), <papid> E09-1085 </papid>or even predicting upcoming turn changes (schlangen,2006; baumann, 2008; ward et al, 2010).</citsent>
<aftsection>
<nextsent>compared to regular turn changes, where short pauses or overlaps occur frequently (weilhammer and rabold,2003), turn completions in natural dialogues are typically precisely aligned and prosodically highly integrated with the turn that is being completed (lo cal, 2007).
</nextsent>
<nextsent>with ever more incremental (and hence quicker) spoken dialogue systems, the phenomenon of completion comes into reach for sdss, and hence questions of micro-timing become important.
</nextsent>
<nextsent>while completing someone elses turn ? especially for computer ? may be considered impolite or even annoying, being able to do so can be useful capability.
</nextsent>
<nextsent>some tasks where it might be helpful are ? negotiation training to induce stress in human trainee as presented by devault et al (2009), <papid> W09-3902 </papid>or ? pronunciation aids for language learners, in which hard to pronounce words could be spoken simultaneously by the system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2294">
<title id=" W11-2015.xml">predicting the micro timing of user input for an incremental spoken dialogue system that completes a users ongoing turn </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with ever more incremental (and hence quicker) spoken dialogue systems, the phenomenon of completion comes into reach for sdss, and hence questions of micro-timing become important.
</prevsent>
<prevsent>while completing someone elses turn ? especially for computer ? may be considered impolite or even annoying, being able to do so can be useful capability.
</prevsent>
</prevsection>
<citsent citstr=" W09-3902 ">
some tasks where it might be helpful are ? negotiation training to induce stress in human trainee as presented by devault et al (2009), <papid> W09-3902 </papid>or ? pronunciation aids for language learners, in which hard to pronounce words could be spoken simultaneously by the system.</citsent>
<aftsection>
<nextsent>a system should certainly not try to complete all or even many user turns, but having the capability to do so means that the system has very efficient interact ional device at its disposal.
</nextsent>
<nextsent>furthermore, monitoring the users timing, as is required for the temporal prediction of turn continuations, can also be used for other conversational tasks such as producing back-channels that are precisely aligned to the users back-channel inviting cues, to enable micro-alignment of turn-onsets, or to quickly react to deviations in the users fluency.in this paper, we concentrate on the temporal aspects of turn completion, that is, the prediction of the precise temporal alignment of turn continuation and the technical realization of this timing.
</nextsent>
<nextsent>we assume the task of predicting the completion itself to be handled by some other system component.
</nextsent>
<nextsent>such components are indeed underdevelopment (see section 2).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2296">
<title id=" W11-2015.xml">predicting the micro timing of user input for an incremental spoken dialogue system that completes a users ongoing turn </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in section 6 we first analyse whether enough time to output completion is available sufficiently often, before turning to the question for the actual sub-tasks of when and how to complete.
</prevsent>
<prevsent>we wrap up with concluding remarks and ideas for future work.
</prevsent>
</prevsection>
<citsent citstr=" W09-3937 ">
the general phenomenon of turn completion can be broken down into cases where the completion is spoken simultaneously with the original speaker (turn sharing, (lerner, 2002)) and where the floor changes in mid-utterance (collaborative turn sequences (lerner, 2004) or split utterances (purveret al, 2009)).<papid> W09-3937 </papid></citsent>
<aftsection>
<nextsent>in this paper, differentiation between the two cases is not important, as we only deal with the question of when to start speaking (for the previously non-speaking system) and not the question of whether the current turn owner will stop speaking.
</nextsent>
<nextsent>moreover, whether the other speaker will stop is beyond the systems control.
</nextsent>
<nextsent>lerner (2004) distinguishes turn co-optation, in which listener joins in to come first and win the floor, and turn co completion, in which the completion is produced inchorus.
</nextsent>
<nextsent>both of these phenomena relate to the current speakers speech: either to match it, or to beat it.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2299">
<title id=" W11-2015.xml">predicting the micro timing of user input for an incremental spoken dialogue system that completes a users ongoing turn </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we extend the task to predicting the remaining duration of any currently ongoing word in the turn.
</prevsent>
<prevsent>of course, for this to be possible, words must be recognized while they are still being uttered.
</prevsent>
</prevsection>
<citsent citstr=" N09-1043 ">
we have previously shown (baumann et al, 2009) <papid> N09-1043 </papid>that this can be achieved with incremental asr for the vast majority of words and with an average of 102 ms between when word is first recognized and the words end.as mentioned above, our work relies on other incremental components to form meaningful, turn 121completing application and such components are being developed: incremental understanding is well underway (sagae et al, 2009; <papid> N09-2014 </papid>heintze et al, 2010), <papid> W10-4302 </papid>as is decisionmaking on whether full understanding of an utterance has been reached (devault et al, 2009), <papid> W09-3902 </papid>and purver et al (2011) present an incremental semantics component aimed explicitly at split utterances.</citsent>
<aftsection>
<nextsent>infact, devault et al (2009) <papid> W09-3902 </papid>provide exactly the counterpart to our work, describing method that, given the words of an ongoing utterance, decides when the point of maximum understanding has been reached and with what words this utterance is likely to end.</nextsent>
<nextsent>however, in their system demonstration, sagae et al (2010) <papid> N10-2009 </papid>use short silence time-outs to trigger system responses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2300">
<title id=" W11-2015.xml">predicting the micro timing of user input for an incremental spoken dialogue system that completes a users ongoing turn </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we extend the task to predicting the remaining duration of any currently ongoing word in the turn.
</prevsent>
<prevsent>of course, for this to be possible, words must be recognized while they are still being uttered.
</prevsent>
</prevsection>
<citsent citstr=" N09-2014 ">
we have previously shown (baumann et al, 2009) <papid> N09-1043 </papid>that this can be achieved with incremental asr for the vast majority of words and with an average of 102 ms between when word is first recognized and the words end.as mentioned above, our work relies on other incremental components to form meaningful, turn 121completing application and such components are being developed: incremental understanding is well underway (sagae et al, 2009; <papid> N09-2014 </papid>heintze et al, 2010), <papid> W10-4302 </papid>as is decisionmaking on whether full understanding of an utterance has been reached (devault et al, 2009), <papid> W09-3902 </papid>and purver et al (2011) present an incremental semantics component aimed explicitly at split utterances.</citsent>
<aftsection>
<nextsent>infact, devault et al (2009) <papid> W09-3902 </papid>provide exactly the counterpart to our work, describing method that, given the words of an ongoing utterance, decides when the point of maximum understanding has been reached and with what words this utterance is likely to end.</nextsent>
<nextsent>however, in their system demonstration, sagae et al (2010) <papid> N10-2009 </papid>use short silence time-outs to trigger system responses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2301">
<title id=" W11-2015.xml">predicting the micro timing of user input for an incremental spoken dialogue system that completes a users ongoing turn </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we extend the task to predicting the remaining duration of any currently ongoing word in the turn.
</prevsent>
<prevsent>of course, for this to be possible, words must be recognized while they are still being uttered.
</prevsent>
</prevsection>
<citsent citstr=" W10-4302 ">
we have previously shown (baumann et al, 2009) <papid> N09-1043 </papid>that this can be achieved with incremental asr for the vast majority of words and with an average of 102 ms between when word is first recognized and the words end.as mentioned above, our work relies on other incremental components to form meaningful, turn 121completing application and such components are being developed: incremental understanding is well underway (sagae et al, 2009; <papid> N09-2014 </papid>heintze et al, 2010), <papid> W10-4302 </papid>as is decisionmaking on whether full understanding of an utterance has been reached (devault et al, 2009), <papid> W09-3902 </papid>and purver et al (2011) present an incremental semantics component aimed explicitly at split utterances.</citsent>
<aftsection>
<nextsent>infact, devault et al (2009) <papid> W09-3902 </papid>provide exactly the counterpart to our work, describing method that, given the words of an ongoing utterance, decides when the point of maximum understanding has been reached and with what words this utterance is likely to end.</nextsent>
<nextsent>however, in their system demonstration, sagae et al (2010) <papid> N10-2009 </papid>use short silence time-outs to trigger system responses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2304">
<title id=" W11-2015.xml">predicting the micro timing of user input for an incremental spoken dialogue system that completes a users ongoing turn </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we have previously shown (baumann et al, 2009) <papid> N09-1043 </papid>that this can be achieved with incremental asr for the vast majority of words and with an average of 102 ms between when word is first recognized and the words end.as mentioned above, our work relies on other incremental components to form meaningful, turn 121completing application and such components are being developed: incremental understanding is well underway (sagae et al, 2009; <papid> N09-2014 </papid>heintze et al, 2010), <papid> W10-4302 </papid>as is decisionmaking on whether full understanding of an utterance has been reached (devault et al, 2009), <papid> W09-3902 </papid>and purver et al (2011) present an incremental semantics component aimed explicitly at split utterances.</prevsent>
<prevsent>infact, devault et al (2009) <papid> W09-3902 </papid>provide exactly the counterpart to our work, describing method that, given the words of an ongoing utterance, decides when the point of maximum understanding has been reached and with what words this utterance is likely to end.</prevsent>
</prevsection>
<citsent citstr=" N10-2009 ">
however, in their system demonstration, sagae et al (2010) <papid> N10-2009 </papid>use short silence time-outs to trigger system responses.</citsent>
<aftsection>
<nextsent>our work eliminates the need for such time-outs.hirasawa et al (1999) present study where immediate, overlapping back-channel feedback fromthe system was found to be inferior to acknowledging information only after the users turn.
</nextsent>
<nextsent>however, they disregarded the back-channels?
</nextsent>
<nextsent>micro-temporalalignment as explored in this study (presumably producing back-channels as early as possible), so their negative results cannot be taken as demonstrating general shortcoming of the interact ional strategy.
</nextsent>
<nextsent>the general task that our timing component tackles is illustrated in figure 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2305">
<title id=" W11-2015.xml">predicting the micro timing of user input for an incremental spoken dialogue system that completes a users ongoing turn </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>depending on the estimated lag, completion can be suppressed or, if it is small, fairly good completions can still be realized by shortening the first (few) phonemes of the completion to be synthesized.
</prevsent>
<prevsent>we will now present our overall system before describing two strategies we developed for solving the task just described, and further on present the experiments we conducted with the system and their results in sections 5 and 6.
</prevsent>
</prevsection>
<citsent citstr=" W10-4308 ">
our system is based on the inprotk toolkit for incremental spoken dialogue systems (schlangen et al., 2010) <papid> W10-4308 </papid>which uses sphinx-4 (walker et al, 2004)and marytts (schroder and trouvain, 2003) as underlying asr and tts engines, respectively.</citsent>
<aftsection>
<nextsent>the core of our system is component that incrementally receives rich speech recognition input (words, their durations and pitch track) from an incremental asr and computes the timing of completions.when receiving new word from asr, our component queries an understanding component whether completion can be predicted, and if so, whether such completion should be performed.
</nextsent>
<nextsent>in order to not duplicate the work of devault et al (2009), <papid> W09-3902 </papid>weuse mock implementation of an understanding module, which actually knows what words are going to be spoken (from transcript file) and aims to complete after every word spoken.</nextsent>
<nextsent>we have implemented two strategies for the timing module, which we will describe in turn, after first discussing simple baseline approach.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2309">
<title id=" W11-2015.xml">predicting the micro timing of user input for an incremental spoken dialogue system that completes a users ongoing turn </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>initial experiments support this idea and we would like to extend it to full error estimation capability.
</prevsent>
<prevsent>we have focused the analysis of incrementally comparing expected to actual speech rate to the task of micro-aligning turn-completion and shadowing speaker.
</prevsent>
</prevsection>
<citsent citstr=" C08-2003 ">
however, we believe that this capability can be used in broad range of tasks, e. g. in combination with word-based end-of-turn detection (atterer et al, 2008) <papid> C08-2003 </papid>to allow for swift turn taking.4 in fact, precise micro-alignment of turn hand overs could be used for controlled testing of linguistic/prosodic theory such as the oscillator model of the timing of turn-taking (wilson and wilson, 2005).</citsent>
<aftsection>
<nextsent>finally, duration modelling can be used to quickly detect deviations in speech rate (which may indicate hesitations or planning problems of the user) as they happen (rather than post-hoc), allowing to take the speakers fluency into account in understanding and turn-taking coordination as outlined by clark (2002).
</nextsent>
<nextsent>acknowledgments this work was funded by dfg grant in the emmynoether programme.
</nextsent>
<nextsent>we wish to thank the anonymous reviewers for their very helpful comments.
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2310">
<title id=" W11-1903.xml">relax cor participation in conll shared task on coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>relax cor is constraint-based graph partitioning approach to coreference resolution solved by relaxation labeling.
</prevsent>
<prevsent>the approach combines the strengths of group wise classifiers and chain formation methods in one global method.
</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
the conll-2011 shared task (pradhan et al, 2011)<papid> W11-1901 </papid>is concerned with intra-document coreference resolution in english, using ontonotes corpora.</citsent>
<aftsection>
<nextsent>the core of the task is to identify which expressions (usually nps) in text refer to the same discourse entity.this paper describes the participation of relax cor and is organized as follows.
</nextsent>
<nextsent>section 2 describes relax cor, the system used in the task.
</nextsent>
<nextsent>next, section 3 describes the tuning needed by the system to adapt it to the task issues.
</nextsent>
<nextsent>the same section also analyzes the obtained results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2311">
<title id=" W11-1903.xml">relax cor participation in conll shared task on coreference resolution </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the same section also analyzes the obtained results.
</prevsent>
<prevsent>finally, section 4 concludes the paper.
</prevsent>
</prevsection>
<citsent citstr=" C10-2125 ">
relax cor (sapena et al, 2010<papid> C10-2125 </papid>a) is coreference resolution system based on constraint satisfaction.</citsent>
<aftsection>
<nextsent>it represents the problem as graph connecting any research supported by the spanish science and innovation ministry, via the know2 project (tin2009-14715-c04 04) and from the european communitys seventh framework programme (fp7/2007-2013) under grant agreement number 247762 (faust)pair of candidate co referent mentions and applies relaxation labeling, over set of constraints, to decide the set of most compatible coreference relations.this approach combines classification and clustering in one step.
</nextsent>
<nextsent>thus, decisions are taken considering the entire set of mentions, which ensures consistency and avoids local classification decisions.
</nextsent>
<nextsent>the relax cor implementation used in this task is an improved version of the system that participated in the semeval-2010 task 1 (recasens et al, 2010).<papid> S10-1001 </papid></nextsent>
<nextsent>the knowledge of the system is represented as set of weighted constraints.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2314">
<title id=" W11-1903.xml">relax cor participation in conll shared task on coreference resolution </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>it represents the problem as graph connecting any research supported by the spanish science and innovation ministry, via the know2 project (tin2009-14715-c04 04) and from the european communitys seventh framework programme (fp7/2007-2013) under grant agreement number 247762 (faust)pair of candidate co referent mentions and applies relaxation labeling, over set of constraints, to decide the set of most compatible coreference relations.this approach combines classification and clustering in one step.
</prevsent>
<prevsent>thus, decisions are taken considering the entire set of mentions, which ensures consistency and avoids local classification decisions.
</prevsent>
</prevsection>
<citsent citstr=" S10-1001 ">
the relax cor implementation used in this task is an improved version of the system that participated in the semeval-2010 task 1 (recasens et al, 2010).<papid> S10-1001 </papid></citsent>
<aftsection>
<nextsent>the knowledge of the system is represented as set of weighted constraints.
</nextsent>
<nextsent>each constraint has an associated weight reflecting its confidence.
</nextsent>
<nextsent>the signof the weight indicates that pair or group of mentions corefer (positive) or not (negative).
</nextsent>
<nextsent>only constraints over pairs of mentions were used in the current version of relaxcor.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2318">
<title id=" W11-1903.xml">relax cor participation in conll shared task on coreference resolution </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>i/j in quotes: mi/j is in quotes or inside np or sentence in quotes.
</prevsent>
<prevsent>i/j first: mi/j is the first mention in the sentence.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
lexical: str match: string matching of mi and mj pro str: both are pronouns and their strings match pn str: both are proper names and their strings match nonpro str: string matching like in soon et al (2001) <papid> J01-4004 </papid>and mentions are not pronouns.</citsent>
<aftsection>
<nextsent>head match: string matching of np heads term match: string matching of np terms i/j head term: mi/j head matches with the term morphological: the number of both mentions match: number yes, number no, number un the gender of both mentions match: gender yes, gender no, gender un agreement: gender and number of both mentions match: agreement yes, agreement no, agreement un closest agreement: mi is the first agreement found looking backward from mj : agreement yes, agreement no, agreement un i/j third person: mi/j is 3rd person i/j proper name: mi/j is proper name i/j noun: mi/j is common noun animacy: animacy of both mentions match (person, object) i/j reflexive: mi/j is reflexive pronoun i/j possessive: mi/j is possessive pronoun i/j type p/e/n: mi/j is pronoun (p), ne (e) or nominal (n) figure 1: mention-pair attributes (1/2).
</nextsent>
<nextsent>inside the feature vector.
</nextsent>
<nextsent>after some experiments overdevelopment data, the value of was assigned to 5.
</nextsent>
<nextsent>thus, the negative examples were discarded when they have more than five attribute values different than any positive example.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2320">
<title id=" W11-1903.xml">relax cor participation in conll shared task on coreference resolution </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>optimizing this parameter depends on properties like document size and the quality of the information given by the constraints.
</prevsent>
<prevsent>the development process calculates grid given the possible values of both parameters: from 0 to 1 for balance with step of 0.05, and from 2 to 14 for pruning with step of 2.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
both parameters were empirically adjusted on the development set for the evaluation measure used in this shared task: theun weighted average of muc (vilain et al, 1995), <papid> M95-1005 </papid>b3 (bagga and baldwin, 1998) and entity-based ceaf (luo, 2005).<papid> H05-1004 </papid>figure 4: development process.</citsent>
<aftsection>
<nextsent>the figure shows mucs precision (red), recall (green), and f1 (blue) for each balance value with pruning adjusted to 6.
</nextsent>
<nextsent>relax cor has participated in the conll task in the closed mode.
</nextsent>
<nextsent>all the knowledge required by the feature functions is obtained from the annotations of the corpora and no external resources have been used with the exception of wordnet (miller, 1995), gender and number information (bergsma and lin, 2006) <papid> P06-1005 </papid>and sense inventories.</nextsent>
<nextsent>all of them are allowed by the task organization and available in their web site.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2321">
<title id=" W11-1903.xml">relax cor participation in conll shared task on coreference resolution </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>optimizing this parameter depends on properties like document size and the quality of the information given by the constraints.
</prevsent>
<prevsent>the development process calculates grid given the possible values of both parameters: from 0 to 1 for balance with step of 0.05, and from 2 to 14 for pruning with step of 2.
</prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
both parameters were empirically adjusted on the development set for the evaluation measure used in this shared task: theun weighted average of muc (vilain et al, 1995), <papid> M95-1005 </papid>b3 (bagga and baldwin, 1998) and entity-based ceaf (luo, 2005).<papid> H05-1004 </papid>figure 4: development process.</citsent>
<aftsection>
<nextsent>the figure shows mucs precision (red), recall (green), and f1 (blue) for each balance value with pruning adjusted to 6.
</nextsent>
<nextsent>relax cor has participated in the conll task in the closed mode.
</nextsent>
<nextsent>all the knowledge required by the feature functions is obtained from the annotations of the corpora and no external resources have been used with the exception of wordnet (miller, 1995), gender and number information (bergsma and lin, 2006) <papid> P06-1005 </papid>and sense inventories.</nextsent>
<nextsent>all of them are allowed by the task organization and available in their web site.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2322">
<title id=" W11-1903.xml">relax cor participation in conll shared task on coreference resolution </title>
<section> conll shared task participation.  </section>
<citcontext>
<prevsection>
<prevsent>the figure shows mucs precision (red), recall (green), and f1 (blue) for each balance value with pruning adjusted to 6.
</prevsent>
<prevsent>relax cor has participated in the conll task in the closed mode.
</prevsent>
</prevsection>
<citsent citstr=" P06-1005 ">
all the knowledge required by the feature functions is obtained from the annotations of the corpora and no external resources have been used with the exception of wordnet (miller, 1995), gender and number information (bergsma and lin, 2006) <papid> P06-1005 </papid>and sense inventories.</citsent>
<aftsection>
<nextsent>all of them are allowed by the task organization and available in their web site.
</nextsent>
<nextsent>there are many remarkable features that make this task different and more difficult but realistic than previous ones.
</nextsent>
<nextsent>about mention annotation, itis important to emphasize that singletons are not annotated, mentions must be detected by the system and the mapping between system and true mention sis limited to exact matching of boundaries.
</nextsent>
<nextsent>more over, some verbs have been annotated as co refering mentions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2323">
<title id=" W11-1903.xml">relax cor participation in conll shared task on coreference resolution </title>
<section> conll shared task participation.  </section>
<citcontext>
<prevsection>
<prevsent>about mention annotation, itis important to emphasize that singletons are not annotated, mentions must be detected by the system and the mapping between system and true mention sis limited to exact matching of boundaries.
</prevsent>
<prevsent>more over, some verbs have been annotated as co refering mentions.
</prevsent>
</prevsection>
<citsent citstr=" W10-4305 ">
regarding the evaluation, the scorer usesthe modification of (cai and strube, 2010), <papid> W10-4305 </papid>unprecedented so far, and the corpora was published very recently and there are no published results yet to use as reference.</citsent>
<aftsection>
<nextsent>finally, all the preprocessed information is automatic for the test dataset, carring out some noisy errors which is handicap from the point of view of machine learning.following there is description of the mention detection system developed for the task and an analysis of the obtained results in the development dataset.
</nextsent>
<nextsent>37 3.1 mention detection system.
</nextsent>
<nextsent>the mention detection system extracts one mention for every np found in the syntactic tree, one for every pronoun and one for every named entity.
</nextsent>
<nextsent>then,the head of every np is determined using part-of speech tags and set of rules from (collins, 1999).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2327">
<title id=" W11-2104.xml">evaluate with confidence estimation machine ranking of translation outputs using grammatical features </title>
<section> automatic ranking method.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 from confidence estimation to ranking.
</prevsent>
<prevsent>confidence estimation has been seen from the natural language processing (nlp) perspective as problem of binary classification in order to assess the correctness of nlp system output.
</prevsent>
</prevsection>
<citsent citstr=" C04-1046 ">
previous work focusing on machine translation includes statistical methods for estimating correctness scores or correctness probabilities, following rich search over the spectrum of possible features (blatz et al, 2004<papid> C04-1046 </papid>a; ueffing and ney, 2005; <papid> H05-1096 </papid>specia et al, 2009; raybaud and caroline lavecchia, 2009; rosti et al, 65 2007).in this work we slightly transform the binary classification practice to fit the standard wmt human evaluation process.</citsent>
<aftsection>
<nextsent>as human annotators have provided their evaluation in the form of ranking of five system outputs at sentence level, we build our evaluation mechanism with similar functionality, aiming to training from and evaluating against this data.
</nextsent>
<nextsent>evaluation scores and results can be then calculated based on comparative analysis of the performance of each system.
</nextsent>
<nextsent>whereas latest work, such as specia et al (2010),has focused on learning to assess segment performance independently for each system output, our contribution measures the performance by comparing the system outputs with each other and consequently ranking them.
</nextsent>
<nextsent>the exact method is described below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2328">
<title id=" W11-2104.xml">evaluate with confidence estimation machine ranking of translation outputs using grammatical features </title>
<section> automatic ranking method.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 from confidence estimation to ranking.
</prevsent>
<prevsent>confidence estimation has been seen from the natural language processing (nlp) perspective as problem of binary classification in order to assess the correctness of nlp system output.
</prevsent>
</prevsection>
<citsent citstr=" H05-1096 ">
previous work focusing on machine translation includes statistical methods for estimating correctness scores or correctness probabilities, following rich search over the spectrum of possible features (blatz et al, 2004<papid> C04-1046 </papid>a; ueffing and ney, 2005; <papid> H05-1096 </papid>specia et al, 2009; raybaud and caroline lavecchia, 2009; rosti et al, 65 2007).in this work we slightly transform the binary classification practice to fit the standard wmt human evaluation process.</citsent>
<aftsection>
<nextsent>as human annotators have provided their evaluation in the form of ranking of five system outputs at sentence level, we build our evaluation mechanism with similar functionality, aiming to training from and evaluating against this data.
</nextsent>
<nextsent>evaluation scores and results can be then calculated based on comparative analysis of the performance of each system.
</nextsent>
<nextsent>whereas latest work, such as specia et al (2010),has focused on learning to assess segment performance independently for each system output, our contribution measures the performance by comparing the system outputs with each other and consequently ranking them.
</nextsent>
<nextsent>the exact method is described below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2329">
<title id=" W11-2104.xml">evaluate with confidence estimation machine ranking of translation outputs using grammatical features </title>
<section> automatic ranking method.  </section>
<citcontext>
<prevsection>
<prevsent>target language model: language models provide statistics concerning the correctness of the words?
</prevsent>
<prevsent>sequence on the target language.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
such language model features include: ? the smoothed n-gram probability of the entire target sentence for language model of order 5, along with ? uni-gram, bi-gram, tri-gram probabilities and ? count of unknown words ? parsing: processing features acquired from pcfg parsing (petrov et al, 2006) <papid> P06-1055 </papid>for both source and target side include: ? parse log likelihood, ? number of n-best trees, ? confidence for the best parse, ? average confidence of all trees.ratios of the above target features to their respective source features were included.</citsent>
<aftsection>
<nextsent>shallow grammatical match: the number of occurences of particular node tags on both the source and the target was counted on the pcfg parses.
</nextsent>
<nextsent>in particular, nps, vps, pps, nns and punctuation occurences were counted.
</nextsent>
<nextsent>then the ratio of the occurences of each tag in the target sentence by its occurences on the source sentence was also calculated.
</nextsent>
<nextsent>2.4 classifiers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2330">
<title id=" W11-2104.xml">evaluate with confidence estimation machine ranking of translation outputs using grammatical features </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>for testing, the classifiers were used to perform ranking on test set of 184 sentences which had been kept apart from the 2010 data, with the criterion that they do not contain contradictions among human judgments.
</prevsent>
<prevsent>in order to allow further comparison with other evaluation metrics, we performed an extended ex periment: we trained the classifiers over the wmt 2008 and 2009 data and let them perform automatic ranking on the full wmt 2010 test set, this time without any restriction on human evaluation agreement.
</prevsent>
</prevsection>
<citsent citstr=" W09-3712 ">
in both experiments, tokenization was performed with the punkt tokenizer (kiss et al, 2006; garrette and klein, 2009), <papid> W09-3712 </papid>while n-gram features were generated with the srilm toolkit (stolcke, 2002).</citsent>
<aftsection>
<nextsent>the language model was relatively big and had been built upon all lower cased monolingual training sets for the wmt 2011 shared task, interpolated on the 2007 test set.
</nextsent>
<nextsent>as pcfg parser, the berkeley parser (petrov and klein, 2007) <papid> N07-1051 </papid>was preferred, due 1data acquired from http://www.statmt.org/wmt11to the possibility of easily obtaining complex internal statistics, including n-best trees.</nextsent>
<nextsent>unfortunately,the time required for parsing leads to significant delays at the overall processing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2331">
<title id=" W11-2104.xml">evaluate with confidence estimation machine ranking of translation outputs using grammatical features </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>in both experiments, tokenization was performed with the punkt tokenizer (kiss et al, 2006; garrette and klein, 2009), <papid> W09-3712 </papid>while n-gram features were generated with the srilm toolkit (stolcke, 2002).</prevsent>
<prevsent>the language model was relatively big and had been built upon all lower cased monolingual training sets for the wmt 2011 shared task, interpolated on the 2007 test set.</prevsent>
</prevsection>
<citsent citstr=" N07-1051 ">
as pcfg parser, the berkeley parser (petrov and klein, 2007) <papid> N07-1051 </papid>was preferred, due 1data acquired from http://www.statmt.org/wmt11to the possibility of easily obtaining complex internal statistics, including n-best trees.</citsent>
<aftsection>
<nextsent>unfortunately,the time required for parsing leads to significant delays at the overall processing.
</nextsent>
<nextsent>the machine learning algorithms were implemented with the orange toolkit (demar et al, 2004).
</nextsent>
<nextsent>3.2 feature selection.
</nextsent>
<nextsent>although the automatic nlp tools provided lot of features (section 2.3), the classification methods weused (and particularly nave bayes were the development was focused on) would be expected to perform better given smaller group of statistically independent features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2334">
<title id=" W12-1811.xml">bridging gaps for spoken dialog system frameworks in instructional settings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lastly we will present some additional needs for spoken dialog systems frameworks to bridge gaps in dialog systems for instructional use.a variety of systems have been developed that address many of these needs, but all suffer from signif 21 icant limitations.
</prevsent>
<prevsent>availability and affordability have posed some of the knottiest problems.
</prevsent>
</prevsection>
<citsent citstr=" H01-1073 ">
for example,many of the galaxy communicator research systems, such as those by university of colorado (pellom et al, 2001), <papid> H01-1073 </papid>mit, and cmu, were made available to the research community.</citsent>
<aftsection>
<nextsent>however, many ofthe systems are no longer available, usable, or supported, as research groups have disbanded and systems architectures have changed.
</nextsent>
<nextsent>maintaining systems over time requires group and community commitment, facilitated by an open-source framework.other tool kits and frameworks have become problematic due to conflicts between availability and affordability.
</nextsent>
<nextsent>the long-popular cslu toolkit (sutton and cole, 1997) has recently shifted to commercial footing.
</nextsent>
<nextsent>similarly, several industry platforms have provided free non-commercial voice xml hosting,as simple spoken dialog development environment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2335">
<title id=" W12-1811.xml">bridging gaps for spoken dialog system frameworks in instructional settings </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the environment changes rapidly.
</prevsent>
<prevsent>of three freely available academic systems and five voice xml platforms listed in 2009 survey (jokinen and mctear, 2009), two have already gone to paid status as of late 2011.
</prevsent>
</prevsection>
<citsent citstr=" W07-0305 ">
two frameworks have emerged in recent years as popular sds frameworks: the ravenclaw/olympus framework (bohus et al, 2007) <papid> W07-0305 </papid>and voice xml, hosted on one of the industrial platforms, such as nuances cafe or voxeo1.</citsent>
<aftsection>
<nextsent>however, they do seemto address the needs of different user groups.
</nextsent>
<nextsent>raven claw/olympus has been more widely adopted in the research community: it is robust, flexible, exten sible, open-source, provides diverse use cases, and has an active support and development community.
</nextsent>
<nextsent>in contrast, the voice xml platforms have proven popular in an instructional setting, as attested by the large number of online homework assignments employing voicexml.
</nextsent>
<nextsent>these voice xml frameworks offer very simple, easy-to-use environments that are largely platform-independent, include basic support and tutorials, and provide simple baseline applications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2336">
<title id=" W11-1915.xml">polyco a multilayer perceptron approach for coreference detection </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>coreference resolution is the process of determining whether two expressions in natural language refer tothe same entity in the world.
</prevsent>
<prevsent>it is an important sub task in natural language processing systems.
</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
in this paper, we present learning approach to coreference resolution of named entities (ne), pronouns (prp), noun phrases (np) in unrestricted text according to the conll-2011 shared task (pradhan et al, 2011).<papid> W11-1901 </papid></citsent>
<aftsection>
<nextsent>this system have been used in the context of closed track.
</nextsent>
<nextsent>many learning-based systems have been proposed to solve coreference resolution task, and soons (soonet al, 2001) <papid> J01-4004 </papid>architecture is one of the most popular ones.</nextsent>
<nextsent>in this proposition, all possible mentions in training document are determined by apipeline of natural language processing (nlp) modules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2337">
<title id=" W11-1915.xml">polyco a multilayer perceptron approach for coreference detection </title>
<section> previous propositions.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we present learning approach to coreference resolution of named entities (ne), pronouns (prp), noun phrases (np) in unrestricted text according to the conll-2011 shared task (pradhan et al, 2011).<papid> W11-1901 </papid></prevsent>
<prevsent>this system have been used in the context of closed track.</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
many learning-based systems have been proposed to solve coreference resolution task, and soons (soonet al, 2001) <papid> J01-4004 </papid>architecture is one of the most popular ones.</citsent>
<aftsection>
<nextsent>in this proposition, all possible mentions in training document are determined by apipeline of natural language processing (nlp) modules.
</nextsent>
<nextsent>then, training examples are generated as feature vectors.
</nextsent>
<nextsent>each feature vector represents pairof mentions that can potentially corefer.
</nextsent>
<nextsent>those vectors are used as training examples given to build c5 classifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2338">
<title id=" W11-1915.xml">polyco a multilayer perceptron approach for coreference detection </title>
<section> previous propositions.  </section>
<citcontext>
<prevsection>
<prevsent>since then, this dominant architecture has been widely implemented.
</prevsent>
<prevsent>as it is very flexible proposition, many families of classifiers have been used,trained with various configurations of feature vectors.
</prevsent>
</prevsection>
<citsent citstr=" L08-1328 ">
good results are obtained with svm classifiers, like described in (versley et al, 2008).<papid> L08-1328 </papid></citsent>
<aftsection>
<nextsent>some propositions keep only the principle of feature vectors, associated with more complex coreference detection algorithms.
</nextsent>
<nextsent>a constraint-based graph partitioning system has been experimented by (sapena et al., 2010) <papid> C10-2125 </papid>and coreference detection system basedon markov logic networks (mlns) has been proposed by (poon and domingos, 2008).<papid> D08-1068 </papid></nextsent>
<nextsent>a considerable engineering effort is needed to achieve the coreference resolution task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2339">
<title id=" W11-1915.xml">polyco a multilayer perceptron approach for coreference detection </title>
<section> previous propositions.  </section>
<citcontext>
<prevsection>
<prevsent>good results are obtained with svm classifiers, like described in (versley et al, 2008).<papid> L08-1328 </papid></prevsent>
<prevsent>some propositions keep only the principle of feature vectors, associated with more complex coreference detection algorithms.</prevsent>
</prevsection>
<citsent citstr=" C10-2125 ">
a constraint-based graph partitioning system has been experimented by (sapena et al., 2010) <papid> C10-2125 </papid>and coreference detection system basedon markov logic networks (mlns) has been proposed by (poon and domingos, 2008).<papid> D08-1068 </papid></citsent>
<aftsection>
<nextsent>a considerable engineering effort is needed to achieve the coreference resolution task.
</nextsent>
<nextsent>a significant part of this effort concerns feature engineering.
</nextsent>
<nextsent>we decided to keep the well established architecture of (soon et al, 2001) <papid> J01-4004 </papid>with pre-processing nlp pipeline used to prepare pairs of coreferencefeatures.</nextsent>
<nextsent>the features are then submitted to the classifier for pairing validation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2340">
<title id=" W11-1915.xml">polyco a multilayer perceptron approach for coreference detection </title>
<section> previous propositions.  </section>
<citcontext>
<prevsection>
<prevsent>good results are obtained with svm classifiers, like described in (versley et al, 2008).<papid> L08-1328 </papid></prevsent>
<prevsent>some propositions keep only the principle of feature vectors, associated with more complex coreference detection algorithms.</prevsent>
</prevsection>
<citsent citstr=" D08-1068 ">
a constraint-based graph partitioning system has been experimented by (sapena et al., 2010) <papid> C10-2125 </papid>and coreference detection system basedon markov logic networks (mlns) has been proposed by (poon and domingos, 2008).<papid> D08-1068 </papid></citsent>
<aftsection>
<nextsent>a considerable engineering effort is needed to achieve the coreference resolution task.
</nextsent>
<nextsent>a significant part of this effort concerns feature engineering.
</nextsent>
<nextsent>we decided to keep the well established architecture of (soon et al, 2001) <papid> J01-4004 </papid>with pre-processing nlp pipeline used to prepare pairs of coreferencefeatures.</nextsent>
<nextsent>the features are then submitted to the classifier for pairing validation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2342">
<title id=" W11-1915.xml">polyco a multilayer perceptron approach for coreference detection </title>
<section> architecture of the proposed system.  </section>
<citcontext>
<prevsection>
<prevsent>ontonotes corpus includes part-of-speech tagging, noun phrases identification and named entity labels.we introduce complementary modules to detect gender and number, and evaluate mentions alia sing andsimilarity.
</prevsent>
<prevsent>the detection task is composed of 4 mod ules: ? candidate mentions detection module, based on extraction rules, using ontonotes layers.
</prevsent>
</prevsection>
<citsent citstr=" W10-4228 ">
named entities alias detection module, based on the previous version of poly-co, described in (charton et al, 2010).<papid> W10-4228 </papid></citsent>
<aftsection>
<nextsent>the purpose of this module is to identify variations in names of the same entity by examination of their surface form.?
</nextsent>
<nextsent>similarity calculation module, used to evaluate the similarity of two mentions according to comparison of their string.
</nextsent>
<nextsent>gender and number detection module, which determines gender and number for any candidate mention.
</nextsent>
<nextsent>in the training pipeline, the candidate mentions detection module and the alias detection module are replaced by unique candidate mentions extraction module.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2343">
<title id=" W11-2213.xml">unsupervised name ambiguity resolution using a generative model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we conduct detailed evaluation on multiple data sets containing ambiguous person, location and organization names and for multiple languages such as english, spanish, romanian and bulgarian.
</prevsent>
<prevsent>we conduct comparative studies with existing approaches and show substantial improvement of 15 to 35% in task accuracy.
</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
recently, ambiguity resolution for names found on the web (artiles et al , 2007), <papid> W07-2012 </papid>wikipedia articles (bunescu and pasca, 2006), news texts (pedersen et al ., 2005) and medical literature (ginter et al , 2004) has become an active area of research.</citsent>
<aftsection>
<nextsent>like words,names are ambiguous and can refer to multiple entities.
</nextsent>
<nextsent>for example, web search for jerry hobbs on google returns mixture of documents associated with two different entities in the top 10 search results.
</nextsent>
<nextsent>one refers to computational linguist at university of southern california and the other refers to fugitive and murderer.
</nextsent>
<nextsent>disambiguating the names and identifying the correct entity is very important especially for web search applications since 11-17% of the web search queries are composed of person name and term (artiles et al , 2009<papid> D09-1056 </papid>a).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2344">
<title id=" W11-2213.xml">unsupervised name ambiguity resolution using a generative model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for example, web search for jerry hobbs on google returns mixture of documents associated with two different entities in the top 10 search results.
</prevsent>
<prevsent>one refers to computational linguist at university of southern california and the other refers to fugitive and murderer.
</prevsent>
</prevsection>
<citsent citstr=" D09-1056 ">
disambiguating the names and identifying the correct entity is very important especially for web search applications since 11-17% of the web search queries are composed of person name and term (artiles et al , 2009<papid> D09-1056 </papid>a).</citsent>
<aftsection>
<nextsent>in the past, there has been substantial body ofwork in the area of name disambiguation under variety of different names and using diverse set of approaches.
</nextsent>
<nextsent>some refer to the task as cross-document coreference resolution (bagga and baldwin, 1998), <papid> P98-1012 </papid>name discrimination (pedersen et al , 2005) or web people search (webps) (artiles et al , 2007).<papid> W07-2012 </papid></nextsent>
<nextsent>the majority of the approaches focus on person name ambiguity (chen and martin, 2007; <papid> W07-2024 </papid>artiles et al ,2010), some have also explored organization and location name disambiguation (pedersen et al , 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2349">
<title id=" W11-2213.xml">unsupervised name ambiguity resolution using a generative model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>disambiguating the names and identifying the correct entity is very important especially for web search applications since 11-17% of the web search queries are composed of person name and term (artiles et al , 2009<papid> D09-1056 </papid>a).</prevsent>
<prevsent>in the past, there has been substantial body ofwork in the area of name disambiguation under variety of different names and using diverse set of ap proaches.</prevsent>
</prevsection>
<citsent citstr=" P98-1012 ">
some refer to the task as cross-document coreference resolution (bagga and baldwin, 1998), <papid> P98-1012 </papid>name discrimination (pedersen et al , 2005) or web people search (webps) (artiles et al , 2007).<papid> W07-2012 </papid></citsent>
<aftsection>
<nextsent>the majority of the approaches focus on person name ambiguity (chen and martin, 2007; <papid> W07-2024 </papid>artiles et al ,2010), some have also explored organization and location name disambiguation (pedersen et al , 2006).</nextsent>
<nextsent>the intuition behind most approaches follows the distributional hypothesis (harris, 1954) according to which ambiguous names sharing the same contexts tend to refer to the same individual.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2351">
<title id=" W11-2213.xml">unsupervised name ambiguity resolution using a generative model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the past, there has been substantial body ofwork in the area of name disambiguation under variety of different names and using diverse set of approaches.
</prevsent>
<prevsent>some refer to the task as cross-document coreference resolution (bagga and baldwin, 1998), <papid> P98-1012 </papid>name discrimination (pedersen et al , 2005) or web people search (webps) (artiles et al , 2007).<papid> W07-2012 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-2024 ">
the majority of the approaches focus on person name ambiguity (chen and martin, 2007; <papid> W07-2024 </papid>artiles et al ,2010), some have also explored organization and location name disambiguation (pedersen et al , 2006).</citsent>
<aftsection>
<nextsent>the intuition behind most approaches follows the distributional hypothesis (harris, 1954) according to which ambiguous names sharing the same contexts tend to refer to the same individual.
</nextsent>
<nextsent>to model these characteristics, bunescu and pasca (2006) and cucerzan (2007) <papid> D07-1074 </papid>incorporate information from wikipedia articles, artiles et al  (2007) <papid> W07-2012 </papid>use webpage content, mann and yarowsky (2003) <papid> W03-0405 </papid>extract biographic facts.</nextsent>
<nextsent>the approaches used in the webps tasks mainly relyon bag-of-words representations (artiles et al , 2007; <papid> W07-2012 </papid>chen and martin, 2007; <papid> W07-2024 </papid>artiles et al , 2009<papid> D09-1056 </papid>b).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2353">
<title id=" W11-2213.xml">unsupervised name ambiguity resolution using a generative model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the majority of the approaches focus on person name ambiguity (chen and martin, 2007; <papid> W07-2024 </papid>artiles et al ,2010), some have also explored organization and location name disambiguation (pedersen et al , 2006).</prevsent>
<prevsent>the intuition behind most approaches follows the distributional hypothesis (harris, 1954) according to which ambiguous names sharing the same contexts tend to refer to the same individual.</prevsent>
</prevsection>
<citsent citstr=" D07-1074 ">
to model these characteristics, bunescu and pasca (2006) and cucerzan (2007) <papid> D07-1074 </papid>incorporate information from wikipedia articles, artiles et al  (2007) <papid> W07-2012 </papid>use webpage content, mann and yarowsky (2003) <papid> W03-0405 </papid>extract biographic facts.</citsent>
<aftsection>
<nextsent>the approaches used in the webps tasks mainly relyon bag-of-words representations (artiles et al , 2007; <papid> W07-2012 </papid>chen and martin, 2007; <papid> W07-2024 </papid>artiles et al , 2009<papid> D09-1056 </papid>b).</nextsent>
<nextsent>most methods suffer from common drawback they relyon surface features such as word co-occurrences, which are insufficient to capture hidden information pertaining to the entities (senses) associated with the documents.we take novel approach for tackling the problem of name ambiguity using an unsupervised topic modeling framework.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2355">
<title id=" W11-2213.xml">unsupervised name ambiguity resolution using a generative model </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the majority of the approaches focus on person name ambiguity (chen and martin, 2007; <papid> W07-2024 </papid>artiles et al ,2010), some have also explored organization and location name disambiguation (pedersen et al , 2006).</prevsent>
<prevsent>the intuition behind most approaches follows the distributional hypothesis (harris, 1954) according to which ambiguous names sharing the same contexts tend to refer to the same individual.</prevsent>
</prevsection>
<citsent citstr=" W03-0405 ">
to model these characteristics, bunescu and pasca (2006) and cucerzan (2007) <papid> D07-1074 </papid>incorporate information from wikipedia articles, artiles et al  (2007) <papid> W07-2012 </papid>use webpage content, mann and yarowsky (2003) <papid> W03-0405 </papid>extract biographic facts.</citsent>
<aftsection>
<nextsent>the approaches used in the webps tasks mainly relyon bag-of-words representations (artiles et al , 2007; <papid> W07-2012 </papid>chen and martin, 2007; <papid> W07-2024 </papid>artiles et al , 2009<papid> D09-1056 </papid>b).</nextsent>
<nextsent>most methods suffer from common drawback they relyon surface features such as word co-occurrences, which are insufficient to capture hidden information pertaining to the entities (senses) associated with the documents.we take novel approach for tackling the problem of name ambiguity using an unsupervised topic modeling framework.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2376">
<title id=" W11-2213.xml">unsupervised name ambiguity resolution using a generative model </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>others (bunescu and pasca, 2006; cucerzan, 2007; <papid> D07-1074 </papid>nguyen and cao, 2008) work on wikipedia articles, using infobox and link information.</prevsent>
<prevsent>pedersen et al  (2006) relyon second order co-occurrence vectors.</prevsent>
</prevsection>
<citsent citstr=" W07-2041 ">
a few others (matthias, 2005; wan et al , 2005; popescu and magnini, 2007) <papid> W07-2041 </papid>identify names of people, location sand organizations and use them as source of evidence to measure the similarity between documents containing the ambiguous names.</citsent>
<aftsection>
<nextsent>the most similar work to ours is that of song et al  (2007) whouse topic-based modeling approach for name disambiguation.
</nextsent>
<nextsent>however, their method explicitly tries to model the distribution of latent topics with regard to person names and words appearing within documents whereas in our method, the latent topics represent the underlying entities (name senses) for an ambiguous name.
</nextsent>
<nextsent>unlike the previous approaches which were specifically designed and evaluated on the webps 106 task or corpus such as wikipedia or the web, inthis paper we show novel unsupervised topic modeling approach for name disambiguation for any corpora (i.e. web, news, wikipedia), languages (i.e.english, spanish, romanian and bulgarian) and semantic categories (i.e. people, location and organization).
</nextsent>
<nextsent>the obtained results show substantial improvements over the existing approaches.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2377">
<title id=" W11-2213.xml">unsupervised name ambiguity resolution using a generative model </title>
<section> name disambiguation with lda.  </section>
<citcontext>
<prevsection>
<prevsent>the obtained results show substantial improvements over the existing approaches.
</prevsent>
<prevsent>recently, topic modeling methods have found widespread applications in nlp for various tasks such as summarization (daume?
</prevsent>
</prevsection>
<citsent citstr=" P10-1044 ">
iii andmarcu, 2006), inferring concept-attribute attachments (reisinger and pasca, 2009), selectional preferences (ritter et al , 2010) <papid> P10-1044 </papid>and cross-document co-reference resolution (haghighi and klein, 2010).<papid> N10-1061 </papid></citsent>
<aftsection>
<nextsent>topic models such as lda are generative models for documents and represent hidden or latent topics (where topic is probability distribution overwords) underlying the semantic structure of documents.
</nextsent>
<nextsent>an important use for methods such as lda is to infer the set of topics associated with given document (or collection of documents).
</nextsent>
<nextsent>next, we present novel approach for the task of name disambiguation using unsupervised topic models.
</nextsent>
<nextsent>3.1 method description.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2378">
<title id=" W11-2213.xml">unsupervised name ambiguity resolution using a generative model </title>
<section> name disambiguation with lda.  </section>
<citcontext>
<prevsection>
<prevsent>the obtained results show substantial improvements over the existing approaches.
</prevsent>
<prevsent>recently, topic modeling methods have found widespread applications in nlp for various tasks such as summarization (daume?
</prevsent>
</prevsection>
<citsent citstr=" N10-1061 ">
iii andmarcu, 2006), inferring concept-attribute attachments (reisinger and pasca, 2009), selectional preferences (ritter et al , 2010) <papid> P10-1044 </papid>and cross-document co-reference resolution (haghighi and klein, 2010).<papid> N10-1061 </papid></citsent>
<aftsection>
<nextsent>topic models such as lda are generative models for documents and represent hidden or latent topics (where topic is probability distribution overwords) underlying the semantic structure of documents.
</nextsent>
<nextsent>an important use for methods such as lda is to infer the set of topics associated with given document (or collection of documents).
</nextsent>
<nextsent>next, we present novel approach for the task of name disambiguation using unsupervised topic models.
</nextsent>
<nextsent>3.1 method description.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2392">
<title id=" W12-1505.xml">minkapp generating spatiotemporal summaries for nature conservation volunteers </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>nlg may serve the function of supplying this feedback.
</prevsent>
<prevsent>we are particularly interested in summarizing raw geographical and temporal data whose semantic sneed to be computed at run time ? so called spatiotemporal nlg.
</prevsent>
</prevsection>
<citsent citstr=" W08-1104 ">
such extended techniques are studied in data-to-text nlg (molina and stent, 2010; portet et al, 2009; reiter et al, 2005; turner et al., 2008; <papid> W08-1104 </papid>thomas et al, published online 2010).</citsent>
<aftsection>
<nextsent>generating text from spatio-temporal data involve snot just finding data abstractions, but also determining appropriate descriptors for them (turner et al, 2008).<papid> W08-1104 </papid></nextsent>
<nextsent>turner et. al (2008) <papid> W08-1104 </papid>present case study in weather forecast generation where selection of spatial descriptors is partly based on domain specific (weather related) links between spatial descriptors 17 and weather phenomena.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2395">
<title id=" W12-1707.xml">modeling covert event retrieval in logical metonymy probabilistic and distributional accounts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>distributional models typically do not require any independence assumptions, and include second-order co-occurrences.
</prevsent>
<prevsent>at the same time, how to integrate context into the vector computation is essentially an open research question (mitchell and lapata, 2010).in this paper, we provide the first (to our knowl edge) distributional model of logical metonymy by extending the context update of lencis ecu model (lenci, 2011).
</prevsent>
</prevsection>
<citsent citstr=" J03-2004 ">
we compare this model toa previous probabilistic approach (lapata and lascarides, 2003<papid> J03-2004 </papid>a; lapata et al , 2003b).</citsent>
<aftsection>
<nextsent>in contrast to most experimental studies on logical metonymy, which deal with english data (with the exception of lapata et al  (2003b)), we focus on german.
</nextsent>
<nextsent>we estimate our models on large web corpus and evaluate them on psycho linguistic dataset (zarcone and pad?, 2011; zarcone et al , 2012).
</nextsent>
<nextsent>the task we use to evaluate our models is to distinguish covert events with high typicality / thematic fit (e.g. the student finished the beer ??
</nextsent>
<nextsent>drinking) from low typicality / thematic fit covert events (??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2396">
<title id=" W12-1707.xml">modeling covert event retrieval in logical metonymy probabilistic and distributional accounts </title>
<section> probabilistic models of logical metonymy.  </section>
<citcontext>
<prevsection>
<prevsent>we present two models with different independence assumptions.
</prevsent>
<prevsent>1this statement refers to the simple probabilistic models we consider, which are estimated directly from corpus co-occurrencefrequencies.
</prevsent>
</prevsection>
<citsent citstr=" C00-2094 ">
the situation is different for more complex probabilistic models, for example generative models that introduce latent variables, which can amount to clustering based on higher order co-occurrences, as in, e.g., prescher et al  (2000).<papid> C00-2094 </papid></citsent>
<aftsection>
<nextsent>2.1 the sovp model.
</nextsent>
<nextsent>lapata et al  develop model which we will referto as the sovp model.2 it assumes generative process which first generates the covert event and then generates all other variables based on the choice of e: (s, v, o, e) ? (e) (o|e) (v|e) (s|e) they predict that the selected covert event e?
</nextsent>
<nextsent>forgiven context is the event which maximizes (s, v, o, e): e?
</nextsent>
<nextsent>= argmax p (e) (o|e) (v|e) (s|e) these distributions are estimated as follows: p?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2397">
<title id=" W12-1707.xml">modeling covert event retrieval in logical metonymy probabilistic and distributional accounts </title>
<section> similarity-based models.  </section>
<citcontext>
<prevsection>
<prevsent>it builds on the distributional hypothesis (harris, 1954; miller and charles, 1991) which states that words occurring in similar contexts are semantically similar.
</prevsent>
<prevsent>in distributional models, the meaning of word is represented as vector whose dimensions represent features of its linguistic context.
</prevsent>
</prevsection>
<citsent citstr=" P98-2127 ">
these features can be chosen in different ways; popular choices are simple words (schtze, 1992) or lexicalized dependency relations (lin, 1998; <papid> P98-2127 </papid>pad?</citsent>
<aftsection>
<nextsent>and lapata, 2007).
</nextsent>
<nextsent>semantic similarity can then be approximated by vector similarity using wide range of similarity metrics (lee, 1999).<papid> P99-1004 </papid></nextsent>
<nextsent>3.1.1 distributional memorya recent multi-purpose framework in distributional semantics is distributional memory (dm, baroni and lenci (2010)).<papid> J10-4006 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2398">
<title id=" W12-1707.xml">modeling covert event retrieval in logical metonymy probabilistic and distributional accounts </title>
<section> similarity-based models.  </section>
<citcontext>
<prevsection>
<prevsent>these features can be chosen in different ways; popular choices are simple words (schtze, 1992) or lexicalized dependency relations (lin, 1998; <papid> P98-2127 </papid>pad?</prevsent>
<prevsent>and lapata, 2007).</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
semantic similarity can then be approximated by vector similarity using wide range of similarity metrics (lee, 1999).<papid> P99-1004 </papid></citsent>
<aftsection>
<nextsent>3.1.1 distributional memorya recent multi-purpose framework in distributional semantics is distributional memory (dm, baroni and lenci (2010)).<papid> J10-4006 </papid></nextsent>
<nextsent>dm does not immediately construct vectors for words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2399">
<title id=" W12-1707.xml">modeling covert event retrieval in logical metonymy probabilistic and distributional accounts </title>
<section> similarity-based models.  </section>
<citcontext>
<prevsection>
<prevsent>and lapata, 2007).
</prevsent>
<prevsent>semantic similarity can then be approximated by vector similarity using wide range of similarity metrics (lee, 1999).<papid> P99-1004 </papid></prevsent>
</prevsection>
<citsent citstr=" J10-4006 ">
3.1.1 distributional memorya recent multi-purpose framework in distributional semantics is distributional memory (dm, baroni and lenci (2010)).<papid> J10-4006 </papid></citsent>
<aftsection>
<nextsent>dm does not immediately construct vectors for words.
</nextsent>
<nextsent>instead, it extracts three-dimensional tensor of weighted word link-word tuples each of which is mapped onto ascore by function ? : w1 w2?
</nextsent>
<nextsent>r+.
</nextsent>
<nextsent>forex ample, pencil obj use?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2400">
<title id=" W12-1707.xml">modeling covert event retrieval in logical metonymy probabilistic and distributional accounts </title>
<section> similarity-based models.  </section>
<citcontext>
<prevsection>
<prevsent>probabilistic models can account for compositionality by estimating conditional probabilities.
</prevsent>
<prevsent>com 3l1 is used to denote the inverse link of (i.e., exchanging the positions of w1 and w2).positionality is less straightforward in similarity based distributional model, because similarity-based distributional models traditionally model meaning at word level.
</prevsent>
</prevsection>
<citsent citstr=" W11-0115 ">
nevertheless, the last years have seen wave of distributional models which make progress at building compositional representations of higher-level structures such as noun-adjective or verb-argument combinations (mitchell and lapata, 2010; guevara, 2011; <papid> W11-0115 </papid>reddy et al , 2011).</citsent>
<aftsection>
<nextsent>3.2.1 expectation composition and update lenci (2011) presents model to predict the degree of thematic fit for verb-argument combinations: the expectation composition and update (ecu) model.
</nextsent>
<nextsent>more specifically, the goal of ecu is explain how the choice of specific subject forgiven verb impacts the semantic expectation for possible objects.
</nextsent>
<nextsent>for example, the verb draw alone might have fair, but not very high, expectations for the two possible objects landscape and card.
</nextsent>
<nextsent>when it is combined with the subject painter, the resulting phrase painter draw the expectation for the object landscape should increase, while it should drop for card.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2401">
<title id=" W12-1707.xml">modeling covert event retrieval in logical metonymy probabilistic and distributional accounts </title>
<section> similarity-based models.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 cognitive relevance.
</prevsent>
<prevsent>similarity-based models build upon the distributional hypothesis, which, in its strong version, is cognitive hypothesis about the form of semantic representations (lenci, 2008): the distributional behavior of word reflects its semantic behavior but is also direct correlate of its semantic content at the cognitive level.
</prevsent>
</prevsection>
<citsent citstr=" W10-2803 ">
also, similarity-based models are highly compatible with known features of human cognition, such as graded category member ship (rosch, 1975) or multiple sense activation (erk, 2010).<papid> W10-2803 </papid></citsent>
<aftsection>
<nextsent>their cognitive relevance for language hasbeen supported by studies of child lexical development (li et al , 2004), category-related deficits (vigliocco et al , 2004), selectional preferences (erk, 2007), <papid> P07-1028 </papid>event types (zarcone and lenci, 2008) <papid> L08-1019 </papid>and more (see landauer et al  (2007) and baroni and lenci (2010) <papid> J10-4006 </papid>for review).</nextsent>
<nextsent>3.4 modeling logical metonymy with ecu.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2402">
<title id=" W12-1707.xml">modeling covert event retrieval in logical metonymy probabilistic and distributional accounts </title>
<section> similarity-based models.  </section>
<citcontext>
<prevsection>
<prevsent>similarity-based models build upon the distributional hypothesis, which, in its strong version, is cognitive hypothesis about the form of semantic representations (lenci, 2008): the distributional behavior of word reflects its semantic behavior but is also direct correlate of its semantic content at the cognitive level.
</prevsent>
<prevsent>also, similarity-based models are highly compatible with known features of human cognition, such as graded category member ship (rosch, 1975) or multiple sense activation (erk, 2010).<papid> W10-2803 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-1028 ">
their cognitive relevance for language hasbeen supported by studies of child lexical development (li et al , 2004), category-related deficits (vigliocco et al , 2004), selectional preferences (erk, 2007), <papid> P07-1028 </papid>event types (zarcone and lenci, 2008) <papid> L08-1019 </papid>and more (see landauer et al  (2007) and baroni and lenci (2010) <papid> J10-4006 </papid>for review).</citsent>
<aftsection>
<nextsent>3.4 modeling logical metonymy with ecu.
</nextsent>
<nextsent>3.4.1 logical metonymy as thematic fit the hypothesis that we follow in this paper is that the ecu model can also be used, with modifications, to predict the interpretation of logical metonymy.
</nextsent>
<nextsent>the underlying assumption is that the interpretation of logical metonymy is essentially the recovery ofa covert event with maximal thematic fit (hightypicality) and can thus make use of ecus mechanisms to treat verb-argument composition.
</nextsent>
<nextsent>strong evidence for this assumption has been found in psy cho linguistic studies, which have established that thematic fit dynamically affects processing, with on line updates of expectations for typical fillers during the incremental processing of linguistic input (see mcrae and matsuki (2009) for review).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2403">
<title id=" W12-1707.xml">modeling covert event retrieval in logical metonymy probabilistic and distributional accounts </title>
<section> similarity-based models.  </section>
<citcontext>
<prevsection>
<prevsent>similarity-based models build upon the distributional hypothesis, which, in its strong version, is cognitive hypothesis about the form of semantic representations (lenci, 2008): the distributional behavior of word reflects its semantic behavior but is also direct correlate of its semantic content at the cognitive level.
</prevsent>
<prevsent>also, similarity-based models are highly compatible with known features of human cognition, such as graded category member ship (rosch, 1975) or multiple sense activation (erk, 2010).<papid> W10-2803 </papid></prevsent>
</prevsection>
<citsent citstr=" L08-1019 ">
their cognitive relevance for language hasbeen supported by studies of child lexical development (li et al , 2004), category-related deficits (vigliocco et al , 2004), selectional preferences (erk, 2007), <papid> P07-1028 </papid>event types (zarcone and lenci, 2008) <papid> L08-1019 </papid>and more (see landauer et al  (2007) and baroni and lenci (2010) <papid> J10-4006 </papid>for review).</citsent>
<aftsection>
<nextsent>3.4 modeling logical metonymy with ecu.
</nextsent>
<nextsent>3.4.1 logical metonymy as thematic fit the hypothesis that we follow in this paper is that the ecu model can also be used, with modifications, to predict the interpretation of logical metonymy.
</nextsent>
<nextsent>the underlying assumption is that the interpretation of logical metonymy is essentially the recovery ofa covert event with maximal thematic fit (hightypicality) and can thus make use of ecus mechanisms to treat verb-argument composition.
</nextsent>
<nextsent>strong evidence for this assumption has been found in psy cho linguistic studies, which have established that thematic fit dynamically affects processing, with on line updates of expectations for typical fillers during the incremental processing of linguistic input (see mcrae and matsuki (2009) for review).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2405">
<title id=" W12-1707.xml">modeling covert event retrieval in logical metonymy probabilistic and distributional accounts </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the effect is seen early on (after the patient position in the self-paced reading and at short isi for the probe recognition), suggesting that knowledge of typical events is quickly integrated in processing and that participants access broader pool of knowledge than what has traditionally been argued to be in the lexical entries of nouns (pustejovsky, 1995).the finding is in agreement with results of psych olin guistic studies which challenge the very distinction between world knowledge and linguistic knowledge (hagoort et al , 2004; mcrae and matsuki, 2009).
</prevsent>
<prevsent>dm for german since dm exists only for english, we constructed german analog using the 884m word sdewac web corpus (faa?
</prevsent>
</prevsection>
<citsent citstr=" C10-1011 ">
et al , 2010) parsed with the mate german dependency parser (bohnet, 2010).<papid> C10-1011 </papid></citsent>
<aftsection>
<nextsent>from this corpus, we extract 55m instances of simple syntactic relations (subj_tr, subj_intr, obj, iobj, comp, nmod) and 104m instances of lexicalized patterns such as nounprepnoun e.g. recht aufauskunft?
</nextsent>
<nextsent>(right to information?), or adjnoun-(of) noun such as strittig entscheidung schiedsrichter?(contested decision referee?).
</nextsent>
<nextsent>these lexicalized patterns make our model roughly similar to the english typedm model (sec.
</nextsent>
<nextsent>3.1.1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2407">
<title id=" W12-1707.xml">modeling covert event retrieval in logical metonymy probabilistic and distributional accounts </title>
<section> future work.  </section>
<citcontext>
<prevsection>
<prevsent>we see possible improvement in the choice of the number of fillers, with which we construct the prototype vectors.
</prevsent>
<prevsent>a smaller number might lead to less noisy prototypes.
</prevsent>
</prevsection>
<citsent citstr=" D10-1029 ">
it has been shown (bergsma et al , 2010) <papid> D10-1029 </papid>that the meaning of the prefix verb can be accurately predicted using the stems vector, when compositional ity applies.</citsent>
<aftsection>
<nextsent>we suspect covert events that are prefix verbs to suffer from sparser representations than the vectors of their stem.
</nextsent>
<nextsent>e.g., absaugen (vacuum off ) is much less frequent than the semantically nearly identical saugen (vacuum).
</nextsent>
<nextsent>thus, by leveraging the richer representation of the stem, our distributional models could more likely assign the correct event.
</nextsent>
<nextsent>we have presented contrastive study of two classes of computational models, probabilistic and distributional similarity-based ones, for the prediction of covert events for german logical metonymies.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2408">
<title id=" W11-2207.xml">twitter polarity classification with label propagation over lexical links and the follower graph </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>full sentiment analysis forgiven question ortopic requires many stages, including but not limited to: (1) extraction of tweets based on an initial query, (2) filtering out spam and irrelevant items from those tweets, (3) identifying subjective tweets, and (4) identifying the polarity of those tweets.
</prevsent>
<prevsent>like most work in sentiment analysis, we focus on thelast stage, polarity classification.
</prevsent>
</prevsection>
<citsent citstr=" D09-1062 ">
the simplest approaches are based on the presence of words oremoticons that are indicators of positive or negative polarity (e.g. twitters own api, oconnor et al (2010)), or calculating ratio of positive to negative terms (choi and cardie, 2009).<papid> D09-1062 </papid></citsent>
<aftsection>
<nextsent>though these are useful first pass, the nuance of language often defeats them (pang and lee, 2008).
</nextsent>
<nextsent>tweets provide additional challenges compared to edited text; e.g. they are short and include infor mal/colloquial/abbreviated language.
</nextsent>
<nextsent>53standard supervised classification methods im prove the situation somewhat (pang et al, 2002),<papid> W02-1011 </papid>but these require texts labeled with polarity as in put and they do not adapt to changes in language use.</nextsent>
<nextsent>one way around this is to use noisy labels (alsoreferred to as distant supervision?), e.g. by taking emoticons like ?:)?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2409">
<title id=" W11-2207.xml">twitter polarity classification with label propagation over lexical links and the follower graph </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>though these are useful first pass, the nuance of language often defeats them (pang and lee, 2008).
</prevsent>
<prevsent>tweets provide additional challenges compared to edited text; e.g. they are short and include infor mal/colloquial/abbreviated language.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
53standard supervised classification methods im prove the situation somewhat (pang et al, 2002),<papid> W02-1011 </papid>but these require texts labeled with polarity as in put and they do not adapt to changes in language use.</citsent>
<aftsection>
<nextsent>one way around this is to use noisy labels (alsoreferred to as distant supervision?), e.g. by taking emoticons like ?:)?
</nextsent>
<nextsent>as positive and ?:(?
</nextsent>
<nextsent>as negative, and train standard classifier (read, 2005; <papid> P05-2008 </papid>go et al, 2009).1 semi-supervised methods can also reduce dependence on labeled texts: for example,sindhwani and melville (2008) use polarity lexicon combined with label propagation.</nextsent>
<nextsent>several have used label propagation starting with small number of hand-labeled words to induce lexicon for use in polarity classification (blair-goldensohn et al,2008; rao and ravichandran, 2009; <papid> E09-1077 </papid>brody andel hadad, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2410">
<title id=" W11-2207.xml">twitter polarity classification with label propagation over lexical links and the follower graph </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one way around this is to use noisy labels (alsoreferred to as distant supervision?), e.g. by taking emoticons like ?:)?
</prevsent>
<prevsent>as positive and ?:(?
</prevsent>
</prevsection>
<citsent citstr=" P05-2008 ">
as negative, and train standard classifier (read, 2005; <papid> P05-2008 </papid>go et al, 2009).1 semi-supervised methods can also reduce dependence on labeled texts: for example,sindhwani and melville (2008) use polarity lexicon combined with label propagation.</citsent>
<aftsection>
<nextsent>several have used label propagation starting with small number of hand-labeled words to induce lexicon for use in polarity classification (blair-goldensohn et al,2008; rao and ravichandran, 2009; <papid> E09-1077 </papid>brody andel hadad, 2010).</nextsent>
<nextsent>in this paper, we bring together several of the above approaches via label propagation using modified adsorption (talukdar and crammer, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2411">
<title id=" W11-2207.xml">twitter polarity classification with label propagation over lexical links and the follower graph </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as positive and ?:(?
</prevsent>
<prevsent>as negative, and train standard classifier (read, 2005; <papid> P05-2008 </papid>go et al, 2009).1 semi-supervised methods can also reduce dependence on labeled texts: for example,sindhwani and melville (2008) use polarity lexicon combined with label propagation.</prevsent>
</prevsection>
<citsent citstr=" E09-1077 ">
several have used label propagation starting with small number of hand-labeled words to induce lexicon for use in polarity classification (blair-goldensohn et al,2008; rao and ravichandran, 2009; <papid> E09-1077 </papid>brody andel hadad, 2010).</citsent>
<aftsection>
<nextsent>in this paper, we bring together several of the above approaches via label propagation using modified adsorption (talukdar and crammer, 2009).
</nextsent>
<nextsent>this also allows us to explore the possibility of exploiting the twitter follower graph to improve polarity classification, under the assumption that people influence one another or have shared affinities about topics.
</nextsent>
<nextsent>we construct graph that has users, tweets,word unigrams, word bigrams, hash tags, and emoti cons as its nodes; users are connected based on the twitter follower graph, users are connected to the tweets they created, and tweets are connected to the unigrams, bigrams, hash tags and emoticons they contain.
</nextsent>
<nextsent>we seed the graph using the polarity values in the opinion finder lexicon (wilson et al, 2005), the known polarity of emoticons, and maximum entropy classifier trained on 1.8 million tweets with automatically assigned labels based on the presence of positive and negative emoticons, like read (2005) <papid> P05-2008 </papid>and go et al (2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2413">
<title id=" W11-2207.xml">twitter polarity classification with label propagation over lexical links and the follower graph </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we seed the graph using the polarity values in the opinion finder lexicon (wilson et al, 2005), the known polarity of emoticons, and maximum entropy classifier trained on 1.8 million tweets with automatically assigned labels based on the presence of positive and negative emoticons, like read (2005) <papid> P05-2008 </papid>and go et al (2009).</prevsent>
<prevsent>we compare the label propagation approach tothe noisily supervised classifier itself and to standard lexicon-based method using positive/negative ratios.</prevsent>
</prevsection>
<citsent citstr=" C10-2028 ">
evaluation is performed on several datasets of tweets that have been annotated for polarity: the stanford twitter sentiment set (go et al, 2009), 1davidov et al (2010) <papid> C10-2028 </papid>use 15 emoticons and 50 twitter hash tags as proxies for sentiment in similar manner, but their evaluation is indirect.</citsent>
<aftsection>
<nextsent>rather than predicting gold standard sentiment labels, they instead predict whether those same emoti cons and hash tags would be appropriate for other tweets.
</nextsent>
<nextsent>tweets from the 2008 debate between obama and mccain (shamma et al, 2009), and new dataset of tweets about healthcare reform that we have created.
</nextsent>
<nextsent>in addition to performing standard per-tweet accuracy, we also measure per-target accuracy (for healthcare reform) and an aggregate error metric over all users in our test set that captures how similar predicted positivity of each user is to their actual positivity.
</nextsent>
<nextsent>across all datasets and measures, we find that label propagation is consistently better than the noisily supervised classifier, which in turn outperforms the lexicon-based method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2414">
<title id=" W11-2207.xml">twitter polarity classification with label propagation over lexical links and the follower graph </title>
<section> datasets.  </section>
<citcontext>
<prevsection>
<prevsent>from the annotated datasets, only tweets with positive or negative polarity are used, so neutral tweets are ignored.
</prevsent>
<prevsent>while important, subjectivity detection is largely different problem from polarity classification.
</prevsent>
</prevsection>
<citsent citstr=" P04-1035 ">
for example, pang and lee (2004) <papid> P04-1035 </papid>use minimum cuts in graphs for the former and machine-learned text classification for the latter.</citsent>
<aftsection>
<nextsent>we also do not give any special treatment to re tweets, though doing so is possible future improvement.
</nextsent>
<nextsent>2.1 emoticon-based training set (emoticon).
</nextsent>
<nextsent>emoticons are commonly exploited as noisy indicators of polarity including by twitters own advanced search with positive/negative attitude.?
</nextsent>
<nextsent>while imperfect, there is potential for millions of tweets containing emoticons to serve as source of noisy training material for supervised classifier.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2415">
<title id=" W11-2207.xml">twitter polarity classification with label propagation over lexical links and the follower graph </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this case, the output of label propagation seeded with noisy-seed reveals that mccain has negative sentiment for this dataset.
</prevsent>
<prevsent>much work in sentiment analysis involves the useand generation of dictionaries capturing the sentiment of words.
</prevsent>
</prevsection>
<citsent citstr=" P02-1053 ">
these methods range from manual approaches of developing domain-dependent lexicons (das and chan, 2001) to semi-automated approaches (hu and liu, 2004) and fully automated approaches (turney, 2002).<papid> P02-1053 </papid></citsent>
<aftsection>
<nextsent>melville et al (2009)use unified framework combining background lexical information in terms of word-class association sand refine this information for specific domains using any available training examples.
</nextsent>
<nextsent>they produce better results than using either lexicon or training.
</nextsent>
<nextsent>oconnor et al (2010) use the opinion finder subjectivity lexicon to label the polarity of tweets about barack obama and compare daily aggregate sentiment scores to the gallup poll time series of manually gathered approval ratings of obama.
</nextsent>
<nextsent>even with this simple polarity determination, they find significant correlation between their predicted aggregate sentiment per day and the gallup poll.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2416">
<title id=" W12-2015.xml">developing aret an nlp based educational tool set for arabic reading enhancement </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>many studies have shown that an on-line learning environment that supplements classroom instruction with additional study materials at an appropriate level for the learner may enhance language learning and development (ware, 2004; chiu et al , 2007; yuan, 2003; wang, 2005;).
</prevsent>
<prevsent>as result, number of recent projects have aimed to dynamically provide supply of accessible authentic texts to language learners by drawing from online resources.
</prevsent>
</prevsection>
<citsent citstr=" W10-1002 ">
werti (meurers et al  2010) <papid> W10-1002 </papid>is an intelligent automatic workbook that uses texts from the web to increase knowledge of english grammatical forms and functions.</citsent>
<aftsection>
<nextsent>read-x (miltsakaki and troutt, 2007) is tool for finding texts at specified reading levels.
</nextsent>
<nextsent>source finder (sheehan et al ,2007) is an authoring tool for finding suitable texts for standardized test items on verbal reasoning and reading comprehension.
</nextsent>
<nextsent>project reap (reader specific lexical practice) (brown and eskenazi, 2004; heilman et al , 2006) takes different approach.
</nextsent>
<nextsent>rather than teachers choosing texts, in reap the system selects individualized practice readings from digital library according to specific lexical constraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2417">
<title id=" W12-2015.xml">developing aret an nlp based educational tool set for arabic reading enhancement </title>
<section> the arabic reading enhancement tools.  </section>
<citcontext>
<prevsection>
<prevsent>various interpretations for the lemma ???
</prevsent>
<prevsent>to address these challenges, we developed an arabic reading enhancement tool (aret) for classroom use with support from the u.s. department of educations international research study program (irs).
</prevsent>
</prevsection>
<citsent citstr=" C96-2140 ">
the aret tool is rather similar in intent to the foreign language learning tool, glosser-rug built by nerbonne and smit (1996) <papid> C96-2140 </papid>for dutch, but targets explicitly the particularities of msa.</citsent>
<aftsection>
<nextsent>aret has two subparts tools : the arabic reading facilitation tool (arft) and the arabic reading assessment tool (arat).
</nextsent>
<nextsent>a major achievement of this project was to create collection of fully annotated texts for learners of arabic, using materials included in an authoritative textbook series that spans several competence levels.
</nextsent>
<nextsent>in this section, we describe the creation, structure and content of the arabic corpus/lexicon database, and then describe the arft and arat tools in more detail.
</nextsent>
<nextsent>5.1 the al-kitaab corpus database.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2418">
<title id=" W12-2015.xml">developing aret an nlp based educational tool set for arabic reading enhancement </title>
<section> the arabic reading enhancement tools.  </section>
<citcontext>
<prevsection>
<prevsent>we first applied the standard arabic morphological analyzer (sama) (maamouri et al , 2010), to enumerate all possible solutions for each word token in given passage.
</prevsent>
<prevsent>the entire passage, with the full set of possible sama solutions for each word token, was then presented to native arabic speaker experienced in the morphological analysis of msa, and their task was to select the particular sama solution for each word based on their understanding of the context; where necessary, the annotator would manually edit the details of pos tags or glosses to fill gaps in samas coverage of the vocabulary.
</prevsent>
</prevsection>
<citsent citstr=" W04-1602 ">
this is standard approach used in the annotation of numerous arabic text corpora, including the arabic treebank project (maamouri and bies 2004).<papid> W04-1602 </papid></citsent>
<aftsection>
<nextsent>as described in section 5.2, the resulting annotation was fully reviewed by expert arabic linguists using our reading facilitation tool, to identify and repair errors.
</nextsent>
<nextsent>a relational database was created to store the corpus and annotations.
</nextsent>
<nextsent>separate tables were used to enumerate (a) the reading passages (keeping track of the book volume, chapter and page number of each passage), (b) the sequence of sentences in each passage, (c) the word token sequence for each sentence, (d) the inventory of distinct word types (i.e. orthographic word forms with their con text-dependant analyses), and (e) the inventory of distinct headwords?
</nextsent>
<nextsent>(lemmas) and affix morphemes (clitics).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2419">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we show that we can significantly improve target language performance, even after annotating up to 64,000 tokens in the target language, by simply concatenating source and target language annotations.
</prevsent>
<prevsent>recognition of named entities in natural language text is an important subtask of information extraction and thus bears importance for modern text mining and information retrieval applications.
</prevsent>
</prevsection>
<citsent citstr=" P11-1138 ">
the needto identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in wikification of documents (ratinov et al, 2011), <papid> P11-1138 </papid>and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation (babych and hartley, 2003) and question answering (leidner et al,2003).<papid> W03-0105 </papid></citsent>
<aftsection>
<nextsent>the advent of massive machine readable factual databases, such as freebase1 and the proposed 1http://www.freebase.com wikidata2, will likely push the need for automatic extraction tools further.
</nextsent>
<nextsent>while these databases store information about entity types and the relationships between those types, the named entity recognition (ner) task concerns finding occurrences of named entities in context.
</nextsent>
<nextsent>this view originated with themes sage understanding conferences (muc) (grishman and sundheim, 1996).<papid> C96-1079 </papid>as with the majority of tasks in contemporary natural language processing, most approaches toner have been based on supervised machine learning.however, although resources for handful of languages have been created, through initiatives such as muc, the multilingual entity task (merchant et al, 1996) <papid> X96-1049 </papid>and the conll shared tasks (tjongkim sang, 2002; tjong kim sang and de meulder, 2003), coverage is still very limited in terms ofboth domains and languages.</nextsent>
<nextsent>with fine-grained entity taxonomies such as that proposed by sekine andnobata (2004), who define over two hundred categories, we can expect an increase in the amount of annotated data required for acceptable performance, as well as an increased annotation cost for each entity occurrence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2420">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, we show that we can significantly improve target language performance, even after annotating up to 64,000 tokens in the target language, by simply concatenating source and target language annotations.
</prevsent>
<prevsent>recognition of named entities in natural language text is an important subtask of information extraction and thus bears importance for modern text mining and information retrieval applications.
</prevsent>
</prevsection>
<citsent citstr=" W03-0105 ">
the needto identify named entities such as persons, locations, organizations and places, arises both in applications where the entities are first class objects of interest, such as in wikification of documents (ratinov et al, 2011), <papid> P11-1138 </papid>and in applications where knowledge of named entities is helpful in boosting performance, e.g., machine translation (babych and hartley, 2003) and question answering (leidner et al,2003).<papid> W03-0105 </papid></citsent>
<aftsection>
<nextsent>the advent of massive machine readable factual databases, such as freebase1 and the proposed 1http://www.freebase.com wikidata2, will likely push the need for automatic extraction tools further.
</nextsent>
<nextsent>while these databases store information about entity types and the relationships between those types, the named entity recognition (ner) task concerns finding occurrences of named entities in context.
</nextsent>
<nextsent>this view originated with themes sage understanding conferences (muc) (grishman and sundheim, 1996).<papid> C96-1079 </papid>as with the majority of tasks in contemporary natural language processing, most approaches toner have been based on supervised machine learning.however, although resources for handful of languages have been created, through initiatives such as muc, the multilingual entity task (merchant et al, 1996) <papid> X96-1049 </papid>and the conll shared tasks (tjongkim sang, 2002; tjong kim sang and de meulder, 2003), coverage is still very limited in terms ofboth domains and languages.</nextsent>
<nextsent>with fine-grained entity taxonomies such as that proposed by sekine andnobata (2004), who define over two hundred categories, we can expect an increase in the amount of annotated data required for acceptable performance, as well as an increased annotation cost for each entity occurrence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2421">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the advent of massive machine readable factual databases, such as freebase1 and the proposed 1http://www.freebase.com wikidata2, will likely push the need for automatic extraction tools further.
</prevsent>
<prevsent>while these databases store information about entity types and the relationships between those types, the named entity recognition (ner) task concerns finding occurrences of named entities in context.
</prevsent>
</prevsection>
<citsent citstr=" C96-1079 ">
this view originated with themes sage understanding conferences (muc) (grishman and sundheim, 1996).<papid> C96-1079 </papid>as with the majority of tasks in contemporary natural language processing, most approaches toner have been based on supervised machine learning.however, although resources for handful of languages have been created, through initiatives such as muc, the multilingual entity task (merchant et al, 1996) <papid> X96-1049 </papid>and the conll shared tasks (tjongkim sang, 2002; tjong kim sang and de meulder, 2003), coverage is still very limited in terms ofboth domains and languages.</citsent>
<aftsection>
<nextsent>with fine-grained entity taxonomies such as that proposed by sekine andnobata (2004), who define over two hundred categories, we can expect an increase in the amount of annotated data required for acceptable performance, as well as an increased annotation cost for each entity occurrence.
</nextsent>
<nextsent>although semi-supervised approaches have been shown to reduce the need for manual annotation (freitag, 2004; <papid> W04-3234 </papid>miller et al, 2004; <papid> N04-1043 </papid>ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008; <papid> P08-1076 </papid>lin and wu, 2009; <papid> P09-1116 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011; tack strom et al, 2012), these methods still require asubstantial amount of manual annotation for each target language.</nextsent>
<nextsent>manually creating sufficient amount of annotated resources for all entity types in all languages thus seems like an herculean task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2422">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the advent of massive machine readable factual databases, such as freebase1 and the proposed 1http://www.freebase.com wikidata2, will likely push the need for automatic extraction tools further.
</prevsent>
<prevsent>while these databases store information about entity types and the relationships between those types, the named entity recognition (ner) task concerns finding occurrences of named entities in context.
</prevsent>
</prevsection>
<citsent citstr=" X96-1049 ">
this view originated with themes sage understanding conferences (muc) (grishman and sundheim, 1996).<papid> C96-1079 </papid>as with the majority of tasks in contemporary natural language processing, most approaches toner have been based on supervised machine learning.however, although resources for handful of languages have been created, through initiatives such as muc, the multilingual entity task (merchant et al, 1996) <papid> X96-1049 </papid>and the conll shared tasks (tjongkim sang, 2002; tjong kim sang and de meulder, 2003), coverage is still very limited in terms ofboth domains and languages.</citsent>
<aftsection>
<nextsent>with fine-grained entity taxonomies such as that proposed by sekine andnobata (2004), who define over two hundred categories, we can expect an increase in the amount of annotated data required for acceptable performance, as well as an increased annotation cost for each entity occurrence.
</nextsent>
<nextsent>although semi-supervised approaches have been shown to reduce the need for manual annotation (freitag, 2004; <papid> W04-3234 </papid>miller et al, 2004; <papid> N04-1043 </papid>ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008; <papid> P08-1076 </papid>lin and wu, 2009; <papid> P09-1116 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011; tack strom et al, 2012), these methods still require asubstantial amount of manual annotation for each target language.</nextsent>
<nextsent>manually creating sufficient amount of annotated resources for all entity types in all languages thus seems like an herculean task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2423">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this view originated with themes sage understanding conferences (muc) (grishman and sundheim, 1996).<papid> C96-1079 </papid>as with the majority of tasks in contemporary natural language processing, most approaches toner have been based on supervised machine learning.however, although resources for handful of languages have been created, through initiatives such as muc, the multilingual entity task (merchant et al, 1996) <papid> X96-1049 </papid>and the conll shared tasks (tjongkim sang, 2002; tjong kim sang and de meulder, 2003), coverage is still very limited in terms ofboth domains and languages.</prevsent>
<prevsent>with fine-grained entity taxonomies such as that proposed by sekine andnobata (2004), who define over two hundred categories, we can expect an increase in the amount of annotated data required for acceptable performance, as well as an increased annotation cost for each entity occurrence.</prevsent>
</prevsection>
<citsent citstr=" W04-3234 ">
although semi-supervised approaches have been shown to reduce the need for manual annotation (freitag, 2004; <papid> W04-3234 </papid>miller et al, 2004; <papid> N04-1043 </papid>ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008; <papid> P08-1076 </papid>lin and wu, 2009; <papid> P09-1116 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011; tack strom et al, 2012), these methods still require asubstantial amount of manual annotation for each target language.</citsent>
<aftsection>
<nextsent>manually creating sufficient amount of annotated resources for all entity types in all languages thus seems like an herculean task.
</nextsent>
<nextsent>in this study, we turn to direct transfer methods (mcdonald et al, 2011; <papid> D11-1006 </papid>tack strom et al, 2012) as 2http://meta.wikimedia.org/wiki/wikidata 55 way to combat the need for annotated resources in all languages.</nextsent>
<nextsent>these methods allow one to traina system for target language, using only annotations in some source language, as long as all source language features also have support in the target lan guages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2424">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this view originated with themes sage understanding conferences (muc) (grishman and sundheim, 1996).<papid> C96-1079 </papid>as with the majority of tasks in contemporary natural language processing, most approaches toner have been based on supervised machine learning.however, although resources for handful of languages have been created, through initiatives such as muc, the multilingual entity task (merchant et al, 1996) <papid> X96-1049 </papid>and the conll shared tasks (tjongkim sang, 2002; tjong kim sang and de meulder, 2003), coverage is still very limited in terms ofboth domains and languages.</prevsent>
<prevsent>with fine-grained entity taxonomies such as that proposed by sekine andnobata (2004), who define over two hundred categories, we can expect an increase in the amount of annotated data required for acceptable performance, as well as an increased annotation cost for each entity occurrence.</prevsent>
</prevsection>
<citsent citstr=" N04-1043 ">
although semi-supervised approaches have been shown to reduce the need for manual annotation (freitag, 2004; <papid> W04-3234 </papid>miller et al, 2004; <papid> N04-1043 </papid>ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008; <papid> P08-1076 </papid>lin and wu, 2009; <papid> P09-1116 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011; tack strom et al, 2012), these methods still require asubstantial amount of manual annotation for each target language.</citsent>
<aftsection>
<nextsent>manually creating sufficient amount of annotated resources for all entity types in all languages thus seems like an herculean task.
</nextsent>
<nextsent>in this study, we turn to direct transfer methods (mcdonald et al, 2011; <papid> D11-1006 </papid>tack strom et al, 2012) as 2http://meta.wikimedia.org/wiki/wikidata 55 way to combat the need for annotated resources in all languages.</nextsent>
<nextsent>these methods allow one to traina system for target language, using only annotations in some source language, as long as all source language features also have support in the target lan guages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2425">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this view originated with themes sage understanding conferences (muc) (grishman and sundheim, 1996).<papid> C96-1079 </papid>as with the majority of tasks in contemporary natural language processing, most approaches toner have been based on supervised machine learning.however, although resources for handful of languages have been created, through initiatives such as muc, the multilingual entity task (merchant et al, 1996) <papid> X96-1049 </papid>and the conll shared tasks (tjongkim sang, 2002; tjong kim sang and de meulder, 2003), coverage is still very limited in terms ofboth domains and languages.</prevsent>
<prevsent>with fine-grained entity taxonomies such as that proposed by sekine andnobata (2004), who define over two hundred categories, we can expect an increase in the amount of annotated data required for acceptable performance, as well as an increased annotation cost for each entity occurrence.</prevsent>
</prevsection>
<citsent citstr=" P05-1001 ">
although semi-supervised approaches have been shown to reduce the need for manual annotation (freitag, 2004; <papid> W04-3234 </papid>miller et al, 2004; <papid> N04-1043 </papid>ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008; <papid> P08-1076 </papid>lin and wu, 2009; <papid> P09-1116 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011; tack strom et al, 2012), these methods still require asubstantial amount of manual annotation for each target language.</citsent>
<aftsection>
<nextsent>manually creating sufficient amount of annotated resources for all entity types in all languages thus seems like an herculean task.
</nextsent>
<nextsent>in this study, we turn to direct transfer methods (mcdonald et al, 2011; <papid> D11-1006 </papid>tack strom et al, 2012) as 2http://meta.wikimedia.org/wiki/wikidata 55 way to combat the need for annotated resources in all languages.</nextsent>
<nextsent>these methods allow one to traina system for target language, using only annotations in some source language, as long as all source language features also have support in the target lan guages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2426">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this view originated with themes sage understanding conferences (muc) (grishman and sundheim, 1996).<papid> C96-1079 </papid>as with the majority of tasks in contemporary natural language processing, most approaches toner have been based on supervised machine learning.however, although resources for handful of languages have been created, through initiatives such as muc, the multilingual entity task (merchant et al, 1996) <papid> X96-1049 </papid>and the conll shared tasks (tjongkim sang, 2002; tjong kim sang and de meulder, 2003), coverage is still very limited in terms ofboth domains and languages.</prevsent>
<prevsent>with fine-grained entity taxonomies such as that proposed by sekine andnobata (2004), who define over two hundred categories, we can expect an increase in the amount of annotated data required for acceptable performance, as well as an increased annotation cost for each entity occurrence.</prevsent>
</prevsection>
<citsent citstr=" P08-1076 ">
although semi-supervised approaches have been shown to reduce the need for manual annotation (freitag, 2004; <papid> W04-3234 </papid>miller et al, 2004; <papid> N04-1043 </papid>ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008; <papid> P08-1076 </papid>lin and wu, 2009; <papid> P09-1116 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011; tack strom et al, 2012), these methods still require asubstantial amount of manual annotation for each target language.</citsent>
<aftsection>
<nextsent>manually creating sufficient amount of annotated resources for all entity types in all languages thus seems like an herculean task.
</nextsent>
<nextsent>in this study, we turn to direct transfer methods (mcdonald et al, 2011; <papid> D11-1006 </papid>tack strom et al, 2012) as 2http://meta.wikimedia.org/wiki/wikidata 55 way to combat the need for annotated resources in all languages.</nextsent>
<nextsent>these methods allow one to traina system for target language, using only annotations in some source language, as long as all source language features also have support in the target lan guages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2427">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this view originated with themes sage understanding conferences (muc) (grishman and sundheim, 1996).<papid> C96-1079 </papid>as with the majority of tasks in contemporary natural language processing, most approaches toner have been based on supervised machine learning.however, although resources for handful of languages have been created, through initiatives such as muc, the multilingual entity task (merchant et al, 1996) <papid> X96-1049 </papid>and the conll shared tasks (tjongkim sang, 2002; tjong kim sang and de meulder, 2003), coverage is still very limited in terms ofboth domains and languages.</prevsent>
<prevsent>with fine-grained entity taxonomies such as that proposed by sekine andnobata (2004), who define over two hundred categories, we can expect an increase in the amount of annotated data required for acceptable performance, as well as an increased annotation cost for each entity occurrence.</prevsent>
</prevsection>
<citsent citstr=" P09-1116 ">
although semi-supervised approaches have been shown to reduce the need for manual annotation (freitag, 2004; <papid> W04-3234 </papid>miller et al, 2004; <papid> N04-1043 </papid>ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008; <papid> P08-1076 </papid>lin and wu, 2009; <papid> P09-1116 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011; tack strom et al, 2012), these methods still require asubstantial amount of manual annotation for each target language.</citsent>
<aftsection>
<nextsent>manually creating sufficient amount of annotated resources for all entity types in all languages thus seems like an herculean task.
</nextsent>
<nextsent>in this study, we turn to direct transfer methods (mcdonald et al, 2011; <papid> D11-1006 </papid>tack strom et al, 2012) as 2http://meta.wikimedia.org/wiki/wikidata 55 way to combat the need for annotated resources in all languages.</nextsent>
<nextsent>these methods allow one to traina system for target language, using only annotations in some source language, as long as all source language features also have support in the target lan guages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2428">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this view originated with themes sage understanding conferences (muc) (grishman and sundheim, 1996).<papid> C96-1079 </papid>as with the majority of tasks in contemporary natural language processing, most approaches toner have been based on supervised machine learning.however, although resources for handful of languages have been created, through initiatives such as muc, the multilingual entity task (merchant et al, 1996) <papid> X96-1049 </papid>and the conll shared tasks (tjongkim sang, 2002; tjong kim sang and de meulder, 2003), coverage is still very limited in terms ofboth domains and languages.</prevsent>
<prevsent>with fine-grained entity taxonomies such as that proposed by sekine andnobata (2004), who define over two hundred categories, we can expect an increase in the amount of annotated data required for acceptable performance, as well as an increased annotation cost for each entity occurrence.</prevsent>
</prevsection>
<citsent citstr=" P10-1040 ">
although semi-supervised approaches have been shown to reduce the need for manual annotation (freitag, 2004; <papid> W04-3234 </papid>miller et al, 2004; <papid> N04-1043 </papid>ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008; <papid> P08-1076 </papid>lin and wu, 2009; <papid> P09-1116 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011; tack strom et al, 2012), these methods still require asubstantial amount of manual annotation for each target language.</citsent>
<aftsection>
<nextsent>manually creating sufficient amount of annotated resources for all entity types in all languages thus seems like an herculean task.
</nextsent>
<nextsent>in this study, we turn to direct transfer methods (mcdonald et al, 2011; <papid> D11-1006 </papid>tack strom et al, 2012) as 2http://meta.wikimedia.org/wiki/wikidata 55 way to combat the need for annotated resources in all languages.</nextsent>
<nextsent>these methods allow one to traina system for target language, using only annotations in some source language, as long as all source language features also have support in the target lan guages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2430">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>although semi-supervised approaches have been shown to reduce the need for manual annotation (freitag, 2004; <papid> W04-3234 </papid>miller et al, 2004; <papid> N04-1043 </papid>ando and zhang, 2005; <papid> P05-1001 </papid>suzuki and isozaki, 2008; <papid> P08-1076 </papid>lin and wu, 2009; <papid> P09-1116 </papid>turian et al, 2010; <papid> P10-1040 </papid>dhillon et al, 2011; tack strom et al, 2012), these methods still require asubstantial amount of manual annotation for each target language.</prevsent>
<prevsent>manually creating sufficient amount of annotated resources for all entity types in all languages thus seems like an herculean task.</prevsent>
</prevsection>
<citsent citstr=" D11-1006 ">
in this study, we turn to direct transfer methods (mcdonald et al, 2011; <papid> D11-1006 </papid>tack strom et al, 2012) as 2http://meta.wikimedia.org/wiki/wikidata 55 way to combat the need for annotated resources in all languages.</citsent>
<aftsection>
<nextsent>these methods allow one to traina system for target language, using only annotations in some source language, as long as all source language features also have support in the target languages.
</nextsent>
<nextsent>specifically, we extend the direct transfer method proposed by tack strom et al (2012) in two ways.
</nextsent>
<nextsent>first, in 3, we use multiple source languages for training.
</nextsent>
<nextsent>we then propose self-training algorithm, which allows for the inclusion of additional target language specific features, in 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2434">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> direct transfer for cross-lingual ner.  </section>
<citcontext>
<prevsection>
<prevsent>finally, in 5, we assess the viability of the different direct transfer systems compared to supervised system trained on target language annotations, and conclude that direct transfer methods may be useful even in this scenario.
</prevsent>
<prevsent>rather than starting from scratch when creating systems that predict linguistic structure in one language,we should be able to take advantage of any corresponding annotations that are available in other languages.
</prevsent>
</prevsection>
<citsent citstr=" H01-1035 ">
this idea is at the heart of both direct transfer methods (mcdonald et al, 2011; <papid> D11-1006 </papid>tack strom et al, 2012) and of annotation projection methods (yarowsky et al, 2001; <papid> H01-1035 </papid>diab and resnik, 2002; <papid> P02-1033 </papid>hwa et al, 2005).</citsent>
<aftsection>
<nextsent>while the aim of the latter is to transfer annotations across languages, direct transfer methods instead aim to transfer systems, trained on some source language, directly to other languages.
</nextsent>
<nextsent>in this paper, we focus on direct transfer methods, however,we briefly discuss the relationship between these approaches in 6.
</nextsent>
<nextsent>considering the substantial differences between languages at the grammatical and lexical level, the prospect of directly applying system trained on one language to another language may seem bleak.however, mcdonald et al (2011) <papid> D11-1006 </papid>showed that language independent dependency parser can indeed be created by training on delexicalized treebank and by only incorporating features defined on universal part-of-speech tags (das and petrov, 2011).<papid> P11-1061 </papid>recently, tack strom et al (2012) developed an algorithm for inducing cross-lingual word clusters and proposed to use these clusters to enrich the feature space of direct transfer systems.</nextsent>
<nextsent>the richer set ofcross-lingual features was shown to substantially im prove on direct transfer of both dependency parsing and ner from english to other languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2436">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> direct transfer for cross-lingual ner.  </section>
<citcontext>
<prevsection>
<prevsent>finally, in 5, we assess the viability of the different direct transfer systems compared to supervised system trained on target language annotations, and conclude that direct transfer methods may be useful even in this scenario.
</prevsent>
<prevsent>rather than starting from scratch when creating systems that predict linguistic structure in one language,we should be able to take advantage of any corresponding annotations that are available in other languages.
</prevsent>
</prevsection>
<citsent citstr=" P02-1033 ">
this idea is at the heart of both direct transfer methods (mcdonald et al, 2011; <papid> D11-1006 </papid>tack strom et al, 2012) and of annotation projection methods (yarowsky et al, 2001; <papid> H01-1035 </papid>diab and resnik, 2002; <papid> P02-1033 </papid>hwa et al, 2005).</citsent>
<aftsection>
<nextsent>while the aim of the latter is to transfer annotations across languages, direct transfer methods instead aim to transfer systems, trained on some source language, directly to other languages.
</nextsent>
<nextsent>in this paper, we focus on direct transfer methods, however,we briefly discuss the relationship between these approaches in 6.
</nextsent>
<nextsent>considering the substantial differences between languages at the grammatical and lexical level, the prospect of directly applying system trained on one language to another language may seem bleak.however, mcdonald et al (2011) <papid> D11-1006 </papid>showed that language independent dependency parser can indeed be created by training on delexicalized treebank and by only incorporating features defined on universal part-of-speech tags (das and petrov, 2011).<papid> P11-1061 </papid>recently, tack strom et al (2012) developed an algorithm for inducing cross-lingual word clusters and proposed to use these clusters to enrich the feature space of direct transfer systems.</nextsent>
<nextsent>the richer set ofcross-lingual features was shown to substantially im prove on direct transfer of both dependency parsing and ner from english to other languages.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2440">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> direct transfer for cross-lingual ner.  </section>
<citcontext>
<prevsection>
<prevsent>while the aim of the latter is to transfer annotations across languages, direct transfer methods instead aim to transfer systems, trained on some source language, directly to other languages.
</prevsent>
<prevsent>in this paper, we focus on direct transfer methods, however,we briefly discuss the relationship between these approaches in 6.
</prevsent>
</prevsection>
<citsent citstr=" P11-1061 ">
considering the substantial differences between languages at the grammatical and lexical level, the prospect of directly applying system trained on one language to another language may seem bleak.however, mcdonald et al (2011) <papid> D11-1006 </papid>showed that language independent dependency parser can indeed be created by training on delexicalized treebank and by only incorporating features defined on universal part-of-speech tags (das and petrov, 2011).<papid> P11-1061 </papid>recently, tack strom et al (2012) developed an algorithm for inducing cross-lingual word clusters and proposed to use these clusters to enrich the feature space of direct transfer systems.</citsent>
<aftsection>
<nextsent>the richer set ofcross-lingual features was shown to substantially im prove on direct transfer of both dependency parsing and ner from english to other languages.
</nextsent>
<nextsent>cross-lingual word clusters are clusterings ofwords in two (or more) languages, such that the clusters are adequate in each language and at the same time consistent across languages.
</nextsent>
<nextsent>for cross-lingualword clusters to be useful in direct transfer of linguistic structure, the clusters should capture cross lingual properties on both the semantic and syntactic level.
</nextsent>
<nextsent>tack strom et al (2012) showed that this is, at least to some degree, achievable by coupling monolingual class-based language models, via wordalignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2441">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> direct transfer for cross-lingual ner.  </section>
<citcontext>
<prevsection>
<prevsent>for cross-lingualword clusters to be useful in direct transfer of linguistic structure, the clusters should capture cross lingual properties on both the semantic and syntactic level.
</prevsent>
<prevsent>tack strom et al (2012) showed that this is, at least to some degree, achievable by coupling monolingual class-based language models, via wordalignments.
</prevsent>
</prevsection>
<citsent citstr=" W97-0309 ">
the basic building block is the following simple monolingual class-based language model (saul and pereira, 1997; <papid> W97-0309 </papid>uszkoreit and brants, 2008): <papid> P08-1086 </papid>l(w; c) = m?</citsent>
<aftsection>
<nextsent>i=1 p(wi|c(wi))p(c(wi)|wi1) , where l(w; c) is the likelihood of sequence of words, w, and is (hard) clustering function, which maps words to cluster identities.
</nextsent>
<nextsent>these monolingual models are coupled through word alignments, which constrains the clusterings to be consistent across languages, and optimized by approximately maximizing the joint likelihood across languages.
</nextsent>
<nextsent>just as monolingual word clusters are broadly applicable as feature sin monolingual models for linguistic structure prediction (turian et al, 2010), <papid> P10-1040 </papid>the resulting cross-lingualword clusters can be used as features in various cross lingual direct transfer models.</nextsent>
<nextsent>we believe that the extensions that we propose are likely to be useful for other tasks as well, e.g., direct transfer dependency parsing, in this paper, we focus solely on discriminative direct transfer models for ner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2442">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> direct transfer for cross-lingual ner.  </section>
<citcontext>
<prevsection>
<prevsent>for cross-lingualword clusters to be useful in direct transfer of linguistic structure, the clusters should capture cross lingual properties on both the semantic and syntactic level.
</prevsent>
<prevsent>tack strom et al (2012) showed that this is, at least to some degree, achievable by coupling monolingual class-based language models, via wordalignments.
</prevsent>
</prevsection>
<citsent citstr=" P08-1086 ">
the basic building block is the following simple monolingual class-based language model (saul and pereira, 1997; <papid> W97-0309 </papid>uszkoreit and brants, 2008): <papid> P08-1086 </papid>l(w; c) = m?</citsent>
<aftsection>
<nextsent>i=1 p(wi|c(wi))p(c(wi)|wi1) , where l(w; c) is the likelihood of sequence of words, w, and is (hard) clustering function, which maps words to cluster identities.
</nextsent>
<nextsent>these monolingual models are coupled through word alignments, which constrains the clusterings to be consistent across languages, and optimized by approximately maximizing the joint likelihood across languages.
</nextsent>
<nextsent>just as monolingual word clusters are broadly applicable as feature sin monolingual models for linguistic structure prediction (turian et al, 2010), <papid> P10-1040 </papid>the resulting cross-lingualword clusters can be used as features in various cross lingual direct transfer models.</nextsent>
<nextsent>we believe that the extensions that we propose are likely to be useful for other tasks as well, e.g., direct transfer dependency parsing, in this paper, we focus solely on discriminative direct transfer models for ner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2444">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> multi-source direct transfer.  </section>
<citcontext>
<prevsection>
<prevsent>just as monolingual word clusters are broadly applicable as feature sin monolingual models for linguistic structure prediction (turian et al, 2010), <papid> P10-1040 </papid>the resulting cross-lingualword clusters can be used as features in various cross lingual direct transfer models.</prevsent>
<prevsent>we believe that the extensions that we propose are likely to be useful for other tasks as well, e.g., direct transfer dependency parsing, in this paper, we focus solely on discriminative direct transfer models for ner.</prevsent>
</prevsection>
<citsent citstr=" N09-1010 ">
learning from multiple languages have been shownto be of benefit both in unsupervised learning of syntax and part-of-speech (snyder et al, 2009; <papid> N09-1010 </papid>berg kirkpatrick and klein, 2010) and in transfer learning of dependency syntax (cohen et al, 2011; <papid> D11-1005 </papid>mcdonald et al, 2011).<papid> D11-1006 </papid></citsent>
<aftsection>
<nextsent>here we perform set of experiments where we investigate the potential of multi-source transfer for ner, in german (de), english (en), spanish (es) and dutch (nl), using cross-lingual word clusters.
</nextsent>
<nextsent>for all experiments, we use the same 56 source de es nl en 39.7 62.0 63.7 en + de ? 61.8 65.5 en + es 39.3 ? 65.6 en + nl 41.0 62.5 ? all 41.0 63.6 66.4 ? development set ? test set en 37.8 59.1 57.2 en + de ? 59.4 57.9 en + es 35.9 ? 59.1 en + nl 38.1 59.7 ? all 36.4 61.9 59.9 table 1: results of multi-source direct transfer, measured with f1-score on the conll 2002/2003 development and test sets.
</nextsent>
<nextsent>all: all languages except the target language are used as source languages.
</nextsent>
<nextsent>256 cross-lingual word clusters and the same feature templates as tack strom et al (2012), with the exception that the transition factors are not conditioned on the input.3 the features used are similar to those used by turian et al (2010), <papid> P10-1040 </papid>but include cross-lingual rather than monolingual word clusters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2445">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> multi-source direct transfer.  </section>
<citcontext>
<prevsection>
<prevsent>just as monolingual word clusters are broadly applicable as feature sin monolingual models for linguistic structure prediction (turian et al, 2010), <papid> P10-1040 </papid>the resulting cross-lingualword clusters can be used as features in various cross lingual direct transfer models.</prevsent>
<prevsent>we believe that the extensions that we propose are likely to be useful for other tasks as well, e.g., direct transfer dependency parsing, in this paper, we focus solely on discriminative direct transfer models for ner.</prevsent>
</prevsection>
<citsent citstr=" D11-1005 ">
learning from multiple languages have been shownto be of benefit both in unsupervised learning of syntax and part-of-speech (snyder et al, 2009; <papid> N09-1010 </papid>berg kirkpatrick and klein, 2010) and in transfer learning of dependency syntax (cohen et al, 2011; <papid> D11-1005 </papid>mcdonald et al, 2011).<papid> D11-1006 </papid></citsent>
<aftsection>
<nextsent>here we perform set of experiments where we investigate the potential of multi-source transfer for ner, in german (de), english (en), spanish (es) and dutch (nl), using cross-lingual word clusters.
</nextsent>
<nextsent>for all experiments, we use the same 56 source de es nl en 39.7 62.0 63.7 en + de ? 61.8 65.5 en + es 39.3 ? 65.6 en + nl 41.0 62.5 ? all 41.0 63.6 66.4 ? development set ? test set en 37.8 59.1 57.2 en + de ? 59.4 57.9 en + es 35.9 ? 59.1 en + nl 38.1 59.7 ? all 36.4 61.9 59.9 table 1: results of multi-source direct transfer, measured with f1-score on the conll 2002/2003 development and test sets.
</nextsent>
<nextsent>all: all languages except the target language are used as source languages.
</nextsent>
<nextsent>256 cross-lingual word clusters and the same feature templates as tack strom et al (2012), with the exception that the transition factors are not conditioned on the input.3 the features used are similar to those used by turian et al (2010), <papid> P10-1040 </papid>but include cross-lingual rather than monolingual word clusters.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2449">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> domain adaptation via self-training.  </section>
<citcontext>
<prevsection>
<prevsent>on the other hand, this suggests an opportunity for adapting to target language specific features through self-training.
</prevsent>
<prevsent>in fact, since the direct transfer models are trained using cross-lingual features, the target language can be viewed as simply representing different domain from the source language.
</prevsent>
</prevsection>
<citsent citstr=" N06-1020 ">
self-training has previously been shown to be asimple and effective way to perform domain adaptation for syntactic parsers and other tasks (mccloskyet al, 2006; <papid> N06-1020 </papid>chen et al, 2011).</citsent>
<aftsection>
<nextsent>the idea of self training for domain adaptation is to first train supervised predictor on labeled instances from source domain.
</nextsent>
<nextsent>this predictor is then used to label instances from some unlabeled target domain.
</nextsent>
<nextsent>those instances for which the predictor is confident are added to the source training set, and the process is repeated until some stopping criterion is met.
</nextsent>
<nextsent>recently, daume?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2451">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> domain adaptation via self-training.  </section>
<citcontext>
<prevsection>
<prevsent>single: single-source transfer, multi: multi-source transfer, self: self-trainingwith only cross-lingual word clusters, self/native: self training with cross-lingual and native word clusters.tive to the target language resembles the way mcdonald et al (2011) <papid> D11-1006 </papid>re-lexicalize delexicalized direct transfer parser.</prevsent>
<prevsent>both methods allow the model tomove weights from shared parameters to more predictive target language specific parameters.</prevsent>
</prevsection>
<citsent citstr=" D11-1138 ">
however,rather than using the direct transfer parsers own predictions through self-training, these authors project head-modifier relations to the target language throughloss-augmented learning (hall et al, 2011).<papid> D11-1138 </papid></citsent>
<aftsection>
<nextsent>the bootstrapping methods for language independent ner of cucerzan and yarowsky (1999) <papid> W99-0612 </papid>have similar effect.</nextsent>
<nextsent>our self-training approach is largely orthogonal tothese approaches.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2452">
<title id=" W12-1908.xml">nudging the envelope of direct transfer methods for multilingual named entity recognition </title>
<section> domain adaptation via self-training.  </section>
<citcontext>
<prevsection>
<prevsent>both methods allow the model tomove weights from shared parameters to more predictive target language specific parameters.
</prevsent>
<prevsent>however,rather than using the direct transfer parsers own predictions through self-training, these authors project head-modifier relations to the target language throughloss-augmented learning (hall et al, 2011).<papid> D11-1138 </papid></prevsent>
</prevsection>
<citsent citstr=" W99-0612 ">
the bootstrapping methods for language independent ner of cucerzan and yarowsky (1999) <papid> W99-0612 </papid>have similar effect.</citsent>
<aftsection>
<nextsent>our self-training approach is largely orthogonal tothese approaches.
</nextsent>
<nextsent>we therefore believe that combining these methods could be fruitful.
</nextsent>
<nextsent>4.1 experiments.
</nextsent>
<nextsent>in these experiments we combine direct transfer with self-training using unlabeled target data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2463">
<title id=" W11-2305.xml">asynchronous fixed grid scanning with dynamic codes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>yet the cognitive overhead of dealing with frequent grid reorganization is typically thought to outweigh any speedup that is achieved through more efficient coding (baletsa et al, 1976; lesher et al, 1998).if one assumes fixed grid, i.e., no dynamic reorganization of the symbols, then row/column scanning can gain efficiency by placing frequent characters in the upper left-hand corner, but cannot use contextually informed models.
</prevsent>
<prevsent>this is akin to morse code, which assigns fixed codes to symbols based on overall frequency, without considering context.
</prevsent>
</prevsection>
<citsent citstr=" W10-1304 ">
figure 2: scanning of non-contiguous sets of cells roark et al (2010)<papid> W10-1304 </papid>presented new approach which dropped the requirement of contiguous highlighting, thus allowing the use of variable codes on fixed grid.</citsent>
<aftsection>
<nextsent>for example, consider the grid in figure 2, where two symbols in different rows and columns are jointly highlighted.
</nextsent>
<nextsent>this approach, which we will term huffman scanning?, allowed the binary codes to be optimized using huffman coding methods (see section 2.2) with respect to contextually sensitive language models without dynamic reorganization of the grid.
</nextsent>
<nextsent>the method resulted in typing speed ups over conventional row/column scanning.
</nextsent>
<nextsent>one downside to the variable scanning that results from huffman scanning is that users cannot anticipate their target symbols binary code in any given context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2493">
<title id=" W11-2305.xml">asynchronous fixed grid scanning with dynamic codes </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>we follow roark et al (2010)<papid> W10-1304 </papid>and build character based smoothed 8-gram language models from anormalized 42m character subset of the english gigaword corpus and the cmu pronunciation dictio nary.</prevsent>
<prevsent>this latter lexicon is used to increase coverage of words that are unobserved in the corpus, and is included in training as one observation per word in the lexicon.</prevsent>
</prevsection>
<citsent citstr=" W05-1107 ">
smoothing is performed with generalized version of witten-bell smoothing (witten and bell,1991) as presented in carpenter (2005).<papid> W05-1107 </papid></citsent>
<aftsection>
<nextsent>text normalization and smoothing parameterizations were as presented in roark et al (2010)<papid> W10-1304 </papid></nextsent>
<nextsent>probability of the delete symbol ? was taken to be 0.05 in all trials(the same as the probability of an error, see section 3.2), and all other probabilities derived from the trained n-gram language model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2540">
<title id=" W12-1638.xml">integrating incremental speech recognition and pomdpbased dialogue systems </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>we present an incremental interaction manager that supports the use of isr with strictly turn-based dialogue managers.
</prevsent>
<prevsent>we then show that using pomdp-based dialogue manager with isr substantially improves the semantic accuracy of the incremental results.
</prevsent>
</prevsection>
<citsent citstr=" N09-1043 ">
this paper builds toward integrating two distinct lines of research in spoken dialogue systems: incremental speech recognition (isr) for input, and partially observable markov decision processes (pomdps) for dialogue management.on the one hand, isr improves on whole utterance speech recognition by streaming results to the dialogue manager (dm) in real time (baumann et al, 2009; <papid> N09-1043 </papid>skantze and schlangen, 2009).<papid> E09-1085 </papid></citsent>
<aftsection>
<nextsent>isr is attractive because it enables sophisticated system behavior such as interruption and back-channeling.
</nextsent>
<nextsent>however, isr output is particularly error-prone, and often requires specialized dialogue manager to be written (bu?
</nextsent>
<nextsent>and schlangen, 2011; schlangen and skantze, 2009).<papid> E09-1081 </papid></nextsent>
<nextsent>1work done while at at&t; labs - research on the other hand, pomdp-based dialogue managers improve on traditional approaches by (in part) tracking distribution over many possible dialogue states, rather than just one, thereby improving robustness to speech recognition errors (williams and young, 2007; thomson and young, 2010; young et al, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2541">
<title id=" W12-1638.xml">integrating incremental speech recognition and pomdpbased dialogue systems </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>we present an incremental interaction manager that supports the use of isr with strictly turn-based dialogue managers.
</prevsent>
<prevsent>we then show that using pomdp-based dialogue manager with isr substantially improves the semantic accuracy of the incremental results.
</prevsent>
</prevsection>
<citsent citstr=" E09-1085 ">
this paper builds toward integrating two distinct lines of research in spoken dialogue systems: incremental speech recognition (isr) for input, and partially observable markov decision processes (pomdps) for dialogue management.on the one hand, isr improves on whole utterance speech recognition by streaming results to the dialogue manager (dm) in real time (baumann et al, 2009; <papid> N09-1043 </papid>skantze and schlangen, 2009).<papid> E09-1085 </papid></citsent>
<aftsection>
<nextsent>isr is attractive because it enables sophisticated system behavior such as interruption and back-channeling.
</nextsent>
<nextsent>however, isr output is particularly error-prone, and often requires specialized dialogue manager to be written (bu?
</nextsent>
<nextsent>and schlangen, 2011; schlangen and skantze, 2009).<papid> E09-1081 </papid></nextsent>
<nextsent>1work done while at at&t; labs - research on the other hand, pomdp-based dialogue managers improve on traditional approaches by (in part) tracking distribution over many possible dialogue states, rather than just one, thereby improving robustness to speech recognition errors (williams and young, 2007; thomson and young, 2010; young et al, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2542">
<title id=" W12-1638.xml">integrating incremental speech recognition and pomdpbased dialogue systems </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>isr is attractive because it enables sophisticated system behavior such as interruption and back-channeling.
</prevsent>
<prevsent>however, isr output is particularly error-prone, and often requires specialized dialogue manager to be written (bu?
</prevsent>
</prevsection>
<citsent citstr=" E09-1081 ">
and schlangen, 2011; schlangen and skantze, 2009).<papid> E09-1081 </papid></citsent>
<aftsection>
<nextsent>1work done while at at&t; labs - research on the other hand, pomdp-based dialogue managers improve on traditional approaches by (in part) tracking distribution over many possible dialogue states, rather than just one, thereby improving robustness to speech recognition errors (williams and young, 2007; thomson and young, 2010; young et al, 2010).
</nextsent>
<nextsent>the overall aim of combining these two lines of research is to improve the robustness of error-prone isr output.to our knowledge only one study to date has combined isr and pomdps.
</nextsent>
<nextsent>lu et al (2011) showhow 1-best isr hypotheses can be used within single dialogue turn.
</nextsent>
<nextsent>this work is different than the present paper, where we use n-best lists of isr results across multiple turns of dialogue.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2543">
<title id=" W12-1638.xml">integrating incremental speech recognition and pomdpbased dialogue systems </title>
<section> incremental interaction manager.  </section>
<citcontext>
<prevsection>
<prevsent>first, only incremental results that could correspond to complete user utterance are con sidered: incomplete results are discarded and never passed to the dm.
</prevsent>
<prevsent>in addition, isr results are of ten unstable, and it is undesirable to proceed with an isr result if it will very likely be revised.
</prevsent>
</prevsection>
<citsent citstr=" W11-2014 ">
thus each candidate isr result is scored for stability (sel fridge et al, 2011) <papid> W11-2014 </papid>and results with scores below manually-set threshold are discarded.</citsent>
<aftsection>
<nextsent>table 1 shows an example of the recognizer, the iim, and the dm.
</nextsent>
<nextsent>forsake of clarity, stability scores are not shown.
</nextsent>
<nextsent>the system asks where are you leaving from??
</nextsent>
<nextsent>and the user answers mckee sport center.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2544">
<title id=" W12-1638.xml">integrating incremental speech recognition and pomdpbased dialogue systems </title>
<section> integrating isr with pomdp-based.  </section>
<citcontext>
<prevsection>
<prevsent>dialogue manager (traditional) dialogue manager based on partially observable markov decision process (pomdp dm)tracks probability distribution over multiple hidden dialogue states called belief state (williamsand young, 2007).3 as such, pomdp dms readily make use of the entire asr n-best list, even for low-confidence results ? the confidence level of each n-best list item contributes proportionally to the probability of its corresponding hidden state.
</prevsent>
<prevsent>it is straightforward to integrate isr and apomdp dm using the iim.
</prevsent>
</prevsection>
<citsent citstr=" W09-3919 ">
each item on the nbest list of an incremental result is assigned confidence score (williams and balakrishnan, 2009) <papid> W09-3919 </papid>and passed to the pomdp dm as if it were complete result, triggering belief state update.</citsent>
<aftsection>
<nextsent>note that this approach is not predicting future user speech from partial results (devault et al, 2009; <papid> W09-3902 </papid>lu et al, 2011), but rather (tentatively) assuming that partial results are complete.</nextsent>
<nextsent>the key benefit is that belief state generated from an incremental result incorporates all of the contextual information available to the system from the start of the dialogue until the moment of that incremental result.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2545">
<title id=" W12-1638.xml">integrating incremental speech recognition and pomdpbased dialogue systems </title>
<section> integrating isr with pomdp-based.  </section>
<citcontext>
<prevsection>
<prevsent>it is straightforward to integrate isr and apomdp dm using the iim.
</prevsent>
<prevsent>each item on the nbest list of an incremental result is assigned confidence score (williams and balakrishnan, 2009) <papid> W09-3919 </papid>and passed to the pomdp dm as if it were complete result, triggering belief state update.</prevsent>
</prevsection>
<citsent citstr=" W09-3902 ">
note that this approach is not predicting future user speech from partial results (devault et al, 2009; <papid> W09-3902 </papid>lu et al, 2011), but rather (tentatively) assuming that partial results are complete.</citsent>
<aftsection>
<nextsent>the key benefit is that belief state generated from an incremental result incorporates all of the contextual information available to the system from the start of the dialogue until the moment of that incremental result.
</nextsent>
<nextsent>by comparison, an isolated incremental result includes only information from the current utterance.
</nextsent>
<nextsent>if the probability models in the pomdp are estimated properly, belief states should be more accurate than isolated incremental results.
</nextsent>
<nextsent>for our experiments we used corpus of 1037 calls from real users to single dialogue system that provides bus timetable information for pittsburgh, pa(a subsequent version of williams (2011)).<papid> W11-2016 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2546">
<title id=" W12-1638.xml">integrating incremental speech recognition and pomdpbased dialogue systems </title>
<section> experimental design.  </section>
<citcontext>
<prevsection>
<prevsent>by comparison, an isolated incremental result includes only information from the current utterance.
</prevsent>
<prevsent>if the probability models in the pomdp are estimated properly, belief states should be more accurate than isolated incremental results.
</prevsent>
</prevsection>
<citsent citstr=" W11-2016 ">
for our experiments we used corpus of 1037 calls from real users to single dialogue system that provides bus timetable information for pittsburgh, pa(a subsequent version of williams (2011)).<papid> W11-2016 </papid></citsent>
<aftsection>
<nextsent>this dialogue system opened by asking the caller to say bus route number or dont know?; if the system had insufficient confidence following recognition, it repeated the question.
</nextsent>
<nextsent>we extracted the first 3 responses to the systems bus route question.
</nextsent>
<nextsent>often the system did not need to ask 3 times; our experimental set contained 1037 calls with one or more attempts, 586 calls with two or more attempts, and3it also uses reinforcement learning to choose actions, although in this paper we are not concerned with this aspect.356 calls with three or more attempts.
</nextsent>
<nextsent>these utterances were all transcribed, and tagged for the bus route they contained, if any: 25% contained neither route nor dont know?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2549">
<title id=" W12-0411.xml">pastiche detection based on stop word rankings exposing impersonators of a romanian writer </title>
<section> distances and clustering.  </section>
<citcontext>
<prevsection>
<prevsent>another useful visualisation method is the principal components analysis, which gives us projection from high-dimensional space into low-dimensionalone, in this case in 2d.
</prevsent>
<prevsent>using this stop word frequency representation, the first principal components plane looks like figure 3.
</prevsent>
</prevsection>
<citsent citstr=" C08-2023 ">
in (popescu and dinu, 2008), <papid> C08-2023 </papid>the use of rankings instead of frequencies is proposed as smoothing method and it is shown to give good results for computational stylometry.</citsent>
<aftsection>
<nextsent>a ranking is simply an ordering of items; in this case, the representation of each document is the ranking of the stopwordsin that particular document.
</nextsent>
<nextsent>the fact that specific function word has the rank 2 (is the second most frequent word) in one text and has the rank 4 (is the fourth most frequent word) in another text can be more directly relevant than the fact that the respective word appears 349 times in the first text and only 299 times in the second.
</nextsent>
<nextsent>rank distance (dinu, 2003) is an ordinal metric able to compare different rankings of set of objects.
</nextsent>
<nextsent>in the general case, rank distance works for 74 figure 2: principal components plot.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2550">
<title id=" W12-2013.xml">judging grammaticality with count induced tree substitution grammars </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>prior work has shown the utility of syntactic tree fragments as features in judging the gram maticality of text.
</prevsent>
<prevsent>to date such fragments have been extracted from derivations of bayesian induced tree substitution grammars (tsgs).
</prevsent>
</prevsection>
<citsent citstr=" P11-2038 ">
evaluating on discriminative coarse and fine grammaticality classification tasks, we show that simple, deterministic, count-based approach to fragment identification performs on par with the more complicated grammars ofpost (2011)<papid> P11-2038 </papid></citsent>
<aftsection>
<nextsent>this represents significant reduction in complexity for those interested in the use of such fragments in the development of systems for the educational domain.
</nextsent>
<nextsent>automatically judging grammaticality is an important component in computer-assisted education,with potential applications including large-scale essay grading and helping to interactively improve the writing of both native and l2 speakers.
</nextsent>
<nextsent>while ngram models have been productive throughout natural language processing (nlp), they are obviously insufficient as models of languages, since they do not model language structure or correspondences beyond the narrow markov context.
</nextsent>
<nextsent>context-free grammars (cfgs) address many ofthe problems inherent in n-grams, and are therefore intuitively much better suited for grammatical ity judgments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2553">
<title id=" W12-2013.xml">judging grammaticality with count induced tree substitution grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while ngram models have been productive throughout natural language processing (nlp), they are obviously insufficient as models of languages, since they do not model language structure or correspondences beyond the narrow markov context.
</prevsent>
<prevsent>context-free grammars (cfgs) address many ofthe problems inherent in n-grams, and are therefore intuitively much better suited for grammatical ity judgments.
</prevsent>
</prevsection>
<citsent citstr=" N04-1021 ">
unfortunately, cfgs used in practice are permissive (och et al, 2004) <papid> N04-1021 </papid>and make unrealistic independence and structural assumptions, resulting in leaky?</citsent>
<aftsection>
<nextsent>grammars that over generate andthus serve poorly as models of language.
</nextsent>
<nextsent>however, approaches that make use of the cfg productions as discriminative features have performed better.
</nextsent>
<nextsent>cherry and quirk (2008) improved upon an ngram baseline in grammatical classification by adjusting cfg production weights with latent svm, while others have found it useful to use comparisons between scores of different parsers (wagner et al,2009) or the use of cfg productions in linear classification settings (wong and dras, 2010) in classifying sentences in different grammaticality settings.
</nextsent>
<nextsent>another successful approach in grammaticality tasks has been the use of grammars with an extended domain of locality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2558">
<title id=" W12-2013.xml">judging grammaticality with count induced tree substitution grammars </title>
<section> tree substitution grammars (tsgs).  </section>
<citcontext>
<prevsection>
<prevsent>figure 1 depicts an example tsg fragment and equivalent cfg rules; note that the entire internal structure of 1a is described within single rewrite.
</prevsent>
<prevsent>unfortunately, learning probabilistic tsgs is not straight-forward, in large part because tsg-specificresources (e.g., large scale tsg-annotated treebanks) do not exist.
</prevsent>
</prevsection>
<citsent citstr=" E93-1006 ">
approaches to this problem began by taking all fragments fall in treebank (bod, 1993; <papid> E93-1006 </papid>goodman, 1996), <papid> W96-0214 </papid>which resulted in very large grammars composed mostly of fragments very unlikely to generalize.1 range of heuristic solutions reduced these grammar sizes to much smaller, more compact subset of all fragments (zollmann and simaan, 2005; zuidema, 2007).<papid> D07-1058 </papid></citsent>
<aftsection>
<nextsent>more recently, more principled models have been proposed, taking the form of inference in bayesian non-parametric models (post and gildea, 2009; <papid> P09-2012 </papid>cohn et al, 2009).<papid> N09-1062 </papid></nextsent>
<nextsent>in addition to providing formal model for tsgs, these techniques address the over fitting problem of1the n-gram analog would be something like storing all 30 grams seen in corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2559">
<title id=" W12-2013.xml">judging grammaticality with count induced tree substitution grammars </title>
<section> tree substitution grammars (tsgs).  </section>
<citcontext>
<prevsection>
<prevsent>figure 1 depicts an example tsg fragment and equivalent cfg rules; note that the entire internal structure of 1a is described within single rewrite.
</prevsent>
<prevsent>unfortunately, learning probabilistic tsgs is not straight-forward, in large part because tsg-specificresources (e.g., large scale tsg-annotated treebanks) do not exist.
</prevsent>
</prevsection>
<citsent citstr=" W96-0214 ">
approaches to this problem began by taking all fragments fall in treebank (bod, 1993; <papid> E93-1006 </papid>goodman, 1996), <papid> W96-0214 </papid>which resulted in very large grammars composed mostly of fragments very unlikely to generalize.1 range of heuristic solutions reduced these grammar sizes to much smaller, more compact subset of all fragments (zollmann and simaan, 2005; zuidema, 2007).<papid> D07-1058 </papid></citsent>
<aftsection>
<nextsent>more recently, more principled models have been proposed, taking the form of inference in bayesian non-parametric models (post and gildea, 2009; <papid> P09-2012 </papid>cohn et al, 2009).<papid> N09-1062 </papid></nextsent>
<nextsent>in addition to providing formal model for tsgs, these techniques address the over fitting problem of1the n-gram analog would be something like storing all 30 grams seen in corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2560">
<title id=" W12-2013.xml">judging grammaticality with count induced tree substitution grammars </title>
<section> tree substitution grammars (tsgs).  </section>
<citcontext>
<prevsection>
<prevsent>figure 1 depicts an example tsg fragment and equivalent cfg rules; note that the entire internal structure of 1a is described within single rewrite.
</prevsent>
<prevsent>unfortunately, learning probabilistic tsgs is not straight-forward, in large part because tsg-specificresources (e.g., large scale tsg-annotated treebanks) do not exist.
</prevsent>
</prevsection>
<citsent citstr=" D07-1058 ">
approaches to this problem began by taking all fragments fall in treebank (bod, 1993; <papid> E93-1006 </papid>goodman, 1996), <papid> W96-0214 </papid>which resulted in very large grammars composed mostly of fragments very unlikely to generalize.1 range of heuristic solutions reduced these grammar sizes to much smaller, more compact subset of all fragments (zollmann and simaan, 2005; zuidema, 2007).<papid> D07-1058 </papid></citsent>
<aftsection>
<nextsent>more recently, more principled models have been proposed, taking the form of inference in bayesian non-parametric models (post and gildea, 2009; <papid> P09-2012 </papid>cohn et al, 2009).<papid> N09-1062 </papid></nextsent>
<nextsent>in addition to providing formal model for tsgs, these techniques address the over fitting problem of1the n-gram analog would be something like storing all 30 grams seen in corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2561">
<title id=" W12-2013.xml">judging grammaticality with count induced tree substitution grammars </title>
<section> tree substitution grammars (tsgs).  </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, learning probabilistic tsgs is not straight-forward, in large part because tsg-specificresources (e.g., large scale tsg-annotated treebanks) do not exist.
</prevsent>
<prevsent>approaches to this problem began by taking all fragments fall in treebank (bod, 1993; <papid> E93-1006 </papid>goodman, 1996), <papid> W96-0214 </papid>which resulted in very large grammars composed mostly of fragments very unlikely to generalize.1 range of heuristic solutions reduced these grammar sizes to much smaller, more compact subset of all fragments (zollmann and simaan, 2005; zuidema, 2007).<papid> D07-1058 </papid></prevsent>
</prevsection>
<citsent citstr=" P09-2012 ">
more recently, more principled models have been proposed, taking the form of inference in bayesian non-parametric models (post and gildea, 2009; <papid> P09-2012 </papid>cohn et al, 2009).<papid> N09-1062 </papid></citsent>
<aftsection>
<nextsent>in addition to providing formal model for tsgs, these techniques address the over fitting problem of1the n-gram analog would be something like storing all 30 grams seen in corpus.
</nextsent>
<nextsent>all fragments grammars with priors that discourage large fragments unless there is enough evidence to warrant their inclusion in the grammar.
</nextsent>
<nextsent>the problem with such approaches, however, is that the sampling procedures used to infer them can be complex, difficult to code, and slow to converge.
</nextsent>
<nextsent>although more general techniques have been proposed to better explore the search space (cohn and blunsom, 2010;cohn et al, 2010; liang et al, 2010), <papid> N10-1082 </papid>the complexity and non-determinism of these samplers remain, and there are no publicly available implementations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2563">
<title id=" W12-2013.xml">judging grammaticality with count induced tree substitution grammars </title>
<section> tree substitution grammars (tsgs).  </section>
<citcontext>
<prevsection>
<prevsent>unfortunately, learning probabilistic tsgs is not straight-forward, in large part because tsg-specificresources (e.g., large scale tsg-annotated treebanks) do not exist.
</prevsent>
<prevsent>approaches to this problem began by taking all fragments fall in treebank (bod, 1993; <papid> E93-1006 </papid>goodman, 1996), <papid> W96-0214 </papid>which resulted in very large grammars composed mostly of fragments very unlikely to generalize.1 range of heuristic solutions reduced these grammar sizes to much smaller, more compact subset of all fragments (zollmann and simaan, 2005; zuidema, 2007).<papid> D07-1058 </papid></prevsent>
</prevsection>
<citsent citstr=" N09-1062 ">
more recently, more principled models have been proposed, taking the form of inference in bayesian non-parametric models (post and gildea, 2009; <papid> P09-2012 </papid>cohn et al, 2009).<papid> N09-1062 </papid></citsent>
<aftsection>
<nextsent>in addition to providing formal model for tsgs, these techniques address the over fitting problem of1the n-gram analog would be something like storing all 30 grams seen in corpus.
</nextsent>
<nextsent>all fragments grammars with priors that discourage large fragments unless there is enough evidence to warrant their inclusion in the grammar.
</nextsent>
<nextsent>the problem with such approaches, however, is that the sampling procedures used to infer them can be complex, difficult to code, and slow to converge.
</nextsent>
<nextsent>although more general techniques have been proposed to better explore the search space (cohn and blunsom, 2010;cohn et al, 2010; liang et al, 2010), <papid> N10-1082 </papid>the complexity and non-determinism of these samplers remain, and there are no publicly available implementations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2564">
<title id=" W12-2013.xml">judging grammaticality with count induced tree substitution grammars </title>
<section> tree substitution grammars (tsgs).  </section>
<citcontext>
<prevsection>
<prevsent>all fragments grammars with priors that discourage large fragments unless there is enough evidence to warrant their inclusion in the grammar.
</prevsent>
<prevsent>the problem with such approaches, however, is that the sampling procedures used to infer them can be complex, difficult to code, and slow to converge.
</prevsent>
</prevsection>
<citsent citstr=" N10-1082 ">
although more general techniques have been proposed to better explore the search space (cohn and blunsom, 2010;cohn et al, 2010; liang et al, 2010), <papid> N10-1082 </papid>the complexity and non-determinism of these samplers remain, and there are no publicly available implementations.</citsent>
<aftsection>
<nextsent>the underlying premise behind these grammar learning approaches was the need for probabilistic grammar for parsing.
</nextsent>
<nextsent>post (2011)<papid> P11-2038 </papid>showed that the fragments extracted from derivations obtained by parsing with probabilistic tsgs were useful as features in two coarse-grained grammaticality tasks.in such setting, fragments are needed for classification, but it is not clear that they need to be obtained from derivations produced by parsing with probabilistic tsgs.</nextsent>
<nextsent>in the next section, we describe simple, deterministic, count-based approach to learning an unweighted tsg.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2579">
<title id=" W12-2013.xml">judging grammaticality with count induced tree substitution grammars </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for count+cfg, we included binary feature for every rule that was used in the most likely parse of query sentence, according to pcfg7.following post (2011)<papid> P11-2038 </papid>we train an `-2 regularized svm using liblinear8 (fan et al, 2008) per model.</prevsent>
<prevsent>we optimized the models on dev data, letting the smoothing parameter be 10m, for integral ? [4, 2]: 0.1 was optimal for all models.</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
6we parsed all sentences with the berkeley parser (petrov et al., 2006).<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>7we used the berkeley grammar/parser (petrov et al, 2006) <papid> P06-1055 </papid>inaccurate mode; all other options were their default values.</nextsent>
<nextsent>8csie.ntu.edu.tw/cjlin/liblinear/ 118 task count count+lex count+cfg coarse 86.3 86.8 88.3 fine 62.9 64.3 67.0 (a) our count-based models, with = 15, = 50k.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2589">
<title id=" W12-1004.xml">toward language independent methodology for generating artwork descriptions  exploring framenet information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the first sentence contains the semantic roles creator and represented, the second sentence contains represented and time,and in the third sentence we find creator, represented and time.
</prevsent>
<prevsent>as the examples show there are sever always of semantically characterizing the situation expressed by verb, with implications for the syntactic realization of that verb.when generating natural language from semantic web ontologies it is important to find generic strategies that allow us to identify the semantic elements of verb and associate them with the appropriate argument realization of that verb.
</prevsent>
</prevsection>
<citsent citstr=" W09-0302 ">
this is particularly relevant in multilingual settings because the semantic and syntactic behavior of verbs will vary depending on the target language, both in the constructions found and in their distribution.previous work on natural language generation of cultural heritage information from semantic web ontologies has relied on large amount of specially tailored manual linguistic information to produce descriptions that are targeted to specific group of readers (androutsopoulos et al, 2001; dan 18nlls, 2008; konstantopoulos et al, 2009).<papid> W09-0302 </papid></citsent>
<aftsection>
<nextsent>although valuable information for generating natural languages is found in computationallexical-semantic resources such as the berkeley framenet (section 3) which exist today in several languages (erk et al, 2003; <papid> P03-1068 </papid>subirats and petruck, 2003; ohara et al, 2003; borin et al., 2010), there has been little emphasis on how to manage digitized data from digital libraries using these open source resources.in this paper we demonstrate how the information available in such electronically available resources can be exploited for generating multilingual artwork descriptions.</nextsent>
<nextsent>in the remainder of this paper we describea case study on english and swedish that underscores the importance of using lexical resource such as framenet (section 2).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2590">
<title id=" W12-1004.xml">toward language independent methodology for generating artwork descriptions  exploring framenet information </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as the examples show there are sever always of semantically characterizing the situation expressed by verb, with implications for the syntactic realization of that verb.when generating natural language from semantic web ontologies it is important to find generic strategies that allow us to identify the semantic elements of verb and associate them with the appropriate argument realization of that verb.
</prevsent>
<prevsent>this is particularly relevant in multilingual settings because the semantic and syntactic behavior of verbs will vary depending on the target language, both in the constructions found and in their distribution.previous work on natural language generation of cultural heritage information from semantic web ontologies has relied on large amount of specially tailored manual linguistic information to produce descriptions that are targeted to specific group of readers (androutsopoulos et al, 2001; dan 18nlls, 2008; konstantopoulos et al, 2009).<papid> W09-0302 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1068 ">
although valuable information for generating natural languages is found in computationallexical-semantic resources such as the berkeley framenet (section 3) which exist today in several languages (erk et al, 2003; <papid> P03-1068 </papid>subirats and petruck, 2003; ohara et al, 2003; borin et al., 2010), there has been little emphasis on how to manage digitized data from digital libraries using these open source resources.in this paper we demonstrate how the information available in such electronically available resources can be exploited for generating multilingual artwork descriptions.</citsent>
<aftsection>
<nextsent>in the remainder of this paper we describea case study on english and swedish that underscores the importance of using lexical resource such as framenet (section 2).
</nextsent>
<nextsent>we present the kind of information that is offered by two existing frame nets (section 3).
</nextsent>
<nextsent>we demonstrate how domain specific natural language generator can benefit from the information that is available in both frame nets (section 4).
</nextsent>
<nextsent>we end with discussion and pointers to future work (section 5).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2591">
<title id=" W11-1907.xml">unrestricted coreference resolution via global hypergraph partitioning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>most recent approaches to coreference resolution divide this task into two steps: (1) classification step which determines whether pair of mentions is co referent orwhich outputs confidence value, and (2) clustering step which groups mentions into entities based on the output of step 1.in this paper we present an end-to-end coreference resolution system, copa, which avoids the division into two steps and instead performs global decision in one step.
</prevsent>
<prevsent>the system presents document as hypergraph, where the vertices denote mentions and the edges denote relational features between mentions.
</prevsent>
</prevsection>
<citsent citstr=" C10-1017 ">
coreference resolution is then performed globally in one step by partitioning the hypergraph into sub hypergraphs so that all mentions in one sub hypergraph refer to the same entity (cai and strube, 2010).<papid> C10-1017 </papid></citsent>
<aftsection>
<nextsent>copa assigns edge weights by applying simple descriptive statistics on the tranin ing data.
</nextsent>
<nextsent>since copa does not need to learn an explicit model, we used only 30% of the conll shared task training data.
</nextsent>
<nextsent>we did this not for efficiency reasons, only for convenience.
</nextsent>
<nextsent>while copa has been developed originally to perform coreference resolution on muc and ace data (cai and strube, 2010), <papid> C10-1017 </papid>the move to the ontonotes data (weischedel et al, 2011) required mainly to update the mention detector and the feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2594">
<title id=" W11-1907.xml">unrestricted coreference resolution via global hypergraph partitioning </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we did this not for efficiency reasons, only for convenience.
</prevsent>
<prevsent>while copa has been developed originally to perform coreference resolution on muc and ace data (cai and strube, 2010), <papid> C10-1017 </papid>the move to the ontonotes data (weischedel et al, 2011) required mainly to update the mention detector and the feature set.</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
since several off-the-shelf preprocessing components are used, copa participated in the open setting of the conll shared task on modeling unrestricted coreference (pradhan et al, 2011).<papid> W11-1901 </papid></citsent>
<aftsection>
<nextsent>we didnot make extensive use of information beyond information from the closed class setting.
</nextsent>
<nextsent>copa is implemented on top of the bart-toolkit (versley et al, 2008).<papid> L08-1328 </papid></nextsent>
<nextsent>documents are transformed into the mmax2-format (muller and strube, 2006)which allows for easy visualization and (linguis tic) debugging.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2595">
<title id=" W11-1907.xml">unrestricted coreference resolution via global hypergraph partitioning </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>since several off-the-shelf preprocessing components are used, copa participated in the open setting of the conll shared task on modeling unrestricted coreference (pradhan et al, 2011).<papid> W11-1901 </papid></prevsent>
<prevsent>we didnot make extensive use of information beyond information from the closed class setting.</prevsent>
</prevsection>
<citsent citstr=" L08-1328 ">
copa is implemented on top of the bart-toolkit (versley et al, 2008).<papid> L08-1328 </papid></citsent>
<aftsection>
<nextsent>documents are transformed into the mmax2-format (muller and strube, 2006)which allows for easy visualization and (linguis tic) debugging.
</nextsent>
<nextsent>each document is stored in severalxml-files representing different layers of annotations.
</nextsent>
<nextsent>these annotations are created by pipeline of preprocessing components.
</nextsent>
<nextsent>we use the stanford maxenttagger (toutanova et al, 2003) <papid> N03-1033 </papid>for partof-speech tagging, and the stanford named entity recognizer (finkel et al, 2005) <papid> P05-1045 </papid>for annotating named entities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2596">
<title id=" W11-1907.xml">unrestricted coreference resolution via global hypergraph partitioning </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>each document is stored in severalxml-files representing different layers of annotations.
</prevsent>
<prevsent>these annotations are created by pipeline of preprocessing components.
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
we use the stanford maxenttagger (toutanova et al, 2003) <papid> N03-1033 </papid>for partof-speech tagging, and the stanford named entity recognizer (finkel et al, 2005) <papid> P05-1045 </papid>for annotating named entities.</citsent>
<aftsection>
<nextsent>in order to derive syntactic information, we use the charniak/johnson reranking parser (charniak and johnson, 2005) <papid> P05-1022 </papid>com 56 bined with constituent-to-dependency conversion tool (http://nlp.cs.lth.se/software/ treebank_converter).</nextsent>
<nextsent>the preprocessing models are not trained on conll data, so we only participated in the open task.we have implemented an in-house mention detector, which makes use of the parsing output, the partof-speech tags, as well as the chunks from the yam cha chunker (kudoh and matsumoto, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2597">
<title id=" W11-1907.xml">unrestricted coreference resolution via global hypergraph partitioning </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>each document is stored in severalxml-files representing different layers of annotations.
</prevsent>
<prevsent>these annotations are created by pipeline of preprocessing components.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
we use the stanford maxenttagger (toutanova et al, 2003) <papid> N03-1033 </papid>for partof-speech tagging, and the stanford named entity recognizer (finkel et al, 2005) <papid> P05-1045 </papid>for annotating named entities.</citsent>
<aftsection>
<nextsent>in order to derive syntactic information, we use the charniak/johnson reranking parser (charniak and johnson, 2005) <papid> P05-1022 </papid>com 56 bined with constituent-to-dependency conversion tool (http://nlp.cs.lth.se/software/ treebank_converter).</nextsent>
<nextsent>the preprocessing models are not trained on conll data, so we only participated in the open task.we have implemented an in-house mention detector, which makes use of the parsing output, the partof-speech tags, as well as the chunks from the yam cha chunker (kudoh and matsumoto, 2000).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2598">
<title id=" W11-1907.xml">unrestricted coreference resolution via global hypergraph partitioning </title>
<section> preprocessing.  </section>
<citcontext>
<prevsection>
<prevsent>these annotations are created by pipeline of preprocessing components.
</prevsent>
<prevsent>we use the stanford maxenttagger (toutanova et al, 2003) <papid> N03-1033 </papid>for partof-speech tagging, and the stanford named entity recognizer (finkel et al, 2005) <papid> P05-1045 </papid>for annotating named entities.</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
in order to derive syntactic information, we use the charniak/johnson reranking parser (charniak and johnson, 2005) <papid> P05-1022 </papid>com 56 bined with constituent-to-dependency conversion tool (http://nlp.cs.lth.se/software/ treebank_converter).</citsent>
<aftsection>
<nextsent>the preprocessing models are not trained on conll data, so we only participated in the open task.we have implemented an in-house mention detector, which makes use of the parsing output, the partof-speech tags, as well as the chunks from the yam cha chunker (kudoh and matsumoto, 2000).
</nextsent>
<nextsent>for the ontonotes data, the mention detector annotates the biggest noun phrase spans.
</nextsent>
<nextsent>the copa system consists of modules which derive hyperedges from features and assign edge weights indicating positive correlation with the coreference relation, and resolution modules which create hypergraph representation for the testing data and perform partitioning to produce sub hypergraphs, each of which represents an entity.
</nextsent>
<nextsent>3.1 hyperedgecreator.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2604">
<title id=" W11-1907.xml">unrestricted coreference resolution via global hypergraph partitioning </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>(6) contrasubjobj: two mentions are in the subject and object positions of the same verb, and the anaphor is non-possesive pronoun.
</prevsent>
<prevsent>4.2 positive features.
</prevsent>
</prevsection>
<citsent citstr=" P09-1074 ">
the majority of well studied coreference features (e.g. stoyanov et al (2009)) <papid> P09-1074 </papid>are actually positive coreference indicators.</citsent>
<aftsection>
<nextsent>in our system, the mentions which participate in positive relations are included in the graph representation.(7) str match npron &amp; (8) str match pron: after discarding stop words, if the strings of mentions completely match and are not pronouns, they are put into edges of the str match npron type.
</nextsent>
<nextsent>when the matched mentions are pronouns, they are put into the str match pron type edges.(9) alias: after discarding stop words, if mentions are aliases of each other (i.e. proper names with partial match, full names and acronyms, etc.).(10) headmatch: if the syntactic heads of mentions match.(11) nprn prn: if the antecedent is not pronoun and the anaphor is pronoun.
</nextsent>
<nextsent>this feature is restricted to sentence distance of 2.
</nextsent>
<nextsent>though it isnot highly weighted, it is crucial for integrating pronouns into the graph.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2605">
<title id=" W11-2212.xml">unsupervised alignment for segmental based language understanding </title>
<section> semantic concept alignment.  </section>
<citcontext>
<prevsection>
<prevsent>the alignment task aims at finding the mapping between words oftwo sentences in relation of translation.
</prevsent>
<prevsent>it faces several difficulties: ? some source words are not associated with translated word; ? others are translated by several words; ? matched words may occur at different positions in both sentences according to the syntactic rules of the considered languages.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
several statistical models have been proposed to align two sentences (brown et al, 1993).<papid> J93-2003 </papid></citsent>
<aftsection>
<nextsent>one of their main interests is their ability to be built in an unsupervised way from parallel corpus aligned atthe sentence level, but not at the word level.
</nextsent>
<nextsent>formally, from sentence = s1 . . .
</nextsent>
<nextsent>sm expressed in asource language and its translation = t1 . . .
</nextsent>
<nextsent>tn expressed in target language, an ibm-style alignmenta = a1 . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2606">
<title id=" W11-2212.xml">unsupervised alignment for segmental based language understanding </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>the audio data are distributed with their manual transcripts and automatic speech recognition (asr) hypotheses.
</prevsent>
<prevsent>the corp usis divided into three parts: training set (approxi mat ively 12k utterances), development set (1.2k) and test set (3k).
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
the experiments led on the alignment methods were evaluated on the development corpus using mgiza++ (gao and vogel, 2008), <papid> W08-0509 </papid>multi-thread version of giza++ (och and ney, 2003) which also allows previously trained ibm alignments models to be applied on the development and test corpora.1 the conceptual tagging process was evaluated on the test corpus, using wapiti (lavergne et al, 2010) to train the crf models.</citsent>
<aftsection>
<nextsent>several setups have been tested: ? manual vs asr transcriptions, ? inclusion (or not) of values during the error computation.several concept orderings (before automatic align ment) have also been considered: ? first ideal one, which takes reference concept sequences as they are, aka sequential order;?
</nextsent>
<nextsent>two more realistic variants that sort concepts either alphabetically or randomly, in order to simulate bag-of-concepts.
</nextsent>
<nextsent>alphabetical order is introduced solely to show that particular order (which is not related to the natural order)might misled the alignment process by introducing undue regularities.
</nextsent>
<nextsent>to give rough idea, these experiments required few minutes of computing time to train alignment models of 12k utterances, few hours to train crf models (using 8 cpus on our cluster of xeon cpus)and few seconds to apply alignment and crf models in order to decode the test corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2607">
<title id=" W12-0505.xml">an unsupervised and data driven approach for spell checking in vietnamese ocr scanned texts </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, shape or visual similarity forces ocr scanners to misunderstand some characters; or input text documents do not have good quality, causing noises in resulting scanned texts.
</prevsent>
<prevsent>the task of spell checking for ocr-scanned text documents proposed aims to solve the above situation.
</prevsent>
</prevsection>
<citsent citstr=" W96-0108 ">
researchers in the literature used to approach this task for various languages such as: english (tong and evans, 1996; <papid> W96-0108 </papid>taghva and stofsky, 2001; kolak and resnik, 2002), chinese (zhuang et al, 2004), japanese (nagata, 1996; <papid> C96-2136 </papid>nagata, 1998), <papid> P98-2152 </papid>arabic (magdy and darwish, 2006), <papid> W06-1648 </papid>and thai (meknavin et al, 1998).<papid> P98-2138 </papid></citsent>
<aftsection>
<nextsent>the most common approach is to involve users for their intervention with computer support.taghva and stofsky (2001) designed an interactive system (called ocrspell) that assists users as many interactive features as possible during their correction, such as: choose word boundary, memorize user-corrected words for future correction,provide specific prior knowledge about typical errors.
</nextsent>
<nextsent>for certain applications requiring automation, the interactive scheme may not work.unlike (taghva and stofsky, 2001), non interactive (or fully automatic) approaches have been investigated.
</nextsent>
<nextsent>such approaches need pre specified lexicons &amp; confusion resources (tong and evans, 1996), <papid> W96-0108 </papid>language-specific knowledge(meknavin et al, 1998) <papid> P98-2138 </papid>or manually-created phonetic transformation rules (hodge and austin, 2003) to assist correction process.other approaches used supervised mechanisms for ocr error correction, such as: statistical language models (nagata, 1996; <papid> C96-2136 </papid>zhuang etal., 2004; magdy and darwish, 2006), <papid> W06-1648 </papid>noisy channel model (kolak and resnik, 2002).</nextsent>
<nextsent>these approaches performed well but are limited due to requiring large annotated training data specific to ocr spell checking in languages that are very hard to obtain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2608">
<title id=" W12-0505.xml">an unsupervised and data driven approach for spell checking in vietnamese ocr scanned texts </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, shape or visual similarity forces ocr scanners to misunderstand some characters; or input text documents do not have good quality, causing noises in resulting scanned texts.
</prevsent>
<prevsent>the task of spell checking for ocr-scanned text documents proposed aims to solve the above situation.
</prevsent>
</prevsection>
<citsent citstr=" C96-2136 ">
researchers in the literature used to approach this task for various languages such as: english (tong and evans, 1996; <papid> W96-0108 </papid>taghva and stofsky, 2001; kolak and resnik, 2002), chinese (zhuang et al, 2004), japanese (nagata, 1996; <papid> C96-2136 </papid>nagata, 1998), <papid> P98-2152 </papid>arabic (magdy and darwish, 2006), <papid> W06-1648 </papid>and thai (meknavin et al, 1998).<papid> P98-2138 </papid></citsent>
<aftsection>
<nextsent>the most common approach is to involve users for their intervention with computer support.taghva and stofsky (2001) designed an interactive system (called ocrspell) that assists users as many interactive features as possible during their correction, such as: choose word boundary, memorize user-corrected words for future correction,provide specific prior knowledge about typical errors.
</nextsent>
<nextsent>for certain applications requiring automation, the interactive scheme may not work.unlike (taghva and stofsky, 2001), non interactive (or fully automatic) approaches have been investigated.
</nextsent>
<nextsent>such approaches need pre specified lexicons &amp; confusion resources (tong and evans, 1996), <papid> W96-0108 </papid>language-specific knowledge(meknavin et al, 1998) <papid> P98-2138 </papid>or manually-created phonetic transformation rules (hodge and austin, 2003) to assist correction process.other approaches used supervised mechanisms for ocr error correction, such as: statistical language models (nagata, 1996; <papid> C96-2136 </papid>zhuang etal., 2004; magdy and darwish, 2006), <papid> W06-1648 </papid>noisy channel model (kolak and resnik, 2002).</nextsent>
<nextsent>these approaches performed well but are limited due to requiring large annotated training data specific to ocr spell checking in languages that are very hard to obtain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2610">
<title id=" W12-0505.xml">an unsupervised and data driven approach for spell checking in vietnamese ocr scanned texts </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, shape or visual similarity forces ocr scanners to misunderstand some characters; or input text documents do not have good quality, causing noises in resulting scanned texts.
</prevsent>
<prevsent>the task of spell checking for ocr-scanned text documents proposed aims to solve the above situation.
</prevsent>
</prevsection>
<citsent citstr=" P98-2152 ">
researchers in the literature used to approach this task for various languages such as: english (tong and evans, 1996; <papid> W96-0108 </papid>taghva and stofsky, 2001; kolak and resnik, 2002), chinese (zhuang et al, 2004), japanese (nagata, 1996; <papid> C96-2136 </papid>nagata, 1998), <papid> P98-2152 </papid>arabic (magdy and darwish, 2006), <papid> W06-1648 </papid>and thai (meknavin et al, 1998).<papid> P98-2138 </papid></citsent>
<aftsection>
<nextsent>the most common approach is to involve users for their intervention with computer support.taghva and stofsky (2001) designed an interactive system (called ocrspell) that assists users as many interactive features as possible during their correction, such as: choose word boundary, memorize user-corrected words for future correction,provide specific prior knowledge about typical errors.
</nextsent>
<nextsent>for certain applications requiring automation, the interactive scheme may not work.unlike (taghva and stofsky, 2001), non interactive (or fully automatic) approaches have been investigated.
</nextsent>
<nextsent>such approaches need pre specified lexicons &amp; confusion resources (tong and evans, 1996), <papid> W96-0108 </papid>language-specific knowledge(meknavin et al, 1998) <papid> P98-2138 </papid>or manually-created phonetic transformation rules (hodge and austin, 2003) to assist correction process.other approaches used supervised mechanisms for ocr error correction, such as: statistical language models (nagata, 1996; <papid> C96-2136 </papid>zhuang etal., 2004; magdy and darwish, 2006), <papid> W06-1648 </papid>noisy channel model (kolak and resnik, 2002).</nextsent>
<nextsent>these approaches performed well but are limited due to requiring large annotated training data specific to ocr spell checking in languages that are very hard to obtain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2611">
<title id=" W12-0505.xml">an unsupervised and data driven approach for spell checking in vietnamese ocr scanned texts </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, shape or visual similarity forces ocr scanners to misunderstand some characters; or input text documents do not have good quality, causing noises in resulting scanned texts.
</prevsent>
<prevsent>the task of spell checking for ocr-scanned text documents proposed aims to solve the above situation.
</prevsent>
</prevsection>
<citsent citstr=" W06-1648 ">
researchers in the literature used to approach this task for various languages such as: english (tong and evans, 1996; <papid> W96-0108 </papid>taghva and stofsky, 2001; kolak and resnik, 2002), chinese (zhuang et al, 2004), japanese (nagata, 1996; <papid> C96-2136 </papid>nagata, 1998), <papid> P98-2152 </papid>arabic (magdy and darwish, 2006), <papid> W06-1648 </papid>and thai (meknavin et al, 1998).<papid> P98-2138 </papid></citsent>
<aftsection>
<nextsent>the most common approach is to involve users for their intervention with computer support.taghva and stofsky (2001) designed an interactive system (called ocrspell) that assists users as many interactive features as possible during their correction, such as: choose word boundary, memorize user-corrected words for future correction,provide specific prior knowledge about typical errors.
</nextsent>
<nextsent>for certain applications requiring automation, the interactive scheme may not work.unlike (taghva and stofsky, 2001), non interactive (or fully automatic) approaches have been investigated.
</nextsent>
<nextsent>such approaches need pre specified lexicons &amp; confusion resources (tong and evans, 1996), <papid> W96-0108 </papid>language-specific knowledge(meknavin et al, 1998) <papid> P98-2138 </papid>or manually-created phonetic transformation rules (hodge and austin, 2003) to assist correction process.other approaches used supervised mechanisms for ocr error correction, such as: statistical language models (nagata, 1996; <papid> C96-2136 </papid>zhuang etal., 2004; magdy and darwish, 2006), <papid> W06-1648 </papid>noisy channel model (kolak and resnik, 2002).</nextsent>
<nextsent>these approaches performed well but are limited due to requiring large annotated training data specific to ocr spell checking in languages that are very hard to obtain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2613">
<title id=" W12-0505.xml">an unsupervised and data driven approach for spell checking in vietnamese ocr scanned texts </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, shape or visual similarity forces ocr scanners to misunderstand some characters; or input text documents do not have good quality, causing noises in resulting scanned texts.
</prevsent>
<prevsent>the task of spell checking for ocr-scanned text documents proposed aims to solve the above situation.
</prevsent>
</prevsection>
<citsent citstr=" P98-2138 ">
researchers in the literature used to approach this task for various languages such as: english (tong and evans, 1996; <papid> W96-0108 </papid>taghva and stofsky, 2001; kolak and resnik, 2002), chinese (zhuang et al, 2004), japanese (nagata, 1996; <papid> C96-2136 </papid>nagata, 1998), <papid> P98-2152 </papid>arabic (magdy and darwish, 2006), <papid> W06-1648 </papid>and thai (meknavin et al, 1998).<papid> P98-2138 </papid></citsent>
<aftsection>
<nextsent>the most common approach is to involve users for their intervention with computer support.taghva and stofsky (2001) designed an interactive system (called ocrspell) that assists users as many interactive features as possible during their correction, such as: choose word boundary, memorize user-corrected words for future correction,provide specific prior knowledge about typical errors.
</nextsent>
<nextsent>for certain applications requiring automation, the interactive scheme may not work.unlike (taghva and stofsky, 2001), non interactive (or fully automatic) approaches have been investigated.
</nextsent>
<nextsent>such approaches need pre specified lexicons &amp; confusion resources (tong and evans, 1996), <papid> W96-0108 </papid>language-specific knowledge(meknavin et al, 1998) <papid> P98-2138 </papid>or manually-created phonetic transformation rules (hodge and austin, 2003) to assist correction process.other approaches used supervised mechanisms for ocr error correction, such as: statistical language models (nagata, 1996; <papid> C96-2136 </papid>zhuang etal., 2004; magdy and darwish, 2006), <papid> W06-1648 </papid>noisy channel model (kolak and resnik, 2002).</nextsent>
<nextsent>these approaches performed well but are limited due to requiring large annotated training data specific to ocr spell checking in languages that are very hard to obtain.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2620">
<title id=" W12-0505.xml">an unsupervised and data driven approach for spell checking in vietnamese ocr scanned texts </title>
<section> proposed approach.  </section>
<citcontext>
<prevsection>
<prevsent>freq(si) is normalized frequency of si over retrieved list of possible candidates.
</prevsent>
<prevsent>is value to control the weight biased to string similarity or frequency.
</prevsent>
</prevsection>
<citsent citstr=" D09-1129 ">
in order to compute the string similarity, we followed combined weighted string similarity (cwss) computation in (islam and inkpen, 2009) <papid> D09-1129 </papid>as follows: sim(si, ? c) = 1 nlcs(si, ? c) +2 nclcs1(si, ? c) + 3 nclcsn(si, ? c) +4 nclcsz(si, ? c) (6) where: ? 1, 2, 3, and 4 are pre-defined weights for each similarity computation.</citsent>
<aftsection>
<nextsent>initially, all ? are set equal to 1/4.
</nextsent>
<nextsent>? nlcs(si, sc) is normalized length of longest common sub sequence between si and sc . ? nclcs1(si, sc), nclcsn(si, ? c), and nclcsz(si, sc) is normalized length of maximal consecutive longest common sub sequence between si and sc starting from the first character, from any character, and from the last character, respectively.
</nextsent>
<nextsent>sim(si, sc) has its value in range of [0, 1].we believe that the cwss method will obtain better performance than standard methods (e.g. levenshtein-based string matching (navarro, 2001) or n-gram based similarity (lin,1998)) because it can exactly capture more information (beginning, body, ending) of incomplete syllables caused by ocr errors.
</nextsent>
<nextsent>as result, this step will produce ranked top-k list of potential candidates for possibly erroneous syllables.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2621">
<title id=" W12-1910.xml">two baselines for unsupervised dependency parsing </title>
<section> rank: simple heuristic baseline.  </section>
<citcontext>
<prevsection>
<prevsent>the graph over the words in the input sentence is constructed by adding directed edges between the word nodes.
</prevsent>
<prevsent>the edges are not weighted, but multiple edges between nodes will make transitions between them more likely.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the edge template was validated on development data from the english penn-iii treebank (marcus et al., 1993) <papid> J93-2004 </papid>and first presented in sgaard (2012): ? short edges.</citsent>
<aftsection>
<nextsent>to favor short dependencies, we add links between all words and their neighbors.
</nextsent>
<nextsent>this makes probability mass flow from central words to their neighboring words.
</nextsent>
<nextsent>function words.
</nextsent>
<nextsent>we use keyword extraction algorithm without stop word lists to extract function or non-content words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2622">
<title id=" W12-1910.xml">two baselines for unsupervised dependency parsing </title>
<section> rank: simple heuristic baseline.  </section>
<citcontext>
<prevsection>
<prevsent>function words.
</prevsent>
<prevsent>we use keyword extraction algorithm without stop word lists to extract function or non-content words.
</prevsent>
</prevsection>
<citsent citstr=" W04-3252 ">
the algorithm is crude simplification of text rank (mihalcea and tarau, 2004) <papid> W04-3252 </papid>that does not relyon linguistic resources, so that we can easily apply it to low-resource languages.</citsent>
<aftsection>
<nextsent>since we do not use stop word lists, highly ranked words will typically be function words.
</nextsent>
<nextsent>for the 50-most highly ranked words, we add additional links from their neighboring words.
</nextsent>
<nextsent>this will add additional probability mass to the function words.
</nextsent>
<nextsent>this is relevant to capture structures such as prepositional phrases where the function words take content words as complements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2623">
<title id=" W12-1910.xml">two baselines for unsupervised dependency parsing </title>
<section> rules: simple rule-based baseline.  </section>
<citcontext>
<prevsection>
<prevsent>in case of ties, we select the head with the highest pagerank.
</prevsent>
<prevsent>our second baseline is even simpler than our fir stone, but makes use of input part of speech.
</prevsent>
</prevsection>
<citsent citstr=" D10-1120 ">
in particular it builds on the idea that unsupervised parsing can be informed by universal dependency rules(naseem et al, 2010).<papid> D10-1120 </papid></citsent>
<aftsection>
<nextsent>we reformulate the universal dependency rules used in naseem et al (2010) <papid> D10-1120 </papid>in terms of the universal tags provided in the shared task (figure 2), but unlike them, we do not engage in grammar induction.</nextsent>
<nextsent>instead we simply present astraight-forward heuristic application of the universal dependency rules: rules finds the head of each word by finding the nearest word w?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2626">
<title id=" W12-1910.xml">two baselines for unsupervised dependency parsing </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>punctuation).
</prevsent>
<prevsent>surprisingly, rules turns out to be very competitive baseline.
</prevsent>
</prevsection>
<citsent citstr=" P11-1067 ">
shared task results were evaluated by the organizers in terms of directed accuracy (da), also known as unlabeled attachment score, undirected accuracy (ua) and ned (schwartz et al, 2011), <papid> P11-1067 </papid>both for short and full length sentences.</citsent>
<aftsection>
<nextsent>we will focus on da for full length sentences here, arguable the most widely accepted metric.
</nextsent>
<nextsent>table 1 presents results forall 10 datasets, with dmv based on fine-grained native pos (which performs best on average compared to dmv-cpos and dmv-upos),1 and tu, standard as the winning system (win?).
</nextsent>
<nextsent>the best?
</nextsent>
<nextsent>result cherry-picks the best system for each dataset.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2627">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, haitian creole is low resource language, for which there are few language technology tools and corpora available.our main focus has been to make the best possible use of the available training data through different ways of cleaning the data, and by replacing unknown words in the test data by plausible spellingequivalents.
</prevsent>
<prevsent>we have also investigated effects of different ways to combine the available data in translation and language models.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we performed all our experiments using standard phrase-based statistical machine translation (pbsmt) system, trained using the moses toolkit (koehn et al, 2007), <papid> P07-2045 </papid>with srilm (stolcke, 2002)and kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modeling, and giza++ (och and ney, 2003) <papid> J03-1002 </papid>for word alignment.</citsent>
<aftsection>
<nextsent>we also used lexicalized reordering model (koehn et al, 2005).
</nextsent>
<nextsent>we optimized each system separately using minimum error rate training (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>the development and devtest data were available in two versions, as raw, noisy data, and in clean version, where the raw data had been cleaned by human post-editors.the different sub corpora had different tokenizations and casing conventions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2628">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, haitian creole is low resource language, for which there are few language technology tools and corpora available.our main focus has been to make the best possible use of the available training data through different ways of cleaning the data, and by replacing unknown words in the test data by plausible spellingequivalents.
</prevsent>
<prevsent>we have also investigated effects of different ways to combine the available data in translation and language models.
</prevsent>
</prevsection>
<citsent citstr=" W11-2123 ">
we performed all our experiments using standard phrase-based statistical machine translation (pbsmt) system, trained using the moses toolkit (koehn et al, 2007), <papid> P07-2045 </papid>with srilm (stolcke, 2002)and kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modeling, and giza++ (och and ney, 2003) <papid> J03-1002 </papid>for word alignment.</citsent>
<aftsection>
<nextsent>we also used lexicalized reordering model (koehn et al, 2005).
</nextsent>
<nextsent>we optimized each system separately using minimum error rate training (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>the development and devtest data were available in two versions, as raw, noisy data, and in clean version, where the raw data had been cleaned by human post-editors.the different sub corpora had different tokenizations and casing conventions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2629">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, haitian creole is low resource language, for which there are few language technology tools and corpora available.our main focus has been to make the best possible use of the available training data through different ways of cleaning the data, and by replacing unknown words in the test data by plausible spellingequivalents.
</prevsent>
<prevsent>we have also investigated effects of different ways to combine the available data in translation and language models.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we performed all our experiments using standard phrase-based statistical machine translation (pbsmt) system, trained using the moses toolkit (koehn et al, 2007), <papid> P07-2045 </papid>with srilm (stolcke, 2002)and kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modeling, and giza++ (och and ney, 2003) <papid> J03-1002 </papid>for word alignment.</citsent>
<aftsection>
<nextsent>we also used lexicalized reordering model (koehn et al, 2005).
</nextsent>
<nextsent>we optimized each system separately using minimum error rate training (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>the development and devtest data were available in two versions, as raw, noisy data, and in clean version, where the raw data had been cleaned by human post-editors.the different sub corpora had different tokenizations and casing conventions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2630">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>we performed all our experiments using standard phrase-based statistical machine translation (pbsmt) system, trained using the moses toolkit (koehn et al, 2007), <papid> P07-2045 </papid>with srilm (stolcke, 2002)and kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modeling, and giza++ (och and ney, 2003) <papid> J03-1002 </papid>for word alignment.</prevsent>
<prevsent>we also used lexicalized reordering model (koehn et al, 2005).</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we optimized each system separately using minimum error rate training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>the development and devtest data were available in two versions, as raw, noisy data, and in clean version, where the raw data had been cleaned by human post-editors.the different sub corpora had different tokenizations and casing conventions.
</nextsent>
<nextsent>we normalized punctuation by applying tokenizer that separated most punctuation marks into separate tokens, excludingapostrophes that were suspected to belong to contracted words or haitian short forms, periods for abbreviations, and periods in urls.
</nextsent>
<nextsent>there were often many consecutive punctuation marks; these were replaced by only the first of the punctuation marks.
</nextsent>
<nextsent>in the english translations of the sms data there were often translators notes at the end of the translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2631">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>case information was inconsistent, especially for sms data, and for this reason we lower-cased all haitian source data.
</prevsent>
<prevsent>on the english target side we wanted to use true-cased data, since we wanted case distinctions in the translation output.
</prevsent>
</prevsection>
<citsent citstr=" W09-0429 ">
we based the true-casing on koehn and haddow (2009), <papid> W09-0429 </papid>who changed the case of the first word in each sentence, to the most common case variant of that word in the corpus when it is not sentence initial.</citsent>
<aftsection>
<nextsent>in the noisy sms data, though, there were many sentences with all capital letters that would influence this true casing method negatively.
</nextsent>
<nextsent>to address this, we modified the algorithm to exclude sentences with more than 40% capital letters when calculating corpus statistics, and to lowercase all unknown capitalized words.
</nextsent>
<nextsent>470 data sentences words tm lm reo tc in-domain sms data 17,192 35k sms sms yes yes medical domain 1,619 10k other other ? ?
</nextsent>
<nextsent>newswire domain 13,517 30k other other ? yes glossary 35,728 85k other other ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2632">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>all corpora are bilingual english haitian creole.
</prevsent>
<prevsent>all translation results are reported for the devtest corpus, on true cased data.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we report results on three metrics, bleu (papineni et al, 2002), <papid> P02-1040 </papid>nist(doddington, 2002), and meteor optimized on flu ency/adequacy (lavie and agarwal, 2007).<papid> W07-0734 </papid></citsent>
<aftsection>
<nextsent>the corpora available for the task was small bilingual in-domain corpus of smt data, limited amount of bilingual out-of-domain corpora, such as dictionaries and the bible.
</nextsent>
<nextsent>this is different to the common situation of domain adaptation, as in the standard wmt shared tasks, where there is small bilingual in-domain corpus, larger in-domainmonolingual corpus, and possibly several out-of domain corpora that can be both monolingual and bilingual.
</nextsent>
<nextsent>in such scenario it is often useful to use all available training data for both translation and language models, possibly in separate models (koehn and schroeder, 2007).<papid> W07-0733 </papid></nextsent>
<nextsent>table 1 summarizes how we used the available corpora, in our different models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2633">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>all corpora are bilingual english haitian creole.
</prevsent>
<prevsent>all translation results are reported for the devtest corpus, on true cased data.
</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
we report results on three metrics, bleu (papineni et al, 2002), <papid> P02-1040 </papid>nist(doddington, 2002), and meteor optimized on flu ency/adequacy (lavie and agarwal, 2007).<papid> W07-0734 </papid></citsent>
<aftsection>
<nextsent>the corpora available for the task was small bilingual in-domain corpus of smt data, limited amount of bilingual out-of-domain corpora, such as dictionaries and the bible.
</nextsent>
<nextsent>this is different to the common situation of domain adaptation, as in the standard wmt shared tasks, where there is small bilingual in-domain corpus, larger in-domainmonolingual corpus, and possibly several out-of domain corpora that can be both monolingual and bilingual.
</nextsent>
<nextsent>in such scenario it is often useful to use all available training data for both translation and language models, possibly in separate models (koehn and schroeder, 2007).<papid> W07-0733 </papid></nextsent>
<nextsent>table 1 summarizes how we used the available corpora, in our different models.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2634">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> corpus usage.  </section>
<citcontext>
<prevsection>
<prevsent>the corpora available for the task was small bilingual in-domain corpus of smt data, limited amount of bilingual out-of-domain corpora, such as dictionaries and the bible.
</prevsent>
<prevsent>this is different to the common situation of domain adaptation, as in the standard wmt shared tasks, where there is small bilingual in-domain corpus, larger in-domainmonolingual corpus, and possibly several out-of domain corpora that can be both monolingual and bilingual.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
in such scenario it is often useful to use all available training data for both translation and language models, possibly in separate models (koehn and schroeder, 2007).<papid> W07-0733 </papid></citsent>
<aftsection>
<nextsent>table 1 summarizes how we used the available corpora, in our different models.
</nextsent>
<nextsent>for translation and language models we separated the bilingual data into three parts, the sms data, the bible, and every thing else.
</nextsent>
<nextsent>for our lexicalized reordering model we only used sms data, since we believe word order there is likely to differ from the other corpora.
</nextsent>
<nextsent>for the english true-casing model we concatenated the english side of all bilingual corpora that were not lower-cased.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2635">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> spell checking-based replacement of.  </section>
<citcontext>
<prevsection>
<prevsent>the non-standardized spelling means that many unknown words (out-of-vocabulary words,oovs) have known spelling variant in the training corpus.
</prevsent>
<prevsent>we thus decided to treat oovs using method inspired by spell-checking techniques, and applied an approximate string matching technique to oovs in the translation input in order to change them into known spelling variants.
</prevsent>
</prevsection>
<citsent citstr=" P09-1089 ">
oov replacement has been proposed by several researchers, replacing oovs e.g. by morphological variants (arora et al, 2008) or synonyms (mirkin et al., 2009).<papid> P09-1089 </papid></citsent>
<aftsection>
<nextsent>habash (2008) <papid> P08-2015 </papid>used several techniques for expanding oovs in order to extend the phrasetable.</nextsent>
<nextsent>yang and kirchhoff (2006) <papid> E06-1006 </papid>trained morphologically based back-off model for oovs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2636">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> spell checking-based replacement of.  </section>
<citcontext>
<prevsection>
<prevsent>we thus decided to treat oovs using method inspired by spell-checking techniques, and applied an approximate string matching technique to oovs in the translation input in order to change them into known spelling variants.
</prevsent>
<prevsent>oov replacement has been proposed by several researchers, replacing oovs e.g. by morphological variants (arora et al, 2008) or synonyms (mirkin et al., 2009).<papid> P09-1089 </papid></prevsent>
</prevsection>
<citsent citstr=" P08-2015 ">
habash (2008) <papid> P08-2015 </papid>used several techniques for expanding oovs in order to extend the phrasetable.</citsent>
<aftsection>
<nextsent>yang and kirchhoff (2006) <papid> E06-1006 </papid>trained morphologically based back-off model for oovs.</nextsent>
<nextsent>bertoldi et al (2010) <papid> N10-1064 </papid>created confusion networks as input of translation input with artificially created misspelled words, not specifically targetting oovs, however.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2637">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> spell checking-based replacement of.  </section>
<citcontext>
<prevsection>
<prevsent>oov replacement has been proposed by several researchers, replacing oovs e.g. by morphological variants (arora et al, 2008) or synonyms (mirkin et al., 2009).<papid> P09-1089 </papid></prevsent>
<prevsent>habash (2008) <papid> P08-2015 </papid>used several techniques for expanding oovs in order to extend the phrasetable.</prevsent>
</prevsection>
<citsent citstr=" E06-1006 ">
yang and kirchhoff (2006) <papid> E06-1006 </papid>trained morphologically based back-off model for oovs.</citsent>
<aftsection>
<nextsent>bertoldi et al (2010) <papid> N10-1064 </papid>created confusion networks as input of translation input with artificially created misspelled words, not specifically targetting oovs, however.</nextsent>
<nextsent>the work most similar to ours is deneefe et al(2008), who also created lattices with spelling alternatives for oovs, which did not improve translation results, however.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2638">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> spell checking-based replacement of.  </section>
<citcontext>
<prevsection>
<prevsent>habash (2008) <papid> P08-2015 </papid>used several techniques for expanding oovs in order to extend the phrasetable.</prevsent>
<prevsent>yang and kirchhoff (2006) <papid> E06-1006 </papid>trained morphologically based back-off model for oovs.</prevsent>
</prevsection>
<citsent citstr=" N10-1064 ">
bertoldi et al (2010) <papid> N10-1064 </papid>created confusion networks as input of translation input with artificially created misspelled words, not specifically targetting oovs, however.</citsent>
<aftsection>
<nextsent>the work most similar to ours is deneefe et al(2008), who also created lattices with spelling alternatives for oovs, which did not improve translation results, however.
</nextsent>
<nextsent>contrary to us, they only considered one edit per word, and did not weigh edits or lattice arcs.
</nextsent>
<nextsent>many standard spell checkers are based on the noisy channel model, which use an error (channel)model and source model, which is normally mod 472 eled by language model.
</nextsent>
<nextsent>the error model normally use some type of approximate string matching, such as levenshtein distance (levenshtein, 1966), which measures the distance between two strings as the number of insertions, deletions, and substitutions of characters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2639">
<title id=" W11-2159.xml">spell checking techniques for replacement of unknown words and data cleaning for haitian creole sms translation </title>
<section> spell checking-based replacement of.  </section>
<citcontext>
<prevsection>
<prevsent>it is often normalized based on the length of the strings (yujian and bo, 2007), and the distance calculation has also been improved by associating different costs to individual error operations.
</prevsent>
<prevsent>church and gale (1991) used large training corpus to assign probabilities to each unique error operation, and also conditioned operations on one consecutive character.
</prevsent>
</prevsection>
<citsent citstr=" P00-1037 ">
brill and moore (2000) <papid> P00-1037 </papid>introduced model that worked on character sequences, not only on character level, and was conditioned on where in the word the sequences occurred.</citsent>
<aftsection>
<nextsent>they trained weights on corpus of misspelled words with corrections.
</nextsent>
<nextsent>treating oovs in the sms corpus as spell checking problem differs from standard spell checking scenario in that the goal is not necessarily to change an incorrectly spelled word into correct word, but rather to change word that is not in our corpus into spelling variant that we have seen in the corpus, but which might not necessarily be correctly spelled.
</nextsent>
<nextsent>it is also the case that many of the oovs are not wrong, but just happen to be unseen; for instance there are many place names.
</nextsent>
<nextsent>thus we must make sure that our algorithm for finding spelling equivalents is bi-directional, so that it cannot only change incorrect spellings into correct spellings, but also go the other way, which could be needed in some cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2642">
<title id=" W12-1012.xml">computing similarity between cultural heritage items using multimodal features </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>it seems likely that information from all of these types would help humans to identify similar items and that it could help to identify them automatically.
</prevsent>
<prevsent>however, previous work on computing similarity in the ch domain has been limited and, in particular, has not made use of information from multiple types of media.for example, grieser et al  (2011) computed similarity between exhibits in melbourne museum by applying range of text similarity measures but did not make use of other media.
</prevsent>
</prevsection>
<citsent citstr=" N10-1125 ">
techniques for exploiting information from multimedia collections have been developed and are commonly applied to wide range of problems such as content-based image retrieval (datta etal., 2008) and image annotation (feng and lap ata, 2010).<papid> N10-1125 </papid></citsent>
<aftsection>
<nextsent>85 this paper makes use of information from two media (text and images) to compute the similarity between items in large collection of chitems (europeana).
</nextsent>
<nextsent>a range of similarity measures for text and images are compared and combined.
</nextsent>
<nextsent>evaluation is carried out using set of items from europe ana with similarity judgements that were obtained in crowdsourcing experiment.
</nextsent>
<nextsent>we find that combining information from both media produces better results than when either is used alone.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2643">
<title id=" W12-1012.xml">computing similarity between cultural heritage items using multimodal features </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the integration of information from text and im age features has been explored in several fields.
</prevsent>
<prevsent>in content-based image retrieval image features are combined together with words from caption sto retrieve images relevant to query (la cas cia et al , 1998; srihari et al , 2000; barnard and forsyth, 2001; wester veld, 2002; zhou and huang, 2002; wang et al , 2004).
</prevsent>
</prevsection>
<citsent citstr=" P06-2071 ">
image clustering methods have been developed to combine information from images and text to create clusters of similar images (loeff et al , 2006; <papid> P06-2071 </papid>bekkerman and jeon, 2007).</citsent>
<aftsection>
<nextsent>techniques for automatic image annotation that generate models as mixture of word and image features have also been described (jeon et al , 2003; blei and jordan, 2003; feng and lapata, 2010).<papid> N10-1125 </papid></nextsent>
<nextsent>2.4 similarity in cultural heritage.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2645">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> discourse connectives in translation.  </section>
<citcontext>
<prevsection>
<prevsent>the paper concludes with comparison to related work (sec tion 7) and an outline of future work (section 8).
</prevsent>
<prevsent>discourse connectives such as although, however, since or while form functional category of lexical items that are frequently used to mark coherence or discourse relations such as explanation, synch rony or contrast between units of text or discourse.
</prevsent>
</prevsection>
<citsent citstr=" W11-1211 ">
for example, in the europarl corpus from years 199x (koehn, 2005), the following nine lexical items, which are often (though not always) discourse connectives, are among the 400 most frequent tokens over total of 12,846,003 (in parentheses, rank and number of occurrences): after (244th/6485), although (375th/4062), however (110th/12,857), indeed (334th/4486), rather (316th/4688), 129 since (190th/8263), still (168th/9195), while(390th/3938), yet (331st/4532) ? see also (car toni et al, 2011).<papid> W11-1211 </papid></citsent>
<aftsection>
<nextsent>discourse connectives can be difficult to translate, because many of them can signal different relations between clauses indifferent contexts.
</nextsent>
<nextsent>moreover, if wrong connective is used in translation, then text becomes incoherent, as in the two examples below, taken from europarl and translated (en/fr) with moses (koehn et al, 2007) <papid> P07-2045 </papid>trained on the entire corpus: 1.</nextsent>
<nextsent>en: this tax, though [contrast], does not come.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2646">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> discourse connectives in translation.  </section>
<citcontext>
<prevsection>
<prevsent>for example, in the europarl corpus from years 199x (koehn, 2005), the following nine lexical items, which are often (though not always) discourse connectives, are among the 400 most frequent tokens over total of 12,846,003 (in parentheses, rank and number of occurrences): after (244th/6485), although (375th/4062), however (110th/12,857), indeed (334th/4486), rather (316th/4688), 129 since (190th/8263), still (168th/9195), while(390th/3938), yet (331st/4532) ? see also (car toni et al, 2011).<papid> W11-1211 </papid></prevsent>
<prevsent>discourse connectives can be difficult to translate, because many of them can signal different relations between clauses indifferent contexts.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
moreover, if wrong connective is used in translation, then text becomes incoherent, as in the two examples below, taken from europarl and translated (en/fr) with moses (koehn et al, 2007) <papid> P07-2045 </papid>trained on the entire corpus: 1.</citsent>
<aftsection>
<nextsent>en: this tax, though [contrast], does not come.
</nextsent>
<nextsent>without its problems.
</nextsent>
<nextsent>fr-smt: *cette taxe, meme si [concession], ne se pres ente pas sans ses proble`mes.
</nextsent>
<nextsent>2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2648">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> data used in our experiments.  </section>
<citcontext>
<prevsection>
<prevsent>this section shows how we made use of these resources and how we augmented them by manual and automated annotation of the senses of discourse connectives.
</prevsent>
<prevsent>3.1 data for the disambiguation of.
</prevsent>
</prevsection>
<citsent citstr=" L08-1093 ">
discourse connectives one of the most important resources for discourse connectives in english is the penn discourse treebank (prasad et al, 2008).<papid> L08-1093 </papid></citsent>
<aftsection>
<nextsent>the pdtb provides discourse-layer annotation over the wall street journal corpus (wsj) and the penn treebank syntactic annotation.
</nextsent>
<nextsent>the discourse annotation consists of manually annotated senses for about 100 types of explicit connectives, for implicit ones, and their clause spans.
</nextsent>
<nextsent>for the entire wsj corpus of about 1,000,000 tokens there are 18,459 instances of annotated explicit connectives.
</nextsent>
<nextsent>the senses that discourse connectives can signal are organized in hierarchy with 4 top level senses, followed by 16 sub types on the second level and 23 detailed sub senses on the third level.studies making use of the pdtb to build classifiers usually split the wsj corpus into sections 0221 for training and section 23 for testing (as we did for our disambiguation experiments, see section 4).from the pdtb, we extracted the 13 most frequent and most ambiguous connectives: after, although, however, indeed, meanwhile, nevertheless, nonetheless, rather, since, still, then, while,and yet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2650">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> data used in our experiments.  </section>
<citcontext>
<prevsection>
<prevsent>c: integration of automated annotation: europarl?
</prevsent>
<prevsent>years 199x (58,673 sentences), all occurrences of the 13 pdtb subset connective types have been labeled by classifiers (in 6,961 sentences).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
for minimum error rate tuning (mert) (och, 2003) <papid> P03-1021 </papid>of the smt systems, we used the 2009 1statmt.org/wmt10/translation-task.html news commentary (nc) en/fr development set with the following modifications: d: phrase table: nc 2009 (2,051 sentences), no modifications.e: manual annotation: nc 2009 (2,051 sen tences), minus all 123 sentences containing one of the above 5 connective types, plus 102sentences with manually sense-labeled con nectives.f: automated annotation: nc 2009 (2,051 sentences), all occurrences of the 13 pdtb subset connective types have been labeled by classifiers (in 340 sentences).</citsent>
<aftsection>
<nextsent>for testing our modified smt systems, three test sets were extracted in the following way:g: 35 sentences from nc 2007, with 7 occurrences for each of the 5 connective types above, manually labeled.h: 62 sentences from nc 2007 and 2006 with occurrences for the 13 pdtb connective types, automatically labeled with classifiers.
</nextsent>
<nextsent>i: 10,311 sentences from the en/fr un corpus,all occurrences of the five europarl connective types, automatically labeled with classifiers.
</nextsent>
<nextsent>these test sets might appear small compared to the amount of data normally used for smt system testing.
</nextsent>
<nextsent>in our system evaluation however, apart from automated scoring, we also had to perform manual counts of improved translations, which is why we could not evaluate more than hundred sentences (section 5).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2653">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> automatically disambiguating.  </section>
<citcontext>
<prevsection>
<prevsent>the sense labels are coded as follows.
</prevsent>
<prevsent>al: alternative, as: asynchronous, ca: cause, cd: condition, cj: conjunction, cp: comparison, cs: concession, ct: contrast, e: expansion, i: instantiation, r: restatement, s: synchrony.
</prevsent>
</prevsection>
<citsent citstr=" N03-5008 ">
in some cases marked with ?*?, the test sets are too small to provide meaningful scores.specialized classifier, by using the stanford maximum entropy classifier package (manning and klein, 2003).<papid> N03-5008 </papid></citsent>
<aftsection>
<nextsent>maximum entropy is known to handle discrete features well and has been applied successfully to connective disambiguation before (see section 7).an initial set of features can directly be obtained from the pdtb (and must hence be considered as oracle features): the (capitalized) connective token, its pos tag, first word of clause 1, last word of clause 1, first word of clause 2 (the one containing the explicit connective), last word of clause 2, pos tag of the first word of clause 2, type of first word of clause 2, parent syntactical categories of the connective, punctuation pattern of the sentences.
</nextsent>
<nextsent>apart from these standard features in discourse connective disambiguation we used wordnet (miller, 1995) to compute lexical similarity scores with the lesk metric (banerjee and pedersen, 2002) for all the possible combinations of nouns, verbs and adjectives in the two clauses, as well as antonyms found for these word groups.
</nextsent>
<nextsent>in addition, we used features that are likely to help detecting temporal relations and were obtained from the tarsqi toolkit (verhagen and pustejovsky, 2008), <papid> C08-3012 </papid>which annotates english sentences automatically with the timeml annotation language for temporal expressions.</nextsent>
<nextsent>forex ample, in the sentence the crimes may appear small, but the prices can be huge (pdtb section 2, wsj file 0290), for example, our features would indicate the antonyms small vs. huge that signal the contrast, along with temporal ordering of the event appear before the event can.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2654">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> automatically disambiguating.  </section>
<citcontext>
<prevsection>
<prevsent>maximum entropy is known to handle discrete features well and has been applied successfully to connective disambiguation before (see section 7).an initial set of features can directly be obtained from the pdtb (and must hence be considered as oracle features): the (capitalized) connective token, its pos tag, first word of clause 1, last word of clause 1, first word of clause 2 (the one containing the explicit connective), last word of clause 2, pos tag of the first word of clause 2, type of first word of clause 2, parent syntactical categories of the connective, punctuation pattern of the sentences.
</prevsent>
<prevsent>apart from these standard features in discourse connective disambiguation we used wordnet (miller, 1995) to compute lexical similarity scores with the lesk metric (banerjee and pedersen, 2002) for all the possible combinations of nouns, verbs and adjectives in the two clauses, as well as antonyms found for these word groups.
</prevsent>
</prevsection>
<citsent citstr=" C08-3012 ">
in addition, we used features that are likely to help detecting temporal relations and were obtained from the tarsqi toolkit (verhagen and pustejovsky, 2008), <papid> C08-3012 </papid>which annotates english sentences automatically with the timeml annotation language for temporal expressions.</citsent>
<aftsection>
<nextsent>forex ample, in the sentence the crimes may appear small, but the prices can be huge (pdtb section 2, wsj file 0290), for example, our features would indicate the antonyms small vs. huge that signal the contrast, along with temporal ordering of the event appear before the event can.
</nextsent>
<nextsent>we report the classifier performances as f1 scores for each connective (weighting precision and recall equally) in table 1, testing on section23 of the pdtb.
</nextsent>
<nextsent>this sense classifier will be referred to as classifier pt in the rest of the paper, in particular when used for the smt experiments.
</nextsent>
<nextsent>4.2 classifier pt+: with candidate.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2655">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> automatically disambiguating.  </section>
<citcontext>
<prevsection>
<prevsent>the sense labels are coded as follows.
</prevsent>
<prevsent>cs: concession, ct: contrast, s: synch rony, ca: cause.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
glish source with target french) by using giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>in this alignment, we searched for the translation equivalents of the 13pdtb connectives by using hand-crafted dictionary of possible french translations.
</nextsent>
<nextsent>when the translation candidate is not ambiguous ? e.g. bienque as translation for while clearly signals concession ? its specific sense label was added as the value of an additional feature.
</nextsent>
<nextsent>in some cases,however, the values of the features are not determined (and are set to none): either when the smt system or giza++ failed in translating or aligning connective, or when the target connective was just as ambiguous as the source one (e.g.while translated as tandis que, which can be labeled both temporal or contrast).
</nextsent>
<nextsent>overall, this procedure led to an accuracy gain of classifier pt+ with respect to classifier pt of about 0.1 to 0.6 f1 score for some of the connectives, as can be seen in the last column of table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2656">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> automatically disambiguating.  </section>
<citcontext>
<prevsection>
<prevsent>for the europarl data sets,we built new maxent classifier (called classifier eu) using the same feature set as classifier pt.
</prevsent>
<prevsent>however, all features were this time extracted automatically (no oracle).
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
in particular, we used charniak and johnsons (2005) <papid> P05-1022 </papid>parser to then extract the syntactic features.</citsent>
<aftsection>
<nextsent>in table 2, we report the results of classifier eu, again in terms of f1 scores.
</nextsent>
<nextsent>for all three classifiers, pt, pt+ and eu, the f1 scores are in range of 0.6 and0.8, thus comparing favorably to the state-of-the art for discourse connective disambiguation with detailed senses (section 7).
</nextsent>
<nextsent>classifier eu also compares favorably to pt and pt+, as seen for instance for since (0.80 vs. 0.78) or although (0.67 vs. 0.600.66).
</nextsent>
<nextsent>in this section, we report on experiments that study the effect of discourse connective labeling on smt.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2657">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> use of labeled connectives for smt.  </section>
<citcontext>
<prevsection>
<prevsent>the experiments differ with respect tothe method used for taking advantage of the labels, but also with respect to the datasets and the sense classifiers that are used.
</prevsent>
<prevsent>5.1 evaluation metrics for mt. the variation in mt quality can be estimated in several ways.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
on the one hand, we use the bleu metric (papineni et al, 2002) <papid> P02-1040 </papid>with one reference translation as is most often done in current smt research2.</citsent>
<aftsection>
<nextsent>to improve confidence in the bleu scores, especially when test sets are small, we also compute bleu scores using bootstrapping of datasets (zhang and vogel, 2010); the test sets are re-sampled thousand times and the average bleu score is computed from individual sample scores.
</nextsent>
<nextsent>the bleu approach is not likely,however, to be sensitive enough to the small differences due to the correction of discourse connectives (less than one word per sentence).
</nextsent>
<nextsent>we therefore additionally resort to manual evaluation metric, referred to as connectives, which counts the occurrences of connectives that are better translated by our modified systems compared to the baseline ones.
</nextsent>
<nextsent>2the scores are generated by the nist mteval script version 11b, available from www.itl.nist.gov/iad/ mig/tools/.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2658">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for the disambiguation of explicit connectives, the state-of-theart performance for labeling all types of connectives in english is quite high.
</prevsent>
<prevsent>in the pdtb data, the disambiguation of discourse vs. non-discourse uses of connectives reaches 97% accuracy (lin et al., 2010).
</prevsent>
</prevsection>
<citsent citstr=" P09-2004 ">
the labeling of the four main senses from the pdtb sense hierarchy (temporal, contingency, comparison, expansion) reaches 94% accuracy (pitler and nenkova, 2009) ? <papid> P09-2004 </papid>however, the baseline accuracy is already around 85% when using only the connective token as feature.</citsent>
<aftsection>
<nextsent>various methods for classification and feature analysis have been proposed (wellner et al, 2006; <papid> W06-1317 </papid>elwell and baldridge, 2008).</nextsent>
<nextsent>other studies have focused on the analysis of highly ambiguous discourse connectives only.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2659">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the pdtb data, the disambiguation of discourse vs. non-discourse uses of connectives reaches 97% accuracy (lin et al., 2010).
</prevsent>
<prevsent>the labeling of the four main senses from the pdtb sense hierarchy (temporal, contingency, comparison, expansion) reaches 94% accuracy (pitler and nenkova, 2009) ? <papid> P09-2004 </papid>however, the baseline accuracy is already around 85% when using only the connective token as feature.</prevsent>
</prevsection>
<citsent citstr=" W06-1317 ">
various methods for classification and feature analysis have been proposed (wellner et al, 2006; <papid> W06-1317 </papid>elwell and baldridge, 2008).</citsent>
<aftsection>
<nextsent>other studies have focused on the analysis of highly ambiguous discourse connectives only.
</nextsent>
<nextsent>miltsakaki et al (2005) report classification results for the connectives since, while and when.
</nextsent>
<nextsent>using maximum entropy classifier, they reach 75.5% accuracy for since, 71.8% for while and 61.6% for when.
</nextsent>
<nextsent>as the pdtb was not completed at that time, the datasets and labels are not exactly identical to the ones that we used above (see section 4).the disambiguation of senses signaled by discourse connectives can be seen as word sense disambiguation (wsd) problem for functional words (as opposed to wsd for content words,which is more frequently studied).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2660">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>using maximum entropy classifier, they reach 75.5% accuracy for since, 71.8% for while and 61.6% for when.
</prevsent>
<prevsent>as the pdtb was not completed at that time, the datasets and labels are not exactly identical to the ones that we used above (see section 4).the disambiguation of senses signaled by discourse connectives can be seen as word sense disambiguation (wsd) problem for functional words (as opposed to wsd for content words,which is more frequently studied).
</prevsent>
</prevsection>
<citsent citstr=" D07-1007 ">
the integration of wsd into smt has especially been studied by carpuat and wu (2007), <papid> D07-1007 </papid>who used the translation candidates output by baseline smt system as word sense labels.</citsent>
<aftsection>
<nextsent>this is similar to our use of translation candidates as an additional feature for classification in section 4.2.
</nextsent>
<nextsent>then,the output of several classifiers based on linguistic features was weighed against the translation candidates output by the baseline smt system.with this procedure, their wsd+smt system improved the bleu scores by 0.40.5 for the en glish/chinese pair.chang et al (2009) <papid> W09-0436 </papid>use loglinear classifier with linguistic features in order to disambiguate the chinese particle de?</nextsent>
<nextsent>that has five different context-dependent uses (modifier, preposition, relative clause etc.).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2661">
<title id=" W12-0117.xml">using sense labeled discourse connectives for statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the integration of wsd into smt has especially been studied by carpuat and wu (2007), <papid> D07-1007 </papid>who used the translation candidates output by baseline smt system as word sense labels.</prevsent>
<prevsent>this is similar to our use of translation candidates as an additional feature for classification in section 4.2.</prevsent>
</prevsection>
<citsent citstr=" W09-0436 ">
then,the output of several classifiers based on linguistic features was weighed against the translation candidates output by the baseline smt system.with this procedure, their wsd+smt system improved the bleu scores by 0.40.5 for the en glish/chinese pair.chang et al (2009) <papid> W09-0436 </papid>use loglinear classifier with linguistic features in order to disambiguate the chinese particle de?</citsent>
<aftsection>
<nextsent>that has five different context-dependent uses (modifier, preposition, relative clause etc.).
</nextsent>
<nextsent>when the classifier is used to annotate the particle prior to smt, the output of the translation system improves by up to 1.49 bleu score for phrase-based chinese to english translation.
</nextsent>
<nextsent>ma et al (2011) use maximum entropy model to pos tag english collocational particles (e.g. come down/by, turn against,inform of ) more specifically than usual pos tagger does (where only one label is given to all par ticles).
</nextsent>
<nextsent>the authors claim the usefulness of such particle tagger for english/chinese translation, but do not show its actual integration into an mt system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2662">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the unsupervised parallel data is created by automatically translating monolingual source language corpora.
</prevsent>
<prevsent>this approach is called lightly-supervised training in the literature and has been introduced by schwenk (2008).
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
in contrast to schwenk, we do not apply lightly-supervised training to conventional phrase-based system (och et al, 1999; <papid> W99-0604 </papid>koehn et al, 2003) <papid> N03-1017 </papid>but to hierarchical phrase-based translation (hpbt) system.</citsent>
<aftsection>
<nextsent>in hierarchical phrase-based translation (chiang,2005) <papid> P05-1033 </papid>weighted synchronous context-free grammar is induced from parallel text, the search is based on cyk+ parsing (chappelier and rajman,1998) and typically carried out using the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></nextsent>
<nextsent>in addition to the contiguous lexical phrases as in standardphrase-based translation, the hierarchical phrase based paradigm also allows for phrases with gaps which are called hierarchical phrases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2663">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the unsupervised parallel data is created by automatically translating monolingual source language corpora.
</prevsent>
<prevsent>this approach is called lightly-supervised training in the literature and has been introduced by schwenk (2008).
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
in contrast to schwenk, we do not apply lightly-supervised training to conventional phrase-based system (och et al, 1999; <papid> W99-0604 </papid>koehn et al, 2003) <papid> N03-1017 </papid>but to hierarchical phrase-based translation (hpbt) system.</citsent>
<aftsection>
<nextsent>in hierarchical phrase-based translation (chiang,2005) <papid> P05-1033 </papid>weighted synchronous context-free grammar is induced from parallel text, the search is based on cyk+ parsing (chappelier and rajman,1998) and typically carried out using the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></nextsent>
<nextsent>in addition to the contiguous lexical phrases as in standardphrase-based translation, the hierarchical phrase based paradigm also allows for phrases with gaps which are called hierarchical phrases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2664">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach is called lightly-supervised training in the literature and has been introduced by schwenk (2008).
</prevsent>
<prevsent>in contrast to schwenk, we do not apply lightly-supervised training to conventional phrase-based system (och et al, 1999; <papid> W99-0604 </papid>koehn et al, 2003) <papid> N03-1017 </papid>but to hierarchical phrase-based translation (hpbt) system.</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
in hierarchical phrase-based translation (chiang,2005) <papid> P05-1033 </papid>weighted synchronous context-free grammar is induced from parallel text, the search is based on cyk+ parsing (chappelier and rajman,1998) and typically carried out using the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></citsent>
<aftsection>
<nextsent>in addition to the contiguous lexical phrases as in standardphrase-based translation, the hierarchical phrase based paradigm also allows for phrases with gaps which are called hierarchical phrases.
</nextsent>
<nextsent>a generic non-terminal symbol serves as place holder that marks the gaps.
</nextsent>
<nextsent>in this paper we study several different ways of incorporating unsupervised training data into hierarchical system.
</nextsent>
<nextsent>the basic techniques we employ are the use of multiple translation models and distinction of the hierarchical and thenon-hierarchical (i.e. lexical) part of the translation model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2665">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this approach is called lightly-supervised training in the literature and has been introduced by schwenk (2008).
</prevsent>
<prevsent>in contrast to schwenk, we do not apply lightly-supervised training to conventional phrase-based system (och et al, 1999; <papid> W99-0604 </papid>koehn et al, 2003) <papid> N03-1017 </papid>but to hierarchical phrase-based translation (hpbt) system.</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
in hierarchical phrase-based translation (chiang,2005) <papid> P05-1033 </papid>weighted synchronous context-free grammar is induced from parallel text, the search is based on cyk+ parsing (chappelier and rajman,1998) and typically carried out using the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></citsent>
<aftsection>
<nextsent>in addition to the contiguous lexical phrases as in standardphrase-based translation, the hierarchical phrase based paradigm also allows for phrases with gaps which are called hierarchical phrases.
</nextsent>
<nextsent>a generic non-terminal symbol serves as place holder that marks the gaps.
</nextsent>
<nextsent>in this paper we study several different ways of incorporating unsupervised training data into hierarchical system.
</nextsent>
<nextsent>the basic techniques we employ are the use of multiple translation models and distinction of the hierarchical and thenon-hierarchical (i.e. lexical) part of the translation model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2667">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we report experimental results on the large-scale nist arabic-english translation taskand show that lightly-supervised training yields significant gains over the baseline.
</prevsent>
<prevsent>large-scale lightly-supervised training for smt as we define it in this paper has been first carried out by schwenk (2008).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
schwenk translates large amount of monolingual french data with an initial moses (koehn et al, 2007) <papid> P07-2045 </papid>baseline system into en glish.</citsent>
<aftsection>
<nextsent>in schwenks original work, an additional bilingual dictionary is added to the baseline.
</nextsent>
<nextsent>withlightly-supervised training, schwenk achieves improvements of around one bleu point over the baseline.
</nextsent>
<nextsent>in later work (schwenk and senellart, 2009) he applies the same method for translation model adaptation on an arabic-french task with 91 gains of up to 3.5 points bleu.
</nextsent>
<nextsent>1hierarchical phrase-based translation has been pioneered by david chiang (chiang, 2005; <papid> P05-1033 </papid>chiang, 2007) <papid> J07-2003 </papid>with his hiero system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2669">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>withlightly-supervised training, schwenk achieves improvements of around one bleu point over the baseline.
</prevsent>
<prevsent>in later work (schwenk and senellart, 2009) he applies the same method for translation model adaptation on an arabic-french task with 91 gains of up to 3.5 points bleu.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
1hierarchical phrase-based translation has been pioneered by david chiang (chiang, 2005; <papid> P05-1033 </papid>chiang, 2007) <papid> J07-2003 </papid>with his hiero system.</citsent>
<aftsection>
<nextsent>the hierarchical paradigm has been implemented and extended by several groups since, some have published their software as open source (li et al, 2009; <papid> W09-0424 </papid>hoang et al, 2009; vilar et al, 2010).<papid> W10-1738 </papid></nextsent>
<nextsent>combining multiple translation models has been investigated for domain adaptation by foster andkuhn (2007) <papid> W07-0717 </papid>and koehn and schroeder (2007) <papid> W07-0733 </papid>before.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2670">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in later work (schwenk and senellart, 2009) he applies the same method for translation model adaptation on an arabic-french task with 91 gains of up to 3.5 points bleu.
</prevsent>
<prevsent>1hierarchical phrase-based translation has been pioneered by david chiang (chiang, 2005; <papid> P05-1033 </papid>chiang, 2007) <papid> J07-2003 </papid>with his hiero system.</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
the hierarchical paradigm has been implemented and extended by several groups since, some have published their software as open source (li et al, 2009; <papid> W09-0424 </papid>hoang et al, 2009; vilar et al, 2010).<papid> W10-1738 </papid></citsent>
<aftsection>
<nextsent>combining multiple translation models has been investigated for domain adaptation by foster andkuhn (2007) <papid> W07-0717 </papid>and koehn and schroeder (2007) <papid> W07-0733 </papid>before.</nextsent>
<nextsent>heger et al (2010) exploit the distinction between hierarchical and lexical phrases in similar way as we do.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2671">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in later work (schwenk and senellart, 2009) he applies the same method for translation model adaptation on an arabic-french task with 91 gains of up to 3.5 points bleu.
</prevsent>
<prevsent>1hierarchical phrase-based translation has been pioneered by david chiang (chiang, 2005; <papid> P05-1033 </papid>chiang, 2007) <papid> J07-2003 </papid>with his hiero system.</prevsent>
</prevsection>
<citsent citstr=" W10-1738 ">
the hierarchical paradigm has been implemented and extended by several groups since, some have published their software as open source (li et al, 2009; <papid> W09-0424 </papid>hoang et al, 2009; vilar et al, 2010).<papid> W10-1738 </papid></citsent>
<aftsection>
<nextsent>combining multiple translation models has been investigated for domain adaptation by foster andkuhn (2007) <papid> W07-0717 </papid>and koehn and schroeder (2007) <papid> W07-0733 </papid>before.</nextsent>
<nextsent>heger et al (2010) exploit the distinction between hierarchical and lexical phrases in similar way as we do.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2672">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>1hierarchical phrase-based translation has been pioneered by david chiang (chiang, 2005; <papid> P05-1033 </papid>chiang, 2007) <papid> J07-2003 </papid>with his hiero system.</prevsent>
<prevsent>the hierarchical paradigm has been implemented and extended by several groups since, some have published their software as open source (li et al, 2009; <papid> W09-0424 </papid>hoang et al, 2009; vilar et al, 2010).<papid> W10-1738 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-0717 ">
combining multiple translation models has been investigated for domain adaptation by foster andkuhn (2007) <papid> W07-0717 </papid>and koehn and schroeder (2007) <papid> W07-0733 </papid>before.</citsent>
<aftsection>
<nextsent>heger et al (2010) exploit the distinction between hierarchical and lexical phrases in similar way as we do.
</nextsent>
<nextsent>they train phrase translation probabilities with forced alignment using conventionalphrase-based system (wuebker et al, 2010) <papid> P10-1049 </papid>and employ them for the lexical phrases while the hierarchical phrases stay untouched.</nextsent>
<nextsent>the most straightforward way of trying to improve the baseline with lightly-supervised training would be to concatenate the human-generated parallel data and the unsupervised data and to jointly extract phrases from the unified parallel data (after having trained word alignments for the unsupervised bitexts as well).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2673">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>1hierarchical phrase-based translation has been pioneered by david chiang (chiang, 2005; <papid> P05-1033 </papid>chiang, 2007) <papid> J07-2003 </papid>with his hiero system.</prevsent>
<prevsent>the hierarchical paradigm has been implemented and extended by several groups since, some have published their software as open source (li et al, 2009; <papid> W09-0424 </papid>hoang et al, 2009; vilar et al, 2010).<papid> W10-1738 </papid></prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
combining multiple translation models has been investigated for domain adaptation by foster andkuhn (2007) <papid> W07-0717 </papid>and koehn and schroeder (2007) <papid> W07-0733 </papid>before.</citsent>
<aftsection>
<nextsent>heger et al (2010) exploit the distinction between hierarchical and lexical phrases in similar way as we do.
</nextsent>
<nextsent>they train phrase translation probabilities with forced alignment using conventionalphrase-based system (wuebker et al, 2010) <papid> P10-1049 </papid>and employ them for the lexical phrases while the hierarchical phrases stay untouched.</nextsent>
<nextsent>the most straightforward way of trying to improve the baseline with lightly-supervised training would be to concatenate the human-generated parallel data and the unsupervised data and to jointly extract phrases from the unified parallel data (after having trained word alignments for the unsupervised bitexts as well).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2674">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>combining multiple translation models has been investigated for domain adaptation by foster andkuhn (2007) <papid> W07-0717 </papid>and koehn and schroeder (2007) <papid> W07-0733 </papid>before.</prevsent>
<prevsent>heger et al (2010) exploit the distinction between hierarchical and lexical phrases in similar way as we do.</prevsent>
</prevsection>
<citsent citstr=" P10-1049 ">
they train phrase translation probabilities with forced alignment using conventionalphrase-based system (wuebker et al, 2010) <papid> P10-1049 </papid>and employ them for the lexical phrases while the hierarchical phrases stay untouched.</citsent>
<aftsection>
<nextsent>the most straightforward way of trying to improve the baseline with lightly-supervised training would be to concatenate the human-generated parallel data and the unsupervised data and to jointly extract phrases from the unified parallel data (after having trained word alignments for the unsupervised bitexts as well).
</nextsent>
<nextsent>this method is simple and expected to be effective usually.
</nextsent>
<nextsent>there may however be two drawbacks: first, the reliability and the amount of parallel sentences may differ between the human generated and the unsupervised part of the trainingdata.
</nextsent>
<nextsent>it might be desirable to run separate extractions on the two corpora in order to be able to distinguish and weight phrases (or rather their scores) according to their origin during decoding.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2676">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 baseline system.
</prevsent>
<prevsent>the baseline system has been trained using ahuman-generated parallel corpus of 2.5m arabic english sentence pairs.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
word alignments in both 92directions were produced with giza++ and sym metrized according to the refined method that was suggested by och and ney (2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>the models integrated into our baseline system are: phrase translation probabilities and lexical translation probabilities for both translation directions, length penalties on word and phrase level, three binary features marking hierarchical phrases,glue rule, and rules with non-terminals at the boundaries, four simple additional count- and length based binary features, and large 4-gram language model with modified kneser-ney smoothing that was trained with the srilm toolkit (stolcke, 2002).
</nextsent>
<nextsent>we ran the cube pruning algorithm, the depth of the hierarchical recur sion was restricted to one by using shallow rules as proposed by iglesias et al (2009).<papid> E09-1044 </papid>the scaling factors of the log-linear model combination have been optimized towards bleu with mert (och, 2003) <papid> P03-1021 </papid>on the mt06 nist test corpus.</nextsent>
<nextsent>mt08 was employed as held-out test data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2677">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>word alignments in both 92directions were produced with giza++ and sym metrized according to the refined method that was suggested by och and ney (2003).<papid> J03-1002 </papid></prevsent>
<prevsent>the models integrated into our baseline system are: phrase translation probabilities and lexical translation probabilities for both translation directions, length penalties on word and phrase level, three binary features marking hierarchical phrases,glue rule, and rules with non-terminals at the boundaries, four simple additional count- and length based binary features, and large 4-gram language model with modified kneser-ney smoothing that was trained with the srilm toolkit (stolcke, 2002).</prevsent>
</prevsection>
<citsent citstr=" E09-1044 ">
we ran the cube pruning algorithm, the depth of the hierarchical recur sion was restricted to one by using shallow rules as proposed by iglesias et al (2009).<papid> E09-1044 </papid>the scaling factors of the log-linear model combination have been optimized towards bleu with mert (och, 2003) <papid> P03-1021 </papid>on the mt06 nist test corpus.</citsent>
<aftsection>
<nextsent>mt08 was employed as held-out test data.
</nextsent>
<nextsent>detailed statistics for the parallel training data are given in table 1, for the development and the test corpus in table 2.
</nextsent>
<nextsent>4.2 unsupervised data.
</nextsent>
<nextsent>the unsupervised data that we integrate has been created by automatic translations of parts of the arabic ldc gigaword corpus (mostly from thehyt collection) with standard phrase-based system (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2678">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>word alignments in both 92directions were produced with giza++ and sym metrized according to the refined method that was suggested by och and ney (2003).<papid> J03-1002 </papid></prevsent>
<prevsent>the models integrated into our baseline system are: phrase translation probabilities and lexical translation probabilities for both translation directions, length penalties on word and phrase level, three binary features marking hierarchical phrases,glue rule, and rules with non-terminals at the boundaries, four simple additional count- and length based binary features, and large 4-gram language model with modified kneser-ney smoothing that was trained with the srilm toolkit (stolcke, 2002).</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we ran the cube pruning algorithm, the depth of the hierarchical recur sion was restricted to one by using shallow rules as proposed by iglesias et al (2009).<papid> E09-1044 </papid>the scaling factors of the log-linear model combination have been optimized towards bleu with mert (och, 2003) <papid> P03-1021 </papid>on the mt06 nist test corpus.</citsent>
<aftsection>
<nextsent>mt08 was employed as held-out test data.
</nextsent>
<nextsent>detailed statistics for the parallel training data are given in table 1, for the development and the test corpus in table 2.
</nextsent>
<nextsent>4.2 unsupervised data.
</nextsent>
<nextsent>the unsupervised data that we integrate has been created by automatic translations of parts of the arabic ldc gigaword corpus (mostly from thehyt collection) with standard phrase-based system (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2680">
<title id=" W11-2211.xml">lightly supervised training for hierarchical phrase based machine translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>results in bold are significantly better than the baseline.
</prevsent>
<prevsent>4.4 experimental results.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
the empirical evaluation of all our systems on the two standard metrics bleu (papineni et al, 2002)<papid> P02-1040 </papid>and ter (snover et al, 2006) is presented in table 5.</citsent>
<aftsection>
<nextsent>we have also checked the results for statistical significance over the baseline.
</nextsent>
<nextsent>the confidence intervals have been computed using bootstrapping for bleu and cochrans approximate ratio variance for ter (leusch and ney, 2009).when we combine the full baseline phrase table with the unsupervised phrase table or the lexical part of it, we either use common scaling factors for their source-to-target and target-to-source translation costs, or we use common scaling factors butmark entries from the unsupervised table with binary feature, or we optimize the four translation features separately for each of the two tables as part of the log-linear model combination.including the unsupervised data leads to substantial gain on the unseen test set of up to +1.0% bleu absolute.
</nextsent>
<nextsent>the different ways of combining the manually produced data with the unsupervised have little impact on translation quality.
</nextsent>
<nextsent>this holds specifically for the combination with only the lexical phrases, which, when marked with binary feature, is able to obtain the same results as the full (joint extraction) system but with much less phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2681">
<title id=" W11-2003.xml">which system differences matter using l1l2 regularization to compare dialogue systems </title>
<section> finding features that predict.  </section>
<citcontext>
<prevsection>
<prevsent>when comparing two sdss, we label the baseline system with 1, and the alternate version with +1.?
</prevsent>
<prevsent>modeling performance.
</prevsent>
</prevsection>
<citsent citstr=" J06-2004 ">
although our approach does not depend on specific performance metric, in this paper we use dialogue success, binary indicator that triggers that the users query was answered by the sds.task completion is cheaper to compute than dialogue success, as it does not require manual human labeled reference, but we consider that dialogue success is more accurate metric.task completion is used in commercial applications (bacchiani et al, 2008), and has been extensively studied in the literature (walker et al,2001; walker et al, 2002; hajdinjak and mihelic, 2006; <papid> J06-2004 </papid>levin and pieraccini, 2006; moller et al, 2007; moller et al, 2008; schmitt et al., 2010).</citsent>
<aftsection>
<nextsent>we encode success of dialogues by manually annotating them with binary variable that distinguishes if the user query is fulfilled by the sds.we now present two algorithms to find what differences matter between systems.
</nextsent>
<nextsent>we introduce serial evaluation analysis (serena) as scaffold for the join evaluation and differences identification (jedi) algorithm.
</nextsent>
<nextsent>3.1 serena algorithm.
</nextsent>
<nextsent>the input to serena is collection of log files created by two different sdss and two functions that represent the correct label for the regression tasks.in our case these functions should return binary labels (+1,1): one task distinguishes between successful and unsuccessful dialogues, and the other task distinguishes baseline from an alternative sds version.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2682">
<title id=" W11-2003.xml">which system differences matter using l1l2 regularization to compare dialogue systems </title>
<section> case study.  </section>
<citcontext>
<prevsection>
<prevsent>user: when is the next one?
</prevsent>
<prevsent>system: the next 61c going to forbes and murray will leave carnegie mellon at 5:13 pm.
</prevsent>
</prevsection>
<citsent citstr=" W07-0305 ">
figure 1: example of lets go dialogue, from (raux et al., 2006)use an older version of the olympus sds infrastructure (bohus et al, 2007), <papid> W07-0305 </papid>and the other half uses olympus ii.</citsent>
<aftsection>
<nextsent>since each system was deployed in different period of time, we want to corroborate that we are modeling the differences among systems, and not seasonal.
</nextsent>
<nextsent>hence, for control conditions, we also chose dataset that contained no major change to the system or to other conditions (set c).
</nextsent>
<nextsent>sets were built by randomly sampling from the collection of logs.
</nextsent>
<nextsent>they have the same number of dialogues from each sds version (baseline/alternate).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2684">
<title id=" W11-2003.xml">which system differences matter using l1l2 regularization to compare dialogue systems </title>
<section> relation to prior work.  </section>
<citcontext>
<prevsection>
<prevsent>sometimes, because of human error, this history is incomplete.
</prevsent>
<prevsent>the ability of jedi to identify system differences has been able to help completing the history of changes (gonzalez-brenes et al, 2009).
</prevsent>
</prevsection>
<citsent citstr=" H92-1005 ">
the scientific literature offers several performance metrics to assess sds performance (polifroni et al, 1992; <papid> H92-1005 </papid>danieli and gerbino, 1995; bacchiani et al,2008; suendermann et al, 2010).</citsent>
<aftsection>
<nextsent>sds are evaluated using different objective and subjective metrics.
</nextsent>
<nextsent>examples of objective metrics are the mean number of turns in the dialogue, and dialogue success.
</nextsent>
<nextsent>subjective evaluations study measure satisfaction through controlled user studies.
</nextsent>
<nextsent>ai et al (2007) studied the differences in using assessment metrics with real users and paid users.paradise, notable example of sds subjective evaluation, finds linear predictors of satisfaction score using automatic and hand-labeled features (hajdinjak and mihelic, 2006; <papid> J06-2004 </papid>walker et al, 2001),or only automatic features (hastie et al, 2002).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2686">
<title id=" W11-2003.xml">which system differences matter using l1l2 regularization to compare dialogue systems </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>common techniques in econometrics, suchas the seemingly unrelated regressions (sur) formulation (zellner, 1962), may prove useful for this.in our approach we used single binary evaluation criterion.
</prevsent>
<prevsent>by using different loss function, jedi can be extended to allow continuous-valued metrics.
</prevsent>
</prevsection>
<citsent citstr=" W01-0902 ">
moreover, previous work has argued that evaluating sdss should not be based on just single criterion (paek, 2001).<papid> W01-0902 </papid></citsent>
<aftsection>
<nextsent>jedis multi-task formulation can be extended to include more than one performance criterion at the same time, and may prove helpful to understand trade-offs among different evaluation criteria.
</nextsent>
<nextsent>a implementation details of feature selection in this appendix we review how to set-up multi-task feature selection as an optimization problem.
</nextsent>
<nextsent>14 a.1 `1-regularized regression for single-task feature selection we first review using regression with `1 regularization for single-task feature selection.
</nextsent>
<nextsent>given training set represented by x, denoting n ? matrix, where is the number of dialogues, and is the number of features extracted for each dialogue, we want to find the coefficients of the parameter vector ~?, that can predict the output variables described in the vector ~y of length n.for this, we find the parameter vector that minimizes the loss function , penalized by regularization term (tibshirani, 1996): argmin ~?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2687">
<title id=" W12-0104.xml">an empirical evaluation of stop word removal in statistical machine translation </title>
<section> frequent word prediction.  </section>
<citcontext>
<prevsection>
<prevsent>the next section describes the implemented word prediction model in detail.
</prevsent>
<prevsent>it constitutes fundamental element of our proposed relaxed smt approach.
</prevsent>
</prevsection>
<citsent citstr=" D07-1053 ">
word prediction has been widely studied and used in several different tasks such as, for example, augmented and alternative communication (wandmacher and antoine, 2007) <papid> D07-1053 </papid>and spelling correction (thiele et al, 2000).</citsent>
<aftsection>
<nextsent>in addition to the commonly used word n-gram, various language modeling techniques have been applied, such as the semantic model (lus and rosa, 2002; wandmacher and antoine, 2007) <papid> D07-1053 </papid>and the class-based model (thiele et al, 2000; zohar and roth, 2000; ruch et al, 2001).</nextsent>
<nextsent>the role of such word predictor in our considered problem is to recover the null tokens in the translation output by replacing them with the words that best fit the sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2689">
<title id=" W11-2137.xml">regmt system for machine translation system combination and evaluation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this also gives us computational advantage when considering the high dimensionality of the problem as each sentence can be mapped to many features.the goal in transductive regression based machine translation (regmt) is both reducing the computational burden of the regression approach by reducing the dimensionality of the training set and the feature set and also improving the translation quality by using transduction.
</prevsent>
<prevsent>we present translation results using our training instance selection methods, translation results using graph decoding, system combination results with regmt, and performance evaluation with the f1measure over target features as metric for evaluating translation quality.
</prevsent>
</prevsection>
<citsent citstr=" W10-1741 ">
regmt work builds on our previous regression-based machine translation results (bicici and yuret, 2010) <papid> W10-1741 </papid>especially with instance selection and additional graph decoding capability.</citsent>
<aftsection>
<nextsent>we present our results to this years challenges.
</nextsent>
<nextsent>outline: section 2 gives an overview of there gmt model.
</nextsent>
<nextsent>in section 3, we present our training instance selection techniques and wmt11 results.
</nextsent>
<nextsent>in section 4, we present the graph decoding results on the haitian creole-english translation task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2691">
<title id=" W11-2137.xml">regmt system for machine translation system combination and evaluation </title>
<section> machine translation using regression.  </section>
<citcontext>
<prevsection>
<prevsent>we use forward stage wise regression (fsr) (hastieet al, 2006), which approximates lasso for l1 regularized regression.
</prevsent>
<prevsent>2.2 related work:.
</prevsent>
</prevsection>
<citsent citstr=" N07-2047 ">
regression techniques can be used to model the relationship between strings (cortes et al, 2007).wang et al (2007) <papid> N07-2047 </papid>applies string-to-string mapping approach to machine translation by using ordinary least squares regression and n-gram string kernels to small dataset.</citsent>
<aftsection>
<nextsent>later they use l2 regularized least squares regression (wang and shawe-taylor, 2008).
</nextsent>
<nextsent>although the translation quality they achieve is not better than moses (koehn et al, 2007), <papid> P07-2045 </papid>which is accepted to be the state-of-the-art, they show the feasibility of the approach.</nextsent>
<nextsent>serrano et al (2009) use kernel regression to find translation mappings from source to target feature vectors and experiment with translating hotel front desk requests.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2692">
<title id=" W11-2137.xml">regmt system for machine translation system combination and evaluation </title>
<section> machine translation using regression.  </section>
<citcontext>
<prevsection>
<prevsent>regression techniques can be used to model the relationship between strings (cortes et al, 2007).wang et al (2007) <papid> N07-2047 </papid>applies string-to-string mapping approach to machine translation by using ordinary least squares regression and n-gram string kernels to small dataset.</prevsent>
<prevsent>later they use l2 regularized least squares regression (wang and shawe-taylor, 2008).</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
although the translation quality they achieve is not better than moses (koehn et al, 2007), <papid> P07-2045 </papid>which is accepted to be the state-of-the-art, they show the feasibility of the approach.</citsent>
<aftsection>
<nextsent>serrano et al (2009) use kernel regression to find translation mappings from source to target feature vectors and experiment with translating hotel front desk requests.
</nextsent>
<nextsent>locally weighted regression solves separate weighted least squares problems for each instance (hastie et al, 2009), weighted by kernel similarity function.
</nextsent>
<nextsent>translation proper selection of training instances plays an important role for accurately learning feature mappings with limited computational resources.
</nextsent>
<nextsent>coverage of the features is important since if we do not have the correct features in the training matrices, we will not be able to translate them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2694">
<title id=" W11-2137.xml">regmt system for machine translation system combination and evaluation </title>
<section> graph decoding for regmt.  </section>
<citcontext>
<prevsection>
<prevsent>we perform graph-based decoding by first generating de bruijn graph from the estimated y?
</prevsent>
<prevsent>(cortes etal., 2007) and then finding euler ian paths with maximum path weight.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we use four features when scoring paths: (1) estimation weight from regression, (2) language model score, (3) brevity penalty as foundby e?(lr?|s|/|path|) for lr representing the length ratio from the parallel corpus and |path| representing the length of the current path, (4) future cost as in moses (koehn et al, 2007) <papid> P07-2045 </papid>and weights are tuned using mert (och, 2003) <papid> P03-1021 </papid>on the de-en dev set.we demonstrate that sparse l1 regularized regression performs better than l2 regularized regression.</citsent>
<aftsection>
<nextsent>graph based decoding can provide an alternative to state of the art phrase-based decoding system moses in translation domains with small vocabulary and training set size.
</nextsent>
<nextsent>4.1 haitian creole to english translation task.
</nextsent>
<nextsent>with regmtwe have trained moses system for the haitian creole to english translation task, cleaned corpus, us 325 ing the options as described in section 3.1.
</nextsent>
<nextsent>moses achieves 0.3186 bleu on this task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2695">
<title id=" W11-2137.xml">regmt system for machine translation system combination and evaluation </title>
<section> system combination with regmt.  </section>
<citcontext>
<prevsection>
<prevsent>scores for each translation using the language model trained over the target corpus provided in the translation task.since we do not have access to the reference translations nor to the translation model scores each system obtained for each sentence, we estimate translation model performance (cbleu) by measuring the average bleu performance of each translation relative to the other translations in the -best list.
</prevsent>
<prevsent>thus, each possible translation in the -best list isbleu scored against other translations and the average of these scores is selected as the cbleu score for the sentence.
</prevsent>
</prevsection>
<citsent citstr=" D07-1105 ">
sentence level bleu score calculation avoids singularities in n-gram precis ions by taking the maximum of the match count and 12|si| for |si| denoting the length of the source sentence si as used in (macherey and och, 2007).<papid> D07-1105 </papid>table 2 presents reranking results on all of the language pairs we considered, using regmt, cbleu, and lm scores with the same combination weights as above.</citsent>
<aftsection>
<nextsent>we also list the performance of the best model (max) as well as the worst (min).
</nextsent>
<nextsent>we are able to achieve close or better bleu scores in allof the listed systems when compared with the performance of the best translation system except for the ht-en language pair.
</nextsent>
<nextsent>the lower performance inthe ht-en language pair may be due to having single best translation system that outperforms otherssignificantly.
</nextsent>
<nextsent>this happens for instance when an unconstrained model use external resources to achieve significantly better performance than the second best model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2696">
<title id=" W11-2137.xml">regmt system for machine translation system combination and evaluation </title>
<section> system combination with regmt.  </section>
<citcontext>
<prevsection>
<prevsent>for es-en task, there is 0.36 bleu points difference with the second best model and these models likely to complement each other.
</prevsent>
<prevsent>326 the existence of complementing smt models is important for the reranking approach to achieve performance better than the best model, as there isa need for the existence of model performing better than the best model on some test sentences.
</prevsent>
</prevsection>
<citsent citstr=" W10-1740 ">
we can use the competitive smt model to achieve the performance of the best with guarantee even when single model is dominating the rest (bicici and kozat, 2010).<papid> W10-1740 </papid></citsent>
<aftsection>
<nextsent>for competing translation systems in an on-line machine translation setting adaptively learning of model weights can be performed based on the previous transaltion performance (bicici and kozat, 2010).<papid> W10-1740 </papid></nextsent>
<nextsent>metric we use target sentence f1 measure over the target features as translation performance evaluation metric.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2702">
<title id=" W11-2315.xml">towards an on demand simple portuguese wikipedia </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this project uses simplification in different linguistic levels to provide simplified text to poor literacy readers.
</prevsent>
<prevsent>for english, automatic text simplification has been exploited for helping readers with poor literacy (max, 2006) and readers with other special needs, such as aphasic people (devlin and unthank, 2006; carroll et al. 1999).
</prevsent>
</prevsection>
<citsent citstr=" P08-1040 ">
it has also been used in bilingual education (petersen, 2007) and for improving the accuracy of natural language processing (nlp) tasks (klebanov et al, 2004; vickrey and koller, 2008).<papid> P08-1040 </papid></citsent>
<aftsection>
<nextsent>given the general scarcity of human resources to manually simplify large content repositories such as wikipedia, simplifying texts automatically can be the only feasible option.
</nextsent>
<nextsent>the portuguese wikipedia, for example, is the tenth largest wikipedia (as of may 2011), with 683,215 articles and approximately 860,242 contributors6.
</nextsent>
<nextsent>in this paper we propose new rule-based syntactic simplification system to create simple portuguese wikipedia on demand, based on user interactions with the main portuguese wikipedia.
</nextsent>
<nextsent>we use simplification engine to change passive into active voice and to break down and change the syntax of subordinate clauses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2703">
<title id=" W11-2315.xml">towards an on demand simple portuguese wikipedia </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>approaches using operations learned from corpus have not shown to be able to perform complex operations such the splitting of sentences with relative clauses (chandrasekar and srinivas, 1997; daelemans et al., 2004; specia, 2010).
</prevsent>
<prevsent>on the other hand.
</prevsent>
</prevsection>
<citsent citstr=" W10-0406 ">
the use of machine learning techniques to predict when to simplify sentence, i.e. learning the properties of language that distinguish simple from normal texts, has achieved relative success (napoles and dredze, 2010).<papid> W10-0406 </papid></citsent>
<aftsection>
<nextsent>therefore, most work on syntactic simplification still relies on rule-based systems to simplify set of syntactic constructions.
</nextsent>
<nextsent>this is also the approach we follow in this paper.
</nextsent>
<nextsent>in what follows we review some relevant and work on syntactic simplification.
</nextsent>
<nextsent>the seminal work of chandrasekar and srinivas (1997) investigated the induction of syntactic rules from corpus annotated with part-of-speech tags augmented by agreement and subcategorization information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2704">
<title id=" W11-2315.xml">towards an on demand simple portuguese wikipedia </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>more recently, specia (2010) presented new approach for text simplification, based on the framework of statistical machine 138 translation.
</prevsent>
<prevsent>although the results are promising for lexical simplification, syntactic rewriting was not captured by the model to address long-distance operations, since syntactic information was not included into the framework.
</prevsent>
</prevsection>
<citsent citstr=" W03-1602 ">
inui et al (2003) <papid> W03-1602 </papid>proposed rule-based system for text simplification aimed at deaf people.</citsent>
<aftsection>
<nextsent>using about one thousand manually created rules, the authors generate several paraphrases for each sentence and train classifier to select the simpler ones.
</nextsent>
<nextsent>promising results were obtained, although different types of errors on the paraphrase generation are encountered, such as problems with verb conjugation and regency.
</nextsent>
<nextsent>our work aims at making portuguese wikipedia information accessible to large audience and instead of generating several possible outputs we generate only one based on rules taken from manual of simplification for bp.
</nextsent>
<nextsent>siddharthan (2006) proposed syntactic simplification architecture that relies on shallow parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2705">
<title id=" W12-1623.xml">a reranking model for discourse segmentation using subtree features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our model exploits subtree features to rerank best outputs of base segmenter, which uses syntactic and lexical features in crf framework.
</prevsent>
<prevsent>experimental results on the rst discourse treebank corpus show that our model outperforms existing discourse segment ers inboth settings that use gold standard penn tree bank parse trees and stanford parse trees.
</prevsent>
</prevsection>
<citsent citstr=" W10-4327 ">
discourse structure has been shown to have an important role in many natural language applications, such as text summarization (marcu, 2000; louis et al., 2010), <papid> W10-4327 </papid>information presentation (bateman et al, 2001), <papid> J01-3004 </papid>question answering (sun and chai, 2007), and dialogue generation (hernault et al, 2008).</citsent>
<aftsection>
<nextsent>to produce such kinds of discourse structure, several attempts have been made to build discourse parsers in the framework of rhetorical structure theory (rst) (mann and thompson, 1988), one of the most widely used theories of text structure.
</nextsent>
<nextsent>in the rst framework, text is first divided into several elementary discourse units (edus).
</nextsent>
<nextsent>eachedu may be simple sentence or clause in complex sentence.
</nextsent>
<nextsent>consecutive edus are then put in relation with each other to build discourse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2706">
<title id=" W12-1623.xml">a reranking model for discourse segmentation using subtree features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our model exploits subtree features to rerank best outputs of base segmenter, which uses syntactic and lexical features in crf framework.
</prevsent>
<prevsent>experimental results on the rst discourse treebank corpus show that our model outperforms existing discourse segment ers inboth settings that use gold standard penn tree bank parse trees and stanford parse trees.
</prevsent>
</prevsection>
<citsent citstr=" J01-3004 ">
discourse structure has been shown to have an important role in many natural language applications, such as text summarization (marcu, 2000; louis et al., 2010), <papid> W10-4327 </papid>information presentation (bateman et al, 2001), <papid> J01-3004 </papid>question answering (sun and chai, 2007), and dialogue generation (hernault et al, 2008).</citsent>
<aftsection>
<nextsent>to produce such kinds of discourse structure, several attempts have been made to build discourse parsers in the framework of rhetorical structure theory (rst) (mann and thompson, 1988), one of the most widely used theories of text structure.
</nextsent>
<nextsent>in the rst framework, text is first divided into several elementary discourse units (edus).
</nextsent>
<nextsent>eachedu may be simple sentence or clause in complex sentence.
</nextsent>
<nextsent>consecutive edus are then put in relation with each other to build discourse tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2707">
<title id=" W12-1623.xml">a reranking model for discourse segmentation using subtree features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1 shows an example of discourse tree with three edus.
</prevsent>
<prevsent>the goal of the discourse segmentation task is to divide the input text into such edus.
</prevsent>
</prevsection>
<citsent citstr=" N03-1030 ">
figure 1: discourse tree (soricut and marcu, 2003).<papid> N03-1030 </papid>the quality of the discourse segmenter contributes significant part to the overall accuracy of every discourse parsing system.</citsent>
<aftsection>
<nextsent>if text is wrongly segmented, no discourse parsing algorithm can build correct discourse tree.existing discourse segment ers usually exploit lexical and syntactic features to label each word in asentence with one of two labels, boundary or no boundary.
</nextsent>
<nextsent>the limitation of this approach is that it only focuses on the boundaries of edus.
</nextsent>
<nextsent>it cannot capture features that describe whole edus.
</nextsent>
<nextsent>recently, discriminative reranking has been used successfully in some nlp tasks such as pos tagging, chunking, and statistical parsing (collins and koo, 2005; <papid> J05-1003 </papid>kudo et al, 2005; <papid> P05-1024 </papid>huang, 2008; <papid> P08-1067 </papid>fraser et al, 2009).<papid> E09-1033 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2708">
<title id=" W12-1623.xml">a reranking model for discourse segmentation using subtree features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the limitation of this approach is that it only focuses on the boundaries of edus.
</prevsent>
<prevsent>it cannot capture features that describe whole edus.
</prevsent>
</prevsection>
<citsent citstr=" J05-1003 ">
recently, discriminative reranking has been used successfully in some nlp tasks such as pos tagging, chunking, and statistical parsing (collins and koo, 2005; <papid> J05-1003 </papid>kudo et al, 2005; <papid> P05-1024 </papid>huang, 2008; <papid> P08-1067 </papid>fraser et al, 2009).<papid> E09-1033 </papid></citsent>
<aftsection>
<nextsent>the advantage of the reranking method is that it can exploit the output of base model tolearn.
</nextsent>
<nextsent>based on that output, we can extract long distance non-local features to rerank.
</nextsent>
<nextsent>in this paper, we present reranking model for the discourse segmentation task.
</nextsent>
<nextsent>we show how to use subtree features, features extracted from wholeedus, to rerank outputs of base model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2709">
<title id=" W12-1623.xml">a reranking model for discourse segmentation using subtree features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the limitation of this approach is that it only focuses on the boundaries of edus.
</prevsent>
<prevsent>it cannot capture features that describe whole edus.
</prevsent>
</prevsection>
<citsent citstr=" P05-1024 ">
recently, discriminative reranking has been used successfully in some nlp tasks such as pos tagging, chunking, and statistical parsing (collins and koo, 2005; <papid> J05-1003 </papid>kudo et al, 2005; <papid> P05-1024 </papid>huang, 2008; <papid> P08-1067 </papid>fraser et al, 2009).<papid> E09-1033 </papid></citsent>
<aftsection>
<nextsent>the advantage of the reranking method is that it can exploit the output of base model tolearn.
</nextsent>
<nextsent>based on that output, we can extract long distance non-local features to rerank.
</nextsent>
<nextsent>in this paper, we present reranking model for the discourse segmentation task.
</nextsent>
<nextsent>we show how to use subtree features, features extracted from wholeedus, to rerank outputs of base model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2710">
<title id=" W12-1623.xml">a reranking model for discourse segmentation using subtree features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the limitation of this approach is that it only focuses on the boundaries of edus.
</prevsent>
<prevsent>it cannot capture features that describe whole edus.
</prevsent>
</prevsection>
<citsent citstr=" P08-1067 ">
recently, discriminative reranking has been used successfully in some nlp tasks such as pos tagging, chunking, and statistical parsing (collins and koo, 2005; <papid> J05-1003 </papid>kudo et al, 2005; <papid> P05-1024 </papid>huang, 2008; <papid> P08-1067 </papid>fraser et al, 2009).<papid> E09-1033 </papid></citsent>
<aftsection>
<nextsent>the advantage of the reranking method is that it can exploit the output of base model tolearn.
</nextsent>
<nextsent>based on that output, we can extract long distance non-local features to rerank.
</nextsent>
<nextsent>in this paper, we present reranking model for the discourse segmentation task.
</nextsent>
<nextsent>we show how to use subtree features, features extracted from wholeedus, to rerank outputs of base model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2711">
<title id=" W12-1623.xml">a reranking model for discourse segmentation using subtree features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the limitation of this approach is that it only focuses on the boundaries of edus.
</prevsent>
<prevsent>it cannot capture features that describe whole edus.
</prevsent>
</prevsection>
<citsent citstr=" E09-1033 ">
recently, discriminative reranking has been used successfully in some nlp tasks such as pos tagging, chunking, and statistical parsing (collins and koo, 2005; <papid> J05-1003 </papid>kudo et al, 2005; <papid> P05-1024 </papid>huang, 2008; <papid> P08-1067 </papid>fraser et al, 2009).<papid> E09-1033 </papid></citsent>
<aftsection>
<nextsent>the advantage of the reranking method is that it can exploit the output of base model tolearn.
</nextsent>
<nextsent>based on that output, we can extract long distance non-local features to rerank.
</nextsent>
<nextsent>in this paper, we present reranking model for the discourse segmentation task.
</nextsent>
<nextsent>we show how to use subtree features, features extracted from wholeedus, to rerank outputs of base model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2712">
<title id=" W12-1623.xml">a reranking model for discourse segmentation using subtree features </title>
<section> coordinate clauses and coordinate elliptical.  </section>
<citcontext>
<prevsection>
<prevsent>cognitive verbs are edus.
</prevsent>
<prevsent>the segmenter then uses cue phrases to correct the output of the first step.
</prevsent>
</prevsection>
<citsent citstr=" P09-2020 ">
tofiloski et al (2009) <papid> P09-2020 </papid>describe another rule-based discourse segmenter.</citsent>
<aftsection>
<nextsent>the core of this segmenter consists of 12 syntactic segmentation rules and some rules concerning list of stop phrases, discourse cue phrases, and part-of-speech tags.
</nextsent>
<nextsent>they also use list of phrasal discourse cues to insert boundaries not derivable from the parsers output.soricut and marcu (2003) <papid> N03-1030 </papid>introduce statistical discourse segmenter, which is trained on rst dt to label words with boundary or no-boundary labels.</nextsent>
<nextsent>they use lexical and syntactic features to determine the probabilities of discourse boundaries (bi|wi, t), where wi is the ith word of the input sentence s, is the syntactic parse tree of s, and bi ? {boundary, no-boundary}.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2731">
<title id=" W12-1002.xml">a high speed transcription interface for annotating primary linguistic data </title>
<section> future possibilities: computational.  </section>
<citcontext>
<prevsection>
<prevsent>the goal there is, again, to reduce annotation time, sothat the linguist can work more on linguistic analysis and less on annotating.
</prevsent>
<prevsent>at the same time, working set of annotyzers will promote more standardised glossing, which can then be used for further automated research, cf.
</prevsent>
</prevsection>
<citsent citstr=" D11-1037 ">
automatic tree bank production or similar (bender et al, 2011).<papid> D11-1037 </papid></citsent>
<aftsection>
<nextsent>the diversity of the worlds languages is in danger.
</nextsent>
<nextsent>perhaps user interface design is not the first thing that comes to mind in response to this sobering fact.
</nextsent>
<nextsent>yet in field that increasingly works with digital annotations of primary linguistic data, it is imperative that the basic tools for annotation and transcription are optimally designed to get the job done.
</nextsent>
<nextsent>we have described transcription mode, newuser interface in elan that accelerates the transcription process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2732">
<title id=" W12-1609.xml">the effect of cognitive load on a statistical dialogue system </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, this study has found that users barge-in and use filler words significantly more often when they are cognitively loaded.
</prevsent>
<prevsent>this suggests the need for much richer turn-taking model which allows the system to use back-channels and barge-in whenthe user hesitates.
</prevsent>
</prevsection>
<citsent citstr=" E09-1081 ">
an obvious candidate is the incremental approach (schlangen and skantze, 2009;<papid> E09-1081 </papid>devault et al, 2009) <papid> W09-3902 </papid>which allows the system to process partial user inputs, back-channels, predict short term user input and interrupt the user during hesita tions.</citsent>
<aftsection>
<nextsent>while incremental dialogue is growing areaof study, it has not so far been examined in the context of dialogue for secondary tasks.
</nextsent>
<nextsent>we signpost this as an important area for future work.
</nextsent>
<nextsent>acknowledgments we would like to thank to peter robinson and ian davies for their help with the experiments.
</nextsent>
<nextsent>77
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2733">
<title id=" W12-1609.xml">the effect of cognitive load on a statistical dialogue system </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, this study has found that users barge-in and use filler words significantly more often when they are cognitively loaded.
</prevsent>
<prevsent>this suggests the need for much richer turn-taking model which allows the system to use back-channels and barge-in whenthe user hesitates.
</prevsent>
</prevsection>
<citsent citstr=" W09-3902 ">
an obvious candidate is the incremental approach (schlangen and skantze, 2009;<papid> E09-1081 </papid>devault et al, 2009) <papid> W09-3902 </papid>which allows the system to process partial user inputs, back-channels, predict short term user input and interrupt the user during hesita tions.</citsent>
<aftsection>
<nextsent>while incremental dialogue is growing areaof study, it has not so far been examined in the context of dialogue for secondary tasks.
</nextsent>
<nextsent>we signpost this as an important area for future work.
</nextsent>
<nextsent>acknowledgments we would like to thank to peter robinson and ian davies for their help with the experiments.
</nextsent>
<nextsent>77
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2734">
<title id=" W12-2020.xml">an interactive analytic tool for peer review exploration </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>one major goal of peer review studies in educational research is to understand how to better improve student learning, directly or indirectly.
</prevsent>
<prevsent>empirical studies of textual review comments based on manual coding have discovered that certain review features (e.g., whether the solution to problem is explicitly stated in comment) can predict both whether the problem will be understand and the feedback implemented (nelson and schunn, 2009).
</prevsent>
</prevsection>
<citsent citstr=" P11-2088 ">
our previous studies used machine learning and nlp techniques to automatically identify the presence of such useful features in review comments (xiong et al, 2010); similar techniques have also been used to determine review comment helpfulness (xiong and litman, 2011; <papid> P11-2088 </papid>cho, 2008).</citsent>
<aftsection>
<nextsent>with respect to paper analysis, sandor and vorndran (2009) used nlp to highlight key sentences, in order to focus reviewer attention on important paper aspects.
</nextsent>
<nextsent>finally, giannoukos etal.
</nextsent>
<nextsent>(2010) focused on peer matching based on students?
</nextsent>
<nextsent>profile information to maximize learning outcomes, while crespo garcia and pardo (2010) explored the use of document clustering to adaptively guide the assignment of papers to peers.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2735">
<title id=" W12-2020.xml">an interactive analytic tool for peer review exploration </title>
<section> rev explore.  </section>
<citcontext>
<prevsection>
<prevsent>176 figure 2: peer-review exploration using rev explore, for mining differences between strong and weak students.compared with respect to specific reviewing dimensions using list of topic words that are automatically computed in real-time.extracting topic words of peer reviews for comparison purposes is different from most traditionaltopic-word extraction tasks that are commonly involved in text summarization.
</prevsent>
<prevsent>in traditional text summarization, the informative ness measurement is designed to extract the common themes, while in our case of comparison, instructors are more concerned with the uniqueness of each target set of peer reviews compared to the others.
</prevsent>
</prevsection>
<citsent citstr=" C00-1072 ">
thus topic-signature acquisition algorithm (lin and hovy,2000), <papid> C00-1072 </papid>which extracts topic words through comparing the vocabulary distribution of target corpus against that of generic background corpus using statistic metric, suits our application better than other approaches, such as probabilistic graphical models (e.g. lda) and frequency based methods.</citsent>
<aftsection>
<nextsent>therefore, rev explore considers topic signatures as the topic words for group of reviews, using all peer reviews as the background corpus.4 again, to minimize the impact of the domain content of the relevant papers, we apply topic-masking which replaces all domain words5 with ddd?
</nextsent>
<nextsent>before computing the topic signatures.
</nextsent>
<nextsent>as the software outputs topic signatures together with their associated weights which reflect signature importance, rev explore uses this weight information to order the topic words as list, and visualizes the weight as the font size and foreground color of the relevant topic word.
</nextsent>
<nextsent>these lists are placed intwo rows regarding their group membership dimension by dimension.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2736">
<title id=" W12-2020.xml">an interactive analytic tool for peer review exploration </title>
<section> rev explore.  </section>
<citcontext>
<prevsection>
<prevsent>as the software outputs topic signatures together with their associated weights which reflect signature importance, rev explore uses this weight information to order the topic words as list, and visualizes the weight as the font size and foreground color of the relevant topic word.
</prevsent>
<prevsent>these lists are placed intwo rows regarding their group membership dimension by dimension.
</prevsent>
</prevsection>
<citsent citstr=" P08-1094 ">
for each dimension, the corresponding lists of both rows are aligned vertically with the same background color to indicate that dimension (e.g. topic-list detail view of figure 2).to further facilitate the comparison within dimension, rev explore highlights the topic words that are unique to one group with darker background color.4we use topics (nenkova and louis, 2008) <papid> P08-1094 </papid>provided by annie louis.</citsent>
<aftsection>
<nextsent>5learned from all student papers against 5000 documents from the english gigaword corpus using topics.
</nextsent>
<nextsent>177if the user cannot interpret the topic that an extracted word might imply, the user can click on the word to read the relevant original reviews, with that word highlighted in red (e.g. original reviews pane of figure 2).
</nextsent>
<nextsent>figure 2 shows how rev explore is used to discover the difference between strong and weak students with respect to their writing performance on logic?
</nextsent>
<nextsent>in the history peer-review assignment introduced in section 4.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2737">
<title id=" W12-1525.xml">the surface realisation task recent developments and future plans </title>
<section> sr11.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we report on our work in this direction so far and relate it to somenew shared task proposals which have been developed in part as response to the above difficulties.
</prevsent>
<prevsent>we discuss how these developments might usefully be integrated, and outline plans for sr13, the next edition of the sr task.
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
the sr11 input representations were created by post-processing the conll 2008 shared task data (surdeanu et al, 2008), <papid> W08-2121 </papid>for the preparation of which selected sections of the wsj treebank we reconverted to syntactic dependencies with the pen nconverter (johansson and nugues, 2007).</citsent>
<aftsection>
<nextsent>the resulting dependency bank was then merged with nombank (meyers et al, 2004) <papid> W04-2705 </papid>and propbank (palmer et al, 2005).<papid> J05-1004 </papid></nextsent>
<nextsent>named entity information from the bbn entity type corpus was also incorpo rated.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2738">
<title id=" W12-1525.xml">the surface realisation task recent developments and future plans </title>
<section> sr11.  </section>
<citcontext>
<prevsection>
<prevsent>we discuss how these developments might usefully be integrated, and outline plans for sr13, the next edition of the sr task.
</prevsent>
<prevsent>the sr11 input representations were created by post-processing the conll 2008 shared task data (surdeanu et al, 2008), <papid> W08-2121 </papid>for the preparation of which selected sections of the wsj treebank we reconverted to syntactic dependencies with the pen nconverter (johansson and nugues, 2007).</prevsent>
</prevsection>
<citsent citstr=" W04-2705 ">
the resulting dependency bank was then merged with nombank (meyers et al, 2004) <papid> W04-2705 </papid>and propbank (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>named entity information from the bbn entity type corpus was also incorporated.
</nextsent>
<nextsent>the sr11 shallow representation was based on the penn converter dependencies, while the deep representation was derived from the merged nombank, propbank and syntactic dependencies in pro 136cess similar to the graph completion algorithm outlined by bohnet (2010).
</nextsent>
<nextsent>five teams submitted total of six systems to sr11 which we evaluated automatically using range of intrinsic metrics.
</nextsent>
<nextsent>in addition, systems we reassessed by human judges in terms of clarity, read ability and meaning similarity.the four top-performing systems were all statistical dependency realisers that do not make use ofan explicit, pre-existing grammar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2739">
<title id=" W12-1525.xml">the surface realisation task recent developments and future plans </title>
<section> sr11.  </section>
<citcontext>
<prevsection>
<prevsent>we discuss how these developments might usefully be integrated, and outline plans for sr13, the next edition of the sr task.
</prevsent>
<prevsent>the sr11 input representations were created by post-processing the conll 2008 shared task data (surdeanu et al, 2008), <papid> W08-2121 </papid>for the preparation of which selected sections of the wsj treebank we reconverted to syntactic dependencies with the pen nconverter (johansson and nugues, 2007).</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
the resulting dependency bank was then merged with nombank (meyers et al, 2004) <papid> W04-2705 </papid>and propbank (palmer et al, 2005).<papid> J05-1004 </papid></citsent>
<aftsection>
<nextsent>named entity information from the bbn entity type corpus was also incorporated.
</nextsent>
<nextsent>the sr11 shallow representation was based on the penn converter dependencies, while the deep representation was derived from the merged nombank, propbank and syntactic dependencies in pro 136cess similar to the graph completion algorithm outlined by bohnet (2010).
</nextsent>
<nextsent>five teams submitted total of six systems to sr11 which we evaluated automatically using range of intrinsic metrics.
</nextsent>
<nextsent>in addition, systems we reassessed by human judges in terms of clarity, read ability and meaning similarity.the four top-performing systems were all statistical dependency realisers that do not make use ofan explicit, pre-existing grammar.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2740">
<title id=" W12-1525.xml">the surface realisation task recent developments and future plans </title>
<section> towards sr13.  </section>
<citcontext>
<prevsection>
<prevsent>for each set of results, we will report single-best andn-best results.
</prevsent>
<prevsent>for single-best results, we may furthermore report results both with and without missing outputs.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
we will rank systems, and report significance of pairwise differences using bootstrap re sampling where necessary (koehn, 2004; <papid> W04-3250 </papid>zhang and vogel, 2010).</citsent>
<aftsection>
<nextsent>we will separately report correlation between human and automatic metrics, and between different automatic metrics.
</nextsent>
<nextsent>3.4 assessing different aspects of realisation.
</nextsent>
<nextsent>separately in addition, we will consider measuring different aspects of the realisation performance of participating systems (syntax, word order, morphology) since asystem can perform well on one and badly on an other.
</nextsent>
<nextsent>for instance, system might perform wellon morphological realisation while it has poor results on linearisation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2741">
<title id=" W11-2117.xml">cmu system combination in wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>humans judged our combination the best on eight of ten tracks.
</prevsent>
<prevsent>we participated in all ten tracks of the 2011 work shop on machine translation system combination task as cmu-heafield-combo.
</prevsent>
</prevsection>
<citsent citstr=" W10-1744 ">
this uses system combination scheme that builds on our prior work (heafield and lavie, 2010), <papid> W10-1744 </papid>especially with respect to language modeling and handling non english languages.</citsent>
<aftsection>
<nextsent>we present summary of the system, describe improvements, list the data used (all of the constrained monolingual data), and present automatic results in anticipation of human evaluation by the workshop.
</nextsent>
<nextsent>given single-best outputs from each system, the scheme aligns system outputs then searches space based on these alignments.
</nextsent>
<nextsent>the scheme is continuation of our previous system (heafield and lavie,2010) <papid> W10-1744 </papid>so we describe unchanged parts of the system in less detail, preferring instead to focus on new components.</nextsent>
<nextsent>2.1 alignment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2743">
<title id=" W11-2117.xml">cmu system combination in wmt 2011 </title>
<section> our combination scheme.  </section>
<citcontext>
<prevsection>
<prevsent>the scheme is continuation of our previous system (heafield and lavie,2010) <papid> W10-1744 </papid>so we describe unchanged parts of the system in less detail, preferring instead to focus on new components.</prevsent>
<prevsent>2.1 alignment.</prevsent>
</prevsection>
<citsent citstr=" W10-1751 ">
we run the meteor matcher (denkowski and lavie, 2010) <papid> W10-1751 </papid>on every pair of system outputs for agiven sentence.</citsent>
<aftsection>
<nextsent>it identifies exact matches, identical stems (porter, 2001) except for czech, wordnet synonym matches for english (fellbaum, 1998), and automatically extracted matches for all five targetlanguages.
</nextsent>
<nextsent>the automatic matches come from pivoting (bannard and callison-burch, 2005) on constrained data.
</nextsent>
<nextsent>an example meteor alignment is shown in figure 1, though it need not be monotone.
</nextsent>
<nextsent>twice that produced by nuclear plants double that that produce nuclear power stations figure 1: alignment generated by meteor showing exact (thatthat and nuclearnuclear), stem (producedproduce), synonym (twicedouble), and unigram paraphrase (plantsstations) alignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2746">
<title id=" W11-2117.xml">cmu system combination in wmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>here, supported?
</prevsent>
<prevsent>counts because it aligns with support?.
</prevsent>
</prevsection>
<citsent citstr=" W09-0406 ">
hypothesis selection (hildebrand and vogel, 2009) <papid> W09-0406 </papid>selects an entire sentence at time instead of picking and merging words.</citsent>
<aftsection>
<nextsent>this makes the approach less flexible, in that it cannot synthesize new sentences, but also less risky by avoiding matching and related problems entirely.
</nextsent>
<nextsent>while our alignment is based on meteor, other techniques are based on ter (snover et al, 2006), inversion transduction grammars (narsale, 2010), <papid> W10-1746 </papid>and other alignment methods.</nextsent>
<nextsent>these use exact alignments and positional information to infer alignments, ignoring the content-based method used by meteor.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2747">
<title id=" W11-2117.xml">cmu system combination in wmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>hypothesis selection (hildebrand and vogel, 2009) <papid> W09-0406 </papid>selects an entire sentence at time instead of picking and merging words.</prevsent>
<prevsent>this makes the approach less flexible, in that it cannot synthesize new sentences, but also less risky by avoiding matching and related problems entirely.</prevsent>
</prevsection>
<citsent citstr=" W10-1746 ">
while our alignment is based on meteor, other techniques are based on ter (snover et al, 2006), inversion transduction grammars (narsale, 2010), <papid> W10-1746 </papid>and other alignment methods.</citsent>
<aftsection>
<nextsent>these use exact alignments and positional information to infer alignments, ignoring the content-based method used by meteor.
</nextsent>
<nextsent>this means they might align content words to function words, while we never do.
</nextsent>
<nextsent>in practice, using both signals would likely work better.
</nextsent>
<nextsent>confusion networks (rosti et al, 2010; <papid> W10-1748 </papid>narsale,2010) <papid> W10-1746 </papid>are the dominant method for system combi nation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2748">
<title id=" W11-2117.xml">cmu system combination in wmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>this means they might align content words to function words, while we never do.
</prevsent>
<prevsent>in practice, using both signals would likely work better.
</prevsent>
</prevsection>
<citsent citstr=" W10-1748 ">
confusion networks (rosti et al, 2010; <papid> W10-1748 </papid>narsale,2010) <papid> W10-1746 </papid>are the dominant method for system combi nation.</citsent>
<aftsection>
<nextsent>these base their word order on one system, dubbed the backbone, and have all systems vote on editing the backbone.
</nextsent>
<nextsent>word order is largely fixed tothat of one system; by contrast, ours can piece together word orders taken from multiple systems.
</nextsent>
<nextsent>in loose sense, our approach is confusion network where the backbone is permitted to switch after each word.
</nextsent>
<nextsent>interestingly, bbn (rosti et al, 2010) <papid> W10-1748 </papid>this year added novel-bigram penalty that penalizes bigram sin the output if they do not appear in one of the sys 146 tem outputs.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2753">
<title id=" W11-2117.xml">cmu system combination in wmt 2011 </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>in order for an n-gram to be queried, all of the words must appear in system outputs for the same sentence.
</prevsent>
<prevsent>this enables filtering constraint stronger than normal vocabulary filtering, which permits ngrams supported only by words in different sentences.
</prevsent>
</prevsection>
<citsent citstr=" W11-2123 ">
finally, we use kenlm (heafield, 2011) <papid> W11-2123 </papid>for inference at runtime.our primary use of data is for language model ing.</citsent>
<aftsection>
<nextsent>we used essientially every constrained resource available and appended them together to build one large model.
</nextsent>
<nextsent>for every language, we used the provided europarl v6 (koehn, 2005), news crawl, and news commentary corpora.
</nextsent>
<nextsent>in addition, we used: english gigaword fourth edition (parker et al,2009) and the english parts of united nations documents, giga-fren, and czeng (bojar and zabokrtsky?, 2009) sections 07.
</nextsent>
<nextsent>for the haitian creole-english tasks, we built separate language model on the sms messages and used it alongside the large english model.czech czeng (bojar and zabokrtsky?, 2009) sections 07 french gigaword second edition (mendonca et al., 2009a) and the french parts of giga-fren and united nations documents.german there were no additional corpora available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2754">
<title id=" W11-2117.xml">cmu system combination in wmt 2011 </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>as punctuation to limit the amount of html code.
</prevsent>
<prevsent>less than half the characters are latin letters.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
system outputs and language model training data were normalized using the provided punctuation normalization script, unicode code point collapsing, the provided moses (koehn et al, 2007) <papid> P07-2045 </papid>to kenizer, and several custom rules.</citsent>
<aftsection>
<nextsent>these remove formatting-related tokens from gigaword, rejoin some french words with internal apostrophes, and threshold repetitive punctuation.
</nextsent>
<nextsent>in addition, german words were segmented as explained in section 4.3.
</nextsent>
<nextsent>text normalization is more difficult for system.
</nextsent>
<nextsent>combination because the system outputs, while theoretically detokenized, contain errors that result from different preprocessing at each site.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2755">
<title id=" W11-2117.xml">cmu system combination in wmt 2011 </title>
<section> resources.  </section>
<citcontext>
<prevsection>
<prevsent>in order to properly align differently segmented words, we normalize by segmenting all system outputs and our language model training data using words separate compounded jahrzehnte lang 554 542 klar gemacht 840 802 unter anderem 49538 4 wieder herzustellen 513 1532 table 1: counts of separate or compounded versions of select words in the lower cased german monolingual data.
</prevsent>
<prevsent>compounding can be optional or biased in either way.
</prevsent>
</prevsection>
<citsent citstr=" P10-4002 ">
the single-best segmentation from cdec (dyer et al., 2010).<papid> P10-4002 </papid></citsent>
<aftsection>
<nextsent>running our system therefore produces segmented german output.
</nextsent>
<nextsent>internally, we tuned towards segmented references but for final output it is desirable to rejoin compound words.
</nextsent>
<nextsent>since the cdec segmentation was designed for german english translation, no corresponding desegmenter was provided.
</nextsent>
<nextsent>we created german desegmenter in the naturalway: segment german words then invert the mapping to identify words that should be rejoined.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2756">
<title id=" W11-2117.xml">cmu system combination in wmt 2011 </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>casing of unchanged words comes from equally-weighted system votes at the character level while casing of rejoined words is based on the majority appearance in the corpus; this is almost always initial capital.
</prevsent>
<prevsent>we ran our desegmenter followed by the workshops provided detokenizer to produce the submitted out put.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we tried many variations on the scheme, such as selecting different systems, tuning to bleu (papineni et al, 2002) <papid> P02-1040 </papid>or meteor (denkowski and lavie, 2010), <papid> W10-1751 </papid>and changing the structure of the match count features from section 2.3.</citsent>
<aftsection>
<nextsent>to try these, we ran mert 242 times, or about 24 times for each of the ten tasks in which we participated.
</nextsent>
<nextsent>then we selected 148 the best performing systems on the tuning set and submitted them, with the secondary system chosen to meaningfully differ from the primary while still scoring well.
</nextsent>
<nextsent>once the evaluation released references, we scored against them to generate table 2.
</nextsent>
<nextsent>on the featured haitian creole task, we show no and sometimes even negative improvement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2758">
<title id=" W12-1808.xml">incremental spoken dialogue systems tools and data </title>
<section> incremental spoken dialogue systems.  </section>
<citcontext>
<prevsection>
<prevsent>(sub utterance processing units) resulting in dialogues that are more fluid and responsive.
</prevsent>
<prevsent>recent work has shown that processing smaller chunks?
</prevsent>
</prevsection>
<citsent citstr=" E09-1085 ">
of input and output can improve the user experience (aist et al., 2007; skantze and schlangen, 2009; <papid> E09-1085 </papid>buss et al, 2010; baumann et al, 2011; selfridge et al, 2011).<papid> W11-2014 </papid></citsent>
<aftsection>
<nextsent>incrementality enables the system designer to model several dialogue phenomena that play vital role in human discourse (levelt, 1989) but have so far been absent from systems.
</nextsent>
<nextsent>these include more natural turn-taking through rapid system responses, grounding through the generation of backchannelsand feedback, and barge-ins (from both user and sys tem).
</nextsent>
<nextsent>in addition, corrections and self-correctionsthrough constant monitoring of user and system utterances play an important role, enabling the system to recover smoothly from recognition error or change in users preferences.
</nextsent>
<nextsent>some examples of the phenomena we are targeting are given in figure 1.parlance, fp7 ec project1, is currently developing incremental systems for english and mandarin.the goal of parlance is to develop mobile, interactive, hyper-local?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2759">
<title id=" W12-1808.xml">incremental spoken dialogue systems tools and data </title>
<section> incremental spoken dialogue systems.  </section>
<citcontext>
<prevsection>
<prevsent>(sub utterance processing units) resulting in dialogues that are more fluid and responsive.
</prevsent>
<prevsent>recent work has shown that processing smaller chunks?
</prevsent>
</prevsection>
<citsent citstr=" W11-2014 ">
of input and output can improve the user experience (aist et al., 2007; skantze and schlangen, 2009; <papid> E09-1085 </papid>buss et al, 2010; baumann et al, 2011; selfridge et al, 2011).<papid> W11-2014 </papid></citsent>
<aftsection>
<nextsent>incrementality enables the system designer to model several dialogue phenomena that play vital role in human discourse (levelt, 1989) but have so far been absent from systems.
</nextsent>
<nextsent>these include more natural turn-taking through rapid system responses, grounding through the generation of backchannelsand feedback, and barge-ins (from both user and sys tem).
</nextsent>
<nextsent>in addition, corrections and self-correctionsthrough constant monitoring of user and system utterances play an important role, enabling the system to recover smoothly from recognition error or change in users preferences.
</nextsent>
<nextsent>some examples of the phenomena we are targeting are given in figure 1.parlance, fp7 ec project1, is currently developing incremental systems for english and mandarin.the goal of parlance is to develop mobile, interactive, hyper-local?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2760">
<title id=" W11-2151.xml">upm system for the translation task </title>
<section> overall description of the system.  </section>
<citcontext>
<prevsection>
<prevsent>the translation system used is based on moses, the software released to support the translation task (http://www.statmt.org/wmt11/) at the emnlp 2011 workshop on statistical machine translation.
</prevsent>
<prevsent>figure 1: moses translation system 420 the phrase model has been trained following these steps (figure 1): ? word alignment computation.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
giza++ (och and ney, 2003) <papid> J03-1002 </papid>is statistical machine translation toolkit that is used to calculate the alignments between spanish and english words in both direction (spanish-english and english spanish).</citsent>
<aftsection>
<nextsent>to generate the translation model, the parameter alignment?
</nextsent>
<nextsent>was fixed to grow diag-final?
</nextsent>
<nextsent>(default value), and the parameter reordering?
</nextsent>
<nextsent>was fixed to msd-bidirectional fe?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2761">
<title id=" W11-1827.xml">adapting a general semantic interpretation approach to biological event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we apply our methodology to core bio-event extraction and specu lation/negation detection tasks in three main tracks.
</prevsent>
<prevsent>our results demonstrate that such general approach is viable and pinpoint some of its shortcomings.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
in the past two years, largely due to the availability of genia event corpus (kim et al , 2008) and the resulting shared task competition (bionlp09 shared task on event extraction (kim et al , 2009)), <papid> W09-1401 </papid>event extraction in biological domain hasbeen attracting greater attention.</citsent>
<aftsection>
<nextsent>one of the criticisms towards this paradigm of corpus annota tion/competition has been that they are concerned with narrow domains and specific representations,and that they may not generalize well.
</nextsent>
<nextsent>for instance, genia event corpus contains only medline abstracts on transcription factors in human blood cells.
</nextsent>
<nextsent>whether models trained on this corpus would perform well on full-text articles or on text focusing on other aspects of biomedicine (e.g., treatment or etiology of disease) remains largely unclear.
</nextsent>
<nextsent>since annotated corpora are not available for every conceivable domain, it is desirable for automatic event extraction systems to be generally applicable to different types of text and domains without requiring much training data or customization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2762">
<title id=" W11-1827.xml">adapting a general semantic interpretation approach to biological event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>y y n full-text?
</prevsent>
<prevsent>y y n spec/neg?
</prevsent>
</prevsection>
<citsent citstr=" W11-1802 ">
y y n table 1: an overview of bionlp-st11 tracks in the follow-up event to bionlp09 shared task on event extraction, organizers of the secondbionlp shared task on event extraction (bionlp st11) (kim et al , 2011<papid> W11-1802 </papid>a) address this challenge tosome extent.</citsent>
<aftsection>
<nextsent>the theme of bionlp-st11 is generalization and the net is cast much wider.
</nextsent>
<nextsent>there are 4 event extraction tracks: in addition to the genia track that again focuses on transcription factors (kim et al , 2011<papid> W11-1802 </papid>b), the epi genetics and post translational modification track (epi) focuses on events relating to epi genetic change, such as dna methyl ation and histone modification, as well asother common post-translational protein modifications (ohta et al , 2011), <papid> W11-1803 </papid>whereas the infectious diseases track (id) focuses on bio-molecular mechanisms of infectious diseases (pyysalo et al , 2011<papid> W11-1812 </papid>a).</nextsent>
<nextsent>both genia and id tracks include data pertaining to full-text articles, as well.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2770">
<title id=" W11-1827.xml">adapting a general semantic interpretation approach to biological event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>y y n table 1: an overview of bionlp-st11 tracks in the follow-up event to bionlp09 shared task on event extraction, organizers of the secondbionlp shared task on event extraction (bionlp st11) (kim et al , 2011<papid> W11-1802 </papid>a) address this challenge tosome extent.</prevsent>
<prevsent>the theme of bionlp-st11 is generalization and the net is cast much wider.</prevsent>
</prevsection>
<citsent citstr=" W11-1803 ">
there are 4 event extraction tracks: in addition to the genia track that again focuses on transcription factors (kim et al , 2011<papid> W11-1802 </papid>b), the epi genetics and post translational modification track (epi) focuses on events relating to epi genetic change, such as dna methyl ation and histone modification, as well asother common post-translational protein modifications (ohta et al , 2011), <papid> W11-1803 </papid>whereas the infectious diseases track (id) focuses on bio-molecular mechanisms of infectious diseases (pyysalo et al , 2011<papid> W11-1812 </papid>a).</citsent>
<aftsection>
<nextsent>both genia and id tracks include data pertaining to full-text articles, as well.
</nextsent>
<nextsent>the fourth track, bacteria, consists of two sub-tracks: biotopes (bb) and interactions (bi) (bossy et al  (2011) <papid> W11-1809 </papid>and jourde 173 et al  (2011), respectively).</nextsent>
<nextsent>a summary of the bionlp-st11 tracks is given in table (1).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2771">
<title id=" W11-1827.xml">adapting a general semantic interpretation approach to biological event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>y y n table 1: an overview of bionlp-st11 tracks in the follow-up event to bionlp09 shared task on event extraction, organizers of the secondbionlp shared task on event extraction (bionlp st11) (kim et al , 2011<papid> W11-1802 </papid>a) address this challenge tosome extent.</prevsent>
<prevsent>the theme of bionlp-st11 is generalization and the net is cast much wider.</prevsent>
</prevsection>
<citsent citstr=" W11-1812 ">
there are 4 event extraction tracks: in addition to the genia track that again focuses on transcription factors (kim et al , 2011<papid> W11-1802 </papid>b), the epi genetics and post translational modification track (epi) focuses on events relating to epi genetic change, such as dna methyl ation and histone modification, as well asother common post-translational protein modifications (ohta et al , 2011), <papid> W11-1803 </papid>whereas the infectious diseases track (id) focuses on bio-molecular mechanisms of infectious diseases (pyysalo et al , 2011<papid> W11-1812 </papid>a).</citsent>
<aftsection>
<nextsent>both genia and id tracks include data pertaining to full-text articles, as well.
</nextsent>
<nextsent>the fourth track, bacteria, consists of two sub-tracks: biotopes (bb) and interactions (bi) (bossy et al  (2011) <papid> W11-1809 </papid>and jourde 173 et al  (2011), respectively).</nextsent>
<nextsent>a summary of the bionlp-st11 tracks is given in table (1).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2773">
<title id=" W11-1827.xml">adapting a general semantic interpretation approach to biological event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are 4 event extraction tracks: in addition to the genia track that again focuses on transcription factors (kim et al , 2011<papid> W11-1802 </papid>b), the epi genetics and post translational modification track (epi) focuses on events relating to epi genetic change, such as dna methyl ation and histone modification, as well asother common post-translational protein modifications (ohta et al , 2011), <papid> W11-1803 </papid>whereas the infectious diseases track (id) focuses on bio-molecular mechanisms of infectious diseases (pyysalo et al , 2011<papid> W11-1812 </papid>a).</prevsent>
<prevsent>both genia and id tracks include data pertaining to full-text articles, as well.</prevsent>
</prevsection>
<citsent citstr=" W11-1809 ">
the fourth track, bacteria, consists of two sub-tracks: biotopes (bb) and interactions (bi) (bossy et al  (2011) <papid> W11-1809 </papid>and jourde 173 et al  (2011), respectively).</citsent>
<aftsection>
<nextsent>a summary of the bionlp-st11 tracks is given in table (1).
</nextsent>
<nextsent>we participated in three tracks: genia, epi, and id. in the spirit of the competition, our aim was to demonstrate methodology that was general and required little, if any, customization or training for individual tracks.
</nextsent>
<nextsent>for this purpose, we used two phase approach: syntax-driven composition phase that exploits linguistic generalizations to create agen eral semantic representation in bottom-up manner and mapping phase, which relies on the shared task event definitions and constraints to map relevant parts of this semantic representation to event instances.
</nextsent>
<nextsent>the composition phase takes as its input simple entities and syntactic dependency relations and is intended to be fully general.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2774">
<title id=" W11-1827.xml">adapting a general semantic interpretation approach to biological event extraction </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>we first briefly explain the construction of the trigger dictionary.
</prevsent>
<prevsent>3.1 dictionary of trigger expressions.
</prevsent>
</prevsection>
<citsent citstr=" W09-1418 ">
in the previous shared task, we relied on training data and simple statistical measures to identify good figure 1: embedding proposition categorization relevant to the shared task trigger expressions for events and used list of triggers that we manually compiled for speculation and negation detection (see kilicoglu and bergler (2009) <papid> W09-1418 </papid>for details).</citsent>
<aftsection>
<nextsent>with respect to atomic propositions, our method of constructing dictionary of trigger expressions remains essentially the same, including the use of statistical measures to distinguish good triggers.
</nextsent>
<nextsent>the only change we made was to consider affixal negation and set polarity of several atomic proposition triggers to negative (e.g., non expression, unglycosylated).
</nextsent>
<nextsent>on the other hand, we have been extending our manually compiled list of speculation/negation triggers to include other types of embedding triggers and to encode finer grained distinctions in terms of their categorization and trigger behaviors.
</nextsent>
<nextsent>the training data provided for the shared task also helped us expand this trigger dictionary,particularly with respect to relational trigger expressions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2775">
<title id=" W11-1827.xml">adapting a general semantic interpretation approach to biological event extraction </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>several entries from the embedding trigger dictionary are summarized in table (2).
</prevsent>
<prevsent>lexical polarity and strength values play rolein the composition phase in associating context dependent scalar value with propositions.
</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
lexical polarity values are largely derived from polarity lexicon (wilson et al , 2005) <papid> H05-1044 </papid>and extended by us 175 trigger pos semantic type lexical polarity strength show vb demonstrative positive 1.0 unknown jj epistemic negative 0.7 induce vb causal positive 1.0 fail vb success negative 0.0 effect nn causal neutral 0.5weakly rb hedge neutral absence nn reverse negative table 2: several entries from the embedding dictionary ing heuristics involving the event types associated with the trigger2.</citsent>
<aftsection>
<nextsent>some polarity values were assigned manually.
</nextsent>
<nextsent>some strength values were basedon prior work (kilicoglu and bergler, 2008), others were manually assigned.
</nextsent>
<nextsent>as table (2) shows, insome cases, the semantic type (e.g., demonstrative, causal) is simply mapping to the embedding categorization.
</nextsent>
<nextsent>in other cases, such as weakly or absence, the semantic type identifies the role thatthe trigger plays in the composition phase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2776">
<title id=" W11-1827.xml">adapting a general semantic interpretation approach to biological event extraction </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>as mentioned above, the composition phase assumes simple entities, syntactic dependency relations and trigger expressions.
</prevsent>
<prevsent>using these elements, we construct semantic embedding graph of the document.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
to obtain syntactic dependency relations, we segment documents into sentences, parse the musing the re-ranking parser of charniak and johnson (2005) <papid> P05-1022 </papid>adapted to the biomedical domain (mc closky and charniak, 2008) <papid> P08-2026 </papid>and extract syntactic 2for example, if the most likely event type associated withthe trigger is negative regulation, its polarity is considered neg ative.</citsent>
<aftsection>
<nextsent>3note, however, that not all embedding propositions (or their triggers) were directly relevant to the shared task.
</nextsent>
<nextsent>dependencies from parse trees using the stanford dependency scheme (de marneffe et al , 2006).
</nextsent>
<nextsent>in addition to syntactic dependencies, we also require information regarding individual tokens, including lemma, part-of-speech, and positional information, for which we also relyon stanford parser tools.
</nextsent>
<nextsent>we present high level description of the composition phase below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2777">
<title id=" W11-1827.xml">adapting a general semantic interpretation approach to biological event extraction </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>as mentioned above, the composition phase assumes simple entities, syntactic dependency relations and trigger expressions.
</prevsent>
<prevsent>using these elements, we construct semantic embedding graph of the document.
</prevsent>
</prevsection>
<citsent citstr=" P08-2026 ">
to obtain syntactic dependency relations, we segment documents into sentences, parse the musing the re-ranking parser of charniak and johnson (2005) <papid> P05-1022 </papid>adapted to the biomedical domain (mc closky and charniak, 2008) <papid> P08-2026 </papid>and extract syntactic 2for example, if the most likely event type associated withthe trigger is negative regulation, its polarity is considered neg ative.</citsent>
<aftsection>
<nextsent>3note, however, that not all embedding propositions (or their triggers) were directly relevant to the shared task.
</nextsent>
<nextsent>dependencies from parse trees using the stanford dependency scheme (de marneffe et al , 2006).
</nextsent>
<nextsent>in addition to syntactic dependencies, we also require information regarding individual tokens, including lemma, part-of-speech, and positional information, for which we also relyon stanford parser tools.
</nextsent>
<nextsent>we present high level description of the composition phase below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2779">
<title id=" W11-2405.xml">diversity aware evaluation for paraphrase patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to assassinated?
</prevsent>
<prevsent>(in the rest of this paper we denote such rule as killed2, assassinated3?).
</prevsent>
</prevsection>
<citsent citstr=" W06-1610 ">
in automatic evaluation for machine translation (mt) (zhou et al, 2006; <papid> W06-1610 </papid>kauchak and barzilay, 2006; <papid> N06-1058 </papid>pad?</citsent>
<aftsection>
<nextsent>et al, 2009), this rule may enable metric to identify phrase-level semantic similarity between system response containing killed?, and reference translation containing assassinated?.
</nextsent>
<nextsent>similarly in query expansion for information retrieval (ir) (riezler et al, 2007), <papid> P07-1059 </papid>this rule may enable system to 1 diversity-aware metric for pattern learning experiments 2 source term/phrase that contains killed?</nextsent>
<nextsent>3 paraphrase that contains assassinated?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2780">
<title id=" W11-2405.xml">diversity aware evaluation for paraphrase patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to assassinated?
</prevsent>
<prevsent>(in the rest of this paper we denote such rule as killed2, assassinated3?).
</prevsent>
</prevsection>
<citsent citstr=" N06-1058 ">
in automatic evaluation for machine translation (mt) (zhou et al, 2006; <papid> W06-1610 </papid>kauchak and barzilay, 2006; <papid> N06-1058 </papid>pad?</citsent>
<aftsection>
<nextsent>et al, 2009), this rule may enable metric to identify phrase-level semantic similarity between system response containing killed?, and reference translation containing assassinated?.
</nextsent>
<nextsent>similarly in query expansion for information retrieval (ir) (riezler et al, 2007), <papid> P07-1059 </papid>this rule may enable system to 1 diversity-aware metric for pattern learning experiments 2 source term/phrase that contains killed?</nextsent>
<nextsent>3 paraphrase that contains assassinated?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2781">
<title id=" W11-2405.xml">diversity aware evaluation for paraphrase patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in automatic evaluation for machine translation (mt) (zhou et al, 2006; <papid> W06-1610 </papid>kauchak and barzilay, 2006; <papid> N06-1058 </papid>pad?</prevsent>
<prevsent>et al, 2009), this rule may enable metric to identify phrase-level semantic similarity between system response containing killed?, and reference translation containing assassinated?.</prevsent>
</prevsection>
<citsent citstr=" P07-1059 ">
similarly in query expansion for information retrieval (ir) (riezler et al, 2007), <papid> P07-1059 </papid>this rule may enable system to 1 diversity-aware metric for pattern learning experiments 2 source term/phrase that contains killed?</citsent>
<aftsection>
<nextsent>3 paraphrase that contains assassinated?
</nextsent>
<nextsent>expand the query term killed?
</nextsent>
<nextsent>with the paraphrase assassinated?, in order to match potentially relevant document containing the expanded term.
</nextsent>
<nextsent>to evaluate paraphrase patterns during pattern discovery, ideally we should use an evaluation metric that strongly predicts performance on the extrinsic task (e.g. fluency and adequacy scores in mt, mean average precision in ir) where the paraphrase patterns are used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2782">
<title id=" W11-2405.xml">diversity aware evaluation for paraphrase patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to evaluate paraphrase patterns during pattern discovery, ideally we should use an evaluation metric that strongly predicts performance on the extrinsic task (e.g. fluency and adequacy scores in mt, mean average precision in ir) where the paraphrase patterns are used.
</prevsent>
<prevsent>many existing approaches use paraphrase evaluation methodology where human assessors judge each paraphrase pair as to whether they have the same meaning.
</prevsent>
</prevsection>
<citsent citstr=" N10-1017 ">
over set of paraphrase rules for one source term, expected precision (ep) is calculated by taking the mean of precision, or the ratio of positive labels annotated by assessors (bannard and callison-burch, 2005; callison-burch, 2008; kok and brockett, 2010; <papid> N10-1017 </papid>metzler et al, 2011).<papid> P11-2096 </papid></citsent>
<aftsection>
<nextsent>the weakness of this approach is that ep is an intrinsic measure that does not necessarily predict how well paraphrase-embedded system will perform in practice.
</nextsent>
<nextsent>for example, set of paraphrase pairs killed?, shot and killed??, killed?, reported killed??
</nextsent>
<nextsent>killed?, killed in??
</nextsent>
<nextsent>may receive perfect score of 1.0 in ep; however, these patterns do not provide lexical diversity (e.g. killed?, assassi nated??)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2783">
<title id=" W11-2405.xml">diversity aware evaluation for paraphrase patterns </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to evaluate paraphrase patterns during pattern discovery, ideally we should use an evaluation metric that strongly predicts performance on the extrinsic task (e.g. fluency and adequacy scores in mt, mean average precision in ir) where the paraphrase patterns are used.
</prevsent>
<prevsent>many existing approaches use paraphrase evaluation methodology where human assessors judge each paraphrase pair as to whether they have the same meaning.
</prevsent>
</prevsection>
<citsent citstr=" P11-2096 ">
over set of paraphrase rules for one source term, expected precision (ep) is calculated by taking the mean of precision, or the ratio of positive labels annotated by assessors (bannard and callison-burch, 2005; callison-burch, 2008; kok and brockett, 2010; <papid> N10-1017 </papid>metzler et al, 2011).<papid> P11-2096 </papid></citsent>
<aftsection>
<nextsent>the weakness of this approach is that ep is an intrinsic measure that does not necessarily predict how well paraphrase-embedded system will perform in practice.
</nextsent>
<nextsent>for example, set of paraphrase pairs killed?, shot and killed??, killed?, reported killed??
</nextsent>
<nextsent>killed?, killed in??
</nextsent>
<nextsent>may receive perfect score of 1.0 in ep; however, these patterns do not provide lexical diversity (e.g. killed?, assassi nated??)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2784">
<title id=" W11-2405.xml">diversity aware evaluation for paraphrase patterns </title>
<section> dimple metric.  </section>
<citcontext>
<prevsection>
<prevsent>since takes real value between 0 and 1, and takes an integer between 1 and 3, .}13^2{ 1?
</prevsent>
<prevsent>= ?= kiz being able to design and independently is one of characteristics in dimple.
</prevsent>
</prevsection>
<citsent citstr=" P07-1058 ">
in theory, can be any quality measure on paraphrase patterns, such as the in stance-based evaluation score (szpektor et al, 2007), <papid> P07-1058 </papid>or alignment-based evaluation score (callison-burch et al, 2008).</citsent>
<aftsection>
<nextsent>similarly, can be implemented depending on the domain task; for example, if we are interested in learning paraphrases that are out-of-vocabulary or do main-specific, could consult dictionary, and return high score if the lexical entry could not be found.
</nextsent>
<nextsent>the dimple framework is implemented in the following way4.
</nextsent>
<nextsent>let be the ratio of positive labels 4 implementation used for this experiment is available at http://code.google.com/p/dimple/ averaged over pairs by human assessors given pi as to whether paraphrase has the same meaning as the source term or not.
</nextsent>
<nextsent>let be the degree of lexical diversity of pattern calculated using algorithm 1 below.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2785">
<title id=" W11-2405.xml">diversity aware evaluation for paraphrase patterns </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>by extrinsic score, we mean to measure how much the paraphrase recognition component helps the entire system to achieve task.
</prevsent>
<prevsent>the correlation score is 1 if there is perfect positive correlation, 0 if there is no correlation and -1 if there is perfect negative correlation.
</prevsent>
</prevsection>
<citsent citstr=" P08-1077 ">
using task performance score to evaluate paraphrase generation algorithm has been studied previously (bhagat and ravichandran, 2008; <papid> P08-1077 </papid>szpektor and dagan, 2007; szpektor and dagan, 2008).<papid> C08-1107 </papid></citsent>
<aftsection>
<nextsent>a common issue in extrinsic evaluations is that it is hard to separate out errors, or contributions from other possibly complex modules.
</nextsent>
<nextsent>this paper presents an approach which can predict task performance in more simple experimental settings.
</nextsent>
<nextsent>3.1 annotated paraphrase resource.
</nextsent>
<nextsent>we used the paraphrase pattern dataset paraph rase-eval?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2786">
<title id=" W11-2405.xml">diversity aware evaluation for paraphrase patterns </title>
<section> experiment.  </section>
<citcontext>
<prevsection>
<prevsent>by extrinsic score, we mean to measure how much the paraphrase recognition component helps the entire system to achieve task.
</prevsent>
<prevsent>the correlation score is 1 if there is perfect positive correlation, 0 if there is no correlation and -1 if there is perfect negative correlation.
</prevsent>
</prevsection>
<citsent citstr=" C08-1107 ">
using task performance score to evaluate paraphrase generation algorithm has been studied previously (bhagat and ravichandran, 2008; <papid> P08-1077 </papid>szpektor and dagan, 2007; szpektor and dagan, 2008).<papid> C08-1107 </papid></citsent>
<aftsection>
<nextsent>a common issue in extrinsic evaluations is that it is hard to separate out errors, or contributions from other possibly complex modules.
</nextsent>
<nextsent>this paper presents an approach which can predict task performance in more simple experimental settings.
</nextsent>
<nextsent>3.1 annotated paraphrase resource.
</nextsent>
<nextsent>we used the paraphrase pattern dataset paraph rase-eval?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2794">
<title id=" W12-0606.xml">a hybrid framework for scalable opinion mining in social media detecting polarities and attitude targets </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>detecting the subject or targets of opinions is one of the mainlines of work within opinion mining, and considerable effort has been put into it, since it has been shown to be highly-domain specific task (consumer reviews will focus on specific products and features, tweets have hash tags to identify topics, blogs can talk almost about anything, etc.).
</prevsent>
<prevsent>outside of user-generated content, coursey, mihalcea, &amp; moen (2009) have suggested using indirect semantic resources, such as the wikipedia, to identify document topics.
</prevsent>
</prevsection>
<citsent citstr=" H05-1043 ">
for opinion mining genres, and extending on hu &amp; liu (2004), popescu &amp; etzioni (2005) <papid> H05-1043 </papid>use combination of pointwise mutual information, 4 http://lucene.apache.org/solr/ 47 relaxation labeling and dependency analysis to extract possible targets and features in product reviews.</citsent>
<aftsection>
<nextsent>kim &amp; hovy (2006), <papid> W06-0301 </papid>for example, use thematic roles to establish relation between candidate opinion holders and opinion topics, while exploiting clustering to improve coverage in their role-labeling.</nextsent>
<nextsent>recent approaches have included adaptation of ner techniques to noisy and irregular text, either by using learning algorithms or by doing text normalization (locke &amp; martin, 2009; ritter, clark &amp; etzioni, 2011).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2795">
<title id=" W12-0606.xml">a hybrid framework for scalable opinion mining in social media detecting polarities and attitude targets </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>outside of user-generated content, coursey, mihalcea, &amp; moen (2009) have suggested using indirect semantic resources, such as the wikipedia, to identify document topics.
</prevsent>
<prevsent>for opinion mining genres, and extending on hu &amp; liu (2004), popescu &amp; etzioni (2005) <papid> H05-1043 </papid>use combination of pointwise mutual information, 4 http://lucene.apache.org/solr/ 47 relaxation labeling and dependency analysis to extract possible targets and features in product reviews.</prevsent>
</prevsection>
<citsent citstr=" W06-0301 ">
kim &amp; hovy (2006), <papid> W06-0301 </papid>for example, use thematic roles to establish relation between candidate opinion holders and opinion topics, while exploiting clustering to improve coverage in their role-labeling.</citsent>
<aftsection>
<nextsent>recent approaches have included adaptation of ner techniques to noisy and irregular text, either by using learning algorithms or by doing text normalization (locke &amp; martin, 2009; ritter, clark &amp; etzioni, 2011).
</nextsent>
<nextsent>telecom-related online postings we collected close to 200,000 postings from various sm sources in 4 month timeframe, including fairly carefully-written product oriented forums, blogs, etc., as well as more casually-drafted face book and twitter micro blogging, that discussed spanish telecoms services and products.
</nextsent>
<nextsent>of these, we randomly sub-selected representative 190-document sample that was manually marked-up (for test involving machine learning of cue-polarity-target relationships) by two different human annotators with 20-document overlap, using simplified annotation guidelines focused on opinion targets, topics, cues and polarities.
</nextsent>
<nextsent>an interesting observation about the inter annotator agreement (but one we cant discuss in detail here) is that with regard to targets one of the human annotators tended more towards complete syntactic units (noun phrases), while the other chose more conceptual and semantic extensions as subjects for the opinions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2796">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> translation approaches.  </section>
<citcontext>
<prevsection>
<prevsent>we briefly describe the rationale behind the pbsmt(section 2.1) and the shallow-transfer rbmt (sec tion 2.2) systems we have used in our hybrid isation approach.
</prevsent>
<prevsent>2.1 phrase-based statistical machine.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
translationphrase-based statistical machine translation systems (koehn et al, 2003) <papid> N03-1017 </papid>translate sentences by maximising the translation probability as defined by the log-linear combination of number of feature functions, whose weights are chosen to opti 457mise translation quality (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>a core component of every pbsmt system is the phrase table, which contains bilingual phrase pairs extracted from bilingual corpus after word alignment (och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>the set of translations from which the most probable one is chosen is built by segmenting the source-language (sl) sentence in all possible ways and then combining the translation of the different source segments according to the phrase ta ble.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2797">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> translation approaches.  </section>
<citcontext>
<prevsection>
<prevsent>we briefly describe the rationale behind the pbsmt(section 2.1) and the shallow-transfer rbmt (sec tion 2.2) systems we have used in our hybrid isation approach.
</prevsent>
<prevsent>2.1 phrase-based statistical machine.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
translationphrase-based statistical machine translation systems (koehn et al, 2003) <papid> N03-1017 </papid>translate sentences by maximising the translation probability as defined by the log-linear combination of number of feature functions, whose weights are chosen to opti 457mise translation quality (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>a core component of every pbsmt system is the phrase table, which contains bilingual phrase pairs extracted from bilingual corpus after word alignment (och and ney, 2003).<papid> J03-1002 </papid></nextsent>
<nextsent>the set of translations from which the most probable one is chosen is built by segmenting the source-language (sl) sentence in all possible ways and then combining the translation of the different source segments according to the phrase ta ble.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2798">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> translation approaches.  </section>
<citcontext>
<prevsection>
<prevsent>2.1 phrase-based statistical machine.
</prevsent>
<prevsent>translationphrase-based statistical machine translation systems (koehn et al, 2003) <papid> N03-1017 </papid>translate sentences by maximising the translation probability as defined by the log-linear combination of number of feature functions, whose weights are chosen to opti 457mise translation quality (och, 2003).<papid> P03-1021 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
a core component of every pbsmt system is the phrase table, which contains bilingual phrase pairs extracted from bilingual corpus after word alignment (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>the set of translations from which the most probable one is chosen is built by segmenting the source-language (sl) sentence in all possible ways and then combining the translation of the different source segments according to the phrase table.
</nextsent>
<nextsent>common feature functions are: source-to-target and target-to-source phrase translation probabilities,source-to-target and target-to-source lexical weightings (calculated by using probabilistic bilingual dictionary), reordering costs, number of words in the output (word penalty), number of phrase pairs used (phrase penalty), and likelihood of the output as given by target-language (tl) model.
</nextsent>
<nextsent>2.2 shallow-transfer rule-based machine.
</nextsent>
<nextsent>translation the rbmt process (hutchins and somers, 1992) can be split into three different steps: i) analysis of the sl text to build sl intermediate representation, ii) transfer from that sl intermediate representation to tl intermediate representation, and iii) generation of the final translation from the tl intermediate representation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2800">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the chunk sequence haber pp (verb in present perfect tense) inf (verb in infinitive mood) match esa second-level rule which adds the preposition to between them: adv{ on the other hand adv  } noun_phrase{ my det  pos  pl  friend  pl  american adj  } haber_pp{ have vbhaver  pres  decide vblex  pp  } to{ to pr  } inf{ come vblex  inf  }third-level structural transfer removes chunk en capsulations so that plain sequence of lexical forms is generated: on the other hand adv  my det  pos  pl  american adj  friend  pl  have vbhaver  pres  decide vblex  pp  to pr  come vblex  inf  finally, the translation into tl is generated fromthe tl lexical forms: on the other hand my american friends have decided to come.
</prevsent>
<prevsent>linguistic data from rbmt have already been used to enrich smt systems in different ways.
</prevsent>
</prevsection>
<citsent citstr=" H93-1039 ">
bilingual dictionaries have been added to smt systems since its early days (brown et al, 1993); <papid> H93-1039 </papid>one of the simplest strategies involves adding the dictionary entries directly to the training parallel corpus (tyers, 2009; schwenk et al, 2009).<papid> W09-0423 </papid></citsent>
<aftsection>
<nextsent>other approaches go beyond that.
</nextsent>
<nextsent>eisele et al (2008) <papid> W08-0328 </papid>first translate the sentences in the test set with an rbmt system, then apply the usual phrase-extraction algorithm over the resulting small parallel corpus, and finally add the obtained phrase pairs to the original phrase table.</nextsent>
<nextsent>it is worth noting that neither of these two strategies guarantee that the multi-word expressions in the rbmt bilingual dictionary appearing in the sentences to translate will be translated as such because they may besplit into smaller units by the phrase-extraction algo rithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2801">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the chunk sequence haber pp (verb in present perfect tense) inf (verb in infinitive mood) match esa second-level rule which adds the preposition to between them: adv{ on the other hand adv  } noun_phrase{ my det  pos  pl  friend  pl  american adj  } haber_pp{ have vbhaver  pres  decide vblex  pp  } to{ to pr  } inf{ come vblex  inf  }third-level structural transfer removes chunk en capsulations so that plain sequence of lexical forms is generated: on the other hand adv  my det  pos  pl  american adj  friend  pl  have vbhaver  pres  decide vblex  pp  to pr  come vblex  inf  finally, the translation into tl is generated fromthe tl lexical forms: on the other hand my american friends have decided to come.
</prevsent>
<prevsent>linguistic data from rbmt have already been used to enrich smt systems in different ways.
</prevsent>
</prevsection>
<citsent citstr=" W09-0423 ">
bilingual dictionaries have been added to smt systems since its early days (brown et al, 1993); <papid> H93-1039 </papid>one of the simplest strategies involves adding the dictionary entries directly to the training parallel corpus (tyers, 2009; schwenk et al, 2009).<papid> W09-0423 </papid></citsent>
<aftsection>
<nextsent>other approaches go beyond that.
</nextsent>
<nextsent>eisele et al (2008) <papid> W08-0328 </papid>first translate the sentences in the test set with an rbmt system, then apply the usual phrase-extraction algorithm over the resulting small parallel corpus, and finally add the obtained phrase pairs to the original phrase table.</nextsent>
<nextsent>it is worth noting that neither of these two strategies guarantee that the multi-word expressions in the rbmt bilingual dictionary appearing in the sentences to translate will be translated as such because they may besplit into smaller units by the phrase-extraction algo rithm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2802">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>bilingual dictionaries have been added to smt systems since its early days (brown et al, 1993); <papid> H93-1039 </papid>one of the simplest strategies involves adding the dictionary entries directly to the training parallel corpus (tyers, 2009; schwenk et al, 2009).<papid> W09-0423 </papid></prevsent>
<prevsent>other approaches go beyond that.</prevsent>
</prevsection>
<citsent citstr=" W08-0328 ">
eisele et al (2008) <papid> W08-0328 </papid>first translate the sentences in the test set with an rbmt system, then apply the usual phrase-extraction algorithm over the resulting small parallel corpus, and finally add the obtained phrase pairs to the original phrase table.</citsent>
<aftsection>
<nextsent>it is worth noting that neither of these two strategies guarantee that the multi-word expressions in the rbmt bilingual dictionary appearing in the sentences to translate will be translated as such because they may besplit into smaller units by the phrase-extraction algorithm.
</nextsent>
<nextsent>our approach overcomes this issue by adding the data obtained from the rbmt system directly to the phrase table.
</nextsent>
<nextsent>preliminary experiments withapertium data shows that our hybrid approach outperforms the one by eisele et al (2008) <papid> W08-0328 </papid>when translating spanish texts into english.</nextsent>
<nextsent>shallow-transfer linguistic resource sas already mentioned, the apertium structural transfer detects sequences of lexical forms which needto be translated together to prevent them from being translated word for word, which would result in an incorrect translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2808">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> system training.  </section>
<citcontext>
<prevsection>
<prevsent>the apertium (forcada et al, 2011) engine and the linguistic resources for spanish english were downloaded from the apertium subversion repos itory.the linguistic data contains 326 228 entries in the bilingual dictionary, 106 first-level structural transfer rules, and 31 second-level rules.
</prevsent>
<prevsent>as entries in the bilingual dictionary contain mappings between sl and tl lemmas, when phrase pairs matching the bilingual dictionary are generated all the possible inflections of these lemmas are produced.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
we used the free/open-source pbsmt system moses (koehn et al, 2007), <papid> P07-2045 </papid>together with the irstlm language modelling toolkit (federico etal., 2008), which was used to train 5-gram lan 1the corpora can be downloaded from http://www.</citsent>
<aftsection>
<nextsent>statmt.org/wmt11/translation-task.html.
</nextsent>
<nextsent>task corpus sentences language model europarl 2 015 440 news crawl 112 905 708 total 114 921 148 training europarl 1 786 594 news commentary 132 571 united nations 10 662 993 total 12 582 158 total clean 8 992 751 tuning newstest2008 2 051 test newstest2011 3 003 table 1: size of the corpora used in the experiments.the bilingual training corpora has been cleaned to remove empty parallel sentences and those which contain more than 40 tokens.guage model using interpolated kneser-ney discounting (goodman and chen, 1998).
</nextsent>
<nextsent>word alignments from the training parallel corpus were computed by means of giza++ (och and ney, 2003).<papid> J03-1002 </papid>the cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>decoding algorithm was chosen in order to speed-up the tuning step and the translation of the test set.</nextsent>
<nextsent>table 2 reports the translation performance as measured by bleu (papineni et al,2002), <papid> P02-1040 </papid>gtm (melamed et al, 2003) <papid> N03-2021 </papid>and me teor2 (banerjee and lavie, 2005) <papid> W05-0909 </papid>for apertium and the three systems presented in the previous section, as well as the size of the phrase table and the amount of unknown words in the test set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2811">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> system training.  </section>
<citcontext>
<prevsection>
<prevsent>statmt.org/wmt11/translation-task.html.
</prevsent>
<prevsent>task corpus sentences language model europarl 2 015 440 news crawl 112 905 708 total 114 921 148 training europarl 1 786 594 news commentary 132 571 united nations 10 662 993 total 12 582 158 total clean 8 992 751 tuning newstest2008 2 051 test newstest2011 3 003 table 1: size of the corpora used in the experiments.the bilingual training corpora has been cleaned to remove empty parallel sentences and those which contain more than 40 tokens.guage model using interpolated kneser-ney discounting (goodman and chen, 1998).
</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
word alignments from the training parallel corpus were computed by means of giza++ (och and ney, 2003).<papid> J03-1002 </papid>the cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>decoding algorithm was chosen in order to speed-up the tuning step and the translation of the test set.</citsent>
<aftsection>
<nextsent>table 2 reports the translation performance as measured by bleu (papineni et al,2002), <papid> P02-1040 </papid>gtm (melamed et al, 2003) <papid> N03-2021 </papid>and me teor2 (banerjee and lavie, 2005) <papid> W05-0909 </papid>for apertium and the three systems presented in the previous section, as well as the size of the phrase table and the amount of unknown words in the test set.</nextsent>
<nextsent>the hybrid approach outperforms the baseline pbsmt system in terms of the three evaluation metrics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2812">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>task corpus sentences language model europarl 2 015 440 news crawl 112 905 708 total 114 921 148 training europarl 1 786 594 news commentary 132 571 united nations 10 662 993 total 12 582 158 total clean 8 992 751 tuning newstest2008 2 051 test newstest2011 3 003 table 1: size of the corpora used in the experiments.the bilingual training corpora has been cleaned to remove empty parallel sentences and those which contain more than 40 tokens.guage model using interpolated kneser-ney discounting (goodman and chen, 1998).
</prevsent>
<prevsent>word alignments from the training parallel corpus were computed by means of giza++ (och and ney, 2003).<papid> J03-1002 </papid>the cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>decoding algorithm was chosen in order to speed-up the tuning step and the translation of the test set.</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
table 2 reports the translation performance as measured by bleu (papineni et al,2002), <papid> P02-1040 </papid>gtm (melamed et al, 2003) <papid> N03-2021 </papid>and me teor2 (banerjee and lavie, 2005) <papid> W05-0909 </papid>for apertium and the three systems presented in the previous section, as well as the size of the phrase table and the amount of unknown words in the test set.</citsent>
<aftsection>
<nextsent>the hybrid approach outperforms the baseline pbsmt system in terms of the three evaluation metrics.
</nextsent>
<nextsent>the confidence interval of the difference between them, computed by doing 1 000 iterations of paired 2modules exact, stem, synonym and paraphrase (denkowski and lavie, 2010) <papid> W10-1751 </papid>were used.</nextsent>
<nextsent>461 system bleu gtm meteor # of unknown words phrase table size baseline 28.06 52.40 47.27 1 447 254 693 494 ua-dict 28.58 52.55 47.41 1 274 255 860 346 ua 28.73 52.66 47.51 1 274 255 872 094apertium 23.89 50.71 45.65 4 064 table 2: case-insensitive bleu, gtm, and meteor scores obtained by the hybrid approach submitted to the wmt 2011 shared translation task (ua), reduced version of it whose phrase table is enriched using only bilingual dictionary entries (ua-dict), baseline pbsmt system trained with the same corpus (baseline), and apertium on the newstest2011 test set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2813">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>task corpus sentences language model europarl 2 015 440 news crawl 112 905 708 total 114 921 148 training europarl 1 786 594 news commentary 132 571 united nations 10 662 993 total 12 582 158 total clean 8 992 751 tuning newstest2008 2 051 test newstest2011 3 003 table 1: size of the corpora used in the experiments.the bilingual training corpora has been cleaned to remove empty parallel sentences and those which contain more than 40 tokens.guage model using interpolated kneser-ney discounting (goodman and chen, 1998).
</prevsent>
<prevsent>word alignments from the training parallel corpus were computed by means of giza++ (och and ney, 2003).<papid> J03-1002 </papid>the cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>decoding algorithm was chosen in order to speed-up the tuning step and the translation of the test set.</prevsent>
</prevsection>
<citsent citstr=" N03-2021 ">
table 2 reports the translation performance as measured by bleu (papineni et al,2002), <papid> P02-1040 </papid>gtm (melamed et al, 2003) <papid> N03-2021 </papid>and me teor2 (banerjee and lavie, 2005) <papid> W05-0909 </papid>for apertium and the three systems presented in the previous section, as well as the size of the phrase table and the amount of unknown words in the test set.</citsent>
<aftsection>
<nextsent>the hybrid approach outperforms the baseline pbsmt system in terms of the three evaluation metrics.
</nextsent>
<nextsent>the confidence interval of the difference between them, computed by doing 1 000 iterations of paired 2modules exact, stem, synonym and paraphrase (denkowski and lavie, 2010) <papid> W10-1751 </papid>were used.</nextsent>
<nextsent>461 system bleu gtm meteor # of unknown words phrase table size baseline 28.06 52.40 47.27 1 447 254 693 494 ua-dict 28.58 52.55 47.41 1 274 255 860 346 ua 28.73 52.66 47.51 1 274 255 872 094apertium 23.89 50.71 45.65 4 064 table 2: case-insensitive bleu, gtm, and meteor scores obtained by the hybrid approach submitted to the wmt 2011 shared translation task (ua), reduced version of it whose phrase table is enriched using only bilingual dictionary entries (ua-dict), baseline pbsmt system trained with the same corpus (baseline), and apertium on the newstest2011 test set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2814">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>task corpus sentences language model europarl 2 015 440 news crawl 112 905 708 total 114 921 148 training europarl 1 786 594 news commentary 132 571 united nations 10 662 993 total 12 582 158 total clean 8 992 751 tuning newstest2008 2 051 test newstest2011 3 003 table 1: size of the corpora used in the experiments.the bilingual training corpora has been cleaned to remove empty parallel sentences and those which contain more than 40 tokens.guage model using interpolated kneser-ney discounting (goodman and chen, 1998).
</prevsent>
<prevsent>word alignments from the training parallel corpus were computed by means of giza++ (och and ney, 2003).<papid> J03-1002 </papid>the cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>decoding algorithm was chosen in order to speed-up the tuning step and the translation of the test set.</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
table 2 reports the translation performance as measured by bleu (papineni et al,2002), <papid> P02-1040 </papid>gtm (melamed et al, 2003) <papid> N03-2021 </papid>and me teor2 (banerjee and lavie, 2005) <papid> W05-0909 </papid>for apertium and the three systems presented in the previous section, as well as the size of the phrase table and the amount of unknown words in the test set.</citsent>
<aftsection>
<nextsent>the hybrid approach outperforms the baseline pbsmt system in terms of the three evaluation metrics.
</nextsent>
<nextsent>the confidence interval of the difference between them, computed by doing 1 000 iterations of paired 2modules exact, stem, synonym and paraphrase (denkowski and lavie, 2010) <papid> W10-1751 </papid>were used.</nextsent>
<nextsent>461 system bleu gtm meteor # of unknown words phrase table size baseline 28.06 52.40 47.27 1 447 254 693 494 ua-dict 28.58 52.55 47.41 1 274 255 860 346 ua 28.73 52.66 47.51 1 274 255 872 094apertium 23.89 50.71 45.65 4 064 table 2: case-insensitive bleu, gtm, and meteor scores obtained by the hybrid approach submitted to the wmt 2011 shared translation task (ua), reduced version of it whose phrase table is enriched using only bilingual dictionary entries (ua-dict), baseline pbsmt system trained with the same corpus (baseline), and apertium on the newstest2011 test set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2815">
<title id=" W11-2157.xml">the universitat dalacant hybrid machine translation system for wmt 2011 </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>table 2 reports the translation performance as measured by bleu (papineni et al,2002), <papid> P02-1040 </papid>gtm (melamed et al, 2003) <papid> N03-2021 </papid>and me teor2 (banerjee and lavie, 2005) <papid> W05-0909 </papid>for apertium and the three systems presented in the previous section, as well as the size of the phrase table and the amount of unknown words in the test set.</prevsent>
<prevsent>the hybrid approach outperforms the baseline pbsmt system in terms of the three evaluation metrics.</prevsent>
</prevsection>
<citsent citstr=" W10-1751 ">
the confidence interval of the difference between them, computed by doing 1 000 iterations of paired 2modules exact, stem, synonym and paraphrase (denkowski and lavie, 2010) <papid> W10-1751 </papid>were used.</citsent>
<aftsection>
<nextsent>461 system bleu gtm meteor # of unknown words phrase table size baseline 28.06 52.40 47.27 1 447 254 693 494 ua-dict 28.58 52.55 47.41 1 274 255 860 346 ua 28.73 52.66 47.51 1 274 255 872 094apertium 23.89 50.71 45.65 4 064 table 2: case-insensitive bleu, gtm, and meteor scores obtained by the hybrid approach submitted to the wmt 2011 shared translation task (ua), reduced version of it whose phrase table is enriched using only bilingual dictionary entries (ua-dict), baseline pbsmt system trained with the same corpus (baseline), and apertium on the newstest2011 test set.
</nextsent>
<nextsent>the number of unknown words and the phrase table size are also reported when applicable.
</nextsent>
<nextsent>bootstrap re sampling (zhang et al, 2004) with p-level of 0.05, does not overlap with zero for any evaluation metric,3 which confirms that it is statistically significant.
</nextsent>
<nextsent>our hybrid approach also outperforms apertium in terms of the three evaluation metrics.4 however, the difference between our complete hybrid system and the version which only takes advantage of bilingual dictionary is not statistically significant for any metric.5the results show how the addition of rbmt generated data leads to an improvement over the baseline pbmst system, even though it was trained with very large parallel corpus and the proportion of entries from the apertium data in the phrase table is very small (0.46%).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2816">
<title id=" W11-2118.xml">the rwth system combination system for wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one (i.e. will give the best?
</prevsent>
<prevsent>output)?
</prevsent>
</prevsection>
<citsent citstr=" N07-2017 ">
this approach is inspired byirover (hillard et al, 2007).<papid> N07-2017 </papid></citsent>
<aftsection>
<nextsent>consensus translations from different settings of these approaches could then be combined again by an additional application of system combination ? which we refer to as meta combination (rosti et al, 2007a).
</nextsent>
<nextsent>these three approaches are described in more detail in section 2.
</nextsent>
<nextsent>in section 3 we describe how we tuned the parameters and decisions of our system combination approaches for wmt 2011.
</nextsent>
<nextsent>section 4 th enlists our experimental setup as well as the experimental results we obtained on the wmt 2011 system combination track.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2817">
<title id=" W11-2118.xml">the rwth system combination system for wmt 2011 </title>
<section> system combination algorithm (a2l).  </section>
<citcontext>
<prevsection>
<prevsent>since it is not clear which hypothesis should be primary, i. e. has the best?
</prevsent>
<prevsent>word order, we let several or all hypothesis play the role of the primary translation, and align all pairs of hypotheses (en, em); 6= m. the word alignment is trained in analogy to the alignment training procedure in statistical mt. the difference is that the two sentences that have to be aligned are in the same language.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
we use theibm model 1 (brown et al, 1993) <papid> J93-2003 </papid>and the hidden markov model (hmm, (vogel et al, 1996)) to estimate the alignment model.</citsent>
<aftsection>
<nextsent>the alignment training corpus is created from test corpus of effectively ?(n1) sentences translated by the involved mt engines.
</nextsent>
<nextsent>model parameters are trained iteratively using the giza++toolkit (och and ney, 2003).
</nextsent>
<nextsent>the training is performed in the directions em ? en and en ? em.
</nextsent>
<nextsent>the final alignments are determined using cost matrix for each sentence pair (em, en).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2819">
<title id=" W11-2118.xml">the rwth system combination system for wmt 2011 </title>
<section> tuning.  </section>
<citcontext>
<prevsection>
<prevsent># words #sys tune dev test fren 15670 11410 49832 25 deen 15508 10878 49395 24 esen 15989 11234 50612 15 # sent 609 394 2000
</prevsent>
<prevsent>3.1 feature weights.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for lattice rescoring, we selected linear combination of bleu (papineni et al, 2002) <papid> P02-1040 </papid>and ter (snover et al, 2006) as optimization criterion, ??</citsent>
<aftsection>
<nextsent>:= argmax?
</nextsent>
<nextsent>{bleu ? ter} for the a2l engine, based on previous experience (mauser et al., 2008).
</nextsent>
<nextsent>to achieve more stable results, we usethe case-insensitive variants for both measures, despite the explicit use of case information in thepipeline.
</nextsent>
<nextsent>system weights were tuned to this criterion using the downhill simplex method.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2820">
<title id=" W11-2141.xml">stochastic parse tree selection for an existing rbmt system </title>
<section> system architecture.  </section>
<citcontext>
<prevsection>
<prevsent>as additional feature, we chose to use the tree edit distance of each analysis candidate to stochastic parse tree.
</prevsent>
<prevsent>an advantage of stochastic parsing lies in the fact that parsers from this class can deal very well even with ungrammatical or unknown output, which we have seen is problematic for rule base parser.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we decided to make use of the stanford parser as described in (klein and manning, 2003),<papid> P03-1054 </papid>which uses an un lexicalised probabilistic context free grammar that was trained on the penn tree bank2.</citsent>
<aftsection>
<nextsent>we parse the original source sentence with this pcfg grammar to get stochastic parse tree that can be compared to the trees from the lucy analysis forest.
</nextsent>
<nextsent>in our experiments, we compare the stochastic parse tree with the alternatives given by lucy lt. tree comparison is implemented based on the tree edit distance, as originally defined in (zhang andshasha, 1989).
</nextsent>
<nextsent>in analogy to the word editor lev 2further experiments with different grammars are currently on-going.
</nextsent>
<nextsent>best analysis tree percentage default (id=1) 42 (61.76%) alternative (id=2-7) 26 (38.24%) table 1: evaluation of analysis forests enshtein distance, the distance between two trees is the number of editing actions that are required to transform the first tree into the second tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2821">
<title id=" W12-0901.xml">distinguishing contact induced change from language drift in genetically related languages </title>
<section> evolutionary change in relations.  </section>
<citcontext>
<prevsection>
<prevsent>if single link is added to the phonetic relation, then all lexical meanings expressed using that phoneme-in-context can now realise it with the new phone.
</prevsent>
<prevsent>this multiplier effect on changes means single sound change scan have disproportionate effect on the similarity of cognate forms in two languages.
</prevsent>
</prevsection>
<citsent citstr=" P06-1035 ">
ellison and kirby (2006) <papid> P06-1035 </papid>presented similarity measure which bypasses this superficial difference: pairs of domain elements are compared for the similarity of the corresponding sets of range elements, and these similarity values are then compared cross-linguistically.</citsent>
<aftsection>
<nextsent>this measure mitigates the effect of global substitutions.
</nextsent>
<nextsent>the iterated application of local mutational changes to language structures is called drift.
</nextsent>
<nextsent>in traditional models of language history, it is the primary mechanism for explaining difference, while the shared parent language is the primary explanation of similarity.
</nextsent>
<nextsent>3.3 contact-induced change.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2822">
<title id=" W12-1806.xml">the future of spoken dialogue systems is in their past longterm adaptive conversational assistants </title>
<section> long-term adaptive ....  </section>
<citcontext>
<prevsection>
<prevsent>interaction with these systems must be less driven by fixed system-intiative, and be more conversational: ? user and system must be able to mean more than they say, by making use of context, both from 11the ongoing conversation as well as from the common ground that was built up over previous interaction.
</prevsent>
<prevsent>systems should be responsive, incremental, providing feedback where required; realising tight interaction loop, not strict turn-based exchanges.
</prevsent>
</prevsection>
<citsent citstr=" W04-2325 ">
things will go wrong, so error handling needs to be graceful and natural, using the full range of conversational repair devices (schlangen, 2004; <papid> W04-2325 </papid>purver, 2004); including handing off tasks to other modalities if expected success rate is low.</citsent>
<aftsection>
<nextsent>conversations express and project personality, emotionality, sociality; systems need to model the dynamics of this as part of their modelling of the conversation.again, these are active areas of research (for responsive systems, see e.g.
</nextsent>
<nextsent>(skantze and schlangen, 2009; <papid> E09-1085 </papid>bu?</nextsent>
<nextsent>et al, 2010; schlangen et al, 2010); <papid> W10-4308 </papid>for error handling / acting under uncertainty, see e.g.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2823">
<title id=" W12-1806.xml">the future of spoken dialogue systems is in their past longterm adaptive conversational assistants </title>
<section> long-term adaptive ....  </section>
<citcontext>
<prevsection>
<prevsent>things will go wrong, so error handling needs to be graceful and natural, using the full range of conversational repair devices (schlangen, 2004; <papid> W04-2325 </papid>purver, 2004); including handing off tasks to other modalities if expected success rate is low.</prevsent>
<prevsent>conversations express and project personality, emotionality, sociality; systems need to model the dynamics of this as part of their modelling of the conversation.again, these are active areas of research (for responsive systems, see e.g.</prevsent>
</prevsection>
<citsent citstr=" E09-1085 ">
(skantze and schlangen, 2009; <papid> E09-1085 </papid>bu?</citsent>
<aftsection>
<nextsent>et al, 2010; schlangen et al, 2010); <papid> W10-4308 </papid>for error handling / acting under uncertainty, see e.g.</nextsent>
<nextsent>(williams and young, 2007); for social aspects of dialogue, see e.g.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2824">
<title id=" W12-1806.xml">the future of spoken dialogue systems is in their past longterm adaptive conversational assistants </title>
<section> long-term adaptive ....  </section>
<citcontext>
<prevsection>
<prevsent>conversations express and project personality, emotionality, sociality; systems need to model the dynamics of this as part of their modelling of the conversation.again, these are active areas of research (for responsive systems, see e.g.
</prevsent>
<prevsent>(skantze and schlangen, 2009; <papid> E09-1085 </papid>bu?</prevsent>
</prevsection>
<citsent citstr=" W10-4308 ">
et al, 2010; schlangen et al, 2010); <papid> W10-4308 </papid>for error handling / acting under uncertainty, see e.g.</citsent>
<aftsection>
<nextsent>(williams and young, 2007); for social aspects of dialogue, see e.g.
</nextsent>
<nextsent>(kopp, 2010)); pulling them together in this kind of application will likely provide new challenges and insights for all of them.
</nextsent>
<nextsent>4 ...
</nextsent>
<nextsent>assistants of course, the systems will need to provide actual services, for it at all to come to repeated conversations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2825">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>components of these interactive systems, including nlg systems, have so far treated the utterance as the smallest processing unit that triggers module into action.
</prevsent>
<prevsent>more recently,work on incremental systems has shown that processing smaller chunks?
</prevsent>
</prevsection>
<citsent citstr=" E09-1085 ">
of user input can improve the user experience (skantze and schlangen, 2009; <papid> E09-1085 </papid>buss et al , 2010; skantze and hjalmarsson, 2010;<papid> W10-4301 </papid>baumann et al , 2011).</citsent>
<aftsection>
<nextsent>incrementality in nlg systems enables the system designer to model several dialogue phenomena that play vital role in human discourse (levelt, 1989) but have so far been absent from nlg systems.
</nextsent>
<nextsent>these include more natural turn-taking through rapid system responses, grounding through the generation of backchannelsand feedback, and barge-ins (from both user and sys tem).
</nextsent>
<nextsent>in addition, corrections and self-correctionsthrough constant monitoring of user and system utterances play an important role, enabling the system to recover smoothly from recognition error or change in the users preferences.
</nextsent>
<nextsent>some examples of the phenomena we are targeting are given in fig.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2826">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>components of these interactive systems, including nlg systems, have so far treated the utterance as the smallest processing unit that triggers module into action.
</prevsent>
<prevsent>more recently,work on incremental systems has shown that processing smaller chunks?
</prevsent>
</prevsection>
<citsent citstr=" W10-4301 ">
of user input can improve the user experience (skantze and schlangen, 2009; <papid> E09-1085 </papid>buss et al , 2010; skantze and hjalmarsson, 2010;<papid> W10-4301 </papid>baumann et al , 2011).</citsent>
<aftsection>
<nextsent>incrementality in nlg systems enables the system designer to model several dialogue phenomena that play vital role in human discourse (levelt, 1989) but have so far been absent from nlg systems.
</nextsent>
<nextsent>these include more natural turn-taking through rapid system responses, grounding through the generation of backchannelsand feedback, and barge-ins (from both user and sys tem).
</nextsent>
<nextsent>in addition, corrections and self-correctionsthrough constant monitoring of user and system utterances play an important role, enabling the system to recover smoothly from recognition error or change in the users preferences.
</nextsent>
<nextsent>some examples of the phenomena we are targeting are given in fig.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2828">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1: example phenomena generated with the trained policy.
</prevsent>
<prevsent>the agent has learnt to produce backchannelswhen the user pauses, monitor and (self-)correct its out put, and present information according to its confidence.
</prevsent>
</prevsection>
<citsent citstr=" P10-1103 ">
pro aches to nlg have also been developed and shown to outperform the previous (handcrafted, rule-based) methods for specific problems (rieser et al ., 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010; <papid> P10-1008 </papid>dethlefs and cuayahuitl, 2011).</citsent>
<aftsection>
<nextsent>this work has established that nlg can fruitfully be treated as data-driven statistical planning process, where the objective isto maximise expected utility of the generated utterances (van deemter, 2009), by adapting them to the context and user.
</nextsent>
<nextsent>statistical approaches to sentence planning and surface realisation have also been explored (stent et al , 2004; <papid> P04-1011 </papid>belz, 2008; mairesse et al ., 2010; <papid> P10-1157 </papid>angeli et al , 2010).<papid> D10-1049 </papid></nextsent>
<nextsent>the advantages of data-driven methods are that nlg is more robust in the face of noise, can adapt to various contexts and, trained on real data, can produce more natural and desirable variation in system utterances.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2829">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 1: example phenomena generated with the trained policy.
</prevsent>
<prevsent>the agent has learnt to produce backchannelswhen the user pauses, monitor and (self-)correct its out put, and present information according to its confidence.
</prevsent>
</prevsection>
<citsent citstr=" P10-1008 ">
pro aches to nlg have also been developed and shown to outperform the previous (handcrafted, rule-based) methods for specific problems (rieser et al ., 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010; <papid> P10-1008 </papid>dethlefs and cuayahuitl, 2011).</citsent>
<aftsection>
<nextsent>this work has established that nlg can fruitfully be treated as data-driven statistical planning process, where the objective isto maximise expected utility of the generated utterances (van deemter, 2009), by adapting them to the context and user.
</nextsent>
<nextsent>statistical approaches to sentence planning and surface realisation have also been explored (stent et al , 2004; <papid> P04-1011 </papid>belz, 2008; mairesse et al ., 2010; <papid> P10-1157 </papid>angeli et al , 2010).<papid> D10-1049 </papid></nextsent>
<nextsent>the advantages of data-driven methods are that nlg is more robust in the face of noise, can adapt to various contexts and, trained on real data, can produce more natural and desirable variation in system utterances.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2831">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pro aches to nlg have also been developed and shown to outperform the previous (handcrafted, rule-based) methods for specific problems (rieser et al ., 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010; <papid> P10-1008 </papid>dethlefs and cuayahuitl, 2011).</prevsent>
<prevsent>this work has established that nlg can fruitfully be treated as data-driven statistical planning process, where the objective isto maximise expected utility of the generated utterances (van deemter, 2009), by adapting them to the context and user.</prevsent>
</prevsection>
<citsent citstr=" P04-1011 ">
statistical approaches to sentence planning and surface realisation have also been explored (stent et al , 2004; <papid> P04-1011 </papid>belz, 2008; mairesse et al ., 2010; <papid> P10-1157 </papid>angeli et al , 2010).<papid> D10-1049 </papid></citsent>
<aftsection>
<nextsent>the advantages of data-driven methods are that nlg is more robust in the face of noise, can adapt to various contexts and, trained on real data, can produce more natural and desirable variation in system utterances.
</nextsent>
<nextsent>this paper describes an initial investigation into novel nlg architecture that combines incremental processing with statistical optimisation.
</nextsent>
<nextsent>in order to move away from conventional strict-turn taking, we have to be able to model the complex interactions observed in human-human conversation.
</nextsent>
<nextsent>doing this in deterministic fashion through hand-written rules would be time consuming and potentially inaccurate, with no guarantee of optimality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2832">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pro aches to nlg have also been developed and shown to outperform the previous (handcrafted, rule-based) methods for specific problems (rieser et al ., 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010; <papid> P10-1008 </papid>dethlefs and cuayahuitl, 2011).</prevsent>
<prevsent>this work has established that nlg can fruitfully be treated as data-driven statistical planning process, where the objective isto maximise expected utility of the generated utterances (van deemter, 2009), by adapting them to the context and user.</prevsent>
</prevsection>
<citsent citstr=" P10-1157 ">
statistical approaches to sentence planning and surface realisation have also been explored (stent et al , 2004; <papid> P04-1011 </papid>belz, 2008; mairesse et al ., 2010; <papid> P10-1157 </papid>angeli et al , 2010).<papid> D10-1049 </papid></citsent>
<aftsection>
<nextsent>the advantages of data-driven methods are that nlg is more robust in the face of noise, can adapt to various contexts and, trained on real data, can produce more natural and desirable variation in system utterances.
</nextsent>
<nextsent>this paper describes an initial investigation into novel nlg architecture that combines incremental processing with statistical optimisation.
</nextsent>
<nextsent>in order to move away from conventional strict-turn taking, we have to be able to model the complex interactions observed in human-human conversation.
</nextsent>
<nextsent>doing this in deterministic fashion through hand-written rules would be time consuming and potentially inaccurate, with no guarantee of optimality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2833">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pro aches to nlg have also been developed and shown to outperform the previous (handcrafted, rule-based) methods for specific problems (rieser et al ., 2010; <papid> P10-1103 </papid>janarthanam and lemon, 2010; <papid> P10-1008 </papid>dethlefs and cuayahuitl, 2011).</prevsent>
<prevsent>this work has established that nlg can fruitfully be treated as data-driven statistical planning process, where the objective isto maximise expected utility of the generated utterances (van deemter, 2009), by adapting them to the context and user.</prevsent>
</prevsection>
<citsent citstr=" D10-1049 ">
statistical approaches to sentence planning and surface realisation have also been explored (stent et al , 2004; <papid> P04-1011 </papid>belz, 2008; mairesse et al ., 2010; <papid> P10-1157 </papid>angeli et al , 2010).<papid> D10-1049 </papid></citsent>
<aftsection>
<nextsent>the advantages of data-driven methods are that nlg is more robust in the face of noise, can adapt to various contexts and, trained on real data, can produce more natural and desirable variation in system utterances.
</nextsent>
<nextsent>this paper describes an initial investigation into novel nlg architecture that combines incremental processing with statistical optimisation.
</nextsent>
<nextsent>in order to move away from conventional strict-turn taking, we have to be able to model the complex interactions observed in human-human conversation.
</nextsent>
<nextsent>doing this in deterministic fashion through hand-written rules would be time consuming and potentially inaccurate, with no guarantee of optimality.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2834">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> previous work: incremental processing.  </section>
<citcontext>
<prevsection>
<prevsent>architectures the smallest unit of processing in incremental systems is called incremental unit (iu).
</prevsent>
<prevsent>its instantia tion depends on the particular processing module.
</prevsent>
</prevsection>
<citsent citstr=" W11-2015 ">
in speech recognition, ius can correspond to phoneme sequences that are mapped onto words (baumann and schlangen, 2011).<papid> W11-2015 </papid></citsent>
<aftsection>
<nextsent>in dialogue management, ius can correspond to dialogue acts (buss et al , 2010).
</nextsent>
<nextsent>in speech synthesis, ius can correspond to speech unit sequences which are mapped to segments and speech plans (skantze and hjalmarsson, 2010).<papid> W10-4301 </papid></nextsent>
<nextsent>iusare typically linked to other ius by two types of rela tions: same-level links connect ius sequentially and express relationships at the same level; grounded-in links express hierarchical relations between ius.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2838">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> previous work: incremental processing.  </section>
<citcontext>
<prevsection>
<prevsent>iusare typically linked to other ius by two types of rela tions: same-level links connect ius sequentially and express relationships at the same level; grounded-in links express hierarchical relations between ius.
</prevsent>
<prevsent>2.1 buffer-based incremental processing.
</prevsent>
</prevsection>
<citsent citstr=" E09-1081 ">
a general abstract model of incremental processing based on buffers and processor was developed by schlangen and skantze (2009) <papid> E09-1081 </papid>and is illustrated in figure 2.</citsent>
<aftsection>
<nextsent>it assumes that the left buffer of module, such as the nlg module, receives ius from one or more other processing modules, such as the dialogue manager.
</nextsent>
<nextsent>these input ius are then passed on to the processor, where they are mapped to corresponding (higher-level) ius.
</nextsent>
<nextsent>for an nlg module, this could be mapping from the dialogue act present(cuisine=indian) to the realisation they serve indian food?.
</nextsent>
<nextsent>the resulting ius are passed on to the right buffer which co-incides with the left buffer of another module (for example the speech synthesis module in our example).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2843">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> previous work: incremental processing.  </section>
<citcontext>
<prevsection>
<prevsent>we follow baumann et al  (2011) in calling them beat-driven?
</prevsent>
<prevsent>systems.
</prevsent>
</prevsection>
<citsent citstr=" N09-1071 ">
raux and eskenazi(2009) <papid> N09-1071 </papid>use cost matrix and decision theoretic principles to optimise turn-taking in dialogue system under the constraint that users prefer no gaps and no overlap at turn boundaries.</citsent>
<aftsection>
<nextsent>devault et al  (2009) <papid> W09-3902 </papid>use maximum entropy classification to support responsive overlap in an incremental system by predicting the completions of user utterances.</nextsent>
<nextsent>2.3 decision-making in incremental systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2844">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> previous work: incremental processing.  </section>
<citcontext>
<prevsection>
<prevsent>systems.
</prevsent>
<prevsent>raux and eskenazi(2009) <papid> N09-1071 </papid>use cost matrix and decision theoretic principles to optimise turn-taking in dialogue system under the constraint that users prefer no gaps and no overlap at turn boundaries.</prevsent>
</prevsection>
<citsent citstr=" W09-3902 ">
devault et al  (2009) <papid> W09-3902 </papid>use maximum entropy classification to support responsive overlap in an incremental system by predicting the completions of user utterances.</citsent>
<aftsection>
<nextsent>2.3 decision-making in incremental systems.
</nextsent>
<nextsent>some of the main advantages of the buffer- and isu based approaches include their inherently incremental mechanisms for updating and revising system hypotheses.
</nextsent>
<nextsent>they are able to process input of varying size and type and, at the same time, produce arbitrarily complex output which is monitored and can be modified at any time.
</nextsent>
<nextsent>on the other hand, current models are based on deterministic decision making and thus share some of the same drawbacks that non incremental systems have faced: (1) they relyon hand-written rules which are time-consuming and expensive to produce, (2) they do not provide mechanism to deal with uncertainty introduced by varying user behaviour, and (3) they are unable to generalise and adapt flexibly to unseen situations.for nlg in particular, we have seen that incrementality can enhance the responsiveness of systems and facilitate turn-taking.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2859">
<title id=" W12-1509.xml">optimising incremental generation for spoken dialogue systems reducing the need for fillers </title>
<section> conclusion and future directions.  </section>
<citcontext>
<prevsection>
<prevsent>(skantze and hjalmarsson, 2010).<papid> W10-4301 </papid></prevsent>
<prevsent>our work avoids the need for these fillers by content reordering.since this paper has focused on proof-of concept study, our goal has not been to demonstrate the superiority of automatic optimisation over handcrafted behaviour.</prevsent>
</prevsection>
<citsent citstr=" W11-2011 ">
previous studies have shown the advantages of optimisation (janarthanam and lemon, 2010; <papid> P10-1008 </papid>rieser et al , 2010; <papid> P10-1103 </papid>dethlefs et al ,2011).<papid> W11-2011 </papid></citsent>
<aftsection>
<nextsent>rather, our main goal has been to demonstrate that incremental nlg can be phrased as an optimisation problem and that reasonable action policies can be learnt so that an application within an incremental framework is feasible.
</nextsent>
<nextsent>this observation allows us to take incremental systems, which so farhave been restricted to deterministic decision making, one step further in terms of their adaptability and flexibility.
</nextsent>
<nextsent>to demonstrate the effectiveness of synergy between rl and incremental nlg on large scale, we would like to train fully incremental nlg system from human data using data-driven reward function.
</nextsent>
<nextsent>further, an evaluation with human users will be required to verify the advantages of different policies for information presentation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2860">
<title id=" W12-2017.xml">generating grammar exercises </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 reports on an evaluation of the exercise items produced and on the results obtained.
</prevsent>
<prevsent>section 6 concludes.
</prevsent>
</prevsection>
<citsent citstr=" W06-1416 ">
a prominent strand of research in computer aided language learning (call) addresses the automation of exercise specifications relying on natural language processing (nlp) techniques (mitkov etal., 2006; heilman and eskenazi, 2007; karamanis et al, 2006; <papid> W06-1416 </papid>chao-lin et al, 2005; coniam, 1997; sumita et al, 2005; <papid> W05-0210 </papid>simon smith, 2010; lin et al, 2007; lee and seneff, 2007).</citsent>
<aftsection>
<nextsent>mostly, this work targets the automatic generation of so-called objective test items i.e., test items such as multiple choice questions, fill in the blank and cloze exercise items, whose answer is strongly constrained and can therefore be predicted and checked with high accuracy.
</nextsent>
<nextsent>these approaches use large corpora and machine learning techniques to automatically generate the stems (exercise sentences), the keys (correct an swers) and the dis tractors (incorrect answers) that are required by such test items.
</nextsent>
<nextsent>among these approaches, some proposals target grammar exercises.
</nextsent>
<nextsent>thus, (chen et al, 2006) <papid> P06-4001 </papid>describes system called fast which supports the semi-automatic generation of multiple-choice and error detection exercises while (aldabe et al, 2006)presents the arikiturri automatic question generator for constructing fill-in-the-blank, word formation, multiple choice and error detection exercises.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2861">
<title id=" W12-2017.xml">generating grammar exercises </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 reports on an evaluation of the exercise items produced and on the results obtained.
</prevsent>
<prevsent>section 6 concludes.
</prevsent>
</prevsection>
<citsent citstr=" W05-0210 ">
a prominent strand of research in computer aided language learning (call) addresses the automation of exercise specifications relying on natural language processing (nlp) techniques (mitkov etal., 2006; heilman and eskenazi, 2007; karamanis et al, 2006; <papid> W06-1416 </papid>chao-lin et al, 2005; coniam, 1997; sumita et al, 2005; <papid> W05-0210 </papid>simon smith, 2010; lin et al, 2007; lee and seneff, 2007).</citsent>
<aftsection>
<nextsent>mostly, this work targets the automatic generation of so-called objective test items i.e., test items such as multiple choice questions, fill in the blank and cloze exercise items, whose answer is strongly constrained and can therefore be predicted and checked with high accuracy.
</nextsent>
<nextsent>these approaches use large corpora and machine learning techniques to automatically generate the stems (exercise sentences), the keys (correct an swers) and the dis tractors (incorrect answers) that are required by such test items.
</nextsent>
<nextsent>among these approaches, some proposals target grammar exercises.
</nextsent>
<nextsent>thus, (chen et al, 2006) <papid> P06-4001 </papid>describes system called fast which supports the semi-automatic generation of multiple-choice and error detection exercises while (aldabe et al, 2006)presents the arikiturri automatic question generator for constructing fill-in-the-blank, word formation, multiple choice and error detection exercises.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2862">
<title id=" W12-2017.xml">generating grammar exercises </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these approaches use large corpora and machine learning techniques to automatically generate the stems (exercise sentences), the keys (correct an swers) and the dis tractors (incorrect answers) that are required by such test items.
</prevsent>
<prevsent>among these approaches, some proposals target grammar exercises.
</prevsent>
</prevsection>
<citsent citstr=" P06-4001 ">
thus, (chen et al, 2006) <papid> P06-4001 </papid>describes system called fast which supports the semi-automatic generation of multiple-choice and error detection exercises while (aldabe et al, 2006)presents the arikiturri automatic question generator for constructing fill-in-the-blank, word formation, multiple choice and error detection exercises.</citsent>
<aftsection>
<nextsent>these approaches are similar to the approach we propose.
</nextsent>
<nextsent>first, bank of sentences is built which are automatically annotated with syntactic and morphosyntactic information.
</nextsent>
<nextsent>second, sentences are retrieved from this bank based on their annotation and on the linguistic phenomena the exercise is meant to illustrate.
</nextsent>
<nextsent>third, the exercise question is constructed from the retrieved sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2863">
<title id=" W11-2507.xml">experimenting with transitive verbs in a disco cat </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>formal and distributional semantic models offer complementary benefits in modelingmeaning.
</prevsent>
<prevsent>the categorical compositional distributional model of meaning of coecke et al (2010) (abbreviated to disco cat in the title)combines aspects of both to provide general framework in which meanings of words, obtained distributionally, are composed using methods from the logical setting to form sentence meaning.
</prevsent>
</prevsection>
<citsent citstr=" W11-0114 ">
concrete consequences of this general abstract setting and applications to empirical data are under active study (grefen stette et al, 2011; <papid> W11-0114 </papid>grefenstette and sadrzadeh, 2011).<papid> D11-1129 </papid></citsent>
<aftsection>
<nextsent>in this paper, we extend this study by examining transitive verbs, represented as matrices in discocat.
</nextsent>
<nextsent>we discuss three ways of constructing such matrices, and evaluate each method in disambiguation task developed by grefenstette and sadrzadeh (2011).<papid> D11-1129 </papid></nextsent>
<nextsent>the categorical distributional compositional model of meaning of coecke et al (2010) combines themodularity of formal semantic models with the empirical nature of vector space models of lexical se mantics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2864">
<title id=" W11-2507.xml">experimenting with transitive verbs in a disco cat </title>
<section> abstract </section>
<citcontext>
<prevsection>
<prevsent>formal and distributional semantic models offer complementary benefits in modelingmeaning.
</prevsent>
<prevsent>the categorical compositional distributional model of meaning of coecke et al (2010) (abbreviated to disco cat in the title)combines aspects of both to provide general framework in which meanings of words, obtained distributionally, are composed using methods from the logical setting to form sentence meaning.
</prevsent>
</prevsection>
<citsent citstr=" D11-1129 ">
concrete consequences of this general abstract setting and applications to empirical data are under active study (grefen stette et al, 2011; <papid> W11-0114 </papid>grefenstette and sadrzadeh, 2011).<papid> D11-1129 </papid></citsent>
<aftsection>
<nextsent>in this paper, we extend this study by examining transitive verbs, represented as matrices in discocat.
</nextsent>
<nextsent>we discuss three ways of constructing such matrices, and evaluate each method in disambiguation task developed by grefenstette and sadrzadeh (2011).<papid> D11-1129 </papid></nextsent>
<nextsent>the categorical distributional compositional model of meaning of coecke et al (2010) combines themodularity of formal semantic models with the empirical nature of vector space models of lexical se mantics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2869">
<title id=" W11-2507.xml">experimenting with transitive verbs in a disco cat </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>the categorical distributional compositional model of meaning of coecke et al (2010) combines themodularity of formal semantic models with the empirical nature of vector space models of lexical semantics.
</prevsent>
<prevsent>the meaning of sentence is defined to be the application of its grammatical structure represented in type-logical modelto the kro necker product of the meanings of its words, as computed in distributional model.
</prevsent>
</prevsection>
<citsent citstr=" D10-1115 ">
the concrete and experimental consequences of this setting, and other models that aim to bring together the logical and distributional approaches, are active topics in current natural language semantics research, e.g. see (grefenstette et al, 2011; <papid> W11-0114 </papid>grefenstette and sadrzadeh, 2011; <papid> D11-1129 </papid>clark et al, 2010; baroni and zamparelli, 2010; <papid> D10-1115 </papid>guevara, 2010; mitchell and la pata, 2008).<papid> P08-1028 </papid>in this paper, we focus on our recent concrete dis cocat model (grefenstette and sadrzadeh, 2011) <papid> D11-1129 </papid>and in particular on nouns composed with transitive verbs.</citsent>
<aftsection>
<nextsent>whereby the meaning of transitive sentence sub tverb obj?
</nextsent>
<nextsent>is obtained by taking the component wise multiplication of the matrix of the verb with the kron ecker product of the vectors of subject and object: ?????????
</nextsent>
<nextsent>sub tverb obj = tverb ( ??
</nextsent>
<nextsent>sub?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2870">
<title id=" W11-2507.xml">experimenting with transitive verbs in a disco cat </title>
<section> background </section>
<citcontext>
<prevsection>
<prevsent>the categorical distributional compositional model of meaning of coecke et al (2010) combines themodularity of formal semantic models with the empirical nature of vector space models of lexical semantics.
</prevsent>
<prevsent>the meaning of sentence is defined to be the application of its grammatical structure represented in type-logical modelto the kro necker product of the meanings of its words, as computed in distributional model.
</prevsent>
</prevsection>
<citsent citstr=" P08-1028 ">
the concrete and experimental consequences of this setting, and other models that aim to bring together the logical and distributional approaches, are active topics in current natural language semantics research, e.g. see (grefenstette et al, 2011; <papid> W11-0114 </papid>grefenstette and sadrzadeh, 2011; <papid> D11-1129 </papid>clark et al, 2010; baroni and zamparelli, 2010; <papid> D10-1115 </papid>guevara, 2010; mitchell and la pata, 2008).<papid> P08-1028 </papid>in this paper, we focus on our recent concrete dis cocat model (grefenstette and sadrzadeh, 2011) <papid> D11-1129 </papid>and in particular on nouns composed with transitive verbs.</citsent>
<aftsection>
<nextsent>whereby the meaning of transitive sentence sub tverb obj?
</nextsent>
<nextsent>is obtained by taking the component wise multiplication of the matrix of the verb with the kron ecker product of the vectors of subject and object: ?????????
</nextsent>
<nextsent>sub tverb obj = tverb ( ??
</nextsent>
<nextsent>sub?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2882">
<title id=" W12-1819.xml">towards quality adaptive spoken dialogue management </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>finally, section 5 concludes this work.
</prevsent>
<prevsent>in recent years, several studies have been published on determining the qualitative performance of asds.
</prevsent>
</prevsection>
<citsent citstr=" W09-3926 ">
engelbrecht et al (2009) <papid> W09-3926 </papid>predicted user satisfaction on five-point scale at any point within the dialogue using hidden markov models (hmms).</citsent>
<aftsection>
<nextsent>evaluation was based on labels the users applied themselves during wizard-of-oz experiment.
</nextsent>
<nextsent>to guarantee for comparable conditions, the dialogue flow was controlled by predefined scenarios creating transcripts with equal length for each scenario.
</nextsent>
<nextsent>further work based on hmms was presented by higashinaka et al (2010).<papid> W10-4304 </papid></nextsent>
<nextsent>the hmm was trained on us rated at each exchange.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2883">
<title id=" W12-1819.xml">towards quality adaptive spoken dialogue management </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>evaluation was based on labels the users applied themselves during wizard-of-oz experiment.
</prevsent>
<prevsent>to guarantee for comparable conditions, the dialogue flow was controlled by predefined scenarios creating transcripts with equal length for each scenario.
</prevsent>
</prevsection>
<citsent citstr=" W10-4304 ">
further work based on hmms was presented by higashinaka et al (2010).<papid> W10-4304 </papid></citsent>
<aftsection>
<nextsent>the hmm was trained on us rated at each exchange.
</nextsent>
<nextsent>these exchange ratings were derived from ratings for the whole dialogue.
</nextsent>
<nextsent>the authors compare their approach with hmms trained on manually annotated exchanges achieving better performance for the latter.
</nextsent>
<nextsent>49 in order to predict us, hara et al (2010) created n-gram models from dialogue acts (da).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2884">
<title id=" W12-1819.xml">towards quality adaptive spoken dialogue management </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>based on dialogues from real users interacting with music retrieval system, overall ratings for the whole dialogue have been labeled on five point scale after the interaction.
</prevsent>
<prevsent>an accuracy (i.e., rate of correctly predicted ratings) of 34% by 3-gram model was the best performance which could be achieved.
</prevsent>
</prevsection>
<citsent citstr=" W11-2020 ">
dealing with true user satisfaction, schmitt et al presented their work about statistical classification methods for automatic recognition of us (schmitt et al, 2011<papid> W11-2020 </papid>b).</citsent>
<aftsection>
<nextsent>the data was collected in lab study where the users themselves had to rate the conversation during the ongoing dialogue.
</nextsent>
<nextsent>labels were applied on scale from 1 to 5.
</nextsent>
<nextsent>performing automatic classification using support vector machine (svm), they achieved an unweighted average recall (uar) of 49.2 (i.e., average rate of correctly predicted ratings, compensated for unbalanced data).
</nextsent>
<nextsent>an approach for affective dialogue modeling based on partially observable markov decision processes (pomdps) was presented by bui et al (2007).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2891">
<title id=" W12-1630.xml">adapting to multiple affective states in spoken dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we are now taking the next step by incorporating adaptation to second user affective state: user disengagement.
</prevsent>
<prevsent>we target user disengagement for two reasons: first, our prior manual annotation showed disengagement and uncertainty to be the most frequent user affective states that occur in our system,and second, our prior analyses show that the occurrence of disengagement is negatively correlated with task success and user satisfaction (forbes-riley and litman, 2012).2 thus, we hypothesized that providing appropriate system responses to both affective states could have multiple benefits: 1) reduce the frequency of one or both states, 2) break?
</prevsent>
</prevsection>
<citsent citstr=" W09-3927 ">
the nega 2redesigning system in light of cor relational analyses can improve performance (rotaru and litman, 2009).<papid> W09-3927 </papid></citsent>
<aftsection>
<nextsent>217tive correlations with performance, and 3) yield further improvements in global and local performance.in this paper, we test these hypotheses, presenting the results of controlled experiment evaluatinga wizard-of-oz version of our spoken dialogue computer tutor that adapts to both user uncertainty anduser disengagement (section 3).
</nextsent>
<nextsent>although we address these states within the tutoring domain, speech researchers from other domains and applications arealso focusing on detecting and adapting to user disengagement (e.g., (schuller et al, 2010; wang and hirschberg, 2011)) <papid> W11-2018 </papid>and uncertainty (e.g.</nextsent>
<nextsent>(pon-barry and shieber, 2011; paek and ju, 2008)) to improve system performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2893">
<title id=" W12-1630.xml">adapting to multiple affective states in spoken dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the nega 2redesigning system in light of cor relational analyses can improve performance (rotaru and litman, 2009).<papid> W09-3927 </papid></prevsent>
<prevsent>217tive correlations with performance, and 3) yield further improvements in global and local performance.in this paper, we test these hypotheses, presenting the results of controlled experiment evaluatinga wizard-of-oz version of our spoken dialogue computer tutor that adapts to both user uncertainty anduser disengagement (section 3).</prevsent>
</prevsection>
<citsent citstr=" W11-2018 ">
although we address these states within the tutoring domain, speech researchers from other domains and applications arealso focusing on detecting and adapting to user disengagement (e.g., (schuller et al, 2010; wang and hirschberg, 2011)) <papid> W11-2018 </papid>and uncertainty (e.g.</citsent>
<aftsection>
<nextsent>(pon-barry and shieber, 2011; paek and ju, 2008)) to improve system performance.
</nextsent>
<nextsent>our results should be of interest not only to these researchers but also more generally to any researchers working towards comprehensive affect-adaptive spoken dialogue systems.
</nextsent>
<nextsent>in particular, our results show that iteratively adding new affect adaptations to an existing affect-adaptive system can yield performance improvements.
</nextsent>
<nextsent>wefind no increase (but also no decrease) in task success or user satisfaction, but we do find an increase in motivation for users who most frequently received the disengagement adaptation (section 4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2895">
<title id=" W12-1630.xml">adapting to multiple affective states in spoken dialogue </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>further more, we find that responding to disengagement breaks?
</prevsent>
<prevsent>negative correlations with task success anduser satisfaction (section 5), and also yields reduction both in uncertainty levels (section 4) and in the likelihood of continued disengagement (section 6).
</prevsent>
</prevsection>
<citsent citstr=" W09-3933 ">
user disengagement is highly undesirable because of its potential to increase dissatisfaction and task failure, and there is growing awareness of its potential to negatively impact commercial applica tions; thus there has been substantial prior work focused on detecting disengagement (along with the closely related states of boredom and lack of interest) (e.g., (schuller et al, 2010; wang and hirschberg, 2011; <papid> W11-2018 </papid>bohus and horvitz, 2009)).<papid> W09-3933 </papid></citsent>
<aftsection>
<nextsent>to date, however, only few disengagement-adaptive systems have been evaluated, and within the tutoring domain these have focused on only one disengagement behavior: gaming.
</nextsent>
<nextsent>for example, responding to gaming with supplementary material reduced gaming and improved task success for users who most frequently gamed (baker et al, 2006), while adding progress reports and productive learning tips at the end of problems (i.e., without specifically targeting gaming instances) increased task success, engagement, and user satisfaction (arroyo et al, 2007).
</nextsent>
<nextsent>our research builds on this work but is novel in thatwe focus on speech and dialogue-based disengagement and on adapting to multiple affective states.more generally, while substantial spoken dialogue and affective systems research has shown that users display range of affective states when interacting with system (e.g.
</nextsent>
<nextsent>(schuller et al, 2009; conati and maclaren, 2009)), to date only few systems adapt to multiple affective states(e.g., (dmello et al, 2010; aist et al, 2002; tsukahara and ward, 2001)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2896">
<title id=" W12-1630.xml">adapting to multiple affective states in spoken dialogue </title>
<section> the experiment.  </section>
<citcontext>
<prevsection>
<prevsent>the pre/post motivation surveys are reduced version of widely used motivation survey in the tutoring domain (pintrich and degroot, 1990); our selected questions were relevant to our system and also selected in other recent research (ward, 2010; roll, 2009).
</prevsent>
<prevsent>the two surveys are isomorphic, each containing 19 statements rated on 7-point likert scale.
</prevsent>
</prevsection>
<citsent citstr=" W11-2019 ">
average pre and post scores were 68% and 70% (out of 100%), respectively.the user satisfaction survey was recently developed and validated for use with spoken dialogue computer tutors (dzikovska et al, 2011).<papid> W11-2019 </papid></citsent>
<aftsection>
<nextsent>it contains 40 statements rated on 5-point likert scale.
</nextsent>
<nextsent>average score was 68% (out of 100%).
</nextsent>
<nextsent>the test?
</nextsent>
<nextsent>dialogue is isomorphic to the fifth training dialogue, such that all questions are identical except for the identities of the objects discussed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2899">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>combining capitalization with punctuation-induced constraints in inference further improved parsing performance, attaining state-of-the-art levels for many languages.
</prevsent>
<prevsent>dependency grammar induction and related problems of unsupervised syntactic structure discovery are attracting increasing attention (rasooli and faili, 2012; marecek and zabokrtsky?, 2011, inter alia).
</prevsent>
</prevsection>
<citsent citstr=" D11-1005 ">
since sentence structure is under determined by raw text, there have been efforts to simplify the task, via(i) pooling features of syntax across languages (co hen et al, 2011; <papid> D11-1005 </papid>mcdonald et al, 2011; <papid> D11-1006 </papid>cohen and smith, 2009); <papid> N09-1009 </papid>as well as (ii) identifying universal rules (naseem et al, 2010) ? <papid> D10-1120 </papid>such as verbo cen tricity (gimpel and smith, 2011) ? that need notbe learned at all.</citsent>
<aftsection>
<nextsent>unfortunately most of these techniques do not apply to plain text, because theyre quire knowing, for example, which words are verbs.
</nextsent>
<nextsent>as standard practice shifts away from relying ongold part-of-speech (pos) tags (seginer, 2007; <papid> P07-1049 </papid>ponvert et al, 2010; sgaard, 2011b; spitkovsky et al, 2011<papid> W11-0303 </papid>c, inter alia), lighter cues to inducing linguistic structure become more important.</nextsent>
<nextsent>examples of useful pos-agnostic clues include punctuation boundaries (ponvert et al, 2011; <papid> P11-1108 </papid>spitkovsky et al, 2011<papid> W11-0303 </papid>b;briscoe, 1994) and various kinds of bracketing constraints (naseem and barzilay, 2011; spitkovsky et al., 2010<papid> P10-1130 </papid>b; pereira and schabes, 1992).<papid> P92-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2900">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>combining capitalization with punctuation-induced constraints in inference further improved parsing performance, attaining state-of-the-art levels for many languages.
</prevsent>
<prevsent>dependency grammar induction and related problems of unsupervised syntactic structure discovery are attracting increasing attention (rasooli and faili, 2012; marecek and zabokrtsky?, 2011, inter alia).
</prevsent>
</prevsection>
<citsent citstr=" D11-1006 ">
since sentence structure is under determined by raw text, there have been efforts to simplify the task, via(i) pooling features of syntax across languages (co hen et al, 2011; <papid> D11-1005 </papid>mcdonald et al, 2011; <papid> D11-1006 </papid>cohen and smith, 2009); <papid> N09-1009 </papid>as well as (ii) identifying universal rules (naseem et al, 2010) ? <papid> D10-1120 </papid>such as verbo cen tricity (gimpel and smith, 2011) ? that need notbe learned at all.</citsent>
<aftsection>
<nextsent>unfortunately most of these techniques do not apply to plain text, because theyre quire knowing, for example, which words are verbs.
</nextsent>
<nextsent>as standard practice shifts away from relying ongold part-of-speech (pos) tags (seginer, 2007; <papid> P07-1049 </papid>ponvert et al, 2010; sgaard, 2011b; spitkovsky et al, 2011<papid> W11-0303 </papid>c, inter alia), lighter cues to inducing linguistic structure become more important.</nextsent>
<nextsent>examples of useful pos-agnostic clues include punctuation boundaries (ponvert et al, 2011; <papid> P11-1108 </papid>spitkovsky et al, 2011<papid> W11-0303 </papid>b;briscoe, 1994) and various kinds of bracketing constraints (naseem and barzilay, 2011; spitkovsky et al., 2010<papid> P10-1130 </papid>b; pereira and schabes, 1992).<papid> P92-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2901">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>combining capitalization with punctuation-induced constraints in inference further improved parsing performance, attaining state-of-the-art levels for many languages.
</prevsent>
<prevsent>dependency grammar induction and related problems of unsupervised syntactic structure discovery are attracting increasing attention (rasooli and faili, 2012; marecek and zabokrtsky?, 2011, inter alia).
</prevsent>
</prevsection>
<citsent citstr=" N09-1009 ">
since sentence structure is under determined by raw text, there have been efforts to simplify the task, via(i) pooling features of syntax across languages (co hen et al, 2011; <papid> D11-1005 </papid>mcdonald et al, 2011; <papid> D11-1006 </papid>cohen and smith, 2009); <papid> N09-1009 </papid>as well as (ii) identifying universal rules (naseem et al, 2010) ? <papid> D10-1120 </papid>such as verbo cen tricity (gimpel and smith, 2011) ? that need notbe learned at all.</citsent>
<aftsection>
<nextsent>unfortunately most of these techniques do not apply to plain text, because theyre quire knowing, for example, which words are verbs.
</nextsent>
<nextsent>as standard practice shifts away from relying ongold part-of-speech (pos) tags (seginer, 2007; <papid> P07-1049 </papid>ponvert et al, 2010; sgaard, 2011b; spitkovsky et al, 2011<papid> W11-0303 </papid>c, inter alia), lighter cues to inducing linguistic structure become more important.</nextsent>
<nextsent>examples of useful pos-agnostic clues include punctuation boundaries (ponvert et al, 2011; <papid> P11-1108 </papid>spitkovsky et al, 2011<papid> W11-0303 </papid>b;briscoe, 1994) and various kinds of bracketing constraints (naseem and barzilay, 2011; spitkovsky et al., 2010<papid> P10-1130 </papid>b; pereira and schabes, 1992).<papid> P92-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2902">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>combining capitalization with punctuation-induced constraints in inference further improved parsing performance, attaining state-of-the-art levels for many languages.
</prevsent>
<prevsent>dependency grammar induction and related problems of unsupervised syntactic structure discovery are attracting increasing attention (rasooli and faili, 2012; marecek and zabokrtsky?, 2011, inter alia).
</prevsent>
</prevsection>
<citsent citstr=" D10-1120 ">
since sentence structure is under determined by raw text, there have been efforts to simplify the task, via(i) pooling features of syntax across languages (co hen et al, 2011; <papid> D11-1005 </papid>mcdonald et al, 2011; <papid> D11-1006 </papid>cohen and smith, 2009); <papid> N09-1009 </papid>as well as (ii) identifying universal rules (naseem et al, 2010) ? <papid> D10-1120 </papid>such as verbo cen tricity (gimpel and smith, 2011) ? that need notbe learned at all.</citsent>
<aftsection>
<nextsent>unfortunately most of these techniques do not apply to plain text, because theyre quire knowing, for example, which words are verbs.
</nextsent>
<nextsent>as standard practice shifts away from relying ongold part-of-speech (pos) tags (seginer, 2007; <papid> P07-1049 </papid>ponvert et al, 2010; sgaard, 2011b; spitkovsky et al, 2011<papid> W11-0303 </papid>c, inter alia), lighter cues to inducing linguistic structure become more important.</nextsent>
<nextsent>examples of useful pos-agnostic clues include punctuation boundaries (ponvert et al, 2011; <papid> P11-1108 </papid>spitkovsky et al, 2011<papid> W11-0303 </papid>b;briscoe, 1994) and various kinds of bracketing constraints (naseem and barzilay, 2011; spitkovsky et al., 2010<papid> P10-1130 </papid>b; pereira and schabes, 1992).<papid> P92-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2903">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since sentence structure is under determined by raw text, there have been efforts to simplify the task, via(i) pooling features of syntax across languages (co hen et al, 2011; <papid> D11-1005 </papid>mcdonald et al, 2011; <papid> D11-1006 </papid>cohen and smith, 2009); <papid> N09-1009 </papid>as well as (ii) identifying universal rules (naseem et al, 2010) ? <papid> D10-1120 </papid>such as verbo cen tricity (gimpel and smith, 2011) ? that need notbe learned at all.</prevsent>
<prevsent>unfortunately most of these techniques do not apply to plain text, because theyre quire knowing, for example, which words are verbs.</prevsent>
</prevsection>
<citsent citstr=" P07-1049 ">
as standard practice shifts away from relying ongold part-of-speech (pos) tags (seginer, 2007; <papid> P07-1049 </papid>ponvert et al, 2010; sgaard, 2011b; spitkovsky et al, 2011<papid> W11-0303 </papid>c, inter alia), lighter cues to inducing linguistic structure become more important.</citsent>
<aftsection>
<nextsent>examples of useful pos-agnostic clues include punctuation boundaries (ponvert et al, 2011; <papid> P11-1108 </papid>spitkovsky et al, 2011<papid> W11-0303 </papid>b;briscoe, 1994) and various kinds of bracketing constraints (naseem and barzilay, 2011; spitkovsky et al., 2010<papid> P10-1130 </papid>b; pereira and schabes, 1992).<papid> P92-1017 </papid></nextsent>
<nextsent>we propose adding capitalization to this growing list of sources of partial bracketings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2904">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>since sentence structure is under determined by raw text, there have been efforts to simplify the task, via(i) pooling features of syntax across languages (co hen et al, 2011; <papid> D11-1005 </papid>mcdonald et al, 2011; <papid> D11-1006 </papid>cohen and smith, 2009); <papid> N09-1009 </papid>as well as (ii) identifying universal rules (naseem et al, 2010) ? <papid> D10-1120 </papid>such as verbo cen tricity (gimpel and smith, 2011) ? that need notbe learned at all.</prevsent>
<prevsent>unfortunately most of these techniques do not apply to plain text, because theyre quire knowing, for example, which words are verbs.</prevsent>
</prevsection>
<citsent citstr=" W11-0303 ">
as standard practice shifts away from relying ongold part-of-speech (pos) tags (seginer, 2007; <papid> P07-1049 </papid>ponvert et al, 2010; sgaard, 2011b; spitkovsky et al, 2011<papid> W11-0303 </papid>c, inter alia), lighter cues to inducing linguistic structure become more important.</citsent>
<aftsection>
<nextsent>examples of useful pos-agnostic clues include punctuation boundaries (ponvert et al, 2011; <papid> P11-1108 </papid>spitkovsky et al, 2011<papid> W11-0303 </papid>b;briscoe, 1994) and various kinds of bracketing constraints (naseem and barzilay, 2011; spitkovsky et al., 2010<papid> P10-1130 </papid>b; pereira and schabes, 1992).<papid> P92-1017 </papid></nextsent>
<nextsent>we propose adding capitalization to this growing list of sources of partial bracketings.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2922">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unfortunately most of these techniques do not apply to plain text, because theyre quire knowing, for example, which words are verbs.
</prevsent>
<prevsent>as standard practice shifts away from relying ongold part-of-speech (pos) tags (seginer, 2007; <papid> P07-1049 </papid>ponvert et al, 2010; sgaard, 2011b; spitkovsky et al, 2011<papid> W11-0303 </papid>c, inter alia), lighter cues to inducing linguistic structure become more important.</prevsent>
</prevsection>
<citsent citstr=" P11-1108 ">
examples of useful pos-agnostic clues include punctuation boundaries (ponvert et al, 2011; <papid> P11-1108 </papid>spitkovsky et al, 2011<papid> W11-0303 </papid>b;briscoe, 1994) and various kinds of bracketing constraints (naseem and barzilay, 2011; spitkovsky et al., 2010<papid> P10-1130 </papid>b; pereira and schabes, 1992).<papid> P92-1017 </papid></citsent>
<aftsection>
<nextsent>we propose adding capitalization to this growing list of sources of partial bracketings.
</nextsent>
<nextsent>our intuition stems from english, where (maximal) spans of capitalized words ? such as apple ii, world war i, mayor william h. hudnut iii, international business machines corp. and alexandria, va ? tend to demarcate proper nouns.consider motivating example (all of our examples are from wsj) without punctuation, in which all(eight) capitalized word clumps and uncased numerals match base noun phrase constituent boundaries: [np jay stevens] of [np dean witter] actually cut his per-share earnings estimate to [np $9] from [np $9.50] for [np 1989] and to [np $9.50] from [np $10.35] in [np 1990] because he decided sales would be even weaker than he had expected.
</nextsent>
<nextsent>and another (whose first word happens to be leaf), where capitalization complements punctuation cues: [np jurors] in [np u.s. district court] in [np miami] cleared [np harold hershhenson], former executive vice president; [np john pagones], former vice presi dent; and [np stephen vadas] and [np dean ciporkin], who had been engineers with [np cordis].could such chunks help bootstrap grammar induction and/or improve the accuracy of already-trained unsupervised parsers?
</nextsent>
<nextsent>in answering these questions, we will focus predominantly on sentence-internal capitalization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2941">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unfortunately most of these techniques do not apply to plain text, because theyre quire knowing, for example, which words are verbs.
</prevsent>
<prevsent>as standard practice shifts away from relying ongold part-of-speech (pos) tags (seginer, 2007; <papid> P07-1049 </papid>ponvert et al, 2010; sgaard, 2011b; spitkovsky et al, 2011<papid> W11-0303 </papid>c, inter alia), lighter cues to inducing linguistic structure become more important.</prevsent>
</prevsection>
<citsent citstr=" P10-1130 ">
examples of useful pos-agnostic clues include punctuation boundaries (ponvert et al, 2011; <papid> P11-1108 </papid>spitkovsky et al, 2011<papid> W11-0303 </papid>b;briscoe, 1994) and various kinds of bracketing constraints (naseem and barzilay, 2011; spitkovsky et al., 2010<papid> P10-1130 </papid>b; pereira and schabes, 1992).<papid> P92-1017 </papid></citsent>
<aftsection>
<nextsent>we propose adding capitalization to this growing list of sources of partial bracketings.
</nextsent>
<nextsent>our intuition stems from english, where (maximal) spans of capitalized words ? such as apple ii, world war i, mayor william h. hudnut iii, international business machines corp. and alexandria, va ? tend to demarcate proper nouns.consider motivating example (all of our examples are from wsj) without punctuation, in which all(eight) capitalized word clumps and uncased numerals match base noun phrase constituent boundaries: [np jay stevens] of [np dean witter] actually cut his per-share earnings estimate to [np $9] from [np $9.50] for [np 1989] and to [np $9.50] from [np $10.35] in [np 1990] because he decided sales would be even weaker than he had expected.
</nextsent>
<nextsent>and another (whose first word happens to be leaf), where capitalization complements punctuation cues: [np jurors] in [np u.s. district court] in [np miami] cleared [np harold hershhenson], former executive vice president; [np john pagones], former vice presi dent; and [np stephen vadas] and [np dean ciporkin], who had been engineers with [np cordis].could such chunks help bootstrap grammar induction and/or improve the accuracy of already-trained unsupervised parsers?
</nextsent>
<nextsent>in answering these questions, we will focus predominantly on sentence-internal capitalization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2943">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unfortunately most of these techniques do not apply to plain text, because theyre quire knowing, for example, which words are verbs.
</prevsent>
<prevsent>as standard practice shifts away from relying ongold part-of-speech (pos) tags (seginer, 2007; <papid> P07-1049 </papid>ponvert et al, 2010; sgaard, 2011b; spitkovsky et al, 2011<papid> W11-0303 </papid>c, inter alia), lighter cues to inducing linguistic structure become more important.</prevsent>
</prevsection>
<citsent citstr=" P92-1017 ">
examples of useful pos-agnostic clues include punctuation boundaries (ponvert et al, 2011; <papid> P11-1108 </papid>spitkovsky et al, 2011<papid> W11-0303 </papid>b;briscoe, 1994) and various kinds of bracketing constraints (naseem and barzilay, 2011; spitkovsky et al., 2010<papid> P10-1130 </papid>b; pereira and schabes, 1992).<papid> P92-1017 </papid></citsent>
<aftsection>
<nextsent>we propose adding capitalization to this growing list of sources of partial bracketings.
</nextsent>
<nextsent>our intuition stems from english, where (maximal) spans of capitalized words ? such as apple ii, world war i, mayor william h. hudnut iii, international business machines corp. and alexandria, va ? tend to demarcate proper nouns.consider motivating example (all of our examples are from wsj) without punctuation, in which all(eight) capitalized word clumps and uncased numerals match base noun phrase constituent boundaries: [np jay stevens] of [np dean witter] actually cut his per-share earnings estimate to [np $9] from [np $9.50] for [np 1989] and to [np $9.50] from [np $10.35] in [np 1990] because he decided sales would be even weaker than he had expected.
</nextsent>
<nextsent>and another (whose first word happens to be leaf), where capitalization complements punctuation cues: [np jurors] in [np u.s. district court] in [np miami] cleared [np harold hershhenson], former executive vice president; [np john pagones], former vice presi dent; and [np stephen vadas] and [np dean ciporkin], who had been engineers with [np cordis].could such chunks help bootstrap grammar induction and/or improve the accuracy of already-trained unsupervised parsers?
</nextsent>
<nextsent>in answering these questions, we will focus predominantly on sentence-internal capitalization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2944">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> english capitalization from treebank.  </section>
<citcontext>
<prevsection>
<prevsent>in answering these questions, we will focus predominantly on sentence-internal capitalization.
</prevsent>
<prevsent>but we will also show that first words ? those capitalized by convention ? and uncased segments ? whose characters are not even drawn from an alphabet ? could play useful role as well.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we began our study by consulting the 51,558 parsed sentences of the wsj corpus (marcus et al, 1993):<papid> J93-2004 </papid>30,691 (59.5%) of them contain non-trivially capitalized fragments ? maximal (non-empty and not 16 count pos sequence frac cum 1 27,524 nnp 44.6% 2 17,222 nnp nnp 27.9 72.5 4 2,973 jj 4.8 84.8 5 1,716 nnp nnp nnp nnp 2.8 87.5 6 1,037 nn 1.7 89.2 7 932 prp 1.5 90.7 8 846 nnps 1.4 92.1 9 604 nnp nnps 1.0 93.1 10 526 nnp nnp nnp nnp nnp 0.9 93.9 wsj +3,753 more with count ? 498 6.1% table 1: top 10 fragments of pos tag sequences in wsj.</citsent>
<aftsection>
<nextsent>sentence-initial) consecutive sequences of words that each differs from its own lower-cased form.nearly all ? 59,388 (96.2%) ? of the 61,731 fragments are dominated by noun phrases; slightly less than half ? 27,005 (43.8%) ? perfectly align with constituent boundaries in the treebank; and about as many ? 27,230 (44.1%) are multi-token.
</nextsent>
<nextsent>table 1 shows the top pos sequences comprising fragments.
</nextsent>
<nextsent>we gauged the suitability of capitalization-inducedfragments for guiding dependency grammar induction by assessing accuracy, in wsj,1 of parsing constraints derived from their end-points.
</nextsent>
<nextsent>following the suite of increasingly-restrictive constraints on how dependencies may interact with fragments, introduced by spitkovsky et al (2011<papid> W11-0303 </papid>b, 2.2), we tested several such heuristics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2970">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> pilot experiments on supervised parsing.  </section>
<citcontext>
<prevsection>
<prevsent>table 2 (capital) shows scores averaged over the entire treebank.
</prevsent>
<prevsent>columns markup (spitkovsky et al, 2010<papid> P10-1130 </papid>b) and punct (spitkovsky et al, 2011<papid> W11-0303 </papid>b) indicate that capitalization yields across-the-board more accurate constraints (for english) compared with fragments derived from punctuation or markup (i.e., anchor text, bold, italics and underline tags in html), for which such constraints were originally intended.</prevsent>
</prevsection>
<citsent citstr=" D12-1063 ">
to further test the potential of capitalization-induced constraints, we applied them in the viterbi-decodingphase of simple (unlexicalized) supervised dependency parser ? an instance of dbm-1 (spitkovsky et al, 2012, <papid> D12-1063 </papid>2.1), trained on wsj sentences with up punct.: thread tear sprawl loose none: 71.8 74.3 74.4 74.5 73.3 capital:thread 72.3 74.6 74.7 74.9 73.6 tear 72.4 74.7 74.7 74.9 73.6 sprawl 72.4 74.7 74.7 74.9 73.4 loose 72.4 74.8 74.7 74.9 73.3 strict?</citsent>
<aftsection>
<nextsent>71.4 73.7 73.7 73.9 72.7 strict 71.0 73.1 73.1 73.2 72.1 table 3: supervised (directed) accuracy on section 23 of wsj using capitalization-induced constraints (vertical) jointly with punctuation (horizontal) in viterbi-decoding.
</nextsent>
<nextsent>17 conll year filtered training directed accuracies with initial constraints fragments &amp; language tokens / sentences none thread tear sprawl loose strict?
</nextsent>
<nextsent>strict multi single german 2006 139,333 12,296 36.3 36.3 36.3 39.1 36.2 36.3 30.1 3,287 30,435 czech 6 187,505 20,378 51.3 51.3 51.3 51.3 52.5 52.5 51.4 1,831 6,722 english 7 74,023 5,087 29.2 28.5 28.3 29.0 29.3 28.3 27.7 1,135 2,218 bulgarian 6 46,599 5,241 59.4 59.3 59.3 59.4 59.1 59.3 59.5 184 1,506 danish 6 14,150 1,599 21.3 17.7 22.7 21.5 21.4 31.4 27.9 113 317 greek 7 11,943 842 28.1 46.1 46.3 46.3 46.4 31.1 31.0 113 456 dutch 6 72,043 7,107 45.9 45.8 45.9 45.8 45.8 45.7 29.6 89 4,335 italian 7 9,142 921 41.7 52.6 52.7 52.6 44.2 52.6 45.8 41 296 catalan 7 62,811 4,082 61.3 61.3 61.3 61.3 61.3 61.3 36.5 28 2,828 turkish 6 17,610 2,835 32.9 32.9 32.2 33.0 33.0 33.6 33.9 27 590 portuguese 6 24,494 2,042 68.9 67.1 69.1 69.2 68.9 68.9 38.5 9 953 hungarian 7 10,343 1,258 43.2 43.2 43.1 43.2 43.2 43.7 25.5 7 277 swedish 6 41,918 4,105 48.6 48.6 48.6 48.5 48.5 48.5 48.8 3 296 slovenian 6 3,627 477 30.4 30.5 30.5 30.4 30.5 30.5 30.8 1 63 median: 42.5 46.0 46.1 46.0 45.0 44.7 32.5 mean: 42.8 44.4 44.8 45.0 44.3 44.6 36.9 table 4: parsing performance for grammar inducers trained with capitalization-based initial constraints, tested against 14 held-out sets from 2006/7 conll shared tasks, and ordered by number of multi-token fragments in training data.
</nextsent>
<nextsent>to 45 words (excluding section 23).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2971">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> multi-lingual grammar induction.  </section>
<citcontext>
<prevsection>
<prevsent>so far, we showed only that capitalization information can be helpful in parsing very specific genre of english.
</prevsent>
<prevsent>next, we tested its ability to generally aid dependency grammar induction, focusing on situations when other bracketing cues are unavailable.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
we experimented with 14 languages from 2006/7 conll shared tasks (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007), <papid> D07-1096 </papid>excluding arabic, chinese and japanese (which lack case), as well as basque and spanish (which are pre-processed in way that loses relevant capitalization information).</citsent>
<aftsection>
<nextsent>for all remaining languages we trained only on simple sentences ? those lacking sentence-internal punctuation ? from the relevant training sets (for blind evaluation).restricting our attention to subset of the available training data serves dual purpose.
</nextsent>
<nextsent>first, it allows us to estimate capitalizations impact where no other (known or obvious) cues could also be used.
</nextsent>
<nextsent>otherwise, unconstrained baselines would not yield the strongest possible alternative, and hence not the most interesting comparison.
</nextsent>
<nextsent>second, to the extent that presence of punctuation may correlate with sentence complexity (frank, 2000), there are benefits to starting small?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2972">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> multi-lingual grammar induction.  </section>
<citcontext>
<prevsection>
<prevsent>so far, we showed only that capitalization information can be helpful in parsing very specific genre of english.
</prevsent>
<prevsent>next, we tested its ability to generally aid dependency grammar induction, focusing on situations when other bracketing cues are unavailable.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
we experimented with 14 languages from 2006/7 conll shared tasks (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007), <papid> D07-1096 </papid>excluding arabic, chinese and japanese (which lack case), as well as basque and spanish (which are pre-processed in way that loses relevant capitalization information).</citsent>
<aftsection>
<nextsent>for all remaining languages we trained only on simple sentences ? those lacking sentence-internal punctuation ? from the relevant training sets (for blind evaluation).restricting our attention to subset of the available training data serves dual purpose.
</nextsent>
<nextsent>first, it allows us to estimate capitalizations impact where no other (known or obvious) cues could also be used.
</nextsent>
<nextsent>otherwise, unconstrained baselines would not yield the strongest possible alternative, and hence not the most interesting comparison.
</nextsent>
<nextsent>second, to the extent that presence of punctuation may correlate with sentence complexity (frank, 2000), there are benefits to starting small?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI2977">
<title id=" W12-1903.xml">capitalization cues improve dependency grammar induction </title>
<section> multi-lingual grammar induction.  </section>
<citcontext>
<prevsection>
<prevsent>second, to the extent that presence of punctuation may correlate with sentence complexity (frank, 2000), there are benefits to starting small?
</prevsent>
<prevsent>(elman, 1993): e.g., relegating full data to later stages helps training (spitkovsky et al, 2010<papid> P10-1130 </papid>a; cohn et al, 2011; tu and honavar, 2011).</prevsent>
</prevsection>
<citsent citstr=" P10-1152 ">
our base systems induced dbm-1, starting from uniformly-at-random chosen parse trees (cohen and smith, 2010) <papid> P10-1152 </papid>of each sentence, followed by inside outside re-estimation (baker, 1979) with add-onesmoothing.2 capitalization-constrained systems differed from controls in exactly one way: each learner got slight nudge towards more promising structures by choosing initial seed trees satisfying an appropriate constraint (but otherwise still uniformly).</citsent>
<aftsection>
<nextsent>table 4 contains the stats for all 14 training sets,ordered by number of multi-token fragments.
</nextsent>
<nextsent>final accuracies on respective (disjoint, full) evaluation sets are improved by all constraints other than strict, with the highest average performance resulting from sprawl: 45.0% directed dependency accu racy,3 on average.
</nextsent>
<nextsent>this increase of about two points over the base systems 42.8% is driven primarily by improvements in two languages (greek and italian).
</nextsent>
<nextsent>2we used early-stopping lateen em?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3033">
<title id=" W11-2004.xml">a two stage domain selection framework for extensible multi domain spoken dialogue systems </title>
<section> domain selection in multi-domain.  </section>
<citcontext>
<prevsection>
<prevsent>section 5 describes an example implementation and its evaluation results, and section 6 concludes the paper.
</prevsent>
<prevsent>spoken dialogue systems 2.1 distributed architecture.
</prevsent>
</prevsection>
<citsent citstr=" W08-0114 ">
in distributed multi-domain spoken dialogue architecture (figure 1), distributed modules independently manage their own dialogue state and knowledge for speech understanding and utterance generation (lin et al , 1999; salonen et al , 2004; pakucs, 2003; nakano et al , 2008).<papid> W08-0114 </papid></citsent>
<aftsection>
<nextsent>although those modules are referred to with various names in that literature, we call them domain experts in this paper.
</nextsent>
<nextsent>in this architecture, when an input utterance is received, its asr results are sent to domain experts.
</nextsent>
<nextsent>they try to understand the asr results using their own knowledge for understanding.
</nextsent>
<nextsent>the domain selector gathers information from those experts and decides which expert should deal with the utterance and then decide on the system utterances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3034">
<title id=" W11-2004.xml">a two stage domain selection framework for extensible multi domain spoken dialogue systems </title>
<section> domain selection in multi-domain.  </section>
<citcontext>
<prevsection>
<prevsent>so far many multi-domain spoken dialogue systems based on distributed architecture have been user utterance information for domain selection domain selector activate/deactivate system utterance(from the activatedexpert) speech understanding utterance generation domain expert 1 domain expert 2 domain expert 3 dialoguehistoryfigure 1: distributed multi-domain spoken dialogue system architecture.
</prevsent>
<prevsent>built and have demonstrated their ability to engage in dialogues in variety of domains.
</prevsent>
</prevsection>
<citsent citstr=" W06-1302 ">
for example, several systems integrated information providing and database searches in multiple domains (lin et al , 1999; komatani et al , 2006; <papid> W06-1302 </papid>oneill et al ,2004; gustafson and bell, 2000).</citsent>
<aftsection>
<nextsent>some other systems integrated domain experts that employ very different dialogue strategies.
</nextsent>
<nextsent>lee et al  (2009) and nakano et al  (2006) integrated task-oriented and non-task-oriented dialogue managements.
</nextsent>
<nextsent>nakano et al  (2008) <papid> W08-0114 </papid>integrated domain experts for not only dialogues but also tasks requiring physical actions.</nextsent>
<nextsent>below we explain an example system that weused to collect dialogue data for the domain selection experiment described in section 5.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3040">
<title id=" W11-2004.xml">a two stage domain selection framework for extensible multi domain spoken dialogue systems </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>these studies, however, use some features available only in some specific typeof domain experts, such as features concerning slot filling, so they cannot be used with other kinds of domain experts.
</prevsent>
<prevsent>that is, these methods do not satisfy extensibility.
</prevsent>
</prevsection>
<citsent citstr=" W06-1644 ">
methods that use classifiers based on word (andn-gram) frequencies have been developed for utterance classification (e.g., chu-carroll and carpenter(1999)), topic estimation for asr of speech corpora (e.g., hsu and glass (2006) <papid> W06-1644 </papid>and heidel and lee (2007)) and human-human dialogues (lane and kawahara, 2005).</citsent>
<aftsection>
<nextsent>these methods can be applied to domain selection in multi-domain spoken dialogue systems.
</nextsent>
<nextsent>however, since they require training data in the same set of domains as the target system, it detracts from extensibility.
</nextsent>
<nextsent>in addition, they are not robust because they cannot utilize variety of dialogue and understanding related features.
</nextsent>
<nextsent>word frequencies are not always effective when two domains share words as in our system described in section 2.2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3041">
<title id=" W12-1813.xml">framework for the development of spoken dialogue system based on collaboratively constructed semantic resources </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>those semantically structured data enable more precise search than simple text matching (e.g.  find dental clinic near kyoto station opens at saturday night. ) and more complex search than simple query to relational database (rdb) (e.g. query  find machine learning books written by researcher of nlp.  needs cross search on book 1 http://www.freebase.com/ db and researcher db).
</prevsent>
<prevsent>since search conditions of such queries to the structured data become complex, natural language, especially speech, for smart phone and tablet pc, is promising method of query input.
</prevsent>
</prevsection>
<citsent citstr=" N06-4005 ">
there are some previous researches on converting natural language input to the query of structured data (lopez et al, 2006) (<papid> N06-4005 </papid>tablan et al, 2008).</citsent>
<aftsection>
<nextsent>these researches basically concentrated on the in put sentence analysis and the query construction.
</nextsent>
<nextsent>if the developer want to apply existing natural language understanding methods to spoken dialogue system (sds) for structured data search, therere mains fair amount of components that need to be implemented, such as speech input component, dialogue flow management, backend interface, etc. in order to realize development environment of sds for structured data search, we designed data model driven framework for rapid prototyping of sds based on csrs.
</nextsent>
<nextsent>the proposed framework can be regarded as an extension of existing rails framework of web application to (1) enabling speech interaction and (2) utilizing benefit of csrs.
</nextsent>
<nextsent>by using csrs and the extended rails framework, the troublesome definitions of rules and templates for sds prototyping can be reduced significantly compared with the ordinary rdb based approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3042">
<title id=" W12-1816.xml">mining search query logs for spoken language understanding </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this case).
</prevsent>
<prevsent>the use of click information obtained through massive search query click logs has been the focus of previous research.
</prevsent>
</prevsection>
<citsent citstr=" P11-1009 ">
specifically, query logs have been used for building more robust web search and better information retrieval (pantel and fuxman,2011; <papid> P11-1009 </papid>li et al, 2008), improve personalization experience and understand social networking behaviors (wang et al, 2011), etc. the use of query logs in spoken dialog research is fairly new.</citsent>
<aftsection>
<nextsent>in this paper, we will survey the recent research on utilizing the search query logs to obtain more accurate and robust spoken dialog systems, focusing on the slu.
</nextsent>
<nextsent>later in the discussion section, we will discuss the implimications on the dialog models.
</nextsent>
<nextsent>the paper is organized as follows: in ? 2, we briefly describe query click logs.
</nextsent>
<nextsent>we then summarize recent research papers to give snapshot of how user search queries are being used in ? 3, and how information from click-through graphs (queries and 37 movie theaters in san bruno regal sunset square cinemas the majestic crest theater cinema in rosewell rave cinemas in east field queries clicked urls moviefone.com movies.eventful.com yelp.com amctheaters.com find cheap tickets for inception movie ticket deals watch movie deals for inception queries clicked urls fandango.com movietickets.com movie.yahoo.com ticketmakers.com movie world carslton ticket prices 1783 20 530 32 24 549 46 121 figure 1: sample query click graph.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3044">
<title id=" W11-2040.xml">the coda system for monologuetodialogue generation </title>
<section> system design.  </section>
<citcontext>
<prevsection>
<prevsent>a: correct.
</prevsent>
<prevsent>dialogue merger select one of theda sequences based on overall dialogue table 1: example of the output from each component input for our system is. the system expects text thathas already been annotated with discourse structure.
</prevsent>
</prevsection>
<citsent citstr=" P09-1075 ">
there have been recent encouraging advances in the automatic parsing of discourse structure, e.g.,see duverle and prendinger (2009), <papid> P09-1075 </papid>but the state-ofthe-art is not yet at point where it provides sufficiently reliable inputs for our purposes.</citsent>
<aftsection>
<nextsent>to demonstrate the functionality of our system without relying on still imperfect discourse parsing, we use the rst parsed wall street journal corpus as input (carlson et al, 2001).<papid> W01-1605 </papid></nextsent>
<nextsent>throughout the remainder of this section, we use the outputs for each of the modules in table 1 as running example.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3045">
<title id=" W11-2040.xml">the coda system for monologuetodialogue generation </title>
<section> system design.  </section>
<citcontext>
<prevsection>
<prevsent>dialogue merger select one of theda sequences based on overall dialogue table 1: example of the output from each component input for our system is. the system expects text thathas already been annotated with discourse structure.
</prevsent>
<prevsent>there have been recent encouraging advances in the automatic parsing of discourse structure, e.g.,see duverle and prendinger (2009), <papid> P09-1075 </papid>but the state-ofthe-art is not yet at point where it provides sufficiently reliable inputs for our purposes.</prevsent>
</prevsection>
<citsent citstr=" W01-1605 ">
to demonstrate the functionality of our system without relying on still imperfect discourse parsing, we use the rst parsed wall street journal corpus as input (carlson et al, 2001).<papid> W01-1605 </papid></citsent>
<aftsection>
<nextsent>throughout the remainder of this section, we use the outputs for each of the modules in table 1 as running example.
</nextsent>
<nextsent>2.1 dialogue modeller.
</nextsent>
<nextsent>the dialogue modeller component takes as input snippet of monologue text annotated with discoursestructure.
</nextsent>
<nextsent>for each input discourse relation structure (dr), the dialogue modeller outputs set of dialogue act (da) sequences appropriate for expressing the same information, but now in dialogue form.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3046">
<title id=" W11-2040.xml">the coda system for monologuetodialogue generation </title>
<section> system design.  </section>
<citcontext>
<prevsection>
<prevsent>the verbalizer is rule-based and has three types of rules: discourse relation (dr)-specific, generic, and canned.
</prevsent>
<prevsent>all of the rules take as input monologue segment and target dialogue act.
</prevsent>
</prevsection>
<citsent citstr=" N10-1086 ">
dr-specific rules also use the discourse relation and segment nuclear ity of the input segment.2 the verbal ization rules are ordered according to their priority with dr-specific rules having higher priority.generic and dr-specific rules use the cmu question generation tool (heilman and smith, 2010) <papid> N10-1086 </papid>in combination with syntactic and lexical manipulationrules.</citsent>
<aftsection>
<nextsent>canned text rules are used to generate answer yes, agree and clarify dialogue acts by proba 2nucleus is the more salient segment in relation.
</nextsent>
<nextsent>336 bilistic selection from set of utterances extracted from the coda corpus.
</nextsent>
<nextsent>for example, the agree dialogue act is verbalized as one of the statements: agree with you; agree; couldnt agree more; completely agree; absolutely; very true; right; true.
</nextsent>
<nextsent>probabilistic selection from list allows us to generate non-repetitive dialogues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3047">
<title id=" W11-2040.xml">the coda system for monologuetodialogue generation </title>
<section> conclusions and further work.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we described text-to-dialogue generation system that converts text annotated with discourse relations into dialogue.
</prevsent>
<prevsent>the system is modular, data-driven, and takes advantage of state-of-the art question generation tools.
</prevsent>
</prevsection>
<citsent citstr=" P11-2042 ">
our evaluation of the dialogue modeller and verbalizer components described in (piwek and stoyanchev, 2011) <papid> P11-2042 </papid>shows that both accuracy and fluency of generated dialogues are not worse than that of human-written dialogues.</citsent>
<aftsection>
<nextsent>we plan to release the coda text-to-dialoguesystem as open source code later this year.
</nextsent>
<nextsent>the system can be used as starting point for researchers interested in evaluating nlp tools for question generation, dialogue modelling and paraphrasing in dialogue generation task.
</nextsent>


</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3048">
<title id=" W11-2309.xml">source language categorization for improving a speech into sign language translation system </title>
<section> state of the art.  </section>
<citcontext>
<prevsection>
<prevsent>section 7 includes the main experiments and the obtained results, and finally, sections 8 and 9 include the main conclusions and the future work.
</prevsent>
<prevsent>in recent years, several groups have developed prototypes for translating spoken language into sign language: example-based (morrissey, 2008), rule-based (marshall and sfr, 2005; san segundo et al  2008), full sentence (cox et al , 2002) or statistical approaches (stein et al , 2006; morrissey et al , 2007; vendrame et al , 2010) approaches.
</prevsent>
</prevsection>
<citsent citstr=" L08-1469 ">
given the sparseness of data for researching in sign languages, in the last five years, several projects have started to generate more resources: in american sign language (dreuw et al ., 2008), <papid> L08-1469 </papid>british sign language (schembri, 2008), greek sign language (efthimiou and fotinea, 2008), in irish sign language (morrissey et al , 2010), ngs (german sign language) (hanke et al , 2010), and italian sign language (geraci et al , 2010).</citsent>
<aftsection>
<nextsent>for lse, the biggest database was generated two years ago in plan avanza project (www.traduccionvozlse.es) (san-segundo et al , 2010) and it is has been used in this work.
</nextsent>
<nextsent>not only the data but also new practice (forster et al , 2010) and new uses of traditional annotation tools (cras born et al , 2010) have been developed.
</nextsent>
<nextsent>the work presented in this paper describes experiments with relevant database despite the small amount of data available for research into 85 sign languages, the system presented in this paper demonstrates very good performance compared to similar systems previously developed.
</nextsent>
<nextsent>the presented results are also the best results for translating spanish into lse using the biggest database that includes these languages.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3049">
<title id=" W11-2309.xml">source language categorization for improving a speech into sign language translation system </title>
<section> statistical translation strategies.  </section>
<citcontext>
<prevsection>
<prevsent>every sentence is split in several phrases automatically so this segmentation can have errors.
</prevsent>
<prevsent>but, the main target, when training phrase-based model, is to split the sentence in several phrases and to find their corresponding translations in the target language.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the phrase model has been trained starting from word alignment computed using giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>giza++ is statistical machine translation toolkit that is used to train ibm models 1-5 and an hmm word alignment model.
</nextsent>
<nextsent>in this step, the alignments between words and signs in both directions (spanish-lse and lsespanish) are calculated.
</nextsent>
<nextsent>the alignment?
</nextsent>
<nextsent>parameter has been fixed to target-source?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3050">
<title id=" W11-2309.xml">source language categorization for improving a speech into sign language translation system </title>
<section> statistical translation strategies.  </section>
<citcontext>
<prevsection>
<prevsent>diagram of the fst-based translation module.
</prevsent>
<prevsent>the translation model consists of an sfst made up of aggregations: sub sequences of aligned source and target words.
</prevsent>
</prevsection>
<citsent citstr=" J04-2004 ">
the sfst is inferred from the word alignment (obtained with giza++) using the giati (grammatical inference and alignments for transducer inference) algorithm (casacuberta and vidal, 2004).<papid> J04-2004 </papid></citsent>
<aftsection>
<nextsent>the sfst probabilities are also trained from aligned corpora.
</nextsent>
<nextsent>the software used in this paper has been downloaded from http://prhlt.iti.es/content.phppage=software.php.
</nextsent>
<nextsent>as it was presented in figure 1, the categorization module proposed in this paper analyzes the source language sentence (sentence in spanish) andre places spanish words with their associated tags.
</nextsent>
<nextsent>this module uses list of 1014 spanish words (the vocabulary in this restricted domain) and the corresponding tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3051">
<title id=" W11-2309.xml">source language categorization for improving a speech into sign language translation system </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>(you must pay the taxes in the cash desk) is translated into vent anilla especfico caja tu pagar?
</prevsent>
<prevsent>(window specific cash-desk you pay).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
for evaluating the performance of the translation systems, the bleu (bilingual evaluation understudy) metric (papineni et al , 2002) <papid> P02-1040 </papid>has been used.</citsent>
<aftsection>
<nextsent>bleu is one of the most well-known metric for evaluating automatic translation systems because this metric presents good correlation with human evaluations.
</nextsent>
<nextsent>this metric has been also adopted to evaluate speech into sign language translation systems (stein et al , 2006; morrissey et al ., 2007; vendrame et al , 2010, san-segundo et al . 2008).
</nextsent>
<nextsent>in order to analyze the significance of the differences between several systems, for every bleu result, the confidence interval (at 95%) is also presented.
</nextsent>
<nextsent>this interval is calculated using the following formula: )1()100(96,1 bleu bleu ? =??
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3052">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>we finally conclude the paper in section 6.
</prevsent>
<prevsent>for the wmt 2011 evaluation we utilized rwthsstate-of-the-art phrase-based and hierarchical translation systems as well as our in-house system combination framework.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
giza++ (och and ney, 2003) <papid> J03-1002 </papid>was employed to train word alignments, language models have been created with the srilm toolkit (stolcke, 2002).</citsent>
<aftsection>
<nextsent>2.1 phrase-based system.
</nextsent>
<nextsent>we applied phrase-based translation (pbt) system similar to the one described in (zens and ney, 2008).phrase pairs are extracted from word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies.
</nextsent>
<nextsent>the standard feature set moreover includes an n-gram language model, phrase-level single-word lexicon sand word-, phrase- and distortion-penalties.
</nextsent>
<nextsent>to lexi calize reordering, discriminative reordering model(zens and ney, 2006<papid> W06-3110 </papid>a) is used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3053">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>we applied phrase-based translation (pbt) system similar to the one described in (zens and ney, 2008).phrase pairs are extracted from word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies.
</prevsent>
<prevsent>the standard feature set moreover includes an n-gram language model, phrase-level single-word lexicon sand word-, phrase- and distortion-penalties.
</prevsent>
</prevsection>
<citsent citstr=" W06-3110 ">
to lexi calize reordering, discriminative reordering model(zens and ney, 2006<papid> W06-3110 </papid>a) is used.</citsent>
<aftsection>
<nextsent>parameters are optimized with the downhill-simplex algorithm (nelder and mead, 1965) on the word graph.
</nextsent>
<nextsent>2.2 hierarchical system.
</nextsent>
<nextsent>for the hierarchical setups described in this paper, the open source jane toolkit (vilar et al, 2010) <papid> W10-1738 </papid>was employed.</nextsent>
<nextsent>jane has been developed at rwth and implements the hierarchical approach as introduced by chiang (2007) <papid> J07-2003 </papid>with some state-of-the-art exten sions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3061">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>parameters are optimized with the downhill-simplex algorithm (nelder and mead, 1965) on the word graph.
</prevsent>
<prevsent>2.2 hierarchical system.
</prevsent>
</prevsection>
<citsent citstr=" W10-1738 ">
for the hierarchical setups described in this paper, the open source jane toolkit (vilar et al, 2010) <papid> W10-1738 </papid>was employed.</citsent>
<aftsection>
<nextsent>jane has been developed at rwth and implements the hierarchical approach as introduced by chiang (2007) <papid> J07-2003 </papid>with some state-of-the-art exten sions.</nextsent>
<nextsent>in hierarchical phrase-based translation, aweighted synchronous context-free grammar is induced from parallel text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3062">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 hierarchical system.
</prevsent>
<prevsent>for the hierarchical setups described in this paper, the open source jane toolkit (vilar et al, 2010) <papid> W10-1738 </papid>was employed.</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
jane has been developed at rwth and implements the hierarchical approach as introduced by chiang (2007) <papid> J07-2003 </papid>with some state-of-the-art exten sions.</citsent>
<aftsection>
<nextsent>in hierarchical phrase-based translation, aweighted synchronous context-free grammar is induced from parallel text.
</nextsent>
<nextsent>in addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted.
</nextsent>
<nextsent>the search is typically carried out using the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></nextsent>
<nextsent>the standard models integrated intoour jane systems are: phrase translation probabilities and lexical translation probabilities on phrase level, each for both translation directions, length 405penalties on word and phrase level, three binary features marking hierarchical phrases, glue rule, and rules with non-terminals at the boundaries, source to-target and target-to-source phrase length ratios, four binary count features and an n-gram languagemodel.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3063">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>in hierarchical phrase-based translation, aweighted synchronous context-free grammar is induced from parallel text.
</prevsent>
<prevsent>in addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted.
</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
the search is typically carried out using the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></citsent>
<aftsection>
<nextsent>the standard models integrated intoour jane systems are: phrase translation probabilities and lexical translation probabilities on phrase level, each for both translation directions, length 405penalties on word and phrase level, three binary features marking hierarchical phrases, glue rule, and rules with non-terminals at the boundaries, source to-target and target-to-source phrase length ratios, four binary count features and an n-gram languagemodel.
</nextsent>
<nextsent>the model weights are optimized with standard mert (och, 2003) <papid> P03-1021 </papid>on 100-best lists.</nextsent>
<nextsent>2.3 system combination.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3065">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>the search is typically carried out using the cube pruning algorithm (huang and chiang, 2007).<papid> P07-1019 </papid></prevsent>
<prevsent>the standard models integrated intoour jane systems are: phrase translation probabilities and lexical translation probabilities on phrase level, each for both translation directions, length 405penalties on word and phrase level, three binary features marking hierarchical phrases, glue rule, and rules with non-terminals at the boundaries, source to-target and target-to-source phrase length ratios, four binary count features and an n-gram languagemodel.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the model weights are optimized with standard mert (och, 2003) <papid> P03-1021 </papid>on 100-best lists.</citsent>
<aftsection>
<nextsent>2.3 system combination.
</nextsent>
<nextsent>system combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in termsof translation quality than any of the individual hypotheses.
</nextsent>
<nextsent>the basic concept of rwths approach to machine translation system combination has been described by matusov et al (matusov et al, 2006; <papid> E06-1005 </papid>matusov et al, 2008).</nextsent>
<nextsent>this approach includes an enhanced alignment and reordering framework.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3066">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation systems.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 system combination.
</prevsent>
<prevsent>system combination is used to produce consensus translations from multiple hypotheses produced with different translation engines that are better in termsof translation quality than any of the individual hypotheses.
</prevsent>
</prevsection>
<citsent citstr=" E06-1005 ">
the basic concept of rwths approach to machine translation system combination has been described by matusov et al (matusov et al, 2006; <papid> E06-1005 </papid>matusov et al, 2008).</citsent>
<aftsection>
<nextsent>this approach includes an enhanced alignment and reordering framework.
</nextsent>
<nextsent>alattice is built from the input hypotheses.
</nextsent>
<nextsent>the translation with the best score within the lattice according to couple of statistical models is selected as consensus translation.
</nextsent>
<nextsent>we incorporated several novel methods into our systems for the wmt 2011 evaluation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3067">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation modeling.  </section>
<citcontext>
<prevsection>
<prevsent>this section provides short survey of three of the methods which we suppose to be of particular interest.
</prevsent>
<prevsent>3.1 language model data selection.
</prevsent>
</prevsection>
<citsent citstr=" P10-2041 ">
for the english and german language models, we applied the data selection method proposed in (moore and lewis, 2010).<papid> P10-2041 </papid></citsent>
<aftsection>
<nextsent>each sentence is scored by the difference in cross-entropy between language model trained from in-domain data and language model trained from similar-sized sample of the out-of-domain data.
</nextsent>
<nextsent>as in-domain data we used the news-commentary corpus.
</nextsent>
<nextsent>the out-of-domain data from which the data was selected are the news crawl corpus for both languages and for english the 109 corpus and the ldc gigaword data.
</nextsent>
<nextsent>we used 3-gram trained with the sri toolkit to compute the cross-entropy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3068">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation modeling.  </section>
<citcontext>
<prevsection>
<prevsent>of the 109 corpus we retained 1/2 and of the ldc gigaword data we retained 1/4 of the sentences to train the language models.
</prevsent>
<prevsent>3.2 phrase model training.
</prevsent>
</prevsection>
<citsent citstr=" W06-3105 ">
for the german english and frenchenglishtranslation tasks we applied forced alignment procedure to train the phrase translation model with theem algorithm, similar to the one described in (denero et al, 2006).<papid> W06-3105 </papid></citsent>
<aftsection>
<nextsent>here, the phrase translation probabilities are estimated from their relative frequencies in the phrase-aligned training data.
</nextsent>
<nextsent>the phrase alignment is produced by modified version of the translation decoder.
</nextsent>
<nextsent>in addition to providing statistically well-founded phrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid experiments.
</nextsent>
<nextsent>a detailed description of the training procedure is given in (wuebker et al, 2010).<papid> P10-1049 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3069">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation modeling.  </section>
<citcontext>
<prevsection>
<prevsent>the phrase alignment is produced by modified version of the translation decoder.
</prevsent>
<prevsent>in addition to providing statistically well-founded phrase model, this has the benefit of producing smaller phrase tables and thus allowing more rapid experiments.
</prevsent>
</prevsection>
<citsent citstr=" P10-1049 ">
a detailed description of the training procedure is given in (wuebker et al, 2010).<papid> P10-1049 </papid></citsent>
<aftsection>
<nextsent>3.3 soft string-to-dependency.
</nextsent>
<nextsent>given dependency tree of the target language, we are able to introduce language models that span over longer distances than the usual n-grams, as in (shen et al, 2008).<papid> P08-1066 </papid></nextsent>
<nextsent>to obtain dependency structures, we apply the stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>on the target side of the training material.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3070">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation modeling.  </section>
<citcontext>
<prevsection>
<prevsent>a detailed description of the training procedure is given in (wuebker et al, 2010).<papid> P10-1049 </papid></prevsent>
<prevsent>3.3 soft string-to-dependency.</prevsent>
</prevsection>
<citsent citstr=" P08-1066 ">
given dependency tree of the target language, we are able to introduce language models that span over longer distances than the usual n-grams, as in (shen et al, 2008).<papid> P08-1066 </papid></citsent>
<aftsection>
<nextsent>to obtain dependency structures, we apply the stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>on the target side of the training material.</nextsent>
<nextsent>rwths open source hierarchical translation toolkit jane has been extended to include dependency information in the phrase table and to build dependency trees on the output hypotheses at decoding time from this information.shen et al (2008) <papid> P08-1066 </papid>use only phrases that meet certain restrictions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3071">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> translation modeling.  </section>
<citcontext>
<prevsection>
<prevsent>3.3 soft string-to-dependency.
</prevsent>
<prevsent>given dependency tree of the target language, we are able to introduce language models that span over longer distances than the usual n-grams, as in (shen et al, 2008).<papid> P08-1066 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
to obtain dependency structures, we apply the stanford parser (klein and manning, 2003) <papid> P03-1054 </papid>on the target side of the training material.</citsent>
<aftsection>
<nextsent>rwths open source hierarchical translation toolkit jane has been extended to include dependency information in the phrase table and to build dependency trees on the output hypotheses at decoding time from this information.shen et al (2008) <papid> P08-1066 </papid>use only phrases that meet certain restrictions.</nextsent>
<nextsent>the first possibility is what the authors call fixed dependency structure.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3074">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> french-english setups.  </section>
<citcontext>
<prevsection>
<prevsent>the results for the french english task are given in table 3.
</prevsent>
<prevsent>rwths three submissions ? one primary and two contrastive ? are labeled accordingly in thetable.
</prevsent>
</prevsection>
<citsent citstr=" D09-1022 ">
the first contrastive submission is phrase based system with standard feature set plus an additional triplet lexicon model (mauser et al, 2009).<papid> D09-1022 </papid></citsent>
<aftsection>
<nextsent>the triplet lexicon model was trained on in-domain news commentary data only.
</nextsent>
<nextsent>the second contrastive submission is hierarchical jane system with threesyntax-based extensions: parse match model (vi lar et al, 2008), soft syntactic labels (stein et al, 2010), and the soft string-to-dependency extension as described in section 3.3.
</nextsent>
<nextsent>the primary submission combines the phrase-based contrastive system, hierarchical system that is very similar to the jane contrastive submission but with slightly worse language model, and an additional pbt system that has been trained with forced alignment (wuebker et al, 2010) <papid> P10-1049 </papid>on wmt 2010 data only.</nextsent>
<nextsent>4.2 experimental results englishfrench.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3085">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> french-english setups.  </section>
<citcontext>
<prevsection>
<prevsent>we likewise submitted two contrastive systems for this translation direction.
</prevsent>
<prevsent>the first contrastive submission is phrase-based system, enhanced with triplet lexicon model and discriminative word lexicon model (mauser et al, 2009) ? <papid> D09-1022 </papid>both trained on in-domain news commentary data only ? as well as sentence-level single-word lexicon model and discriminative reordering model(zens and ney, 2006<papid> W06-3110 </papid>a).</prevsent>
</prevsection>
<citsent citstr=" E09-1044 ">
the second contrastive submission is hierarchical jane system with shallow rules (iglesias et al, 2009), <papid> E09-1044 </papid>triplet lexicon model, discriminative word lexicon, the parse match model, and second phrase table extracted from in-domain data only.</citsent>
<aftsection>
<nextsent>our primary submission is very similar to the latter jane setup.
</nextsent>
<nextsent>it does not comprise the extended lexicon models and the parse match extension, but instead includes lexical phrases from the full 30 mio.
</nextsent>
<nextsent>sentence corpus as described above.
</nextsent>
<nextsent>we trained phrase-based and hierarchical translation systems for both translation directions of thegerman-english language pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3086">
<title id=" W11-2149.xml">the rwth aachen machine translation system for wmt 2011 </title>
<section> german-english setups.  </section>
<citcontext>
<prevsection>
<prevsent>the scores for newstest2010 are included for completeness.
</prevsent>
<prevsent>5.1 morpho-syntactic analysis.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
in order to reduce the source vocabulary size for the german english translation, the source side was preprocessed by splitting german compound words with the frequency-based method described in (koehn and knight, 2003).<papid> E03-1076 </papid></citsent>
<aftsection>
<nextsent>to further reduce translation complexity, we performed the long-range part-of-speech based reordering rules proposed by (popovic?
</nextsent>
<nextsent>et al, 2006).
</nextsent>
<nextsent>for additional experiments we used the tree tagger (schmid, 1995) to produce lemmatized version of the german source.
</nextsent>
<nextsent>5.2 optimization criterion.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3104">
<title id=" W11-1828.xml">generalizing biomedical event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using natural language processing techniques, an event extraction system predicts relations between proteins/genes and the processes they take part in.
</prevsent>
<prevsent>manually annotated corpora are used to evaluate event extraction techniques and to train machine-learning based systems.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
event extraction was popularised by the bionlp09 shared task on event extraction (kim et al, 2009), <papid> W09-1401 </papid>providing more detailed alternative for the older approach of binary interaction detection, where each pair of protein names co-occurring in the text is classified as interacting or not.</citsent>
<aftsection>
<nextsent>events extend this formalism by adding to the relations direction, type and nesting.
</nextsent>
<nextsent>events define the type of interaction, such as phosphorylation, and commonly mark in the text trigger word (e.g. phosphorylates?)
</nextsent>
<nextsent>describing the interaction.
</nextsent>
<nextsent>directed events can define the role of their protein or gene arguments as e.g. cause or theme, the agent or the target of the biological process.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3105">
<title id=" W11-1828.xml">generalizing biomedical event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we developed for the bionlp09 shared task the turku event extraction system, achieving the best performance at 51.95% f-score (bjorne et al, 2009).
</prevsent>
<prevsent>this system separated event extraction into multiple classification tasks, detecting individually the trigger words defining events, and the arguments that describe which proteins or genes take part in theseevents.
</prevsent>
</prevsection>
<citsent citstr=" W09-1406 ">
other approaches used in the shared task included e.g. joint inference (riedel et al, 2009).<papid> W09-1406 </papid></citsent>
<aftsection>
<nextsent>an overall notable trend was the use of full dependency parsing (buyko et al, 2009; <papid> W09-1403 </papid>van landeghem et al, 2009; kilicoglu and bergler, 2009).<papid> W09-1418 </papid></nextsent>
<nextsent>in the following years, event extraction has beenthe subject of continuous development.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3106">
<title id=" W11-1828.xml">generalizing biomedical event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this system separated event extraction into multiple classification tasks, detecting individually the trigger words defining events, and the arguments that describe which proteins or genes take part in theseevents.
</prevsent>
<prevsent>other approaches used in the shared task included e.g. joint inference (riedel et al, 2009).<papid> W09-1406 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-1403 ">
an overall notable trend was the use of full dependency parsing (buyko et al, 2009; <papid> W09-1403 </papid>van landeghem et al, 2009; kilicoglu and bergler, 2009).<papid> W09-1418 </papid></citsent>
<aftsection>
<nextsent>in the following years, event extraction has beenthe subject of continuous development.
</nextsent>
<nextsent>in 2009, after the bionlp09 shared task, we extended our system and improved its performance to 52.85% (bjorne et al, 2011).
</nextsent>
<nextsent>in 2010, the system introduced by miwa et. al. reached new record performance of 56.00% (miwa et al, 2010<papid> W10-1905 </papid>a).</nextsent>
<nextsent>183 regulation nn nn vb nn cc .conj_and   nn dobj   nsubj nn proteinstat3 phosphorylationphosphorylation regulation involve proteinvav and proteinrac-1 . cause  cause  theme un merging c edge detection trigger detection a dobj  parsing proteinstat3 phosphorylationphosphorylation regulation involve proteinvav and proteinrac-1 .  theme cause  cause  proteinstat3 phosphorylationphosphorylation regulation involve proteinvav and proteinrac-1 . proteinstat3 phosphorylation involve proteinvav and proteinrac-1 . stat3 phosphorylation involve vav and rac-1 .ser(727) maynn appos   aux vb ser(727) may ser(727) may ser(727) may ser(727) may entity  site entity entity  theme  theme site  theme regulation proteinstat3 phosphorylationphosphorylation involve proteinvav and proteinrac-1 . cause  cause  theme speculation and negation detectionf ser(727) may entity  theme site  theme regulation spec spec figure 1: event extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3107">
<title id=" W11-1828.xml">generalizing biomedical event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this system separated event extraction into multiple classification tasks, detecting individually the trigger words defining events, and the arguments that describe which proteins or genes take part in theseevents.
</prevsent>
<prevsent>other approaches used in the shared task included e.g. joint inference (riedel et al, 2009).<papid> W09-1406 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-1418 ">
an overall notable trend was the use of full dependency parsing (buyko et al, 2009; <papid> W09-1403 </papid>van landeghem et al, 2009; kilicoglu and bergler, 2009).<papid> W09-1418 </papid></citsent>
<aftsection>
<nextsent>in the following years, event extraction has beenthe subject of continuous development.
</nextsent>
<nextsent>in 2009, after the bionlp09 shared task, we extended our system and improved its performance to 52.85% (bjorne et al, 2011).
</nextsent>
<nextsent>in 2010, the system introduced by miwa et. al. reached new record performance of 56.00% (miwa et al, 2010<papid> W10-1905 </papid>a).</nextsent>
<nextsent>183 regulation nn nn vb nn cc .conj_and   nn dobj   nsubj nn proteinstat3 phosphorylationphosphorylation regulation involve proteinvav and proteinrac-1 . cause  cause  theme un merging c edge detection trigger detection a dobj  parsing proteinstat3 phosphorylationphosphorylation regulation involve proteinvav and proteinrac-1 .  theme cause  cause  proteinstat3 phosphorylationphosphorylation regulation involve proteinvav and proteinrac-1 . proteinstat3 phosphorylation involve proteinvav and proteinrac-1 . stat3 phosphorylation involve vav and rac-1 .ser(727) maynn appos   aux vb ser(727) may ser(727) may ser(727) may ser(727) may entity  site entity entity  theme  theme site  theme regulation proteinstat3 phosphorylationphosphorylation involve proteinvav and proteinrac-1 . cause  cause  theme speculation and negation detectionf ser(727) may entity  theme site  theme regulation spec spec figure 1: event extraction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3108">
<title id=" W11-1828.xml">generalizing biomedical event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in the following years, event extraction has beenthe subject of continuous development.
</prevsent>
<prevsent>in 2009, after the bionlp09 shared task, we extended our system and improved its performance to 52.85% (bjorne et al, 2011).
</prevsent>
</prevsection>
<citsent citstr=" W10-1905 ">
in 2010, the system introduced by miwa et. al. reached new record performance of 56.00% (miwa et al, 2010<papid> W10-1905 </papid>a).</citsent>
<aftsection>
<nextsent>183 regulation nn nn vb nn cc .conj_and   nn dobj   nsubj nn proteinstat3 phosphorylationphosphorylation regulation involve proteinvav and proteinrac-1 . cause  cause  theme un merging c edge detection trigger detection a dobj  parsing proteinstat3 phosphorylationphosphorylation regulation involve proteinvav and proteinrac-1 .  theme cause  cause  proteinstat3 phosphorylationphosphorylation regulation involve proteinvav and proteinrac-1 . proteinstat3 phosphorylation involve proteinvav and proteinrac-1 . stat3 phosphorylation involve vav and rac-1 .ser(727) maynn appos   aux vb ser(727) may ser(727) may ser(727) may ser(727) may entity  site entity entity  theme  theme site  theme regulation proteinstat3 phosphorylationphosphorylation involve proteinvav and proteinrac-1 . cause  cause  theme speculation and negation detectionf ser(727) may entity  theme site  theme regulation spec spec figure 1: event extraction.
</nextsent>
<nextsent>in most tasks named entities are given (a).
</nextsent>
<nextsent>sentences are parsed (b) to produce dependency parse.
</nextsent>
<nextsent>entities not given are predicted through trigger detection (c).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3110">
<title id=" W11-1828.xml">generalizing biomedical event extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>finally, event modality is predicted (f).
</prevsent>
<prevsent>when the graph is converted to the shared task format, site arguments are paired with core arguments that have the same target protein.in 2010, we applied the turku event extraction system to detecting events in all 18 millionpubmed abstracts, showing its scala bility and generalizability into real-world data beyond domain corpora (bjorne et al, 2010).
</prevsent>
</prevsection>
<citsent citstr=" W11-1801 ">
in the current bionlp11 shared task1 (kim et al, 2011), <papid> W11-1801 </papid>we demonstrate its generalizability to different event extraction tasks by applying what is, to large extent, the same system to every single task and subtask.</citsent>
<aftsection>
<nextsent>our system divides event extraction into three main steps (figure 1 c, and e).
</nextsent>
<nextsent>first, entities are predicted for each word in sentence.
</nextsent>
<nextsent>then, arguments are predicted between entities.
</nextsent>
<nextsent>finally, entity/argument sets are separated into individual events.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3111">
<title id=" W11-1828.xml">generalizing biomedical event extraction </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 syntactic analyses.
</prevsent>
<prevsent>the machine learning features that are used inevent detection are mostly derived from the syntactic parses of the sentences.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
parsing links together related words that may be distant in their linear order, creating parse tree (see figure 1 b).we used the charniak-johnson parser (char niak and johnson, 2005) <papid> P05-1022 </papid>with david mccloskys bio model (mcclosky, 2010) trained on the genia corpus and unlabeled pubmed articles.</citsent>
<aftsection>
<nextsent>the parse trees produced by the charniak-johnson parser were further processed with the stanford conversion tool (de marneffe et al, 2006), creating dependency parse (de marneffe and manning, 2008).
</nextsent>
<nextsent>in the supporting tasks (rel, ren and co) this parsing was done by us, but in the main tasks the organizers provided official parses which were used.
</nextsent>
<nextsent>all parses for tasks where named entities were givenas gold data were further processed with protein name splitter that divides at punctuation tokens which contain named entities, such as p50/p65?
</nextsent>
<nextsent>or gata3-binding?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3114">
<title id=" W11-1828.xml">generalizing biomedical event extraction </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>into valid trigger and argument combinations.
</prevsent>
<prevsent>in the bionlp09 shared task, this was done with rule-based system.
</prevsent>
</prevsection>
<citsent citstr=" W10-1914 ">
since then, further research has been done on machine learning approaches for this question (miwa et al, 2010<papid> W10-1905 </papid>b;heimonen et al, 2010).<papid> W10-1914 </papid></citsent>
<aftsection>
<nextsent>in our current system, un merging is done as an svm-classification step.
</nextsent>
<nextsent>an example is constructed for each argument edge combination of each predicted node, and classified as true event or false event to be removed.
</nextsent>
<nextsent>tested onthe bionlp09 shared task data, this system performs roughly on par with our earlier rule-based system, but has the advantage of being more general and thus applicable to all bionlp11 shared task 186 ge1 ge2 ge3 epi id bb bi co rel rentask 0 20 40 60 80 100 f-s cor figure 3: ranking of the systems participating in the bionlp11 shared task.
</nextsent>
<nextsent>our system is marked with black dots and the dotted line shows its theoretical maximum performance (see section 2.1) with all correct clas sifications.tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3115">
<title id=" W11-1909.xml">combining syntactic and semantic features by svm for unrestricted coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>coreference resolution, defined as finding the different mentions in document which refer to thesame entity in reality, is an important subject in natural language processing.
</prevsent>
<prevsent>in particular, coreference resolution is critical component of information extraction systems (chinchor and nancy, 1998; sundheim and beth, 1995) and series of coreference resolution tasks have been introduced and evaluated from muc (muc-6, 1995).
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
some machine learning approaches have been applied to coreference resolution (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>bengtson and roth, 2008; <papid> D08-1031 </papid>stoyanov et al, 2009).<papid> P09-1074 </papid></citsent>
<aftsection>
<nextsent>soon et al(2001) <papid> J01-4004 </papid>use decision tree classifier to decide whether two mentions in document are coreferent.</nextsent>
<nextsent>bergsma and lin (2006) <papid> P06-1005 </papid>exploit an effective feature of gender and number to pronoun resolution system and improve the performance significantly,which is also appeared in our feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3116">
<title id=" W11-1909.xml">combining syntactic and semantic features by svm for unrestricted coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>coreference resolution, defined as finding the different mentions in document which refer to thesame entity in reality, is an important subject in natural language processing.
</prevsent>
<prevsent>in particular, coreference resolution is critical component of information extraction systems (chinchor and nancy, 1998; sundheim and beth, 1995) and series of coreference resolution tasks have been introduced and evaluated from muc (muc-6, 1995).
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
some machine learning approaches have been applied to coreference resolution (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>bengtson and roth, 2008; <papid> D08-1031 </papid>stoyanov et al, 2009).<papid> P09-1074 </papid></citsent>
<aftsection>
<nextsent>soon et al(2001) <papid> J01-4004 </papid>use decision tree classifier to decide whether two mentions in document are coreferent.</nextsent>
<nextsent>bergsma and lin (2006) <papid> P06-1005 </papid>exploit an effective feature of gender and number to pronoun resolution system and improve the performance significantly,which is also appeared in our feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3117">
<title id=" W11-1909.xml">combining syntactic and semantic features by svm for unrestricted coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>coreference resolution, defined as finding the different mentions in document which refer to thesame entity in reality, is an important subject in natural language processing.
</prevsent>
<prevsent>in particular, coreference resolution is critical component of information extraction systems (chinchor and nancy, 1998; sundheim and beth, 1995) and series of coreference resolution tasks have been introduced and evaluated from muc (muc-6, 1995).
</prevsent>
</prevsection>
<citsent citstr=" D08-1031 ">
some machine learning approaches have been applied to coreference resolution (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>bengtson and roth, 2008; <papid> D08-1031 </papid>stoyanov et al, 2009).<papid> P09-1074 </papid></citsent>
<aftsection>
<nextsent>soon et al(2001) <papid> J01-4004 </papid>use decision tree classifier to decide whether two mentions in document are coreferent.</nextsent>
<nextsent>bergsma and lin (2006) <papid> P06-1005 </papid>exploit an effective feature of gender and number to pronoun resolution system and improve the performance significantly,which is also appeared in our feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3118">
<title id=" W11-1909.xml">combining syntactic and semantic features by svm for unrestricted coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>coreference resolution, defined as finding the different mentions in document which refer to thesame entity in reality, is an important subject in natural language processing.
</prevsent>
<prevsent>in particular, coreference resolution is critical component of information extraction systems (chinchor and nancy, 1998; sundheim and beth, 1995) and series of coreference resolution tasks have been introduced and evaluated from muc (muc-6, 1995).
</prevsent>
</prevsection>
<citsent citstr=" P09-1074 ">
some machine learning approaches have been applied to coreference resolution (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>bengtson and roth, 2008; <papid> D08-1031 </papid>stoyanov et al, 2009).<papid> P09-1074 </papid></citsent>
<aftsection>
<nextsent>soon et al(2001) <papid> J01-4004 </papid>use decision tree classifier to decide whether two mentions in document are coreferent.</nextsent>
<nextsent>bergsma and lin (2006) <papid> P06-1005 </papid>exploit an effective feature of gender and number to pronoun resolution system and improve the performance significantly,which is also appeared in our feature set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3120">
<title id=" W11-1909.xml">combining syntactic and semantic features by svm for unrestricted coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>some machine learning approaches have been applied to coreference resolution (soon et al, 2001; <papid> J01-4004 </papid>ng and cardie, 2002; <papid> P02-1014 </papid>bengtson and roth, 2008; <papid> D08-1031 </papid>stoyanov et al, 2009).<papid> P09-1074 </papid></prevsent>
<prevsent>soon et al(2001) <papid> J01-4004 </papid>use decision tree classifier to decide whether two mentions in document are coreferent.</prevsent>
</prevsection>
<citsent citstr=" P06-1005 ">
bergsma and lin (2006) <papid> P06-1005 </papid>exploit an effective feature of gender and number to pronoun resolution system and improve the performance significantly,which is also appeared in our feature set.</citsent>
<aftsection>
<nextsent>however, automatic coreference resolution is hard task since it needs both syntactic and semantic knowledge and some intra-document knowledge.
</nextsent>
<nextsent>to improve the performance further, many deep knowledge resources like shallow syntactic and semantic knowledge are exploited for coreference resolution (harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; denis and baldridge, 2007; <papid> N07-1030 </papid>ponzetto and strube, 2005; versley, 2007; <papid> D07-1052 </papid>ng, 2007).</nextsent>
<nextsent>in order to make use of more syntactic information, kong et al(2010) <papid> C10-1068 </papid>employ tree kernel to anaphoricity determination for coreference resolution and show that applying proper tree structure in corefernce resolution can achieve good performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3121">
<title id=" W11-1909.xml">combining syntactic and semantic features by svm for unrestricted coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>bergsma and lin (2006) <papid> P06-1005 </papid>exploit an effective feature of gender and number to pronoun resolution system and improve the performance significantly,which is also appeared in our feature set.</prevsent>
<prevsent>however, automatic coreference resolution is hard task since it needs both syntactic and semantic knowledge and some intra-document knowledge.</prevsent>
</prevsection>
<citsent citstr=" N01-1008 ">
to improve the performance further, many deep knowledge resources like shallow syntactic and semantic knowledge are exploited for coreference resolution (harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; denis and baldridge, 2007; <papid> N07-1030 </papid>ponzetto and strube, 2005; versley, 2007; <papid> D07-1052 </papid>ng, 2007).</citsent>
<aftsection>
<nextsent>in order to make use of more syntactic information, kong et al(2010) <papid> C10-1068 </papid>employ tree kernel to anaphoricity determination for coreference resolution and show that applying proper tree structure in corefernce resolution can achieve good performance.</nextsent>
<nextsent>the conll-2011 share task (pradhan et al., 2011) <papid> W11-1901 </papid>modeling unrestricted coreference in ontonotes?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3122">
<title id=" W11-1909.xml">combining syntactic and semantic features by svm for unrestricted coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>bergsma and lin (2006) <papid> P06-1005 </papid>exploit an effective feature of gender and number to pronoun resolution system and improve the performance significantly,which is also appeared in our feature set.</prevsent>
<prevsent>however, automatic coreference resolution is hard task since it needs both syntactic and semantic knowledge and some intra-document knowledge.</prevsent>
</prevsection>
<citsent citstr=" N07-1030 ">
to improve the performance further, many deep knowledge resources like shallow syntactic and semantic knowledge are exploited for coreference resolution (harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; denis and baldridge, 2007; <papid> N07-1030 </papid>ponzetto and strube, 2005; versley, 2007; <papid> D07-1052 </papid>ng, 2007).</citsent>
<aftsection>
<nextsent>in order to make use of more syntactic information, kong et al(2010) <papid> C10-1068 </papid>employ tree kernel to anaphoricity determination for coreference resolution and show that applying proper tree structure in corefernce resolution can achieve good performance.</nextsent>
<nextsent>the conll-2011 share task (pradhan et al., 2011) <papid> W11-1901 </papid>modeling unrestricted coreference in ontonotes?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3123">
<title id=" W11-1909.xml">combining syntactic and semantic features by svm for unrestricted coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>bergsma and lin (2006) <papid> P06-1005 </papid>exploit an effective feature of gender and number to pronoun resolution system and improve the performance significantly,which is also appeared in our feature set.</prevsent>
<prevsent>however, automatic coreference resolution is hard task since it needs both syntactic and semantic knowledge and some intra-document knowledge.</prevsent>
</prevsection>
<citsent citstr=" D07-1052 ">
to improve the performance further, many deep knowledge resources like shallow syntactic and semantic knowledge are exploited for coreference resolution (harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; denis and baldridge, 2007; <papid> N07-1030 </papid>ponzetto and strube, 2005; versley, 2007; <papid> D07-1052 </papid>ng, 2007).</citsent>
<aftsection>
<nextsent>in order to make use of more syntactic information, kong et al(2010) <papid> C10-1068 </papid>employ tree kernel to anaphoricity determination for coreference resolution and show that applying proper tree structure in corefernce resolution can achieve good performance.</nextsent>
<nextsent>the conll-2011 share task (pradhan et al., 2011) <papid> W11-1901 </papid>modeling unrestricted coreference in ontonotes?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3124">
<title id=" W11-1909.xml">combining syntactic and semantic features by svm for unrestricted coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, automatic coreference resolution is hard task since it needs both syntactic and semantic knowledge and some intra-document knowledge.
</prevsent>
<prevsent>to improve the performance further, many deep knowledge resources like shallow syntactic and semantic knowledge are exploited for coreference resolution (harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; denis and baldridge, 2007; <papid> N07-1030 </papid>ponzetto and strube, 2005; versley, 2007; <papid> D07-1052 </papid>ng, 2007).</prevsent>
</prevsection>
<citsent citstr=" C10-1068 ">
in order to make use of more syntactic information, kong et al(2010) <papid> C10-1068 </papid>employ tree kernel to anaphoricity determination for coreference resolution and show that applying proper tree structure in corefernce resolution can achieve good performance.</citsent>
<aftsection>
<nextsent>the conll-2011 share task (pradhan et al., 2011) <papid> W11-1901 </papid>modeling unrestricted coreference in ontonotes?</nextsent>
<nextsent>proposes task about unrestricted coreference resolution, which aims to recognize mentions and find coreference chains in one docu ment.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3125">
<title id=" W11-1909.xml">combining syntactic and semantic features by svm for unrestricted coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to improve the performance further, many deep knowledge resources like shallow syntactic and semantic knowledge are exploited for coreference resolution (harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; denis and baldridge, 2007; <papid> N07-1030 </papid>ponzetto and strube, 2005; versley, 2007; <papid> D07-1052 </papid>ng, 2007).</prevsent>
<prevsent>in order to make use of more syntactic information, kong et al(2010) <papid> C10-1068 </papid>employ tree kernel to anaphoricity determination for coreference resolution and show that applying proper tree structure in corefernce resolution can achieve good performance.</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
the conll-2011 share task (pradhan et al., 2011) <papid> W11-1901 </papid>modeling unrestricted coreference in ontonotes?</citsent>
<aftsection>
<nextsent>proposes task about unrestricted coreference resolution, which aims to recognize mentions and find coreference chains in one document.
</nextsent>
<nextsent>we participate in the closed test.
</nextsent>
<nextsent>in this paper, we exploit multi-features to coreference resolution system for the conll-2011share task, including flat features and tree structure feature.
</nextsent>
<nextsent>the task is divided into two steps in our system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3127">
<title id=" W11-1909.xml">combining syntactic and semantic features by svm for unrestricted coreference resolution </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>our experiments are all carried out on conll-2011 share task dataset (pradhan et al, 2007).
</prevsent>
<prevsent>the result of mention identification in the first step is evaluated through mention recall.
</prevsent>
</prevsection>
<citsent citstr=" S10-1001 ">
and the performance of coreference resolution in the second step is measured using the average f1-measures of muc, b-cubed and ceafe metrics (recasens etal., 2010).<papid> S10-1001 </papid></citsent>
<aftsection>
<nextsent>all the evaluations are implemented using the scorer downloaded from the conll-2011 share task website 1 . 1http://conll.bbn.com/index.php/software.html 3.1 rule-based identification of mentions.
</nextsent>
<nextsent>the mention recall of our system in the mention dentification step reaches 87.69%, which can result in good performance of the coreference resolutionstep.
</nextsent>
<nextsent>we also do comparative experiments to investigate the effect of our rule-based mention identification.
</nextsent>
<nextsent>the result is shown in table 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3129">
<title id=" W12-1624.xml">landmark based location belief tracking in a spoken dialog system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, asr is notoriously error-prone and modern asr engines provide ranked lists of possible interpretations of speech input rather than single hypotheses.
</prevsent>
<prevsent>second, the suit ability of particular landmark or its likelihood of usage by the speaker depends on number of factors such as distance, size and prominence of the land mark, familiarity of the user and his expectation of 169 common ground for understanding.
</prevsent>
</prevsection>
<citsent citstr=" W10-4306 ">
these factors, or at least the resulting variability, must be taken into account when making inferences about target locations from landmark-based expressions.the first source of ambiguity (speech understand ing) has been the target of research on belief tracking (mehta et al, 2010; <papid> W10-4306 </papid>raux and ma, 2011; thomson and young, 2010).</citsent>
<aftsection>
<nextsent>in previous work, the concepts of interest are entities that are onto logically related(i.e. with is-a or has-a relations), thus discrete probabilistic graphical models such as dbns have generally sufficed as representations.
</nextsent>
<nextsent>but these models are ill-suited for dense continuous spatial relations like the distance between any two locations on map.
</nextsent>
<nextsent>in this paper, we introduce kernel-based belief tracker as probabilistic model for inferring target locations from (uncertain) landmarks.
</nextsent>
<nextsent>the kernel-based representation allows natural way to weigh the suitability of landmark and the speech understanding confidence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3130">
<title id=" W12-0105.xml">natural language descriptions of visual scenes corpus generation and analysis </title>
<section> corpus creation.  </section>
<citcontext>
<prevsection>
<prevsent>for most of these datasets annotations are available in the form of keywords (e.g., actions such as sit, stand, walk).
</prevsent>
<prevsent>they were developed for keyword search, object recognition or event identification tasks.
</prevsent>
</prevsection>
<citsent citstr=" W10-0721 ">
rashtchian et al(2010) <papid> W10-0721 </papid>provided an interesting dataset of 1000 images which contain natural language descriptions of those images.</citsent>
<aftsection>
<nextsent>in this study we select video clips from trec video benchmark for creating annotations.
</nextsent>
<nextsent>they include categories such as news, meeting, crowd, grouping, indoor/outdoor scene settings, traffic, costume, documentary, identity, music, sports and animals videos.
</nextsent>
<nextsent>the most important and probably the most frequent content in these videos appears to be human (or humans), showing their activities, emotions and interactions with other objects.
</nextsent>
<nextsent>we do not intend to derive dataset with full scope of video categories, which is beyond our work.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3131">
<title id=" W12-0105.xml">natural language descriptions of visual scenes corpus generation and analysis </title>
<section> corpus analysis.  </section>
<citcontext>
<prevsection>
<prevsent>while keyword is mostly used for showing separate activities of multiple humans such as man is walking while woman is sitting?.
</prevsent>
<prevsent>3.5 similarity between descriptions.
</prevsent>
</prevsection>
<citsent citstr=" J04-1005 ">
a well-established approach to calculating humaninter-annotator agreement is kappa statistics (eu genio and glass, 2004).<papid> J04-1005 </papid></citsent>
<aftsection>
<nextsent>however in the current task it is not possible to compute inter-annotatoragreement using this approach because no category was defined for video descriptions.
</nextsent>
<nextsent>further the description length for one video can vary among annotators.
</nextsent>
<nextsent>alternatively the similarity between natural language descriptions can be calcu lated; an effective and commonly used measure to find the similarity between pair of documents is the overlap similarity coefficient (manning and schutze, 1999): simoverlap(x,y ) = |s(x,n) ? s(y, n)| min(|s(x,n)|, |s(y, n)|) where s(x,n) and s(y, n) are the set of distinct n-grams in documents and respectively.
</nextsent>
<nextsent>it is similarity measure related to the jaccard index(tan et al, 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3132">
<title id=" W12-1622.xml">global features for shallow discourse parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are relevant studies on the impact of global and local features on the models for natural language understanding.
</prevsent>
<prevsent>in this work we address similar problem in the context of discourse parsing.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
although good number of the papers in this area heavily relyon local classifiers (grosz et al , 1995; <papid> J95-2003 </papid>soricut et al , 2003; lapata, 2003; <papid> P03-1069 </papid>barzilay et al , 2005), there are still some important works using global and local informations together to form model of discourse (grosz et al , 1992; barzilay et al , 2004; soricut et al , 2006).</citsent>
<aftsection>
<nextsent>one of the main issues is the basis of the choice between global or local or joint model for discourse parsing: it all depends on the criteria to be able to capture maximum amount of information inside the discourse model.
</nextsent>
<nextsent>the policy for discourse segmentation plays big role to formulate the maximizing criteria (grosz et al , 1992).
</nextsent>
<nextsent>westudy in the literature that defining discourse segment is mostly data-driven process: some argue for prosodic units, some for intentional structure and some for clause-like structures.
</nextsent>
<nextsent>we work with pdtb 2.0 annotation framework, therefore use aclause-like structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3133">
<title id=" W12-1622.xml">global features for shallow discourse parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are relevant studies on the impact of global and local features on the models for natural language understanding.
</prevsent>
<prevsent>in this work we address similar problem in the context of discourse parsing.
</prevsent>
</prevsection>
<citsent citstr=" P03-1069 ">
although good number of the papers in this area heavily relyon local classifiers (grosz et al , 1995; <papid> J95-2003 </papid>soricut et al , 2003; lapata, 2003; <papid> P03-1069 </papid>barzilay et al , 2005), there are still some important works using global and local informations together to form model of discourse (grosz et al , 1992; barzilay et al , 2004; soricut et al , 2006).</citsent>
<aftsection>
<nextsent>one of the main issues is the basis of the choice between global or local or joint model for discourse parsing: it all depends on the criteria to be able to capture maximum amount of information inside the discourse model.
</nextsent>
<nextsent>the policy for discourse segmentation plays big role to formulate the maximizing criteria (grosz et al , 1992).
</nextsent>
<nextsent>westudy in the literature that defining discourse segment is mostly data-driven process: some argue for prosodic units, some for intentional structure and some for clause-like structures.
</nextsent>
<nextsent>we work with pdtb 2.0 annotation framework, therefore use aclause-like structure.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3134">
<title id=" W12-1622.xml">global features for shallow discourse parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>still thereis room for improvement with more structure level information to that discourse model; though it is cost-intensive to modify this discourse model.
</prevsent>
<prevsent>therefore in this paper we re-use the model (ghosh et al , 2011a) and optimize the current loss function adding the global features through reranking of the single-best model.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
reranking has been popular technique applied in variety of comparable nlp problems including parsing (collins, 2000; 150 charniak and johnson, 2005), <papid> P05-1022 </papid>semantic role labeling (toutanova et al , 2008), np bracketing (daume iii et al , 2004), ner (collins, 2002), <papid> P02-1062 </papid>opinion expression detection (johansson and moschitti, 2010), <papid> W10-2910 </papid>now we employ this technique in the area of discourse parsing.in the next sections, we detail on the backgrounds and motivations of this work, before this we also add short discussion on pdtb (penn discourse treebank), i.e. the data we used to tra inthe system.</citsent>
<aftsection>
<nextsent>then we proceed to the reranking approaches and results sections after describing our global feature set.
</nextsent>
<nextsent>finally we state and analyze the results.
</nextsent>
<nextsent>the penn discourse treebank (pdtb) is resource containing one million words from thewallstreet journal corpus (marcus et al , 1993) <papid> J93-2004 </papid>annotated with discourse relations.connectives in the ptdb are treated as discourse predicates taking two text spans as arguments (arg), i.e. parts of the text that describe events, propositions, facts, situations.</nextsent>
<nextsent>such two arguments in the pdtb are called arg1 andarg2, with the numbering not necessarily corresponding to their order in text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3135">
<title id=" W12-1622.xml">global features for shallow discourse parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>still thereis room for improvement with more structure level information to that discourse model; though it is cost-intensive to modify this discourse model.
</prevsent>
<prevsent>therefore in this paper we re-use the model (ghosh et al , 2011a) and optimize the current loss function adding the global features through reranking of the single-best model.
</prevsent>
</prevsection>
<citsent citstr=" P02-1062 ">
reranking has been popular technique applied in variety of comparable nlp problems including parsing (collins, 2000; 150 charniak and johnson, 2005), <papid> P05-1022 </papid>semantic role labeling (toutanova et al , 2008), np bracketing (daume iii et al , 2004), ner (collins, 2002), <papid> P02-1062 </papid>opinion expression detection (johansson and moschitti, 2010), <papid> W10-2910 </papid>now we employ this technique in the area of discourse parsing.in the next sections, we detail on the backgrounds and motivations of this work, before this we also add short discussion on pdtb (penn discourse treebank), i.e. the data we used to tra inthe system.</citsent>
<aftsection>
<nextsent>then we proceed to the reranking approaches and results sections after describing our global feature set.
</nextsent>
<nextsent>finally we state and analyze the results.
</nextsent>
<nextsent>the penn discourse treebank (pdtb) is resource containing one million words from thewallstreet journal corpus (marcus et al , 1993) <papid> J93-2004 </papid>annotated with discourse relations.connectives in the ptdb are treated as discourse predicates taking two text spans as arguments (arg), i.e. parts of the text that describe events, propositions, facts, situations.</nextsent>
<nextsent>such two arguments in the pdtb are called arg1 andarg2, with the numbering not necessarily corresponding to their order in text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3136">
<title id=" W12-1622.xml">global features for shallow discourse parsing </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>still thereis room for improvement with more structure level information to that discourse model; though it is cost-intensive to modify this discourse model.
</prevsent>
<prevsent>therefore in this paper we re-use the model (ghosh et al , 2011a) and optimize the current loss function adding the global features through reranking of the single-best model.
</prevsent>
</prevsection>
<citsent citstr=" W10-2910 ">
reranking has been popular technique applied in variety of comparable nlp problems including parsing (collins, 2000; 150 charniak and johnson, 2005), <papid> P05-1022 </papid>semantic role labeling (toutanova et al , 2008), np bracketing (daume iii et al , 2004), ner (collins, 2002), <papid> P02-1062 </papid>opinion expression detection (johansson and moschitti, 2010), <papid> W10-2910 </papid>now we employ this technique in the area of discourse parsing.in the next sections, we detail on the backgrounds and motivations of this work, before this we also add short discussion on pdtb (penn discourse treebank), i.e. the data we used to tra inthe system.</citsent>
<aftsection>
<nextsent>then we proceed to the reranking approaches and results sections after describing our global feature set.
</nextsent>
<nextsent>finally we state and analyze the results.
</nextsent>
<nextsent>the penn discourse treebank (pdtb) is resource containing one million words from thewallstreet journal corpus (marcus et al , 1993) <papid> J93-2004 </papid>annotated with discourse relations.connectives in the ptdb are treated as discourse predicates taking two text spans as arguments (arg), i.e. parts of the text that describe events, propositions, facts, situations.</nextsent>
<nextsent>such two arguments in the pdtb are called arg1 andarg2, with the numbering not necessarily corresponding to their order in text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3137">
<title id=" W12-1622.xml">global features for shallow discourse parsing </title>
<section> the penn discourse treebank 2.0.  </section>
<citcontext>
<prevsection>
<prevsent>then we proceed to the reranking approaches and results sections after describing our global feature set.
</prevsent>
<prevsent>finally we state and analyze the results.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the penn discourse treebank (pdtb) is resource containing one million words from thewallstreet journal corpus (marcus et al , 1993) <papid> J93-2004 </papid>annotated with discourse relations.connectives in the ptdb are treated as discourse predicates taking two text spans as arguments (arg), i.e. parts of the text that describe events, propositions, facts, situations.</citsent>
<aftsection>
<nextsent>such two arguments in the pdtb are called arg1 andarg2, with the numbering not necessarily corresponding to their order in text.
</nextsent>
<nextsent>indeed, arg2 isthe argument syntactically bound to the connective, while arg1 is the other one.
</nextsent>
<nextsent>in the pdtb, discourse relations can be either overtly or implicitly expressed.
</nextsent>
<nextsent>however, we focus here exclusively on explicit connectives and the identification of their arguments, including the exact spans.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3139">
<title id=" W12-1622.xml">global features for shallow discourse parsing </title>
<section> the penn discourse treebank 2.0.  </section>
<citcontext>
<prevsection>
<prevsent>however, we focus here exclusively on explicit connectives and the identification of their arguments, including the exact spans.
</prevsent>
<prevsent>this kind of classification is very complex, since arg1 and arg2 can occur in many different configurations (see table 1).
</prevsent>
</prevsection>
<citsent citstr=" L08-1093 ">
explicit connectives (tokens) 18, 459 explicit connectives (types) 100 arg1 in same sentence as connective 60.9% arg1 in previous, adjacent sentence 30.1% arg1 in previous, non adjacent sentence 9.0% table 1: statistics about pdtb annotation from prasad et al (2008).<papid> L08-1093 </papid></citsent>
<aftsection>
<nextsent>in pdtb the senses are assigned according to three-layered hierarchy: the top-level classes are the most generic ones and include temporal, contingency, comparison and expansion labels.
</nextsent>
<nextsent>we used these four surface senses only in our task.
</nextsent>
<nextsent>2.1 backgrounds &amp; motivation.
</nextsent>
<nextsent>currently we are using the single-best discourse parser by ghosh et al  (2011a).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3140">
<title id=" W12-1622.xml">global features for shallow discourse parsing </title>
<section> the penn discourse treebank 2.0.  </section>
<citcontext>
<prevsection>
<prevsent>currently we are using the single-best discourse parser by ghosh et al  (2011a).
</prevsent>
<prevsent>this discourse parser can automatically extract of discourse arguments using pipeline, illustrated in fig 1.first, we input the explicit discourse connectives (with senses) to the system.
</prevsent>
</prevsection>
<citsent citstr=" P09-2004 ">
these can be the gold labeled or automatically identified (pitler and nenkova, 2009);<papid> P09-2004 </papid>for simplicity here weuse penn discourse treebank (pdtb 2.0) gold standard connectives (cf.</citsent>
<aftsection>
<nextsent>see 2).
</nextsent>
<nextsent>then cascaded module is applied extracting the arg2 arguments, then the arg1s are extracted.figure 1: pipeline for argument detection given connec tive.the arg2 and arg1 extractors are implemented as conditional random field sequence la belers, which use set of syntactic and structural features (cf.
</nextsent>
<nextsent>ghosh et al  (2011a)).
</nextsent>
<nextsent>in order to reduce the complexities, the sentence containing the connective, and context window of up to two sentences before and after are supplied to these quence labelers.we present passage of 6 sentences from nutrition journal article parsed with that parser 1.:  conn id=1,sense=comparison  although /conn id=1   arg2 id=1  the mechanism of obesity development is not fully understood, it is confirmed  arg1 id=2 that obesity occurs /arg1 id=2   conn id=2,sense=temporal when /conn id=2   arg2 id=2 energy intake exceeds energy expenditure /arg2 id=2   /arg2 id=1 .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3145">
<title id=" W12-1622.xml">global features for shallow discourse parsing </title>
<section> reranking approaches.  </section>
<citcontext>
<prevsection>
<prevsent>in this paper we followed two approaches for the reranking task: 1.
</prevsent>
<prevsent>structured learning approach: in this case.
</prevsent>
</prevsection>
<citsent citstr=" P02-1034 ">
the reranker learns directly from scoring function that is trained to maximize the performance of the reranking task (collins and duffy, 2002).<papid> P02-1034 </papid></citsent>
<aftsection>
<nextsent>we also investigate two popular and efficient online structured learning algorithms: the structured voted perceptron by collins and duffy (2002) <papid> P02-1034 </papid>and passive-aggressive(pa) algorithm by crammer et al  (2006).</nextsent>
<nextsent>the weight-vectors observed from the training phase are averaged following schapire and freund (1999).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3147">
<title id=" W12-1622.xml">global features for shallow discourse parsing </title>
<section> reranking approaches.  </section>
<citcontext>
<prevsection>
<prevsent>2.
</prevsent>
<prevsent>best vs. rest approach: in the prefer-.
</prevsent>
</prevsection>
<citsent citstr=" W03-0402 ">
ence kernel approach (shen and joshi, 2003) <papid> W03-0402 </papid>the reranking problem is reduced to binary classification task on pairs.</citsent>
<aftsection>
<nextsent>this reduction enables even standard support vector machine to optimize the problem.
</nextsent>
<nextsent>we use component of this task.
</nextsent>
<nextsent>we define the best scored discourse window (section4.1) as positive example and the rest are the negatives to the system.
</nextsent>
<nextsent>we use standard support vector machine (vapnik, 1995) with linear kernel.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3156">
<title id=" W12-1520.xml">blogging birds generating narratives about reintroduced species to promote public engagement </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>data-to-text systems (e.g., goldberg et al (1994);theune et al (2001); portet et al (2009)) have typ 120 (a) (b) figure 1: plot of (a) distance from nest as function of time, and (b) clusters of visited locations.
</prevsent>
<prevsent>ically been used to generate summaries of technical data for professionals, such as engineers, nurses and oil rig workers.
</prevsent>
</prevsection>
<citsent citstr=" W10-1301 ">
there is some work on the use ofdata-to-text for lay audiences; e.g., generating narratives from sensor data for automotive (reddington et al, 2011) and environmental (molina et al, 2011) applications, generating personal narratives to help children with complex communication needs (black et al, 2010), <papid> W10-1301 </papid>and summarising neonatal intensive care data for parents (mahamood et al, 2008).</citsent>
<aftsection>
<nextsent>our application differs from the above-mentioneddata-to-text applications, in that we aim to generate inspiring as well as informative texts.
</nextsent>
<nextsent>it bears some resemblance to nlg systems that offer info tainment?, such as dial your disc (van deemter and odijk, 1997) and ilex (odonnell et al, 2001).
</nextsent>
<nextsent>infact, dial your disc, which generates spoken monologues about classical music, focused emphatically on generating engaging texts, and achieved linguistic variation through the use of recursive, syntactically structured templates (see also, theune et al (2001)).
</nextsent>
<nextsent>we intend to extend data-to-text system in similar ways, using ecological insights to make narratives engaging for non-experts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3157">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> abstract </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P06-1055 ">
we provide model that extends the split merge framework of petrov et al (2006)<papid> P06-1055 </papid>to jointly learn latent annotations and tree substitution grammars (tsgs).</citsent>
<aftsection>
<nextsent>we then conduct variety of experiments with this model, first inducing grammars on portion of the penn treebank and the korean treebank 2.0, and next experimenting with grammar refinement from single nonterminal and from the universal part of speech tagset.
</nextsent>
<nextsent>we present qualitative analysis showing promising signs across all experiments that our combined approach successfully provides for greater flexibility in grammar induction within the structured guidance provided by the treebank, leveraging the complementary natures of these two approaches.
</nextsent>
<nextsent>context-free grammars (cfgs) are useful tool for describing the structure of language, modeling variety of linguistic phenomena while still permitting efficient inference.
</nextsent>
<nextsent>however, it is widely acknowledged that cfgs employed in practice make unrealistic independence and structural assumptions, resulting in grammars that are overly permissive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3160">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>context-free grammars (cfgs) are useful tool for describing the structure of language, modeling variety of linguistic phenomena while still permitting efficient inference.
</prevsent>
<prevsent>however, it is widely acknowledged that cfgs employed in practice make unrealistic independence and structural assumptions, resulting in grammars that are overly permissive.
</prevsent>
</prevsection>
<citsent citstr=" J98-4004 ">
one successful approach has been to refine the nonterminals of grammars, first manually (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003) <papid> P03-1054 </papid>and later automatically (matsuzaki et al, 2005; <papid> P05-1010 </papid>dreyer and eisner, 2006;<papid> W06-1638 </papid>petrov et al, 2006).<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>in addition to improving parsing accuracy, the automatically learned latent annotations of these latter approaches yield results that accord well with human intuitions, especially at the lexical or pre terminal level (for example, separating demonstrative adjectives from definite articles under the dt tag).
</nextsent>
<nextsent>it is more difficult, though, to extend this analysis to higher-level nonterminals, where the long-distance interactions among latent annotations of internal nodes are subtle and difficult to trace.in another line of work, many researchers have examined the use of formalisms with an extended do main of locality (joshi and schabes, 1997), where the basic grammatical units are arbitrary tree fragments instead of traditional depth-one context-freegrammar productions.
</nextsent>
<nextsent>in particular, tree substitution grammars (tsgs) retain the context-free properties of cfgs (and thus the cubic-time inference) while at the same time allowing for the modeling of long distance dependencies.
</nextsent>
<nextsent>fragments from such grammars are intuitive, capturing exactly the sorts of phrasal-level properties (such as predicate-argument structure) that are not present in treebank cfgs and which are difficult to model with latent annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3161">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>context-free grammars (cfgs) are useful tool for describing the structure of language, modeling variety of linguistic phenomena while still permitting efficient inference.
</prevsent>
<prevsent>however, it is widely acknowledged that cfgs employed in practice make unrealistic independence and structural assumptions, resulting in grammars that are overly permissive.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
one successful approach has been to refine the nonterminals of grammars, first manually (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003) <papid> P03-1054 </papid>and later automatically (matsuzaki et al, 2005; <papid> P05-1010 </papid>dreyer and eisner, 2006;<papid> W06-1638 </papid>petrov et al, 2006).<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>in addition to improving parsing accuracy, the automatically learned latent annotations of these latter approaches yield results that accord well with human intuitions, especially at the lexical or pre terminal level (for example, separating demonstrative adjectives from definite articles under the dt tag).
</nextsent>
<nextsent>it is more difficult, though, to extend this analysis to higher-level nonterminals, where the long-distance interactions among latent annotations of internal nodes are subtle and difficult to trace.in another line of work, many researchers have examined the use of formalisms with an extended do main of locality (joshi and schabes, 1997), where the basic grammatical units are arbitrary tree fragments instead of traditional depth-one context-freegrammar productions.
</nextsent>
<nextsent>in particular, tree substitution grammars (tsgs) retain the context-free properties of cfgs (and thus the cubic-time inference) while at the same time allowing for the modeling of long distance dependencies.
</nextsent>
<nextsent>fragments from such grammars are intuitive, capturing exactly the sorts of phrasal-level properties (such as predicate-argument structure) that are not present in treebank cfgs and which are difficult to model with latent annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3162">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>context-free grammars (cfgs) are useful tool for describing the structure of language, modeling variety of linguistic phenomena while still permitting efficient inference.
</prevsent>
<prevsent>however, it is widely acknowledged that cfgs employed in practice make unrealistic independence and structural assumptions, resulting in grammars that are overly permissive.
</prevsent>
</prevsection>
<citsent citstr=" P05-1010 ">
one successful approach has been to refine the nonterminals of grammars, first manually (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003) <papid> P03-1054 </papid>and later automatically (matsuzaki et al, 2005; <papid> P05-1010 </papid>dreyer and eisner, 2006;<papid> W06-1638 </papid>petrov et al, 2006).<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>in addition to improving parsing accuracy, the automatically learned latent annotations of these latter approaches yield results that accord well with human intuitions, especially at the lexical or pre terminal level (for example, separating demonstrative adjectives from definite articles under the dt tag).
</nextsent>
<nextsent>it is more difficult, though, to extend this analysis to higher-level nonterminals, where the long-distance interactions among latent annotations of internal nodes are subtle and difficult to trace.in another line of work, many researchers have examined the use of formalisms with an extended do main of locality (joshi and schabes, 1997), where the basic grammatical units are arbitrary tree fragments instead of traditional depth-one context-freegrammar productions.
</nextsent>
<nextsent>in particular, tree substitution grammars (tsgs) retain the context-free properties of cfgs (and thus the cubic-time inference) while at the same time allowing for the modeling of long distance dependencies.
</nextsent>
<nextsent>fragments from such grammars are intuitive, capturing exactly the sorts of phrasal-level properties (such as predicate-argument structure) that are not present in treebank cfgs and which are difficult to model with latent annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3163">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>context-free grammars (cfgs) are useful tool for describing the structure of language, modeling variety of linguistic phenomena while still permitting efficient inference.
</prevsent>
<prevsent>however, it is widely acknowledged that cfgs employed in practice make unrealistic independence and structural assumptions, resulting in grammars that are overly permissive.
</prevsent>
</prevsection>
<citsent citstr=" W06-1638 ">
one successful approach has been to refine the nonterminals of grammars, first manually (johnson, 1998; <papid> J98-4004 </papid>klein and manning, 2003) <papid> P03-1054 </papid>and later automatically (matsuzaki et al, 2005; <papid> P05-1010 </papid>dreyer and eisner, 2006;<papid> W06-1638 </papid>petrov et al, 2006).<papid> P06-1055 </papid></citsent>
<aftsection>
<nextsent>in addition to improving parsing accuracy, the automatically learned latent annotations of these latter approaches yield results that accord well with human intuitions, especially at the lexical or pre terminal level (for example, separating demonstrative adjectives from definite articles under the dt tag).
</nextsent>
<nextsent>it is more difficult, though, to extend this analysis to higher-level nonterminals, where the long-distance interactions among latent annotations of internal nodes are subtle and difficult to trace.in another line of work, many researchers have examined the use of formalisms with an extended do main of locality (joshi and schabes, 1997), where the basic grammatical units are arbitrary tree fragments instead of traditional depth-one context-freegrammar productions.
</nextsent>
<nextsent>in particular, tree substitution grammars (tsgs) retain the context-free properties of cfgs (and thus the cubic-time inference) while at the same time allowing for the modeling of long distance dependencies.
</nextsent>
<nextsent>fragments from such grammars are intuitive, capturing exactly the sorts of phrasal-level properties (such as predicate-argument structure) that are not present in treebank cfgs and which are difficult to model with latent annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3169">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper is motivated by the complementarity of these approaches.
</prevsent>
<prevsent>we present our progress in learning latent-variable tsgs in joint approach that extends the split-merge framework of petrov et al (2006)<papid> P06-1055 </papid></prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
we present our current results on the penn and korean treebanks (marcus et al, 1993; <papid> J93-2004 </papid>han et al., 2001), demonstrating that we are able to learn fragments that draw on the strengths of both ap proaches.</citsent>
<aftsection>
<nextsent>table 1 situ ates this work among other contributions.
</nextsent>
<nextsent>in addition to experimenting directly with the penn and korean treebanks, we also conducted two experiments in this framework with the universal 23 cfg tsg none charniak 97 cohn et al 09 manual klein &amp; manning 03 bansal &amp; klein 10 automatic matsuzaki et al 05 this paper petrov et al 06 dreyer &amp; eisner 06table 1: representative prior work in learning refinements for context-free and tree substitution grammars,with zero, manual, or automatically induced latent annotations.
</nextsent>
<nextsent>pos tagset (petrov et al, 2011).
</nextsent>
<nextsent>first, we investigate whether the tagset can be automatically derived after mapping all nonterminals to single, coarse nonterminal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3175">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>these grammars employ an extended domain of locality over traditional context free grammars by generalizing the atomic units of the grammar from depth-one productions to fragments of arbitrary size.
</prevsent>
<prevsent>an example tsg fragment along with equivalent cfg rules are depicted in figure 1.the two formalisms are weakly equivalent, and computing the most probable derivation of sentence with tsg can be done in cubic time.unfortunately, learning tsgs is not straightforward, in large part because tsg-specific resources (e.g., large scale tsg-annotated treebanks) do not exist.
</prevsent>
</prevsection>
<citsent citstr=" E93-1006 ">
one class of existing approaches, known as data-oriented parsing, simply uses all the fragments (bod, 1993, <papid> E93-1006 </papid>dop).</citsent>
<aftsection>
<nextsent>this does not scale well to large treebanks, forcing the use of implicit representations (goodman, 1996) <papid> W96-0214 </papid>or heuristic subsets (bod, 2001).<papid> P01-1010 </papid></nextsent>
<nextsent>it has also been generally observed that the use of all fragments results in poor, overfit grammars, though this can be addressed withheld-out data (zollmann and simaan, 2005) or statistical estimators to rule out fragments that are unlikely to generalize (zuidema, 2007).<papid> D07-1058 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3176">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>an example tsg fragment along with equivalent cfg rules are depicted in figure 1.the two formalisms are weakly equivalent, and computing the most probable derivation of sentence with tsg can be done in cubic time.unfortunately, learning tsgs is not straightforward, in large part because tsg-specific resources (e.g., large scale tsg-annotated treebanks) do not exist.
</prevsent>
<prevsent>one class of existing approaches, known as data-oriented parsing, simply uses all the fragments (bod, 1993, <papid> E93-1006 </papid>dop).</prevsent>
</prevsection>
<citsent citstr=" W96-0214 ">
this does not scale well to large treebanks, forcing the use of implicit representations (goodman, 1996) <papid> W96-0214 </papid>or heuristic subsets (bod, 2001).<papid> P01-1010 </papid></citsent>
<aftsection>
<nextsent>it has also been generally observed that the use of all fragments results in poor, overfit grammars, though this can be addressed withheld-out data (zollmann and simaan, 2005) or statistical estimators to rule out fragments that are unlikely to generalize (zuidema, 2007).<papid> D07-1058 </papid></nextsent>
<nextsent>more recently, number of groups have found success employing bayesian non-parametric priors (post and gildea, 2009; <papid> P09-2012 </papid>cohn et al, 2010), which put downward pressure on fragment size except where the data warrant the inclusion of larger fragments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3177">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>an example tsg fragment along with equivalent cfg rules are depicted in figure 1.the two formalisms are weakly equivalent, and computing the most probable derivation of sentence with tsg can be done in cubic time.unfortunately, learning tsgs is not straightforward, in large part because tsg-specific resources (e.g., large scale tsg-annotated treebanks) do not exist.
</prevsent>
<prevsent>one class of existing approaches, known as data-oriented parsing, simply uses all the fragments (bod, 1993, <papid> E93-1006 </papid>dop).</prevsent>
</prevsection>
<citsent citstr=" P01-1010 ">
this does not scale well to large treebanks, forcing the use of implicit representations (goodman, 1996) <papid> W96-0214 </papid>or heuristic subsets (bod, 2001).<papid> P01-1010 </papid></citsent>
<aftsection>
<nextsent>it has also been generally observed that the use of all fragments results in poor, overfit grammars, though this can be addressed withheld-out data (zollmann and simaan, 2005) or statistical estimators to rule out fragments that are unlikely to generalize (zuidema, 2007).<papid> D07-1058 </papid></nextsent>
<nextsent>more recently, number of groups have found success employing bayesian non-parametric priors (post and gildea, 2009; <papid> P09-2012 </papid>cohn et al, 2010), which put downward pressure on fragment size except where the data warrant the inclusion of larger fragments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3178">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>one class of existing approaches, known as data-oriented parsing, simply uses all the fragments (bod, 1993, <papid> E93-1006 </papid>dop).</prevsent>
<prevsent>this does not scale well to large treebanks, forcing the use of implicit representations (goodman, 1996) <papid> W96-0214 </papid>or heuristic subsets (bod, 2001).<papid> P01-1010 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1058 ">
it has also been generally observed that the use of all fragments results in poor, overfit grammars, though this can be addressed withheld-out data (zollmann and simaan, 2005) or statistical estimators to rule out fragments that are unlikely to generalize (zuidema, 2007).<papid> D07-1058 </papid></citsent>
<aftsection>
<nextsent>more recently, number of groups have found success employing bayesian non-parametric priors (post and gildea, 2009; <papid> P09-2012 </papid>cohn et al, 2010), which put downward pressure on fragment size except where the data warrant the inclusion of larger fragments.</nextsent>
<nextsent>unfortunately, proper inference under these models is intractable, and though monte carlo techniques can 24provide an approximation, the samplers can be complex, difficult to code, and slow to converge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3179">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>this does not scale well to large treebanks, forcing the use of implicit representations (goodman, 1996) <papid> W96-0214 </papid>or heuristic subsets (bod, 2001).<papid> P01-1010 </papid></prevsent>
<prevsent>it has also been generally observed that the use of all fragments results in poor, overfit grammars, though this can be addressed withheld-out data (zollmann and simaan, 2005) or statistical estimators to rule out fragments that are unlikely to generalize (zuidema, 2007).<papid> D07-1058 </papid></prevsent>
</prevsection>
<citsent citstr=" P09-2012 ">
more recently, number of groups have found success employing bayesian non-parametric priors (post and gildea, 2009; <papid> P09-2012 </papid>cohn et al, 2010), which put downward pressure on fragment size except where the data warrant the inclusion of larger fragments.</citsent>
<aftsection>
<nextsent>unfortunately, proper inference under these models is intractable, and though monte carlo techniques can 24provide an approximation, the samplers can be complex, difficult to code, and slow to converge.
</nextsent>
<nextsent>this history suggests two approaches to state-splittsgs: (1) bayesian non-parametric sampling approach (incorporate state-splitting into existing tsg work), or (2) em (incorporate tsg induction into existing state-splitting work).
</nextsent>
<nextsent>we choose the latter path, and in the next section will describe our approach which combines the simplicity of dop, the intuitions motivating the bayesian approach, and the efficiency of em-based state-splitting.
</nextsent>
<nextsent>in related work, bansal and klein (2010) <papid> P10-1112 </papid>combine(1996)s implicit dop representation with number of the manual refinements described in klein and manning (2003).<papid> P03-1054 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3181">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>this history suggests two approaches to state-splittsgs: (1) bayesian non-parametric sampling approach (incorporate state-splitting into existing tsg work), or (2) em (incorporate tsg induction into existing state-splitting work).
</prevsent>
<prevsent>we choose the latter path, and in the next section will describe our approach which combines the simplicity of dop, the intuitions motivating the bayesian approach, and the efficiency of em-based state-splitting.
</prevsent>
</prevsection>
<citsent citstr=" P10-1112 ">
in related work, bansal and klein (2010) <papid> P10-1112 </papid>combine(1996)s implicit dop representation with number of the manual refinements described in klein and manning (2003).<papid> P03-1054 </papid></citsent>
<aftsection>
<nextsent>they achieve some of the best reported parsing scores for tsgwork and demonstrate the complementarity of the tasks, but their approach is not able to learn arbitrary distributions over fragments, and the state splits are determined in fixed pre-processing step.
</nextsent>
<nextsent>our approach addresses both of these limitations.
</nextsent>
<nextsent>in this section we describe howwe combine the ideas of dop, bayesian-induced tsgs and petrov et al (2006)<papid> P06-1055 </papid>s state-splitting framework.1 we are able to do so by adding coupling step to each iteration.</nextsent>
<nextsent>that is, each iteration is of the form: (1) split all symbols in two, (2) merge 50% of the splits, and (3) couple existing fragments.because every step results in new grammar, production probabilities are fit to observed data by running at most 50 rounds of em after every step listedabove.2 we focus on our contribution ? the coupling step?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3195">
<title id=" W12-1904.xml">toward tree substitution grammars with latent annotations </title>
<section> datasets.  </section>
<citcontext>
<prevsection>
<prevsent>we perform qualitative analysis of fragments learned on datasets for two languages: the korean treebank v2.0 (han and ryu, 2005) and comparably-sized portion of the wsj portion of the penn treebank (marcus et al, 1993).<papid> J93-2004 </papid></prevsent>
<prevsent>the korean treebank (ktb) has predefined splits; to be comparable for our analysis, from the ptb we used 2-3 for training and 22 for validation (we refer to thisas wsj2-3).</prevsent>
</prevsection>
<citsent citstr=" W10-1406 ">
as described in chung et al (2010), <papid> W10-1406 </papid>although korean presents its own challenges to grammar induction, the ktb yields additional difficulties by including high occurrence of very flat rules (in 5k sentences, there are 13 np rules with at least four right hand side nps) and coarser nonterminal set than that of the penn treebank.</citsent>
<aftsection>
<nextsent>on both sets, we run for two iterations.
</nextsent>
<nextsent>recall that our algorithm is designed to induce state-split tsg on binarized tree; as neither dataset is binarized in native form we apply left-branching binarization across all trees in both collections as apreprocessing step.
</nextsent>
<nextsent>petrov et al (2006)<papid> P06-1055 </papid>found different binarization methods to be inconsequential, andwe have yet to observe significant impact of this bi nar ization decision (this will be considered in more detail in future work).</nextsent>
<nextsent>recently petrov et al (2011) provided set of coarse, universal?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3199">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automated assessment (hereafter aa) systems of english learner text assign grades based on textual features which attempt to balance evidence of writing competence against evidence of performance errors.
</prevsent>
<prevsent>previous work has mostly treated aa as supervised text classification or regression task.
</prevsent>
</prevsection>
<citsent citstr=" P11-1019 ">
anumber of techniques have been investigated, including cosine similarity of feature vectors (attaliand burstein, 2006), often combined with dimensionality reduction techniques such as latent semantic analysis (lsa) (landauer et al , 2003), and generative machine learning models (rudner and liang, 2002) as well as discriminative ones (yannakoudakis et al , 2011).<papid> P11-1019 </papid></citsent>
<aftsection>
<nextsent>as multiple factors influence the linguistic quality of texts, such systems exploit features that correspond to different properties of texts, such as grammar, style, vocabulary usage,topic similarity, and discourse coherence and cohesion.
</nextsent>
<nextsent>cohesion refers to the use of explicit linguistic cohesive devices (e.g., anaphora, lexical semantic relatedness, discourse markers, etc.) within text that can signal primarily supra sentential discourse relations between textual units (halliday and hasan,1976).
</nextsent>
<nextsent>cohesion is not the only mechanism of discourse coherence, which may also be inferred from meaning without presence of explicit linguistic cues.coherence can be assessed locally in terms of transitions between adjacent clauses, parentheticals, and other textual units capable of standing in discourse relations, or more globally in terms of the overall topical coherence of text passages.there is large body of work that has investigated number of different coherence models onnews texts (e.g., lin et al  (2011), <papid> P11-1100 </papid>elsner and charniak (2008), <papid> P08-2011 </papid>and soricut and marcu (2006)).<papid> P06-2103 </papid></nextsent>
<nextsent>recently, pitler et al  (2010) <papid> P10-1056 </papid>presented detailed survey of current techniques incoherence analysis of extractive summaries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3200">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as multiple factors influence the linguistic quality of texts, such systems exploit features that correspond to different properties of texts, such as grammar, style, vocabulary usage,topic similarity, and discourse coherence and cohesion.
</prevsent>
<prevsent>cohesion refers to the use of explicit linguistic cohesive devices (e.g., anaphora, lexical semantic relatedness, discourse markers, etc.) within text that can signal primarily supra sentential discourse relations between textual units (halliday and hasan,1976).
</prevsent>
</prevsection>
<citsent citstr=" P11-1100 ">
cohesion is not the only mechanism of discourse coherence, which may also be inferred from meaning without presence of explicit linguistic cues.coherence can be assessed locally in terms of transitions between adjacent clauses, parentheticals, and other textual units capable of standing in discourse relations, or more globally in terms of the overall topical coherence of text passages.there is large body of work that has investigated number of different coherence models onnews texts (e.g., lin et al  (2011), <papid> P11-1100 </papid>elsner and charniak (2008), <papid> P08-2011 </papid>and soricut and marcu (2006)).<papid> P06-2103 </papid></citsent>
<aftsection>
<nextsent>recently, pitler et al  (2010) <papid> P10-1056 </papid>presented detailed survey of current techniques incoherence analysis of extractive summaries.</nextsent>
<nextsent>to date, however, few attempt shave been made to develop new methods and validate existing ones for automatic evaluation of discourse coherence and cohesion in the noisy domain of learner texts, where spelling and grammatical errors are common.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3201">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as multiple factors influence the linguistic quality of texts, such systems exploit features that correspond to different properties of texts, such as grammar, style, vocabulary usage,topic similarity, and discourse coherence and cohesion.
</prevsent>
<prevsent>cohesion refers to the use of explicit linguistic cohesive devices (e.g., anaphora, lexical semantic relatedness, discourse markers, etc.) within text that can signal primarily supra sentential discourse relations between textual units (halliday and hasan,1976).
</prevsent>
</prevsection>
<citsent citstr=" P08-2011 ">
cohesion is not the only mechanism of discourse coherence, which may also be inferred from meaning without presence of explicit linguistic cues.coherence can be assessed locally in terms of transitions between adjacent clauses, parentheticals, and other textual units capable of standing in discourse relations, or more globally in terms of the overall topical coherence of text passages.there is large body of work that has investigated number of different coherence models onnews texts (e.g., lin et al  (2011), <papid> P11-1100 </papid>elsner and charniak (2008), <papid> P08-2011 </papid>and soricut and marcu (2006)).<papid> P06-2103 </papid></citsent>
<aftsection>
<nextsent>recently, pitler et al  (2010) <papid> P10-1056 </papid>presented detailed survey of current techniques incoherence analysis of extractive summaries.</nextsent>
<nextsent>to date, however, few attempt shave been made to develop new methods and validate existing ones for automatic evaluation of discourse coherence and cohesion in the noisy domain of learner texts, where spelling and grammatical errors are common.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3203">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as multiple factors influence the linguistic quality of texts, such systems exploit features that correspond to different properties of texts, such as grammar, style, vocabulary usage,topic similarity, and discourse coherence and cohesion.
</prevsent>
<prevsent>cohesion refers to the use of explicit linguistic cohesive devices (e.g., anaphora, lexical semantic relatedness, discourse markers, etc.) within text that can signal primarily supra sentential discourse relations between textual units (halliday and hasan,1976).
</prevsent>
</prevsection>
<citsent citstr=" P06-2103 ">
cohesion is not the only mechanism of discourse coherence, which may also be inferred from meaning without presence of explicit linguistic cues.coherence can be assessed locally in terms of transitions between adjacent clauses, parentheticals, and other textual units capable of standing in discourse relations, or more globally in terms of the overall topical coherence of text passages.there is large body of work that has investigated number of different coherence models onnews texts (e.g., lin et al  (2011), <papid> P11-1100 </papid>elsner and charniak (2008), <papid> P08-2011 </papid>and soricut and marcu (2006)).<papid> P06-2103 </papid></citsent>
<aftsection>
<nextsent>recently, pitler et al  (2010) <papid> P10-1056 </papid>presented detailed survey of current techniques incoherence analysis of extractive summaries.</nextsent>
<nextsent>to date, however, few attempt shave been made to develop new methods and validate existing ones for automatic evaluation of discourse coherence and cohesion in the noisy domain of learner texts, where spelling and grammatical errors are common.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3204">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>cohesion refers to the use of explicit linguistic cohesive devices (e.g., anaphora, lexical semantic relatedness, discourse markers, etc.) within text that can signal primarily supra sentential discourse relations between textual units (halliday and hasan,1976).
</prevsent>
<prevsent>cohesion is not the only mechanism of discourse coherence, which may also be inferred from meaning without presence of explicit linguistic cues.coherence can be assessed locally in terms of transitions between adjacent clauses, parentheticals, and other textual units capable of standing in discourse relations, or more globally in terms of the overall topical coherence of text passages.there is large body of work that has investigated number of different coherence models onnews texts (e.g., lin et al  (2011), <papid> P11-1100 </papid>elsner and charniak (2008), <papid> P08-2011 </papid>and soricut and marcu (2006)).<papid> P06-2103 </papid></prevsent>
</prevsection>
<citsent citstr=" P10-1056 ">
recently, pitler et al  (2010) <papid> P10-1056 </papid>presented detailed survey of current techniques incoherence analysis of extractive summaries.</citsent>
<aftsection>
<nextsent>to date, however, few attempt shave been made to develop new methods and validate existing ones for automatic evaluation of discourse coherence and cohesion in the noisy domain of learner texts, where spelling and grammatical errors are common.
</nextsent>
<nextsent>coherence quality is typically present in marking criteria for evaluating learner texts, and it is iden 33 tified by examiners as determinant of the overallscore.
</nextsent>
<nextsent>thus we expect that adding coherence metric to the feature set of an aa system would better reflect the evaluation performed by examiners and improve performance.
</nextsent>
<nextsent>the goal of the experiments presented in this paper is to measure the effect anumber of (previously-developed and new) coherence models have on performance when combined with an aa system that achieves competitive results, but does not use discourse coherence features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3227">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>2http://ilexir.co.uk/applications/clc-fce-dataset/ 3http://www.cup.cam.ac.uk/gb/elt/catalogue/subject/custom /item3646603/ 34texts under the framework of aa.
</prevsent>
<prevsent>most of the methods we investigate require syntactic analysis.
</prevsent>
</prevsection>
<citsent citstr=" P06-4020 ">
as in yannakoudakis et al  (2011), <papid> P11-1019 </papid>we analyze all texts using the rasp toolkit (briscoe et al , 2006)<papid> P06-4020 </papid>4.</citsent>
<aftsection>
<nextsent>4.1 superficial?
</nextsent>
<nextsent>proxies in this section we introduce diverse classes of su perficial?
</nextsent>
<nextsent>cohesive features that serve as proxies forcoherence.
</nextsent>
<nextsent>surface text properties have been assessed in the framework of automatic summary evaluation (pitler et al , 2010), <papid> P10-1056 </papid>and have been shown to significantly correlate with the fluency of machine translated sentences (chae and nenkova, 2009).<papid> E09-1017 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3229">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>proxies in this section we introduce diverse classes of su perficial?
</prevsent>
<prevsent>cohesive features that serve as proxies forcoherence.
</prevsent>
</prevsection>
<citsent citstr=" E09-1017 ">
surface text properties have been assessed in the framework of automatic summary evaluation (pitler et al , 2010), <papid> P10-1056 </papid>and have been shown to significantly correlate with the fluency of machine translated sentences (chae and nenkova, 2009).<papid> E09-1017 </papid></citsent>
<aftsection>
<nextsent>4.1.1 part-of-speech (pos) distribution the aa system described in yannakoudakis etal.
</nextsent>
<nextsent>(2011) exploited features based on pos tag sequences, but did not consider the distribution of pos types across grades.
</nextsent>
<nextsent>incoherent texts, constituent clauses and sentences are related and depend on each other for their interpretation.
</nextsent>
<nextsent>anaphors such as pronouns link the current sentence to those where the entities were previously mentioned.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3233">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>we explore the utility of inter-sentential feature types for assessing discourse coherence.
</prevsent>
<prevsent>among the features used in yannakoudakis et al  (2011), <papid> P11-1019 </papid>none explicitly captures coherence and none models inter sentential relationships.</prevsent>
</prevsection>
<citsent citstr=" W07-0607 ">
incremental semantic analysis (isa) (baroni et al , 2007) <papid> W07-0607 </papid>is word-level distributional model that induces semantic space from input texts.</citsent>
<aftsection>
<nextsent>isa is fully-incremental variation of random indexing (ri) (sahlgren, 2005), which can efficiently capture second-order effects in common with other dimensionality-reduction methods based on singular value decomposition, but does not relyon stop lists or global statistics for weighting purposes.
</nextsent>
<nextsent>utilizing the s-space package (jurgens and stevens, 2010), <papid> P10-4006 </papid>we trained an isa model5 using asubset of ukwac (ferraresi et al , 2008), large corpus of english containing more than 2 billion tokens.</nextsent>
<nextsent>we used the pos tagger lexicon provided with therasp system to discard documents whose proportion of valid english words to total words is less than 0.4; 78,000 documents were extracted in total andwere then preprocessed replacing urls, email addresses, ip addresses, numbers and emoticons with special markers.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3234">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>incremental semantic analysis (isa) (baroni et al , 2007) <papid> W07-0607 </papid>is word-level distributional model that induces semantic space from input texts.</prevsent>
<prevsent>isa is fully-incremental variation of random indexing (ri) (sahlgren, 2005), which can efficiently capture second-order effects in common with other dimensionality-reduction methods based on singular value decomposition, but does not relyon stop lists or global statistics for weighting pur poses.</prevsent>
</prevsection>
<citsent citstr=" P10-4006 ">
utilizing the s-space package (jurgens and stevens, 2010), <papid> P10-4006 </papid>we trained an isa model5 using asubset of ukwac (ferraresi et al , 2008), large corpus of english containing more than 2 billion tokens.</citsent>
<aftsection>
<nextsent>we used the pos tagger lexicon provided with therasp system to discard documents whose proportion of valid english words to total words is less than 0.4; 78,000 documents were extracted in total andwere then preprocessed replacing urls, email addresses, ip addresses, numbers and emoticons with special markers.
</nextsent>
<nextsent>to measure local coherence we define the similarity between two sentences si and si+1as the maximum cosine similarity between the history vectors of the words they contain.
</nextsent>
<nextsent>the overall coherence of text is then measured by taking the mean of all sentence-pair scores: coherence(t ) = n1 i=1 maxk,j sim(s i , j i+1) n?
</nextsent>
<nextsent>1 (1) where sim(ski , j i+1) is the cosine similarity between the history vectors of the kth word in si and the jth word in si+1, and is the total number of sentences6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3235">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>35 sim value found over the entire text, to the vectors of features associated with text.
</prevsent>
<prevsent>the hypothesis is that the degree of semantic relatedness between adjoining sentences serves as proxy for local discourse coherence; that is, coherent text units contain semantically-related words.
</prevsent>
</prevsection>
<citsent citstr=" N04-1024 ">
higgins et al  (2004)<papid> N04-1024 </papid>and higgins and burstein (2007) use ri to determine the semantic similarity between sentences of same/different discourse segments (e.g., from the essay thesis and conclusion, or between sentences and the essay prompt), and assess the percentage of sentences that are correctly classified as related or unrelated.</citsent>
<aftsection>
<nextsent>the main differences from our approach are that we assess the utility of semantic space models for predicting the overall grade for text, in contrast to binary classification at the sentence-level, and we use isa rather than ri7.
</nextsent>
<nextsent>4.3 entity-based coherence.
</nextsent>
<nextsent>the entity-based coherence model, proposed by barzilay and lapata (2008), <papid> J08-1001 </papid>is one of the most popular statistical models of inter-sentential coherence,and learns coherence properties similar to those employed by centering theory (grosz et al , 1995).<papid> J95-2003 </papid>local coherence is modeled on the basis of sequences of entity mentions that are labeled with their syntactic roles (e.g., subject, object).</nextsent>
<nextsent>we construct the entity grids using the brown coherence toolkit8,9 (elsner and charniak, 2011<papid> P11-2022 </papid>b), and use as features the probabilities of different entity transition types, defined in terms of their role in adjacent sentences10.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3237">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>the main differences from our approach are that we assess the utility of semantic space models for predicting the overall grade for text, in contrast to binary classification at the sentence-level, and we use isa rather than ri7.
</prevsent>
<prevsent>4.3 entity-based coherence.
</prevsent>
</prevsection>
<citsent citstr=" J08-1001 ">
the entity-based coherence model, proposed by barzilay and lapata (2008), <papid> J08-1001 </papid>is one of the most popular statistical models of inter-sentential coherence,and learns coherence properties similar to those employed by centering theory (grosz et al , 1995).<papid> J95-2003 </papid>local coherence is modeled on the basis of sequences of entity mentions that are labeled with their syntactic roles (e.g., subject, object).</citsent>
<aftsection>
<nextsent>we construct the entity grids using the brown coherence toolkit8,9 (elsner and charniak, 2011<papid> P11-2022 </papid>b), and use as features the probabilities of different entity transition types, defined in terms of their role in adjacent sentences10.</nextsent>
<nextsent>burstein et al  (2010) <papid> N10-1099 </papid>show howthe entity-grid can be used to discriminate high coherence from low-coherence learner texts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3238">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>the main differences from our approach are that we assess the utility of semantic space models for predicting the overall grade for text, in contrast to binary classification at the sentence-level, and we use isa rather than ri7.
</prevsent>
<prevsent>4.3 entity-based coherence.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
the entity-based coherence model, proposed by barzilay and lapata (2008), <papid> J08-1001 </papid>is one of the most popular statistical models of inter-sentential coherence,and learns coherence properties similar to those employed by centering theory (grosz et al , 1995).<papid> J95-2003 </papid>local coherence is modeled on the basis of sequences of entity mentions that are labeled with their syntactic roles (e.g., subject, object).</citsent>
<aftsection>
<nextsent>we construct the entity grids using the brown coherence toolkit8,9 (elsner and charniak, 2011<papid> P11-2022 </papid>b), and use as features the probabilities of different entity transition types, defined in terms of their role in adjacent sentences10.</nextsent>
<nextsent>burstein et al  (2010) <papid> N10-1099 </papid>show howthe entity-grid can be used to discriminate high coherence from low-coherence learner texts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3239">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>4.3 entity-based coherence.
</prevsent>
<prevsent>the entity-based coherence model, proposed by barzilay and lapata (2008), <papid> J08-1001 </papid>is one of the most popular statistical models of inter-sentential coherence,and learns coherence properties similar to those employed by centering theory (grosz et al , 1995).<papid> J95-2003 </papid>local coherence is modeled on the basis of sequences of entity mentions that are labeled with their syntactic roles (e.g., subject, object).</prevsent>
</prevsection>
<citsent citstr=" P11-2022 ">
we construct the entity grids using the brown coherence toolkit8,9 (elsner and charniak, 2011<papid> P11-2022 </papid>b), and use as features the probabilities of different entity transition types, defined in terms of their role in adjacent sentences10.</citsent>
<aftsection>
<nextsent>burstein et al  (2010) <papid> N10-1099 </papid>show howthe entity-grid can be used to discriminate high coherence from low-coherence learner texts.</nextsent>
<nextsent>themain difference with our approach is that we evaluate the entity-grid model in the context of aa text grading, rather than binary classification.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3241">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>the entity-based coherence model, proposed by barzilay and lapata (2008), <papid> J08-1001 </papid>is one of the most popular statistical models of inter-sentential coherence,and learns coherence properties similar to those employed by centering theory (grosz et al , 1995).<papid> J95-2003 </papid>local coherence is modeled on the basis of sequences of entity mentions that are labeled with their syntactic roles (e.g., subject, object).</prevsent>
<prevsent>we construct the entity grids using the brown coherence toolkit8,9 (elsner and charniak, 2011<papid> P11-2022 </papid>b), and use as features the probabilities of different entity transition types, defined in terms of their role in adjacent sentences10.</prevsent>
</prevsection>
<citsent citstr=" N10-1099 ">
burstein et al  (2010) <papid> N10-1099 </papid>show howthe entity-grid can be used to discriminate high coherence from low-coherence learner texts.</citsent>
<aftsection>
<nextsent>themain difference with our approach is that we evaluate the entity-grid model in the context of aa text grading, rather than binary classification.
</nextsent>
<nextsent>7we also used ri in addition to isa, and found that it did not yield significantly different results.
</nextsent>
<nextsent>in particular, we trained ri model with 2,000 dimensions and context window of 3 on the same ukwac data.
</nextsent>
<nextsent>below we only report results for the fully-incremental isa model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3243">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>4.4 pronoun coreference model.
</prevsent>
<prevsent>pronominal anaphora is another important aspect of coherence.
</prevsent>
</prevsection>
<citsent citstr=" E09-1018 ">
charniak and elsner (2009) <papid> E09-1018 </papid>present an unsupervised generative model of pronominal anaphora for coherence modeling.</citsent>
<aftsection>
<nextsent>in their implementation, they model each pronoun as generated byan antecedent somewhere in the previous two sentences.
</nextsent>
<nextsent>if good?
</nextsent>
<nextsent>antecedent is found, the probability of pronoun will be high; otherwise, the probability will be low.
</nextsent>
<nextsent>the overall probability of textis then calculated as the probability of the resulting sequence of pronoun assignments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3259">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>we compute two features introduced by soricut and marcu (2006): <papid> P06-2103 </papid>the forward likelihood and the backward likelihood.</prevsent>
<prevsent>the first refers to the likelihood of observing the words in sentence si+1 conditioned on si, and the latter to the likelihood of observing the words in si conditioned on si+1.</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
we extract 3 million adjacent sentences from ukwac12,and use the giza++ (och and ney, 2000) <papid> P00-1056 </papid>implementation of ibm model 1 to obtain the probabilities of recurring patterns.</citsent>
<aftsection>
<nextsent>the forward and backward probabilities are calculated over the entire text, and their values are used as features in our feature vectors13.
</nextsent>
<nextsent>we further extend the above model and incorporate syntactic aspects of text coherence by training on pos tags instead of lexical items.
</nextsent>
<nextsent>we try to model the intuition that local coherence is signaled by the identification of pos co-occurrence patterns across adjacent sentences, where the use of certain pos tags in sentence tends to trigger the use of other pos tags in an adjacent sentence.
</nextsent>
<nextsent>we analyze 3 million adjacent sentences using the rasp pos tagger and train the same ibm model to obtain the probabilities of recurring pos patterns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3266">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> discourse coherence.  </section>
<citcontext>
<prevsection>
<prevsent>this representation is able to capture sequential trends abstracted into pos tags.
</prevsent>
<prevsent>we try to model the hypothesis that coherence is signaled by sequential, mostly inter-sentential progression of pos types.
</prevsent>
</prevsection>
<citsent citstr=" P11-1030 ">
since each text is represented by set of localhistrograms/vectors, and standard svm kernels can not work with such input spaces, we use instead kernel defined over sets of vectors: the diffusion kernel (lafferty and lebanon, 2005) compares local histograms in one-to-one fashion (i.e., his tograms at the same locations are compared to each other), and has proven to be useful for related tasks (lebanon et al , 2007; escalante et al , 2011).<papid> P11-1030 </papid></citsent>
<aftsection>
<nextsent>to the best of our knowledge, lowbow representations have not been investigated for coherence evaluation (under the aa framework).
</nextsent>
<nextsent>so far, they have been applied to discourse segmentation (amida, 2007),text categorization (lebanon et al , 2007), and authorship attribution (escalante et al , 2011).<papid> P11-1030 </papid></nextsent>
<nextsent>we examine the predictive power of each of the coherence models/features described in section 4 by measuring the effect on performance when combined with an aa system that achieves state-of-theart results on the fce dataset, but does not use discourse coherence features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3303">
<title id=" W12-2004.xml">modeling coherence in esol learner texts </title>
<section> previous work.  </section>
<citcontext>
<prevsection>
<prevsent>they argue that lsa maybe more appropriate for comparing the relative quality of texts; for determining the overall text coherence it may be difficult to set criterion for the coherence value since it depends on variety of different factors, such as the size of the text units to be compared.
</prevsent>
<prevsent>nevertheless, our results show that isa,a similar distributional semantic model with dimen 40 sionality reduction, improves fce grading accuracy.
</prevsent>
</prevsection>
<citsent citstr=" N04-1015 ">
barzilay and lee (2004) <papid> N04-1015 </papid>implement lexicalized content models that represent global text properties on news articles and narratives using hidden markov models (hmms).</citsent>
<aftsection>
<nextsent>in the hmm, states correspond to distinct topics, and transitions between states represent the probability of moving from one topic to another.
</nextsent>
<nextsent>this approach has the advanta geof capturing the order in which different topics appear in texts; however, the hmms are highly domain specific and would probably need retraining for each distinct essay prompt.
</nextsent>
<nextsent>soricut and marcu (2006) <papid> P06-2103 </papid>use log-linear model that combines local and global models of coherence and show that it outperforms each of the individual ones on news articles and accident reports.their global model is based on the document content model proposed by barzilay and lee (2004).<papid> N04-1015 </papid></nextsent>
<nextsent>their local model of discourse coherence is based on the entity-grid (barzilay and lapata, 2008), <papid> J08-1001 </papid>as well as on the lexicalized ibm model (see section 4.6 above); we have experimented with both, and showed that they have minimal effect on grading performance with the fce dataset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3341">
<title id=" W12-1008.xml">distributional techniques for philosophical enquiry </title>
<section> a distributional semantics system </section>
<citcontext>
<prevsection>
<prevsent>3.1 distributional semantics.
</prevsent>
<prevsent>presented as complement to model-theoretic semantics, distributional semantics aims to represent lexical meaning as function of the contexts in which given word appears (wittgen stein, 1953; see also harris, 1954, credited with the distributional hypothesis?
</prevsent>
</prevsection>
<citsent citstr=" C65-1010 ">
which states that words which are similar in meaning occur in similar contexts).following this idea, some work in computational linguistics (starting with harper, 1965) <papid> C65-1010 </papid>has been devoted to building and evaluating models which represent words as distributions, i.e., vectors in multidimensional space where each dimension corresponds to potential context for alexical item (curran, 2003).</citsent>
<aftsection>
<nextsent>the notion of context itself has been studied to try and determine which representations work best for various tasks.
</nextsent>
<nextsent>47word windows (lund and burgess, 1996), dependencies (pado?
</nextsent>
<nextsent>and lapata, 2007) and syntactic relations (grefenstette, 1994) have been proposed.
</nextsent>
<nextsent>in our work, we use as context the words appearing in the same sentence as the query.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3342">
<title id=" W12-1008.xml">distributional techniques for philosophical enquiry </title>
<section> a distributional semantics system </section>
<citcontext>
<prevsection>
<prevsent>all models assume that the intersec tive composition of two elements should return distribution, i.e. lexical meaning, whichis made of the individual distributions, or meanings, of those elements.
</prevsent>
<prevsent>but there are difference sin how those models are evaluated.
</prevsent>
</prevsection>
<citsent citstr=" W10-2805 ">
two categories can be drawn: models designed to emulate the distribution of the resulting phrase itself,as it would be observed given large enough corpus (guevara, 2010 <papid> W10-2805 </papid>and 2011; baroni and zamparelli, 2010), <papid> D10-1115 </papid>and those which only focus on the composition operation and try to produce an adequate representation of the semantic intersection of the phrases components, independently from the phrasal distribution (mitchell and la pata, 2010; grefenstette and sadrzadeh, 2011).<papid> D11-1129 </papid></citsent>
<aftsection>
<nextsent>the former, which we will refer to as phrasal models are trained and evaluated against phrases?
</nextsent>
<nextsent>distributions while the latter, intersec tive models,call for task-based evaluations (for instance, similarity ratings: see mitchell and lapata, 2010).
</nextsent>
<nextsent>we argue that phrasal and intersec tive models are bound to produce different aspects of meaning.
</nextsent>
<nextsent>consider, for instance, the phrase big city.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3343">
<title id=" W12-1008.xml">distributional techniques for philosophical enquiry </title>
<section> a distributional semantics system </section>
<citcontext>
<prevsection>
<prevsent>all models assume that the intersec tive composition of two elements should return distribution, i.e. lexical meaning, whichis made of the individual distributions, or meanings, of those elements.
</prevsent>
<prevsent>but there are difference sin how those models are evaluated.
</prevsent>
</prevsection>
<citsent citstr=" D10-1115 ">
two categories can be drawn: models designed to emulate the distribution of the resulting phrase itself,as it would be observed given large enough corpus (guevara, 2010 <papid> W10-2805 </papid>and 2011; baroni and zamparelli, 2010), <papid> D10-1115 </papid>and those which only focus on the composition operation and try to produce an adequate representation of the semantic intersection of the phrases components, independently from the phrasal distribution (mitchell and la pata, 2010; grefenstette and sadrzadeh, 2011).<papid> D11-1129 </papid></citsent>
<aftsection>
<nextsent>the former, which we will refer to as phrasal models are trained and evaluated against phrases?
</nextsent>
<nextsent>distributions while the latter, intersec tive models,call for task-based evaluations (for instance, similarity ratings: see mitchell and lapata, 2010).
</nextsent>
<nextsent>we argue that phrasal and intersec tive models are bound to produce different aspects of meaning.
</nextsent>
<nextsent>consider, for instance, the phrase big city.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3344">
<title id=" W12-1008.xml">distributional techniques for philosophical enquiry </title>
<section> a distributional semantics system </section>
<citcontext>
<prevsection>
<prevsent>all models assume that the intersec tive composition of two elements should return distribution, i.e. lexical meaning, whichis made of the individual distributions, or meanings, of those elements.
</prevsent>
<prevsent>but there are difference sin how those models are evaluated.
</prevsent>
</prevsection>
<citsent citstr=" D11-1129 ">
two categories can be drawn: models designed to emulate the distribution of the resulting phrase itself,as it would be observed given large enough corpus (guevara, 2010 <papid> W10-2805 </papid>and 2011; baroni and zamparelli, 2010), <papid> D10-1115 </papid>and those which only focus on the composition operation and try to produce an adequate representation of the semantic intersection of the phrases components, independently from the phrasal distribution (mitchell and la pata, 2010; grefenstette and sadrzadeh, 2011).<papid> D11-1129 </papid></citsent>
<aftsection>
<nextsent>the former, which we will refer to as phrasal models are trained and evaluated against phrases?
</nextsent>
<nextsent>distributions while the latter, intersec tive models,call for task-based evaluations (for instance, similarity ratings: see mitchell and lapata, 2010).
</nextsent>
<nextsent>we argue that phrasal and intersec tive models are bound to produce different aspects of meaning.
</nextsent>
<nextsent>consider, for instance, the phrase big city.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3345">
<title id=" W11-2135.xml">limsi  wmt11 </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>based on neural networks, the soul lm can handle an arbitrary large vocabulary and high order markov ian assumption (up to 10-gram in this work).
</prevsent>
<prevsent>finally, experimental results are reported in section 5 both in terms of bleu scores and translation edit rates (ter) measured on the provided newstest2010 dataset.
</prevsent>
</prevsection>
<citsent citstr=" J04-2004 ">
our in-house n-code smt system implements the bilingual n-gram approach to statistical machine translation (casacuberta and vidal, 2004).<papid> J04-2004 </papid></citsent>
<aftsection>
<nextsent>given a1this kind of characters was used for teletype up to the seventies or early eighties.
</nextsent>
<nextsent>309 source sentence sj1, translation hypothesis t?
</nextsent>
<nextsent>i1 is defined as the sentence which maximizes linear combination of feature functions: ti1 = argmax ti1 { ? m=1 mhm(sj1, ti1) } (1) where sj1 and i 1 respectively denote the source and the target sentences, and is the weight associated with the feature function hm.
</nextsent>
<nextsent>the translation feature is the log-score of the translation model basedon bilingual units called tuples.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3346">
<title id=" W11-2135.xml">limsi  wmt11 </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>the probability assigned to sentence pair by the translation model is estimated by using the n-gram assumption: p(sj1, i 1) = ? k=1 p((s, t)k|(s, t)k1 . . .(s, t)kn+1) where refers to source symbol (t for target) and (s, t)k to the kth tuple of the given bilingual sentence pair.
</prevsent>
<prevsent>it is worth noticing that, since both languages are linked up in tuples, the context information provided by this translation model is bilingual.
</prevsent>
</prevsection>
<citsent citstr=" N04-4026 ">
in addition to the translation model, eleven feature functions are combined: target-language model (seesection 4 for details); four lexicon models; two lexicalized reordering models (tillmann, 2004) <papid> N04-4026 </papid>aiming at predicting the orientation of the next translation unit; weak?</citsent>
<aftsection>
<nextsent>distance-based distortion model; and finally word-bonus model and tuple-bonus model which compensate for the system preference for short translations.
</nextsent>
<nextsent>the four lexicon models are similar to the ones used in standard phrase-basedsystem: two scores correspond to the relative frequencies of the tuples and two lexical weights are estimated from the automatically generated wordalignments.
</nextsent>
<nextsent>the weights associated to feature functions are optimally combined using discriminative training framework (och, 2003) (<papid> P03-1021 </papid>minimum error rate training (mert), see details in section 5.4),using the provided newstest2009 data as development set.</nextsent>
<nextsent>2.1 training.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3347">
<title id=" W11-2135.xml">limsi  wmt11 </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>distance-based distortion model; and finally word-bonus model and tuple-bonus model which compensate for the system preference for short translations.
</prevsent>
<prevsent>the four lexicon models are similar to the ones used in standard phrase-basedsystem: two scores correspond to the relative frequencies of the tuples and two lexical weights are estimated from the automatically generated wordalignments.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the weights associated to feature functions are optimally combined using discriminative training framework (och, 2003) (<papid> P03-1021 </papid>minimum error rate training (mert), see details in section 5.4),using the provided newstest2009 data as development set.</citsent>
<aftsection>
<nextsent>2.1 training.
</nextsent>
<nextsent>our translation model is estimated over training corpus composed of tuple sequences using classical smoothing techniques.
</nextsent>
<nextsent>tuples are extracted froma word-aligned corpus (using mgiza++2 with default settings) in such way that unique segmentation of the bilingual corpus is achieved, allowing to estimate the n-gram model.
</nextsent>
<nextsent>figure 1 presents simple example illustrating the unique tuple segmentation forgiven word-aligned pair of sentences (top).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3348">
<title id=" W11-2135.xml">limsi  wmt11 </title>
<section> data pre-processing and selection.  </section>
<citcontext>
<prevsection>
<prevsent>to train the target language models, we also used all provided data and monolingual corpora released by the ldc for french and english.
</prevsent>
<prevsent>moreover, all parallel corpora were pos-tagged with the tree tagger (schmid, 1994).
</prevsent>
</prevsection>
<citsent citstr=" C08-1098 ">
for german, the fine-grained pos information usedfor pre-processing was computed by the rftag ger (schmid and laws, 2008).<papid> C08-1098 </papid></citsent>
<aftsection>
<nextsent>3.1 tokenization.
</nextsent>
<nextsent>we took advantage of our in-house text processing tools for the tokenization and detokenizationsteps (dechelotte et al, 2008).
</nextsent>
<nextsent>previous experiments have demonstrated that better normalization tools provide better bleu scores (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
<nextsent>thus all systems are built in true-case.?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3349">
<title id=" W11-2135.xml">limsi  wmt11 </title>
<section> data pre-processing and selection.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 tokenization.
</prevsent>
<prevsent>we took advantage of our in-house text processing tools for the tokenization and detokenizationsteps (dechelotte et al, 2008).
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
previous experiments have demonstrated that better normalization tools provide better bleu scores (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>thus all systems are built in true-case.?
</nextsent>
<nextsent>as german is morphologically more complex than english, the default policy which consists in treating each word form independently is plagued with data sparsity, which poses number of difficulties both at training and decoding time.
</nextsent>
<nextsent>thus, to translate from german to english, the german side was normalized using specific pre-processing scheme (described in (allauzen et al, 2010)), <papid> W10-1704 </papid>which aims at reducing the lexical redundancy and splitting complex compounds.using the same pre-processing scheme to translate from english to german would require to post process the output to undo the pre-processing.</nextsent>
<nextsent>as in our last years experiments (allauzen et al, 2010), <papid> W10-1704 </papid>this pre-processing step could be achieved with atwo-step decoding.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3350">
<title id=" W11-2135.xml">limsi  wmt11 </title>
<section> data pre-processing and selection.  </section>
<citcontext>
<prevsection>
<prevsent>thus all systems are built in true-case.?
</prevsent>
<prevsent>as german is morphologically more complex than english, the default policy which consists in treating each word form independently is plagued with data sparsity, which poses number of difficulties both at training and decoding time.
</prevsent>
</prevsection>
<citsent citstr=" W10-1704 ">
thus, to translate from german to english, the german side was normalized using specific pre-processing scheme (described in (allauzen et al, 2010)), <papid> W10-1704 </papid>which aims at reducing the lexical redundancy and splitting complex compounds.using the same pre-processing scheme to translate from english to german would require to post process the output to undo the pre-processing.</citsent>
<aftsection>
<nextsent>as in our last years experiments (allauzen et al, 2010), <papid> W10-1704 </papid>this pre-processing step could be achieved with atwo-step decoding.</nextsent>
<nextsent>however, by stacking two decoding steps, we may stack errors as well.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3352">
<title id=" W11-2135.xml">limsi  wmt11 </title>
<section> target language modeling.  </section>
<citcontext>
<prevsection>
<prevsent>4.2 the soul model.
</prevsent>
<prevsent>we give here brief overview of the soul lm; refer to (le et al, 2011) for the complete trainingprocedure.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
following the classical work on distributed word representation (brown et al, 1992), <papid> J92-4003 </papid>we assume that the output vocabulary is structured by clustering tree, where each word belongs to only one class and its associated sub-classes.</citsent>
<aftsection>
<nextsent>if wi denotes the i-th word in sentence, the sequence c1:d(wi) = c1, . . .
</nextsent>
<nextsent>,cd encodes the path for the word wi in the clustering tree, with the depth of the tree, cd(wi) class or sub-class assigned to wi, and cd(wi) the leaf associated with wi (the word itself).
</nextsent>
<nextsent>the n-gram probability of wi given its history can then be estimated as follows using the chain rule: p(wi|h) = p(c1(wi)|h) ? d=2 p(cd(wi)|h,c1:d1) figure 2 represents the architecture of the nnlm to estimate this distribution, for tree of depth = 3.
</nextsent>
<nextsent>the soul architecture is the same as for the standard model up to the output layer.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3353">
<title id=" W11-2135.xml">limsi  wmt11 </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>soul lm en2fr en2de bleu ter bleu ter without 28.1 56.0 16.3 66.0 4-gram 28.4 55.5 16.5 64.9 6-gram 28.7 55.3 16.7 64.9 10-gram 28.8 55.2 16.8 64.6 table 3: translation results from english to french and english to german measured on newstest2010 using 100-best rescoring with soul lms of different orders.
</prevsent>
<prevsent>5.4 optimization issues.
</prevsent>
</prevsection>
<citsent citstr=" D07-1080 ">
along with mira (margin infused relaxed al gorithm) (watanabe et al, 2007), <papid> D07-1080 </papid>mert is themost widely used algorithm for system optimiza tion.</citsent>
<aftsection>
<nextsent>however, standard mert procedure is known to suffer from instability of results and very slow training cycle with approximate estimates of one decoding cycle for each training parameter.
</nextsent>
<nextsent>for this years evaluation, we experimented with several alternatives to the standard n-best mert procedure, namely, merton word lattices (macherey et al, 2008) <papid> D08-1076 </papid>and two differentiable variants to the bleu objective function optimized during the mert cycle.</nextsent>
<nextsent>we have recast the former in terms of specific semi ring and implemented it using general purpose finite state automata framework (sokolov and yvon, 2011).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3354">
<title id=" W11-2135.xml">limsi  wmt11 </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>along with mira (margin infused relaxed al gorithm) (watanabe et al, 2007), <papid> D07-1080 </papid>mert is themost widely used algorithm for system optimiza tion.</prevsent>
<prevsent>however, standard mert procedure is known to suffer from instability of results and very slow training cycle with approximate estimates of one decoding cycle for each training parameter.</prevsent>
</prevsection>
<citsent citstr=" D08-1076 ">
for this years evaluation, we experimented with several alternatives to the standard n-best mert procedure, namely, merton word lattices (macherey et al, 2008) <papid> D08-1076 </papid>and two differentiable variants to the bleu objective function optimized during the mert cycle.</citsent>
<aftsection>
<nextsent>we have recast the former in terms of specific semi ring and implemented it using general purpose finite state automata framework (sokolov and yvon, 2011).
</nextsent>
<nextsent>the last two approaches, hereafter referred to as zhn and bbn, replace the bleu objective function, with the usual bleu score on expected n-gram counts (rosti et al, 2010) <papid> W10-1748 </papid>and with an expected bleu score for normal n-gramcounts (zens et al, 2007), <papid> D07-1055 </papid>respectively.</nextsent>
<nextsent>all expectations (of the n-gram counts in the first case and thebleu score in the second) are taken over all hypotheses from n-best lists for each source sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3355">
<title id=" W11-2135.xml">limsi  wmt11 </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>for this years evaluation, we experimented with several alternatives to the standard n-best mert procedure, namely, merton word lattices (macherey et al, 2008) <papid> D08-1076 </papid>and two differentiable variants to the bleu objective function optimized during the mert cycle.</prevsent>
<prevsent>we have recast the former in terms of specific semi ring and implemented it using general purpose finite state automata framework (sokolov and yvon, 2011).</prevsent>
</prevsection>
<citsent citstr=" W10-1748 ">
the last two approaches, hereafter referred to as zhn and bbn, replace the bleu objective function, with the usual bleu score on expected n-gram counts (rosti et al, 2010) <papid> W10-1748 </papid>and with an expected bleu score for normal n-gramcounts (zens et al, 2007), <papid> D07-1055 </papid>respectively.</citsent>
<aftsection>
<nextsent>all expectations (of the n-gram counts in the first case and thebleu score in the second) are taken over all hypotheses from n-best lists for each source sentence.
</nextsent>
<nextsent>experiments with the alternative optimization methods achieved virtually the same performance in terms of bleu score, but 2 to 4 times faster.
</nextsent>
<nextsent>neither approach, however, showed any consistent and significant improvement for the majority of setups tried (with the exception of the bbn approach, that had almost always improved over n-best mert, but forthe sole french to english translation direction).
</nextsent>
<nextsent>additional experiments with 9 complementary translation models as additional features were performed with lattice-mert, but neither showed any substantial improvement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3356">
<title id=" W11-2135.xml">limsi  wmt11 </title>
<section> experimental results.  </section>
<citcontext>
<prevsection>
<prevsent>for this years evaluation, we experimented with several alternatives to the standard n-best mert procedure, namely, merton word lattices (macherey et al, 2008) <papid> D08-1076 </papid>and two differentiable variants to the bleu objective function optimized during the mert cycle.</prevsent>
<prevsent>we have recast the former in terms of specific semi ring and implemented it using general purpose finite state automata framework (sokolov and yvon, 2011).</prevsent>
</prevsection>
<citsent citstr=" D07-1055 ">
the last two approaches, hereafter referred to as zhn and bbn, replace the bleu objective function, with the usual bleu score on expected n-gram counts (rosti et al, 2010) <papid> W10-1748 </papid>and with an expected bleu score for normal n-gramcounts (zens et al, 2007), <papid> D07-1055 </papid>respectively.</citsent>
<aftsection>
<nextsent>all expectations (of the n-gram counts in the first case and thebleu score in the second) are taken over all hypotheses from n-best lists for each source sentence.
</nextsent>
<nextsent>experiments with the alternative optimization methods achieved virtually the same performance in terms of bleu score, but 2 to 4 times faster.
</nextsent>
<nextsent>neither approach, however, showed any consistent and significant improvement for the majority of setups tried (with the exception of the bbn approach, that had almost always improved over n-best mert, but forthe sole french to english translation direction).
</nextsent>
<nextsent>additional experiments with 9 complementary translation models as additional features were performed with lattice-mert, but neither showed any substantial improvement.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3357">
<title id=" W11-1818.xml">complex biological event extraction from full text using signatures of linguistic and semantic features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>using leave-one out analysis, we report the contribution of linguistic and shallow semantic features in the trigger prediction and candidate argument extraction.
</prevsent>
<prevsent>lastly, we examine evaluations and posit causes for errors in our complex biological event extraction.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
the bionlp 2009 shared task (kim et al, 2009)<papid> W09-1401 </papid>was the first shared task to address fine-grained information extraction for the bio-molecular domain, by defining task involving extraction of event types from the genia ontology.</citsent>
<aftsection>
<nextsent>the bionlp 2011 shared task ( (kim et al, 2011)) <papid> W11-1801 </papid>series generalized this defining series of tasks involving more text types, domains and target event types.</nextsent>
<nextsent>among the tasks for the new series is the infection disease task, proposed and investigated by (pyysalo et al, 2011; <papid> W11-1804 </papid>pyysalo et al, 2010; <papid> W10-1919 </papid>bjorne et al, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3358">
<title id=" W11-1818.xml">complex biological event extraction from full text using signatures of linguistic and semantic features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lastly, we examine evaluations and posit causes for errors in our complex biological event extraction.
</prevsent>
<prevsent>the bionlp 2009 shared task (kim et al, 2009)<papid> W09-1401 </papid>was the first shared task to address fine-grained information extraction for the bio-molecular domain, by defining task involving extraction of event types from the genia ontology.</prevsent>
</prevsection>
<citsent citstr=" W11-1801 ">
the bionlp 2011 shared task ( (kim et al, 2011)) <papid> W11-1801 </papid>series generalized this defining series of tasks involving more text types, domains and target event types.</citsent>
<aftsection>
<nextsent>among the tasks for the new series is the infection disease task, proposed and investigated by (pyysalo et al, 2011; <papid> W11-1804 </papid>pyysalo et al, 2010; <papid> W10-1919 </papid>bjorne et al, 2010).</nextsent>
<nextsent>like the other tasks for the bionlp shared task series, the goal is to extract mentions of relevant events from biomedical publications.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3359">
<title id=" W11-1818.xml">complex biological event extraction from full text using signatures of linguistic and semantic features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the bionlp 2009 shared task (kim et al, 2009)<papid> W09-1401 </papid>was the first shared task to address fine-grained information extraction for the bio-molecular domain, by defining task involving extraction of event types from the genia ontology.</prevsent>
<prevsent>the bionlp 2011 shared task ( (kim et al, 2011)) <papid> W11-1801 </papid>series generalized this defining series of tasks involving more text types, domains and target event types.</prevsent>
</prevsection>
<citsent citstr=" W11-1804 ">
among the tasks for the new series is the infection disease task, proposed and investigated by (pyysalo et al, 2011; <papid> W11-1804 </papid>pyysalo et al, 2010; <papid> W10-1919 </papid>bjorne et al, 2010).</citsent>
<aftsection>
<nextsent>like the other tasks for the bionlp shared task series, the goal is to extract mentions of relevant events from biomedical publications.
</nextsent>
<nextsent>to extract an event, the event trigger and all arguments must be identified in the text by exact offset and typed according to given set of event and argument classes (miwa et al, 2010).
</nextsent>
<nextsent>entity annotations are given for set of entity types that fill many of the arguments.here we describe pacific northwest national laboratorys (pnnl) submission to the bionlp 2011infectious disease shared task.
</nextsent>
<nextsent>we describe the approach and then discuss results, including an analysis of errors and contribution of various features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3360">
<title id=" W11-1818.xml">complex biological event extraction from full text using signatures of linguistic and semantic features </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the bionlp 2009 shared task (kim et al, 2009)<papid> W09-1401 </papid>was the first shared task to address fine-grained information extraction for the bio-molecular domain, by defining task involving extraction of event types from the genia ontology.</prevsent>
<prevsent>the bionlp 2011 shared task ( (kim et al, 2011)) <papid> W11-1801 </papid>series generalized this defining series of tasks involving more text types, domains and target event types.</prevsent>
</prevsection>
<citsent citstr=" W10-1919 ">
among the tasks for the new series is the infection disease task, proposed and investigated by (pyysalo et al, 2011; <papid> W11-1804 </papid>pyysalo et al, 2010; <papid> W10-1919 </papid>bjorne et al, 2010).</citsent>
<aftsection>
<nextsent>like the other tasks for the bionlp shared task series, the goal is to extract mentions of relevant events from biomedical publications.
</nextsent>
<nextsent>to extract an event, the event trigger and all arguments must be identified in the text by exact offset and typed according to given set of event and argument classes (miwa et al, 2010).
</nextsent>
<nextsent>entity annotations are given for set of entity types that fill many of the arguments.here we describe pacific northwest national laboratorys (pnnl) submission to the bionlp 2011infectious disease shared task.
</nextsent>
<nextsent>we describe the approach and then discuss results, including an analysis of errors and contribution of various features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3361">
<title id=" W11-1818.xml">complex biological event extraction from full text using signatures of linguistic and semantic features </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>table 1 shows the summary of the event extraction tasks for the infectious disease track.
</prevsent>
<prevsent>2.2 annotation.
</prevsent>
</prevsection>
<citsent citstr=" W09-1410 ">
linguistic and domain annotations are automatically applied to the document to be used for trigger and argument identification in framing the tasks for classification and generating features for each instance.linguistic annotations include sentence splits, tokens, parts of speech, tree parses, typed dependencies (demarneffe et al, 2006; mackinlay et al, 2009), <papid> W09-1410 </papid>and stems.</citsent>
<aftsection>
<nextsent>for the infectious disease task,the parses from the stanford parser (klein and manning, 2003) provided by the supporting analysis (stenetorp et al, 2011) <papid> W11-1816 </papid>was used to obtain all of these linguistic annotations, except for the stems, which were obtained from the porter stemmer (van rijsbergen et al, 1980).for the infectious disease task, two sets of do main specific annotations are included: known trigger words for each event class and semantic tags from the unified medical language system (umls) (bodenreider, 2004).</nextsent>
<nextsent>annotations for known trigger words are created using dictionary of word stem-event class pairs created from annotated training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3362">
<title id=" W11-1818.xml">complex biological event extraction from full text using signatures of linguistic and semantic features </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 annotation.
</prevsent>
<prevsent>linguistic and domain annotations are automatically applied to the document to be used for trigger and argument identification in framing the tasks for classification and generating features for each instance.linguistic annotations include sentence splits, tokens, parts of speech, tree parses, typed dependencies (demarneffe et al, 2006; mackinlay et al, 2009), <papid> W09-1410 </papid>and stems.</prevsent>
</prevsection>
<citsent citstr=" W11-1816 ">
for the infectious disease task,the parses from the stanford parser (klein and manning, 2003) provided by the supporting analysis (stenetorp et al, 2011) <papid> W11-1816 </papid>was used to obtain all of these linguistic annotations, except for the stems, which were obtained from the porter stemmer (van rijsbergen et al, 1980).for the infectious disease task, two sets of do main specific annotations are included: known trigger words for each event class and semantic tags from the unified medical language system (umls) (bodenreider, 2004).</citsent>
<aftsection>
<nextsent>annotations for known trigger words are created using dictionary of word stem-event class pairs created from annotated training data.
</nextsent>
<nextsent>an entry is created in the dictionary every time new stem is seen as trigger for an event class.
</nextsent>
<nextsent>when word with one of these stems is seen during processing, it is annotated as typical trigger word for that event class.
</nextsent>
<nextsent>semantic tags are calculating using metamap 2010 (aronson and lang, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3363">
<title id=" W11-1818.xml">complex biological event extraction from full text using signatures of linguistic and semantic features </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>each pair of an event trigger and candidate argument serves as an instance for the classification.
</prevsent>
<prevsent>a binary model is trained for each event type, and each pair is tested against each classifier.
</prevsent>
</prevsection>
<citsent citstr=" J02-3001 ">
many of the features used are inspired by those used in semantic role labeling systems (gildea and jurafsky, 2002).<papid> J02-3001 </papid></citsent>
<aftsection>
<nextsent>given an event trigger and candidate argument, the following features are used to classify event arguments: ? trigger type ? the predicted event type of the trigger ? argument terms ? the text of the argument?
</nextsent>
<nextsent>argument type ? entity or event type annotation on the argument?
</nextsent>
<nextsent>argument super-type ? core entity or core argument ? trigger and argument stems ? the stems of each ? trigger and argument parts of speech ? the part of speech of each ? parse tree path ? from the trigger to argument via least common ancestor in tree parse, as list of phrase types ? voice of sentence ? active or passive ? trigger and argument partial paths ? fromthe trigger or argument to the least common ancestor in tree parse, as list of phrase types 132?
</nextsent>
<nextsent>relative position of argument to trigger ? before or after ? trigger sub-categorization ? representation ofthe phrase structure rule that describes the relationship between the trigger, its parent and its siblings.the training data used is the same as for trigger identification: the infectious disease training set plus the genia training set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3364">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the entries of thephrase-table are automatically extracted from sentence aligned parallel data and they are usually quitenoisy.
</prevsent>
<prevsent>it is not uncommon to encounter several hundreds, or even thousands of possible translations of frequent source phrases.
</prevsent>
</prevsection>
<citsent citstr=" D07-1103 ">
many of these automatically extracted translations are probably wrong andare never used since their probabilities are (fortu nately) small in comparison to better translations.therefore, several approaches were proposed to filter these phrase-tables, reducing considerably their size without any loss of the quality, or even achieving improved performance (johnson et al, 2007).<papid> D07-1103 </papid>given these observations, adaptation of the translation model of pbsmt systems could be performed by modifying the probability distribution of the existing phrases without necessarily modifying the entries.</citsent>
<aftsection>
<nextsent>the idea is of course to increase the probabilities of translations that are appropriate to the task and to decrease the probabilities of the other ones.
</nextsent>
<nextsent>ideally, we should also add new translations or source phrase, but this seems to be more challenging without any additional parallel data.
</nextsent>
<nextsent>a common way to modify statistical model is to use mixture model and to optimize the coefficients to the adaptation domain.
</nextsent>
<nextsent>this was investigated inthe framework of smt by several authors, for instance for word alignment (civera and juan, 2007), <papid> W07-0722 </papid>for language modeling (zhao et al, 2004; <papid> C04-1059 </papid>koehn and schroeder, 2007) <papid> W07-0733 </papid>and to lesser extent for the translation model (foster and kuhn, 2007; <papid> W07-0717 </papid>chen etal., 2008).<papid> P08-2040 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3365">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ideally, we should also add new translations or source phrase, but this seems to be more challenging without any additional parallel data.
</prevsent>
<prevsent>a common way to modify statistical model is to use mixture model and to optimize the coefficients to the adaptation domain.
</prevsent>
</prevsection>
<citsent citstr=" W07-0722 ">
this was investigated inthe framework of smt by several authors, for instance for word alignment (civera and juan, 2007), <papid> W07-0722 </papid>for language modeling (zhao et al, 2004; <papid> C04-1059 </papid>koehn and schroeder, 2007) <papid> W07-0733 </papid>and to lesser extent for the translation model (foster and kuhn, 2007; <papid> W07-0717 </papid>chen etal., 2008).<papid> P08-2040 </papid></citsent>
<aftsection>
<nextsent>this mixture approach has the advantage that only few parameters need to be modified, the mixture coefficients.
</nextsent>
<nextsent>on the other hand, many translation probabilities are modified at once and it is not possible to selectively modify the probabilities of particular phrases.
</nextsent>
<nextsent>another direction of research is self-enhancing of the translation model.
</nextsent>
<nextsent>this was first proposed by ueffing (2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3366">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ideally, we should also add new translations or source phrase, but this seems to be more challenging without any additional parallel data.
</prevsent>
<prevsent>a common way to modify statistical model is to use mixture model and to optimize the coefficients to the adaptation domain.
</prevsent>
</prevsection>
<citsent citstr=" C04-1059 ">
this was investigated inthe framework of smt by several authors, for instance for word alignment (civera and juan, 2007), <papid> W07-0722 </papid>for language modeling (zhao et al, 2004; <papid> C04-1059 </papid>koehn and schroeder, 2007) <papid> W07-0733 </papid>and to lesser extent for the translation model (foster and kuhn, 2007; <papid> W07-0717 </papid>chen etal., 2008).<papid> P08-2040 </papid></citsent>
<aftsection>
<nextsent>this mixture approach has the advantage that only few parameters need to be modified, the mixture coefficients.
</nextsent>
<nextsent>on the other hand, many translation probabilities are modified at once and it is not possible to selectively modify the probabilities of particular phrases.
</nextsent>
<nextsent>another direction of research is self-enhancing of the translation model.
</nextsent>
<nextsent>this was first proposed by ueffing (2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3367">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ideally, we should also add new translations or source phrase, but this seems to be more challenging without any additional parallel data.
</prevsent>
<prevsent>a common way to modify statistical model is to use mixture model and to optimize the coefficients to the adaptation domain.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
this was investigated inthe framework of smt by several authors, for instance for word alignment (civera and juan, 2007), <papid> W07-0722 </papid>for language modeling (zhao et al, 2004; <papid> C04-1059 </papid>koehn and schroeder, 2007) <papid> W07-0733 </papid>and to lesser extent for the translation model (foster and kuhn, 2007; <papid> W07-0717 </papid>chen etal., 2008).<papid> P08-2040 </papid></citsent>
<aftsection>
<nextsent>this mixture approach has the advantage that only few parameters need to be modified, the mixture coefficients.
</nextsent>
<nextsent>on the other hand, many translation probabilities are modified at once and it is not possible to selectively modify the probabilities of particular phrases.
</nextsent>
<nextsent>another direction of research is self-enhancing of the translation model.
</nextsent>
<nextsent>this was first proposed by ueffing (2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3368">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ideally, we should also add new translations or source phrase, but this seems to be more challenging without any additional parallel data.
</prevsent>
<prevsent>a common way to modify statistical model is to use mixture model and to optimize the coefficients to the adaptation domain.
</prevsent>
</prevsection>
<citsent citstr=" W07-0717 ">
this was investigated inthe framework of smt by several authors, for instance for word alignment (civera and juan, 2007), <papid> W07-0722 </papid>for language modeling (zhao et al, 2004; <papid> C04-1059 </papid>koehn and schroeder, 2007) <papid> W07-0733 </papid>and to lesser extent for the translation model (foster and kuhn, 2007; <papid> W07-0717 </papid>chen etal., 2008).<papid> P08-2040 </papid></citsent>
<aftsection>
<nextsent>this mixture approach has the advantage that only few parameters need to be modified, the mixture coefficients.
</nextsent>
<nextsent>on the other hand, many translation probabilities are modified at once and it is not possible to selectively modify the probabilities of particular phrases.
</nextsent>
<nextsent>another direction of research is self-enhancing of the translation model.
</nextsent>
<nextsent>this was first proposed by ueffing (2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3369">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ideally, we should also add new translations or source phrase, but this seems to be more challenging without any additional parallel data.
</prevsent>
<prevsent>a common way to modify statistical model is to use mixture model and to optimize the coefficients to the adaptation domain.
</prevsent>
</prevsection>
<citsent citstr=" P08-2040 ">
this was investigated inthe framework of smt by several authors, for instance for word alignment (civera and juan, 2007), <papid> W07-0722 </papid>for language modeling (zhao et al, 2004; <papid> C04-1059 </papid>koehn and schroeder, 2007) <papid> W07-0733 </papid>and to lesser extent for the translation model (foster and kuhn, 2007; <papid> W07-0717 </papid>chen etal., 2008).<papid> P08-2040 </papid></citsent>
<aftsection>
<nextsent>this mixture approach has the advantage that only few parameters need to be modified, the mixture coefficients.
</nextsent>
<nextsent>on the other hand, many translation probabilities are modified at once and it is not possible to selectively modify the probabilities of particular phrases.
</nextsent>
<nextsent>another direction of research is self-enhancing of the translation model.
</nextsent>
<nextsent>this was first proposed by ueffing (2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3370">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in practice, such an approach is probably only feasible when large amounts of test data are collected and processed at once, e.g. typical evaluation set up with test set of about 50k words.
</prevsent>
<prevsent>this method of self-enhancing the translation model seems to be more difficult to apply for on-line smt, e.g. web service, since often the translation of some sentences only is requested.
</prevsent>
</prevsection>
<citsent citstr=" P07-1004 ">
in follow up work, this approach was refined (ueffing et al, 2007).<papid> P07-1004 </papid></citsent>
<aftsection>
<nextsent>domain adaptation was also performed simultaneously for the translation, language andre ordering model (chen et al, 2008).<papid> P08-2040 </papid>a somehow related approach was named lightly supervised training (schwenk, 2008).</nextsent>
<nextsent>in that work an smt system is used to translate large amounts of monolingual texts, to filter them and to add them to the translation model training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3372">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>domain adaptation was also performed simultaneously for the translation, language andre ordering model (chen et al, 2008).<papid> P08-2040 </papid>a somehow related approach was named lightly supervised training (schwenk, 2008).</prevsent>
<prevsent>in that work an smt system is used to translate large amounts of monolingual texts, to filter them and to add them to the translation model training data.</prevsent>
</prevsection>
<citsent citstr=" W09-0432 ">
this approach was reported to obtain interesting improvements in the translations quality (schwenk and senellart, 2009; bertoldi and federico, 2009).<papid> W09-0432 </papid></citsent>
<aftsection>
<nextsent>in comparison to self enhancing as proposed by ueffing (2006), lightly-supervised training does not adapt itself tothe test data, but large amounts of monolingual training data are translated and completely new model is built.
</nextsent>
<nextsent>this model can be applied to any test data, including web service.
</nextsent>
<nextsent>in this paper we propose to extend this approach in several ways.
</nextsent>
<nextsent>first, we argue that the automatic translations should not be performed from the source to the target language, but in the opposite direction.second, we propose to use the segmentation obtained during translation instead of performing word alignments with giza++ (och and ney, 2003) <papid> J03-1002 </papid>of the automatic translations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3373">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this model can be applied to any test data, including web service.
</prevsent>
<prevsent>in this paper we propose to extend this approach in several ways.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
first, we argue that the automatic translations should not be performed from the source to the target language, but in the opposite direction.second, we propose to use the segmentation obtained during translation instead of performing word alignments with giza++ (och and ney, 2003) <papid> J03-1002 </papid>of the automatic translations.</citsent>
<aftsection>
<nextsent>finally, we propose to enrich the vocabulary of the adapted system by detecting untranslated words and automatically inferring possible translations from the stemmed form and the existing translations in the phrase table.
</nextsent>
<nextsent>this paper is organized as follows.
</nextsent>
<nextsent>in the next section we first describe our approach in detail.
</nextsent>
<nextsent>section 3 describes the considered task, the available resources and the baseline pbsmt system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3375">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> architecture of the approach.  </section>
<citcontext>
<prevsection>
<prevsent>these alignments are simply added to the previously calculated alignments of the human translated bitexts and new phrase table is built.
</prevsent>
<prevsent>this new procedure does not only speed-up the overall processing, but there are also investigations that these alignments obtained by decoding are more suitable to extract phrases than the symmetrizedword alignments produced by giza++.
</prevsent>
</prevsection>
<citsent citstr=" P10-1049 ">
for instance, wuebker et al (2010) <papid> P10-1049 </papid>proposed to translate the training data, using forced alignment and leave-one-out technique, and to use the induced alignments to extract phrases.</citsent>
<aftsection>
<nextsent>they have observed improvements with respect to word alignment obtained by giza++.
</nextsent>
<nextsent>on the other hand, bertoldi and federico (2009) <papid> W09-0432 </papid>adapted an smt system with automatic translations and trained the translation and reordering models on the word alignment used bymoses.</nextsent>
<nextsent>they reported very small drop in performance with respect to training word alignments with giza++.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3377">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> architecture of the approach.  </section>
<citcontext>
<prevsection>
<prevsent>table 1: example of translations from french to english which are automatically extracted from the phrase-table with the stemmed form.known in some forms and not in others.
</prevsent>
<prevsent>for instance, for user of mt technology it is quite difficult to understand why the system can translate the french word je pense1, but not tu penses2.
</prevsent>
</prevsection>
<citsent citstr=" P08-2015 ">
there have been attempts in the literature to address this problem, for instance by habash (2008) <papid> P08-2015 </papid>to deal with the arabic language.</citsent>
<aftsection>
<nextsent>it is actually possible to automatically infer possible translations when translating from morphologically rich language, to simpler language.
</nextsent>
<nextsent>in our case we use this approach to translate from french to english.several of the unknown words are actually adjectives, nouns or verbs in particular form that itself is not known, but the phrase table would contain the translation of different form.
</nextsent>
<nextsent>as an example we can mention the french adjective finies which is in the female plural form.
</nextsent>
<nextsent>after stemming we may be able to find the translation in dictionary which is automatically extracted from the phrase-table (seetable 1).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3378">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> task description and resources.  </section>
<citcontext>
<prevsection>
<prevsent>version 13).
</prevsent>
<prevsent>3.1 baseline system.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the baseline system is standard phrase-based smt system based on the the moses smt toolkit (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>it uses fourteen features functions for translation, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, word and phrase penalty, and target language model.
</nextsent>
<nextsent>it is con 4http://matrix.statmt.org structed as follows.
</nextsent>
<nextsent>first, word alignments in both directions are calculated.
</nextsent>
<nextsent>we used multi-threaded version of the giza++ tool (gao and vogel, 2008).<papid> W08-0509 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3379">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> task description and resources.  </section>
<citcontext>
<prevsection>
<prevsent>it is con 4http://matrix.statmt.org structed as follows.
</prevsent>
<prevsent>first, word alignments in both directions are calculated.
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
we used multi-threaded version of the giza++ tool (gao and vogel, 2008).<papid> W08-0509 </papid></citsent>
<aftsection>
<nextsent>phrases and lexical reorderings are extracted using the default settings of the moses toolkit.
</nextsent>
<nextsent>all the bi texts were concatenated.
</nextsent>
<nextsent>the parameters of moses are tuned on the development data using the merttool.
</nextsent>
<nextsent>for most of the runs, we performed three op timizations using different starting points and report average results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3380">
<title id=" W11-2132.xml">investigations on translation model adaptation using monolingual data </title>
<section> task description and resources.  </section>
<citcontext>
<prevsection>
<prevsent>starting with the europarl and the news commentary corpora, various amounts of human translated data were added.
</prevsent>
<prevsent>the organizers of the evaluation provide the so called 109 french english parallel corpus which contains almost 800 million words of data crawled from canadian and european internet pages.
</prevsent>
</prevsection>
<citsent citstr=" W10-1716 ">
following works from the 2010 wmt evaluation (lambert et al, 2010), <papid> W10-1716 </papid>we.</citsent>
<aftsection>
<nextsent>filtered this data using ibm-1 probabilities and language model scores to keep only the most reliable translations.
</nextsent>
<nextsent>two subsets were built with 115m and232m english words respectively (using two differ 288 alignment dev test bleu bleu ter giza 27.34 (0.01) 29.80 (0.06) 55.34 (0.06) reused giza 27.40 (0.05) 29.82 (0.10) 55.30 (0.02) reused moses 27.42 (0.02) 29.77 (0.06) 55.27 (0.03) table 5: results for systems trained via different word alignment configurations.
</nextsent>
<nextsent>the values are the average over 3 mert runs performed with different seeds.
</nextsent>
<nextsent>the numbers in parentheses are the standard deviation of these three.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3381">
<title id=" W11-1914.xml">hybrid approach for coreference resolution </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>we build language model using the above ml method to identify the non-anaphoric pronouns and the features used in training are word and its pos in window of five (two preceding and two following words to the pronoun).
</prevsent>
<prevsent>after the non-anaphoric pronoun identification, we resolve the anaphoric pronouns using pronominal resolution system.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
though we use salience factors based on the lappin and leass (1994), <papid> J94-4002 </papid>we have substantially deviated from the basic algorithm and have also used factors from sobha (2008), where named entity and ontology are considered for resolution.</citsent>
<aftsection>
<nextsent>for identifying an antecedent for pronoun we consider all the noun phrases before the pronoun in 93 the current sentence and in the four sentences preceding the current sentence.
</nextsent>
<nextsent>those noun phrases which agree in png with the pronoun are considered as the possible candidates.
</nextsent>
<nextsent>the png is obtained using the gender data work of shane bergsma and dekang lin (2006).<papid> P06-1005 </papid></nextsent>
<nextsent>the possible candidates are scored based on the salience factors and ranked.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3382">
<title id=" W11-1914.xml">hybrid approach for coreference resolution </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>for identifying an antecedent for pronoun we consider all the noun phrases before the pronoun in 93 the current sentence and in the four sentences preceding the current sentence.
</prevsent>
<prevsent>those noun phrases which agree in png with the pronoun are considered as the possible candidates.
</prevsent>
</prevsection>
<citsent citstr=" P06-1005 ">
the png is obtained using the gender data work of shane bergsma and dekang lin (2006).<papid> P06-1005 </papid></citsent>
<aftsection>
<nextsent>the possible candidates are scored based on the salience factors and ranked.
</nextsent>
<nextsent>the salience factors considered here are presented in the table 1.
</nextsent>
<nextsent>salience factors weights current sentence (sentence in which pronoun occurs) 100 for the preceding sentences up to four sentences from the current sentence reduce sentence score by 10 current clause (clause in which pronoun occurs) 100 ? for possessive pronoun 50 ? for non-possessive pronouns immediate clause (clause preceding or following the current clause) 50 ? for possessive pronoun 100 ? for non possessive pronouns non-immediate clause (neither the current or immediate clause) 50 possessive np 65 existential np 70 subject 80 direct object 50 indirect object 40 compliment of pp 30 table 1: salience factors and weights improving pronominal resolution using name entity (ne) and wordnet: pronouns such as he?, she?, i? and you?
</nextsent>
<nextsent>can take antecedents which are animate and particularly having the ne tag person.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3383">
<title id=" W11-1914.xml">hybrid approach for coreference resolution </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>crfs are well known for label sequencing tasks such as chunking, named entity tagging (lafferty et al  2001; taku kudo 2005).
</prevsent>
<prevsent>here we have crfs for classification task, by using only the current state features and not the features related to state transition.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
the features used for training are based on soon et al (2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>we have changed the method of deriving, values of the features such as string match, alias, from the soon el al method and found that our method is giving more result.
</nextsent>
<nextsent>the features used in our work are as follows.
</nextsent>
<nextsent>a) distance feature ? same as in soon et al  b) definite np - same as in soon et al  c) demonstrative np ? same as in soon et al  d) string match ?
</nextsent>
<nextsent>(not as soon et al the possible values are between 0 and 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3389">
<title id=" W11-1914.xml">hybrid approach for coreference resolution </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>this process is done for all the members of the identified pairs and the members in each group are aligned based on their position in the document to form the chain.
</prevsent>
<prevsent>in this section we present the evaluation of the complete system, which was developed under the closed task, along with the independent evaluation of the two sub-modules.
</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
a) non-anaphoric detection modules b) pronominal resolution module the data used for training as well as testing was provided conll-2001 shared task (pradhan et al , 2011), (<papid> W11-1901 </papid>pradhan et al , 2007) organizers.</citsent>
<aftsection>
<nextsent>the results shown in this paper were obtained for the development data.
</nextsent>
<nextsent>the non-anaphoric pronoun detection module is trained using the training data.
</nextsent>
<nextsent>this module was evaluated using the 91files development data.
</nextsent>
<nextsent>the training data contained 1326 non-anaphoric pronouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3390">
<title id=" W11-1922.xml">link type based pre cluster pair model for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more details will be given in section 3.
</prevsent>
<prevsent>from our in-house experiments, the final scores for coreference resolution can be improved by this mention detection part.
</prevsent>
</prevsection>
<citsent citstr=" P06-1005 ">
for coreference res 1http://conll.bbn.com 2http://www.bbn.com/ontonotes/ 131 features describing ci or cj words the first and last words of the given np in ci ( or cj) , also including the words in the context with window size 2 pos tags the part of speech tags corresponding to the words pronoun if mentions in ci( or cj) are pronouns; else definite if mentions in ci( or cj) are definite np; else demonstrative if mentions in ci( or cj) are demonstrative np; else number singular or plural, determined using data file published by bergsma and lin (2006) <papid> P06-1005 </papid>gender male, female, neuter, or unknown, determined using data file published by bergsma and lin (2006) <papid> P06-1005 </papid>semantic class semantic classes are given by ontonotes for named entities mentino type common noun phrases or pronouns table 1: the feature set describing ci or cj . olution, traditinal pair-wise model is applied, in which we first use exact string matching to generate some pre-clusters.</citsent>
<aftsection>
<nextsent>it should be noted that each pronoun must be treated as singleton pre-cluster, be cause they are not like names or nominal mentions, which can be resolved effectively with exact string matching.
</nextsent>
<nextsent>we then implement classification basedpre-cluster pair model combined with several effective coreference resolution features to determine whether two pre-clusters refer to the same entity.
</nextsent>
<nextsent>finally, we use closest-first clustering method to linkall the coreferential pre-clusters and generate the final cluster results.
</nextsent>
<nextsent>as mentioned before, mention shave three types: names, nominal mentions and pronouns.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3394">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> abstract </section>
<citcontext>
<prevsection>

<prevsent>we present novel unsupervised framework for focused meeting summarization that views the problem as an instance of relation extraction.
</prevsent>
</prevsection>
<citsent citstr=" P11-1054 ">
we adapt an existing in-domain relation learner (chen et al , 2011) <papid> P11-1054 </papid>by exploiting set of task-specific constraints and fea tures.</citsent>
<aftsection>
<nextsent>we evaluate the approach on decision summarization task and show that it outperforms unsupervised utterance-level extractive summarization baselines as well as an existing generic relation-extraction-based summarization method.
</nextsent>
<nextsent>moreover, our approach produces summaries competitive with those generated by supervised methods in terms of the standard rouge score.
</nextsent>
<nextsent>for better or worse, meetings play an integral rolein most of our daily lives ? they let us share information and collaborate with others to solve problem, to generate ideas, and to weigh options.
</nextsent>
<nextsent>not surprisingly then, there is growing interest in developing automatic methods for meeting summarization (e.g., zechner (2002), <papid> J02-4003 </papid>maskey and hirschberg(2005), galley (2006), <papid> W06-1643 </papid>lin and chen (2010), <papid> P10-1009 </papid>murray et al  (2010<papid> W10-4211 </papid>a)).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3396">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, our approach produces summaries competitive with those generated by supervised methods in terms of the standard rouge score.
</prevsent>
<prevsent>for better or worse, meetings play an integral rolein most of our daily lives ? they let us share information and collaborate with others to solve problem, to generate ideas, and to weigh options.
</prevsent>
</prevsection>
<citsent citstr=" J02-4003 ">
not surprisingly then, there is growing interest in developing automatic methods for meeting summarization (e.g., zechner (2002), <papid> J02-4003 </papid>maskey and hirschberg(2005), galley (2006), <papid> W06-1643 </papid>lin and chen (2010), <papid> P10-1009 </papid>murray et al  (2010<papid> W10-4211 </papid>a)).</citsent>
<aftsection>
<nextsent>this paper tackles the task of focused meeting summarization , i.e., generating summaries of particular aspect of meeting rather than of the meeting as whole (carenini et al , 2011).
</nextsent>
<nextsent>for example, one might want summary of just the decisions made during the meeting, the action items that emerged, the ideas discussed, or the hypotheses put forth, etc. consider, for example, the task of summarizing the decisions in the dialogue snippet in figure 1.
</nextsent>
<nextsent>the figure shows only the decision-related dialogue acts (drdas) ? utterances associated with one or moredecisions.1 each drda is labeled numerically according to the decision it supports; so the first two utterances support decision 1 as do the final two utterances in the snippet.
</nextsent>
<nextsent>manually constructed decision abstracts for each decision are shown at the bottom of the figure.2 these constitute the decision focused summary for the snippet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3397">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, our approach produces summaries competitive with those generated by supervised methods in terms of the standard rouge score.
</prevsent>
<prevsent>for better or worse, meetings play an integral rolein most of our daily lives ? they let us share information and collaborate with others to solve problem, to generate ideas, and to weigh options.
</prevsent>
</prevsection>
<citsent citstr=" W06-1643 ">
not surprisingly then, there is growing interest in developing automatic methods for meeting summarization (e.g., zechner (2002), <papid> J02-4003 </papid>maskey and hirschberg(2005), galley (2006), <papid> W06-1643 </papid>lin and chen (2010), <papid> P10-1009 </papid>murray et al  (2010<papid> W10-4211 </papid>a)).</citsent>
<aftsection>
<nextsent>this paper tackles the task of focused meeting summarization , i.e., generating summaries of particular aspect of meeting rather than of the meeting as whole (carenini et al , 2011).
</nextsent>
<nextsent>for example, one might want summary of just the decisions made during the meeting, the action items that emerged, the ideas discussed, or the hypotheses put forth, etc. consider, for example, the task of summarizing the decisions in the dialogue snippet in figure 1.
</nextsent>
<nextsent>the figure shows only the decision-related dialogue acts (drdas) ? utterances associated with one or moredecisions.1 each drda is labeled numerically according to the decision it supports; so the first two utterances support decision 1 as do the final two utterances in the snippet.
</nextsent>
<nextsent>manually constructed decision abstracts for each decision are shown at the bottom of the figure.2 these constitute the decision focused summary for the snippet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3398">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, our approach produces summaries competitive with those generated by supervised methods in terms of the standard rouge score.
</prevsent>
<prevsent>for better or worse, meetings play an integral rolein most of our daily lives ? they let us share information and collaborate with others to solve problem, to generate ideas, and to weigh options.
</prevsent>
</prevsection>
<citsent citstr=" P10-1009 ">
not surprisingly then, there is growing interest in developing automatic methods for meeting summarization (e.g., zechner (2002), <papid> J02-4003 </papid>maskey and hirschberg(2005), galley (2006), <papid> W06-1643 </papid>lin and chen (2010), <papid> P10-1009 </papid>murray et al  (2010<papid> W10-4211 </papid>a)).</citsent>
<aftsection>
<nextsent>this paper tackles the task of focused meeting summarization , i.e., generating summaries of particular aspect of meeting rather than of the meeting as whole (carenini et al , 2011).
</nextsent>
<nextsent>for example, one might want summary of just the decisions made during the meeting, the action items that emerged, the ideas discussed, or the hypotheses put forth, etc. consider, for example, the task of summarizing the decisions in the dialogue snippet in figure 1.
</nextsent>
<nextsent>the figure shows only the decision-related dialogue acts (drdas) ? utterances associated with one or moredecisions.1 each drda is labeled numerically according to the decision it supports; so the first two utterances support decision 1 as do the final two utterances in the snippet.
</nextsent>
<nextsent>manually constructed decision abstracts for each decision are shown at the bottom of the figure.2 these constitute the decision focused summary for the snippet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3399">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, our approach produces summaries competitive with those generated by supervised methods in terms of the standard rouge score.
</prevsent>
<prevsent>for better or worse, meetings play an integral rolein most of our daily lives ? they let us share information and collaborate with others to solve problem, to generate ideas, and to weigh options.
</prevsent>
</prevsection>
<citsent citstr=" W10-4211 ">
not surprisingly then, there is growing interest in developing automatic methods for meeting summarization (e.g., zechner (2002), <papid> J02-4003 </papid>maskey and hirschberg(2005), galley (2006), <papid> W06-1643 </papid>lin and chen (2010), <papid> P10-1009 </papid>murray et al  (2010<papid> W10-4211 </papid>a)).</citsent>
<aftsection>
<nextsent>this paper tackles the task of focused meeting summarization , i.e., generating summaries of particular aspect of meeting rather than of the meeting as whole (carenini et al , 2011).
</nextsent>
<nextsent>for example, one might want summary of just the decisions made during the meeting, the action items that emerged, the ideas discussed, or the hypotheses put forth, etc. consider, for example, the task of summarizing the decisions in the dialogue snippet in figure 1.
</nextsent>
<nextsent>the figure shows only the decision-related dialogue acts (drdas) ? utterances associated with one or moredecisions.1 each drda is labeled numerically according to the decision it supports; so the first two utterances support decision 1 as do the final two utterances in the snippet.
</nextsent>
<nextsent>manually constructed decision abstracts for each decision are shown at the bottom of the figure.2 these constitute the decision focused summary for the snippet.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3405">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, the decision cue is generally directly followed by the actual decision content (e.g., be little apple?, have rubber cases?).
</prevsent>
<prevsent>decision content phrases are denoted in figure 1 via italics and square brackets.
</prevsent>
</prevsection>
<citsent citstr=" W09-3934 ">
importantly, it is just the decision content portion of the utterance that should be considered for incorporation into the focused summary.1these are similar, but not completely equivalent, to the decision dialogue acts (ddas) of (bui et al , 2009), (<papid> W09-3934 </papid>fernandez et al ., 2008), (frampton et al , 2009).<papid> D09-1118 </papid>2murray et al  (2010<papid> W10-4211 </papid>b) show that users much prefer abstrac tive summaries over extracts when the text to be summarized is conversation.</citsent>
<aftsection>
<nextsent>in particular, extractive summaries drawn from group conversations can be confusing to the reader with out additional context; and the noisy, error-prone, dis fluent text of speech transcripts is likely to result in extractive summaries with low readability.
</nextsent>
<nextsent>304 c: say the standby button is quite kinda separate from all the other functions.
</nextsent>
<nextsent>(1) c: maybe that could be [a little apple].
</nextsent>
<nextsent>(1) c: it seems like youre gonna have [rubber cases], as well as [buttons].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3406">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moreover, the decision cue is generally directly followed by the actual decision content (e.g., be little apple?, have rubber cases?).
</prevsent>
<prevsent>decision content phrases are denoted in figure 1 via italics and square brackets.
</prevsent>
</prevsection>
<citsent citstr=" D09-1118 ">
importantly, it is just the decision content portion of the utterance that should be considered for incorporation into the focused summary.1these are similar, but not completely equivalent, to the decision dialogue acts (ddas) of (bui et al , 2009), (<papid> W09-3934 </papid>fernandez et al ., 2008), (frampton et al , 2009).<papid> D09-1118 </papid>2murray et al  (2010<papid> W10-4211 </papid>b) show that users much prefer abstrac tive summaries over extracts when the text to be summarized is conversation.</citsent>
<aftsection>
<nextsent>in particular, extractive summaries drawn from group conversations can be confusing to the reader with out additional context; and the noisy, error-prone, dis fluent text of speech transcripts is likely to result in extractive summaries with low readability.
</nextsent>
<nextsent>304 c: say the standby button is quite kinda separate from all the other functions.
</nextsent>
<nextsent>(1) c: maybe that could be [a little apple].
</nextsent>
<nextsent>(1) c: it seems like youre gonna have [rubber cases], as well as [buttons].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3415">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and rubber case?
</prevsent>
<prevsent>are both arguments.
</prevsent>
</prevsection>
<citsent citstr=" W11-0503 ">
although not shown in figure 1, it is also possible to identify relations that correspond to the decision cue phrases.3specifically, we focus on the task of decision summarization and, as in previous work in meeting summarization (e.g., fernandez et al  (2008), wang andcardie (2011)), <papid> W11-0503 </papid>assume that all decision-related utterances (drdas) have been identified.</citsent>
<aftsection>
<nextsent>we adapt the unsupervised relation learning approach of chenet al  (2011) <papid> P11-1054 </papid>to separately identify relations associated with decision cues vs. the decision content within drdas by defining new set of task-specific constraints and features to take the place of thedomain-specific constraints and features of the original model.</nextsent>
<nextsent>output of the system is set of extracted indicator-argument decision content relations (see the our method?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3417">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>are possible indicators with i? and we?
</prevsent>
<prevsent>as their arguments, respectively.
</prevsent>
</prevsection>
<citsent citstr=" D09-1044 ">
305finally, in order to compare our approach to an other relation-based summarization technique, we modify the multi-document summarization system of hachey (2009) <papid> D09-1044 </papid>to the single-document meetingscenario.</citsent>
<aftsection>
<nextsent>here again, our proposed approach performs better (37.47% vs. 34.69%).
</nextsent>
<nextsent>experiments under the system clusterings setting produce the same overall results, albeit with lower scores for all of the systems and baselines.
</nextsent>
<nextsent>in the remainder of the paper, we review related work in section 2 and give high-level description of the relation-based approach to focused summarization in section 3.
</nextsent>
<nextsent>sections 4, 5 and 6 present the modifications to the chen et al  (2011)<papid> P11-1054 </papid>relation extraction model required for its instantiation for the meeting summarization task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3432">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> focused summarization as relation ex-.  </section>
<citcontext>
<prevsection>
<prevsent>traction given the drdas for each meeting grouped (not necessarily correctly) according to the decisions they support, we put each cluster of drdas (or dered according to time within the cluster) into one decision document?.
</prevsent>
<prevsent>the goal will be to produce one decision abstract for each such decision document.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
we obtain constituent and dependency parses using the stanford parser (klein and manning, 2003; <papid> P03-1054 </papid>de marneffe et al , 2006).</citsent>
<aftsection>
<nextsent>with the corpus of constituent-parsed decision documents as the input, we will use and modify chen et al  (2011)<papid> P11-1054 </papid>ssystem to identify decision cue relations and decision content relations for each cluster.4 (section 6will make clear how the learned decision cue relations will be used to identify decision content relations.)</nextsent>
<nextsent>the salient decision content relation instances will be returned as decision summary com 4other unsupervised relation learning methods might also be appropriate (e.g., open ie (banko et al , 2007)), but they generally model relations between pairs of entities and group relations only according to lexical similarity.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3440">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> parameter estimation and inference via.  </section>
<citcontext>
<prevsection>
<prevsent>we define four types of constraints for the decision relation extraction model.
</prevsent>
<prevsent>syntactic constraints.
</prevsent>
</prevsection>
<citsent citstr=" P08-1004 ">
syntactic constraints are widely used for information extraction (ie) systems (snow et al , 2005; banko and etzioni, 2008), <papid> P08-1004 </papid>as it has been shown that most relations are expressed via small number of common syntactic patterns.</citsent>
<aftsection>
<nextsent>for each relation type, we require at least 80%5 of the induced relation instances in expectation to match one of the following syntactic patterns: ? the indicator is verb and the argument is noun phrase.
</nextsent>
<nextsent>the headword of the argument is the direct object of the indicator or the nominal subject of the indicator.5experiments show that this threshold is suitable for decision relation extraction, so we adopt it from (chen et al , 2011).<papid> P11-1054 </papid>?</nextsent>
<nextsent>the indicator is verb and the argument is prepositional phrase or clause starting with to?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3446">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>table 1 lists the features we use for discovering both the decision cue relations and decision content relations.
</prevsent>
<prevsent>we start with collection of domain independent basic features shown to be useful in relation extraction (banko and etzioni, 2008;<papid> P08-1004 </papid>chen et al , 2011).<papid> P11-1054 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1004 ">
then we add meeting features, structural features and semantic features that have been found to be good predictors for decision detection (hsueh and moore,2007) <papid> N07-1004 </papid>or meeting and decision summarization (gal 308 basic features unigram (stemmed) part-of-speech (pos) constituent label (np, vp, s/sbar (start with to?)) dependency label meeting features dialogue act (da) type speaker role topic structural features (galley, 2006) (<papid> W06-1643 </papid>wang and cardie, 2011) <papid> W11-0503 </papid>in an adjacency pair (ap)?</citsent>
<aftsection>
<nextsent>if in an ap, ap type if in an ap, the other part is decision-related?
</nextsent>
<nextsent>if in an ap, the source part or target part?
</nextsent>
<nextsent>if in an ap and is source part, is the target positive feedback?
</nextsent>
<nextsent>if in an ap and is target part, is the source question?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3449">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>(an adjacency pair (ap) is an important conversational analysis concept (schegloff and sacks, 1973).
</prevsent>
<prevsent>in the ami corpus, an ap pair consists of source utterance and target utterance, produced by different speakers.)
</prevsent>
</prevsection>
<citsent citstr=" D08-1081 ">
ley, 2006; murray and carenini, 2008; <papid> D08-1081 </papid>fernandez etal., 2008; wang and cardie, 2011).<papid> W11-0503 </papid></citsent>
<aftsection>
<nextsent>features employed only for arguments are listed in the last category in table 1.
</nextsent>
<nextsent>after applying the features in table 1 and the global constraints from section 5 in preliminary experiments, we found that the extracted relation instances are mostly derived from decision cue relations.
</nextsent>
<nextsent>sample decision cue relations and instances are displayed in table 2 and are not necessarily sur prising: previous research (hsueh and moore, 2007)<papid> N07-1004 </papid>has observed the important role of personal pronouns, such as we?</nextsent>
<nextsent>and i?, in decision-making expressions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3455">
<title id=" W12-1642.xml">focused meeting summarization via unsupervised relation extraction </title>
<section> experiment setup.  </section>
<citcontext>
<prevsection>
<prevsent>as better approaches for drda clustering become available, they could be employed instead.
</prevsent>
<prevsent>evaluation metrics.
</prevsent>
</prevsection>
<citsent citstr=" N03-1020 ">
we use the widely accepted rouge (lin and hovy, 2003) <papid> N03-1020 </papid>evaluation measure.we adopt the rouge-1 and rouge-su4 metrics from (hachey, 2009)<papid> D09-1044 </papid>and also use rouge 2.</citsent>
<aftsection>
<nextsent>we choose the stemming option of the rouge.
</nextsent>
<nextsent>software at http://berouge.com/ and remove stop words from both the system and gold-standard summaries.training and parameters.
</nextsent>
<nextsent>the dirichlet hyper parameters are set to 0.1 for the priors.
</nextsent>
<nextsent>when training the model, ten random restarts are performed and each run stops when reaching convergence threshold (105).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3477">
<title id=" W12-2016.xml">generating diagnostic multiple choice comprehension cloze questions </title>
<section> analysis of errors.  </section>
<citcontext>
<prevsection>
<prevsent>second, the word that completes an idiom can be far likelier than any other choice, making it too easy to guess based solely on local context, whether correct or not.
</prevsent>
<prevsent>third, because idioms have non-componential semantics, the missing word is liable to be semantically unrelated to other sentence words, causing dqgen to badly underestimate its local relevance.
</prevsent>
</prevsection>
<citsent citstr=" D09-1033 ">
detecting idioms automatically is research problem in its own right (li, roth, &amp; sporleder, 2010; li &amp; sporleder, 2009).<papid> D09-1033 </papid></citsent>
<aftsection>
<nextsent>we might be able to recognize idioms by using the fact that its n-gram frequency is much higher than expected based on the frequency of its individual words.
</nextsent>
<nextsent>a simpler approach is to consult dictionary of common phrases.
</nextsent>
<nextsent>either approach would require extension to handle parameterized idioms such as chip on [someones] shoulder, or non-contiguous forms such as actions do in fact speak louder than words.
</nextsent>
<nextsent>5.3 lexical issues for distracters.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3478">
<title id=" W12-2016.xml">generating diagnostic multiple choice comprehension cloze questions </title>
<section> relation to prior work.  </section>
<citcontext>
<prevsection>
<prevsent>a multiple choice cloze question to test vocabulary and grammar is constructed from sentence selected from corpus by deleting part of it (typical ly the target vocabulary word) and selecting distract ers for it.
</prevsent>
<prevsent>selecting distract ers with the same pos and approximate frequency as the answer word is common strategy (brown, frishkoff, &amp; eskenazi, 2005; coniam, 1997; liu, wang, &amp; gao, 2005).
</prevsent>
</prevsection>
<citsent citstr=" W05-0201 ">
besides matching the correct answers pos and frequency, liu et al (2005) <papid> W05-0201 </papid>added culture dependent strategy for generating distracters: choose english words with semantically similar translations in the learners native language to the translation of the answer word.</citsent>
<aftsection>
<nextsent>correia et al (2010) generated vocabulary questions for portuguese with three types of distracters.
</nextsent>
<nextsent>one type of distracter had the same pos and word level as the target word, based on its unigram frequency in portuguese textbooks used in different grades.
</nextsent>
<nextsent>a second type had the lowest levenshtein distance to the target out of all words with its pos.
</nextsent>
<nextsent>a third type was misspellings of the target word using table of common spelling mistakes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3479">
<title id=" W12-2016.xml">generating diagnostic multiple choice comprehension cloze questions </title>
<section> relation to prior work.  </section>
<citcontext>
<prevsection>
<prevsent>pino et al (2008) selected distract ers that made the completed sentence grammatical and tended to co-occur with the words in the sentence, but were semantically distant from the target word as measured by wordnet.
</prevsent>
<prevsent>in constr ast, smith et al (2008) looked for distract ers semantically similar to the answer word based on distributional similarity.
</prevsent>
</prevsection>
<citsent citstr=" W05-0210 ">
in addition, sumita et al (2005) <papid> W05-0210 </papid>used thesaurus for the same purpose, and then consulted the web to filter out plausible distracters.</citsent>
<aftsection>
<nextsent>aldabe et al (2009) considered context in question sentence when choosing distracters.
</nextsent>
<nextsent>they used an n-gram language model to predict the probability of occurrence of distracter with its preceding words.
</nextsent>
<nextsent>gates et al (2011) generated phrase-type distract ers, unlike other work.
</nextsent>
<nextsent>they generated questions from dictionary definition of the target vocabulary word.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3480">
<title id=" W12-2006.xml">hoo 2012 a report on the preposition and determiner error correction shared task </title>
<section> the task.  </section>
<citcontext>
<prevsection>
<prevsent>section 2 provides an overview of the task and the timeline across which it was carried out; section 3 provides details of the participating teams; section 4 describes the training and test data in more detail; section 5 presents the results of the evaluation; and section 6 provides some concluding remarks and discussion, reflecting on lessons learned.
</prevsent>
<prevsent>non-native speakers who are learning english find prepositions and determiners particularly problematic.
</prevsent>
</prevsection>
<citsent citstr=" W10-4236 ">
the selection of the appropriate preposition ina given context often appears to be matter of idiom or convention rather than being governed by consistent set of rules; and selecting determiner2hoo stands for helping our own?, reflection of the historical origins of the exercise as an attempt to develop tools to help researchers in natural language processing to write better papers: see (dale and kilgarriff, 2010) <papid> W10-4236 </papid>for the background to this enterprise and (dale and kilgarriff, 2011) for report on the pilot round of the task held in 2011.</citsent>
<aftsection>
<nextsent>54 team id group or institution subtasks runs cu computer laboratory, university of cambridge, uk drc 8 et educational testing service, new jersey, usa dr 3 ju jadavpur university, kolkata, india drc 1 ku natural language processing lab, korea university, seoul, korea drc 10 le ku leuven, belgium drc 2 na naist, japan drc 8 nu national university of singapore, singapore drc 1 tc department of computer science and statistics, trinity college dublin, ireland drc 10 th nlplab, national tsing hua university, hsinchu, taiwan drc 4 ud ukp lab, technische universitat darmstadt, germany drc 3 ui cognitive computation group, university of illinois, usa drc 10 ut theoretical computational linguistics group, university of tubingen, germany drc 10 va valkuil.net, the netherlands drc 6 vt vtex, vilnius, lithuania drc 9 table 1: participating teams depends on complex of contextual factors which is particularly challenging for those whose native language does not make use of determiners.
</nextsent>
<nextsent>the literature suggests that mistakes in the use of the determiners and prepositions account for 2050% of grammar and usage errors; the extent to whicha learner has problems with determiners varies depending on their native language, while the degree of difficulty experienced with prepositions is less varied (see chapter 3 in (leacock et al, 2010)).
</nextsent>
<nextsent>for the shared task, we made use of data drawn from the clc fce dataset, set of 1,244 exam scripts written by candidates sitting the cambridgeesol first certificate in english (fce) examination in 2000 and 2001, and made available by cambridge universiy press; see (yannakoudakis et al, 2011).<papid> P11-1019 </papid></nextsent>
<nextsent>this data is described in more detail below.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3481">
<title id=" W12-2006.xml">hoo 2012 a report on the preposition and determiner error correction shared task </title>
<section> the task.  </section>
<citcontext>
<prevsection>
<prevsent>54 team id group or institution subtasks runs cu computer laboratory, university of cambridge, uk drc 8 et educational testing service, new jersey, usa dr 3 ju jadavpur university, kolkata, india drc 1 ku natural language processing lab, korea university, seoul, korea drc 10 le ku leuven, belgium drc 2 na naist, japan drc 8 nu national university of singapore, singapore drc 1 tc department of computer science and statistics, trinity college dublin, ireland drc 10 th nlplab, national tsing hua university, hsinchu, taiwan drc 4 ud ukp lab, technische universitat darmstadt, germany drc 3 ui cognitive computation group, university of illinois, usa drc 10 ut theoretical computational linguistics group, university of tubingen, germany drc 10 va valkuil.net, the netherlands drc 6 vt vtex, vilnius, lithuania drc 9 table 1: participating teams depends on complex of contextual factors which is particularly challenging for those whose native language does not make use of determiners.
</prevsent>
<prevsent>the literature suggests that mistakes in the use of the determiners and prepositions account for 2050% of grammar and usage errors; the extent to whicha learner has problems with determiners varies depending on their native language, while the degree of difficulty experienced with prepositions is less varied (see chapter 3 in (leacock et al, 2010)).
</prevsent>
</prevsection>
<citsent citstr=" P11-1019 ">
for the shared task, we made use of data drawn from the clc fce dataset, set of 1,244 exam scripts written by candidates sitting the cambridgeesol first certificate in english (fce) examination in 2000 and 2001, and made available by cambridge universiy press; see (yannakoudakis et al, 2011).<papid> P11-1019 </papid></citsent>
<aftsection>
<nextsent>this data is described in more detail below.
</nextsent>
<nextsent>the version of the data we provided to teams as training data consisted of the original text as writ tenby the examination subjects, so it contains many errors besides the preposition and determiner errors; it thus provides quite realistic challenge, as opposed to artificial datasets where the only errors present are the particular errors of interest.
</nextsent>
<nextsent>the training data we provided consisted of the raw, error ful texts, andfor each text file set of gold-standard standoff annotations indicating the locations of the preposition and determiner errors and their corrections, which we extracted from the cup data annotations.
</nextsent>
<nextsent>the task consisted in attempting to generate sets of standoff annotations that matched those in the gold standard.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3482">
<title id=" W12-2006.xml">hoo 2012 a report on the preposition and determiner error correction shared task </title>
<section> discussion and conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>however, the second option has the opposite problem: by removing all the other errors from the text, we would be providing very artificial dataset where one assumes some other process has fixed all the other errors before the errors of interest hereare addressed.
</prevsent>
<prevsent>while there are some types of errors that might sensibly be addressed before others in pipeline, in general this is not very plausible model; any real system is going to have to address noisy data containing many different kinds of errors simultaneously.
</prevsent>
</prevsection>
<citsent citstr=" N10-1019 ">
a third alternative, that of selectively removing or correcting errors, is something of middle road, and has been used in other work using the clc data: in particular, gamon (2010) <papid> N10-1019 </papid>removes from the data sentences where some other error appears immediately next to preposition or determiner error.</citsent>
<aftsection>
<nextsent>60 detection recognition correction team run r run r run r cu 6 7.8 49.31 13.48 6 6.86 43.32 11.84 6 5.25 33.18 9.07 et 0 51.67* 28.57* 36.8* 0 50.83* 28.11* 36.2* ? ?
</nextsent>
<nextsent>ju 1 7.73 6.45 7.04 1 7.73 6.45 7.04 1 1.66 1.38 1.51 ku 0 12.85 10.6 11.62 0 6.7 5.53 6.06 0 6.15 5.07 5.56 le 0 40.41 35.94 38.05 0 37.31 33.18 35.12 0 34.72 30.88 32.68 na 1 37.43 32.26 34.65 1 36.36 31.34 33.66 1 28.88 24.88 26.73 nu 0 57.76 30.88 40.24 0 57.76 30.88 40.24 0 48.28 25.81 33.63 tc 3 8.68 8.76 8.72 3 7.76 7.83 7.8 3 4.11 4.15 4.13 th 1 17.69 34.56 23.4 1 17.69 34.56 23.4 1 9.91 19.35 13.1 ud 2 6.41 24.88 10.19 1 1.98 6.45 3.03 0 0.0 0.0 0.0 ui 0 40.0 37.79 38.86 0 38.05 35.94 36.97 0 35.61 33.64 34.6 ut 5 34.38 25.35 29.18 5 31.87 23.5 27.06 6 25.75 19.82 22.4 va 3 11.04 15.21 12.79 3 10.37 14.29 12.02 3 5.02 6.91 5.81 vt 5 9.82 7.37 8.42 5 9.82 7.37 8.42 5 7.98 5.99 6.84 table 9: results before revisions, determiner errors only detection recognition correction team run r run r run r cu 6 8.53 51.09 14.63 6 7.37 44.1 12.63 6 5.91 35.37 10.13 et 0 57.5* 30.13* 39.54* 0 56.67* 29.69* 38.97* ? ?
</nextsent>
<nextsent>ju 1 9.39 7.42 8.29 1 9.39 7.42 8.29 1 2.21 1.75 1.95 ku 0 14.53 11.35 12.75 0 6.7 5.24 5.88 0 6.15 4.8 5.39 le 0 44.56 37.55 40.76 0 40.93 34.5 37.44 0 38.34 32.31 35.07 na 1 41.18 33.62 37.02 1 39.57 32.31 35.58 1 33.16 27.07 29.81 nu 0 68.1 34.5 45.8 0 68.1 34.5 45.8 0 62.93 31.88 42.32 tc 8 5.17 20.96 8.3 3 7.31 6.99 7.14 8 2.8 11.35 4.49 th 1 19.34 35.81 25.11 1 19.34 35.81 25.11 1 11.08 20.52 14.4 ud 1 8.07 24.89 12.19 1 1.98 6.11 2.99 0 0.0 0.0 0.0 ui 0 43.9 39.3 41.47 2 45.98 34.93 39.7 0 41.46 37.12 39.17 ut 5 39.38 27.51 32.39 5 35.63 24.89 29.31 6 30.54 22.27 25.76 va 3 11.71 15.28 13.26 3 10.7 13.97 12.12 3 6.02 7.86 6.82 vt 5 9.82 6.99 8.16 5 9.82 6.99 8.16 5 7.98 5.68 6.63 table 10: results after revisions, determiner errors only in the end, we opted for the first alternative here, on the grounds that this is the best approximation to the real task of non-native speaker error correction.
</nextsent>
<nextsent>the third alternative would also have been possible, but we were concerned about the impact on the size of our test dataset that would result from carrying out this process across the board.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3483">
<title id=" W12-2006.xml">hoo 2012 a report on the preposition and determiner error correction shared task </title>
<section> discussion and conclusions.  </section>
<citcontext>
<prevsection>
<prevsent>it is often inaccuracies at this level that contribute to the differences between ateams detection score and the corresponding recognition score.
</prevsent>
<prevsent>while precise character offset information is important for some error correction tasks(for example, one would not want an automated corrector to insert corrections misplaced by one character), arguably it is too strict in the present circumstances.
</prevsent>
</prevsection>
<citsent citstr=" N12-1067 ">
dahlmeier and ng (2012) <papid> N12-1067 </papid>propose an alternative evaluation scheme which, along with other properties, overcomes this by operating in terms of tokens rather than character offsets.</citsent>
<aftsection>
<nextsent>6.4 summary.
</nextsent>
<nextsent>overall, we were immensely pleased with the levelof interest in this shared task.
</nextsent>
<nextsent>the hoo 2012 training data and evaluation tools are publicly available, so interested parties who did not take part in the shared task can still try their hand retrospectively; unfortunately, our contract with cup means that the test data used in this round is not publicly available.
</nextsent>
<nextsent>our future plans include packaging subset of the initially held-out public fce dataset as new testset, with the aim of establishing standardised training and testing setup in the same way as section 23 of the wall street journal corpus is conventionally used as test set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3484">
<title id=" W11-1814.xml">extracting bacteria biotopes with semi supervised named entity recognition and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to create the training data for coreference resolution, we have manually annotated the corpus with coreference links.
</prevsent>
<prevsent>the overall f-score ofevent extraction was 33.2 at the official evaluation of the shared task, but it has been improved to 33.8 thanks to the refinement made after the submission deadline.
</prevsent>
</prevsection>
<citsent citstr=" W11-1809 ">
in this paper, we present machine learning-based approach for bacteria biotopes extraction of the bionlp shared task 2011 (bossy et al , 2011).<papid> W11-1809 </papid></citsent>
<aftsection>
<nextsent>the task consists of extracting bacteria localization events, namely, mentions of given species and the place where it lives.
</nextsent>
<nextsent>places related to bacteria localization events range from plant or animal hosts for pathogenic or symbiotic bacteria to natural environments like soil or water1.
</nextsent>
<nextsent>this task also targets specific environments of interest such as medical environments (hospitals, surgery devices, etc.), processed food (dairy) and geographical localizations.
</nextsent>
<nextsent>1https://sites.google.com/site/bionlpst/ home/bacteria-biotopes the task of extracting bacteria biotopes involves two steps: named entity recognition (ner) and event detection.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3485">
<title id=" W11-1814.xml">extracting bacteria biotopes with semi supervised named entity recognition and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this observation motivated us to perform coreference resolution as pre-processing step, so that each event can be recognized within narrower textual scope.
</prevsent>
<prevsent>there are two common approaches to coreference resolution: one mainly relies on heuristics, and the other employs machine learning.
</prevsent>
</prevsection>
<citsent citstr=" N01-1008 ">
some 94instances of the heuristics-based approach are described in (harabagiu et al, 2001; <papid> N01-1008 </papid>markert and nissim, 2005; <papid> J05-3004 </papid>yang and su, 2007), where they use lexical and encyclopedic knowledge.</citsent>
<aftsection>
<nextsent>machine learning-based methods (soon and ng, 2001; ng and cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003; <papid> P03-1023 </papid>luo et al, 2004; <papid> P04-1018 </papid>daume and marcu, 2005) train classifier or search model using corpus annotated with anaphoric pairs.</nextsent>
<nextsent>in our system, we employ the simple supervised method presented in soon and ng(2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3486">
<title id=" W11-1814.xml">extracting bacteria biotopes with semi supervised named entity recognition and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this observation motivated us to perform coreference resolution as pre-processing step, so that each event can be recognized within narrower textual scope.
</prevsent>
<prevsent>there are two common approaches to coreference resolution: one mainly relies on heuristics, and the other employs machine learning.
</prevsent>
</prevsection>
<citsent citstr=" J05-3004 ">
some 94instances of the heuristics-based approach are described in (harabagiu et al, 2001; <papid> N01-1008 </papid>markert and nissim, 2005; <papid> J05-3004 </papid>yang and su, 2007), where they use lexical and encyclopedic knowledge.</citsent>
<aftsection>
<nextsent>machine learning-based methods (soon and ng, 2001; ng and cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003; <papid> P03-1023 </papid>luo et al, 2004; <papid> P04-1018 </papid>daume and marcu, 2005) train classifier or search model using corpus annotated with anaphoric pairs.</nextsent>
<nextsent>in our system, we employ the simple supervised method presented in soon and ng(2001).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3487">
<title id=" W11-1814.xml">extracting bacteria biotopes with semi supervised named entity recognition and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are two common approaches to coreference resolution: one mainly relies on heuristics, and the other employs machine learning.
</prevsent>
<prevsent>some 94instances of the heuristics-based approach are described in (harabagiu et al, 2001; <papid> N01-1008 </papid>markert and nissim, 2005; <papid> J05-3004 </papid>yang and su, 2007), where they use lexical and encyclopedic knowledge.</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
machine learning-based methods (soon and ng, 2001; ng and cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003; <papid> P03-1023 </papid>luo et al, 2004; <papid> P04-1018 </papid>daume and marcu, 2005) train classifier or search model using corpus annotated with anaphoric pairs.</citsent>
<aftsection>
<nextsent>in our system, we employ the simple supervised method presented in soon and ng(2001).
</nextsent>
<nextsent>to create the training data, we have manually annotated the corpus with coreference information about bacteria.
</nextsent>
<nextsent>our approach, consequently, has three processes: ner, coreference resolution of bacterium entities, and event extraction.
</nextsent>
<nextsent>the latter two processes can be formulated as classification problems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3488">
<title id=" W11-1814.xml">extracting bacteria biotopes with semi supervised named entity recognition and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are two common approaches to coreference resolution: one mainly relies on heuristics, and the other employs machine learning.
</prevsent>
<prevsent>some 94instances of the heuristics-based approach are described in (harabagiu et al, 2001; <papid> N01-1008 </papid>markert and nissim, 2005; <papid> J05-3004 </papid>yang and su, 2007), where they use lexical and encyclopedic knowledge.</prevsent>
</prevsection>
<citsent citstr=" P03-1023 ">
machine learning-based methods (soon and ng, 2001; ng and cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003; <papid> P03-1023 </papid>luo et al, 2004; <papid> P04-1018 </papid>daume and marcu, 2005) train classifier or search model using corpus annotated with anaphoric pairs.</citsent>
<aftsection>
<nextsent>in our system, we employ the simple supervised method presented in soon and ng(2001).
</nextsent>
<nextsent>to create the training data, we have manually annotated the corpus with coreference information about bacteria.
</nextsent>
<nextsent>our approach, consequently, has three processes: ner, coreference resolution of bacterium entities, and event extraction.
</nextsent>
<nextsent>the latter two processes can be formulated as classification problems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3489">
<title id=" W11-1814.xml">extracting bacteria biotopes with semi supervised named entity recognition and coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there are two common approaches to coreference resolution: one mainly relies on heuristics, and the other employs machine learning.
</prevsent>
<prevsent>some 94instances of the heuristics-based approach are described in (harabagiu et al, 2001; <papid> N01-1008 </papid>markert and nissim, 2005; <papid> J05-3004 </papid>yang and su, 2007), where they use lexical and encyclopedic knowledge.</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
machine learning-based methods (soon and ng, 2001; ng and cardie, 2002; <papid> P02-1014 </papid>yang et al , 2003; <papid> P03-1023 </papid>luo et al, 2004; <papid> P04-1018 </papid>daume and marcu, 2005) train classifier or search model using corpus annotated with anaphoric pairs.</citsent>
<aftsection>
<nextsent>in our system, we employ the simple supervised method presented in soon and ng(2001).
</nextsent>
<nextsent>to create the training data, we have manually annotated the corpus with coreference information about bacteria.
</nextsent>
<nextsent>our approach, consequently, has three processes: ner, coreference resolution of bacterium entities, and event extraction.
</nextsent>
<nextsent>the latter two processes can be formulated as classification problems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3490">
<title id=" W11-1814.xml">extracting bacteria biotopes with semi supervised named entity recognition and coreference resolution </title>
<section> semi-supervised ner.  </section>
<citcontext>
<prevsection>
<prevsent>in this work, we use crf model to perform ner.cfrs (lafferty et. al., 2001) are sequence modeling framework that not only has all the advantages of memms but also solves the label bias problem in principled way.
</prevsent>
<prevsent>this model is suitable for labeling sequence data, especially for ner.
</prevsent>
</prevsection>
<citsent citstr=" P09-1054 ">
based onthis model, our crf tagger is trained with stochastic gradient descent-based method described in tsuruoka et al (2009), <papid> P09-1054 </papid>which can produce compact and accurate model.</citsent>
<aftsection>
<nextsent>due to the small size of the training corpus and the complexity of their category, the entities cannot be easily recognized by standard supervised learning.
</nextsent>
<nextsent>therefore, we enhance our learning model by incorporating related information from other external resources.
</nextsent>
<nextsent>on top of the lexical and syntactic features, we use two additional types of information, which are expected to alleviate the data sparseness problem.
</nextsent>
<nextsent>in summary, we use four types of features including lexical and syntactic features, word cluster and word sense features as the input for the crf model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3491">
<title id=" W11-1814.xml">extracting bacteria biotopes with semi supervised named entity recognition and coreference resolution </title>
<section> semi-supervised ner.  </section>
<citcontext>
<prevsection>
<prevsent>kamaza et. al.
</prevsent>
<prevsent>(2001) use hidden markov model (hmm) to produce word cluster features for their maximum entropy model for part-of-speech tagging.
</prevsent>
</prevsection>
<citsent citstr=" P08-1068 ">
koo et al (2008) <papid> P08-1068 </papid>implement the brown clustering algorithm to produce additional features for their dependencyparser.</citsent>
<aftsection>
<nextsent>for our ner task, we use an hmm to produce word cluster features for our crf model.we employed an open source library2 for learning hmms with the online expectation maximization (em) algorithm proposed by liang and klein(2009).<papid> N09-1069 </papid></nextsent>
<nextsent>the online em algorithm is much more efficient than the standard batch em algorithm and allows us to use large amount of data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3492">
<title id=" W11-1814.xml">extracting bacteria biotopes with semi supervised named entity recognition and coreference resolution </title>
<section> semi-supervised ner.  </section>
<citcontext>
<prevsection>
<prevsent>(2001) use hidden markov model (hmm) to produce word cluster features for their maximum entropy model for part-of-speech tagging.
</prevsent>
<prevsent>koo et al (2008) <papid> P08-1068 </papid>implement the brown clustering algorithm to produce additional features for their dependencyparser.</prevsent>
</prevsection>
<citsent citstr=" N09-1069 ">
for our ner task, we use an hmm to produce word cluster features for our crf model.we employed an open source library2 for learning hmms with the online expectation maximization (em) algorithm proposed by liang and klein(2009).<papid> N09-1069 </papid></citsent>
<aftsection>
<nextsent>the online em algorithm is much more efficient than the standard batch em algorithm and allows us to use large amount of data.
</nextsent>
<nextsent>for each hidden state, words that are produced by this state with the highest probability are written.
</nextsent>
<nextsent>we use this result of word clustering as feature for ner.
</nextsent>
<nextsent>the optimal number of hidden states is selected by evaluating its effectiveness on ner using the development set.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3493">
<title id=" W11-1814.xml">extracting bacteria biotopes with semi supervised named entity recognition and coreference resolution </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>all possible relationships between host and host part entities are generated if they are in the same paragraph.
</prevsent>
<prevsent>the training and evaluation data used in these experiments are provided by the shared task organizers.
</prevsent>
</prevsection>
<citsent citstr=" W11-1816 ">
the token and syntactic information are extracted from the supporting resources (stenetorp et. al. , 2011).<papid> W11-1816 </papid></citsent>
<aftsection>
<nextsent>more detail, the tokenized text was done bygenia tools, and the syntactic analyses was created by the mcclosky-charinak parser (mcclosky experiment acc.
</nextsent>
<nextsent>pre.
</nextsent>
<nextsent>re.
</nextsent>
<nextsent>f-score baseline 94.28 76.32 35.51 48.47 word cluster 94.46 78.23 39.59 52.57 word sense 94.63 74.15 44.49 55.61 all features 94.70 77.62 45.31 57.22 table 2: performance of named entity recognition in terms of accuracy, precision, recall and f-score with different features on the development set.and charniak, 2008), trained on the genia tree bank corpus (tateisi et al, 2005), <papid> I05-2038 </papid>which is one of the most accurate parsers for biomedical documents.for both classification of anaphoric pairs in coreference resolution and determining relationship oftwo entites, we used the svm light library 5, state of-the-art classifier, with the linear kernel.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3494">
<title id=" W11-1814.xml">extracting bacteria biotopes with semi supervised named entity recognition and coreference resolution </title>
<section> experiments and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>pre.
</prevsent>
<prevsent>re.
</prevsent>
</prevsection>
<citsent citstr=" I05-2038 ">
f-score baseline 94.28 76.32 35.51 48.47 word cluster 94.46 78.23 39.59 52.57 word sense 94.63 74.15 44.49 55.61 all features 94.70 77.62 45.31 57.22 table 2: performance of named entity recognition in terms of accuracy, precision, recall and f-score with different features on the development set.and charniak, 2008), trained on the genia tree bank corpus (tateisi et al, 2005), <papid> I05-2038 </papid>which is one of the most accurate parsers for biomedical documents.for both classification of anaphoric pairs in coreference resolution and determining relationship oftwo entites, we used the svm light library 5, state of-the-art classifier, with the linear kernel.</citsent>
<aftsection>
<nextsent>in order to find the best parameters and features for our final system, we conducted series of experiments at each step of the approach.
</nextsent>
<nextsent>5.1 named entity recognition.
</nextsent>
<nextsent>we evaluated the impact of additional featues onner by running four experiments.
</nextsent>
<nextsent>the baseline experiment was conducted by using the original crf tagger, which did not use any additional features derived from external resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3495">
<title id=" W11-1823.xml">an incremental model for the coreference resolution task of bionlp 2011 </title>
<section> our incremental model for coreference.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 restricted accessibility of antecedent.
</prevsent>
<prevsent>candidate sin order to reduce under specification, mi is compared to virtual prototype of each coreference set (similar to e.g.
</prevsent>
</prevsection>
<citsent citstr=" P04-1018 ">
(luo et al, 2004; <papid> P04-1018 </papid>yang et al, 2004; <papid> C04-1033 </papid>rahman and ng, 2009)).</citsent>
<aftsection>
<nextsent>the virtual prototype bears morphologic and semantic information accumulated from all elements of the coreference set.
</nextsent>
<nextsent>access to coreference sets is restricted to the virtual prototype.
</nextsent>
<nextsent>this reduces the number of considered pairs (from the cardinality of set to 1).
</nextsent>
<nextsent>3.2 filtering based on anaphora type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3496">
<title id=" W11-1823.xml">an incremental model for the coreference resolution task of bionlp 2011 </title>
<section> our incremental model for coreference.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 restricted accessibility of antecedent.
</prevsent>
<prevsent>candidate sin order to reduce under specification, mi is compared to virtual prototype of each coreference set (similar to e.g.
</prevsent>
</prevsection>
<citsent citstr=" C04-1033 ">
(luo et al, 2004; <papid> P04-1018 </papid>yang et al, 2004; <papid> C04-1033 </papid>rahman and ng, 2009)).</citsent>
<aftsection>
<nextsent>the virtual prototype bears morphologic and semantic information accumulated from all elements of the coreference set.
</nextsent>
<nextsent>access to coreference sets is restricted to the virtual prototype.
</nextsent>
<nextsent>this reduces the number of considered pairs (from the cardinality of set to 1).
</nextsent>
<nextsent>3.2 filtering based on anaphora type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3497">
<title id=" W11-1823.xml">an incremental model for the coreference resolution task of bionlp 2011 </title>
<section> an empirically-based salience measure.  </section>
<citcontext>
<prevsection>
<prevsent>we have not yet implemented full1as we do not perform anaphoricity determination of nominal nps, we do not consider bridging anaphora (anaphoricnouns that are connected to their antecedents through semantic relations and cannot be identified by string matching).blown binding theory.
</prevsent>
<prevsent>instead, we check if the antecedent and the anaphor are governed by the same verb.
</prevsent>
</prevsection>
<citsent citstr=" J94-4002 ">
our salience measure is partial adaption of the measure from (lappin and leass, 1994).<papid> J94-4002 </papid></citsent>
<aftsection>
<nextsent>the salience of np is solely defined by the salience of the dependency label it bears.
</nextsent>
<nextsent>the salience of dependency label, d, is estimated by the number of true mentions (i.e. co-refering nps) that bear (i.e. are connected to their heads with d), divided by the total number of true mentions (bearing any d).
</nextsent>
<nextsent>the salience of the label subject is thus calculated by: number of true mentions bearing subject total number of truementionswe get hierarchical ordering of the dependency labels (subject   object   pobject   ...)
</nextsent>
<nextsent>according to which antecedents are ranked and selected.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3498">
<title id=" W11-2505.xml">encoding syntactic dependencies by vector permutation </title>
<section> background and motivation.  </section>
<citcontext>
<prevsection>
<prevsent>the type of semantics represented in word space depends on the context.
</prevsent>
<prevsent>if we choose documents as context we obtain semantics different from the one we would obtain by selecting sentences as context.
</prevsent>
</prevsection>
<citsent citstr=" J10-4006 ">
several approaches have investigated the abovementioned problem: (baroni andlenci, 2010) <papid> J10-4006 </papid>use representation based on third order tensors and provide general framework for distributional semantics in which it is possible to represent several aspects of meaning using single data structure.</citsent>
<aftsection>
<nextsent>(sahlgren et al, 2008) adopt vector permutations as means to encode order in word space, as described in section 2.
</nextsent>
<nextsent>beagle (jones and mewhort, 2007) is very well-knownmethod to encode word order and context information in wordspace.
</nextsent>
<nextsent>the drawback of the beagle model is that it relies on complex model to build vectors which is computational expensive.
</nextsent>
<nextsent>this problem is solved by (de vine and bruza, 2010) in which the authors propose an approach similar to beagle, but using method based on circular holographic reduced representations to compute vectors.all these methods tackle the problem of representing word order in word space, but they do nottake into account syntactic context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3499">
<title id=" W11-2505.xml">encoding syntactic dependencies by vector permutation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>examples of pairs follow: support offer help provide 7 old person right hand 1 where the similarity between offer-support andprovide-help (verb-object) is higher than the one between old-person and right-hand (adjective-noun).as suggested by the authors, the goal of the evaluation is to compare the system perform ace against humans scores by means of spearman correlation.
</prevsent>
<prevsent>5.1 system setup.
</prevsent>
</prevsection>
<citsent citstr=" L08-1028 ">
the system is implemented in java and relies on some portions of code publicly available in the semantic vectors package (widdows and ferraro, 2008).<papid> L08-1028 </papid></citsent>
<aftsection>
<nextsent>for the evaluation of the system, we build two separate word spaces using the following cor pora: ukwac (baroni et al, 2009) and tasa.
</nextsent>
<nextsent>ukwac contains 2 billion words and it is constructed from the web by limiting the crawling to the .uk domain and using medium-frequency words fromthe bnc corpus as seeds.
</nextsent>
<nextsent>we use only portion of ukwac corpus consisting of 7,025,587 sentences (about 220,000 documents).
</nextsent>
<nextsent>the tasa corpus (compiled by touchstone applied science as sociates) was kindly made available to us by prof. thomas landauer from the university of colorado.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3500">
<title id=" W11-2505.xml">encoding syntactic dependencies by vector permutation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>to perform the experiment on compound nouns, we rebuild the spaces encoding the nn?
</prevsent>
<prevsent>relation provided by minipar which refers to compound nouns dependency.
</prevsent>
</prevsection>
<citsent citstr=" P08-1028 ">
table 6 shows the best result obtained by mitchell and lapata (mitchell and lapata, 2008)<papid> P08-1028 </papid>using the same dataset.</citsent>
<aftsection>
<nextsent>our method is able to out perform mlbest and obtains very high results when adjective-noun combination is involved.
</nextsent>
<nextsent>corpus combination ? tasa verb-object 0.260 adjective-noun 0.637 compound nouns 0.341 overall 0.275 ukwac verb-object 0.292 adjective-noun 0.445 compound nouns 0.227 overall 0.261 - mlbest 0.190 table 6: gems 2011 shared evaluation results.the experiments reported in this preliminary evaluation are only small fraction of the experiments that are required to make proper evaluation of the effectiveness of our semantic space and to compare it with other approaches.
</nextsent>
<nextsent>this will be the main focus of our future research.
</nextsent>
<nextsent>the obtained results seem to be encouraging and the strength of our approach, capturing syntactic relations, allows to implement several kind of queries using only one wordspace.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3501">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we evaluate on dataset of political blogs, measuring our systems ability to disco vera set of reference entities (recall) while maintaining compact number of rows and columns (precision).
</prevsent>
<prevsent>with as few as five partially-complete prototype examples, our approach gives accurate tables that match well against manually-annotated reference list.
</prevsent>
</prevsection>
<citsent citstr=" W07-2058 ">
our method outperforms baseline single link clustering approach inspired by one of the most successful entries (elmacioglu et al , 2007) <papid> W07-2058 </papid>in the semeval web people search?</citsent>
<aftsection>
<nextsent>shared task (ar tiles et al , 2007).<papid> W07-2012 </papid></nextsent>
<nextsent>in this work, we assume that bag of mentions in text have been identified.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3502">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with as few as five partially-complete prototype examples, our approach gives accurate tables that match well against manually-annotated reference list.
</prevsent>
<prevsent>our method outperforms baseline single link clustering approach inspired by one of the most successful entries (elmacioglu et al , 2007) <papid> W07-2058 </papid>in the semeval web people search?</prevsent>
</prevsection>
<citsent citstr=" W07-2012 ">
shared task (ar tiles et al , 2007).<papid> W07-2012 </papid></citsent>
<aftsection>
<nextsent>in this work, we assume that bag of mentions in text have been identified.
</nextsent>
<nextsent>the mth mention wm is sequence of contiguous word tokens (its length is denoted nm) understood to refer to real-world entity.
</nextsent>
<nextsent>the entities (and the mapping of mentions to entities) are not known in advance.
</nextsent>
<nextsent>while our focus in this paper is names of people, the task is defined in more generic way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3503">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> evaluation setup.  </section>
<citcontext>
<prevsection>
<prevsent>we also perform qualitative analysis, noting the areas where our method outperforms string matching approaches, and where there is need for further improvement.
</prevsent>
<prevsent>data evaluation was performed on corpus of blogs describing united states politics in2008 (eisenstein and xing, 2010).
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
we ran the stanford named entity recognition system (finkel etal., 2005) <papid> P05-1045 </papid>to obtain set of 25,000 candidate mentions which the system judged to be names of peo ple.</citsent>
<aftsection>
<nextsent>we then pruned strings that appeared fewer than four times and eliminated strings with more than seven tokens (these were usually errors).
</nextsent>
<nextsent>the resulting dataset has 19,247 mentions comprising 45,466 word tokens, and 813 unique mention strings.
</nextsent>
<nextsent>gold standard we develop reference set of 100entities for evaluation.
</nextsent>
<nextsent>this set was created by sorting the unique name strings in the training set by frequency, and manually merging strings that reference the same entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3504">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> evaluation setup.  </section>
<citcontext>
<prevsection>
<prevsent>most entities only include first and last names, though the most frequent entities have many more: for example, the entity barack obama has known names: {barack, obama, sen., mr.}.
</prevsent>
<prevsent>metrics we evaluate the recall and precision of systems response set by matching against the reference set.
</prevsent>
</prevsection>
<citsent citstr=" P11-1080 ">
the first step is to create bipartite matching between response and reference entities.3 using cost function that quantifies the sim 2recent work exploiting wikipedia disambiguation pages for evaluating cross-document coreference suggests an appealing alternative for future work (singh et al , 2011).<papid> P11-1080 </papid></citsent>
<aftsection>
<nextsent>3bipartite matchings are typical in information extraction evaluation metrics (e.g., doddington et al , 2004).
</nextsent>
<nextsent>7ilarity of response and reference entities, we optimize the matching using the kuhn-munkres algorithm (kuhn, 1955).
</nextsent>
<nextsent>for recall, the cost function counts the number of shared word tokens, divided by the number of word tokens in the reference enti ties; the recall is one minus the average cost of thebest matching (with cost of one for reference entities that are not matched, and no cost for unmatched response entities).
</nextsent>
<nextsent>precision is computed identically, but we normalize by the number of word tokens in the response entity.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3506">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>after mistakenly merging bhutto and clinton at an early stage, the gibbs sampler ? which treats each mention independently ? is unable to separate them.
</prevsent>
<prevsent>given that several other mentions of bhutto are already in the row occupied by clinton, the overall likelihood would benefit little from creating new row for single mention, though moving all such mentions simultaneously would result in an improvement.
</prevsent>
</prevsection>
<citsent citstr=" N10-1082 ">
larger scale metropolis hastings moves, such as split-merge or type-based sampling (liang et al , 2010) <papid> N10-1082 </papid>may help.</citsent>
<aftsection>
<nextsent>information extraction tradition of research in information extraction focuses on processing rawtext to fill in the fields of manually-defined templates, thus populating databases of events or relations (mcnamee and dang, 2009).
</nextsent>
<nextsent>while early approaches focused on surface-level methods such as wrapper induction (kushmerick et al , 1997), more recent work in this area includes bayesian nonparametrics to select the number of rows in the database (haghighi and klein, 2010<papid> P10-2054 </papid>a).</nextsent>
<nextsent>however, even in such non parametric work, the form of the template and the number of slots are fixed in ad vance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3507">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>larger scale metropolis hastings moves, such as split-merge or type-based sampling (liang et al , 2010) <papid> N10-1082 </papid>may help.</prevsent>
<prevsent>information extraction tradition of research in information extraction focuses on processing rawtext to fill in the fields of manually-defined templates, thus populating databases of events or relations (mcnamee and dang, 2009).</prevsent>
</prevsection>
<citsent citstr=" P10-2054 ">
while early approaches focused on surface-level methods such as wrapper induction (kushmerick et al , 1997), more recent work in this area includes bayesian nonparametrics to select the number of rows in the database (haghighi and klein, 2010<papid> P10-2054 </papid>a).</citsent>
<aftsection>
<nextsent>however, even in such non parametric work, the form of the template and the number of slots are fixed in advance.
</nextsent>
<nextsent>our approach differs in that the number of fields and their meaning is learned from data.
</nextsent>
<nextsent>recent work by chambers and jurafsky (2011) <papid> P11-1098 </papid>approach esa related problem, applying agglomerative clustering over sentences to detect events, and then clustering syntactic constituents to induce the relevant fields of each event entity.</nextsent>
<nextsent>as described in section 6, our method performs well against an agglomerative clustering baseline, though more comprehensive comparison of the two approaches is an important step for future work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3511">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, even in such non parametric work, the form of the template and the number of slots are fixed in advance.
</prevsent>
<prevsent>our approach differs in that the number of fields and their meaning is learned from data.
</prevsent>
</prevsection>
<citsent citstr=" P11-1098 ">
recent work by chambers and jurafsky (2011) <papid> P11-1098 </papid>approach esa related problem, applying agglomerative clustering over sentences to detect events, and then clustering syntactic constituents to induce the relevant fields of each event entity.</citsent>
<aftsection>
<nextsent>as described in section 6, our method performs well against an agglomerative clustering baseline, though more comprehensive comparison of the two approaches is an important step for future work.
</nextsent>
<nextsent>name segmentation and structure related stream of research focuses specifically on names:identifying them in raw text, discovering their structure, and matching names that refer to the same entity.
</nextsent>
<nextsent>we do not undertake the problem of named entity recognition (tjong kim sang, 2002), but rather apply an existing ner system as preprocessing step (finkel et al , 2005).<papid> P05-1045 </papid></nextsent>
<nextsent>typical ner systems do not attempt to discover the internal structure of names or database of canonical names, although they often use prefabricated gazetteers?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3513">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we do not undertake the problem of named entity recognition (tjong kim sang, 2002), but rather apply an existing ner system as preprocessing step (finkel et al , 2005).<papid> P05-1045 </papid></prevsent>
<prevsent>typical ner systems do not attempt to discover the internal structure of names or database of canonical names, although they often use prefabricated gazetteers?</prevsent>
</prevsection>
<citsent citstr=" W98-1118 ">
of names and name parts as features to improve performance (borthwick et al , 1998; <papid> W98-1118 </papid>sarawagi and cohen, 2005).</citsent>
<aftsection>
<nextsent>charniak (2001) <papid> N01-1007 </papid>shows that it is possible to learn model of name structure, either by using coreference information as labeled data, or by leveraging small set of hand-crafted constraints.</nextsent>
<nextsent>elsner et al  (2009) <papid> N09-1019 </papid>develop non parametric bayesian model of name structure using adaptor grammars, which they use to distinguish types of names (e.g., people, places, andorganizations).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3514">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>typical ner systems do not attempt to discover the internal structure of names or database of canonical names, although they often use prefabricated gazetteers?
</prevsent>
<prevsent>of names and name parts as features to improve performance (borthwick et al , 1998; <papid> W98-1118 </papid>sarawagi and cohen, 2005).</prevsent>
</prevsection>
<citsent citstr=" N01-1007 ">
charniak (2001) <papid> N01-1007 </papid>shows that it is possible to learn model of name structure, either by using coreference information as labeled data, or by leveraging small set of hand-crafted constraints.</citsent>
<aftsection>
<nextsent>elsner et al  (2009) <papid> N09-1019 </papid>develop non parametric bayesian model of name structure using adaptor grammars, which they use to distinguish types of names (e.g., people, places, andorganizations).</nextsent>
<nextsent>li et al  (2004) use set of manually crafted transformations?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3515">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>of names and name parts as features to improve performance (borthwick et al , 1998; <papid> W98-1118 </papid>sarawagi and cohen, 2005).</prevsent>
<prevsent>charniak (2001) <papid> N01-1007 </papid>shows that it is possible to learn model of name structure, either by using coreference information as labeled data, or by leveraging small set of hand-crafted constraints.</prevsent>
</prevsection>
<citsent citstr=" N09-1019 ">
elsner et al  (2009) <papid> N09-1019 </papid>develop non parametric bayesian model of name structure using adaptor grammars, which they use to distinguish types of names (e.g., people, places, andorganizations).</citsent>
<aftsection>
<nextsent>li et al  (2004) use set of manually crafted transformations?
</nextsent>
<nextsent>of name parts to build amodel of how name might be rendered in multiple different ways.
</nextsent>
<nextsent>while each of these approaches bears on one or more facets of the problem that we consider here, none provides holistic treatment of name disambiguation and structure.
</nextsent>
<nextsent>9 resolving mentions to entities the problem of resolving mentions to entities has been approach from variety of different perspectives.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3516">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>many of these prior models have been applied to bibliographic data, where different conventions and abbreviations lead to im perfect matches in different references to the same publication.
</prevsent>
<prevsent>in our task, we consider name mentions in raw text; such mentions are short, and may not offer as many redundant clues for linkage as bibliographic references.in natural language processing, coreference resolution is the task of grouping entity mentions (strings), in one or more documents, based on their common referents in the world.
</prevsent>
</prevsection>
<citsent citstr=" P07-1107 ">
although much of coreference resolution has on the single document setting, there has been some recent work on cross document coreference resolution (li et al , 2004; haghighi and klein, 2007; <papid> P07-1107 </papid>poon and domingos, 2008; <papid> D08-1068 </papid>singh et al , 2011).<papid> P11-1080 </papid></citsent>
<aftsection>
<nextsent>the problem we consider is related to cross-document coreference, although we take on the additional challenge of providinga canonical ized name for each referent (the corresponding table row), and in inferring structured representation of entity names (the table columns).for this reason, our evaluation focuses on the induced table of entities, rather than the clustering of mention strings.
</nextsent>
<nextsent>the best coreference systems depend on carefully crafted, problem-specific linguistic features (bengtson and roth, 2008) <papid> D08-1031 </papid>and external knowledge (haghighi and klein, 2010<papid> P10-2054 </papid>b).</nextsent>
<nextsent>future work might consider how to exploit such features for the more holistic information extraction setting.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3517">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>many of these prior models have been applied to bibliographic data, where different conventions and abbreviations lead to im perfect matches in different references to the same publication.
</prevsent>
<prevsent>in our task, we consider name mentions in raw text; such mentions are short, and may not offer as many redundant clues for linkage as bibliographic references.in natural language processing, coreference resolution is the task of grouping entity mentions (strings), in one or more documents, based on their common referents in the world.
</prevsent>
</prevsection>
<citsent citstr=" D08-1068 ">
although much of coreference resolution has on the single document setting, there has been some recent work on cross document coreference resolution (li et al , 2004; haghighi and klein, 2007; <papid> P07-1107 </papid>poon and domingos, 2008; <papid> D08-1068 </papid>singh et al , 2011).<papid> P11-1080 </papid></citsent>
<aftsection>
<nextsent>the problem we consider is related to cross-document coreference, although we take on the additional challenge of providinga canonical ized name for each referent (the corresponding table row), and in inferring structured representation of entity names (the table columns).for this reason, our evaluation focuses on the induced table of entities, rather than the clustering of mention strings.
</nextsent>
<nextsent>the best coreference systems depend on carefully crafted, problem-specific linguistic features (bengtson and roth, 2008) <papid> D08-1031 </papid>and external knowledge (haghighi and klein, 2010<papid> P10-2054 </papid>b).</nextsent>
<nextsent>future work might consider how to exploit such features for the more holistic information extraction setting.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3520">
<title id=" W11-2202.xml">structured databases of named entities from bayesian nonparametrics </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>although much of coreference resolution has on the single document setting, there has been some recent work on cross document coreference resolution (li et al , 2004; haghighi and klein, 2007; <papid> P07-1107 </papid>poon and domingos, 2008; <papid> D08-1068 </papid>singh et al , 2011).<papid> P11-1080 </papid></prevsent>
<prevsent>the problem we consider is related to cross-document coreference, although we take on the additional challenge of providinga canonical ized name for each referent (the corresponding table row), and in inferring structured representation of entity names (the table columns).for this reason, our evaluation focuses on the induced table of entities, rather than the clustering of mention strings.</prevsent>
</prevsection>
<citsent citstr=" D08-1031 ">
the best coreference systems depend on carefully crafted, problem-specific linguistic features (bengtson and roth, 2008) <papid> D08-1031 </papid>and external knowledge (haghighi and klein, 2010<papid> P10-2054 </papid>b).</citsent>
<aftsection>
<nextsent>future work might consider how to exploit such features for the more holistic information extraction setting.
</nextsent>
<nextsent>this paper presents bayesian non parametric approach to recover structured records from text.
</nextsent>
<nextsent>using only small set of prototype records, we are ableto recover an accurate table that jointly identifies entities and internal name structure.
</nextsent>
<nextsent>in our view, the main advantage of bayesian approach compared to more heuristic alternatives is that it facilitates incorporation of additional information sources when available.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3525">
<title id=" W12-1614.xml">improving implicit discourse relation recognition through feature set optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the ability to recognize the discourse relations that exist between arbitrary text spans is crucial for understanding given text.
</prevsent>
<prevsent>indeed, number of natural language processing (nlp) applications relyon it ? e.g., question answering, text summarization, and textual entailment.
</prevsent>
</prevsection>
<citsent citstr=" C08-2022 ">
fortunately, explicit discourse relations ? discourse relations marked by explicit connectives ? have been shown to be easily identified by automatic means (pitler et al, 2008): <papid> C08-2022 </papid>each such connective is generally strongly coupled with particular relation.</citsent>
<aftsection>
<nextsent>the connective because?, for example, serves as prominent cue for the contingency relation.
</nextsent>
<nextsent>the identification of implicit discourse relations ? where such connectives are absent ? is muchharder.
</nextsent>
<nextsent>it has been the subject of much recent research since the release of the penn discourse treebank 2.0 (pdtb) (prasad et al, 2008), <papid> L08-1093 </papid>which annotates relations between adjacent text spans in wall street journal (wsj) articles, while clearly distinguishing implicit from explicit discourse relations.1 recent studies, for example, explored the utility of various classes of features for the task, including linguistically informed features, context, constituent and dependency parse features, and features that encode entity information or relyon language models (pitler et al, 2009; <papid> P09-1077 </papid>lin et al, 2009; <papid> D09-1036 </papid>louis et al, 2010; <papid> W10-4310 </papid>zhou et al, 2010).<papid> C10-2172 </papid></nextsent>
<nextsent>to date, however, there has not been systematic study of combinations of these features for implicit discourse relation identification.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3526">
<title id=" W12-1614.xml">improving implicit discourse relation recognition through feature set optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the connective because?, for example, serves as prominent cue for the contingency relation.
</prevsent>
<prevsent>the identification of implicit discourse relations ? where such connectives are absent ? is muchharder.
</prevsent>
</prevsection>
<citsent citstr=" L08-1093 ">
it has been the subject of much recent research since the release of the penn discourse treebank 2.0 (pdtb) (prasad et al, 2008), <papid> L08-1093 </papid>which annotates relations between adjacent text spans in wall street journal (wsj) articles, while clearly distinguishing implicit from explicit discourse relations.1 recent studies, for example, explored the utility of various classes of features for the task, including linguistically informed features, context, constituent and dependency parse features, and features that encode entity information or relyon language models (pitler et al, 2009; <papid> P09-1077 </papid>lin et al, 2009; <papid> D09-1036 </papid>louis et al, 2010; <papid> W10-4310 </papid>zhou et al, 2010).<papid> C10-2172 </papid></citsent>
<aftsection>
<nextsent>to date, however, there has not been systematic study of combinations of these features for implicit discourse relation identification.
</nextsent>
<nextsent>in addition, there sults of existing studies are often difficult to compare because of differences in dataset creation, feature set choice, or experimental methodology.this paper provides systematic study of previously proposed features for implicit discourse relation identification and identifies feature combinations that optimize f1-score using forward selection (john et al, 1994).
</nextsent>
<nextsent>we report the performance of our binary (one vs. rest) classifiers on the pdtb dataset for its four top-level discourse relation classes: comparison, contingency, expansion, and temporal.
</nextsent>
<nextsent>in each case, the resulting classifiers achieve the best f1-scores for the pdtb to date.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3528">
<title id=" W12-1614.xml">improving implicit discourse relation recognition through feature set optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the connective because?, for example, serves as prominent cue for the contingency relation.
</prevsent>
<prevsent>the identification of implicit discourse relations ? where such connectives are absent ? is muchharder.
</prevsent>
</prevsection>
<citsent citstr=" P09-1077 ">
it has been the subject of much recent research since the release of the penn discourse treebank 2.0 (pdtb) (prasad et al, 2008), <papid> L08-1093 </papid>which annotates relations between adjacent text spans in wall street journal (wsj) articles, while clearly distinguishing implicit from explicit discourse relations.1 recent studies, for example, explored the utility of various classes of features for the task, including linguistically informed features, context, constituent and dependency parse features, and features that encode entity information or relyon language models (pitler et al, 2009; <papid> P09-1077 </papid>lin et al, 2009; <papid> D09-1036 </papid>louis et al, 2010; <papid> W10-4310 </papid>zhou et al, 2010).<papid> C10-2172 </papid></citsent>
<aftsection>
<nextsent>to date, however, there has not been systematic study of combinations of these features for implicit discourse relation identification.
</nextsent>
<nextsent>in addition, there sults of existing studies are often difficult to compare because of differences in dataset creation, feature set choice, or experimental methodology.this paper provides systematic study of previously proposed features for implicit discourse relation identification and identifies feature combinations that optimize f1-score using forward selection (john et al, 1994).
</nextsent>
<nextsent>we report the performance of our binary (one vs. rest) classifiers on the pdtb dataset for its four top-level discourse relation classes: comparison, contingency, expansion, and temporal.
</nextsent>
<nextsent>in each case, the resulting classifiers achieve the best f1-scores for the pdtb to date.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3529">
<title id=" W12-1614.xml">improving implicit discourse relation recognition through feature set optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the connective because?, for example, serves as prominent cue for the contingency relation.
</prevsent>
<prevsent>the identification of implicit discourse relations ? where such connectives are absent ? is muchharder.
</prevsent>
</prevsection>
<citsent citstr=" D09-1036 ">
it has been the subject of much recent research since the release of the penn discourse treebank 2.0 (pdtb) (prasad et al, 2008), <papid> L08-1093 </papid>which annotates relations between adjacent text spans in wall street journal (wsj) articles, while clearly distinguishing implicit from explicit discourse relations.1 recent studies, for example, explored the utility of various classes of features for the task, including linguistically informed features, context, constituent and dependency parse features, and features that encode entity information or relyon language models (pitler et al, 2009; <papid> P09-1077 </papid>lin et al, 2009; <papid> D09-1036 </papid>louis et al, 2010; <papid> W10-4310 </papid>zhou et al, 2010).<papid> C10-2172 </papid></citsent>
<aftsection>
<nextsent>to date, however, there has not been systematic study of combinations of these features for implicit discourse relation identification.
</nextsent>
<nextsent>in addition, there sults of existing studies are often difficult to compare because of differences in dataset creation, feature set choice, or experimental methodology.this paper provides systematic study of previously proposed features for implicit discourse relation identification and identifies feature combinations that optimize f1-score using forward selection (john et al, 1994).
</nextsent>
<nextsent>we report the performance of our binary (one vs. rest) classifiers on the pdtb dataset for its four top-level discourse relation classes: comparison, contingency, expansion, and temporal.
</nextsent>
<nextsent>in each case, the resulting classifiers achieve the best f1-scores for the pdtb to date.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3530">
<title id=" W12-1614.xml">improving implicit discourse relation recognition through feature set optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the connective because?, for example, serves as prominent cue for the contingency relation.
</prevsent>
<prevsent>the identification of implicit discourse relations ? where such connectives are absent ? is muchharder.
</prevsent>
</prevsection>
<citsent citstr=" W10-4310 ">
it has been the subject of much recent research since the release of the penn discourse treebank 2.0 (pdtb) (prasad et al, 2008), <papid> L08-1093 </papid>which annotates relations between adjacent text spans in wall street journal (wsj) articles, while clearly distinguishing implicit from explicit discourse relations.1 recent studies, for example, explored the utility of various classes of features for the task, including linguistically informed features, context, constituent and dependency parse features, and features that encode entity information or relyon language models (pitler et al, 2009; <papid> P09-1077 </papid>lin et al, 2009; <papid> D09-1036 </papid>louis et al, 2010; <papid> W10-4310 </papid>zhou et al, 2010).<papid> C10-2172 </papid></citsent>
<aftsection>
<nextsent>to date, however, there has not been systematic study of combinations of these features for implicit discourse relation identification.
</nextsent>
<nextsent>in addition, there sults of existing studies are often difficult to compare because of differences in dataset creation, feature set choice, or experimental methodology.this paper provides systematic study of previously proposed features for implicit discourse relation identification and identifies feature combinations that optimize f1-score using forward selection (john et al, 1994).
</nextsent>
<nextsent>we report the performance of our binary (one vs. rest) classifiers on the pdtb dataset for its four top-level discourse relation classes: comparison, contingency, expansion, and temporal.
</nextsent>
<nextsent>in each case, the resulting classifiers achieve the best f1-scores for the pdtb to date.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3531">
<title id=" W12-1614.xml">improving implicit discourse relation recognition through feature set optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the connective because?, for example, serves as prominent cue for the contingency relation.
</prevsent>
<prevsent>the identification of implicit discourse relations ? where such connectives are absent ? is muchharder.
</prevsent>
</prevsection>
<citsent citstr=" C10-2172 ">
it has been the subject of much recent research since the release of the penn discourse treebank 2.0 (pdtb) (prasad et al, 2008), <papid> L08-1093 </papid>which annotates relations between adjacent text spans in wall street journal (wsj) articles, while clearly distinguishing implicit from explicit discourse relations.1 recent studies, for example, explored the utility of various classes of features for the task, including linguistically informed features, context, constituent and dependency parse features, and features that encode entity information or relyon language models (pitler et al, 2009; <papid> P09-1077 </papid>lin et al, 2009; <papid> D09-1036 </papid>louis et al, 2010; <papid> W10-4310 </papid>zhou et al, 2010).<papid> C10-2172 </papid></citsent>
<aftsection>
<nextsent>to date, however, there has not been systematic study of combinations of these features for implicit discourse relation identification.
</nextsent>
<nextsent>in addition, there sults of existing studies are often difficult to compare because of differences in dataset creation, feature set choice, or experimental methodology.this paper provides systematic study of previously proposed features for implicit discourse relation identification and identifies feature combinations that optimize f1-score using forward selection (john et al, 1994).
</nextsent>
<nextsent>we report the performance of our binary (one vs. rest) classifiers on the pdtb dataset for its four top-level discourse relation classes: comparison, contingency, expansion, and temporal.
</nextsent>
<nextsent>in each case, the resulting classifiers achieve the best f1-scores for the pdtb to date.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3532">
<title id=" W12-1614.xml">improving implicit discourse relation recognition through feature set optimization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we report the performance of our binary (one vs. rest) classifiers on the pdtb dataset for its four top-level discourse relation classes: comparison, contingency, expansion, and temporal.
</prevsent>
<prevsent>in each case, the resulting classifiers achieve the best f1-scores for the pdtb to date.
</prevsent>
</prevsection>
<citsent citstr=" P02-1047 ">
we 1research on implicit discourse relation recognition prior tothe release of the pdtb instead relied on synthetic data created by removing explicit connectives from explicit discourse relation instances (marcu and echihabi, 2002), <papid> P02-1047 </papid>but the trained classifiers do not perform as well on real-world data (blair golden sohn et al, 2007).</citsent>
<aftsection>
<nextsent>108 further identify factors for feature extraction that canhave major impact performance, including stemming and lexicon look-up.
</nextsent>
<nextsent>finally, by documenting an easily replicable experimental methodology and making public the code for feature extraction2, we hope to provide new set of baselines for future studies of implicit discourse relation identification.
</nextsent>
<nextsent>the experiments are conducted on the pdtb(prasad et al, 2008), <papid> L08-1093 </papid>which provides discourse relation annotations between adjacent text spans in wsj articles.</nextsent>
<nextsent>each training and test instance represents one such pair of text spans and is classified in the pdtb w.r.t. its relation type and relation sense.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3536">
<title id=" W12-1614.xml">improving implicit discourse relation recognition through feature set optimization </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>the relation sense determines the relation that exists between its text span arguments as one of: comparison, contingency, expansion, and temporal.
</prevsent>
<prevsent>for example, the following shows an explicit contingency relation between argument1 (arg1) and argument2 (arg2), denoted via the connective because?: the federal government suspended sales of u.s. savings bonds because congress hasnt listed the ceiling on government debt.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
the four relation senses comprise the target classes for our classifiers.a notable feature of the pdtb is that the annotation is done on the same corpus as penn tree bank (marcus et al, 1993), <papid> J93-2004 </papid>which provides parse trees and part-of-speech (pos) tags.</citsent>
<aftsection>
<nextsent>this enables the use of gold standard parse information for some features, e.g., the production rules feature, one of the most effective features proposed to date.
</nextsent>
<nextsent>below are brief descriptions of features whose efficacy have been empirically determined in prior works3, along with the rationales behind them: 2these are available from http://www.joonsuk.org.
</nextsent>
<nextsent>3word pairs (marcu and echihabi, 2002).<papid> P02-1047 </papid></nextsent>
<nextsent>first-last-first3 (wellner et al, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3540">
<title id=" W12-1614.xml">improving implicit discourse relation recognition through feature set optimization </title>
<section> features.  </section>
<citcontext>
<prevsection>
<prevsent>word pairs (cross product of unigrams: arg1 arg2) ? few of these word pairs may capture information revealing the discourse relation of the target spans.
</prevsent>
<prevsent>for instance, rain-wet can hint at contingency.
</prevsent>
</prevsection>
<citsent citstr=" H05-1044 ">
first-last-first3 (the first, last, and first three words of each argument) ? the words in this range may be expressions that function as connectives for certain relations.polarity (the count of words in arg1 and arg2, respectively, that hold negated vs. non-negated positive, negative, and neutral sentiment) according to the mpqa corpus (wilson et al, 2005)) ? <papid> H05-1044 </papid>the change in sentiment from arg1 to arg2 could be good indication of comparison.inquirer tags (negated and non-negated fine grained semantic classification tags for the verbs in each argument and their cross product) ? the tags are drawn from the general inquirer lexicon (stone et al, 1966)4, which provides word level relations that might be propagated to the target spans?</citsent>
<aftsection>
<nextsent>discourse relation, e.g., rise:fall.
</nextsent>
<nextsent>verbs (count of pairs of verbs from arg1 and arg2 belonging to the same levin english verb class (levin and somers, 1993)5, the average lengths of verb phrases as well as their cross product, and the pos of the main verb from each argument) ? levin verb classes provide means of clustering verbs according to their meanings and behaviors.
</nextsent>
<nextsent>also,longer verb phrases might correlate with contingency, indicating justification.
</nextsent>
<nextsent>modality (three features denoting the presence of modal verbs in arg1, arg2, or both) ? modal verbs often appear in contingency relations.context (the connective and the sense of the immediately preceding and following relations (if explicit), and feature denoting if arg1 starts para graph) ? certain relations co-occur.production rules (three features denoting the presence of syntactic productions in arg1, arg2 or both,based on all pairs of parent-children nodes in the argument parse trees) ? the syntactic structure of an argument can influence that of the other argument as 4http://www.wjh.harvard.edu/ inquirer/inqdict.txt 5http://www-personal.umich.edu/ jlawler/levin.html 109 well as its relation type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3544">
<title id=" W12-1614.xml">improving implicit discourse relation recognition through feature set optimization </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>once the 6some prior work uses different experimental setting.
</prevsent>
<prevsent>for instance, zhou et al (2010) <papid> C10-2172 </papid>only considers two of the non explicit relations, namely implicit and norel.</prevsent>
</prevsection>
<citsent citstr=" P06-4018 ">
7we use classifiers from the nltk package (bird, 2006).<papid> P06-4018 </papid></citsent>
<aftsection>
<nextsent>8stanford parser (klein and manning, 2003).<papid> P03-1054 </papid>optimal feature set for each relation sense is determined by testing on the validation set, we retrain each classifier using the entire training set andre port final performance on the test set.</nextsent>
<nextsent>table 5 indicates the performance achieved by employing the feature set found to be optimal for each relation sense via forward selection, along with the performance of the individual features that constitute the ideal subset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3545">
<title id=" W12-1614.xml">improving implicit discourse relation recognition through feature set optimization </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>for instance, zhou et al (2010) <papid> C10-2172 </papid>only considers two of the non explicit relations, namely implicit and norel.</prevsent>
<prevsent>7we use classifiers from the nltk package (bird, 2006).<papid> P06-4018 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
8stanford parser (klein and manning, 2003).<papid> P03-1054 </papid>optimal feature set for each relation sense is determined by testing on the validation set, we retrain each classifier using the entire training set andre port final performance on the test set.</citsent>
<aftsection>
<nextsent>table 5 indicates the performance achieved by employing the feature set found to be optimal for each relation sense via forward selection, along with the performance of the individual features that constitute the ideal subset.
</nextsent>
<nextsent>the two bottom rows show the results reported in two previous papers with the most similar experiment methodology as ours.
</nextsent>
<nextsent>the notable efficacy of the production rules feature, yielding the best or the second best result across all relation senses w.r.t. both f1-score and accuracy, confirms the finding of zhou et al (2010).<papid> C10-2172 </papid></nextsent>
<nextsent>in contrast to their work, however, combining existing features enhances the performance.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3551">
<title id=" W11-1918.xml">ubiu a robust system for resolving unrestricted coreference </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for this reason, many systems use superficial information suchas string match.
</prevsent>
<prevsent>the conll shared task on modeling unrestricted coreference in ontonotes?
</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
(pradhan et al , 2011) <papid> W11-1901 </papid>presents challenges that go beyond previous definitions of the task.</citsent>
<aftsection>
<nextsent>on the one hand, mention extraction is part of the task while many previous approaches assumed gold standard mentions.
</nextsent>
<nextsent>on the other hand, coreference is not restricted to noun phrases, verbs are also included.
</nextsent>
<nextsent>thus, in sales of passenger cars grew 22%.
</nextsent>
<nextsent>the strong growth followed year-to-year increases., the verb grew has an identity relation with the noun phrase the strong growth.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3553">
<title id=" W11-1918.xml">ubiu a robust system for resolving unrestricted coreference </title>
<section> final results.  </section>
<citcontext>
<prevsection>
<prevsent>a comparison of the results for the experiments with the base set as opposed to the extended set in5 shows that the extended feature set using wordnet information is detrimental to the final results averaged over all metrics while it led to slight improvement on the mention level.
</prevsent>
<prevsent>our assumption is that while in general, the onto logical information is useful, the additional information may be mixture of relevant and irrelevant information.
</prevsent>
</prevsection>
<citsent citstr=" C02-1039 ">
mihalcea (2002) <papid> C02-1039 </papid>showed for word sense disambiguation that 115 im muc b3 ceafe average p f1 p f1 p f1 p f1 f1 automatic mention identification auto ubiub 67.27 37.48 48.14 28.75 20.61 24.01 67.17 56.81 61.55 31.67 41.22 35.82 40.46 ubiue 67.49 37.60 48.29 28.87 20.66 24.08 67.14 56.67 61.46 31.57 41.21 35.75 40.43 gold ubiub 65.92 40.56 50.22 31.05 25.57 28.04 64.94 62.23 63.56 33.53 39.08 36.09 42.56 ubiue 66.11 40.37 50.13 30.84 25.14 27.70 65.07 61.83 63.41 33.23 39.05 35.91 42.34 gold mention boundaries auto ubiub 67.57 58.66 62.80 34.14 40.43 37.02 54.24 71.09 61.53 39.65 33.73 36.45 45.00 ubiue 69.19 57.27 62.67 33.48 37.15 35.22 55.47 68.23 61.20 38.29 34.65 36.38 44.27 gold ubiub 67.64 58.75 62.88 34.37 40.68 37.26 54.28 71.18 61.59 39.69 33.76 36.49 45.11 ubiue 67.72 58.66 62.87 34.18 40.40 37.03 54.30 71.04 61.55 39.64 33.78 36.47 45.02 table 5: final system results for the coreference resolution module on automatically extracted mentions on the gold standard mentions for the base and extended feature sets.memory-based learning is extremely sensitive to irrelevant features.</citsent>
<aftsection>
<nextsent>for the future, we are planning to investigate this problem by applying forward backward feature selection, as proposed by mihalcea (2002) <papid> C02-1039 </papid>and dinu and kubler (2007).</nextsent>
<nextsent>4.2 gold mention boundaries.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3555">
<title id=" W12-0701.xml">fast unsupervised dependency parsing with arc standard transitions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised learning of grammars has achieved considerable focus in recent years.
</prevsent>
<prevsent>the lack of sufficient manually tagged linguistic data andthe considerable successes of unsupervised approaches on some languages have motivated researchers to test different models of unsupervised learning on different linguistic representations.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
since the introduction of the dependency model with valence (dmv) proposed by klein and manning (2004), <papid> P04-1061 </papid>dependency grammar induction has received great attention by researchers.</citsent>
<aftsection>
<nextsent>dmvwas the first model to outperform the right attachment accuracy in english.
</nextsent>
<nextsent>since this achievement, the model has been used by many researchers (e.g.
</nextsent>
<nextsent>(cohen and smith, 2010); (gillenwater et al, 2011); (headden iii et al, 2009); and (spitkovsky et al, 2011<papid> W11-0303 </papid>b)).</nextsent>
<nextsent>the main task of unsupervised dependency parsing is to obtain the most likely dependency tree of sentence without using any annotated training data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3556">
<title id=" W12-0701.xml">fast unsupervised dependency parsing with arc standard transitions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>dmvwas the first model to outperform the right attachment accuracy in english.
</prevsent>
<prevsent>since this achievement, the model has been used by many researchers (e.g.
</prevsent>
</prevsection>
<citsent citstr=" W11-0303 ">
(cohen and smith, 2010); (gillenwater et al, 2011); (headden iii et al, 2009); and (spitkovsky et al, 2011<papid> W11-0303 </papid>b)).</citsent>
<aftsection>
<nextsent>the main task of unsupervised dependency parsing is to obtain the most likely dependency tree of sentence without using any annotated training data.
</nextsent>
<nextsent>in dependency trees, each word hasonly one head and the head of the sentence is dependent of an artificial root word.
</nextsent>
<nextsent>problems suchas data sparsity and large search space that increases the ambiguity have made the task difficult.
</nextsent>
<nextsent>even deciding the direction of the link between two words in dependency relation has made the task more difficult than finding phrase structures themselves (klein and manning, 2004).<papid> P04-1061 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3569">
<title id=" W12-0701.xml">fast unsupervised dependency parsing with arc standard transitions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>problems suchas data sparsity and large search space that increases the ambiguity have made the task difficult.
</prevsent>
<prevsent>even deciding the direction of the link between two words in dependency relation has made the task more difficult than finding phrase structures themselves (klein and manning, 2004).<papid> P04-1061 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-0308 ">
in this paper, we propose model based on arc-standard transition system of nivre (2004),<papid> W04-0308 </papid>which is known as an incremental greedy projective parsing model that parses sentences in linear time.</citsent>
<aftsection>
<nextsent>to the best of our knowledge, the only incremental unsupervised dependency parsing is the model of daume?
</nextsent>
<nextsent>iii (2009) with shift-reduce parsing model (nivre, 2003).1our model is not lexicalized, has simple feature space and converges in 15 iterations with linear (o(n)) parsing and training time, while other methods based on dmv in the best casework ino(n3) time complexity witho(n3) memory use for sentences with of length n. we believe that the output of this model can also im prove dmv.2 in addition, we use punctuation clues (spitkovsky et al, 2011<papid> W11-0303 </papid>c), tying feature similarity in the transition system configuration, and1the other study is in seginer (2007) <papid> P07-1049 </papid>that is for constituency parsing (phrase structure extraction).2for the effect of model initialization in unsupervised dependency parsing, see gimpel and smith (2011).</nextsent>
<nextsent>1 baby steps?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3582">
<title id=" W12-0701.xml">fast unsupervised dependency parsing with arc standard transitions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in this paper, we propose model based on arc-standard transition system of nivre (2004),<papid> W04-0308 </papid>which is known as an incremental greedy projective parsing model that parses sentences in linear time.</prevsent>
<prevsent>to the best of our knowledge, the only incremental unsupervised dependency parsing is the model of daume?</prevsent>
</prevsection>
<citsent citstr=" P07-1049 ">
iii (2009) with shift-reduce parsing model (nivre, 2003).1our model is not lexicalized, has simple feature space and converges in 15 iterations with linear (o(n)) parsing and training time, while other methods based on dmv in the best casework ino(n3) time complexity witho(n3) memory use for sentences with of length n. we believe that the output of this model can also im prove dmv.2 in addition, we use punctuation clues (spitkovsky et al, 2011<papid> W11-0303 </papid>c), tying feature similarity in the transition system configuration, and1the other study is in seginer (2007) <papid> P07-1049 </papid>that is for constituency parsing (phrase structure extraction).2for the effect of model initialization in unsupervised dependency parsing, see gimpel and smith (2011).</citsent>
<aftsection>
<nextsent>1 baby steps?
</nextsent>
<nextsent>notion (spitkovsky et al, 2009) to improve the model accuracy.
</nextsent>
<nextsent>we test our model on 9 conll 2006 and 2007 shared task datasets (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007) <papid> D07-1096 </papid>and wsj part of penn treebank and show that in some languages our model is better than the recent models.</nextsent>
<nextsent>we also test our model on part of an ongoing first persian dependency corpus (rasooli et al, 2011).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3583">
<title id=" W12-0701.xml">fast unsupervised dependency parsing with arc standard transitions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 baby steps?
</prevsent>
<prevsent>notion (spitkovsky et al, 2009) to improve the model accuracy.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
we test our model on 9 conll 2006 and 2007 shared task datasets (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007) <papid> D07-1096 </papid>and wsj part of penn treebank and show that in some languages our model is better than the recent models.</citsent>
<aftsection>
<nextsent>we also test our model on part of an ongoing first persian dependency corpus (rasooli et al, 2011).
</nextsent>
<nextsent>our study may be the first work to test dependency parsing on the persian language.the remainder of this paper is organized as follows.
</nextsent>
<nextsent>in section 2, related work on unsupervised dependency parsing is reviewed.
</nextsent>
<nextsent>in section 3, we describe our dependency parsing model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3585">
<title id=" W12-0701.xml">fast unsupervised dependency parsing with arc standard transitions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1 baby steps?
</prevsent>
<prevsent>notion (spitkovsky et al, 2009) to improve the model accuracy.
</prevsent>
</prevsection>
<citsent citstr=" D07-1096 ">
we test our model on 9 conll 2006 and 2007 shared task datasets (buchholz and marsi, 2006; <papid> W06-2920 </papid>nivre et al, 2007) <papid> D07-1096 </papid>and wsj part of penn treebank and show that in some languages our model is better than the recent models.</citsent>
<aftsection>
<nextsent>we also test our model on part of an ongoing first persian dependency corpus (rasooli et al, 2011).
</nextsent>
<nextsent>our study may be the first work to test dependency parsing on the persian language.the remainder of this paper is organized as follows.
</nextsent>
<nextsent>in section 2, related work on unsupervised dependency parsing is reviewed.
</nextsent>
<nextsent>in section 3, we describe our dependency parsing model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3608">
<title id=" W12-0701.xml">fast unsupervised dependency parsing with arc standard transitions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in spitkovsky et al (2011<papid> W11-0303 </papid>b), mixture of ems is used to improve the dmv by trying to escape from local maxima; i.e., changing the em policy in some iterations in order to escape from local maxima.</prevsent>
<prevsent>the model is termed lateenem.</prevsent>
</prevsection>
<citsent citstr=" P10-1130 ">
in spitkovsky et al (2010<papid> P10-1130 </papid>b), html hypertext tags are used as indicators of phrases in order to localize the search space of the dependency model.</citsent>
<aftsection>
<nextsent>in spitkovsky et al (2011<papid> W11-0303 </papid>c), punctuation marks are used as indicators of local dependencies of the words in the sentence.in cohen and smith (2010), shared logistic normal distribution is used to tie grammatical roles that are not assumed to be independent from each other.</nextsent>
<nextsent>in the study, the bilingual similarity of each pos tag probability in the dependency model is applied to the probability model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3631">
<title id=" W12-0701.xml">fast unsupervised dependency parsing with arc standard transitions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in spitkovsky et al (2011<papid> W11-0303 </papid>c), punctuation marks are used as indicators of local dependencies of the words in the sentence.in cohen and smith (2010), shared logistic normal distribution is used to tie grammatical roles that are not assumed to be independent from each other.</prevsent>
<prevsent>in the study, the bilingual similarity of each pos tag probability in the dependency model is applied to the probability model.</prevsent>
</prevsection>
<citsent citstr=" D10-1117 ">
in blunsom andcohn (2010), <papid> D10-1117 </papid>pitman-yor priors (pyp) are applied to the dmv.</citsent>
<aftsection>
<nextsent>furthermore, tree substitution grammar (tsg) is used as an intermediate representation of the tree.
</nextsent>
<nextsent>in gillenwater et al (2011), mathematical model is employed to overcome the posterior sparsity in the dmv, by defining constraints on the probability model.
</nextsent>
<nextsent>there are also some models different fromdmv.
</nextsent>
<nextsent>in daume?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3633">
<title id=" W12-0701.xml">fast unsupervised dependency parsing with arc standard transitions </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(2011), by applying gibbs sampling method to count the data occurrences, simple probability model (the fraction of each dependency relation divided by the number of head postags) is used.
</prevsent>
<prevsent>in that model, non-projective dependency trees are allowed and all noun-root dependency probabilities are multiplied by small number, to decrease the chance of choosing noun root dependency.
</prevsent>
</prevsection>
<citsent citstr=" D11-1005 ">
there are also some studies in which labeled data in one language is employed to guide unsupervised parsing in the others (co hen et al, 2011).<papid> D11-1005 </papid></citsent>
<aftsection>
<nextsent>in this section, after brief description of the arc standard parsing model, our probability model,and the unsupervised search-based structure prediction (daume?
</nextsent>
<nextsent>iii, 2009) are reviewed.
</nextsent>
<nextsent>after these descriptions, we go through baby steps,?
</nextsent>
<nextsent>the use of curricula in unsupervised learning (tu and honavar, 2011), and the use of punctuation in unsupervised parsing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3771">
<title id=" W12-0701.xml">fast unsupervised dependency parsing with arc standard transitions </title>
<section> analysis and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>in some languages like slovenian, we see that even with good undirected accuracy, the model does not succeed in finding the dependency direction with heuristics.
</prevsent>
<prevsent>while in czech, dutch, and bulgarian the second heuristic works well,it does not change accuracy lot in other languages (in languages like turkish and english this heuristic decreases accuracy).
</prevsent>
</prevsection>
<citsent citstr=" D10-1120 ">
we believe that choosing better linguistic knowledge like the ones in naseem et al (2010), <papid> D10-1120 </papid>tying grammatical rules from other languages similar to the work in cohen and smith (2010), and choosing better probability models that can be enriched with lexical features and broad context consideration (like the works in supervised incremental dependency parsing) will help the model perform better on different lan guages.</citsent>
<aftsection>
<nextsent>despite the fact that our study is the first work done on persian, we believe that the results thatwe achieve for persian is very considerable, regarding the free-word order nature of the persian language.
</nextsent>
<nextsent>7 acknowledgments the paper is funded by computer research center of islamic sciences (crcis).
</nextsent>
<nextsent>we would liketo appreciate valentin spitkovsky and shay cohen for their technical comments on there search and paper draft.
</nextsent>
<nextsent>we would also thank maryam faal-hamedanchi, manouchehr kouhes tani, amirsaeid moloodi, hamidreza ghader, maryam aminian and anonymous reviewers for their comments on the draft version.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3772">
<title id=" W12-1617.xml">estimating adaptation of dialogue partners with different verbal intelligence </title>
<section> measuring adaptation.  </section>
<citcontext>
<prevsection>
<prevsent>according to this modification, prime words of the first dialogue partner were determined.
</prevsent>
<prevsent>for measuring lexical convergence, the use of prime words by the second dialogue partner for each turn was calculated.
</prevsent>
</prevsection>
<citsent citstr=" P08-2043 ">
in(nenkova et al, 2008) <papid> P08-2043 </papid>the measurements of adaptation between dialogue partners were based on the us age of high-frequency words.</citsent>
<aftsection>
<nextsent>stoyanchev and stent (2009) <papid> N09-2048 </papid>analysed adaptation calculating the number of reused verbs and prepositions by speaker that occurred in his dialogue partners turns.in this work we measure adaptation as cross referencing, proportion of i?, you?</nextsent>
<nextsent>and we?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3773">
<title id=" W12-1617.xml">estimating adaptation of dialogue partners with different verbal intelligence </title>
<section> measuring adaptation.  </section>
<citcontext>
<prevsection>
<prevsent>for measuring lexical convergence, the use of prime words by the second dialogue partner for each turn was calculated.
</prevsent>
<prevsent>in(nenkova et al, 2008) <papid> P08-2043 </papid>the measurements of adaptation between dialogue partners were based on the us age of high-frequency words.</prevsent>
</prevsection>
<citsent citstr=" N09-2048 ">
stoyanchev and stent (2009) <papid> N09-2048 </papid>analysed adaptation calculating the number of reused verbs and prepositions by speaker that occurred in his dialogue partners turns.in this work we measure adaptation as cross referencing, proportion of i?, you?</citsent>
<aftsection>
<nextsent>and we?
</nextsent>
<nextsent>words, between-subject correlation and similarity between two texts.
</nextsent>
<nextsent>these approaches are described in the following sections.
</nextsent>
<nextsent>3.1 cross referencing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3774">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this facilitates generic and extensible implementation of alignment-based extraction methods.
</prevsent>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
</prevsection>
<citsent citstr=" W99-0604 ">
a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</citsent>
<aftsection>
<nextsent>from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></nextsent>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3775">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this facilitates generic and extensible implementation of alignment-based extraction methods.
</prevsent>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
</prevsection>
<citsent citstr=" P05-1033 ">
a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</citsent>
<aftsection>
<nextsent>from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></nextsent>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3776">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3777">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3778">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" N07-1063 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3779">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" D07-1104 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3780">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" P08-1114 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3781">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3782">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" J10-3008 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3783">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3784">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" W06-1606 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3785">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" P06-1077 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3786">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" W06-3601 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3787">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" P07-1089 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3788">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" D08-1022 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3789">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" P08-1064 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3790">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the tradition of extracting translation rules from aligned sentence pairs dates back more than decade.
</prevsent>
<prevsent>a prominent early example is phrase-based extraction (och et al, 1999).<papid> W99-0604 </papid>around the middle of the last decade, two extraction paradigms were proposed for syntax-basedmachine translation: the hiero paradigm of (chi ang, 2005) <papid> P05-1033 </papid>and the ghkm paradigm of (galley et al., 2004).</prevsent>
</prevsection>
<citsent citstr=" P09-1063 ">
from these papers followed two largely independent lines of research, respectively dubbed formally syntax-based machine translation (chiang, 2007; <papid> J07-2003 </papid>zollmann and venugopal, 2006; <papid> W06-3119 </papid>venugopal et al., 2007; <papid> N07-1063 </papid>lopez, 2007; <papid> D07-1104 </papid>marton and resnik, 2008;<papid> P08-1114 </papid>li et al, 2009; <papid> W09-0424 </papid>de gispert et al, 2010) <papid> J10-3008 </papid>and linguistically syntax-based machine translation (galley et al., 2006; <papid> P06-1121 </papid>marcu et al, 2006; <papid> W06-1606 </papid>liu et al, 2006; <papid> P06-1077 </papid>huang et al, 2006; <papid> W06-3601 </papid>liu et al, 2007; <papid> P07-1089 </papid>mi and huang, 2008; <papid> D08-1022 </papid>zhang et al, 2008; <papid> P08-1064 </papid>liu et al, 2009).<papid> P09-1063 </papid></citsent>
<aftsection>
<nextsent>in this paper, we unify these strands of research by showing how to express hiero extraction, ghkm extraction, and phrase-based extraction as instances of single master extraction method.
</nextsent>
<nextsent>specifically, we express each technique as simple program?
</nextsent>
<nextsent>given to generic evaluator?.
</nextsent>
<nextsent>table 1 summarizes how to express several popular extraction methods as extraction programs.?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3801">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> building blocks.  </section>
<citcontext>
<prevsection>
<prevsent>trivspa pmaplpt?
</prevsent>
<prevsent>forest ghkm (mi and huang, 2008) <papid> D08-1022 </papid>mapppt trivspa pmaplpt tree-to-tree ghkm (liu et al, 2009) <papid> P09-1063 </papid>mapppt mapsp?,a imaplp{t},{?}</prevsent>
</prevsection>
<citsent citstr=" P10-1146 ">
forest-to-forest ghkm (liu et al, 2009) <papid> P09-1063 </papid>mapppt mapspt ,a imaplpt,t fuzzy dual syntax (chiang, 2010) <papid> P10-1146 </papid>mapppt?</citsent>
<aftsection>
<nextsent>mapsp??
</nextsent>
<nextsent>,a imaplp{t?},{??}
</nextsent>
<nextsent>table 1: various rule extraction methods, expressed as extraction programs.
</nextsent>
<nextsent>bold faced methods are proven in this paper; the rest are left as conjecture.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3802">
<title id=" W11-2166.xml">extraction programs a unified approach to translation rule extraction </title>
<section> building blocks.  </section>
<citcontext>
<prevsection>
<prevsent>2.
</prevsent>
<prevsent>an stsg label (from synchronous tree sub-.
</prevsent>
</prevsection>
<citsent citstr=" P03-2041 ">
stitution grammar (eisner, 2003)) <papid> P03-2041 </papid>is pair of trees.</citsent>
<aftsection>
<nextsent>stsg labels subsume scfg labels.
</nextsent>
<nextsent>thus stsgextraction techniques can be used as scfg extraction techniques by ignoring the extra hierarchical structure of the stsg label.
</nextsent>
<nextsent>due to space constraints, we will restrict our focus to scfg labels.
</nextsent>
<nextsent>when considering techniques originally formulated to extract stsg rules (ghkm, for instance), we will consider their scfg equivalents.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3812">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the results also show that monolingual distribution similarity can serve as threshold for high precision paraphrase selection.
</prevsent>
<prevsent>paraphrasing is the rewording of phrase such that meaning is preserved.
</prevsent>
</prevsection>
<citsent citstr=" J10-3003 ">
data-driven paraphrase acquisition techniques can be categorized by the type of data that they use (madnani and dorr,2010).<papid> J10-3003 </papid></citsent>
<aftsection>
<nextsent>monolingual paraphrasing techniques cluster phrases through statistical characteristics suchas dependency path similarities or distributional cooccurrence information (lin and pantel, 2001; pascaand dienes, 2005).
</nextsent>
<nextsent>bilingual paraphrasing techniques use parallel corpora to extract potential paraphrases by grouping english phrases that share thesame foreign translations (bannard and callison burch, 2005).<papid> P05-1074 </papid></nextsent>
<nextsent>other efforts blur the lines between the two, applying techniques from statistical machine translation to monolingual data or extracting paraphrases from multiple english translations of the same foreign text (barzilay and mckeown, 2001; <papid> P01-1008 </papid>pang et al, 2003; <papid> N03-1024 </papid>quirk et al, 2004).<papid> W04-3219 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3813">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>data-driven paraphrase acquisition techniques can be categorized by the type of data that they use (madnani and dorr,2010).<papid> J10-3003 </papid></prevsent>
<prevsent>monolingual paraphrasing techniques cluster phrases through statistical characteristics suchas dependency path similarities or distributional cooccurrence information (lin and pantel, 2001; pascaand dienes, 2005).</prevsent>
</prevsection>
<citsent citstr=" P05-1074 ">
bilingual paraphrasing techniques use parallel corpora to extract potential paraphrases by grouping english phrases that share thesame foreign translations (bannard and callison burch, 2005).<papid> P05-1074 </papid></citsent>
<aftsection>
<nextsent>other efforts blur the lines between the two, applying techniques from statistical machine translation to monolingual data or extracting paraphrases from multiple english translations of the same foreign text (barzilay and mckeown, 2001; <papid> P01-1008 </papid>pang et al, 2003; <papid> N03-1024 </papid>quirk et al, 2004).<papid> W04-3219 </papid></nextsent>
<nextsent>we exploit both methodologies, applying amonolingually-derived similarity metric to the out put of pivot-based bilingual paraphrase model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3814">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>monolingual paraphrasing techniques cluster phrases through statistical characteristics suchas dependency path similarities or distributional cooccurrence information (lin and pantel, 2001; pascaand dienes, 2005).
</prevsent>
<prevsent>bilingual paraphrasing techniques use parallel corpora to extract potential paraphrases by grouping english phrases that share thesame foreign translations (bannard and callison burch, 2005).<papid> P05-1074 </papid></prevsent>
</prevsection>
<citsent citstr=" P01-1008 ">
other efforts blur the lines between the two, applying techniques from statistical machine translation to monolingual data or extracting paraphrases from multiple english translations of the same foreign text (barzilay and mckeown, 2001; <papid> P01-1008 </papid>pang et al, 2003; <papid> N03-1024 </papid>quirk et al, 2004).<papid> W04-3219 </papid></citsent>
<aftsection>
<nextsent>we exploit both methodologies, applying amonolingually-derived similarity metric to the out put of pivot-based bilingual paraphrase model.
</nextsent>
<nextsent>inthis paper we investigate the strengths and weaknesses of scoring paraphrases using monolingual distributional similarity versus the bilingually calculated paraphrase probability.
</nextsent>
<nextsent>we show that monolingual cosine similarity calculated on large volumes of text ranks bilingually-extracted paraphrases better than the paraphrase probability originally defined by bannard and callison-burch (2005).
</nextsent>
<nextsent>while our current implementation shows improvement mainly in grammaticality, other contextual features are expected to enhance the meaning preservation of paraphrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3815">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>monolingual paraphrasing techniques cluster phrases through statistical characteristics suchas dependency path similarities or distributional cooccurrence information (lin and pantel, 2001; pascaand dienes, 2005).
</prevsent>
<prevsent>bilingual paraphrasing techniques use parallel corpora to extract potential paraphrases by grouping english phrases that share thesame foreign translations (bannard and callison burch, 2005).<papid> P05-1074 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-1024 ">
other efforts blur the lines between the two, applying techniques from statistical machine translation to monolingual data or extracting paraphrases from multiple english translations of the same foreign text (barzilay and mckeown, 2001; <papid> P01-1008 </papid>pang et al, 2003; <papid> N03-1024 </papid>quirk et al, 2004).<papid> W04-3219 </papid></citsent>
<aftsection>
<nextsent>we exploit both methodologies, applying amonolingually-derived similarity metric to the out put of pivot-based bilingual paraphrase model.
</nextsent>
<nextsent>inthis paper we investigate the strengths and weaknesses of scoring paraphrases using monolingual distributional similarity versus the bilingually calculated paraphrase probability.
</nextsent>
<nextsent>we show that monolingual cosine similarity calculated on large volumes of text ranks bilingually-extracted paraphrases better than the paraphrase probability originally defined by bannard and callison-burch (2005).
</nextsent>
<nextsent>while our current implementation shows improvement mainly in grammaticality, other contextual features are expected to enhance the meaning preservation of paraphrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3816">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>monolingual paraphrasing techniques cluster phrases through statistical characteristics suchas dependency path similarities or distributional cooccurrence information (lin and pantel, 2001; pascaand dienes, 2005).
</prevsent>
<prevsent>bilingual paraphrasing techniques use parallel corpora to extract potential paraphrases by grouping english phrases that share thesame foreign translations (bannard and callison burch, 2005).<papid> P05-1074 </papid></prevsent>
</prevsection>
<citsent citstr=" W04-3219 ">
other efforts blur the lines between the two, applying techniques from statistical machine translation to monolingual data or extracting paraphrases from multiple english translations of the same foreign text (barzilay and mckeown, 2001; <papid> P01-1008 </papid>pang et al, 2003; <papid> N03-1024 </papid>quirk et al, 2004).<papid> W04-3219 </papid></citsent>
<aftsection>
<nextsent>we exploit both methodologies, applying amonolingually-derived similarity metric to the out put of pivot-based bilingual paraphrase model.
</nextsent>
<nextsent>inthis paper we investigate the strengths and weaknesses of scoring paraphrases using monolingual distributional similarity versus the bilingually calculated paraphrase probability.
</nextsent>
<nextsent>we show that monolingual cosine similarity calculated on large volumes of text ranks bilingually-extracted paraphrases better than the paraphrase probability originally defined by bannard and callison-burch (2005).
</nextsent>
<nextsent>while our current implementation shows improvement mainly in grammaticality, other contextual features are expected to enhance the meaning preservation of paraphrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3817">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1 illustrates their paraphrase extraction process.
</prevsent>
<prevsent>the target phrase, e.g. thrown into jail, is found in german-english parallel corpus.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the corresponding foreign phrase (festgenommen) is identified using word alignment and phrase extraction techniques from phrase-based statistical machine translation (koehn et al, 2003).<papid> N03-1017 </papid>other occurrences of the foreign phrase in the parallel corpus may align to distinct english phrase,such as jailed.</citsent>
<aftsection>
<nextsent>as the original phrase occurs several times and aligns with many different foreign phrases, each of these may align to variety of other english paraphrases.
</nextsent>
<nextsent>thus, thrown into jail not only paraphrases as jailed, but also as arrested, detained, imprisoned, incarcerated, locked up, and so on.
</nextsent>
<nextsent>bad paraphrases, such as maltreated, thrown, cases, custody, arrest, and protection, may also arise due to poor word alignment quality and other factors.
</nextsent>
<nextsent>33 ... letztewoche wurden in irland fnf landwirte festgenommen , weil sie verhindern wollten ... last week five farmers were thrown into jail in ireland because they resisted ...
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3818">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>callison-burch (2008)attempts to improve the ranking by limiting paraphrases to be the same syntactic type.
</prevsent>
<prevsent>we attempt to rerank the paraphrases using other information.
</prevsent>
</prevsection>
<citsent citstr=" P08-1116 ">
this is similar to the efforts of zhao et al (2008), <papid> P08-1116 </papid>who made use of multiple resources to derive feature functions and extract paraphrase ta bles.</citsent>
<aftsection>
<nextsent>the paraphrase that maximizes log-linearcombination of various feature functions is then selected as the optimal paraphrase.
</nextsent>
<nextsent>feature weights in the model are optimized by minimizing phrase substitution error rate, measure proposed by the authors, on development set.
</nextsent>
<nextsent>2.2 monolingual distributional similarity.
</nextsent>
<nextsent>prior work has explored the acquisition of paraphrases using distributional similarity computed from monolingual resources, such as in the dirt results of lin and pantel (2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3819">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in these models, phrases are judged to be similar based on the cosine distance of their associated context vectors.
</prevsent>
<prevsent>in some cases, such as by lin and pantel, or the seminal work of church and hanks (1991), distributional context is defined using frequencies of words appearing in various syntactic relations with other lexical items.for example, the nouns apple and orange are contextually similar partly because they both often appear as the object of the verb eat.
</prevsent>
</prevsection>
<citsent citstr=" P08-1077 ">
while syntactic contexts provide strong evidence of distributional preferences, it is computationally expensive to parse very large corpora, so it is also common to represent context vectors with simpler representations like adjacent words and n-grams (lapata and keller, 2005; bhagat and ravichandran, 2008; <papid> P08-1077 </papid>lin et al, 2010;van durme and lall, 2010).</citsent>
<aftsection>
<nextsent>in these models, apple and orange might be judged similar because both tend to be one word to the right of some, and one to the left of juice.
</nextsent>
<nextsent>here we calculate distributional similarity using web-scale n-gram corpus (brants and franz, 2006;lin et al, 2010).
</nextsent>
<nextsent>given both the size of the collection, and that the n-grams are sub-sentential (the grams are no longer than 5 tokens by design), it was not feasible to parse, which led to the use of n-gram contexts.
</nextsent>
<nextsent>here we use adjacent unigrams.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3820">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>here we use adjacent unigrams.
</prevsent>
<prevsent>for each phrase we wished to paraphrase, we extracted the context vector of from the n-gram collection as such: every (n-gram, frequency) pair of the form: (ax, ), or (xb, ), gave rise to the (feature, value) pair: (wi1=a, ), or (wi+1=b, ), respectively.
</prevsent>
</prevsection>
<citsent citstr=" P05-1077 ">
in order to scale to this size of collection, we relied on locality sensitive hashing (lsh), as was done previously by ravichandran et al (2005) <papid> P05-1077 </papid>and bha gat and ravichandran (2008).<papid> P08-1077 </papid></citsent>
<aftsection>
<nextsent>to avoid computing feature vectors explicitly, which can be memory intensive bottleneck, we employed the online lsh variant described by van durme and lall (2010).
</nextsent>
<nextsent>this variant, based on the earlier work of indyk and motwani (1998) and chari kar (2002), approximates the cosine similarity between two feature vectors based on the hamming distance in reduced bit wise representation.
</nextsent>
<nextsent>in brief, for the feature vectors ~u, ~v, each of dimension d, then the cosine similarity is defined as: ~u?~v|~u||~v| . if we project ~u and ~v through d by random matrix populated withdraws from 34 huge amount of bip syntbip bip-monods large number of, .33 large number of, .38 huge amount of, 1.0 in large numbers, .11 great number of, .09 large quantity of, .98 great number of, .08 huge amount of, .06 large number of, .98 large numbers of, .06 vast number of, .06 great number of, .97 vast number of, .06 vast number of, .94 huge amount of, .06 in large numbers, .10 large quantity of, .03 large numbers of, .08 table 1: paraphrases for huge amount of according to the bilingual pivoting (bip), syntactic-constrainted bilingual pivoting (syntbip) translation score and the monolingual similarity score via lsh (monods), ranked by corresponding scores listed next to each paraphrase.
</nextsent>
<nextsent>syntactic type of the phrase is [jj+nn+in].
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3823">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> ranking paraphrases.  </section>
<citcontext>
<prevsection>
<prevsent>identity paraphrases are excluded for the rest of the discussion in this paper.
</prevsent>
<prevsent>3.2 susceptibility to antonyms.
</prevsent>
</prevsection>
<citsent citstr=" D08-1103 ">
monolingual distributional similarity is widely known to conflate words with opposite meaning and has motivated large body of prior work on antonym detection (lin and zhao, 2003; lin and pantel, 2001; mohammad et al, 2008<papid> D08-1103 </papid>a; mohammad et al, 2008<papid> D08-1103 </papid>b; marneffe et al, 2008; voorhees, 2008).<papid> P08-1008 </papid></citsent>
<aftsection>
<nextsent>in contrast, the antonyms of phrase are rarely produced during pivoting of the bip methods because they tend not to share the same foreign translations.since the reranking framework proposed here begins with paraphrases acquired by the bip methodol 35 ogy, monods can considerably enhance the quality of ranking while sidestepping the antonym problem that arises from using monods alone.to support this intuition, an example of paraphrase list with inserted hand-selected phrases ranked by each reranking methods is shown in table 21.
</nextsent>
<nextsent>hand-selected antonyms of reluctant are inserted into the paraphrase candidates extracted by bip before they are reranked by monods.
</nextsent>
<nextsent>this is analogous to the case without pre-filtering of paraphrases by bip and all phrases are treated equally by monods alone.
</nextsent>
<nextsent>bip cannot rank these hand selected paraphrases since, by construction, they do not share any foreign translation and hence their paraphrase scores are not defined.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3827">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> ranking paraphrases.  </section>
<citcontext>
<prevsection>
<prevsent>identity paraphrases are excluded for the rest of the discussion in this paper.
</prevsent>
<prevsent>3.2 susceptibility to antonyms.
</prevsent>
</prevsection>
<citsent citstr=" P08-1008 ">
monolingual distributional similarity is widely known to conflate words with opposite meaning and has motivated large body of prior work on antonym detection (lin and zhao, 2003; lin and pantel, 2001; mohammad et al, 2008<papid> D08-1103 </papid>a; mohammad et al, 2008<papid> D08-1103 </papid>b; marneffe et al, 2008; voorhees, 2008).<papid> P08-1008 </papid></citsent>
<aftsection>
<nextsent>in contrast, the antonyms of phrase are rarely produced during pivoting of the bip methods because they tend not to share the same foreign translations.since the reranking framework proposed here begins with paraphrases acquired by the bip methodol 35 ogy, monods can considerably enhance the quality of ranking while sidestepping the antonym problem that arises from using monods alone.to support this intuition, an example of paraphrase list with inserted hand-selected phrases ranked by each reranking methods is shown in table 21.
</nextsent>
<nextsent>hand-selected antonyms of reluctant are inserted into the paraphrase candidates extracted by bip before they are reranked by monods.
</nextsent>
<nextsent>this is analogous to the case without pre-filtering of paraphrases by bip and all phrases are treated equally by monods alone.
</nextsent>
<nextsent>bip cannot rank these hand selected paraphrases since, by construction, they do not share any foreign translation and hence their paraphrase scores are not defined.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3828">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> ranking paraphrases.  </section>
<citcontext>
<prevsection>
<prevsent>word alignments were generated with the berkeley aligner.
</prevsent>
<prevsent>for syntbip, the english sideof the parallel corpus was parsed using the stanford parser (klein and manning, 2003).
</prevsent>
</prevsection>
<citsent citstr=" W11-2160 ">
the translation models were trained with thrax, grammar extractor for machine translation (weese et al, 2011).<papid> W11-2160 </papid></citsent>
<aftsection>
<nextsent>thrax extracts phrase pairs that are labeled with complex syntactic labels following zollmann and venugopal (2006).<papid> W06-3119 </papid></nextsent>
<nextsent>for monods, the web-scale n-gram collection oflin et al (2010) was used to compute the monolingual distributional similarity features, using 512 bits per signature in the resultant lsh projection.following van durme and lall (2010), we implic 1generating paraphrase list by monods alone requires building features for all phrases in the corpus, which is computationally impractical and hence, was not considered here.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3829">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> ranking paraphrases.  </section>
<citcontext>
<prevsection>
<prevsent>for syntbip, the english sideof the parallel corpus was parsed using the stanford parser (klein and manning, 2003).
</prevsent>
<prevsent>the translation models were trained with thrax, grammar extractor for machine translation (weese et al, 2011).<papid> W11-2160 </papid></prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
thrax extracts phrase pairs that are labeled with complex syntactic labels following zollmann and venugopal (2006).<papid> W06-3119 </papid></citsent>
<aftsection>
<nextsent>for monods, the web-scale n-gram collection oflin et al (2010) was used to compute the monolingual distributional similarity features, using 512 bits per signature in the resultant lsh projection.following van durme and lall (2010), we implic 1generating paraphrase list by monods alone requires building features for all phrases in the corpus, which is computationally impractical and hence, was not considered here.
</nextsent>
<nextsent>itly represented the projection matrix with pool of size 10,000.
</nextsent>
<nextsent>in order to expand the coverage of the candidates scored by the monolingual method, the lsh signatures are obtained only for the phrases in the union set of the phrase-level outputs from the original and from the syntactically constrained paraphrase models.
</nextsent>
<nextsent>since the n-gram corpus consists of at most 5-gram and each distributional similarity feature requires single neighboring token, the lsh signatures are generated only for phrases that are 4-gram or less.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3830">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> human evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>phrases that didnt appear in the n-grams with at least one feature were discarded.
</prevsent>
<prevsent>the different paraphrase scoring methods were compared through manual evaluation conducted on amazon mechanical turk.
</prevsent>
</prevsection>
<citsent citstr=" P07-1058 ">
a set of 100 test phrases were selected and for each test phrase, five distinct sentences were randomly sampled to capture the fact that paraphrases are valid in some contexts but not others (szpektor et al, 2007).<papid> P07-1058 </papid></citsent>
<aftsection>
<nextsent>judges evaluated the paraphrase quality through substitution test: for each sampled sentence, the test phrase is substituted with automatically-generated paraphrases.
</nextsent>
<nextsent>the sentences and the phrases are drawn from the english side of the europarl corpus.
</nextsent>
<nextsent>judges indicated the amount of the original meaning preserved by the paraphrases and the grammaticality of the resultingsentences.
</nextsent>
<nextsent>they assigned two values to each sentence using the 5-point scales defined in callison burch (2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3832">
<title id=" W11-2504.xml">reranking bilingually extracted paraphrases using monolingual distributional similarity </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>through manual evaluation, it was shown that monolingual distributional scores strongly correlate with human assessment of paraphrase quality in terms of grammaticality, yet have minimal effects on meaning preservation of paraphrases.while we speculated that monods would improve both meaning and grammar scoring for paraphrases, we found in the results that only grammaticality was improved from the monolingual approach.
</prevsent>
<prevsent>this is likely due to the choice of how context is represented, which in this case is only single neighboring words.
</prevsent>
</prevsection>
<citsent citstr=" P97-1009 ">
a consideration for future work to enhance paraphrasal meaning preservation would be to explore other contextual representations, suchas syntactic dependency parsing (lin, 1997), <papid> P97-1009 </papid>mutual information between co-occurences of phrases church and hanks (1991), or increasing the number of neighboring words used in n-gram based repre sentations.in future work we will make use of other complementary bilingual and monolingual knowledge sources by combining other features such as n-gram length, language model scores, etc. one approach would be to perform minimum error rate training similar to zhao et al (2008) <papid> P08-1116 </papid>in which linear weights of feature function for set of paraphrases candidate are trained iteratively to minimize the phrasalsubstitution-based error rate.</citsent>
<aftsection>
<nextsent>instead of phrasal substitution in zhaos method, quantitative measure of correlation with human judgment can be used asthe objective function to be optimized during training.
</nextsent>
<nextsent>other techniques such as svm-rank (joachims,2002) may also be investigated for aggregating results from multiple ranked lists.
</nextsent>
<nextsent>thanks to courtney napoles for advice regarding pilot version of this work.
</nextsent>
<nextsent>thanks to jonathanweese, matt post and juri ganitkevitch for their assistance with thrax.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3834">
<title id=" W11-1906.xml">rule and tree ensembles for unrestricted coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and the event grew?.
</prevsent>
<prevsent>throughout this work is partially funded by the funcap grant 0011 00147.01.00/09.this paper, we use the term mention to mean reference to an entity or event.
</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
the conll 2011 shared task (pradhan et al,2011) <papid> W11-1901 </papid>is dedicated to modeling unrestricted coreference in ontonotes.</citsent>
<aftsection>
<nextsent>the participants are provided with large corpus that contains various annotation layers such as part-of-speech (pos) tagging, parsing, named entities and semantic role labeling.
</nextsent>
<nextsent>thetask consists in the automatic identification of co referring entities and events given predicted information on other ontonotes layers.
</nextsent>
<nextsent>a previous work on modeling unrestricted coreference using an earlier version of this corpus is presented in (pradhan et al, 2007).
</nextsent>
<nextsent>in this paper, we describe the machine learning approach that we used to the closed track of the conll 2011 shared task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3835">
<title id=" W11-1906.xml">rule and tree ensembles for unrestricted coreference resolution </title>
<section> corpus processing.  </section>
<citcontext>
<prevsection>
<prevsent>therefore, the system does not resolve co references involving events.
</prevsent>
<prevsent>2.2 candidate co-referring pairs generation.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
in the training phase, we generate positive and negative examples of co-referring pairs using strategy similar to the one of soon et al (2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>in their method, the text is examined in left-to-right manner.
</nextsent>
<nextsent>for each anaphoric mention mj , is generated apositive example pair that includes mj and its closest preceding antecedent, mi.
</nextsent>
<nextsent>a negative example is created for mj paired with each of the intervening mentions, mi+1, mi+2, ..., mj1.
</nextsent>
<nextsent>we extend the soon et al (2001) <papid> J01-4004 </papid>approach by also including all positive and negative pairs that can be formed with the mentions in the sentence of the closest preceding antecedent, mi.in the classification phase, the text is also examined in left-to-right manner.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3837">
<title id=" W11-1906.xml">rule and tree ensembles for unrestricted coreference resolution </title>
<section> corpus processing.  </section>
<citcontext>
<prevsection>
<prevsent>we use set of 80 features to describe each pair of mentions (mi, mj).
</prevsent>
<prevsent>the feature set includes lexical, morphological, syntactic, semantic and positional information.
</prevsent>
</prevsection>
<citsent citstr=" P02-1014 ">
most of them are borrowed from the works of ng and cardie (2002) <papid> P02-1014 </papid>and sapena et al(2010).<papid> S10-1017 </papid></citsent>
<aftsection>
<nextsent>however, we also propose some new features.
</nextsent>
<nextsent>in the following, due to space constraints, we briefly describe some of them.
</nextsent>
<nextsent>the features marked with * are the new proposed ones.
</nextsent>
<nextsent>lexical: head word of mi/j ; string matching of (head word of) mi and mj (y/n); both are pronouns and their strings match (y/n); previous/next two words of mi/j ; length of mi/j ; edit distance of head words; mi/j is definitive np (y/n); mi/j is demonstrative np (y/n).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3838">
<title id=" W11-1906.xml">rule and tree ensembles for unrestricted coreference resolution </title>
<section> corpus processing.  </section>
<citcontext>
<prevsection>
<prevsent>we use set of 80 features to describe each pair of mentions (mi, mj).
</prevsent>
<prevsent>the feature set includes lexical, morphological, syntactic, semantic and positional information.
</prevsent>
</prevsection>
<citsent citstr=" S10-1017 ">
most of them are borrowed from the works of ng and cardie (2002) <papid> P02-1014 </papid>and sapena et al(2010).<papid> S10-1017 </papid></citsent>
<aftsection>
<nextsent>however, we also propose some new features.
</nextsent>
<nextsent>in the following, due to space constraints, we briefly describe some of them.
</nextsent>
<nextsent>the features marked with * are the new proposed ones.
</nextsent>
<nextsent>lexical: head word of mi/j ; string matching of (head word of) mi and mj (y/n); both are pronouns and their strings match (y/n); previous/next two words of mi/j ; length of mi/j ; edit distance of head words; mi/j is definitive np (y/n); mi/j is demonstrative np (y/n).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3839">
<title id=" W11-1906.xml">rule and tree ensembles for unrestricted coreference resolution </title>
<section> corpus processing.  </section>
<citcontext>
<prevsection>
<prevsent>the features marked with * are the new proposed ones.
</prevsent>
<prevsent>lexical: head word of mi/j ; string matching of (head word of) mi and mj (y/n); both are pronouns and their strings match (y/n); previous/next two words of mi/j ; length of mi/j ; edit distance of head words; mi/j is definitive np (y/n); mi/j is demonstrative np (y/n).
</prevsent>
</prevsection>
<citsent citstr=" P06-1005 ">
morphological: both are proper names and their strings match (y/n); basic gender agreement*, which use list of proper names extracted from the training corpus (y/n); gender/number of mi/j ; gen der/number agreement(y/n), this and the previous feature are generated using the number and gender data provided by bergsma and lin (2006).<papid> P06-1005 </papid>syntactic: pos tag of the mi/j head word; previ ous/next two pos tags of mi/j ; mi and mj are both pronouns / proper names (y/n); previous/next predicate of mi/j*; compatible pronouns, which checks whether two pronouns agree in number, gender and person (y/n)*; np embedding level; number of embedded nps in mi/j*.</citsent>
<aftsection>
<nextsent>semantic: the result of baseline system; sense of the mi/j head word; named entity type of mi/j ; mi and mj have the same named entity; semantic role of mi/j for the prev/next predicate*; concatenation of semantic roles of mi and mj for the same predicate (if they are in the same sentence)*; samespeaker* (y/n); alias (y/n); mi and mj have hy pernym/hyponym relation (y/n); mi and mj have the 52 same semantic class (y/n); sum of distances between mi and mj to their class.
</nextsent>
<nextsent>the last three features are generated using wordnet 3.0 (miller, 1995).
</nextsent>
<nextsent>distance and position: distance between mi and mj in sentences; distance in number of mentions; distance in number of person names (applies only for the cases where mi and mj are both pronouns or one of them is person name)*; one mention is in apposition to the other (y/n).
</nextsent>
<nextsent>2.4 clustering strategy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3841">
<title id=" W11-2123.xml">kenlm faster and smaller language model queries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>throughout this paper we compare with several packages: srilm 1.5.12 (stolcke, 2002) is popular toolkit based on tries used in several decoders.
</prevsent>
<prevsent>irstlm 5.60.02 (federico et al, 2008) is sortedtrie implementation designed for lower memory consumption.mitlm 0.4 (hsu and glass, 2008) is mostly designed for accurate model estimation, but can also compute perplexity.
</prevsent>
</prevsection>
<citsent citstr=" P07-1065 ">
randlm 0.2 (talbot and osborne, 2007) <papid> P07-1065 </papid>storeslarge-scale models in less memory using randomized data structures.</citsent>
<aftsection>
<nextsent>berkeleylm revision 152 (pauls and klein, 2011) <papid> P11-1027 </papid>implements tries based on hash tables and sorted arrays in java with lossy quantization.sheffield guthrie and hepple (2010) <papid> D10-1026 </papid>explore several randomized compression techniques, but did not release code.tpt germann et al (2009) <papid> W09-1505 </papid>describe tries with better locality properties, but did not release code.</nextsent>
<nextsent>these packages are further described in section 3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3843">
<title id=" W11-2123.xml">kenlm faster and smaller language model queries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>irstlm 5.60.02 (federico et al, 2008) is sortedtrie implementation designed for lower memory consumption.mitlm 0.4 (hsu and glass, 2008) is mostly designed for accurate model estimation, but can also compute perplexity.
</prevsent>
<prevsent>randlm 0.2 (talbot and osborne, 2007) <papid> P07-1065 </papid>storeslarge-scale models in less memory using randomized data structures.</prevsent>
</prevsection>
<citsent citstr=" P11-1027 ">
berkeleylm revision 152 (pauls and klein, 2011) <papid> P11-1027 </papid>implements tries based on hash tables and sorted arrays in java with lossy quantization.sheffield guthrie and hepple (2010) <papid> D10-1026 </papid>explore several randomized compression techniques, but did not release code.tpt germann et al (2009) <papid> W09-1505 </papid>describe tries with better locality properties, but did not release code.</citsent>
<aftsection>
<nextsent>these packages are further described in section 3.
</nextsent>
<nextsent>we substantially outperform all of them on query 187 speed and offer lower memory consumption than loss less alternatives.
</nextsent>
<nextsent>performance improvements transfer to the moses (koehn et al, 2007), <papid> P07-2045 </papid>cdec (dyer et al, 2010), <papid> P10-4002 </papid>and joshua (li et al, 2009)<papid> W09-0424 </papid>translation systems where our code has been inte grated.</nextsent>
<nextsent>our open-source (lgpl) implementation is also available for download as standalone package with minimal (posix and g++) dependencies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3846">
<title id=" W11-2123.xml">kenlm faster and smaller language model queries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>irstlm 5.60.02 (federico et al, 2008) is sortedtrie implementation designed for lower memory consumption.mitlm 0.4 (hsu and glass, 2008) is mostly designed for accurate model estimation, but can also compute perplexity.
</prevsent>
<prevsent>randlm 0.2 (talbot and osborne, 2007) <papid> P07-1065 </papid>storeslarge-scale models in less memory using randomized data structures.</prevsent>
</prevsection>
<citsent citstr=" D10-1026 ">
berkeleylm revision 152 (pauls and klein, 2011) <papid> P11-1027 </papid>implements tries based on hash tables and sorted arrays in java with lossy quantization.sheffield guthrie and hepple (2010) <papid> D10-1026 </papid>explore several randomized compression techniques, but did not release code.tpt germann et al (2009) <papid> W09-1505 </papid>describe tries with better locality properties, but did not release code.</citsent>
<aftsection>
<nextsent>these packages are further described in section 3.
</nextsent>
<nextsent>we substantially outperform all of them on query 187 speed and offer lower memory consumption than loss less alternatives.
</nextsent>
<nextsent>performance improvements transfer to the moses (koehn et al, 2007), <papid> P07-2045 </papid>cdec (dyer et al, 2010), <papid> P10-4002 </papid>and joshua (li et al, 2009)<papid> W09-0424 </papid>translation systems where our code has been inte grated.</nextsent>
<nextsent>our open-source (lgpl) implementation is also available for download as standalone package with minimal (posix and g++) dependencies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3848">
<title id=" W11-2123.xml">kenlm faster and smaller language model queries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>irstlm 5.60.02 (federico et al, 2008) is sortedtrie implementation designed for lower memory consumption.mitlm 0.4 (hsu and glass, 2008) is mostly designed for accurate model estimation, but can also compute perplexity.
</prevsent>
<prevsent>randlm 0.2 (talbot and osborne, 2007) <papid> P07-1065 </papid>storeslarge-scale models in less memory using randomized data structures.</prevsent>
</prevsection>
<citsent citstr=" W09-1505 ">
berkeleylm revision 152 (pauls and klein, 2011) <papid> P11-1027 </papid>implements tries based on hash tables and sorted arrays in java with lossy quantization.sheffield guthrie and hepple (2010) <papid> D10-1026 </papid>explore several randomized compression techniques, but did not release code.tpt germann et al (2009) <papid> W09-1505 </papid>describe tries with better locality properties, but did not release code.</citsent>
<aftsection>
<nextsent>these packages are further described in section 3.
</nextsent>
<nextsent>we substantially outperform all of them on query 187 speed and offer lower memory consumption than loss less alternatives.
</nextsent>
<nextsent>performance improvements transfer to the moses (koehn et al, 2007), <papid> P07-2045 </papid>cdec (dyer et al, 2010), <papid> P10-4002 </papid>and joshua (li et al, 2009)<papid> W09-0424 </papid>translation systems where our code has been inte grated.</nextsent>
<nextsent>our open-source (lgpl) implementation is also available for download as standalone package with minimal (posix and g++) dependencies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3849">
<title id=" W11-2123.xml">kenlm faster and smaller language model queries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these packages are further described in section 3.
</prevsent>
<prevsent>we substantially outperform all of them on query 187 speed and offer lower memory consumption than loss less alternatives.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
performance improvements transfer to the moses (koehn et al, 2007), <papid> P07-2045 </papid>cdec (dyer et al, 2010), <papid> P10-4002 </papid>and joshua (li et al, 2009)<papid> W09-0424 </papid>translation systems where our code has been inte grated.</citsent>
<aftsection>
<nextsent>our open-source (lgpl) implementation is also available for download as standalone package with minimal (posix and g++) dependencies.
</nextsent>
<nextsent>we implement two data structures: probing, designed for speed, and trie, optimized for memory.
</nextsent>
<nextsent>the set of n-grams appearing in model is sparse, and we want to efficiently find their associated probabilities and backoff penalties.
</nextsent>
<nextsent>an important sub problem of language model storage is therefore sparse mapping: storing values for sparse keys using little memory then retrieving values given keys using little time.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3850">
<title id=" W11-2123.xml">kenlm faster and smaller language model queries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these packages are further described in section 3.
</prevsent>
<prevsent>we substantially outperform all of them on query 187 speed and offer lower memory consumption than loss less alternatives.
</prevsent>
</prevsection>
<citsent citstr=" P10-4002 ">
performance improvements transfer to the moses (koehn et al, 2007), <papid> P07-2045 </papid>cdec (dyer et al, 2010), <papid> P10-4002 </papid>and joshua (li et al, 2009)<papid> W09-0424 </papid>translation systems where our code has been inte grated.</citsent>
<aftsection>
<nextsent>our open-source (lgpl) implementation is also available for download as standalone package with minimal (posix and g++) dependencies.
</nextsent>
<nextsent>we implement two data structures: probing, designed for speed, and trie, optimized for memory.
</nextsent>
<nextsent>the set of n-grams appearing in model is sparse, and we want to efficiently find their associated probabilities and backoff penalties.
</nextsent>
<nextsent>an important sub problem of language model storage is therefore sparse mapping: storing values for sparse keys using little memory then retrieving values given keys using little time.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3852">
<title id=" W11-2123.xml">kenlm faster and smaller language model queries </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these packages are further described in section 3.
</prevsent>
<prevsent>we substantially outperform all of them on query 187 speed and offer lower memory consumption than loss less alternatives.
</prevsent>
</prevsection>
<citsent citstr=" W09-0424 ">
performance improvements transfer to the moses (koehn et al, 2007), <papid> P07-2045 </papid>cdec (dyer et al, 2010), <papid> P10-4002 </papid>and joshua (li et al, 2009)<papid> W09-0424 </papid>translation systems where our code has been inte grated.</citsent>
<aftsection>
<nextsent>our open-source (lgpl) implementation is also available for download as standalone package with minimal (posix and g++) dependencies.
</nextsent>
<nextsent>we implement two data structures: probing, designed for speed, and trie, optimized for memory.
</nextsent>
<nextsent>the set of n-grams appearing in model is sparse, and we want to efficiently find their associated probabilities and backoff penalties.
</nextsent>
<nextsent>an important sub problem of language model storage is therefore sparse mapping: storing values for sparse keys using little memory then retrieving values given keys using little time.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3856">
<title id=" W11-2123.xml">kenlm faster and smaller language model queries </title>
<section> data structures.  </section>
<citcontext>
<prevsection>
<prevsent>to conserve memory at the expense of accuracy, values may be quant ized using bits per probability and bits per backoff6.
</prevsent>
<prevsent>we allow any number of bits from 2 to 25, unlike irstlm (8 bits) and berkeleylm (1720 bits).
</prevsent>
</prevsection>
<citsent citstr=" W06-3113 ">
to quantize, we use the binning method (federico and bertoldi, 2006) <papid> W06-3113 </papid>that sorts values, divides into equally sized bins, and averages within each bin.</citsent>
<aftsection>
<nextsent>the cost of storing these averages, in bits, is [32(n ? 1)2q + 32(n ? 2)2r because there are comparatively few unigrams,we elected to store them byte-aligned and unquan tized, making every query faster.
</nextsent>
<nextsent>unigrams also have 64-bit overhead for vocabulary lookup.
</nextsent>
<nextsent>using cn to denote the number of n-grams, total memory consumption of trie, in bits, is (32 + 32 + 64 + 64)c1+ n1?
</nextsent>
<nextsent>n=2 (dlog2 c1e+ + + dlog2 cn+1e)cn+ (dlog2 c1e+ q)cn plus quant ization tables, if used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3871">
<title id=" W11-2123.xml">kenlm faster and smaller language model queries </title>
<section> benchmarks.  </section>
<citcontext>
<prevsection>
<prevsent>it also does not prune, so comparing to our pruned model would be unfair.
</prevsent>
<prevsent>using randlm and the documented settings (8-bit values and 1256 false-positive prob ability), we built stupid backoff model on the same data as in section 5.2.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we used this data to build an un pruned arpa file with irstlms 195 ram (gb) pack variant time (m) res virt bleu ken trie 82.9 12.16 14.39 27.24 trie 8 bits 82.7 8.41 9.41 27.22 trie 4 bits 83.2 7.74 8.55 27.09 rand stupid 8 bits 218.7 5.07 5.18 25.54 backoff 8 bits 337.4 7.17 7.28 25.45 table 4: cpu time, memory usage, and uncased bleu (papineni et al, 2002) <papid> P02-1040 </papid>score for single-threaded moses translating the same test set.</citsent>
<aftsection>
<nextsent>we ran each lossy model twice: once with specially-tuned weights and once with weights tuned using an exact model.
</nextsent>
<nextsent>the difference in bleu was minor and we report the better result.
</nextsent>
<nextsent>improved-kneser-ney option and the default three pieces.
</nextsent>
<nextsent>table 4 shows the results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3879">
<title id=" W12-1514.xml">rich morphology generation using statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>if all of the gold morphological features are provided as input, our best model achieves 98.9% accuracy.
</prevsent>
<prevsent>1this work was funded by google research award.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
in the context of morphological generation for mt,the state-of-the-art factored machine translation approach models morphology using generation factors in the translation process (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>oneof the limitations of factored models is that generation is based on the word level not the phrase level and the context is only captured through language model.
</nextsent>
<nextsent>minkov et al (2007) <papid> P07-1017 </papid>and toutanova etal.</nextsent>
<nextsent>(2008) model translation and morphology independently for english-arabic and english-russian mt. they use maximum entropy model to predict inflected word forms directly.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3881">
<title id=" W12-1514.xml">rich morphology generation using statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in the context of morphological generation for mt,the state-of-the-art factored machine translation approach models morphology using generation factors in the translation process (koehn et al, 2007).<papid> P07-2045 </papid></prevsent>
<prevsent>oneof the limitations of factored models is that generation is based on the word level not the phrase level and the context is only captured through language model.</prevsent>
</prevsection>
<citsent citstr=" P07-1017 ">
minkov et al (2007) <papid> P07-1017 </papid>and toutanova etal.</citsent>
<aftsection>
<nextsent>(2008) model translation and morphology independently for english-arabic and english-russian mt. they use maximum entropy model to predict inflected word forms directly.
</nextsent>
<nextsent>clifton and sarkar (2011) <papid> P11-1004 </papid>use similar approach for english-finnishmt where they predict morpheme sequences.</nextsent>
<nextsent>unlike both approaches, we generate the word forms from the deeper representation of lemmas and fea tures.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3882">
<title id=" W12-1514.xml">rich morphology generation using statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>minkov et al (2007) <papid> P07-1017 </papid>and toutanova etal.</prevsent>
<prevsent>(2008) model translation and morphology independently for english-arabic and english-russian mt. they use maximum entropy model to predict inflected word forms directly.</prevsent>
</prevsection>
<citsent citstr=" P11-1004 ">
clifton and sarkar (2011) <papid> P11-1004 </papid>use similar approach for english-finnishmt where they predict morpheme sequences.</citsent>
<aftsection>
<nextsent>unlike both approaches, we generate the word forms from the deeper representation of lemmas and features.
</nextsent>
<nextsent>as for using smt in generation, there are many previous efforts.
</nextsent>
<nextsent>wong and mooney (2007) <papid> N07-1022 </papid>use smt methods for tactical nlg.</nextsent>
<nextsent>they learn through smt to map meaning representations to natural language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3883">
<title id=" W12-1514.xml">rich morphology generation using statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>unlike both approaches, we generate the word forms from the deeper representation of lemmas and features.
</prevsent>
<prevsent>as for using smt in generation, there are many previous efforts.
</prevsent>
</prevsection>
<citsent citstr=" N07-1022 ">
wong and mooney (2007) <papid> N07-1022 </papid>use smt methods for tactical nlg.</citsent>
<aftsection>
<nextsent>they learn through smt to map meaning representations to natural language.
</nextsent>
<nextsent>quirk et al (2004) <papid> W04-3219 </papid>apply smt tools to generate paraphrases of input sentences in the same language.</nextsent>
<nextsent>both of these efforts target english, morphologically poor language.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3884">
<title id=" W12-1514.xml">rich morphology generation using statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>wong and mooney (2007) <papid> N07-1022 </papid>use smt methods for tactical nlg.</prevsent>
<prevsent>they learn through smt to map meaning representations to natural language.</prevsent>
</prevsection>
<citsent citstr=" W04-3219 ">
quirk et al (2004) <papid> W04-3219 </papid>apply smt tools to generate paraphrases of input sentences in the same language.</citsent>
<aftsection>
<nextsent>both of these efforts target english, morphologically poor language.
</nextsent>
<nextsent>our work is conceptually closer to wong and mooney (2007), <papid> N07-1022 </papid>except thatwe focus on the question of morphological generation and our approach includes an optional feature prediction component.</nextsent>
<nextsent>in related publication, we integrate our generation model as part of end-to-end english-arabic smt (el kholy and habash, 2012).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3886">
<title id=" W12-1514.xml">rich morphology generation using statistical machine translation </title>
<section> arabic challenges.  </section>
<citcontext>
<prevsection>
<prevsent>arabic has complex morpho-syntactic agreement rules in terms of gen, num and definiteness.
</prevsent>
<prevsent>adjectives agree with nouns in gen and num but plural irrational nouns exceptionally take feminine singular adjectives.
</prevsent>
</prevsection>
<citsent citstr=" P11-2062 ">
moreover, verbs agree with subjects in gen only in vso order while they agree in gen and num in svo order (alkuhlani and habash, 2011).<papid> P11-2062 </papid></citsent>
<aftsection>
<nextsent>the det in arabic is used to distinguish different syntactic constructions such as the possessive or adjectival modification.
</nextsent>
<nextsent>these agreement rules make the generation of correctly inflected forms in context challenging task.
</nextsent>
<nextsent>in this section, we discuss our approach in generating arabic words from arabic lemmas (lemma) using pipeline of three steps.1.
</nextsent>
<nextsent>(optional)morphology prediction of linguistic features to inflect lemmas.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3887">
<title id=" W12-1514.xml">rich morphology generation using statistical machine translation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>morphology generation is the main contribution of this paper which in addition to detokenization represents an end-to-end inflection generator.
</prevsent>
<prevsent>the morphology prediction step is an optional step that complements the whole process by enriching the input of the morphology generation step with one or more predicted morphological features.
</prevsent>
</prevsection>
<citsent citstr=" P08-2039 ">
we follow numerous previously published efforts on the value of tokenization for arabic nlp tasks (badr et al, 2008; <papid> P08-2039 </papid>el kholy and habash, 2010).</citsent>
<aftsection>
<nextsent>we use the best performing tokenization scheme (patb)in machine translation in all our experiments and focus on the question of how to generate arabic inflected words from lemmas and features.
</nextsent>
<nextsent>figure 1shows an example of tokenized word and its decomposition into lemma and morphological features.
</nextsent>
<nextsent>morphology prediction this optional step takes sequence of lemmas and tries to enrich them by predicting one or more morphological features.
</nextsent>
<nextsent>it is implemented using supervised discriminative learning model, namely conditional random fields (crf) (lafferty et al, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3888">
<title id=" W12-1514.xml">rich morphology generation using statistical machine translation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>this task is similar to pos tagging 91 predicted baseline prediction feature accuracy% accuracy% case (cas) 42.87 70.39 state (stt) 42.85 76.93 gender (gen) 67.42 84.17 determiner (det) 59.71 85.41 number (num) 70.61 87.31 aspect (asp) 90.38 92.10 person (per) 85.71 92.80 voice (vox) 90.38 93.70 mood (mod) 90.38 93.80table 1: accuracy (%) of feature prediction starting from arabic lemmas (lemma).
</prevsent>
<prevsent>the second column shows the baseline for prediction using the most common feature value.
</prevsent>
</prevsection>
<citsent citstr=" P05-1071 ">
the third column is the prediction accuracy using crf.except that it starts with lemmas as opposed to inflected forms (habash and rambow, 2005; <papid> P05-1071 </papid>alkuhlani and habash, 2012).</citsent>
<aftsection>
<nextsent>as such, we expect it to perform worse than comparable pos tagging task.
</nextsent>
<nextsent>for example, habash and rambow (2005) <papid> P05-1071 </papid>report 98.2% and 98.8% for gen and num, respectively, compared to our 84.2% and 87.3%.in the context of specific application, the performance of the prediction could be improved using information other than the context of providedlemmas.</nextsent>
<nextsent>for example, in mt, source language lexical, syntactic and morphological information could be used in the prediction module (el kholy and habash, 2012).the morphology prediction step produces lattice with all the possible feature values each having an associated confidence score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3895">
<title id=" W12-1514.xml">rich morphology generation using statistical machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we report results on the arabic side of the 2005 nist mt evaluation set (mt05), our development set.
</prevsent>
<prevsent>we use the arabic side of mt06 nist dataset for blind test.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we evaluate using bleu-1 and bleu-4 (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>bleu is precision-based evaluation metric commonly used in mt research.given the way we define our generation task to exclude reordering and word deletion/addition, bleu 1 can be interpreted as measure of word accuracy.
</nextsent>
<nextsent>bleu-4 is the geometric mean of unigram, bigram, trigram and 4-gram precision.4 since arabic text 3http://www.ldc.upenn.edu 4n-gram precision is the number of test n-word sequences that appear in the reference divided by the number of all possible n-word sequences in the test.
</nextsent>
<nextsent>92 is generally written without diacritics, we evaluate on undiacritized text only.
</nextsent>
<nextsent>in the future, we plan to study generation into diacritized arabic, more challenging goal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3896">
<title id=" W11-2101.xml">a grain of salt for the wmt manual evaluation </title>
<section> for consistency with the wmt </section>
<citcontext>
<prevsection>
<prevsent>another popular (and cont rover sial) rule of thumb (krippendorff, 1980) is more strict and says that ?   0.67 is not suitable even for tentative conclusions.for this reason, and given that majority of sentences are indeed more than 10 words in length (the median is 20 words), we suggest that future evaluations either include fewer outputs per block, or divide longer sentences into shorter segments (e.g. on clause boundaries), so these segments are more easily and reliably comparable.
</prevsent>
<prevsent>the latter suggestions assumes word alignment as preprocessing and presenting the annotators the context of the judged segment.
</prevsent>
</prevsection>
<citsent citstr=" J08-4004 ">
2.2.2 estimating (e), the expected agreement by chance several agreement measures (usually called kap pas) were designed based on the equation 1 (see artstein and poesio (2008) <papid> J08-4004 </papid>and eugenio and glass (2004) for an overview and discussion).</citsent>
<aftsection>
<nextsent>those measures differ from each other in how to define the individual components of equation 2, and hence differ in what the expected agreement by chance (p (e)) would be:8 ? the measure (bennett et al, 1954) assumes uniform distribution over the categories.?
</nextsent>
<nextsent>scotts pi (scott, 1955) estimates the distribution empirically from actual annotation.?
</nextsent>
<nextsent>cohens ?
</nextsent>
<nextsent>(cohen, 1960) estimates the distribution empirically as well, and further assumes separate distribution for each annotator.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3897">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" P06-2095 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3898">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" W04-3208 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3902">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" J05-4003 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3904">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" L08-1111 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3905">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" P95-1050 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3906">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3908">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" P07-1084 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3909">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" N09-2031 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3910">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" C10-1073 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3911">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" P06-1011 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3918">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" N04-1034 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3919">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>parallel corpora have been extensively exploited in different ways in machine translation (mt) ? both in statistical (smt) and more recently, in rule-based (rbmt) architectures: in smt aligned parallel resources are used for building translation phrase tables and calculating translation probabilities; and in rbmt, they are used for automatically building bilingual dictionaries of translation equivalents and automatically deriving bilingual mappings for frequent structural patterns.
</prevsent>
<prevsent>however, large parallel resources are not always available, especially for under-resourcedlanguages or narrow domains.
</prevsent>
</prevsection>
<citsent citstr=" N10-1063 ">
therefore, in recent years, the use of cross-lingual comparable corpora has attracted considerable attention in the mt community (sharoff et al, 2006; <papid> P06-2095 </papid>fung and cheung, 2004<papid> W04-3208 </papid>a; munteanu and marcu, 2005; <papid> J05-4003 </papid>babych et al, 2008).<papid> L08-1111 </papid>most of the applications of comparable corpora focus on discovering translation equivalents to support machine translation, such as bilingual lexicon extraction (rapp, 1995; <papid> P95-1050 </papid>rapp, 1999; <papid> P99-1067 </papid>morin et al, 2007; <papid> P07-1084 </papid>yu and tsujii, 2009; <papid> N09-2031 </papid>li and gaussier, 2010; <papid> C10-1073 </papid>prachasson and fung, 2011), parallel phrase extraction (munteanu and marcu, 2006), <papid> P06-1011 </papid>and parallel sentence extraction (fung and cheung, 2004<papid> W04-3208 </papid>b; munteanu and marcu, 2005; <papid> J05-4003 </papid>munteanu et al, 2004; <papid> N04-1034 </papid>smith et al, 2010).<papid> N10-1063 </papid>comparability between documents is often understood as belonging to the same subject domain, genre or text type, so this definition relies on these vague linguistic concepts.</citsent>
<aftsection>
<nextsent>the problem with this definition then is that it cannot be exactly benchmarked, since it becomes hard to relate automated measures of comparability to such inexact and unmeasurable linguistic concepts.
</nextsent>
<nextsent>research on comparable corpora needs not only good measures for comparability, but also clearer, technologically grounded and quantifiable definition of comparability in the first place.in this paper we relate comparability to usefulness of comparable texts for mt. in particular, we propose performance-based definition of comparability, as the possibility to extract parallel or quasi-parallel translation equivalents ? words, phrases and sentences which are translations ofeach other.
</nextsent>
<nextsent>this definition directly relates comparability to texts?
</nextsent>
<nextsent>potential to improve the quality of mt by adding extracted phrases to phrase tables, training corpus or dictionaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3928">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> comparability metrics.  </section>
<citcontext>
<prevsection>
<prevsent>however, unlike the language pairs in which both languages are rich-resourced (e.g.,english-french, or english-spanish) and dictionary resources are relatively easy to obtain, it is likely that bilingual dictionaries with good word coverage are not publicly available for under resourced languages (e.g., english-slovenian, or english-lithuanian).
</prevsent>
<prevsent>in order to address this problem, we automatically construct dictionaries by using word alignment on large-scale parallel corpora (e.g., europarl and jrc-acquis2).
</prevsent>
</prevsection>
<citsent citstr=" P00-1056 ">
specifically, giza++ toolkit (och and ney,2000) <papid> P00-1056 </papid>with default setting is used for word alignment on the jrc-acquis parallel corpora (steinberger et al, 2006).</citsent>
<aftsection>
<nextsent>the aligned word pairs together with the alignment probabilities are then converted into dictionary entries.
</nextsent>
<nextsent>for example, in estonian-english language pair, the alignment example kompanii company 0.625?
</nextsent>
<nextsent>in the word alignment table means the estonian word kom panii?
</nextsent>
<nextsent>can be translated as (or aligned with) the english candidate word company?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3929">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> comparability metrics.  </section>
<citcontext>
<prevsection>
<prevsent>the lexical mapping based metric takes all the words in the text into account for comparability measure, but if we only retain small number of representative words (keywords) and discard allthe other less informative words in each document, can we judge the comparability of document pair by comparing these words?
</prevsent>
<prevsent>our intuition is that, if two document share more keywords, they should be more comparable.
</prevsent>
</prevsection>
<citsent citstr=" W03-1028 ">
to validate this, we then perform keyword extraction by using simple tfidf based approach, which has been shown effective for keyword or key phrase extraction from the texts (frank et al, 1999; hulth, 2003; <papid> W03-1028 </papid>liu et al, 2009).<papid> N09-1070 </papid></citsent>
<aftsection>
<nextsent>more specifically, the keyword based metric can be described as below.
</nextsent>
<nextsent>first, similar to the lexical mapping based metric, bilingual dictionaries are used to map non-english texts into english.
</nextsent>
<nextsent>thus, only the english resources are applied for stop-word filtering and word lemmatiza tion, which are useful text preprocessing steps for keyword extraction.
</nextsent>
<nextsent>we then use tfidf to measure the weight of words in the document and rank the words by their tfidf weights in descending order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3930">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> comparability metrics.  </section>
<citcontext>
<prevsection>
<prevsent>the lexical mapping based metric takes all the words in the text into account for comparability measure, but if we only retain small number of representative words (keywords) and discard allthe other less informative words in each document, can we judge the comparability of document pair by comparing these words?
</prevsent>
<prevsent>our intuition is that, if two document share more keywords, they should be more comparable.
</prevsent>
</prevsection>
<citsent citstr=" N09-1070 ">
to validate this, we then perform keyword extraction by using simple tfidf based approach, which has been shown effective for keyword or key phrase extraction from the texts (frank et al, 1999; hulth, 2003; <papid> W03-1028 </papid>liu et al, 2009).<papid> N09-1070 </papid></citsent>
<aftsection>
<nextsent>more specifically, the keyword based metric can be described as below.
</nextsent>
<nextsent>first, similar to the lexical mapping based metric, bilingual dictionaries are used to map non-english texts into english.
</nextsent>
<nextsent>thus, only the english resources are applied for stop-word filtering and word lemmatiza tion, which are useful text preprocessing steps for keyword extraction.
</nextsent>
<nextsent>we then use tfidf to measure the weight of words in the document and rank the words by their tfidf weights in descending order.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3931">
<title id=" W12-0102.xml">measuring comparability of documents in non parallel corpora for efficient extraction of semi parallel translation equivalents </title>
<section> comparability metrics.  </section>
<citcontext>
<prevsection>
<prevsent>named entity feature: named entities ofeach document.
</prevsent>
<prevsent>if more named entities co occur in two documents, they are very likely to talk about the same event or subject and6available at http://code.google.com/p/microsoft translator-java-api/ 13 thus should be more comparable.
</prevsent>
</prevsection>
<citsent citstr=" P05-1045 ">
we use stanford named entity recognizer7 to extract named entities from the texts (finkel et al,2005).<papid> P05-1045 </papid></citsent>
<aftsection>
<nextsent>again, cosine is then applied to measure the similarity of named entities (denoted by wn ) between document pair.
</nextsent>
<nextsent>we then combine these four different types of score in an ensemble manner.
</nextsent>
<nextsent>specifically, aweighted average strategy is applied: each individual score is associated with constant weight, indicating the relative confidence (importance) ofthe corresponding type of score.
</nextsent>
<nextsent>the overall comparability score (denoted by sc) of document pair is thus computed as below: sc = ? wl + ? ws + ? wk + ? wn where ?, ?, ?, and ? ?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3933">
<title id=" W12-1915.xml">combining the sparsity and un ambiguity biases for grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ten corpora of nine different languages are used in the challenge: arabic (hajic?
</prevsent>
<prevsent>et al, 2004), basque (aduriz et al, 2003), czech (hajic?
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
et al, 2000), danish (buch-kromann et al,2007), dutch (beek et al, 2002), english wsj (mar cus et al, 1993), <papid> J93-2004 </papid>english childes (sagae et al, 2007), <papid> W07-0604 </papid>portuguese (afonso et al, 2002), slovene (erjavec et al, 2010), and swedish (nivre et al, 2006).</citsent>
<aftsection>
<nextsent>for each corpus, large set of unannotated sentences are provided as the training data, along with small set of annotated sentences as the development data; the predictions on the unannotated test data submitted by challenge participants are evaluated against the gold standard annotations.we participate in the track of inducing dependency structures from gold standard part-of-speech tags.
</nextsent>
<nextsent>our system incorporates two types of inductive biases in learning dependency grammars: the spar sity bias and the un ambiguity bias.
</nextsent>
<nextsent>the sparsity bias favors grammar with fewer grammar rules.
</nextsent>
<nextsent>we employ two different approaches to inducing sparsity: dirichlet priors over grammar rule probabilities and an approach based on posterior regularization (gillenwater et al, 2010).<papid> P10-2036 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3934">
<title id=" W12-1915.xml">combining the sparsity and un ambiguity biases for grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ten corpora of nine different languages are used in the challenge: arabic (hajic?
</prevsent>
<prevsent>et al, 2004), basque (aduriz et al, 2003), czech (hajic?
</prevsent>
</prevsection>
<citsent citstr=" W07-0604 ">
et al, 2000), danish (buch-kromann et al,2007), dutch (beek et al, 2002), english wsj (mar cus et al, 1993), <papid> J93-2004 </papid>english childes (sagae et al, 2007), <papid> W07-0604 </papid>portuguese (afonso et al, 2002), slovene (erjavec et al, 2010), and swedish (nivre et al, 2006).</citsent>
<aftsection>
<nextsent>for each corpus, large set of unannotated sentences are provided as the training data, along with small set of annotated sentences as the development data; the predictions on the unannotated test data submitted by challenge participants are evaluated against the gold standard annotations.we participate in the track of inducing dependency structures from gold standard part-of-speech tags.
</nextsent>
<nextsent>our system incorporates two types of inductive biases in learning dependency grammars: the spar sity bias and the un ambiguity bias.
</nextsent>
<nextsent>the sparsity bias favors grammar with fewer grammar rules.
</nextsent>
<nextsent>we employ two different approaches to inducing sparsity: dirichlet priors over grammar rule probabilities and an approach based on posterior regularization (gillenwater et al, 2010).<papid> P10-2036 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3935">
<title id=" W12-1915.xml">combining the sparsity and un ambiguity biases for grammar induction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our system incorporates two types of inductive biases in learning dependency grammars: the spar sity bias and the un ambiguity bias.
</prevsent>
<prevsent>the sparsity bias favors grammar with fewer grammar rules.
</prevsent>
</prevsection>
<citsent citstr=" P10-2036 ">
we employ two different approaches to inducing sparsity: dirichlet priors over grammar rule probabilities and an approach based on posterior regularization (gillenwater et al, 2010).<papid> P10-2036 </papid></citsent>
<aftsection>
<nextsent>the un ambiguity bias favors grammar that leads to unambiguous parses, which is motivated by the observation that natural language is remarkably unambiguous in the sense that the number of plausible parses of natural language sentence is very small.
</nextsent>
<nextsent>to induce un ambiguity in the learned grammar we propose an approach named un ambiguity regularization based on the posterior regularization framework (ganchev etal., 2010).
</nextsent>
<nextsent>to combine dirichlet priors with unam 105biguity regularization, we derive mean-field variational inference algorithm.
</nextsent>
<nextsent>to combine the sparsityinducing posterior regularization approach with un ambiguity regularization, we employ simplistic approach that optimizes the two regularization terms separately.the rest of the paper is organized as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3941">
<title id=" W12-1915.xml">combining the sparsity and un ambiguity biases for grammar induction </title>
<section> un ambiguity bias.  </section>
<citcontext>
<prevsection>
<prevsent>the un ambiguity bias favors grammar that leads to unambiguous parses on natural language sentences (tu and honavar, 2012).
</prevsent>
<prevsent>this bias is motivated by the observation that natural language is remarkably unambiguous in the sense that the number of plausible parses of natural language sentence is very small in comparison with the total number of possible parses.
</prevsent>
</prevsection>
<citsent citstr=" P06-1055 ">
to illustrate this, we randomly sample an english sentence from thewall street journal and parse the sentence using the berkeley parser (petrovet al, 2006), <papid> P06-1055 </papid>one of the state-of-the-art english language parsers.</citsent>
<aftsection>
<nextsent>the estimated total number of possible parses of this sentence is 2 ? 1020 (by assuming complete chomsky normal form grammar with 106 0 20 40 60 80 1000 0.05 0.1 0.15 0.2 0.25 100 best parses.
</nextsent>
<nextsent>pro bab ility figure 1: the probabilities of the 100 best parses of the sample sentence.the same number of nonterminals as in the berkeley parser).
</nextsent>
<nextsent>however, as shown in figure 1, most of the parses have probabilities that are negligible compared with the probability of the best parse.
</nextsent>
<nextsent>to induce un ambiguity in the learned grammar,we derive an approach named un ambiguity regularization (tu and honavar, 2012) based on the posterior regularization framework (ganchev et al,2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3942">
<title id=" W12-1915.xml">combining the sparsity and un ambiguity biases for grammar induction </title>
<section> implementation and experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we trained our system on the fine pos tags except for the dutch corpus.
</prevsent>
<prevsent>in the dutch corpus, the finepos tags are the same as the coarse pos tags except that each multi-word unit is annotated with the concatenation of the pos tags of all the component words, making the training data for such tags extremely sparse.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
so we chose to use the coarse pos tags for the dutch corpus.we employed the informed initialization proposed in (klein and manning, 2004) <papid> P04-1061 </papid>and ran our two approaches on the training set.</citsent>
<aftsection>
<nextsent>we tuned the param 1available at http://code.google.com/p/ pr-toolkit/ eters by coordinate ascent on the development set.
</nextsent>
<nextsent>the parameters that we tuned include the maximal length of sentences used in training, the valence andback-off strength of the e-dmvmodel, the hyperparameter ? of dirichlet priors, the type (pr-s or pr as) and strength of sparsity-inducing posterior regularization, and the strength of unambiguityregularization.
</nextsent>
<nextsent>sparsity-inducing posterior regularization has high computational cost.
</nextsent>
<nextsent>consequently, we were not able to run our second approach on the english childes corpus and the czech corpus, and performed relatively limited parameter tuning of the second approach on the other eight corpora.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3943">
<title id=" W11-1811.xml">overview of bionlp 2011 protein coreference shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation results show that state-of-the-art performance on the task can find 22.18% of protein co references with the precision of 73.26%.
</prevsent>
<prevsent>analysis of the submissions shows that several types of anaphoric expressions including definite expressions, which occupies significant part of the problem, have not yet been solved.
</prevsent>
</prevsection>
<citsent citstr=" P10-1142 ">
while named entity recognition (ner) and relation or event extraction are regarded as standard tasksof information extraction (ie), coreference resolution (ng, 2010; <papid> P10-1142 </papid>bejan and harabagiu, 2010) <papid> P10-1143 </papid>is more and more recognized as an important component of ie for higher performance.</citsent>
<aftsection>
<nextsent>without coreference resolution, the performance of ie is often substantially limited due to an abundance of coreference structures in natural language text, i.e. information pieces written in text with involvement of coreference structure are hard to be captured (miwa et al,2010).
</nextsent>
<nextsent>there have been several attempts for coreference resolution, particularly for newswire texts (strassel et al, 2008; <papid> L08-1390 </papid>chinchor, 1998).<papid> M98-1001 </papid></nextsent>
<nextsent>it is also oneof the lessons from bionlp shared task (bionlp st, hereafter) 2009 that coreference structures in biomedical text substantially hinder the progress of fine-grained ie (kim et al, 2009).<papid> W09-1401 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3944">
<title id=" W11-1811.xml">overview of bionlp 2011 protein coreference shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>evaluation results show that state-of-the-art performance on the task can find 22.18% of protein co references with the precision of 73.26%.
</prevsent>
<prevsent>analysis of the submissions shows that several types of anaphoric expressions including definite expressions, which occupies significant part of the problem, have not yet been solved.
</prevsent>
</prevsection>
<citsent citstr=" P10-1143 ">
while named entity recognition (ner) and relation or event extraction are regarded as standard tasksof information extraction (ie), coreference resolution (ng, 2010; <papid> P10-1142 </papid>bejan and harabagiu, 2010) <papid> P10-1143 </papid>is more and more recognized as an important component of ie for higher performance.</citsent>
<aftsection>
<nextsent>without coreference resolution, the performance of ie is often substantially limited due to an abundance of coreference structures in natural language text, i.e. information pieces written in text with involvement of coreference structure are hard to be captured (miwa et al,2010).
</nextsent>
<nextsent>there have been several attempts for coreference resolution, particularly for newswire texts (strassel et al, 2008; <papid> L08-1390 </papid>chinchor, 1998).<papid> M98-1001 </papid></nextsent>
<nextsent>it is also oneof the lessons from bionlp shared task (bionlp st, hereafter) 2009 that coreference structures in biomedical text substantially hinder the progress of fine-grained ie (kim et al, 2009).<papid> W09-1401 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3945">
<title id=" W11-1811.xml">overview of bionlp 2011 protein coreference shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while named entity recognition (ner) and relation or event extraction are regarded as standard tasksof information extraction (ie), coreference resolution (ng, 2010; <papid> P10-1142 </papid>bejan and harabagiu, 2010) <papid> P10-1143 </papid>is more and more recognized as an important component of ie for higher performance.</prevsent>
<prevsent>without coreference resolution, the performance of ie is often substantially limited due to an abundance of coreference structures in natural language text, i.e. information pieces written in text with involvement of coreference structure are hard to be captured (miwa et al,2010).</prevsent>
</prevsection>
<citsent citstr=" L08-1390 ">
there have been several attempts for coreference resolution, particularly for newswire texts (strassel et al, 2008; <papid> L08-1390 </papid>chinchor, 1998).<papid> M98-1001 </papid></citsent>
<aftsection>
<nextsent>it is also oneof the lessons from bionlp shared task (bionlp st, hereafter) 2009 that coreference structures in biomedical text substantially hinder the progress of fine-grained ie (kim et al, 2009).<papid> W09-1401 </papid></nextsent>
<nextsent>to address the problem of coreference resolution in molecular biology literature, the protein coreference (coref) task is arranged in bionlp-st 2011 as supporting task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3946">
<title id=" W11-1811.xml">overview of bionlp 2011 protein coreference shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while named entity recognition (ner) and relation or event extraction are regarded as standard tasksof information extraction (ie), coreference resolution (ng, 2010; <papid> P10-1142 </papid>bejan and harabagiu, 2010) <papid> P10-1143 </papid>is more and more recognized as an important component of ie for higher performance.</prevsent>
<prevsent>without coreference resolution, the performance of ie is often substantially limited due to an abundance of coreference structures in natural language text, i.e. information pieces written in text with involvement of coreference structure are hard to be captured (miwa et al,2010).</prevsent>
</prevsection>
<citsent citstr=" M98-1001 ">
there have been several attempts for coreference resolution, particularly for newswire texts (strassel et al, 2008; <papid> L08-1390 </papid>chinchor, 1998).<papid> M98-1001 </papid></citsent>
<aftsection>
<nextsent>it is also oneof the lessons from bionlp shared task (bionlp st, hereafter) 2009 that coreference structures in biomedical text substantially hinder the progress of fine-grained ie (kim et al, 2009).<papid> W09-1401 </papid></nextsent>
<nextsent>to address the problem of coreference resolution in molecular biology literature, the protein coreference (coref) task is arranged in bionlp-st 2011 as supporting task.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3948">
<title id=" W11-1811.xml">overview of bionlp 2011 protein coreference shared task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>without coreference resolution, the performance of ie is often substantially limited due to an abundance of coreference structures in natural language text, i.e. information pieces written in text with involvement of coreference structure are hard to be captured (miwa et al,2010).
</prevsent>
<prevsent>there have been several attempts for coreference resolution, particularly for newswire texts (strassel et al, 2008; <papid> L08-1390 </papid>chinchor, 1998).<papid> M98-1001 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
it is also oneof the lessons from bionlp shared task (bionlp st, hereafter) 2009 that coreference structures in biomedical text substantially hinder the progress of fine-grained ie (kim et al, 2009).<papid> W09-1401 </papid></citsent>
<aftsection>
<nextsent>to address the problem of coreference resolution in molecular biology literature, the protein coreference (coref) task is arranged in bionlp-st 2011 as supporting task.
</nextsent>
<nextsent>while the task itself is notan ie task, it is expected to be useful component in performing the main ie tasks more effectively.
</nextsent>
<nextsent>to establish stable evaluation and to observe the effect of the results of the task to the main ietasks, the coref task particularly focuses on finding anaphoric protein references.the benchmark datasets for developing and testing coreference resolution system were developed based on various manual annotations made to the genia corpus (ohta et al, 2002).
</nextsent>
<nextsent>after 7 weeks of system development phase, for which training and development datasets with coreference annotation were given, six teams submitted their prediction ofcoreferences for the test data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3949">
<title id=" W11-1811.xml">overview of bionlp 2011 protein coreference shared task </title>
<section> data preparation.  </section>
<citcontext>
<prevsection>
<prevsent>however, those not involving specific protein references are also provided in the training data to help system development, and will be considered in the secondary evaluation mode.
</prevsent>
<prevsent>see section 5 for more detail.
</prevsent>
</prevsection>
<citsent citstr=" I05-2038 ">
the datasets for the coref task are produced based on three resources: medco coreference annotation (su et al, 2008), genia event annotation (kim et al, 2008), and genia treebank (tateisi et al., 2005).<papid> I05-2038 </papid></citsent>
<aftsection>
<nextsent>although the three have been developed independently from each other, they are annotations made to the same corpus, the genia corpus (kim et al., 2008).
</nextsent>
<nextsent>since coref was focused on finding anaphoric references to proteins (or genes), only relevant annotations were extracted from the medco corpus though the following process: 1.
</nextsent>
<nextsent>from medco annotation, coreference entities that.
</nextsent>
<nextsent>were pronouns and definite base nps were extracted, which became candidate anaphoric expressions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3950">
<title id=" W11-1811.xml">overview of bionlp 2011 protein coreference shared task </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>if protein-name-embedding an teceden is connected to an anaphora through more than one surface link, we call it an indirect protein antecedent, and the antecedents in the middle of the chain intermediate antecedents.
</prevsent>
<prevsent>the performance evaluated in this mode may be directly connected to the potential performance in main ie tasks: the more the (anaphoric) protein references are found, the more the protein-related events may be found.for this reason, the protein coreference mode is chosen as the primary evaluation mode.
</prevsent>
</prevsection>
<citsent citstr=" W97-1306 ">
evaluation results for both evaluation modes are 76 given in traditional precision, recall and f-score, which are similar to (baldwin, 1997).<papid> W97-1306 </papid></citsent>
<aftsection>
<nextsent>5.1 surface coreference.
</nextsent>
<nextsent>a response expression is matched with gold expression following partial match criterion.
</nextsent>
<nextsent>in particular, response expression is considered correct when it covers the minimal boundary, and is included in the maximal boundary of expression.maximal boundary is the span of expression annotation, and minimal boundary is the head of expression, as defined in muc annotation schemes (chinchor, 1998).<papid> M98-1001 </papid></nextsent>
<nextsent>a response link is correct when its two argument expressions are correctly matched with those of gold link.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3953">
<title id=" W11-1811.xml">overview of bionlp 2011 protein coreference shared task </title>
<section> participation.  </section>
<citcontext>
<prevsection>
<prevsent>total number of gold link = 284.
</prevsent>
<prevsent>resp=response, c=correct, p=precision, r=recall, f=fscore the tool column shows the external tools used in resolution processing.
</prevsent>
</prevsection>
<citsent citstr=" P10-2029 ">
among these tools,there is only one team used an external coreference resolution framework, reconcile, which achieved the state-of-the-art performance for supervised learning-based coreference resolution (stoy anov et al, 2010<papid> P10-2029 </papid>b).</citsent>
<aftsection>
<nextsent>7.1 protein coreference results.
</nextsent>
<nextsent>evaluation results in the protein coreference modeare shown in table 3.
</nextsent>
<nextsent>the uu team got the highest f-score 34.05%.
</nextsent>
<nextsent>the uz and cu teams are the second- and third-best teams with 30.96% and29.65% f-score correspondingly, which are comparable to each other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3954">
<title id=" W11-1811.xml">overview of bionlp 2011 protein coreference shared task </title>
<section> analysis.  </section>
<citcontext>
<prevsection>
<prevsent>we have to seek for better method for solving the dnp links, in order to significantly improve protein coreference resolution system.
</prevsent>
<prevsent>concerning the pron type, table 8 shows that except for that-1, no other figures are higher than50 percent f-score.
</prevsent>
</prevsection>
<citsent citstr=" D10-1048 ">
this is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains(raghunathan et al, 2010), <papid> D10-1048 </papid>and also on other bio data (hsiang lin and liang, 2004).</citsent>
<aftsection>
<nextsent>one of the reasons for the low recall is because target anaphoric pronouns in the bio domain are neutral gender and third-person pronouns(nguyen and kim, 2008), <papid> C08-1079 </papid>which are difficult to resolve than other types of pronouns(stoyanov et al, 2010<papid> P10-2029 </papid>a).</nextsent>
<nextsent>8.3 protein coreference analysis - intermediate.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3955">
<title id=" W11-1811.xml">overview of bionlp 2011 protein coreference shared task </title>
<section> analysis.  </section>
<citcontext>
<prevsection>
<prevsent>concerning the pron type, table 8 shows that except for that-1, no other figures are higher than50 percent f-score.
</prevsent>
<prevsent>this is an interesting observation because pronominal anaphora problem has been reported with much higher results on other domains(raghunathan et al, 2010), <papid> D10-1048 </papid>and also on other bio data (hsiang lin and liang, 2004).</prevsent>
</prevsection>
<citsent citstr=" C08-1079 ">
one of the reasons for the low recall is because target anaphoric pronouns in the bio domain are neutral gender and third-person pronouns(nguyen and kim, 2008), <papid> C08-1079 </papid>which are difficult to resolve than other types of pronouns(stoyanov et al, 2010<papid> P10-2029 </papid>a).</citsent>
<aftsection>
<nextsent>8.3 protein coreference analysis - intermediate.
</nextsent>
<nextsent>antecedent as mentioned in the task setting, anaphors can directly link to their antecedent, or indirectly link via one or more intermediate antecedents.
</nextsent>
<nextsent>we counted the numbers of correct direct and indirect protein coreference links in each submission (table 12).
</nextsent>
<nextsent>80 subtype type count subtype type count subtype type count both 1 pron 2 both 2 pron 4 either 1 pron 0 it 1 pron 17 its 1 pron 61 one 2 pron 1 such 2 dnp 2 that 1 relat 37 the 2 dnp 20 their 1 pron 27 them 1 pron 1 these 1 pron 1 these 2 dnp 26 they 1 pron 5 this 1 pron 1 this 2 dnp 20 those 1 pron 9 which 1 relat 37 whose 1 relat 1 whose 2 relat 0 (others) n/c 11 table 10: mapping from subtype to coreference type.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3957">
<title id=" W12-2001.xml">question ranking and selection in tutorial dialogues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moment.
</prevsent>
<prevsent>numerous studies have illustrated the effectiveness of socratic-style tutoring (vanlehn et al, 2007; rose et al, 2001; collins and stevens, 1982); consequently recreating the behavior on computer has long been goal of research in intelligent tutoring systems (its).
</prevsent>
</prevsection>
<citsent citstr=" N04-3002 ">
recent successes have shown the efficacy of conversational its (graesser et al, 2005; litman and silliman, 2004; <papid> N04-3002 </papid>ward et al, 2011<papid> W11-1417 </papid>b), however these systems are still not as effective as human tutors, and much improvement is needed before they can truly claim to be socratic.</citsent>
<aftsection>
<nextsent>furthermore, development and tuning of tutorial dialogue behavior requires significant human effort.
</nextsent>
<nextsent>while our overarching goal is to improve its by automatically learning tutorial dialogue strategies directly from expert tutor behavior, we focus on the crucial subtask of selecting follow-up questions.
</nextsent>
<nextsent>although asking questions is only subset of the over all tutoring process, it is still complex process that requires understanding of the dialogue state, the students ability, and the learning goals.
</nextsent>
<nextsent>this work frames question selection as task of scoring and ranking candidate questions for specific point in the tutorial dialogue.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3958">
<title id=" W12-2001.xml">question ranking and selection in tutorial dialogues </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>moment.
</prevsent>
<prevsent>numerous studies have illustrated the effectiveness of socratic-style tutoring (vanlehn et al, 2007; rose et al, 2001; collins and stevens, 1982); consequently recreating the behavior on computer has long been goal of research in intelligent tutoring systems (its).
</prevsent>
</prevsection>
<citsent citstr=" W11-1417 ">
recent successes have shown the efficacy of conversational its (graesser et al, 2005; litman and silliman, 2004; <papid> N04-3002 </papid>ward et al, 2011<papid> W11-1417 </papid>b), however these systems are still not as effective as human tutors, and much improvement is needed before they can truly claim to be socratic.</citsent>
<aftsection>
<nextsent>furthermore, development and tuning of tutorial dialogue behavior requires significant human effort.
</nextsent>
<nextsent>while our overarching goal is to improve its by automatically learning tutorial dialogue strategies directly from expert tutor behavior, we focus on the crucial subtask of selecting follow-up questions.
</nextsent>
<nextsent>although asking questions is only subset of the over all tutoring process, it is still complex process that requires understanding of the dialogue state, the students ability, and the learning goals.
</nextsent>
<nextsent>this work frames question selection as task of scoring and ranking candidate questions for specific point in the tutorial dialogue.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3960">
<title id=" W12-2001.xml">question ranking and selection in tutorial dialogues </title>
<section> background and related works.  </section>
<citcontext>
<prevsection>
<prevsent>however, these approaches are typically optimized to maximize learning gains, andare not necessarily focused on replicating human tutor behavior.
</prevsent>
<prevsent>other work has explored specific factors in questioning such as when to ask why?
</prevsent>
</prevsection>
<citsent citstr=" N10-1086 ">
questions (rose et al, 2003), provide hints (tsovaltzi and matheson, 2001), or insert discourse markers (kim et al, 2000).there is also an expanding body of work that applies ranking algorithms toward the task of question generation (qg) using approaches such as over generation-and-ranking (heilman and smith, 2010),<papid> N10-1086 </papid>language model ranking (yao, 2010), and heuristics based ranking (agarwal and mannem, 2011).<papid> W11-1407 </papid></citsent>
<aftsection>
<nextsent>while the focus of these efforts centers on issues of grammaticality, fluency, and content selection for automatic creation of standalone questions, we move tothe higher level task of choosing context appropriate questions.
</nextsent>
<nextsent>our work merges aspects of theseqg approaches with the sentence planning tradition from natural language generation (walker et al, 2001; <papid> N01-1003 </papid>rambow et al, 2001).<papid> P01-1056 </papid></nextsent>
<nextsent>in sentence planning the goal is to select lexico-structural resources that encode communicative action.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3961">
<title id=" W12-2001.xml">question ranking and selection in tutorial dialogues </title>
<section> background and related works.  </section>
<citcontext>
<prevsection>
<prevsent>however, these approaches are typically optimized to maximize learning gains, andare not necessarily focused on replicating human tutor behavior.
</prevsent>
<prevsent>other work has explored specific factors in questioning such as when to ask why?
</prevsent>
</prevsection>
<citsent citstr=" W11-1407 ">
questions (rose et al, 2003), provide hints (tsovaltzi and matheson, 2001), or insert discourse markers (kim et al, 2000).there is also an expanding body of work that applies ranking algorithms toward the task of question generation (qg) using approaches such as over generation-and-ranking (heilman and smith, 2010),<papid> N10-1086 </papid>language model ranking (yao, 2010), and heuristics based ranking (agarwal and mannem, 2011).<papid> W11-1407 </papid></citsent>
<aftsection>
<nextsent>while the focus of these efforts centers on issues of grammaticality, fluency, and content selection for automatic creation of standalone questions, we move tothe higher level task of choosing context appropriate questions.
</nextsent>
<nextsent>our work merges aspects of theseqg approaches with the sentence planning tradition from natural language generation (walker et al, 2001; <papid> N01-1003 </papid>rambow et al, 2001).<papid> P01-1056 </papid></nextsent>
<nextsent>in sentence planning the goal is to select lexico-structural resources that encode communicative action.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3962">
<title id=" W12-2001.xml">question ranking and selection in tutorial dialogues </title>
<section> background and related works.  </section>
<citcontext>
<prevsection>
<prevsent>questions (rose et al, 2003), provide hints (tsovaltzi and matheson, 2001), or insert discourse markers (kim et al, 2000).there is also an expanding body of work that applies ranking algorithms toward the task of question generation (qg) using approaches such as over generation-and-ranking (heilman and smith, 2010),<papid> N10-1086 </papid>language model ranking (yao, 2010), and heuristics based ranking (agarwal and mannem, 2011).<papid> W11-1407 </papid></prevsent>
<prevsent>while the focus of these efforts centers on issues of grammaticality, fluency, and content selection for automatic creation of standalone questions, we move tothe higher level task of choosing context appropriate questions.</prevsent>
</prevsection>
<citsent citstr=" N01-1003 ">
our work merges aspects of theseqg approaches with the sentence planning tradition from natural language generation (walker et al, 2001; <papid> N01-1003 </papid>rambow et al, 2001).<papid> P01-1056 </papid></citsent>
<aftsection>
<nextsent>in sentence planning the goal is to select lexico-structural resources that encode communicative action.
</nextsent>
<nextsent>rather than selecting representations, we use them directly as part of the feature space for learning functions to rank the questions?
</nextsent>
<nextsent>actual surface form realization.
</nextsent>
<nextsent>to our knowledge there has been no research in ranking the quality and suitability of questions within tutorial dialogue context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3963">
<title id=" W12-2001.xml">question ranking and selection in tutorial dialogues </title>
<section> background and related works.  </section>
<citcontext>
<prevsection>
<prevsent>questions (rose et al, 2003), provide hints (tsovaltzi and matheson, 2001), or insert discourse markers (kim et al, 2000).there is also an expanding body of work that applies ranking algorithms toward the task of question generation (qg) using approaches such as over generation-and-ranking (heilman and smith, 2010),<papid> N10-1086 </papid>language model ranking (yao, 2010), and heuristics based ranking (agarwal and mannem, 2011).<papid> W11-1407 </papid></prevsent>
<prevsent>while the focus of these efforts centers on issues of grammaticality, fluency, and content selection for automatic creation of standalone questions, we move tothe higher level task of choosing context appropriate questions.</prevsent>
</prevsection>
<citsent citstr=" P01-1056 ">
our work merges aspects of theseqg approaches with the sentence planning tradition from natural language generation (walker et al, 2001; <papid> N01-1003 </papid>rambow et al, 2001).<papid> P01-1056 </papid></citsent>
<aftsection>
<nextsent>in sentence planning the goal is to select lexico-structural resources that encode communicative action.
</nextsent>
<nextsent>rather than selecting representations, we use them directly as part of the feature space for learning functions to rank the questions?
</nextsent>
<nextsent>actual surface form realization.
</nextsent>
<nextsent>to our knowledge there has been no research in ranking the quality and suitability of questions within tutorial dialogue context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3965">
<title id=" W12-2001.xml">question ranking and selection in tutorial dialogues </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>instead of using one label, discuss move is tuple composed of three dimensions: dialogue act, rhetorical form, predicate type.
</prevsent>
<prevsent>together these labels account for the action, function, and content of an utterance.
</prevsent>
</prevsection>
<citsent citstr=" W04-2307 ">
this scheme draws from past work in task-oriented dialogue acts (bunt, 2009; core and allen, 1997), tutorial act taxonomies (pilkington, 1999; tsovaltzi and karagjosova, 2004; <papid> W04-2307 </papid>buckley and wolska, 2008; <papid> C08-1010 </papid>boyer et al, 2009b) discourse relations (mann and thompson, 1986) and question taxonomies (graesser and person, 1994; nielsen et al., 2008).dialogue act (22 tags): the dialogue act dimension is the top-level dimension in discuss, and its values govern the possible values for the other di mensions.</citsent>
<aftsection>
<nextsent>though the discuss dialogue act layer seeks to replicate the learnings from other well established taxonomies like dit++ (bunt, 2009) or damsl (core and allen, 1997) wherever possible,the qta style of pedagogy driving our tutoring sessions dictated the addition of two tutorial specific acts: marking and revoicing.
</nextsent>
<nextsent>a mark act highlights key words from the students speech to draw attention to particular term or concept.
</nextsent>
<nextsent>like with marking, re voicing keys in on student language, but instead of highlighting specific words, revoice act will summarize or refine the students language to bring clarity to concept.rhetorical form (22 tags): although the dialogue act is useful for identifying the speakers intent, it gives no indication of how the speaker is advancing the conversation.
</nextsent>
<nextsent>the rhetorical form refines the dialogue act by providing link to its surface form realization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3966">
<title id=" W12-2001.xml">question ranking and selection in tutorial dialogues </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>instead of using one label, discuss move is tuple composed of three dimensions: dialogue act, rhetorical form, predicate type.
</prevsent>
<prevsent>together these labels account for the action, function, and content of an utterance.
</prevsent>
</prevsection>
<citsent citstr=" C08-1010 ">
this scheme draws from past work in task-oriented dialogue acts (bunt, 2009; core and allen, 1997), tutorial act taxonomies (pilkington, 1999; tsovaltzi and karagjosova, 2004; <papid> W04-2307 </papid>buckley and wolska, 2008; <papid> C08-1010 </papid>boyer et al, 2009b) discourse relations (mann and thompson, 1986) and question taxonomies (graesser and person, 1994; nielsen et al., 2008).dialogue act (22 tags): the dialogue act dimension is the top-level dimension in discuss, and its values govern the possible values for the other di mensions.</citsent>
<aftsection>
<nextsent>though the discuss dialogue act layer seeks to replicate the learnings from other well established taxonomies like dit++ (bunt, 2009) or damsl (core and allen, 1997) wherever possible,the qta style of pedagogy driving our tutoring sessions dictated the addition of two tutorial specific acts: marking and revoicing.
</nextsent>
<nextsent>a mark act highlights key words from the students speech to draw attention to particular term or concept.
</nextsent>
<nextsent>like with marking, re voicing keys in on student language, but instead of highlighting specific words, revoice act will summarize or refine the students language to bring clarity to concept.rhetorical form (22 tags): although the dialogue act is useful for identifying the speakers intent, it gives no indication of how the speaker is advancing the conversation.
</nextsent>
<nextsent>the rhetorical form refines the dialogue act by providing link to its surface form realization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3967">
<title id=" W12-2001.xml">question ranking and selection in tutorial dialogues </title>
<section> data collection.  </section>
<citcontext>
<prevsection>
<prevsent>this consisted of 18 doubly annotated transcripts comprised of 828 dialogue utterances.
</prevsent>
<prevsent>to assess inter-rater reliability we use cohens kappa (?)
</prevsent>
</prevsection>
<citsent citstr=" J96-2004 ">
(carletta, 1996).<papid> J96-2004 </papid></citsent>
<aftsection>
<nextsent>because discuss permits multiple labels per instance, we compute ? value for each label and provide mean for each discuss dimension.
</nextsent>
<nextsent>to get an additional sense of agreement, we use two other metrics: exact agreement and partial agreement.
</nextsent>
<nextsent>for each of these metrics, we treat each annotators?
</nextsent>
<nextsent>annotations as per class bag-of-labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3970">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the difference from the baseline moses-based translation system lies in the pre-translation step, in which we introduce discriminative source string permutation model based on probabilistic parse tree transduction.
</prevsent>
<prevsent>the idea here is to permute the order of the source words in such way that the resulting permutation allows as monotone translation process as possible is not new.
</prevsent>
</prevsection>
<citsent citstr=" C10-1043 ">
this approach to enhance smt by using reordering step prior to translation has proved to be successful in improving translation quality for many translation tasks, see (genzel, 2010; <papid> C10-1043 </papid>costa-jussa` and fonollosa, 2006; collins et al, 2005), <papid> P05-1066 </papid>for example.</citsent>
<aftsection>
<nextsent>the general problem of source-side reordering is that the number of permutations is facto rial in n, and learning sequence of transductions for explaining source permutation can be computationally rather challenging.
</nextsent>
<nextsent>we propose to address this problem by defining the source-side permutation process as the learning problem of how to transfer given source parse tree into parse tree that minimizes the divergence from target word order.
</nextsent>
<nextsent>our reordering system is inspired by the direction taken in (tromble and eisner, 2009), <papid> D09-1105 </papid>but differs in defining the space of permutations, using local probabilistic tree transductions, as well as in the learning objective aiming at scoring permutations based on log-linear interpolation of local syntax-based model with global string-based (language) model.</nextsent>
<nextsent>the reordering (novel) and translation (standard) components are described in the following sections.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3971">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the difference from the baseline moses-based translation system lies in the pre-translation step, in which we introduce discriminative source string permutation model based on probabilistic parse tree transduction.
</prevsent>
<prevsent>the idea here is to permute the order of the source words in such way that the resulting permutation allows as monotone translation process as possible is not new.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
this approach to enhance smt by using reordering step prior to translation has proved to be successful in improving translation quality for many translation tasks, see (genzel, 2010; <papid> C10-1043 </papid>costa-jussa` and fonollosa, 2006; collins et al, 2005), <papid> P05-1066 </papid>for example.</citsent>
<aftsection>
<nextsent>the general problem of source-side reordering is that the number of permutations is facto rial in n, and learning sequence of transductions for explaining source permutation can be computationally rather challenging.
</nextsent>
<nextsent>we propose to address this problem by defining the source-side permutation process as the learning problem of how to transfer given source parse tree into parse tree that minimizes the divergence from target word order.
</nextsent>
<nextsent>our reordering system is inspired by the direction taken in (tromble and eisner, 2009), <papid> D09-1105 </papid>but differs in defining the space of permutations, using local probabilistic tree transductions, as well as in the learning objective aiming at scoring permutations based on log-linear interpolation of local syntax-based model with global string-based (language) model.</nextsent>
<nextsent>the reordering (novel) and translation (standard) components are described in the following sections.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3972">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the general problem of source-side reordering is that the number of permutations is facto rial in n, and learning sequence of transductions for explaining source permutation can be computationally rather challenging.
</prevsent>
<prevsent>we propose to address this problem by defining the source-side permutation process as the learning problem of how to transfer given source parse tree into parse tree that minimizes the divergence from target word order.
</prevsent>
</prevsection>
<citsent citstr=" D09-1105 ">
our reordering system is inspired by the direction taken in (tromble and eisner, 2009), <papid> D09-1105 </papid>but differs in defining the space of permutations, using local probabilistic tree transductions, as well as in the learning objective aiming at scoring permutations based on log-linear interpolation of local syntax-based model with global string-based (language) model.</citsent>
<aftsection>
<nextsent>the reordering (novel) and translation (standard) components are described in the following sections.
</nextsent>
<nextsent>the rest of this paper is structured as follows.
</nextsent>
<nextsent>after abrief description of the phrase-based translation system in section 2, we present the architecture and details of our reordering system (section 3), section 4reviews related work, section 5 reports the experimental setup, details the submissions and discusses the results, while section 6 concludes the article.
</nextsent>
<nextsent>2.1 statistical machine translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3973">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>= argmaxt { p(t|s) } = argmaxt { p(s|t) ? p(t) }.
</prevsent>
<prevsent>2.2 phrase-based translation.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
while first systems following this approach performed translation on the word level, modern state of-the-art phrase-based smt systems (och and ney,2002; <papid> P02-1038 </papid>koehn et al, 2003) <papid> N03-1017 </papid>start-out from word aligned parallel corpus working with (in principle)arbitrarily large phrase pairs (also called blocks) acquired from word-aligned parallel data under simple definition of translational equivalence (zens et al., 2002).</citsent>
<aftsection>
<nextsent>the conditional probabilities of one phrase given its counterpart is estimated as the relative frequency ratio of the phrases in the multi set of phrase-pairsextracted from the parallel corpus and are interpolated log-linearly together with set of other model estimates: ei1 = argmaxei1 { m?
</nextsent>
<nextsent>m=1 mhm(ei1, fj1 ) } (1) where feature function hm refer to system model, and the corresponding refers to the relative weight given to this model.a phrase-based system employs feature functions for phrase pair translation model, language model, reordering model, and model to score translation hypothesis according to length.the weights are optimized for system performance (och, 2003) <papid> P03-1021 </papid>as measured by bleu (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
<nextsent>apart from the novel syntax-based reordering model, we consider two reordering methods that are widely used in phrase-based systems: simpledistance-based reordering and lexicalized block oriented data-driven reordering model (tillman, 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3974">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>= argmaxt { p(t|s) } = argmaxt { p(s|t) ? p(t) }.
</prevsent>
<prevsent>2.2 phrase-based translation.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
while first systems following this approach performed translation on the word level, modern state of-the-art phrase-based smt systems (och and ney,2002; <papid> P02-1038 </papid>koehn et al, 2003) <papid> N03-1017 </papid>start-out from word aligned parallel corpus working with (in principle)arbitrarily large phrase pairs (also called blocks) acquired from word-aligned parallel data under simple definition of translational equivalence (zens et al., 2002).</citsent>
<aftsection>
<nextsent>the conditional probabilities of one phrase given its counterpart is estimated as the relative frequency ratio of the phrases in the multi set of phrase-pairsextracted from the parallel corpus and are interpolated log-linearly together with set of other model estimates: ei1 = argmaxei1 { m?
</nextsent>
<nextsent>m=1 mhm(ei1, fj1 ) } (1) where feature function hm refer to system model, and the corresponding refers to the relative weight given to this model.a phrase-based system employs feature functions for phrase pair translation model, language model, reordering model, and model to score translation hypothesis according to length.the weights are optimized for system performance (och, 2003) <papid> P03-1021 </papid>as measured by bleu (papineni et al, 2002).<papid> P02-1040 </papid></nextsent>
<nextsent>apart from the novel syntax-based reordering model, we consider two reordering methods that are widely used in phrase-based systems: simpledistance-based reordering and lexicalized block oriented data-driven reordering model (tillman, 2004).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3975">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>while first systems following this approach performed translation on the word level, modern state of-the-art phrase-based smt systems (och and ney,2002; <papid> P02-1038 </papid>koehn et al, 2003) <papid> N03-1017 </papid>start-out from word aligned parallel corpus working with (in principle)arbitrarily large phrase pairs (also called blocks) acquired from word-aligned parallel data under simple definition of translational equivalence (zens et al., 2002).</prevsent>
<prevsent>the conditional probabilities of one phrase given its counterpart is estimated as the relative frequency ratio of the phrases in the multi set of phrase-pairsextracted from the parallel corpus and are interpolated log-linearly together with set of other model estimates: ei1 = argmaxei1 { m?</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
m=1 mhm(ei1, fj1 ) } (1) where feature function hm refer to system model, and the corresponding refers to the relative weight given to this model.a phrase-based system employs feature functions for phrase pair translation model, language model, reordering model, and model to score translation hypothesis according to length.the weights are optimized for system performance (och, 2003) <papid> P03-1021 </papid>as measured by bleu (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>apart from the novel syntax-based reordering model, we consider two reordering methods that are widely used in phrase-based systems: simpledistance-based reordering and lexicalized block oriented data-driven reordering model (tillman, 2004).
</nextsent>
<nextsent>we approach the word order challenge by including syntactic information in pre-translation reordering framework.
</nextsent>
<nextsent>this section details the general idea of our approach and details the reordering model that was used in english-to-german experiments.
</nextsent>
<nextsent>3.1 pre-translation reordering framework.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3976">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>while first systems following this approach performed translation on the word level, modern state of-the-art phrase-based smt systems (och and ney,2002; <papid> P02-1038 </papid>koehn et al, 2003) <papid> N03-1017 </papid>start-out from word aligned parallel corpus working with (in principle)arbitrarily large phrase pairs (also called blocks) acquired from word-aligned parallel data under simple definition of translational equivalence (zens et al., 2002).</prevsent>
<prevsent>the conditional probabilities of one phrase given its counterpart is estimated as the relative frequency ratio of the phrases in the multi set of phrase-pairsextracted from the parallel corpus and are interpolated log-linearly together with set of other model estimates: ei1 = argmaxei1 { m?</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
m=1 mhm(ei1, fj1 ) } (1) where feature function hm refer to system model, and the corresponding refers to the relative weight given to this model.a phrase-based system employs feature functions for phrase pair translation model, language model, reordering model, and model to score translation hypothesis according to length.the weights are optimized for system performance (och, 2003) <papid> P03-1021 </papid>as measured by bleu (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>apart from the novel syntax-based reordering model, we consider two reordering methods that are widely used in phrase-based systems: simpledistance-based reordering and lexicalized block oriented data-driven reordering model (tillman, 2004).
</nextsent>
<nextsent>we approach the word order challenge by including syntactic information in pre-translation reordering framework.
</nextsent>
<nextsent>this section details the general idea of our approach and details the reordering model that was used in english-to-german experiments.
</nextsent>
<nextsent>3.1 pre-translation reordering framework.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3978">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>415
</prevsent>
<prevsent>the integration of linguistic syntax into smt systems offers potential solution to reordering problem.
</prevsent>
</prevsection>
<citsent citstr=" W06-3119 ">
for example, syntax is successfully integrated into hierarchical smt (zollmann and venugopal,2006).<papid> W06-3119 </papid></citsent>
<aftsection>
<nextsent>in (yamada and knight, 2001), <papid> P01-1067 </papid>set of tree string channel operations is defined over the parse tree nodes, while reordering is modeled by permutations of children nodes.</nextsent>
<nextsent>similarly, the tree-to-stringsyntax-based transduction approach offers complete translation framework (galley et al, 2006).<papid> P06-1121 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3979">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the integration of linguistic syntax into smt systems offers potential solution to reordering problem.
</prevsent>
<prevsent>for example, syntax is successfully integrated into hierarchical smt (zollmann and venugopal,2006).<papid> W06-3119 </papid></prevsent>
</prevsection>
<citsent citstr=" P01-1067 ">
in (yamada and knight, 2001), <papid> P01-1067 </papid>set of tree string channel operations is defined over the parse tree nodes, while reordering is modeled by permutations of children nodes.</citsent>
<aftsection>
<nextsent>similarly, the tree-to-stringsyntax-based transduction approach offers complete translation framework (galley et al, 2006).<papid> P06-1121 </papid></nextsent>
<nextsent>the idea of augmenting smt by reordering step prior to translation has often been shown to improve translation quality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3980">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>for example, syntax is successfully integrated into hierarchical smt (zollmann and venugopal,2006).<papid> W06-3119 </papid></prevsent>
<prevsent>in (yamada and knight, 2001), <papid> P01-1067 </papid>set of tree string channel operations is defined over the parse tree nodes, while reordering is modeled by permutations of children nodes.</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
similarly, the tree-to-stringsyntax-based transduction approach offers complete translation framework (galley et al, 2006).<papid> P06-1121 </papid></citsent>
<aftsection>
<nextsent>the idea of augmenting smt by reordering step prior to translation has often been shown to improve translation quality.
</nextsent>
<nextsent>clause restructuring performed with hand-crafted reordering rules for german-to english and chinese-to-english tasks are presentedin (collins et al, 2005) <papid> P05-1066 </papid>and (wang et al, 2007), <papid> D07-1077 </papid>re spectively.</nextsent>
<nextsent>in (xia and mccord, 2004; <papid> C04-1073 </papid>khalilov, 2009) word reordering is addressed by exploiting syntactic representations of source and target texts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3982">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>similarly, the tree-to-stringsyntax-based transduction approach offers complete translation framework (galley et al, 2006).<papid> P06-1121 </papid></prevsent>
<prevsent>the idea of augmenting smt by reordering step prior to translation has often been shown to improve translation quality.</prevsent>
</prevsection>
<citsent citstr=" D07-1077 ">
clause restructuring performed with hand-crafted reordering rules for german-to english and chinese-to-english tasks are presentedin (collins et al, 2005) <papid> P05-1066 </papid>and (wang et al, 2007), <papid> D07-1077 </papid>re spectively.</citsent>
<aftsection>
<nextsent>in (xia and mccord, 2004; <papid> C04-1073 </papid>khalilov, 2009) word reordering is addressed by exploiting syntactic representations of source and target texts.</nextsent>
<nextsent>in (costa-jussa` and fonollosa, 2006) source and target word order harmonization is done using well established smt techniques and without the use of syntactic knowledge.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3983">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the idea of augmenting smt by reordering step prior to translation has often been shown to improve translation quality.
</prevsent>
<prevsent>clause restructuring performed with hand-crafted reordering rules for german-to english and chinese-to-english tasks are presentedin (collins et al, 2005) <papid> P05-1066 </papid>and (wang et al, 2007), <papid> D07-1077 </papid>re spectively.</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
in (xia and mccord, 2004; <papid> C04-1073 </papid>khalilov, 2009) word reordering is addressed by exploiting syntactic representations of source and target texts.</citsent>
<aftsection>
<nextsent>in (costa-jussa` and fonollosa, 2006) source and target word order harmonization is done using well established smt techniques and without the use of syntactic knowledge.
</nextsent>
<nextsent>other reordering models operate provide the decoder with multiple word orders.
</nextsent>
<nextsent>for example, the maxent reordering model described in (xiong et al, 2006) <papid> P06-1066 </papid>provides hierarchical phrasal reordering system integrated within cky-style decoder.</nextsent>
<nextsent>in (galley and manning, 2008) <papid> D08-1089 </papid>the authors present an extension of the famous msd model (tillman, 2004) able to handle long distance word-block permutations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3984">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in (costa-jussa` and fonollosa, 2006) source and target word order harmonization is done using well established smt techniques and without the use of syntactic knowledge.
</prevsent>
<prevsent>other reordering models operate provide the decoder with multiple word orders.
</prevsent>
</prevsection>
<citsent citstr=" P06-1066 ">
for example, the maxent reordering model described in (xiong et al, 2006) <papid> P06-1066 </papid>provides hierarchical phrasal reordering system integrated within cky-style decoder.</citsent>
<aftsection>
<nextsent>in (galley and manning, 2008) <papid> D08-1089 </papid>the authors present an extension of the famous msd model (tillman, 2004) able to handle long distance word-block permutations.</nextsent>
<nextsent>coming up-to date, in (pvs, 2010) an effective application of data mining techniques to syntax-driven source reordering for mt is presented.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3985">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>other reordering models operate provide the decoder with multiple word orders.
</prevsent>
<prevsent>for example, the maxent reordering model described in (xiong et al, 2006) <papid> P06-1066 </papid>provides hierarchical phrasal reordering system integrated within cky-style decoder.</prevsent>
</prevsection>
<citsent citstr=" D08-1089 ">
in (galley and manning, 2008) <papid> D08-1089 </papid>the authors present an extension of the famous msd model (tillman, 2004) able to handle long distance word-block permutations.</citsent>
<aftsection>
<nextsent>coming up-to date, in (pvs, 2010) an effective application of data mining techniques to syntax-driven source reordering for mt is presented.
</nextsent>
<nextsent>different syntax-based reordering systems can befound in (genzel, 2010).<papid> C10-1043 </papid></nextsent>
<nextsent>in this system, reordering rules capable to capture many important word order transformations are automatically learned and applied in the preprocessing step.recently, tromble and eisner (tromble and eisner, 2009) <papid> D09-1105 </papid>define source permutation as the word ordering learning problem; the model works with apreference matrix for word pairs, expressing preference for their two alternative orders, and corresponding weight matrix that is fit to the paralleldata.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3988">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> experiments and submissions.  </section>
<citcontext>
<prevsection>
<prevsent>asl nc ge 161.8m 3.9g 136.7m 23.9 ns ge 45.3m 799.4m 3.0m 17.7table 2: monolingual german corpora used for target side language modeling.
</prevsent>
<prevsent>5.2 experimental setup.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>in its standard setting was used to build the smt systems: ? giza++/mkcls (och, 2003; <papid> P03-1021 </papid>och, 1999) <papid> E99-1010 </papid>for word alignment.?</citsent>
<aftsection>
<nextsent>sri lm (stolcke, 2002) for language modeling.
</nextsent>
<nextsent>a 3-gram target language model was estimated and smoothed with modified kneser ney discounting.?
</nextsent>
<nextsent>moses (koehn et al, 2007) <papid> P07-2045 </papid>to build an un factored translation system.</nextsent>
<nextsent>the stanford parser (klein and manning,2003) <papid> P03-1054 </papid>was used as source-side parsing en gine3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3991">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> experiments and submissions.  </section>
<citcontext>
<prevsection>
<prevsent>asl nc ge 161.8m 3.9g 136.7m 23.9 ns ge 45.3m 799.4m 3.0m 17.7table 2: monolingual german corpora used for target side language modeling.
</prevsent>
<prevsent>5.2 experimental setup.
</prevsent>
</prevsection>
<citsent citstr=" E99-1010 ">
moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>in its standard setting was used to build the smt systems: ? giza++/mkcls (och, 2003; <papid> P03-1021 </papid>och, 1999) <papid> E99-1010 </papid>for word alignment.?</citsent>
<aftsection>
<nextsent>sri lm (stolcke, 2002) for language modeling.
</nextsent>
<nextsent>a 3-gram target language model was estimated and smoothed with modified kneser ney discounting.?
</nextsent>
<nextsent>moses (koehn et al, 2007) <papid> P07-2045 </papid>to build an un factored translation system.</nextsent>
<nextsent>the stanford parser (klein and manning,2003) <papid> P03-1054 </papid>was used as source-side parsing en gine3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3994">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> experiments and submissions.  </section>
<citcontext>
<prevsection>
<prevsent>a 3-gram target language model was estimated and smoothed with modified kneser ney discounting.?
</prevsent>
<prevsent>moses (koehn et al, 2007) <papid> P07-2045 </papid>to build an un factored translation system.</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
the stanford parser (klein and manning,2003) <papid> P03-1054 </papid>was used as source-side parsing en gine3.</citsent>
<aftsection>
<nextsent>for maximum entropy modeling we used the maxent toolkit4.
</nextsent>
<nextsent>the discriminative syntactic reordering model is applied to reorder training, development, and test corpora.
</nextsent>
<nextsent>a moses-based translation system (corpusrealignment included5) is then trained using there ordered input.
</nextsent>
<nextsent>5.3 internal results and submissions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3995">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> experiments and submissions.  </section>
<citcontext>
<prevsection>
<prevsent>5.4 official results and discussion.
</prevsent>
<prevsent>unfortunately, the results of our participation this year were discouraging.
</prevsent>
</prevsection>
<citsent citstr=" W10-3812 ">
the primary submission was ranked 30th (12.6 uncased bleu-4) and the secondary 31th (11.2) out of 32 submitted systems.it turned out that our preliminary idea to extrapolate the positive results of english-to-dutch translation reported in (khalilov and simaan, 2010) <papid> W10-3812 </papid>to the wmt english-to-german translation task was not right.</citsent>
<aftsection>
<nextsent>analyzing the reasons of negative results during the post-evaluation period, we discovered that translation into german differs from english-to-dutch task in many cases.
</nextsent>
<nextsent>in contrast to english-to-dutch translation, the difference in terms of automatic scores between the internal baseline system (without external reordering) and the system enhanced with the pre-translation reordering is minimal.
</nextsent>
<nextsent>it turns out that translating into german is more complex in general and discriminative reordering is more advantageous for english-to-dutch than for english to-german translation.
</nextsent>
<nextsent>a negative aspect influencing is the way how the rules are extracted and applied according to our approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3997">
<title id=" W11-2150.xml">illcuva translation system for emnlpwmt 2011 </title>
<section> experiments and submissions.  </section>
<citcontext>
<prevsection>
<prevsent>at the same time, many reorderings can be performed more efficiently based on fixed (hand-crafted) rules (as it is done in (collins et al, 2005)).<papid> P05-1066 </papid></prevsent>
<prevsent>a possible remedy to this problem is to combine automatically extracted features with fixed (hand-crafted) rules.</prevsent>
</prevsection>
<citsent citstr=" C10-1126 ">
our last claims are supported by the observations described in (visweswariah et al., 2010).<papid> C10-1126 </papid></citsent>
<aftsection>
<nextsent>during post-evaluation period we analyzed the reasons why the system performance has slightly improved when separate maxent models are applied.
</nextsent>
<nextsent>the outline of reordered nodes for each of syntactic categories considered (sent , sbar(q) and np ) can be found in table 4 (the size of the corpus is 1.7 of sentences).
</nextsent>
<nextsent>category # of applications np 497,186 sbar(q) 106,243 sent 221,568 table 4: application of reorderings for separate syntactic categories.
</nextsent>
<nextsent>it is seen that the reorderings for np nodes is higher than for sent and sbar(q) categories.while sent and sbar(q) reorderings work analogously for dutch and german, our intuition is that german has more features that play role in reordering of np structures than dutch and there is need of more specific features to model np permutations in an accurate way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3998">
<title id=" W11-2208.xml">unsupervised bilingual pos tagging with markov random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiments show that estimating the parameters this way, using overlapping features with joint mrfs performs better than previous work on the 1984 dataset.
</prevsent>
<prevsent>this paper considers unsupervised learning of linguistic structure specifically, parts of speechinparallel text data.
</prevsent>
</prevsection>
<citsent citstr=" D08-1109 ">
this setting, and more generally the multilingual learning scenario, has been found advantageous for variety of unsupervised nlp tasks (snyder et al , 2008; <papid> D08-1109 </papid>cohen and smith, 2010; berg-kirkpatrick et al , 2010; das and petrov, 2011).<papid> P11-1061 </papid></citsent>
<aftsection>
<nextsent>we consider globally normalized markov random fields (mrfs) as an alternative to directed models based on multinomial distributions or locally normalized log-linear distributions.
</nextsent>
<nextsent>this alternate parameterization allows us to introduce correlated features that, at least in principle, depend on any parts of the hidden structure.
</nextsent>
<nextsent>such models, sometimes called undirected,?
</nextsent>
<nextsent>are widespread in supervisednlp; the most notable instances are conditional random fields (lafferty et al , 2001), which have enabled rich feature engineering to incorporate knowledge and improve performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI3999">
<title id=" W11-2208.xml">unsupervised bilingual pos tagging with markov random fields </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our experiments show that estimating the parameters this way, using overlapping features with joint mrfs performs better than previous work on the 1984 dataset.
</prevsent>
<prevsent>this paper considers unsupervised learning of linguistic structure specifically, parts of speechinparallel text data.
</prevsent>
</prevsection>
<citsent citstr=" P11-1061 ">
this setting, and more generally the multilingual learning scenario, has been found advantageous for variety of unsupervised nlp tasks (snyder et al , 2008; <papid> D08-1109 </papid>cohen and smith, 2010; berg-kirkpatrick et al , 2010; das and petrov, 2011).<papid> P11-1061 </papid></citsent>
<aftsection>
<nextsent>we consider globally normalized markov random fields (mrfs) as an alternative to directed models based on multinomial distributions or locally normalized log-linear distributions.
</nextsent>
<nextsent>this alternate parameterization allows us to introduce correlated features that, at least in principle, depend on any parts of the hidden structure.
</nextsent>
<nextsent>such models, sometimes called undirected,?
</nextsent>
<nextsent>are widespread in supervisednlp; the most notable instances are conditional random fields (lafferty et al , 2001), which have enabled rich feature engineering to incorporate knowledge and improve performance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4002">
<title id=" W11-2208.xml">unsupervised bilingual pos tagging with markov random fields </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>(2008).
</prevsent>
<prevsent>their work proposes joint model over pairs of tag sequences and words that can be under stood as pair of hidden markov models (hmms) 64 in which aligned words share states (a fixed and observable word alignment is assumed).
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
figure 1 gives an example for french-english sentence pair.following goldwater and griffiths (2007), <papid> P07-1094 </papid>the transition, emission and coupling parameters are governed by dirichlet priors, and token-level collapsed gibbs sampler is used for inference.</citsent>
<aftsection>
<nextsent>the hy per parameters of the prior distributions are inferred from data in an empirical bayesian fashion.
</nextsent>
<nextsent>why repeat that catastrophe ? pourquoi rpter la mme catastrophe x1/y1 x2/y2 y3 y4 x5/y6x4/y5 x3 figure 1: bilingual directed pos induction model when word alignments are monotonic (i.e., there are no crossing links in the alignment graph), the model of snyder et al  is straightforward to construct.
</nextsent>
<nextsent>however, crossing alignment links pose problem: they induce cycles in the tag sequence graph, which corresponds to an ill-defined probability model.
</nextsent>
<nextsent>their solution is to eliminate such alignment pairs (their algorithm for doing so is discussedbelow).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4003">
<title id=" W11-2208.xml">unsupervised bilingual pos tagging with markov random fields </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>crossing alignments often correspond to systematic word order differences between languages (e.g., svo vs. sov languages).
</prevsent>
<prevsent>as such, leaving them out prevents useful information about entire subsets of pos types from exploiting of bilingual context.
</prevsent>
</prevsection>
<citsent citstr=" P05-1044 ">
in the monolingual setting, smith and eisner (2005) <papid> P05-1044 </papid>showed similarly that pos induction model can be improved with spelling features (prefixes and suffixes of words), and haghighi and klein (2006) <papid> N06-1041 </papid>describe an mrf-based monolingual pos induction model that uses features.</citsent>
<aftsection>
<nextsent>an example of such amonolingual model is shown in figure 2.
</nextsent>
<nextsent>both papers developed different approximations of the computationally expensive partition function.
</nextsent>
<nextsent>haghighi and klein (2006) <papid> N06-1041 </papid>approximated by ignoring all sentences of length greater than some maximum, and the contrastive estimation?</nextsent>
<nextsent>of smith and eisner (2005) <papid> P05-1044 </papid>approximates the partition function with set eco nom ic dis cre pan cie a arev gro win v figure 2: monolingual mrf tag model (haghighi and klein, 2006) <papid> N06-1041 </papid>of automatically distorted training examples which are compactly represented in wfsts.das and petrov (2011) <papid> P11-1061 </papid>also consider the problem of unsupervised bilingual pos induction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4005">
<title id=" W11-2208.xml">unsupervised bilingual pos tagging with markov random fields </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>crossing alignments often correspond to systematic word order differences between languages (e.g., svo vs. sov languages).
</prevsent>
<prevsent>as such, leaving them out prevents useful information about entire subsets of pos types from exploiting of bilingual context.
</prevsent>
</prevsection>
<citsent citstr=" N06-1041 ">
in the monolingual setting, smith and eisner (2005) <papid> P05-1044 </papid>showed similarly that pos induction model can be improved with spelling features (prefixes and suffixes of words), and haghighi and klein (2006) <papid> N06-1041 </papid>describe an mrf-based monolingual pos induction model that uses features.</citsent>
<aftsection>
<nextsent>an example of such amonolingual model is shown in figure 2.
</nextsent>
<nextsent>both papers developed different approximations of the computationally expensive partition function.
</nextsent>
<nextsent>haghighi and klein (2006) <papid> N06-1041 </papid>approximated by ignoring all sentences of length greater than some maximum, and the contrastive estimation?</nextsent>
<nextsent>of smith and eisner (2005) <papid> P05-1044 </papid>approximates the partition function with set eco nom ic dis cre pan cie a arev gro win v figure 2: monolingual mrf tag model (haghighi and klein, 2006) <papid> N06-1041 </papid>of automatically distorted training examples which are compactly represented in wfsts.das and petrov (2011) <papid> P11-1061 </papid>also consider the problem of unsupervised bilingual pos induction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4011">
<title id=" W11-2208.xml">unsupervised bilingual pos tagging with markov random fields </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in this way, the complex inference and modeling challenges associated with bilingual tagging model are avoided.
</prevsent>
<prevsent>finally, multilingual pos induction has also been considered without using parallel data.
</prevsent>
</prevsection>
<citsent citstr=" D11-1005 ">
cohen et al  (2011) <papid> D11-1005 </papid>present multilingual estimation technique for part-of-speech tagging (and grammar induction), where the lack of parallel data is compensated bythe use of labeled data for some languages and unlabeled data for other languages.</citsent>
<aftsection>
<nextsent>our model is markov random field whose random variables correspond to words in two parallel sentences and pos tags for those words.
</nextsent>
<nextsent>let = s1, . . .
</nextsent>
<nextsent>, sns?
</nextsent>
<nextsent>and = t1, . . .
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4020">
<title id=" W11-2208.xml">unsupervised bilingual pos tagging with markov random fields </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we use the last 25% of sentences in the dataset as test set, following previous work.
</prevsent>
<prevsent>the dataset is manually annotated with part-of-speech tags.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
we use automatically induced word alignments using giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>the data show very regular patterns of tags that are aligned together: words with the same tag in two languages tend to be aligned with each other.
</nextsent>
<nextsent>when complete tag dictionary derived from the slavic language data is available, the level of ambiguity is very low.
</nextsent>
<nextsent>the baseline of choosing random tags for each word gives an accuracy in the low 80s.
</nextsent>
<nextsent>for english, we use an extended tag dictionary built from the wall street journal and the 1984 data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4027">
<title id=" W11-2208.xml">unsupervised bilingual pos tagging with markov random fields </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>to see whether crossing links do have an effect when they come in larger number, we tested our model on french-english data.
</prevsent>
<prevsent>we aligned 10,000 sentences from the europarl corpus (koehn, 2005), resulting in 87k crossing links out of total of 673k links.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
using the penn treebank (marcus et al , 1993) <papid> J93-2004 </papid>and the french treebank (abeille?</citsent>
<aftsection>
<nextsent>et al , 2003) to evaluate the model, results are given in table 3.
</nextsent>
<nextsent>it is evident that crossing links have larger effect here, but it is mixed: crossing links improve performance for french while harming it for english.
</nextsent>
<nextsent>in this paper, we explored the capabilities of jointmrfs for modeling bilingual part-of-speech models.
</nextsent>
<nextsent>exact inference with dynamic programming isnot applicable, forcing us to experiment with approximate inference techniques.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4028">
<title id=" W11-2162.xml">ceuupv english spanish system for wmt11 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the goal of statistical machine translation (smt) is to translate sentence between two languages.
</prevsent>
<prevsent>giving the source language sentence , it would be translated to an equivalent target language sentencee.
</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
the most extended formalization is done via loglinear models (papineni et al, 1998; och and ney, 2002) <papid> P02-1038 </papid>as follows: e?</citsent>
<aftsection>
<nextsent>= arg max k?
</nextsent>
<nextsent>k=1 khk(f , e) (1) where hk(f , e) is score function representing an important feature for the translation of into e, is the number of models (or features) and are the weights of the log-linear combination.
</nextsent>
<nextsent>typically, the weights are optimized during the tuning stage with the use of development set.
</nextsent>
<nextsent>smt systems relyon bilingual sentence aligned training corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4029">
<title id=" W11-2162.xml">ceuupv english spanish system for wmt11 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>typically, the weights are optimized during the tuning stage with the use of development set.
</prevsent>
<prevsent>smt systems relyon bilingual sentence aligned training corpus.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
these sentences are aligned at theword level (brown et al, 1993), <papid> J93-2003 </papid>and after that, different hk feature functions are trained.</citsent>
<aftsection>
<nextsent>in some practical cases, the out-of-domain training data is larger than the in-domain training data.
</nextsent>
<nextsent>in these cases the target language model (lm) is composed of linear interpolation of independent lms, one for each available training domain or corpus.
</nextsent>
<nextsent>nevertheless, the training of phrase-based translation models is an open problem in these cases.some recent works (resnik and smith, 2003; <papid> J03-3002 </papid>yasuda et al, ; koehn and schroeder, 2007; <papid> W07-0733 </papid>matsoukas et al, 2009; <papid> D09-1074 </papid>foster et al, 2010; sanchis-trillesand casacuberta, 2010) related to corpus weighting, make use of data selection, data weighting, and translation model adaptation to overcome thisproblem.</nextsent>
<nextsent>in this work, we explore simple corpus weighting technique to interpol ate any number of different phrase tables.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4030">
<title id=" W11-2162.xml">ceuupv english spanish system for wmt11 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in some practical cases, the out-of-domain training data is larger than the in-domain training data.
</prevsent>
<prevsent>in these cases the target language model (lm) is composed of linear interpolation of independent lms, one for each available training domain or corpus.
</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
nevertheless, the training of phrase-based translation models is an open problem in these cases.some recent works (resnik and smith, 2003; <papid> J03-3002 </papid>yasuda et al, ; koehn and schroeder, 2007; <papid> W07-0733 </papid>matsoukas et al, 2009; <papid> D09-1074 </papid>foster et al, 2010; sanchis-trillesand casacuberta, 2010) related to corpus weighting, make use of data selection, data weighting, and translation model adaptation to overcome thisproblem.</citsent>
<aftsection>
<nextsent>in this work, we explore simple corpus weighting technique to interpol ate any number of different phrase tables.
</nextsent>
<nextsent>two different approaches are tested, obtaining similar performance.
</nextsent>
<nextsent>on the one hand, count-based smoothing technique that applies weight to the counting of phrases and lexical links depending on the relevance of each corpus.on the other hand, linear interpolation of independent trained phrase tables.
</nextsent>
<nextsent>another important feature of this work is the use of neural network language models (nn lms) (bengio, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4031">
<title id=" W11-2162.xml">ceuupv english spanish system for wmt11 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in some practical cases, the out-of-domain training data is larger than the in-domain training data.
</prevsent>
<prevsent>in these cases the target language model (lm) is composed of linear interpolation of independent lms, one for each available training domain or corpus.
</prevsent>
</prevsection>
<citsent citstr=" W07-0733 ">
nevertheless, the training of phrase-based translation models is an open problem in these cases.some recent works (resnik and smith, 2003; <papid> J03-3002 </papid>yasuda et al, ; koehn and schroeder, 2007; <papid> W07-0733 </papid>matsoukas et al, 2009; <papid> D09-1074 </papid>foster et al, 2010; sanchis-trillesand casacuberta, 2010) related to corpus weighting, make use of data selection, data weighting, and translation model adaptation to overcome thisproblem.</citsent>
<aftsection>
<nextsent>in this work, we explore simple corpus weighting technique to interpol ate any number of different phrase tables.
</nextsent>
<nextsent>two different approaches are tested, obtaining similar performance.
</nextsent>
<nextsent>on the one hand, count-based smoothing technique that applies weight to the counting of phrases and lexical links depending on the relevance of each corpus.on the other hand, linear interpolation of independent trained phrase tables.
</nextsent>
<nextsent>another important feature of this work is the use of neural network language models (nn lms) (bengio, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4032">
<title id=" W11-2162.xml">ceuupv english spanish system for wmt11 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in some practical cases, the out-of-domain training data is larger than the in-domain training data.
</prevsent>
<prevsent>in these cases the target language model (lm) is composed of linear interpolation of independent lms, one for each available training domain or corpus.
</prevsent>
</prevsection>
<citsent citstr=" D09-1074 ">
nevertheless, the training of phrase-based translation models is an open problem in these cases.some recent works (resnik and smith, 2003; <papid> J03-3002 </papid>yasuda et al, ; koehn and schroeder, 2007; <papid> W07-0733 </papid>matsoukas et al, 2009; <papid> D09-1074 </papid>foster et al, 2010; sanchis-trillesand casacuberta, 2010) related to corpus weighting, make use of data selection, data weighting, and translation model adaptation to overcome thisproblem.</citsent>
<aftsection>
<nextsent>in this work, we explore simple corpus weighting technique to interpol ate any number of different phrase tables.
</nextsent>
<nextsent>two different approaches are tested, obtaining similar performance.
</nextsent>
<nextsent>on the one hand, count-based smoothing technique that applies weight to the counting of phrases and lexical links depending on the relevance of each corpus.on the other hand, linear interpolation of independent trained phrase tables.
</nextsent>
<nextsent>another important feature of this work is the use of neural network language models (nn lms) (bengio, 2008).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4033">
<title id=" W11-2162.xml">ceuupv english spanish system for wmt11 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>on the one hand, count-based smoothing technique that applies weight to the counting of phrases and lexical links depending on the relevance of each corpus.on the other hand, linear interpolation of independent trained phrase tables.
</prevsent>
<prevsent>another important feature of this work is the use of neural network language models (nn lms) (bengio, 2008).
</prevsent>
</prevsection>
<citsent citstr=" P06-2093 ">
this kind of lms hasbeen successfully applied in some connection ist approaches to language modeling (bengio et al, 2003; castro-bleda and prat, 2003; schwenk et al, 2006; <papid> P06-2093 </papid>490 schwenk, 2010).</citsent>
<aftsection>
<nextsent>the advantage of these nn lms is the projection of words on continuous space were the probabilities of n-grams are learned.
</nextsent>
<nextsent>a neural network (nn) is proposed to learn both the word projections and the n-gram probabilities.the presented system combines standard, state of-the-art smt system with nn lm via log-linear combination and -best output re-scoring.
</nextsent>
<nextsent>we chose to participate in the english-spanish direction.
</nextsent>
<nextsent>a standard phrase-based translation model is composed of the following five hk features: ? inverse phrase translation probability p(f |e) ? inverse lexical weighting l(f |e) ? direct phrase translation probability p(e|f) ? direct lexical weighting l(e|f) ? phrase penalty (always = 2.718).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4035">
<title id=" W11-2162.xml">ceuupv english spanish system for wmt11 </title>
<section> weighting different translation models.  </section>
<citcontext>
<prevsection>
<prevsent>(i,j)a w(ej |fi)
</prevsent>
<prevsent>the proposed modifications of the phrase-based translation models are similar to (foster et al, 2010;matsoukas et al, 2009), <papid> D09-1074 </papid>but in this case the weighting is simpler and focused at the corpus level.</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
if we have different training sets, we could define as the weight of the set t, for 1 ? ? . the word alignments are computed via giza++ (och and ney, 2003) <papid> J03-1002 </papid>over the concatenation of all the training material available for the translation models (in this case, europarl, news-commentary, and united na tions).</citsent>
<aftsection>
<nextsent>after that, we could recompute the lexical translation distribution using the weights information, and compute the phrase-based translation models taking into account these weights.
</nextsent>
<nextsent>the count function will be redefined to take into account only information of the corresponding training set.
</nextsent>
<nextsent>3.1 count smoothing.
</nextsent>
<nextsent>the weight is applied to the count function, in order to modify the corpus effect on the probability of each phrase pair alignment, and each word pair alignment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4036">
<title id=" W11-2162.xml">ceuupv english spanish system for wmt11 </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>however, one of the drawbacks of such approach is the high computational cost entailed whenever the nn lmis computed directly, with no simplification whatsoever.
</prevsent>
<prevsent>for this reason, the vocabulary size will be restricted in the experiments presented in this work.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the baseline smt system is built with the open source smt toolkit moses (koehn et al, 2007), <papid> P07-2045 </papid>in its standard setup.</citsent>
<aftsection>
<nextsent>the decoder includes log-linear model comprising phrase-based translation model, language model, lexicalized distortion model and word and phrase penalties.
</nextsent>
<nextsent>the weights of the log-linear interpolation were optimized by means of mert (och, 2003), <papid> P03-1021 </papid>using the news-commentary test set of the 2008 shared task as development set.the phrase-based translation model uses the con table 1: spanish corpora statistics.</nextsent>
<nextsent>nc stands for news-commentary and un for united nations, while|?| stands for vocabulary size, and /k for mil lions/thousands of elements.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4037">
<title id=" W11-2162.xml">ceuupv english spanish system for wmt11 </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the baseline smt system is built with the open source smt toolkit moses (koehn et al, 2007), <papid> P07-2045 </papid>in its standard setup.</prevsent>
<prevsent>the decoder includes log-linear model comprising phrase-based translation model, language model, lexicalized distortion model and word and phrase penalties.</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
the weights of the log-linear interpolation were optimized by means of mert (och, 2003), <papid> P03-1021 </papid>using the news-commentary test set of the 2008 shared task as development set.the phrase-based translation model uses the con table 1: spanish corpora statistics.</citsent>
<aftsection>
<nextsent>nc stands for news-commentary and un for united nations, while|?| stands for vocabulary size, and /k for mil lions/thousands of elements.
</nextsent>
<nextsent>all numbers are computed with tokenized and lower cased data.
</nextsent>
<nextsent>set # lines # words |?| nc v6 159k 4.44m 80k news-shuffled 9.17m 269m 596k europarl v6 1.94m 55m 177k un 6.22m 214m 579k total 21.93m 678m 1.03mtable 2: weights of different combination of phrase based translation models.
</nextsent>
<nextsent>system europarl nc un smooth1 0.35 0.35 0.30 smooth2 0.40 0.40 0.20 smooth3 0.15 0.80 0.05 linear 0.35 0.35 0.30 cate nation of news-commentary, united nations,and europarl corpora, to estimate the four translation model features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4038">
<title id=" W11-2162.xml">ceuupv english spanish system for wmt11 </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>smooth3 29.5 59.6 30.9 58.5 + nn lm 29.9 59.2 31.4 58.0 linear 29.5 59.5 30.9 58.7 + nn lm 30.2 58.8 31.5 57.9 set to 2 000 unique output sentences.
</prevsent>
<prevsent>results can be seen in table 3.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
in order to assess the reliability of such results, we computed pairwise improvement intervals as described in (koehn, 2004), <papid> W04-3250 </papid>by means of bootstrapping with 1 000 bootstrap iterations andat 95% confidence level.</citsent>
<aftsection>
<nextsent>such confidence test reported the improvements to be statistically significant.
</nextsent>
<nextsent>a difference of more than 0.3 points of bleu is considered significant in the pairwise comparison.the final results leads to 31.5 points of bleu, positioning this system as second in the final classification.
</nextsent>
<nextsent>the presented ceu-upv system, using phrase translation models combinations and nn lms, leads an improvement of 0.4 points of bleu in the two cases: the count smoothing approach (smooth3system) and the linear interpolation approach (lin ear system).
</nextsent>
<nextsent>the incorporation of nn lms in both systems gets an additional improvement of 0.5 bleu points for the smooth3 system, and 0.6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4039">
<title id=" W12-2018.xml">a comparison of greedy and optimal assessment of natural language student input using wordtoword similarity metrics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the expert answer could also be an 157 anticipated wrong answer, usually called misconception.
</prevsent>
<prevsent>a student contribution similar to misconception would trigger misconception correction strategy.
</prevsent>
</prevsection>
<citsent citstr=" C04-1051 ">
we model the problem of assessing natural language student input in tutoring systems as paraphrase identification problem (dolan et al, 2004).<papid> C04-1051 </papid></citsent>
<aftsection>
<nextsent>the student input assessment problem has been also modeled as textual entailment task in the past (rus &amp; graesser, 2006).
</nextsent>
<nextsent>our novel method to assess student contribution against an expert-generated answer relies on the compositionality principle and the sailor assignment algorithm that was proposed to solve the assignment problem, well-known combinatorial optimization problem.
</nextsent>
<nextsent>the sailor assignment algorithm optimally assigns sailors to ships based on the fitness of the sailors?
</nextsent>
<nextsent>skills to the ships?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4040">
<title id=" W12-2018.xml">a comparison of greedy and optimal assessment of natural language student input using wordtoword similarity metrics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in our case, we would like to optimally match words in the student input (the sailors) to words in the expert-generated answer (the ships) based on how well the words in student input (the sailors) fit the words in the expert answer (the ships).
</prevsent>
<prevsent>the fitness between the words is nothing else but their similarity according to some metric of word similarity.
</prevsent>
</prevsection>
<citsent citstr=" N04-3012 ">
we use the wordnet word-to-word similarity metrics (pedersen et al, 2004) <papid> N04-3012 </papid>and latent semantic analysis (landauer et al, 2007).</citsent>
<aftsection>
<nextsent>the methods proposed so far that relyon the principle of compositionality to compute the semantic similarity of longer texts have been primarily greedy methods (corley &amp; mihalcea, 2005; <papid> W05-1203 </papid>lintean &amp; rus, 2012).</nextsent>
<nextsent>to the best of our knowledge, nobody proposed an optimal solution based on the principle of compositionality and word-to-word similarity metrics for the student input assessment problem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4041">
<title id=" W12-2018.xml">a comparison of greedy and optimal assessment of natural language student input using wordtoword similarity metrics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the fitness between the words is nothing else but their similarity according to some metric of word similarity.
</prevsent>
<prevsent>we use the wordnet word-to-word similarity metrics (pedersen et al, 2004) <papid> N04-3012 </papid>and latent semantic analysis (landauer et al, 2007).</prevsent>
</prevsection>
<citsent citstr=" W05-1203 ">
the methods proposed so far that relyon the principle of compositionality to compute the semantic similarity of longer texts have been primarily greedy methods (corley &amp; mihalcea, 2005; <papid> W05-1203 </papid>lintean &amp; rus, 2012).</citsent>
<aftsection>
<nextsent>to the best of our knowledge, nobody proposed an optimal solution based on the principle of compositionality and word-to-word similarity metrics for the student input assessment problem.
</nextsent>
<nextsent>it is important to note that the optimal method proposed here is generally applicable to compute the similarity of any texts.
</nextsent>
<nextsent>we provide experimental results on two datasets provided to us by researchers developing two world-class dialogue-based tutoring systems: auto tutor (graesser et al, 2005) and istart (mcnamara et al, 2004).
</nextsent>
<nextsent>background it is beyond the scope of this work to offer an exhaustive overview of methods proposed so far to handle the task of assessing natural language student input in intelligent tutoring systems.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4043">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we train crf on manually annotated phrases, and predict fine-grained set of labels.
</prevsent>
<prevsent>we achieve an accuracy score of 69.56% on our most detailed label set, 76.62% when gold standard coreference is available.
</prevsent>
</prevsection>
<citsent citstr=" W06-1612 ">
the automatic identification of information status(prince, 1981; 1992), i.e. categorizing discourse entities into different classes on the given-new scale, has recently been identified as an important issue in natural language processing (nissim, 2006; <papid> W06-1612 </papid>rahman and ng, 2011; 2012).</citsent>
<aftsection>
<nextsent>it is widely acknowledged that information status and, more generally, information structure,1 is reflected in word order, in the form of referring expressions as well as in prosody.
</nextsent>
<nextsent>in computational linguistics, the ability to automatically label text with information status, therefore, could beof great benefit to many applications, including surface realization, text-to-speech synthesis, anaphora resolution, summarization, etc.the task of automatically labeling text with information status, however, is difficult one.
</nextsent>
<nextsent>part of1information structure is usually taken to describe clause internal divisions into focus-background, topic-comment, ortheme-rheme, which are in turn defined in terms of contextual factors such as given-new information, salience, contrast and alternatives, cf.
</nextsent>
<nextsent>steedman and kruijff-korbayova?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4044">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> learning information status.  </section>
<citcontext>
<prevsection>
<prevsent>the difficulty arises from the fact that, to certain degree, such labeling requires world knowledge and semantic comprehension of the text, but another obstacle is simply that theoretical notions of information status are not used consistently in the literature.
</prevsent>
<prevsent>in this paper we outline system, trained on small amount of data, that achieves encouraging results on the task of automatically labeling transcribed german radio news data with fine-grained information status labels.
</prevsent>
</prevsection>
<citsent citstr=" P99-1048 ">
a simpler variant of the task is anaphoricity detection (discourse-new detection) (bean and riloff, 1999; <papid> P99-1048 </papid>ng and cardie, 2002; <papid> C02-1139 </papid>uryupina, 2003; <papid> P03-2012 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>zhou and kong, 2011), which divides discourse entities into anaphoric (given) and new.</citsent>
<aftsection>
<nextsent>identifying discourse-new expressions in texts is helpful as precursor to coreference resolution,since, by definition, there is no need to identify antecedents for new entities.
</nextsent>
<nextsent>in the linguistic literature, referring expressions have been distinguished in much more detail, and there is reason to believe that this could also provide useful information for nlp applications.
</nextsent>
<nextsent>nissim(2006) <papid> W06-1612 </papid>and rahman and ng (2011) <papid> D11-1099 </papid>developed methods to automatically identify three different classes:old, mediated and new expressions.</nextsent>
<nextsent>this classification, which is described in nissim et al (2004), has been used for annotating the switchboard dialog corpus (calhoun et al, 2010), on which both studies are based.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4045">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> learning information status.  </section>
<citcontext>
<prevsection>
<prevsent>the difficulty arises from the fact that, to certain degree, such labeling requires world knowledge and semantic comprehension of the text, but another obstacle is simply that theoretical notions of information status are not used consistently in the literature.
</prevsent>
<prevsent>in this paper we outline system, trained on small amount of data, that achieves encouraging results on the task of automatically labeling transcribed german radio news data with fine-grained information status labels.
</prevsent>
</prevsection>
<citsent citstr=" C02-1139 ">
a simpler variant of the task is anaphoricity detection (discourse-new detection) (bean and riloff, 1999; <papid> P99-1048 </papid>ng and cardie, 2002; <papid> C02-1139 </papid>uryupina, 2003; <papid> P03-2012 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>zhou and kong, 2011), which divides discourse entities into anaphoric (given) and new.</citsent>
<aftsection>
<nextsent>identifying discourse-new expressions in texts is helpful as precursor to coreference resolution,since, by definition, there is no need to identify antecedents for new entities.
</nextsent>
<nextsent>in the linguistic literature, referring expressions have been distinguished in much more detail, and there is reason to believe that this could also provide useful information for nlp applications.
</nextsent>
<nextsent>nissim(2006) <papid> W06-1612 </papid>and rahman and ng (2011) <papid> D11-1099 </papid>developed methods to automatically identify three different classes:old, mediated and new expressions.</nextsent>
<nextsent>this classification, which is described in nissim et al (2004), has been used for annotating the switchboard dialog corpus (calhoun et al, 2010), on which both studies are based.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4046">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> learning information status.  </section>
<citcontext>
<prevsection>
<prevsent>the difficulty arises from the fact that, to certain degree, such labeling requires world knowledge and semantic comprehension of the text, but another obstacle is simply that theoretical notions of information status are not used consistently in the literature.
</prevsent>
<prevsent>in this paper we outline system, trained on small amount of data, that achieves encouraging results on the task of automatically labeling transcribed german radio news data with fine-grained information status labels.
</prevsent>
</prevsection>
<citsent citstr=" P03-2012 ">
a simpler variant of the task is anaphoricity detection (discourse-new detection) (bean and riloff, 1999; <papid> P99-1048 </papid>ng and cardie, 2002; <papid> C02-1139 </papid>uryupina, 2003; <papid> P03-2012 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>zhou and kong, 2011), which divides discourse entities into anaphoric (given) and new.</citsent>
<aftsection>
<nextsent>identifying discourse-new expressions in texts is helpful as precursor to coreference resolution,since, by definition, there is no need to identify antecedents for new entities.
</nextsent>
<nextsent>in the linguistic literature, referring expressions have been distinguished in much more detail, and there is reason to believe that this could also provide useful information for nlp applications.
</nextsent>
<nextsent>nissim(2006) <papid> W06-1612 </papid>and rahman and ng (2011) <papid> D11-1099 </papid>developed methods to automatically identify three different classes:old, mediated and new expressions.</nextsent>
<nextsent>this classification, which is described in nissim et al (2004), has been used for annotating the switchboard dialog corpus (calhoun et al, 2010), on which both studies are based.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4047">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> learning information status.  </section>
<citcontext>
<prevsection>
<prevsent>the difficulty arises from the fact that, to certain degree, such labeling requires world knowledge and semantic comprehension of the text, but another obstacle is simply that theoretical notions of information status are not used consistently in the literature.
</prevsent>
<prevsent>in this paper we outline system, trained on small amount of data, that achieves encouraging results on the task of automatically labeling transcribed german radio news data with fine-grained information status labels.
</prevsent>
</prevsection>
<citsent citstr=" N07-1030 ">
a simpler variant of the task is anaphoricity detection (discourse-new detection) (bean and riloff, 1999; <papid> P99-1048 </papid>ng and cardie, 2002; <papid> C02-1139 </papid>uryupina, 2003; <papid> P03-2012 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>zhou and kong, 2011), which divides discourse entities into anaphoric (given) and new.</citsent>
<aftsection>
<nextsent>identifying discourse-new expressions in texts is helpful as precursor to coreference resolution,since, by definition, there is no need to identify antecedents for new entities.
</nextsent>
<nextsent>in the linguistic literature, referring expressions have been distinguished in much more detail, and there is reason to believe that this could also provide useful information for nlp applications.
</nextsent>
<nextsent>nissim(2006) <papid> W06-1612 </papid>and rahman and ng (2011) <papid> D11-1099 </papid>developed methods to automatically identify three different classes:old, mediated and new expressions.</nextsent>
<nextsent>this classification, which is described in nissim et al (2004), has been used for annotating the switchboard dialog corpus (calhoun et al, 2010), on which both studies are based.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4049">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> learning information status.  </section>
<citcontext>
<prevsection>
<prevsent>identifying discourse-new expressions in texts is helpful as precursor to coreference resolution,since, by definition, there is no need to identify antecedents for new entities.
</prevsent>
<prevsent>in the linguistic literature, referring expressions have been distinguished in much more detail, and there is reason to believe that this could also provide useful information for nlp applications.
</prevsent>
</prevsection>
<citsent citstr=" D11-1099 ">
nissim(2006) <papid> W06-1612 </papid>and rahman and ng (2011) <papid> D11-1099 </papid>developed methods to automatically identify three different classes:old, mediated and new expressions.</citsent>
<aftsection>
<nextsent>this classification, which is described in nissim et al (2004), has been used for annotating the switchboard dialog corpus (calhoun et al, 2010), on which both studies are based.
</nextsent>
<nextsent>most recently, rahman and ng (2012) <papid> E12-1081 </papid>extend their automatic prediction system to more fine-grained set of 16 subtypes.</nextsent>
<nextsent>232 old.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4052">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> learning information status.  </section>
<citcontext>
<prevsection>
<prevsent>nissim(2006) <papid> W06-1612 </papid>and rahman and ng (2011) <papid> D11-1099 </papid>developed methods to automatically identify three different classes:old, mediated and new expressions.</prevsent>
<prevsent>this classification, which is described in nissim et al (2004), has been used for annotating the switchboard dialog corpus (calhoun et al, 2010), on which both studies are based.</prevsent>
</prevsection>
<citsent citstr=" E12-1081 ">
most recently, rahman and ng (2012) <papid> E12-1081 </papid>extend their automatic prediction system to more fine-grained set of 16 subtypes.</citsent>
<aftsection>
<nextsent>232 old.
</nextsent>
<nextsent>the class of old entities in nissim et al (2004) is not limited to full-fledged anaphors like in example (1a) but also includes cases of generic and first/second person pronouns like in (1b), which may or may not possess previous mention.
</nextsent>
<nextsent>(1) a. shares in general electric rose as investors bet that the us company would take more lucrative engine orders for the a380.
</nextsent>
<nextsent>b. wonder where this comes from.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4055">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> learning information status.  </section>
<citcontext>
<prevsection>
<prevsent>mediated.
</prevsent>
<prevsent>the group of mediated entities mainly has two subtypes: (2a) shows an expression which has not been mentioned before but which is dependent on previous context.
</prevsent>
</prevsection>
<citsent citstr=" J98-2001 ">
such items have also been called bridging anaphors (poesio and vieira, 1998).<papid> J98-2001 </papid></citsent>
<aftsection>
<nextsent>(2b) contains phrase which is generally known but does not depend on the discourse context.
</nextsent>
<nextsent>(2) a. tomorrow, the shen zhou 8 spacecraft will be in position to attempt the docking.
</nextsent>
<nextsent>b. they hope that he will be given the right to remain in the netherlands.
</nextsent>
<nextsent>new.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4065">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> extending information status prediction.  </section>
<citcontext>
<prevsection>
<prevsent>forex ample, wolfgang bosbach, deputy chairman of the 233 countable boolean descriptive # words in phrase* phrase contains compound noun adverbial type, e.g. locative # predicative phrases phrase contains coordination determiner type, e.g. definite * # dps and nps in phrase phrase contains time expression left/right-most pos tag of phrase # top category children phrase contains   2, 5 or 10 words highest syntactic node label # labels/titles phrase does not have complete parse that dominates the phrase # depth of syntactic phrase phrase is pronoun grammatical function, e.g. subj * # cardinal numbers phrase contains more than 1 dp type of pronoun, e.g. demonstrative # depth of syntactic phrase and 1 np (i.e. phrase contains syntactic shape, e.g. apposition with ignoring unary branching an embedded argument) determiner and attributive modifier # apposition phrases head noun appears (partly or completely) head noun type, e.g. common * # year phrases in previous 10 sentences * head noun number, e.g. singular table 1: features of the crf prediction model (* indicates feature used in baseline model) cdu parliamentary group may be known to parts of german audience but not to other people.
</prevsent>
<prevsent>we address this by collecting both hearer-known and hearer-unknown definite expressions into one class unused.
</prevsent>
</prevsection>
<citsent citstr=" H05-1031 ">
this does not rule out further sub classification (known/unknown) or the possibility of using machine learning techniques to identify this distinction, see nenkova et al (2005).<papid> H05-1031 </papid></citsent>
<aftsection>
<nextsent>the fact that rahman and ng (2011) <papid> D11-1099 </papid>report the highest confusion rate between new and mediated entities may have its roots in this issue.</nextsent>
<nextsent>new.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4069">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> extending information status prediction.  </section>
<citcontext>
<prevsection>
<prevsent>generic.
</prevsent>
<prevsent>an issue which is not dealt with in nissim et al (2004) are generic expressions as in lions have manes.
</prevsent>
</prevsection>
<citsent citstr=" P10-1005 ">
reiter and frank (2010) <papid> P10-1005 </papid>discuss thetask of identifying generic items in manner similar to the learning tasks presented above, using abayesian network.</citsent>
<aftsection>
<nextsent>we believe it makes sense to integrate genericity detection into information-status prediction.3
</nextsent>
<nextsent>our work is based on the dirndl radio news corpus of eckart et al (2012) which has been hand annotated with information status labels.
</nextsent>
<nextsent>we choosea selection of 6668 annotated phrases (1420 sen tences).
</nextsent>
<nextsent>this is an order of magnitude smaller than the annotated switchboard corpus of calhoun et al (2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4070">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> prediction model for information status.  </section>
<citcontext>
<prevsection>
<prevsent>this is an order of magnitude smaller than the annotated switchboard corpus of calhoun et al (2010).
</prevsent>
<prevsent>we parse each sentence with the german lexical functional grammar of rohrer and forst(2006) using the xle parser in order to auto mati 3note that in coreference annotation it is an open question whether two identical generic terms should count as coreferent.cally extract (morpho-)syntactic and functional features for our model.
</prevsent>
</prevsection>
<citsent citstr=" P09-1092 ">
cahill and riester (2009) <papid> P09-1092 </papid>show that there are asymmetries between pairs of information status labels contained in sentences, i.e. certain classes of expressions tend to precede certain other classes.</citsent>
<aftsection>
<nextsent>we therefore treat the prediction of is labels as sequence labeling task.4 we train crf using wapiti (lavergne et al, 2010), <papid> P10-1052 </papid>with the features outlined intable 1.</nextsent>
<nextsent>we also include basic coreference?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4071">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> prediction model for information status.  </section>
<citcontext>
<prevsection>
<prevsent>we parse each sentence with the german lexical functional grammar of rohrer and forst(2006) using the xle parser in order to auto mati 3note that in coreference annotation it is an open question whether two identical generic terms should count as coreferent.cally extract (morpho-)syntactic and functional features for our model.
</prevsent>
<prevsent>cahill and riester (2009) <papid> P09-1092 </papid>show that there are asymmetries between pairs of information status labels contained in sentences, i.e. certain classes of expressions tend to precede certain other classes.</prevsent>
</prevsection>
<citsent citstr=" P10-1052 ">
we therefore treat the prediction of is labels as sequence labeling task.4 we train crf using wapiti (lavergne et al, 2010), <papid> P10-1052 </papid>with the features outlined intable 1.</citsent>
<aftsection>
<nextsent>we also include basic coreference?
</nextsent>
<nextsent>feature, similar to the lexical features of rahman and ng (2011), <papid> D11-1099 </papid>that fires if there is some lexical overlap of nouns (or compound nouns) in the preceding 10 sentences.</nextsent>
<nextsent>the original label set described in riester et al (2010) contains 21 labels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4079">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> prediction model for information status.  </section>
<citcontext>
<prevsection>
<prevsent>for example, to infer that the waitress can be categorized as bridging in the context of the restaurant requires information that links the two concepts.
</prevsent>
<prevsent>rahman and ng (2012) <papid> E12-1081 </papid>also note this and include features based on framenet, wordnet and the reverb corpus for english.</prevsent>
</prevsection>
<citsent citstr=" W97-0802 ">
for german, we address this issue by introducing two further types of features into our model based on the germanet resource (hamp and feldweg, 1997).<papid> W97-0802 </papid></citsent>
<aftsection>
<nextsent>the first type is based on the germanet synset of the head noun in the phrase and its distance from the root node (the assumption is that entities closer to root are more generic than those further away).
</nextsent>
<nextsent>the second include the sum and maximum of the lin semantic relatedness measures (lin, 1998) of how similar the head noun of the phrase is to the other nouns in current and immediately preceding sentence surrounding the phrase (calculated with germanet pathfinder; finthammer and cramer, 2008).<papid> L08-1345 </papid></nextsent>
<nextsent>the results are given in table 3b.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4080">
<title id=" W12-1632.xml">automatically acquiring fine grained information status distinctions in german </title>
<section> prediction model for information status.  </section>
<citcontext>
<prevsection>
<prevsent>for german, we address this issue by introducing two further types of features into our model based on the germanet resource (hamp and feldweg, 1997).<papid> W97-0802 </papid></prevsent>
<prevsent>the first type is based on the germanet synset of the head noun in the phrase and its distance from the root node (the assumption is that entities closer to root are more generic than those further away).</prevsent>
</prevsection>
<citsent citstr=" L08-1345 ">
the second include the sum and maximum of the lin semantic relatedness measures (lin, 1998) of how similar the head noun of the phrase is to the other nouns in current and immediately preceding sentence surrounding the phrase (calculated with germanet pathfinder; finthammer and cramer, 2008).<papid> L08-1345 </papid></citsent>
<aftsection>
<nextsent>the results are given in table 3b.
</nextsent>
<nextsent>here we see consistent increase in performance of around 4% for each label set over the model that does not include the germanet features.
</nextsent>
<nextsent>again, we see the same decrease in performance on the nissim label set when using gold standard coreference information.
</nextsent>
<nextsent>label set accuracy gold baseline coref.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4081">
<title id=" W11-2120.xml">the uzh system combination system for wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the system compares well to other system combination submissions, with no other submission being significantly better.
</prevsent>
<prevsent>a bleu-basedcomparison to the individual systems, how ever, indicates that it achieves no significant gains over the best individual system.
</prevsent>
</prevsection>
<citsent citstr=" W07-0726 ">
for our submission to the wmt 2011 shared task,we built system with the multi-engine mt approach described in (sennrich, 2011), which builds on the idea by (chen et al, 2007).<papid> W07-0726 </papid></citsent>
<aftsection>
<nextsent>a moses smt system (koehn et al, 2007) <papid> P07-2045 </papid>is used as backbone, trained on the wmt 2011 training data.</nextsent>
<nextsent>translation hypotheses by other systems are integrated througha second phrase table.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4082">
<title id=" W11-2120.xml">the uzh system combination system for wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a bleu-basedcomparison to the individual systems, how ever, indicates that it achieves no significant gains over the best individual system.
</prevsent>
<prevsent>for our submission to the wmt 2011 shared task,we built system with the multi-engine mt approach described in (sennrich, 2011), which builds on the idea by (chen et al, 2007).<papid> W07-0726 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
a moses smt system (koehn et al, 2007) <papid> P07-2045 </papid>is used as backbone, trained on the wmt 2011 training data.</citsent>
<aftsection>
<nextsent>translation hypotheses by other systems are integrated througha second phrase table.
</nextsent>
<nextsent>in this second phrase table, the phrase translation probabilities and lexical weights are computed based on the word and phrase frequencies in both the translation hypotheses and parallel training corpus.
</nextsent>
<nextsent>on the evaluation data in(sennrich, 2011), this system significantly outperformed memt (heafield and lavie, 2010), <papid> W10-1744 </papid>which was among the best-performing system combination tools at wmt 2010 (callison-burch et al, 2010).in this paper, we apply the same approach to different translation scenario, namely the wmt 2011 shared task.</nextsent>
<nextsent>we fail to significantly outperform the best individual system in terms of bleu score.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4083">
<title id=" W11-2120.xml">the uzh system combination system for wmt 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>translation hypotheses by other systems are integrated througha second phrase table.
</prevsent>
<prevsent>in this second phrase table, the phrase translation probabilities and lexical weights are computed based on the word and phrase frequencies in both the translation hypotheses and parallel training corpus.
</prevsent>
</prevsection>
<citsent citstr=" W10-1744 ">
on the evaluation data in(sennrich, 2011), this system significantly outperformed memt (heafield and lavie, 2010), <papid> W10-1744 </papid>which was among the best-performing system combination tools at wmt 2010 (callison-burch et al, 2010).in this paper, we apply the same approach to different translation scenario, namely the wmt 2011 shared task.</citsent>
<aftsection>
<nextsent>we fail to significantly outperform the best individual system in terms of bleu score.
</nextsent>
<nextsent>in section 2, we describe our system combination approach.
</nextsent>
<nextsent>in section 3, we present the results, and discuss possible reasons why the system fails to show the same performance gains as in the translation task on which it was evaluated initially.
</nextsent>
<nextsent>we participated in the system combination task de?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4084">
<title id=" W11-2120.xml">the uzh system combination system for wmt 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>we use news-commentary and europarl as parallel training data.
</prevsent>
<prevsent>the language models area linear interpolation of the news-commentary, eu roparl and news corpora, optimized for minimal cross-entropy on the newstest2008 datasets in the respective target language.
</prevsent>
</prevsection>
<citsent citstr=" D07-1103 ">
additionally, we prune the primary phrase table using statistical significance tests, as described by (johnson et al, 2007).<papid> D07-1103 </papid></citsent>
<aftsection>
<nextsent>for the translation direction deen, the german source text is reordered based 1described at http://www.statmt.org/wmt11/ baseline.html 166 on syntactic parsing with pro3gresde (sennrich etal., 2009), and reordering rules similar to those described by (collins et al, 2005).<papid> P05-1066 </papid>the moses phrase table consists of five features: phrase translation probabilities in both translation directions (p(t|s) and p(s|t)), lexical weights (lex(t|s) and lex(s|t)), and constant phrase penalty (koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>the computation of the phrase translation probabilities and lexical weights is based on the word, phrase and word/phrase pair frequencies that are extracted from the parallel corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4085">
<title id=" W11-2120.xml">the uzh system combination system for wmt 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the language models area linear interpolation of the news-commentary, eu roparl and news corpora, optimized for minimal cross-entropy on the newstest2008 datasets in the respective target language.
</prevsent>
<prevsent>additionally, we prune the primary phrase table using statistical significance tests, as described by (johnson et al, 2007).<papid> D07-1103 </papid></prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
for the translation direction deen, the german source text is reordered based 1described at http://www.statmt.org/wmt11/ baseline.html 166 on syntactic parsing with pro3gresde (sennrich etal., 2009), and reordering rules similar to those described by (collins et al, 2005).<papid> P05-1066 </papid>the moses phrase table consists of five features: phrase translation probabilities in both translation directions (p(t|s) and p(s|t)), lexical weights (lex(t|s) and lex(s|t)), and constant phrase penalty (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the computation of the phrase translation probabilities and lexical weights is based on the word, phrase and word/phrase pair frequencies that are extracted from the parallel corpus.
</nextsent>
<nextsent>we modified the moses training scripts to collect and store these frequencies for later re-use.
</nextsent>
<nextsent>we did not submit the primary system outputs to the machine translation shared task, since we did not experiment with new techniques.
</nextsent>
<nextsent>instead, the primary system forms the backbone of the system combination system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4086">
<title id=" W11-2120.xml">the uzh system combination system for wmt 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>the language models area linear interpolation of the news-commentary, eu roparl and news corpora, optimized for minimal cross-entropy on the newstest2008 datasets in the respective target language.
</prevsent>
<prevsent>additionally, we prune the primary phrase table using statistical significance tests, as described by (johnson et al, 2007).<papid> D07-1103 </papid></prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
for the translation direction deen, the german source text is reordered based 1described at http://www.statmt.org/wmt11/ baseline.html 166 on syntactic parsing with pro3gresde (sennrich etal., 2009), and reordering rules similar to those described by (collins et al, 2005).<papid> P05-1066 </papid>the moses phrase table consists of five features: phrase translation probabilities in both translation directions (p(t|s) and p(s|t)), lexical weights (lex(t|s) and lex(s|t)), and constant phrase penalty (koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the computation of the phrase translation probabilities and lexical weights is based on the word, phrase and word/phrase pair frequencies that are extracted from the parallel corpus.
</nextsent>
<nextsent>we modified the moses training scripts to collect and store these frequencies for later re-use.
</nextsent>
<nextsent>we did not submit the primary system outputs to the machine translation shared task, since we did not experiment with new techniques.
</nextsent>
<nextsent>instead, the primary system forms the backbone of the system combination system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4087">
<title id=" W11-2120.xml">the uzh system combination system for wmt 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 integrating secondary phrase tables.
</prevsent>
<prevsent>to combine the output of several systems, we train second phrase table on the translation hypotheses of these systems.
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
for this, we create parallel corpus consisting of translation hypotheses and copies of the corresponding source text, both lower cased and detokenized.2 we compute the word alignment with mgiza++ (gao and vogel, 2008), <papid> W08-0509 </papid>based on the word alignment model from the primary corpus that we have previously saved to disk.after training phrase table from the word aligned corpus with moses, the lexical weights and translation probabilities are rescored, using the sufficient statistics (i.e. the word, phrase and word/phrase pair counts) of both the primary and the secondary corpus.</citsent>
<aftsection>
<nextsent>this rescoring step has been shown to markedly improve performance in (sennrich, 2011).we will discuss its effects in section 3.1.
</nextsent>
<nextsent>there scored phrase table is integrated into the primary moses system as an alternative decoding path, and tuned for maximal bleu score on newssyscomb tune2011 with mert.
</nextsent>
<nextsent>2for convenience and speed, we combined the translation hypotheses for newssyscombtune2011 and newssyscombtest2011 into single corpus.
</nextsent>
<nextsent>in principle, we could train separate phrase tables for each dataset, or even for arbitrarily low numbers of sentences, without significant loss in performance (see (sennrich, 2011)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4088">
<title id=" W11-2120.xml">the uzh system combination system for wmt 2011 </title>
<section> system description.  </section>
<citcontext>
<prevsection>
<prevsent>for the secondary phrase table, we chose to select the best individual systems according to their bleu score on the tuning set.
</prevsent>
<prevsent>we determined the optimal empirically by trying different n, measuring each systems bleu score on the tuning set and selecting the highest-scoring one.
</prevsent>
</prevsection>
<citsent citstr=" W09-0405 ">
for the deen translation task, = 2 turned out to be optimal, for ende, = 3.chen et al (2009) <papid> W09-0405 </papid>propose additional, tunable features in the phrase table to indicate the origin of phrase translations.</citsent>
<aftsection>
<nextsent>for better comparability with the results described in (sennrich, 2011), we did not add such features.
</nextsent>
<nextsent>this means that there are no priori weights that bias the phrase selection for or against certain systems, but that decoding is purely driven by the usual moses features: two phrase tables ? the primary one and the re-scored, secondary one ? the language model, the primary reordering model, and the corresponding parameters established through mert.
</nextsent>
<nextsent>in the manual evaluation, the system combination submissions are only compared to each other, not to the individual systems.
</nextsent>
<nextsent>according to the manual evaluation, no other system combination submission outperforms ours by statistically significant margin.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4089">
<title id=" W11-2120.xml">the uzh system combination system for wmt 2011 </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>according to the manual evaluation, no other system combination submission outperforms ours by statistically significant margin.
</prevsent>
<prevsent>in comparison to individual systems, however, bleu scores indicate that our system fails to yield significant performance gain over the best individual system in this translation scenario.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
in tables 1 and 2, we present case-insensitivebleu scores (papineni et al, 2002).<papid> P02-1040 </papid></citsent>
<aftsection>
<nextsent>as statistical significance test, we applied bootstrap resam pling (riezler and maxwell, 2005).<papid> W05-0908 </papid></nextsent>
<nextsent>tables 1 and2 show the bleu scores for the translation directions deen and ende, respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4090">
<title id=" W11-2120.xml">the uzh system combination system for wmt 2011 </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>in comparison to individual systems, however, bleu scores indicate that our system fails to yield significant performance gain over the best individual system in this translation scenario.
</prevsent>
<prevsent>in tables 1 and 2, we present case-insensitivebleu scores (papineni et al, 2002).<papid> P02-1040 </papid></prevsent>
</prevsection>
<citsent citstr=" W05-0908 ">
as statistical significance test, we applied bootstrap resam pling (riezler and maxwell, 2005).<papid> W05-0908 </papid></citsent>
<aftsection>
<nextsent>tables 1 and2 show the bleu scores for the translation directions deen and ende, respectively.
</nextsent>
<nextsent>systems included are the primary translation system described 167 system bleu primary 14.99 best individual 17.44 submission 17.51 vanilla scoring 17.32 table 2: ende results.
</nextsent>
<nextsent>case insensitive bleu scores.
</nextsent>
<nextsent>in section 2.1, the best individual system (online-bin both cases) and the submitted combination system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4094">
<title id=" W11-2031.xml">an approach to the automated evaluation of pipeline architectures in natural language dialogue systems </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in apipeline, each user utterance is processed in series of successive processing steps, with the output of each module serving as the input of the next module, until the systems response is determined.
</prevsent>
<prevsent>now at saarland university, germany.while there are many approaches to dialogue system evaluation (see e.g.
</prevsent>
</prevsection>
<citsent citstr=" P97-1035 ">
(walker et al, 1997; <papid> P97-1035 </papid>eckert et al, 1997; walker, 2005)), in many ways, the primary data for assessing the performance of dialogue system comes from the collection of live interactive dialogues between an implemented system and members of its intended user population.</citsent>
<aftsection>
<nextsent>yet,live dialogue-based evaluation suffers from number of limitations and drawbacks.
</nextsent>
<nextsent>each dialogue set can be expensive and time-consuming to collect, and may only reflect specific version of system under active development.
</nextsent>
<nextsent>additional effort is also generally necessary to identify specific system responses as problematic or unacceptable.
</nextsent>
<nextsent>further annotation and analysis is then necessary to diagnose and pinpoint the cause of the problematic responses, so that the relevant pipeline module(s) may be improved.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4096">
<title id=" W11-2031.xml">an approach to the automated evaluation of pipeline architectures in natural language dialogue systems </title>
<section> research setting.  </section>
<citcontext>
<prevsection>
<prevsent>the output of the nlu module (also the input to thedm module) is speech act representation.
</prevsent>
<prevsent>the out put of the dm, which we treat here as the systems response to the user, is also speech act representation.
</prevsent>
</prevsection>
<citsent citstr=" N09-2014 ">
both of these systems use statistical classification models for nlu (leuski and traum, 2010; sagae et al, 2009), <papid> N09-2014 </papid>and finite state machine models for dm (gandhe et al, 2008; rizzo et al, 2011).</citsent>
<aftsection>
<nextsent>target dialogues are annotated versions of dialogues system designer would like the system to support.
</nextsent>
<nextsent>3.1 developing target dialogues.
</nextsent>
<nextsent>wizard-of-oz (woz) and role play dialogues provide valuable data to designers of dialogue systems, especially in the form of natural dialogue data and insights into human-level performance and strategies for the specific dialogue task.
</nextsent>
<nextsent>however, in practice, system builders may not be able to implement all of the strategies and competences of the wizards or role players, and simplifications may be needed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4100">
<title id=" W11-2125.xml">a minimally supervised approach for detecting and ranking document translation pairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to avoid the computational cost of )( 2no document pair comparisons, we employ locality sensitive hashing (lsh) approximation algorithm for cosine similarity, which reduces our time complexity to )log( nno .
</prevsent>
<prevsent>a dearth of parallel data has been, and still is, major problem for developing highly reliable statistical machine translation systems in many languages and domains.
</prevsent>
</prevsection>
<citsent citstr=" J03-3002 ">
there have been many proposed approaches for alleviating this problem by utilizing techniques for creating and extracting parallel documents, sentences or phrases from comparable bilingual data available on the open web (resnik and smith, 2003), <papid> J03-3002 </papid>such as wikipedia articles (smith et. al, 2010), <papid> N10-1063 </papid>to name few, or through digitized archives from various sources (zhao and vogel, 2002), (munteanu and marcu, 2005).<papid> J05-4003 </papid></citsent>
<aftsection>
<nextsent>in general, in the process of utilizing comparable corpora to obtain sentence-aligned bilingual text, the first step involves performing initial filtering where text entities from both language collections are compared to each other and based on comparison score they are matched and grouped as potential translation candidate pairs.
</nextsent>
<nextsent>after this initial step, text entity pairs or tuples are further analyzed in order to extract parallel sentence pairs.
</nextsent>
<nextsent>in this paper we only focus on this initial step.
</nextsent>
<nextsent>we present novel exploration of approaches that retrieve actual document translation pairs without the use of any bilingual resources such as lexicons or sentence aligned bitext.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4101">
<title id=" W11-2125.xml">a minimally supervised approach for detecting and ranking document translation pairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to avoid the computational cost of )( 2no document pair comparisons, we employ locality sensitive hashing (lsh) approximation algorithm for cosine similarity, which reduces our time complexity to )log( nno .
</prevsent>
<prevsent>a dearth of parallel data has been, and still is, major problem for developing highly reliable statistical machine translation systems in many languages and domains.
</prevsent>
</prevsection>
<citsent citstr=" N10-1063 ">
there have been many proposed approaches for alleviating this problem by utilizing techniques for creating and extracting parallel documents, sentences or phrases from comparable bilingual data available on the open web (resnik and smith, 2003), <papid> J03-3002 </papid>such as wikipedia articles (smith et. al, 2010), <papid> N10-1063 </papid>to name few, or through digitized archives from various sources (zhao and vogel, 2002), (munteanu and marcu, 2005).<papid> J05-4003 </papid></citsent>
<aftsection>
<nextsent>in general, in the process of utilizing comparable corpora to obtain sentence-aligned bilingual text, the first step involves performing initial filtering where text entities from both language collections are compared to each other and based on comparison score they are matched and grouped as potential translation candidate pairs.
</nextsent>
<nextsent>after this initial step, text entity pairs or tuples are further analyzed in order to extract parallel sentence pairs.
</nextsent>
<nextsent>in this paper we only focus on this initial step.
</nextsent>
<nextsent>we present novel exploration of approaches that retrieve actual document translation pairs without the use of any bilingual resources such as lexicons or sentence aligned bitext.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4102">
<title id=" W11-2125.xml">a minimally supervised approach for detecting and ranking document translation pairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to avoid the computational cost of )( 2no document pair comparisons, we employ locality sensitive hashing (lsh) approximation algorithm for cosine similarity, which reduces our time complexity to )log( nno .
</prevsent>
<prevsent>a dearth of parallel data has been, and still is, major problem for developing highly reliable statistical machine translation systems in many languages and domains.
</prevsent>
</prevsection>
<citsent citstr=" J05-4003 ">
there have been many proposed approaches for alleviating this problem by utilizing techniques for creating and extracting parallel documents, sentences or phrases from comparable bilingual data available on the open web (resnik and smith, 2003), <papid> J03-3002 </papid>such as wikipedia articles (smith et. al, 2010), <papid> N10-1063 </papid>to name few, or through digitized archives from various sources (zhao and vogel, 2002), (munteanu and marcu, 2005).<papid> J05-4003 </papid></citsent>
<aftsection>
<nextsent>in general, in the process of utilizing comparable corpora to obtain sentence-aligned bilingual text, the first step involves performing initial filtering where text entities from both language collections are compared to each other and based on comparison score they are matched and grouped as potential translation candidate pairs.
</nextsent>
<nextsent>after this initial step, text entity pairs or tuples are further analyzed in order to extract parallel sentence pairs.
</nextsent>
<nextsent>in this paper we only focus on this initial step.
</nextsent>
<nextsent>we present novel exploration of approaches that retrieve actual document translation pairs without the use of any bilingual resources such as lexicons or sentence aligned bitext.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4103">
<title id=" W11-2125.xml">a minimally supervised approach for detecting and ranking document translation pairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for this joint approach, we represent each document in both languages using an n-dimensional feature vector template which consists of the set of intersecting words which are found across all documents in both language collections.
</prevsent>
<prevsent>for each dimension i.e. word, in the feature vector template we calculate tfidf score for the given document.
</prevsent>
</prevsection>
<citsent citstr=" W04-3208 ">
unlike other approaches, where documents or their word representations are first translated from foreign language to english using bilingual dictionary (fung and cheung, 2004), (<papid> W04-3208 </papid>munteanu and marcu, 2005) <papid> J05-4003 </papid>and (uszkoreit et. al., 2010) <papid> C10-1124 </papid>in our approach we dont utilize any existing mt type artifact.</citsent>
<aftsection>
<nextsent>in other words, forgiven language pair we dont use translation lexicon by training an existing statistical machine translation system using sentence aligned parallel bilingual data in the same language or existing translation lexicon.
</nextsent>
<nextsent>earlier work done by enright and kondrak (2007) <papid> N07-2008 </papid>uses only hapax words to represent and rank (based on the overlap number) translation documents pair in parallel bilingual collection which is an easier task to evaluation due to the presence of one-to-one matching among the bilingual documents.</nextsent>
<nextsent>most recently, patry and langlais (2011) <papid> W11-1212 </papid>show an improvement over this method by using an ir system to first retrieve translation document candidates and then identify translation document pairs by training classifier.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4105">
<title id=" W11-2125.xml">a minimally supervised approach for detecting and ranking document translation pairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for this joint approach, we represent each document in both languages using an n-dimensional feature vector template which consists of the set of intersecting words which are found across all documents in both language collections.
</prevsent>
<prevsent>for each dimension i.e. word, in the feature vector template we calculate tfidf score for the given document.
</prevsent>
</prevsection>
<citsent citstr=" C10-1124 ">
unlike other approaches, where documents or their word representations are first translated from foreign language to english using bilingual dictionary (fung and cheung, 2004), (<papid> W04-3208 </papid>munteanu and marcu, 2005) <papid> J05-4003 </papid>and (uszkoreit et. al., 2010) <papid> C10-1124 </papid>in our approach we dont utilize any existing mt type artifact.</citsent>
<aftsection>
<nextsent>in other words, forgiven language pair we dont use translation lexicon by training an existing statistical machine translation system using sentence aligned parallel bilingual data in the same language or existing translation lexicon.
</nextsent>
<nextsent>earlier work done by enright and kondrak (2007) <papid> N07-2008 </papid>uses only hapax words to represent and rank (based on the overlap number) translation documents pair in parallel bilingual collection which is an easier task to evaluation due to the presence of one-to-one matching among the bilingual documents.</nextsent>
<nextsent>most recently, patry and langlais (2011) <papid> W11-1212 </papid>show an improvement over this method by using an ir system to first retrieve translation document candidates and then identify translation document pairs by training classifier.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4106">
<title id=" W11-2125.xml">a minimally supervised approach for detecting and ranking document translation pairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unlike other approaches, where documents or their word representations are first translated from foreign language to english using bilingual dictionary (fung and cheung, 2004), (<papid> W04-3208 </papid>munteanu and marcu, 2005) <papid> J05-4003 </papid>and (uszkoreit et. al., 2010) <papid> C10-1124 </papid>in our approach we dont utilize any existing mt type artifact.</prevsent>
<prevsent>in other words, forgiven language pair we dont use translation lexicon by training an existing statistical machine translation system using sentence aligned parallel bilingual data in the same language or existing translation lexicon.</prevsent>
</prevsection>
<citsent citstr=" N07-2008 ">
earlier work done by enright and kondrak (2007) <papid> N07-2008 </papid>uses only hapax words to represent and rank (based on the overlap number) translation documents pair in parallel bilingual collection which is an easier task to evaluation due to the presence of one-to-one matching among the bilingual documents.</citsent>
<aftsection>
<nextsent>most recently, patry and langlais (2011) <papid> W11-1212 </papid>show an improvement over this method by using an ir system to first retrieve translation document candidates and then identify translation document pairs by training classifier.</nextsent>
<nextsent>we start off by giving detailed explanation of the abovementioned data representation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4107">
<title id=" W11-2125.xml">a minimally supervised approach for detecting and ranking document translation pairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>in other words, forgiven language pair we dont use translation lexicon by training an existing statistical machine translation system using sentence aligned parallel bilingual data in the same language or existing translation lexicon.
</prevsent>
<prevsent>earlier work done by enright and kondrak (2007) <papid> N07-2008 </papid>uses only hapax words to represent and rank (based on the overlap number) translation documents pair in parallel bilingual collection which is an easier task to evaluation due to the presence of one-to-one matching among the bilingual documents.</prevsent>
</prevsection>
<citsent citstr=" W11-1212 ">
most recently, patry and langlais (2011) <papid> W11-1212 </papid>show an improvement over this method by using an ir system to first retrieve translation document candidates and then identify translation document pairs by training classifier.</citsent>
<aftsection>
<nextsent>we start off by giving detailed explanation of the abovementioned data representation.
</nextsent>
<nextsent>we then test the feasibility of our approach using aligned parallel document data from three different bilingual collections in several languages and writing systems.
</nextsent>
<nextsent>results from these tests are given in section 3.
</nextsent>
<nextsent>the goal of developing our approach was to util-.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4108">
<title id=" W11-2125.xml">a minimally supervised approach for detecting and ranking document translation pairs </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>ize it as an initial filtering step in developing parallel corpora from large, multilingual collections, such as the collection of more than 800k english and german books we describe in section 4.
</prevsent>
<prevsent>since we start with no information on the possible translation pairs in our large collection and in order to verify the potential of our method, we first show results on retrieving 17 known parallel book pairs embedded in small randomly selected subset of 1k books (section 4.1).
</prevsent>
</prevsection>
<citsent citstr=" P05-1077 ">
since performing cosine similarity across all document pairs is computationally expensive with time complexity of )( 2no we utilize the lsh based approximation algorithm for the cosine similarity measurement based on the work by ravichandran et. al (2005).<papid> P05-1077 </papid></citsent>
<aftsection>
<nextsent>a brief overview of this approach is given in section 5, which is followed by our implementation results explained and analyzed in section 6.
</nextsent>
<nextsent>to conclude the paper, we give brief outlook on future work.
</nextsent>
<nextsent>in figure 1, we depict the process that we use to represent documents from bilingual collections in vector space and perform similarity measurements.
</nextsent>
<nextsent>we start by computing word frequency count for each of the documents in our collection and creating word frequency list.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4111">
<title id=" W11-2402.xml">towards a probabilistic model for lexical entailment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given two textual fragments, termed hypothesis (h) and text (t ), the text is said to textually entail the hypothesis (th) if person reading the text can infer the meaning of the hypothesis.
</prevsent>
<prevsent>since itwas first introduced, the six rounds of the recognizing textual entailment (rte) challenges1 have be come standard benchmark for entailment systems.
</prevsent>
</prevsection>
<citsent citstr=" W07-1404 ">
entailment systems apply various techniques to tackle this task, including logical inference (tatu and moldovan, 2007; <papid> W07-1404 </papid>maccartney and manning, 2007), <papid> W07-1431 </papid>semantic analysis (burchardt et al, 2007) <papid> W07-1402 </papid>and syntactic parsing (bar-haim et al, 2008; wang 1http://www.nist.gov/tac/et al, 2009).</citsent>
<aftsection>
<nextsent>inference at these levels usually requires substantial processing and resources, aiming at high performance.
</nextsent>
<nextsent>nevertheless, simple lexical level entailment systems pose strong baselines which most complex entailment systems did not outperform (mirkin et al, 2009<papid> E09-1064 </papid>a; majumdar and bhattacharyya, 2010).</nextsent>
<nextsent>additionally, within complex system, lexical entailment modeling is one of themost effective component.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4112">
<title id=" W11-2402.xml">towards a probabilistic model for lexical entailment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given two textual fragments, termed hypothesis (h) and text (t ), the text is said to textually entail the hypothesis (th) if person reading the text can infer the meaning of the hypothesis.
</prevsent>
<prevsent>since itwas first introduced, the six rounds of the recognizing textual entailment (rte) challenges1 have be come standard benchmark for entailment systems.
</prevsent>
</prevsection>
<citsent citstr=" W07-1431 ">
entailment systems apply various techniques to tackle this task, including logical inference (tatu and moldovan, 2007; <papid> W07-1404 </papid>maccartney and manning, 2007), <papid> W07-1431 </papid>semantic analysis (burchardt et al, 2007) <papid> W07-1402 </papid>and syntactic parsing (bar-haim et al, 2008; wang 1http://www.nist.gov/tac/et al, 2009).</citsent>
<aftsection>
<nextsent>inference at these levels usually requires substantial processing and resources, aiming at high performance.
</nextsent>
<nextsent>nevertheless, simple lexical level entailment systems pose strong baselines which most complex entailment systems did not outperform (mirkin et al, 2009<papid> E09-1064 </papid>a; majumdar and bhattacharyya, 2010).</nextsent>
<nextsent>additionally, within complex system, lexical entailment modeling is one of themost effective component.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4113">
<title id=" W11-2402.xml">towards a probabilistic model for lexical entailment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given two textual fragments, termed hypothesis (h) and text (t ), the text is said to textually entail the hypothesis (th) if person reading the text can infer the meaning of the hypothesis.
</prevsent>
<prevsent>since itwas first introduced, the six rounds of the recognizing textual entailment (rte) challenges1 have be come standard benchmark for entailment systems.
</prevsent>
</prevsection>
<citsent citstr=" W07-1402 ">
entailment systems apply various techniques to tackle this task, including logical inference (tatu and moldovan, 2007; <papid> W07-1404 </papid>maccartney and manning, 2007), <papid> W07-1431 </papid>semantic analysis (burchardt et al, 2007) <papid> W07-1402 </papid>and syntactic parsing (bar-haim et al, 2008; wang 1http://www.nist.gov/tac/et al, 2009).</citsent>
<aftsection>
<nextsent>inference at these levels usually requires substantial processing and resources, aiming at high performance.
</nextsent>
<nextsent>nevertheless, simple lexical level entailment systems pose strong baselines which most complex entailment systems did not outperform (mirkin et al, 2009<papid> E09-1064 </papid>a; majumdar and bhattacharyya, 2010).</nextsent>
<nextsent>additionally, within complex system, lexical entailment modeling is one of themost effective component.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4114">
<title id=" W11-2402.xml">towards a probabilistic model for lexical entailment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>entailment systems apply various techniques to tackle this task, including logical inference (tatu and moldovan, 2007; <papid> W07-1404 </papid>maccartney and manning, 2007), <papid> W07-1431 </papid>semantic analysis (burchardt et al, 2007) <papid> W07-1402 </papid>and syntactic parsing (bar-haim et al, 2008; wang 1http://www.nist.gov/tac/et al, 2009).</prevsent>
<prevsent>inference at these levels usually requires substantial processing and resources, aiming at high performance.</prevsent>
</prevsection>
<citsent citstr=" E09-1064 ">
nevertheless, simple lexical level entailment systems pose strong baselines which most complex entailment systems did not outperform (mirkin et al, 2009<papid> E09-1064 </papid>a; majumdar and bhattacharyya, 2010).</citsent>
<aftsection>
<nextsent>additionally, within complex system, lexical entailment modeling is one of themost effective component.
</nextsent>
<nextsent>finally, the simpler lexical approach can be used in cases where complex systems cannot be used, e.g. when there is no parser for targeted language.
</nextsent>
<nextsent>for these reasons lexical entailment systems are widely used.
</nextsent>
<nextsent>they derive sentence-level entailment decision base on lexical-level entailment evidence.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4117">
<title id=" W11-2402.xml">towards a probabilistic model for lexical entailment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such rules are derived from lexical semantic resources, suchas wordnet (fellbaum, 1998), which capture lexical entailment relations.
</prevsent>
<prevsent>common heuristics for quantifying the degree of coverage are setting threshold on the percentage of coverage of hs terms (majumdar and bhattacharyya, 2010), counting the absolute number of uncovered terms (clark and harrison, 2010), or applying an information retrieval-style vector space similarity score (mackinlay and baldwin, 2009).
</prevsent>
</prevsection>
<citsent citstr=" W05-1203 ">
other works (corley and mihalcea, 2005; <papid> W05-1203 </papid>zanzotto and moschitti, 2006) <papid> P06-1051 </papid>have applied heuristic formu 10 las to estimate the similarity between text fragments based on similarity function between their terms.the abovementioned methods do not capture several important aspects of entailment.</citsent>
<aftsection>
<nextsent>such aspects include the varying reliability levels of entailment resources and the impact of rule chaining and multiple evidence on entailment likelihood.
</nextsent>
<nextsent>an additional observation from these and other systems is that their performance improves only moderately when utilizing lexical-semantic resources2.
</nextsent>
<nextsent>we believe that the textual entailment field would benefit from more principled models for various entailment phenomena.
</nextsent>
<nextsent>in this work we formulate aconcrete generative probabilistic modeling framework that captures the basic aspects of lexical entailment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4118">
<title id=" W11-2402.xml">towards a probabilistic model for lexical entailment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>such rules are derived from lexical semantic resources, suchas wordnet (fellbaum, 1998), which capture lexical entailment relations.
</prevsent>
<prevsent>common heuristics for quantifying the degree of coverage are setting threshold on the percentage of coverage of hs terms (majumdar and bhattacharyya, 2010), counting the absolute number of uncovered terms (clark and harrison, 2010), or applying an information retrieval-style vector space similarity score (mackinlay and baldwin, 2009).
</prevsent>
</prevsection>
<citsent citstr=" P06-1051 ">
other works (corley and mihalcea, 2005; <papid> W05-1203 </papid>zanzotto and moschitti, 2006) <papid> P06-1051 </papid>have applied heuristic formu 10 las to estimate the similarity between text fragments based on similarity function between their terms.the abovementioned methods do not capture several important aspects of entailment.</citsent>
<aftsection>
<nextsent>such aspects include the varying reliability levels of entailment resources and the impact of rule chaining and multiple evidence on entailment likelihood.
</nextsent>
<nextsent>an additional observation from these and other systems is that their performance improves only moderately when utilizing lexical-semantic resources2.
</nextsent>
<nextsent>we believe that the textual entailment field would benefit from more principled models for various entailment phenomena.
</nextsent>
<nextsent>in this work we formulate aconcrete generative probabilistic modeling framework that captures the basic aspects of lexical entailment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4119">
<title id=" W11-2402.xml">towards a probabilistic model for lexical entailment </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we believe that the textual entailment field would benefit from more principled models for various entailment phenomena.
</prevsent>
<prevsent>in this work we formulate aconcrete generative probabilistic modeling framework that captures the basic aspects of lexical entailment.
</prevsent>
</prevsection>
<citsent citstr=" P11-2098 ">
a first step in this direction was proposed in shnarch et al (2011) (<papid> P11-2098 </papid>a short paper), where we presented base model with somewhat complicated and difficult to estimate extension to handle cover age.</citsent>
<aftsection>
<nextsent>this paper extends that work to more mature model with new extensions.
</nextsent>
<nextsent>we first consider the logical?
</nextsent>
<nextsent>structure of lexical entailment reasoning and then interpret it in probabilistic terms.
</nextsent>
<nextsent>over this base model we suggest several extensions whose significance is then assessed by our evaluations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4121">
<title id=" W11-2402.xml">towards a probabilistic model for lexical entailment </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>to overcome this problem they suggested simple ad-hoc variant of the cosine similarity score which removed from the textall terms which did not appear in the corresponding hypothesis.
</prevsent>
<prevsent>while this heuristic improved performance considerably, they reported decrease in performance when utilizing synonym and derivation relations from wordnet.on the rte-6 dataset, the syntactic-based system of jia et. al (2010) achieved the best results, only slightly higher than the lexical-level system of (majumdar and bhattacharyya, 2010).
</prevsent>
</prevsection>
<citsent citstr=" W04-3205 ">
the latter utilized several resources for matching hypothesis terms with text terms: wordnet, verb ocean (chklovski and pantel, 2004), <papid> W04-3205 </papid>utilizing two of its relations, as well as an acronym database, number matching module, co-reference resolution and named entity recognition tools.</citsent>
<aftsection>
<nextsent>their final entailment decision was based on threshold over the 11 number of matched hypothesis terms.
</nextsent>
<nextsent>they found out that hypotheses of different length require different thresholds.
</nextsent>
<nextsent>while the above systems measure the number of hypothesis terms matched by the text, clark and harrison (2010) based their entailment decision on the number of mismatched hypothesis terms.
</nextsent>
<nextsent>they utilized both wordnet and the dirt paraphrase database (lin and pantel, 2001).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4122">
<title id=" W11-2402.xml">towards a probabilistic model for lexical entailment </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>glickman et al (2005) presented simple model that recasted the lexical entailment task as variant of text classification and estimated entailment probabilities solely from co-occurrence statistics.
</prevsent>
<prevsent>their model did not utilize any lexical resources.
</prevsent>
</prevsection>
<citsent citstr=" N03-1013 ">
in contrary to these systems, our model shows improvement when utilizing high quality resources such as wordnet and the catvar (categorial variation) database (habash and dorr, 2003).<papid> N03-1013 </papid></citsent>
<aftsection>
<nextsent>as majumdar and bhattacharyya (2010), our model considers the impact of hypothesis length, however it does not require the tuning of unique threshold for each length.
</nextsent>
<nextsent>finally, most of the above systems do not differentiate between the various lexical resources they use, even though it is known that resources reliability vary considerably (mirkin et al, 2009<papid> E09-1064 </papid>b).</nextsent>
<nextsent>our probabilistic model, on the other hand, learns unique reliability parameter for each resource it utilizes.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4131">
<title id=" W11-2402.xml">towards a probabilistic model for lexical entailment </title>
<section> a probabilistic model </section>
<citcontext>
<prevsection>
<prevsent>for term to be entailed by it is enough that at least one of the chains from to would be valid.
</prevsent>
<prevsent>this condition is realized in the model by an or gate.
</prevsent>
</prevsection>
<citsent citstr=" W06-1621 ">
finally, for to lexically entail it is usually assumed that every hh should be entailed by (glickman et al, 2006).<papid> W06-1621 </papid></citsent>
<aftsection>
<nextsent>therefore, the final decision follows an and gate combining the entailment decisions for all hypothesis terms.
</nextsent>
<nextsent>thus, the 1-bit outcome of this gate corresponds to the sentence-level entailment status.
</nextsent>
<nextsent>3.1.2 probabilistic setting when assessing entailment for (t,h) pair, we do not know for sure which rule applications are valid.taking probabilistic perspective, we assume parameter for each resourcer, denoting its reliability, i.e. the prior probability that applying rule from for an arbitrary (t,h) pair corresponds to valid entailment3.
</nextsent>
<nextsent>under this perspective, direct matchs are considered as rules coming from special re source?, for which match is expected to be close to 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4137">
<title id=" W11-2402.xml">towards a probabilistic model for lexical entailment </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>future work is still needed to reflect the impact of transitivity.
</prevsent>
<prevsent>we consider replacing the and gate on the rules of chain by noisy-and, to relax its strict demand that all its input rules must be valid.
</prevsent>
</prevsection>
<citsent citstr=" P08-1078 ">
additionally, we would like to integrate contextual preferences (szpektor et al, 2008) <papid> P08-1078 </papid>and other works on selectional preference (erk and pado, 2010) to verify the validity of the application of rule in specific (t,h) context.</citsent>
<aftsection>
<nextsent>we also intend to explore the contribution of our model within complex system that integrates multiple levels of inference as well as its contribution for other applications, such as passage retrieval.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4138">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for most new problems, however, missing data is the norm,which makes it impossible to train supervised models.
</prevsent>
<prevsent>unsupervised learning techniques can make use of unannotated data and are thus well-suited for these problems.for sequential labeling tasks (pos-tagging, nerecognition), em-trained hmms are the most common unsupervised model.
</prevsent>
</prevsection>
<citsent citstr=" D07-1031 ">
however, running vanilla forward-backward-em leads to mediocre results, due to various properties of the training method (johnson, 2007).<papid> D07-1031 </papid></citsent>
<aftsection>
<nextsent>running repeated restarts with random initialization can help escape local maxima, but in order to find the global optimum, we need to run great number (100 or more) of them (ravi and knight, 2009; <papid> P09-1057 </papid>hovy et al, 2011)<papid> P11-2056 </papid></nextsent>
<nextsent>however, there is another solution.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4139">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised learning techniques can make use of unannotated data and are thus well-suited for these problems.for sequential labeling tasks (pos-tagging, nerecognition), em-trained hmms are the most common unsupervised model.
</prevsent>
<prevsent>however, running vanilla forward-backward-em leads to mediocre results, due to various properties of the training method (johnson, 2007).<papid> D07-1031 </papid></prevsent>
</prevsection>
<citsent citstr=" P09-1057 ">
running repeated restarts with random initialization can help escape local maxima, but in order to find the global optimum, we need to run great number (100 or more) of them (ravi and knight, 2009; <papid> P09-1057 </papid>hovy et al, 2011)<papid> P11-2056 </papid></citsent>
<aftsection>
<nextsent>however, there is another solution.
</nextsent>
<nextsent>various papers have shown that the inclusion of some knowledge greatly enhances performance of unsupervised systems.
</nextsent>
<nextsent>they introduce constraints on the initial model and the parameters.
</nextsent>
<nextsent>this directs the learning algorithm towards better parameter configuration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4141">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised learning techniques can make use of unannotated data and are thus well-suited for these problems.for sequential labeling tasks (pos-tagging, nerecognition), em-trained hmms are the most common unsupervised model.
</prevsent>
<prevsent>however, running vanilla forward-backward-em leads to mediocre results, due to various properties of the training method (johnson, 2007).<papid> D07-1031 </papid></prevsent>
</prevsection>
<citsent citstr=" P11-2056 ">
running repeated restarts with random initialization can help escape local maxima, but in order to find the global optimum, we need to run great number (100 or more) of them (ravi and knight, 2009; <papid> P09-1057 </papid>hovy et al, 2011)<papid> P11-2056 </papid></citsent>
<aftsection>
<nextsent>however, there is another solution.
</nextsent>
<nextsent>various papers have shown that the inclusion of some knowledge greatly enhances performance of unsupervised systems.
</nextsent>
<nextsent>they introduce constraints on the initial model and the parameters.
</nextsent>
<nextsent>this directs the learning algorithm towards better parameter configuration.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4143">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they introduce constraints on the initial model and the parameters.
</prevsent>
<prevsent>this directs the learning algorithm towards better parameter configuration.
</prevsent>
</prevsection>
<citsent citstr=" P07-1036 ">
types of constraints include ilp-based methods (chang et al, 2007;<papid> P07-1036 </papid>chang et al, 2008; ravi and knight, 2009), <papid> P09-1057 </papid>and posterior regularization (graca et al, 2007; ganchev et al., 2010).</citsent>
<aftsection>
<nextsent>while those approaches are powerful and yield good results, they require us to reformulate the constraints in certain language, and either use an external solver, or re-design parts of the maximization step.
</nextsent>
<nextsent>this is time-consuming and requires certain expertise.one of the most natural ways of providing constraints is to annotate small amount of data.
</nextsent>
<nextsent>thiscan either be done manually, or via simple heuristics, for example, if some words?
</nextsent>
<nextsent>parts of speech are unambiguous.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4145">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> preliminaries.  </section>
<citcontext>
<prevsection>
<prevsent>this is encoded in dictionary.
</prevsent>
<prevsent>for pos-tagging, it narrows the possible tags for each word irrespective of context down to manageable set.
</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
merialdo (1994) <papid> J94-2001 </papid>showed how the amount of available dictionary information is correlated withperformance.</citsent>
<aftsection>
<nextsent>however, dictionaries list all applicable labels per word, regardless of context.
</nextsent>
<nextsent>we can often restrict the applicable label for an observation in specific context even more.
</nextsent>
<nextsent>we extend this to include constraints applied to some, but not all instances.
</nextsent>
<nextsent>this allows us to restrict the choice for an observation to one label.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4148">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> preliminaries.  </section>
<citcontext>
<prevsection>
<prevsent>disambiguating prepositions is thus challenging and interesting task in itself (see semeval 2007 task, 32 (litkowski and hargraves, 2007)).
</prevsent>
<prevsent>there are three elements in the syntactic structure of prepositional phrases, namely the head word (usually noun, verb, or adjective), the preposition p, and the object of the preposition, o. the triple (h, p, o) forms syntactically and semantically constrained structure.
</prevsent>
</prevsection>
<citsent citstr=" N09-3017 ">
this structure is reflected in dependency parses as common construction.tratz and hovy (2009) <papid> N09-3017 </papid>show how to use the dependency structure to solve it.</citsent>
<aftsection>
<nextsent>their method outperformed the previous state-of-the-art (which used window-based approach) by significant margin.hovy et al (2011) <papid> P11-2056 </papid>showed how the sequential nature of the problem can be exploited in unsupervised learning.</nextsent>
<nextsent>they present various sequential model sand training options.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4157">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> preliminaries.  </section>
<citcontext>
<prevsection>
<prevsent>for each word, we know the possible labels in general.
</prevsent>
<prevsent>the model has to learn the labels in context.
</prevsent>
</prevsection>
<citsent citstr=" P10-2039 ">
subsequent work (johnson, 2007; <papid> D07-1031 </papid>ravi and knight, 2009; <papid> P09-1057 </papid>vaswani et al., 2010) <papid> P10-2039 </papid>has expanded on this in various ways, with accuracy between 86% and 96%.</citsent>
<aftsection>
<nextsent>in this paper, we do not attempt to beat the state of the art, but rather test whether our constraints can be applied to different task and dataset.
</nextsent>
<nextsent>3.1 data.
</nextsent>
<nextsent>for psd, we use the semeval task data.
</nextsent>
<nextsent>it consists of training (16k) and test set (8k) of sentences with sense-annotated prepositions following the sense inventory of the preposition project, tpp (litkowski, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4158">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> methodology.  </section>
<citcontext>
<prevsection>
<prevsent>we can thus learn different parameter settings for the different prepositions.
</prevsent>
<prevsent>we use em with smoothing and random restarts to train our models.
</prevsent>
</prevsection>
<citsent citstr=" W02-0102 ">
for smoothing,  is added to each fractional count before normalization at each iteration to prevent over fitting (eisner, 2002<papid> W02-0102 </papid>a).</citsent>
<aftsection>
<nextsent>we 33 set  to 0.01.
</nextsent>
<nextsent>we stop training after 40 iterations, or if the perplexity change between iterations was less than 0.0001.
</nextsent>
<nextsent>we experimented with different numbers of random restarts (none, 10, 50, and 100).
</nextsent>
<nextsent>3.3 dealing with partial annotations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4163">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we also test the effect more unsupervised data has on the task.
</prevsent>
<prevsent>theoretically, unsupervised methods should be able to exploit additional training data.
</prevsent>
</prevsection>
<citsent citstr=" H94-1048 ">
we use 27k examples extracted from the prepositional attachment corpus from ratnaparkhi et al (1994).<papid> H94-1048 </papid></citsent>
<aftsection>
<nextsent>4.2 what kind of annotation is needed?.
</nextsent>
<nextsent>we can assume that not only the quantity, but also the distribution of the partial annotations makes adifference.
</nextsent>
<nextsent>given that we can only annotate certain percentage of the data, how should we best distribute those annotations among instances to maximize accuracy?
</nextsent>
<nextsent>in order to test this, we hold the amount of annotated data fixed, but vary the labels we use.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4166">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>data, 10 rr 62.47 semi-supervised, addtl.
</prevsent>
<prevsent>data, 50 rr 62.58 semi-supervised, addtl.
</prevsent>
</prevsection>
<citsent citstr=" C10-2052 ">
data, 100 rr 62.58 supervised (hovy et al, 2010) <papid> C10-2052 </papid>84.50 table 1: accuracy of various psd systems.</citsent>
<aftsection>
<nextsent>baseline is most frequent sense.
</nextsent>
<nextsent>table 1 shows the results for the psd systems wetested.
</nextsent>
<nextsent>since not all test sets are the same size, we report the weighted average over all prepositions.
</nextsent>
<nextsent>for significance tests, we use two-tailed t-tests over the difference inaccuracy at   0.001.the difference between our models and the base line as well as the best unsupervised models inhovy et al (2011) <papid> P11-2056 </papid>are significant.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4171">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>it seems surprising, though, that the model does not benefit from the additional data1.
</prevsent>
<prevsent>more aggressive smoothing might help alleviate that prob lem.the results on the distribution of partial annotation are shown in figure 4.
</prevsent>
</prevsection>
<citsent citstr=" P05-1044 ">
using only the most1note that similar effects were observed by (smith and eisner, 2005; <papid> P05-1044 </papid>goldwater and griffiths, 2007).<papid> P07-1094 </papid></citsent>
<aftsection>
<nextsent>35 010 20 30 40 50 60 70 80 90 100 all 1st 2nd 3rd 4th 5th one each 53.55 48.77 44.71 43.00 45.65 49.69 63.12 c u a y ( % ) senses used figure 4: labeling one example of each sense yields better results than all examples of any one sense.
</nextsent>
<nextsent>senses ordered by frequency frequent sense, accuracy drops to 49.69%.
</nextsent>
<nextsent>while this is better than the baseline which simply assigns this sense to every instance, it is steep drop.
</nextsent>
<nextsent>we get better results using just one annotated example of each sense (53.55%).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4172">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>it seems surprising, though, that the model does not benefit from the additional data1.
</prevsent>
<prevsent>more aggressive smoothing might help alleviate that prob lem.the results on the distribution of partial annotation are shown in figure 4.
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
using only the most1note that similar effects were observed by (smith and eisner, 2005; <papid> P05-1044 </papid>goldwater and griffiths, 2007).<papid> P07-1094 </papid></citsent>
<aftsection>
<nextsent>35 010 20 30 40 50 60 70 80 90 100 all 1st 2nd 3rd 4th 5th one each 53.55 48.77 44.71 43.00 45.65 49.69 63.12 c u a y ( % ) senses used figure 4: labeling one example of each sense yields better results than all examples of any one sense.
</nextsent>
<nextsent>senses ordered by frequency frequent sense, accuracy drops to 49.69%.
</nextsent>
<nextsent>while this is better than the baseline which simply assigns this sense to every instance, it is steep drop.
</nextsent>
<nextsent>we get better results using just one annotated example of each sense (53.55%).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4177">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>while em is guaranteed to improve the data likelihood, it can get stuck in local maxima.
</prevsent>
<prevsent>merialdo (1994) <papid> J94-2001 </papid>showed how the the initial ized model influences the outcome after fixed number of iterations.</prevsent>
</prevsection>
<citsent citstr=" P08-1085 ">
the importance is underscored succinctly by goldberg et al (2008).<papid> P08-1085 </papid></citsent>
<aftsection>
<nextsent>they experiment with various constraints.
</nextsent>
<nextsent>the idea of using partial annotations has been explored in various settings.
</nextsent>
<nextsent>druck et al (2008) present an approach to label features instead of instances for discriminative probabilistic models, yielding substantial improvements.
</nextsent>
<nextsent>they also study the effectiveness of labeling features vs. labeling instances.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4178">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>druck et al (2008) present an approach to label features instead of instances for discriminative probabilistic models, yielding substantial improvements.
</prevsent>
<prevsent>they also study the effectiveness of labeling features vs. labeling instances.
</prevsent>
</prevsection>
<citsent citstr=" W09-3003 ">
rehbein et al (2009) <papid> W09-3003 </papid>study the utility of partial annotations as precursor to further, humanannotation.</citsent>
<aftsection>
<nextsent>their experiments do not extend to unsupervised training.
</nextsent>
<nextsent>tsuboi et al (2008) <papid> C08-1113 </papid>used data that was not full annotated.</nextsent>
<nextsent>however, their setting is in principle supervised, only few words are miss ing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4179">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>rehbein et al (2009) <papid> W09-3003 </papid>study the utility of partial annotations as precursor to further, humanannotation.</prevsent>
<prevsent>their experiments do not extend to unsupervised training.</prevsent>
</prevsection>
<citsent citstr=" C08-1113 ">
tsuboi et al (2008) <papid> C08-1113 </papid>used data that was not full annotated.</citsent>
<aftsection>
<nextsent>however, their setting is in principle supervised, only few words are missing.
</nextsent>
<nextsent>instead of no labels, those words have limited number of possible alternatives.
</nextsent>
<nextsent>this works well for tasks with small label alphabet or data where annotators left multiple options for some words.
</nextsent>
<nextsent>in contrast, we start out with unannotated data and assume that some words can be labeled.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4180">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> related research.  </section>
<citcontext>
<prevsection>
<prevsent>this works well for tasks with small label alphabet or data where annotators left multiple options for some words.
</prevsent>
<prevsent>in contrast, we start out with unannotated data and assume that some words can be labeled.
</prevsent>
</prevsection>
<citsent citstr=" W10-1701 ">
gao et al (2010) <papid> W10-1701 </papid>present successful word alignment approach that uses partial annotations.</citsent>
<aftsection>
<nextsent>these are derived from human annotation or heuristics.
</nextsent>
<nextsent>their method improves bleu, but requires some modification of the em framework.
</nextsent>
<nextsent>it is obvious, and common knowledge, that providing some annotation to an unsupervised algorithm will improve accuracy and learning speed.
</nextsent>
<nextsent>surprisingly, however, our literature search did not turn up any papers stating exactly how and to what degree the improvements appear.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4181">
<title id=" W12-1905.xml">exploiting partial annotations with em training </title>
<section> conclusion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>given that we can only annotate certain percentage of the data, it isbest to distribute those annotations among all applicable senses, rather than focus on one.
</prevsent>
<prevsent>this obviates the need for random restarts and speeds up training.this work suggests several interesting new avenues to explore.
</prevsent>
</prevsection>
<citsent citstr=" C08-1142 ">
can one integrate this procedure into large-scale human annotation effort to obtain kind of active learning, suggesting which instances to annotate next, until appropriate stopping criteria are satisfied (zhu et al, 2008)?<papid> C08-1142 </papid></citsent>
<aftsection>
<nextsent>can one determine upper bounds for the number of random restarts given the amount of annotations?
</nextsent>
<nextsent>acknowledgements we would like to thank victoria fossum, kevin knight, zornitsa kozareva, and ashish vaswani for invaluable discussions and advice.
</nextsent>
<nextsent>we would also like to thank the reviewers who provided us with helpful feedback and suggestions.
</nextsent>
<nextsent>research supported in part by air force contract fa8750-09-c 0172 under the darpa machine reading program.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4182">
<title id=" W11-1904.xml">inference protocols for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>and link them to an underlying set of referents.
</prevsent>
<prevsent>human readers use syntactic and semantic cues to identify and disambiguate the referring phrases; successful automated system must replicate this behavior by linking mentions that refer to the same underlying entity.this paper describes illinois-coref, coreference resolution system built on learning based java (rizzolo and roth, 2010), that participated in the closed?
</prevsent>
</prevsection>
<citsent citstr=" W11-1901 ">
track of the conll-2011 shared task (pradhan et al, 2011).<papid> W11-1901 </papid></citsent>
<aftsection>
<nextsent>building on elements of the coreference system described in bengtson and roth (2008), <papid> D08-1031 </papid>we design an end-to-end system (sec.</nextsent>
<nextsent>2) that identifies candidate mentions and then applies one of two inference protocols, best-linkand all-link (sec.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4183">
<title id=" W11-1904.xml">inference protocols for coreference resolution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>human readers use syntactic and semantic cues to identify and disambiguate the referring phrases; successful automated system must replicate this behavior by linking mentions that refer to the same underlying entity.this paper describes illinois-coref, coreference resolution system built on learning based java (rizzolo and roth, 2010), that participated in the closed?
</prevsent>
<prevsent>track of the conll-2011 shared task (pradhan et al, 2011).<papid> W11-1901 </papid></prevsent>
</prevsection>
<citsent citstr=" D08-1031 ">
building on elements of the coreference system described in bengtson and roth (2008), <papid> D08-1031 </papid>we design an end-to-end system (sec.</citsent>
<aftsection>
<nextsent>2) that identifies candidate mentions and then applies one of two inference protocols, best-linkand all-link (sec.
</nextsent>
<nextsent>2.3), to disambiguate and cluster them.
</nextsent>
<nextsent>these protocols were designed to easily incorporate domain knowledge in the form of constraints.
</nextsent>
<nextsent>in sec.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4191">
<title id=" W12-0509.xml">collaborative annotation of dialogue acts application of a new iso standard to the switchboard corpus </title>
<section> corpus resource.  </section>
<citcontext>
<prevsection>
<prevsent>in the end, the 303 tags were clustered into 60 different individual communicative functions.
</prevsent>
<prevsent>see table 2 for the basic statistics of the 60 da clusters.
</prevsent>
</prevsection>
<citsent citstr=" J00-3003 ">
according to table 2, we observe that the 60 da clusters range from 780,570 word tokens for the top-ranking statement-non-opinion to only 4 word 2 past studies (e.g. stolcke et al, 2000; <papid> J00-3003 </papid>jurafsky et al,.</citsent>
<aftsection>
<nextsent>1997; jurafsky et al, 1998<papid> W98-0319 </papid>a; jurafsky et al, 1998<papid> W98-0319 </papid>b) have been focused on only 1115 conversations in the swbd-da corpus as the training set.</nextsent>
<nextsent>as there is no clear description which 40 conversations have been used as the testing set or for future use, we use all the 1155 conversations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4192">
<title id=" W12-0509.xml">collaborative annotation of dialogue acts application of a new iso standard to the switchboard corpus </title>
<section> corpus resource.  </section>
<citcontext>
<prevsection>
<prevsent>see table 2 for the basic statistics of the 60 da clusters.
</prevsent>
<prevsent>according to table 2, we observe that the 60 da clusters range from 780,570 word tokens for the top-ranking statement-non-opinion to only 4 word 2 past studies (e.g. stolcke et al, 2000; <papid> J00-3003 </papid>jurafsky et al,.</prevsent>
</prevsection>
<citsent citstr=" W98-0319 ">
1997; jurafsky et al, 1998<papid> W98-0319 </papid>a; jurafsky et al, 1998<papid> W98-0319 </papid>b) have been focused on only 1115 conversations in the swbd-da corpus as the training set.</citsent>
<aftsection>
<nextsent>as there is no clear description which 40 conversations have been used as the testing set or for future use, we use all the 1155 conversations.
</nextsent>
<nextsent>tokens for youre-welcome.
</nextsent>
<nextsent>in table 2, the token % column lists the relative importance of da types measured as the proportion of the word tokens in the swbd-da corpus as whole.
</nextsent>
<nextsent>it can be observed that, as yet another example to illustrate the uneven use of da types, statement-opinion accounts for 21.04% of the total number of word tokens in the corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4196">
<title id=" W12-1528.xml">shared task proposal syntactic paraphrase ranking </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>as explained further below, developers of realization systems that can generate and optionally rank multiple outputs forgiven input will be encouraged to participate in the task, which will test the systems ability to produce acceptable paraphrases and/or to rank competing realizations.
</prevsent>
<prevsent>the objectives of the shared task are as follows: broaden participation we expect developers of automatic quality metrics in the mt community to be interested in the proposed task, which is anticipated to be both more focused (withlexical choice largely excluded) and more challenging than in the mt case, given the generally high level of quality in realization results: as realization quality increases, the metrics task becomes more difficult, since the paraphrases of given sentence often involve subtle differences between acceptable and unacceptable variation.
</prevsent>
</prevsection>
<citsent citstr=" D10-1055 ">
in an earlier study of the utility of automatic metrics with penn tree bank (ptb) surface realization data (espinosaet al , 2010), <papid> D10-1055 </papid>we observed moderate correlations between the most popular metrics and human judgments, though lower than the levels seen with mt data.</citsent>
<aftsection>
<nextsent>promote reuse of human judgments the task is intended to test the effectiveness of realization ranking models in way that reuses human judgments, making it possible to carry out re 150 track reference ptb ptb sentence gold auto realization ranking y hybrid y metrics meta-eval n table 1: additional inputs for the three realization tracks producible system comparisons.mitigate input conversion issues realizer evaluations have typically focused on single-best outputs, where the depth and specificity of system inputs has large impact on quality, making comparative evaluation difficult.
</nextsent>
<nextsent>while the surface realization shared task seeks to address this issue by developing common ground input representations, to date it has proved to be difficult to adapt existing systems to work with these inputs.
</nextsent>
<nextsent>by focusing on ranking paraphrases that are distinct from the reference sentence, the proposed task may provide way to mitigate these issues, as discussed below.
</nextsent>
<nextsent>ranking to metrics meta-evaluation we propose three tracks for the task, going from pure realization ranking to metrics meta-evaluation, with hybrid case in the middle.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4198">
<title id=" W12-1528.xml">shared task proposal syntactic paraphrase ranking </title>
<section> pilot experiments.  </section>
<citcontext>
<prevsection>
<prevsent>in this section, we present two pilot experiments intended to demonstrate the feasibility of the task.
</prevsent>
<prevsent>the experiments use the human judgments collected in espinosa et al (2010) <papid> D10-1055 </papid>study, which consist of adequacy and fluency ratings from two judges for variety of realizations for ptb section 00.</prevsent>
</prevsection>
<citsent citstr=" D09-1043 ">
the realizations in the corpus were generated using several openccg realization ranking models (white and rajkumar, 2009) <papid> D09-1043 </papid>and using the xle symbolic re alizer with subsequent n-gram ranking (paraphrases involving wordnet substitutions were excluded).for comparison purposes, three well-known metrics (bleu, meteor and ter) were tested, along with three openccg ranking models: (i) generative baseline model, incorporating three n-grammodels as well as hockenmaiers (2003) generative model; (ii) model additionally incorporating slew of discriminative features, extending white&amp; rajkumars model with dependency ordering features; and (iii) model adding one additional feature for minimizing dependency length.</citsent>
<aftsection>
<nextsent>note that models ii and iii are very similar, usually yielding the same single-best output, though occasionally differing in important ways; by contrast, both models represent substantial refinement of model i.the two experiments investigate different strategies for approaching the hybrid task.
</nextsent>
<nextsent>the first experiment investigates the approximating-hter strategy (with an analysis-by-synthesis component) using 20-best list.
</nextsent>
<nextsent>for simplicity, edit rate (edit distance normalized by the number of words in the reference sentence) was used to find the realization in the 20-best list that was closest to the paraphrase to be ranked.
</nextsent>
<nextsent>the score for the paraphrase was then calculated by normalizing the realizer model score for the closest realization (linearly interpol ating using the min and max scores across all 20-best lists),subtracting the edit rate, and adding in the metric score, for each of bleu, meteor and ter.1 since edit rate is less reliable than ter, as it overly penalizes phrasal shifts, the metric score was used alone in cases where the edit rate exceeded 0.5.the results of the first experiment appear in table 2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4199">
<title id=" W11-2308.xml">read8211it assessing readability of italian texts with a view to text simplification </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>these approaches can be seen as generalization of the vocabulary-based approach, aimed at capturing finer-grained and more flexible information about vocabulary usage.
</prevsent>
<prevsent>if un igram language models help capturing important content information and variation of word usage, they do not cover other types of features which are reported to play significant role in the assessment of readability.
</prevsent>
</prevsection>
<citsent citstr=" P05-1065 ">
more recently, the role of syntactic features started being investigated (schwarm and ostendorf, 2005; <papid> P05-1065 </papid>heilman et al, 2007; <papid> N07-1058 </papid>petersen and ostendorf, 2009): in these studies syntactic structure is tracked through combination of features from ngram (trigram, bigram and unigram) language models and parse trees (parse tree height, number of noun phrases, verb phrases and subordinated clauses or sbars) with more traditional features.yet, besides lexical and syntactic complexity features there are other important factors, such as the structure of the text, the definition of discourse topic,discourse cohesion and coherence and so on, play 74ing central role in determining the reading difficulty of text.</citsent>
<aftsection>
<nextsent>more recent approaches esplored the role of these features in readability assessment:this is the case, for instance, of barzilay and lap ata (2008) <papid> J08-1001 </papid>or feng (2010).</nextsent>
<nextsent>the last few years have been characterised by approaches based on the combination of features ranging over different linguistic levels, namely lexical, syntactic and discourse (see e.g. pitler and nenkova (2008), <papid> D08-1020 </papid>kate (2010)).another important factor determining the typology of features to be considered for assessing read ability has to do with the intended audience of readers: it is commonly agreed that reading ease does not follow from intrinsic text properties alone, but it is also affected by the expected audience.among the studies addressing readability with respect to specific audiences, it is worth mentioning here: schwarm and ostendorf (2005) <papid> P05-1065 </papid>and heilman et al (2007) <papid> N07-1058 </papid>dealing with language learners, or feng (2009) focussing on people with mild intellectualdisabilities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4201">
<title id=" W11-2308.xml">read8211it assessing readability of italian texts with a view to text simplification </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>these approaches can be seen as generalization of the vocabulary-based approach, aimed at capturing finer-grained and more flexible information about vocabulary usage.
</prevsent>
<prevsent>if un igram language models help capturing important content information and variation of word usage, they do not cover other types of features which are reported to play significant role in the assessment of readability.
</prevsent>
</prevsection>
<citsent citstr=" N07-1058 ">
more recently, the role of syntactic features started being investigated (schwarm and ostendorf, 2005; <papid> P05-1065 </papid>heilman et al, 2007; <papid> N07-1058 </papid>petersen and ostendorf, 2009): in these studies syntactic structure is tracked through combination of features from ngram (trigram, bigram and unigram) language models and parse trees (parse tree height, number of noun phrases, verb phrases and subordinated clauses or sbars) with more traditional features.yet, besides lexical and syntactic complexity features there are other important factors, such as the structure of the text, the definition of discourse topic,discourse cohesion and coherence and so on, play 74ing central role in determining the reading difficulty of text.</citsent>
<aftsection>
<nextsent>more recent approaches esplored the role of these features in readability assessment:this is the case, for instance, of barzilay and lap ata (2008) <papid> J08-1001 </papid>or feng (2010).</nextsent>
<nextsent>the last few years have been characterised by approaches based on the combination of features ranging over different linguistic levels, namely lexical, syntactic and discourse (see e.g. pitler and nenkova (2008), <papid> D08-1020 </papid>kate (2010)).another important factor determining the typology of features to be considered for assessing read ability has to do with the intended audience of readers: it is commonly agreed that reading ease does not follow from intrinsic text properties alone, but it is also affected by the expected audience.among the studies addressing readability with respect to specific audiences, it is worth mentioning here: schwarm and ostendorf (2005) <papid> P05-1065 </papid>and heilman et al (2007) <papid> N07-1058 </papid>dealing with language learners, or feng (2009) focussing on people with mild intellectualdisabilities.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4203">
<title id=" W11-2308.xml">read8211it assessing readability of italian texts with a view to text simplification </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>if un igram language models help capturing important content information and variation of word usage, they do not cover other types of features which are reported to play significant role in the assessment of readability.
</prevsent>
<prevsent>more recently, the role of syntactic features started being investigated (schwarm and ostendorf, 2005; <papid> P05-1065 </papid>heilman et al, 2007; <papid> N07-1058 </papid>petersen and ostendorf, 2009): in these studies syntactic structure is tracked through combination of features from ngram (trigram, bigram and unigram) language models and parse trees (parse tree height, number of noun phrases, verb phrases and subordinated clauses or sbars) with more traditional features.yet, besides lexical and syntactic complexity features there are other important factors, such as the structure of the text, the definition of discourse topic,discourse cohesion and coherence and so on, play 74ing central role in determining the reading difficulty of text.</prevsent>
</prevsection>
<citsent citstr=" J08-1001 ">
more recent approaches esplored the role of these features in readability assessment:this is the case, for instance, of barzilay and lap ata (2008) <papid> J08-1001 </papid>or feng (2010).</citsent>
<aftsection>
<nextsent>the last few years have been characterised by approaches based on the combination of features ranging over different linguistic levels, namely lexical, syntactic and discourse (see e.g. pitler and nenkova (2008), <papid> D08-1020 </papid>kate (2010)).another important factor determining the typology of features to be considered for assessing read ability has to do with the intended audience of readers: it is commonly agreed that reading ease does not follow from intrinsic text properties alone, but it is also affected by the expected audience.among the studies addressing readability with respect to specific audiences, it is worth mentioning here: schwarm and ostendorf (2005) <papid> P05-1065 </papid>and heilman et al (2007) <papid> N07-1058 </papid>dealing with language learners, or feng (2009) focussing on people with mild intellectualdisabilities.</nextsent>
<nextsent>interestingly,heilman et al (2007) <papid> N07-1058 </papid>differentiate the typology of used features when addressing first (l1) or second (l2) language learn ers: they argue that grammatical features are more relevant for l2 than for l1 learners.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4204">
<title id=" W11-2308.xml">read8211it assessing readability of italian texts with a view to text simplification </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>more recently, the role of syntactic features started being investigated (schwarm and ostendorf, 2005; <papid> P05-1065 </papid>heilman et al, 2007; <papid> N07-1058 </papid>petersen and ostendorf, 2009): in these studies syntactic structure is tracked through combination of features from ngram (trigram, bigram and unigram) language models and parse trees (parse tree height, number of noun phrases, verb phrases and subordinated clauses or sbars) with more traditional features.yet, besides lexical and syntactic complexity features there are other important factors, such as the structure of the text, the definition of discourse topic,discourse cohesion and coherence and so on, play 74ing central role in determining the reading difficulty of text.</prevsent>
<prevsent>more recent approaches esplored the role of these features in readability assessment:this is the case, for instance, of barzilay and lap ata (2008) <papid> J08-1001 </papid>or feng (2010).</prevsent>
</prevsection>
<citsent citstr=" D08-1020 ">
the last few years have been characterised by approaches based on the combination of features ranging over different linguistic levels, namely lexical, syntactic and discourse (see e.g. pitler and nenkova (2008), <papid> D08-1020 </papid>kate (2010)).another important factor determining the typology of features to be considered for assessing read ability has to do with the intended audience of readers: it is commonly agreed that reading ease does not follow from intrinsic text properties alone, but it is also affected by the expected audience.among the studies addressing readability with respect to specific audiences, it is worth mentioning here: schwarm and ostendorf (2005) <papid> P05-1065 </papid>and heilman et al (2007) <papid> N07-1058 </papid>dealing with language learners, or feng (2009) focussing on people with mild intellectualdisabilities.</citsent>
<aftsection>
<nextsent>interestingly,heilman et al (2007) <papid> N07-1058 </papid>differentiate the typology of used features when addressing first (l1) or second (l2) language learn ers: they argue that grammatical features are more relevant for l2 than for l1 learners.</nextsent>
<nextsent>feng (2009)propose set of cognitively motivated features operating at the discourse level specifically addressing the cognitive characteristics of the expected users.when readability is targeted towards adult competent language users more prominent role is played by discourse features (pitler and nenkova, 2008).<papid> D08-1020 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4213">
<title id=" W11-2308.xml">read8211it assessing readability of italian texts with a view to text simplification </title>
<section> our approach.  </section>
<citcontext>
<prevsection>
<prevsent>last but not least, as already done by aluisio et al (2010) the set of selected syntactic features also includes simplification oriented ones, with the final aim of aligning the readability assessment step with the text simplification process.
</prevsent>
<prevsent>another qualifying feature of our approach to readability assessment consists in the fact that weare dealing with two types of textual objects: documents and sentences.
</prevsent>
</prevsection>
<citsent citstr=" W10-1007 ">
the latter represents an important novelty of our work since so far most research focused on readability classification at the document level (skory and eskenazi, 2010).<papid> W10-1007 </papid></citsent>
<aftsection>
<nextsent>when the target application is text simplification, we strongly believe that also assessing readability at the sentence level could be very useful.
</nextsent>
<nextsent>we know that methods developed so far perform well to characterize the level of an entire document, but they are unreliable for short texts and thus also for single sentences.sentence-based readability assessment thus represents further challenge we decided to tackle: in fact, if all sentences occurring in simplified texts can be assumed to be easy-to-read sentences, the reverse does not necessarily hold since not all sentences occurring in complex texts are difficult-to-read sen 75tences.
</nextsent>
<nextsent>since there are no training data at the sentence level, it becomes difficult ? if not impossible ? to evaluate the effectiveness of our approach, i.e. erroneous readability assessments within the class of difficult-to-read texts may either correspond tothose easytoread sentences occurring within complex texts or represent real classification errors.
</nextsent>
<nextsent>inorder to overcome this problem in the readability assessment of individual sentences, we introduced anotion of distance with respect to easy-to-read sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4222">
<title id=" W11-2308.xml">read8211it assessing readability of italian texts with a view to text simplification </title>
<section> readit.  </section>
<citcontext>
<prevsection>
<prevsent>of embedded subordinate clause sand b) the probability distribution of embedded subordinate clauses chains?
</prevsent>
<prevsent>by depth.
</prevsent>
</prevsection>
<citsent citstr=" C96-2123 ">
length of dependency links feature: both lin (1996) <papid> C96-2123 </papid>and gibson (1998) showed that the syntactic complexity of sentences can be predicted with measures based on the length of dependency links.</citsent>
<aftsection>
<nextsent>this is also demonstrated in mcdonald and nivre (2007)<papid> D07-1013 </papid>who claim that statistical parsers have drop in accuracy when analysing long dependencies.</nextsent>
<nextsent>here, the 77 dependency length is measured in terms of the words occurring between the syntactic head and the dependent.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4223">
<title id=" W11-2308.xml">read8211it assessing readability of italian texts with a view to text simplification </title>
<section> readit.  </section>
<citcontext>
<prevsection>
<prevsent>by depth.
</prevsent>
<prevsent>length of dependency links feature: both lin (1996) <papid> C96-2123 </papid>and gibson (1998) showed that the syntactic complexity of sentences can be predicted with measures based on the length of dependency links.</prevsent>
</prevsection>
<citsent citstr=" D07-1013 ">
this is also demonstrated in mcdonald and nivre (2007)<papid> D07-1013 </papid>who claim that statistical parsers have drop in accuracy when analysing long dependencies.</citsent>
<aftsection>
<nextsent>here, the 77 dependency length is measured in terms of the words occurring between the syntactic head and the dependent.
</nextsent>
<nextsent>this feature is the dependency-based counterpart of the phrase length?
</nextsent>
<nextsent>feature used for readability assessment by nenkova (2010) and feng (2010).
</nextsent>
<nextsent>one challenge in this work was finding an appropriate corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4224">
<title id=" W11-2308.xml">read8211it assessing readability of italian texts with a view to text simplification </title>
<section> experiments and results.  </section>
<citcontext>
<prevsection>
<prevsent>as already pointed out, such distinction is reliable in document classification scenario, while at the sentence classification level it poses the remarkable issue of discerning easytoread sentences within difficulttoread documents (i.e. rep).
</prevsent>
<prevsent>readit was tested on the 2par and rep corpora automatically pos tagged by the partof?
</prevsent>
</prevsection>
<citsent citstr=" W06-2922 ">
speech tagger described in dellorletta (2009) and dependency parsed by the desr parser (attardi,2006) <papid> W06-2922 </papid>using support vector machine as learning al gorithm.</citsent>
<aftsection>
<nextsent>three different sets of experiments were devised to test the performance of read-it in the following subtasks: i) document readability classification, ii) sentence readability classification and iii) detection of easytoread sentences within difficult?
</nextsent>
<nextsent>78 toread texts.
</nextsent>
<nextsent>for what concerns the document classificationsubtask, we used corpus made up of 638 documents of which 319 were extracted from 2par (taken as representative of the class easytoread texts) and 319 from rep (representing the class of difficult?
</nextsent>
<nextsent>toread texts).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4225">
<title id=" W12-0404.xml">in search of a gold standard in studies of deception </title>
<section> non-gold standard approaches.  </section>
<citcontext>
<prevsection>
<prevsent>first, many of the same challenges that face manual annotation efforts inother domains also applies to annotations of deception.
</prevsent>
<prevsent>for example, manual annotations can be expensive to obtain, especially in large-scale settings, e.g., the web.most seriously however, is that human ability to detect deception is notoriously poor (bond and depaulo, 2006).
</prevsent>
</prevsection>
<citsent citstr=" P11-1032 ">
indeed, recent studies have confirmed that human agreement and deception detection performance is often no better than chance (ott et al, 2011); <papid> P11-1032 </papid>this is especially the 25 case when considering the over trusting nature of most human judges, phenomenon referred to in the psychological deception literature as truth bias (vrij, 2008).</citsent>
<aftsection>
<nextsent>3.2 heuristic ally labeled.
</nextsent>
<nextsent>work by jindal and liu (2008) studying the characteristics of untruthful (deceptive) amazon.com reviews, has instead developed an approach forheuristically assigning approximate labels of deceptive ness, based on set of assumptions specific to their domain.
</nextsent>
<nextsent>in particular, after removing certain types of irrelevant reviews,?
</nextsent>
<nextsent>e.g., questions, advertisements, etc., they determine whether each review has been duplicated, i.e., whether the reviews text heavily overlaps with the text of other reviews in the same corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4226">
<title id=" W12-0404.xml">in search of a gold standard in studies of deception </title>
<section> crowdsourcing approaches.  </section>
<citcontext>
<prevsection>
<prevsent>craigs list, while not crowdsourcing platform, also promotes similar solicitations for writing.
</prevsent>
<prevsent>in the case of fake online reviews (see section 5), and by leveraging platforms such as mechanical turk, we can often generate gold standard deceptive content in contexts very similar to those observed in practice.
</prevsent>
</prevsection>
<citsent citstr=" P09-2078 ">
mihalcea and strapparava (2009) <papid> P09-2078 </papid>were among the first to use mechanical turk to collect deceptive and truthful opinions ? personal stances on issues such as abortion and the death penalty.</citsent>
<aftsection>
<nextsent>in particular, forgiven topic, they solicited one truthful and one deceptive stance from each mechanical turk participant.
</nextsent>
<nextsent>ott et al (2011)<papid> P11-1032 </papid>have also used mechanical turk to produce gold standard deceptive content.in particular, they use mechanical turk to generate dataset of 400 positive (5-star), gold standard deceptive hotel reviews.</nextsent>
<nextsent>these were combined with 400 (positive) truthful reviews covering the same set of hotels and used to train alearning-based classifier that could distinguish deceptive vs. truthful positive reviews at 90% accuracy levels.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4259">
<title id=" W11-1812.xml">overview of the entity relations rel supporting task of bionlp shared task 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while experiments suggest use of the data can help improve event extraction performance, the task data has so far received only limited use in support of event extraction.
</prevsent>
<prevsent>the rel task continues as an open challenge, with all resources available from the shared task website.
</prevsent>
</prevsection>
<citsent citstr=" W11-1802 ">
the bionlp shared task 2011 (bionlp st11) (kim et al, 2011<papid> W11-1802 </papid>a), the follow-up event to the bionlp09 shared task (kim et al, 2009), <papid> W09-1401 </papid>was organized from august 2010 (sample data release) to march 2011.</citsent>
<aftsection>
<nextsent>the shared task was divided intotwo stages, with supporting tasks carried out before the main tasks.
</nextsent>
<nextsent>the motivation for this task setup drew in part from analysis of the results of the previous shared task, which suggested that events that involve coreference or entity relations represent particular challenges for extraction.
</nextsent>
<nextsent>to help address these challenges and encourage modular extraction approaches, increased sharing of successful solutions, and an efficient division of labor, the two were separated into independent supporting tasks on coreference (co) (nguyen et al, 2011) and entity relations in bionlp st11.
</nextsent>
<nextsent>this paper presents the entity relations (rel) supporting task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4265">
<title id=" W11-1812.xml">overview of the entity relations rel supporting task of bionlp shared task 2011 </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while experiments suggest use of the data can help improve event extraction performance, the task data has so far received only limited use in support of event extraction.
</prevsent>
<prevsent>the rel task continues as an open challenge, with all resources available from the shared task website.
</prevsent>
</prevsection>
<citsent citstr=" W09-1401 ">
the bionlp shared task 2011 (bionlp st11) (kim et al, 2011<papid> W11-1802 </papid>a), the follow-up event to the bionlp09 shared task (kim et al, 2009), <papid> W09-1401 </papid>was organized from august 2010 (sample data release) to march 2011.</citsent>
<aftsection>
<nextsent>the shared task was divided intotwo stages, with supporting tasks carried out before the main tasks.
</nextsent>
<nextsent>the motivation for this task setup drew in part from analysis of the results of the previous shared task, which suggested that events that involve coreference or entity relations represent particular challenges for extraction.
</nextsent>
<nextsent>to help address these challenges and encourage modular extraction approaches, increased sharing of successful solutions, and an efficient division of labor, the two were separated into independent supporting tasks on coreference (co) (nguyen et al, 2011) and entity relations in bionlp st11.
</nextsent>
<nextsent>this paper presents the entity relations (rel) supporting task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4267">
<title id=" W11-1812.xml">overview of the entity relations rel supporting task of bionlp shared task 2011 </title>
<section> task setting.  </section>
<citcontext>
<prevsection>
<prevsent>in the design of the rel task, we followed the general policy of the shared task in assuming named entity recognition (ner) as given starting point: participants were provided with manually annotated gold standard annotations identifying gene/protein names in all of the training, development, and final test data.
</prevsent>
<prevsent>by limiting effects due toner performance, the task remains more specifically focused on the key challenge studied.
</prevsent>
</prevsection>
<citsent citstr=" W09-1301 ">
following the results and analysis from previous studies (pyysalo et al, 2009; <papid> W09-1301 </papid>ohta et al, 2010), wechose to limit the task specifically to relations involving gene/protein named entity (ne) and one other entity.</citsent>
<aftsection>
<nextsent>fixing one entity involved in each relation to an ne helps assure that the relations are anchored?
</nextsent>
<nextsent>to real-world entities, and the specific choice of the gene/protein ne class further provides category with several existing systems and substantial ongoing efforts addressing the identification of those referents through named entity recognition and normalization (leaman and gonzalez, 2008; hakenberg et al, 2008; krallinger et al, 2008; morgan et al, 2008; wermter et al, 2009).
</nextsent>
<nextsent>the recognition of biologically relevant associations of gene/protein nes is key focus of the main event extraction tasks of the shared task.
</nextsent>
<nextsent>by contrast, in the rel task setting, only one participant in each binary relation is gene/protein ne, while the other can be either non-name reference such as promoter or the name of an entity not of the gene/protein type (e.g. complex).1 motivated in part by the relatively limited number of existing methods for the detec 1pronominal references are excluded from annotation scope.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4278">
<title id=" W11-1812.xml">overview of the entity relations rel supporting task of bionlp shared task 2011 </title>
<section> task setting.  </section>
<citcontext>
<prevsection>
<prevsent>following the biological motivation and the general practice in the shared task to term genes and gene products protein for simplicity, we named these two relations protein-component and subunit-complex.
</prevsent>
<prevsent>figure 1 shows an illustration of simple relation with an associated event (not part of rel).
</prevsent>
</prevsection>
<citsent citstr=" W11-1803 ">
events with site arguments such as that shown in the figure are targeted in the ge, epi, and id tasks (kim et al, 2011<papid> W11-1802 </papid>b; ohta et al, 2011; <papid> W11-1803 </papid>pyysalo et al, 2011) <papid> W11-1804 </papid>that rel is intended to support.</citsent>
<aftsection>
<nextsent>the task dataset consists of new annotations for the genia corpus (kim et al, 2008), building on the existing biomedical term annotation (ohta etal., 2002), the gene and gene product name annotation (ohta et al, 2009) <papid> W09-1313 </papid>and the syntactic annotation(tateisi et al, 2005) <papid> I05-2038 </papid>of the corpus.</nextsent>
<nextsent>the general features of the annotation are presented by pyysalo et al.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4279">
<title id=" W11-1812.xml">overview of the entity relations rel supporting task of bionlp shared task 2011 </title>
<section> task setting.  </section>
<citcontext>
<prevsection>
<prevsent>following the biological motivation and the general practice in the shared task to term genes and gene products protein for simplicity, we named these two relations protein-component and subunit-complex.
</prevsent>
<prevsent>figure 1 shows an illustration of simple relation with an associated event (not part of rel).
</prevsent>
</prevsection>
<citsent citstr=" W11-1804 ">
events with site arguments such as that shown in the figure are targeted in the ge, epi, and id tasks (kim et al, 2011<papid> W11-1802 </papid>b; ohta et al, 2011; <papid> W11-1803 </papid>pyysalo et al, 2011) <papid> W11-1804 </papid>that rel is intended to support.</citsent>
<aftsection>
<nextsent>the task dataset consists of new annotations for the genia corpus (kim et al, 2008), building on the existing biomedical term annotation (ohta etal., 2002), the gene and gene product name annotation (ohta et al, 2009) <papid> W09-1313 </papid>and the syntactic annotation(tateisi et al, 2005) <papid> I05-2038 </papid>of the corpus.</nextsent>
<nextsent>the general features of the annotation are presented by pyysalo et al.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4280">
<title id=" W11-1812.xml">overview of the entity relations rel supporting task of bionlp shared task 2011 </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1 shows an illustration of simple relation with an associated event (not part of rel).
</prevsent>
<prevsent>events with site arguments such as that shown in the figure are targeted in the ge, epi, and id tasks (kim et al, 2011<papid> W11-1802 </papid>b; ohta et al, 2011; <papid> W11-1803 </papid>pyysalo et al, 2011) <papid> W11-1804 </papid>that rel is intended to support.</prevsent>
</prevsection>
<citsent citstr=" W09-1313 ">
the task dataset consists of new annotations for the genia corpus (kim et al, 2008), building on the existing biomedical term annotation (ohta etal., 2002), the gene and gene product name annotation (ohta et al, 2009) <papid> W09-1313 </papid>and the syntactic annotation(tateisi et al, 2005) <papid> I05-2038 </papid>of the corpus.</citsent>
<aftsection>
<nextsent>the general features of the annotation are presented by pyysalo et al.
</nextsent>
<nextsent>(2009), describing previous release of subset of the data.
</nextsent>
<nextsent>the rel task annotation effort extended the coverage of the previously released annotation toall relations of the targeted types stated within sentence scope in the genia corpus.
</nextsent>
<nextsent>for compatibility with the bionlp st09 and its repeat as the ge task in 2011 (kim et al, 2011<papid> W11-1802 </papid>b), the rel task training/development/test set division of the genia corpus abstracts matches that of the bionlp st09 data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4281">
<title id=" W11-1812.xml">overview of the entity relations rel supporting task of bionlp shared task 2011 </title>
<section> data.  </section>
<citcontext>
<prevsection>
<prevsent>figure 1 shows an illustration of simple relation with an associated event (not part of rel).
</prevsent>
<prevsent>events with site arguments such as that shown in the figure are targeted in the ge, epi, and id tasks (kim et al, 2011<papid> W11-1802 </papid>b; ohta et al, 2011; <papid> W11-1803 </papid>pyysalo et al, 2011) <papid> W11-1804 </papid>that rel is intended to support.</prevsent>
</prevsection>
<citsent citstr=" I05-2038 ">
the task dataset consists of new annotations for the genia corpus (kim et al, 2008), building on the existing biomedical term annotation (ohta etal., 2002), the gene and gene product name annotation (ohta et al, 2009) <papid> W09-1313 </papid>and the syntactic annotation(tateisi et al, 2005) <papid> I05-2038 </papid>of the corpus.</citsent>
<aftsection>
<nextsent>the general features of the annotation are presented by pyysalo et al.
</nextsent>
<nextsent>(2009), describing previous release of subset of the data.
</nextsent>
<nextsent>the rel task annotation effort extended the coverage of the previously released annotation toall relations of the targeted types stated within sentence scope in the genia corpus.
</nextsent>
<nextsent>for compatibility with the bionlp st09 and its repeat as the ge task in 2011 (kim et al, 2011<papid> W11-1802 </papid>b), the rel task training/development/test set division of the genia corpus abstracts matches that of the bionlp st09 data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4290">
<title id=" W11-1812.xml">overview of the entity relations rel supporting task of bionlp shared task 2011 </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 participation.
</prevsent>
<prevsent>table 2 summarizes the participating groups and approaches.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
we find remarkable number of similarities between the approaches of the systems,with all four utilizing full parsing and dependency representation of the syntactic analysis, and the three highest-ranking further specifically the phrase structure parser of charniak and johnson(2005) <papid> P05-1022 </papid>with the biomedical domain model of mcclosky (2009), converted into stanford dependency form using the stanford tools (de marneffe et al,2006).</citsent>
<aftsection>
<nextsent>these specific choices may perhaps be influenced by the success of systems building on them in the 2009 shared task (e.g. bjorne et al (2009)).
</nextsent>
<nextsent>while uturku (bjorne and salakoski, 2011) and vib ghent (van landeghem et al, 2011) further agree in the choice of support vector machines forthe recognition of entities and the extraction of relations, concordu (kilicoglu and bergler, 2011) <papid> W11-1827 </papid>and hcmus (le minh et al, 2011) pursue approaches building on dictionary- and rule-based extraction.</nextsent>
<nextsent>only the vib ghent system makes use of resources external to those provided for the task, extracting specific semantic entity types from the genia corpus as well as inducing word similarities from large unannotated corpus of pubmed abstracts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4291">
<title id=" W11-1812.xml">overview of the entity relations rel supporting task of bionlp shared task 2011 </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>we find remarkable number of similarities between the approaches of the systems,with all four utilizing full parsing and dependency representation of the syntactic analysis, and the three highest-ranking further specifically the phrase structure parser of charniak and johnson(2005) <papid> P05-1022 </papid>with the biomedical domain model of mcclosky (2009), converted into stanford dependency form using the stanford tools (de marneffe et al,2006).</prevsent>
<prevsent>these specific choices may perhaps be influenced by the success of systems building on them in the 2009 shared task (e.g. bjorne et al (2009)).</prevsent>
</prevsection>
<citsent citstr=" W11-1827 ">
while uturku (bjorne and salakoski, 2011) and vib ghent (van landeghem et al, 2011) further agree in the choice of support vector machines forthe recognition of entities and the extraction of relations, concordu (kilicoglu and bergler, 2011) <papid> W11-1827 </papid>and hcmus (le minh et al, 2011) pursue approaches building on dictionary- and rule-based extraction.</citsent>
<aftsection>
<nextsent>only the vib ghent system makes use of resources external to those provided for the task, extracting specific semantic entity types from the genia corpus as well as inducing word similarities from large unannotated corpus of pubmed abstracts.
</nextsent>
<nextsent>5.2 evaluation results.
</nextsent>
<nextsent>table 3 shows the results of the rel task.
</nextsent>
<nextsent>we find that the four systems diverge substantially in terms of overall performance, with all pairs of systems of neighboring ranks showing differences approaching or exceeding 10% points in f-score.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4292">
<title id=" W11-1812.xml">overview of the entity relations rel supporting task of bionlp shared task 2011 </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>while the limited amount ofdata available prevents strong conclusions from being drawn, overall the lack of correlation between training data size and extraction performance suggests that performance may not be primarily limited by the size of the available training data.
</prevsent>
<prevsent>the rel task was explicitly cast in support rolefor the main event extraction tasks, and rel participants were encouraged to make their predictions of the task extraction targets for the various main task datasets available to main task participants.
</prevsent>
</prevsection>
<citsent citstr=" W11-1816 ">
the uturku team responded to this call for supporting analyses, running their top-ranking rel task system on all main task datasets and making its output available as supporting resource (stenetorp et al, 2011).<papid> W11-1816 </papid></citsent>
<aftsection>
<nextsent>in the main tasks, we are so far aware of one application of this data: the bmi@asu team (emadzadeh et al, 2011) <papid> W11-1824 </papid>applied the uturku rel predictions as part of their ge task system for resolving the site arguments in events such as binding and phosphorylation (see figure 1).</nextsent>
<nextsent>while more extensive use of the data would have been desirable, we find this application of the rel analyses very appropriate to our general design for the role of the supporting and main tasks and hope to see other groups pursue similar possibilities in future work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4293">
<title id=" W11-1812.xml">overview of the entity relations rel supporting task of bionlp shared task 2011 </title>
<section> discussion.  </section>
<citcontext>
<prevsection>
<prevsent>the rel task was explicitly cast in support rolefor the main event extraction tasks, and rel participants were encouraged to make their predictions of the task extraction targets for the various main task datasets available to main task participants.
</prevsent>
<prevsent>the uturku team responded to this call for supporting analyses, running their top-ranking rel task system on all main task datasets and making its output available as supporting resource (stenetorp et al, 2011).<papid> W11-1816 </papid></prevsent>
</prevsection>
<citsent citstr=" W11-1824 ">
in the main tasks, we are so far aware of one application of this data: the bmi@asu team (emadzadeh et al, 2011) <papid> W11-1824 </papid>applied the uturku rel predictions as part of their ge task system for resolving the site arguments in events such as binding and phosphorylation (see figure 1).</citsent>
<aftsection>
<nextsent>while more extensive use of the data would have been desirable, we find this application of the rel analyses very appropriate to our general design for the role of the supporting and main tasks and hope to see other groups pursue similar possibilities in future work.
</nextsent>
<nextsent>we have presented the preparation, resources, results and analysis of the entity relations (rel) task, supporting task of the bionlp shared task 2011 involving the recognition of two specific types ofpart-of relations between genes/proteins and associated entities.
</nextsent>
<nextsent>the task was run in separate early stage in the overall shared task schedule to allow participants to make use of methods and analyses for the task as part of their main task submissions.
</nextsent>
<nextsent>of four teams submitting finals results, thehighest-performing system, uturku, achieved precision of 68% at 50% recall (58% f-score), promising level of performance given the relative novelty of the specific extraction targets and the short development period.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4294">
<title id=" W11-2023.xml">commitments to preferences in dialogue </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>but such system could lead to sub optimal dialogue movese.g., to help the speaker go to the mall even if he has already received food.whats required, then, is method for extracting partial information about preferences and the dependencies among them that are expressed in dialogue, perhaps indirectly, and method for exploiting that partial information to identify the next optimal action.
</prevsent>
<prevsent>this paper proposes method for achieving these tasks by exploiting discourse structure.
</prevsent>
</prevsection>
<citsent citstr=" W05-0613 ">
we exploited the corpus of baldridge and lascarides(2005<papid> W05-0613 </papid>a), who annotated 100 randomly chosen spontaneous face-to-face dialogues from the verb mobil corpus (wahlster, 2000) with their discourse structure according to segmented discourse representation theory (sdrt, asher and lascarides (2003))these structures represent the types of (relational) speech acts that the agents perform.</citsent>
<aftsection>
<nextsent>heres typical fragment: (2) a. a: shall we meet sometime in the next week?
</nextsent>
<nextsent>b. a: what days are good for you?
</nextsent>
<nextsent>c. b: well, have some free time on almost every day except fridays.
</nextsent>
<nextsent>204 d. b: in fact, im busy on thursday too.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4296">
<title id=" W11-2023.xml">commitments to preferences in dialogue </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>it leads to conception of dialogue thats more general than one based purely on gricean cooperative principles (grice, 1975).
</prevsent>
<prevsent>on purely gricean approach, conversation is cooperative in at least two ways: basic level concerning the conventions that govern linguistic meaning (ba sic cooperativity); and level concerning shared attitudes towards what is said, including shared intentions (con tent cooperativity).
</prevsent>
</prevsection>
<citsent citstr=" J98-4001 ">
while basic cooperation is needed for communication to work at all, content cooperativity involves strongly cooperative axioms like cooperativity (interlocutors normally adopt the speakers inten tions) (allen and litman, 1987, grosz and sidner, 1990, lochbaum, 1998).<papid> J98-4001 </papid></citsent>
<aftsection>
<nextsent>our approach allows for divergent preferences and divergent intentions, i.e. conversations that arent based on content cooperativity.
</nextsent>
<nextsent>this will allow us to exploit information about conflicting agents preferences and game-theoretic techniques that are inherent in the logics of cp-nets for computing optimal moves (bonzon, 2007).
</nextsent>
<nextsent>and in contrast to franke et al (2009), who analyse conversations where content cooperativitydoesnt hold using game-theoretic framework, our approach allows for partial and qualitative representations of preferences rather than demanding complete and quantitative representations of them.
</nextsent>
<nextsent>212
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4297">
<title id=" W12-1626.xml">exploiting machine transcribed dialog corpus to improve multiple dialog states tracking methods </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with present automatic speech recognition (asr) and spoken language understanding (slu) errors, it is impossible to directly observe the true user goal and action.
</prevsent>
<prevsent>it is crucial, therefore, to efficiently infer this true state from erroneous observations over multiple dialog turns.
</prevsent>
</prevsection>
<citsent citstr=" J08-4002 ">
the partially observable markov decision process (pomdp) framework has offered well-founded theory for this purpose (henderson et al, 2008; <papid> J08-4002 </papid>thomson and young, 2010a; williams and young, 2007; young et al, 2010).</citsent>
<aftsection>
<nextsent>several approximate methods have also emerged to tackle the vast complexity of representing and maintaining belief states, e.g., partition-based approaches (ga sic and young, 2011; williams, 2010; young etal., 2010) and bayesian network (bn)-based methods (raux and ma, 2011; thomson and young, 2010a).
</nextsent>
<nextsent>the partition-based approaches attempt to group user goals into small number of partition sand split partition only when distinction is required by observations.
</nextsent>
<nextsent>this property endows it with the high scala bility that is suitable for fairly complex domains.
</nextsent>
<nextsent>however, the parameter learning procedures for the partition-based methods isstill limited to hand-crafting or the use of simple maximum likelihood estimation (keizer et al, 2008; roy et al, 2000; <papid> P00-1013 </papid>thomson and young, 2010a; williams, 2008).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4298">
<title id=" W12-1626.xml">exploiting machine transcribed dialog corpus to improve multiple dialog states tracking methods </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the partition-based approaches attempt to group user goals into small number of partition sand split partition only when distinction is required by observations.
</prevsent>
<prevsent>this property endows it with the high scala bility that is suitable for fairly complex domains.
</prevsent>
</prevsection>
<citsent citstr=" P00-1013 ">
however, the parameter learning procedures for the partition-based methods isstill limited to hand-crafting or the use of simple maximum likelihood estimation (keizer et al, 2008; roy et al, 2000; <papid> P00-1013 </papid>thomson and young, 2010a; williams, 2008).</citsent>
<aftsection>
<nextsent>in contrast, several unsupervised methods which do not require human transcription and annotation have been recently proposed to learn bn-based models (jurcicek et al, 2010; syed and williams, 2008; <papid> P08-2031 </papid>thomson et al, 2010b).</nextsent>
<nextsent>in this paper we describe an unsupervised process that can be applied to the partition-based methods.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4299">
<title id=" W12-1626.xml">exploiting machine transcribed dialog corpus to improve multiple dialog states tracking methods </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this property endows it with the high scala bility that is suitable for fairly complex domains.
</prevsent>
<prevsent>however, the parameter learning procedures for the partition-based methods isstill limited to hand-crafting or the use of simple maximum likelihood estimation (keizer et al, 2008; roy et al, 2000; <papid> P00-1013 </papid>thomson and young, 2010a; williams, 2008).</prevsent>
</prevsection>
<citsent citstr=" P08-2031 ">
in contrast, several unsupervised methods which do not require human transcription and annotation have been recently proposed to learn bn-based models (jurcicek et al, 2010; syed and williams, 2008; <papid> P08-2031 </papid>thomson et al, 2010b).</citsent>
<aftsection>
<nextsent>in this paper we describe an unsupervised process that can be applied to the partition-based methods.
</nextsent>
<nextsent>we adopt dynamic bayesian network to learn the user action model which defines the likelihood of user actions forgiven context.
</nextsent>
<nextsent>in addition, we propose simple confidence score calibration method to improve the observation model which represents the probability of an observation given the true user action.this paper is structured as follows.
</nextsent>
<nextsent>section 2 describes previous research and the novelty of our approach.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4301">
<title id=" W12-1633.xml">a unified probabilistic approach to referring expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>descriptive expressions(such as the blue glass on the table?)
</prevsent>
<prevsent>exploit attributes of entities and relations between them to distinguish an entity from the rest.
</prevsent>
</prevsection>
<citsent citstr=" J03-1003 ">
they are well studied in natural language generation, e.g., (daleand reiter, 1995; krahmer et al, 2003; <papid> J03-1003 </papid>dale and viethen, 2009).</citsent>
<aftsection>
<nextsent>anaphoric expressions (such as it?)refer to entities or concepts introduced in the preceding discourse and are studied mostly on textual monologues, e.g., (kamp and reyle, 1993; mitkov, 2002; ng, 2010).<papid> P10-1142 </papid></nextsent>
<nextsent>deictic (exophoric) expressions(such as this one?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4302">
<title id=" W12-1633.xml">a unified probabilistic approach to referring expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>exploit attributes of entities and relations between them to distinguish an entity from the rest.
</prevsent>
<prevsent>they are well studied in natural language generation, e.g., (daleand reiter, 1995; krahmer et al, 2003; <papid> J03-1003 </papid>dale and viethen, 2009).</prevsent>
</prevsection>
<citsent citstr=" P10-1142 ">
anaphoric expressions (such as it?)refer to entities or concepts introduced in the preceding discourse and are studied mostly on textual monologues, e.g., (kamp and reyle, 1993; mitkov, 2002; ng, 2010).<papid> P10-1142 </papid></citsent>
<aftsection>
<nextsent>deictic (exophoric) expressions(such as this one?)
</nextsent>
<nextsent>refer to entities outside the preceding discourse.
</nextsent>
<nextsent>they are often studied focusing on pronouns accompanied with pointing gestures in physical spaces, e.g., (gieselmann, 2004).dialogue systems (dss) as natural human machine (hm) interfaces are expected to handle all the three categories of referring expressions (salmon-alt and romary, 2001).
</nextsent>
<nextsent>in fact, the three categories are not mutually exclusive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4303">
<title id=" W12-1633.xml">a unified probabilistic approach to referring expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the bn is used to estimate the probability with which the corresponding re refers to an entity.
</prevsent>
<prevsent>one of the two major contributions of this paper is our probabilistic formulation that handles the above three kinds of resin unified manner.
</prevsent>
</prevsection>
<citsent citstr=" P10-1128 ">
previously iida et al (2010) <papid> P10-1128 </papid>proposed quantitative approach that handles anaphoric and deictic expressions in aunified manner.</citsent>
<aftsection>
<nextsent>however it lacks handling of descriptive expressions.
</nextsent>
<nextsent>our formulation subsumes and extends it to handle descriptive res.
</nextsent>
<nextsent>so far, no previously proposed method for reference resolution handles all three types of res.
</nextsent>
<nextsent>the other contribution is bringing reference domains into that formulation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4304">
<title id=" W12-1633.xml">a unified probabilistic approach to referring expressions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>237 1.1 reference domains.
</prevsent>
<prevsent>first, we explain reference domains concretely.
</prevsent>
</prevsection>
<citsent citstr=" W10-4203 ">
reference domains (rds) (salmon-alt and romary, 2000; salmon-alt and romary, 2001; denis, 2010) <papid> W10-4203 </papid>are theoretical constructs, which are basically sets of entities presupposed at each use of res.</citsent>
<aftsection>
<nextsent>rds in the original literature are not mere sets of entities but mental objects equipped with properties such as type, focus, or saliency and internally structured with partitions.
</nextsent>
<nextsent>in this paper, while we do not explicitly handle partitions, reference domains can be nested as an approximation of partitioning, that is,an entity included in rd is either an individual entity or another rd. each rd has its focus and degree of saliency (a non-negative real number).
</nextsent>
<nextsent>here after, two of them are denoted as foc(d) and sal(d)respectively.
</nextsent>
<nextsent>rds are sorted in descending order according to saliency.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4332">
<title id=" W12-1633.xml">a unified probabilistic approach to referring expressions </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>the evaluation for complex res is necessary to validate this potential of rebn.
</prevsent>
<prevsent>currently rebn assumes res whose referents are concrete entities.
</prevsent>
</prevsection>
<citsent citstr=" P02-1011 ">
an extension for handling abstract entities (byron, 2002; <papid> P02-1011 </papid>muller, 2007) is important future work.</citsent>
<aftsection>
<nextsent>another direction would be generating res with rebns.
</nextsent>
<nextsent>a generate and-test approach is naive application of rebn for generation.
</nextsent>
<nextsent>more efficient method is, however, necessary.
</nextsent>
<nextsent>244
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4333">
<title id=" W11-2704.xml">task based evaluation of nlg systems control vs real world context </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however there was lot of noise?
</prevsent>
<prevsent>(in the statisticalsense) in the stop evaluation, because different people (with different personalities, attitudes towards smoking, personal circumstances, etc) received the tailored and non-tailored letters, and this impacted smoking-cessation rates in the the three groups.
</prevsent>
</prevsection>
<citsent citstr=" P05-1007 ">
another evaluation which was controlled and was done at least partially in real-world context was the evaluation of the diag-nlp intelligent tutoring system (di eugenio et al, 2005).<papid> P05-1007 </papid></citsent>
<aftsection>
<nextsent>in this experiment, 75students (the appropriate subject group for this tutoring system) were divided into three groups: two groups interacted with two versions of the diag nlp system, and third interacted with control version of diag which did not include any nlg.
</nextsent>
<nextsent>effectiveness was measured by learning gain (change in knowledge, measured by differences in scores ina pre-test and post-test), which is standard in the tutoring system domain.
</nextsent>
<nextsent>the evaluation showed that students learned more from the second (more ad vanced) version of the diag-nlp system than from the non-nlg version of diag.
</nextsent>
<nextsent>the diag-nlp evaluation was controlled, and itwas real-world in the sense that it used representative subjects and measured real-world outcome.however, it appears (the paper is not completely explicit about this) that the evaluation assessed learning about topic (fixing home heating system)which was not part of the students normal curricu lum; if this is the case, then the evaluation was not 100% in real-world context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4334">
<title id=" W11-2506.xml">assessing interpret able attribute related meaning representations for adjective noun phrases in a similarity prediction task </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the underlying relations between adjectives and nouns, respectively, and the attributes they denote is captured by way of latent semantic information obtained from latent dirichlet allocation (lda; blei et al  (2003)).
</prevsent>
<prevsent>thus, we treat attributes as an abstract meaning layer that generalizes over latent topics inferred by lda and utilize this inter pre table layer as the dimensions of our vsm.
</prevsent>
</prevsection>
<citsent citstr=" D11-1050 ">
this approach has been shown to be effective in an attribute selection task (hartung and frank,2011), <papid> D11-1050 </papid>where the goal is to predict the most prominent attribute(s) hidden?</citsent>
<aftsection>
<nextsent>in the compositional semantics of adjective-noun phrases.
</nextsent>
<nextsent>in this paper,our main interest is to assess the potential of modeling adjective semantics in terms of discrete, inter pre table attribute meanings in similarity judgement task, as opposed to representation in latent semantic space that is usually applied to tasks of this kind.
</nextsent>
<nextsent>52 for this purpose, we relyon the evaluation dataset of m&l; which serves as shared benchmark inthe gems 2011 workshop.
</nextsent>
<nextsent>their similarity judgement task, being tailored to measuring latent similarity, represents true challenge for an analysis focused on discrete onto logical attributes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4335">
<title id=" W11-2506.xml">assessing interpret able attribute related meaning representations for adjective noun phrases in a similarity prediction task </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>his approach suffers from severe sparsity problems and does not account for the compositional nature of adjective-noun phrases, as it disregards the meaning contributed bythe noun.
</prevsent>
<prevsent>it is therefore unable to perform disambiguation of adjectives in the context of noun.
</prevsent>
</prevsection>
<citsent citstr=" D10-1115 ">
baroni and zamparelli (2010) <papid> D10-1115 </papid>and guevara(2010) <papid> W10-2805 </papid>focus on how best to represent compositionality in adjective-noun phrases considering different types of composition operators.</citsent>
<aftsection>
<nextsent>these works adhere to fully latent representation of meaning, whereas hartung and frank (2010) <papid> C10-1049 </papid>assign symbolic attribute meanings to adjectives, nouns and composed phrases by incorporating attributes as dimensions in compositional vsm.</nextsent>
<nextsent>by holding the attribute meaning of adjectives and nouns in distinct vector representations and combining them through vector composition, their approach improves on both weaknesses of almuharebs work.however, their account is still closely tied to al muharebs pattern-based approach in that counts of co-occurrence patterns linking adjectives and nounsto attributes are used to populate the vector represen tations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4336">
<title id=" W11-2506.xml">assessing interpret able attribute related meaning representations for adjective noun phrases in a similarity prediction task </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>his approach suffers from severe sparsity problems and does not account for the compositional nature of adjective-noun phrases, as it disregards the meaning contributed bythe noun.
</prevsent>
<prevsent>it is therefore unable to perform disambiguation of adjectives in the context of noun.
</prevsent>
</prevsection>
<citsent citstr=" W10-2805 ">
baroni and zamparelli (2010) <papid> D10-1115 </papid>and guevara(2010) <papid> W10-2805 </papid>focus on how best to represent compositionality in adjective-noun phrases considering different types of composition operators.</citsent>
<aftsection>
<nextsent>these works adhere to fully latent representation of meaning, whereas hartung and frank (2010) <papid> C10-1049 </papid>assign symbolic attribute meanings to adjectives, nouns and composed phrases by incorporating attributes as dimensions in compositional vsm.</nextsent>
<nextsent>by holding the attribute meaning of adjectives and nouns in distinct vector representations and combining them through vector composition, their approach improves on both weaknesses of almuharebs work.however, their account is still closely tied to al muharebs pattern-based approach in that counts of co-occurrence patterns linking adjectives and nounsto attributes are used to populate the vector represen tations.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4337">
<title id=" W11-2506.xml">assessing interpret able attribute related meaning representations for adjective noun phrases in a similarity prediction task </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>it is therefore unable to perform disambiguation of adjectives in the context of noun.
</prevsent>
<prevsent>baroni and zamparelli (2010) <papid> D10-1115 </papid>and guevara(2010) <papid> W10-2805 </papid>focus on how best to represent compositionality in adjective-noun phrases considering different types of composition operators.</prevsent>
</prevsection>
<citsent citstr=" C10-1049 ">
these works adhere to fully latent representation of meaning, whereas hartung and frank (2010) <papid> C10-1049 </papid>assign symbolic attribute meanings to adjectives, nouns and composed phrases by incorporating attributes as dimensions in compositional vsm.</citsent>
<aftsection>
<nextsent>by holding the attribute meaning of adjectives and nouns in distinct vector representations and combining them through vector composition, their approach improves on both weaknesses of almuharebs work.however, their account is still closely tied to al muharebs pattern-based approach in that counts of co-occurrence patterns linking adjectives and nounsto attributes are used to populate the vector representations.
</nextsent>
<nextsent>these, however, are inherently sparse.
</nextsent>
<nextsent>the resulting model therefore still suffers from sparsity of co-occurrence data.finally, latent dirichlet allocation, originally designed for tasks such as text classification and document modeling (blei et al , 2003), found its way into lexical semantics.
</nextsent>
<nextsent>ritter et al  (2010) <papid> P10-1044 </papid>ando seaghdha (2010), e.g., model selectional restrictions of verb arguments by inducing topic distributions that characterize mixtures of topics observed in verb argument positions.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4338">
<title id=" W11-2506.xml">assessing interpret able attribute related meaning representations for adjective noun phrases in a similarity prediction task </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>these, however, are inherently sparse.
</prevsent>
<prevsent>the resulting model therefore still suffers from sparsity of co-occurrence data.finally, latent dirichlet allocation, originally designed for tasks such as text classification and document modeling (blei et al , 2003), found its way into lexical semantics.
</prevsent>
</prevsection>
<citsent citstr=" P10-1044 ">
ritter et al  (2010) <papid> P10-1044 </papid>ando seaghdha (2010), e.g., model selectional restrictions of verb arguments by inducing topic distributions that characterize mixtures of topics observed in verb argument positions.</citsent>
<aftsection>
<nextsent>mitchell and lapata (2009), <papid> D09-1045 </papid>mitchell and lapata (2010) were the first to use lda-inferred topics as dimensions in vsms.hartung and frank (2011) <papid> D11-1050 </papid>adopt similar approach, by embedding lda into vsm for adjective-noun meaning composition, with lda topics providing latent variables for attribute mean ings.</nextsent>
<nextsent>that is, contrary to m&l;, lda is used to convey information about interpret able semantic attributes rather than latent topics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4339">
<title id=" W11-2506.xml">assessing interpret able attribute related meaning representations for adjective noun phrases in a similarity prediction task </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the resulting model therefore still suffers from sparsity of co-occurrence data.finally, latent dirichlet allocation, originally designed for tasks such as text classification and document modeling (blei et al , 2003), found its way into lexical semantics.
</prevsent>
<prevsent>ritter et al  (2010) <papid> P10-1044 </papid>ando seaghdha (2010), e.g., model selectional restrictions of verb arguments by inducing topic distributions that characterize mixtures of topics observed in verb argument positions.</prevsent>
</prevsection>
<citsent citstr=" D09-1045 ">
mitchell and lapata (2009), <papid> D09-1045 </papid>mitchell and lapata (2010) were the first to use lda-inferred topics as dimensions in vsms.hartung and frank (2011) <papid> D11-1050 </papid>adopt similar approach, by embedding lda into vsm for adjective-noun meaning composition, with lda topics providing latent variables for attribute mean ings.</citsent>
<aftsection>
<nextsent>that is, contrary to m&l;, lda is used to convey information about interpret able semantic attributes rather than latent topics.
</nextsent>
<nextsent>in fact, hartung and frank (2011) <papid> D11-1050 </papid>are able to show that injecting?</nextsent>
<nextsent>topic distributions inferred from lda into vsm alleviates sparsity problems that persisted with the pattern-based vsm of hartung and frank (2010).<papid> C10-1049 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4352">
<title id=" W11-2506.xml">assessing interpret able attribute related meaning representations for adjective noun phrases in a similarity prediction task </title>
<section> error analysis.  </section>
<citcontext>
<prevsection>
<prevsent>an interesting type of similarity is represented byearly evening ? previous day.
</prevsent>
<prevsent>in this case, we observe contrast in the semantics of the nouns involved, while the pair exhibits strong similarity on the attribute level, which is reflected in the systems similarity score.
</prevsent>
</prevsection>
<citsent citstr=" C08-1114 ">
this type of similarity is reminiscent of relational analogies investigated in turney(2008).<papid> C08-1114 </papid></citsent>
<aftsection>
<nextsent>a related example is rural community ? federal assembly.
</nextsent>
<nextsent>unlike the human judges, c-lda predicts high similarity for both pairs.
</nextsent>
<nextsent>the examples given in agrm&l;, by contrast,clearly point to lack in capturing adjective semantics, with mis judgements such as effective way ? efficient use, large number ? vast amount or large quantity ? great majority.
</nextsent>
<nextsent>turning to agrc-lda-a again, we find 9/10 items exhibit values greater than 0.67 (average: 0.78).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4354">
<title id=" W11-2506.xml">assessing interpret able attribute related meaning representations for adjective noun phrases in a similarity prediction task </title>
<section> conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>the c-lda models focus on specific, interpret able meaning dimension shared by adjectives and nouns, with tendency for stronger modeling capacity for adjectives.they are currently not prepared to capture dissimilarity in cases of contrastive attribute values, whileon the positive side, they effectively cope with relational analogies, both with similar and dissimilar noun meanings.our findings suggest that adding more discriminative power to the noun representations and scalar information about attribute values to the adjective vectors might be beneficial.
</prevsent>
<prevsent>further research is needed to investigate how to combine interpret able semantic representations tailored to specific relations, as captured by c-lda, with m&amp;l-like; bag-of-words representations in single distributional model.applying interpreted models to the present similarity rating task will still remain challenge, as it involves mapping diverse mixtures of aspects and grades of similarity to human judgements.
</prevsent>
</prevsection>
<citsent citstr=" W10-2415 ">
how ever, if the performance of an integrated model can compete with purely latent semantic analysis, this offers clear advantage for more general tasks that require linking phrase meaning to symbolic knowledge bases such as (multilingual) ontologies, or for application scenarios that involve discrete semantic labels, such as text classification based on topic modeling (blei et al , 2003) or fine-grained named entity classification (ekbal et al , 2010).<papid> W10-2415 </papid></citsent>
<aftsection>
<nextsent>60
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4355">
<title id=" W12-1911.xml">unsupervised dependency parsing using reducibility and fertility features </title>
<section> dependency models.  </section>
<citcontext>
<prevsection>
<prevsent>stands for the count of words with pos tag ti and fertility fi in the history, and p0 is prior probability for the given fertility which depends on the total number of node dependents denoted by |fi| (the sum of numbers of left and right dependents): p0(fi) = 1 2|fi|+1 (5) this prior probability has nice property: for agiven number of nodes, the product of fertility probabilities over all the nodes is equal for all possible dependency trees.
</prevsent>
<prevsent>this ensures balance of this model during inference.
</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
5in dmv (klein and manning, 2004) <papid> P04-1061 </papid>and in the extended model evg (headden iii et al, 2009), there is stop sign indicating that no more dependents in given direction will begenerated.</citsent>
<aftsection>
<nextsent>given certain head, all its dependents in left direction are generated first, then the stop sign in that direction,then all its right dependents and then stop in the other direction.
</nextsent>
<nextsent>this process continues recursively for all generated dependents.
</nextsent>
<nextsent>6for example, fertility 1-3?
</nextsent>
<nextsent>means that the node has one left and three right dependents, fertility 0-0?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4356">
<title id=" W12-1911.xml">unsupervised dependency parsing using reducibility and fertility features </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we employ the maximum spanning tree (mst) algorithm (chu and liu, 1965) to find them.13 tree projectivity is not guaranteed by the mst algorithm.
</prevsent>
<prevsent>we evaluated our parser on 10 treebanks included inthe wils shared-task data.
</prevsent>
</prevsection>
<citsent citstr=" D11-1117 ">
similarly to some previous papers on unsupervised parsing (gillenwater etal., 2011; spitkovsky et al, 2011), <papid> D11-1117 </papid>the tuning experiments were performed on english only.</citsent>
<aftsection>
<nextsent>we used 12after each small change is made, the edges from the whole corpus are collected with probability 0.01.
</nextsent>
<nextsent>13the weights of edges needed in mst algorithm correspond to the number of times they were present during the sampling.
</nextsent>
<nextsent>87 language tokens (mil.)
</nextsent>
<nextsent>language tokens (mil.)
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4357">
<title id=" W12-1911.xml">unsupervised dependency parsing using reducibility and fertility features </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>(2012).
</prevsent>
<prevsent>their statistics across languages are showed in table 2.
</prevsent>
</prevsection>
<citsent citstr=" A00-1031 ">
to make them useful, the necessary preprocessing steps must have been done.the texts were first automatically segmented and to kenized14 and then they were part-of-speech tagged by tnt tagger (brants, 2000), <papid> A00-1031 </papid>which was trained on the respective wils training data.</citsent>
<aftsection>
<nextsent>the quality of such tagging is not very high, since we do not use any lexicons15 or pre trained models.
</nextsent>
<nextsent>however, it is sufficient for obtaining good reducibility scores.
</nextsent>
<nextsent>5.2 setting the hyperparameters.
</nextsent>
<nextsent>the applicability of individual models and their parameters were tested on english development data14the segmentation to sentences and tokenization was performed using the tectomt framework (popel and zabokrtsky?, 2010).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4358">
<title id=" W12-1637.xml">a study in how nlu performance can affect the choice of dialogue system architecture </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we are generally interested in the extent to which these various authoring steps are necessary in order to achieve specific levels of system performance.
</prevsent>
<prevsent>in this paper, we present case study analysis of the performance of two alternative architectures for specific virtual human.
</prevsent>
</prevsection>
<citsent citstr=" W11-2006 ">
the two architectures, which have been developed and evaluated in prior work (devault et al , 2011<papid> W11-2006 </papid>b; devault et al , 2011<papid> W11-2006 </papid>a), differ substantially in their semantic annotation and policy authoring requirements.</citsent>
<aftsection>
<nextsent>we describe these architectures and our evaluation corpus in section 2.
</nextsent>
<nextsent>wefocus our new analysis specifically on how the over all performance of one of the architectures, which uses natural language understanding (nlu) module and hand-authored rules for the dialogue policy, depends on the performance of the nlu module.
</nextsent>
<nextsent>in section 3, we describe our finding that, depending on the attainable level of nlu accuracy, this modular approach may or may not perform better than asimpler direct classification design that omits separate nlu module and has lower annotation and rule authoring burden.
</nextsent>
<nextsent>in section 4, we present an initial exploration of whether hybrid architecture may be able to combine these approaches?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4389">
<title id=" W12-1637.xml">a study in how nlu performance can affect the choice of dialogue system architecture </title>
<section> summary of dataset and prior results.  </section>
<citcontext>
<prevsection>
<prevsent>we consider two existing baseline systems in our experiments here.
</prevsent>
<prevsent>the first system (rules-nlu-sa) consists of statistical nlu module that maps user utterance to single user sa label, and rule-based dialogue policy hand-crafted by one of the authors.
</prevsent>
</prevsection>
<citsent citstr=" J96-1002 ">
the nlu uses maximum-entropy model (berger et al , 1996) <papid> J96-1002 </papid>to classify utterances as one of the user sas using shallow text features.</citsent>
<aftsection>
<nextsent>training this model requires corpus of user utterances that have been semantically annotated with the appropriate sa.we developed our rule-based policy by manually writing the simple rules needed to implement amanis dialogue policy.
</nextsent>
<nextsent>given user sa labelat for turn t, the rules for determining amanis response rt take one of three forms: (a)ifat = sai thenrt = saj (b)ifat = sai ? katk = sal thenrt = saj (c)ifat = sai ? katk = sal thenrt = saj the first rule form specifies that given user sa should always lead to given system response.
</nextsent>
<nextsent>the second and third rule forms enable the systems response to depend on the user having previously performed (or not performed) specific sa.
</nextsent>
<nextsent>one the system developers, who is also computational linguist, created the current set of 42 rules in about 2 hours.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4390">
<title id=" W12-1637.xml">a study in how nlu performance can affect the choice of dialogue system architecture </title>
<section> summary of dataset and prior results.  </section>
<citcontext>
<prevsection>
<prevsent>one the system developers, who is also computational linguist, created the current set of 42 rules in about 2 hours.
</prevsent>
<prevsent>there are 30 rules of form (a), 6 rules of form (b), and 6 rules of form (c).the second baseline system (rm-text) is statistical classifier that selects system sas by analyzing shallow features of the user utterances and system responses.
</prevsent>
</prevsection>
<citsent citstr=" W06-1303 ">
we use the relevance model (rm) approach pioneered by lavrenko et al  (2002) for cross-lingual information retrieval and adapted to question-answering by leuski et al  (2006).<papid> W06-1303 </papid></citsent>
<aftsection>
<nextsent>this method does not require semantic annotation or ruleauthoring; instead, the necessary training data is defined by linking user utterances directly to the appropriate system responses (leuski and traum, 2010).table 1 summarizes the performance for the baseline systems (devault et al , 2011<papid> W11-2006 </papid>a).</nextsent>
<nextsent>the nlu module accuracy is approximately 53%, and the weak accuracy of .58 for the corresponding system (rules nlu-sa) is relatively low when compared to therm system at .71.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4398">
<title id=" W12-1507.xml">generation for grammar engineering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we briefly review this work focusing first, on approaches that are based on parsing and second, on those that exploit generation.
</prevsent>
<prevsent>debugging grammars using parsing over thelast two decades, treebank-based evaluation has be come the standard way of evaluating parsers and grammars.
</prevsent>
</prevsection>
<citsent citstr=" H91-1060 ">
in this framework (black et al, 1991),<papid> H91-1060 </papid>the output of parser is evaluated on set of sentences that have been manually annotated with their syntactic parses.</citsent>
<aftsection>
<nextsent>whenever the parse tree produced by the parser differs from the manual annotation, the difference can be traced back to the parser (timeout, disambiguation component), the grammar and/or tothe lexicon.
</nextsent>
<nextsent>conversely, if the parser fails to return an output, under generation can be traced back to missing or erroneous information in the grammar or/and in the lexicon.while it has supported the development of robust, large coverage parsers, treebank based evaluation is limited to the set of syntactic constructions and lexical items present in the treebank.
</nextsent>
<nextsent>it also fails to directly identify the most likely source of parsing failures.
</nextsent>
<nextsent>to bypass these limitations, error mining techniques have been proposed which permit detecting grammar and lexicon errors by parsing large quantities of data (van noord, 2004; sagot and de la clergerie, 2006; de kok et al, 2009).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4399">
<title id=" W12-1507.xml">generation for grammar engineering </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>starting from set of manually defined semantic representations, the approach consists in running surface realiser on these repre sentations; manually sorting the generated sentences as correct or incorrect; and using the resulting two datasets to detect grammatical structures that systematically occur in the incorrect dataset.
</prevsent>
<prevsent>the approach however is only partially automatised since both the input and the output need to be manually produced/annotated.
</prevsent>
</prevsection>
<citsent citstr=" P12-1062 ">
more recently, (gardent and narayan, 2012) <papid> P12-1062 </papid>has shown how the fully automatic error mining techniques used for parsing could be adapted to mine for errors in the output of surface realiser tested on the sr input data.</citsent>
<aftsection>
<nextsent>in essence, they present an algorithm which enumerate the subtrees in the input data that frequently occur in surface realisation failure (the surface realiser fails to gener 32ate sentence) and rarely occur in surface realisation success.
</nextsent>
<nextsent>in this way, they can identify subtrees in the input that are predominantly associated with generation failure.in sum, tree-bank based evaluation permits detecting over- and under-generation while error mining techniques permits identifying sources of errors; treebank-based evaluation requires reference corpus while error mining techniques require way to sort good from bad ouput; and in all cases, generation-based grammar debugging requires input to be provided (while for parsing, textual input is freely available).
</nextsent>
<nextsent>discussion the main difference between the grade approach and both error mining and tree bank based evaluation is that grade is grammar based.
</nextsent>
<nextsent>no other input is required for the grade algorithm to work than the grammar1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4400">
<title id=" W12-1507.xml">generation for grammar engineering </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>we start by describing the grammar used (semtag), we then summarise the implementation of grade for fb-ltag.
</prevsent>
<prevsent>4.1 semtag.
</prevsent>
</prevsection>
<citsent citstr=" C08-1032 ">
for our experiments, we use the fb-ltag described in (crabbe?, 2005; gardent, 2008).<papid> C08-1032 </papid></citsent>
<aftsection>
<nextsent>this grammar,called semtag, integrates unification-based semantics and can be used both for parsing and for generation.
</nextsent>
<nextsent>it covers the core constructs for nonverbal constituents and most of the verbal constructions for french.
</nextsent>
<nextsent>the semantic representations built are mrss (minimal recur sion semantic representations, (copestake et al, 2001)).<papid> P01-1019 </papid></nextsent>
<nextsent>more specifically, tree adjoining grammar(tag) is tuple ??, n, i, a, s?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4401">
<title id=" W12-1507.xml">generation for grammar engineering </title>
<section> implementation.  </section>
<citcontext>
<prevsection>
<prevsent>this grammar,called semtag, integrates unification-based semantics and can be used both for parsing and for generation.
</prevsent>
<prevsent>it covers the core constructs for nonverbal constituents and most of the verbal constructions for french.
</prevsent>
</prevsection>
<citsent citstr=" P01-1019 ">
the semantic representations built are mrss (minimal recur sion semantic representations, (copestake et al, 2001)).<papid> P01-1019 </papid></citsent>
<aftsection>
<nextsent>more specifically, tree adjoining grammar(tag) is tuple ??, n, i, a, s?
</nextsent>
<nextsent>with ? set of terminals, a set of non-terminals, a finite set of initial trees, a finite set of auxiliary trees, and a distinguished non-terminal (s ? ).
</nextsent>
<nextsent>initial trees are trees whose leaves are labeled with substitution nodes (marked with downarrow) or terminal cate gories3.
</nextsent>
<nextsent>auxiliary trees are distinguished by foot node (marked with star) whose category must be the same as that of the root node.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4402">
<title id=" W12-0106.xml">combining ebmt smt tm and ir technologies for quality and scale </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>a tm essentially stores source and target-language translation pairs for effective reuse of previous translations originally created by human translators.
</prevsent>
<prevsent>tms are often used tostore examples for ebmt systems.
</prevsent>
</prevsection>
<citsent citstr=" W03-0313 ">
after retrieving set of examples with associated translations, ebmt systems automatically extract translations of suitable fragments and combine them to produce grammatical target output.phrase-based smt systems (koehn, 2010a), produce source target al gned sub sentential phrase table which can be adapted as an additional tm to be used in cat environment (simard, 2003; <papid> W03-0313 </papid>bicici and dymetman, 2008; bourdaillet et al ,2009; simard and isabelle, 2009).</citsent>
<aftsection>
<nextsent>koehn and senellart (2010b) use smt to produce the translation ofthe non-matched fragments after obtaining the tm based match.
</nextsent>
<nextsent>ebmt phrases have also been usedto populate the knowledge database of an smt system (groves et al , 2006).
</nextsent>
<nextsent>however, to the best of our knowledge, the use of smt phrase tables within an ebmt system as an additional sub-sentential tm has not been attempted so far.
</nextsent>
<nextsent>some work has been carried out to integrate mt in cat environment to translate the whole segment using the mt system when no sufficiently well matching translation unit (tu) is found in the tm.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4403">
<title id=" W12-0106.xml">combining ebmt smt tm and ir technologies for quality and scale </title>
<section> mt systems.  </section>
<citcontext>
<prevsection>
<prevsent>by contrast, our approach attempts to integrate the sub sentential tm obtained using smt techniques within an ebmt system.
</prevsent>
<prevsent>the smt system used in our hybrid smt ebmt approach is the vanilla moses4 decoder.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
4http://www.statmt.org/moses/ 49 moses (koehn et al , 2007) <papid> P07-2045 </papid>is set of smt tools that include routines to automatically train translation model for any language pair and an efficient decoder to find the most probable translation.</citsent>
<aftsection>
<nextsent>due to lack of space and the wide usage of moses, here wefocus more on the novel ebmt system we have developed for our hybrid smt-ebmt approach.
</nextsent>
<nextsent>the ebmt system described in this section is based on previous work (dandapat et al , 2010) and some of the material has been reproduced here to make the paper complete.like all other ebmt systems, our particular approach comprises three stages: matching, alignment and recombination.
</nextsent>
<nextsent>our ebmt system also uses sub sentential tm in addition to the sentence alignedexample-base.
</nextsent>
<nextsent>using the original tm as training set, additional sub sentential tus (words andphrases) are extracted from it based on word alignments and phrase pairs produced by moses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4404">
<title id=" W12-0106.xml">combining ebmt smt tm and ir technologies for quality and scale </title>
<section> mt systems.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, only considering linguistically motivated tus may limit the matching potential of tm.
</prevsent>
<prevsent>because of this, we used smt technology to automatically create the sub sentential part of our tm at the phrase (i.e. no longer necessarily linguistically motivated) and word level.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
based on moses word alignment (usinggiza++ (och and ney, 2003)) <papid> J03-1002 </papid>and phrase table construction, we construct the additional tm for further use within an ebmt approach.</citsent>
<aftsection>
<nextsent>firstly, we add entries to the tm based on the aligned phrase pairs from the moses phrase table using the following two scores: 1.
</nextsent>
<nextsent>direct phrase translation probabilities: ?(t|s).
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>direct lexical weight: lex(t|s).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4405">
<title id=" W12-0106.xml">combining ebmt smt tm and ir technologies for quality and scale </title>
<section> results and observations.  </section>
<citcontext>
<prevsection>
<prevsent>the training data consists of 250,806 unique parallel sentences.9 as testset we use set of 10,000 randomly drawn sentences disjoint from the training corpus.
</prevsent>
<prevsent>this data also represents particular domain (medicine) but with longer sentence lengths (with an average of 18.8 words per sentence) compared to the iwslt09 data.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we used bleu (papineni et al , 2002) <papid> P02-1040 </papid>for automatic evaluation of our ebmt systems.</citsent>
<aftsection>
<nextsent>table 2 shows the accuracy obtained for both entr and enfr by the ebmttm system described in section 3.
</nextsent>
<nextsent>herewe have two baseline systems (smt and tm) as described in the first two experiments in section 5.
</nextsent>
<nextsent>table 2: baseline bleu scores of the two systems and the scores for ebmttm system.
</nextsent>
<nextsent>system language pairs entr enfr smt 23.59 55.04 tm 15.60 40.23 ebmttm 20.08 48.31 table 2 shows that ebmttm has lower system accuracy than smt for both the language pairs, but 7http://mastarpj.nict.go.jp/iwslt2009/2009/12/downloads.html 8http://opus.lingfil.uu.se/emea.php 9a large number of duplicate sentences exists in the original corpus (approximately 1m sentences).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4406">
<title id=" W12-0106.xml">combining ebmt smt tm and ir technologies for quality and scale </title>
<section> results and observations.  </section>
<citcontext>
<prevsection>
<prevsent>53 better scores than tm alone.
</prevsent>
<prevsent>tables 3 and 4 show that combining ebmt with smt systems shows improvements of 0.82 and 2.75 bleu absolute over the smt baseline (table 2) for both the entr and the enfr datasets.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
in each case, the improvement of ebmttm + smt over the baseline smt is statistically significant (reliability of 98%) using bootstrap re sampling (koehn, 2004).<papid> W04-3250 </papid>table 3: entr mt system accuracies of the combined systems (ebmttm + smt) with different combining factors.</citsent>
<aftsection>
<nextsent>the second column indicates the number (and percentage) of sentences translated by the ebmttm system during combination.
</nextsent>
<nextsent>system: ebmttm + smt condition times ebmttm used bleu (in %) fms 0.85 35 (8.5%) 24.22 fms 0.80 114 (27.5%) 23.99 fms 0.70 197 (47.6%) 22.74 fms 0.80 or (fms 0.70 &amp; equs) 165 (40.0%) 23.87 fms 0.85 &amp; equs 24 (5.8%) 24.41 fms 0.80 &amp; equs 76 (18.4%) 24.19 fms 0.70 &amp; equs 127 (30.7%) 24.08table 4: enfr mt system accuracies for the combined systems (ebmttm + smt) with different combining factors.
</nextsent>
<nextsent>system: ebmttm + smt condition times ebmttm used bleu (in %) fms 0.85 3323 (33.2%) 57.79 fms 0.80 4300 (43.0%) 57.55 fms 0.70 5283 (52.8%) 57.05 fms 0.60 6148 (61.5%) 56.25 fms 0.80 or (fms 0.70 &amp; equs) 4707 (47.1%) 57.46 fms 0.85 &amp; equs 2358 (23.6%) 57.24 fms 0.80 &amp; equs 2953 (29.5%) 57.16 fms 0.70 &amp; equs 3360 (33.6%) 57.08 particular objective of our work is to scale theruntime ebmt system to larger amount of training examples.
</nextsent>
<nextsent>we experiment with the two approaches described in section 4 to improve the run time of the system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4407">
<title id=" W11-2703.xml">a corpus of human written summaries of line graphs </title>
<section> availability.  </section>
<citcontext>
<prevsection>
<prevsent>the files are named according to the graph they are associated with and their position in that graphs collection (e.g., 8-10.txt is the 10th summary for the 8th line graph, and is located in the directory named 8).
</prevsent>
<prevsent>the root of the distribution package contains directory of original image files for the line graphs(named line graphs?), the initial sentences describing each graphs intended message (which was provided to the participants) in sentences.txt, and readme file describing the corpus layout.
</prevsent>
</prevsection>
<citsent citstr=" W02-0109 ">
the corpus is easily loaded with nltk (loper and bird, 2002) <papid> W02-0109 </papid>using these python commands: from nltk.corpus import plaintextcorpusreader lgsroot =  ./lgsummarycorpus/summaries  corpus = plaintextcorpusreader(lgsroot,  .* ) acknowledgments this work was supported in part by the national institute on disability and rehabilitation research under grant no.</citsent>
<aftsection>
<nextsent>h133g080047.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4408">
<title id=" W12-1519.xml">interactive natural language query construction for report generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the authors would also like to thank the referees for their insights and suggestions.of technical proficiency to ask questions using natural language and receive answers in an appropriate, intuitive format.
</prevsent>
<prevsent>using natural language to ask these questions may be easy for users, but is challenging due to the ambiguity inherent in natural languageanaylsis.
</prevsent>
</prevsection>
<citsent citstr=" C00-2161 ">
proposals involving controlled natural language, such as (nelken and francez, 2000), <papid> C00-2161 </papid>can deal with some of the challenges, but the task becomes more difficult when we seek to answer natural language questions in way that is domain portable.</citsent>
<aftsection>
<nextsent>before we can attempt to design and implement aquestion answering system, we need to address several key issues.
</nextsent>
<nextsent>first, we need to decide what knowledge our system needs.
</nextsent>
<nextsent>specifically, we must decide what linguistic knowledge is needed to properly interpret users?
</nextsent>
<nextsent>questions.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4409">
<title id=" W12-1519.xml">interactive natural language query construction for report generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the stance we take regarding each of these issues strongly influences design decisions, ease of installation/configuration, and the end-user experience.here we solve this problem in the context of ac 115 cessing information from structured database ? natural language interface to database (nlidb)(kapetanios et al, 2010).
</prevsent>
<prevsent>however, instead of treating it as natural language analysis problem, we will consider it as task involving natural language generation (nlg) where users build natural language questions by making choices that add words and phrases.
</prevsent>
</prevsection>
<citsent citstr=" P83-1023 ">
using our method, users construct queries in menu driven manner (tennant et al, 1983; <papid> P83-1023 </papid>evans and power, 2003) <papid> E03-2005 </papid>to ask questions thatare always unambiguous and easy for anyone to understand, getting answers in the form of interactive database reports (not textual reports) that are both immediate and consistent.this approach retains the main advantage of traditional nlidbs that allow input of question in afree form text ? the ability for the user to communicate with the information system in english.</citsent>
<aftsection>
<nextsent>there is no need for the user to master computer querylangauge such as sql or mdx.
</nextsent>
<nextsent>many disadvant ges of traditional free input nlidbs are removed (tennant et al, 1983).<papid> P83-1023 </papid></nextsent>
<nextsent>traditional nlidbs fail to analyze some questions and indicate so to the user,greatly decreasing the users confidence in the sys tem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4410">
<title id=" W12-1519.xml">interactive natural language query construction for report generation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the stance we take regarding each of these issues strongly influences design decisions, ease of installation/configuration, and the end-user experience.here we solve this problem in the context of ac 115 cessing information from structured database ? natural language interface to database (nlidb)(kapetanios et al, 2010).
</prevsent>
<prevsent>however, instead of treating it as natural language analysis problem, we will consider it as task involving natural language generation (nlg) where users build natural language questions by making choices that add words and phrases.
</prevsent>
</prevsection>
<citsent citstr=" E03-2005 ">
using our method, users construct queries in menu driven manner (tennant et al, 1983; <papid> P83-1023 </papid>evans and power, 2003) <papid> E03-2005 </papid>to ask questions thatare always unambiguous and easy for anyone to understand, getting answers in the form of interactive database reports (not textual reports) that are both immediate and consistent.this approach retains the main advantage of traditional nlidbs that allow input of question in afree form text ? the ability for the user to communicate with the information system in english.</citsent>
<aftsection>
<nextsent>there is no need for the user to master computer querylangauge such as sql or mdx.
</nextsent>
<nextsent>many disadvant ges of traditional free input nlidbs are removed (tennant et al, 1983).<papid> P83-1023 </papid></nextsent>
<nextsent>traditional nlidbs fail to analyze some questions and indicate so to the user,greatly decreasing the users confidence in the sys tem.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4416">
<title id=" W12-1527.xml">content selection from semantic web data </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>this often led in the past to template or graph-based combined content selection and discourse structuring approaches operating on idiosyncratic ally encoded small sets of input data.
</prevsent>
<prevsent>furthermore, in many nlg-applications, target text sand sometimes even empirical data are not available, which makes it difficult to employ empirical approaches to knowledge elicitation.
</prevsent>
</prevsection>
<citsent citstr=" H05-1042 ">
nonetheless, during the last decade, there has been steady flowof new work on content selection that employed machine learning (barzilay and lapata, 2005; <papid> H05-1042 </papid>duboue and mckeown, 2003; <papid> W03-1016 </papid>jordan and walker, 2005; kelly et al, 2009), <papid> W09-0623 </papid>heuristic search (odonnell et al., 2001; demir et al, 2010; <papid> W10-4202 </papid>mellish and pan, 2008), or combination thereof (bouayad-agha et al., 2011).</citsent>
<aftsection>
<nextsent>all of these strategies can deal with large volumes of data.
</nextsent>
<nextsent>on the other side, there is clear tendency in nlg towards the use of resources encoded in terms of standard semantic web representation formats such as owl and rdf, e.g., (wilcock and jokinen, 2003; bontcheva and wilks, 2004; mellish and pan, 2008; power and third, 2010; <papid> C10-2116 </papid>bouayad-agha et al, 2011; dannells et al, 2012), to name but few.</nextsent>
<nextsent>however, although most of these works make good attempt at realisation, the problem of content determination from semantic web data is relatively untouched.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4417">
<title id=" W12-1527.xml">content selection from semantic web data </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>this often led in the past to template or graph-based combined content selection and discourse structuring approaches operating on idiosyncratic ally encoded small sets of input data.
</prevsent>
<prevsent>furthermore, in many nlg-applications, target text sand sometimes even empirical data are not available, which makes it difficult to employ empirical approaches to knowledge elicitation.
</prevsent>
</prevsection>
<citsent citstr=" W03-1016 ">
nonetheless, during the last decade, there has been steady flowof new work on content selection that employed machine learning (barzilay and lapata, 2005; <papid> H05-1042 </papid>duboue and mckeown, 2003; <papid> W03-1016 </papid>jordan and walker, 2005; kelly et al, 2009), <papid> W09-0623 </papid>heuristic search (odonnell et al., 2001; demir et al, 2010; <papid> W10-4202 </papid>mellish and pan, 2008), or combination thereof (bouayad-agha et al., 2011).</citsent>
<aftsection>
<nextsent>all of these strategies can deal with large volumes of data.
</nextsent>
<nextsent>on the other side, there is clear tendency in nlg towards the use of resources encoded in terms of standard semantic web representation formats such as owl and rdf, e.g., (wilcock and jokinen, 2003; bontcheva and wilks, 2004; mellish and pan, 2008; power and third, 2010; <papid> C10-2116 </papid>bouayad-agha et al, 2011; dannells et al, 2012), to name but few.</nextsent>
<nextsent>however, although most of these works make good attempt at realisation, the problem of content determination from semantic web data is relatively untouched.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4419">
<title id=" W12-1527.xml">content selection from semantic web data </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>this often led in the past to template or graph-based combined content selection and discourse structuring approaches operating on idiosyncratic ally encoded small sets of input data.
</prevsent>
<prevsent>furthermore, in many nlg-applications, target text sand sometimes even empirical data are not available, which makes it difficult to employ empirical approaches to knowledge elicitation.
</prevsent>
</prevsection>
<citsent citstr=" W09-0623 ">
nonetheless, during the last decade, there has been steady flowof new work on content selection that employed machine learning (barzilay and lapata, 2005; <papid> H05-1042 </papid>duboue and mckeown, 2003; <papid> W03-1016 </papid>jordan and walker, 2005; kelly et al, 2009), <papid> W09-0623 </papid>heuristic search (odonnell et al., 2001; demir et al, 2010; <papid> W10-4202 </papid>mellish and pan, 2008), or combination thereof (bouayad-agha et al., 2011).</citsent>
<aftsection>
<nextsent>all of these strategies can deal with large volumes of data.
</nextsent>
<nextsent>on the other side, there is clear tendency in nlg towards the use of resources encoded in terms of standard semantic web representation formats such as owl and rdf, e.g., (wilcock and jokinen, 2003; bontcheva and wilks, 2004; mellish and pan, 2008; power and third, 2010; <papid> C10-2116 </papid>bouayad-agha et al, 2011; dannells et al, 2012), to name but few.</nextsent>
<nextsent>however, although most of these works make good attempt at realisation, the problem of content determination from semantic web data is relatively untouched.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4420">
<title id=" W12-1527.xml">content selection from semantic web data </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>this often led in the past to template or graph-based combined content selection and discourse structuring approaches operating on idiosyncratic ally encoded small sets of input data.
</prevsent>
<prevsent>furthermore, in many nlg-applications, target text sand sometimes even empirical data are not available, which makes it difficult to employ empirical approaches to knowledge elicitation.
</prevsent>
</prevsection>
<citsent citstr=" W10-4202 ">
nonetheless, during the last decade, there has been steady flowof new work on content selection that employed machine learning (barzilay and lapata, 2005; <papid> H05-1042 </papid>duboue and mckeown, 2003; <papid> W03-1016 </papid>jordan and walker, 2005; kelly et al, 2009), <papid> W09-0623 </papid>heuristic search (odonnell et al., 2001; demir et al, 2010; <papid> W10-4202 </papid>mellish and pan, 2008), or combination thereof (bouayad-agha et al., 2011).</citsent>
<aftsection>
<nextsent>all of these strategies can deal with large volumes of data.
</nextsent>
<nextsent>on the other side, there is clear tendency in nlg towards the use of resources encoded in terms of standard semantic web representation formats such as owl and rdf, e.g., (wilcock and jokinen, 2003; bontcheva and wilks, 2004; mellish and pan, 2008; power and third, 2010; <papid> C10-2116 </papid>bouayad-agha et al, 2011; dannells et al, 2012), to name but few.</nextsent>
<nextsent>however, although most of these works make good attempt at realisation, the problem of content determination from semantic web data is relatively untouched.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4421">
<title id=" W12-1527.xml">content selection from semantic web data </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>nonetheless, during the last decade, there has been steady flowof new work on content selection that employed machine learning (barzilay and lapata, 2005; <papid> H05-1042 </papid>duboue and mckeown, 2003; <papid> W03-1016 </papid>jordan and walker, 2005; kelly et al, 2009), <papid> W09-0623 </papid>heuristic search (odonnell et al., 2001; demir et al, 2010; <papid> W10-4202 </papid>mellish and pan, 2008), or combination thereof (bouayad-agha et al., 2011).</prevsent>
<prevsent>all of these strategies can deal with large volumes of data.</prevsent>
</prevsection>
<citsent citstr=" C10-2116 ">
on the other side, there is clear tendency in nlg towards the use of resources encoded in terms of standard semantic web representation formats such as owl and rdf, e.g., (wilcock and jokinen, 2003; bontcheva and wilks, 2004; mellish and pan, 2008; power and third, 2010; <papid> C10-2116 </papid>bouayad-agha et al, 2011; dannells et al, 2012), to name but few.</citsent>
<aftsection>
<nextsent>however, although most of these works make good attempt at realisation, the problem of content determination from semantic web data is relatively untouched.
</nextsent>
<nextsent>for these reasons, we believe that the time has come to bring together researchers working on (orinterested in working on) content selection to participate in challenge for this task using standard freely available web data as input.
</nextsent>
<nextsent>the availability of open modular multi-domain multi-billion triple data and of open onto logical resources (bizer et al,2009) presented in standard knowledge representation formalism make semantic web data natural choice for such challenge.
</nextsent>
<nextsent>as will be presented below, this initial challenge presents relatively simple content selection task with no user model and straightforward communicative goal so that people are encouraged to take part and motivated to stay on for later challenges, in which the task will be successively enhanced from gained experience.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4425">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> development methodology.  </section>
<citcontext>
<prevsection>
<prevsent>fig 1 a).
</prevsent>
<prevsent>(b) having completed this phase, we extend the dictionaries and train the analysis-, transfer- and generation-components of the rule-based core systems using monolingual and bilingual corpora.
</prevsent>
</prevsection>
<citsent citstr=" A94-1016 ">
1 prominent early example is frederking and colleagues (frederking &amp; nirenburg, 1994).<papid> A94-1016 </papid></citsent>
<aftsection>
<nextsent>for an overview of hybrid mt till the late nineties see streiter et al (1999).
</nextsent>
<nextsent>more recent approaches include groves &amp; way (2006a),  way (2006b).
</nextsent>
<nextsent>commercial implementations include apptek (http://www.apptek.com) and language weaver (http://www.languageweaver.com).
</nextsent>
<nextsent>an ongoing mt important project investigating hybrid methods is euromatrixplus (http://www.euromatrixplus.net/) 102 (ii) error detection and improvement cycle: (a) we automatically discover the most frequent problematic grammatical constructions and multiword expressions for commercial rbmt and smt systems using automatic construction-based evaluation as proposed in (babych and hartley, 2009) and develop framework for fixing corresponding grammar rules and extending grammatical coverage of the systems in semiautomatic way.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4426">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> development methodology.  </section>
<citcontext>
<prevsection>
<prevsent>this shortens development time for commercial mt and contributes to yielding significantly higher translation quality.
</prevsent>
<prevsent>(iii) extension to other languages: structural similarity and translation by pivot languages is used to obtain extension to further languages: high-quality translation between closely related languages (e.g., russian and ukrainian or portuguese and spanish) can be achieved with relatively simple resources (using linguistic similarity, but also homomorphism assumptions with respect to parallel text, if available), while greater efforts are put into ensuring better-quality translation between more distant languages (e.g. german and russian).
</prevsent>
</prevsection>
<citsent citstr=" P07-1018 ">
according to our prior research (babych et al, 2007<papid> P07-1018 </papid>b) the pipeline between languages of different similarity results in improved translation quality for larger number of language pairs (e.g., mt from portuguese or ukrainian into german is easier if there are high quality analysis and transfer modules for spanish and russian into german (respectively).</citsent>
<aftsection>
<nextsent>of course, (iii) draws heavily on the detailed analysis and mt systems that the industrial partner in hyghtra provides for number of languages.
</nextsent>
<nextsent>in the following sections we give more details of the work currently done with regard to (i) and with regard to parts of (ii): the creation of new mt system following the strategy sketched.
</nextsent>
<nextsent>we cannot go further into detail with (ii) and (iii) here, which will become priority for future research.
</nextsent>
<nextsent>early pilot studies covering some aspects of the strategy described here (using information from pivot languages and similarity) showed promising results (rapp, 1999; <papid> P99-1067 </papid>rapp &amp; martn vide, 2007; see also koehn &amp; knight, 2002).<papid> W02-0902 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4427">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>in the following sections we give more details of the work currently done with regard to (i) and with regard to parts of (ii): the creation of new mt system following the strategy sketched.
</prevsent>
<prevsent>we cannot go further into detail with (ii) and (iii) here, which will become priority for future research.
</prevsent>
</prevsection>
<citsent citstr=" P99-1067 ">
early pilot studies covering some aspects of the strategy described here (using information from pivot languages and similarity) showed promising results (rapp, 1999; <papid> P99-1067 </papid>rapp &amp; martn vide, 2007; see also koehn &amp; knight, 2002).<papid> W02-0902 </papid></citsent>
<aftsection>
<nextsent>we expect that the proposed semi-automatic creation of new mt system as sketched above will work best if one of the two languages involved is already  known  by modules to which the system has access.
</nextsent>
<nextsent>against the background of the pipeline approach mentioned above in (iii), this means that we assume an analysis and translation system that continuously grows by  learning  new languages where  learning  is facilitated by information about the languages already  known  and by exploiting similarity assumptions ? and, of course, by being fed with information prepared and provided by the human  companion  of the system.
</nextsent>
<nextsent>from this perspective, we assume the following steps of extending the system (with work done by the  companion  and work done by the system) 1.
</nextsent>
<nextsent>acquire parallel and comparable corpora..
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4428">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>in the following sections we give more details of the work currently done with regard to (i) and with regard to parts of (ii): the creation of new mt system following the strategy sketched.
</prevsent>
<prevsent>we cannot go further into detail with (ii) and (iii) here, which will become priority for future research.
</prevsent>
</prevsection>
<citsent citstr=" W02-0902 ">
early pilot studies covering some aspects of the strategy described here (using information from pivot languages and similarity) showed promising results (rapp, 1999; <papid> P99-1067 </papid>rapp &amp; martn vide, 2007; see also koehn &amp; knight, 2002).<papid> W02-0902 </papid></citsent>
<aftsection>
<nextsent>we expect that the proposed semi-automatic creation of new mt system as sketched above will work best if one of the two languages involved is already  known  by modules to which the system has access.
</nextsent>
<nextsent>against the background of the pipeline approach mentioned above in (iii), this means that we assume an analysis and translation system that continuously grows by  learning  new languages where  learning  is facilitated by information about the languages already  known  and by exploiting similarity assumptions ? and, of course, by being fed with information prepared and provided by the human  companion  of the system.
</nextsent>
<nextsent>from this perspective, we assume the following steps of extending the system (with work done by the  companion  and work done by the system) 1.
</nextsent>
<nextsent>acquire parallel and comparable corpora..
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4430">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>the size of the current version is up to 40 million words per language, and several of the languages we are currently considering are covered.
</prevsent>
<prevsent>also, we make use of other parallel corpora such as the canadian hansa rds (proceedings of the canadian parliament) for the english french language pair.
</prevsent>
</prevsection>
<citsent citstr=" P99-1068 ">
for non-eu languages (mainly russian), we intend to conduct pilot study to establish the feasibility of retrieving parallel corpora from the web, problem for which various approaches have been proposed (resnik, 1999; <papid> P99-1068 </papid>munteanu &amp; marcu, 2005; <papid> J05-4003 </papid>wu &amp; fung, 2005).<papid> I05-1023 </papid></citsent>
<aftsection>
<nextsent>in addition to the parallel corpora, we will need large monolingual corpora in the future (at least 200 million words) for each of the six languages.
</nextsent>
<nextsent>here, we intend to use newspaper corpora supplemented with text collections downloadable from the web.
</nextsent>
<nextsent>the corpora are stored in database that allows for assigning analyses of different depth and nature to the sentences and for alignment between the sentences and their analyses.
</nextsent>
<nextsent>the architecture of this database and the corresponding analysis and evaluation fron tend is described in (eberle et al 2010, 2012).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4431">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>the size of the current version is up to 40 million words per language, and several of the languages we are currently considering are covered.
</prevsent>
<prevsent>also, we make use of other parallel corpora such as the canadian hansa rds (proceedings of the canadian parliament) for the english french language pair.
</prevsent>
</prevsection>
<citsent citstr=" J05-4003 ">
for non-eu languages (mainly russian), we intend to conduct pilot study to establish the feasibility of retrieving parallel corpora from the web, problem for which various approaches have been proposed (resnik, 1999; <papid> P99-1068 </papid>munteanu &amp; marcu, 2005; <papid> J05-4003 </papid>wu &amp; fung, 2005).<papid> I05-1023 </papid></citsent>
<aftsection>
<nextsent>in addition to the parallel corpora, we will need large monolingual corpora in the future (at least 200 million words) for each of the six languages.
</nextsent>
<nextsent>here, we intend to use newspaper corpora supplemented with text collections downloadable from the web.
</nextsent>
<nextsent>the corpora are stored in database that allows for assigning analyses of different depth and nature to the sentences and for alignment between the sentences and their analyses.
</nextsent>
<nextsent>the architecture of this database and the corresponding analysis and evaluation fron tend is described in (eberle et al 2010, 2012).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4432">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>the size of the current version is up to 40 million words per language, and several of the languages we are currently considering are covered.
</prevsent>
<prevsent>also, we make use of other parallel corpora such as the canadian hansa rds (proceedings of the canadian parliament) for the english french language pair.
</prevsent>
</prevsection>
<citsent citstr=" I05-1023 ">
for non-eu languages (mainly russian), we intend to conduct pilot study to establish the feasibility of retrieving parallel corpora from the web, problem for which various approaches have been proposed (resnik, 1999; <papid> P99-1068 </papid>munteanu &amp; marcu, 2005; <papid> J05-4003 </papid>wu &amp; fung, 2005).<papid> I05-1023 </papid></citsent>
<aftsection>
<nextsent>in addition to the parallel corpora, we will need large monolingual corpora in the future (at least 200 million words) for each of the six languages.
</nextsent>
<nextsent>here, we intend to use newspaper corpora supplemented with text collections downloadable from the web.
</nextsent>
<nextsent>the corpora are stored in database that allows for assigning analyses of different depth and nature to the sentences and for alignment between the sentences and their analyses.
</nextsent>
<nextsent>the architecture of this database and the corresponding analysis and evaluation fron tend is described in (eberle et al 2010, 2012).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4433">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>in (babych et al, 2012) we propose systematic approach to recovering such missing generation oriented representations from grammar models and statistical combinatorial properties of annotated features.
</prevsent>
<prevsent>step 3: generating dictionary extensions from parallel corpora based on parallel corpora, dictionaries can be derived using established techniques of automatic sentence alignment and word alignment.
</prevsent>
</prevsection>
<citsent citstr=" J99-1003 ">
for sentence alignment, the length-based gale &amp; church aligner (1993) can be used, or ? alternatively ? dan mela meds gsa-algorithm (geometric sentence alignment; melamed, 1999).<papid> J99-1003 </papid></citsent>
<aftsection>
<nextsent>for segmentation of text we use corresponding lingenio-tools (unpublished).2 for word alignment giza++ (och &amp; ney, 2003) <papid> J03-1002 </papid>is the standard tool.</nextsent>
<nextsent>given word alignment, the extraction of (smt) dictionary is relatively straightforward.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4434">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>step 3: generating dictionary extensions from parallel corpora based on parallel corpora, dictionaries can be derived using established techniques of automatic sentence alignment and word alignment.
</prevsent>
<prevsent>for sentence alignment, the length-based gale &amp; church aligner (1993) can be used, or ? alternatively ? dan mela meds gsa-algorithm (geometric sentence alignment; melamed, 1999).<papid> J99-1003 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
for segmentation of text we use corresponding lingenio-tools (unpublished).2 for word alignment giza++ (och &amp; ney, 2003) <papid> J03-1002 </papid>is the standard tool.</citsent>
<aftsection>
<nextsent>given word alignment, the extraction of (smt) dictionary is relatively straightforward.
</nextsent>
<nextsent>with the exception of sentence segmentation, these algorithms are largely language independent and can be used for all of the languages that we consider.
</nextsent>
<nextsent>we did this for number of language pairs on the basis of the 2 if these cannot be applied because of lack of.
</nextsent>
<nextsent>information about language, we intend to use the algorithm by kiss &amp; strunk (2006).<papid> J06-4003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4435">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>with the exception of sentence segmentation, these algorithms are largely language independent and can be used for all of the languages that we consider.
</prevsent>
<prevsent>we did this for number of language pairs on the basis of the 2 if these cannot be applied because of lack of.
</prevsent>
</prevsection>
<citsent citstr=" J06-4003 ">
information about language, we intend to use the algorithm by kiss &amp; strunk (2006).<papid> J06-4003 </papid></citsent>
<aftsection>
<nextsent>an open-source implementation of parts of the kiss &amp; strunk algorithm is available from patrick tschorn at http://www.denkselbst.de/sentrick/index.html.
</nextsent>
<nextsent>104 europarl-texts considered (as stored in our database).
</nextsent>
<nextsent>in order to optimize the results we use the dictionaries of step 1 as set of cognates (cf.
</nextsent>
<nextsent>simard at al 1992, gough &amp; way 2004), as well as other words easily obtainable from the internet that can be used for this purpose (like company names and other named entities with cross-language identity and terminology translations).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4436">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>this is far too small for serious general purpose mt system.
</prevsent>
<prevsent>note that, in comparison, the english german dictionary used in the current lingenio mt product comprises more than 480,000 keywords and phrases.
</prevsent>
</prevsection>
<citsent citstr=" W97-0119 ">
step 4: expanding dictionaries using comparable corpora (word equations) in order to expand the dictionaries using set of monolingual comparable corpora, the basic approach pioneered by fung &amp; mckeown (1997) <papid> W97-0119 </papid>and rapp (1995),  <papid> P95-1050 </papid>and rapp (1999) <papid> P99-1067 </papid>is to be further developed and refined in the second phase of the project as to obtain practical tool that can be used in an industrial context.</citsent>
<aftsection>
<nextsent>the basic assumption underlying the approach is that across languages there is correlation between the co-occurrences of words that are translations of each other.
</nextsent>
<nextsent>if ? for example ? in text of one language two words and co-occur more often than expected by chance, then in text of another language those words that are translations of and should also co-occur more frequently than expected.
</nextsent>
<nextsent>it is further assumed that small dictionary (as generated in step 2) is available at the beginning, and that the aim is to expand this basic lexicon.
</nextsent>
<nextsent>using corpus of the target language, first co-occurrence matrix is computed whose rows are all word types occurring in the corpus and whose columns are all target words appearing in the basic lexicon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4437">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>this is far too small for serious general purpose mt system.
</prevsent>
<prevsent>note that, in comparison, the english german dictionary used in the current lingenio mt product comprises more than 480,000 keywords and phrases.
</prevsent>
</prevsection>
<citsent citstr=" P95-1050 ">
step 4: expanding dictionaries using comparable corpora (word equations) in order to expand the dictionaries using set of monolingual comparable corpora, the basic approach pioneered by fung &amp; mckeown (1997) <papid> W97-0119 </papid>and rapp (1995),  <papid> P95-1050 </papid>and rapp (1999) <papid> P99-1067 </papid>is to be further developed and refined in the second phase of the project as to obtain practical tool that can be used in an industrial context.</citsent>
<aftsection>
<nextsent>the basic assumption underlying the approach is that across languages there is correlation between the co-occurrences of words that are translations of each other.
</nextsent>
<nextsent>if ? for example ? in text of one language two words and co-occur more often than expected by chance, then in text of another language those words that are translations of and should also co-occur more frequently than expected.
</nextsent>
<nextsent>it is further assumed that small dictionary (as generated in step 2) is available at the beginning, and that the aim is to expand this basic lexicon.
</nextsent>
<nextsent>using corpus of the target language, first co-occurrence matrix is computed whose rows are all word types occurring in the corpus and whose columns are all target words appearing in the basic lexicon.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4440">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>also, as the frequent words are already covered by the basic lexicon (whose production from parallel corpora on the basis of manually compiled kernel does not show 105 an ambiguity problem of similar significance), and as experience shows that most low frequency words in full-size lexicon tend to be unambiguous, the ambiguity problem is reduced further for the words investigated and extracted by this comparison method.
</prevsent>
<prevsent>step 5: expanding dictionaries using comparable corpora (multiword units) in order to account for technical terms, idioms, collocations, and typical short phrases, an important feature of an mt lexicon is high coverage of multiword units.
</prevsent>
</prevsection>
<citsent citstr=" P06-2095 ">
very recent work conducted at the university of leeds (sharoff et al., 2006) <papid> P06-2095 </papid>shows that dictionary entries for such multiword units can be derived from comparable corpora if dictionary of single words is available.</citsent>
<aftsection>
<nextsent>it could even be shown that this methodology can be superior to deriving multiword-units from parallel corpora (babych et al, 2007<papid> P07-1018 </papid>).</nextsent>
<nextsent>this is major breakthrough as comparable corpora are far easier to acquire than parallel corpora.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4442">
<title id=" W12-0114.xml">design of a hybrid high quality machine translation system </title>
<section> creation of new system.  </section>
<citcontext>
<prevsection>
<prevsent>this is major breakthrough as comparable corpora are far easier to acquire than parallel corpora.
</prevsent>
<prevsent>it even opens up the possibility of building domain specific dictionaries by using texts from different domains.
</prevsent>
</prevsection>
<citsent citstr=" J93-1007 ">
the outline of the algorithm is as follows: ? extract collocations from corpus of the source language (smadja, 1993) ? <papid> J93-1007 </papid>to translate collocation, look up all its words using any dictionary ? generate all possible permutations (sequences) of the word translations ? count the occurrence frequencies of these sequences in corpus of the target language and test for significance ? consider the most significant sequence to be the translation of the source language collocation of course, in later steps of the project, we will experiment on filtering these sequences by exploiting structural knowledge similarly to what was described in the two previous steps.</citsent>
<aftsection>
<nextsent>this can be obtained on the basis of the declarative analysis component of the new language which is developed in parallel.
</nextsent>
<nextsent>step 6: cross-validate dictionaries the combination of the corpus-based methods for automatic dictionary generation as described in steps 3 to 5 will lead to high coverage dictionaries as the availability of very large monolingual corpora is no major problem for our languages.
</nextsent>
<nextsent>however, as all steps are error prone, it can be expected that considerable number of dictionary entries (e.g. 50%) are not correct.
</nextsent>
<nextsent>to facilitate (but not eliminate) the manual verification of the dictionary, we will perform an automatic cross check which utilizes the dictionaries?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4445">
<title id=" W12-1619.xml">integrating location visibility and question answering in a spoken dialogue system for pedestrian city exploration </title>
<section> architecture.  </section>
<citcontext>
<prevsection>
<prevsent>3.5 question-answering server.
</prevsent>
<prevsent>the qa server currently answers range of definition questions.
</prevsent>
</prevsection>
<citsent citstr=" P09-2082 ">
e.g., tell me more about the scottish parliament?, who was david hume??, etc. qaidentifies the entity focused on in the question using machine-learning techniques (mikhailian et al, 2009), <papid> P09-2082 </papid>and then proceeds to textual search on texts from the gazetteer of scotland and wikipedia, and definitions from wordnet glosses.</citsent>
<aftsection>
<nextsent>candidates are reranked using trained confidence score with the top candidate used as the final answer.
</nextsent>
<nextsent>this answer is provided as flow of sentence chunks that the user can interrupt.
</nextsent>
<nextsent>this information can also be pushed by the system when salient entity appears in the users viewshed.
</nextsent>
<nextsent>for the purposes of this (necessarily non-mobile) demonstration, we present web-based interface that simulates users walking in 3d city environment.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4446">
<title id=" W12-1619.xml">integrating location visibility and question answering in a spoken dialogue system for pedestrian city exploration </title>
<section> web-based user interface.  </section>
<citcontext>
<prevsection>
<prevsent>for the purposes of this (necessarily non-mobile) demonstration, we present web-based interface that simulates users walking in 3d city environment.
</prevsent>
<prevsent>users will be able to provide speech or text input (if the demonstration environment is too noisy for usable speech recognition as is often the case at conference demonstration sessions).the web-based client is javascript/html program running on the users web browser.
</prevsent>
</prevsection>
<citsent citstr=" P12-3009 ">
for ade tailed description of this component, please refer to (janarthanam et al, 2012).<papid> P12-3009 </papid></citsent>
<aftsection>
<nextsent>it consists of two parts: the street view panel and the interaction panel.
</nextsent>
<nextsent>the street view panel presents simulated real world visually to the user.
</nextsent>
<nextsent>a google street view client (google maps api) is created with an initial user coordinate which then allows the web user to get panoramic view of the streets around the users virtual location.
</nextsent>
<nextsent>the user can walk around using the arrow keys on his keyboard or the mouse.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4447">
<title id=" W11-2014.xml">stability and accuracy in incremental speech recognition </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>where conventional methods only return result after some indication of user completion (for example, short period of si lence), isr returns partial phrase results while the user is still speaking.
</prevsent>
<prevsent>having access to real time stream of user speech enables more natural behavior by sds, and is foundation for creating systems which take more active role in conversations.
</prevsent>
</prevsection>
<citsent citstr=" E09-1085 ">
research by fink et al(1998) and skantze&amp; schlangen (2009), <papid> E09-1085 </papid>among others, has demonstrated the efficacy of isr but has also drawn attention to significant obstacle to widespreaduse: partial phrase results are generally unstable and so, as more speech is decoded, are prone to revision.</citsent>
<aftsection>
<nextsent>for example, the isr component in bus information sds may return the partial leaving from hills?, where hills?
</nextsent>
<nextsent>is neighborhood name.
</nextsent>
<nextsent>it may then return the revision leaving from pittsburgh?, which the system must handle gracefully.
</nextsent>
<nextsent>given this propensity to revise, stability measure (sm) ? likelihood of partial result remaining unchanged compared to the final result ? is necessary for optimal incremental system behavior.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4450">
<title id=" W11-2014.xml">stability and accuracy in incremental speech recognition </title>
<section> background and related work.  </section>
<citcontext>
<prevsection>
<prevsent>skantze &amp; schlangen (2009) <papid> E09-1085 </papid>observed asimilar trend, finding that an incremental system was clearly preferred?</prevsent>
<prevsent>since it was experienced as more pleasant and human-like?,though it did not actually outperform the non incremental system in number dictation task.some recent work has focused on incremental natural language understanding (nlu).</prevsent>
</prevsection>
<citsent citstr=" W09-3902 ">
devault et al (2009) <papid> W09-3902 </papid>showed that when using arelatively small number of semantic possibilities the correct interpretation could be predicted by early incremental results.</citsent>
<aftsection>
<nextsent>schlangen et al(2009) <papid> W09-3905 </papid>demonstrated that an incremental reference re solver could identify the correct reference out of 12 more than 50% of the time.</nextsent>
<nextsent>this type of nlu can use context and other information to be somewhat resilient to errors, and word recognition inaccuracies may not yield 111 change in understanding.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4451">
<title id=" W11-2014.xml">stability and accuracy in incremental speech recognition </title>
<section> background and related work.  </section>
<citcontext>
<prevsection>
<prevsent>since it was experienced as more pleasant and human-like?,though it did not actually outperform the non incremental system in number dictation task.some recent work has focused on incremental natural language understanding (nlu).
</prevsent>
<prevsent>devault et al (2009) <papid> W09-3902 </papid>showed that when using arelatively small number of semantic possibilities the correct interpretation could be predicted by early incremental results.</prevsent>
</prevsection>
<citsent citstr=" W09-3905 ">
schlangen et al(2009) <papid> W09-3905 </papid>demonstrated that an incremental reference re solver could identify the correct reference out of 12 more than 50% of the time.</citsent>
<aftsection>
<nextsent>this type of nlu can use context and other information to be somewhat resilient to errors, and word recognition inaccuracies may not yield 111 change in understanding.
</nextsent>
<nextsent>in this paper we focus on improving accuracy and stability at the word level; we belief that improvements at the word level are likely to improve performance at the understanding level, although we do not evaluate this here.a number of researchers have described methods for evaluating and improving the stability of isr results (baumann et al, 2009; <papid> N09-1043 </papid>fink et al, 1998).</nextsent>
<nextsent>baumann, atterer, &amp; schlangen spoke directly to stability by comparing partial phrase results against the final hypothesis produced by the asr?.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4452">
<title id=" W11-2014.xml">stability and accuracy in incremental speech recognition </title>
<section> background and related work.  </section>
<citcontext>
<prevsection>
<prevsent>schlangen et al(2009) <papid> W09-3905 </papid>demonstrated that an incremental reference re solver could identify the correct reference out of 12 more than 50% of the time.</prevsent>
<prevsent>this type of nlu can use context and other information to be somewhat resilient to errors, and word recognition inaccuracies may not yield 111 change in understanding.</prevsent>
</prevsection>
<citsent citstr=" N09-1043 ">
in this paper we focus on improving accuracy and stability at the word level; we belief that improvements at the word level are likely to improve performance at the understanding level, although we do not evaluate this here.a number of researchers have described methods for evaluating and improving the stability of isr results (baumann et al, 2009; <papid> N09-1043 </papid>fink et al, 1998).</citsent>
<aftsection>
<nextsent>baumann, atterer, &amp; schlangen spoke directly to stability by comparing partial phrase results against the final hypothesis produced by the asr?.
</nextsent>
<nextsent>they show that increasing the amount of right context?
</nextsent>
<nextsent>the amount of speech after the end of the putative partial result ? increases the stability of the partials.
</nextsent>
<nextsent>fink etal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4453">
<title id=" W11-2014.xml">stability and accuracy in incremental speech recognition </title>
<section> stability and confidence measures.  </section>
<citcontext>
<prevsection>
<prevsent>both are useful in real systems: for example, if partial is likely stable but unlikely correct, the system might interrupt the user and ask them to start again.
</prevsent>
<prevsent>we use logistic regression to learn separate classifiers for sm and cm.
</prevsent>
</prevsection>
<citsent citstr=" W09-3919 ">
logistic regression is appealing because it is well-calibrated, and has shown good performance for whole-utteranceconfidence measures (williams and balakrishnan, 2009).<papid> W09-3919 </papid></citsent>
<aftsection>
<nextsent>for this, we use the bxr package with default settings (genkin et al, 2011).
</nextsent>
<nextsent>for terminal and basic isr we use 11 features:the raw watson confidence score, the individual features which affect the confidence score,the normalized cost, the normalized speech likelihood, the likelihoods of competing models, the best path score of word confusion network(wcn), the length of wcn, the worst probability in the wcn, and the length of n-best list.
</nextsent>
<nextsent>for laisr, four additional features are used: three binary indicators of whether the partial is terminal, immortal or terminal following an immortal, and one which gives the percentage of words in the hypothesis that are immortal.
</nextsent>
<nextsent>we built stability and confidence measures for basic isr, terminal isr, and laisr.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4454">
<title id=" W11-2014.xml">stability and accuracy in incremental speech recognition </title>
<section> discussion and conclusion.  </section>
<citcontext>
<prevsection>
<prevsent>confidence and stability measures couldbe used to determine whether/when/how to display recognized text to viewer, or to informdown-stream processes such as named entity extraction or machine translation.of course, an important objective is to evaluate our stability and confidence measures with laisr in an actual spoken dialogue system.
</prevsent>
<prevsent>isr completely restructures the conventional turn-based dialogue manager, giving the agent the opportunity to speak at any moment.
</prevsent>
</prevsection>
<citsent citstr=" P10-1019 ">
the use of reinforcement learning to make these turn-taking decisions has been shown in asmall simulated domain by selfridge and hee man (2010), <papid> P10-1019 </papid>and we believe this paper builds foundation for pursuing these ideas in real system.</citsent>
<aftsection>
<nextsent>acknowledgments thanks to vincent goffin for help with this work, and the anonymous reviewers for their thoughtful suggestions and critique.
</nextsent>
<nextsent>we acknowledge funding from the nsf under grant iis-0713698.
</nextsent>
<nextsent>118
</nextsent>

</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4455">
<title id=" W11-2508.xml">a distributional similarity approach to the detection of semantic change in the google books ngram corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>computational analysis of such representative dia chronic data made it possible to trace different cultural trends in the last centuries.
</prevsent>
<prevsent>mitchel et al (2010) exploit the change in word frequency as the main measure for the quantitative investigation of cultural and linguistic phenomena; in this paper, we extend this approach by measuring the semantic similarity of the word occurrences in two different time points using distributional semantics model (turney and pantel, 2010).
</prevsent>
</prevsection>
<citsent citstr=" N06-1017 ">
semantic change, defined as change of one or more meanings of the word in time (lehmann, 1992), is of interest to historical linguistics and is related to the natural language processing task of unknown word sense detection (erk, 2006).<papid> N06-1017 </papid></citsent>
<aftsection>
<nextsent>developing automatic methods for identifying changes inword meaning can therefore be useful for both theoretical linguistics and variety of nlp applications which depend on lexical information.some first automatic approaches to the semantic change detection task were recently proposed by sagi et al (2009) <papid> W09-0214 </papid>and cook and stevenson (2010).</nextsent>
<nextsent>these works focus on specific types of semantic change, i.e., sagi et al (2009) <papid> W09-0214 </papid>aim to identify widening and narrowing of meaning, while cook and stevenson (2010) concentrate on amelioration and pejoration cases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4456">
<title id=" W11-2508.xml">a distributional similarity approach to the detection of semantic change in the google books ngram corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>mitchel et al (2010) exploit the change in word frequency as the main measure for the quantitative investigation of cultural and linguistic phenomena; in this paper, we extend this approach by measuring the semantic similarity of the word occurrences in two different time points using distributional semantics model (turney and pantel, 2010).
</prevsent>
<prevsent>semantic change, defined as change of one or more meanings of the word in time (lehmann, 1992), is of interest to historical linguistics and is related to the natural language processing task of unknown word sense detection (erk, 2006).<papid> N06-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" W09-0214 ">
developing automatic methods for identifying changes inword meaning can therefore be useful for both theoretical linguistics and variety of nlp applications which depend on lexical information.some first automatic approaches to the semantic change detection task were recently proposed by sagi et al (2009) <papid> W09-0214 </papid>and cook and stevenson (2010).</citsent>
<aftsection>
<nextsent>these works focus on specific types of semantic change, i.e., sagi et al (2009) <papid> W09-0214 </papid>aim to identify widening and narrowing of meaning, while cook and stevenson (2010) concentrate on amelioration and pejoration cases.</nextsent>
<nextsent>their evaluation of the proposed methods is rather qualitative, concerning just few examples.in present work we address the task of automatic detection of the semantic change of words in quantitative way, comparing our novel distributional similarity approach to relative-frequency-based method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4460">
<title id=" W11-2508.xml">a distributional similarity approach to the detection of semantic change in the google books ngram corpus </title>
<section> measuring semantic change.  </section>
<citcontext>
<prevsection>
<prevsent>the vectors can be compared by computing the cosine of their angle.
</prevsent>
<prevsent>since the context vectors are computed in the same vector space, the procedure is completely equivalent to calculating similarity between two different words in the same corpora;the context vectors can be considered as belonging to one co-occurrence matrix and corresponding to two different row elements word 60s and word 90s.
</prevsent>
</prevsection>
<citsent citstr=" J10-4006 ">
2lmi proved to be good measure for different semantic tasks, see for example the work of baroni and lenci, 2010.<papid> J10-4006 </papid></citsent>
<aftsection>
<nextsent>68 group examples sim freq more frequent users 0.29 -0.94 in 90s sleep 0.23 -0.32 disease 0.87 -0.3 card 0.17 -0.1 more frequent dealers 0.16 0.04 in 60s coach 0.25 0.12 energy 0.79 0.14 cent 0.99 1.13table 1: examples illustrating word selection with similarity (sim) and log-frequency (freq) metric values.we use the described procedure to measure semantic change of word in two corpora of interest,and hence between two time periods.
</nextsent>
<nextsent>high similarity value (close to 1) would suggest that word has not undergone semantic change, while obtaining low similarity (close to 0) should indicate noticeable change in the meaning and the use of the word.
</nextsent>
<nextsent>4.1 distributional space construction.
</nextsent>
<nextsent>to be able to compute distributional similarity for the words in the 60s and 90s corpora, we randomly chose 250,000 mid-frequency words as the context elements of the vector space.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4461">
<title id=" W11-2508.xml">a distributional similarity approach to the detection of semantic change in the google books ngram corpus </title>
<section> results and discussion.  </section>
<citcontext>
<prevsection>
<prevsent>it is enough to have look at their highest weighted co-occurrences to admit that the context of their usage has indeed changed (table 3).
</prevsent>
<prevsent>these examples show the difference between the phenomenon of semantic change in linguistics and the case of context change.
</prevsent>
</prevsection>
<citsent citstr=" D10-1114 ">
it is well known that the different contexts that distributional semantics catches do not always directly refer to what linguists would consider distinct senses (reisinger and mooney, 2010).<papid> D10-1114 </papid></citsent>
<aftsection>
<nextsent>most people would agree that the word parent?
</nextsent>
<nextsent>has the same meaning now as it had 40 years before, still the social context in which it is used has evidently changed, reflected by the more frequent single parent family(ies)?
</nextsent>
<nextsent>col locate found in the 90s.
</nextsent>
<nextsent>the same is true for sleep?, whose usage context did not change radically, but might have parent?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4462">
<title id=" W11-2029.xml">learning to balance grounding rationales for dialogue systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to limit communication errors, an sds can relyon strategies to detect and recover from incorrect recognition output (bohus, 2007).
</prevsent>
<prevsent>in others?
</prevsent>
</prevsection>
<citsent citstr=" H05-1029 ">
work, the grounding status of an utterance is typically binary (i.e., understood or not) (allen, ferguson and stent, 2001; bohus and rudnicky, 2005; <papid> H05-1029 </papid>paek and horvitz, 2000) or ternary (i.e., understood, misunderstood, not understood) (bohus and rudnicky, 2009).</citsent>
<aftsection>
<nextsent>forrsooths grounding decisions relyon mixture of strategies, are based on degrees of evidence (bohus and rudnicky, 2009; roque and traum, 2009), and disambiguate among candidate interpretations.
</nextsent>
<nextsent>work in (devault and stone, 2009) <papid> E09-1022 </papid>on disambiguation in task-oriented dialogue differs from ours in that it addresses genuine ambiguities rather than noise resulting from inaccurate asr.</nextsent>
<nextsent>forrsooth is based on forr (for the right reasons), an architecture for learning and problem solving (epstein, 1994).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4463">
<title id=" W11-2029.xml">learning to balance grounding rationales for dialogue systems </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>work, the grounding status of an utterance is typically binary (i.e., understood or not) (allen, ferguson and stent, 2001; bohus and rudnicky, 2005; <papid> H05-1029 </papid>paek and horvitz, 2000) or ternary (i.e., understood, misunderstood, not understood) (bohus and rudnicky, 2009).</prevsent>
<prevsent>forrsooths grounding decisions relyon mixture of strategies, are based on degrees of evidence (bohus and rudnicky, 2009; roque and traum, 2009), and disambiguate among candidate interpreta tions.</prevsent>
</prevsection>
<citsent citstr=" E09-1022 ">
work in (devault and stone, 2009) <papid> E09-1022 </papid>on disambiguation in task-oriented dialogue differs from ours in that it addresses genuine ambiguities rather than noise resulting from inaccurate asr.</citsent>
<aftsection>
<nextsent>forrsooth is based on forr (for the right reasons), an architecture for learning and problem solving (epstein, 1994).
</nextsent>
<nextsent>forr uses sequences of decisions from multiple rationales to solve problems.
</nextsent>
<nextsent>implementations have proved robust in game learning, simulated path finding, and constraint solving.
</nextsent>
<nextsent>forr relies on an adaptive, hierarchical mixture of resource-bounded procedures called advisors.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4464">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>because both of these mechanisms work at the phrase level, they have proven very effective at capturing short-range reordering behaviors, but unable to describe lon grange movements; in fact, the distortion penalty effectively causes the translation system to not prefer long-range re-orderings, even when they are assigned significantly higher probability by the language model.
</prevsent>
<prevsent>the problem is particularly acute in translating from arabic to english: arabic sentences frequently exhibit vso ordering (both vso and svo are permitted in arabic), while english permits only an svo order.
</prevsent>
</prevsection>
<citsent citstr=" W10-1735 ">
past research has shown that verb anticipation and subject-span detection is major source of error when translating from arabic to english (green et al, 2009; bisazza and federico, 2010).<papid> W10-1735 </papid></citsent>
<aftsection>
<nextsent>unable to perform long-range reordering, psmt frequently produces english sentences in which verbs precede their subjects (sometimes with hallucinated?
</nextsent>
<nextsent>pronouns in front of them) or do not appear at all.
</nextsent>
<nextsent>intuitively, better handling of these reorderings has the potential to improve both accuracy and fluency of translation.
</nextsent>
<nextsent>in this paper, we present two parse fuzzificationtechniques which allow the translation system to select among range of possible sv re-orderings.with this approach, we demonstrate 0.3-point improvement in bleu score (69% of the maximum possible using gold parses), and corresponding improvement in the percentage of syntactically well formed subjects under manual evaluation.the rest of the paper is structured as follows.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4465">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>section 2 gives review of research on this topic.
</prevsent>
<prevsent>section 3 motivates the approach discussed in section 4.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
227 section 5 presents the results of set of machine translation experiments using the automatic metrics bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (baner jee and lavie, 2005), <papid> W05-0909 </papid>and manual-evaluation of subject integrity.</citsent>
<aftsection>
<nextsent>section 6 discusses our conclusions and future plans.
</nextsent>
<nextsent>the general approach pursued in this paper that of using pre-ordering to improve translation output?
</nextsent>
<nextsent>has been explored by many researchers.
</nextsent>
<nextsent>most work has focused on automatically learning reordering rules (xia and mccord, 2004; <papid> C04-1073 </papid>habash, 2007b; elming, 2008; <papid> W08-0406 </papid>elming and habash, 2009; <papid> W09-0809 </papid>dyerand resnik, 2010).<papid> N10-1128 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4466">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>section 2 gives review of research on this topic.
</prevsent>
<prevsent>section 3 motivates the approach discussed in section 4.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
227 section 5 presents the results of set of machine translation experiments using the automatic metrics bleu (papineni et al, 2002) <papid> P02-1040 </papid>and meteor (baner jee and lavie, 2005), <papid> W05-0909 </papid>and manual-evaluation of subject integrity.</citsent>
<aftsection>
<nextsent>section 6 discusses our conclusions and future plans.
</nextsent>
<nextsent>the general approach pursued in this paper that of using pre-ordering to improve translation output?
</nextsent>
<nextsent>has been explored by many researchers.
</nextsent>
<nextsent>most work has focused on automatically learning reordering rules (xia and mccord, 2004; <papid> C04-1073 </papid>habash, 2007b; elming, 2008; <papid> W08-0406 </papid>elming and habash, 2009; <papid> W09-0809 </papid>dyerand resnik, 2010).<papid> N10-1128 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4467">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the general approach pursued in this paper that of using pre-ordering to improve translation output?
</prevsent>
<prevsent>has been explored by many researchers.
</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
most work has focused on automatically learning reordering rules (xia and mccord, 2004; <papid> C04-1073 </papid>habash, 2007b; elming, 2008; <papid> W08-0406 </papid>elming and habash, 2009; <papid> W09-0809 </papid>dyerand resnik, 2010).<papid> N10-1128 </papid></citsent>
<aftsection>
<nextsent>xia and mccord (2004) <papid> C04-1073 </papid>describe an approach for translation from french to english, where context-free constituency reordering rules are acquired automatically using source and target parses and word alignment.</nextsent>
<nextsent>elming (2008) <papid> W08-0406 </papid>and elming and habash (2009) <papid> W09-0809 </papid>use large set of linguistic features to automatically learn reordering rules for english-danish and english-arabic; the rules are used to pre-order the input into lattice of variant orders.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4468">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the general approach pursued in this paper that of using pre-ordering to improve translation output?
</prevsent>
<prevsent>has been explored by many researchers.
</prevsent>
</prevsection>
<citsent citstr=" W08-0406 ">
most work has focused on automatically learning reordering rules (xia and mccord, 2004; <papid> C04-1073 </papid>habash, 2007b; elming, 2008; <papid> W08-0406 </papid>elming and habash, 2009; <papid> W09-0809 </papid>dyerand resnik, 2010).<papid> N10-1128 </papid></citsent>
<aftsection>
<nextsent>xia and mccord (2004) <papid> C04-1073 </papid>describe an approach for translation from french to english, where context-free constituency reordering rules are acquired automatically using source and target parses and word alignment.</nextsent>
<nextsent>elming (2008) <papid> W08-0406 </papid>and elming and habash (2009) <papid> W09-0809 </papid>use large set of linguistic features to automatically learn reordering rules for english-danish and english-arabic; the rules are used to pre-order the input into lattice of variant orders.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4469">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the general approach pursued in this paper that of using pre-ordering to improve translation output?
</prevsent>
<prevsent>has been explored by many researchers.
</prevsent>
</prevsection>
<citsent citstr=" W09-0809 ">
most work has focused on automatically learning reordering rules (xia and mccord, 2004; <papid> C04-1073 </papid>habash, 2007b; elming, 2008; <papid> W08-0406 </papid>elming and habash, 2009; <papid> W09-0809 </papid>dyerand resnik, 2010).<papid> N10-1128 </papid></citsent>
<aftsection>
<nextsent>xia and mccord (2004) <papid> C04-1073 </papid>describe an approach for translation from french to english, where context-free constituency reordering rules are acquired automatically using source and target parses and word alignment.</nextsent>
<nextsent>elming (2008) <papid> W08-0406 </papid>and elming and habash (2009) <papid> W09-0809 </papid>use large set of linguistic features to automatically learn reordering rules for english-danish and english-arabic; the rules are used to pre-order the input into lattice of variant orders.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4470">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the general approach pursued in this paper that of using pre-ordering to improve translation output?
</prevsent>
<prevsent>has been explored by many researchers.
</prevsent>
</prevsection>
<citsent citstr=" N10-1128 ">
most work has focused on automatically learning reordering rules (xia and mccord, 2004; <papid> C04-1073 </papid>habash, 2007b; elming, 2008; <papid> W08-0406 </papid>elming and habash, 2009; <papid> W09-0809 </papid>dyerand resnik, 2010).<papid> N10-1128 </papid></citsent>
<aftsection>
<nextsent>xia and mccord (2004) <papid> C04-1073 </papid>describe an approach for translation from french to english, where context-free constituency reordering rules are acquired automatically using source and target parses and word alignment.</nextsent>
<nextsent>elming (2008) <papid> W08-0406 </papid>and elming and habash (2009) <papid> W09-0809 </papid>use large set of linguistic features to automatically learn reordering rules for english-danish and english-arabic; the rules are used to pre-order the input into lattice of variant orders.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4475">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>dyer andres nik (2010) <papid> N10-1128 </papid>use an input forest structure to represent word-order alternatives and learn models forlong-range source reordering that maximize translation quality.</prevsent>
<prevsent>their results for arabic-english are negative.</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
in contrast to these approaches, collins et al (2005) <papid> P05-1066 </papid>apply six manually defined transformations to german parse trees which yield an improvement on german-english translation task.</citsent>
<aftsection>
<nextsent>in this paper, we follow collins et al (2005) <papid> P05-1066 </papid>and restrict ourselves to handcrafted rules (in our case, actually singleover-generating rule) motivated by linguistic under standing.</nextsent>
<nextsent>one major concern not addressed in any of the aforementioned research on syntax-based reordering is the fact that the quality of parsers for many languages is still quite poor.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4486">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>while the state-of-the-art in english parsing is fairly good (though far from perfect), this is not the case in other languages, where parsing shows substantial error rates.
</prevsent>
<prevsent>moreover, when attempting to reorder so as to bring the source text more grammatically in line with the target language, bad parse can be disastrous: moving parts of the sentence that shouldnt be moved, and introducing more distortion error than it is able to correct.
</prevsent>
</prevsection>
<citsent citstr=" P10-2033 ">
to address the problem of noisy parse data, bisazza and federico (2010) <papid> W10-1735 </papid>identify the subject using chunker,then fuzzify it, creating lattice in which the translation system has choice of several different paths, corresponding to re-orderings of different subject spans.in investigating syntax-based reordering for arabic specifically, carpuat et al (2010)<papid> P10-2033 </papid>show that syntax-driven reordering of the training data only for the purpose of alignment improvement leads to substantial improvement in translation quality, butdo not report corresponding improvement when reordering test data in similar fashion.</citsent>
<aftsection>
<nextsent>interestingly,bisazza and federico (2010) <papid> W10-1735 </papid>report that fuzzy reordering the test data improves mt output, suggesting that fuzzification may be the mechanism necessary to render reordering on test data useful.</nextsent>
<nextsent>to thebest of our knowledge, nobody has yet used fuzzification to correct the identified subject span of complete arabic dependency parses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4493">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>to thebest of our knowledge, nobody has yet used fuzzification to correct the identified subject span of complete arabic dependency parses.
</prevsent>
<prevsent>green et al (2009) use conditional random field sequence classifier to detect arabic noun phrase subjects in verb-initialclauses achieving an f-score of 61.3%.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
they integrate their classifiers decisions as additional features in the moses decoder (koehn et al, 2007), <papid> P07-2045 </papid>but do not show any gains.</citsent>
<aftsection>
<nextsent>the present work may be thought of as extending the fuzzification explored by bisazza and federico(2010) <papid> W10-1735 </papid>to the domain of full par singa combination, in some sense, of their approach with the work of carpuat et al (2010)<papid> P10-2033 </papid></nextsent>
<nextsent>the approach examined in this paper differs from collins et al (2005) <papid> P05-1066 </papid>in its use of fuzzification, from bisazza and federico (2010) <papid> W10-1735 </papid>in its use of complete dependency parse, and from carpuat et al (2010)<papid> P10-2033 </papid>in its use of reordered test set.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4509">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> motivation.  </section>
<citcontext>
<prevsection>
<prevsent>the baseline system produced bleu score of 47.13, forced reordering produced bleu score of 47.43, and optional reordering produced bleu score of 47.55.
</prevsent>
<prevsent>these results indicate that, given correct reordering boundaries, the translation quality can indeed be improved with reordered test data.
</prevsent>
</prevsection>
<citsent citstr=" P09-2056 ">
furthermore, the improvement noted above between the orced eordering and optional reordering experiments, while small, indicates that even with correct parses it is sometimes preferable to leave the input sentence un-reordered.this is consistent with carpuat et al (2010)<papid> P10-2033 </papid>s ob 1the gold parses for nist mt05 are part of the columbia arabic treeebank (catib) (habash and roth, 2009).<papid> P09-2056 </papid></citsent>
<aftsection>
<nextsent>229servation that even vs-ordered matrix verbs in arabic are sometimes translated monotonic ally into english (as, for example, in passive constructions).
</nextsent>
<nextsent>an alternative explanation may be that since the training data itself is not re-ordered, it is plausible that some re-ordering may cause otherwise good possible matches in the phrase table to not match any more.
</nextsent>
<nextsent>3.2 parser error.
</nextsent>
<nextsent>the problem of finding correct subject span boundaries for reordering, however, is particularly difficult one.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4514">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> approach.  </section>
<citcontext>
<prevsection>
<prevsent>fortunately, these pathological cases make up small enough portion of the dataset that they can be safely disregarded.
</prevsent>
<prevsent>more promisingly, 66.5% of incorrect spans can be corrected with the addition or removal of singleconstituent; in other words, the recall of span identification can be improved from 73.6% to 91.2% by adding or removing at most one constituent at the end of the parsers identified span.
</prevsent>
</prevsection>
<citsent citstr=" W10-1402 ">
to improve translation of matrix subjects, we implement fuzzy reordering by using lattice-based approach similar to bisazza and federico (2010) <papid> W10-1735 </papid>to correct the matrix subject spans identified by state of-the-art dependency parser (marton et al, 2010).<papid> W10-1402 </papid></citsent>
<aftsection>
<nextsent>specifically, we take twofold approach to fuzzy reordering.
</nextsent>
<nextsent>first, we present the translation system with both un-reordered and reordered options.
</nextsent>
<nextsent>this is motivated by the observation that on gold parses, optional reordering outperformed forced reordering(section 3.1).
</nextsent>
<nextsent>second, we apply fuzzification algorithm to the reordered subject span, adding yet more options to the lattice.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4521">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>training data was newswire (msa-english) parallel text with 12m words on the arabic side (ldc2007e103)5 sentences were reordered only for alignment, following the approach of carpuat et al (2010)<papid> P10-2033 </papid></prevsent>
<prevsent>parses were obtained using publicly available parser for arabic (marton et al, 2010).<papid> W10-1402 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
giza++ was used for word alignment (och and ney, 2003) <papid> J03-1002 </papid>and phrase translations of up to 10 words are extracted in the moses phrase table.</citsent>
<aftsection>
<nextsent>thesame baseline phrase table was used in all experiments.
</nextsent>
<nextsent>the systems language model was trained both onthe english portion of the training corpus and english gigaword (graff and cieri, 2003).
</nextsent>
<nextsent>we used 5all data is available from the linguistic data consortium: http://www.ldc.upenn.edu.
</nextsent>
<nextsent>5-gram language model with modified kneser-ney smoothing implemented using the srilm toolkit (stolcke, 2002).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4522">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we used 5all data is available from the linguistic data consortium: http://www.ldc.upenn.edu.
</prevsent>
<prevsent>5-gram language model with modified kneser-ney smoothing implemented using the srilm toolkit (stolcke, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
feature weights were tuned with mert (och, 2003) <papid> P03-1021 </papid>to maximize bleu on the nist mt06 corpus.</citsent>
<aftsection>
<nextsent>mert was done only for the baselinesystem; these same weights were used for all experiments to control for the effect of mert instability.in the future, we plan to experiment with approach specific optimization and to use recent published suggestions on controlling for optimizer instability (clark et al, 2011).<papid> P11-2031 </papid></nextsent>
<nextsent>english data was tokenized using simplepunctuation-based rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4523">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>5-gram language model with modified kneser-ney smoothing implemented using the srilm toolkit (stolcke, 2002).
</prevsent>
<prevsent>feature weights were tuned with mert (och, 2003) <papid> P03-1021 </papid>to maximize bleu on the nist mt06 corpus.</prevsent>
</prevsection>
<citsent citstr=" P11-2031 ">
mert was done only for the baselinesystem; these same weights were used for all experiments to control for the effect of mert instability.in the future, we plan to experiment with approach specific optimization and to use recent published suggestions on controlling for optimizer instability (clark et al, 2011).<papid> P11-2031 </papid></citsent>
<aftsection>
<nextsent>english data was tokenized using simplepunctuation-based rules.
</nextsent>
<nextsent>arabic data was segmented with to the arabic treebank tokenization scheme (maamouri et al, 2004) using the mada+tokan morphological disambiguator and tokenizer (habash and rambow, 2005; <papid> P05-1071 </papid>habash, 2007a; roth et al, 2008).<papid> P08-2030 </papid></nextsent>
<nextsent>the arabic text wasalso alif/ya normalized (habash, 2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4524">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>mert was done only for the baselinesystem; these same weights were used for all experiments to control for the effect of mert instability.in the future, we plan to experiment with approach specific optimization and to use recent published suggestions on controlling for optimizer instability (clark et al, 2011).<papid> P11-2031 </papid></prevsent>
<prevsent>english data was tokenized using simplepunctuation-based rules.</prevsent>
</prevsection>
<citsent citstr=" P05-1071 ">
arabic data was segmented with to the arabic treebank tokenization scheme (maamouri et al, 2004) using the mada+tokan morphological disambiguator and tokenizer (habash and rambow, 2005; <papid> P05-1071 </papid>habash, 2007a; roth et al, 2008).<papid> P08-2030 </papid></citsent>
<aftsection>
<nextsent>the arabic text wasalso alif/ya normalized (habash, 2010).
</nextsent>
<nextsent>mada produced arabic lemmas were used for word alignment.
</nextsent>
<nextsent>we compare four settings with predicted parses (as opposed to the gold parse experiments discussed in section 3): ? base an un-reordered test set; ? force test set which forced reordering on matrix verbs;?
</nextsent>
<nextsent>opt test set with fuzzification through optional reordering on matrix verbs; and?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4525">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>mert was done only for the baselinesystem; these same weights were used for all experiments to control for the effect of mert instability.in the future, we plan to experiment with approach specific optimization and to use recent published suggestions on controlling for optimizer instability (clark et al, 2011).<papid> P11-2031 </papid></prevsent>
<prevsent>english data was tokenized using simplepunctuation-based rules.</prevsent>
</prevsection>
<citsent citstr=" P08-2030 ">
arabic data was segmented with to the arabic treebank tokenization scheme (maamouri et al, 2004) using the mada+tokan morphological disambiguator and tokenizer (habash and rambow, 2005; <papid> P05-1071 </papid>habash, 2007a; roth et al, 2008).<papid> P08-2030 </papid></citsent>
<aftsection>
<nextsent>the arabic text wasalso alif/ya normalized (habash, 2010).
</nextsent>
<nextsent>mada produced arabic lemmas were used for word alignment.
</nextsent>
<nextsent>we compare four settings with predicted parses (as opposed to the gold parse experiments discussed in section 3): ? base an un-reordered test set; ? force test set which forced reordering on matrix verbs;?
</nextsent>
<nextsent>opt test set with fuzzification through optional reordering on matrix verbs; and?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4528">
<title id=" W11-2127.xml">fuzzy syntactic reordering for phrase based statistical machine translation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>columns three and four (prec-1g and prec-4g) indicate the corresponding 1-gram and 4-gram (sub-bleu) precision scores, respectively.
</prevsent>
<prevsent>232 system bleu prec-1g prec-4g meteor base 47.13 81.91 29.52 53.09 force 47.03 81.78 29.52 53.11 opt 47.42 81.88 30.04 53.22 span 47.41 81.92 30.03 53.21 table 2: automatic evaluation results both opt and span showed statistically significant improvement in bleu score over base and force above the 95% level.
</prevsent>
</prevsection>
<citsent citstr=" W04-3250 ">
statistical significance is computed using paired bootstrap resam pling (koehn, 2004).<papid> W04-3250 </papid></citsent>
<aftsection>
<nextsent>the difference between opt and span, however, was not statistically significant.the relatively small difference in bleu score between the baseline and gold reordering (section 3:baseline 47.13 and optional reordering 47.55) suggests that we should expect at most modest in crease in bleu from improving the predicted trees.
</nextsent>
<nextsent>the first key observation in these results is that with noisy parser, translation quality actually goes down with forced reordering the opposite of whatwas observed in the gold experiment.
</nextsent>
<nextsent>by introducing either optional reordering or complete fuzzifi cation, however, bleu score increases .3 past the baseline to achieve nearly three quarters of the gain obtained by optional reordering using the gold parse (section 3: baseline 47.13 and optional reordering 47.55).
</nextsent>
<nextsent>in other words, it is possible to compensate for the parser noisiness without actually attempting to correct spans: simply allowing the translation system to fall back on an un-reordered input leads to significant gain in bleu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4529">
<title id=" W12-1517.xml">sign language generation with expert systems and ccg </title>
<section> parsing and interpretation.  </section>
<citcontext>
<prevsection>
<prevsent>indicates an argument relation, i.e. an obligatory relation between the head and its argument.
</prevsent>
<prevsent>the edge label rmod?
</prevsent>
</prevsection>
<citsent citstr=" W04-1501 ">
indicates restricting modifier relation, i.e. non obligatory relation from the head and its dependent (bosco and lombardo, 2004).<papid> W04-1501 </papid></citsent>
<aftsection>
<nextsent>!! ##$%&amp; ()*+,-%.+/! #!!,.0# 1%2.+(1&amp;$ -%.+/! $ ! 3&amp;1 4&amp;/% #!!0 -5(3 $*&amp;/! &amp;!41&amp; -&amp;1(-5 +/% $!!0&amp; 2*1&amp; (3 $*&amp;/!   ()*+,-./,0 ()*+,-./, ()*+,*1 (-11,234,5-6 (234)7*.
</nextsent>
<nextsent>figure 2: the fragment of the semantic network resulting from the interpretation of the sentence valori di temper atura superiori alla media?.the second step of the translation is the semantic interpretation: the syntax-semantics interface is based on ontologies (lesmo et al, 2011).<papid> W11-0140 </papid></nextsent>
<nextsent>the knowledge in the ontology, which has been designed for this specific application, concerns the application domain, i.e. weather forecasts, as well as more general common knowledge about the world.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4530">
<title id=" W12-1517.xml">sign language generation with expert systems and ccg </title>
<section> parsing and interpretation.  </section>
<citcontext>
<prevsection>
<prevsent>indicates restricting modifier relation, i.e. non obligatory relation from the head and its dependent (bosco and lombardo, 2004).<papid> W04-1501 </papid></prevsent>
<prevsent>!! ##$%&amp; ()*+,-%.+/! #!!,.0# 1%2.+(1&amp;$ -%.+/! $ ! 3&amp;1 4&amp;/% #!!0 -5(3 $*&amp;/! &amp;!41&amp; -&amp;1(-5 +/% $!!0&amp; 2*1&amp; (3 $*&amp;/!   ()*+,-./,0 ()*+,-./, ()*+,*1 (-11,234,5-6 (234)7*.</prevsent>
</prevsection>
<citsent citstr=" W11-0140 ">
figure 2: the fragment of the semantic network resulting from the interpretation of the sentence valori di temper atura superiori alla media?.the second step of the translation is the semantic interpretation: the syntax-semantics interface is based on ontologies (lesmo et al, 2011).<papid> W11-0140 </papid></citsent>
<aftsection>
<nextsent>the knowledge in the ontology, which has been designed for this specific application, concerns the application domain, i.e. weather forecasts, as well as more general common knowledge about the world.
</nextsent>
<nextsent>note that the ontology used by the semantic interpreter is notthe same ontology used by the generator (microplanner and realizer): indeed, whilst the semantic interpreter ontology describes the linguistic knowledge of the italian language, the generator describes the linguistic knowledge of the lis.
</nextsent>
<nextsent>starting from the lexical semantics of the words and on the basis of the dependency structure, recursive function searches in the ontology providing number of connection paths?
</nextsent>
<nextsent>that represent the meaning.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4534">
<title id=" W12-0513.xml">a generalised hybrid architecture for nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, it is possible that the properties affecting the effectiveness of particular technique may vary within single document (de roeck, 2007).
</prevsent>
<prevsent>as result of this, for many important nlp applications there is no single technique which is clearly to be preferred.
</prevsent>
</prevsection>
<citsent citstr=" D09-1120 ">
for example, recent approaches to the task of anaphora resolution include syntactic analyses (haghighi and klein, 2009), <papid> D09-1120 </papid>maximum entropy models (charniak and elsner, 2009) <papid> E09-1018 </papid>and support vector machines (yanget al , 2006; <papid> P06-1006 </papid>versley et al , 2008).<papid> C08-1121 </papid></citsent>
<aftsection>
<nextsent>the performance of each of these techniques varies depending upon the particular choice of training and test data.this state of affairs provides particular opportunity for hybrid system development.
</nextsent>
<nextsent>the overall performance of an nlp system depend son complex interactions between the various phenomena exhibited by the text under analysis, and the success of given technique can be sensitive to the different properties of that text.
</nextsent>
<nextsent>in particular, the texts or documents properties are not generally known until the document comes to be analysed.
</nextsent>
<nextsent>therefore, there is need for systems which are able to adapt to different text styles atthe point of analysis, and select the most appropriate combination of techniques for the individual cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4535">
<title id=" W12-0513.xml">a generalised hybrid architecture for nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, it is possible that the properties affecting the effectiveness of particular technique may vary within single document (de roeck, 2007).
</prevsent>
<prevsent>as result of this, for many important nlp applications there is no single technique which is clearly to be preferred.
</prevsent>
</prevsection>
<citsent citstr=" E09-1018 ">
for example, recent approaches to the task of anaphora resolution include syntactic analyses (haghighi and klein, 2009), <papid> D09-1120 </papid>maximum entropy models (charniak and elsner, 2009) <papid> E09-1018 </papid>and support vector machines (yanget al , 2006; <papid> P06-1006 </papid>versley et al , 2008).<papid> C08-1121 </papid></citsent>
<aftsection>
<nextsent>the performance of each of these techniques varies depending upon the particular choice of training and test data.this state of affairs provides particular opportunity for hybrid system development.
</nextsent>
<nextsent>the overall performance of an nlp system depend son complex interactions between the various phenomena exhibited by the text under analysis, and the success of given technique can be sensitive to the different properties of that text.
</nextsent>
<nextsent>in particular, the texts or documents properties are not generally known until the document comes to be analysed.
</nextsent>
<nextsent>therefore, there is need for systems which are able to adapt to different text styles atthe point of analysis, and select the most appropriate combination of techniques for the individual cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4536">
<title id=" W12-0513.xml">a generalised hybrid architecture for nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, it is possible that the properties affecting the effectiveness of particular technique may vary within single document (de roeck, 2007).
</prevsent>
<prevsent>as result of this, for many important nlp applications there is no single technique which is clearly to be preferred.
</prevsent>
</prevsection>
<citsent citstr=" P06-1006 ">
for example, recent approaches to the task of anaphora resolution include syntactic analyses (haghighi and klein, 2009), <papid> D09-1120 </papid>maximum entropy models (charniak and elsner, 2009) <papid> E09-1018 </papid>and support vector machines (yanget al , 2006; <papid> P06-1006 </papid>versley et al , 2008).<papid> C08-1121 </papid></citsent>
<aftsection>
<nextsent>the performance of each of these techniques varies depending upon the particular choice of training and test data.this state of affairs provides particular opportunity for hybrid system development.
</nextsent>
<nextsent>the overall performance of an nlp system depend son complex interactions between the various phenomena exhibited by the text under analysis, and the success of given technique can be sensitive to the different properties of that text.
</nextsent>
<nextsent>in particular, the texts or documents properties are not generally known until the document comes to be analysed.
</nextsent>
<nextsent>therefore, there is need for systems which are able to adapt to different text styles atthe point of analysis, and select the most appropriate combination of techniques for the individual cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4537">
<title id=" W12-0513.xml">a generalised hybrid architecture for nlp </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>also, it is possible that the properties affecting the effectiveness of particular technique may vary within single document (de roeck, 2007).
</prevsent>
<prevsent>as result of this, for many important nlp applications there is no single technique which is clearly to be preferred.
</prevsent>
</prevsection>
<citsent citstr=" C08-1121 ">
for example, recent approaches to the task of anaphora resolution include syntactic analyses (haghighi and klein, 2009), <papid> D09-1120 </papid>maximum entropy models (charniak and elsner, 2009) <papid> E09-1018 </papid>and support vector machines (yanget al , 2006; <papid> P06-1006 </papid>versley et al , 2008).<papid> C08-1121 </papid></citsent>
<aftsection>
<nextsent>the performance of each of these techniques varies depending upon the particular choice of training and test data.this state of affairs provides particular opportunity for hybrid system development.
</nextsent>
<nextsent>the overall performance of an nlp system depend son complex interactions between the various phenomena exhibited by the text under analysis, and the success of given technique can be sensitive to the different properties of that text.
</nextsent>
<nextsent>in particular, the texts or documents properties are not generally known until the document comes to be analysed.
</nextsent>
<nextsent>therefore, there is need for systems which are able to adapt to different text styles atthe point of analysis, and select the most appropriate combination of techniques for the individual cases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4538">
<title id=" W12-0513.xml">a generalised hybrid architecture for nlp </title>
<section> case study: sentiment analysis.  </section>
<citcontext>
<prevsection>
<prevsent>because the individual heuristics are partial descriptions of the whole language model of the text, it is possible to reason about the interaction of these partial descriptions, and identify cases where either none, or many, of the potential interpretations of the text are possible.
</prevsent>
<prevsent>the systems use either machine learning technique or voting strategies to combine the individual heuristics.in sections 3 and 4, we explore how the previously proposed solutions can be classed as instances of the proposed hybrid isation model.
</prevsent>
</prevsection>
<citsent citstr=" W02-1011 ">
following pang et al  (2002) <papid> W02-1011 </papid>and the release of the polarity 2.0 dataset, it is common for sentiment analysis tasks to attempt to classify text segments as either of positive or negative sentiment.</citsent>
<aftsection>
<nextsent>the task has been extended to allow sentences to be annotated as displaying both positive and negative sentiment (wilson et al , 2009) <papid> J09-3003 </papid>or indicating the degree of intensity (thelwall et al , 2010).the dataset used for the 2011 i2b2 shared challenge (pestian et al , 2012) differs from this model by containing total of 15 different sentiments to classify the sentences.</nextsent>
<nextsent>each text fragment was labelled with zero, one or more of the 15 senti ments.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4539">
<title id=" W12-0513.xml">a generalised hybrid architecture for nlp </title>
<section> case study: sentiment analysis.  </section>
<citcontext>
<prevsection>
<prevsent>the systems use either machine learning technique or voting strategies to combine the individual heuristics.in sections 3 and 4, we explore how the previously proposed solutions can be classed as instances of the proposed hybrid isation model.
</prevsent>
<prevsent>following pang et al  (2002) <papid> W02-1011 </papid>and the release of the polarity 2.0 dataset, it is common for sentiment analysis tasks to attempt to classify text segments as either of positive or negative sentiment.</prevsent>
</prevsection>
<citsent citstr=" J09-3003 ">
the task has been extended to allow sentences to be annotated as displaying both positive and negative sentiment (wilson et al , 2009) <papid> J09-3003 </papid>or indicating the degree of intensity (thelwall et al , 2010).the dataset used for the 2011 i2b2 shared challenge (pestian et al , 2012) differs from this model by containing total of 15 different sentiments to classify the sentences.</citsent>
<aftsection>
<nextsent>each text fragment was labelled with zero, one or more of the 15 sentiments.
</nextsent>
<nextsent>for example, sentence (2) was annotated with both love and guilt.
</nextsent>
<nextsent>the fragments varied between phrases and full sentences, and the task aims to identify all the sentiments displayed by 98 each text fragment.
</nextsent>
<nextsent>in fact, several of the proposed sentiments were identified using keyword recognition alone, so the hybrid framework was applied only to recognise the sentiments thankful ness, love, guilt, hopelessness, information and instruction; instances of the other sentiments were too sparse to be reliably classified with the hybrid system.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4540">
<title id=" W12-0513.xml">a generalised hybrid architecture for nlp </title>
<section> nocuous ambiguity detection.  </section>
<citcontext>
<prevsection>
<prevsent>this is defined as nocu ous ambiguity (willis et al , 2008), in contrast to innocuous ambiguity, where the text is interpreted in the same way by different readers, even if that text supports different possible analyses.the phenomenon of nocuous ambiguity is particularly problematic in high stake situations.
</prevsent>
<prevsent>for example, in software engineering, failure to share common interpretation of requirements stated in natural language may lead to incorrect system implementation and the attendant risk of system failure, or higher maintenance costs.
</prevsent>
</prevsection>
<citsent citstr=" C10-1137 ">
the systems described by chantree et al  (2006) andyang et al  (2010<papid> C10-1137 </papid>a) aim not to resolve ambigu 100 individual heuristics hybrid models emotion crf nb me svm any majority combined thankful ness 59.5 59.6 61.9 60.3 63.9 63.0 64.2 love 63.7 69.3 66.5 61.5 72.0 70.3 71.0 guilt 35.3 40.5 27.7 37.8 46.3 29.9 45.8 hopelessness 63.2 64.1 59.9 57.0 67.3 65.4 67.3 information 42.3 47.7 43.7 43.4 50.2 45.5 47.8 instruction 65.7 65.7 63.4 58.8 72.1 65.4 72.0 table 2: f-scores (%) for individual and combined heuristics (sentiment analysis) any majority combined r p f r thankful ness 52.6 81.6 63.9 60.6 65.7 63.0 55.0 77.1 64.2 love 68.7 75.6 72.0 77.9 64.0 70.3 74.6 67.7 71.0 guilt 46.6 46.2 46.3 50.0 21.4 29.9 50.5 41.9 45.8 hopelessness 64.1 70.8 67.3 80.3 55.2 65.4 66.3 68.4 67.3 information 40.9 64.9 50.2 49.9 41.8 45.5 45.2 50.7 47.8 instruction 68.5 76.1 72.1 80.8 54.9 65.4 70.3 73.7 72.0 table 3: precision, recall and f-scores (%) for the combined systems (sentiment analysis)ous text in requirements, but to identify where instances of text might display nocuous ambiguity.</citsent>
<aftsection>
<nextsent>these systems demonstrate how, for hybrid systems, the correct choice of combination function is crucial to how the individual heuristics work together to optimise overall system performance.
</nextsent>
<nextsent>4.1 nocuous ambiguity: coordination.
</nextsent>
<nextsent>chantree et al  (2006) focus on coordination attachment ambiguity, which occurs when modifier can attach to one or more conjuncts of coordinated phrase.
</nextsent>
<nextsent>for example, in sentence(3), readers may divide over whether the modifier short attaches to both books and papers (wide scope), or only to books (narrow scope).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4546">
<title id=" W12-0513.xml">a generalised hybrid architecture for nlp </title>
<section> nocuous ambiguity detection.  </section>
<citcontext>
<prevsection>
<prevsent>4.1.2 selectional heuristicsa series of heuristics was developed, each capturing information that would lead to preference for either wide or narrow scope modifier attachment.
</prevsent>
<prevsent>examples from chantree et al  (2006) propose seven heuristics, including the following: co-ordination matching if the head wordsof the two conjuncts are frequently coordinated, this is taken to predict wide modifier scope.
</prevsent>
</prevsection>
<citsent citstr=" P99-1004 ">
distributional similarity if the headwords of the two conjuncts have high distributional similarity (lee, 1999), <papid> P99-1004 </papid>this is taken to predict wide modifier scope.</citsent>
<aftsection>
<nextsent>collocation frequency if the head word of the near conjunct has higher collocation with the modifier than the far conjunct, this is taken to predict narrow modifier scope.
</nextsent>
<nextsent>morphology if the conjunct headwords have similar morphological markers, this is taken to predict wide modifier scope (okumura and muraki, 1994).<papid> A94-1007 </papid></nextsent>
<nextsent>as with the sentiment recognition heuristics (section 3.2), each predicts one interpretation of the sentence with high precision, but potentially low recall.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4547">
<title id=" W12-0513.xml">a generalised hybrid architecture for nlp </title>
<section> nocuous ambiguity detection.  </section>
<citcontext>
<prevsection>
<prevsent>distributional similarity if the headwords of the two conjuncts have high distributional similarity (lee, 1999), <papid> P99-1004 </papid>this is taken to predict wide modifier scope.</prevsent>
<prevsent>collocation frequency if the head word of the near conjunct has higher collocation with the modifier than the far conjunct, this is taken to predict narrow modifier scope.</prevsent>
</prevsection>
<citsent citstr=" A94-1007 ">
morphology if the conjunct headwords have similar morphological markers, this is taken to predict wide modifier scope (okumura and muraki, 1994).<papid> A94-1007 </papid></citsent>
<aftsection>
<nextsent>as with the sentiment recognition heuristics (section 3.2), each predicts one interpretation of the sentence with high precision, but potentially low recall.
</nextsent>
<nextsent>recall of the system is improved by combining the heuristics, as described in the next section.
</nextsent>
<nextsent>note that for the first three of these heuristics, chantree et al  (2006) use the british national corpus4, accessed via the sketch engine(kilgarriff et al , 2004), although domain specific corpus could potentially be constructed.
</nextsent>
<nextsent>4.1.3 combining the heuristics chantree et al  (2006) combine the heuristics using the logistic regression algorithms contained in the weka machine learning package (witten and frank, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4578">
<title id=" W11-2604.xml">syntactic transformations for swiss german dialects </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper explore show dialect syntax fieldwork can guide the development of multidialectal natural language processing tools.
</prevsent>
<prevsent>our goal is to transform standard german sentence structures so that they become syntactically valid in swiss german dialects.11here, we do not take into account the phonetic, morphological and lexical changes involved in generating the actual swiss german word forms.
</prevsent>
</prevsection>
<citsent citstr=" D10-1112 ">
for such model, see for example scherrer and rambow (2010<papid> D10-1112 </papid>a).</citsent>
<aftsection>
<nextsent>these transformations are accomplished by set of hand-crafted rules, developed and evaluated on the basis of the dependency version of the standard german tiger treebank.
</nextsent>
<nextsent>ultimately, the rule set can be used either as tool for treebank transduction(i.e. deriving swiss german treebanks from standard german ones), or as the syntactic transfer module of transfer-based machine translation system.
</nextsent>
<nextsent>after the discussion of related work (section 2), we present the major syntactic differences between standard german and swiss german dialects (sec tion 3).
</nextsent>
<nextsent>we then show how these differences canbe covered by set of transformation rules that apply to syntactically annotated standard german text, such as found in treebanks (section 4).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4579">
<title id=" W11-2604.xml">syntactic transformations for swiss german dialects </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>we agree with this point of view: we devise transformation rules that relate swiss german dialects to standard german.
</prevsent>
<prevsent>in the case of closely related languages,2 different 2in any case, it is difficult to establish strict linguistic criteria 30 types of annotation projection have been proposed to facilitate the creation of treebanks.
</prevsent>
</prevsection>
<citsent citstr=" W04-1910 ">
see volk and samuelsson (2004) <papid> W04-1910 </papid>for an overview of the problem.</citsent>
<aftsection>
<nextsent>in rather different approach, vaillant (2008) presents hand-crafted multi-dialect grammar that conceives of dialect as some kind of agreement feature?.
</nextsent>
<nextsent>this allows to share identical rules across dialects and differentiate them only where necessary.
</nextsent>
<nextsent>we follow similar approach by linking the transformation rules to geographical data from recent dialectological fieldwork.another line of research is oriented towards machine translation models for closely related languages.
</nextsent>
<nextsent>it is common in this field that minor syntactic differences are dealt with explicitly.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4580">
<title id=" W11-2604.xml">syntactic transformations for swiss german dialects </title>
<section> transformation rules.  </section>
<citcontext>
<prevsection>
<prevsent>the transformation rules require morpho syntactically annotated standard german input data.
</prevsent>
<prevsent>therefore, we had to choose specific annotation format and specific corpus to test the rules on.
</prevsent>
</prevsection>
<citsent citstr=" W06-2920 ">
we selected the standard german tiger treebank (brants et al ., 2002), in the conll-style dependency format (buchholz and marsi, 2006; <papid> W06-2920 </papid>kubler, 2008).8 this format allows compact representation of the syntactic structure.</citsent>
<aftsection>
<nextsent>figure 2 shows sample sentence, annotated in this format.while we use the tiger corpus for test and evaluation purposes in this paper, the rules are aimed to be sufficiently generic so that they apply correctly to any other corpus annotated according to the same guidelines.
</nextsent>
<nextsent>4.2 rule implementation.
</nextsent>
<nextsent>we have manually created transformation rules for dozen of syntactic and morphosyntactic phenomena.
</nextsent>
<nextsent>these rules (i) detect specific syntactic pattern in sentence and (ii) modify the position, content and/or dependency link of the nodes in that pattern.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4582">
<title id=" W11-2030.xml">an annotation scheme for cross cultural argumentation and persuasion dialogues </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>our specific focus is on the role of argumentation and per 272suasion.
</prevsent>
<prevsent>sycara (1990) studied the role of argumentation in negotiation with regard to the role of arguments in changing the decision process of the interlocutor.
</prevsent>
</prevsection>
<citsent citstr=" J87-1002 ">
most attempts have focused on studying the structure of argumentation and persuasion, often using formal logic (cohen, 1987; <papid> J87-1002 </papid>prakken, 2008).</citsent>
<aftsection>
<nextsent>dung (1995) showed that argumentation can be viewed as special form of logic programming with negation as failure.
</nextsent>
<nextsent>an argumentation scheme is defined as structure or template for forming an argument.
</nextsent>
<nextsent>schemes are necessary for identifying arguments, finding missing premises, analyzing arguments, and evaluating arguments (pollock, 1995; katzav and reed, 2004; walton et al, 2008).recently, there has been some work on using machine learning techniques for automatically interpreting (george et al, 2007) and generating arguments (zukerman, 2001).
</nextsent>
<nextsent>note also the work of piwek (2008) who performed study on how arguments can be presented as fictive dialogues.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4583">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>automatic identification of co referring entities and events in text has been an uphill battle for several decades, partly because it can require world knowledge which is not well-defined and partly owing to the lack of substantial annotated data.
</prevsent>
<prevsent>early work on corpus-based coreference resolution dates back to the mid-90s by mccarthy and lenhert (1995) where they experimented with using decision trees and hand-written rules.
</prevsent>
</prevsection>
<citsent citstr=" J01-4004 ">
a systematic study was then conducted using decision trees by soon et al (2001).<papid> J01-4004 </papid></citsent>
<aftsection>
<nextsent>significant improvements have been made in the field of language processing in general, and improved learning techniques have been developed to push the state of the art in coreference resolution forward (morton, 2000; <papid> P00-1023 </papid>harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; culotta et al, 2007; <papid> N07-1011 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>rahman and ng, 2009;haghighi and klein, 2010).<papid> N10-1061 </papid></nextsent>
<nextsent>various different knowledge sources from shallow semantics to encyclopedic knowledge are being exploited (ponzetto and strube, 2005; ponzetto and strube, 2006; <papid> N06-1025 </papid>versley, 2007; <papid> D07-1052 </papid>ng, 2007).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4584">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>early work on corpus-based coreference resolution dates back to the mid-90s by mccarthy and lenhert (1995) where they experimented with using decision trees and hand-written rules.
</prevsent>
<prevsent>a systematic study was then conducted using decision trees by soon et al (2001).<papid> J01-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" P00-1023 ">
significant improvements have been made in the field of language processing in general, and improved learning techniques have been developed to push the state of the art in coreference resolution forward (morton, 2000; <papid> P00-1023 </papid>harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; culotta et al, 2007; <papid> N07-1011 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>rahman and ng, 2009;haghighi and klein, 2010).<papid> N10-1061 </papid></citsent>
<aftsection>
<nextsent>various different knowledge sources from shallow semantics to encyclopedic knowledge are being exploited (ponzetto and strube, 2005; ponzetto and strube, 2006; <papid> N06-1025 </papid>versley, 2007; <papid> D07-1052 </papid>ng, 2007).</nextsent>
<nextsent>researchers continued finding novel ways of exploiting ontologies such as word net.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4585">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>early work on corpus-based coreference resolution dates back to the mid-90s by mccarthy and lenhert (1995) where they experimented with using decision trees and hand-written rules.
</prevsent>
<prevsent>a systematic study was then conducted using decision trees by soon et al (2001).<papid> J01-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" N01-1008 ">
significant improvements have been made in the field of language processing in general, and improved learning techniques have been developed to push the state of the art in coreference resolution forward (morton, 2000; <papid> P00-1023 </papid>harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; culotta et al, 2007; <papid> N07-1011 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>rahman and ng, 2009;haghighi and klein, 2010).<papid> N10-1061 </papid></citsent>
<aftsection>
<nextsent>various different knowledge sources from shallow semantics to encyclopedic knowledge are being exploited (ponzetto and strube, 2005; ponzetto and strube, 2006; <papid> N06-1025 </papid>versley, 2007; <papid> D07-1052 </papid>ng, 2007).</nextsent>
<nextsent>researchers continued finding novel ways of exploiting ontologies such as word net.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4586">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>early work on corpus-based coreference resolution dates back to the mid-90s by mccarthy and lenhert (1995) where they experimented with using decision trees and hand-written rules.
</prevsent>
<prevsent>a systematic study was then conducted using decision trees by soon et al (2001).<papid> J01-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1011 ">
significant improvements have been made in the field of language processing in general, and improved learning techniques have been developed to push the state of the art in coreference resolution forward (morton, 2000; <papid> P00-1023 </papid>harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; culotta et al, 2007; <papid> N07-1011 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>rahman and ng, 2009;haghighi and klein, 2010).<papid> N10-1061 </papid></citsent>
<aftsection>
<nextsent>various different knowledge sources from shallow semantics to encyclopedic knowledge are being exploited (ponzetto and strube, 2005; ponzetto and strube, 2006; <papid> N06-1025 </papid>versley, 2007; <papid> D07-1052 </papid>ng, 2007).</nextsent>
<nextsent>researchers continued finding novel ways of exploiting ontologies such as word net.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4587">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>early work on corpus-based coreference resolution dates back to the mid-90s by mccarthy and lenhert (1995) where they experimented with using decision trees and hand-written rules.
</prevsent>
<prevsent>a systematic study was then conducted using decision trees by soon et al (2001).<papid> J01-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" N07-1030 ">
significant improvements have been made in the field of language processing in general, and improved learning techniques have been developed to push the state of the art in coreference resolution forward (morton, 2000; <papid> P00-1023 </papid>harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; culotta et al, 2007; <papid> N07-1011 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>rahman and ng, 2009;haghighi and klein, 2010).<papid> N10-1061 </papid></citsent>
<aftsection>
<nextsent>various different knowledge sources from shallow semantics to encyclopedic knowledge are being exploited (ponzetto and strube, 2005; ponzetto and strube, 2006; <papid> N06-1025 </papid>versley, 2007; <papid> D07-1052 </papid>ng, 2007).</nextsent>
<nextsent>researchers continued finding novel ways of exploiting ontologies such as word net.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4588">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>early work on corpus-based coreference resolution dates back to the mid-90s by mccarthy and lenhert (1995) where they experimented with using decision trees and hand-written rules.
</prevsent>
<prevsent>a systematic study was then conducted using decision trees by soon et al (2001).<papid> J01-4004 </papid></prevsent>
</prevsection>
<citsent citstr=" N10-1061 ">
significant improvements have been made in the field of language processing in general, and improved learning techniques have been developed to push the state of the art in coreference resolution forward (morton, 2000; <papid> P00-1023 </papid>harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; culotta et al, 2007; <papid> N07-1011 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>rahman and ng, 2009;haghighi and klein, 2010).<papid> N10-1061 </papid></citsent>
<aftsection>
<nextsent>various different knowledge sources from shallow semantics to encyclopedic knowledge are being exploited (ponzetto and strube, 2005; ponzetto and strube, 2006; <papid> N06-1025 </papid>versley, 2007; <papid> D07-1052 </papid>ng, 2007).</nextsent>
<nextsent>researchers continued finding novel ways of exploiting ontologies such as word net.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4589">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a systematic study was then conducted using decision trees by soon et al (2001).<papid> J01-4004 </papid></prevsent>
<prevsent>significant improvements have been made in the field of language processing in general, and improved learning techniques have been developed to push the state of the art in coreference resolution forward (morton, 2000; <papid> P00-1023 </papid>harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; culotta et al, 2007; <papid> N07-1011 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>rahman and ng, 2009;haghighi and klein, 2010).<papid> N10-1061 </papid></prevsent>
</prevsection>
<citsent citstr=" N06-1025 ">
various different knowledge sources from shallow semantics to encyclopedic knowledge are being exploited (ponzetto and strube, 2005; ponzetto and strube, 2006; <papid> N06-1025 </papid>versley, 2007; <papid> D07-1052 </papid>ng, 2007).</citsent>
<aftsection>
<nextsent>researchers continued finding novel ways of exploiting ontologies such as wordnet.
</nextsent>
<nextsent>given that wordnet is static ontology and as such has limitation on coverage, more recently,there have been successful attempts to utilize information from much larger, collaboratively built resources such as wikipedia (ponzetto and strube, 2006).<papid> N06-1025 </papid></nextsent>
<nextsent>inspite of all the progress, current techniques still rely primarily on surface level features such as string match, proximity, and edit distance; syntactic features such as apposition; and shallow semantic features such as number, gender, named entities, semantic class, hobbs?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4590">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a systematic study was then conducted using decision trees by soon et al (2001).<papid> J01-4004 </papid></prevsent>
<prevsent>significant improvements have been made in the field of language processing in general, and improved learning techniques have been developed to push the state of the art in coreference resolution forward (morton, 2000; <papid> P00-1023 </papid>harabagiu et al, 2001; <papid> N01-1008 </papid>mccallum and wellner, 2004; culotta et al, 2007; <papid> N07-1011 </papid>denis and baldridge, 2007; <papid> N07-1030 </papid>rahman and ng, 2009;haghighi and klein, 2010).<papid> N10-1061 </papid></prevsent>
</prevsection>
<citsent citstr=" D07-1052 ">
various different knowledge sources from shallow semantics to encyclopedic knowledge are being exploited (ponzetto and strube, 2005; ponzetto and strube, 2006; <papid> N06-1025 </papid>versley, 2007; <papid> D07-1052 </papid>ng, 2007).</citsent>
<aftsection>
<nextsent>researchers continued finding novel ways of exploiting ontologies such as wordnet.
</nextsent>
<nextsent>given that wordnet is static ontology and as such has limitation on coverage, more recently,there have been successful attempts to utilize information from much larger, collaboratively built resources such as wikipedia (ponzetto and strube, 2006).<papid> N06-1025 </papid></nextsent>
<nextsent>inspite of all the progress, current techniques still rely primarily on surface level features such as string match, proximity, and edit distance; syntactic features such as apposition; and shallow semantic features such as number, gender, named entities, semantic class, hobbs?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4592">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given that wordnet is static ontology and as such has limitation on coverage, more recently,there have been successful attempts to utilize information from much larger, collaboratively built resources such as wikipedia (ponzetto and strube, 2006).<papid> N06-1025 </papid></prevsent>
<prevsent>inspite of all the progress, current techniques still rely primarily on surface level features such as string match, proximity, and edit distance; syntactic features such as apposition; and shallow semantic features such as number, gender, named entities, semantic class, hobbs?</prevsent>
</prevsection>
<citsent citstr=" P10-1142 ">
distance, etc. better ideaof the progress in the field can be obtained by reading recent survey articles (ng, 2010) <papid> P10-1142 </papid>and tutorials(ponzetto and poesio, 2009) <papid> P09-5006 </papid>dedicated to this sub ject.</citsent>
<aftsection>
<nextsent>corpora to support supervised learning of this task date back to the message understanding conferences (muc).
</nextsent>
<nextsent>these corpora were tagged with co referring entities identified by noun phrases in thetext.
</nextsent>
<nextsent>the de facto standard datasets for current coreference studies are the muc (hirschman and chin 1chor, 1997; chinchor, 2001; chinchor and sundheim, 2003) and the ace1 (g. doddington et al, 2000) corpora.
</nextsent>
<nextsent>the muc corpora cover all noun phrases in text, but represent small training and test sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4593">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>given that wordnet is static ontology and as such has limitation on coverage, more recently,there have been successful attempts to utilize information from much larger, collaboratively built resources such as wikipedia (ponzetto and strube, 2006).<papid> N06-1025 </papid></prevsent>
<prevsent>inspite of all the progress, current techniques still rely primarily on surface level features such as string match, proximity, and edit distance; syntactic features such as apposition; and shallow semantic features such as number, gender, named entities, semantic class, hobbs?</prevsent>
</prevsection>
<citsent citstr=" P09-5006 ">
distance, etc. better ideaof the progress in the field can be obtained by reading recent survey articles (ng, 2010) <papid> P10-1142 </papid>and tutorials(ponzetto and poesio, 2009) <papid> P09-5006 </papid>dedicated to this sub ject.</citsent>
<aftsection>
<nextsent>corpora to support supervised learning of this task date back to the message understanding conferences (muc).
</nextsent>
<nextsent>these corpora were tagged with co referring entities identified by noun phrases in thetext.
</nextsent>
<nextsent>the de facto standard datasets for current coreference studies are the muc (hirschman and chin 1chor, 1997; chinchor, 2001; chinchor and sundheim, 2003) and the ace1 (g. doddington et al, 2000) corpora.
</nextsent>
<nextsent>the muc corpora cover all noun phrases in text, but represent small training and test sets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4594">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are also less consistent, in terms of inter-annotator agreement (ita) (hirschman et al,1998).
</prevsent>
<prevsent>this lessens the reliability of statistical evidence in the form of lexical coverage and semantic relatedness that could be derived from the dataand used by classifier to generate better predictive models.
</prevsent>
</prevsection>
<citsent citstr=" W04-2327 ">
the importance of well-defined tagging scheme and consistent ita has been well recognized and studied in the past (poesio, 2004; <papid> W04-2327 </papid>poe sio and artstein, 2005; <papid> W05-0311 </papid>passonneau, 2004).</citsent>
<aftsection>
<nextsent>there is growing consensus that in order for these to be most useful for language understanding applications such as question answering or distillation ? both of which seek to take information access technology to the next level ? we need more consistent annotation of larger amounts of broad coverage data for training better automatic techniques for entity and event identification.
</nextsent>
<nextsent>identification and encoding of richer knowledge ? possibly linked to knowledge sources ? and development of learning algorithms that would effectively incorporate them is necessary next step towards improving the current state of the art.
</nextsent>
<nextsent>the computational learning community,in general, is also witnessing move towards evaluations based on joint inference, with the two previous conll tasks (surdeanu et al, 2008; <papid> W08-2121 </papid>hajic?</nextsent>
<nextsent>et al., 2009) devoted to joint learning of syntactic and semantic dependencies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4595">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they are also less consistent, in terms of inter-annotator agreement (ita) (hirschman et al,1998).
</prevsent>
<prevsent>this lessens the reliability of statistical evidence in the form of lexical coverage and semantic relatedness that could be derived from the dataand used by classifier to generate better predictive models.
</prevsent>
</prevsection>
<citsent citstr=" W05-0311 ">
the importance of well-defined tagging scheme and consistent ita has been well recognized and studied in the past (poesio, 2004; <papid> W04-2327 </papid>poe sio and artstein, 2005; <papid> W05-0311 </papid>passonneau, 2004).</citsent>
<aftsection>
<nextsent>there is growing consensus that in order for these to be most useful for language understanding applications such as question answering or distillation ? both of which seek to take information access technology to the next level ? we need more consistent annotation of larger amounts of broad coverage data for training better automatic techniques for entity and event identification.
</nextsent>
<nextsent>identification and encoding of richer knowledge ? possibly linked to knowledge sources ? and development of learning algorithms that would effectively incorporate them is necessary next step towards improving the current state of the art.
</nextsent>
<nextsent>the computational learning community,in general, is also witnessing move towards evaluations based on joint inference, with the two previous conll tasks (surdeanu et al, 2008; <papid> W08-2121 </papid>hajic?</nextsent>
<nextsent>et al., 2009) devoted to joint learning of syntactic and semantic dependencies.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4596">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>there is growing consensus that in order for these to be most useful for language understanding applications such as question answering or distillation ? both of which seek to take information access technology to the next level ? we need more consistent annotation of larger amounts of broad coverage data for training better automatic techniques for entity and event identification.
</prevsent>
<prevsent>identification and encoding of richer knowledge ? possibly linked to knowledge sources ? and development of learning algorithms that would effectively incorporate them is necessary next step towards improving the current state of the art.
</prevsent>
</prevsection>
<citsent citstr=" W08-2121 ">
the computational learning community,in general, is also witnessing move towards evaluations based on joint inference, with the two previous conll tasks (surdeanu et al, 2008; <papid> W08-2121 </papid>hajic?</citsent>
<aftsection>
<nextsent>et al., 2009) devoted to joint learning of syntactic and semantic dependencies.
</nextsent>
<nextsent>a principle ingredient for joint learning is the presence of multiple layers of semantic information.
</nextsent>
<nextsent>one fundamental question still remains, and that is ? what would it take to improve the state of the art in coreference resolution that has not been attempted so far?
</nextsent>
<nextsent>many different algorithms have been tried in the past 15 years, but one thing that is still lacking is corpus comprehensively tagged on large scale with consistent, multiple layers of semantic information.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4597">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one fundamental question still remains, and that is ? what would it take to improve the state of the art in coreference resolution that has not been attempted so far?
</prevsent>
<prevsent>many different algorithms have been tried in the past 15 years, but one thing that is still lacking is corpus comprehensively tagged on large scale with consistent, multiple layers of semantic information.
</prevsent>
</prevsection>
<citsent citstr=" N06-2015 ">
one of the many goals of the ontonotes project2 (hovy et al, 2006; <papid> N06-2015 </papid>weischedel et al, 2011) is to explore whether it can fill this void and help push the progress further ? not only in coreference, but with the various layers of semantics that it tries to capture.</citsent>
<aftsection>
<nextsent>as one of its layers, it has created acorpus for general anaphoric coreference that cov 1http://projects.ldc.upenn.edu/ace/data/ 2http://www.bbn.com/nlp/ontonotes ers entities and events not limited to noun phrases or limited set of entity types.
</nextsent>
<nextsent>a small portion of this corpus from the newswire and broadcast news genres (120k) was recently used for semeval task (recasens et al, 2010).<papid> S10-1001 </papid></nextsent>
<nextsent>as mentioned earlier, the coreference layer in ontonotes constitutes just one part of multi-layered, integrated annotation of shallow semantic structure in text with high inter annotator agreement, which also provides unique opportunity for performing joint inference over substantial body of data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4598">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>one of the many goals of the ontonotes project2 (hovy et al, 2006; <papid> N06-2015 </papid>weischedel et al, 2011) is to explore whether it can fill this void and help push the progress further ? not only in coreference, but with the various layers of semantics that it tries to capture.</prevsent>
<prevsent>as one of its layers, it has created acorpus for general anaphoric coreference that cov 1http://projects.ldc.upenn.edu/ace/data/ 2http://www.bbn.com/nlp/ontonotes ers entities and events not limited to noun phrases or limited set of entity types.</prevsent>
</prevsection>
<citsent citstr=" S10-1001 ">
a small portion of this corpus from the newswire and broadcast news genres (120k) was recently used for semeval task (recasens et al, 2010).<papid> S10-1001 </papid></citsent>
<aftsection>
<nextsent>as mentioned earlier, the coreference layer in ontonotes constitutes just one part of multi-layered, integrated annotation of shallow semantic structure in text with high inter annotator agreement, which also provides unique opportunity for performing joint inference over substantial body of data.
</nextsent>
<nextsent>the remainder of this paper is organized as follows.
</nextsent>
<nextsent>section 2 presents an overview of the ontonotes corpus.
</nextsent>
<nextsent>section 3 describes the coreference annotation in ontonotes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4599">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> the ontonotes corpus.  </section>
<citcontext>
<prevsection>
<prevsent>there is core portion, however, which is roughly 2 1.3m words which has been annotated with all the layers.
</prevsent>
<prevsent>it comprises 450k words from newswire,150k from magazine articles, 200k from broadcast news, 200k from broadcast conversations and 200k web data.ontonotes comprises the following layers of an notation:?
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
syntax ? syntactic layer representing revised penn treebank (marcus et al, 1993; <papid> J93-2004 </papid>babko-malaya et al, 2006).</citsent>
<aftsection>
<nextsent>propositions ? the proposition structure of verbs in the form of revised propbank(palmer et al, 2005; <papid> J05-1004 </papid>babko-malaya et al, 2006).</nextsent>
<nextsent>word sense ? coarse grained word senses are tagged for the most frequent polysemousverbs and nouns, in order to maximize cov erage.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4600">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> the ontonotes corpus.  </section>
<citcontext>
<prevsection>
<prevsent>it comprises 450k words from newswire,150k from magazine articles, 200k from broadcast news, 200k from broadcast conversations and 200k web data.ontonotes comprises the following layers of an notation:?
</prevsent>
<prevsent>syntax ? syntactic layer representing revised penn treebank (marcus et al, 1993; <papid> J93-2004 </papid>babko-malaya et al, 2006).</prevsent>
</prevsection>
<citsent citstr=" J05-1004 ">
propositions ? the proposition structure of verbs in the form of revised propbank(palmer et al, 2005; <papid> J05-1004 </papid>babko-malaya et al, 2006).</citsent>
<aftsection>
<nextsent>word sense ? coarse grained word senses are tagged for the most frequent polysemousverbs and nouns, in order to maximize coverage.
</nextsent>
<nextsent>the word sense granularity is tailored to achieve 90% inter-annotator agreement as demonstrated by palmer et al (2007).
</nextsent>
<nextsent>these senses are defined in the sense inventory files and each individual sense has been connected to multiple wordnet senses.
</nextsent>
<nextsent>this provides adirect access to the wordnet semantic structure for users to make use of.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4603">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> conll-2011 coreference task.  </section>
<citcontext>
<prevsection>
<prevsent>looking at various numbers reported in literature can greatly affect the perceived difficulty of the task.
</prevsent>
<prevsent>it can seem to be very hard problem (soon et al, 2001) <papid> J01-4004 </papid>or one that is somewhat easier (culotta et al, 2007).<papid> N07-1011 </papid></prevsent>
</prevsection>
<citsent citstr=" P09-1074 ">
given the space constraints, we refer the reader to stoyanov et al (2009) <papid> P09-1074 </papid>for detailed treatment of the issue.</citsent>
<aftsection>
<nextsent>limitations in the size and scope of the available datasets have also constrained research progress.
</nextsent>
<nextsent>the muc and ace corpora are the two that have been used most for reporting comparative results,but they differ in the types of entities and coreference annotated.
</nextsent>
<nextsent>the ace corpus is also one that evolved over period of almost five years, with different incarnations of the task definition and different corpus cross-sections on which performance numbers have been reported, making it hard to untangle and interpret the results.
</nextsent>
<nextsent>the availability of the ontonotes data offered an opportunity to define coreference task based on larger, more broad-coverage corpus.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4604">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> conll-2011 coreference task.  </section>
<citcontext>
<prevsection>
<prevsent>as is customary for conll tasks, there were two tracks, closed and open.
</prevsent>
<prevsent>for the closed track, systems were limited to using the distributed resources,in order to allow fair comparison of algorithm performance, while the open track allowed for almost unrestricted use of external resources in addition to the provided data.
</prevsent>
</prevsection>
<citsent citstr=" P06-1005 ">
4.2.1 closed trackin the closed track, systems were limited to the provided data, plus the use of two pre-specified externalresources: i) wordnet and ii) pre-computed number and gender table by bergsma and lin (2006).<papid> P06-1005 </papid></citsent>
<aftsection>
<nextsent>for the training and test data, in addition to the underlying text, predicted versions of all the supplementary layers of annotation were provided, where those predictions were derived using off-the-shelf tools (parsers, semantic role label ers, named entity taggers, etc.) as described in section 4.4.2.
</nextsent>
<nextsent>for the training data, however, in addition to predicted values for the other layers, we also provided manualgold-standard annotations for all the layers.
</nextsent>
<nextsent>participants were allowed to use either the gold-standard or predicted annotation for training their systems.
</nextsent>
<nextsent>they were also free to use the gold-standard data to train their own models for the various layers of annotation, if they judged that those would either provide more accurate predictions or alternative predictions for use as multiple views, or wished to use lattice of predictions.more so than previous conll tasks, coreference predictions depend on world knowledge, and many state-of-the-art systems use information from external resources such as wordnet, which canadd layer that helps the system to recognize semantic connections between the various lexicalized mentions in the text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4606">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> conll-2011 coreference task.  </section>
<citcontext>
<prevsection>
<prevsent>recent enhancements to the propbank to make it synchronize better with the tree bank (babko-malaya et al, 2006) have enhanced the information in the proposition by the addition oftwo types of links that represent pragmatic coreference (link-pcr) and selectional preferences (link slc).
</prevsent>
<prevsent>more details can be found in the addendum tothe propbank guidelines9 in the ontonotes 4.0 re7there is another phrase type ? embed in the telephone conversation genre which is similar to the edited phrase type, and sometimes identifies insertions, but sometimes contains logical continuation of phrases, so we decided not to remove that from the data.
</prevsent>
</prevsection>
<citsent citstr=" N01-1016 ">
8a study by charniak and johnson (2001) <papid> N01-1016 </papid>shows that one can identify and remove edits from transcribed conversational speech with an f-score of about 78, with roughly 95 precision and 67 recall.</citsent>
<aftsection>
<nextsent>9doc/propbank/english-propbank.pdf 9lease.
</nextsent>
<nextsent>since the community is not used to this representation which relies heavily on the trace structure in the treebank which we are excluding, we decided to unfold the links back to their original representation as in the release 1.0 of the proposition bank.
</nextsent>
<nextsent>this functionality is part of the ontonotes db tool.10 word sense gold word sense annotation was supplied using sense numbers as specified in the ontonotes list of senses for each lemma.11 the sense inventories that were provided in the ontonotes 4.0 release were not all mapped to the latest version 3.0 of wordnet, so we provided revised version of the sense inventories, containing mapping to wordnet 3.0, on the task page for the participants.
</nextsent>
<nextsent>named entities named entities in ontonotes data are specified using catalog of 18 name types.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4607">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> conll-2011 coreference task.  </section>
<citcontext>
<prevsection>
<prevsent>for training 10http://cemantix.org/ontonotes.html 11it should be noted that word sense annotation in ontonotes is note complete, so only some of the verbs and nouns have word sense tags specified.
</prevsent>
<prevsent>senses lemmas 1 1,506 2 1,046   2 1,016table 6: word sense polysemy over verb and noun lem mas in ontonotes models for each of the layers, where feasible, we used all the data that we could for that layer from the training portion of the entire ontonotes release.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
parse trees predicted parse trees were produced using the charniak parser (charniak and johnson, 2005).<papid> P05-1022 </papid>12 some additional tag types used in the ontonotes trees were added to the parsers tagset, including the nml tag that has recently been added to capture internal np structure, and the rules used to determine headwords were appropriately extended.the parser was then re-trained on the training portion of the release 4.0 data using 10-fold cross validation.</citsent>
<aftsection>
<nextsent>table 5 shows the performance of the re-trained charniak parser on the conll-2011 test set.
</nextsent>
<nextsent>we did not get chance to re-train the re-ranker,and since the stock re-ranker crashes when run on best parses containing nmls, because it has not seen that tag in training, we could not make use of it.word sense we trained word sense tagger using svm classifier and contextual word and part of speech features on all the training portion of the ontonotes data.
</nextsent>
<nextsent>the ontonotes 4.0 corpus comprises total of 14,662 sense definitions across 4877 verb and noun lemmas13.
</nextsent>
<nextsent>the distribution of senses per lemma is as shown in table 6.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4609">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> conll-2011 coreference task.  </section>
<citcontext>
<prevsection>
<prevsent>this choice means that scores for the conll-2011 coreference task are likely to be lower than for coref evaluations based on muc, where the mention spans are specified in the input,17 or those based on ace data, where an approximate match is often allowed based on the specified head of the np mention.
</prevsent>
<prevsent>4.5.1 metric sas noted above, the choice of an evaluation metric for coreference has been tricky issue and there does not appear to be any silver bullet approach that addresses all the concerns.
</prevsent>
</prevsection>
<citsent citstr=" M95-1005 ">
three metrics have been proposed for evaluating coreference performance over an unrestricted set of entity types: i) the link based muc metric (vilain et al, 1995), <papid> M95-1005 </papid>ii) the mention based b-cubed metric (bagga and baldwin, 1998) and iii) the entity based ceaf (constrained entity aligned f-measure) metric (luo, 2005).<papid> H05-1004 </papid></citsent>
<aftsection>
<nextsent>very recently blanc (bilateral assessment of noun phrase coreference) measure (recasens and hovy, 17as is the case in this evaluation with gold mentions2011) has been proposed as well.
</nextsent>
<nextsent>each of the metric tries to address the shortcomings or biases of the earlier metrics.
</nextsent>
<nextsent>given set of key entities k, anda set of response entities r, with each entity comprising one or more mentions, each metric generates its variation of precision and recall measure.
</nextsent>
<nextsent>the muc measure if the oldest and most widely used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4610">
<title id=" W11-1901.xml">conll2011 shared task modeling unrestricted coreference in ontonotes </title>
<section> conll-2011 coreference task.  </section>
<citcontext>
<prevsection>
<prevsent>this choice means that scores for the conll-2011 coreference task are likely to be lower than for coref evaluations based on muc, where the mention spans are specified in the input,17 or those based on ace data, where an approximate match is often allowed based on the specified head of the np mention.
</prevsent>
<prevsent>4.5.1 metric sas noted above, the choice of an evaluation metric for coreference has been tricky issue and there does not appear to be any silver bullet approach that addresses all the concerns.
</prevsent>
</prevsection>
<citsent citstr=" H05-1004 ">
three metrics have been proposed for evaluating coreference performance over an unrestricted set of entity types: i) the link based muc metric (vilain et al, 1995), <papid> M95-1005 </papid>ii) the mention based b-cubed metric (bagga and baldwin, 1998) and iii) the entity based ceaf (constrained entity aligned f-measure) metric (luo, 2005).<papid> H05-1004 </papid></citsent>
<aftsection>
<nextsent>very recently blanc (bilateral assessment of noun phrase coreference) measure (recasens and hovy, 17as is the case in this evaluation with gold mentions2011) has been proposed as well.
</nextsent>
<nextsent>each of the metric tries to address the shortcomings or biases of the earlier metrics.
</nextsent>
<nextsent>given set of key entities k, anda set of response entities r, with each entity comprising one or more mentions, each metric generates its variation of precision and recall measure.
</nextsent>
<nextsent>the muc measure if the oldest and most widely used.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4613">
<title id=" W11-2021.xml">topics as contextual indicators for word choice in sms conversations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with respect to language and communication, text messaging is still an under examined research area.
</prevsent>
<prevsent>thurlow and poff (2009) provide comprehensive overview of existing literature about sms in linguistics.
</prevsent>
</prevsection>
<citsent citstr=" P06-2005 ">
moreover, there exists noteworthy work on sms text normalization (aw et. al., 2006; <papid> P06-2005 </papid>fairon and paumier, 2006; cook and stevenson, 2009; <papid> W09-2010 </papid>kobus et. al., 2008; <papid> C08-1056 </papid>pennell and liu, 2010), for instance for the purpose of machine translation, text-to-speech engines or spell checking, work on sms based question answering 185 services (kothari, 2009), and work on predefined sms replies in automobiles (wu et. al., 2010).</citsent>
<aftsection>
<nextsent>however, conversed topics in the context of sms discourse have not been examined in the literature, neither in linguistics nor for any natural language processing applications.
</nextsent>
<nextsent>hence, in this paper we have developed new approach to make topics useful as context knowledge for sms dictation by voice.
</nextsent>
<nextsent>we describe topic annotation of novel sms corpus and study the influence which sms dialog topics may have on the choice of words.
</nextsent>
<nextsent>based on the results, we are able to estimate and initially quantify its impact.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4614">
<title id=" W11-2021.xml">topics as contextual indicators for word choice in sms conversations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with respect to language and communication, text messaging is still an under examined research area.
</prevsent>
<prevsent>thurlow and poff (2009) provide comprehensive overview of existing literature about sms in linguistics.
</prevsent>
</prevsection>
<citsent citstr=" W09-2010 ">
moreover, there exists noteworthy work on sms text normalization (aw et. al., 2006; <papid> P06-2005 </papid>fairon and paumier, 2006; cook and stevenson, 2009; <papid> W09-2010 </papid>kobus et. al., 2008; <papid> C08-1056 </papid>pennell and liu, 2010), for instance for the purpose of machine translation, text-to-speech engines or spell checking, work on sms based question answering 185 services (kothari, 2009), and work on predefined sms replies in automobiles (wu et. al., 2010).</citsent>
<aftsection>
<nextsent>however, conversed topics in the context of sms discourse have not been examined in the literature, neither in linguistics nor for any natural language processing applications.
</nextsent>
<nextsent>hence, in this paper we have developed new approach to make topics useful as context knowledge for sms dictation by voice.
</nextsent>
<nextsent>we describe topic annotation of novel sms corpus and study the influence which sms dialog topics may have on the choice of words.
</nextsent>
<nextsent>based on the results, we are able to estimate and initially quantify its impact.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4615">
<title id=" W11-2021.xml">topics as contextual indicators for word choice in sms conversations </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with respect to language and communication, text messaging is still an under examined research area.
</prevsent>
<prevsent>thurlow and poff (2009) provide comprehensive overview of existing literature about sms in linguistics.
</prevsent>
</prevsection>
<citsent citstr=" C08-1056 ">
moreover, there exists noteworthy work on sms text normalization (aw et. al., 2006; <papid> P06-2005 </papid>fairon and paumier, 2006; cook and stevenson, 2009; <papid> W09-2010 </papid>kobus et. al., 2008; <papid> C08-1056 </papid>pennell and liu, 2010), for instance for the purpose of machine translation, text-to-speech engines or spell checking, work on sms based question answering 185 services (kothari, 2009), and work on predefined sms replies in automobiles (wu et. al., 2010).</citsent>
<aftsection>
<nextsent>however, conversed topics in the context of sms discourse have not been examined in the literature, neither in linguistics nor for any natural language processing applications.
</nextsent>
<nextsent>hence, in this paper we have developed new approach to make topics useful as context knowledge for sms dictation by voice.
</nextsent>
<nextsent>we describe topic annotation of novel sms corpus and study the influence which sms dialog topics may have on the choice of words.
</nextsent>
<nextsent>based on the results, we are able to estimate and initially quantify its impact.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4616">
<title id=" W11-2021.xml">topics as contextual indicators for word choice in sms conversations </title>
<section> topic annotation for sms.  </section>
<citcontext>
<prevsection>
<prevsent>to ensure annotator agreement linguist verified and confirmed the growing topic list and all topic assignments in several iterations.
</prevsent>
<prevsent>further annotation of larger corpus may be semi-automated based on the achieved topic list.
</prevsent>
</prevsection>
<citsent citstr=" C92-1049 ">
assigning topics to dialog remains intuitive to certain extent, because any mutual understanding of the dialogs content and pragmatic meaning is supported by social cues, situation awareness and world knowledge of dialog partners (levinson, 1983; lambert and carberry, 1992).<papid> C92-1049 </papid></citsent>
<aftsection>
<nextsent>these know ledge dimensions need to be reconstituted during the annotation process, when assigning new topic.
</nextsent>
<nextsent>one criterion is to ask if the topic is distinct from other topics with regard to describing pieces of our world knowledge dimensions, e.g. scripts and events that people repeatedly experience, or subjects, they are re currently dealing with.
</nextsent>
<nextsent>furthermore, task driven approach demands to determine the level of specialization and detail for topics.
</nextsent>
<nextsent>even if broad topics, such as food?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4617">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> unsupervised pos-tagging.  </section>
<citcontext>
<prevsection>
<prevsent>this is especially useful for the task of word class clustering which is hard to evaluate.
</prevsent>
<prevsent>there have been several suggestions of clustering methods for obtaining word classes that are completely unsupervised, and induce classes from raw 28 text.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
brown et al (1992) <papid> J92-4003 </papid>described hierarchical word clustering method which maximizes the mutual information of bigrams.</citsent>
<aftsection>
<nextsent>schutze (1995) described distributional clustering algorithm that uses global context vectors as basis for clustering.
</nextsent>
<nextsent>biemann (2006) <papid> P06-3002 </papid>described graph-basedclustering methods for word classes.</nextsent>
<nextsent>goldwater and griffiths (2007) <papid> P07-1094 </papid>used bayesian reasoning for word class induction.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4618">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> unsupervised pos-tagging.  </section>
<citcontext>
<prevsection>
<prevsent>brown et al (1992) <papid> J92-4003 </papid>described hierarchical word clustering method which maximizes the mutual information of bigrams.</prevsent>
<prevsent>schutze (1995) described distributional clustering algorithm that uses global context vectors as basis for clus tering.</prevsent>
</prevsection>
<citsent citstr=" P06-3002 ">
biemann (2006) <papid> P06-3002 </papid>described graph-basedclustering methods for word classes.</citsent>
<aftsection>
<nextsent>goldwater and griffiths (2007) <papid> P07-1094 </papid>used bayesian reasoning for word class induction.</nextsent>
<nextsent>och (1999) <papid> E99-1010 </papid>described method for determining bilingual word classes,used to improve the extraction of alignment templates through alignments between classes, notonly between words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4619">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> unsupervised pos-tagging.  </section>
<citcontext>
<prevsection>
<prevsent>schutze (1995) described distributional clustering algorithm that uses global context vectors as basis for clustering.
</prevsent>
<prevsent>biemann (2006) <papid> P06-3002 </papid>described graph-basedclustering methods for word classes.</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
goldwater and griffiths (2007) <papid> P07-1094 </papid>used bayesian reasoning for word class induction.</citsent>
<aftsection>
<nextsent>och (1999) <papid> E99-1010 </papid>described method for determining bilingual word classes,used to improve the extraction of alignment templates through alignments between classes, notonly between words.</nextsent>
<nextsent>he also described monolingual word clustering method, which is basedon maximum likelihood approach, using the frequencies of unigrams and bigrams in the training corpus.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4620">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> unsupervised pos-tagging.  </section>
<citcontext>
<prevsection>
<prevsent>biemann (2006) <papid> P06-3002 </papid>described graph-basedclustering methods for word classes.</prevsent>
<prevsent>goldwater and griffiths (2007) <papid> P07-1094 </papid>used bayesian reasoning for word class induction.</prevsent>
</prevsection>
<citsent citstr=" E99-1010 ">
och (1999) <papid> E99-1010 </papid>described method for determining bilingual word classes,used to improve the extraction of alignment templates through alignments between classes, notonly between words.</citsent>
<aftsection>
<nextsent>he also described monolingual word clustering method, which is basedon maximum likelihood approach, using the frequencies of unigrams and bigrams in the training corpus.
</nextsent>
<nextsent>the above methods are fully unsupervised, and produce un labelled classes.
</nextsent>
<nextsent>there has also been work on what goldwater and griffiths (2007) <papid> P07-1094 </papid>call pos disambiguation, where the learning of classes is constrained by dictionary of the allowable tags for each word.</nextsent>
<nextsent>such work has for instance been based on hidden markov models (merialdo, 1994), <papid> J94-2001 </papid>log-linear models (smith and eisner, 2005), <papid> P05-1044 </papid>and bayesian reasoning (goldwa ter and griffiths, 2007).<papid> P07-1094 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4622">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> unsupervised pos-tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the above methods are fully unsupervised, and produce un labelled classes.
</prevsent>
<prevsent>there has also been work on what goldwater and griffiths (2007) <papid> P07-1094 </papid>call pos disambiguation, where the learning of classes is constrained by dictionary of the allowable tags for each word.</prevsent>
</prevsection>
<citsent citstr=" J94-2001 ">
such work has for instance been based on hidden markov models (merialdo, 1994), <papid> J94-2001 </papid>log-linear models (smith and eisner, 2005), <papid> P05-1044 </papid>and bayesian reasoning (goldwa ter and griffiths, 2007).<papid> P07-1094 </papid></citsent>
<aftsection>
<nextsent>word clusters have previously been used for smt for improving word alignment (och, 1999), <papid> E99-1010 </papid>in class-based language model (costa-jussa` etal., 2007) or for extracting gappy patterns (gimpel and smith, 2011).<papid> W11-2165 </papid></nextsent>
<nextsent>to the best of our knowledge this is the first study of applying clustered word classes for creating pre-translation reordering rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4623">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> unsupervised pos-tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the above methods are fully unsupervised, and produce un labelled classes.
</prevsent>
<prevsent>there has also been work on what goldwater and griffiths (2007) <papid> P07-1094 </papid>call pos disambiguation, where the learning of classes is constrained by dictionary of the allowable tags for each word.</prevsent>
</prevsection>
<citsent citstr=" P05-1044 ">
such work has for instance been based on hidden markov models (merialdo, 1994), <papid> J94-2001 </papid>log-linear models (smith and eisner, 2005), <papid> P05-1044 </papid>and bayesian reasoning (goldwa ter and griffiths, 2007).<papid> P07-1094 </papid></citsent>
<aftsection>
<nextsent>word clusters have previously been used for smt for improving word alignment (och, 1999), <papid> E99-1010 </papid>in class-based language model (costa-jussa` etal., 2007) or for extracting gappy patterns (gimpel and smith, 2011).<papid> W11-2165 </papid></nextsent>
<nextsent>to the best of our knowledge this is the first study of applying clustered word classes for creating pre-translation reordering rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4626">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> unsupervised pos-tagging.  </section>
<citcontext>
<prevsection>
<prevsent>there has also been work on what goldwater and griffiths (2007) <papid> P07-1094 </papid>call pos disambiguation, where the learning of classes is constrained by dictionary of the allowable tags for each word.</prevsent>
<prevsent>such work has for instance been based on hidden markov models (merialdo, 1994), <papid> J94-2001 </papid>log-linear models (smith and eisner, 2005), <papid> P05-1044 </papid>and bayesian reasoning (goldwa ter and griffiths, 2007).<papid> P07-1094 </papid></prevsent>
</prevsection>
<citsent citstr=" W11-2165 ">
word clusters have previously been used for smt for improving word alignment (och, 1999), <papid> E99-1010 </papid>in class-based language model (costa-jussa` etal., 2007) or for extracting gappy patterns (gimpel and smith, 2011).<papid> W11-2165 </papid></citsent>
<aftsection>
<nextsent>to the best of our knowledge this is the first study of applying clustered word classes for creating pre-translation reordering rules.
</nextsent>
<nextsent>the most similar work we are aware of is costa-jussa` and fonollosa (2006) who used clustered word classes in strategy they call statistical machine reordering, where the corpus is translated into reordered language using standard smt techniques in pre-processing step.
</nextsent>
<nextsent>the addition of word classes led to improvements over just using surface form, but no comparison to using pos-tags were shown.
</nextsent>
<nextsent>clustered word classes have also been used indiscriminate reordering model (zens and ney, 2006), <papid> W06-3108 </papid>and were shown to reduce the classification error rate.word clusters have also been used for unsupervised and semi-supervised parsing.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4627">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> unsupervised pos-tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the most similar work we are aware of is costa-jussa` and fonollosa (2006) who used clustered word classes in strategy they call statistical machine reordering, where the corpus is translated into reordered language using standard smt techniques in pre-processing step.
</prevsent>
<prevsent>the addition of word classes led to improvements over just using surface form, but no comparison to using pos-tags were shown.
</prevsent>
</prevsection>
<citsent citstr=" W06-3108 ">
clustered word classes have also been used indiscriminate reordering model (zens and ney, 2006), <papid> W06-3108 </papid>and were shown to reduce the classification error rate.word clusters have also been used for unsupervised and semi-supervised parsing.</citsent>
<aftsection>
<nextsent>klein and manning (2004) <papid> P04-1061 </papid>used pos-tags as the basis of afully unsupervised parsing method, both forde pendency and constituency parsing.</nextsent>
<nextsent>they showed that clustered word classes can be used instead of conventional pos-tags, with some result degradation, but that it is better than several baseline systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4628">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> unsupervised pos-tagging.  </section>
<citcontext>
<prevsection>
<prevsent>the addition of word classes led to improvements over just using surface form, but no comparison to using pos-tags were shown.
</prevsent>
<prevsent>clustered word classes have also been used indiscriminate reordering model (zens and ney, 2006), <papid> W06-3108 </papid>and were shown to reduce the classification error rate.word clusters have also been used for unsupervised and semi-supervised parsing.</prevsent>
</prevsection>
<citsent citstr=" P04-1061 ">
klein and manning (2004) <papid> P04-1061 </papid>used pos-tags as the basis of afully unsupervised parsing method, both forde pendency and constituency parsing.</citsent>
<aftsection>
<nextsent>they showed that clustered word classes can be used instead of conventional pos-tags, with some result degradation, but that it is better than several baseline systems.
</nextsent>
<nextsent>koo et al (2008) <papid> P08-1068 </papid>used features based on clustered word classes for semi-supervised dependency parsing and showed that using word class features together with pos-based features led to improvements, but using word class features instead of pos-based features only degraded results somewhat.</nextsent>
<nextsent>there is large amount of work on reordering for statistical machine translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4629">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> unsupervised pos-tagging.  </section>
<citcontext>
<prevsection>
<prevsent>klein and manning (2004) <papid> P04-1061 </papid>used pos-tags as the basis of afully unsupervised parsing method, both forde pendency and constituency parsing.</prevsent>
<prevsent>they showed that clustered word classes can be used instead of conventional pos-tags, with some result degradation, but that it is better than several baseline systems.</prevsent>
</prevsection>
<citsent citstr=" P08-1068 ">
koo et al (2008) <papid> P08-1068 </papid>used features based on clustered word classes for semi-supervised dependency parsing and showed that using word class features together with pos-based features led to improvements, but using word class features instead of pos-based features only degraded results somewhat.</citsent>
<aftsection>
<nextsent>there is large amount of work on reordering for statistical machine translation.
</nextsent>
<nextsent>one way to approach reordering is by extending the translation model, either by adding extra models, suchas lexicalized (koehn et al, 2005) or discriminative (zens and ney, 2006) <papid> W06-3108 </papid>reordering models or by directly modelling reordering in hierarchical (chiang, 2007) <papid> J07-2003 </papid>or syntactical translation models (yamada and knight, 2002).<papid> P02-1039 </papid></nextsent>
<nextsent>pre ordering is another common strategy for handling reordering.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4631">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> reordering for smt.  </section>
<citcontext>
<prevsection>
<prevsent>koo et al (2008) <papid> P08-1068 </papid>used features based on clustered word classes for semi-supervised dependency parsing and showed that using word class features together with pos-based features led to improvements, but using word class features instead of pos-based features only degraded results somewhat.</prevsent>
<prevsent>there is large amount of work on reordering for statistical machine translation.</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
one way to approach reordering is by extending the translation model, either by adding extra models, suchas lexicalized (koehn et al, 2005) or discriminative (zens and ney, 2006) <papid> W06-3108 </papid>reordering models or by directly modelling reordering in hierarchical (chiang, 2007) <papid> J07-2003 </papid>or syntactical translation models (yamada and knight, 2002).<papid> P02-1039 </papid></citsent>
<aftsection>
<nextsent>pre ordering is another common strategy for handling reordering.
</nextsent>
<nextsent>here the source side of the corpus is transformed in preprocessing step to become more similar to the target side.
</nextsent>
<nextsent>there have been many suggestions of pre ordering strategies.
</nextsent>
<nextsent>transformation rules can be handwritten rules targeting known syntactic differences (collins et al, 2005; <papid> P05-1066 </papid>popovic?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4632">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> reordering for smt.  </section>
<citcontext>
<prevsection>
<prevsent>koo et al (2008) <papid> P08-1068 </papid>used features based on clustered word classes for semi-supervised dependency parsing and showed that using word class features together with pos-based features led to improvements, but using word class features instead of pos-based features only degraded results somewhat.</prevsent>
<prevsent>there is large amount of work on reordering for statistical machine translation.</prevsent>
</prevsection>
<citsent citstr=" P02-1039 ">
one way to approach reordering is by extending the translation model, either by adding extra models, suchas lexicalized (koehn et al, 2005) or discriminative (zens and ney, 2006) <papid> W06-3108 </papid>reordering models or by directly modelling reordering in hierarchical (chiang, 2007) <papid> J07-2003 </papid>or syntactical translation models (yamada and knight, 2002).<papid> P02-1039 </papid></citsent>
<aftsection>
<nextsent>pre ordering is another common strategy for handling reordering.
</nextsent>
<nextsent>here the source side of the corpus is transformed in preprocessing step to become more similar to the target side.
</nextsent>
<nextsent>there have been many suggestions of pre ordering strategies.
</nextsent>
<nextsent>transformation rules can be handwritten rules targeting known syntactic differences (collins et al, 2005; <papid> P05-1066 </papid>popovic?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4633">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> reordering for smt.  </section>
<citcontext>
<prevsection>
<prevsent>here the source side of the corpus is transformed in preprocessing step to become more similar to the target side.
</prevsent>
<prevsent>there have been many suggestions of pre ordering strategies.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
transformation rules can be handwritten rules targeting known syntactic differences (collins et al, 2005; <papid> P05-1066 </papid>popovic?</citsent>
<aftsection>
<nextsent>and ney, 2006),or they can be learnt automatically (xia and mccord, 2004; <papid> C04-1073 </papid>habash, 2007).</nextsent>
<nextsent>in these studies the reordering decision was taken deterministically on the source side.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4634">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> reordering for smt.  </section>
<citcontext>
<prevsection>
<prevsent>there have been many suggestions of pre ordering strategies.
</prevsent>
<prevsent>transformation rules can be handwritten rules targeting known syntactic differences (collins et al, 2005; <papid> P05-1066 </papid>popovic?</prevsent>
</prevsection>
<citsent citstr=" C04-1073 ">
and ney, 2006),or they can be learnt automatically (xia and mccord, 2004; <papid> C04-1073 </papid>habash, 2007).</citsent>
<aftsection>
<nextsent>in these studies the reordering decision was taken deterministically on the source side.
</nextsent>
<nextsent>this decision can be delayed to decoding time by presenting several reordering options to the decoder as lattice (zhang et al, 2007; niehues and kolss, 2009) <papid> W09-0435 </papid>or as an n-best list (li et al, 2007).<papid> P07-1091 </papid></nextsent>
<nextsent>generally reordering rules are applied to the source language, but there have been attempts at target side reordering as well (na et al, 2009).reordering rules can be based on different levels of linguistic annotation, such as pos-tags (niehues and kolss, 2009), <papid> W09-0435 </papid>chunks (zhang et al, 2007) or parse trees (xia and mccord, 2004).<papid> C04-1073 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4635">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> reordering for smt.  </section>
<citcontext>
<prevsection>
<prevsent>and ney, 2006),or they can be learnt automatically (xia and mccord, 2004; <papid> C04-1073 </papid>habash, 2007).</prevsent>
<prevsent>in these studies the reordering decision was taken deterministically on the source side.</prevsent>
</prevsection>
<citsent citstr=" W09-0435 ">
this decision can be delayed to decoding time by presenting several reordering options to the decoder as lattice (zhang et al, 2007; niehues and kolss, 2009) <papid> W09-0435 </papid>or as an n-best list (li et al, 2007).<papid> P07-1091 </papid></citsent>
<aftsection>
<nextsent>generally reordering rules are applied to the source language, but there have been attempts at target side reordering as well (na et al, 2009).reordering rules can be based on different levels of linguistic annotation, such as pos-tags (niehues and kolss, 2009), <papid> W09-0435 </papid>chunks (zhang et al, 2007) or parse trees (xia and mccord, 2004).<papid> C04-1073 </papid></nextsent>
<nextsent>common for all these levels is that tool like tagger or parser is needed for them to work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4636">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> reordering for smt.  </section>
<citcontext>
<prevsection>
<prevsent>and ney, 2006),or they can be learnt automatically (xia and mccord, 2004; <papid> C04-1073 </papid>habash, 2007).</prevsent>
<prevsent>in these studies the reordering decision was taken deterministically on the source side.</prevsent>
</prevsection>
<citsent citstr=" P07-1091 ">
this decision can be delayed to decoding time by presenting several reordering options to the decoder as lattice (zhang et al, 2007; niehues and kolss, 2009) <papid> W09-0435 </papid>or as an n-best list (li et al, 2007).<papid> P07-1091 </papid></citsent>
<aftsection>
<nextsent>generally reordering rules are applied to the source language, but there have been attempts at target side reordering as well (na et al, 2009).reordering rules can be based on different levels of linguistic annotation, such as pos-tags (niehues and kolss, 2009), <papid> W09-0435 </papid>chunks (zhang et al, 2007) or parse trees (xia and mccord, 2004).<papid> C04-1073 </papid></nextsent>
<nextsent>common for all these levels is that tool like tagger or parser is needed for them to work.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4639">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> reordering for smt.  </section>
<citcontext>
<prevsection>
<prevsent>they found that it was better to use the latter option, to reorder the training data based on the rules, than to use the original order in the training data.
</prevsent>
<prevsent>using alignment-based reordering wasnot successful, however.
</prevsent>
</prevsection>
<citsent citstr=" W09-0413 ">
another option for using reorderings in the training data was presented by niehues et al (2009), <papid> W09-0413 </papid>who directly extracted phrase pairs from reordering lattices, and showed small gain over non-reordered training data.</citsent>
<aftsection>
<nextsent>3.1 pos-based preordering.
</nextsent>
<nextsent>our work is based on the pos-based reordering model described by niehues and kolss (2009), <papid> W09-0435 </papid>in which pos-based rules are extracted from word aligned corpus, where the source side is part-of-speech tagged.</nextsent>
<nextsent>there are two types of rules.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4647">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>the clustering was performed on the same corpus as the smt training.
</prevsent>
<prevsent>the translation system used is standard phrase-based smt system.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
the translation model was trained by first creating unidirectional word alignments in both directions using giza++ (och and ney, 2003), <papid> J03-1002 </papid>which are then symmetrized by the grow-diag-final-and method (koehn et al,2005).</citsent>
<aftsection>
<nextsent>from this many-to-many alignment, consistent phrases of up to length 7 were extracted.
</nextsent>
<nextsent>a 5-gram language model was used, produced by srilm (stolcke, 2002).
</nextsent>
<nextsent>for training and decoding we used the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and the feature weights were optimized using minimum error rate training (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>1http://www.connexor.eu/technology/ machinese/machinesesyntax/ 2http://www-i6.informatik.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4649">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>from this many-to-many alignment, consistent phrases of up to length 7 were extracted.
</prevsent>
<prevsent>a 5-gram language model was used, produced by srilm (stolcke, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
for training and decoding we used the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and the feature weights were optimized using minimum error rate training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>1http://www.connexor.eu/technology/ machinese/machinesesyntax/ 2http://www-i6.informatik.
</nextsent>
<nextsent>rwth-aachen.de/web/software/mkcls.html tagset classes rules paths pos 23 319147 2.1e09 dep 523 328415 2.8e09 func 49 325091 1.5e10 syntax 20 315407 4.5e11 class50 50 303292 6.2e09 class125 125 271348 1.3e07 class625 625 211606 31654 table 2: number of tags for each tagset in the english training corpus, number of rules extracted for each tagset, and average numbers of paths per sentence in the testset lattice using each tagset to create rules the baseline systems were trained using no additional pre ordering, only distance-based reordering penalty for modelling reordering.
</nextsent>
<nextsent>for the haitian creole english experiments we also added lexicalized reordering model (koehn etal., 2005), both to the baseline and to there ordered systems.
</nextsent>
<nextsent>for the english german experiments, the translation system was trained and tested using part of the europarl corpus (koehn, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4650">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>from this many-to-many alignment, consistent phrases of up to length 7 were extracted.
</prevsent>
<prevsent>a 5-gram language model was used, produced by srilm (stolcke, 2002).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
for training and decoding we used the moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>and the feature weights were optimized using minimum error rate training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>1http://www.connexor.eu/technology/ machinese/machinesesyntax/ 2http://www-i6.informatik.
</nextsent>
<nextsent>rwth-aachen.de/web/software/mkcls.html tagset classes rules paths pos 23 319147 2.1e09 dep 523 328415 2.8e09 func 49 325091 1.5e10 syntax 20 315407 4.5e11 class50 50 303292 6.2e09 class125 125 271348 1.3e07 class625 625 211606 31654 table 2: number of tags for each tagset in the english training corpus, number of rules extracted for each tagset, and average numbers of paths per sentence in the testset lattice using each tagset to create rules the baseline systems were trained using no additional pre ordering, only distance-based reordering penalty for modelling reordering.
</nextsent>
<nextsent>for the haitian creole english experiments we also added lexicalized reordering model (koehn etal., 2005), both to the baseline and to there ordered systems.
</nextsent>
<nextsent>for the english german experiments, the translation system was trained and tested using part of the europarl corpus (koehn, 2005).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4653">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> experimental setup.  </section>
<citcontext>
<prevsection>
<prevsent>since we know of no pos-tagger for haitian creole, we only compare the clustered result to baseline system.
</prevsent>
<prevsent>reordering rules were extracted from the same corpora that were used for training the smt system.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the word alignments needed for reordering were created using giza++ (och and ney, 2003), <papid> J03-1002 </papid>an implementation of the ibm models (brown et al., 1993) <papid> J93-2003 </papid>of alignment, which is trained in fully unsupervised manner based on the em algorithm (dempster et al, 1977).</citsent>
<aftsection>
<nextsent>31
</nextsent>
<nextsent>table 2 shows the number of rules, and the average number of paths for each sentence in thetest data lattice, using each tagset.
</nextsent>
<nextsent>for the standard tagsets the number of rules is relatively constant, despite the fact that the number of tags in the tagsets are quite different.
</nextsent>
<nextsent>for the clustered word classes, there are slightly fewer rules with50 classes than for the standard tags, and the number of rules decreases with higher number of classes.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4654">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>for the average number of lattice paths per sentence, there are some differences for the standard tags, but it is not related to tagset size.again, the clustering with 50 classes has similar number as the standard classes, but here there is sharp decrease of lattice paths with higher number of classes.
</prevsent>
<prevsent>the translation results for the english german experiments are shown in table 3.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we report translation results for two metrics, bleu (papineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002), and significance testing is performed using approximate randomization (riezler and maxwell, 2005),<papid> W05-0908 </papid>with 10,000 iterations.</citsent>
<aftsection>
<nextsent>all the systems with reordering have higher scores than the baseline on both metrics.
</nextsent>
<nextsent>this difference is always significant for nist, and significant for bleu in all cases except for two systems, one with standard tags andone with clustered tags.
</nextsent>
<nextsent>between most of the systems with reordering the differences are small andmost of them are not significant.
</nextsent>
<nextsent>overall the systems with standard word classes perform slightly better than the clustered systems, especially the func tagset gives consistently high results, and is significantly better than four of the clustered systems on bleu, and than one system on nist.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4655">
<title id=" W12-0704.xml">clustered word classes for pre ordering in statistical machine translation </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>for the average number of lattice paths per sentence, there are some differences for the standard tags, but it is not related to tagset size.again, the clustering with 50 classes has similar number as the standard classes, but here there is sharp decrease of lattice paths with higher number of classes.
</prevsent>
<prevsent>the translation results for the english german experiments are shown in table 3.
</prevsent>
</prevsection>
<citsent citstr=" W05-0908 ">
we report translation results for two metrics, bleu (papineni et al, 2002) <papid> P02-1040 </papid>and nist (doddington, 2002), and significance testing is performed using approximate randomization (riezler and maxwell, 2005),<papid> W05-0908 </papid>with 10,000 iterations.</citsent>
<aftsection>
<nextsent>all the systems with reordering have higher scores than the baseline on both metrics.
</nextsent>
<nextsent>this difference is always significant for nist, and significant for bleu in all cases except for two systems, one with standard tags andone with clustered tags.
</nextsent>
<nextsent>between most of the systems with reordering the differences are small andmost of them are not significant.
</nextsent>
<nextsent>overall the systems with standard word classes perform slightly better than the clustered systems, especially the func tagset gives consistently high results, and is significantly better than four of the clustered systems on bleu, and than one system on nist.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4656">
<title id=" W11-2706.xml">linguistically motivated complementizer choice in surface realization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the experiments also show that the improvements in prediction accuracy apply to cases in which the presence of that-complementizer arguably makes asubstantial difference to fluency or intelli giblity.
</prevsent>
<prevsent>our ultimate goal is to improve the performance of ranking model for surface realization, and to this end we conclude with discussion of how we plan to combine the local complementizer-choice features with those in the global ranking model.
</prevsent>
</prevsection>
<citsent citstr=" W09-0103 ">
johnson (2009) <papid> W09-0103 </papid>observes that in developing statistical parsing models, shotgun?</citsent>
<aftsection>
<nextsent>features ? that is,myriad scatter shot features that pay attention to superficial aspects of structure ? tend to be remarkably useful, while features based on linguistic theory seem to be of more questionable utility, with the most basic linguistic insights tending to have the greatest impact.1 johnson also notes that feature design is perhaps the most important but least understood aspect of statistical parsing, and thus the disappointing impact of linguistic theory on parsing models is of real consequence.
</nextsent>
<nextsent>in this paper,by contrast, we show that in the context of surface realization, using linguistically motivated features for english that-complementizer choice can improve upon the prediction accuracy of state-of the-art realization ranking model, arguably in ways that make substantial difference to fluency and intelligiblity.2 in particular, we report results on binary classification task for predicting the presence or absence of that-complementizer using features adapted from jaegers (2010) investigation of the uniform information density principle in the context of that-mentioning.
</nextsent>
<nextsent>this information-theoreticprinciple predicts that language production is affected by preference to distribute information uniformly across the linguistic signal.
</nextsent>
<nextsent>in jaegers study,uniform information density emerges as an important predictor of speakers?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4657">
<title id=" W11-2706.xml">linguistically motivated complementizer choice in surface realization </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>while in many cases, adding or removing that results in an acceptable paraphrase, in the following example, the absence of that in (2) introduces local ambiguity, which the original penn treebank sentence avoids by including the complementizer.
</prevsent>
<prevsent>(1) he said that for the second month in row, food processors reported shortage of nonfat dry milk.
</prevsent>
</prevsection>
<citsent citstr=" D09-1043 ">
(wsj0036.61) (2) ? he said for the second month in row, food processors reported shortage of nonfat dry milk.the starting point for this paper is white and rajkumars (2009) <papid> D09-1043 </papid>realization ranking model, stateof-the-art model employing shotgun features ga lore.</citsent>
<aftsection>
<nextsent>an error analysis of this model, performed by comparing ccgbank section 00 realized derivations with their corresponding gold standard derivations, revealed that out of total of 543 that complementizer cases, the realized output did not match the gold standard choice 82 times (see table 3 in section 5 for details).
</nextsent>
<nextsent>most of these mismatches involved cases where clause originally containing that-complementizer was realized in reduced form, with no that.
</nextsent>
<nextsent>this under-prediction of that-inclusion is not surprising, since the realization ranking model makes use of baseline n-gram model features, and n-gram models are known to have built-in bias for strings with fewer words.
</nextsent>
<nextsent>3openccg.sf.net we report here on experiments comparing this global model to ones that employ local features specifically designed for that-choice in complementclauses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4660">
<title id=" W11-2706.xml">linguistically motivated complementizer choice in surface realization </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>(6) ? realized with sadness in my heart [he had done it].
</prevsent>
<prevsent>ccg (steedman, 2000) is unification-based categorial grammar formalism defined almost entirely in terms of lexical entries that encode subcategorization as well as syntactic features (e.g.number and agreement).
</prevsent>
</prevsection>
<citsent citstr=" P02-1041 ">
openccg is pars ing/generation library which includes hybrid symbolic-statistical chart realizer (white, 2006).the chart realizer takes as input logical forms represented internally using hybrid logic dependency semantics (hlds), dependency-based approach to representing linguistic meaning (baldridge and kruijff, 2002).<papid> P02-1041 </papid></citsent>
<aftsection>
<nextsent>to illustrate the input to openccg, consider the semantic dependency graph in figure 1.
</nextsent>
<nextsent>in the graph, each node has lexical predication (e.g. make.03) and set of semantic features (e.g. 40 aa1 heh3 he h2  det   arg0   arg1   tense pres  num sg  arg0  w1 want.01 m1  arg1   genrel   arg1   tense pres p1point h1have.03 make.03  arg0  s[b]\np/np np/n np s[dcl]\np/np s[dcl]\np/(s[to]\np) np figure 1: semantic dependency graph from the ccgbank for he has point he wants to make [.
</nextsent>
<nextsent>], along with gold-standard supertags (category labels)numsg); nodes are connected via dependency relations (e.g. arg0?).
</nextsent>
<nextsent>in hlds, each semantic head (corresponding to node in the graph) is associated with nominal that identifies its discourse referent, and relations between heads and their dependents are modeled as modal relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4664">
<title id=" W11-2706.xml">linguistically motivated complementizer choice in surface realization </title>
<section> feature design.  </section>
<citcontext>
<prevsection>
<prevsent>alternative realizations are ranked using an averaged perceptron model described in the next section.
</prevsent>
<prevsent>white and rajkumars (2009) <papid> D09-1043 </papid>realization ranking model serves as the baseline for this paper.</prevsent>
</prevsection>
<citsent citstr=" W05-1510 ">
it is global, averaged perceptron ranking model using three kinds of features: (1) the log probability of the candidate realizations word sequence according to three linearly interpolated language models (as well as feature for each component model), much as in the log-linear models of velldal &amp; oepen (2005)and nakanishi et al (2005); (<papid> W05-1510 </papid>2) integer-valued syntactic features, representing counts of occurrences in derivation, from clark &amp; currans (2007) <papid> J07-4004 </papid>normal form model; and (3) discriminative n-gram features (roark et al, 2004), <papid> P04-1007 </papid>which count the occurrences of each n-gram in the word sequence.</citsent>
<aftsection>
<nextsent>table 1 shows the new complementizer-choicefeatures investigated in this paper.
</nextsent>
<nextsent>the example features mentioned in the table are taken from the two complement clause (cc) forms (with-that cc vs. that-less cc) of the sentence below: (7) the finding probably will support those who argue [ that/?
</nextsent>
<nextsent>the u.s. should regulate the class of asbestos including crocidolite more stringently than the common kind of asbestos, chrysotile, found in most schools and other buildings], dr. talcott said.
</nextsent>
<nextsent>(wsj0003.19) the first class of features, dependency length and position of cc, have been adapted from the related control features in jaegers (2010) study.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4665">
<title id=" W11-2706.xml">linguistically motivated complementizer choice in surface realization </title>
<section> feature design.  </section>
<citcontext>
<prevsection>
<prevsent>alternative realizations are ranked using an averaged perceptron model described in the next section.
</prevsent>
<prevsent>white and rajkumars (2009) <papid> D09-1043 </papid>realization ranking model serves as the baseline for this paper.</prevsent>
</prevsection>
<citsent citstr=" J07-4004 ">
it is global, averaged perceptron ranking model using three kinds of features: (1) the log probability of the candidate realizations word sequence according to three linearly interpolated language models (as well as feature for each component model), much as in the log-linear models of velldal &amp; oepen (2005)and nakanishi et al (2005); (<papid> W05-1510 </papid>2) integer-valued syntactic features, representing counts of occurrences in derivation, from clark &amp; currans (2007) <papid> J07-4004 </papid>normal form model; and (3) discriminative n-gram features (roark et al, 2004), <papid> P04-1007 </papid>which count the occurrences of each n-gram in the word sequence.</citsent>
<aftsection>
<nextsent>table 1 shows the new complementizer-choicefeatures investigated in this paper.
</nextsent>
<nextsent>the example features mentioned in the table are taken from the two complement clause (cc) forms (with-that cc vs. that-less cc) of the sentence below: (7) the finding probably will support those who argue [ that/?
</nextsent>
<nextsent>the u.s. should regulate the class of asbestos including crocidolite more stringently than the common kind of asbestos, chrysotile, found in most schools and other buildings], dr. talcott said.
</nextsent>
<nextsent>(wsj0003.19) the first class of features, dependency length and position of cc, have been adapted from the related control features in jaegers (2010) study.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4666">
<title id=" W11-2706.xml">linguistically motivated complementizer choice in surface realization </title>
<section> feature design.  </section>
<citcontext>
<prevsection>
<prevsent>alternative realizations are ranked using an averaged perceptron model described in the next section.
</prevsent>
<prevsent>white and rajkumars (2009) <papid> D09-1043 </papid>realization ranking model serves as the baseline for this paper.</prevsent>
</prevsection>
<citsent citstr=" P04-1007 ">
it is global, averaged perceptron ranking model using three kinds of features: (1) the log probability of the candidate realizations word sequence according to three linearly interpolated language models (as well as feature for each component model), much as in the log-linear models of velldal &amp; oepen (2005)and nakanishi et al (2005); (<papid> W05-1510 </papid>2) integer-valued syntactic features, representing counts of occurrences in derivation, from clark &amp; currans (2007) <papid> J07-4004 </papid>normal form model; and (3) discriminative n-gram features (roark et al, 2004), <papid> P04-1007 </papid>which count the occurrences of each n-gram in the word sequence.</citsent>
<aftsection>
<nextsent>table 1 shows the new complementizer-choicefeatures investigated in this paper.
</nextsent>
<nextsent>the example features mentioned in the table are taken from the two complement clause (cc) forms (with-that cc vs. that-less cc) of the sentence below: (7) the finding probably will support those who argue [ that/?
</nextsent>
<nextsent>the u.s. should regulate the class of asbestos including crocidolite more stringently than the common kind of asbestos, chrysotile, found in most schools and other buildings], dr. talcott said.
</nextsent>
<nextsent>(wsj0003.19) the first class of features, dependency length and position of cc, have been adapted from the related control features in jaegers (2010) study.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4670">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical substitution (ls) aims at providing alternative substitute words (or phrases) for target word in context, process useful for monolingual tasks such as paraphrasing and textual entailment (mccarthy and navigli, 2009).
</prevsent>
<prevsent>its multilingual counterpart, cross-lingual lexical substitution (clls),aims at finding for target word in context, alternative substitute words in another language.
</prevsent>
</prevsection>
<citsent citstr=" W09-2412 ">
clls systems may assist human translators and language learners, while their output may constitute the input to cross-language information retrieval and machine translation (mt) systems (sinha et al, 2009;<papid> W09-2412 </papid>mihalcea et al, 2010).<papid> S10-1002 </papid>the multilingual context in which clls is performed permits to override some issues common to monolingual semantic processing tasks, such as the selection of an adequate sense inventory and the definition of the granularity of the semantic descrip tions.</citsent>
<aftsection>
<nextsent>in multilingual context, word senses can be easily identified using their translations in other languages (resnik and yarowsky, 2000).
</nextsent>
<nextsent>although this conception of senses presents some theoretical and practical drawbacks, it provides standard criterion for sense delimitation which explains its wide adoption in recent works on multilingual word sense disambiguation (wsd) and wsd in mt (carpuat and wu, 2007; <papid> D07-1007 </papid>ng and chan, 2007).<papid> W07-2010 </papid></nextsent>
<nextsent>in this paper, we explain how semantic clustering may provide answers to some of the issues posedby the traditional cross-lingual sense induction approach, and how it can be efficiently exploited for clls.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4672">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>lexical substitution (ls) aims at providing alternative substitute words (or phrases) for target word in context, process useful for monolingual tasks such as paraphrasing and textual entailment (mccarthy and navigli, 2009).
</prevsent>
<prevsent>its multilingual counterpart, cross-lingual lexical substitution (clls),aims at finding for target word in context, alternative substitute words in another language.
</prevsent>
</prevsection>
<citsent citstr=" S10-1002 ">
clls systems may assist human translators and language learners, while their output may constitute the input to cross-language information retrieval and machine translation (mt) systems (sinha et al, 2009;<papid> W09-2412 </papid>mihalcea et al, 2010).<papid> S10-1002 </papid>the multilingual context in which clls is performed permits to override some issues common to monolingual semantic processing tasks, such as the selection of an adequate sense inventory and the definition of the granularity of the semantic descrip tions.</citsent>
<aftsection>
<nextsent>in multilingual context, word senses can be easily identified using their translations in other languages (resnik and yarowsky, 2000).
</nextsent>
<nextsent>although this conception of senses presents some theoretical and practical drawbacks, it provides standard criterion for sense delimitation which explains its wide adoption in recent works on multilingual word sense disambiguation (wsd) and wsd in mt (carpuat and wu, 2007; <papid> D07-1007 </papid>ng and chan, 2007).<papid> W07-2010 </papid></nextsent>
<nextsent>in this paper, we explain how semantic clustering may provide answers to some of the issues posedby the traditional cross-lingual sense induction approach, and how it can be efficiently exploited for clls.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4674">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>clls systems may assist human translators and language learners, while their output may constitute the input to cross-language information retrieval and machine translation (mt) systems (sinha et al, 2009;<papid> W09-2412 </papid>mihalcea et al, 2010).<papid> S10-1002 </papid>the multilingual context in which clls is performed permits to override some issues common to monolingual semantic processing tasks, such as the selection of an adequate sense inventory and the definition of the granularity of the semantic descrip tions.</prevsent>
<prevsent>in multilingual context, word senses can be easily identified using their translations in other languages (resnik and yarowsky, 2000).</prevsent>
</prevsection>
<citsent citstr=" D07-1007 ">
although this conception of senses presents some theoretical and practical drawbacks, it provides standard criterion for sense delimitation which explains its wide adoption in recent works on multilingual word sense disambiguation (wsd) and wsd in mt (carpuat and wu, 2007; <papid> D07-1007 </papid>ng and chan, 2007).<papid> W07-2010 </papid></citsent>
<aftsection>
<nextsent>in this paper, we explain how semantic clustering may provide answers to some of the issues posedby the traditional cross-lingual sense induction approach, and how it can be efficiently exploited for clls.
</nextsent>
<nextsent>given that existing clls systems relyon predefined semantic resources, we show, for the first time, that clls can be performed in fully unsupervised manner.
</nextsent>
<nextsent>the paper is organized as follows: in the next section, we present some arguments towards unsupervised clustering for cross lingual sense induction.
</nextsent>
<nextsent>the clustering method used is presented in section 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4675">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>clls systems may assist human translators and language learners, while their output may constitute the input to cross-language information retrieval and machine translation (mt) systems (sinha et al, 2009;<papid> W09-2412 </papid>mihalcea et al, 2010).<papid> S10-1002 </papid>the multilingual context in which clls is performed permits to override some issues common to monolingual semantic processing tasks, such as the selection of an adequate sense inventory and the definition of the granularity of the semantic descrip tions.</prevsent>
<prevsent>in multilingual context, word senses can be easily identified using their translations in other languages (resnik and yarowsky, 2000).</prevsent>
</prevsection>
<citsent citstr=" W07-2010 ">
although this conception of senses presents some theoretical and practical drawbacks, it provides standard criterion for sense delimitation which explains its wide adoption in recent works on multilingual word sense disambiguation (wsd) and wsd in mt (carpuat and wu, 2007; <papid> D07-1007 </papid>ng and chan, 2007).<papid> W07-2010 </papid></citsent>
<aftsection>
<nextsent>in this paper, we explain how semantic clustering may provide answers to some of the issues posedby the traditional cross-lingual sense induction approach, and how it can be efficiently exploited for clls.
</nextsent>
<nextsent>given that existing clls systems relyon predefined semantic resources, we show, for the first time, that clls can be performed in fully unsupervised manner.
</nextsent>
<nextsent>the paper is organized as follows: in the next section, we present some arguments towards unsupervised clustering for cross lingual sense induction.
</nextsent>
<nextsent>the clustering method used is presented in section 3.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4676">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> cross-lingual sense induction.  </section>
<citcontext>
<prevsection>
<prevsent>in this setting, the senses of words in one language are identified by their translations in another language, usually found in parallel corpus (resnik and yarowsky, 2000).this empirical approach to sense induction offers standard criterion for sense delimitation and,consequently, dissociates wsd from semantic theories and predefined semantic inventories.
</prevsent>
<prevsent>moreover, by establishing semantic distinctions pertinent for translation between the implicated languages, it allows to tune sense induction to the needs of multilingual applications.
</prevsent>
</prevsection>
<citsent citstr=" W02-0808 ">
it has thus been widely adopted in works on multilingual wsd and wsd in mt, where senses are derived from parallel data (diab, 2003; ide, 1999; ide et al, 2002; <papid> W02-0808 </papid>ng et al, 2003; <papid> P03-1058 </papid>chan et al., 2007; <papid> P07-1005 </papid>carpuat and wu, 2007).<papid> D07-1007 </papid></citsent>
<aftsection>
<nextsent>by linking wsd and its evaluation to translation, this hypothesis also offers solution to the problem of non-conformity of monolingual wsd methods in this setting.nevertheless, the assumption of biunivocal (oneto-one?)
</nextsent>
<nextsent>correspondences between senses and translations is rather simplistic.
</nextsent>
<nextsent>one word sense may be translated by different synonymous words in another language, whose relatedness should be considered during sense induction.
</nextsent>
<nextsent>furthermore, this approach does not permit to account for cases of parallel ambiguities (resnik, 2007), and cases where the senses of word share some of their translations (sinha et al., 2009).<papid> W09-2412 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4677">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> cross-lingual sense induction.  </section>
<citcontext>
<prevsection>
<prevsent>in this setting, the senses of words in one language are identified by their translations in another language, usually found in parallel corpus (resnik and yarowsky, 2000).this empirical approach to sense induction offers standard criterion for sense delimitation and,consequently, dissociates wsd from semantic theories and predefined semantic inventories.
</prevsent>
<prevsent>moreover, by establishing semantic distinctions pertinent for translation between the implicated languages, it allows to tune sense induction to the needs of multilingual applications.
</prevsent>
</prevsection>
<citsent citstr=" P03-1058 ">
it has thus been widely adopted in works on multilingual wsd and wsd in mt, where senses are derived from parallel data (diab, 2003; ide, 1999; ide et al, 2002; <papid> W02-0808 </papid>ng et al, 2003; <papid> P03-1058 </papid>chan et al., 2007; <papid> P07-1005 </papid>carpuat and wu, 2007).<papid> D07-1007 </papid></citsent>
<aftsection>
<nextsent>by linking wsd and its evaluation to translation, this hypothesis also offers solution to the problem of non-conformity of monolingual wsd methods in this setting.nevertheless, the assumption of biunivocal (oneto-one?)
</nextsent>
<nextsent>correspondences between senses and translations is rather simplistic.
</nextsent>
<nextsent>one word sense may be translated by different synonymous words in another language, whose relatedness should be considered during sense induction.
</nextsent>
<nextsent>furthermore, this approach does not permit to account for cases of parallel ambiguities (resnik, 2007), and cases where the senses of word share some of their translations (sinha et al., 2009).<papid> W09-2412 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4678">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> cross-lingual sense induction.  </section>
<citcontext>
<prevsection>
<prevsent>in this setting, the senses of words in one language are identified by their translations in another language, usually found in parallel corpus (resnik and yarowsky, 2000).this empirical approach to sense induction offers standard criterion for sense delimitation and,consequently, dissociates wsd from semantic theories and predefined semantic inventories.
</prevsent>
<prevsent>moreover, by establishing semantic distinctions pertinent for translation between the implicated languages, it allows to tune sense induction to the needs of multilingual applications.
</prevsent>
</prevsection>
<citsent citstr=" P07-1005 ">
it has thus been widely adopted in works on multilingual wsd and wsd in mt, where senses are derived from parallel data (diab, 2003; ide, 1999; ide et al, 2002; <papid> W02-0808 </papid>ng et al, 2003; <papid> P03-1058 </papid>chan et al., 2007; <papid> P07-1005 </papid>carpuat and wu, 2007).<papid> D07-1007 </papid></citsent>
<aftsection>
<nextsent>by linking wsd and its evaluation to translation, this hypothesis also offers solution to the problem of non-conformity of monolingual wsd methods in this setting.nevertheless, the assumption of biunivocal (oneto-one?)
</nextsent>
<nextsent>correspondences between senses and translations is rather simplistic.
</nextsent>
<nextsent>one word sense may be translated by different synonymous words in another language, whose relatedness should be considered during sense induction.
</nextsent>
<nextsent>furthermore, this approach does not permit to account for cases of parallel ambiguities (resnik, 2007), and cases where the senses of word share some of their translations (sinha et al., 2009).<papid> W09-2412 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4681">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> cross-lingual sense induction.  </section>
<citcontext>
<prevsection>
<prevsent>2.2 cross-lingual sense clustering.
</prevsent>
<prevsent>instead of using translations as straightforward sense indicators, it is possible to perform more thorough semantic analysis during cross-lingualwsi by combining distributional and translation information.
</prevsent>
</prevsection>
<citsent citstr=" L08-1585 ">
the sense clustering method proposed by apidianaki (2008) <papid> L08-1585 </papid>identifies complex semantic relations between word senses and their translations.the method is based on the contextual hypotheses of meaning and of semantic similarity (harris, 1954; miller and charles, 1991), which underlie monolingual wsi methods, and is combined to the assumption of semantic correspondence between words and their translations in real texts (chesterman, 1998).</citsent>
<aftsection>
<nextsent>following these hypotheses, information coming from the source contexts of target word when translated with precise translation in parallel corpus, is used to reveal the senses carried by the translation.
</nextsent>
<nextsent>furthermore, the similarity of the source contexts reveals the semantic relatedness of the translations.this cross-lingual wsi method groups the semantically similar translations of ambiguous words into clusters that serve to describe their senses instead of the individual translations.
</nextsent>
<nextsent>for instance, the traditional cross-lingual wsi approach would propose three senses for the english noun coach, corresponding to each of its spanish translations: entrenador, autocar and autobus.1 however, this solution is not sound given that the translations autocar and autobus are semantically related and do not lexical ize distinct senses of the english word, as is the case with entrenador.
</nextsent>
<nextsent>sense clustering permits to estimate the semantic similarity of the translation sand to not consider synonymous translations as indicators of distinct senses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4683">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> cross-lingual sense induction.  </section>
<citcontext>
<prevsection>
<prevsent>this type of sense clustering has proved to be useful in various application settings.
</prevsent>
<prevsent>when exploited in cross-lingual wsd, it permits to assign sensetags?
</prevsent>
</prevsection>
<citsent citstr=" E09-1010 ">
containing several semantically correct translations to new instances of words in context (apidianaki, 2009).<papid> E09-1010 </papid></citsent>
<aftsection>
<nextsent>moreover, the use of clustering information during evaluation allows for differing penal ization of wsd errors.
</nextsent>
<nextsent>in an mt evaluation setting, sense clusters have been integrated into anmt evaluation metric (meteor) (lavie and agarwal, 2007) <papid> W07-0734 </papid>and brought about an increase of the metrics correlation with human judgments of translation quality in different languages (apidianaki andhe, 2010).</nextsent>
<nextsent>the use of sense clusters in this setting permits to identify semantic correspondences between translations and hypotheses, and to circumvent the strict requirement for exact surface correspondences, one of the main critics addressed to mtevaluation metrics.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4685">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> cross-lingual sense induction.  </section>
<citcontext>
<prevsection>
<prevsent>containing several semantically correct translations to new instances of words in context (apidianaki, 2009).<papid> E09-1010 </papid></prevsent>
<prevsent>moreover, the use of clustering information during evaluation allows for differing penal ization of wsd errors.</prevsent>
</prevsection>
<citsent citstr=" W07-0734 ">
in an mt evaluation setting, sense clusters have been integrated into anmt evaluation metric (meteor) (lavie and agarwal, 2007) <papid> W07-0734 </papid>and brought about an increase of the metrics correlation with human judgments of translation quality in different languages (apidianaki andhe, 2010).</citsent>
<aftsection>
<nextsent>the use of sense clusters in this setting permits to identify semantic correspondences between translations and hypotheses, and to circumvent the strict requirement for exact surface correspondences, one of the main critics addressed to mtevaluation metrics.
</nextsent>
<nextsent>the same notion of sense clusters has been adopted in the most recent semeval cross-lingual wsd task (lefever and hoste, 2010).
</nextsent>
<nextsent>instead of considering translations as indicators of distinct senses, as was the case in previous tasks, the senses of small number of ambiguous words were described by manually created clusters of transla tions.we consider that the sense cluster inventories created by the unsupervised wsi method proposed by apidianaki (2008) <papid> L08-1585 </papid>would be useful in other applica tive contexts as well and, especially, in clls.</nextsent>
<nextsent>in unsupervised cross-lingual wsd, the clusters constitute the candidate senses from which one has to be selected for each new instance of the words incontext.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4691">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> unsupervised clustering for sense.  </section>
<citcontext>
<prevsection>
<prevsent>before clustering, some preprocessing steps are performed.
</prevsent>
<prevsent>first, the corpus is lemmatized and tagged by pos (schmid, 1994).
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
then sentence pairs presenting great difference in length (i.e cases where one sentence is three times longer than the other) are eliminated and the corpus is aligned at the level of word types using giza++ (och and ney, 2003).<papid> J03-1002 </papid></citsent>
<aftsection>
<nextsent>two bilingual lexicons of content words are built from the alignment results, one for each translation direction (en-sp/sp-en).
</nextsent>
<nextsent>in the entries of these lexicons, source words are associated with the translations to which they are aligned.
</nextsent>
<nextsent>as these lexicons are automatically created, they contain some noise mainly due to spurious word alignments.
</nextsent>
<nextsent>in order to eliminate erroneous translation correspondences, we first apply filter which discards translations with probability below 0.001 (according to the scores assigned during word alignment).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4697">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>in the table) outperforms the 14 systems that participated in the clls task as well as there call (r) and precision (p) baselines.
</prevsent>
<prevsent>it is important to note that, contrary to our method which is totally unsupervised, all the systems that participated in the semeval-2010 task used predefined resources.
</prevsent>
</prevsection>
<citsent citstr=" S10-1025 ">
the second ranked system (swat-e), for instance, performs lexical substitution in english and then translates each substitute into spanish using two predefined bilingual dictionaries, while swat-s does the inverse, performing lexical substitution in the translated text (wicentowski et al, 2010).<papid> S10-1025 </papid></citsent>
<aftsection>
<nextsent>systems p mode mode wsd 180.10 186.25 56.52 58.44 swat-e 174.59 174.59 66.94 66.94 swat-s 97.98 97.98 79.01 79.01 uvt-v 58.91 58.91 62.96 62.96 uvt-g 55.29 55.29 73.94 73.94 dict 44.04 44.04 73.53 73.53 dictcorp 42.65 42.65 71.60 71.60 table 3: oot results (%) another interesting point is that the sense cluster inventory used by the cross-lingual wsd method is derived from europarl, which is the european parliament proceedings parallel corpus (koehn, 2005).
</nextsent>
<nextsent>despite this fact, the wsd method that exploits this inventory performs particularly well on this task which concerns the semantic analysis and translation of words of general language.
</nextsent>
<nextsent>we would thus expect the results to be even better if the sense induc8we report the results obtained by the highest-ranked systems in the semeval-2010 clls task.
</nextsent>
<nextsent>the full table of results can be found in mihalcea et al (2010).<papid> S10-1002 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4702">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the full table of results can be found in mihalcea et al (2010).<papid> S10-1002 </papid>target language context (for instance, by using language model) in order to retain the most adequate translation.</prevsent>
<prevsent>it is interesting to note that the systems that perform better in the best subtask get relatively low results in the oot subtask, and the inverse.</prevsent>
</prevsection>
<citsent citstr=" S10-1054 ">
thisis the case, for instance, for uba-t (basile and semeraro, 2010), <papid> S10-1054 </papid>while aziz and specia (2010) <papid> S10-1024 </papid>clearly specify that their main goal is to maximize the accuracy of their system (uspwlv) in choosing the best translation.</citsent>
<aftsection>
<nextsent>a conclusion that can be drawn is that each subtask has different requirements, which may be satisfied by different types of methods.in order to investigate other possible reasons behind the different behavior of the wsd method inthe two evaluation subtasks, we performed the evaluation separately for each pos.
</nextsent>
<nextsent>the results are presented in tables 5 and 6.
</nextsent>
<nextsent>pos p mode mode adjs 287.94 296.41 72.44 74.43 nouns 127.01 141.65 37.78 42.29 verbs 115.94 121.43 53.17 55.90 advs 111.46 111.46 65.15 65.15 table 5: oot results for different pos (%) pos p mode mode adjs 30.77 31.00 63.56 64.13 nouns 14.61 16.29 25.78 28.86 verbs 14.98 14.98 29.76 29.76 advs 13.07 13.07 37.88 37.88 table 6: best results for different pos (%) in both the oot and best evaluation subtasks, the best scores are obtained for adjectives.
</nextsent>
<nextsent>especially inthe best subtask, where the method seemed to perform worse than the other systems, the recall and precision scores obtained for adjectives (with and without mode) are higher than those obtained by the highest-ranked system (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4703">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>the full table of results can be found in mihalcea et al (2010).<papid> S10-1002 </papid>target language context (for instance, by using language model) in order to retain the most adequate translation.</prevsent>
<prevsent>it is interesting to note that the systems that perform better in the best subtask get relatively low results in the oot subtask, and the inverse.</prevsent>
</prevsection>
<citsent citstr=" S10-1024 ">
thisis the case, for instance, for uba-t (basile and semeraro, 2010), <papid> S10-1054 </papid>while aziz and specia (2010) <papid> S10-1024 </papid>clearly specify that their main goal is to maximize the accuracy of their system (uspwlv) in choosing the best translation.</citsent>
<aftsection>
<nextsent>a conclusion that can be drawn is that each subtask has different requirements, which may be satisfied by different types of methods.in order to investigate other possible reasons behind the different behavior of the wsd method inthe two evaluation subtasks, we performed the evaluation separately for each pos.
</nextsent>
<nextsent>the results are presented in tables 5 and 6.
</nextsent>
<nextsent>pos p mode mode adjs 287.94 296.41 72.44 74.43 nouns 127.01 141.65 37.78 42.29 verbs 115.94 121.43 53.17 55.90 advs 111.46 111.46 65.15 65.15 table 5: oot results for different pos (%) pos p mode mode adjs 30.77 31.00 63.56 64.13 nouns 14.61 16.29 25.78 28.86 verbs 14.98 14.98 29.76 29.76 advs 13.07 13.07 37.88 37.88 table 6: best results for different pos (%) in both the oot and best evaluation subtasks, the best scores are obtained for adjectives.
</nextsent>
<nextsent>especially inthe best subtask, where the method seemed to perform worse than the other systems, the recall and precision scores obtained for adjectives (with and without mode) are higher than those obtained by the highest-ranked system (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4704">
<title id=" W11-2203.xml">unsupervised cross lingual lexical substitution </title>
<section> conclusions and future work.  </section>
<citcontext>
<prevsection>
<prevsent>as unsupervised methods heavily relyon the training data, it would also be interesting to experiment with different corpora in order to evaluate the impact of the type and the size of the corpus on clls.the sense clusters assigned to target word instances during clls contain semantically similar translations of these words, more or less substitutable in the target language context.
</prevsent>
<prevsent>we consider that it would be interesting to integrate target language information in the clls decision process for selecting best translations.
</prevsent>
</prevsection>
<citsent citstr=" H05-1097 ">
given that mt is one of the envisaged applications for this type of task, but the use of full-blown mt system would probably mask system capabilities at lexical level, possibility would be to exploit the clls system suggestions in simplified mt task such as word translation (vickrey et al, 2005) <papid> H05-1097 </papid>or lexical selection (apid ianaki, 2009), <papid> E09-1010 </papid>or in an mt evaluation context.</citsent>
<aftsection>
<nextsent>this would permit to estimate the usefulness of the system suggestions in specific application setting.
</nextsent>



</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4706">
<title id=" W12-0306.xml">focus group on computer tools used for professional writing and preliminary evaluation of linguistech </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper focuses on computer writing tools used during the production of documents, be they letters, newsletters, policies, guidelines, releases or annual reports, in professional setting, what we call professional writing (beaudet, 1998).
</prevsent>
<prevsent>the importance of professional writing in private and public organisations is undeniable as written documents serve as communication between employees, support in decisionmaking and organisational memory.
</prevsent>
</prevsection>
<citsent citstr=" W10-0405 ">
computer tools can be used in variety of writing situations, such as learning how to write in schools (kuhn et al, 2009), learning second language (milton and cheng, 2010), <papid> W10-0405 </papid>and helping people with cognitive, visual or motor disabilities (majaranta and kari-jouko, 2002).</citsent>
<aftsection>
<nextsent>however, our knowledge and understanding of computer tools used by professional writers are somewhat limited.
</nextsent>
<nextsent>which tools are used by professional writers?
</nextsent>
<nextsent>are these tools meeting their needs?
</nextsent>
<nextsent>do writers know what these tools can do?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4707">
<title id=" W12-1613.xml">the structure and generality of spoken route instructions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>generating and interpreting instructions is topic of enduring interest.
</prevsent>
<prevsent>cognitive psychologists have examined how people perceive spatial entities and structure route instructions (daniel and denis, 1998; allen, 1997).
</prevsent>
</prevsection>
<citsent citstr=" L08-1033 ">
linguists and others have investigated how people articulate route instructions in conversation with people or agents (eberhard et al, 2010; gargett et al, 2010; stoia et al, 2008; <papid> L08-1033 </papid>marge and rudnicky, 2010).<papid> W10-4328 </papid></citsent>
<aftsection>
<nextsent>artificial intelligence researchers have shown that under supervised conditions autonomous agents can learn to interpret route instructions (kollar et al, 2010; macmahon et al, 2006; ma tuszek et al, 2010; bugmann et al, 2004; chen and mooney, 2010).
</nextsent>
<nextsent>while the subject has been approached from different perspectives, it has been generally held that the language of directions is mostly limited and only parts of the vocabulary (such as location names) will vary from case to case.
</nextsent>
<nextsent>we are interested in being able to interpret natural directions, as might be given to robot, and generating corresponding trajectory.
</nextsent>
<nextsent>but natural directions contain different types of information, some (more-or-less) easily interpreted (e.g.,  go to the end of the hall ) while others seem daunting (e.g.,  walk past the abstract mural with birds ).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4708">
<title id=" W12-1613.xml">the structure and generality of spoken route instructions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>generating and interpreting instructions is topic of enduring interest.
</prevsent>
<prevsent>cognitive psychologists have examined how people perceive spatial entities and structure route instructions (daniel and denis, 1998; allen, 1997).
</prevsent>
</prevsection>
<citsent citstr=" W10-4328 ">
linguists and others have investigated how people articulate route instructions in conversation with people or agents (eberhard et al, 2010; gargett et al, 2010; stoia et al, 2008; <papid> L08-1033 </papid>marge and rudnicky, 2010).<papid> W10-4328 </papid></citsent>
<aftsection>
<nextsent>artificial intelligence researchers have shown that under supervised conditions autonomous agents can learn to interpret route instructions (kollar et al, 2010; macmahon et al, 2006; ma tuszek et al, 2010; bugmann et al, 2004; chen and mooney, 2010).
</nextsent>
<nextsent>while the subject has been approached from different perspectives, it has been generally held that the language of directions is mostly limited and only parts of the vocabulary (such as location names) will vary from case to case.
</nextsent>
<nextsent>we are interested in being able to interpret natural directions, as might be given to robot, and generating corresponding trajectory.
</nextsent>
<nextsent>but natural directions contain different types of information, some (more-or-less) easily interpreted (e.g.,  go to the end of the hall ) while others seem daunting (e.g.,  walk past the abstract mural with birds ).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4711">
<title id=" W12-1613.xml">the structure and generality of spoken route instructions </title>
<section> understanding experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the concepts in the grammar are listed in the table 5.
</prevsent>
<prevsent>5.1.1 managing variable vocabulary concepts such as locations, pathways and adjectivesof-location use vocabulary that is specific to an environment, and the vocabulary of these concepts will change 104 corpus #instr words/instr environmnt modality h/r-h/r lifting device pathways landmarks adjectives nav 934 9 univ campus speech human-human 0.029 0.046 0.169 0.13 mit 684 15 univ campus written human-human 0.045 0.016 0.163 0.062 ibl 769 8 model city speech human-robot n.a. 0.039 0.076 0.13 ttalk 1619 7 open space speech human-robot n.a. 0.027 0.01 0.039 figure 4: (a) nature of the corpora (b) type-token ratio of concepts across corpora table 5: higher level and leaf node concepts in grammar category concepts examples imperative goto place, turn, etc conditional imperative move_until_x where is condition advisory instructions you_will_see_location grounding instructions you_are_at_location auxillary concepts examples locations buildings, other landmarks on the route adjectives-of-locations large, open, black, small etc. pathways hallway, corridor, bridge, doors, etc. lifting device elevator, staircase, stairwell, etc. spatial relations behind, above, on right, on left, etc. numbers turn-angles, distance, etc. ordin als first, second as in floor numbers filler phrases you may want to; you are gonna; etc.with surroundings.
</prevsent>
</prevsection>
<citsent citstr=" N03-1033 ">
we used an off-the-shelf part-of speech tagger (toutanova et al, 2003) <papid> N03-1033 </papid>on nav-train to identify location-based?</citsent>
<aftsection>
<nextsent>nouns and adjectives.
</nextsent>
<nextsent>these were added to the grammar as instances of their respective concepts.
</nextsent>
<nextsent>5.2 parsing nav instructions.
</nextsent>
<nextsent>a parse can fall into one of the following categories: 1) complete: clean and correct parse with all concepts and actions mentioned in the instruction.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4714">
<title id=" W11-2036.xml">examining the impacts of dialogue content and system automation on affect models in a spoken tutorial dialogue system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>(2010) observed similar poor performance when porting their dialogue act classifier between threecorpora: switchboard, the meeting recorder dialog act corpus, and machine-translated version ofthe spanish call home corpus.
</prevsent>
<prevsent>they report promising results through varying their feature set.
</prevsent>
</prevsection>
<citsent citstr=" P07-1056 ">
blitzer et al (2007) <papid> P07-1056 </papid>also observed poor performance and the need for adaptation when porting product review sentiment classifiers.</citsent>
<aftsection>
<nextsent>they used four review corpora from amazon (books, dvds, electronics, and smallappliances), which yielded 12 cross-domain training/testing pairs.
</nextsent>
<nextsent>their algorithmic adaptation methods showed promising results.our work is in the first direction, as we also empirically analyze the impact of differences in training and testing corpora to demonstrate the need for adaptation methods.
</nextsent>
<nextsent>however, our work differs from domain adaptation, as the corpora in this experiment all come from one intelligent spoken physics tutor.instead, we analyze differences resulting from vary 312ing levels of automation and small changes india logue content between versions of our system.with respect to analyzing automation, we empirically compare the impact of differences in training on data from wizarded (woz) versus fully automated systems.
</nextsent>
<nextsent>though many systems use data from woz version of the system to train models which are then used in fully automated versions ofthe system, the effectiveness of this method of dialogue system development has not been tested.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4715">
<title id=" W12-1914.xml">hierarchical clustering of word class distributions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this simple labeler outperforms baseline based on brown clusters on 9 out of 10 datasets.
</prevsent>
<prevsent>unsupervised induction of word categories has been approached from three broad perspectives.
</prevsent>
</prevsection>
<citsent citstr=" W08-2112 ">
first, it isof interest to cognitive scientists who model syntactic category acquisition by children (redington et al  1998, mintz 2003, parisien et al  2008, <papid> W08-2112 </papid>chrupaa and alishahi 2010), where the primary concern is matching human performance patterns and satisfying cog nit ively motivated constraints such as incremental learning.</citsent>
<aftsection>
<nextsent>second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes ravi and knight (2009), <papid> P09-1057 </papid>lee et al  (2010), <papid> D10-1083 </papid>lamar et al  (2010), <papid> P10-2040 </papid>christodoulopoulos et al  (2011)), <papid> D11-1059 </papid>and primarily motivated as useful for tagging under-resourced languages.finally, learning categories has also been researched from the point of view of feature learning,where the induced categories provide an intermediate level of representation, abstracting away and generalizing over word form features in an nlp application (brown et al  1992, <papid> J92-4003 </papid>miller et al  2004, <papid> N04-1043 </papid>lin and wu 2009, <papid> P09-1116 </papid>turian et al  2010, <papid> P10-1040 </papid>chrupala 2011, tack strom et al  2012).</nextsent>
<nextsent>the main difference fromthe part-of-speech setting is that the focus is on evaluating the performance of the learned categories in real tasks rather than on measuring how closely they match gold part-of-speech tags.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4716">
<title id=" W12-1914.xml">hierarchical clustering of word class distributions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised induction of word categories has been approached from three broad perspectives.
</prevsent>
<prevsent>first, it isof interest to cognitive scientists who model syntactic category acquisition by children (redington et al  1998, mintz 2003, parisien et al  2008, <papid> W08-2112 </papid>chrupaa and alishahi 2010), where the primary concern is matching human performance patterns and satisfying cog nit ively motivated constraints such as incremental learning.</prevsent>
</prevsection>
<citsent citstr=" P09-1057 ">
second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes ravi and knight (2009), <papid> P09-1057 </papid>lee et al  (2010), <papid> D10-1083 </papid>lamar et al  (2010), <papid> P10-2040 </papid>christodoulopoulos et al  (2011)), <papid> D11-1059 </papid>and primarily motivated as useful for tagging under-resourced languages.finally, learning categories has also been researched from the point of view of feature learning,where the induced categories provide an intermediate level of representation, abstracting away and generalizing over word form features in an nlp application (brown et al  1992, <papid> J92-4003 </papid>miller et al  2004, <papid> N04-1043 </papid>lin and wu 2009, <papid> P09-1116 </papid>turian et al  2010, <papid> P10-1040 </papid>chrupala 2011, tack strom et al  2012).</citsent>
<aftsection>
<nextsent>the main difference fromthe part-of-speech setting is that the focus is on evaluating the performance of the learned categories in real tasks rather than on measuring how closely they match gold part-of-speech tags.
</nextsent>
<nextsent>some researchers have used both approaches to evaluation.
</nextsent>
<nextsent>this difference in evaluation methodology also naturally leads to differing constraints on the nature of the induced representations.
</nextsent>
<nextsent>for part-of-speechtagging what is needed is mapping from word tokens to small set of discrete, atomic labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4717">
<title id=" W12-1914.xml">hierarchical clustering of word class distributions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised induction of word categories has been approached from three broad perspectives.
</prevsent>
<prevsent>first, it isof interest to cognitive scientists who model syntactic category acquisition by children (redington et al  1998, mintz 2003, parisien et al  2008, <papid> W08-2112 </papid>chrupaa and alishahi 2010), where the primary concern is matching human performance patterns and satisfying cog nit ively motivated constraints such as incremental learning.</prevsent>
</prevsection>
<citsent citstr=" D10-1083 ">
second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes ravi and knight (2009), <papid> P09-1057 </papid>lee et al  (2010), <papid> D10-1083 </papid>lamar et al  (2010), <papid> P10-2040 </papid>christodoulopoulos et al  (2011)), <papid> D11-1059 </papid>and primarily motivated as useful for tagging under-resourced languages.finally, learning categories has also been researched from the point of view of feature learning,where the induced categories provide an intermediate level of representation, abstracting away and generalizing over word form features in an nlp application (brown et al  1992, <papid> J92-4003 </papid>miller et al  2004, <papid> N04-1043 </papid>lin and wu 2009, <papid> P09-1116 </papid>turian et al  2010, <papid> P10-1040 </papid>chrupala 2011, tack strom et al  2012).</citsent>
<aftsection>
<nextsent>the main difference fromthe part-of-speech setting is that the focus is on evaluating the performance of the learned categories in real tasks rather than on measuring how closely they match gold part-of-speech tags.
</nextsent>
<nextsent>some researchers have used both approaches to evaluation.
</nextsent>
<nextsent>this difference in evaluation methodology also naturally leads to differing constraints on the nature of the induced representations.
</nextsent>
<nextsent>for part-of-speechtagging what is needed is mapping from word tokens to small set of discrete, atomic labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4718">
<title id=" W12-1914.xml">hierarchical clustering of word class distributions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised induction of word categories has been approached from three broad perspectives.
</prevsent>
<prevsent>first, it isof interest to cognitive scientists who model syntactic category acquisition by children (redington et al  1998, mintz 2003, parisien et al  2008, <papid> W08-2112 </papid>chrupaa and alishahi 2010), where the primary concern is matching human performance patterns and satisfying cog nit ively motivated constraints such as incremental learning.</prevsent>
</prevsection>
<citsent citstr=" P10-2040 ">
second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes ravi and knight (2009), <papid> P09-1057 </papid>lee et al  (2010), <papid> D10-1083 </papid>lamar et al  (2010), <papid> P10-2040 </papid>christodoulopoulos et al  (2011)), <papid> D11-1059 </papid>and primarily motivated as useful for tagging under-resourced languages.finally, learning categories has also been researched from the point of view of feature learning,where the induced categories provide an intermediate level of representation, abstracting away and generalizing over word form features in an nlp application (brown et al  1992, <papid> J92-4003 </papid>miller et al  2004, <papid> N04-1043 </papid>lin and wu 2009, <papid> P09-1116 </papid>turian et al  2010, <papid> P10-1040 </papid>chrupala 2011, tack strom et al  2012).</citsent>
<aftsection>
<nextsent>the main difference fromthe part-of-speech setting is that the focus is on evaluating the performance of the learned categories in real tasks rather than on measuring how closely they match gold part-of-speech tags.
</nextsent>
<nextsent>some researchers have used both approaches to evaluation.
</nextsent>
<nextsent>this difference in evaluation methodology also naturally leads to differing constraints on the nature of the induced representations.
</nextsent>
<nextsent>for part-of-speechtagging what is needed is mapping from word tokens to small set of discrete, atomic labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4719">
<title id=" W12-1914.xml">hierarchical clustering of word class distributions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised induction of word categories has been approached from three broad perspectives.
</prevsent>
<prevsent>first, it isof interest to cognitive scientists who model syntactic category acquisition by children (redington et al  1998, mintz 2003, parisien et al  2008, <papid> W08-2112 </papid>chrupaa and alishahi 2010), where the primary concern is matching human performance patterns and satisfying cog nit ively motivated constraints such as incremental learning.</prevsent>
</prevsection>
<citsent citstr=" D11-1059 ">
second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes ravi and knight (2009), <papid> P09-1057 </papid>lee et al  (2010), <papid> D10-1083 </papid>lamar et al  (2010), <papid> P10-2040 </papid>christodoulopoulos et al  (2011)), <papid> D11-1059 </papid>and primarily motivated as useful for tagging under-resourced languages.finally, learning categories has also been researched from the point of view of feature learning,where the induced categories provide an intermediate level of representation, abstracting away and generalizing over word form features in an nlp application (brown et al  1992, <papid> J92-4003 </papid>miller et al  2004, <papid> N04-1043 </papid>lin and wu 2009, <papid> P09-1116 </papid>turian et al  2010, <papid> P10-1040 </papid>chrupala 2011, tack strom et al  2012).</citsent>
<aftsection>
<nextsent>the main difference fromthe part-of-speech setting is that the focus is on evaluating the performance of the learned categories in real tasks rather than on measuring how closely they match gold part-of-speech tags.
</nextsent>
<nextsent>some researchers have used both approaches to evaluation.
</nextsent>
<nextsent>this difference in evaluation methodology also naturally leads to differing constraints on the nature of the induced representations.
</nextsent>
<nextsent>for part-of-speechtagging what is needed is mapping from word tokens to small set of discrete, atomic labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4720">
<title id=" W12-1914.xml">hierarchical clustering of word class distributions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised induction of word categories has been approached from three broad perspectives.
</prevsent>
<prevsent>first, it isof interest to cognitive scientists who model syntactic category acquisition by children (redington et al  1998, mintz 2003, parisien et al  2008, <papid> W08-2112 </papid>chrupaa and alishahi 2010), where the primary concern is matching human performance patterns and satisfying cog nit ively motivated constraints such as incremental learning.</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes ravi and knight (2009), <papid> P09-1057 </papid>lee et al  (2010), <papid> D10-1083 </papid>lamar et al  (2010), <papid> P10-2040 </papid>christodoulopoulos et al  (2011)), <papid> D11-1059 </papid>and primarily motivated as useful for tagging under-resourced languages.finally, learning categories has also been researched from the point of view of feature learning,where the induced categories provide an intermediate level of representation, abstracting away and generalizing over word form features in an nlp application (brown et al  1992, <papid> J92-4003 </papid>miller et al  2004, <papid> N04-1043 </papid>lin and wu 2009, <papid> P09-1116 </papid>turian et al  2010, <papid> P10-1040 </papid>chrupala 2011, tack strom et al  2012).</citsent>
<aftsection>
<nextsent>the main difference fromthe part-of-speech setting is that the focus is on evaluating the performance of the learned categories in real tasks rather than on measuring how closely they match gold part-of-speech tags.
</nextsent>
<nextsent>some researchers have used both approaches to evaluation.
</nextsent>
<nextsent>this difference in evaluation methodology also naturally leads to differing constraints on the nature of the induced representations.
</nextsent>
<nextsent>for part-of-speechtagging what is needed is mapping from word tokens to small set of discrete, atomic labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4721">
<title id=" W12-1914.xml">hierarchical clustering of word class distributions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised induction of word categories has been approached from three broad perspectives.
</prevsent>
<prevsent>first, it isof interest to cognitive scientists who model syntactic category acquisition by children (redington et al  1998, mintz 2003, parisien et al  2008, <papid> W08-2112 </papid>chrupaa and alishahi 2010), where the primary concern is matching human performance patterns and satisfying cog nit ively motivated constraints such as incremental learning.</prevsent>
</prevsection>
<citsent citstr=" N04-1043 ">
second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes ravi and knight (2009), <papid> P09-1057 </papid>lee et al  (2010), <papid> D10-1083 </papid>lamar et al  (2010), <papid> P10-2040 </papid>christodoulopoulos et al  (2011)), <papid> D11-1059 </papid>and primarily motivated as useful for tagging under-resourced languages.finally, learning categories has also been researched from the point of view of feature learning,where the induced categories provide an intermediate level of representation, abstracting away and generalizing over word form features in an nlp application (brown et al  1992, <papid> J92-4003 </papid>miller et al  2004, <papid> N04-1043 </papid>lin and wu 2009, <papid> P09-1116 </papid>turian et al  2010, <papid> P10-1040 </papid>chrupala 2011, tack strom et al  2012).</citsent>
<aftsection>
<nextsent>the main difference fromthe part-of-speech setting is that the focus is on evaluating the performance of the learned categories in real tasks rather than on measuring how closely they match gold part-of-speech tags.
</nextsent>
<nextsent>some researchers have used both approaches to evaluation.
</nextsent>
<nextsent>this difference in evaluation methodology also naturally leads to differing constraints on the nature of the induced representations.
</nextsent>
<nextsent>for part-of-speechtagging what is needed is mapping from word tokens to small set of discrete, atomic labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4722">
<title id=" W12-1914.xml">hierarchical clustering of word class distributions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised induction of word categories has been approached from three broad perspectives.
</prevsent>
<prevsent>first, it isof interest to cognitive scientists who model syntactic category acquisition by children (redington et al  1998, mintz 2003, parisien et al  2008, <papid> W08-2112 </papid>chrupaa and alishahi 2010), where the primary concern is matching human performance patterns and satisfying cog nit ively motivated constraints such as incremental learning.</prevsent>
</prevsection>
<citsent citstr=" P09-1116 ">
second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes ravi and knight (2009), <papid> P09-1057 </papid>lee et al  (2010), <papid> D10-1083 </papid>lamar et al  (2010), <papid> P10-2040 </papid>christodoulopoulos et al  (2011)), <papid> D11-1059 </papid>and primarily motivated as useful for tagging under-resourced languages.finally, learning categories has also been researched from the point of view of feature learning,where the induced categories provide an intermediate level of representation, abstracting away and generalizing over word form features in an nlp application (brown et al  1992, <papid> J92-4003 </papid>miller et al  2004, <papid> N04-1043 </papid>lin and wu 2009, <papid> P09-1116 </papid>turian et al  2010, <papid> P10-1040 </papid>chrupala 2011, tack strom et al  2012).</citsent>
<aftsection>
<nextsent>the main difference fromthe part-of-speech setting is that the focus is on evaluating the performance of the learned categories in real tasks rather than on measuring how closely they match gold part-of-speech tags.
</nextsent>
<nextsent>some researchers have used both approaches to evaluation.
</nextsent>
<nextsent>this difference in evaluation methodology also naturally leads to differing constraints on the nature of the induced representations.
</nextsent>
<nextsent>for part-of-speechtagging what is needed is mapping from word tokens to small set of discrete, atomic labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4723">
<title id=" W12-1914.xml">hierarchical clustering of word class distributions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>unsupervised induction of word categories has been approached from three broad perspectives.
</prevsent>
<prevsent>first, it isof interest to cognitive scientists who model syntactic category acquisition by children (redington et al  1998, mintz 2003, parisien et al  2008, <papid> W08-2112 </papid>chrupaa and alishahi 2010), where the primary concern is matching human performance patterns and satisfying cog nit ively motivated constraints such as incremental learning.</prevsent>
</prevsection>
<citsent citstr=" P10-1040 ">
second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes ravi and knight (2009), <papid> P09-1057 </papid>lee et al  (2010), <papid> D10-1083 </papid>lamar et al  (2010), <papid> P10-2040 </papid>christodoulopoulos et al  (2011)), <papid> D11-1059 </papid>and primarily motivated as useful for tagging under-resourced languages.finally, learning categories has also been researched from the point of view of feature learning,where the induced categories provide an intermediate level of representation, abstracting away and generalizing over word form features in an nlp application (brown et al  1992, <papid> J92-4003 </papid>miller et al  2004, <papid> N04-1043 </papid>lin and wu 2009, <papid> P09-1116 </papid>turian et al  2010, <papid> P10-1040 </papid>chrupala 2011, tack strom et al  2012).</citsent>
<aftsection>
<nextsent>the main difference fromthe part-of-speech setting is that the focus is on evaluating the performance of the learned categories in real tasks rather than on measuring how closely they match gold part-of-speech tags.
</nextsent>
<nextsent>some researchers have used both approaches to evaluation.
</nextsent>
<nextsent>this difference in evaluation methodology also naturally leads to differing constraints on the nature of the induced representations.
</nextsent>
<nextsent>for part-of-speechtagging what is needed is mapping from word tokens to small set of discrete, atomic labels.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4724">
<title id=" W12-1914.xml">hierarchical clustering of word class distributions </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we then label the development set using path prefixes of length ? {8, 9, . . .
</prevsent>
<prevsent>, 20} for each of the trees, and record1we ran 200 gibbs sampling passes, and set the lda hyper parameters to ? = 10k and ? = 0.1.
</prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
102 dataset l brown hcd arabic 40 13 39.6 51.4 basque 40 16 39.5 48.3 czech 80 8 42.1 42.4 danish 40 19 50.2 56.8 dutch 40 10 43.3 54.8 english ch 10 12 64.1 67.8 english ptb 40 8 61.6 60.2 portuguese 80 10 51.7 52.4 slovene 80 19 44.5 46.6 swedish 20 17 51.8 56.1 table 1: evaluation of coarse-grained pos tagging on test data dataset l brown hcd arabic 40 13 42.2 52.9 basque 40 16 38.5 54.4 czech 40 19 45.3 46.8 danish 40 20 49.2 63.6 dutch 20 12 49.4 53.4 english ch 10 12 66.0 78.2 english ptb 80 14 62.0 61.3 portuguese 80 11 52.9 54.7 slovene 80 20 45.8 51.9 swedish 20 17 51.8 56.1 table 2: evaluation of coarse-grained pos tagging on test data the v-measure (rosenberg and hirschberg 2007) <papid> D07-1043 </papid>against gold part-of-speech tags.</citsent>
<aftsection>
<nextsent>we choose the best-performing pair ofk and and use this setting to label the test set.
</nextsent>
<nextsent>we tune separately for coarse grained and fine-grained pos tags.
</nextsent>
<nextsent>other than using the development set labels to tune these two parameters our system is unsupervised and uses no data other than the sentences in the provided data files.
</nextsent>
<nextsent>table 1 and table 2 show the best settings for the coarse- and fine-grained pos tagging for all the datasets, and the v-measure scores on the test set achieved by our labeler (hcd for hierarchy over class distributions).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4726">
<title id=" W11-2124.xml">wider context by using bilingual language models in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we could show improvements of translation quality on german-to-english and arabic-to-english.
</prevsent>
<prevsent>in addition, for the arabic-to-english task, training an extra bilingual language model on the pos tags instead of the surface word forms led to further improvements.
</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
in many state-of-the art smt systems, the phrase based (koehn et al, 2003) <papid> N03-1017 </papid>approach is used.</citsent>
<aftsection>
<nextsent>in this approach, instead of building the translation by translating word by word, sequences of source and target words, so-called phrase pairs, are used as the basic translation unit.
</nextsent>
<nextsent>a table of correspondences between source and target phrases forms the translation model in this approach.
</nextsent>
<nextsent>target language fluency is modeled by language model storing monolingual n-gram occurrences.
</nextsent>
<nextsent>a log-linear combination of these main models as well as additional features is used to score the different translation hypotheses.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4727">
<title id=" W11-2124.xml">wider context by using bilingual language models in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>target language fluency is modeled by language model storing monolingual n-gram occurrences.
</prevsent>
<prevsent>a log-linear combination of these main models as well as additional features is used to score the different translation hypotheses.
</prevsent>
</prevsection>
<citsent citstr=" J04-2004 ">
then the decoder searches for the translation with the highest score.a different approach to smt is to use stochastic finite state transducer based on bilingual ngrams (casacuberta and vidal, 2004).<papid> J04-2004 </papid></citsent>
<aftsection>
<nextsent>this approach was for example successfully applied by allauzen et al (2010) <papid> W10-1704 </papid>on the french-english translation task.</nextsent>
<nextsent>in this so-called n-gram approach the translation model is trained by using an n-gram language model of pairs of source and target words,called tuples.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4728">
<title id=" W11-2124.xml">wider context by using bilingual language models in machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>a log-linear combination of these main models as well as additional features is used to score the different translation hypotheses.
</prevsent>
<prevsent>then the decoder searches for the translation with the highest score.a different approach to smt is to use stochastic finite state transducer based on bilingual ngrams (casacuberta and vidal, 2004).<papid> J04-2004 </papid></prevsent>
</prevsection>
<citsent citstr=" W10-1704 ">
this approach was for example successfully applied by allauzen et al (2010) <papid> W10-1704 </papid>on the french-english translation task.</citsent>
<aftsection>
<nextsent>in this so-called n-gram approach the translation model is trained by using an n-gram language model of pairs of source and target words,called tuples.
</nextsent>
<nextsent>while the phrase-based approach captures only bilingual context within the phrase pairs, in the n-gram approach the n-gram model trained onthe tuples is used to capture bilingual context between the tuples.
</nextsent>
<nextsent>as in the phrase-based approach,the translation model can also be combined with additional models like, for example, language models using log-linear combination.inspired by the n-gram-based approach, we introduce bilingual language model that extends the translation model of the phrase-based smt approach by providing bilingual word context.
</nextsent>
<nextsent>in addition to the bilingual word context, this approach enables us also to integrate bilingual context based on part of speech (pos) into the translation model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4730">
<title id=" W11-2124.xml">wider context by using bilingual language models in machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>asit is also done in phrase-based translations, the different translations are scored by log-linear combination of the translation model and additional models.
</prevsent>
<prevsent>crego and yvon (2010) extended the approach to be able to handle different word factors.
</prevsent>
</prevsection>
<citsent citstr=" N03-2002 ">
they used factored language models introduced by bilmes and kirchhoff (2003) <papid> N03-2002 </papid>to integrate different word factors into the translation process.</citsent>
<aftsection>
<nextsent>in contrast, we use alog-linear combination of language models on different factors in our approach.
</nextsent>
<nextsent>a first approach of integrating the idea presented in the n-gram approach into phrase-based machine translation was described in matusov et al (2006).
</nextsent>
<nextsent>in contrast to our work, they used the bilingual units as defined in the original approach and they did not use additional word factors.hasan et al (2008) <papid> D08-1039 </papid>used lexicalized triplets to introduce bilingual context into the translation process.</nextsent>
<nextsent>these triplets include source words from out side the phrase and form and additional probabilityp(f |e, e?)</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4731">
<title id=" W11-2124.xml">wider context by using bilingual language models in machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, we use alog-linear combination of language models on different factors in our approach.
</prevsent>
<prevsent>a first approach of integrating the idea presented in the n-gram approach into phrase-based machine translation was described in matusov et al (2006).
</prevsent>
</prevsection>
<citsent citstr=" D08-1039 ">
in contrast to our work, they used the bilingual units as defined in the original approach and they did not use additional word factors.hasan et al (2008) <papid> D08-1039 </papid>used lexicalized triplets to introduce bilingual context into the translation process.</citsent>
<aftsection>
<nextsent>these triplets include source words from out side the phrase and form and additional probabilityp(f |e, e?)
</nextsent>
<nextsent>that modifies the conventional word probability of given depending on trigger words e?
</nextsent>
<nextsent>in the sentence enabling context-based translation of ambiguous phrases.other approaches address this problem by integrating word sense disambiguation engines into phrase-based smt system.
</nextsent>
<nextsent>in chan and ng (2007)a classifier exploits information such as local collocations, parts-of-speech or surrounding words to determine the lexical choice of target words, while carpuat and wu (2007) <papid> D07-1007 </papid>use rich context features based on position, syntax and local collocations to dynamically adapt the lexicons for each sentence and facilitate the choice of longer phrases.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4732">
<title id=" W11-2124.xml">wider context by using bilingual language models in machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>that modifies the conventional word probability of given depending on trigger words e?
</prevsent>
<prevsent>in the sentence enabling context-based translation of ambiguous phrases.other approaches address this problem by integrating word sense disambiguation engines into phrase-based smt system.
</prevsent>
</prevsection>
<citsent citstr=" D07-1007 ">
in chan and ng (2007)a classifier exploits information such as local collocations, parts-of-speech or surrounding words to determine the lexical choice of target words, while carpuat and wu (2007) <papid> D07-1007 </papid>use rich context features based on position, syntax and local collocations to dynamically adapt the lexicons for each sentence and facilitate the choice of longer phrases.</citsent>
<aftsection>
<nextsent>in this work we present method to extend the locally limited context of phrase pairs and n-grams by using bilingual language models.
</nextsent>
<nextsent>we keep the phrase-based approach as the main smt framework and introduce an n-gram language model trained in asimilar way as the one used in the finite state transducer approach as an additional feature in the loglinear model.
</nextsent>
<nextsent>to motivate the introduction of the bilingual language model, we will analyze the bilingual context that is used when selecting the target words.
</nextsent>
<nextsent>in phrase-based system, this context is limited by the phrase boundaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4733">
<title id=" W11-2124.xml">wider context by using bilingual language models in machine translation </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the german-to-english translation system was trained on the european parliament corpus, news commentary corpus and small amounts of additional web data.
</prevsent>
<prevsent>the data was preprocessed and compound splitting was applied.
</prevsent>
</prevsection>
<citsent citstr=" W08-0303 ">
afterwards the discriminative word alignment approach as described in (niehues and vogel, 2008) <papid> W08-0303 </papid>was applied to generate the alignments between source and target words.</citsent>
<aftsection>
<nextsent>the phrase table was built using the scripts from the moses package (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>the language model was trained on the target side of the parallel data as well as on additional monolingual news data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4734">
<title id=" W11-2124.xml">wider context by using bilingual language models in machine translation </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the data was preprocessed and compound splitting was applied.
</prevsent>
<prevsent>afterwards the discriminative word alignment approach as described in (niehues and vogel, 2008) <papid> W08-0303 </papid>was applied to generate the alignments between source and target words.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
the phrase table was built using the scripts from the moses package (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>the language model was trained on the target side of the parallel data as well as on additional monolingual news data.
</nextsent>
<nextsent>the translation model as well as the language model was adapted towards the target domain in log-linear way.the arabic-to-english system was trained using gale arabic data, which contains 6.1m sentences.
</nextsent>
<nextsent>the word alignment is generated using emdc, which is combination of discriminative approach and the ibm models as described in gao et al (2010).<papid> C10-1040 </papid></nextsent>
<nextsent>the phrase table is generated using chaski as described in gao and vogel (2010).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4735">
<title id=" W11-2124.xml">wider context by using bilingual language models in machine translation </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>the language model was trained on the target side of the parallel data as well as on additional monolingual news data.
</prevsent>
<prevsent>the translation model as well as the language model was adapted towards the target domain in log-linear way.the arabic-to-english system was trained using gale arabic data, which contains 6.1m sentences.
</prevsent>
</prevsection>
<citsent citstr=" C10-1040 ">
the word alignment is generated using emdc, which is combination of discriminative approach and the ibm models as described in gao et al (2010).<papid> C10-1040 </papid></citsent>
<aftsection>
<nextsent>the phrase table is generated using chaski as described in gao and vogel (2010).
</nextsent>
<nextsent>the language model data we trained on the gigaword 202 v3 data plus bbn english data.
</nextsent>
<nextsent>after splitting the corpus according to sources, individual models weretrained.
</nextsent>
<nextsent>then the individual models were interpolated to minimize the perplexity on the mt03/mt04 data.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4736">
<title id=" W11-2124.xml">wider context by using bilingual language models in machine translation </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>after splitting the corpus according to sources, individual models weretrained.
</prevsent>
<prevsent>then the individual models were interpolated to minimize the perplexity on the mt03/mt04 data.
</prevsent>
</prevsection>
<citsent citstr=" C94-1027 ">
for both tasks the reordering was performed as preprocessing step using pos information from the tree tagger (schmid, 1994) <papid> C94-1027 </papid>for german and using the amira tagger (diab, 2009) for arabic.</citsent>
<aftsection>
<nextsent>for arabic the approach described in rottmann and vogel (2007) was used covering short-range reorderings.for the german-to-english translation task the extended approach described in niehues et al (2009) <papid> W09-0413 </papid>was used to cover also the long-range reorderings typical when translating between german and en glish.for both directions an in-house phrase-based decoder (vogel, 2003) was used to generate the translation hypotheses and the optimization was performed using mer training.</nextsent>
<nextsent>the performance on the test sets were measured in case-insensitive bleu and ter scores.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4737">
<title id=" W11-2124.xml">wider context by using bilingual language models in machine translation </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>then the individual models were interpolated to minimize the perplexity on the mt03/mt04 data.
</prevsent>
<prevsent>for both tasks the reordering was performed as preprocessing step using pos information from the tree tagger (schmid, 1994) <papid> C94-1027 </papid>for german and using the amira tagger (diab, 2009) for arabic.</prevsent>
</prevsection>
<citsent citstr=" W09-0413 ">
for arabic the approach described in rottmann and vogel (2007) was used covering short-range reorderings.for the german-to-english translation task the extended approach described in niehues et al (2009) <papid> W09-0413 </papid>was used to cover also the long-range reorderings typical when translating between german and en glish.for both directions an in-house phrase-based decoder (vogel, 2003) was used to generate the translation hypotheses and the optimization was performed using mer training.</citsent>
<aftsection>
<nextsent>the performance on the test sets were measured in case-insensitive bleu and ter scores.
</nextsent>
<nextsent>5.2 german to english.
</nextsent>
<nextsent>we evaluated the approach on two different test sets from the news commentary domain.
</nextsent>
<nextsent>the first consists of 2000 sentences with one reference.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4738">
<title id=" W11-2022.xml">multilingual annotation and disambiguation of discourse connectives for machine translation </title>
<section> explicit connectives and their.  </section>
<citcontext>
<prevsection>
<prevsent>translation 2.1 three multi-functional connectives.
</prevsent>
<prevsent>discourse connectives form functional category of lexical items that are used to mark coherence relations such as cause or contrast between units of discourse.
</prevsent>
</prevsection>
<citsent citstr=" W11-1211 ">
along with other function words, many connectives appear among the most frequent words, as shown for instance by counts (cartoni et al, 2011) <papid> W11-1211 </papid>over the europarl corpus (koehn, 2005).</citsent>
<aftsection>
<nextsent>the penn discourse treebank (prasad et al, 2008) (<papid> L08-1093 </papid>see section 3.1 below) includes around 100 connective types, but the exact number varies across studies, 194 depending on the discourse theory used to classify them.</nextsent>
<nextsent>among these types, pitler et al(2008) <papid> C08-2022 </papid>have shown that most of them are unambiguous and easyto identify, but others, especially temporal ones, often signal multiple senses depending on their con text.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4739">
<title id=" W11-2022.xml">multilingual annotation and disambiguation of discourse connectives for machine translation </title>
<section> explicit connectives and their.  </section>
<citcontext>
<prevsection>
<prevsent>discourse connectives form functional category of lexical items that are used to mark coherence relations such as cause or contrast between units of discourse.
</prevsent>
<prevsent>along with other function words, many connectives appear among the most frequent words, as shown for instance by counts (cartoni et al, 2011) <papid> W11-1211 </papid>over the europarl corpus (koehn, 2005).</prevsent>
</prevsection>
<citsent citstr=" L08-1093 ">
the penn discourse treebank (prasad et al, 2008) (<papid> L08-1093 </papid>see section 3.1 below) includes around 100 connective types, but the exact number varies across studies, 194 depending on the discourse theory used to classify them.</citsent>
<aftsection>
<nextsent>among these types, pitler et al(2008) <papid> C08-2022 </papid>have shown that most of them are unambiguous and easyto identify, but others, especially temporal ones, often signal multiple senses depending on their con text.</nextsent>
<nextsent>following the terminology of petukhova and bunt (2009, <papid> W09-3715 </papid>section 2), we are interested here in sequential?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4740">
<title id=" W11-2022.xml">multilingual annotation and disambiguation of discourse connectives for machine translation </title>
<section> explicit connectives and their.  </section>
<citcontext>
<prevsection>
<prevsent>along with other function words, many connectives appear among the most frequent words, as shown for instance by counts (cartoni et al, 2011) <papid> W11-1211 </papid>over the europarl corpus (koehn, 2005).</prevsent>
<prevsent>the penn discourse treebank (prasad et al, 2008) (<papid> L08-1093 </papid>see section 3.1 below) includes around 100 connective types, but the exact number varies across studies, 194 depending on the discourse theory used to classify them.</prevsent>
</prevsection>
<citsent citstr=" C08-2022 ">
among these types, pitler et al(2008) <papid> C08-2022 </papid>have shown that most of them are unambiguous and easyto identify, but others, especially temporal ones, often signal multiple senses depending on their con text.</citsent>
<aftsection>
<nextsent>following the terminology of petukhova and bunt (2009, <papid> W09-3715 </papid>section 2), we are interested here in sequential?</nextsent>
<nextsent>multi-functionality, i.e. the fact that thesame connective can signal different relations in different contexts.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4741">
<title id=" W11-2022.xml">multilingual annotation and disambiguation of discourse connectives for machine translation </title>
<section> explicit connectives and their.  </section>
<citcontext>
<prevsection>
<prevsent>the penn discourse treebank (prasad et al, 2008) (<papid> L08-1093 </papid>see section 3.1 below) includes around 100 connective types, but the exact number varies across studies, 194 depending on the discourse theory used to classify them.</prevsent>
<prevsent>among these types, pitler et al(2008) <papid> C08-2022 </papid>have shown that most of them are unambiguous and easyto identify, but others, especially temporal ones, often signal multiple senses depending on their con text.</prevsent>
</prevsection>
<citsent citstr=" W09-3715 ">
following the terminology of petukhova and bunt (2009, <papid> W09-3715 </papid>section 2), we are interested here in sequential?</citsent>
<aftsection>
<nextsent>multi-functionality, i.e. the fact that thesame connective can signal different relations in different contexts.
</nextsent>
<nextsent>we do not deal with simultane ous?
</nextsent>
<nextsent>multi-functionality, i.e. the possibility for single occurrence to signal several relations, which has been less frequently studied for connectives (see petukhova and bunt (2009) <papid> W09-3715 </papid>for the discourse usage of and).</nextsent>
<nextsent>we identified the two english connectives while and since, along with the french connective alors que, as being particularly problematic because theyare highly multi-functional, i.e. they can signal multiple senses.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4743">
<title id=" W11-2022.xml">multilingual annotation and disambiguation of discourse connectives for machine translation </title>
<section> explicit connectives and their.  </section>
<citcontext>
<prevsection>
<prevsent>the disambiguation of such connectives in source text is crucial for its translation, because each sense may be translated by different connective and/or syntactical construct in the target language.
</prevsent>
<prevsent>more specifically, we hypothesize that correctly labeled connectives are easier to learn and to translate by statistical mt systems than unlabeled ones.
</prevsent>
</prevsection>
<citsent citstr=" P11-3009 ">
to support this hypothesis, we set up an experiment(meyer, 2011) <papid> P11-3009 </papid>in which we constrained the translation of the three senses of the discourse connective while that were previously annotated as temporal, contrast and concession.</citsent>
<aftsection>
<nextsent>the system was forced touse predefined french translations known to be correct, by directly modifying the phrase table of the trained mt system.
</nextsent>
<nextsent>this modification noticeably helped to improve translation quality and rose the bleu score by 0.8 for preliminary test set of 20 sentences.
</nextsent>
<nextsent>2.3 illustration of mistranslations.
</nextsent>
<nextsent>among the connectives that we plan to process in order to improve mt, the three connectives we focuson in this paper are frequent, ambiguous and therefore difficult to translate correctly by mt systems, as illustrated in the following examples.a first reason why machine translation of connectives can be difficult is that there may be no direct lexical correspondence for the explicit source language connective in the target language, as shown in the reference translation of the first example in table 1, taken from the europarl corpus (koehn, 2005).en it is also important that we should not leave these indicators floating in the air while congratulating ourselves on the fact that we have produced them.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4744">
<title id=" W11-2022.xml">multilingual annotation and disambiguation of discourse connectives for machine translation </title>
<section> explicit connectives and their.  </section>
<citcontext>
<prevsection>
<prevsent>discourse connectives, their translations, and their senses are indicated in bold.
</prevsent>
<prevsent>the first example is reference translation from en into fr, while the others are wrong translations generated by mt (en/fr and respectively fr/en), hence marked with an asterisk.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
195 when an ambiguous connective is explicitly translated by another connective, the incorrect rendering of its sense can lead to erroneous translations, as in the second and third examples in table 1, which are translated by the moses smt decoder (koehn etal., 2007) <papid> P07-2045 </papid>trained on the europarl corpus.</citsent>
<aftsection>
<nextsent>the reference translation for the second example uses the french connective car with correct causal sense, instead of the wrong depuis que generated by smt,which expresses temporal relation.
</nextsent>
<nextsent>in the third example, the french connective alors que, in its contrastive usage, is wrongly translated into the english connective so, which has causal meaning (the reference translation uses whereas to express contrast).
</nextsent>
<nextsent>it may even occur that the system fails to translate connective at all, as in the fourth example where the discourse information provided by while, namely contrast relation, is lost in the french translation, which is hardly coherent any longer.
</nextsent>
<nextsent>3.1 annotated resources.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4746">
<title id=" W11-2022.xml">multilingual annotation and disambiguation of discourse connectives for machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>resources for czech are also becoming available (zikanova?
</prevsent>
<prevsent>et al, 2010).
</prevsent>
</prevsection>
<citsent citstr=" P98-2202 ">
for german, lexicon of discourse markers named dimlex exists since the 1990s (stede and umbach, 1998).<papid> P98-2202 </papid></citsent>
<aftsection>
<nextsent>an equivalent, more recent database for french is the lexconn lexicon of connectives (roze et al, 2010) containing list of 328 explicit connectives.
</nextsent>
<nextsent>for each of them, lexconnindicates and exemplifies the possible senses, chosen from list of 30 labels inspired from rhetorical structure theory (mann and thompson, 1988).
</nextsent>
<nextsent>3.2 automatic disambiguation of connectives.
</nextsent>
<nextsent>the release of the pdtb had quite an impact on automatic disambiguation experiments.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4747">
<title id=" W11-2022.xml">multilingual annotation and disambiguation of discourse connectives for machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 automatic disambiguation of connectives.
</prevsent>
<prevsent>the release of the pdtb had quite an impact on automatic disambiguation experiments.
</prevsent>
</prevsection>
<citsent citstr=" P09-2004 ">
the stateof-the-art for recognizing all types of explicit connectives in english is therefore already high, at97% accuracy for disambiguating discourse vs. non discourse uses (lin et al, 2010) and 94% for disambiguating the four main senses from the pdtb hierarchy (pitler and nenkova, 2009).<papid> P09-2004 </papid></citsent>
<aftsection>
<nextsent>lin et al (2010) recently built the first end-to-end pdtb discourse parser, which is able to parse unrestricted text with an f1 score of 38.18% for senses on the second levelof the pdtb hierarchy.
</nextsent>
<nextsent>other important contributions to automatic discourse connective classification and feature analysis has been provided by wellner et al (2006) <papid> W06-1317 </papid>and elwell and baldrige (2008).</nextsent>
<nextsent>fewer studies focus on the detailed analysis of specific discourse connectives.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4748">
<title id=" W11-2022.xml">multilingual annotation and disambiguation of discourse connectives for machine translation </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>the stateof-the-art for recognizing all types of explicit connectives in english is therefore already high, at97% accuracy for disambiguating discourse vs. non discourse uses (lin et al, 2010) and 94% for disambiguating the four main senses from the pdtb hierarchy (pitler and nenkova, 2009).<papid> P09-2004 </papid></prevsent>
<prevsent>lin et al (2010) recently built the first end-to-end pdtb discourse parser, which is able to parse unrestricted text with an f1 score of 38.18% for senses on the second levelof the pdtb hierarchy.</prevsent>
</prevsection>
<citsent citstr=" W06-1317 ">
other important contributions to automatic discourse connective classification and feature analysis has been provided by wellner et al (2006) <papid> W06-1317 </papid>and elwell and baldrige (2008).</citsent>
<aftsection>
<nextsent>fewer studies focus on the detailed analysis of specific discourse connectives.
</nextsent>
<nextsent>in section 5.3, we will compare our results to miltsakaki et al (2005) who report classification results for the connectives since, while and when.
</nextsent>
<nextsent>in their study, as in the present one, the goal is to disambiguate senses from the second level of the pdtb hierarchy, level which, as we will show, is appropriate for the translation of these connectives as well.
</nextsent>
<nextsent>corpora the resources mentioned above are either monolingual only (pdtb, lexconn) and/or not yet publicly available (annodis, dimlex).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4750">
<title id=" W11-2022.xml">multilingual annotation and disambiguation of discourse connectives for machine translation </title>
<section> disambiguation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>5.1 features.
</prevsent>
<prevsent>for feature extraction, all the datasets described in section 4 were processed as follows.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
the english texts were parsed and pos-tagged by charniak and johnsons (2005) <papid> P05-1022 </papid>reranking parser.</citsent>
<aftsection>
<nextsent>the french texts were pos-tagged with the melt tagger (denis and sagot, 2009) and parsed with malt parser (nivre, 2003).
</nextsent>
<nextsent>as the english parser provides constituency trees, and the parser for french generates dependency trees, the features are slightly different in thetwo languages.
</nextsent>
<nextsent>the other features below were extracted using elementary pre-processing of the sen tences.for english sentences, we used the following features: the sentence-initial character of the connec 198 tive (yes/no); the pos tag of the first verb in thesentence; the type of first auxiliary verb in the sentence (if any); the word preceding the connective; the word following the connective; the pos tag of the first verb following the connective; the type of the first auxiliary verb after the connective (if any).for french sentences, the features were the following: the sentence-initial character of the connective (yes/no); the dependency tag of the connective; the first verb in the sentence; its dependency tag; theword preceding the connective; its pos tag; its dependency tag; the word following the connective; its pos tag; its dependency tag; the first verb after the connective; its dependency tag.the cased connective word forms from the corpus were not lower-cased, thus keeping the implicit indication of the sentence-initial character of the occurrence, i.e. whether it starts sentence or not.
</nextsent>
<nextsent>the output of the pos taggers was used for neighboring words, but not for the connectives, which almost always received the same tag.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4751">
<title id=" W11-2022.xml">multilingual annotation and disambiguation of discourse connectives for machine translation </title>
<section> disambiguation experiments.  </section>
<citcontext>
<prevsection>
<prevsent>the occurrence of auxiliary verbs (be, have, do,or need) may give additional indications about temporal relations in the sentence.
</prevsent>
<prevsent>we therefore used the types of auxiliary verbs as features, including the elementary conjugations, represented for to be as: be present, be past, be part, be inf, be gerund ? and similarly for the other auxiliary verbs, as in (miltsakaki et al, 2005).
</prevsent>
</prevsection>
<citsent citstr=" P09-1075 ">
as shown by lin et al (2010), duverle and prendinger (2009) <papid> P09-1075 </papid>or wellner et al (2006), <papid> W06-1317 </papid>the context of connective is very important.</citsent>
<aftsection>
<nextsent>we therefore extracted the words preceding and following each connective, the verbs and the first and the last word of the sentences.
</nextsent>
<nextsent>these may include numbers, sometimes indicating numerical comparison, time expressions, or antonyms, which could indicate contrastive relations, such as rise vs. fall (e.g. it is interesting to see the fundamental stock pickers screamfoul?
</nextsent>
<nextsent>on program trading when the markets decline, while hailing the great values still abounding as the markets rise.).for french, we likewise extracted the words immediately preceding and following each connective,supplemented by their pos tags.
</nextsent>
<nextsent>in contrast to constituents, dependency structures contain information about the grammatical function of each word (heads) and link the dependents belonging to the same head.however, as the dependency parser provides no differentiated verb tags, we extracted the verb word forms themselves and added their dependency tags.the same applies to the connective itself, and preceding and following words and their dependency tags.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4754">
<title id=" W12-1912.xml">induction of linguistic structure with combinatory categorial grammars </title>
<section> introduction </section>
<citcontext>
<prevsection>

<prevsent>our system consists of simple, em-based induction algorithm (bisk and hockenmaier, 2012), which induces language-specific combinatory categorial grammar (ccg) and lexicon based on small number of linguistic principles, e.g. that verbs may be the roots of sentences and can take nouns as arguments.
</prevsent>
</prevsection>
<citsent citstr=" D10-1120 ">
much of the recent work on grammar induction has focused on the development of sophisticated statistical models that incorporate expressive priors (cohen and smith, 2010) or linguistic universals (naseem et al., 2010; <papid> D10-1120 </papid>boonkwan and steedman, 2011) that have all been shown to be very helpful.</citsent>
<aftsection>
<nextsent>but, with some notable exceptions, such as (cohn et al, 2011),the question of what underlying linguistic representation to use has received considerably less attention.
</nextsent>
<nextsent>our induction algorithm is based on com bina tory categorial grammar (steedman, 2000), alinguistically expressive, lexicalized grammar formalism which associates words with rich syntactic categories that capture language-specific facts about basic word order and subcategorization.
</nextsent>
<nextsent>while boonkwan and steedman (2011) have shown that linguists can easily devise language-specific inventory of such categories that allows parser to achieve high performance in the absence of annotated training data, our algorithm automatically discovers the set of categories it requires to parse the sentences in the training data.
</nextsent>
<nextsent>(ccg) the set of ccg categories is built recursively fromtwo atomic types, (sentence) and (noun).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4755">
<title id=" W12-1912.xml">induction of linguistic structure with combinatory categorial grammars </title>
<section> combinatory categorial grammar.  </section>
<citcontext>
<prevsection>
<prevsent>the slash indicates whether the precedes (\) or follows (/) the functor.
</prevsent>
<prevsent>an english lexicon should contain categories such as s\n and (s\n)/n for verbs: both transitive and in transitive verbs sub categorize for apreceding subject, and the transitive verb additionally takes an object to its right.
</prevsent>
</prevsection>
<citsent citstr=" J07-3004 ">
in this manner, the argument slots of lexical categories also define word-word dependencies between heads and their arguments (clark and hockenmaier, 2002; hockenmaier and steedman, 2007).<papid> J07-3004 </papid></citsent>
<aftsection>
<nextsent>modifiers are generally of the form x|x: in english, pre-nominal adjectives are n/n, whereas adverbs may be (n/n)/(n/n), s/s, or s\s, and prepositions can have categories such as (n\n)/n or (s\s)/n. that is, ccg assumes that the direction of the corresponding dependency goes from the modifier to the head.
</nextsent>
<nextsent>this discrepancy between ccg and most other analyses can easily be removed under the assumption that all categories of the form x|x are modifiers whose dependencies should be reversed when comparing against other frameworks.
</nextsent>
<nextsent>adjacent constituents can be combined according to small, universal set of combinatory rules.
</nextsent>
<nextsent>for the purposes of this work we restrict ourselves to function application and b1 composition: x/y ? ( ) 90 x\y ? ( ) x/y y|iz ? x|iz (b1 ) y|iz x\y ? x|iz (b1 ) here the slash variable |i can be instantiated with either the forward or backward slash.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4756">
<title id=" W12-1912.xml">induction of linguistic structure with combinatory categorial grammars </title>
<section> combinatory categorial grammar.  </section>
<citcontext>
<prevsection>
<prevsent>this restricted set of combinatory rules provides sufficient power for reasonable parse accuracy butdoes not allow us to capture non-projective (cross ing) dependencies.
</prevsent>
<prevsent>coordination is handled by ternary rule conj ? ( ) which we binarize as: x[conj] ? (  &amp;) conj ? x[conj] (  &amp;) punctuation, when present, can be absorbed by rules of the form pct ? (  p) pct ? (  p)the iterative combination of these categories resulting in or is considered successful parse.
</prevsent>
</prevsection>
<citsent citstr=" C10-1053 ">
in order to avoid spurious ambiguities, we restrict our derivations to be normal-form (hockenmaier and bisk, 2010).<papid> C10-1053 </papid></citsent>
<aftsection>
<nextsent>induction we now describe our induction algorithm, which consists of two stages: category induction (creation of the grammar), followed by parameter estimation for the probability model.
</nextsent>
<nextsent>3.1 category induction.
</nextsent>
<nextsent>we assume there are two atomic categories, (nounsor noun phrases) and (sentences), special conjunction category conj, and special start symbol top.
</nextsent>
<nextsent>we assume that all strings we encounter are either nouns or sentences: n?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4757">
<title id=" W12-1912.xml">induction of linguistic structure with combinatory categorial grammars </title>
<section> an algorithm for unsupervised ccg.  </section>
<citcontext>
<prevsection>
<prevsent>top s?
</prevsent>
<prevsent>top we also assume that we can group pos-tags into four groups: nominal tags, verbal tags, conjunctions, and others.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
this allows us to create an initial lexiconl(0), which only contains entries for atomic categories, e.g. for the english penn treebank tag set (marcus et al, 1993): : {<papid> J93-2004 </papid>nn,nns,nnp,prp,dt} : {md,vb,vbz,vbg,vbn,vbd} conj : {cc} we force any string that contains one or more verbs (besides vbg in english), to be parsed with the s?</citsent>
<aftsection>
<nextsent>top rule.
</nextsent>
<nextsent>since the initial lexicon would only allow us to parse single word utterances (or coordinationsthereof), we need to induce complex functor categories.
</nextsent>
<nextsent>the lexicon entries for atomic categories remain, but all pos-tags, including nouns and conjunctions, will be able to acquire complex categories during induction.
</nextsent>
<nextsent>we impose the following constraints on the lexical categories we induce: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4758">
<title id=" W12-1912.xml">induction of linguistic structure with combinatory categorial grammars </title>
<section> modifiers (x/x or x\x) can be modified.  </section>
<citcontext>
<prevsection>
<prevsent>this allows us to induce (s\s)/n for in, since we can combine and friend to n. 3.2 parameter estimation.
</prevsent>
<prevsent>after constructing the lexicon, we parse the training corpus, and use the inside-outside algorithm (lariand young, 1991), variant of the expectation maximization algorithm for probabilistic context free grammars, to estimate model parameters.
</prevsent>
</prevsection>
<citsent citstr=" P02-1043 ">
weuse the baseline model of hockenmaier and steedman (2002), <papid> P02-1043 </papid>which is simple generative model that is equivalent to an un lexicalized pcfg.</citsent>
<aftsection>
<nextsent>in cfg, the set of terminals and non-terminals is disjoint, but in ccg, not every category can be lexical.
</nextsent>
<nextsent>since this model is also the basis of lexicalized model that captures dependencies, it distinguishes between lexical expansions (which produce words), unary expansions (which are the result of type-raising or the top rules), binary expansions where the head is the left child, and binary expansions whose head is the right child.
</nextsent>
<nextsent>each tree is generated top-down from the start category top.
</nextsent>
<nextsent>for each (parent) node, first its expansion type exp ? {lex,unary,left,right} is generated.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4759">
<title id=" W11-2044.xml">rapid development of advanced question answering characters by non experts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the amanicharacter (artstein et al, 2009) is an example advanced question-answering character.
</prevsent>
<prevsent>several different architectures have been used for building virtual human dialogue systems (traum, 2008).
</prevsent>
</prevsection>
<citsent citstr=" W06-1303 ">
leuski et al (2006), <papid> W06-1303 </papid>leuski et al (2010) describe one such architecture that can be used to build simple question-answering characters.</citsent>
<aftsection>
<nextsent>in this architecture, scenario designers author list of questions, listof answers and all possible links between these.
</nextsent>
<nextsent>although this approach allows non-experts to develop virtual characters, it falls short of maintaining coherence over sequence of utterances greater in length than two.
</nextsent>
<nextsent>traum et al (2008) describe an architecture that models such dependencies by using an information-state based dialogue model (traum and larsson, 2003), but this architecture is not currently accessible to non-experts for authoring, due to expertise needed in designing task model plans and thematic-role based framebanks.we choose an intermediate approach, using simple information-state dialogue manager, making authoring accessible to non-experts through use ofthe accompanying integrated authoring tool, do main editor (gandhe et al, 2009).
</nextsent>
<nextsent>private first class (pfc) sean avery is virtual character who has witnessed fellow soldier and his accomplice smuggling something suspicious on u.s. army base.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4760">
<title id=" W12-1702.xml">semi supervised learning for automatic conceptual property extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>more comparable to previous and related work.
</prevsent>
<prevsent>having framed our task in this way, there is an obvious parallel with relation extraction: both necessitate the selection/classification of relationships between individual entities (in our case, between concept and feature).
</prevsent>
</prevsection>
<citsent citstr=" C92-2082 ">
hearst (1992) <papid> C92-2082 </papid>was the firstto propose pattern-based approach to this task using lexico-syntactic patterns to automatically extract hyponyms and this technique has frequently been used for ontology learning.</citsent>
<aftsection>
<nextsent>for example, pantel and pennacchiotti (2008) linked instantiations of set of semantic relations into existing semantic ontologies and davidov et al  (2007) <papid> P07-1030 </papid>employed seed concepts from given semantic class to discover relations shared by concepts in that class.our task is more complex than classic relation extraction for two main reasons: 1) the relations which we aim to extract are not limited to small set ofjust few well-defined relations (e.g., is-a and part of) nor to the relations of specific semantic class (e.g., capital-is for countries).</nextsent>
<nextsent>indeed the relation scan be as many and diverse as the concepts themselves (e.g., each concept could possess unique and distinguishing relation and feature).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4761">
<title id=" W12-1702.xml">semi supervised learning for automatic conceptual property extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>having framed our task in this way, there is an obvious parallel with relation extraction: both necessitate the selection/classification of relationships between individual entities (in our case, between concept and feature).
</prevsent>
<prevsent>hearst (1992) <papid> C92-2082 </papid>was the firstto propose pattern-based approach to this task using lexico-syntactic patterns to automatically extract hyponyms and this technique has frequently been used for ontology learning.</prevsent>
</prevsection>
<citsent citstr=" P07-1030 ">
for example, pantel and pennacchiotti (2008) linked instantiations of set of semantic relations into existing semantic ontologies and davidov et al  (2007) <papid> P07-1030 </papid>employed seed concepts from given semantic class to discover relations shared by concepts in that class.our task is more complex than classic relation extraction for two main reasons: 1) the relations which we aim to extract are not limited to small set ofjust few well-defined relations (e.g., is-a and part of) nor to the relations of specific semantic class (e.g., capital-is for countries).</citsent>
<aftsection>
<nextsent>indeed the relation scan be as many and diverse as the concepts themselves (e.g., each concept could possess unique and distinguishing relation and feature).
</nextsent>
<nextsent>2) we are attempting to simultaneously extract two pieces ofinformation: features of the concept and those fea tures?
</nextsent>
<nextsent>defining relationship with the concept, but only those relations and features which would be classified as common-sense?, something which iseasy for humans to recognise but difficult (if not im possible) to describe rigorously or formally.there has recently been work on the automatic ex 12traction of binary relations that scale to web corpus, for example the reverb (etzioni et al , 2011) and woe (wu and weld, 2010) <papid> P10-1013 </papid>systems.</nextsent>
<nextsent>these systems are designed to extract legitimate relations from given sentence.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4762">
<title id=" W12-1702.xml">semi supervised learning for automatic conceptual property extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>indeed the relation scan be as many and diverse as the concepts themselves (e.g., each concept could possess unique and distinguishing relation and feature).
</prevsent>
<prevsent>2) we are attempting to simultaneously extract two pieces ofinformation: features of the concept and those fea tures?
</prevsent>
</prevsection>
<citsent citstr=" P10-1013 ">
defining relationship with the concept, but only those relations and features which would be classified as common-sense?, something which iseasy for humans to recognise but difficult (if not im possible) to describe rigorously or formally.there has recently been work on the automatic ex 12traction of binary relations that scale to web corpus, for example the reverb (etzioni et al , 2011) and woe (wu and weld, 2010) <papid> P10-1013 </papid>systems.</citsent>
<aftsection>
<nextsent>these systems are designed to extract legitimate relations from given sentence.
</nextsent>
<nextsent>in contrast, our aim is to capture more general relationships which are common sense?; just because an extracted relation is correct in given context does not automatically make it true in general.
</nextsent>
<nextsent>previous reasoned approaches to ourtask have taken their lead from hearst and her successors, employing manually-created rule sets to extract such properties from corpora (e.g., baroni et al  (2009), devereux et al  (2010), and our comparison system (kelly et al , 2010)).<papid> W10-0608 </papid></nextsent>
<nextsent>baroni et al  extract relational information in the form of type-sketches?, which give an approximate, implicit description of the relationship whereas we are aiming to extract explicit relations between the target concept and its corresponding features.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4763">
<title id=" W12-1702.xml">semi supervised learning for automatic conceptual property extraction </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these systems are designed to extract legitimate relations from given sentence.
</prevsent>
<prevsent>in contrast, our aim is to capture more general relationships which are common sense?; just because an extracted relation is correct in given context does not automatically make it true in general.
</prevsent>
</prevsection>
<citsent citstr=" W10-0608 ">
previous reasoned approaches to ourtask have taken their lead from hearst and her successors, employing manually-created rule sets to extract such properties from corpora (e.g., baroni et al  (2009), devereux et al  (2010), and our comparison system (kelly et al , 2010)).<papid> W10-0608 </papid></citsent>
<aftsection>
<nextsent>baroni et al  extract relational information in the form of type-sketches?, which give an approximate, implicit description of the relationship whereas we are aiming to extract explicit relations between the target concept and its corresponding features.
</nextsent>
<nextsent>devereux et al  and kelly et al  have attempted this, but both employ wordnet(fellbaum, 1998) to extract semantic relatedness information.
</nextsent>
<nextsent>we use semi-supervised learning as it offers flexible technique of harnessing small amounts of labelled data to derive information from unlabelleddatasets/corpora and allows us to guide the extraction towards our desired common-sense?
</nextsent>
<nextsent>output.we chose svms as they have been used for variety of tasks in nlp (e.g., joachims et al  (1998),gimenez and marquez (2004)).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4767">
<title id=" W12-1702.xml">semi supervised learning for automatic conceptual property extraction </title>
<section> behavioural properties become does? properties.  </section>
<citcontext>
<prevsection>
<prevsent>this yielded 7,518 property-triples with 254 distinct relations and an average of 14.7 triples per concept.
</prevsent>
<prevsent>2.3 parsing.
</prevsent>
</prevsection>
<citsent citstr=" J07-4004 ">
we parsed both corpora using the c&c; parser (clark and curran, 2007) <papid> J07-4004 </papid>as we employ both grand pos information in our learning method.</citsent>
<aftsection>
<nextsent>to accelerate this stage, we process only sentences containing form (e.g., singular/plural) of one of our training/testing concepts.
</nextsent>
<nextsent>we lemmatise each word using the wordnet nltk lemmatiser (bird, 2006).<papid> P06-4018 </papid></nextsent>
<nextsent>parsing our corpora yields around 10gb and 12gb of data for ukwac and wikipedia respectively.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4768">
<title id=" W12-1702.xml">semi supervised learning for automatic conceptual property extraction </title>
<section> behavioural properties become does? properties.  </section>
<citcontext>
<prevsection>
<prevsent>we parsed both corpora using the c&c; parser (clark and curran, 2007) <papid> J07-4004 </papid>as we employ both grand pos information in our learning method.</prevsent>
<prevsent>to accelerate this stage, we process only sentences containing form (e.g., singular/plural) of one of our training/testing concepts.</prevsent>
</prevsection>
<citsent citstr=" P06-4018 ">
we lemmatise each word using the wordnet nltk lemmatiser (bird, 2006).<papid> P06-4018 </papid></citsent>
<aftsection>
<nextsent>parsing our corpora yields around 10gb and 12gb of data for ukwac and wikipedia respectively.
</nextsent>
<nextsent>the c&c; dependency parse output contains, forgiven sentence, set of grs forming an acyclic graph whose nodes correspond to words from the sentence, with each node also labelled with the pos of that word.
</nextsent>
<nextsent>thus the gr-pos graph inter relates all lexical, pos and gr information for the entire sentence.
</nextsent>
<nextsent>it is therefore possible to construct gr-posgraph rooted at our target term (the concept in ques tion), with pos-labelled words as nodes, and edges labelled with grs linking the nodes to one another.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4770">
<title id=" W12-1702.xml">semi supervised learning for automatic conceptual property extraction </title>
<section> behavioural properties become does? properties.  </section>
<citcontext>
<prevsection>
<prevsent>to mitigate this, we extract both log-likelihood (ll) and pointwise mutual information (pmi) scores for each concept/feature pair to assess the relative saliency of each extracted feature, with view to down weighting common but less interesting features.
</prevsent>
<prevsent>to speed up this and later stages, we calculate both statistics for the top 1,000 triples extracted for each concept only.
</prevsent>
</prevsection>
<citsent citstr=" J90-1003 ">
pmi was proposed by church and hanks (1990)<papid> J90-1003 </papid>to estimate word association.</citsent>
<aftsection>
<nextsent>we will use it to measure the strength of association between concept and its feature.
</nextsent>
<nextsent>we hope that emphasising concept feature pairs with high mutual information will render our triples more relevant/informative.
</nextsent>
<nextsent>we also employ the ll measure across our set of concept-feature pairs.
</nextsent>
<nextsent>proposed by dunning (1993),<papid> J93-1003 </papid>ll is measure of the distribution of linguistic phenomena in texts and has been used to contrast the relative corpus frequencies of words.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4771">
<title id=" W12-1702.xml">semi supervised learning for automatic conceptual property extraction </title>
<section> behavioural properties become does? properties.  </section>
<citcontext>
<prevsection>
<prevsent>we hope that emphasising concept feature pairs with high mutual information will render our triples more relevant/informative.
</prevsent>
<prevsent>we also employ the ll measure across our set of concept-feature pairs.
</prevsent>
</prevsection>
<citsent citstr=" J93-1003 ">
proposed by dunning (1993),<papid> J93-1003 </papid>ll is measure of the distribution of linguistic phenomena in texts and has been used to contrast the relative corpus frequencies of words.</citsent>
<aftsection>
<nextsent>our aim is to highlight features which are particularly distinctive forgiven concept, and hence likely to be features of that concept alone.
</nextsent>
<nextsent>we calculate an overall score for triple, t, by weighted combination of the triples svm, pmi and ll scores using the following formula: score(t) = pmipmi(t)+llll(t)+svmsvm(t) where the pmi, svm and ll scores are normalised so they are in the range [0, 1].
</nextsent>
<nextsent>the relative ? weights thus give an estimate of the three measures?
</nextsent>
<nextsent>importance relative to one another and allows us to gauge which combination of these scores is optimal.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4780">
<title id=" W11-2111.xml">erating machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, there has also been some work on methods that are not dependent on human-authored translations.
</prevsent>
<prevsent>one subset of such methods is task-based in that the methods determine the quality of translation interms of how well it serves the need of an extrinsic task.
</prevsent>
</prevsection>
<citsent citstr=" P09-1048 ">
these tasks can either be downstream nlp tasks such as information extraction (parton et al, 2009) <papid> P09-1048 </papid>and information retrieval (fujii et al, 2009) orhuman tasks such as answering questions on reading comprehension test (jones et al, 2007).<papid> N07-2020 </papid></citsent>
<aftsection>
<nextsent>besides extrinsic evaluation, there is another set of methods that attempt to learn?
</nextsent>
<nextsent>what makes good translation and then predict the quality of new translations without comparing to reference translations.
</nextsent>
<nextsent>corston-oliver et al (2001) proposed theidea of building decision tree classifier to simply distinguish between machine and human translations using language model (lm) and syntactic features.
</nextsent>
<nextsent>kulesza and shieber (2004) attempt the same task using an support vector machine (svm) classifier and features derived from reference-based mt metrics such as wer, per, bleu and nist.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4781">
<title id=" W11-2111.xml">erating machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>how ever, there has also been some work on methods that are not dependent on human-authored translations.
</prevsent>
<prevsent>one subset of such methods is task-based in that the methods determine the quality of translation interms of how well it serves the need of an extrinsic task.
</prevsent>
</prevsection>
<citsent citstr=" N07-2020 ">
these tasks can either be downstream nlp tasks such as information extraction (parton et al, 2009) <papid> P09-1048 </papid>and information retrieval (fujii et al, 2009) orhuman tasks such as answering questions on reading comprehension test (jones et al, 2007).<papid> N07-2020 </papid></citsent>
<aftsection>
<nextsent>besides extrinsic evaluation, there is another set of methods that attempt to learn?
</nextsent>
<nextsent>what makes good translation and then predict the quality of new translations without comparing to reference translations.
</nextsent>
<nextsent>corston-oliver et al (2001) proposed theidea of building decision tree classifier to simply distinguish between machine and human translations using language model (lm) and syntactic features.
</nextsent>
<nextsent>kulesza and shieber (2004) attempt the same task using an support vector machine (svm) classifier and features derived from reference-based mt metrics such as wer, per, bleu and nist.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4782">
<title id=" W11-2111.xml">erating machine translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they also claim that the confidence score for the classifier being used, if available, may be taken as an estimate of translation quality.
</prevsent>
<prevsent>quirk (2004) took adifferent approach and examined whether it is possible to explicitly compute confidence measure for each translated sentence by using features derived from both the source and target language sides.
</prevsent>
</prevsection>
<citsent citstr=" P07-1111 ">
albrecht and hwa (2007<papid> P07-1111 </papid>a) expanded on this idea and conducted larger scale study to show the viability of regression as sentence-level metric of mt quality.</citsent>
<aftsection>
<nextsent>they used features derived from several other reference-driven mt metrics.
</nextsent>
<nextsent>in other work (albrecht and hwa, 2007<papid> P07-1111 </papid>b), they showed that one could substitute translations from other mt systems for human-authored reference translations and derive the regression features from them.gamon et al (2005) build classifier to distinguish machine-generated translations from human 108 ones using fluency-based features and show that by combining the scores of this classifier with lm perplexities, they obtain an mt metric that has good correlation with human judgments but not better than the baseline bleu metric.the fundamental questions that inspired our proposed metrics are as follows:?</nextsent>
<nextsent>can an operational english-proficiency measurement system, built with absolutely no forethought of using it for evaluation of translation quality, actually be used for this purpose?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4786">
<title id=" W11-2111.xml">erating machine translation </title>
<section> e-rater </section>
<citcontext>
<prevsection>
<prevsent>e-rater is proprietary automated essay scoring system developed by educational testing service (ets) to assess writing quality.1 the system hasbeen used operationally for over 10 years in high stakes exams such as the gre and toefl given its speed, reliability and high agreement with human raters.e-rater combines 8 main features using linear regression to produce numerical score for an essay.
</prevsent>
<prevsent>these features are grammar, usage, mechanics, style, organization, development, lexical complexity and vocabulary usage.
</prevsent>
</prevsection>
<citsent citstr=" A00-2019 ">
the grammar feature covers errors such as sentence fragments, verb form errors and pronoun errors (chodorow and leacock, 2000).<papid> A00-2019 </papid></citsent>
<aftsection>
<nextsent>the usage feature detects errors related to articles (han et al, 2006), prepositions (tetreault and chodorow, 2008) <papid> C08-1109 </papid>and collocations (futagi et al, 2008).</nextsent>
<nextsent>the mechanics feature checks for spelling,punctuation and capitalization errors.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4787">
<title id=" W11-2111.xml">erating machine translation </title>
<section> e-rater </section>
<citcontext>
<prevsection>
<prevsent>these features are grammar, usage, mechanics, style, organization, development, lexical complexity and vocabulary usage.
</prevsent>
<prevsent>the grammar feature covers errors such as sentence fragments, verb form errors and pronoun errors (chodorow and leacock, 2000).<papid> A00-2019 </papid></prevsent>
</prevsection>
<citsent citstr=" C08-1109 ">
the usage feature detects errors related to articles (han et al, 2006), prepositions (tetreault and chodorow, 2008) <papid> C08-1109 </papid>and collocations (futagi et al, 2008).</citsent>
<aftsection>
<nextsent>the mechanics feature checks for spelling,punctuation and capitalization errors.
</nextsent>
<nextsent>the style feature checks for passive constructions and word repetition, among others.
</nextsent>
<nextsent>organization and development tabulate the presence or absence of discourse elements and the length of each element.
</nextsent>
<nextsent>finally, the lexical complexity feature details how complex the writers words are based on frequency indices and writing scales, and the vocabulary feature evaluates how appropriate the words are for the given topic).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4788">
<title id=" W11-2111.xml">erating machine translation </title>
<section> e-rating machine translation </section>
<citcontext>
<prevsection>
<prevsent>we used existing automatic mt metrics as baselines in our evaluation, and also as features in our hybrid metric.
</prevsent>
<prevsent>the metrics we used were: 1.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
bleu (papineni et al, 2002): <papid> P02-1040 </papid>case-insensitive.</citsent>
<aftsection>
<nextsent>and case-sensitive bleu scores were produced using mteval-v13a.pl, which calculates smoothed sentence-level scores.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>terp (snover et al, 2009): <papid> W09-0441 </papid>translation edit.</nextsent>
<nextsent>rate plus (terp) scores were produced using terp v1.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4789">
<title id=" W11-2111.xml">erating machine translation </title>
<section> e-rating machine translation </section>
<citcontext>
<prevsection>
<prevsent>and case-sensitive bleu scores were produced using mteval-v13a.pl, which calculates smoothed sentence-level scores.
</prevsent>
<prevsent>2.
</prevsent>
</prevsection>
<citsent citstr=" W09-0441 ">
terp (snover et al, 2009): <papid> W09-0441 </papid>translation edit.</citsent>
<aftsection>
<nextsent>rate plus (terp) scores were produced using terp v1.
</nextsent>
<nextsent>the scores were case-insensitive and edit costs from snover et al (2009) <papid> W09-0441 </papid>were usedto produce scores tuned for fluency and ade quacy.</nextsent>
<nextsent>3.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4791">
<title id=" W11-2111.xml">erating machine translation </title>
<section> e-rating machine translation </section>
<citcontext>
<prevsection>
<prevsent>this is low-precision heuristic for counting out of vocabulary (oov) words, since it also counts named entities and words that happen to be the same in different languages.
</prevsent>
<prevsent>4.3 ranking model.
</prevsent>
</prevsection>
<citsent citstr=" W08-0331 ">
following (duh, 2008), <papid> W08-0331 </papid>we represent sentence-levelmt evaluation as ranking problem.</citsent>
<aftsection>
<nextsent>for particular source sentence, there are machine translations and one reference translation.
</nextsent>
<nextsent>a feature vector is extracted from each {source, reference, mt} tu ple.
</nextsent>
<nextsent>the training data consists of sets of translations that have been annotated with relative ranks.
</nextsent>
<nextsent>during training, all ranked sets are converted to sets of feature vectors, where the label for each feature vector is the rank.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4792">
<title id=" W11-2403.xml">classification based contextual preferences </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>similarly, inferring the protest-related event demonstrate based on demo is deemed invalid although demo implies the meaning of the word demonstrate in other contexts, e.g., concerning software demonstration.although seemingly equivalent, closer look reveals that the above two examples correspond to two distinct contextual mismatch situations.
</prevsent>
<prevsent>while the match of hurt is invalid for injure in the particular given context, an inference based on demo is invalid for the protest demonstrate event in any context.thus, several types of context matching are involved in textual inference.
</prevsent>
</prevsection>
<citsent citstr=" P08-1078 ">
while most prior work addressed only specific context matching scenarios, szpektor et al  (2008) <papid> P08-1078 </papid>presented broader view,proposing generic framework for context matching in inference, termed contextual preferences (cp).</citsent>
<aftsection>
<nextsent>cp specifies the types of context matching that need to be considered in inference, allowing model of choice to be applied for validating each type of match.szpektor et al  applied cp to an ie task using different models to validate each type of context match.
</nextsent>
<nextsent>in this work we adopt cp as our context matching framework and propose novel classification-based scheme which provides unified modeling for cp.
</nextsent>
<nextsent>we represent typical contexts of the textual objects that participate in inference using classifiers; at inference time, each match is assessed by the respective classifiers which determine its contextual validity.
</nextsent>
<nextsent>as test bed we applied our scheme to the task 20of name-based text categorization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4796">
<title id=" W11-2403.xml">classification based contextual preferences </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>the wsd task requires selecting the meaning of target term from amongst predefined set of senses, based on sense-inventories such as wordnet (fellbaum, 1998).
</prevsent>
<prevsent>an alternative approach eliminates the reliance onsuch inventories.
</prevsent>
</prevsection>
<citsent citstr=" P06-1057 ">
instead of explicit sense identification, direct sense-match between terms is pursued (dagan et al , 2006).<papid> P06-1057 </papid></citsent>
<aftsection>
<nextsent>lexical substitution (mccarthy and navigli, 2009) is probably the most commonly known task that follows this approach.
</nextsent>
<nextsent>context matching is generalization of lexical substitution, which seeks match between terms in context,not necessarily for the purpose of substitution.
</nextsent>
<nextsent>for instance, the word played in u2 played their first-everconcert in russia?
</nextsent>
<nextsent>contextually matches music, although music cannot substitute played in this context.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4799">
<title id=" W11-2403.xml">classification based contextual preferences </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>a direct match occurs when term in is identical to term in t. an inference based on an indirect match is viewed as the application of lexical entailment rule, r, such as hurt?
</prevsent>
<prevsent>injure?, where the entailing left-hand side (lhs) of the rule(hurt) is matched in the text, while the entailed right hand side (rhs), injure, is matched in the hypothesis.hence, three inference objects take part in inference operations: t, and r. most prior work addressed only specific contextual matches between these objects.
</prevsent>
</prevsection>
<citsent citstr=" N09-2009 ">
for example, harabagiu et al  (2003) matched the contexts of and for qa (answer and question, respectively); barak et al  (2009)<papid> N09-2009 </papid>matched and (document and category) in tc, while other works, including those applying lexical substitution, typically validated the context match between and (kauchak and barzilay, 2006; <papid> N06-1058 </papid>dagan et al , 2006; <papid> P06-1057 </papid>pantel et al , 2007; <papid> N07-1071 </papid>connor and roth, 2007).</citsent>
<aftsection>
<nextsent>in comparison, in the cp framework, all possible contextual matches among t, and are considered: th, t?
</nextsent>
<nextsent>r and rh. the three context matches are depicted in figure 1 (left).
</nextsent>
<nextsent>in cp, the representation of each inference object is enriched with contextual information which is used to characterize its valid contexts.
</nextsent>
<nextsent>such information may be the words of the event description in ie, corpus instances based on which rule was learned, or an annotation of relevant wordnet senses in name-based tc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4801">
<title id=" W11-2403.xml">classification based contextual preferences </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>a direct match occurs when term in is identical to term in t. an inference based on an indirect match is viewed as the application of lexical entailment rule, r, such as hurt?
</prevsent>
<prevsent>injure?, where the entailing left-hand side (lhs) of the rule(hurt) is matched in the text, while the entailed right hand side (rhs), injure, is matched in the hypothesis.hence, three inference objects take part in inference operations: t, and r. most prior work addressed only specific contextual matches between these objects.
</prevsent>
</prevsection>
<citsent citstr=" N06-1058 ">
for example, harabagiu et al  (2003) matched the contexts of and for qa (answer and question, respectively); barak et al  (2009)<papid> N09-2009 </papid>matched and (document and category) in tc, while other works, including those applying lexical substitution, typically validated the context match between and (kauchak and barzilay, 2006; <papid> N06-1058 </papid>dagan et al , 2006; <papid> P06-1057 </papid>pantel et al , 2007; <papid> N07-1071 </papid>connor and roth, 2007).</citsent>
<aftsection>
<nextsent>in comparison, in the cp framework, all possible contextual matches among t, and are considered: th, t?
</nextsent>
<nextsent>r and rh. the three context matches are depicted in figure 1 (left).
</nextsent>
<nextsent>in cp, the representation of each inference object is enriched with contextual information which is used to characterize its valid contexts.
</nextsent>
<nextsent>such information may be the words of the event description in ie, corpus instances based on which rule was learned, or an annotation of relevant wordnet senses in name-based tc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4804">
<title id=" W11-2403.xml">classification based contextual preferences </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>a direct match occurs when term in is identical to term in t. an inference based on an indirect match is viewed as the application of lexical entailment rule, r, such as hurt?
</prevsent>
<prevsent>injure?, where the entailing left-hand side (lhs) of the rule(hurt) is matched in the text, while the entailed right hand side (rhs), injure, is matched in the hypothesis.hence, three inference objects take part in inference operations: t, and r. most prior work addressed only specific contextual matches between these objects.
</prevsent>
</prevsection>
<citsent citstr=" N07-1071 ">
for example, harabagiu et al  (2003) matched the contexts of and for qa (answer and question, respectively); barak et al  (2009)<papid> N09-2009 </papid>matched and (document and category) in tc, while other works, including those applying lexical substitution, typically validated the context match between and (kauchak and barzilay, 2006; <papid> N06-1058 </papid>dagan et al , 2006; <papid> P06-1057 </papid>pantel et al , 2007; <papid> N07-1071 </papid>connor and roth, 2007).</citsent>
<aftsection>
<nextsent>in comparison, in the cp framework, all possible contextual matches among t, and are considered: th, t?
</nextsent>
<nextsent>r and rh. the three context matches are depicted in figure 1 (left).
</nextsent>
<nextsent>in cp, the representation of each inference object is enriched with contextual information which is used to characterize its valid contexts.
</nextsent>
<nextsent>such information may be the words of the event description in ie, corpus instances based on which rule was learned, or an annotation of relevant wordnet senses in name-based tc.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4814">
<title id=" W11-2403.xml">classification based contextual preferences </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>to overcome sparseness, other works represented context in latent space.
</prevsent>
<prevsent>pennacchiotti et al  (2007) and szpektor et al  (2008) <papid> P08-1078 </papid>measured the similarity between the latent semantic analysis (lsa) (deerwester et al , 1990)representations of matched contexts.</prevsent>
</prevsection>
<citsent citstr=" C10-2029 ">
dinu and la pata (2010) <papid> C10-2029 </papid>used latent dirichlet allocation (lda) (blei et al , 2003) to model templates?</citsent>
<aftsection>
<nextsent>latent senses, determining rule applicability based on the similarity between the two sides of the rule when instantiated by the context, while ritter et al  (2010) <papid> P10-1044 </papid>used lda to model argument classes, considering rule valid forgiven argument instantiation if its instantiated templates are drawn from the same hidden topic.a different approach is provided by classification based models which learn classifiers for inference objects.</nextsent>
<nextsent>a classifier is trained based on positive and negative examples which represent valid or invalid contexts of the object; from those, features characterizing the context are extracted, e.g. words in window around the target term or syntactic links withit.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4815">
<title id=" W11-2403.xml">classification based contextual preferences </title>
<section> background.  </section>
<citcontext>
<prevsection>
<prevsent>pennacchiotti et al  (2007) and szpektor et al  (2008) <papid> P08-1078 </papid>measured the similarity between the latent semantic analysis (lsa) (deerwester et al , 1990)representations of matched contexts.</prevsent>
<prevsent>dinu and la pata (2010) <papid> C10-2029 </papid>used latent dirichlet allocation (lda) (blei et al , 2003) to model templates?</prevsent>
</prevsection>
<citsent citstr=" P10-1044 ">
latent senses, determining rule applicability based on the similarity between the two sides of the rule when instantiated by the context, while ritter et al  (2010) <papid> P10-1044 </papid>used lda to model argument classes, considering rule valid forgiven argument instantiation if its instantiated templates are drawn from the same hidden topic.a different approach is provided by classification based models which learn classifiers for inference objects.</citsent>
<aftsection>
<nextsent>a classifier is trained based on positive and negative examples which represent valid or invalid contexts of the object; from those, features characterizing the context are extracted, e.g. words in window around the target term or syntactic links withit.
</nextsent>
<nextsent>given new context, the classifier assesses its validity with respect to the learned classification model.
</nextsent>
<nextsent>classifiers in prior work were applied to determine rule applicability in given context (t ? r).
</nextsent>
<nextsent>training classifier for word paraphrasing, kauchak and barzilay (2006) <papid> N06-1058 </papid>used occurrences of the rules rhs as positive context examples, and randomly picked negative examples.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4829">
<title id=" W11-2403.xml">classification based contextual preferences </title>
<section> a self-supervised context model </section>
<citcontext>
<prevsection>
<prevsent>5.1.2 obtaining negative examples negative examples are even more challenging toacquire.
</prevsent>
<prevsent>in prior work negative examples were selected randomly (kauchak and barzilay, 2006; <papid> N06-1058 </papid>connor and roth, 2007).</prevsent>
</prevsection>
<citsent citstr=" P05-1044 ">
we follow this method, but also attempt to identify negative examples that are semantically similar to the positive ones in order to improve the discriminative power of the classifier (smith and eisner, 2005).<papid> P05-1044 </papid></citsent>
<aftsection>
<nextsent>we do that by applying similar procedure which uses cohyponyms of the seeds, e.g. baseball for hockey or islam for christianity.
</nextsent>
<nextsent>cohyponymy is non-entailing relation; hence, by using it we expect to obtain semantically-related,yet invalid contexts.
</nextsent>
<nextsent>if not enough negative examples are retrieved using cohyponyms, we select the remaining required examples randomly.as the distribution of positive and negative examples in the data is unknown, we set the ratio of negative to positive examples as parameter of the model, as in (bergsma et al , 2008).<papid> D08-1007 </papid></nextsent>
<nextsent>5.1.3 insufficient examples when the number of training examples for ruleor category is below certain minimum, there sulting classifier is expected to be of poor quality.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4830">
<title id=" W11-2403.xml">classification based contextual preferences </title>
<section> a self-supervised context model </section>
<citcontext>
<prevsection>
<prevsent>we do that by applying similar procedure which uses cohyponyms of the seeds, e.g. baseball for hockey or islam for christianity.
</prevsent>
<prevsent>cohyponymy is non-entailing relation; hence, by using it we expect to obtain semantically-related,yet invalid contexts.
</prevsent>
</prevsection>
<citsent citstr=" D08-1007 ">
if not enough negative examples are retrieved using cohyponyms, we select the remaining required examples randomly.as the distribution of positive and negative examples in the data is unknown, we set the ratio of negative to positive examples as parameter of the model, as in (bergsma et al , 2008).<papid> D08-1007 </papid></citsent>
<aftsection>
<nextsent>5.1.3 insufficient examples when the number of training examples for ruleor category is below certain minimum, there sulting classifier is expected to be of poor quality.
</nextsent>
<nextsent>this usually happens for positive examples in any of the following two cases: (i) the seed is rare in the training set; (ii) the desired sense of the seed is rarely found in the training set, and unwanted senses were filtered by our retrieval query.
</nextsent>
<nextsent>for instance, nazarene does not occur at all in the training set, and the classifier corresponding to the rule nazarene?
</nextsent>
<nextsent>christian?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4831">
<title id=" W11-2403.xml">classification based contextual preferences </title>
<section> a self-supervised context model </section>
<citcontext>
<prevsection>
<prevsent>for randomly sampled negative examples, where no matched query terms exist, we randomly select terms in the document as matches?
</prevsent>
<prevsent>for local feature extraction.
</prevsent>
</prevsection>
<citsent citstr=" H92-1045 ">
if more than one match ofthe same term is found in document, we assume one sense-per-discourse (gale et al , 1992) <papid> H92-1045 </papid>and jointly extract features for all matches of the term.</citsent>
<aftsection>
<nextsent>5.2 applying the classifiers.
</nextsent>
<nextsent>during inference, for each direct match in document, the corresponding ch is applied.
</nextsent>
<nextsent>for an indirect match, the respective cr is also applied.
</nextsent>
<nextsent>in addition, ch is applied to the matched rules.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4837">
<title id=" W11-2403.xml">classification based contextual preferences </title>
<section> experimental setting.  </section>
<citcontext>
<prevsection>
<prevsent>other types of information may be used for this purpose, e.g. words from category descriptions, if such exist.we applied standard preprocessing (sentence splitting, tokenization, lemmatization and part of speech tagging) to all documents in the datasets.
</prevsent>
<prevsent>all terms, including those denoting category names and rules, are represented by their lemma and part of speech.
</prevsent>
</prevsection>
<citsent citstr=" P09-1051 ">
as sources for lexical entailment rules we used wordnet 3.0 (synonyms, hyponyms, derivations and meronyms) and wikipedia-derived rule-base (shnarch et al , 2009).<papid> P09-1051 </papid></citsent>
<aftsection>
<nextsent>unlike barak09 we did not limit the rules extracted from wordnet to the most frequent senses and used all rule types from the wikipedia-based resource.
</nextsent>
<nextsent>7.2 self-supervised model tuning.
</nextsent>
<nextsent>tuning of the self-supervised context models parameters (number of training examples, negative to positive ratio, feature set and the way negative examples are obtained) was performed over development sets sampled from the training sets.
</nextsent>
<nextsent>based on this tuning, some parameters varied between the datasets and between classifier types (ch vs. cr).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4840">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>this paper describes the german-englishtranslation system developed by the ark research group at carnegie mellon university for the sixth workshop on machine translation (wmt11).
</prevsent>
<prevsent>we present the results of several modeling and training improvement sto our core hierarchical phrase-based translation system, including: feature engineering to improve modeling of the derivation structure of translations; better handing of oovs; and using development set translations into other languages to create additional pseudo references for training.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
we describe the german-english translation system submitted to the shared translation task in the sixth workshop on machine translation (wmt11) by theark research group at carnegie mellon univer sity.1 the core translation system is hierarchical phrase-based machine translation system (chiang,2007) <papid> J07-2003 </papid>that has been extended in several ways described in this paper.</citsent>
<aftsection>
<nextsent>some of our innovations focus on modeling.
</nextsent>
<nextsent>since german and english word orders can diverge considerably, particularly in non-matrix clauses, we focused on feature engineering to improve the modeling of long-distance relationships, which are poorly captured in standard hierarchical phrase based translation models.
</nextsent>
<nextsent>to do so, we developed features that assess the goodness of the source 1http://www.ark.cs.cmu.edu language parse tree under the translation grammar (rather than of linguistic?
</nextsent>
<nextsent>grammar).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4841">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>to do so, we developed features that assess the goodness of the source 1http://www.ark.cs.cmu.edu language parse tree under the translation grammar (rather than of linguistic?
</prevsent>
<prevsent>grammar).
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
to train the feature weights, we made use of novel two-phase training algorithm that incorporates probabilistic training objective and standard minimum error training (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>these segmentation features were supplemented with 7-gram class-based language model, which more directly models long-distance relationships.
</nextsent>
<nextsent>together, these features provide modest improvement over the baseline and suggest interesting directions for future work.
</nextsent>
<nextsent>while our work on parse modeling was involved and required substantial changes to the training pipeline, some other modeling enhancements were quite simple: for example, improving how out-of-vocabulary words are handled.
</nextsent>
<nextsent>we propose very simple change, and show that it provides small, consistent gain.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4842">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we propose very simple change, and show that it provides small, consistent gain.
</prevsent>
<prevsent>on the training side, we had two improvements over our baseline system.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
first, we were inspired by the work of madnani (2010), who showed that when training to optimize bleu (papineni et al,2002), <papid> P02-1040 </papid>over fitting is reduced by supplementing single human-generated reference translation with additional computer-generated references.</citsent>
<aftsection>
<nextsent>we generated supplementary pseudo-references for our development set (which is translated into many languages, but once) by using mt output from secondary spanish-english translation system.
</nextsent>
<nextsent>second,following foster and kuhn (2009), <papid> W09-0439 </papid>we used secondary development set to select from among many optimization runs, which further improved general ization.</nextsent>
<nextsent>we largely sought techniques that did not require language-specific resources (e.g., treebanks, pos 337annotations, morphological analyzers).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4843">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>first, we were inspired by the work of madnani (2010), who showed that when training to optimize bleu (papineni et al,2002), <papid> P02-1040 </papid>over fitting is reduced by supplementing single human-generated reference translation with additional computer-generated references.</prevsent>
<prevsent>we generated supplementary pseudo-references for our development set (which is translated into many languages, but once) by using mt output from secondary spanish-english translation system.</prevsent>
</prevsection>
<citsent citstr=" W09-0439 ">
second,following foster and kuhn (2009), <papid> W09-0439 </papid>we used secondary development set to select from among many optimization runs, which further improved general ization.</citsent>
<aftsection>
<nextsent>we largely sought techniques that did not require language-specific resources (e.g., treebanks, pos 337annotations, morphological analyzers).
</nextsent>
<nextsent>an exception is compound segmentation model used for preprocessing that was trained on corpus of manually segmented german.
</nextsent>
<nextsent>aside from this, no further manually annotated data was used, and we suspect many of the improvements described here can be had in other language pairs.
</nextsent>
<nextsent>despite avoidinglanguage-specific resources and using only the training data provided by the workshop, an extensive manual evaluation determined that the outputs produced were of significantly higher quality than both statistical and rule-based systems that made use of language-specific resources (callison-burch et al, 2011).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4846">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> baseline system and data.  </section>
<citcontext>
<prevsection>
<prevsent>aside from this, no further manually annotated data was used, and we suspect many of the improvements described here can be had in other language pairs.
</prevsent>
<prevsent>despite avoidinglanguage-specific resources and using only the training data provided by the workshop, an extensive manual evaluation determined that the outputs produced were of significantly higher quality than both statistical and rule-based systems that made use of language-specific resources (callison-burch et al, 2011).
</prevsent>
</prevsection>
<citsent citstr=" P10-4002 ">
our translation system is based on hierarchical phrase-based translation model (chiang, 2007), <papid> J07-2003 </papid>as implemented in the cdec decoder (dyer et al, 2010).<papid> P10-4002 </papid></citsent>
<aftsection>
<nextsent>since german is language that makes productive use of closed?
</nextsent>
<nextsent>compounds (compound words written as single orthographic token), we use crf segmentation model of to evaluate the probability of all possible segment ations, encoding the most probable ones compactly in lattice (dyer, 2009).<papid> N09-1046 </papid></nextsent>
<nextsent>for the purposes of grammar induction, the single most probable segmentation of each word in the source side of the parallel training data under the model was inferred.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4847">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> baseline system and data.  </section>
<citcontext>
<prevsection>
<prevsent>our translation system is based on hierarchical phrase-based translation model (chiang, 2007), <papid> J07-2003 </papid>as implemented in the cdec decoder (dyer et al, 2010).<papid> P10-4002 </papid></prevsent>
<prevsent>since german is language that makes productive use of closed?</prevsent>
</prevsection>
<citsent citstr=" N09-1046 ">
compounds (compound words written as single orthographic token), we use crf segmentation model of to evaluate the probability of all possible segment ations, encoding the most probable ones compactly in lattice (dyer, 2009).<papid> N09-1046 </papid></citsent>
<aftsection>
<nextsent>for the purposes of grammar induction, the single most probable segmentation of each word in the source side of the parallel training data under the model was inferred.
</nextsent>
<nextsent>the parallel data were aligned using the giza++ implementation of ibm model 4 run in both directions and then symmetrized using the grow-diag-final-and heuristic (och and ney, 2002; <papid> P02-1038 </papid>brown et al, 1993; <papid> J93-2003 </papid>koehn et al, 2003).<papid> N03-1017 </papid></nextsent>
<nextsent>the aligned corpus was encoded as suffix array(lopez, 2008) <papid> C08-1064 </papid>and lattice-specific grammars (con taining just the rules that are capable of matching spans in the input lattice) were extracted for each sentence in the test and development sets, using the heuristics recommended by chiang (2007).<papid> J07-2003 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4848">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> baseline system and data.  </section>
<citcontext>
<prevsection>
<prevsent>compounds (compound words written as single orthographic token), we use crf segmentation model of to evaluate the probability of all possible segment ations, encoding the most probable ones compactly in lattice (dyer, 2009).<papid> N09-1046 </papid></prevsent>
<prevsent>for the purposes of grammar induction, the single most probable segmentation of each word in the source side of the parallel training data under the model was inferred.</prevsent>
</prevsection>
<citsent citstr=" P02-1038 ">
the parallel data were aligned using the giza++ implementation of ibm model 4 run in both directions and then symmetrized using the grow-diag-final-and heuristic (och and ney, 2002; <papid> P02-1038 </papid>brown et al, 1993; <papid> J93-2003 </papid>koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the aligned corpus was encoded as suffix array(lopez, 2008) <papid> C08-1064 </papid>and lattice-specific grammars (con taining just the rules that are capable of matching spans in the input lattice) were extracted for each sentence in the test and development sets, using the heuristics recommended by chiang (2007).<papid> J07-2003 </papid></nextsent>
<nextsent>a 4-gram modified kneser-ney language model (chen and goodman, 1996) <papid> P96-1041 </papid>was constructed using the sri language modeling toolkit (stolcke, 2002)from the english side of the parallel text, the monolingual english data, and the english version 4 gigaword corpus (parker et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4849">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> baseline system and data.  </section>
<citcontext>
<prevsection>
<prevsent>compounds (compound words written as single orthographic token), we use crf segmentation model of to evaluate the probability of all possible segment ations, encoding the most probable ones compactly in lattice (dyer, 2009).<papid> N09-1046 </papid></prevsent>
<prevsent>for the purposes of grammar induction, the single most probable segmentation of each word in the source side of the parallel training data under the model was inferred.</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
the parallel data were aligned using the giza++ implementation of ibm model 4 run in both directions and then symmetrized using the grow-diag-final-and heuristic (och and ney, 2002; <papid> P02-1038 </papid>brown et al, 1993; <papid> J93-2003 </papid>koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the aligned corpus was encoded as suffix array(lopez, 2008) <papid> C08-1064 </papid>and lattice-specific grammars (con taining just the rules that are capable of matching spans in the input lattice) were extracted for each sentence in the test and development sets, using the heuristics recommended by chiang (2007).<papid> J07-2003 </papid></nextsent>
<nextsent>a 4-gram modified kneser-ney language model (chen and goodman, 1996) <papid> P96-1041 </papid>was constructed using the sri language modeling toolkit (stolcke, 2002)from the english side of the parallel text, the monolingual english data, and the english version 4 gigaword corpus (parker et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4850">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> baseline system and data.  </section>
<citcontext>
<prevsection>
<prevsent>compounds (compound words written as single orthographic token), we use crf segmentation model of to evaluate the probability of all possible segment ations, encoding the most probable ones compactly in lattice (dyer, 2009).<papid> N09-1046 </papid></prevsent>
<prevsent>for the purposes of grammar induction, the single most probable segmentation of each word in the source side of the parallel training data under the model was inferred.</prevsent>
</prevsection>
<citsent citstr=" N03-1017 ">
the parallel data were aligned using the giza++ implementation of ibm model 4 run in both directions and then symmetrized using the grow-diag-final-and heuristic (och and ney, 2002; <papid> P02-1038 </papid>brown et al, 1993; <papid> J93-2003 </papid>koehn et al, 2003).<papid> N03-1017 </papid></citsent>
<aftsection>
<nextsent>the aligned corpus was encoded as suffix array(lopez, 2008) <papid> C08-1064 </papid>and lattice-specific grammars (con taining just the rules that are capable of matching spans in the input lattice) were extracted for each sentence in the test and development sets, using the heuristics recommended by chiang (2007).<papid> J07-2003 </papid></nextsent>
<nextsent>a 4-gram modified kneser-ney language model (chen and goodman, 1996) <papid> P96-1041 </papid>was constructed using the sri language modeling toolkit (stolcke, 2002)from the english side of the parallel text, the monolingual english data, and the english version 4 gigaword corpus (parker et al, 2009).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4851">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> baseline system and data.  </section>
<citcontext>
<prevsection>
<prevsent>for the purposes of grammar induction, the single most probable segmentation of each word in the source side of the parallel training data under the model was inferred.
</prevsent>
<prevsent>the parallel data were aligned using the giza++ implementation of ibm model 4 run in both directions and then symmetrized using the grow-diag-final-and heuristic (och and ney, 2002; <papid> P02-1038 </papid>brown et al, 1993; <papid> J93-2003 </papid>koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
</prevsection>
<citsent citstr=" C08-1064 ">
the aligned corpus was encoded as suffix array(lopez, 2008) <papid> C08-1064 </papid>and lattice-specific grammars (con taining just the rules that are capable of matching spans in the input lattice) were extracted for each sentence in the test and development sets, using the heuristics recommended by chiang (2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>a 4-gram modified kneser-ney language model (chen and goodman, 1996) <papid> P96-1041 </papid>was constructed using the sri language modeling toolkit (stolcke, 2002)from the english side of the parallel text, the monolingual english data, and the english version 4 gigaword corpus (parker et al, 2009).</nextsent>
<nextsent>since there were many duplicate segments in the training data (muchof which was crawled from the web), duplicate segments and segments longer than 100 words were re moved.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4853">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> baseline system and data.  </section>
<citcontext>
<prevsection>
<prevsent>the parallel data were aligned using the giza++ implementation of ibm model 4 run in both directions and then symmetrized using the grow-diag-final-and heuristic (och and ney, 2002; <papid> P02-1038 </papid>brown et al, 1993; <papid> J93-2003 </papid>koehn et al, 2003).<papid> N03-1017 </papid></prevsent>
<prevsent>the aligned corpus was encoded as suffix array(lopez, 2008) <papid> C08-1064 </papid>and lattice-specific grammars (con taining just the rules that are capable of matching spans in the input lattice) were extracted for each sentence in the test and development sets, using the heuristics recommended by chiang (2007).<papid> J07-2003 </papid></prevsent>
</prevsection>
<citsent citstr=" P96-1041 ">
a 4-gram modified kneser-ney language model (chen and goodman, 1996) <papid> P96-1041 </papid>was constructed using the sri language modeling toolkit (stolcke, 2002)from the english side of the parallel text, the monolingual english data, and the english version 4 gigaword corpus (parker et al, 2009).</citsent>
<aftsection>
<nextsent>since there were many duplicate segments in the training data (muchof which was crawled from the web), duplicate segments and segments longer than 100 words were removed.
</nextsent>
<nextsent>inference was carried out using the language modeling library described by heafield (2011).<papid> W11-2123 </papid></nextsent>
<nextsent>the newstest-2009 set (with the 500 longest segments removed) was used for development,2 and newstest-2010 was used as development testset.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4854">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> baseline system and data.  </section>
<citcontext>
<prevsection>
<prevsent>a 4-gram modified kneser-ney language model (chen and goodman, 1996) <papid> P96-1041 </papid>was constructed using the sri language modeling toolkit (stolcke, 2002)from the english side of the parallel text, the monolingual english data, and the english version 4 gigaword corpus (parker et al, 2009).</prevsent>
<prevsent>since there were many duplicate segments in the training data (muchof which was crawled from the web), duplicate segments and segments longer than 100 words were re moved.</prevsent>
</prevsection>
<citsent citstr=" W11-2123 ">
inference was carried out using the language modeling library described by heafield (2011).<papid> W11-2123 </papid></citsent>
<aftsection>
<nextsent>the newstest-2009 set (with the 500 longest segments removed) was used for development,2 and newstest-2010 was used as development testset.
</nextsent>
<nextsent>results in this paper are reported on the devtest set using uncased bleu4 with single reference translation.
</nextsent>
<nextsent>minimum error rate training (och, 2003) <papid> P03-1021 </papid>was used to optimize the parameters of the system to maximize bleu on the development data,and inference was performed over pruned hypergraph representation of the translation hypothesis space (kumar et al, 2009).<papid> P09-1019 </papid></nextsent>
<nextsent>for the experiments reported in this paper, viterbi (max-derivation) decoding was used.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4857">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> baseline system and data.  </section>
<citcontext>
<prevsection>
<prevsent>the newstest-2009 set (with the 500 longest segments removed) was used for development,2 and newstest-2010 was used as development testset.
</prevsent>
<prevsent>results in this paper are reported on the devtest set using uncased bleu4 with single reference translation.
</prevsent>
</prevsection>
<citsent citstr=" P09-1019 ">
minimum error rate training (och, 2003) <papid> P03-1021 </papid>was used to optimize the parameters of the system to maximize bleu on the development data,and inference was performed over pruned hypergraph representation of the translation hypothesis space (kumar et al, 2009).<papid> P09-1019 </papid></citsent>
<aftsection>
<nextsent>for the experiments reported in this paper, viterbi (max-derivation) decoding was used.
</nextsent>
<nextsent>the system submitted for manual evaluation used segment-level mbr decoding with 1 ? bleu as the loss function, approximated over 500-best list for each sentence.this reliably results in small but consistent improvement in translation quality, but is much more time consuming to compute (kumar and byrne, 2004).<papid> N04-1022 </papid></nextsent>
<nextsent>improving phrase-based translation systems is challenging in part because our intuitions about what makes good?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4858">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> baseline system and data.  </section>
<citcontext>
<prevsection>
<prevsent>minimum error rate training (och, 2003) <papid> P03-1021 </papid>was used to optimize the parameters of the system to maximize bleu on the development data,and inference was performed over pruned hypergraph representation of the translation hypothesis space (kumar et al, 2009).<papid> P09-1019 </papid></prevsent>
<prevsent>for the experiments reported in this paper, viterbi (max-derivation) decoding was used.</prevsent>
</prevsection>
<citsent citstr=" N04-1022 ">
the system submitted for manual evaluation used segment-level mbr decoding with 1 ? bleu as the loss function, approximated over 500-best list for each sentence.this reliably results in small but consistent improvement in translation quality, but is much more time consuming to compute (kumar and byrne, 2004).<papid> N04-1022 </papid></citsent>
<aftsection>
<nextsent>improving phrase-based translation systems is challenging in part because our intuitions about what makes good?
</nextsent>
<nextsent>phrase or translation derivation are often poor.
</nextsent>
<nextsent>for example, restricting phrases and rules to be consistent with syntactic constituents consistently harms performance (chiang, 2007; <papid> J07-2003 </papid>galley et al, 2006; <papid> P06-1121 </papid>koehn et al, 2003), <papid> N03-1017 </papid>although our intuitions might suggest this is reasonable thing to do.</nextsent>
<nextsent>on the other hand, it has been shown that incorporating syntactic information in the form of features can lead to improved performance (chiang, 2010; <papid> P10-1146 </papid>gimpel and smith, 2009; <papid> D09-1023 </papid>marton and resnik,2008).<papid> P08-1114 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4860">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>improving phrase-based translation systems is challenging in part because our intuitions about what makes good?
</prevsent>
<prevsent>phrase or translation derivation are often poor.
</prevsent>
</prevsection>
<citsent citstr=" P06-1121 ">
for example, restricting phrases and rules to be consistent with syntactic constituents consistently harms performance (chiang, 2007; <papid> J07-2003 </papid>galley et al, 2006; <papid> P06-1121 </papid>koehn et al, 2003), <papid> N03-1017 </papid>although our intuitions might suggest this is reasonable thing to do.</citsent>
<aftsection>
<nextsent>on the other hand, it has been shown that incorporating syntactic information in the form of features can lead to improved performance (chiang, 2010; <papid> P10-1146 </papid>gimpel and smith, 2009; <papid> D09-1023 </papid>marton and resnik,2008).<papid> P08-1114 </papid></nextsent>
<nextsent>syntactic features that are computed by assessing the overlap of the translation parse with alinguistic parse can be understood to improve translation because they lead to better model of what correct?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4862">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>phrase or translation derivation are often poor.
</prevsent>
<prevsent>for example, restricting phrases and rules to be consistent with syntactic constituents consistently harms performance (chiang, 2007; <papid> J07-2003 </papid>galley et al, 2006; <papid> P06-1121 </papid>koehn et al, 2003), <papid> N03-1017 </papid>although our intuitions might suggest this is reasonable thing to do.</prevsent>
</prevsection>
<citsent citstr=" P10-1146 ">
on the other hand, it has been shown that incorporating syntactic information in the form of features can lead to improved performance (chiang, 2010; <papid> P10-1146 </papid>gimpel and smith, 2009; <papid> D09-1023 </papid>marton and resnik,2008).<papid> P08-1114 </papid></citsent>
<aftsection>
<nextsent>syntactic features that are computed by assessing the overlap of the translation parse with alinguistic parse can be understood to improve translation because they lead to better model of what correct?
</nextsent>
<nextsent>parse of the source sentence is under the translation grammar.like the soft syntactic features?
</nextsent>
<nextsent>used in pre 2removing long segments substantially reduces training time and does not appear to negatively affect performance.
</nextsent>
<nextsent>338 vious work (marton and resnik, 2008; <papid> P08-1114 </papid>chiang et al., 2008), <papid> D08-1024 </papid>we propose features to assess the tree structure induced during translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4863">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>phrase or translation derivation are often poor.
</prevsent>
<prevsent>for example, restricting phrases and rules to be consistent with syntactic constituents consistently harms performance (chiang, 2007; <papid> J07-2003 </papid>galley et al, 2006; <papid> P06-1121 </papid>koehn et al, 2003), <papid> N03-1017 </papid>although our intuitions might suggest this is reasonable thing to do.</prevsent>
</prevsection>
<citsent citstr=" D09-1023 ">
on the other hand, it has been shown that incorporating syntactic information in the form of features can lead to improved performance (chiang, 2010; <papid> P10-1146 </papid>gimpel and smith, 2009; <papid> D09-1023 </papid>marton and resnik,2008).<papid> P08-1114 </papid></citsent>
<aftsection>
<nextsent>syntactic features that are computed by assessing the overlap of the translation parse with alinguistic parse can be understood to improve translation because they lead to better model of what correct?
</nextsent>
<nextsent>parse of the source sentence is under the translation grammar.like the soft syntactic features?
</nextsent>
<nextsent>used in pre 2removing long segments substantially reduces training time and does not appear to negatively affect performance.
</nextsent>
<nextsent>338 vious work (marton and resnik, 2008; <papid> P08-1114 </papid>chiang et al., 2008), <papid> D08-1024 </papid>we propose features to assess the tree structure induced during translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4864">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>phrase or translation derivation are often poor.
</prevsent>
<prevsent>for example, restricting phrases and rules to be consistent with syntactic constituents consistently harms performance (chiang, 2007; <papid> J07-2003 </papid>galley et al, 2006; <papid> P06-1121 </papid>koehn et al, 2003), <papid> N03-1017 </papid>although our intuitions might suggest this is reasonable thing to do.</prevsent>
</prevsection>
<citsent citstr=" P08-1114 ">
on the other hand, it has been shown that incorporating syntactic information in the form of features can lead to improved performance (chiang, 2010; <papid> P10-1146 </papid>gimpel and smith, 2009; <papid> D09-1023 </papid>marton and resnik,2008).<papid> P08-1114 </papid></citsent>
<aftsection>
<nextsent>syntactic features that are computed by assessing the overlap of the translation parse with alinguistic parse can be understood to improve translation because they lead to better model of what correct?
</nextsent>
<nextsent>parse of the source sentence is under the translation grammar.like the soft syntactic features?
</nextsent>
<nextsent>used in pre 2removing long segments substantially reduces training time and does not appear to negatively affect performance.
</nextsent>
<nextsent>338 vious work (marton and resnik, 2008; <papid> P08-1114 </papid>chiang et al., 2008), <papid> D08-1024 </papid>we propose features to assess the tree structure induced during translation.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4866">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>parse of the source sentence is under the translation grammar.like the soft syntactic features?
</prevsent>
<prevsent>used in pre 2removing long segments substantially reduces training time and does not appear to negatively affect performance.
</prevsent>
</prevsection>
<citsent citstr=" D08-1024 ">
338 vious work (marton and resnik, 2008; <papid> P08-1114 </papid>chiang et al., 2008), <papid> D08-1024 </papid>we propose features to assess the tree structure induced during translation.</citsent>
<aftsection>
<nextsent>however, unlike that work, we do not relyon linguistic source parses, but instead only make use of features that are directly computable from the source sentence and the parse structure being considered in the decoder.
</nextsent>
<nextsent>in particular, we take inspiration from the model of klein and manning (2002), <papid> P02-1017 </papid>which models constituency in terms of the contexts that rule productions occur in.</nextsent>
<nextsent>additionally, we make use of salient aspects of the spans being dominated by nonterminal, such as the words at the beginning andend of the span, and the length of the span.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4867">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>338 vious work (marton and resnik, 2008; <papid> P08-1114 </papid>chiang et al., 2008), <papid> D08-1024 </papid>we propose features to assess the tree structure induced during translation.</prevsent>
<prevsent>however, unlike that work, we do not relyon linguistic source parses, but instead only make use of features that are directly computable from the source sentence and the parse structure being considered in the de coder.</prevsent>
</prevsection>
<citsent citstr=" P02-1017 ">
in particular, we take inspiration from the model of klein and manning (2002), <papid> P02-1017 </papid>which models constituency in terms of the contexts that rule productions occur in.</citsent>
<aftsection>
<nextsent>additionally, we make use of salient aspects of the spans being dominated by nonterminal, such as the words at the beginning andend of the span, and the length of the span.
</nextsent>
<nextsent>importantly, the features do not relyon the target words being predicted, but only look at the structure of the translation derivation.
</nextsent>
<nextsent>as such, they can be under stood as monolingual parse features.3 table 1 lists the feature templates that were used.
</nextsent>
<nextsent>template description ctx:fi1, fj context bigram ctx:fi1, fj , context bigram + nt ctx:fi1, fj , x, (j ? i) context bigram + nt + len lu:fi1 left unigram lb:fi1, fi left bigram (overlapping) ru:fj right unigram rb:fj1, fj right bigram (overlapping) table 1: context feature templates for features extracted from every translation rule used; and indicate hypothesized constituent span, is its nonterminal category label (in our grammar, or s), and fk is the kth word of the source sentence, with 1 = s? and |f| = ?/s?.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4868">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 two-phase discriminative learning.
</prevsent>
<prevsent>the parse features just introduced are numerous and sparse, which means that mert can not be usedto infer their weights.
</prevsent>
</prevsection>
<citsent citstr=" W04-3201 ">
instead, we require learning algorithm that can cope with millions of features and avoid over fitting, perhaps by eliminating most of the features and keeping only the most valuable (which would also keep the model compact).3similar features have been proposed for use in discriminative monolingual parsing models (taskar et al, 2004).<papid> W04-3201 </papid>furthermore, we would like to be able to still target the bleu measure of translation quality during learning.</citsent>
<aftsection>
<nextsent>while large-scale discriminative training for machine translation is widely studied problem(hopkins and may, 2011; <papid> D11-1125 </papid>li and eisner, 2009; <papid> D09-1005 </papid>devlin, 2009; blunsom et al, 2008; <papid> P08-1024 </papid>watanabe et al, 2007; <papid> D07-1080 </papid>arun and koehn, 2007; liang et al, 2006), <papid> P06-1096 </papid>no tractable algorithm exists for learning large number of feature weights while directly optimizing corpus-level metric like bleu.</nextsent>
<nextsent>rather than resorting to decomposable approximation, we have explored new two-phase training algorithm in development of this system.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4869">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>the parse features just introduced are numerous and sparse, which means that mert can not be usedto infer their weights.
</prevsent>
<prevsent>instead, we require learning algorithm that can cope with millions of features and avoid over fitting, perhaps by eliminating most of the features and keeping only the most valuable (which would also keep the model compact).3similar features have been proposed for use in discriminative monolingual parsing models (taskar et al, 2004).<papid> W04-3201 </papid>furthermore, we would like to be able to still target the bleu measure of translation quality during learning.</prevsent>
</prevsection>
<citsent citstr=" D11-1125 ">
while large-scale discriminative training for machine translation is widely studied problem(hopkins and may, 2011; <papid> D11-1125 </papid>li and eisner, 2009; <papid> D09-1005 </papid>devlin, 2009; blunsom et al, 2008; <papid> P08-1024 </papid>watanabe et al, 2007; <papid> D07-1080 </papid>arun and koehn, 2007; liang et al, 2006), <papid> P06-1096 </papid>no tractable algorithm exists for learning large number of feature weights while directly optimizing corpus-level metric like bleu.</citsent>
<aftsection>
<nextsent>rather than resorting to decomposable approximation, we have explored new two-phase training algorithm in development of this system.
</nextsent>
<nextsent>the two-phase algorithm works as follows.
</nextsent>
<nextsent>in phase 1, we use non-bleu objective to train translation model that includes the large feature set.then, we use this model to compute small number of coarse summary features,?
</nextsent>
<nextsent>which summarize the opinion?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4870">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>the parse features just introduced are numerous and sparse, which means that mert can not be usedto infer their weights.
</prevsent>
<prevsent>instead, we require learning algorithm that can cope with millions of features and avoid over fitting, perhaps by eliminating most of the features and keeping only the most valuable (which would also keep the model compact).3similar features have been proposed for use in discriminative monolingual parsing models (taskar et al, 2004).<papid> W04-3201 </papid>furthermore, we would like to be able to still target the bleu measure of translation quality during learning.</prevsent>
</prevsection>
<citsent citstr=" D09-1005 ">
while large-scale discriminative training for machine translation is widely studied problem(hopkins and may, 2011; <papid> D11-1125 </papid>li and eisner, 2009; <papid> D09-1005 </papid>devlin, 2009; blunsom et al, 2008; <papid> P08-1024 </papid>watanabe et al, 2007; <papid> D07-1080 </papid>arun and koehn, 2007; liang et al, 2006), <papid> P06-1096 </papid>no tractable algorithm exists for learning large number of feature weights while directly optimizing corpus-level metric like bleu.</citsent>
<aftsection>
<nextsent>rather than resorting to decomposable approximation, we have explored new two-phase training algorithm in development of this system.
</nextsent>
<nextsent>the two-phase algorithm works as follows.
</nextsent>
<nextsent>in phase 1, we use non-bleu objective to train translation model that includes the large feature set.then, we use this model to compute small number of coarse summary features,?
</nextsent>
<nextsent>which summarize the opinion?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4871">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>the parse features just introduced are numerous and sparse, which means that mert can not be usedto infer their weights.
</prevsent>
<prevsent>instead, we require learning algorithm that can cope with millions of features and avoid over fitting, perhaps by eliminating most of the features and keeping only the most valuable (which would also keep the model compact).3similar features have been proposed for use in discriminative monolingual parsing models (taskar et al, 2004).<papid> W04-3201 </papid>furthermore, we would like to be able to still target the bleu measure of translation quality during learning.</prevsent>
</prevsection>
<citsent citstr=" P08-1024 ">
while large-scale discriminative training for machine translation is widely studied problem(hopkins and may, 2011; <papid> D11-1125 </papid>li and eisner, 2009; <papid> D09-1005 </papid>devlin, 2009; blunsom et al, 2008; <papid> P08-1024 </papid>watanabe et al, 2007; <papid> D07-1080 </papid>arun and koehn, 2007; liang et al, 2006), <papid> P06-1096 </papid>no tractable algorithm exists for learning large number of feature weights while directly optimizing corpus-level metric like bleu.</citsent>
<aftsection>
<nextsent>rather than resorting to decomposable approximation, we have explored new two-phase training algorithm in development of this system.
</nextsent>
<nextsent>the two-phase algorithm works as follows.
</nextsent>
<nextsent>in phase 1, we use non-bleu objective to train translation model that includes the large feature set.then, we use this model to compute small number of coarse summary features,?
</nextsent>
<nextsent>which summarize the opinion?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4872">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>the parse features just introduced are numerous and sparse, which means that mert can not be usedto infer their weights.
</prevsent>
<prevsent>instead, we require learning algorithm that can cope with millions of features and avoid over fitting, perhaps by eliminating most of the features and keeping only the most valuable (which would also keep the model compact).3similar features have been proposed for use in discriminative monolingual parsing models (taskar et al, 2004).<papid> W04-3201 </papid>furthermore, we would like to be able to still target the bleu measure of translation quality during learning.</prevsent>
</prevsection>
<citsent citstr=" D07-1080 ">
while large-scale discriminative training for machine translation is widely studied problem(hopkins and may, 2011; <papid> D11-1125 </papid>li and eisner, 2009; <papid> D09-1005 </papid>devlin, 2009; blunsom et al, 2008; <papid> P08-1024 </papid>watanabe et al, 2007; <papid> D07-1080 </papid>arun and koehn, 2007; liang et al, 2006), <papid> P06-1096 </papid>no tractable algorithm exists for learning large number of feature weights while directly optimizing corpus-level metric like bleu.</citsent>
<aftsection>
<nextsent>rather than resorting to decomposable approximation, we have explored new two-phase training algorithm in development of this system.
</nextsent>
<nextsent>the two-phase algorithm works as follows.
</nextsent>
<nextsent>in phase 1, we use non-bleu objective to train translation model that includes the large feature set.then, we use this model to compute small number of coarse summary features,?
</nextsent>
<nextsent>which summarize the opinion?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4873">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>the parse features just introduced are numerous and sparse, which means that mert can not be usedto infer their weights.
</prevsent>
<prevsent>instead, we require learning algorithm that can cope with millions of features and avoid over fitting, perhaps by eliminating most of the features and keeping only the most valuable (which would also keep the model compact).3similar features have been proposed for use in discriminative monolingual parsing models (taskar et al, 2004).<papid> W04-3201 </papid>furthermore, we would like to be able to still target the bleu measure of translation quality during learning.</prevsent>
</prevsection>
<citsent citstr=" P06-1096 ">
while large-scale discriminative training for machine translation is widely studied problem(hopkins and may, 2011; <papid> D11-1125 </papid>li and eisner, 2009; <papid> D09-1005 </papid>devlin, 2009; blunsom et al, 2008; <papid> P08-1024 </papid>watanabe et al, 2007; <papid> D07-1080 </papid>arun and koehn, 2007; liang et al, 2006), <papid> P06-1096 </papid>no tractable algorithm exists for learning large number of feature weights while directly optimizing corpus-level metric like bleu.</citsent>
<aftsection>
<nextsent>rather than resorting to decomposable approximation, we have explored new two-phase training algorithm in development of this system.
</nextsent>
<nextsent>the two-phase algorithm works as follows.
</nextsent>
<nextsent>in phase 1, we use non-bleu objective to train translation model that includes the large feature set.then, we use this model to compute small number of coarse summary features,?
</nextsent>
<nextsent>which summarize the opinion?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4875">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>= ? |k|, the `1 norm, which forces many parameters to be exactly 0.
</prevsent>
<prevsent>although is not convex in ?
</prevsent>
</prevsection>
<citsent citstr=" P09-1054 ">
(on account of the latent derivation variable), we make use of an online stochastic gradient descent algorithm that imposes an `1 penalty on the objective (tsuruoka et al., 2009).<papid> P09-1054 </papid></citsent>
<aftsection>
<nextsent>online algorithms are often effective for non-convex objectives (liang and klein, 2009).<papid> N09-1069 </papid></nextsent>
<nextsent>we selected 12,500 sentences randomly from the news-commentary portion of the training data to useto train the latent variable model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4876">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>although is not convex in ?
</prevsent>
<prevsent>(on account of the latent derivation variable), we make use of an online stochastic gradient descent algorithm that imposes an `1 penalty on the objective (tsuruoka et al., 2009).<papid> P09-1054 </papid></prevsent>
</prevsection>
<citsent citstr=" N09-1069 ">
online algorithms are often effective for non-convex objectives (liang and klein, 2009).<papid> N09-1069 </papid></citsent>
<aftsection>
<nextsent>we selected 12,500 sentences randomly from the news-commentary portion of the training data to useto train the latent variable model.
</nextsent>
<nextsent>using the standard rule extraction heuristics (chiang, 2007), <papid> J07-2003 </papid>9,967 of the sentence pairs could be derived.4 in addition to the parse features describe above, the standard phrase features (relative frequency and lexical translation probabilities), and rule count feature wereincluded.</nextsent>
<nextsent>training was run for 48 hours on single machine, which resulted in 8 passes through the training data, instantiating over 8m unique features.the regularization strength ? was chosen so that approximately 10, 000 (of the 8m) features would be non-zero.5 3.1.2 summary feature sas outlined above, the phase 1 model will be incorporated into the final translation model using low dimensional summary?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4880">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>to further support the modeling of larger spans, we incorporated 7-gram class-based language model.
</prevsent>
<prevsent>automatic word clusters are attractive because they can be learned for any language without supervised data, and, unlike part-of-speech annotations, each word is in only single class, which simplifies inference.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
we performed brown clustering (brown et al, 1992) <papid> J92-4003 </papid>on 900k sentences from our language modeling data(including the news commentary corpus and subset of gigaword).</citsent>
<aftsection>
<nextsent>we obtained 1,000 clusters using an implementation provided by liang (2005),6 asturian et al (2010) <papid> P10-1040 </papid>found that relatively large numbers clusters gave better performance for information extraction tasks.</nextsent>
<nextsent>we then replaced words with their clusters in our language modeling data and built 7-gram lm with witten-bell smoothing(witten and bell, 1991).7 the last two rows of ta 6http://www.cs.berkeley.edu/pliang/ software7the distributional assumptions made by the more commonly used kneser-ney estimator do not hold in the word 340 ble 2 shows that in conjunction with the source parse features, slight improvement comes from including the 7-gram lm.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4881">
<title id=" W11-2139.xml">the cmuark german english translation system </title>
<section> source parse structure modeling.  </section>
<citcontext>
<prevsection>
<prevsent>automatic word clusters are attractive because they can be learned for any language without supervised data, and, unlike part-of-speech annotations, each word is in only single class, which simplifies inference.
</prevsent>
<prevsent>we performed brown clustering (brown et al, 1992) <papid> J92-4003 </papid>on 900k sentences from our language modeling data(including the news commentary corpus and subset of gigaword).</prevsent>
</prevsection>
<citsent citstr=" P10-1040 ">
we obtained 1,000 clusters using an implementation provided by liang (2005),6 asturian et al (2010) <papid> P10-1040 </papid>found that relatively large numbers clusters gave better performance for information extraction tasks.</citsent>
<aftsection>
<nextsent>we then replaced words with their clusters in our language modeling data and built 7-gram lm with witten-bell smoothing(witten and bell, 1991).7 the last two rows of ta 6http://www.cs.berkeley.edu/pliang/ software7the distributional assumptions made by the more commonly used kneser-ney estimator do not hold in the word 340 ble 2 shows that in conjunction with the source parse features, slight improvement comes from including the 7-gram lm.
</nextsent>
<nextsent>when two languages share common alphabet (asgerman and english largely do), it is often appropriate to leave some tokens untranslated when translating.
</nextsent>
<nextsent>named entities, numbers, and graphical elements such as emoticons are few common examples of such non-translating?
</nextsent>
<nextsent>elements.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4885">
<title id=" W11-2603.xml">paddy wac a minimally supervised web corpus of hibernoenglish </title>
<section> constructing web-corpus of.  </section>
<citcontext>
<prevsection>
<prevsent>english, and so not considered appropriate in the written register.
</prevsent>
<prevsent>hiberno-englishwithin the wacky initiative (web-as-corpus kool ynitiative) (baroni and bernard ini, 2006) community of linguists and information technology specialists developed set of tools to selectively crawl sections of the web, andthen process, index and search the resulting data.
</prevsent>
</prevsection>
<citsent citstr=" W10-1501 ">
contributions like bootcat (baroni and bernard ini, 2004), an iterative procedure to bootstrap specialised corpora and terms from the web, have been successfully used in range of projects: first in the construction of the wacky corpora, collection of very large ( 1 billion words) corpora of english (ukwac), german (dewac) and italian (itwac); and subsequently by other groups, e.g. nowac and jpwac (baroni et al, 2009; guevara, 2010; <papid> W10-1501 </papid>erjavec et al, 2008).</citsent>
<aftsection>
<nextsent>here we use bootcat to build seven prototype corpora of hiberno-english, and evaluate the dialect-specificity of each by measuring the incidence of proper terms and constructions that are associated with this language variant.
</nextsent>
<nextsent>additionally, we use ukwac as the de-facto standard british english web corpus, and construct medium size web-corpus of the us domain to represent american usage.
</nextsent>
<nextsent>each corpus is preprocessed and formatted for the ims open corpus workbench (cwb, (christ, 1994; web, 2008)), generic query engine for large text corpora that was developed for applications in computational lex icography.
</nextsent>
<nextsent>bootcat first takes set of manually assembled seed terms, these (possibly multi-word) terms are randomly combined, and then are used as search queries with aweb search engine; the html documents of the top results are downloaded and cleaned to extract running textand discard all web-markup.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4886">
<title id=" W12-0705.xml">improving distantly supervised extraction of drug drug and protein protein interactions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>extracting high quality interaction pairs from free text allows for these authors contributed equally.
</prevsent>
<prevsent>building networks, e. g. of proteins, which need less manual cur ation to serve as model for further knowledge processing steps.
</prevsent>
</prevsection>
<citsent citstr=" D09-1013 ">
nevertheless, just assuming co-occurrence to model an interaction or relation is common, as the development of interaction extraction systems can be time-consuming and complex.currently, lot of relation extraction (re) systems relyon machine learning, namely classifying pairs of entities to be related or not (airola et al,2008; miwa et al, 2009; <papid> D09-1013 </papid>kim et al, 2010).</citsent>
<aftsection>
<nextsent>despite the fact that machine learning has been most successful in identifying relevant relations in text, drawback is the need for manually annotated training data.
</nextsent>
<nextsent>domain experts have to dedicate time and effort to this tedious and labor-intensive process.specific biomedical domains have been explored more extensively than others, thus creating an imbalance in the number of existing corpora for specific re task.
</nextsent>
<nextsent>protein-protein interactions (ppi) have been investigated the most, which gave rise to number of available corpora.
</nextsent>
<nextsent>pyysalo et al (2008) standardized five ppi corpora to unified xml format.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4887">
<title id=" W12-0705.xml">improving distantly supervised extraction of drug drug and protein protein interactions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>pyysalo et al (2008) standardized five ppi corpora to unified xml format.
</prevsent>
<prevsent>recently, drug-drug-interaction(ddi) corpus is made available in the same format, originally for the ddi extraction workshop1 (segura-bedmar et al, 2011b).as consequence of the overall scarcity of annotated corpora for re in the biomedical domain,the approach of distant supervision, e. g. to automatically label training set is emerging.
</prevsent>
</prevsection>
<citsent citstr=" P09-1113 ">
many approaches make use of the distant supervision assumption (mintz et al, 2009; <papid> P09-1113 </papid>riedel et al, 2010): 1associated with the conference of the spanish society for natural language processing (sepln) in 2011, http: //labda.inf.uc3m.es/ddiextraction2011/ 35 if two entities participate in relation,all sentences that mention these two entities express that relation.obviously, this assumption does not hold in general, and therefore exceptions need to be detected which are not used for training model.</citsent>
<aftsection>
<nextsent>thomas etal.
</nextsent>
<nextsent>(2011b) successfully used simple filtering techniques in distantly supervised setting to extract ppi.
</nextsent>
<nextsent>in contrast to their work, we introduce more generic filter to detect frequent exceptions from the distant supervision assumption and make use of more data sources, by merging the interaction information from intact and kups databases (dis cussed in section 2.1).
</nextsent>
<nextsent>in addition, we present the first system (to our knowledge), evaluating distant supervision for drug-drug interaction with promising results.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4889">
<title id=" W12-0705.xml">improving distantly supervised extraction of drug drug and protein protein interactions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, most of the work is focusing on domains other than biomedical texts.
</prevsent>
<prevsent>mintz et al (2009) <papid> P09-1113 </papid>use distant supervision to learn to extract relations that are represented in free base (bollacker et al, 2008).</prevsent>
</prevsection>
<citsent citstr=" D10-1099 ">
yao et al (2010) <papid> D10-1099 </papid>use free base as source of supervision, dealing with entity identification and relation extraction in joint fashion.</citsent>
<aftsection>
<nextsent>entity types are restricted to those compatible with selected relations.
</nextsent>
<nextsent>riedel et al.
</nextsent>
<nextsent>(2010) argue that distant supervision leads to noisy training data that hurts precision and suggest two step approach to reduce this problem.
</nextsent>
<nextsent>they identify the sentences which express the known relations (expressed-at-least-once?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4890">
<title id=" W12-0705.xml">improving distantly supervised extraction of drug drug and protein protein interactions </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>they identify the sentences which express the known relations (expressed-at-least-once?
</prevsent>
<prevsent>assumption) and thus frame the problem of distant supervision as an instance of constraint-driven semi-supervision, achieving 31 % of error reduction.
</prevsent>
</prevsection>
<citsent citstr=" W09-1405 ">
vlachos et al (2009) <papid> W09-1405 </papid>tackle the problem of biomedical event extraction.</citsent>
<aftsection>
<nextsent>the scope of their interest is to identify different event types without using knowledge base as source of supervision, but explore the possibility of inferring relations from the text based on the trigger words and dependency parsing, without previously annotated data.thomas et al (2011b) develop distantly labeled corpus for protein-protein interaction extraction.
</nextsent>
<nextsent>different strategies are evaluated to select valuable training instances.
</nextsent>
<nextsent>competitive results are obtained, compared to purely supervised methods.
</nextsent>
<nextsent>very recent work examines the usability of knowledge from pharmgkb (gong et al, 2008) to generate training sets that capture gene-drug, gene-disease and drug-disease relations (buyko etal., 2012).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4891">
<title id=" W12-0705.xml">improving distantly supervised extraction of drug drug and protein protein interactions </title>
<section> methods.  </section>
<citcontext>
<prevsection>
<prevsent>(lex denotes the use of lexical features, lex+dep the additional use of dependency parsing-based features.)grams based, with ? {1, 2, 3, 4}.
</prevsent>
<prevsent>they encompass the local (window size 3) and global (window size 13) context left and right of the entity pair, along with the area between the entities (li et al,2010).
</prevsent>
</prevsection>
<citsent citstr=" H05-1091 ">
additionally, dictionary based domain specific trigger words are taken into account.the respective dependency parse tree is included through following the shortest dependency path hypothesis (bunescu and mooney, 2005), <papid> H05-1091 </papid>by using the syntactical and dependency information of edges (e) and vertices (v).</citsent>
<aftsection>
<nextsent>so-called v-walks and e-walks of length 3 are created as well as grams along the shortest path (miwa et al, 2010).
</nextsent>
<nextsent>3.2 automatically labeling corpus in.
</nextsent>
<nextsent>general one of the most important source of publications in the biomedical domain is medline5, currently containing more than 21 million citations.6 the initial step is annotation of named entities ? in our case performed by pro miner (hanisch et al, 2005), tool proving state-of-the-art results in e. g. the bio creative competition (fluck et al, 2007).based on the named entity recognition, only sentences containing co-occurrences are further processed.
</nextsent>
<nextsent>based on the distant supervision assumption, each pair of entities is labeled as related if mentioned so in structured interaction databases.note that this requires the step of entity normalization.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4892">
<title id=" W12-0705.xml">improving distantly supervised extraction of drug drug and protein protein interactions </title>
<section> results.  </section>
<citcontext>
<prevsection>
<prevsent>this leads to more reliable precision, recall, and f1 values.
</prevsent>
<prevsent>8separating into training and validation sets is performed on document level, not on instance (entity pair) level.
</prevsent>
</prevsection>
<citsent citstr=" C10-2087 ">
the latter could lead to an unrealisticallly optimistic estimate (van landeghem et al, 2008) 38 aimed bio infer hprd50 iepa lll r f1 r f1 r f1 r f1 r f1 (airola et al, 2008) 52.9 61.8 56.4 56.7 67.2 61.3 64.3 65.8 63.4 69.6 82.7 75.1 72.5 87.2 76.8 (kim et al, 2010) 61.4 53.2 56.6 61.8 54.2 57.6 66.7 69.2 67.8 73.7 71.8 72.9 76.9 91.1 82.4 (fayruzov et al, 2009) 39.0 34.0 56.0 72.0 76.0 (liu et al, 2010) <papid> C10-2087 </papid>54.7 59.8 64.9 62.1 78.1 (miwa et al, 2009) <papid> D09-1013 </papid>55.0 68.8 60.8 65.7 71.1 68.1 68.5 76.1 70.9 67.5 78.6 71.7 77.6 86.0 80.1 (tikk et al, 2010) 47.5 65.5 54.5 55.1 66.5 60.0 64.4 67 64.2 71.2 69.3 69.3 74.5 85.3 74.5 our s.</citsent>
<aftsection>
<nextsent>(lex) 62.3 46.3 53.1 59.1 54.3 56.6 69.7 69.4 69.6 67.5 73.2 70.2 66.9 84.6 74.7 our s.
</nextsent>
<nextsent>(lex+dep) 65.1 48.6 55.7 64.7 57.6 61.0 69.3 69.8 69.5 67.0 72.5 69.7 71.2 86.3 78.0 table 3: comparison of fully supervised relations extraction systems for ppi.
</nextsent>
<nextsent>strategy pairs positive pairs sentences 1 3,304,033 511,665 (0.155) 842,339 2 5,560,975 1,389,036 (0.250) 1,172,920 3 2,764,626 359,437 (0.130) 780,658 4 3,454,805 650,455 (0.188) 896,344 table 4: statistics of the fours strategies used in distant supervision for ppi task: 1) intact, 2) intact + kups, 3) intact + aif, 4) intact + kups + aif.
</nextsent>
<nextsent>ratios are given in brackets.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4894">
<title id=" W12-1603.xml">love ya jerk face using sparse loglinear models to build positive and impolite relationships with teens </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" W07-1906 ">
rapport, the harmonious synch rony between interlocutors, has numerous benefits for range of dialogue types, including direction giving (cassell et al, 2007) <papid> W07-1906 </papid>or contributing to patient recovery (vowles and thompson, 2012).</citsent>
<aftsection>
<nextsent>in peer tutoring, an educational paradigm in which students of similar ability tutor one another, friendship among tutors and tutees leads to better learning (gartner etal., 1971).
</nextsent>
<nextsent>with the burgeoning use of spoken dialogue systems in education, understanding the process by which two humans build and signal rapport during learning becomes vital step for implementing spoken dialogue systems (sdss) that can initiate (and, as importantly, maintain) successful relationship with students over time.
</nextsent>
<nextsent>however, implementing tutorial dialogue system that appropriately challenges students in the way that peers doso well (sharpley et al, 1983), while still demonstrating the rapport that peers can also provide, calls for understanding the differences in communication between peer tutors just meeting and those who are already friends.
</nextsent>
<nextsent>the tickle-degnen and rosenthal (1990) model provides starting point by outlining the components of rapport, including the finding that positivity decreases over the course of relationship.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4896">
<title id=" W12-1603.xml">love ya jerk face using sparse loglinear models to build positive and impolite relationships with teens </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>however, implementing tutorial dialogue system that appropriately challenges students in the way that peers doso well (sharpley et al, 1983), while still demonstrating the rapport that peers can also provide, calls for understanding the differences in communication between peer tutors just meeting and those who are already friends.
</prevsent>
<prevsent>the tickle-degnen and rosenthal (1990) model provides starting point by outlining the components of rapport, including the finding that positivity decreases over the course of relationship.
</prevsent>
</prevsection>
<citsent citstr=" W08-0105 ">
the popularity of this model, however, has not diminished the disproportionate attention that positivity and politeness receive in analyses of rapport (brown and levinson, 1978), including in the vast majority of computational approaches to rapport-building in dialogue (stronks et al, 2002; johnson and rizzo, 2004; bickmore and picard, 2005; gratch et al, 2006; mclaren et al, 2007; cassell et al, 2007; <papid> W07-1906 </papid>baker et al, 2008; <papid> W08-0105 </papid>bickmore et al, 2011).</citsent>
<aftsection>
<nextsent>the creation and expression of rapport is complex, and can also be signaled through negative, or impolite,exchanges (straehle, 1993; watts, 2003; spenceroatey, 2008) that communicate affection andre lationship security among intimates who can flout common social norms (culpeper, 2011; kien point ner, 1997).
</nextsent>
<nextsent>however, it is an open question as to whether such rudeness is likely to impress new student on the first day of class.
</nextsent>
<nextsent>we must better understand how and when im politeness and other negative dialogue moves can contribute to the development and expression of the rapport that is so important in educational relationships.
</nextsent>
<nextsent>in this analysis, then, we begin with corpus of tutoring chat data annotated with set of affectively-charged linguistic devices (e.g.complaining, emoticons), and then differentiate between the linguistic devices that friend and stranger interlocutors employ (with friendship standing as aproxy for pre-existent rapport) and the resulting social effects or functions of those devices on the partners.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4897">
<title id=" W12-1603.xml">love ya jerk face using sparse loglinear models to build positive and impolite relationships with teens </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>of course phenomena such as insults, complaints and pet names, no matter how important, appear relatively rarely in data of this sort.training discriminative models with maximum likelihood estimators (mle) on such datasets usually results in assigning too much weight on less frequent signals.
</prevsent>
<prevsent>this standard mle training method notonly produces dense models, but may also overestimates lower frequency features that might be unreliable signals and overfit to particular set of speakers.
</prevsent>
</prevsection>
<citsent citstr=" P12-1078 ">
in recent studies on speaker state prediction that use lexical features, it has been shown that mleestimators demonstrate large performance gaps between non-overlapping speaker datasets (jeon et al, 2010; wang et al, 2012<papid> P12-1078 </papid>a).</citsent>
<aftsection>
<nextsent>on the other hand, recent studies on `1/`2 based group penalty for evaluating dialogue systems (gonzalez-brenes and mostow, 2011), structuredsparsity for linguistic structure prediction (mar tins et al, 2011), <papid> D11-1139 </papid>and discovering historical legal opinions with sparse mixed-effects latent variable model (wang et al, 2012<papid> P12-1078 </papid>b) have all shown concrete benefits of modeling sparsity in language related predictive tasks.</nextsent>
<nextsent>we therefore apply sparsity sensitive models that can prevent less frequent features from overfitting.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4899">
<title id=" W12-1603.xml">love ya jerk face using sparse loglinear models to build positive and impolite relationships with teens </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>this standard mle training method notonly produces dense models, but may also overestimates lower frequency features that might be unreliable signals and overfit to particular set of speakers.
</prevsent>
<prevsent>in recent studies on speaker state prediction that use lexical features, it has been shown that mleestimators demonstrate large performance gaps between non-overlapping speaker datasets (jeon et al, 2010; wang et al, 2012<papid> P12-1078 </papid>a).</prevsent>
</prevsection>
<citsent citstr=" D11-1139 ">
on the other hand, recent studies on `1/`2 based group penalty for evaluating dialogue systems (gonzalez-brenes and mostow, 2011), structuredsparsity for linguistic structure prediction (mar tins et al, 2011), <papid> D11-1139 </papid>and discovering historical legal opinions with sparse mixed-effects latent variable model (wang et al, 2012<papid> P12-1078 </papid>b) have all shown concrete benefits of modeling sparsity in language related predictive tasks.</citsent>
<aftsection>
<nextsent>we therefore apply sparsity sensitive models that can prevent less frequent features from overfitting.
</nextsent>
<nextsent>we start with the `1 regularized lasso (tibshirani, 1994) model, since, compared to other co variance matrix based sparse models, such as sparse principal component analysis (pca) and sparse canonical correlation analysis (cca), the lasso model is straightforward and requires fewer computing resources when the feature dimension is high.
</nextsent>
<nextsent>hence, we compare the contributions of both automated features and annotated features using the proposed lasso model to predict im politeness and positivity.in addition to lasso and logistic regression base line, we introduce two alternative penalty models:the non-sparse ridge (le cessie and van houwelin gen, 1992) estimator, and an elastic net model (zou and hastie, 2005).
</nextsent>
<nextsent>the ridge estimator applies quadratic penalty for feature selection, resulting ina smooth objective function and non-sparse feature space, which can be seen as strong non-sparse penalty model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4902">
<title id=" W12-1603.xml">love ya jerk face using sparse loglinear models to build positive and impolite relationships with teens </title>
<section> introduction and related work.  </section>
<citcontext>
<prevsection>
<prevsent>this approach also allows us to extend previous work on speaker state prediction.
</prevsent>
<prevsent>although speaker state prediction has attracted much attention in the dialogue research community, most studies have focused on the analysis of anger, frustration, and other classic emotions (litman and forbes-riley, 2004; liscombe et al, 2005; devillers and vidrascu, 2006;ai et al, 2006; grimm et al, 2007; gupta and ni tendra., 2007; metallinou et al, 2011).
</prevsent>
</prevsection>
<citsent citstr=" W11-2018 ">
recently,wang and hirschberg (2011) <papid> W11-2018 </papid>proposed hierarchical model that detects level of interest of speakers in dialogue, using multi stream prediction feedback technique.</citsent>
<aftsection>
<nextsent>however, to the best of our knowledge,we are among the first to study the problem of automatic im politeness and positivity prediction india logue.
</nextsent>
<nextsent>because our ultimate goal is to build an sds that responds to users?
</nextsent>
<nextsent>language use over time, the features from the users target turn that the model is aiming to predict are not observable, which renders the task more difficult than previous speaker state detection tasks.our main contributions are three-fold: (1) analysis of linguistic devices that function to signal rapport among friends - and their effects on non-friend dyads; (2) detailed analyses of language behavior features that predict these rapport behaviors - both im politeness and positivity - in the next turn of teenagers?
</nextsent>
<nextsent>peer tutoring sessions; (3) an evaluation of non-sparse and sparse log-linear models for predicting im politeness and positivity.by understanding the signals of rapport that person is likely to display in response to various linguistic devices, we can begin to build an sds that can anticipate the social response and adapt to the rapport-signaling efforts of its partner, both as newly introduced technology, and, over time, as system with whom the user has rapport.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4903">
<title id=" W12-1603.xml">love ya jerk face using sparse loglinear models to build positive and impolite relationships with teens </title>
<section> feature engineering.  </section>
<citcontext>
<prevsection>
<prevsent>calm down?)
</prevsent>
<prevsent>(chovanec, 2009).
</prevsent>
</prevsection>
<citsent citstr=" C10-1129 ">
since recent text prediction task (wang and mckeown,2010) <papid> C10-1129 </papid>observed benefits from modeling punctuation features[p], we extracted the expressive punctuation that included at least one exclamation point or more than one question-mark (eg.</citsent>
<aftsection>
<nextsent>i dont getit?!??!?)
</nextsent>
<nextsent>(crystal, 2001).
</nextsent>
<nextsent>we used smiley dictionary5 to extract the emoticons[e] that convey emotional states (sanchez et al, 2006) from text.
</nextsent>
<nextsent>we formulate our im politeness and positivity prediction problems as binary classifications.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4904">
<title id=" W11-2155.xml">factored translation with unsupervised word clusters </title>
<section> factored translation.  </section>
<citcontext>
<prevsection>
<prevsent>factored translation models are an extension ofphrase-based models which allow integration of additional word-level annotation into the model.
</prevsent>
<prevsent>operating on more general representations, such as lemmas or some kind of stems, translation model can draw on richer statistics and to some degree offset the data sparsity problem.
</prevsent>
</prevsection>
<citsent citstr=" J92-4003 ">
4.1.1 the brown algorithm in this thesis, we use the bottom-up agglomerative word clustering algorithm of (brown et al, 1992) <papid> J92-4003 </papid>to derive hierarchical clustering of words.</citsent>
<aftsection>
<nextsent>the input to the algorithm is text, which is sequence of words w1, . . .
</nextsent>
<nextsent>, wn.
</nextsent>
<nextsent>the output from the clustering algorithm is binary tree, in which the leaves of the tree are the words.
</nextsent>
<nextsent>we interpret each internal node as cluster containing the words in that subtree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4906">
<title id=" W11-2155.xml">factored translation with unsupervised word clusters </title>
<section> unsupervised word clusters.  </section>
<citcontext>
<prevsection>
<prevsent>the clustering obtained from the brown algorithm does not accommodate this wish.
</prevsent>
<prevsent>we use the implementation2 of liang [2005].
</prevsent>
</prevsection>
<citsent citstr=" P06-3002 ">
2.2 junsuposcontrary to the hard clustering of the brown algorithm, the junsupos algorithm of biemann [2006]<papid> P06-3002 </papid>emits viterbi tagger which is sensitive to the context of token in running text.</citsent>
<aftsection>
<nextsent>thus, word forms can belong to more than single cluster, and such word forms ? which are considered ambiguous by the algorithm ? will be assigned to cluster depending on their context.
</nextsent>
<nextsent>in coarse outline, the algorithm works by first inducing distributional clustering for unambiguoushigh-frequency tokens, as well as co-occurrence based clustering for less common tokens.
</nextsent>
<nextsent>the two partly overlapping clusterings are then combined to1https://github.com/turian/random-indexing word representations 2available at http://www.cs.berkeley.edu/~pliang/software/100001001 immediate urgent ongoing absolute extraordinary exceptional ideological unprecedented appalling overwhelming alleged automatic [...]
</nextsent>
<nextsent>11111100111111110 worried concerned skeptical unhappy uneasy reticent unsure perplexed excited apprehensive legion unconcerned [...]
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4907">
<title id=" W11-2155.xml">factored translation with unsupervised word clusters </title>
<section> unsupervised word clusters.  </section>
<citcontext>
<prevsection>
<prevsent>note that only the 12 most frequent forms from each cluster are displayed, the apparent patterns should be taken with pinch of salt.
</prevsent>
<prevsent>although the qualities suggested can be expected to relate to distributional properties that the clusters reflect, exceptional members are perhaps to be expected.
</prevsent>
</prevsection>
<citsent citstr=" P10-1040 ">
in the present work, we went with the pre-trained models for junsupos3, which have the following characteristics4: lang corpus # sents # tags cs lcc 4 539 de wort schatz 40 396 en medline 2004 34 480 es lcc 4.5 415 fr lcc 3 359for the brown algorithm, we are contrasting cluster count choices of 320 and 1000, based on reports of other successful applications [turian et al, 2010]<papid> P10-1040 </papid>5, with clustering models trained on monolingual data from the europarl corpus and the news commentary corpus.</citsent>
<aftsection>
<nextsent>the baseline systems were set up in accordance with the guidelines on the shared task website.
</nextsent>
<nextsent>that is, they were trained with grow-diag-final-and word alignment heuristics and msd-bidirectional-fe re ordering.translation models were trained on concatenation of the europarl and news commentary corpora, which were first tokenized, then filtered to sentence lengths of up to 40 tokens, and finally lowercased.
</nextsent>
<nextsent>5-gram language models were built usingngram-count on concatenation of the eu roparl corpora and the news commentary corpora.3as available at http://wortschatz.uni leipzig.de/~cbiemann/software/unsupos.html 4lcc refers to the leipzig corpora, available at http://corpora.uni-leipzig.de/.
</nextsent>
<nextsent>wort schatz refers tohttp://www.wortschatz.uni-leipzig.de/.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4908">
<title id=" W11-2501.xml">how we blessed distributional semantic evaluation </title>
<section> distributional semantics benchmarks.  </section>
<citcontext>
<prevsection>
<prevsent>from the point of viewof assessing the performance of dsm, the word sim (and related) similarity ratings are mixed bag,in two senses.
</prevsent>
<prevsent>first, the dataset contains variety of different semantic relations.
</prevsent>
</prevsection>
<citsent citstr=" N09-1003 ">
in recent semantic annotation of the wordsim performed by agirre et al (2009) <papid> N09-1003 </papid>we find that, among the 174pairs with above-median score (and thus presumably related), there is 1 identical pair, 17 synonym pairs, 28 hyper-/hyponym pairs, 30 coordinate pairs, 6 holo-/meronym pairs and 92 (more than half) pairs that are topically related, but none of the above?.</citsent>
<aftsection>
<nextsent>second, the scores are mixture of intuitions about which of these relations are more semantically tight and intuitions about more or less connected pairs within each of the relations.
</nextsent>
<nextsent>for example, among the top-rated scores we find synonyms such as jour ney/voyage and coordinate concepts (king/queen).
</nextsent>
<nextsent>if we look at the relations characterizing pairs around the median rating, we find both less per fect?
</nextsent>
<nextsent>synonyms (monk/brother, that are synonymous only under an unusual sense of brother) and less close coordinates (skin/eye), as well as pairs in stantiating other, less taxonomic ally tight relations,such as many syntagmatically connected items (family/planning, disaster/area, bread/butter).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4909">
<title id=" W11-2501.xml">how we blessed distributional semantic evaluation </title>
<section> how we intend to bless distributional.  </section>
<citcontext>
<prevsection>
<prevsent>finally, either because the datasets were not originally intended as standard benchmarks, or even on purpose, they all are likely to cause coverage problems even for dsms trained on very large corpora.
</prevsent>
<prevsent>think of the presence of extremely rare nouns like casuarina in ap, of proper nouns inwordsim (it is not clear to us that dsms are adequate semantic models for referring expressions ? at the very least they should not be mixed up lightly with common nouns), or multi-word expressions in other datasets.
</prevsent>
</prevsection>
<citsent citstr=" J06-1003 ">
semantic evaluation dsms measure the distributional similarity between words, under the assumption that proximity in distributional space models semantic relatedness, including, as special case, semantic similarity (budanit sky and hirst, 2006).<papid> J06-1003 </papid></citsent>
<aftsection>
<nextsent>however, semantically related words in turn differ for the type of relation holding between them: e.g., dog is strongly related toboth animal and tail, but with different types of relations.
</nextsent>
<nextsent>therefore, evaluating the intrinsic ability ofdsms to represent the semantic space of worden tails both (i) determining to what extent words close in semantic space are actually semantically related, and (ii) analyzing, among related words, which type of semantic relation they tend to instantiate.
</nextsent>
<nextsent>two models can be equally very good in identifying semantically related words, while greatly differing for the type of related pairs they favor.
</nextsent>
<nextsent>the bless dataset complies with both theseconstraints.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4910">
<title id=" W11-2501.xml">how we blessed distributional semantic evaluation </title>
<section> how we intend to bless distributional.  </section>
<citcontext>
<prevsection>
<prevsent>both models have captured similarity with hypernym, and we have no reason, in general semantic terms, to penalize one or the other.
</prevsent>
<prevsent>to maximize coverage, we also make sure that, for each concept and relation, reason able number of relata are frequently attested in our reference corpora (see statistics below), we only include single-word relata and, where appropriate, we include multiple forms for the same relatum (both sock and socks as coordinates of scarf ? as discussed in section 4.1, we avoided similar ambiguous items as target concepts).
</prevsent>
</prevsection>
<citsent citstr=" J06-3003 ">
currently, distributional models for attributional similarity and relational similarity (turney, 2006) <papid> J06-3003 </papid>are tested on different datasets, e.g., toefl and sat respectively (briefly, attributional similarity pertains to similarity between pair of concepts interms of shared properties, whereas relational similarity measures the similarity of the relations in stantiated by couples of concept pairs).</citsent>
<aftsection>
<nextsent>conversely, bless is not biased towards any particular type of semantic similarity and thus allows both families of models to be evaluated on the same dataset.
</nextsent>
<nextsent>given concept, we can analyze the types of relata that are selected by model as more attribution ally similar to the target.
</nextsent>
<nextsent>alternatively, given concept-relatum pair instantiating specific semantic relation (e.g.,hypernymy) we can evaluate model ability to identify ana logically similar pairs, i.e., others concept relatum pairs instantiating the same relation (we do not illustrate this possibility here).finally, by collecting distributions of 200 similarity values for each relation, bless allows reliable statistical testing of the significance of differences in similarity within dsm (for example, using the procedure we present in section 5 below), as well as across dsms (for example, via linear/anovamodel with relations and dsms as factors ? not illustrated here).
</nextsent>
<nextsent>4.1 concepts.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4911">
<title id=" W11-2501.xml">how we blessed distributional semantic evaluation </title>
<section> evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>we choose few ways to construct dsms for illustrative purposes only.
</prevsent>
<prevsent>all the models contain vector representations for the same words, namely, approximately, the top 20k most frequent nouns, 5k most frequent adjectives and 5k most frequent verbs in the combined corpora.
</prevsent>
</prevsection>
<citsent citstr=" J10-4006 ">
all the models use local mutual information (evert, 2005; baroni and lenci,2010) <papid> J10-4006 </papid>to weight raw co-occurrence counts (this association measure is obtained by multiplying the raw count by pointwise mutual information, and it is close approximation to the log-likelihood ratio).</citsent>
<aftsection>
<nextsent>three dsms are based on counting co-occurrences with collocates within window of fixed width, in the tradition of hal (lund and burgess, 1996) and many later models.
</nextsent>
<nextsent>the contentwindow2 model records sentence-internal co-occurrence with the nearest 2 content words to the left and right of each target concept (the same 30k target nouns, verbs and adjectives are also employed as context content words).
</nextsent>
<nextsent>contentwindow20 is like con tentwindow2, but considers larger window of 20words to the left and right of the target.
</nextsent>
<nextsent>allwin dow2 adopts the same window of contentwindow2, but considers all co-occurrences, not only those with content words.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4912">
<title id=" W11-2156.xml">the bmi2r haitiancr233oletoenglish translation system description for the wmt 2011 evaluation campaign </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our objective in this featured task is to translate from haitian-creole into english either using raw or clean data.
</prevsent>
<prevsent>we propose to build an smt system which couldbe used for both raw and clean data.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
our baseline system is an standard phrase-based smt system built with moses (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>starting from this system we propose to introduce semantic feature function based on latent semantic indexing(landauer et al, 1998).
</nextsent>
<nextsent>additionally, as total different approximation, we propose to orthogonalize the standard feature functions of the phrase-based table using the gram-schmidt methodology (greub,1975).
</nextsent>
<nextsent>then, we experimentally combine both enhancements.
</nextsent>
<nextsent>the only difference among the raw and clean smt system were the training sentences.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4913">
<title id=" W11-2156.xml">the bmi2r haitiancr233oletoenglish translation system description for the wmt 2011 evaluation campaign </title>
<section> phrase-based smt baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>de trad uction ? translation unit, and have different scores associated to them.
</prevsent>
<prevsent>these bilingual phrases are then selected in order to maximize linear combination of feature functions.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
such strategy is known as the log-linear model (och, 2003) <papid> P03-1021 </papid>and it is formally defined as: e?</citsent>
<aftsection>
<nextsent>= argmax [ m?
</nextsent>
<nextsent>m=1 mhm (e, f) ] (1) where hm are different feature functions with weights m. the two main feature functions arethe translation model (tm) and the target language model (lm).
</nextsent>
<nextsent>additional models include lexical weights, phrase and word penalty and reordering.
</nextsent>
<nextsent>source context information is generally disregarded in phrase-based systems given that all training sentences contribute equally to the final translation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4914">
<title id=" W12-0210.xml">recovering dialect geography from an unaligned comparable corpus </title>
<section> corpora and word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, the archimob corpus is not aligned.
</prevsent>
<prevsent>again, algorithms for aligning words in parallel and comparable corpora have been proposed inthe field of machine translation.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
for large parallel corpora, distributional alignment methods based solely on cooccurrence statistics are sufficient (och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>for comparable corpora, the order and frequency of occurrence of the words cannot be used as alignment cues.
</nextsent>
<nextsent>instead, the phonetic and orthographic structures are used to match similar word pairs (simard et al, 1992; koehn and knight, 2002; <papid> W02-0902 </papid>kondrak and sherif, 2006).<papid> W06-1107 </papid></nextsent>
<nextsent>obviously, this approach only works for cognate word pairs word pairs with common etymology and similar surface forms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4915">
<title id=" W12-0210.xml">recovering dialect geography from an unaligned comparable corpus </title>
<section> corpora and word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>in contrast, the archimob corpus is not aligned.
</prevsent>
<prevsent>again, algorithms for aligning words in parallel and comparable corpora have been proposed inthe field of machine translation.
</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
for large parallel corpora, distributional alignment methods based solely on cooccurrence statistics are sufficient (och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>for comparable corpora, the order and frequency of occurrence of the words cannot be used as alignment cues.
</nextsent>
<nextsent>instead, the phonetic and orthographic structures are used to match similar word pairs (simard et al, 1992; koehn and knight, 2002; <papid> W02-0902 </papid>kondrak and sherif, 2006).<papid> W06-1107 </papid></nextsent>
<nextsent>obviously, this approach only works for cognate word pairs word pairs with common etymology and similar surface forms.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4916">
<title id=" W12-0210.xml">recovering dialect geography from an unaligned comparable corpus </title>
<section> corpora and word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>for large parallel corpora, distributional alignment methods based solely on cooccurrence statistics are sufficient (och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2007).<papid> P07-2045 </papid></prevsent>
<prevsent>for comparable corpora, the order and frequency of occurrence of the words cannot be used as alignment cues.</prevsent>
</prevsection>
<citsent citstr=" W02-0902 ">
instead, the phonetic and orthographic structures are used to match similar word pairs (simard et al, 1992; koehn and knight, 2002; <papid> W02-0902 </papid>kondrak and sherif, 2006).<papid> W06-1107 </papid></citsent>
<aftsection>
<nextsent>obviously, this approach only works for cognate word pairs word pairs with common etymology and similar surface forms.
</nextsent>
<nextsent>this task is known as cognate identification.in the next section, we detail how cognate identification is used to compute the distance between different dialect versions of comparable corpus.
</nextsent>
<nextsent>two comparable texts the hypothesis put forward in this paper is that the linguistic similarity of two comparable texts can be approximated by the degree of similarity of the cognate word pairs occurring in the texts.
</nextsent>
<nextsent>computing the similarity of two texts amounts to the following two tasks: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4917">
<title id=" W12-0210.xml">recovering dialect geography from an unaligned comparable corpus </title>
<section> corpora and word alignment.  </section>
<citcontext>
<prevsection>
<prevsent>for large parallel corpora, distributional alignment methods based solely on cooccurrence statistics are sufficient (och and ney, 2003; <papid> J03-1002 </papid>koehn et al, 2007).<papid> P07-2045 </papid></prevsent>
<prevsent>for comparable corpora, the order and frequency of occurrence of the words cannot be used as alignment cues.</prevsent>
</prevsection>
<citsent citstr=" W06-1107 ">
instead, the phonetic and orthographic structures are used to match similar word pairs (simard et al, 1992; koehn and knight, 2002; <papid> W02-0902 </papid>kondrak and sherif, 2006).<papid> W06-1107 </papid></citsent>
<aftsection>
<nextsent>obviously, this approach only works for cognate word pairs word pairs with common etymology and similar surface forms.
</nextsent>
<nextsent>this task is known as cognate identification.in the next section, we detail how cognate identification is used to compute the distance between different dialect versions of comparable corpus.
</nextsent>
<nextsent>two comparable texts the hypothesis put forward in this paper is that the linguistic similarity of two comparable texts can be approximated by the degree of similarity of the cognate word pairs occurring in the texts.
</nextsent>
<nextsent>computing the similarity of two texts amounts to the following two tasks: 1.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4919">
<title id=" W12-0210.xml">recovering dialect geography from an unaligned comparable corpus </title>
<section> computing the linguistic similarity of.  </section>
<citcontext>
<prevsection>
<prevsent>in the following sections, we define these concepts more precisely.
</prevsent>
<prevsent>4.1 identifying cognate word pairs.
</prevsent>
</prevsection>
<citsent citstr=" W06-1108 ">
most recently proposed cognate identification algorithms are based on variants of levenshtein distance, or string edit distance (levenshtein, 1966; heeringa et al, 2006; <papid> W06-1108 </papid>kondrak and sherif, 2006).<papid> W06-1107 </papid></citsent>
<aftsection>
<nextsent>levenshtein distance is defined as the smallest number of insertion, deletion and substitution operations required to transform one string into an other.
</nextsent>
<nextsent>(3) i s h i u i c p l 0 0 1 0 0 0 0 0 1 1 4accented and un accented characters are considered as different.
</nextsent>
<nextsent>see footnote 5.
</nextsent>
<nextsent>65 example (3) shows two words and the associated operation costs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4923">
<title id=" W12-0210.xml">recovering dialect geography from an unaligned comparable corpus </title>
<section> discussion and future work.  </section>
<citcontext>
<prevsection>
<prevsent>the results suggest that more fine-grained variant of levenshtein distance might improve the precision and recall of the cognate detection algorithm.
</prevsent>
<prevsent>notably, it has been found that vowels change more readily than consonant in closely related language varieties.
</prevsent>
</prevsection>
<citsent citstr=" N01-1020 ">
in consequence, changing one vowel by another should be penalized less than changing vowel by consonant (mann and yarowsky, 2001).<papid> N01-1020 </papid></citsent>
<aftsection>
<nextsent>the same holds for accented vs. non-accented characters.
</nextsent>
<nextsent>complex graphemesrepresenting single phoneme appear rather frequently in the dieth transcription system (e.g. forlong vowels) and should also be treated separately.
</nextsent>
<nextsent>we should also mention that the proposed method likely faces problem of scale.
</nextsent>
<nextsent>indeed, each word of each text has to be compared with each word of each text.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4924">
<title id=" W11-2154.xml">the liga liglia machine translation system for wmt 2011 </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>both ligand lia systems are phrase-based translation models.
</prevsent>
<prevsent>all the data were first tokenized withthe tokenizer provided for the workshop.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
kneser ney discounted lms were built from monolingual corpora using the srilm toolkit (stolcke, 2002),while bilingual corpora were aligned at the word level using giza++ (och and ney, 2003) <papid> J03-1002 </papid>or its multi-threaded version mgiza++ (gao and vogel, 2008) <papid> W08-0509 </papid>for the large corpora un and giga.</citsent>
<aftsection>
<nextsent>phrase table and lexicalized reordering models were built with moses (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>finally, 14 features were used in the phrase-based models: 1when not specified otherwise our?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4925">
<title id=" W11-2154.xml">the liga liglia machine translation system for wmt 2011 </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>both ligand lia systems are phrase-based translation models.
</prevsent>
<prevsent>all the data were first tokenized withthe tokenizer provided for the workshop.
</prevsent>
</prevsection>
<citsent citstr=" W08-0509 ">
kneser ney discounted lms were built from monolingual corpora using the srilm toolkit (stolcke, 2002),while bilingual corpora were aligned at the word level using giza++ (och and ney, 2003) <papid> J03-1002 </papid>or its multi-threaded version mgiza++ (gao and vogel, 2008) <papid> W08-0509 </papid>for the large corpora un and giga.</citsent>
<aftsection>
<nextsent>phrase table and lexicalized reordering models were built with moses (koehn et al, 2007).<papid> P07-2045 </papid></nextsent>
<nextsent>finally, 14 features were used in the phrase-based models: 1when not specified otherwise our?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4926">
<title id=" W11-2154.xml">the liga liglia machine translation system for wmt 2011 </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>all the data were first tokenized withthe tokenizer provided for the workshop.
</prevsent>
<prevsent>kneser ney discounted lms were built from monolingual corpora using the srilm toolkit (stolcke, 2002),while bilingual corpora were aligned at the word level using giza++ (och and ney, 2003) <papid> J03-1002 </papid>or its multi-threaded version mgiza++ (gao and vogel, 2008) <papid> W08-0509 </papid>for the large corpora un and giga.</prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
phrase table and lexicalized reordering models were built with moses (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>finally, 14 features were used in the phrase-based models: 1when not specified otherwise our?
</nextsent>
<nextsent>system refers to the liga system.
</nextsent>
<nextsent>440 corpora designation size (sentences) english-french bilingual training news commentary v6 news-c 116 europarl v6 euro 1.8 united nation corpus un 12 109 corpus giga 23 english monolingual training news commentary v6 mono-news-c 181 shuffled news crawl corpus (from 2007 to 2011) news-s 25 europarl v6 mono-euro 1.8 development newstest2008 test08 2,051 newssyscomb2009 testcomb09 502 newstest2009 test09 2,525 test newstest2010 test10 2,489 table 1: used corpora ? 5 translation model scores, ? 1 distance-based reordering score, ? 6 lexicalized reordering score, ? 1 lm score and ? 1 word penalty score.the score weights were optimized on the test09 corpus according to the bleu score with the mert method (och, 2003).<papid> P03-1021 </papid></nextsent>
<nextsent>the experiments led specifically with either lig or lia system are respectively described in sections 3 and 4.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4927">
<title id=" W11-2154.xml">the liga liglia machine translation system for wmt 2011 </title>
<section> system overview.  </section>
<citcontext>
<prevsection>
<prevsent>finally, 14 features were used in the phrase-based models: 1when not specified otherwise our?
</prevsent>
<prevsent>system refers to the liga system.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
440 corpora designation size (sentences) english-french bilingual training news commentary v6 news-c 116 europarl v6 euro 1.8 united nation corpus un 12 109 corpus giga 23 english monolingual training news commentary v6 mono-news-c 181 shuffled news crawl corpus (from 2007 to 2011) news-s 25 europarl v6 mono-euro 1.8 development newstest2008 test08 2,051 newssyscomb2009 testcomb09 502 newstest2009 test09 2,525 test newstest2010 test10 2,489 table 1: used corpora ? 5 translation model scores, ? 1 distance-based reordering score, ? 6 lexicalized reordering score, ? 1 lm score and ? 1 word penalty score.the score weights were optimized on the test09 corpus according to the bleu score with the mert method (och, 2003).<papid> P03-1021 </papid></citsent>
<aftsection>
<nextsent>the experiments led specifically with either lig or lia system are respectively described in sections 3 and 4.
</nextsent>
<nextsent>unless otherwise indicated, all the evaluations were performed using case-insensitive bleu and were computed with themteval-v13a.pl script provided by nist.
</nextsent>
<nextsent>table 2 summarizes the differences between the final configuration of the systems.
</nextsent>
<nextsent>lig participated for the second time to the wmt shared news translation task for the french-english language pair.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4928">
<title id=" W11-2154.xml">the liga liglia machine translation system for wmt 2011 </title>
<section> the lig machine translation system.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 pre-processing.
</prevsent>
<prevsent>training data were first lower cased with the perl script provided for the campaign.
</prevsent>
</prevsection>
<citsent citstr=" W10-1723 ">
they were also processed in order to normalize special french form (named euphonious t?) as described in (potet et al, 2010).<papid> W10-1723 </papid></citsent>
<aftsection>
<nextsent>the baseline system was built using 4-gram lm trained on the monolingual corpora provided last year and translation models trained on news-c andeuro (table 3, system 1).
</nextsent>
<nextsent>a significant improvement in terms of bleu is obtained when taking into account third corpus, un, to build translation models (system 2).
</nextsent>
<nextsent>the next section describes the lmsthat were trained using the monolingual data provided this year.
</nextsent>
<nextsent>3.2 language model training.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4929">
<title id=" W11-2154.xml">the liga liglia machine translation system for wmt 2011 </title>
<section> the lig machine translation system.  </section>
<citcontext>
<prevsection>
<prevsent>translation models were trained from the parallel corpora news-c, euro and un.
</prevsent>
<prevsent>data were aligned at the word-level and then used to build standardphrase-based translation models.
</prevsent>
</prevsection>
<citsent citstr=" D07-1103 ">
we filtered the obtained phrase table using the method described in(johnson et al, 2007).<papid> D07-1103 </papid></citsent>
<aftsection>
<nextsent>since this technique drastically reduces the size of the phrase table, while not degrading (and even slightly improving) the results on the development and test corpora (system 6), we decided to employ filtered phrase tables in the final configuration of the lig system.
</nextsent>
<nextsent>3.4 tuning.
</nextsent>
<nextsent>for decoding, the system uses log-linear combination of translation model scores with the lm log-probability.
</nextsent>
<nextsent>we prevent phrase reordering over punctuation using the moses option -monotone-at punctuation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4931">
<title id=" W11-2154.xml">the liga liglia machine translation system for wmt 2011 </title>
<section> the lia machine translation system.  </section>
<citcontext>
<prevsection>
<prevsent>for example, hildebrand et al (2005) used sentences belonging to the development and test corpora as queries to select thek most similar source sentences in an indexed parallel corpus.
</prevsent>
<prevsent>the retrieved sentence pairs constituted training corpus for the translation models.
</prevsent>
</prevsection>
<citsent citstr=" W10-1713 ">
the rali submission for wmt10 proposed asimilar approach that builds queries from the monolingual news corpus in order to select sentence pairs stylistically close to the news domain (huet et al, 2010).<papid> W10-1713 </papid></citsent>
<aftsection>
<nextsent>this method has the major interest that it does not require to build new training parallel corpus for each news dataset to translate.
</nextsent>
<nextsent>following the best configuration tested in (huet et al, 4432010), we index the three out-of-domain corpora using lemur3, and build queries from english news-s sentences where stop words are removed.
</nextsent>
<nextsent>the 10 top sentence pairs retrieved per query are selected and added to the new training corpus if they are notre dundant with sentence pair already collected.
</nextsent>
<nextsent>the process is repeated until the training parallel corpus reaches threshold over the number of retrieved pairs.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4932">
<title id=" W12-1512.xml">on generating coherent multilingual descriptions of museum objects from semantic web ontologies </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>figure 2: museum object description generated in english and swedish.
</prevsent>
<prevsent>formation needed to generate natural language (mccrae et al, 2012) but it may not carry any information either about the aggregation of semantic concepts or the generation of coherent discourse from referring expressions.
</prevsent>
</prevsection>
<citsent citstr=" J95-2003 ">
halliday and hasan (1976), and other well known theories such as centering theory (grosz etal., 1995), <papid> J95-2003 </papid>propose establishing coherent description by replacing the entity referring to the main subject reference (msr) with pronoun?</citsent>
<aftsection>
<nextsent>a replacement which might result in simple descriptions such as illustrated in figure 2.
</nextsent>
<nextsent>although these descriptions are coherent, i.e. they have connectedness that contributes to the readers understanding of the text, they are considered non-idiomatic and undeveloped by many readers because of consecutive pronouns?
</nextsent>
<nextsent>a usage which in this particular context is unacceptable.
</nextsent>
<nextsent>since previous theories do not specify the types of linguistic expressions different entities may bear in different languages or domains, there remain many open questions that need to be addressed.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4933">
<title id=" W12-1512.xml">on generating coherent multilingual descriptions of museum objects from semantic web ontologies </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>also prasad (2003) employed corpus-basedmethodology to study the usage of referring expressions.
</prevsent>
<prevsent>based on the results of the analysis, he developed an algorithm to generate referential chains in hindi.
</prevsent>
</prevsection>
<citsent citstr=" A00-1020 ">
other algorithms for characterizing referential expressions based on corpus studies have been proposed and implemented in japanese (walker et al, 1996), italian (di eugenio, 1998), catalan and spanish (potau, 2008), and romanian (harabagiu and maiorano, 2000).<papid> A00-1020 </papid></citsent>
<aftsection>
<nextsent>although there has been computational work related to centering for generating coherent text (kibble and power, 2000; barzilay and lee, 2004; <papid> N04-1015 </papid>karamanis et al, 2009), we are not aware of any methodology or nlg system that employs ontologies to guide the generation of referential chains depending on the language considered.</nextsent>
<nextsent>analysis 3.1 material.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4934">
<title id=" W12-1512.xml">on generating coherent multilingual descriptions of museum objects from semantic web ontologies </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>based on the results of the analysis, he developed an algorithm to generate referential chains in hindi.
</prevsent>
<prevsent>other algorithms for characterizing referential expressions based on corpus studies have been proposed and implemented in japanese (walker et al, 1996), italian (di eugenio, 1998), catalan and spanish (potau, 2008), and romanian (harabagiu and maiorano, 2000).<papid> A00-1020 </papid></prevsent>
</prevsection>
<citsent citstr=" N04-1015 ">
although there has been computational work related to centering for generating coherent text (kibble and power, 2000; barzilay and lee, 2004; <papid> N04-1015 </papid>karamanis et al, 2009), we are not aware of any methodology or nlg system that employs ontologies to guide the generation of referential chains depending on the language considered.</citsent>
<aftsection>
<nextsent>analysis 3.1 material.
</nextsent>
<nextsent>to study the domain-specific conventions andthe ways of signalling linguistic content in en 1http://www.grammaticalframework.org/ 77glish, swedish and hebrew, we collected object descriptions written by native speakers of each language from digital libraries that are available through on-line museum databases.
</nextsent>
<nextsent>the majority of the swedish descriptions were taken from the world culture museum.2 the majority of the english descriptions were collected from the metropolitan museum.3 the majority of the hebrew descriptions were taken from artchive.4 table 1 gives an overview ofthe three text collections.
</nextsent>
<nextsent>in addition, we extracted 40 parallel texts that are available under the sub-domain painting from wikipedia.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4935">
<title id=" W12-1512.xml">on generating coherent multilingual descriptions of museum objects from semantic web ontologies </title>
<section> data collection, annotations and.  </section>
<citcontext>
<prevsection>
<prevsent>we used hunpos, an open-source hidden markov model (hmm) tagger (halcsy et al, 2007) and malt parser, version 1.4 (nivre et al, 2007).
</prevsent>
<prevsent>the english model for tagging was downloaded from the hunpos web page.5 the model for swedish was trained on the stockholm ume?
</prevsent>
</prevsection>
<citsent citstr=" N10-1115 ">
corpus (suc) and is available to download from the swedish language bank web page.6the hebrew tagger and parsing models are described in goldberg and elhadad (2010).<papid> N10-1115 </papid></citsent>
<aftsection>
<nextsent>3.3 semantic annotation.
</nextsent>
<nextsent>the texts were semantically annotated by theauthor.
</nextsent>
<nextsent>the annotation schema for the semantic annotation is taken from the cidoc con 2http://collections.smvk.se/pls/vkm/ rigby.welcome 3http://www.metmuseum.org 4http://www.artchive.com/ 5http://code.google.com/p/hunpos/ downloads/list 6http://spraakbanken.gu.se/ ceptual reference model (crm) (crofts et al, 2008).7 ten of the cidoc-crm concepts were employed to annotate the data semantically.these are given in table 2.
</nextsent>
<nextsent>examples of semantically annotated texts are given in figure 3.8 actor man-made_object actor appellation material collection place dimension time-span legal body title table 2: the semantic concepts for annotation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4936">
<title id=" W11-2605.xml">learning word level dialectal variation as phonological replacement rules using a limited parallel corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the idea is to start from limited number of paradigms (essentially pairs of input-output forms where the input is the surface form of word and the output lemmatization plus analysis).
</prevsent>
<prevsent>the problem of finding phonological rules to model morphological paradigms is essentially similar to the problem presented in this paper.
</prevsent>
</prevsection>
<citsent citstr=" P84-1070 ">
an earlier paper, johnson (1984), <papid> P84-1070 </papid>presents discovery procedure?</citsent>
<aftsection>
<nextsent>for learning phonological rules from data, something that can be seen as precursor to the problem dealt with by our ilp algorithm.
</nextsent>
<nextsent>mann and yarowsky (2001) <papid> N01-1020 </papid>present method for inducing translation lexicons based on transduction models of cognate pairs via bridge languages.bilingual lexicons within languages families are induced using probabilistic string edit distance mod els.</nextsent>
<nextsent>inspired by that paper, scherrer (2007) <papid> P07-3010 </papid>uses generate-and-filter approach quite similar to our first method.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4937">
<title id=" W11-2605.xml">learning word level dialectal variation as phonological replacement rules using a limited parallel corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>an earlier paper, johnson (1984), <papid> P84-1070 </papid>presents discovery procedure?</prevsent>
<prevsent>for learning phonological rules from data, something that can be seen as precursor to the problem dealt with by our ilp algorithm.</prevsent>
</prevsection>
<citsent citstr=" N01-1020 ">
mann and yarowsky (2001) <papid> N01-1020 </papid>present method for inducing translation lexicons based on transduction models of cognate pairs via bridge languages.bilingual lexicons within languages families are induced using probabilistic string edit distance mod els.</citsent>
<aftsection>
<nextsent>inspired by that paper, scherrer (2007) <papid> P07-3010 </papid>uses generate-and-filter approach quite similar to our first method.</nextsent>
<nextsent>he compares different measures ofgraphemic similarity applied to the task of bilingual lexicon induction between swiss german and standard german.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4938">
<title id=" W11-2605.xml">learning word level dialectal variation as phonological replacement rules using a limited parallel corpus </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for learning phonological rules from data, something that can be seen as precursor to the problem dealt with by our ilp algorithm.
</prevsent>
<prevsent>mann and yarowsky (2001) <papid> N01-1020 </papid>present method for inducing translation lexicons based on transduction models of cognate pairs via bridge languages.bilingual lexicons within languages families are induced using probabilistic string edit distance mod els.</prevsent>
</prevsection>
<citsent citstr=" P07-3010 ">
inspired by that paper, scherrer (2007) <papid> P07-3010 </papid>uses generate-and-filter approach quite similar to our first method.</citsent>
<aftsection>
<nextsent>he compares different measures ofgraphemic similarity applied to the task of bilingual lexicon induction between swiss german and standard german.
</nextsent>
<nextsent>stochastic transducers are trained with the em algorithm and using handmade transduction rules.
</nextsent>
<nextsent>an improvement of 11% in f-score is reported over baseline method using levenshtein distance.
</nextsent>
<nextsent>40 full corpus 80% part.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4939">
<title id=" W11-2605.xml">learning word level dialectal variation as phonological replacement rules using a limited parallel corpus </title>
<section> overview of methods.  </section>
<citcontext>
<prevsection>
<prevsent>41 4.1 format of rules.
</prevsent>
<prevsent>both of the methods we have evaluated involve learning set of string-transformation rules to convert words, morphemes, or individual letters(graphemes) in the dialectal forms to the standard variant.
</prevsent>
</prevsection>
<citsent citstr=" E09-2008 ">
the rules that are learned are in the format of so-called phonological replacement rules (beesley and karttunen, 2002) which we have later converted into equivalent finite-state transducers using the freely available foma toolkit (hulden, 2009<papid> E09-2008 </papid>a).</citsent>
<aftsection>
<nextsent>the reason for the ultimate conversion of the rule set to finite-state transducers is twofold: first, the transducers are easy to apply rapidly to input data using available tools, and secondly, the transducers can further be modified and combined with the standard morphology already available to us as finite transducer.
</nextsent>
<nextsent>in its simplest form, replacement rule is of the format a?
</nextsent>
<nextsent>b || d (1)where the arguments a,b,c,d are all single symbols or strings.
</nextsent>
<nextsent>such rule dictates the transformation of string to b, whenever the occurs between the strings and d. both and are optional arguments in such rule, and there may be multiple conditioning environments for the same rule.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4941">
<title id=" W12-1814.xml">the inprotk 2012 release </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>these components work fairly domainindependently; we also provide example implementations of higher-level components such as natural language understanding and dialogue management that are somewhat more tied to particular domain.
</prevsent>
<prevsent>we offer this release of the toolkit to foster research in this new and exciting area, which promises to help increase the naturalness of behaviours that can be modelled in such systems.
</prevsent>
</prevsection>
<citsent citstr=" E09-1085 ">
as recent work has shown, incremental (or online) processing of user input or generation of system output enables spoken dialogue systems to produce behaviour that is perceived as more natural than and preferable to that produced by systems that are bound by turn-based processing mode (aist et al., 2006; skantze and schlangen, 2009; <papid> E09-1085 </papid>bu?</citsent>
<aftsection>
<nextsent>et al, 2010; skantze and hjalmarsson, 2010).<papid> W10-4301 </papid></nextsent>
<nextsent>there is still much left to find out about the best ways of modelling these behaviours in such systems, however.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4942">
<title id=" W12-1814.xml">the inprotk 2012 release </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we offer this release of the toolkit to foster research in this new and exciting area, which promises to help increase the naturalness of behaviours that can be modelled in such systems.
</prevsent>
<prevsent>as recent work has shown, incremental (or online) processing of user input or generation of system output enables spoken dialogue systems to produce behaviour that is perceived as more natural than and preferable to that produced by systems that are bound by turn-based processing mode (aist et al., 2006; skantze and schlangen, 2009; <papid> E09-1085 </papid>bu?</prevsent>
</prevsection>
<citsent citstr=" W10-4301 ">
et al, 2010; skantze and hjalmarsson, 2010).<papid> W10-4301 </papid></citsent>
<aftsection>
<nextsent>there is still much left to find out about the best ways of modelling these behaviours in such systems, however.
</nextsent>
<nextsent>to foster research in this area, we are releasing new version of our incremental processing toolkit?
</nextsent>
<nextsent>(inprotk), which provides lower-level components (such as speech recognition and speech synthesis, 1the code of the toolkit and some example applications have been released as open-source at http://inprotk.
</nextsent>
<nextsent>sourceforge.net.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4943">
<title id=" W12-1814.xml">the inprotk 2012 release </title>
<section> an incremental processing architecture.  </section>
<citcontext>
<prevsection>
<prevsent>sourceforge.net.
</prevsent>
<prevsent>but also general modular processing architecture) and allows researchers to concentrate on higher-level modules (such as natural language understanding and dialogue modelling; for which we provide example implementations).2 we describe these components in the following, pointing out the differences and extensions to earlier releases (baumann et al, 2010).
</prevsent>
</prevsection>
<citsent citstr=" E09-1081 ">
inprotk realises the iu-model of incremental processing (schlangen and skantze, 2009; <papid> E09-1081 </papid>schlangen and skantze, 2011), where incremental systems areconceptualised as consisting of network of processing modules.</citsent>
<aftsection>
<nextsent>each module has left buffer, processor, and right buffer, where the normal modeof processing is to take input from the left buffer, process it, and provide output in the right buffer, from where it goes to the next modules left buffer.
</nextsent>
<nextsent>(top down, expectation-based processing would work inthe opposite direction.)
</nextsent>
<nextsent>modules exchange incremental units (ius), which are the smallest chunks?
</nextsent>
<nextsent>of information that can trigger connected modules into action.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4945">
<title id=" W12-1814.xml">the inprotk 2012 release </title>
<section> an incremental processing architecture.  </section>
<citcontext>
<prevsection>
<prevsent>modules can be fully event-driven, only triggered into action by being notified of hypothesis change, or they can run persistently, in order to create endogenous events like time-outs.
</prevsent>
<prevsent>event-driven modules can run concurrently in separate threads or can be called sequentially by another module (which may seem to run counter the spirit of incremental processing, but can be advantageous for very quick computations for which the overhead of creating threads should be avoided).
</prevsent>
</prevsection>
<citsent citstr=" W09-3943 ">
in the case of separate threads, which run at different update intervals, the left-buffer view will automatically be updated to its most recent state.inprotk also comes with an extensive set of monitoring and profiling modules which can be linked into the module network at any point and allow to stream data to disk or to visualise it online through viewing tool (von der malsburg et al, 2009), <papid> W09-3943 </papid>as well as different ways to simulate input (e.g., typed or read from file) for debugging.</citsent>
<aftsection>
<nextsent>all iumodules can also output loggging messages to the viewing tool directly (to ease graphic debugging of error cases in multi-threaded applications).
</nextsent>
<nextsent>3in an earlier release, we used oaa (cheyer and martin, 2001), which however turned out to be too slow.
</nextsent>
<nextsent>our speech recognition module is based on the sphinx-4 (walker et al, 2004) toolkit and comes with acoustic models for german.4 the module queries the asrs current best hypothesis after each frame of audio and changes its output accordingly, adding or revoking wordius and notifying its listeners.
</nextsent>
<nextsent>additionally, for each of the wordius, syllable ius and segment ius are created and bound to the word (andto the syllable respectively) via the grounded-in hierarchy.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4946">
<title id=" W12-1814.xml">the inprotk 2012 release </title>
<section> incremental speech recognition.  </section>
<citcontext>
<prevsection>
<prevsent>furthermore, changes may actually deteriorate results, if good?
</prevsent>
<prevsent>hypothesis is intermittently changed for worse.
</prevsent>
</prevsection>
<citsent citstr=" N09-1043 ">
therefore, we developed hypothesis smoothing approaches (baumann et al, 2009) <papid> N09-1043 </papid>which greatly reduce spurious edits in the output at the cost of some timeliness: with lag of 320ms we reduced the amount of spurious edits to 10% from an initial 90%.</citsent>
<aftsection>
<nextsent>the current implementation of hypothesis smoothing is taylored specifically towards asr output, but other input modules (like gesture or facial expression recognition) could easily be smoothed with similar methods.
</nextsent>
<nextsent>as mentioned above, the more higher-level?
</nextsent>
<nextsent>components in our toolkit are more domain-specific thanthe other components, and in any case are probably exactly those modules which users of the toolkit may want to substitute with their own.
</nextsent>
<nextsent>nevertheless, we provide example implementations of simple keyword-spotting nlu?, as well as statistically 4models for english, french and other languages are available from the sphinx?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4947">
<title id=" W12-1814.xml">the inprotk 2012 release </title>
<section> incremental nlu and dm.  </section>
<citcontext>
<prevsection>
<prevsent>nevertheless, we provide example implementations of simple keyword-spotting nlu?, as well as statistically 4models for english, french and other languages are available from the sphinx?
</prevsent>
<prevsent>distribution and from http://www.voxforge.org.
</prevsent>
</prevsection>
<citsent citstr=" W09-3905 ">
30 trained ones (schlangen et al, 2009; <papid> W09-3905 </papid>heintze et al, 2010).<papid> W10-4302 </papid></citsent>
<aftsection>
<nextsent>we have recently built somewhat more traditional nlu component which could be more easily ported to other domains (by adapting lexicon and grammar).
</nextsent>
<nextsent>it consists of probabilistic, beam-search top-down parser (following (roark, 2001)), which produc esa principled semantic representation in the formalism robust minimal recur sion semantics (copestake, 2006).
</nextsent>
<nextsent>this component is described in more detail in (peldszus et al, 2012).
</nextsent>
<nextsent>rounding out the toolkit is our new component for incremental speech synthesis, which has the following properties: (a) it makes possible changes to the as-yet unspoken part of the ongoing utterance, (b) allows adaptations of delivery parameters such as speaking rate or pitch with very low latency.(c) it autonomously makes delivery-related decisions (such as producing hesitations), and (d) it provides information about delivery status (e. g. useful in case of barge-ins).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4948">
<title id=" W12-1814.xml">the inprotk 2012 release </title>
<section> incremental nlu and dm.  </section>
<citcontext>
<prevsection>
<prevsent>nevertheless, we provide example implementations of simple keyword-spotting nlu?, as well as statistically 4models for english, french and other languages are available from the sphinx?
</prevsent>
<prevsent>distribution and from http://www.voxforge.org.
</prevsent>
</prevsection>
<citsent citstr=" W10-4302 ">
30 trained ones (schlangen et al, 2009; <papid> W09-3905 </papid>heintze et al, 2010).<papid> W10-4302 </papid></citsent>
<aftsection>
<nextsent>we have recently built somewhat more traditional nlu component which could be more easily ported to other domains (by adapting lexicon and grammar).
</nextsent>
<nextsent>it consists of probabilistic, beam-search top-down parser (following (roark, 2001)), which produc esa principled semantic representation in the formalism robust minimal recur sion semantics (copestake, 2006).
</nextsent>
<nextsent>this component is described in more detail in (peldszus et al, 2012).
</nextsent>
<nextsent>rounding out the toolkit is our new component for incremental speech synthesis, which has the following properties: (a) it makes possible changes to the as-yet unspoken part of the ongoing utterance, (b) allows adaptations of delivery parameters such as speaking rate or pitch with very low latency.(c) it autonomously makes delivery-related decisions (such as producing hesitations), and (d) it provides information about delivery status (e. g. useful in case of barge-ins).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4949">
<title id=" W11-2005.xml">a comparison of latent variable models for conversation analysis </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>lei and mirghafori (2 007) attempted to incorporate idiolect based speaker information by using word conditioning of phone -grams to recognize speakers in dialogs with 2 speakers.in our work, the models we use to identify speakers are powerful enough to predict the addressee as well.
</prevsent>
<prevsent>in this context, we note that several attempts have been made recently to automatically identify addressees in dialog settings.
</prevsent>
</prevsection>
<citsent citstr=" E06-1022 ">
these approaches have used information about the context and content of the utterance, using dialog acts and information about the speakers gaze to aid classifier performance (jovanovic et al, 2006).<papid> E06-1022 </papid></citsent>
<aftsection>
<nextsent>den akker andtraum (2009) proposed rule-based methods for addressee classification.
</nextsent>
<nextsent>unlike in these works, we attempt to jointly model both the speaker and the addressee as one of our proposed approaches.
</nextsent>
<nextsent>this is similar to the approach employed by (otsuka etal., 2005, ), who proposed dynamic bayesian network model to understand multiparty conversation structure using non-verbal cues only?
</nextsent>
<nextsent>eye gaze, facial expression, gesticulations and posture.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4950">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we added anumber of features that address problems for translation between german and english such as word order differences, incorrect alignment of certain words such as verbs, and the morphological complexity of german compared to english, as well as dealing with previously unseen words.in both translation directions our systems include compound processing, morphological sequence models, and hierarchical reordering model.for german english translation we also added morphological normalization, source side reordering, and processing of out-of-vocabulary words (oovs).
</prevsent>
<prevsent>for english german translation, we extracted word alignments with supervised method and combined these alignments with giza++ alignments in various ways to improve the phrase table.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we experimented with different ways of combining the two alignments such as using heuristic symmetrization and interpo lating phrase tables.results are reported on three metrics, bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002) and meteor ranking scores (agarwal and lavie, 2008) <papid> W08-0312 </papid>based on true cased output.</citsent>
<aftsection>
<nextsent>this years improvements were added to the liu baseline system (stymne et al, 2010).<papid> W10-1727 </papid></nextsent>
<nextsent>our base line is factored phrase based smt system that usesthe moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for translation model training and decoding, giza++ (ochand ney, 2003) <papid> J03-1002 </papid>for word alignment, srilm (stol cke, 2002) an kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and minimum error rate training (och, 2003) <papid> P03-1021 </papid>to tune model feature weights.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4951">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we added anumber of features that address problems for translation between german and english such as word order differences, incorrect alignment of certain words such as verbs, and the morphological complexity of german compared to english, as well as dealing with previously unseen words.in both translation directions our systems include compound processing, morphological sequence models, and hierarchical reordering model.for german english translation we also added morphological normalization, source side reordering, and processing of out-of-vocabulary words (oovs).
</prevsent>
<prevsent>for english german translation, we extracted word alignments with supervised method and combined these alignments with giza++ alignments in various ways to improve the phrase table.
</prevsent>
</prevsection>
<citsent citstr=" W08-0312 ">
we experimented with different ways of combining the two alignments such as using heuristic symmetrization and interpo lating phrase tables.results are reported on three metrics, bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002) and meteor ranking scores (agarwal and lavie, 2008) <papid> W08-0312 </papid>based on true cased output.</citsent>
<aftsection>
<nextsent>this years improvements were added to the liu baseline system (stymne et al, 2010).<papid> W10-1727 </papid></nextsent>
<nextsent>our base line is factored phrase based smt system that usesthe moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for translation model training and decoding, giza++ (ochand ney, 2003) <papid> J03-1002 </papid>for word alignment, srilm (stol cke, 2002) an kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and minimum error rate training (och, 2003) <papid> P03-1021 </papid>to tune model feature weights.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4952">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>for english german translation, we extracted word alignments with supervised method and combined these alignments with giza++ alignments in various ways to improve the phrase table.
</prevsent>
<prevsent>we experimented with different ways of combining the two alignments such as using heuristic symmetrization and interpo lating phrase tables.results are reported on three metrics, bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002) and meteor ranking scores (agarwal and lavie, 2008) <papid> W08-0312 </papid>based on true cased output.</prevsent>
</prevsection>
<citsent citstr=" W10-1727 ">
this years improvements were added to the liu baseline system (stymne et al, 2010).<papid> W10-1727 </papid></citsent>
<aftsection>
<nextsent>our base line is factored phrase based smt system that usesthe moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for translation model training and decoding, giza++ (ochand ney, 2003) <papid> J03-1002 </papid>for word alignment, srilm (stol cke, 2002) an kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and minimum error rate training (och, 2003) <papid> P03-1021 </papid>to tune model feature weights.</nextsent>
<nextsent>in addition, the liu baseline contains: ? compound processing, including compound splitting and for translation into german also compound merging ? part-of-speech and morphological sequence models all models were trained on true cased data.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4953">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>we experimented with different ways of combining the two alignments such as using heuristic symmetrization and interpo lating phrase tables.results are reported on three metrics, bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002) and meteor ranking scores (agarwal and lavie, 2008) <papid> W08-0312 </papid>based on true cased output.</prevsent>
<prevsent>this years improvements were added to the liu baseline system (stymne et al, 2010).<papid> W10-1727 </papid></prevsent>
</prevsection>
<citsent citstr=" P07-2045 ">
our base line is factored phrase based smt system that usesthe moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for translation model training and decoding, giza++ (ochand ney, 2003) <papid> J03-1002 </papid>for word alignment, srilm (stol cke, 2002) an kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and minimum error rate training (och, 2003) <papid> P03-1021 </papid>to tune model feature weights.</citsent>
<aftsection>
<nextsent>in addition, the liu baseline contains: ? compound processing, including compound splitting and for translation into german also compound merging ? part-of-speech and morphological sequence models all models were trained on true cased data.
</nextsent>
<nextsent>translation and reordering models were trained using the bilingual europarl and news commentary corpora that were concatenated before training.
</nextsent>
<nextsent>we created two language models.
</nextsent>
<nextsent>the first model is 5-gram model that we created by interpol ating two language 393models from bilingual news commentary and eu roparl with more weight on the news commentary model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4954">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>we experimented with different ways of combining the two alignments such as using heuristic symmetrization and interpo lating phrase tables.results are reported on three metrics, bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002) and meteor ranking scores (agarwal and lavie, 2008) <papid> W08-0312 </papid>based on true cased output.</prevsent>
<prevsent>this years improvements were added to the liu baseline system (stymne et al, 2010).<papid> W10-1727 </papid></prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
our base line is factored phrase based smt system that usesthe moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for translation model training and decoding, giza++ (ochand ney, 2003) <papid> J03-1002 </papid>for word alignment, srilm (stol cke, 2002) an kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and minimum error rate training (och, 2003) <papid> P03-1021 </papid>to tune model feature weights.</citsent>
<aftsection>
<nextsent>in addition, the liu baseline contains: ? compound processing, including compound splitting and for translation into german also compound merging ? part-of-speech and morphological sequence models all models were trained on true cased data.
</nextsent>
<nextsent>translation and reordering models were trained using the bilingual europarl and news commentary corpora that were concatenated before training.
</nextsent>
<nextsent>we created two language models.
</nextsent>
<nextsent>the first model is 5-gram model that we created by interpol ating two language 393models from bilingual news commentary and eu roparl with more weight on the news commentary model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4955">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>we experimented with different ways of combining the two alignments such as using heuristic symmetrization and interpo lating phrase tables.results are reported on three metrics, bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002) and meteor ranking scores (agarwal and lavie, 2008) <papid> W08-0312 </papid>based on true cased output.</prevsent>
<prevsent>this years improvements were added to the liu baseline system (stymne et al, 2010).<papid> W10-1727 </papid></prevsent>
</prevsection>
<citsent citstr=" W11-2123 ">
our base line is factored phrase based smt system that usesthe moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for translation model training and decoding, giza++ (ochand ney, 2003) <papid> J03-1002 </papid>for word alignment, srilm (stol cke, 2002) an kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and minimum error rate training (och, 2003) <papid> P03-1021 </papid>to tune model feature weights.</citsent>
<aftsection>
<nextsent>in addition, the liu baseline contains: ? compound processing, including compound splitting and for translation into german also compound merging ? part-of-speech and morphological sequence models all models were trained on true cased data.
</nextsent>
<nextsent>translation and reordering models were trained using the bilingual europarl and news commentary corpora that were concatenated before training.
</nextsent>
<nextsent>we created two language models.
</nextsent>
<nextsent>the first model is 5-gram model that we created by interpol ating two language 393models from bilingual news commentary and eu roparl with more weight on the news commentary model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4956">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>we experimented with different ways of combining the two alignments such as using heuristic symmetrization and interpo lating phrase tables.results are reported on three metrics, bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>nist (doddington, 2002) and meteor ranking scores (agarwal and lavie, 2008) <papid> W08-0312 </papid>based on true cased output.</prevsent>
<prevsent>this years improvements were added to the liu baseline system (stymne et al, 2010).<papid> W10-1727 </papid></prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
our base line is factored phrase based smt system that usesthe moses toolkit (koehn et al, 2007) <papid> P07-2045 </papid>for translation model training and decoding, giza++ (ochand ney, 2003) <papid> J03-1002 </papid>for word alignment, srilm (stol cke, 2002) an kenlm (heafield, 2011) <papid> W11-2123 </papid>for language modelling and minimum error rate training (och, 2003) <papid> P03-1021 </papid>to tune model feature weights.</citsent>
<aftsection>
<nextsent>in addition, the liu baseline contains: ? compound processing, including compound splitting and for translation into german also compound merging ? part-of-speech and morphological sequence models all models were trained on true cased data.
</nextsent>
<nextsent>translation and reordering models were trained using the bilingual europarl and news commentary corpora that were concatenated before training.
</nextsent>
<nextsent>we created two language models.
</nextsent>
<nextsent>the first model is 5-gram model that we created by interpol ating two language 393models from bilingual news commentary and eu roparl with more weight on the news commentary model.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4957">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>morphology to improve target word order and agreement in the translation output, we added an extra output factor in our translation models consisting of tags with pos and morphological features.
</prevsent>
<prevsent>for english we used tags that were obtained by enriching pos tags fromtreetagger (schmid, 1994) with additional morphological features such as number for determiners.
</prevsent>
</prevsection>
<citsent citstr=" C08-1098 ">
for german, the pos and morphological tags were obtained from rftagger (schmid and laws, 2008) <papid> C08-1098 </papid>which provides morphological information such as case, number and gender for nouns and tense for verbs.</citsent>
<aftsection>
<nextsent>we trained two sequence models for each system over this output factor and added them as features in our baseline system.
</nextsent>
<nextsent>the first sequence model is 7-gram model interpolated from models of bilingual europarl and news commentary.
</nextsent>
<nextsent>the second model is 6-gram model trained on monolingual news only.
</nextsent>
<nextsent>2.2 compound processing.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4958">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>the second model is 6-gram model trained on monolingual news only.
</prevsent>
<prevsent>2.2 compound processing.
</prevsent>
</prevsection>
<citsent citstr=" E03-1076 ">
in both translation directions we split compounds,using modified version of the corpus-based splitting method of koehn and knight (2003).<papid> E03-1076 </papid></citsent>
<aftsection>
<nextsent>we split nouns, verb, and adjective compounds into known parts that were content words or cardinal numbers, based on the arithmetic mean of the frequency ofthe parts in the training corpus.
</nextsent>
<nextsent>we allowed 10 common letter changes (langer, 1998) and hyphens atsplit points.
</nextsent>
<nextsent>compound parts were kept in their surface form and compound modifiers received partof-speech tag based on that of the tag of the full compound.
</nextsent>
<nextsent>for translation into german, compounds were merged using the pos-merging strategy of stymne (2009).<papid> E09-3008 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4959">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>we allowed 10 common letter changes (langer, 1998) and hyphens atsplit points.
</prevsent>
<prevsent>compound parts were kept in their surface form and compound modifiers received partof-speech tag based on that of the tag of the full compound.
</prevsent>
</prevsection>
<citsent citstr=" E09-3008 ">
for translation into german, compounds were merged using the pos-merging strategy of stymne (2009).<papid> E09-3008 </papid></citsent>
<aftsection>
<nextsent>a compound part in the translation output, identified by the special part-of-speech tags, was merged with the next word if that word had matching part-of-speech tag.
</nextsent>
<nextsent>if the compound part was followed by the conjunction und (and), we added ahyphen to the part, to account for coordinated compounds.
</nextsent>
<nextsent>2.3 hierarchical reordering.
</nextsent>
<nextsent>in our baseline system we experimented with two lexicalized reordering models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4960">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> baseline system.  </section>
<citcontext>
<prevsection>
<prevsent>2.3 hierarchical reordering.
</prevsent>
<prevsent>in our baseline system we experimented with two lexicalized reordering models.
</prevsent>
</prevsection>
<citsent citstr=" D08-1089 ">
the standard modelin moses (koehn et al, 2005), and the hierarchical model of galley and manning (2008).<papid> D08-1089 </papid></citsent>
<aftsection>
<nextsent>in both models the placement of phrase is compared tothat of the previous and/or next phrase.
</nextsent>
<nextsent>in the standard model up to three reorderings are distinguished,monotone, swap, and discontinuous.
</nextsent>
<nextsent>in the hierarchical model the discontinuous class can be further subdivided into two classes, left and right discontinuous.
</nextsent>
<nextsent>the hierarchical model further differs from the standard model in that it compares the order of the phrase with the next or previous block of phrases, not only with the next or previous single phrase.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4961">
<title id=" W11-2147.xml">experiments with word alignment normalization and clause reordering for smt between english and german </title>
<section> german english.  </section>
<citcontext>
<prevsection>
<prevsent>these changes would have been harmful for translation into german, since they change the language into normalized variant, but for translation from german we considered them safe.
</prevsent>
<prevsent>3.2 source side reordering.
</prevsent>
</prevsection>
<citsent citstr=" P05-1066 ">
to make the word order of german input sentences more english-like version of the rules of(collins et al, 2005) <papid> P05-1066 </papid>were partially implemented using tagged output from the rftagger.</citsent>
<aftsection>
<nextsent>basically, beginnings of subordinate clauses, their subjects (if present) and final verb clusters were identified based on tag sequences, and the clusters were moved to the beginning of the clause, and reordered so thatthe finite verb ended up in the second clause position.
</nextsent>
<nextsent>also, some common adverbs were moved withthe verb cluster and placed between finite and non finite verbs.
</nextsent>
<nextsent>after testing, we decided to apply these rules only to subordinate clauses at the end of sentences, since these were the only ones that could be identified with good precision.
</nextsent>
<nextsent>still, some 750,000 clauses were reordered.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4962">
<title id=" W11-2167.xml">bayesian extraction of minimal scfg rules for hierarchical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>our bayesian model limits the number of scfg rules extracted, by sampling from th espace of all possible hierarchical rules; additionally our informed prior based on the lexical alignment probabilities biases the grammar to extract high quality rules leading to improved generalization and the automatic identification of commonly re-used rules.
</prevsent>
<prevsent>weshow that our bayesian model is able to extract minimal set of hierarchical phrase rules without impacting the translation quality as measured by the bleu score.
</prevsent>
</prevsection>
<citsent citstr=" J07-2003 ">
hierarchical phrase-based (hiero) machine translation (chiang, 2007) <papid> J07-2003 </papid>has attracted significant interest within the machine translation community.</citsent>
<aftsection>
<nextsent>it extends phrase-based translation by automatically inferring synchronous grammar from an aligned bi text.
</nextsent>
<nextsent>the synchronous context-free grammar linksnon-terminals in source and target languages.
</nextsent>
<nextsent>decoding in such systems employ modified cky parser that is integrated with language model.
</nextsent>
<nextsent>the primary advantage of hiero-style systems liein their unsupervised model of syntax for translation: allowing long-distance reordering and capturing certain syntactic constructions, particularly those that involve dis contiguous phrases.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4966">
<title id=" W11-2167.xml">bayesian extraction of minimal scfg rules for hierarchical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>decoding in such systems employ modified cky parser that is integrated with language model.
</prevsent>
<prevsent>the primary advantage of hiero-style systems liein their unsupervised model of syntax for translation: allowing long-distance reordering and capturing certain syntactic constructions, particularly those that involve dis contiguous phrases.
</prevsent>
</prevsection>
<citsent citstr=" C08-1144 ">
it has been demonstrated to be successful framework with comparable performance with other statistical frameworks and suitable for large-scale corpora (zollmann et al, 2008).<papid> C08-1144 </papid></citsent>
<aftsection>
<nextsent>however, one of the major difficulties in hiero-style systems has been on learning concise and general synchronous grammar from the bitext.while most of the research in hiero-style systems is focused on the improving the decoder, andin particular the link to the language model, comparatively few papers have considered the inference of the probabilistic scfg from the word alignments.a majority of the systems employ the classic rule extraction algorithm (chiang, 2007) <papid> J07-2003 </papid>which extracts rules by replacing possible sub-spans (permitted by the word alignments) with non-terminal and then using relative frequencies to estimate the probabilistic synchronous context-free grammar.</nextsent>
<nextsent>one of the issues in building hiero-style systems is in managing the size of the synchronous grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4971">
<title id=" W11-2167.xml">bayesian extraction of minimal scfg rules for hierarchical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the original approach extracts larger number of rules when compared to phrase-based system on the same data leading to practical issues in terms of memory requirements and decoding speed.
</prevsent>
<prevsent>extremely large hiero phrase tables may also lead to statistical issues, where the probability mass has to be shared by more rules: the probability p(e|f) has to be shared by all the rules having the same source side string , leading to fragmentation and resulting in many rules having very poor probability.approaches to improve the inference (the induction of the scfg rules from the bitext) typically follows two streams.
</prevsent>
</prevsection>
<citsent citstr=" E09-1044 ">
one focusses on filtering the extracted hierarchical rules either by removing redundancy (he et al, 2009) or by filtering rules based on certain patterns (iglesias et al, 2009)<papid> E09-1044 </papid>while the other stream is concerned about alternative approaches for learning the synchronous grammar (blunsom et al, 2008; blunsom et al, 2009; <papid> P09-1088 </papid>degispert et al, 2010).</citsent>
<aftsection>
<nextsent>this paper falls under the latter category and we use non-parametric bayesian approach for rule extraction for hiero-style systems.
</nextsent>
<nextsent>our objective in this paper is to provide principled 533 rule extraction method using bayesian framework that can extract the minimal scfg rules without reducing the bleu score.
</nextsent>
<nextsent>the large number of rules in hiero-style systems leads to slow decoding and increased memory requirements.
</nextsent>
<nextsent>the heuristic rule extraction algorithm (chiang, 2007) <papid> J07-2003 </papid>introduces redundant monotone composed rules (he et al, 2009) in the scfg grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4973">
<title id=" W11-2167.xml">bayesian extraction of minimal scfg rules for hierarchical phrase based translation </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the original approach extracts larger number of rules when compared to phrase-based system on the same data leading to practical issues in terms of memory requirements and decoding speed.
</prevsent>
<prevsent>extremely large hiero phrase tables may also lead to statistical issues, where the probability mass has to be shared by more rules: the probability p(e|f) has to be shared by all the rules having the same source side string , leading to fragmentation and resulting in many rules having very poor probability.approaches to improve the inference (the induction of the scfg rules from the bitext) typically follows two streams.
</prevsent>
</prevsection>
<citsent citstr=" P09-1088 ">
one focusses on filtering the extracted hierarchical rules either by removing redundancy (he et al, 2009) or by filtering rules based on certain patterns (iglesias et al, 2009)<papid> E09-1044 </papid>while the other stream is concerned about alternative approaches for learning the synchronous grammar (blunsom et al, 2008; blunsom et al, 2009; <papid> P09-1088 </papid>degispert et al, 2010).</citsent>
<aftsection>
<nextsent>this paper falls under the latter category and we use non-parametric bayesian approach for rule extraction for hiero-style systems.
</nextsent>
<nextsent>our objective in this paper is to provide principled 533 rule extraction method using bayesian framework that can extract the minimal scfg rules without reducing the bleu score.
</nextsent>
<nextsent>the large number of rules in hiero-style systems leads to slow decoding and increased memory requirements.
</nextsent>
<nextsent>the heuristic rule extraction algorithm (chiang, 2007) <papid> J07-2003 </papid>introduces redundant monotone composed rules (he et al, 2009) in the scfg grammar.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4979">
<title id=" W11-2167.xml">bayesian extraction of minimal scfg rules for hierarchical phrase based translation </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>they achieve up to 70% reduction in the phrase table by discarding these redundant rules, without appreciable reduction in the performance as measured by bleu.
</prevsent>
<prevsent>empirically analyzing the effectiveness of specific rule patterns, (iglesias et al, 2009)<papid> E09-1044 </papid>show that some patterns having over 95% of the total scfg rules can be safely eliminated without any reduction in the bleu score.</prevsent>
</prevsection>
<citsent citstr=" D08-1033 ">
along different track, some prior works have employed alternate rule extraction approaches usinga bayesian framework (denero et al, 2008; <papid> D08-1033 </papid>blunsom et al, 2008; blunsom et al, 2009).<papid> P09-1088 </papid></citsent>
<aftsection>
<nextsent>(denero et al, 2008) <papid> D08-1033 </papid>use maximum likelihood model of learning phrase pairs (marcu and wong, 2002), <papid> W02-1018 </papid>but use sampling to compute the expected counts of the phrase pairs for the e-step.</nextsent>
<nextsent>other recent approaches use gibbs sampler for learning the scfg by exploring fixed grammar having pre-defined rule templates (blunsom et al, 2008) or by reasoning over the space of derivations (blunsom et al, 2009).<papid> P09-1088 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4983">
<title id=" W11-2167.xml">bayesian extraction of minimal scfg rules for hierarchical phrase based translation </title>
<section> motivation and related work.  </section>
<citcontext>
<prevsection>
<prevsent>empirically analyzing the effectiveness of specific rule patterns, (iglesias et al, 2009)<papid> E09-1044 </papid>show that some patterns having over 95% of the total scfg rules can be safely eliminated without any reduction in the bleu score.</prevsent>
<prevsent>along different track, some prior works have employed alternate rule extraction approaches usinga bayesian framework (denero et al, 2008; <papid> D08-1033 </papid>blunsom et al, 2008; blunsom et al, 2009).<papid> P09-1088 </papid></prevsent>
</prevsection>
<citsent citstr=" W02-1018 ">
(denero et al, 2008) <papid> D08-1033 </papid>use maximum likelihood model of learning phrase pairs (marcu and wong, 2002), <papid> W02-1018 </papid>but use sampling to compute the expected counts of the phrase pairs for the e-step.</citsent>
<aftsection>
<nextsent>other recent approaches use gibbs sampler for learning the scfg by exploring fixed grammar having pre-defined rule templates (blunsom et al, 2008) or by reasoning over the space of derivations (blunsom et al, 2009).<papid> P09-1088 </papid></nextsent>
<nextsent>we differ from earlier bayesian approaches in thatour model is guided by the word alignments to reason over the space of the scfg rules and this restricts the search space of our model.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4988">
<title id=" W11-2167.xml">bayesian extraction of minimal scfg rules for hierarchical phrase based translation </title>
<section> model.  </section>
<citcontext>
<prevsection>
<prevsent>we hypothesize that the resulting grammar will be compact and also will explain the phrase pairs better (the scfg rules will maximize the likelihood of producing the entire set of observed phrase pairs).using bayes?
</prevsent>
<prevsent>rule, the posterior over the derivations given the phrase pairs rp can be written as: (r|rp) ? (rp|r)p (r) (1) where (rp|r) is equal to one when the sequence of rules and phrase-pairs rp are consistent, i.e. can be partitioned into derivations to compose the set of phrase-pairs such that the derivations respect 534 the given word alignments; otherwise (rp|r) iszero.
</prevsent>
</prevsection>
<citsent citstr=" N09-1062 ">
the overall structure of the model is analogous to the bayesian model for inducing tree substitution grammars proposed by cohn et al (2009).<papid> N09-1062 </papid></citsent>
<aftsection>
<nextsent>note that, our model extracts hierarchical rules forthe word-aligned phrase pairs and not for the sentences.
</nextsent>
<nextsent>similar to the other hiero-style systems, we use two types of rules: terminal and hierarchical rules.
</nextsent>
<nextsent>for each phrase-pair, our model either generates terminal rule by not segmenting the phrase-pair, or decides to segment the phrase-pair and extract some rules.
</nextsent>
<nextsent>though it is possible to segment phrase-pairs by two (or more) non-overlapping spans, we proposea simpler model in this paper and restrict the hierarchical rules to contain only one non-terminal (unlike the case of classic hiero-style grammars containing two non-terminals).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4991">
<title id=" W11-2167.xml">bayesian extraction of minimal scfg rules for hierarchical phrase based translation </title>
<section> inference.  </section>
<citcontext>
<prevsection>
<prevsent>the model samples derivation from the space of derivations that are consistent with the word alignments.
</prevsent>
<prevsent>in orderto achieve this, we need an efficient way to enumerate the derivations for phrase pair such that theyare consistent with the alignments.
</prevsent>
</prevsection>
<citsent citstr=" C08-1136 ">
we use the linear time algorithm to maximally decompose word aligned phrase pair, so as to encode it as compact alignment tree (zhang et al, 2008).<papid> C08-1136 </papid></citsent>
<aftsection>
<nextsent>f0 f1 f2 f3 f4 e0 e1 e2 e3 e4 e5 figure 3: example phrase pair with alignments.
</nextsent>
<nextsent>536 for phrase-pair with given alignment as shown in figure 3, zhang et al (2008) <papid> C08-1136 </papid>generalize theo(n+k) time algorithm for computing all common intervals of two different permutations of length n.the contiguous blocks of the alignment are captured as the nodes in the alignment tree and the tree structure for the example phrase pair in figure 3 isshown in figure 4.</nextsent>
<nextsent>the italicized nodes form left branching chain in the alignment tree and the sub spans of this chain also lead to alignment nodes that are not explicitly captured in the tree (please refer to zhang et al (2008) <papid> C08-1136 </papid>for details).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4996">
<title id=" W11-2167.xml">bayesian extraction of minimal scfg rules for hierarchical phrase based translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>3.
</prevsent>
<prevsent>we use the english-spanish data from wmt-10shared task for the experiments to evaluate the effectiveness of our bayesian rule extraction approach.
</prevsent>
</prevsection>
<citsent citstr=" P03-1021 ">
we used the entire shared task training set except theun data for training translation model and the language model was trained with the same set and an additional 2 million sentences from theun data, using srilm toolkit with knesser-ney discounting.we tuned the feature weights on the wmt-10 dev set using mert (och, 2003) <papid> P03-1021 </papid>and evaluate on thetest set by computing lower-cased bleu score (papineni et al, 2002) <papid> P02-1040 </papid>using the wmt-10 standard evaluation script.we use kriya ? an in-house implementation of hierarchical phrase-based translation written predominantly in python.</citsent>
<aftsection>
<nextsent>kriya supports the entire translation pipeline of scfg rule extraction and decoding with cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>andlm integration (chiang, 2007).<papid> J07-2003 </papid></nextsent>
<nextsent>we use the 7 features (4 translation model features, extracted rules penalty, word penalty and language model) as is typical in hiero-style systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4997">
<title id=" W11-2167.xml">bayesian extraction of minimal scfg rules for hierarchical phrase based translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>3.
</prevsent>
<prevsent>we use the english-spanish data from wmt-10shared task for the experiments to evaluate the effectiveness of our bayesian rule extraction approach.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
we used the entire shared task training set except theun data for training translation model and the language model was trained with the same set and an additional 2 million sentences from theun data, using srilm toolkit with knesser-ney discounting.we tuned the feature weights on the wmt-10 dev set using mert (och, 2003) <papid> P03-1021 </papid>and evaluate on thetest set by computing lower-cased bleu score (papineni et al, 2002) <papid> P02-1040 </papid>using the wmt-10 standard evaluation script.we use kriya ? an in-house implementation of hierarchical phrase-based translation written predominantly in python.</citsent>
<aftsection>
<nextsent>kriya supports the entire translation pipeline of scfg rule extraction and decoding with cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>andlm integration (chiang, 2007).<papid> J07-2003 </papid></nextsent>
<nextsent>we use the 7 features (4 translation model features, extracted rules penalty, word penalty and language model) as is typical in hiero-style systems.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI4998">
<title id=" W11-2167.xml">bayesian extraction of minimal scfg rules for hierarchical phrase based translation </title>
<section> experiments.  </section>
<citcontext>
<prevsection>
<prevsent>we use the english-spanish data from wmt-10shared task for the experiments to evaluate the effectiveness of our bayesian rule extraction approach.
</prevsent>
<prevsent>we used the entire shared task training set except theun data for training translation model and the language model was trained with the same set and an additional 2 million sentences from theun data, using srilm toolkit with knesser-ney discounting.we tuned the feature weights on the wmt-10 dev set using mert (och, 2003) <papid> P03-1021 </papid>and evaluate on thetest set by computing lower-cased bleu score (papineni et al, 2002) <papid> P02-1040 </papid>using the wmt-10 standard evaluation script.we use kriya ? an in-house implementation of hierarchical phrase-based translation written predominantly in python.</prevsent>
</prevsection>
<citsent citstr=" P07-1019 ">
kriya supports the entire translation pipeline of scfg rule extraction and decoding with cube pruning (huang and chiang, 2007) <papid> P07-1019 </papid>andlm integration (chiang, 2007).<papid> J07-2003 </papid></citsent>
<aftsection>
<nextsent>we use the 7 features (4 translation model features, extracted rules penalty, word penalty and language model) as is typical in hiero-style systems.
</nextsent>
<nextsent>for tuning the feature weights, we have adapted the mert implementation in moses1 for use with kriya as the decoder.
</nextsent>
<nextsent>we started by training and evaluating the two baseline systems using i) two non-terminals and ii) one non-terminal, which were trained using the conventional heuristic extraction approach.
</nextsent>
<nextsent>for the baseline with one non-terminal, we modified the heuristic rule extraction algorithm appropriately2.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5010">
<title id=" W11-2109.xml">evaluation without references ibm1 scores as evaluation metrics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>five different european languages are taken into account: english, spanish, french, german and czech.
</prevsent>
<prevsent>the results show that the ibm1 scores are competitive with the classic evaluation metrics, the most promising being ibm1 scores calculated on morphemes and pos-4grams.
</prevsent>
</prevsection>
<citsent citstr=" P02-1040 ">
currently used evaluation metrics such as bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>etc. are based on the comparison between human reference translations and the automatically generated hypotheses in the target language to be evaluated.</citsent>
<aftsection>
<nextsent>while this scenario helps in the design of machine translation systems, it has two major drawbacks.
</nextsent>
<nextsent>the first one is the practical criticism that using reference translations is inefficient and expensive: in real-life situations, the quality of machine translation must be evaluated without having to pay humans for producing reference translations first.
</nextsent>
<nextsent>the second criticism is methodological: inusing reference translation, the problem of evaluating translation quality (e.g., completeness, ordering, domain fit, etc.) is transformed into kind of paraphrase evaluation in the target language, which is very difficult problem itself.
</nextsent>
<nextsent>in addition, the set of selected references always represents only small subset of all good translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5011">
<title id=" W11-2109.xml">evaluation without references ibm1 scores as evaluation metrics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>five different european languages are taken into account: english, spanish, french, german and czech.
</prevsent>
<prevsent>the results show that the ibm1 scores are competitive with the classic evaluation metrics, the most promising being ibm1 scores calculated on morphemes and pos-4grams.
</prevsent>
</prevsection>
<citsent citstr=" W05-0909 ">
currently used evaluation metrics such as bleu (pa pineni et al, 2002), <papid> P02-1040 </papid>meteor (banerjee and lavie, 2005), <papid> W05-0909 </papid>etc. are based on the comparison between human reference translations and the automatically generated hypotheses in the target language to be evaluated.</citsent>
<aftsection>
<nextsent>while this scenario helps in the design of machine translation systems, it has two major drawbacks.
</nextsent>
<nextsent>the first one is the practical criticism that using reference translations is inefficient and expensive: in real-life situations, the quality of machine translation must be evaluated without having to pay humans for producing reference translations first.
</nextsent>
<nextsent>the second criticism is methodological: inusing reference translation, the problem of evaluating translation quality (e.g., completeness, ordering, domain fit, etc.) is transformed into kind of paraphrase evaluation in the target language, which is very difficult problem itself.
</nextsent>
<nextsent>in addition, the set of selected references always represents only small subset of all good translations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5012">
<title id=" W11-2109.xml">evaluation without references ibm1 scores as evaluation metrics </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the second criticism is methodological: inusing reference translation, the problem of evaluating translation quality (e.g., completeness, ordering, domain fit, etc.) is transformed into kind of paraphrase evaluation in the target language, which is very difficult problem itself.
</prevsent>
<prevsent>in addition, the set of selected references always represents only small subset of all good translations.
</prevsent>
</prevsection>
<citsent citstr=" J93-2003 ">
to remedy these drawbacks, we propose truly automatic evaluation metric which is based on the ibm1 lexicon scores (brown et al, 1993).<papid> J93-2003 </papid>the inclusion of ibm1 scores in translation systems has shown experimentally to improve translation quality (och et al, 2003).</citsent>
<aftsection>
<nextsent>they also have been used for confidence estimation for machine translation (blatz et al, 2003).
</nextsent>
<nextsent>to the best of our knowledge, these scores have not yet been used as an evaluation metric.
</nextsent>
<nextsent>we carry out systematic comparison between several variants of ibm1 scores.
</nextsent>
<nextsent>the spearmansrank correlation coefficients on the document (system) level between the ibm1 metrics and the human ranking are computed on the english, french,spanish, german and czech texts generated by various translation systems in the framework of the third (callison-burch et al, 2008), fourth (callison burch et al, 2009) and fifth (callison-burch et al, 2010) shared translation tasks.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5014">
<title id=" W12-0415.xml">identification of truth and deception in text application of vector space model to rhetorical structure theory </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>though there is no clear consensus on reliable predictors of deception, deceptive cues are identified in texts, extracted and clustered conceptually, for instance, to represent diversity, complexity, specificity, and non-immediacy of the analyzed texts (e.g., zhou, burgoon, nunamaker, and twitchell (2004)).
</prevsent>
<prevsent>when implemented with standard classification algorithms (such as neural nets, decision trees, and logistic regression), such methods achieve 74% accuracy (fuller, et al , 2009).
</prevsent>
</prevsection>
<citsent citstr=" P09-2078 ">
existing psycho linguistic lexicons (e.g., lwic by penne baker and francis, 1999) have been adapted to perform binary text classifications for truthful versus deceptive opinions, with an average classifier demonstrating 70% accuracy rate (mihalcea and strapparava, 2009).<papid> P09-2078 </papid></citsent>
<aftsection>
<nextsent>these modest results, though usually achieved on restricted topics, are promising since they supersede notoriously unreliable human abilities in lie-truth discrimination tasks.
</nextsent>
<nextsent>on average, people are not very good at spotting lies (vrij, 2000), succeeding generally only about half of the time (frank, paolantinio, feeley, and 97 servoss, 2004).
</nextsent>
<nextsent>for instance, meta-analytical review of over 100 experiments with over 1,000 participants, showed 54% mean accuracy rate at identifying deception (depaulo, et al , 1997).
</nextsent>
<nextsent>human judges achieve 50 ? 63% success rates, depending on what is considered deceptive on seven-point scale of truth-to-deception continuum (rubin and conroy, 2011, rubin and conroy, 2012), but the higher the actual self reported deception level of the story, the more likely story would be confidently assigned as deceptive.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5015">
<title id=" W12-0415.xml">identification of truth and deception in text application of vector space model to rhetorical structure theory </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>study objective with the recent advances in the identification of verbal cues of deception in mind, and the realization that they focus on linguistic levels below discourse and pragmatic analysis, the study focuses on one main question: ? what is the impact of the relations between discourse constituent parts on the discourse composition of deceptive and truthful messages?
</prevsent>
<prevsent>we hypothesize that if the relations between discourse constituent parts in deceptive messages differ from the ones in truthful messages, then systematic analysis of such relations will help to 1 using corpus of criminal statements, police interrogations and.
</prevsent>
</prevsection>
<citsent citstr=" C08-1006 ">
legal testimonies, their regression and tree-based classification automatic tagger performs at average 69% recall and 85% precision rates, as compared to the performance of human taggers on the same subset (bachenko, et al , 2008).<papid> C08-1006 </papid></citsent>
<aftsection>
<nextsent>detect deception.
</nextsent>
<nextsent>to investigate this question, we propose to use novel methodology for deception detection research, rhetorical structure theory (rst) analysis with subsequent application of the vector space model (vsm).
</nextsent>
<nextsent>rst analysis is promising in deception detection, since rst analysis captures coherence of story in terms of functional relations among different meaningful text units, and describes hierarchical structure of each story (mann and thompson, 1988).
</nextsent>
<nextsent>the result is that each story is set of rst relations connected in hierarchical manner with more salient text units heading this hierarchical tree.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5016">
<title id=" W11-2404.xml">is it worth submitting this run assess your rte system with a good sparring partner </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, in contrast with other more stable tasks in terms of evaluation settings and metrics (e.g. machine transla tion), such changes make it difficult to capitalize on the experience obtained by participants throughout the years.
</prevsent>
<prevsent>third, looking at rte-related literature and the outcomes of the six campaigns organised sofar, the conclusions that can be drawn are often controversial.
</prevsent>
</prevsection>
<citsent citstr=" W07-1412 ">
for instance, it is not clear whether the availability of larger amounts of training data correlates with better performance (hickl et al, 2006) or not (zanzotto et al, 2007; <papid> W07-1412 </papid>hickl and bensley, 2007),<papid> W07-1428 </papid>even within the same evaluation setting.</citsent>
<aftsection>
<nextsent>in addition, ablation tests carried out in recent editions of the challenge do not allow for definite conclusions about the actual usefulness of tools and resources, even the most popular ones (bentivogli et al, 2009).finally, the best performing systems often have different natures from one year to another, showing alternations of deep (hickl and bensley, 2007; <papid> W07-1428 </papid>tatu and moldovan, 2007) <papid> W07-1404 </papid>and shallow approaches (jia et al, 2010) ranked at the top positions.</nextsent>
<nextsent>in lightof these considerations, it would be useful for sys 30tems developers to have: i) automatic ways to support systems?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5017">
<title id=" W11-2404.xml">is it worth submitting this run assess your rte system with a good sparring partner </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>however, in contrast with other more stable tasks in terms of evaluation settings and metrics (e.g. machine transla tion), such changes make it difficult to capitalize on the experience obtained by participants throughout the years.
</prevsent>
<prevsent>third, looking at rte-related literature and the outcomes of the six campaigns organised sofar, the conclusions that can be drawn are often controversial.
</prevsent>
</prevsection>
<citsent citstr=" W07-1428 ">
for instance, it is not clear whether the availability of larger amounts of training data correlates with better performance (hickl et al, 2006) or not (zanzotto et al, 2007; <papid> W07-1412 </papid>hickl and bensley, 2007),<papid> W07-1428 </papid>even within the same evaluation setting.</citsent>
<aftsection>
<nextsent>in addition, ablation tests carried out in recent editions of the challenge do not allow for definite conclusions about the actual usefulness of tools and resources, even the most popular ones (bentivogli et al, 2009).finally, the best performing systems often have different natures from one year to another, showing alternations of deep (hickl and bensley, 2007; <papid> W07-1428 </papid>tatu and moldovan, 2007) <papid> W07-1404 </papid>and shallow approaches (jia et al, 2010) ranked at the top positions.</nextsent>
<nextsent>in lightof these considerations, it would be useful for sys 30tems developers to have: i) automatic ways to support systems?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5019">
<title id=" W11-2404.xml">is it worth submitting this run assess your rte system with a good sparring partner </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>third, looking at rte-related literature and the outcomes of the six campaigns organised sofar, the conclusions that can be drawn are often controversial.
</prevsent>
<prevsent>for instance, it is not clear whether the availability of larger amounts of training data correlates with better performance (hickl et al, 2006) or not (zanzotto et al, 2007; <papid> W07-1412 </papid>hickl and bensley, 2007),<papid> W07-1428 </papid>even within the same evaluation setting.</prevsent>
</prevsection>
<citsent citstr=" W07-1404 ">
in addition, ablation tests carried out in recent editions of the challenge do not allow for definite conclusions about the actual usefulness of tools and resources, even the most popular ones (bentivogli et al, 2009).finally, the best performing systems often have different natures from one year to another, showing alternations of deep (hickl and bensley, 2007; <papid> W07-1428 </papid>tatu and moldovan, 2007) <papid> W07-1404 </papid>and shallow approaches (jia et al, 2010) ranked at the top positions.</citsent>
<aftsection>
<nextsent>in lightof these considerations, it would be useful for sys 30tems developers to have: i) automatic ways to support systems?
</nextsent>
<nextsent>tuning at training stage, and ii) reliable terms of comparison to validate their hypotheses, and position the results of their work before submitting runs for evaluation.
</nextsent>
<nextsent>in this paper we address these needs by extending an open-source rte package (edits1) with mechanism that automatizes the selection of the most promising configuration over training dataset.
</nextsent>
<nextsent>we prove the effectiveness of such extension showing that it allows not only to achieve good performance on all the available rte challenge datasets, but also to improve the official results, achieved with the same system, through adhoc configurations manually defined by the developers team.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5020">
<title id=" W11-2404.xml">is it worth submitting this run assess your rte system with a good sparring partner </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>for system developers, to be used as fast and free term of comparison to position the results of their work.
</prevsent>
<prevsent>2 coping?
</prevsent>
</prevsection>
<citsent citstr=" P10-4008 ">
with configurability edits (kouylekov and negri, 2010) <papid> P10-4008 </papid>is an open source rte package, which offers modular, flexible, and adaptable working environment to experiment with the rte task over different datasets.</citsent>
<aftsection>
<nextsent>the package allows to: i) create an entailment engine by defining its basic components (i.e. algorithms, cost schemes, rules, and optimizers); ii) train such entailment engine over an annotated rte corpus to learn model; and iii) use the entailment engine and the model to assign an entailment judgement and confidence score to each pair of an un-annotated test corpus.
</nextsent>
<nextsent>a key feature of edits is represented by its high configurability, allowed by the availability of different algorithms, the possibility to integrate different sets of lexical entailment/contradiction rules,and the variety of parameters for performance optimization (see also mehdad, 2009).<papid> P09-2073 </papid></nextsent>
<nextsent>although config ura bility is perse an important aspect (especially for an open-source and general purpose system), there is another side of the coin.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5021">
<title id=" W11-2404.xml">is it worth submitting this run assess your rte system with a good sparring partner </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>with configurability edits (kouylekov and negri, 2010) <papid> P10-4008 </papid>is an open source rte package, which offers modular, flexible, and adaptable working environment to experiment with the rte task over different datasets.</prevsent>
<prevsent>the package allows to: i) create an entailment engine by defining its basic components (i.e. algorithms, cost schemes, rules, and optimizers); ii) train such entailment engine over an annotated rte corpus to learn model; and iii) use the entailment engine and the model to assign an entailment judgement and confidence score to each pair of an un-annotated test corpus.</prevsent>
</prevsection>
<citsent citstr=" P09-2073 ">
a key feature of edits is represented by its high configurability, allowed by the availability of different algorithms, the possibility to integrate different sets of lexical entailment/contradiction rules,and the variety of parameters for performance optimization (see also mehdad, 2009).<papid> P09-2073 </papid></citsent>
<aftsection>
<nextsent>although config ura bility is perse an important aspect (especially for an open-source and general purpose system), there is another side of the coin.
</nextsent>
<nextsent>in principle, in order to select the most promising configuration over given development set, one should exhaustively run huge number of training/evaluation routines.
</nextsent>
<nextsent>such num 1http://edits.fbk.eu/ber corresponds to the total number of configurations allowed by the system, which result from the possible combinations of parameter settings.
</nextsent>
<nextsent>when dealing with enlarging dataset sizes, and the tight time constraints usually posed by the evaluation campaigns, this problem becomes particularly challenging, as developers are hardly able to run exhaustive training/evaluation routines.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5022">
<title id=" W11-2153.xml">influence of parser choice on dependency based mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wrong form of pronouns (personal and possessive pronouns referring to the clauses subject should have reflexive forms in czech).thus it is obvious that the parser choice is important and that it might not be enough to choose parser, for machine translation, only according to its uas.
</prevsent>
<prevsent>due to growing popularity of dependency syntax in the last years, there are number of dependency parsers available.
</prevsent>
</prevsection>
<citsent citstr=" H05-1066 ">
the present paper deals with five parsers evaluated within the translation frame work: three genuine dependency parsers, namely the parsers described in (mcdonald et al, 2005), (<papid> H05-1066 </papid>nivre et al, 2007), and (zhang and nivre, 2011), <papid> P11-2033 </papid>and two constituency parsers (charniak and johnson, 2005) <papid> P05-1022 </papid>and (klein and manning, 2003),<papid> P03-1054 </papid>whose outputs we reconverted to dependency structures by penn converter (johansson and nugues, 2007).</citsent>
<aftsection>
<nextsent>as for the related literature, there is no published study measuring the influence of dependency parsers on dependency-based mt to our knowledge.2the remainder of this paper is structured as follows.
</nextsent>
<nextsent>the overall translation pipeline, within which the parsers are tested, is described in section 2.
</nextsent>
<nextsent>section 3 lists the parsers under consideration and their main features.
</nextsent>
<nextsent>section 4 summarizes the influence of the selected parsers on the mt quality in terms of bleu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5023">
<title id=" W11-2153.xml">influence of parser choice on dependency based mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wrong form of pronouns (personal and possessive pronouns referring to the clauses subject should have reflexive forms in czech).thus it is obvious that the parser choice is important and that it might not be enough to choose parser, for machine translation, only according to its uas.
</prevsent>
<prevsent>due to growing popularity of dependency syntax in the last years, there are number of dependency parsers available.
</prevsent>
</prevsection>
<citsent citstr=" P11-2033 ">
the present paper deals with five parsers evaluated within the translation frame work: three genuine dependency parsers, namely the parsers described in (mcdonald et al, 2005), (<papid> H05-1066 </papid>nivre et al, 2007), and (zhang and nivre, 2011), <papid> P11-2033 </papid>and two constituency parsers (charniak and johnson, 2005) <papid> P05-1022 </papid>and (klein and manning, 2003),<papid> P03-1054 </papid>whose outputs we reconverted to dependency structures by penn converter (johansson and nugues, 2007).</citsent>
<aftsection>
<nextsent>as for the related literature, there is no published study measuring the influence of dependency parsers on dependency-based mt to our knowledge.2the remainder of this paper is structured as follows.
</nextsent>
<nextsent>the overall translation pipeline, within which the parsers are tested, is described in section 2.
</nextsent>
<nextsent>section 3 lists the parsers under consideration and their main features.
</nextsent>
<nextsent>section 4 summarizes the influence of the selected parsers on the mt quality in terms of bleu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5024">
<title id=" W11-2153.xml">influence of parser choice on dependency based mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wrong form of pronouns (personal and possessive pronouns referring to the clauses subject should have reflexive forms in czech).thus it is obvious that the parser choice is important and that it might not be enough to choose parser, for machine translation, only according to its uas.
</prevsent>
<prevsent>due to growing popularity of dependency syntax in the last years, there are number of dependency parsers available.
</prevsent>
</prevsection>
<citsent citstr=" P05-1022 ">
the present paper deals with five parsers evaluated within the translation frame work: three genuine dependency parsers, namely the parsers described in (mcdonald et al, 2005), (<papid> H05-1066 </papid>nivre et al, 2007), and (zhang and nivre, 2011), <papid> P11-2033 </papid>and two constituency parsers (charniak and johnson, 2005) <papid> P05-1022 </papid>and (klein and manning, 2003),<papid> P03-1054 </papid>whose outputs we reconverted to dependency structures by penn converter (johansson and nugues, 2007).</citsent>
<aftsection>
<nextsent>as for the related literature, there is no published study measuring the influence of dependency parsers on dependency-based mt to our knowledge.2the remainder of this paper is structured as follows.
</nextsent>
<nextsent>the overall translation pipeline, within which the parsers are tested, is described in section 2.
</nextsent>
<nextsent>section 3 lists the parsers under consideration and their main features.
</nextsent>
<nextsent>section 4 summarizes the influence of the selected parsers on the mt quality in terms of bleu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5025">
<title id=" W11-2153.xml">influence of parser choice on dependency based mt </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>wrong form of pronouns (personal and possessive pronouns referring to the clauses subject should have reflexive forms in czech).thus it is obvious that the parser choice is important and that it might not be enough to choose parser, for machine translation, only according to its uas.
</prevsent>
<prevsent>due to growing popularity of dependency syntax in the last years, there are number of dependency parsers available.
</prevsent>
</prevsection>
<citsent citstr=" P03-1054 ">
the present paper deals with five parsers evaluated within the translation frame work: three genuine dependency parsers, namely the parsers described in (mcdonald et al, 2005), (<papid> H05-1066 </papid>nivre et al, 2007), and (zhang and nivre, 2011), <papid> P11-2033 </papid>and two constituency parsers (charniak and johnson, 2005) <papid> P05-1022 </papid>and (klein and manning, 2003),<papid> P03-1054 </papid>whose outputs we reconverted to dependency structures by penn converter (johansson and nugues, 2007).</citsent>
<aftsection>
<nextsent>as for the related literature, there is no published study measuring the influence of dependency parsers on dependency-based mt to our knowledge.2the remainder of this paper is structured as follows.
</nextsent>
<nextsent>the overall translation pipeline, within which the parsers are tested, is described in section 2.
</nextsent>
<nextsent>section 3 lists the parsers under consideration and their main features.
</nextsent>
<nextsent>section 4 summarizes the influence of the selected parsers on the mt quality in terms of bleu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5027">
<title id=" W11-2153.xml">influence of parser choice on dependency based mt </title>
<section> involved parsers.  </section>
<citcontext>
<prevsection>
<prevsent>3.1 graph-based parser.
</prevsent>
<prevsent>in graph-based parsing, we learn model for scoring graph edges, and we search for the highest-scoringtree composed of the graphs edges.
</prevsent>
</prevsection>
<citsent citstr=" E06-1011 ">
we used maximum spanning tree parser (mcdonald and pereira,2006) <papid> E06-1011 </papid>which is capable of incorporating second order features (mst for short).</citsent>
<aftsection>
<nextsent>3.2 transition-based parsers.
</nextsent>
<nextsent>transition-based parsers utilize the shift-reduce algorithm.
</nextsent>
<nextsent>input words are put into queue and consumed by shift-reduce actions, while the out put parser is gradually built.
</nextsent>
<nextsent>unlike graph-based parsers, transition-based parsers have linear time complexity and allow straightforward application of non-local features.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5031">
<title id=" W11-2153.xml">influence of parser choice on dependency based mt </title>
<section> experiments and evaluation.  </section>
<citcontext>
<prevsection>
<prevsent>4.1 data for parsers?
</prevsent>
<prevsent>training and evaluation.
</prevsent>
</prevsection>
<citsent citstr=" P07-1031 ">
the dependency trees needed for training the parsers and evaluating their uas were created from the penn treebank data (enriched first with internal noun phrase structure applied via scripts provided by vadas and curran (2007)) <papid> P07-1031 </papid>by penn converter (jo hansson and nugues, 2007) with the -conll2007 option (pennconv for short).</citsent>
<aftsection>
<nextsent>all the parsers were evaluated on the same data ? section 23.
</nextsent>
<nextsent>all the parsers were trained on sections 0221, except for the stanford parser which was trained on sections 0121.
</nextsent>
<nextsent>we were able to retrain the parser models only for mst and malt.
</nextsent>
<nextsent>for the other parsers we used pre trained models available on the internet: cjs default model ec50spfinal, stanfords wsjpcfg.ser.gz model, and 10edge length is common feature in dependency parsers, so deleting?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5032">
<title id=" W11-2041.xml">beetle ii an adaptable tutorial dialogue system </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>the exercises were then transferred into computer system with only minor adjustments (e.g., breaking down compound questions into individual questions).
</prevsent>
<prevsent>this resulted in realistic tutoring setup, which presents interesting challenges to language processing components, involving wide variety of language phenomena.we demonstrate version of the system that underwent user evaluation in 2009, which found significant learning gains for students interacting withthe system.
</prevsent>
</prevsection>
<citsent citstr=" P10-2009 ">
the experimental data collection compared two different dialogue policies implemented in the system, and resulted in corpus supporting research into variety of questions about human computer dialogue interaction (dzikovska et al, 2010<papid> P10-2009 </papid>a).</citsent>
<aftsection>
<nextsent>338 figure 1: screen shot of the beetle ii system
</nextsent>
<nextsent>the beetle ii system delivers basic electricity and electronics tutoring to students with no prior knowledge of the subject.
</nextsent>
<nextsent>a screen shot is shown in figure 1.
</nextsent>
<nextsent>the student interface includes an area to display.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5035">
<title id=" W11-2041.xml">beetle ii an adaptable tutorial dialogue system </title>
<section> data analysis and future work.  </section>
<citcontext>
<prevsection>
<prevsent>in the second turn, the system cannot interpret the student utterance, so it responds with targeted help message and hint about the object that needs to be mentioned.
</prevsent>
<prevsent>finally, in the last turn the system combines the information from the tutors hint and the students answers and restates the complete answer since the current answer was completed over multiple turns.
</prevsent>
</prevsection>
<citsent citstr=" W11-2019 ">
the data collected with the beetle ii system has been used to investigate several research questions regarding discourse and dialogue: the effectiveness of different error recovery strategies (dzikovska etal., 2010<papid> P10-2009 </papid>b); the underlying dimensions of user satisfaction and their relationship with learning gain (dzikovska et al, 2011); <papid> W11-2019 </papid>the relationship between (student) alignment in dialogue and learning gain(steinhauser et al, 2011); and the differences between students?</citsent>
<aftsection>
<nextsent>social and meta cognitive statements depending on the interaction style (dzikovska et al, 2010<papid> P10-2009 </papid>a).</nextsent>
<nextsent>we are currently annotating the data with additional interaction parameters, including correctness of student answers and appropriateness of system hints.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5038">
<title id=" W12-2011.xml">predicting learner levels for online exercises of hebrew </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>specifically, we define two-phase classification process, isolating individual errors and linguistic constructions which are then aggregated into second phase; such two-step process allows for easy integration of other exercises and features in the future.
</prevsent>
<prevsent>the aggregation of information also allows us to smooth over sparse features.
</prevsent>
</prevsection>
<citsent citstr=" P11-1019 ">
several strands of research in intelligent computer assisted language learning (icall) focus on determining learner ability (attali and burstein, 2006;yannakoudakis et al, 2011).<papid> P11-1019 </papid></citsent>
<aftsection>
<nextsent>one of the tasks, detecting errors in range of languages and for rangeof types of errors, is becoming an increasingly popular topic (rozovskaya and roth, 2011; <papid> P11-1093 </papid>tetreault and chodorow, 2008); <papid> C08-1109 </papid>see, for example, the recent hoo(helping our own) challenge for automated writing assistance (dale and kilgarriff, 2011).</nextsent>
<nextsent>only rarely has there been work on detecting errors inmore morphologically-complex languages (dickin sonet al, 2011).<papid> W11-1410 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5040">
<title id=" W12-2011.xml">predicting learner levels for online exercises of hebrew </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>the aggregation of information also allows us to smooth over sparse features.
</prevsent>
<prevsent>several strands of research in intelligent computer assisted language learning (icall) focus on determining learner ability (attali and burstein, 2006;yannakoudakis et al, 2011).<papid> P11-1019 </papid></prevsent>
</prevsection>
<citsent citstr=" P11-1093 ">
one of the tasks, detecting errors in range of languages and for rangeof types of errors, is becoming an increasingly popular topic (rozovskaya and roth, 2011; <papid> P11-1093 </papid>tetreault and chodorow, 2008); <papid> C08-1109 </papid>see, for example, the recent hoo(helping our own) challenge for automated writing assistance (dale and kilgarriff, 2011).</citsent>
<aftsection>
<nextsent>only rarely has there been work on detecting errors inmore morphologically-complex languages (dickin sonet al, 2011).<papid> W11-1410 </papid></nextsent>
<nextsent>in our work, we extend the task to predicting the learners level based on the errors, focusing on hebrew.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5041">
<title id=" W12-2011.xml">predicting learner levels for online exercises of hebrew </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>the aggregation of information also allows us to smooth over sparse features.
</prevsent>
<prevsent>several strands of research in intelligent computer assisted language learning (icall) focus on determining learner ability (attali and burstein, 2006;yannakoudakis et al, 2011).<papid> P11-1019 </papid></prevsent>
</prevsection>
<citsent citstr=" C08-1109 ">
one of the tasks, detecting errors in range of languages and for rangeof types of errors, is becoming an increasingly popular topic (rozovskaya and roth, 2011; <papid> P11-1093 </papid>tetreault and chodorow, 2008); <papid> C08-1109 </papid>see, for example, the recent hoo(helping our own) challenge for automated writing assistance (dale and kilgarriff, 2011).</citsent>
<aftsection>
<nextsent>only rarely has there been work on detecting errors inmore morphologically-complex languages (dickin sonet al, 2011).<papid> W11-1410 </papid></nextsent>
<nextsent>in our work, we extend the task to predicting the learners level based on the errors, focusing on hebrew.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5042">
<title id=" W12-2011.xml">predicting learner levels for online exercises of hebrew </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>several strands of research in intelligent computer assisted language learning (icall) focus on determining learner ability (attali and burstein, 2006;yannakoudakis et al, 2011).<papid> P11-1019 </papid></prevsent>
<prevsent>one of the tasks, detecting errors in range of languages and for rangeof types of errors, is becoming an increasingly popular topic (rozovskaya and roth, 2011; <papid> P11-1093 </papid>tetreault and chodorow, 2008); <papid> C08-1109 </papid>see, for example, the recent hoo(helping our own) challenge for automated writing assistance (dale and kilgarriff, 2011).</prevsent>
</prevsection>
<citsent citstr=" W11-1410 ">
only rarely has there been work on detecting errors inmore morphologically-complex languages (dickin sonet al, 2011).<papid> W11-1410 </papid></citsent>
<aftsection>
<nextsent>in our work, we extend the task to predicting the learners level based on the errors, focusing on hebrew.
</nextsent>
<nextsent>our system is targeted to be used in university setting where incoming students need to be placed into the appropriate language leveli.e., the appropriate course based on their proficiency inthe language.
</nextsent>
<nextsent>such level prediction system for hebrew faces number of challenges: 1) unclear correspondence between errors and levels, 2) missing nlp resources, and, most critically, 3) data sparsity.
</nextsent>
<nextsent>placing learners into levels is generally done by human, based on written exam (e.g.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5043">
<title id=" W12-2011.xml">predicting learner levels for online exercises of hebrew </title>
<section> motivation </section>
<citcontext>
<prevsection>
<prevsent>our goal is to move towards freer language production and to analyze language proficiency through more variables, but, in the interest of practicality, we start in more restricted way.
</prevsent>
<prevsent>for lesser-resourced languages, there is generally little data and few nlp resources available.
</prevsent>
</prevsection>
<citsent citstr=" P11-2124 ">
for hebrew, for example, we must create our own pool of 95learner data, and while nlp tools and resources exist (goldberg and elhadad, 2011; <papid> P11-2124 </papid>yona and wintner, 2008; itai and wintner, 2008), they are not adapted for dealing with potentially ill-formed learner productions.</citsent>
<aftsection>
<nextsent>for this reason, we are performing linguistic analysis on the gold standard answers to obtain optimal linguistic analyses.
</nextsent>
<nextsent>then, the system aligns the learner answer to the gold standard answer and determines the types of deviations.
</nextsent>
<nextsent>since hebrew is less commonly taught language (lctl), we have few placement exams from which to learn correspondences.
</nextsent>
<nextsent>compounding the datasparsity problem is that each piece of data is com plex: if learner produces an erroneous answer, there are potentially number of ways to analyze it (cf.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5046">
<title id=" W12-2011.xml">predicting learner levels for online exercises of hebrew </title>
<section> intra-token net cost 1.875 0.000.  </section>
<citcontext>
<prevsection>
<prevsent>6.1 details of the experiments.
</prevsent>
<prevsent>we use timbl (daelemans et al, 2010; daelemans et al, 1999), memory-based learner (mbl), for both phases.
</prevsent>
</prevsection>
<citsent citstr=" H01-1052 ">
we use timbl because mbl has been shown to work well with small datasets (banko and brill, 2001); <papid> H01-1052 </papid>allows for the use of both text-based and numeric features; and does not suffer from fragmented class space.</citsent>
<aftsection>
<nextsent>we mostly use the default settings of timblthe ib1 learning algorithm and overlap comparison metric between instance sand experiment with different values of k. for prediction of phenomenon level (phase 1) and learner level (phase 2), the system is trained on data from placement exams previously collected in hebrew language program, as described in sec.
</nextsent>
<nextsent>2.
</nextsent>
<nextsent>with only 38 learners, we use leave-one-out testing, training on the data from the 37 other learners in order to run model on each learners sentences.
</nextsent>
<nextsent>all of phase 1 is completed (i.e., automatically analyzed) before training the phase 2 models.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5048">
<title id=" W12-1003.xml">bad an assistant tool for making verses in basque </title>
<section> the bad tool.  </section>
<citcontext>
<prevsection>
<prevsent>3.2 structure checking.
</prevsent>
<prevsent>after writing the verse, the system can evaluate if it is technically correct, i.e. if the overall structure is correct and if each line in the form abides by the required syllable count and rhyming scheme.
</prevsent>
</prevsection>
<citsent citstr=" E09-2008 ">
the syllable counter is implemented using the foma software (hulden, 2009), <papid> E09-2008 </papid>and the implementation (hulden, 2006) can be found on the homepage of 14 figure 1: verse written in the bad web application.</citsent>
<aftsection>
<nextsent>foma.3 separately, we have also developed rhyme checker, which extracts special patterns in the lines that must rhyme and checks their conformity.
</nextsent>
<nextsent>these patterns are extracted using foma (see section 3.4) after which some phonological rules are applied.
</nextsent>
<nextsent>for example, an example rule era ? {era, eda, ega, eba}, models the fact that any word ending in era, for example, etxera, will rhyme with all words that end in era, eda, eba or ega.
</nextsent>
<nextsent>these rhyming patterns have been extracted according to the phonological laws described in (amuriza, 1981).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5049">
<title id=" W12-1513.xml">extractive email thread summarization can we do better than he said she said </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>high traffic mailing lists pose challenge to an extended audience laterally interested on the subject matter but unable or unwilling to follow them on everyday minutiae.
</prevsent>
<prevsent>in this context, high-level summaries are of great help and in certain cases there are people or companies that step into the plate to provide such service.
</prevsent>
</prevsection>
<citsent citstr=" W01-0719 ">
in recent years, there has been an ever increasing interest (muresan et al, 2001; <papid> W01-0719 </papid>nenkova and bagga, 2003; newman and blitzer, 2003; rambow et al, 2004; <papid> N04-4027 </papid>wan and mckeown, 2004; <papid> C04-1079 </papid>mckeown et al, 2007; ulrich, 2008; wang et al., 2009) in automating this task, with many works focusing on selectively extracting quotes from key e-mail exchanges.</citsent>
<aftsection>
<nextsent>in this work, we focus on finding appropriate and varied ways to cite selected quotes from the email threads.
</nextsent>
<nextsent>a seemingly simple task, this problemtouches: speech act detection (searle, 1975) (ques tion vs. announcement vs. reply), opinion mining (pang and lee, 2008) (complained vs. thanked) and citation polarity analysis (teufel, 1999): (agreed vs. disagreed vs. added).
</nextsent>
<nextsent>at this stage, we will show training data we have acquired for the task and set of manually assembled verb clusters that show the richness of the problem.
</nextsent>
<nextsent>moreover, we have used these clusters to highlight trade-off of risk taking?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5050">
<title id=" W12-1513.xml">extractive email thread summarization can we do better than he said she said </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>high traffic mailing lists pose challenge to an extended audience laterally interested on the subject matter but unable or unwilling to follow them on everyday minutiae.
</prevsent>
<prevsent>in this context, high-level summaries are of great help and in certain cases there are people or companies that step into the plate to provide such service.
</prevsent>
</prevsection>
<citsent citstr=" N04-4027 ">
in recent years, there has been an ever increasing interest (muresan et al, 2001; <papid> W01-0719 </papid>nenkova and bagga, 2003; newman and blitzer, 2003; rambow et al, 2004; <papid> N04-4027 </papid>wan and mckeown, 2004; <papid> C04-1079 </papid>mckeown et al, 2007; ulrich, 2008; wang et al., 2009) in automating this task, with many works focusing on selectively extracting quotes from key e-mail exchanges.</citsent>
<aftsection>
<nextsent>in this work, we focus on finding appropriate and varied ways to cite selected quotes from the email threads.
</nextsent>
<nextsent>a seemingly simple task, this problemtouches: speech act detection (searle, 1975) (ques tion vs. announcement vs. reply), opinion mining (pang and lee, 2008) (complained vs. thanked) and citation polarity analysis (teufel, 1999): (agreed vs. disagreed vs. added).
</nextsent>
<nextsent>at this stage, we will show training data we have acquired for the task and set of manually assembled verb clusters that show the richness of the problem.
</nextsent>
<nextsent>moreover, we have used these clusters to highlight trade-off of risk taking?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5051">
<title id=" W12-1513.xml">extractive email thread summarization can we do better than he said she said </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>high traffic mailing lists pose challenge to an extended audience laterally interested on the subject matter but unable or unwilling to follow them on everyday minutiae.
</prevsent>
<prevsent>in this context, high-level summaries are of great help and in certain cases there are people or companies that step into the plate to provide such service.
</prevsent>
</prevsection>
<citsent citstr=" C04-1079 ">
in recent years, there has been an ever increasing interest (muresan et al, 2001; <papid> W01-0719 </papid>nenkova and bagga, 2003; newman and blitzer, 2003; rambow et al, 2004; <papid> N04-4027 </papid>wan and mckeown, 2004; <papid> C04-1079 </papid>mckeown et al, 2007; ulrich, 2008; wang et al., 2009) in automating this task, with many works focusing on selectively extracting quotes from key e-mail exchanges.</citsent>
<aftsection>
<nextsent>in this work, we focus on finding appropriate and varied ways to cite selected quotes from the email threads.
</nextsent>
<nextsent>a seemingly simple task, this problemtouches: speech act detection (searle, 1975) (ques tion vs. announcement vs. reply), opinion mining (pang and lee, 2008) (complained vs. thanked) and citation polarity analysis (teufel, 1999): (agreed vs. disagreed vs. added).
</nextsent>
<nextsent>at this stage, we will show training data we have acquired for the task and set of manually assembled verb clusters that show the richness of the problem.
</nextsent>
<nextsent>moreover, we have used these clusters to highlight trade-off of risk taking?
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5055">
<title id=" W12-1513.xml">extractive email thread summarization can we do better than he said she said </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>since the seminal work by muresan et al (2001), <papid> W01-0719 </papid>email summarization and in particular email thread summarization has spanned full dissertations (ulrich, 2008).</prevsent>
<prevsent>existing resources for email summarization (ulrich et al, 2008), however, do not emphasize explicitly the type of quotes being used.understandingly, most of the work has been devoted to selecting the particular words, sentences or 3not unlike this discussion.paragraphs to extract from the original e-mails.</prevsent>
</prevsection>
<citsent citstr=" W04-3240 ">
either by distilling terms or topics (muresan et al,2001; <papid> W01-0719 </papid>newman and blitzer, 2003) or finding representative example (nenkova and bagga, 2003; ram bow et al, 2004; <papid> N04-4027 </papid>wang et al, 2009).the issue of choosing how to introduce the extracted text has only been studied in the context of speech act detection (cohen et al, 2004; <papid> W04-3240 </papid>wan and mckeown, 2004) <papid> C04-1079 </papid>within emails or within threaded discussions (feng et al, 2006), <papid> N06-1027 </papid>which is limited to questions, replies and the like (a very important case which covers 2/3 of our available data).</citsent>
<aftsection>
<nextsent>the problem of detecting question / answer pairs in e-mails is by far the one who has received the most attention in the field (bickel and scheffer, 2004; shrestha and mckeown, 2004; <papid> C04-1128 </papid>mckeown et al, 2007).</nextsent>
<nextsent>the verbs in each of the classes in table 1 havea near-synonym relation:4 even though recom mended?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5057">
<title id=" W12-1513.xml">extractive email thread summarization can we do better than he said she said </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>since the seminal work by muresan et al (2001), <papid> W01-0719 </papid>email summarization and in particular email thread summarization has spanned full dissertations (ulrich, 2008).</prevsent>
<prevsent>existing resources for email summarization (ulrich et al, 2008), however, do not emphasize explicitly the type of quotes being used.understandingly, most of the work has been devoted to selecting the particular words, sentences or 3not unlike this discussion.paragraphs to extract from the original e-mails.</prevsent>
</prevsection>
<citsent citstr=" N06-1027 ">
either by distilling terms or topics (muresan et al,2001; <papid> W01-0719 </papid>newman and blitzer, 2003) or finding representative example (nenkova and bagga, 2003; ram bow et al, 2004; <papid> N04-4027 </papid>wang et al, 2009).the issue of choosing how to introduce the extracted text has only been studied in the context of speech act detection (cohen et al, 2004; <papid> W04-3240 </papid>wan and mckeown, 2004) <papid> C04-1079 </papid>within emails or within threaded discussions (feng et al, 2006), <papid> N06-1027 </papid>which is limited to questions, replies and the like (a very important case which covers 2/3 of our available data).</citsent>
<aftsection>
<nextsent>the problem of detecting question / answer pairs in e-mails is by far the one who has received the most attention in the field (bickel and scheffer, 2004; shrestha and mckeown, 2004; <papid> C04-1128 </papid>mckeown et al, 2007).</nextsent>
<nextsent>the verbs in each of the classes in table 1 havea near-synonym relation:4 even though recom mended?</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5058">
<title id=" W12-1513.xml">extractive email thread summarization can we do better than he said she said </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>existing resources for email summarization (ulrich et al, 2008), however, do not emphasize explicitly the type of quotes being used.understandingly, most of the work has been devoted to selecting the particular words, sentences or 3not unlike this discussion.paragraphs to extract from the original e-mails.
</prevsent>
<prevsent>either by distilling terms or topics (muresan et al,2001; <papid> W01-0719 </papid>newman and blitzer, 2003) or finding representative example (nenkova and bagga, 2003; ram bow et al, 2004; <papid> N04-4027 </papid>wang et al, 2009).the issue of choosing how to introduce the extracted text has only been studied in the context of speech act detection (cohen et al, 2004; <papid> W04-3240 </papid>wan and mckeown, 2004) <papid> C04-1079 </papid>within emails or within threaded discussions (feng et al, 2006), <papid> N06-1027 </papid>which is limited to questions, replies and the like (a very important case which covers 2/3 of our available data).</prevsent>
</prevsection>
<citsent citstr=" C04-1128 ">
the problem of detecting question / answer pairs in e-mails is by far the one who has received the most attention in the field (bickel and scheffer, 2004; shrestha and mckeown, 2004; <papid> C04-1128 </papid>mckeown et al, 2007).</citsent>
<aftsection>
<nextsent>the verbs in each of the classes in table 1 havea near-synonym relation:4 even though recom mended?
</nextsent>
<nextsent>and urged?
</nextsent>
<nextsent>share most of their meaning, the differences in style, color and subtle meaning need to be further elucidated for successful lexicalchoice.
</nextsent>
<nextsent>this topic has started to be explored in detail recently (edmonds and hirst, 2002).<papid> J02-2001 </papid></nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5059">
<title id=" W12-1513.xml">extractive email thread summarization can we do better than he said she said </title>
<section> related work.  </section>
<citcontext>
<prevsection>
<prevsent>and urged?
</prevsent>
<prevsent>share most of their meaning, the differences in style, color and subtle meaning need to be further elucidated for successful lexicalchoice.
</prevsent>
</prevsection>
<citsent citstr=" J02-2001 ">
this topic has started to be explored in detail recently (edmonds and hirst, 2002).<papid> J02-2001 </papid></citsent>
<aftsection>
<nextsent>our work falls in the larger field of summarization by using nlg means, discipline that has received significant attention of late (belz et al, 2009).
</nextsent>
<nextsent>in this paper, we have brought to the attention of nlg practitioners the rich resource embodied in five years of kernel traffic newsletters.
</nextsent>
<nextsent>we had also highlighted the richness of the problem of lexical choice for verbs introducing quotations in extractive email summarization.
</nextsent>
<nextsent>moreover, we contributed 39 clusters manually assembled from naturally occurring verbs extracted from 4000+ high quality summaries.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5060">
<title id=" W12-1508.xml">perceptions of alignment and personality in generated dialogue </title>
<section> generation method.  </section>
<citcontext>
<prevsection>
<prevsent>dialogues are composed by crag 2, java program that provides framework for generating dialogues between two computer characters discus singa movie.
</prevsent>
<prevsent>for more details of this system, see brockmann (2009).
</prevsent>
</prevsection>
<citsent citstr=" W06-1403 ">
within crag 2, linguistic personality and alignment are modelled using the opennlp 41 ccg library (openccg) natural language realiser (white, 2006<papid> W06-1403 </papid>b).</citsent>
<aftsection>
<nextsent>the realiser consults grammar adapted to the movie review domain to allow the generation of utterances about the following top ics: action scenes, characters, dialogue, film, music, plot or special effects.
</nextsent>
<nextsent>the realiser also has access to set of n-gram language models, used to compute probability scores of word sequences.
</nextsent>
<nextsent>the general conversational language model (lm) is based on data from the switchboard corpus and small corpus of movie reviews.
</nextsent>
<nextsent>the general lm is used for fallback probabilities, and is integrated with the personality and alignment language models (described below) using linear interpolation.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5062">
<title id=" W12-1508.xml">perceptions of alignment and personality in generated dialogue </title>
<section> generation method.  </section>
<citcontext>
<prevsection>
<prevsent>this process continues until there are no topics left on the agenda of the current speaker.
</prevsent>
<prevsent>the system creates simple xml representation of the characters utterance, using the specified topic and polarity.
</prevsent>
</prevsection>
<citsent citstr=" W04-0601 ">
following the method described in foster and white (2004), <papid> W04-0601 </papid>the basic utterance specification is transformed, usingstylesheets written in the extensible style sheet language transformations (xslt) language, into anopenccg logical form.</citsent>
<aftsection>
<nextsent>we make use of the facility for defining optional and alternative inputs (white, 2006<papid> W06-1403 </papid>a) and underspecified semantics to mildly over generate candidate utterances.</nextsent>
<nextsent>optional interjections (i mean, you know, sort of ) and conversational markers (right, but, and, well)are added where appropriate given the discourse his tory.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5065">
<title id=" W12-0706.xml">robust induction of partsofspeech in child directed language by co clustering of words and contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>we show that the categorization performance of the algorithm is comparable with the co clustering algorithm of leibbrandt and powers (2008), but out-performs that algorithm in robustly pruning less-useful clusters and merging them into categories strongly corresponding to the three main open classes of english.
</prevsent>
<prevsent>the problem of unsupervised part-of-speech induction has received considerable attention in computational linguistics (for recent comparison of several influential models, see christodoulopoulos, goldwater &amp; steedman, 2010).
</prevsent>
</prevsection>
<citsent citstr=" P07-1094 ">
a common approach is to estimate the parameters of generative model given the natural language data, with the model usually variant of hidden markov model (e.g. goldwater &amp; griffiths, 2007; <papid> P07-1094 </papid>berg-kirkpatrick, ct?, de nero &amp; klein, 2010; moon, erk &amp; baldridge, 2010).</citsent>
<aftsection>
<nextsent>these models are often evaluated on corpora of formal, written english, such as the penn treebank, rather than on natural, spoken language, and typically the aim of these studies is to improve the state-of-the-art of pos induction using various techniques from machine learning, with an implicit focus on devising techniques that can be used in practical applications.
</nextsent>
<nextsent>in the current paper, on the other hand, our focus is on part-of-speech induction mechanisms that children might use when learning their first language.
</nextsent>
<nextsent>hence, we are interested in models that are motivated by psychological considerations, rather than by more abstract mathematical or statistical grounding.
</nextsent>
<nextsent>in language acquisition research, typical approach to part-of-speech induction is to make use of clustering.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5066">
<title id=" W12-0706.xml">robust induction of partsofspeech in child directed language by co clustering of words and contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>1.1 clustering and co-clustering approaches.
</prevsent>
<prevsent>to part-of-speech induction in language acquisition research single-mode clustering approaches clustering algorithms operate on two dimensional matrix where the rows and columns in this context represent words and the linguistic contexts in which they appear, taken from corpus of natural language, and the cells of the matrix contain frequency counts of how often word occurs in particular context.
</prevsent>
</prevsection>
<citsent citstr=" W00-0717 ">
it has often been proposed that children might make use of information about the contextual distribution of usage of words to induce the parts-of-speech of their native language (e.g. marat sos &amp; chalk ley, 1980), and work by, e.g., redington, chater &amp; finch (1998) and clark (2000), <papid> W00-0717 </papid>showed that parts-of-speech can indeed be induced by 44 clustering together words that are used in similar contexts in corpus.</citsent>
<aftsection>
<nextsent>clustering word types together does not take into account the fact that the part-of-speech of word type may change depending on the context in which it is used.
</nextsent>
<nextsent>one of the most influential models in part-of-speech induction in language acquisition, the frequent frames model of mintz (2003), addresses this issue by forming clusters of the contextual frames in which words are used, rather than the words themselves.
</nextsent>
<nextsent>the idea is that the contexts define the part-of-speech, rather than the words themselves.
</nextsent>
<nextsent>this model attains high, but not perfect results in part-of-speech tagging for english child-directed speech; part of the reason is that even frames are sometimes ambiguous in the parts-of-speech that they can accommodate, and erkelens (2008) has shown that this problem is more pronounced when the frequent frames approach is applied to dutch material.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5067">
<title id=" W12-0706.xml">robust induction of partsofspeech in child directed language by co clustering of words and contexts </title>
<section> introduction </section>
<citcontext>
<prevsection>
<prevsent>even apart from its practical utility in part-of speech induction, co-clustering is broadly compatible with psychological outlook that conceives of part-of-speech development in terms of associative learning (see e.g. shanks, 1995).
</prevsent>
<prevsent>under this view, parts-of-speech are mental categories that are formed by repeated exposure to words used in context, in combination with whatever semantic constr ual the language-learning child places on the utterances she hears.
</prevsent>
</prevsection>
<citsent citstr=" C04-1052 ">
only few studies have applied co-clustering to part-of-speech induction with child-directed language (but see freitag, 2004, <papid> C04-1052 </papid>for part-ofspeech induction with co-clustering on adult directed language in the penn treebank).</citsent>
<aftsection>
<nextsent>the pioneering work in this regard was the emile system of adriaans and colleagues (adriaans, 1992), which formed co-clusters of word-context combinations as step in the process of inducing 45 rules for categorial grammar.
</nextsent>
<nextsent>while the grammars formed in this way perform well, emile typically produces large, overlapping categories which do not correspond to the parts of-speech of english (adriaans, 1999).
</nextsent>
<nextsent>hence, it is difficult to evaluate the accuracy of emiles part-of-speech tagging against gold standard.
</nextsent>
<nextsent>leibbrandt &amp; powers (2008) applied co clustering to corpus of english child-directed speech, yielding accuracy comparable to that obtained by the frequent frames model of mintz (2003).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5068">
<title id=" W12-0706.xml">robust induction of partsofspeech in child directed language by co clustering of words and contexts </title>
<section> evaluation of the algorithms.  </section>
<citcontext>
<prevsection>
<prevsent>results are reported in terms of standard measures of precision, recall and f-score, with random baselines in parentheses.
</prevsent>
<prevsent>these measures were calculated, as is customary in unsupervised categorization, by pair counting approach that constructs confusion matrix based on whether pairs of elements are assigned to the same category in the gold-standard, and also in the clustering model (see e.g. mintz, newport &amp; bever, 2002).
</prevsent>
</prevsection>
<citsent citstr=" D07-1043 ">
because of several well-known shortcomings of precision and recall (e.g. powers, 2003; rosenberg &amp; hirschberg, 2007), <papid> D07-1043 </papid>we also report the informed ness measure (powers, 2003), which corresponds to the probability that the predictions made by the algorithm are informed, in the sense of making correct use of information.</citsent>
<aftsection>
<nextsent>for 22 contingency table with the symbols a, b, and respectively indicating the number of true positives, false positives, false negatives and true negatives, informed ness is given by ? = ? ?
</nextsent>
<nextsent>50 informed ness can thus be expressed as recall for particular cluster, discounted by the proportion of all non-category items that occur in that cluster.
</nextsent>
<nextsent>informed ness is equivalent to the well-known delta-p formula expressing association strength in human associative learning (e.g. shanks, 1995).
</nextsent>
<nextsent>for supervised classification problem, with table of arbitrary dimensions mm, informed ness is calculated for the 22 contingency table of each category in turn, and the informed ness values for all categories are combined in weighted sum, where the weight for each category is the proportion of word tokens assigned to that category by the algorithm (i.e. the algorithms bias to assign instances to the category).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5069">
<title id=" W11-2144.xml">the uppsalafbk systems at wmt 2011 </title>
<section> english to french.  </section>
<citcontext>
<prevsection>


</prevsection>
<citsent citstr=" P07-2045 ">
our submission to the english-french task was phrase-based statistical machine translation based on the moses decoder (koehn et al, 2007).<papid> P07-2045 </papid></citsent>
<aftsection>
<nextsent>phrase tables were separately trained on europarl, news commentary and un data and then linearly interpolated with uniform weights.
</nextsent>
<nextsent>for language modelling, we used 5-gram models trained with theirstlm toolkit (federico et al, 2008) on the monolingual news corpus and parts of the english-french 109 corpus.
</nextsent>
<nextsent>more unusual features of our system included special component to handle pronominal anaphora and the hierarchical lexical reordering model by galley and manning (2008).<papid> D08-1089 </papid></nextsent>
<nextsent>selected features of our system will be discussed indepth in the following sections.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5070">
<title id=" W11-2144.xml">the uppsalafbk systems at wmt 2011 </title>
<section> english to french.  </section>
<citcontext>
<prevsection>
<prevsent>phrase tables were separately trained on europarl, news commentary and un data and then linearly interpolated with uniform weights.
</prevsent>
<prevsent>for language modelling, we used 5-gram models trained with theirstlm toolkit (federico et al, 2008) on the monolingual news corpus and parts of the english-french 109 corpus.
</prevsent>
</prevsection>
<citsent citstr=" D08-1089 ">
more unusual features of our system included special component to handle pronominal anaphora and the hierarchical lexical reordering model by galley and manning (2008).<papid> D08-1089 </papid></citsent>
<aftsection>
<nextsent>selected features of our system will be discussed indepth in the following sections.
</nextsent>
<nextsent>1.1 handling pronominal anaphora.
</nextsent>
<nextsent>pronominal anaphora is the use of pronominal expressions to refer to something previously mentioned in the discourse?
</nextsent>
<nextsent>(strube, 2006).
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5071">
<title id=" W11-2144.xml">the uppsalafbk systems at wmt 2011 </title>
<section> english to french.  </section>
<citcontext>
<prevsection>
<prevsent>we therefore added word-dependencymodel (hardmeier and federico, 2010) to our system to handle anaphora explicitly.
</prevsent>
<prevsent>our processing of anaphoric pronouns follows the procedure outlined by hardmeier and federico(2010).
</prevsent>
</prevsection>
<citsent citstr=" S10-1021 ">
we use the open-source coreference resolution system bart (broscheit et al, 2010) <papid> S10-1021 </papid>to link pronouns to their antecedents in the text.</citsent>
<aftsection>
<nextsent>coreference links are handled differently depending on whether or not they cross sentence boundaries.
</nextsent>
<nextsent>if coreference link points to previous sentence, we process the sentence containing the antecedent with the smt system and look up the translation of the antecedent in the translated output.
</nextsent>
<nextsent>if the coreference link is sentence-internal, the translation lookup is done dynamically by the decoder during search.
</nextsent>
<nextsent>in either case, the word-dependency model adds feature function to the decoder score representing the probability of particular pronoun choice given the translation of the antecedent.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5073">
<title id=" W11-2144.xml">the uppsalafbk systems at wmt 2011 </title>
<section> haitian creole to english.  </section>
<citcontext>
<prevsection>
<prevsent>we used standard 5-gram models with witten-bell discounting and backoff interpolation for all language models.
</prevsent>
<prevsent>for the translation model we applied standard techniques and settings for phrase extraction and score estimations.
</prevsent>
</prevsection>
<citsent citstr=" J03-1002 ">
however, we applied two different systems for word alignment: one is the standard giza++ toolbox implementing the ibm alignment models (och and ney, 2003) <papid> J03-1002 </papid>and extensions and the other is based on transduction grammars which will briefly be introduced in the next section.</citsent>
<aftsection>
<nextsent>2.1.1 alignment with plitgsby making the assumption that the parallel corpus constitutes linear transduction (saers, 2011)2 we can induce grammar that is the most likely to have generated the observed corpus.
</nextsent>
<nextsent>the grammar induced will generate parse forest for each sentence pair in the corpus, and each parse tree in that forest will correspond to an alignment between the two sentences.
</nextsent>
<nextsent>following saers et al (2010), <papid> N10-1050 </papid>the alignment corresponding to the best parse can be extracted and used instead of other word alignment approaches such as giza++.</nextsent>
<nextsent>there are several grammar types that generate linear transductions, and inthis work, stochastic bracketing preterminalized linear inversion transduction grammars (plitg) were used (saers and wu, 2011).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5074">
<title id=" W11-2144.xml">the uppsalafbk systems at wmt 2011 </title>
<section> haitian creole to english.  </section>
<citcontext>
<prevsection>
<prevsent>2.1.1 alignment with plitgsby making the assumption that the parallel corpus constitutes linear transduction (saers, 2011)2 we can induce grammar that is the most likely to have generated the observed corpus.
</prevsent>
<prevsent>the grammar induced will generate parse forest for each sentence pair in the corpus, and each parse tree in that forest will correspond to an alignment between the two sentences.
</prevsent>
</prevsection>
<citsent citstr=" N10-1050 ">
following saers et al (2010), <papid> N10-1050 </papid>the alignment corresponding to the best parse can be extracted and used instead of other word alignment approaches such as giza++.</citsent>
<aftsection>
<nextsent>there are several grammar types that generate linear transductions, and inthis work, stochastic bracketing preterminalized linear inversion transduction grammars (plitg) were used (saers and wu, 2011).
</nextsent>
<nextsent>since we were mainly interested in the word alignments, we did not induce phrasal grammars.
</nextsent>
<nextsent>although alignments from plitgs may not reach the same level of translation quality as giza++, they make different mistakes, so both complement2a transduction is set of pairs of strings, and thus represents relation between two languages.
</nextsent>
<nextsent>each other.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5075">
<title id=" W11-2144.xml">the uppsalafbk systems at wmt 2011 </title>
<section> haitian creole to english.  </section>
<citcontext>
<prevsection>
<prevsent>we used moses and its syntax-mode for our experiments with hierarchical phrase-based and syntax augmented models.
</prevsent>
<prevsent>our main interest was to investigate the influence of monolingual parsing on the translation performance.
</prevsent>
</prevsection>
<citsent citstr=" J93-2004 ">
in particular, we tried to integrate english dependency parses created by malt parser (nivre et al, 2007) trained on the wall street journal section of the penn treebank (mar cus et al, 1993) <papid> J93-2004 </papid>extended with about 4000 questions 3we actually swapped the development set and the test set by mistake.</citsent>
<aftsection>
<nextsent>but, of course, we never mixed development and test data in any result reported.
</nextsent>
<nextsent>375 from the question bank (judge et al, 2006).<papid> P06-1063 </papid></nextsent>
<nextsent>the conversion to dependency trees was done using the stanford parser (de marneffe et al, 2006).</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5076">
<title id=" W11-2144.xml">the uppsalafbk systems at wmt 2011 </title>
<section> haitian creole to english.  </section>
<citcontext>
<prevsection>
<prevsent>in particular, we tried to integrate english dependency parses created by malt parser (nivre et al, 2007) trained on the wall street journal section of the penn treebank (mar cus et al, 1993) <papid> J93-2004 </papid>extended with about 4000 questions 3we actually swapped the development set and the test set by mistake.</prevsent>
<prevsent>but, of course, we never mixed development and test data in any result reported.</prevsent>
</prevsection>
<citsent citstr=" P06-1063 ">
375 from the question bank (judge et al, 2006).<papid> P06-1063 </papid></citsent>
<aftsection>
<nextsent>the conversion to dependency trees was done using the stanford parser (de marneffe et al, 2006).
</nextsent>
<nextsent>again, we ran both translation directions to test our settings in more than just one task.
</nextsent>
<nextsent>interesting here is also the question whether there are significant differences when integrating monolingual parses on the source or on the target side.
</nextsent>
<nextsent>the motivation for applying dependency parsing in our experiments is to use the specific information carried by dependency relations.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5077">
<title id=" W11-2144.xml">the uppsalafbk systems at wmt 2011 </title>
<section> haitian creole to english.  </section>
<citcontext>
<prevsection>
<prevsent>this can be done in left-branching and in right-branchingmode.
</prevsent>
<prevsent>we used combination of both in the settings denoted as binarised.
</prevsent>
</prevsection>
<citsent citstr=" C08-1144 ">
the other relaxation algorithms are based on methods proposed for syntax augmented machine translation (zollmann et al, 2008).<papid> C08-1144 </papid></citsent>
<aftsection>
<nextsent>we used two of them: samt1 combines pairsof neighbouring children nodes into combined complex nodes and creates additional complex nodes of all children nodes except the first child and similar complex nodes for all but the last child.
</nextsent>
<nextsent>samt2 combines any pair of neighbouring nodes even if they arenot children of the same parent.
</nextsent>
<nextsent>all of these relaxation algorithms lead to increased rule sets (table 4).
</nextsent>
<nextsent>in terms of translation performance there seems to be strong correlation between rule table size and translation quality as measured by bleu.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5078">
<title id=" W11-2018.xml">detecting levels of interest from spoken dialog with multi stream prediction feedback and similarity based hierarchical fusion learning </title>
<section> our system.  </section>
<citcontext>
<prevsection>
<prevsent>the overall idf score of words important to identifying the loi of an utterance will thus be boosted, as the denominator of the idf metric decreases compared to the standard tfidf.
</prevsent>
<prevsent>discriminative tfidf can be viewed as generalized version of delta tfidf (martineau and finin, 2009) that can be used in various regression settings.
</prevsent>
</prevsection>
<citsent citstr=" C10-1129 ">
wang and mckeown (2010) <papid> C10-1129 </papid>show that adding part-of-speech (pos) information to text can be helpful in similar classification tasks.</citsent>
<aftsection>
<nextsent>so we have also used the stanford pos tagger (toutanova and manning, 2000) <papid> W00-1308 </papid>to tag these transcripts before calculating the discriminative tfidf score.</nextsent>
<nextsent>lexical affect scoring whissells dictionary of affect in language(dal) (whissell, 1989) attempts to quantify emotional language by asking raters to judge 8742 words collected from various sources including college essays, interviews, and teenagers descriptions of their own emotional state.</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5079">
<title id=" W11-2018.xml">detecting levels of interest from spoken dialog with multi stream prediction feedback and similarity based hierarchical fusion learning </title>
<section> our system.  </section>
<citcontext>
<prevsection>
<prevsent>discriminative tfidf can be viewed as generalized version of delta tfidf (martineau and finin, 2009) that can be used in various regression settings.
</prevsent>
<prevsent>wang and mckeown (2010) <papid> C10-1129 </papid>show that adding part-of-speech (pos) information to text can be helpful in similar classification tasks.</prevsent>
</prevsection>
<citsent citstr=" W00-1308 ">
so we have also used the stanford pos tagger (toutanova and manning, 2000) <papid> W00-1308 </papid>to tag these transcripts before calculating the discriminative tfidf score.</citsent>
<aftsection>
<nextsent>lexical affect scoring whissells dictionary of affect in language(dal) (whissell, 1989) attempts to quantify emotional language by asking raters to judge 8742 words collected from various sources including college essays, interviews, and teenagers descriptions of their own emotional state.
</nextsent>
<nextsent>its pleasant ness (ee) score indicates the negative or positive valence of word,rated on scale from 1 to 3.
</nextsent>
<nextsent>for example, abandon?
</nextsent>
<nextsent>scores 1.0, implying fairly low level of pleas antness.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5080">
<title id=" W11-2018.xml">detecting levels of interest from spoken dialog with multi stream prediction feedback and similarity based hierarchical fusion learning </title>
<section> our system.  </section>
<citcontext>
<prevsection>
<prevsent>for example, abandon?
</prevsent>
<prevsent>scores 1.0, implying fairly low level of pleas antness.
</prevsent>
</prevsection>
<citsent citstr=" E09-1004 ">
a previous study (agarwal et al, 2009) <papid> E09-1004 </papid>notes that one of the advantages of this dictionary is that it has different scores for various forms of aroot word.</citsent>
<aftsection>
<nextsent>for example, the words affect?
</nextsent>
<nextsent>and af fection?
</nextsent>
<nextsent>have very different meanings; if they were given the same score, the lexical affect quantification might not be discriminative.
</nextsent>
<nextsent>to calculate an utterances lexical affect score, we first remove the stop words and then sum up 4 the ee score of each word in the utterance.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
<cited id="ZI5081">
<title id=" W11-2018.xml">detecting levels of interest from spoken dialog with multi stream prediction feedback and similarity based hierarchical fusion learning </title>
<section> our system.  </section>
<citcontext>
<prevsection>
<prevsent>prosodic event features to examine the contribution of higher-level prosodic events, we have also experimented withautobi (rosenberg, 2010) to automatically detect pitch accents, word boundaries, intermediate phrase boundaries, and into national boundaries in utterances.
</prevsent>
<prevsent>autobi requires annotated word boundary information; since we do not havehand-annotated boundaries, we use the penn pho netics lab forced aligner (yuan and liberman, 2008) to align each utterance with its transcription.
</prevsent>
</prevsection>
<citsent citstr=" P96-1038 ">
we use autobis models, which were trained on the spontaneous speech boston directions corpus (bdc) (hirschberg and nakatani, 1996), <papid> P96-1038 </papid>to identify prosodic events in our corpus.</citsent>
<aftsection>
<nextsent>3.3 fusion learning approaches.
</nextsent>
<nextsent>assuming that our various lexical, acoustic and prosodic feature streams are informative to some extent when tested separately, we want to combine information from the streams in different domains to improve prediction.
</nextsent>
<nextsent>we experimented with several approaches, including bag-of-features, sum rule combination, hierarchical fusion, and new approach.
</nextsent>
<nextsent>we present here results of each on our loi prediction task.
</nextsent>
</aftsection>
</citcontext>
<tag> </tag>
</cited>
</paper>