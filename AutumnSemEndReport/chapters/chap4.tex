\chapter{Results \& Discussion}
\section{Results}

The following table summarizes results for all the experiments performed. For a detailed description of experiments, please refer to Chapter 3. The initial experiments on combining features were performed without feature scaling ( refer to \ref{scaling} for details). \ref{result1} shows the results of the experiments

\begin{itemize}
\item \texttt{Mean()} is calculated as described in \ref{mean}
\item \texttt{Max()} is calculated as described in \ref{max}
\item \texttt{Min()} is calculated as described in \ref{min}
\item The value of $ \alpha $ is the threshold which is discussed in \ref{thres}
\end{itemize} 

The list of features used in the experiment are as follows :

\begin{table}[!htbp]
\centering
\begin{tabular}{l|l|l}
\hline
\textbf{Index} & \textbf{Feature description}  & \textbf{Pyramid Score} \\ \hline
1              & Unigrams                      & 0.6658455015           \\ \hline
2              & Bigrams                       & 0.6212465025           \\ \hline
3              & No of citations               & 0.5800021814           \\ \hline
4              & UG of POS Tags                & 0.6512963561           \\ \hline
5              & BG of POS Tags                & 0.5258799947           \\ \hline
6              & Bibilographic coupling        & 0.5758991342           \\ \hline
7              & Co-citation matrix similarity & 0.4668755464           \\ \hline
8              & Title similarity              & 0.5743987379           \\ \hline
9              & Author similarity             & 0.5476835667           \\ \hline
10             & Time similarity               & 0.5583852299           \\ \hline
\end{tabular}
\caption{Feature indexes and pryramid scores for individual features}
\label{my-label}

\end{table}



\begin{table}[!htbp]
\centering
\begin{tabular}{l|l}
\textbf{Method description}                                  & \textbf{Pyramid score}                     \\ \hline
\multicolumn{1}{l|}{Mean({[}1,2,3,4,6{]}) (top 5)}          & \multicolumn{1}{l}{0.6173276955}          \\ \hline
\multicolumn{1}{l|}{Mean({[}1,4{]}) (top 2)}                & \multicolumn{1}{l}{0.6155651665}          \\ \hline
\multicolumn{1}{l|}{Mean({[}1:10{]})}                       & \multicolumn{1}{l}{0.6120720413}          \\ \hline
\multicolumn{1}{l|}{Mean ({[}1, 3, 4{]}) (top 3)}           & \multicolumn{1}{l}{0.641261796}           \\ \hline
\multicolumn{1}{l|}{Max {[}1,4,8{]}}                        & \multicolumn{1}{l}{0.5846927132}          \\ \hline
\multicolumn{1}{l|}{Max ({[}1,4,8{]}) ; $ \alpha $ = 0.8}   & \multicolumn{1}{l}{0.5658356889}          \\ \hline
\multicolumn{1}{l|}{Min ({[}1,4,8{]});  $ \alpha $ = 0.9}   & \multicolumn{1}{l}{0.5884321604}          \\ \hline
\multicolumn{1}{l|}{Min ({[}1,4,8{]}); $ \alpha $ = 0.8}    & \multicolumn{1}{l}{\textbf{0.6706331335}} \\ \hline
\multicolumn{1}{l|}{Min ({[}1,4,8{]}); $ \alpha $ = 0.95}   & \multicolumn{1}{l}{\textbf{0.6934690128}} \\ \hline
\multicolumn{1}{l|}{Min ({[}1,4,8{]}); $ \alpha $ = 0.85}   & \multicolumn{1}{l}{\textbf{0.7187605304}} \\ \hline
\multicolumn{1}{l|}{Min ({[}1,4,8{]}); $ \alpha $ = 0.9}    & \multicolumn{1}{l}{\textbf{0.7105636008}} \\ \hline
\multicolumn{1}{l|}{Min ({[}1,2,4,8{]}); $ \alpha $ = 0.85} & \multicolumn{1}{l}{0.6193834661}          \\ \hline
\multicolumn{1}{l|}{Min({[}1,2,4,8{]}); $ \alpha $ = 0.9}   & \multicolumn{1}{l}{0.5856727122}          \\ \hline
\multicolumn{1}{l|}{Min ({[}1,4,6,8{]}); $ \alpha $ = 0.85} & \multicolumn{1}{l}{\textbf{0.7228621087}} \\ \hline
\end{tabular}
\caption{Evaluation scores for feature combinations without feature scaling }
\label{result1}

\end{table}
\pagebreak
After we implement feature scaling we obtain the results as noted in \ref{result2}. The values in bold indicate that the corresponding experiment performed better than the baseline methods. The combination of [1,4,6,8] was chosen to keeping diversity of type of features and best individual pyramid scores in mind.\\[20pt]

\begin{table}[!htbp]
\centering
\begin{tabular}{l|l}
\hline
\textbf{Method description}              & \textbf{Pyramid score} \\ \hline
Min ({[}1,2,4,8{]}); $ \alpha $ = 0.85   & \textbf{0.679249946}   \\ \hline
Min ({[}1,2,4,6,8{]}); $ \alpha $ = 0.85 & 0.6286947577           \\ \hline
Min ({[}1,4,8{]}); $ \alpha $ = 0.85     & \textbf{0.6690628106}  \\ \hline
Min ({[}1,4,6,8{]}); $ \alpha $ = 0.85   & \textbf{0.7151122733}  \\ \hline
Min ({[}1,3,4,6,8{]}); $ \alpha $ = 0.85 & 0.6593057212           \\ \hline
Min ({[}1,4,6,8{]}); $ \alpha $ = 0.9    & \textbf{0.7053210946}  \\ \hline
\end{tabular}

\caption{Evaluation scores for feature combinations with feature scaling }
\label{result2}

\end{table} 
\pagebreak
\section{Discussion \& Future work}
\begin{itemize}
\item We introduce new features to capture the notion of similarity between a pair of sentences in the citation context which we prove produces better results than the state-of-the-art system.
\item We develop a method to combine multiple feature similarity scores to obtain a single score for a pair of sentences. 
\item We fine-tune C-LexRank's graph to improve community detection by introducing the notion of a threshold which gives us better results than the previous system.
\item However we may be dealing with a situation of over-fitting which we intend to cross-verify using a neutral corpus of scientific documents in future.
\item We may shift to a non-factoid based evaluation scheme in future to be able to test the algorithm on a much larger dataset.
\item We also intend to perform the summarization on biomedical scientific documents to better understand medical conditions through a summarized time-line of research and development in the particular field.

\end{itemize}